- DOI: https://doi.org/10.1080/00207543.2020.1836419
  analysis: '>'
  authors:
  - Emiliano Traini
  - Giulia Bruno
  - Franco Lombardi
  citation_count: 30
  full_citation: '>'
  full_text: '>

    Access provided by University of Nebraska, Lincoln Log in  |  Register Cart Home
    All Journals International Journal of Production Research List of Issues Volume
    59, Issue 23 Tool condition monitoring framework for .... Search in:                                        This
    Journal                                                                                Anywhere                                                                  Advanced
    search International Journal of Production Research Volume 59, 2021 - Issue 23
    Submit an article Journal homepage Full access 1,478 Views 16 CrossRef citations
    to date 0 Altmetric Listen Articles Tool condition monitoring framework for predictive
    maintenance: a case study on milling process E. Traini , G. Bruno & F. Lombardi
    Pages 7179-7193 | Received 30 Jan 2020, Accepted 03 Sep 2020, Published online:
    02 Nov 2020 Cite this article https://doi.org/10.1080/00207543.2020.1836419 In
    this article ABSTRACT Introduction State-of-the-Art Problem definition Framework
    Use case Conclusion and future improvements Disclosure statement Additional information
    Footnotes References Full Article Figures & data References Citations Metrics
    Reprints & Permissions View PDF View EPUB Formulae display:? ABSTRACT In metal
    cutting processes, tool condition monitoring has a great importance to prevent
    surface damage and maintaining the quality of surface finishing. With the development
    of digitalisation and connection of industrial machines, it has become possible
    to collect real-time data from various types of sensors (e.g. vibration, acoustic
    or emission) during the process execution. However, information fusion from multiple
    sensor signals and tool health prediction still present a big challenge. The aim
    of this paper is to present a data-driven framework to estimate the tool wear
    status and predict its remaining useful life by using machine learning techniques.
    The first part of the framework is dedicated to sensor data preprocessing and
    feature engineering, while the second part deals with the development of prediction
    models. Different types of machine learning algorithms are used and compared to
    find the best result. A case study in a milling process is presented to illustrate
    the potentialities of the proposed framework for tool condition monitoring. KEYWORDS:
    Predictive maintenancetool condition monitoringmachine learningtool wear estimationremaining
    useful lifemilling Introduction Predictive Maintenance (PM), as alternative of
    traditional periodic maintenance policies, is a strategy to estimate future failures
    in the machine system and, through these estimations, to select the best type
    and time of maintenance to extend the useful life of a component. From the simple
    visual inspection of the machine, the failures prevention has evolved to automated
    methods that use traditional signal processing techniques and new Machine Learning
    (ML) methods. The maintenance strategy optimises a trade-off situation between
    maximising the useful life of a component and up-times through early replacement
    of this component (time-based PM), which has been demonstrated to be ineffective
    for most equipment components, considered as flawed and unreliable in recent years
    by Mobley ( 2002). PM aims to break these trade-offs by empowering companies to
    minimise maintenance by forecasting it ahead of time. Adoption of PM allows to
    maximise useful life of assets by reducing the frequency of maintenance activities,
    avoiding unplanned breakdowns, and eliminating unnecessary preventive maintenance.
    The improving in time and cost savings and the increasing in system reliability
    are so high that preventive maintenance has become one of the major areas of interest
    for companies and research (Dotoli et al. 2020). For a PM strategy, a Condition
    Monitoring (CM) system is necessary. As described in Hassan et al. ( 2018), CM
    is ‘the process of monitoring one or more parameters of machine to predict its
    potential faults early’. Especially for machining operations with cutting tools,
    such as milling and turning, one of the most important condition to monitor is
    the tool degradation. In fact, worn tools both have a negative effect on the quality
    of the workpiece and may damage the machining system (Martinez Arellano 2019).
    A good estimation of the tool status avoids the use of degraded tools that reduce
    the work surface quality and excessive preventive replacements, which involve
    higher costs and production time. The paradigm of Industry 4.0 proposes the digitalisation
    and the interconnection of machines, thus improving the possibilities of having
    a more effective condition monitoring, also by analysing the data coming from
    sensors (Żabiński et al. 2019). Among statistical inference-based methods, Machine
    learning (ML) approaches have been shown to provide increasingly effective solutions
    for tool condition monitoring and predictive maintenance (Patwardhan 2016; Zhang,
    Yang, and Wang 2019). ML techniques are most suitable especially when it comes
    to high-dimensional problems, such as those arising where multiple physical variables
    (e.g. pressures, voltages, currents) act on the process (Susto et al. 2015). The
    aim of this paper is to present a framework designed to monitor the status of
    the tool set on a generic machine tool, i.e. a machine used for metal cutting
    and surface finishing processes, based on ML techniques. Even if the term ‘Tool
    condition monitoring’ refers to the monitoring of different conditions of the
    tool (e.g. wear, breakage, did-not-cut condition, thread depth, damaged or missing
    threads), we limit our analysis to the prediction of wear and remaining useful
    life, as commonly done by previous works. The proposed framework can be applied
    to a generic machine tool for two main reasons: all types of wear of the tool
    consist in a loss of material that is measurable with standard methods; each wear
    type produces increasing cutting forces and temperatures to which the machine
    answers by varying the work status, measurable trough a standard set of sensors.
    This rest of the paper is structured as follows. The State-of-the-Art section
    gives an overview on the studies conducted in the context of tool condition monitoring
    for predictive maintenance. Problem definition section defines the addressed problem
    and provides the formal terminology for the concepts involved. The Framework section
    describes the proposed methodology for the analysis of data and the application
    of ML algorithm to perform the predictive maintenance. The Use case section presents
    the application of the framework to a milling process. Finally, in the last section,
    conclusions and future work perspectives are presented. State-of-the-Art Since
    industrial sensor networks are becoming a widespread data acquisition technology,
    a large amount of mechanical data can be collected with high reliability and in
    a real-time manner (Jiang, Yin, and Kaynak 2018). Due to the continuous improvement
    of data acquisition ability, as well as the exponential growth of data volume,
    data-driven methods for condition monitoring have achieved great success to provide
    information regarding the status of equipment (Li et al. 2017). Data-driven PM
    is an approach characterised by the three following phases: (i) data acquisition
    and preprocessing, (ii) feature engineering and (iii) model training for future
    predictions (Zhang, Yang, and Wang 2019). Our paper follows this approach as well.
    Data-driven PM has been extensively applied to industrial manufacturing using
    machine learning algorithms, such as logistic regression (LR), support vector
    machine (SVM), decision tree (DT) or random forest (RM), and neural networks (NN)
    (Zhang, Yang, and Wang 2019). However, previous works mainly addressed single
    type of sensor measurements, they are focused on one specific learning algorithm,
    and the majority of them used data from private experiments or generated from
    a simulator. Furthermore, few applications addressed the maintenance of cutting
    machines, since most works are related to fault detection of bearings or motors.
    In Caesarendra ( 2010), a logistic regression model is used to estimate failure
    degradation of bearing. Simulated data and experimental data download from a public
    site are used for validating the proposed method. Pandya, Upadhyay, and Harsha
    ( 2014) addressed the fault diagnosis of rolling element bearings by analysing
    the vibration signal. They compared the results of LR, SVM and ANN and stated
    that LR obtained the best results. Similarly, Ahmad et al. ( 2018) proposed a
    method to estimate the RUL of rolling element bearings by using dynamic regression
    models. Wu et al. ( 2017) presented a vibration-based monitoring method based
    on logistic regression for the online detection of punch failures. In Li et al.
    ( 2015), the acoustic emission signal is used to estimate the tool wear through
    a logistic regression model. The model was tested on a private data set generated
    from a milling machine. Yu ( 2018) proposed a method to predicts the remaining
    useful life (RUL) of tools by analysing acoustic and vibration signals. In Widodo
    et al. ( 2009), an approach to detect faults in bearings based on SVM is proposed,
    by analysing data from acoustic emission sensors and accelerometers. Other good
    performances of SVM classifiers were obtained by Shafi et al. ( 2018); Soualhi,
    Medjaher, and Zerhouni ( 2015), for fault perditions of vehicles and bearings,
    respectively. Li et al. ( 2015) developed a multimodal deep support vector classification
    model to diagnose the failure of a gearbox, and the performance was proven to
    outperform that of the basic SVM. Nieto et al. ( 2015) applied an SVM in a nonlinear
    model to predict the remaining life of aircraft engines. Some works also applied
    DT algorithm for predictive maintenance and condition monitoring. For instance,
    Krishnakumari et al. ( 2017) developed an algorithm to monitor the conditions
    of a spur gear and tested it on simulated data. Also Li et al. ( 2018) and Santos,
    Maudes, and Bustillo ( 2018) developed DT algorithms, the first one for a refrigerant
    flow system, and the second one for wind turbines. We found only one paper, which
    addressed the problem of predicting tool wear with DT in milling operations (Wu
    2017). Finally, a lot of works applied differ types of NN to detect faults. Artificial
    NN were applied for fault diagnosis of bearings (Prieto et al. 2013) and to estimate
    laser welding status (You, Gao, and Katayama 2015). Deep NN were applied to fault
    diagnosis of turbines gearboxes (Wang et al. 2017) and bearings (Jia et al. 2016).
    Table 1 summarises the main characteristics of the analysed papers. Table 1. Summary
    of the main characteristics of the analysed papers. Download CSVDisplay Table
    Other recent works on the topic include the ones proposed by Wang et al. ( 2019),
    Hajej et al. ( 2019) and Zhao et al. ( 2020). Differently from the previous works,
    which focused on more specific problems, the main aim of our paper is to define
    a formal framework for data-driven PM that can be applied to every CNC machine
    to support the tool replacement planning, as described in Xiao et al. ( 2020).
    To this aim, a great attention was firstly devoted to present a formal definition
    of variables and parameters applicable in the domain. Then, we focused on the
    development of an automatic data cleaning and feature manipulation procedure to
    preprocess the data from sensors before applying the machine learning algorithms.
    To the best of our knowledge, the proposed combination of data selection, outlier
    detection, feature extraction, feature normalisation and feature selection is
    a novelty with respect to the state of the art. Finally, different state-of-the-art
    machine learning algorithms were proposed to find the best estimate of tool wear
    and RUL. Here we limit the analysis to 5 algorithms, which are the most used,
    but new algorithms can be easily added to our framework. Differently also from
    most previous works, which used private or synthetic datasets, we decided to test
    our framework on a public real milling dataset, to allow the repeatability of
    the procedure and the comparison of the obtained results. A first version of this
    work, containing only a preliminary analysis of data, without the formal definition
    of the framework and with only a partial analysis of results, was described in
    Traini ( 2019). Problem definition This work considers manufacturing processes
    executed by machines with cyclical jobs, i.e. which can be monitored in a fixed
    defined time window. The observed manufacturing process regarding a tool i is
    modelled as a multivariate discrete time stochastic process { Y ( i ) } that takes
    into account | Y | variables, as described in Parzen ( 2015). Considering that
    on a machine can be set different tools, the manufacturing process regarding this
    machine is a ‘composed’ time stochastic process { Y ( i , j ) } , where the (
    i , j ) -th event refers to the j -th job carried out by the i -th tool, thus
    i , j ∈ Z . The variable Y y ( i , j ) is the y -th measurement describing the
    wear of the i -th tool after the j -th manufacturing activity. Note that the last
    job executed with the i -th tool is a stochastic variable indicated with N i .
    Tool wear and remaining useful life As the tool proceeds in the job execution,
    the various deterioration mechanisms, such as abrasion and plastic deformation,
    result in increasing levels of wear on the tool surface, and as consequence, in
    the reduction of its remaining useful life. The gradual wear can be divided into
    two basic types, corresponding to two regions in the cutting tool (Aslantas, Ucun,
    and Cicek 2012). Flank wear occurs on the relief face of the tool and it is measured
    by the width of the wear band V B . Crater wear consists of a cavity in the rake
    face of the tool that forms and grows from the action of the chip sliding against
    the surface and it can be measured either by its depth or its area. All the measures
    of wear are called direct measurements in Dan and Mathew ( 1990). Generally, wear
    mainly depends on (1) tool and work piece material, (2) tool geometry, (3) manufacturing
    parameters (cutting speed, feed rate and depth of cut), (4) type and level of
    lubrication and (5) machine-tool characteristics (Abolarin 2015). The monitoring
    of tool wear is important as the wear affects decreased accuracy of produced parts,
    poor surface finish, economics of cutting operations and decreased tool life.
    Tool wear is an important factor to estimate since it is not directly measurable
    without stopping the process and perform an inspection of the workpiece (Astakhov
    2007). The remaining useful life R U L ( i , j ) is the number of jobs still performable
    before the tool i , that carried out j jobs, does not respect quality parameters
    (Zhang et al. 2016). The useful life U L ( i ) is a stochastic variable referring
    to the number of jobs of the tool i before the one in which the tool exceeds quality
    limits. Let Y c the multivariate array referring to manufacturing quality limits
    for wear. Then, the remaining useful life can be defined as: R U L ( i , j ) :=
    U L ( i ) − j := U L ( i ) := argmax j > 0 ⁡ { Y ( i , j ) : Y ( i , j ) < Y c
    } − j . Note that the following situations may occur: N i > U L ( i ) , i.e. the
    case of a bad maintenance strategy, because the tool is used even if its useful
    life is finished, thus causing a decrease of product quality; N i = U L ( i )
    , i.e. the case of an optimal maintenance strategy, since the tool is changed
    exactly when needed; N i < U L ( i ) , i.e. the case of a too preventive maintenance
    strategy, since the tool is changed when it could have worked for one or more
    jobs. R U L ( i ) is another important factor to estimate since the theoretical
    values of tool durations may change depending on other parameters of the manufacturing
    processes which are not considered in the analytical models. Monitoring factors
    During a manufacturing process, different data can be acquired, which are called
    monitoring factors M ( i , j ) . Such factors can be divided in four sets: 1 M
    := P ∪ S ∪ T ∪ O = P 1 … P | P | ∪ S 1 … S | S | ∪ { t } ∪ O = P 1 … P | P | ∪
    ς 11 ⋮ ς w 1 … ς 1 | S | ⋮ ς w | S | ∪ { t } ∪ O where P is the set of production
    parameters P p with p = 1 , … , | P | , S is the set of time series measurements
    S s := { ς s } with s = 1 , … , | S | , T = { t } is a set that contain a single
    information about time and O is the set of all other factors not considered in
    this work but that can be considered in future papers. The value t = t ( i , j
    ) is the timestamp associated to each job and it is the only information about
    time, P p are the production parameters associated to the job, and the vectors
    S s are the time series of signals registered during each job. The production
    parameters set P ( i , j ) := { P p ( i , j ) : p = 1 , … , | P | } is the set
    of production conditions under whom the machine carries out a manufacturing process
    and its size it is considered constant for any values of ( i , j ) . This set
    groups all the information used to control a standard CNC machine tool. The time
    series measurements in the set S ( i , j ) := { S s ( i , j ) : s = 1 , … , |
    S | } are time series data, i.e. for each sensor s is S s ( i , j ) := { ς s (
    i , j , τ ) : τ = 1 , … , w } , where the number of sensors | S | is considered
    constant for each ( i , j ) . Without loss of generality, in this paper it is
    assumed that the sampling size w and the sampling frequency, i.e. the distance
    between two consecutive sensor acquisition ς s ( i , j , τ ) and ς s ( i , j ,
    τ + 1 ) , are constant for each ( i , j ) . This mean that we consider manufacturing
    processes of the same type, or at least with a similar nominal duration, which
    allow to use a single width w for all the measurement windows. According to Hashemian
    and Bean ( 2011) and Dimla Snr. ( 2000), the time series measurements set is composed
    by data related to tool vibration, table vibration, ambient humidity, ambient
    temperature, tool temperature, table temperature, ambient pressure, tool acoustic
    signal, table acoustic signal, spindle motor alternative current and spindle motor
    direct current. Model estimation The monitoring factors M ( i , j ) collected
    during the manufacturing process are transformed into a set of predictors 2 X
    ( i , j ) , through data fusion and feature extraction techniques (Haghighat,
    Abdel-Mottaleb, and Alhalabi 2016). The models F T C M and F R U L were built
    with a supervised machine learning techniques (Hasti, Tibshirani, and Friedman
    2009) using a training set (subset of tools defined as i ∈ I T R ) and a test
    set (defined as i ∈ I T E S T ). For i ∈ I S U P = I T R ∪ I T E S T , the real
    values of Y and RUL are a-priori known. Figure 1 shows the procedure for the estimation
    of the wear and remaining useful life of a tool i ∗ after the end of its j ∗ -th
    job, using the two models built with the set of historical data, i.e. Y ˆ ( i
    ∗ , j ∗ ) = F T C M ( X ( i ∗ , j ∗ ) ) and R U L ˆ ( i ∗ , j ∗ ) = F R U L (
    Y ˆ ( i ∗ , j ≤ j ∗ ) ) . Figure 1. General description of the framework considering
    all the tools using for the training, validation, testing and estimation activities.
    Display full size Framework This section introduces the framework to transform
    the monitoring factors M in features X and their use to estimate Y and R U L .
    As shown in Figure 2, the processing phase of the monitoring factors is divided
    into two phases: (1) measurement pre-processing and (2) feature manipulation.
    The first phase analyses the monitoring factors M to validate and clean data,
    especially the ones coming from sensors, thus providing the pre-processed M ′
    factors. The second phase analyse in detail the S factors: each of them is summarised
    and normalised, and then only the most significant ones are kept for building
    the prediction models. The details of each phase are reported in the following
    paragraphs. Figure 2. Scheme of the framework from the data acquisition until
    the estimation of wear and remaining useful life. Display full size Measurement
    pre-processing The pre-processing of measurements is composed by two steps: data
    validation, i.e. the analysis of each sensor output to identify outliers and wrong
    values; stationary window selection, i.e. the selection of a sub-window W that
    is the best selection of s j referring to instants in which the machine is used
    in a process. At the end of this phase, the monitoring factors M becomes M ′ =
    [ t , P ′ , S ′ ] . Data validation Data validation is defined as ‘an activity
    aimed at verifying whether the value of a data item comes from the given (finite
    or infinite) set of acceptable values’ (Europe 2000). The data validation of production
    values consists in checking that the processing parameters are in the machine''s
    own domains. The data validation for each time series S s = { s j } is based on
    two process: (1) removal of data that exceed fixed extreme values for the sensor
    and (2) time series outlier detection. First, if exist a τ ∈ [ 1 , w ] such that
    ς s ( i ∗ , j ∗ , τ ) ∉ D s , where D s is the domain of the s -th sensor defined
    with human knowledge and physical limits of the recorder device, ς s ( i ∗ , j
    ∗ , τ ) is removed. For the outlier detection it is necessary to consider two
    steps: (1) a between and (2) a within time series outlier detection. The first
    one is used to decide whether or not to apply the second one to a particular time
    series, in order to decrease the risk of removing extreme signals s s ( i ∗ ,
    j ∗ , τ ) that express a growing of instability during the process. The between
    outlier detection is performed on standard deviations { σ s ( i , j ) } i ≤ i
    ∗ , j ≤ j ∗ referring to the same sensor s to check if σ s ( i ∗ , j ∗ ) is an
    outlier value or not. It is used the classical outlier detection based on the
    Interquartile Rule for Outliers, explained in Upton and Cook ( 1996), where the
    interquartile range (IQR) is multiplied for k I Q R = 1.5 . If σ s ( i ∗ , j ∗
    ) results an outlier, the same outlier detection method is applied on the set
    S s ( i ∗ , j ∗ ) and all the outliers, identified by τ values, are removed. After
    this filtering, the time series S s ( i ∗ , j ∗ ) is maintained if | S s ( i ∗
    , j ∗ ) | > k w o u t ⋅ w and σ s ( i ∗ , j ∗ ) > k σ o u t ⋅ σ ¯ s , where σ
    ¯ s is the average standard deviation over all the time series of the same s -th
    sensor and k w o u t and k σ o u t are two arbitrary cutting parameters. A missing
    s s ( i , j , τ ) value is not considered influent for the Feature manipulation.
    Differently, the case of missing time series S s is discussed in Missing values
    and feature normalisation. Stationary window selection For each S s ( i ∗ , j
    ∗ ) ∈ S ( i ∗ , j ∗ ) , the stationary window selection is the selection of a
    sub-time series S s ′ ( i ∗ , j ∗ ) ⊆ S s ( i ∗ , j ∗ ) referred to stationary
    phase of the machine activity. For this purpose, a Change Point Detection (CPD)
    technique is used, i.e. a technique to identify instants in which the probability
    distribution of a time series changes, as explained in Ross, Tasoulis, and Adams
    ( 2011) and Ross and Adams ( 2012). In each S s ( i , j ) there are measurements
    describing different phases of the machine: the available phase in which the machine
    is on but not working, the start and the end of processing and the stationary
    phase that is in the middle of them. To do this a multiple CPD is run on each
    signal, obtaining multiple subseries of S s ( i , j ) . The stationary subseries
    is the one with maximum value for the average, in the case of non-negative asymmetric
    signals a(e.g. the direct current), or for the standard deviation, in the case
    of symmetric signals (e.g. the alternating current). Feature manipulation The
    feature manipulation used to transform the pre-processed sensor set M ′ in a set
    of predictors X is composed by three steps: Feature extraction, to summarise sensor
    measurements with several statistics; Missing values and feature normalisation,
    to clean and normalise the data; Feature selection, to select only the most significant
    features for building the estimation models. After this section the predictor
    set will be X = [ X 1 , … , X | X | ] = [ t , P , φ ( X s ) ] , where X s is the
    output set of the Feature extraction. The one-dimensional feature set X s of size
    s ⋅ n s (the number of features obtained from each sensor is considered constant
    and equal to n s ) is preferred to the time series set S considered as a one-dimensional
    set { S 1 ( i , j ) , … , S | S | ( i , j ) } = { ς 1 ( i , j , 1 ) , ς 1 ( i
    , j , 2 ) … , ς 2 ( i , j , 1 ) , … } of size s ⋅ w , being n s ≪ w . Feature
    extraction When performing analysis of complex data, one of the major problems
    is dealing with the high number of data involved. The purpose of feature extraction
    is to reduce the initial set of measured data, by extracting only the essential
    and explanatory features, thus simplifying the subsequent learning phases (Alpaydin
    2014). The quality and quantity of features are key determinants which highly
    affect the result of the prediction. As proposed by Zhang et al. ( 2016), the
    feature extracted belong to the following three types: time domain, frequency
    domain and polynomial regression coefficients. Thus, the set S is transformed
    in the set X s = X t ∪ X f ∪ X r . Time domain statistics. Feature extraction
    in time domain allows to evaluate the magnitude of the signal. It consists in
    collecting a set of statistics X t = { X k t : k = 1 , … , n t } that describes
    the stationary time series S s . Examples of time domain feature are maximum value,
    mean value, root mean square, standard deviation, Skewness, Kurtosis, peak-to-peak
    and crest factor. Time domain features are important, but they only reflect the
    signal changes over time. For this reason, frequency domain features need to be
    extracted too. Frequency domain statistics. The frequency-domain, deeply analysed
    in Stoica and Moses ( 2005), is the power spectrum of the stationary time series
    S s and it describes the distribution of power into frequency components composing
    S s . The signal digitised as a time series can be converted in the frequency
    domain by using the Discrete Fourier Transformation (DFT) applicable to finite
    sequences of equally spaced samples and statistics are calculated on module and
    argument of the complex outputs of the DFT. Zhang et al. ( 2016) gives another
    list of statistics of band power spectrum: maximum, sum, mean, standard deviation,
    Skewness, Kurtosis, and relative spectral peal. The feature subset extracted from
    the power spectrum of the time series S s is X f = { X k f : k = 1 , … , n f }
    . Time polynomial regression coefficients. Finally, the last feature extraction
    technique consists in a forward selection procedure to select a n r -grade polynomial
    regression S ˆ s ( π ) = ∑ k = 0 n r X k r π k of the time domain series S s with
    a fixed maximum degree n r m a x , considering not only the stationary phase but
    all the time series. The coefficients of this regression polynomial are considered
    as a subset of features: X r = { X k r : k = 0 , … , n r } ∪ O ( n r m a x − n
    r ) , where O k is a zero array of cardinality equal to k . Missing values and
    feature normalisation Once the most relevant features are extracted, they need
    to be cleaned and normalised before being used to develop the prediction model.
    Data cleaning is performed by managing mission values, while the normalisation
    is used to standardise the ranges of the features. Missing values. There are two
    types of missing values subsets: a set { s s ( i , j , τ ) } of measurements of
    a sensor and a full missing output of a sensor. The first do not affect this part
    because it was sufficient not considering them for statistics calculation in Feature
    extraction (their cardinality is not significant compared to the size w of the
    time series window). The missing sensor output S s ( i ∗ , j ∗ ) is equivalent
    to a missing feature set { X 1 ( i ∗ , j ∗ ) , … , X n s ( i ∗ , j ∗ ) } related
    to the same s -th sensor. Values of the elements of this set are estimated according
    three cases: if j ∗ ≥ 3 , for each missing values X x ( i ∗ , j ∗ ) with x = 1
    , … , n s , predictors X x ( i ∗ , j < j ∗ ) are considered as a time series with
    which forecast the value of the feature X x ( i ∗ , j ∗ ) : in this work a linear
    regression is used to estimate X ˆ x ( i ∗ , j ∗ ) . if j ∗ = 2 , it is X ˆ x
    ( i ∗ , 2 ) = X x ( i ∗ , 1 ) ; if j ∗ = 1 , X ˆ x ( i ∗ , 1 ) is the mean of
    the X x referred to first jobs of old tool, i.e. X ˆ x ( i ∗ , 1 ) = m e a n i
    < i ∗ { X x ( i , 1 ) } . Feature normalisation. Data normalisation is used to
    improve the overall quality of a data avoiding situations in which some values
    over-weighting others. A general choice for the normalisation is a Min–Max normalisation,
    according to the work of Al Shalabi, Shaaban, and Kasasbeh ( 2006). Feature selection
    The goal of this step is to reduce the dimension of the feature set, in order
    to both save training time and minimise the overfitting risk (Kumar and Minz 2014).
    The feature selection presented in this work is completely unsupervised (i.e.
    executed without considering target variables), except for an off-line supervised
    ranking: to each predictor X x is associated a correlation index ρ x Y that is
    equals to the mean value of the Pearson’s Correlation Coefficients between the
    array X x (limited by i ∈ I S U P ) and all the components of Y . The proposed
    feature selection methods are: (1) removing features with a low coefficient of
    variation, (2) selection by correlation between features, (3) selection by hypothesis
    testing, (4) selection by monotonicity and prognosability. Other methods could
    be the selection by trendability or multicollinearity analysis. In the first step,
    for each feature the coefficient of variation C V x is calculated and, if it is
    C V x < C V x m i n , the x -th feature is no longer considered. This is to remove
    constant or low variability features, i.e. according (Hopp and Spearman 2011),
    the choice of the cutting value must be C V x m i n ∈ [ 0 , 0.75 ] . In the second
    step, the correlation ρ x 1 x 2 between each couple of features ( X x 1 , X x
    2 ) is calculated and if | ρ x 1 x 2 | > ρ X m a x the feature with minimum value
    of ρ x Y is no longer considered (it is ‘the feature less affecting the target
    variable’). With the hypothesis testing it is check if the feature has a significant
    (based on the choice of α ) impact on the answer variable. Finally, as explained
    in Coble and Hines ( 2009), an ideal prognostic feature has two quality: monotonicity
    and prognosability. These parameters are calculated for each feature and a weighted
    average of them is compared to a minimum value: features with average lower than
    this value are removed. Tool condition and remaining useful life estimation In
    this section the design of the model F T C M and F R U L is presented. The model
    for the Tool Condition estimation trains in a supervised manner with the supervised
    historical data { X ( i ) : i ∈ I S U P } of previous tools given by sensors and
    experts. After that, it estimates Y ( i ∗ , j ∗ ) with the feature set X ( i ∗
    , j ∗ ) . The model F R U L estimates R U L ( i ∗ , j ∗ ) . This model does not
    estimate R U L ( i ∗ , j ∗ ) if j ∗ = 1 . If j ∗ ≥ 2 and Y ˆ ( i ∗ , j ∗ ) ≥ Y
    c r i t i c , for definition R U L ˆ ( i ∗ , j ∗ ) = 0 . If j ∗ ≥ 2 and Y ˆ (
    i ∗ , j ∗ ) < Y c r i t i c , the coefficients of the linear regression Y ˆ (
    i ∗ , j ≤ j ∗ ) = α 0 + α 1 j + ϵ ( i ∗ , j ∗ ) are fitted on the estimated values
    of wear Y ˆ ( i ∗ , j ≤ j ∗ ) related to the tool i ∗ ( ϵ is the normal error
    of the regression). Using these parameters future values of wear Y ˆ ( i ∗ , j
    > j ∗ ) are predicted and the useful life of the tool i ∗ is estimated as U L
    ˆ ( i ∗ , j ∗ ) := min j ⁡ { j > j ∗ | Y ˆ ( i ∗ , j ) ⟩ Y c r i t i c } − 1 .
    From definition, R U L ˆ ( i ∗ , j ∗ ) = U L ˆ ( i ∗ , j ∗ ) − j ∗ . The ML algorithms
    implemented in our framework are the following: Linear Regression (LR), Bayesian
    Linear Regression (BLR), Decision Forest (DF), Boosted Decision Tree (BDT) and
    Neural Network (NN). We selected these algorithms because they are the most used
    in literature (Abellan-Nebot and Romero Subirón 2010 and Ali 2015). Linear Regression
    (LR) is a linear model, e.g. a model that assumes a linear relationship between
    the input variables and the single output variable. Bayesian Linear Regression
    (BLR) is an approach to linear regression in which the data are supplemented with
    additional information in the form of a prior probability distribution. When the
    regression model has errors that have a normal distribution, and if a particular
    form of prior distribution is assumed, explicit results are available for the
    posterior probability distributions of the model''s parameters. In the Use case
    section, we specified the family of distribution, the a priori coefficients and
    the a priori covariance matrix. Decision Forest (DF) and Boosted Decision Tree
    (BDT) consist of a forest and a set of decision trees. The Neural Network (NN)
    is a method composed by artificial neurons. It receives external on a layer of
    input nodes (processing units), each of which relates to numerous internal nodes,
    organised in several layers. Each node processes the received signals and transmits
    the result to subsequent nodes until the output ones. During the training activity,
    a K-fold cross validation procedure is used to avoid the overfitting: the training
    set is split into K smaller sets of the same size; then, for each of the K folds,
    the model is trained using the data of K-1 folds as training set and it is validated
    on the data of the remaining fold. The final performance measure of the model
    is then the average of the K obtained performance. Use case We applied the framework
    to analyse a public Milling Data Set (Agonino and Goebel 2007, NASA n.d.). This
    data set is the result of an experiment in which six different sensors are adopted
    to capture signals related to the manufacturing process of a milling machine.
    The flank wear is measured at the end of each milling activity, while sensors
    continued to collect data. The experiment is designed by Agonino and Goebel (
    2007) in the Prognostic Center of Excellence (NASA-PCoE) and it includes information
    about 16 milling processes (cases) with different number of runs. The experiment
    has been carried out by employing the Matsuura machining centre MC-510 V, a CNC
    vertical milling machine equipped with a face milling cutter with six insets.
    The dimensions of the workpiece are 483 × 178 × 51 mm. The cutting speed is set
    to 200 m / min . A 70 mm face mill with 6 inserts was chosen as the tool. The
    inserts KC710 was selected based on the recommendations for roughing. KC710 is
    coated with multiple layers of titanium carbide, titanium carbonitride, and titanium
    nitride (TiC/TiC-N/TiN) in sequence. These layers retain the toughness of tungsten
    carbide but have improved resistance to cratering and edge wear. At the same time,
    they have the advantage of titanium carbide plus reduced face friction. The design
    of the experiment involves three production parameters: (1) workpiece material,
    (2) feed rate and (3) depth of cut. Particularly, the investigated materials were
    cast iron and stainless steel 145, the feed was set to 0.25 mm/s or 0.5 mm/s and
    the depth of cut (DOC) was set to 0.75 mm or 1.5 mm. The choice of parameters
    was guided by industrial applicability and recommended manufacturer’s settings.
    The Flank wear was computed as the distance from the cutting edge to the end of
    the abrasive wear on the flank face of the tool. After each run of the experiment,
    the insert was taken out of the tool and the wear was measured by a microscope.
    Flank wear is the most commonly observed and unavoidable phenomenon in metal cutting,
    which is also a major source of economic loss resulting due to material loss and
    machine down time, thus it is a generally accepted parameter for evaluating tool
    wear (Siddhpura and Paurobally 2013). The list of the 16 cases analysed and the
    corresponding parameter values are summarised in Table 2. For each case, the number
    of milling activities (runs) executed with the tool is also reported. In each
    run of each case, six sensor measurements were collected: the alternate and the
    direct motor currents (smcAC and smcDC), the vibrations and the acoustic emissions
    of the table and of the spindle (vib_table, vib_spindle, AE_table and AE_spindle).
    Thus, the cardinality of the time series set S is six ( | S | = 6 ). For all the
    sensor the size of the window of the time series is w = 9000 samples? Since the
    total number of runs is 170, the total number of signals recorded is 1020. Table
    2. Values of production parameters for the 16 milling processes of the use case.
    Download CSVDisplay Table Framework application The steps described in the previous
    section were applied to the use case dataset. All the analyses were conducted
    with the free software environment R (R Foundation). Data validation For the data
    validation, we used the domain ( 0 , + ∞ ) for all the sensors except the alternate
    motor current for which it was set to ( − ∞ , + ∞ ) , that are all the possible
    values that physical quantity can theoretically reach. We checked the time series
    data and we found that no one of them exceeded the fixed thresholds, thus all
    data are acceptable. The outlier detection identified 33 signals as outliers,
    over the total of 1020 signals recorded. The 33 outliers are reported in Figure
    3 on six rows, one for each type of sensor. For example, for the alternate motor
    current, three signals were detected as outliers, the 18th (corresponding to the
    first run of the 2 s case), the 95th (corresponding to the first run of the eleventh
    case), and the 115th (corresponding to the 21 run of the eleventh case). For the
    direct motor current, two signals were detected as outliers, again the 18th and
    the 95th. As it is clear from the figure, it appears that if the signal collected
    in a specific run by a sensor is an outlier, also the signals collected by the
    other sensors at the same time may be outliers. After the application of the outlier
    detection procedure, which removed the data considered as outliers, only the four
    signals related the 95-th measurements were removed. For the other measurements,
    the result of the outlier detection is shown in Figure 4. Figure 3. Sensor measurements
    identified as outlier to be processed. Display full size Figure 4. Sensor measurement
    after data validation. Display full size Stationary window selection For the stationary
    window selection, the cpm-package for R develop by (Ross 2015) is used. For the
    identification of the first change point a the function detectChangePointBatch
    is used with a confidence level α = 0.1 % . The method used for the change point
    detection are the Bartlett test statistic for the alternating current and the
    Generalised Likelihood Ratio test for the other sensors. In Figure 5, an example
    of the data change points identification on the six sensors measurements is shown.
    Figure 5. Stationary window selection applied on milling dataset. Display full
    size Feature extraction The three types of features (i.e. time domain statistics,
    frequency domain statistics and polynomial regression coefficients) were extracted
    from each sensor measurement. The statistics over time domain are the following:
    (1) maximum, (2) minimum, (3) mean, (4) standard deviation, (5) root mean square,
    (6) skewness, (7) Kurtosis and the (8) crest factor. The statistics over frequency
    domain are calculated on the module and the argument of the complex outputs of
    the fftw package of R introduced in Frigo and Johnson ( 2005), and they are the
    following: (1) maximum, (2) minimum, (3) mean, (4) standard deviation, (5) Skewness,
    (6) Kurtosis and the (7) Relative Spectral Peak per Band. Finally, the coefficient
    of regression polynomial with maximum degree d m a x = 5 are computed, starting
    from the constant polynomial S ˆ s 0 ( π ) = X 0 . In each k ∗ -th iteration the
    new polynomial S ˆ s k ∗ ( π ) = ∑ k = 0 k ∗ X k r π k is considered, until finding
    the first k m a x -th iteration in which the p-value referred to the maximum degree
    X k m a x is greater than a fixed confidence level α = 5 % . Summarising, the
    number of features extracted from each sensor is | X s | = s ⋅ ( | X t | + 2 ⋅
    | X f | + | X r | ) = 6 ⋅ ( 8 + 2 ⋅ 7 + 5 ) = 162 . Missing value and feature
    normalisation A total of 22 missing values was detected. They were estimated as
    explained in the previous section. For the normalisation, the Min–Max strategy
    was used, e.g. a linear transformation of each value X x in a new value in [ 0
    , 1 ] . Feature selection After the application of the feature selection phase,
    with a minimum coefficient of variance C V x m i n = 0.25 , α = 0.1 for the hypothesis
    test and weights of 0.8 and 0.2 respectively for the monotonicity and the prognosability,
    a total of 105 features were removed. Note that for the monotonicity the following
    formula for the i -th tool was used: m o n o t o n i c i t y i = 1 N i − 1 | n
    > , i − n < , i | where n > , i = n . o f { ( 1 + p ) X ( i , j ) ≥ X ( i , j
    − 1 } , i.e. the number of increments that are fuzzily positive, and n < , i =
    n . o f { ( 1 + p ) X ( i , j ) < X ( i , j − 1 } , i.e. the number of increments
    that are fuzzily negative with p = 0.25 . Since the small size of the dataset
    made it impossible to evaluate the trendability, we assign the following values:
    a = 0.8 , b = 0.2 and c = 0 . The greater weight for monotonicity compared to
    prognosability is due to two reasons: (1) the small sizes of the dataset (only
    two repetitions for the same scenario with a case with one repetition) do not
    allow a low variability in the initial data compared to measurements close to
    tool wear to be observed; (2) compared to the size of the dataset there are a
    lot of data missing in the first run of the tool and in this way a large part
    of the prognosability is calculated on estimated data. Tool condition and remaining
    useful life estimation To test the stability of the algorithm the training set
    and the test set are resample 10 times and each times the performances of all
    the algorithms are calculated. The training set is composed by all data related
    to 12 tools while data of 3 tools are used as test set. In this way, we tested
    the ability of the algorithms to predicting wear of new tools. The linear model
    is performed using the classical module lm() in R. The BLR, instead, is performed
    using the function stan_glm() with the gaussian family. For the decision random
    forest method, the library randomForest is used as a regression module with the
    default number of 500 trees. For the BLR the method trainControl is used with
    a number of resampling equal to 20 and with a linear regression method. The same
    function is used for the neural network to optimise the training activity of the
    function nnet: the method for the resampling is ‘cv’ and the number of resampling
    is 4, while in the function nnet the parameters are size equals to 1, decay to
    0.01 and maxit to 2000. Figure 6 reports the results obtained by the 5 algorithms
    analysed. NN outperformed the other methods by obtaining the lowest error rates
    with a simple structure with 10 hidden nodes for each of the 3 layers. Figure
    7 shows the comparison between the real data and the data estimated by the NN
    for the tools 14, 15 and 16. Figure 6. Performances of ML methods according to
    root-mean square error and root relative squared error. Display full size Figure
    7. Comparison between test data and estimated values for wear. Display full size
    The Figure 8 shows the result obtain for the prediction of the remaining useful
    life of the tool. Figure 8. Comparison between testing data and estimated ones
    for the remaining useful life. Display full size The results obtained by our framework,
    i.e. the prediction tool wear and RUL, can directly improve the man-machine collaboration
    in production. In fact, the final aim of our work is to develop a web application
    as the one shown in Figure 9, in order to support operators in knowing the actual
    state of the tools and help them in taking decisions regarding tool changes. Figure
    9. An example of a web application exploiting the results of our framework. Display
    full size Conclusion and future improvements The main aim of this work is to define
    a general framework to apply the predictive maintenance to a generic manufacturing
    tool. Particularly, the framework is applicable in all the cases in which the
    manufacturing process is characterised by a set of production parameters and is
    monitored through a set of analogue sensors. An important consideration regarding
    the feature selection must be done. This part of the framework is used to optimise
    the computation time for ML algorithms, but it can be also used to minimise the
    number of sensors needed for monitoring and the features extracted by the signals.
    For example, in our case study, the results showed that the same performance can
    be reached without using the alternative current sensor and without working in
    the frequency domain to analyse signals of the other five sensors. Despite the
    theoretic applicability of our framework, on important limitation of this methodology
    is that the results strongly depend on the amount of data used to train the model.
    This fact also affects the performance results of the model. This limitation can
    be solved by attempting to collect data from different machines, by varying a
    different number of parameters, and add more types of sensors and data sources
    (e.g. noise, temperature, etc.). Another limitation consists of the measure of
    only flank wear. Even if is the most commonly parameter used to evaluate the tool
    wear, other types of wear can occur (e.g. built-up edge, plastic deformation,
    chipping, notch wear, and thermal cracks). Future improvements of the work will
    follow three directions. The first regards the improvement of the dataset. As
    pointed out by other previous works, the main problem in these kinds of works
    is the lack of data coming from real environments. Thus, more types of tools need
    to be considered, with different production parameters and different tool paths
    depending on the part programme. Another improvement of the dataset will consider
    the use of more sensors, even with different data format, e.g. thermal camera
    and others introduced in Hashemian and Bean ( 2011) and Dimla Snr. ( 2000). A
    larger set of sensors would allow an additional analysis of the search for the
    optimal sensor set by also considering the technology costs during the feature
    selection phase. The second direction will be the extension of the framework improving
    the maintenance strategy and using the results to improve the tool warehouse management
    and the supply planning. The goal is to optimise the production planning and the
    maintenance activity, as proposed by Zhou, Zhu, and Yu ( 2020), by also considering
    batch production, as done by Huang, Wang, and Jiang ( 2020), and minimising the
    energy consumption, as in Hajej and Rezg ( 2020). Finally, the last direction
    regards the improvements of the framework. In fact, all the previous features
    related to the same tool can be used to predict the actual wear level. This means
    considering a set of features with time depending sizes and this can be managed
    by extract trends or weighted statistics or developing an algorithm able to receive
    different number of inputs. Another idea is to use a-priori defined or fitted
    distributions f a , f b u s y and f b for the manufacturing window selection.
    Also a quantitative evaluation about the size of the training set necessary to
    obtain acceptable performance could be carried out. Disclosure statement No potential
    conflict of interest was reported by the author(s). Additional information Funding
    Ministero dell''Istruzione, dell''Università e della Ricerca, Grant/Award Number:
    TESUN‐83486178370409 finanziamento dipartimenti di eccellenza CAP. 1694 TIT. 232
    ART. 6. Notes on contributors E. Traini Emiliano Traini is a PhD student in Management,
    Production and Design at the Department of Management and Production Engineering,
    Politecnico di Torino, Italy. He holds a bachelor''s degree in Mathematics for
    Engineering and a master''s degree in Mathematical Engineering. His research interests
    include AI-related topics in the field of manufacturing. G. Bruno Giulia Bruno
    received a M.Sc. degree in Computer Engineering and a Ph.D. in Computer and System
    Engineering from Politecnico di Torino. She is currently Assistant Professor of
    Manufacturing Technologies and Systems in the Department of Management and Production
    Engineering of Politecnico di Torino. Her research activity is mainly focused
    on lean production, process modeling, data analysis and simulation of production
    systems. F. Lombardi Franco Lombardi is Full Professor of Manufacturing Technologies
    and Systems at Politecnico di Torino. He contributed to various national and international
    research projects on High Speed Cutting, Product Quality, CAE/CAPP tools development,
    FMS modelling and evaluation, Artificial Neural Networks, authoring several scientific
    papers. From 2009 to 2014 he was appointed Vice Rector for Academy and Science
    at Turin Polytechnic University in Tashkent (Uzbekistan). Since 2014 he is a member
    of the Academic Senate of the Politecnico di Torino. Notes 1 In this work the
    dependency of stochastic variables on (i, j) is often implied, i.e. M=M (i, j).
    2 The term predictor is used as synonymous of independent variable, regressor,
    covariate, feature or input variable (Dodge 2003). References Abellan-Nebot, J.
    V., and F. Romero Subirón 2010. “A Review of Machine Monitoring Systems Based
    on Artificial Intelligence Process Models.” The International Journal of Advanced
    Manufacturing Technology 47: 237–257.  Web of Science ®Google Scholar Abolarin,
    M. S., O. O. Ayodeji, J. Jonathan, and P. S. Olaoluwa. 2015. “Effect of Cutting
    Speed and Feed Rate on Tool Wear Rate and Surface Roughness in Lathe Turning Process.”
    International Journal of Engineering Trends and Technology (IJETT) 22(4): 173–175.  Google
    Scholar Agonino, A., and K. Goebel. 2007. Milling Dataset. arc.nasa: http://ti.arc.nasa.gov/project/prognostic-data.  Google
    Scholar Ahmad, W., Sheraz AliKhan, M. M. ManjurulIslam, and Jong-Myon Kim. 2018.
    “A Reliable Technique for Remaining Useful Life Estimation of Rolling Element
    Bearings Using Dynamic Regression Model.” Reliability Engineering & System Safety
    184: 67–76.  Web of Science ®Google Scholar Ali, J. B. 2015. “Application of Empirical
    Mode Decomposition and Artificial Neural Network for Automatic Bearing Fault Diagnosis
    Based on Vibration Signals.” Applied Acoustics 89: 16–27.  Web of Science ®Google
    Scholar Alpaydin, E. 2014. Introduction to Machine Learning, 3rd edition. London:
    MIT Press.  Google Scholar Al Shalabi, L., Z. Shaaban, and B. Kasasbeh. 2006.
    “Data Mining: A Preprocessing Engine.” Journal of Computer Science 735: 739.  Google
    Scholar Aslantas, K., I. Ucun, and A. Cicek. 2012. “Tool Life and Wear Mechanism
    of Coated and Uncoated Al2O3/TiCN Mixed Ceramic Tools in Turning Hardened Alloy
    Steel.” Wear 274–275: 442–451.  Web of Science ®Google Scholar Astakhov, V. P.
    2007. “Effects of the Cutting Feed, Depth of cut, and Workpiece (Bore) Diameter
    on the Tool Wear Rate.” The International Journal of Advanced Manufacturing Technology
    34: 631–640.  Web of Science ®Google Scholar Caesarendra, W. W. 2010. “Application
    of Relevance Vector Machine and Logistic Regression for Machine Degradation Assessment.”
    Mechanical Systems and Signal Processing 24 (4): 1161–1171.  Web of Science ®Google
    Scholar Coble, J., and J. W. Hines. 2009. “Identifying Optimal Prognostic Parameters
    From Data: A Genetic Algorithms Approach.” Annual Conference of the Prognostics
    and health management Society 2009.  Google Scholar Dan, L., and J. Mathew. 1990.
    “Tool Wear and Failure Monitoring Techniques for Turning—A Review.” International
    Journal of Machine Tools and Manufacture 30: 579–598.  Web of Science ®Google
    Scholar Dimla Snr., D. E. 2000. “Sensor Signals for Tool-Wear Monitoring in Metal
    Cutting Operations—a Review of Methods.” International Journal of Machine Tools
    & Manufacture 40: 1073–1098.  Web of Science ®Google Scholar Dodge, Y. 2003. The
    Oxford Dictionary of Statistical Terms. Oxford: Oxford University Press.  Google
    Scholar Dotoli, M., A. Fay, M. Miskowicz, and C. Seatzu. 2020. “An Overview of
    Current Technologies and Emerging Trends in Factory Automation.” Internationl
    Journal of Production Research 57: 5047–5067.  Web of Science ®Google Scholar
    Europe, U. N. 2000. Glossary of Terms on Statistical Data Editing. Geneve: United
    Nations.  Google Scholar Frigo, M., and J. G. Johnson. 2005. “The Design and Implementation
    of FFTW3.” IEEE, 216–231.  Google Scholar Haghighat, M., M. Abdel-Mottaleb, and
    W. Alhalabi. 2016. “Recognition, Discriminant Correlation Analysis: Real-Time
    Feature Level Fusion for Multimodal Biometric.” IEEE Transactions on Information
    Forensics and Security 11: 1984–1996.  Web of Science ®Google Scholar Hajej, Z.,
    R. Nidhal, C. Anis, and M. Bouzoubaa. 2019. “An Optimal Integrated Production
    and Maintenance Strategy for a Multi-Wind Turbines System.” International Journal
    of Production Research.  PubMed Web of Science ®Google Scholar Hajej, Z., and
    N. Rezg. 2020. “An Optimal Integrated lot Sizing and Maintenance Strategy for
    Multi-Machines System with Energy Consumption.” International Journal of Production
    Research 58 (14): 4450–4470.  Web of Science ®Google Scholar Hashemian, H. M.,
    and W. C. Bean. 2011. “State-of-the-Art Predictive Maintenance Techniques.” IEEE
    Transactions on Instrumentation and Measurement 60: 3480–3492.  Google Scholar
    Hassan, S., M. M. Tahir, S. Badshah, and A. Hussain. 2018. “Classification of
    RigiD Rotor Faults Using Time Domain Feature Extracted From Multiple Vibration
    Sensors.” Technical Journal 23: 43–52.  Google Scholar Hasti, T., R. Tibshirani,
    and J. H. Friedman. 2009. The Elements of Statistical Learning: Data Mining, Inference,
    and Prediction. New York: Springer.  Google Scholar Hopp, W. J., and M. L. Spearman.
    2011. Factory Physics. Long Grove: Waveland Press.  Google Scholar Huang, J.,
    L. Wang, and Z. Jiang. 2020. “A Method Combining Rules with Genetic Algorithm
    for Minimizing Makespan on a Batch Processing Machine with Preventive Maintenance.”
    International Journal of Production Research 58 (13): 4086–4102.  Web of Science
    ®Google Scholar Jia, F., Yaguo Lei, Jing Lin, Xin Zhou, and Na Lu. 2016. “Deep
    Neural Networks: A Promising Tool for Fault Characteristic Mining and Intelligent
    Diagnosis of Rotating Machinery with Massive Data.” Mechanical Systems and Signal
    Processing 72-73: 303–315.  Web of Science ®Google Scholar Jiang, Y., Shen Yin,
    and Okyay Kaynak. 2018. “Data-driven Monitoring and Safety Control of Industrial
    Cyber-Physical Systems: Basics and Beyond.” IEEE Access 6: 47374–47384.  Web of
    Science ®Google Scholar Krishnakumari, A., A. Elayaperumal, M. Saravanan and C.
    Arvindan. 2017. “Fault Diagnostics of Spur Gear Using Decision Tree and Fuzzy
    Classifier.” The International Journal of Advanced Manufacturing Technology 89
    (9–12): 1–8.  Web of Science ®Google Scholar Kumar, V., and S. Minz. 2014. “Feature
    Selection: A Literature Review.” The Smart Computing Review 4 (3): 211–219.  Google
    Scholar Li, G., Huanxin Chen, Yunpeng Hu, Jiangyu Wang, Yabin Guo, Jiangyan Liu,
    Haorong Li, Ronggeng Huang, Hang Lv, and Jiong Li. 2018. “An Improved Decision
    Tree-Based Fault Diagnosis Method for Practical Variable Refrigerant Flow System
    Using Virtual Sensor-Based Fault Indicators.” Applied Thermal Engineering 129:
    1292–1303.  Web of Science ®Google Scholar Li, X., Di Li, Jiafu Wan, Athanasios
    V. Vasilakos, Chin-Feng Lai, and Shiyong Wang. 2017. “A Review of Industrial Wireless
    Networks in the Context of Industry 4.0.” Wireless Networks 23 (1): 23–41.  Web
    of Science ®Google Scholar Li, C., René-Vinicio Sanchez, Grover Zurita, Mariela
    Cerrada, Diego Cabrera, Rafael E. Vásquez. 2015. “Multimodal Deep Support Vector
    Classification with Homologous Features and its Application to Gearbox Fault Diagnosis.”
    Neurocomputing 168: 119–127.  Web of Science ®Google Scholar Li, H., Yinhu Wang,
    Pengshi Zhao, Xiaowen Zhang, and Peilin Zhou. 2015. “Cutting Tool Operational
    Reliability Prediction Based on Acoustic Emission and Logistic Regression Model.”
    Journal of Intelligent Manufacturing 26 (5): 923–931.  Web of Science ®Google
    Scholar Martinez Arellano, G. R. 2019. “Towards an Active Learning Approach to
    Tool Condition Monitoring with Bayesian Deep Learning.” 33rd International ECMS
    Conference on Modelling and Simulation.  Google Scholar Mobley, R. K. 2002. An
    Intrduction to Predictive Maintenance. Heinemann, St. Louis: IEEE Transactions
    on Instrumentation and Measurement.  Google Scholar NASA. n.d. PCoE Datasets.
    NASA: https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository
    /.  Google Scholar Nieto, P. J., E. García-Gonzalo, F. Sánchez Lasheras, and F.
    J. de Cos Juez. 2015. “Hybrid PSO–SVM-Based Method for Forecasting of the Remaining
    Useful Life for Aircraft Engines and Evaluation of its Reliability.” Reliability
    Engineering & System Safety 138: 219–231.  Web of Science ®Google Scholar Pandya,
    D. H., S. H. Upadhyay, and S. P. Harsha. 2014. “Fault Diagnosis of Rolling Element
    Bearing by Using Multinomial Logistic Regression and Wavelet Packet Transform.”
    Soft Computing 18 (2): 255–266.  Web of Science ®Google Scholar Parzen, E. 2015.
    Stochastic Processes. Philadelphia, PAUnited State: Couvier Dover Publications.  Google
    Scholar Patwardhan, A. V. 2016. “A Survey on Predictive Maintenance Through Big
    Data.” In Current Trends in Reliability, Availability, Maintainability and Safety,
    edited by U. Kumar, A. Ahmadi, A. K. Verma, and P. Varde, 437–445. Cham: Springer.  Google
    Scholar Prieto, M. D., Giansalvo Cirrincione, Antonio Garcia Espinosa, Juan Antonio
    Ortega, and Humberto Henao. 2013. “Bearing Fault Detection by a Novel Condition-Monitoring
    Scheme Based on Statistical-Time Features and Neural Networks.” IEEE Transactions
    on Industrial Electronics 60 (8): 3398–3407.  Web of Science ®Google Scholar Ross,
    G. J. 2015. Sequential and Batch Change Detection Using Parametric and Nonparametric
    Methods. London: CRAN.  Google Scholar Ross, G. J., and N. M. Adams. 2012. “Two
    Nonparametric Control Charts for Detecting Arbitary Distribution Changes.” Journal
    of Quality Technology 102: 116.  Google Scholar Ross, G. J., D. K. Tasoulis, and
    N. M. Adams. 2011. “Nonparametric Monitoring of Data Streams for Changes in Location
    and Scale.” Technometrics 53(4): 379–389.  Web of Science ®Google Scholar Santos,
    P. M., Jesús Maudes, and Andres Bustillo. 2018. “Identifying Maximum Imbalance
    in Datasets for Fault Diagnosis of Gearboxes.” Journal of Intelligent Manufacturing
    29 (2): 333–351.  Web of Science ®Google Scholar Shafi, U., Asad Safi, Ahmad Raza
    Shahid, Sheikh Ziauddin, and Muhammad Qaiser Saleem. 2018. “Vehicle Remote Health
    Monitoring and Prognostic Maintenance System.” Journal of Advanced Transportation
    2018: 1–10.  Google Scholar Siddhpura, A., and R. Paurobally. 2013. “A Review
    of Flank Wear Prediction Methods for Tool Condition Monitoring in a Turning Process.”
    The International Journal of Advanced Manufacturing Technology 65 (1-4): 371–393.  Web
    of Science ®Google Scholar Soualhi, A., Kamal Medjaher, and Noureddine Zerhouni.
    2015. “Bearing Health Monitoring Based on Hilbert–Huang Transform, Support Vector
    Machine, and Regression.” IEEE Transactions on Instrumentation and Measurement
    64 (1): 52–62.  Web of Science ®Google Scholar Stoica, P., and R. Moses. 2005.
    Spectral Analysis of Signals. Upper Saddle River, New Jersey: Prentice Hall.  Google
    Scholar Susto, G. S., Andrea Schirru, Simone Pampuri, Sean McLoone, and Alessandro
    Beghi. 2015. “Machine Learning for Predictive Maintenance: A Multiple Classifier
    Approach.” IEEE Transactions on Industrial Informatics 11 (3): 812–820.  Web of
    Science ®Google Scholar Traini, E. B. 2019. “Machine Learning Framework for Predictive
    Maintenance in Milling.” In IFAC-PapersOnLine. Vol. 52, 177–182. Berlin: Elsevier
    Ltd.  Google Scholar Upton, G., and I. Cook. 1996. Understanding Statistics. Oxford:
    Oxford University Press.  Google Scholar Wang, L., Zijun Zhang, Huan Long, Jia
    Xu, and Ruihua Liu. 2017. “Wind Turbine Gearbox Failure Identification with Deep
    Neural Networks.” IEEE Transactions on Industrial Informatics 13 (3): 1360–1368.  Web
    of Science ®Google Scholar Wang, J., X. Zhang, J. Zeng, and Y. Zhang. 2019. “Optimal
    Dynamic Imperfect Preventive Maintenance of Wind Turbines Based on General Renewal
    Processes.” International Journal of Production Research.  PubMed Web of Science
    ®Google Scholar Widodo, A., Eric Y. Kim, Jong-Duk Son, Bo-Suk Yang, Andy C. C.
    Tan, Dong-Sik Gu, Byeong-Keun Choi, and Joseph Mathew. 2009. “Fault Diagnosis
    of Low Speed Bearing Based on Relevance Vector Machine and Support Vector Machine.”
    Expert Systems with Applications 36 (3): 7252–7261.  Web of Science ®Google Scholar
    Wu, D. J. 2017. “Cloud-based Machine Learning for Predictive Analytics: Tool Wear
    Prediction in Milling.” In Proceeding of IEEE International Conference on Big
    Data, 2062–22069. Washington, DC: IEEE.  Google Scholar Wu, T.-L., D. Y. Sari,
    B.-T. Lin, and C.-W. Chang. 2017. “Monitoring of Punch Failure in Micro-Piercing
    Process Based on Vibratory Signal and Logistic Regression.” The International
    Journal of Advanced Manufacturing Technology 93 (5–8): 2447–2458.  Web of Science
    ®Google Scholar Xiao, L., T. Xia, E. Pan, and X. Zhang. 2020. “Long-term Predictive
    Opportunistic Replacement Optimisation for a Small Multi-Component System Using
    Partial Condition Monitoring Data to Date.” Zhang International Journal of Production
    Research 58: 4015–4032.  Web of Science ®Google Scholar You, D. G., Xiangdong
    Gao, and Seiji Katayama. 2015. “WPD-PCA-based Laser Welding Process Monitoring
    and Defects Diagnosis by Using FNN and SVM.” IEEE Transactions on Industrial Electronics
    62 (1): 628–636.  Web of Science ®Google Scholar Yu, J. 2018. “Tool Condition
    Prognostics Using Logistic Regression with Penalization and Manifold Regularization.”
    Applied Soft Computing 64: 454–467.  Web of Science ®Google Scholar Żabiński,
    T. M., Tomasz Mączka, Jacek Kluska, Michał Madera, and Jarosław Sęp. 2019. “Condition
    Monitoring in Industry 4.0 Production Systems – the Idea of Computational Intelligence
    Methods Application.” Procedia CIRP 79: 63–67.  Google Scholar Zhang, W., Dong
    Yang, and Hongchao Wang. 2019. “Data-Driven Methods for Predictive Maintenance
    of Industrial Equipment: A Survey.” IEEE Systems Journal 13 (3): 2213–2227.  Web
    of Science ®Google Scholar Zhang, C., X. Yao, J. Zhang, and H. Jin. 2016. “Tool
    Condition Monitoring and Remaining Useful Life Prognostic Based on a Wireless
    Sensor in Dry Milling Operations.” Sensors (Basel) 16(6): 795–815.  Web of Science
    ®Google Scholar Zhao, Y., Y. He, D. Z. Zhou, X. Han, Y. Li, and W. Wang. 2020.
    “Functional Risk-Oriented Integrated Preventive Maintenance Considering Product
    Quality Loss for Multistate Manufacturing Systems.” Internation Journal of Production
    Research 0: 1–18.  Google Scholar Zhou, X., M. Zhu, and W. Yu. 2020. “Maintenance
    Scheduling for Flexible Multistage Manufacturing Systems with Uncertain Demands.”
    International Journal of Production Research 0: 1–13.  Google Scholar Download
    PDF X Facebook LinkedIn Email Share Related research  People also read Recommended
    articles Cited by 16 Tool condition monitoring in milling using vibration analysis
    I. Yesilyurt et al. International Journal of Production Research Published online:
    22 Dec 2006 The use of Digital Twin for predictive maintenance in manufacturing
    P. Aivaliotis et al. International Journal of Computer Integrated Manufacturing
    Published online: 13 Nov 2019 Machine learning in manufacturing and industry 4.0
    applications Rahul Rai et al. International Journal of Production Research Published
    online: 14 Aug 2021 View more Information for Authors R&D professionals Editors
    Librarians Societies Open access Overview Open journals Open Select Dove Medical
    Press F1000Research Opportunities Reprints and e-prints Advertising solutions
    Accelerated publication Corporate access solutions Help and information Help and
    contact Newsroom All journals Books Keep up to date Register to receive personalised
    research and resources by email Sign me up Copyright © 2024 Informa UK Limited
    Privacy policy Cookies Terms & conditions Accessibility Registered in England
    & Wales No. 3099067 5 Howick Place | London | SW1P 1WG     Cookies Button About
    Cookies On This Site We and our partners use cookies to enhance your website experience,
    learn how our site is used, offer personalised features, measure the effectiveness
    of our services, and tailor content and ads to your interests while you navigate
    on the web or interact with us across devices. By clicking "Continue" or continuing
    to browse our site you are agreeing to our and our partners use of cookies. For
    more information seePrivacy Policy CONTINUE'
  inline_citation: '>'
  journal: International journal of production research (Print)
  limitations: '>'
  pdf_link: null
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: 'Tool condition monitoring framework for predictive maintenance: a case study
    on milling process'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/su13031412
  analysis: '>'
  authors:
  - Adham Alsharkawi
  - Mohammad Al-Fetyani
  - Maha Dawas
  - Heba Saadeh
  - Musa Al Yaman
  citation_count: 28
  full_citation: '>'
  full_text: '>

    Web Store Add shortcut Name URL Customize Chrome'
  inline_citation: '>'
  journal: Sustainability (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/2071-1050/13/3/1412/pdf?version=1611917364
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: 'Poverty Classification Using Machine Learning: The Case of Jordan'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.asoc.2020.107048
  analysis: '>'
  authors:
  - Miyeon Jeon
  - Yoojeong Noh
  - Kyunghwan Jeon
  - Sang Bong Lee
  - Inwon Lee
  citation_count: 13
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Data preprocessing 3.
    Regression analysis using meta learning 4. Case study 5. Results and discussion
    6. Conclusions CRediT authorship contribution statement Declaration of Competing
    Interest Acknowledgments References Show full outline Cited by (14) Figures (7)
    Show 1 more figure Tables (9) Table 1 Table 2 Table 3 Table 4 Table 5 Table 6
    Show all tables Applied Soft Computing Volume 101, March 2021, 107048 Data gap
    analysis of ship and maritime data using meta learning Author links open overlay
    panel Miyeon Jeon a, Yoojeong Noh a, Kyunghwan Jeon b, Sangbong Lee c, Inwon Lee
    d Show more Share Cite https://doi.org/10.1016/j.asoc.2020.107048 Get rights and
    content Highlights • A data gap analysis framework is proposed to determine real
    ship and maritime data anomalies. • It includes sequential data preprocessing
    and ship performance prediction using machine learning. • Meta-models and hyperparameter
    optimization enable accurate and robust ship performance. • The meta-models for
    ship performance were verified using various error analysis techniques. • The
    data anomalies were detected through relative error intervals of the meta-models.
    Abstract With the developments in new Internet of Things (IoT) technology, ship
    owners and managers can access and analyze vast amounts of real-time onboard data.
    However, data collected from the ship’s engine and navigation information include
    various types of errors owing to imprecision, bias, sensor failure, or human error
    caused by manual recording by the ship operator’s hands. Such abnormal data make
    accurate ship performance prediction and monitoring difficult; thus, the original
    data need to be carefully refined through data preprocessing. Machine learning
    models have been used to detect and remove abnormal data; however, this yields
    inconsistent predictions in results depending on the types of machine learning
    models used. In this study, a robust data gap analysis method is proposed to detect
    abnormal data among ship and marine data collected in real time. Data preprocessing,
    including rule-based data imputation, clustering, denoising, and dimension reduction,
    is systematically performed; subsequently, a meta-learning model, which is a combination
    of various machine learning models, is used to predict ship performance and detect
    its abnormal data. This study compared the performance of single-machine learning
    models and meta models through various error analysis methods that utilize actual
    ship operation data. The single machine leading models have various error values
    depending on types of data and models, while the meta model consistently has values
    of less than 5% of mean absolute percentage error (MAPE) and relative root-mean-square
    error (RRMSE), showing a Nash–Sutcliffe efficiency coefficient(NSE) value of 0.7
    or higher. Our proposed data gap analysis framework, including the meta-learning
    model, can be useful for monitoring the condition of ships, as it can more accurately
    and robustly classify them as normal or abnormal. Previous article in issue Next
    article in issue Keywords Data gap analysisMeta learningData preprocessingMachine
    learning error measures 1. Introduction With the developments in Internet of Things
    (IoT) technology, vast amounts of ship data such as navigation status and engine
    life cycle are being collected through sensors mounted on ships. This has led
    to the smart ship era, where effective ship management and intelligent navigation
    strategy have been enabled through remote ship operation monitoring. The data
    collected onboard involve navigation, ship equipment and machinery, ship status,
    and weather data, which are used as input data to predict ship performance in
    aspects such as engine fuel consumption, shaft revolution, and speed over ground.
    Several researchers have attempted to analyze ship performance using the collected
    ship and maritime data, but they struggle with real data of poor quality [1].
    Some of the real data collected as time-series data are missing during transmission,
    or there exist errors such as noise, bias, and outliers included in the data collection
    process. Such abnormal data lead to inaccurate prediction of ship performance;
    therefore, data preprocessing is crucial before the analysis of data for determining
    ship performance. At the general data preprocessing stage, data gap analysis is
    necessary to detect and refine abnormal data out of the allowable range of reference
    values based on the domain knowledge of ship operators or ship operation policy.
    Herewith, the data gap analysis indicates the identification of abnormal data
    by evaluating the difference between predicted or reference values and the actual
    collected values. Originally, the data gap analysis assesses the performance differences
    between an enterprise’s information systems or soft applications to determine
    whether business requirements have been satisfied and what action needs to be
    taken if business requirements have not been successfully met. This has been studied
    in business evaluation research in reference to needs analysis, needs assessment,
    or need-gap analysis. Bunse et al. [2] suggested a gap analysis by analyzing the
    energy efficiency performance from the perspective of manufacturing production,
    while Wilde [3] also suggested a framework for analyzing the gap between predicted
    and measured energy efficiency values. However, most of these studies focused
    on the business aspects and had not applied the data gap analysis to the vast
    amount of ship and maritime data. In addition, when large amounts of data are
    collected, using domain knowledge or policy is difficult because operators could
    struggle to use the multiple and nested rule-based approach. The allowable ranges
    of reference values could not be easily determined, particularly for ship performance.
    Therefore, proposing a suitable framework of data gap analysis to filter abnormal
    data out of original data for accurate prediction of ship performance and to construct
    a navigation strategy from real-time ship and maritime data is necessary. With
    the recent increase in interest in the creation of accurate predictive models
    for ship performance, there has been an increase in studies applying various machine
    learning and statistical methods. Recently, studies were conducted on predicting
    the fuel consumption of ship engines using Gaussian processes [4] and neural networks
    [1], [5], [6], and research was conducted on forecasting ship performance using
    Lasso regression models [7] and decision tree models [8]. Comparative studies
    of various machine learning methods were also performed. Hu et al. [9] compared
    the backpropagation neural network and Gaussian process with and without considering
    the influence of marine environmental factors. Uyanik et al. [10] compared multiple
    linear regression, Ridge and Lasso regression, support vector regression, tree-based
    algorithms, and boosting algorithms to predict the fuel consumption of container
    ships. Gkeroekos et al. [11] compared support vector machine, random forest regressor,
    extra tree regression, and artificial neural network to predict a ship’s fuel
    consumption. While previous research involved comparative studies of various machine
    learning models for realizing ship’s performance or fuel consumption, dealing
    with the actual ship data collected from hundreds of sensors with high-dimensional,
    complex, and nonlinear factors remains difficult. In addition, as real-time ship
    data includes unpredictable weather conditions and excessive operating conditions,
    analyzing the ship’s normal or abnormal conditions only from the predicted results
    of the machine running model is also difficult. To overcome these limitations,
    Farag and Aykut recently used neural networks to predict ship models in changing
    operating conditions [12], and Yuan et al. developed a ship monitoring model that
    considers weather effects by utilizing LSTM models considering time correlation
    [13]. However, from the standpoint of ship digital management, the use of sensors
    is on the rise and there are difficulties in managing all ship performance models
    with various characteristics. An ensemble model, combining several machine learning
    models, has been used to improve prediction. Several researchers have used the
    ensemble model for generating prediction models such as wind power [14], [15],
    power consumption using wind and solar energy resource [16], and river flow for
    water management using volatile weather and maritime data [17]. In addition, Radonjic
    and Vukadinovic predicted the axial power of transaction boats by combining various
    artificial neural networks [18]. Hinnethal and Clauss used the ensemble model
    to predict weather, thereby aiding in-ship route optimization [19], and Ling and
    Dong-Mei used several support vector machine regressions to predict the steel
    corrosion rate of ships in different seawater environments [20]. However, the
    ensemble model has not been studied for data gap analysis for stable ship performance
    monitoring. To overcome the limitations of the existing research described earlier,
    we herein developed a meta-learning model-based data gap analysis framework to
    determine whether there is an abnormality in the state of ships in real-time operation,
    and it has three distinctions compared to existing research. First, a systematic
    data gap analysis framework was developed for monitoring an actual ship’s operation
    condition. Our proposed framework includes rule-based real-time data imputation
    processing, refining data through clustering, denoising and dimensional reduction,
    and sequentially detecting abnormal data based on the relative error intervals
    of the prediction data obtained from a meta-learning model of the ship’s performance.
    Second, a robust and accurate meta-learning model suitable for ship and marine
    data was developed. The meta-learning model combines single-machine learning models
    with different characteristics to enable robust and accurate data gap analysis
    for real operation data with large uncertainty and variability. Third, various
    error analysis techniques were applied to verify the validity and practicality
    of our proposed data gap analysis framework for a real ship’s operation data.
    Using ship’s operation data containing various environmental factors, various
    error analysis techniques were used to compare the accuracy and robustness of
    single-machine learning models with that of the meta-learning model. This study
    is valuable in that it proposes a systematic data gap analysis framework for monitoring
    ship conditions, thereby enabling accurate detection of abnormal data and appropriate
    actions on ships or land-based ship control centers based on the large amounts
    of data collected in real time. 2. Data preprocessing In this section, we provide
    theoretical explanations for the data preprocessing techniques for data gap analysis
    as shown in Fig. 1 and Table 1. Section 2.1 introduces data imputation methods
    for removing errors in raw data using a rule-based approach. Section 2.2 introduces
    clustering data according to the characteristics of the data using K-means clustering,
    Section 2.3 involves removing abnormal data using a Kalman filter, and Section
    2.4 discusses dimension reduction. The K-means clustering and PCA were implemented
    using scikit-learn 0.20.2 and Kalman filter was implemented using filter-py 1.4.1
    in Python. 2.1. Data imputation The ship’s data are collected from the automatic
    identification system (AIS), including navigation and weather data, and machinery
    data measured using sensors mounted on ships. Once the collected data are provided,
    the data imputation process is performed, with the first step being analyzing
    the characteristics, rules, and relations hidden within the data, as shown in
    Fig. 1. As inappropriate data imputation could lead to incorrect data analysis,
    shipping companies have their own policies and rules to replace missing data with
    allowable values. Let the ship and maritime raw data be collected onboard with
    noise, bias, and anomalies, where for the th time-series data, d is the number
    of dimensions of the input variable, and n is the number of rows in the time-series
    data. As these raw data contain errors, data imputation is the first step of the
    data gap analysis depending on a rule-based approach. In the data imputation step,
    if the datum is not in the range of the lower and upper limits defined by the
    policy according to the domain knowledge, the datum is replaced with an alternative
    datum that does not affect the prediction of the ship’s performance. For example,
    when docking or fixing, datasets that are out of allowable ranges are replaced
    with low-speed datasets to eliminate the anomalous data, and only high-speed operation
    datasets of the entire dataset are selected and used for data gap analysis. The
    allowable ranges for data are determined by the policy set by considerable experience
    in the shipping company. As the acceptable range of factors for data imputation
    is kept confidential by the company, its values were not provided herein. Download
    : Download high-res image (718KB) Download : Download full-size image Fig. 1.
    Data gap analysis process based meta-learning. Table 1. Notation and abbreviation
    on Fig. 1. Process Notation Description Process Notation Description Data clustering
    K, K The number of clusters, Total number of K-clusters using silhouette analysis
    Data regression GAM Generalized Additive Model The kth silhouette value, Maximum
    silhouette value GBR Gradient Boosting Regressor Dimension reduction q , q The
    number of principal components, the user-defined dimension of reduction MARS Multivariate
    Adaptive Regression Splines m , m The index of target feature The user-defined
    number of target feature R2 Determination of coefficient x, y Input and target
    variables of machine learning model MAPE Mean Absolute Percentage Error Correlation
    coefficient between input and target variables, the user-defined threshold of
    correlation coefficient 2.2. Data clustering In the data clustering process, the
    corrected data refined within a specific range are classified into a few clusters
    depending on the operation regions. K-means clustering, which is the most widely
    used heuristic algorithm based on intuition, is used in this study. K-means clustering
    is an algorithm that partitions a given data into K clusters and allocates the
    data to each cluster to minimize the variance of the distance difference with
    each cluster [21]. The number of clusters, K, is a parameter defined by the user,
    and silhouette analysis is typically performed to calculate the similarity of
    the data for deciding how well clustering has been evaluated depending on the
    value of K  [22]. The clustering process is continued until when the calculated
    silhouette value is larger than the allowable maximum silhouette value ( ) defined
    by users, while increasing the number of clusters up to the maximum number of
    clusters, . (1) where a(i) and b(i) denote the average distances between the th
    data and all other data in the same cluster or any other clusters, respectively.
    2.3. Data denoising The data denoising process is performed to smooth the data
    with large variance over time using a statistical approach. The input and output
    variables still contain a dataset containing noise with large variance. Therefore,
    data denoising, which is a step for removing a numerical error, is performed by
    using a filtering method. The Kalman filter is one of the most widely used low-pass
    filters in the industry. The Kalman filter is an optimal estimator of data of
    interest from noisy observations by minimizing the mean square of the estimated
    data. Let the time-series data with n rows be given as with . Assume that a dataset
    measured at time t and its corresponding linear transformation follows a Gaussian
    distribution. Then, the process model from time t-1 to time t can be defined as
    [23] (2) where F is the state transition matrix from the previous state vector
    to , B is the control-input matrix applied to the control vector , and is the
    process noise and is assumed to follow the zero-mean Gaussian with covariance
    Q. Based on the process model, the relation between the state and the measurement
    is formulated as (3) where is the measurement vector, H is the measurement matrix,
    and is the measurement noise vector following zero-mean Gaussian with the covariance
    R. Therefore, when the covariance matrix Q includes large values of the progressive
    noise, the predicted state values tend to follow raw data by trusting the data
    with high fluctuation; otherwise, they tend to obtain a smooth function by removing
    the data with high fluctuation. 2.4. Dimension reduction Dimension reduction removes
    less important variables or selects more important variables affecting output
    variables, which are the targets of the data gap analysis, from a large number
    of variables through principal component analysis (PCA) and correlation analysis.
    The PCA can convert a set of observations of correlated variables into a set of
    values of linearly uncorrelated variables, called principal components. Let the
    sample data for three output variables (m 1 3) with where p variables are compressed
    and collected as time series at a specific time t. The original dataset (x) can
    be converted into a new dataset (y), which is defined in the principal component
    direction. The mean and variance of the new dataset are calculated as [24] (4)
    (5) where denotes the variance of the collected data, and the vector u is the
    eigenvector corresponding to the coordinate axis for the largest independent covariance
    direction, which becomes the principal component for the new dataset. Therefore,
    a new eigenvector in a linear combination with an existing basis vector is derived
    from the following optimization equation: (6) After the optimization process is
    finished, the eigenvectors are obtained according to the principal directions
    such that the variance of each direction of the new dataset is maximized. According
    to the derived eigenvalues, the eigenvectors selected by the number q of principal
    components are used in the order of the decreasing eigenvalues of the eigenvectors.
    Subsequently, new data is generated via orthogonal projection, and the data with
    p-dimension are compressed into q-dimension. The dimension of similar variables
    is reduced using PCA, and it is further reduced using correlation analysis. The
    correlation analysis is a bivariate analysis measuring the strength of association
    between two variables (correlation coefficient). In this study, the linear correlation
    coefficient is calculated using the Pearson correlation coefficient, , and only
    input variables affecting a ship’s performance are extracted. 3. Regression analysis
    using meta learning After data preprocessing, a meta-learning model combining
    three machine learning models – generalized linear model (GAM), gradient boosting
    regressor (GBR), and multivariate adaptive regression splines (MARS) – is used.
    Section 3.1, 3.2, and 3.3 explain the theoretical backgrounds of GAM, GBR, and
    MARS, respectively. To improve model accuracy, Bayesian optimization is used for
    hyperparameter tuning as described in Section 3.4. Section 3.5 demonstrates how
    the meta-regression model is built using three single-machine learning models.
    Three types of error measures – mean absolute percentage error (MAPE), relative
    root-mean-square error (RRMSE), and Nash–Sutcliffe efficiency coefficient (NSE)
    – are introduced in Section 3.6. The GAM and GBR were implemented using pygam
    0.8.0 and scikit-learn 0.20.2, respectively. The MARS and Bayesian optimization
    were implemented using sklearn-contrib-py-earth 0.1.0 and Bayesian-optimization
    1.2.0, respectively. 3.1. Generalized additive model (GAM) Regression analysis
    generally deals with continuous variables whose response variables are normally
    distributed. However, in many cases, assuming that a response variable is normally
    distributed in that the response variable could be a categorical variable is not
    possible. In such cases, using a regression model to deal with all these types
    of cases is necessary. The generalized linear model (GAM) was developed by Nelder
    and Wedderburn [25] to provide a generalization of classical linear models with
    Gaussian errors. GAM relates to a linear model (linear predictor, X ) with the
    expected value of the response variable E(Y) through a link function g ( ) as
    (7) where X [ , , X ] is a vector of d input variables, [ , , ] is a vector of
    weights (regression coefficients) of each variable, and is a constant called the
    intercept. GAM replaces the linear term by a sum of smooth functions of input
    variables. For the input variables X(t) and output variable Y(t), the predicted
    model of GAM can be presented as [26] (8) E(Y(t)) is the expected value of the
    predicted values for the vector of output variables Y assumed to follow a normal
    distribution, and ( ) is a nonparametric smoothing function determined by a small
    dataset with specific intervals of the th input variable. In this study, a spline
    function is used as the nonparametric smoothing function. Thus, GAM can well describe
    a highly nonlinear dependent variable by simultaneously predicting the sum of
    the predictors combined with splines. 3.2. Gradient boosting regressor GBR, proposed
    by Freund and Schapire [27], is a type of boosting ensemble model that combines
    weak learners. It minimizes the total error of the ensemble model by gradually
    enhancing the accuracy of weak predictions, typically decision trees. The decision
    tree is used to (i) build a new regression tree in the descending direction of
    the loss function based on the results of the previous regression tree where the
    loss function is used as an error measure between the target values and predicted
    values and (ii) evaluate the accuracy of the prediction. If a decision tree completely
    reconstructs the loss function by updating new subtrees, the whole ensemble provides
    prediction with minimized errors. Once the datasets are divided into different
    domains (subtrees) according to the decision tree, the GBR model is then built
    on the sub-divided domain. Once the regression tree is constructed, the next step
    is to predict a value on a new dataset that subsequently becomes a current node
    of the tree. If the current node is compared with the left or right subtree of
    the node in terms of its loss functions, either of them becomes the new current
    node, thereby reducing the loss function. To obtain the best predictive GBR model,
    an optimization process is performed to minimize the loss function for the target
    data and predicted data. The loss function for the th data with to n can be expressed
    as (9) The th predictive model ( ) can be obtained for , 2, , M using the gradient
    of loss function (X) at the (m-1) predictive model and is derived as follows [28]:
    (10) A learning rate of the th predictive model is optimized from a starting point
    as a searching point by using steepest descent approach to obtain the optimal
    points of the loss function, and subsequently, the next searching point is extracted.
    Thus, the learning rate of the th predictive model is derived as follows: (11)
    As we renew the searching points and learning rate, the next predictive model
    is updated as (12) After the predictive model is updated, a final regression model
    , which has the minimum loss, is generated. In the GBR process, hyperparameters
    such as the number of nodes and the depth of the tree highly affect the regression
    tree structure, which has a direct association with the accuracy and efficiency
    of the GBR model, and thus requires hyperparameter optimization. 3.3. Multivariate
    adaptive regression splines Multivariate adaptive regression splines (MARS) is
    a nonparametric regression model that can automatically represent nonlinearity
    and interaction between input variables. The MARS model uses the extension and
    segmentation of the spline function to generate a flexible model developed from
    the method of partitioning fewer interactive terms between the input variables
    and output variables. This method is based on the partition of the input space
    (training datasets) into regions with its regression equation (splines), thereby
    making the MARS model suitable for problems with high dimension of input variables
    The splines are smoothly connected in general, and these piecewise polynomials,
    which are known as basis functions, yield a flexible model that can handle linear
    or nonlinear characteristics of data. In this study, a linear function is used
    as a basis function to reduce the computation time of training and testing data.
    As the piecewise basis function, a hinge function , which follows a partial linear
    function, is used where a knot point c similar to a step function is used to assess
    each data point and generate a linear regression model. The linear combination
    of the basis function f(X) and the interaction are expressed as follows [29]:
    (13) where is a basis function represented by a spline function or a multiplication
    of basis functions with two or more exponentiations. is the coefficient estimated
    using the least squares method. MARS generates a model in two phases: forward
    phase and backward phase. In the forward phase, training data are first learned
    based on the intercept coefficient, . Subsequently, input variables and knots,
    which can minimize prediction errors, are selected by using the least squares
    method, and two basis functions are added to the initial models. The addition
    of the basis functions iteratively continues until the training criteria of model
    reaches its predetermined maximum number of iterations or the threshold value
    until an overfitted model is obtained. In the backward phase, the model accuracy
    is improved through generalized cross-validation (GCV) by eliminating the less
    contributing basis functions from the model until the best suited model is observed.
    For N training data, GCV can be calculated as [30] (14) M is the number of basis
    functions, and is a penalty for each basis function included in the developed
    model. The numerator term in Eq. (14) is the mean square error of the model evaluated
    in the training data, and the denominator term describes the incremental change
    when the model complexity increases [31]. 3.4. Bayesian optimization Although
    the regression method through each machine learning shows higher accuracy than
    the existing statistical regression method, optimizing the hyperparameter that
    can significantly affect the accuracy of each model is crucial. In this study,
    Bayesian optimization, which is an adaptive approach to find the optimum hyperparameters
    with a few experiments, is used. In particular, when the optimization in machine
    learning algorithm is time-consuming or when obtaining a differential function
    due to unknown objective function is impossible, Bayesian optimization is a useful
    method to find an optimal hyperparameter by repeating the exploration and exploitation
    process based on Bayes theorem, which makes posterior predictions based on known
    prior information. The Bayesian optimization aims to obtain the optimal unknown
    function f and find . To achieve this, a statistical model is built by collecting
    samples and Gaussian process prior based on Bayes theorem. An acquisition function
    h is evaluated over the statistical model and used as a guide for searching the
    optimum. The posterior distribution of h, P(h ) can be obtained using the prior
    P(h) and a likelihood function P( h) as shown: (15) where , where z is the vector
    of a dataset of hyperparameters. The posterior distribution is constructed as
    a Gaussian process (GP) model. As the number of data for hyperparameters increases,
    the algorithm can obtain regions that are worth being explored in the parameter
    space and the ones that are not. At each step, the GP model is fitted to previously
    explored points and the posterior distribution is used to determine the next point
    likely to yield an improvement in model accuracy using the acquisition function.
    The commonly used type of acquisition function is the upper confidence bound (UCB).
    UCB uses a tunable parameter to balance exploitation against exploration [32].
    The UCB acquisition function is defined as [33] (16) where is a user-defined parameter
    that tunes the trade-off between exploitation (z) and exploration (z). The exploitation
    and exploration processes are continued until the number of sampled data reaches
    a maximum number N, which is defined by the users. Among all sampled data, the
    optimum hyperparameter is finally selected to minimize the acquisition function.
    The optimized parameters will offer the best accurate model. 3.5. Meta-regression
    The ensemble method combines different predictive models to improve the predicted
    accuracy or to generate a reliable model regardless of data quality, dimension,
    or nonlinearity. Meta-regression derives an accurate model by adding extra linear
    regression based on the predicted results of the training dataset. The ensemble
    model using meta-regression can yield a robust prediction model by combining multiple
    predictors with differently assigned weights. Thus, meta-regression is suited
    for accurately predicting ship’s fuel consumption with high reliability. When
    the input variables X(t) and output variable Y(t) obtained following time t are
    collected and n is the number of machine learning models to be combined, the function
    M( ) generated by each machine learning model (X) and the predictive data are
    expressed as follows: (17) where represents the weight of the th machine learning
    model. All predictive models can be combined with equivalent weights, but meta-regression
    assigns high weights to models closer to the actual data. To select these weights,
    the least square method is used, and the weights are selected to enable more accurate
    and stable prediction of fuel consumption. 3.6. Error measures To verify the accuracy
    of the machine learning model, calculating the error between the predicted and
    the target value is necessary. The selection of error measures influences how
    the performance of the machine learning algorithm is measured and compared. Such
    error measures influence the focus on the importance of different characteristics
    in the results and ultimately the choice of the machine learning model. There
    are several types of error measures recently used in machine learning models,
    such as MAPE, RRMSE, and NSE [34]. RRMSE measures the absolute fitness of the
    prediction model by normalizing the average errors to the sum of the target values,
    as shown in Table 2. MAPE calculates the average percent error for given data
    to determine the absolute accuracy of the model. NSE is calculated as the ratio
    of the residual variance to the measured data variance and indicates how well
    the predicted data fit to the observed data. There exist various error measures
    other than RRMSE, MAPE and NSE; however, determining the absolute fitness of the
    model and how well the predicted data match the observed data to determine if
    there are any anomalies in the data is necessary; thus, they were used as error
    measures herein. The formula for the three error measures are listed in Table
    3. If the predicted values differ significantly from actual values based on allowable
    MAPE defined by users, i.e., estimated MAPE value is larger than a user-defined
    error value, , the data exceeding is then classified as abnormal data. To verify
    the accuracy of single-machine learning model and the meta-learning model, these
    three error measures are used. Table 2. Accuracy degree of RRMSE. Accuracy degree
    Range Excellent RRMSE<10% Good 10%<RRMSE<20% Fair 20%<RRMSE<30% Poor RRMSE>30%
    Table 3. Error measures. Types of error measures Formula Mean Absolute Percentage
    Error Relative Root Mean Square Error Nash–Sutcliffe Efficiency coefficient :
    True value of the ith datum, : predicted value of the ith datum. Download : Download
    high-res image (185KB) Download : Download full-size image Fig. 2. Silhouette
    values of different clusters. 4. Case study 4.1. Data collection The data used
    herein were collected from a bulk carrier at a frequency every 10 s for approximately
    three months from June to August 2017. Those data were collected from a digital
    data acquisition system (AIS) and integrated bridge system and they comprise engine
    data, navigation operation data, and weather conditions with 42 variables. The
    variables include engine performance factors such as shaft revolutions and engine
    torque, navigational factors including ship direction and speed, ship status factors
    such as draft, and meteorological factors including direction and speed of waves
    and winds. The number of data is 752,344, including 210,055 (28%) and 542,289
    (72%) data at moored and navigation status. Detailed ship specifications such
    as ship length and maximum rated output of bulk carriers are omitted for confidentiality.
    The number of variables is comparatively large to perform data gap analysis; therefore,
    the dimension of variables needs to be reduced. Some variables could be dependent
    on other variables or other variables could be unimportant ones that do not affect
    the ship’s performance, which could be considered as output variables for the
    gap analysis. Thus, reducing the dimension of input variables by grouping correlated
    variables into independent variables and removing unimportant input variables
    is necessary. In this study, factors related to ship status, engine operation,
    navigation, and weather conditions are used as input variables, and factors related
    to a ship’s performance such as main engine fuel oil consumption (M/E FOC), shaft
    revolution, and speed through water (STW) are used as output variables. After
    the data are refined through data imputation, clustering, and denoising, the input
    and output variables with a reduced dimension are newly defined, and they are
    used to build single-machine learning models and meta-regression for the data
    gap analysis. The detailed description of data preprocessing and meta-regression
    have been provided in Sections 4.2 Data preprocessing, 4.3 Meta-regression of
    ship performance. 4.2. Data preprocessing Data imputation is performed for real-time
    ship maritime data using a rule-based approach described in Section 2.3. In the
    data imputation process, erroneous or missing data are replaced by data at the
    anchor that are not used for data gap analysis through rule-based policies. After
    imputing data, identifying groups of similar features in multivariate datasets
    through data clustering process is necessary. In this study, forward draft and
    aft draft represent the level of cargo loading, which has a significant impact
    on the ship’s fuel consumption in the main engine; therefore, they need to be
    selected as factors for clustering analysis. To select the appropriate number
    of clusters, K-means clustering, which partitions the data into K clusters wherein
    each datum belongs to the cluster to the nearest mean, is performed for the different
    numbers of clusters, K 2–5. As shown in Fig. 2, for and 3, each cluster is clearly
    separated from other clusters. Similarly, the silhouette plot for each cluster
    indicates that each cluster has larger silhouette values over 0.7, indicating
    that the clustering is well defined as shown in Fig. 2. However, for and 5, as
    some clusters are not clearly separated, silhouette values are also much lower
    than those for and 3. The heavier the cargo, the higher are the values of the
    forward draft and aft draft. Accordingly, two or three clusters ( and 3) are appropriate
    for the loading and unloading conditions of the cargo. In this case, is adopted
    to perform data gap analysis under the unloaded or loaded conditions of the cargo.
    The data collected from ships in operation carrying loaded cargo are refined through
    denoising using the Kalman filter described in Section 2.3. Fig. 3 shows the time-series
    data for the SOG before and after the data denoising process. The denoised data
    is smoothed by prior prediction and posterior prediction of raw data while following
    the trend of raw data. In addition to SOG data, all datasets were refined through
    data denoising and tended to be similar to SOG data. The final process of data
    preprocessing is the dimension reduction process using PCA and correlation analysis.
    The weather-related variables in the ship operation data include only seven variables
    but exclude 15 variables from a total of 22 weather-related variables. These weather
    variables can be divided into three groups – wind effect, wave effect, and current
    effect. The wind effect group includes nine variables, including wind direction,
    wind speed, relative wind, and speed. The current effect group includes four variables
    – current speed, current u- and v-speed, and current direction where u- and v-direction
    indicate the east and north directions. The wave effect group includes eight variables,
    including total wave period, total wave direction, and total wave speed. The PCA
    is performed to reduce the weather-related input variables to three principal
    components, namely wind, wave, and current weather effects. Furthermore, brake
    horsepower (BHP) and weather depth are not considered as input or output variables
    because BHP is a dependent variable, which can be calculated by ship’s fuel consumption
    (M/E FOC), and the water depth and slip include many error data. As a result,
    the multi-dimensional ship and maritime data are compressed from 41 variables
    into 20 variables, as shown in Table 4. Download : Download high-res image (162KB)
    Download : Download full-size image Fig. 3. Data denoising of SOG. However, there
    might exist correlated or uninfluential variables among the reduced variables,
    and thus correlation analysis needs to be performed. As shown in Table 5, M/E
    FOC, shaft revolution, and STW are strongly correlated with each other as expected.
    In addition, other factors related to the ship’s performance, such as shaft torque,
    shaft power, and STW, demonstrate strong correlation with the three output variables.
    In this study, only input variables with a high correlation of more than 0.6 with
    each output variable were used to build meta-regression models as presented in
    Table 5. Table 4. Input and output variables of ship maritime data. No Input and
    output Units Remark 1 Shaft torque kN-m Engine 2 Shaft revolution rpm 3 Shaft
    power kW 4 M/E FOC kg/hr 5 SOG knots Navigation 6 STW knots 7 Ship heading deg
    8 Course over ground deg 9 Rudder angle deg Ship state 10 Forward draft m 11 Aft
    draft m 12 Ambient air density kg/m3 Weather conditions 13 Ambient air temperature
    14 Atmospheric pressure MSL 15 Sea surface pressure hPa 16 Sea surface temperature
    17 Sea surface salinity PSU 18 Wave effect – 19 Current effect – 20 Wind effect
    – Therefore, after accurate meta-regression models are built using strongly correlated
    variables with three output variables and the allowable error range of the model
    is selected, the abnormal data for the output variables can be detected if they
    exceed the error range. We herein aim to construct a model that detects abnormalities
    in the performance data of ships; therefore, a regression model is generated considering
    only the highly correlated ship performance factors. However, weather-effect factors
    are necessary for the accurate prediction of fuel consumption during normal operation
    of ships, . Table 5. Correlation analysis results. No Output Units Input Correlation
    coef. 1 M/E FOC kg/hr Shaft torque 0.9496 Shaft power 0.8511 Shaft revolution
    0.6917 STW 0.6603 2 Shaft revolution rpm STW 0.8867 Shaft torque 0.7837 M/E FOC
    0.6917 SOG 0.6749 3 STW kW Shaft revolution 0.8867 SOG 0.7771 Shaft torque 0.6886
    M/E FOC 0.6602 4.3. Meta-regression of ship performance In this section, a meta-regression
    model is built based on input and output variables obtained in Section 4.2. GAM,
    GBR, and MARS were used as regression models for M/E FOC, shaft revolution, and
    STW, respectively. To build each regression model, the datasets are divided into
    training datasets, validation datasets, and test datasets that are sequentially
    used with 4:1:1 ratio. The training dataset is used to build a regression model,
    the validation dataset is used to adjust hyperparameters in the search space of
    hyperparameters, and the test dataset is used to verify the accuracy of the obtained
    model. Among the laden data targeted herein, training and verification data were
    learned at random without duplicates for the generalization of the trained model,
    and test data were sequentially selected over time to confirm the practicality
    of the prediction model. Each model has its own hyperparameters, among which the
    most sensitive parameter to the performance of the model needs to be selected
    and optimized. The initial and upper and lower limits (U/B and L/B) of the hyperparameters
    for each model are listed in Table 6. As each model has a different accuracy depending
    on the values of the hyperparameters, the accuracies of the three models need
    to be compared for different values of hyperparameters that are randomly generated
    following a uniform distribution within lower and upper limits over 50 times,
    and they are used to construct the models. As the number of splines and orders
    increase, the nonlinearity of data is well represented, and the smoothing parameter
    reduces the overfitting data. In GBR, the learning rate controls the overfitting
    of the model, and max_depth indicates the maximum depth of the tree; therefore,
    the larger the max_depth, the better is the nonlinear representation of the model.
    Min_sample_leaf denotes the minimum number of leaves used in the tree, and it
    controls underfitting. The penalty parameter acts as the smoothing parameter of
    GAM, and Max_degree is the max degree of terms generated by the forward phase,
    controlling the nonlinearity of the model with endspan_alpha. Thresh is a parameter
    used for evaluating stopping conditions for the forward phase, and min search
    points denote the minimum number used in training datasets. Table 6. Lower and
    upper bounds for hyperparameters. No Regression model Main hyperparameter L/B
    U/B 1 GAM Number of splines 10 100 Spline order 1 9 Empty Cell Empty Cell Smoothing
    parameter 0.0001 1 2 GBR Learning rate 0.001 0.1 Max depth 100 1000 Empty Cell
    Empty Cell Min. samples leaf 0.001 0.5 3 MARS Penalty 1 10 Endspan_alpha 0.001
    1 Minspan_alpha 0.001 1 Thresh 0.001 0.1 Maximum degree 1 5 Min search points
    10 5000 To compare their accuracies, MAPE, RRMSE and NSE are used as error measures.
    Using Bayesian optimization, the hyperparameters of each model are optimized.
    For this, sampling points for the hyperparameters are randomly generated within
    the lower and upper bounds of the hyperparameters shown in Table 6 over 15 times.
    Through exploration and exploitation, the optimal hyperparameter is obtained and
    used to construct the best fitted regression model. Subsequently, a meta-regression
    is generated based on three models with tuned parameters and its accuracy is compared
    with GAM, GBR, and MARS accuracies using MAPE, RRMSE, and NSE, respectively. For
    all computation of generating models and performing Bayesian optimization, a computer
    with Intel(R) Core(TM) i7-5930K CPU was used. 5. Results and discussion Using
    the randomly selected hyperparameters, training and validation were performed
    to build GAM, GBR, and MARS for M/E FOC, shaft revolution, and STW. The accuracy
    of each model is compared using MAPE, RRMSE, and NSE for the test dataset. In
    this study, a bee swarm plot is used; this is a one-dimensional scatter plot and
    is visualized with closely packed and non- overlapping points. Unlike traditional
    charts, the bee swarm plot describes data on a single axis and then offsets it
    in the other direction to show the data volume so that the data points are better
    categorized and identified at a glance. Figures 4 (a), (b), and (c) show the values
    of MAPE, RRMSE, and NSE, respectively, for the three output variables (M/E FOC,
    Shaft revolution, and STW) modeled by GAM, GBR, and MARS. The accuracy of each
    model is displayed for valid datasets and test datasets, which are intended to
    verify the unbiased evaluation of the model fit. Fig. 4(a) shows the MAPE results
    between target values and predicted values. When the MAPE is closer to zero, the
    more similar are the target (actual) data and the predicted data. As all models
    have average MAPE values of less than 5%, the predicted models seem to be adequate
    for regression models; in particular, GAM and MARS models have small MAPE values
    of less than or slightly above 2% for M/E FOC and shaft revolution. In addition,
    as MAPE values using GAM and MARS are densely distributed, indicating that GAM
    and MARS can yield more robust prediction results regardless of the hyperparameters
    than GBR. However, GBR has high variation in values of error measures, i.e., GBR
    model is very sensitive to the values of hyperparameters, so that it cannot be
    used without hyperparameter tuning. The deterministic tree-based methods such
    as GBR are highly affected by hyperparameter values because the hyperparameters
    build the tree and determine its shape. Thus, GBR models make it difficult to
    obtain reliable results that can be generally applied to large scale real-time
    ship and maritime data. Similar to Fig. 4(a), the RRMSE and NSE results show similar
    patterns with those of MAPE, as shown in Fig. 4(b) and (c). If the RRMSE is less
    than 10%, which is considered for a model being an accurate prediction model;
    therefore, all predictive models are accurate. The closer the NSE value is to
    1, the higher is the accuracy of the model; if it has a value of 0.7 or higher,
    the model is considered to have good accuracy. As in the previous case, GAM and
    MARS have high variation depending on the hyperparameters while both RRMSE and
    NSE values show good accuracy and low variations regardless of the hyperparameters.
    In summary, GBR is the most inaccurate and has a large variation depending on
    the values of hyperparameters, i.e., GBR is the most sensitive to the hyperparameter
    selection. Therefore, GBR should optimize the hyperparameter values to better
    fit the target data. In contrast, GAM and MARS have reasonably good accuracy compared
    to GBR; the MAPE and PPMSE values are smaller than 5% and NSE values are larger
    than 0.7. For M/E FOC and STW, GAM shows slightly better accuracy than MARS. For
    shaft revolution, MARS has slightly better accuracy than GAM. Although GAM and
    MARS are less sensitive to hyperparameter values than GBR, hyperparameter optimization
    is still required, as is the case with GBR, because there is still a clear variation
    in the accuracy of the models owing to the hyperparameters. Download : Download
    high-res image (656KB) Download : Download full-size image Fig. 4. Swarm plot
    for results of various error measures prior to hyperparameter optimization. In
    addition, the prediction models evaluated with test datasets are less accurate
    than the one with valid datasets because the valid datasets and test datasets
    have different characteristics. The target datasets could have only a nonlinear
    pattern in some areas of the entire time domain; however, significant changes
    in target data are not observed over the entire time domain. As valid datasets
    are randomly extracted from a sixth of the total dataset, they are considered
    relatively more error-prone than test datasets because they do not depict nonlinearity
    that occurs continuously over time. However, the difference between the two error
    values is very small; therefore, there is no problem with the bias of the model.
    To improve the accuracies of the prediction models, the GAM, GBR, and MARS hyperparameters
    were adjusted by using Bayesian optimization. Table 7 lists the average values
    of each error measure for the initial hyperparameters and the optimum hyperparameters
    where the initial hyperparameters are randomly selected over five times. The accuracies
    of all models significantly improve when the model is obtained using the optimized
    hyperparameter value rather than the one using the initial hyperparameter value.
    In particular, the GBR model accuracy is significantly improved compared to other
    models after hyperparameter tuning, with the highest accuracy, especially for
    M/E FOC. The accuracy of the MARS model is the highest for the shaft revolution
    and STW. STW has relatively lower accuracy compared with M/E FOC and shaft revolution,
    which are strongly correlated with factors related to performance, while STW is
    somewhat less predictable as it is affected by weather effects, which are not
    considered as input variables to build a model herein. Fig. 5 shows the Taylor
    diagram for graphically comparing the prediction results for the three output
    variables (M/E FOC, Shaft solution, and STW) modeled by GAM, GBR, and MARS. The
    Taylor diagram schematizes how well predictive data fit with observed data through
    standard deviation (SD), correlation coefficient, and center root-mean-square
    reference (CRMSD) [35]. The gray dotted contour plot represents the contour lines
    of the constant CRMSD values that increase as they move away from the contour
    center. The SD for the predicted data is proportional to the radial distance from
    the origin, and the red reference arc represents the SD of the observed data.
    The azimuth position of each point represents the correlation coefficient between
    the predicted and observed data. The closer a model is to the red reference arc
    with a high correlation coefficient, the closer the predicted data is to the observed
    data. Fig. 6 shows the accuracy of each model to evaluate bias in GAM, GBR, and
    MARS using the verification dataset and the test dataset. Before adjusting the
    hyperparameter, the results were marked as a circle (O) and after parameter optimization
    as a triangle ( ). Table 7. Error measure values before and after hyperparameter
    optimization. Empty Cell Empty Cell Empty Cell MAPE RRMSE NSE Empty Cell Empty
    Cell Empty Cell Valid Test Valid Test Valid Test M/E FOC GAM Initial 0.4250 1.2169
    0.6965 1.6396 0.9928 0.8230 Opt. 0.3630 1.2010 0.6301 1.6519 0.9942 0.8207 GBR
    Initial 3.3292 2.2513 4.7733 2.7362 0.6160 0.4487 Opt. 0.0265 0.7284 0.1095 1.2556
    0.9998 0.8964 MARS Initial 0.9552 1.2640 1.4697 1.9451 0.9651 0.7466 Opt. 0.4361
    0.9349 0.7270 1.5200 0.9922 0.8481 Shaft revolution GAM Initial 0.3771 1.1329
    0.8462 2.2900 0.9595 0.8172 Opt. 0.3517 1.1571 0.8184 2.2655 0.9621 0.8214 GBR
    Initial 1.4560 1.7141 2.8431 4.4401 0.5089 0.3024 Opt. 0.0670 0.7758 0.3479 2.0714
    0.9932 0.8507 MARS Initial 0.5846 0.8105 1.1731 1.8587 0.9214 0.8797 Opt. 0.3750
    0.8344 0.7246 1.8126 0.9703 0.8857 STW GAM Initial 1.0150 2.9224 1.3704 3.2765
    0.9498 0.7578 Opt. 0.9101 3.0269 1.2315 3.3798 0.9599 0.7425 GBR Initial 2.6907
    3.3524 4.0446 5.6100 0.5309 0.2828 Opt. 0.2895 3.5198 0.4457 3.9858 0.9947 0.6418
    MARS Initial 1.3339 3.1745 1.9208 3.6411 0.9015 0.7003 Opt. 0.9756 2.9732 1.3031
    3.3592 0.9551 0.7456 The results in Table 7 show that GAM and MARS models have
    high accuracy and robustness regardless of verification and test datasets before
    and after hyperparameter optimization, while the performance of GBR models is
    highly variable. The performance results of each model show that GAM has high
    accuracy in validation datasets, while showing the lowest accuracy for test datasets;
    thus, the possibility of overfitting is higher than that of other models. The
    GBR results converge to the center of CRMSD contours after hyperparameter tuning,
    and the MARS model demonstrated high performance in STW prediction results. All
    models have significantly increased the prediction accuracies through hyperparameter
    optimization, and they have adequate accuracy based on the results of error measures.
    However, depending on the output variable, the model having the highest accuracy
    can be different, similar to the above cases. The actual collection of ship and
    marine data makes it difficult to predict a ship’s performance due to various
    factors such as ship specifications, routes, and weather, and it is difficult
    to know in advance the model to be used for predicting the output variables. Therefore,
    constructing a meta-regression model that can ensure predictive accuracy regardless
    of the nature of the data is necessary. Combining all single-machine learning
    models, meta- regression models are generated. To observe the effect of randomness
    in selecting training, validation, and test datasets on model accuracy, the k-fold
    cross-validation method is used. K-fold cross-validation divides the total datasets
    into training, valid, and test datasets with a 4:1:1 ratio. Once one training
    dataset is determined, another dataset becomes a validation dataset and the subsequent
    dataset becomes a test dataset. In general, k-fold cross-validation continues
    until all data are used as a test dataset at least one time. Subsequently, all
    error values obtained from each cross-validation iteration is taken as averages
    and is used to obtain the most optimum model. In this study, all datasets are
    divided into six datasets; subsequently, the test data with 1:6 ratio is separated
    from the other datasets and extracted sequentially depending on time. After fixing
    the test dataset, datasets with 4:6 ratio are trained in order and validation
    dataset with 1:6 ratio are used for hyperparameter tuning at each cross-validation
    iteration and they are used to verify the variance of model accuracy across five
    iterations. The results of the three single models and meta-regression model are
    presented in Table 7, along with a comparison of accuracies using the training
    dataset and the validation dataset. Fig. 6 shows the results of the accuracy comparison
    between models through the Taylor diagram for five cross-validations. Download
    : Download high-res image (794KB) Download : Download full-size image Fig. 5.
    Taylor diagram of results of various error measures before and after hyperparameter
    optimization. When the meta-learning model was used, it had the highest accuracy
    of predicting M/E FOC, but for shaft revolution and STW, the GBR and MAR models
    had the highest accuracy. This is because the meta model assigns high weights
    on the most accurate model with hyperparameters tuned from the valid datasets,
    but its accuracy is validated for the test datasets. Thus, when the characteristics
    of the valid datasets and the test datasets are marginally different, similar
    to this case study, the meta model may have undesirable results to some extent
    compared with other models. However, as each model has increased accuracy using
    Bayesian optimization, and the meta model shows results to be almost identical
    to the accuracy of each model, a meta model is still needed to double check the
    accuracy of each model. While determining which model is the most accurate after
    learning, verifying, and testing datasets is possible, which model will be the
    most accurate before learning the data cannot be predicted. This is more evident
    in the Taylor diagram in Fig. 6. The three single-machine learning models look
    similar due to the small range of errors for the verification dataset, but the
    test datasets show different results in the predicted results of the three output
    variables. On the contrary, the meta-learning model combines different machine
    learning models to ensure robust prediction results regardless of validation and
    test datasets, while having similar or better accuracy to single-machine learning
    models. Even though the meta model may sometimes have slightly lower accuracy
    than the one with the highest accuracy owing to different characteristics of the
    validation and test datasets. However, if the datasets used from real-time ship
    operation are divided into segmented datasets similar to the manner used for real-time
    ship operation, the accuracy of the meta model is likely to be higher than that
    of other single models, and the characteristics of valid datasets and test datasets
    will be similar. Although the accuracy of each model was mainly compared earlier,
    developing a usable data gap analysis framework for shipping companies is important;
    thus, a gap analysis framework that can always accurately and robustly detect
    abnormal data regardless of the type or nature of the model. Therefore, based
    on the accurately predicted values, the lower and upper bounds of the allowable
    range for three output variables were defined with 5%, 8%, and 10% of the relative
    error values, respectively. The real values of the three output variables are
    not shown by the shipping companies due to confidentiality issues; therefore,
    only the comparison results of prediction and target data and the relative error
    values at a certain range of serial training data are shown in Fig. 7. Table 8.
    Error measure values using GAM, GBR, MARS and meta models. Output var. Model MAPE
    RRMSE NSE Time [min] M/E FOC GAM 1.2189 1.6840 0.8107 33 GBR 0.7294 1.2637 0.8939
    35 MARS 0.9099 1.5101 0.8478 31 Meta 0.7282 1.2610 0.8130 99 Shaft revolution
    GAM 1.2184 2.2953 0.8148 22 GBR 0.8461 2.1030 0.8456 24 MARS 1.7326 3.7539 −0.0070
    26 Meta 1.4283 2.3607 0.7856 72 STW GAM 3.0776 3.4534 0.7439 31 GBR 3.6256 4.0968
    0.6448 45 MARS 2.9085 3.3013 0.7654 63 Meta 3.6675 4.1610 0.7432 139 Download
    : Download high-res image (1MB) Download : Download full-size image Fig. 6. Taylor
    diagram for results of error measures after hyperparameter optimization. The predicted
    data are significantly different from the target data for a particular interval
    expected to be the starting and stopping time intervals of the engine, which is
    outside the acceptable range defined by the relative error values. In particular,
    as shown in Table 8, STWs are more affected by weather factors than other output
    variables, unlike M/E FOC and shaft revolution. Therefore, it is recommended that
    STW use a higher value of relative error to conservatively detect abnormal data.
    As the detection of abnormal data based on the reference relative error value
    differs, the reference relative error value should be determined carefully by
    a skilled engineer. Table 9 shows the numerical results of Fig. 7 using GAM, GBR,
    MARS, and the meta model. As the accuracies of GAM and MARS are similar, the percentage
    ratios of abnormal data are similar. Similarly, GBR and meta-learning models have
    similar accuracies as shown in Table 8, the percentage ratios of abnormal data
    are also similar. As the reference relative error becomes larger, the allowable
    range of normal data becomes wide so that the percentage of data beyond the allowable
    range becomes smaller. Based on the detected abnormal data for the output variables,
    the engineers aboard the actual ship can diagnose the condition of the sensors
    mounted on the ship or machinery components using the obtained abnormal data.
    We herein enable more reliable prediction of ship performance by proposing a robust
    meta-learning model readily available in shipping companies, and in particular,
    helping with data-based decision-making through a sequential data gap analysis
    framework in ships and marine data exposed to various operating conditions and
    climatic environments. The meta-model confirms that NSE 0.7 or higher accuracy
    is obtained for all target data, and it can be seen that normal data accounts
    for 90% of all performance factors within 5% of the relative error in most sections
    of the entire ship operation except for some transient conditions. In addition,
    while single machine learning models obtain different predictive results for the
    same data through various error analysis methods, the proposed meta-model is more
    valuable in enabling more reliable predictions of ship performance through a robust
    integrated machine leading model. However, as with the computational time presented
    in Table 8, the meta model is expected to be the sum of the learning time of single
    machine learning models and thus should be handled carefully if it is necessary
    to frequently learn the data in consideration of the learning time required. However,
    linear regression models of meta models are generated in a short period of time,
    and for abnormal detection, predictions are made in a very short period of time
    using a given machine running the model after learning; thus, monitoring the ship’s
    condition in real time after a sufficient learning period is highly useful. In
    this study, three months’ worth of ship operation data were used, but this was
    limited to account for environmental factors depending on seasonality and transient
    conditions such as engine start-up and shutdown. Therefore, verifying the accuracy
    and effectiveness of the proposed framework by utilizing annual vessel and marine
    data for long-term operation ships in the future is necessary. Download : Download
    high-res image (439KB) Download : Download full-size image Fig. 7. Results of
    detecting abnormal data with 5% reference relative error. Table 9. Percentage
    ratio of abnormal and normal data. Empty Cell Reference error M/E FOC Shaft revolution
    STW Empty Cell Empty Cell Abnorm. Norm. Abnorm. Norm. Abnorm. Norm. 5% GAM 2.5816
    97.418 2.9434 97.057 7.1494 92.851 GBR 2.2154 97.785 2.5322 97.468 18.8038 81.196
    MARS 3.0310 96.969 2.4109 97.589 4.1185 95.882 Meta 2.2109 97.789 2.5434 97.457
    19.6508 80.349 8% GAM 0.1842 99.816 2.0693 97.931 1.7817 98.218 GBR 0.0000 100.000
    2.0761 97.924 1.5548 98.445 MARS 0.7212 99.279 1.7907 98.209 1.2223 98.778 Meta
    0.0000 100.00 2.0716 97.928 1.8851 98.115 10% GAM 0.0427 99.957 1.7570 98.243
    1.3818 98.618 GBR 0.0000 100.000 1.6312 98.369 0.5842 99.416 MARS 0.2966 99.7034
    1.5818 98.418 0.9010 99.099 Meta 0.0000 100.000 1.5997 98.400 0.5999 99.400 6.
    Conclusions Large amounts of ship and maritime data include various forms of error
    such as outliers and bias, and some of them are even missing. To eliminate these
    errors, a rule-based approach has been primarily used to detect and replace error
    data based on allowable reference values. However, using the rule-based approach
    is difficult when the rules are complicated and nested, and the output data associated
    with ship performance are not easily detected with rule-based approach. To detect
    and replace these errors, the data was refined through the rule-based method and
    data preprocessing methods; moreover, a data gap analysis framework for detecting
    abnormal data was proposed using the meta-learning model. The developed methodologies
    and obtained results are summarized as follows: • A data gap analysis framework
    has been built for ship and maritime data. The quality of real-time ship maritime
    data such as ship engine data, weather data, and navigation data are improved
    via sequential and systematic data preprocessing, including data imputation, clustering,
    denoising, and dimension reduction. • This study generated a more accurate and
    robust model using a meta-regression model that combines widely used machine learning
    models in the ship and maritime field, GAM, GBR, and MARS. Through Bayesian optimization,
    model accuracies of each model are improved and the meta model demonstrates accurate
    and robust prediction results. Through various error measures, the accuracy of
    the model has been verified because the meta model has a value of less than 5%
    MAPE, RRMSE, and more than 0.7 NSE for M/E FOC, shaft revolution, and STW. The
    prediction results using the meta model are consistently accurate regardless of
    the validation and test datasets through the Taylor diagram. • Using the meta
    model, the data gap analysis of M/E FOC, shaft revolution, and STW was performed
    and abnormal data were well detected with 5%, 8%, and 10% of relative error percentages
    of abnormal data, respectively. As a follow-up study of the study to predict ship
    performance through ship and sea data, this paper contributes to ensuring the
    reliability of the data-driven decision for ship management by proposing a robust
    model that solves the problem of obtaining unpredictable prediction results of
    data-based models in the form of black boxes. Constructing the meta model requires
    a long time as it needs to learn and combine each machine learning model; however,
    it can be a very effective method for data gap analysis as it can ensure the accuracy
    and stability of predictions. The exact prediction model enables us to predict
    ship performance and economical ship operation, and the data gap analysis based
    on it can detect faults of in-ship machinery or sensors in advance, thereby enabling
    stable and efficient ship operation and reducing ship maintenance costs. Therefore,
    smart ships that collect ship and marine data in real time indeed require the
    proposed data gap analysis for intelligent decision-making and efficient and economical
    ship management. CRediT authorship contribution statement Miyeon Jeon: Software,
    Validation, Formal analysis, Visualization, Investigation, Writing - original
    draft. Yoojeong Noh: Conceptualization, Supervision, Writing - review & editing,
    Project administration. Kyunghwan Jeon: Data acquisition, Methodology. Sangbong
    Lee: Data acquisition. Inwon Lee: Funding acquisition. Declaration of Competing
    Interest The authors declare that they have no known competing financial interests
    or personal relationships that could have appeared to influence the work reported
    in this paper. Acknowledgments This work was supported by the National Research
    Foundation of Korea (NRF) grant funded by the Korea government (MSIP) through
    GCRC-SOP (No. 2011-0030013) and the MSIT (2018R1D1A1A02086093 and 2020R1A5A8018822).
    References [1] Jeon M., Noh Y.Y. Shin Y., Lim O.-K. Prediction of ship’s fuel
    consumption using artificial neural network J. Mech. Sci. Technol., 32 (12) (2018),
    pp. 5785-5796 CrossRefView in ScopusGoogle Scholar [2] Bunse K., Vodicka M., Schönsleben
    P., Brülhart M., Ernst F.O. Integrating energy efficiency performance in production
    management–gap analysis between industrial needs and scientific literature J.
    Cleaner Prod., 19 (6–7) (2011), pp. 667-679 View PDFView articleView in ScopusGoogle
    Scholar [3] de Wilde P. The gap between predicted and measured energy performance
    of buildings: A framework for investigation Autom. Constr., 41 (2014), pp. 40-49
    View PDFView articleView in ScopusGoogle Scholar [4] Yuan J., V. Nian V. Ship
    energy consumption prediction with Gaussian process metamodel Energy Procedia,
    152 (2018), pp. 655-660 View PDFView articleView in ScopusGoogle Scholar [5] Beşikçi
    E.B., Arslan O., Turan O., Ölçer A.I. An artificial neural network based decision
    support system for energy efficient ship operations Comput. Oper. Res., 66 (2016),
    pp. 393-401 Google Scholar [6] Petersen J.P., Winther O., Jacobsen D.J. A machine-learning
    approach to predict main energy consumption under realistic operational conditions
    Ship Technol. Res., 59 (1) (2012), pp. 64-72 CrossRefView in ScopusGoogle Scholar
    [7] Wang S., Ji B., Zhao J., Liu W., Xu T. Predicting ship fuel consumption based
    on LASSO regression Transp. Res. D, 65 (2018), pp. 817-824 View PDFView articleView
    in ScopusGoogle Scholar [8] Soner O., Akyuz E., Celik M. Use of tree based methods
    in ship performance monitoring under operating conditions Ocean Eng., 166 (2018),
    pp. 302-310 View PDFView articleView in ScopusGoogle Scholar [9] Hu Z., Jing Y.,
    Hu Q., Sen S., Zhou T., Osman M.T. Prediction of fuel consumption for enroute
    ship based on machine learning IEEE Access, 7 (2019), pp. 119497-119505 CrossRefView
    in ScopusGoogle Scholar [10] Uyanik T., Karatuğ Ç., Arslanoğlu Y. Machine learning
    approach to ship fuel consumption: A case of container vessel Transp. Res. D,
    84 (2020), 10.1016/j.trd.2020.102389 Google Scholar [11] Gkerekos C., Lazakis
    I., Theotokatos G. Machine learning models for predicting ship main engine fuel
    oil consumption: A comparative study Ocean Eng., 188 (2019), Article 106282 View
    PDFView articleView in ScopusGoogle Scholar [12] Farag Y.B.A., Ölçer A.I. The
    development of a ship performance model in varying operating conditions based
    on ANN and regression techniques Ocean Eng., 198 (2020), Article 106972 View PDFView
    articleView in ScopusGoogle Scholar [13] Yuan Z., Liu J., Liu Y., Zhang Q., Liu
    R.W. A multi-task analysis and modelling paradigm using LSTM for multi-source
    monitoring data of inland vessels Ocean Eng., 213 (2020), Article 107604 View
    PDFView articleView in ScopusGoogle Scholar [14] Wang H., Zhang Y.-M., Mao J.-X.,
    Wan H.-P. A probabilistic approach for short-term prediction of wind gust speed
    using ensemble learning J. Wind Eng. Ind. Aerodyn., 202 (2020), Article 104198
    View PDFView articleView in ScopusGoogle Scholar [15] Qureshi A.S., Khan A., Zameer
    A., Usman A. Wind power prediction using deep neural network based meta regression
    and transfer learning Appl. Soft Comput., 58 (2017), pp. 742-755 View PDFView
    articleView in ScopusGoogle Scholar [16] S.E. Haupt, B. Kosovicv, Big data and
    machine learning for applied weather forecasts: Forecasting solar power for utility
    operations, in: Proc. IEEE Symposium Series on Computational Intelligence, Cape
    Town, South Africa, 2015. Google Scholar [17] Erdal H.I., Karakurt O. Advancing
    monthly streamflow prediction accuracy of CART models using ensemble learning
    paradigms J. Hydrol., 477 (16) (2013), pp. 119-128 View PDFView articleView in
    ScopusGoogle Scholar [18] A. Radonjic A., Vukadinovic K. Application of ensemble
    neural networks to prediction of towboat shaft power J. Mar. Sci. Technol., 20
    (1) (2015), pp. 64-80 Google Scholar [19] Hinnenthal J., Clauss G. Robust Pareto-optimum
    routing of ships utilizing deterministic and ensemble weather forecasts Ships
    Offshore Struct., 5 (2) (2010), pp. 105-114 CrossRefView in ScopusGoogle Scholar
    [20] W. Ling, F. Dong-Mei, A novel approach using SVR ensembles for minor prototypes
    prediction of seawater corrosion rate, in: Proc. Second International Workshop
    on Computer Science and Engineering, Qingdao, China, 2009. Google Scholar [21]
    Stuart L. Least squares quantization in PCM IEEE Trans. Inf. Theory, 28.2 (1982),
    pp. 129-137 CrossRefView in ScopusGoogle Scholar [22] Rousseeuw P.J. Silhouettes:
    a graphical aid to the interpretation and validation of cluster analysis J. Comput.
    Appl. Math., 20 (1987), pp. 53-65 View PDFView articleView in ScopusGoogle Scholar
    [23] Roweis S., Ghahramani Z. A unifying review of linear Gaussian models Neural
    Comput., 11 (2) (1999), pp. 305-345 View in ScopusGoogle Scholar [24] Perera L.P.,
    Mo B. Marine engine operating regions under principal component analysis to evaluate
    ship performance and navigation behavior IFAC-PapersOnLine, 49 (23) (2016), pp.
    512-517 View PDFView articleView in ScopusGoogle Scholar [25] Nelder J.A., Wedderburn
    R.W. Generalized linear models J. R. Stat. Soc. Ser. A General, 135 (3) (1972),
    pp. 370-384 CrossRefGoogle Scholar [26] Larsen K. GAM: The predictive modeling
    silver bullet, Stitch Fix (2015) [Online]. Available: http://multithreaded.stitchfix.com/assets/files/gam.pdf.
    (Accessed 20 September 2019) Google Scholar [27] Freund Y., Schapire R.E. A decision-theoretic
    generalization of on-line learning and an application to boosting J. Comput. Syst.
    Sci., 55 (1) (1997), pp. 119-139 View PDFView articleView in ScopusGoogle Scholar
    [28] P. Wang, Y. Dou, Y. Xin, The analysis and design of the job recommendation
    model based on gbrt and time factors, in: Proc. 2016 IEEE International Conference
    on Knowledge Engineering and Applications, ICKEA, Singapore, 2016. Google Scholar
    [29] Zhang W., Goh A.T. Multivariate adaptive regression splines and neural network
    models for prediction of pile drivability Geosci. Front., 7 (1) (2016), pp. 45-52
    View PDFView articleGoogle Scholar [30] Friedman J.H. Multivariate adaptive regression
    splines Ann. Statist., 19 (1) (1991), pp. 1-67 Google Scholar [31] T. T. Hastie,
    R. Tibshirani, J. Friedman, The Elements of Statistical Learning: Data Mining,
    Inference, and Prediction, Springer Series in Statistics, New York, NY, USA, 2009.
    Google Scholar [32] K. Kawaguchi, L.P. Kaelbling, T. Lozano-Pérez, Bayesian optimization
    with exponential convergence, in: Proc. Advances in neural information processing
    systems, Montreal, Canada, 2015. Google Scholar [33] Brochu E., Cora V.M., De
    Freitas N. A Tutorial on Bayesian Optimization of Expensive Cost Functions, with
    Application To Active User Modeling and Hierarchical Reinforcement Learning: Technical
    Report TR-2009-23 Department of Computer Science, University of British Columbia
    (2009) Google Scholar [34] Botchkarev A. A new typology design of performance
    metrics to measure errors in machine learning regression algorithms Interdiscip.
    J. Inf. Knowl. Manag., 76 (2019), p. 45 View in ScopusGoogle Scholar [35] Taylor
    K.E. Summarizing multiple aspects of model performance in a single diagram J.
    Geophys. Res. Atmos., 106 (D7) (2001), pp. 7183-7192 View in ScopusGoogle Scholar
    Cited by (14) Meta-knowledge guided Bayesian optimization framework for robust
    crop yield estimation 2024, Journal of King Saud University - Computer and Information
    Sciences Show abstract An Evolutionary Artificial Neural Network approach for
    spatio-temporal wave height time series reconstruction 2023, Applied Soft Computing
    Show abstract Generalizing supervised deep learning MRI reconstruction to multiple
    and unseen contrasts using meta-learning hypernetworks[Formula presented] 2023,
    Applied Soft Computing Show abstract Hierarchical level fault detection and diagnosis
    of ship engine systems 2023, Expert Systems with Applications Citation Excerpt
    : Hampel filter is adopted to detect the fluctuating sensor values outside the
    normal operating pattern based on sliding (moving) windows. Outliers can reduce
    the accuracy of data analysis and learning or diagnosis, so they should be removed
    using domain knowledge of the engine; missing data should be replaced with alternative
    values (Jeon, Noh, Jeon, Lee, & Lee, 2021). A marine engine is tested in accordance
    with the standards of certification, such as Det Norske Veritas (DNV), called
    a shop-test, and sensor values of the engine are measured according to varying
    loads. Show abstract A comprehensive review on the prediction of ship energy consumption
    and pollution gas emissions 2022, Ocean Engineering Citation Excerpt : The related
    data on ship energy consumption can be obtained by the real-time monitoring tool
    of energy efficiency (Chi et al., 2018; Tsujimoto and Orihara, 2019) and fuel
    consumption monitoring system (Capezza et al., 2019). On this basis, the big data
    analysis technology can be adopted to evaluate the energy efficiency level of
    the energy-consumed equipment and to reveal the causes of low energy efficiency,
    thus realizing the intelligent analysis and optimization decisions which are difficult
    to achieve only depending on the operators’ experience (Jeon et al., 2021; Lee
    et al., 2018b). Therefore, a big data collection and processing scheme is vital
    for ship energy consumption analysis (Perera and Mo, 2016). Show abstract Identification
    and reconstruction of anomalous sensing data for combustion analysis of marine
    diesel engines 2022, Measurement: Journal of the International Measurement Confederation
    Citation Excerpt : Liu et al. [26] proposed a data-driven anomaly detection framework
    for exhaust gas temperature sensing data by combining Gaussian process regression
    and kernel principal component analysis. A meta-learning model—a combination of
    various machine learning models—was used to detect the abnormal data of ship engines
    and navigation information [27]. A convolutional auto-encoder was adopted to construct
    channel-wise reconstruction error as a new feature, then local outlier factors
    were trained on the feature for detecting anomalous sensor signals [28]. Show
    abstract View all citing articles on Scopus View Abstract © 2020 Elsevier B.V.
    All rights reserved. Recommended articles Spatial and temporal allocation of ship
    exhaust emissions in Australian coastal waters using AIS data: Analysis and treatment
    of data gaps Atmospheric Environment, Volume 163, 2017, pp. 77-86 Brett Goldsworthy
    View PDF Optimal rerandomization designs via a criterion that provides insurance
    against failed experiments Journal of Statistical Planning and Inference, Volume
    219, 2022, pp. 63-84 Adam Kapelner, …, David Azriel View PDF A matrix completion-based
    multiview learning method for imputing missing values in buoy monitoring data
    Information Sciences, Volume 487, 2019, pp. 18-30 Qin Mengjiao, …, Liu Renyi View
    PDF Show 3 more articles Article Metrics Citations Citation Indexes: 13 Captures
    Readers: 46 View details About ScienceDirect Remote access Shopping cart Advertise
    Contact and support Terms and conditions Privacy policy Cookies are used by this
    site. Cookie settings | Your Privacy Choices All content on this site: Copyright
    © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved,
    including those for text and data mining, AI training, and similar technologies.
    For all open access content, the Creative Commons licensing terms apply.'
  inline_citation: '>'
  journal: Applied soft computing (Print)
  limitations: '>'
  pdf_link: null
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: Data gap analysis of ship and maritime data using meta learning
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/iccworkshops50388.2021.9473590
  analysis: '>'
  authors:
  - Lamia Chaari Fourati
  - Samiha Ayed
  citation_count: 8
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2021 IEEE International Confe... Federated
    Learning toward Data Preprocessing: COVID-19 Context Publisher: IEEE Cite This
    PDF Lamia CHAARI FOURATI; Samiha AYED All Authors 8 Cites in Papers 828 Full Text
    Views Abstract Document Sections I. Introduction II. AI/ML/DL for COVID-19 Use-cases
    III. Health Data Pre-processing at the Edge/Fog Layers IV. From Traditional Cloud/Fog/Edge
    Architecture to Federated Learning Architecture V. Future Directions and Recommendations
    toward secure and real-time COVID-19 data pre-processing Show Full Outline Authors
    Figures References Citations Keywords Metrics Abstract: During this last decade,
    in the digital era, online and real-time data management becomes essential and
    primordial in several scenarios. In the health domain, and especially for remote
    healthcare monitoring systems, the management of data in real time becomes a requirement.
    Indeed, care providers need to access the vital information and sometimes the
    processed data in order to take timely the adequate decision. However, many issues
    arise in the data processing regarding real-time aspect, computational complexity
    and patient mobility. Therefore, Federated Learning (FL) engages promising technologies
    such as the fog and the cloud computing as well as machine learning (ML) and deep
    learning (DL) to address the aforementioned issues. Fog computing enables data
    preprocessing in proximity of medical users, exploiting patients mobile phones
    or personal digital assistant (PDA) or small-scale distributed servers. In this
    paper, we pinpoint the important role of the FL-based system within Internet of
    Medical Things (IoMT) to combat COVID-19 pandemic. Specifically, we first introduce
    the architecture highlighting the fog layer within the smart healthcare system.
    We then discuss the preprocesing tasks that could be implemented at the fog layer
    with a particular focus on ML and DL tasks. After that, an investigation related
    to the FL against several COVID-19 contexts is provided. Finally, this paper explores
    open issues and future directions regarding the FL potentialities in pandemic
    situation. Published in: 2021 IEEE International Conference on Communications
    Workshops (ICC Workshops) Date of Conference: 14-23 June 2021 Date Added to IEEE
    Xplore: 09 July 2021 ISBN Information: ISSN Information: DOI: 10.1109/ICCWorkshops50388.2021.9473590
    Publisher: IEEE Conference Location: Montreal, QC, Canada SECTION I. Introduction
    A. General Context and Motivations Over the past few years, a growing interest
    has been marked with the deployment of mobile communications, computational intelligence
    systems, and Internet of Medical Things (IoMT) [1] into healthcare systems to
    provide smart health services (SHS). This emerging technologies played an important
    role during COVID-19 outbreak. Indeed, IoMT systems [2]–[4] proved their potentialities
    in combating COVID-19 pandemic in different use cases and contexts. Advances related
    to Wireless Area Networks (WBANs) [5], [6], ambient intelligence [7], big data
    analytic [8], complex event processing (CEP) [9], decision making [10] and networking
    technologies (such as 5G) [11], [12] will enable remote real-time health-monitoring
    of COVID-19 patients at any time and any location. However, COVID-19 related smart
    services facing a big challenge regarding the record, the transmission and the
    process of large amount of medical data that are collected from wearable or implantable
    medical devices due to the huge number of contaminated persons in a short time.
    Therefore, implementing pre-processing tasks at a fog layer is a promising approach
    toward cost-effective, convenient and real-time efficient for smart healthcare
    services provisioning. Several pre-processing tasks could be moved at the fog
    layer such as data filtering, data fusion, data classification, feature extraction
    and data reduction. Accordingly, the fog layer will act as a selective transfer
    scheme that transmits to the cloud layer (for data storage and data processing)
    only the necessary data based on the pre-processing results and the COVID-19 patient
    health situation. In fact, based on the patient’s state (emergency situation or
    normal), the SHS based fog computing will send the pre-processed data either to
    the cloud computing layer or to the medical staff. Furthermore, traditional cloud-based
    ML mechanisms that centralize all the data into a cloud server is not convenient
    in all COVID-19 scenarios. In fact, this facing critical issues regarding data
    privacy and security. FL [13] as an emerging paradigm come to fill this gap. FL
    implies that end-devices (mobile phones or PDA) or fog nodes are used to train
    a ML model required by the cloud nodes. After that, the end devices or the fog
    nodes send only the model updates instead of sending raw data to the cloud servers.
    According to the FL paradigm, the end devices enable the collaborative training
    of a ML model. In the following, we propose a cognitive architecture denoted FSHS
    (Fog based Smart Healthcare System) embedding all the prepocessing tasks and ML/DL
    collaborative training model at the fog layer. Fig. 1 illustrates the proposed
    FSHS architecture. The distributed mobile phones carried by patients can play
    the role of the fog layer and can do lightweight prepossessing tasks. However
    for heavy processing functionalities (such as DL models) a dedicated computing
    and storing node will be deployed in the proximity of COVID-19 patients. In emergency
    situation, notification and alerting are transmitted directly from the fog layer
    to the healthcare providers. However, in normal situations, the gathered data
    will be transferred to the knowledge and pre-processing layer for advanced analysis
    at the cloud computing nodes in order to provide advanced healthcare services.
    B. Main Contribution and Paper Structure The main goal of this paper is to study,
    analyse recent joint solutions integrating artificial intelligence (AI) module
    within the IoMT architecture that could be implemented at the fog layer according
    to the FL paradigm and that are dedicated to counter COVID-19 outbreak. In this
    regard, this paper contributes by: Presenting our vision of leveraging fog computing
    to pre-process sensed data before their transmission to the remote servers. Providing
    a review of various research efforts that deployed AI and IoMT to counter the
    COVID-19 Out-break. Identifying and discussing the research challenges of FL toward
    COVID-19 data prepossessing at the fog layer. In this context, the rest of the
    paper is organized as follows: Section 2 highlights the different use-cases regarding
    the use of AI/ML/DL and IoMT to counter COVID-19. Section 3 outlines recent works
    studied or provided architectures deploying edge or fog computing for FL. Section
    4 analyses, compares and discusses intensively the different approaches that pre-processe
    COVID-19 health data at the Edge/fog layers. Section 5 derives the future directions
    and recommendations regarding real-time COVID-19 healthcare data pre-processing
    at the fog layer. Finally, Section 6 summarizes this work. SECTION II. AI/ML/DL
    for COVID-19 Use-cases AI implies the ability of a machine to learn from previous
    experiences, adjust according to new inputs, and perform human-like tasks. This
    commonly AI definition fits well with the COVID-19 use-cases and needs. Indeed,
    AI has a primordial role in assisting with relevant questions regarding the fight
    against COVID-19 outbreak, including contact tracing, diagnosis, workplace safety,
    social distancing, ect. Many considerations should be taken into account for managing
    AI applications. In this regard and specifically for COVID-19 context authors
    in [14], highlighted considerations related to management of AI-based applications
    within COVID-19 context. In the following we highlight the main COVID-19 use-cases
    requiring the AI and the IoMT-based systems. A. Contact Tracing Contact tracing
    corresponds to the process of identifying people that have been exposed to infected
    persons which is a challenging task for the authorities. Contact tracing is useful
    for the countries in the beginning of the COVID-19 outbreak (in the first or in
    the second stage). Authors in [15] pinpointed that most of contact tracing applications
    that rely only on GPS and Bluetooth technologies to track contact-persons and
    infected persons suffer from several limitations (security, battery, proximity,
    etc.). Accordingly, they recommended the use of emerging technologies especially
    AI for contact tracing solutions. Besides that, authors in [16] highlighted the
    example of South Korea and Singapore countries that have implemented COVID-19
    contact tracing apps. The smartphones that use AI and fever detecting infrared
    cameras have been deployed to scan public space for potentially affected persons
    and to trace a person’s location. In general, CNN (Convolutional Neural Networks)
    algorithms are used to detect and to classify COVID-19 radiology images, the RNN
    (Recurrent Neural Network) are deployed to predict patients’ status and the LSTM
    (Long-Short Term Memory) to diagnose and predict future medical outcome. Furthermore,
    AI models were suggested also to monitor crowd information and to enforce a physical
    distancing. B. COVID screening and Diagnosis Rapid screening and diagnosis process
    limits the spread of COVID-19. In this regard, AI and ML are used to augment the
    efficiency’s of diagnosis and screening processes. The AI-powered temperature
    screening allow symptoms detection and isolation of suspected persons, this technique
    was deployed in several Chinese public locations during the COVID-19 pandemic.
    The use of AI on X-ray [18] and computed tomography (CT) medical imaging played
    an important role against COVID-19. In this context, authors in [17] reviewed
    AI techniques in imaging data Acquisition, processing, and diagnosis toward COVID-19
    detection. Besides that, authors in [19] suggested a new model for COVID-19 diagnosis
    using CNN (including: VGG-16, VGG-19, SqueezeNet, AlexNet, GoogleNet, ResNet-18,
    ResNet-50, MobileNet-V2, ResNet-101, and Xception). The proposed system employs
    ML on 1020 CT images of 108 Covid-19 infected patients along with viral pneumonia
    of 86 patients. The result is that the best performances are obtained with ResNet-101.
    In the same context, but using chest X-rays, authors in [20] proposed an accurate
    method in terms of processing time and memory and for COVID-19 screening in chest
    X-rays. Accordingly, they exploited and extended the EfficientNet family of deep
    artificial neural networks due to their high accuracy. They used a database comprised
    of 13,800 X-ray images including 183 images from COVID-19 patients. The obtained
    result are promising. C. Prediction of COVID-19 Treatments and Drugs Recently,
    a great efforts have been made to deploy AI in therapeutic strategies against
    COVID-19. ML algorithms can be applied to predict whether approved medications
    can be used for disease treatment or not. In this context, authors in [21] reported
    the the use of the Naïve Bayes algorithm, to predict among ten FDA approved drugs
    which one could be used for the COVID-19 treatment. Based on their study, they
    suggested the antiretroviral drug Atazanavir (DrugBank ID – DB01072). D. Predicting
    the mortality ML prognostic algorithms deployed in several researches to estimate
    the mortality risk of a COVID-19 patient. In this regards, authors in [22] proposed
    an XGBoost ML-based prognostic model that identify critically ill COVID-19 patients
    through the extraction of three key laboratory parameters including lactic dehydrogenase,
    high-sensitivity C-reactive protein and lymphocyte count. Besides that, the model
    can predict at more than 90% accuracy the survival rates of severe patients. Fig.
    1. FSHS Architecture Show All SECTION III. Health Data Pre-processing at the Edge/Fog
    Layers A. Data Pre-processing basic concepts Data pre-processing is the most important
    and essential step to transform raw data into an obvious and coherent format at
    the fog or edge nodes. Thus, Data pre-processing aims to resolve some problems
    related to sensed data such imperfect, incomplete, and inconsistent data, and
    that contain errors and also data used to train ML/DL models. Several techniques
    are used in the data mining methods such as data pre-processing [23] which is
    used to solve problems using Knowledge Discovery from Data (KDD) process in order
    to eliminate some problems like the imperfect and unnecessary data and to standardize
    the data format. Since it exists large amounts of raw medical data in the world,
    human or manual applications cannot treat these data. So, KDD is used to have
    good treatment of healthcare data. Data pre-processing requires several steps
    including: (1) Data cleaning which assumes to detect and correct errors presented
    on data stored in databases or in files; (2) Data integration which is used to
    get a coherent combining of data; (3) Data transformation that involve the conversion
    of data from a format or structure to another; (4) Data reduction to reduce the
    mandatory amount of capacity to store data ; and (5) Data training. B. Benefits
    of Moving Data Pre-processing to the EDGE/FOG Layer for e-health systems Recently,
    several contributions suggested SHS architectures that integrates the fog or the
    edge layer for health data pre-processing. In the following, we discuss relevant
    literature’s that studied, examined or provided architectures based on the use
    of edge or fog computing layers for data pre-processing. The authors in [24] studied
    and pinpointed the benefits of the Fog Computing paradigm when it is applied to
    healthcare system. The main benefits are related to network usage, latency, and
    power consumption. Authors in [25] studied fog-enabled SHS toward secure and cooperative
    healthcare service provision. They suggested an infrastructure that includes a
    fog layer and they highlighted the benefits of the fog layer toward emergent healthcare
    service, healthcare notification and health risk assessment. Besides that they
    discussed the security and cooperative challenges facing fog-enabled SHS. To illustrate
    the efficiency of the use of fog computing regarding healthcare service the authors
    presented a privacy-preserving fog-assisted health data sharing case study. In
    the same context, authors in [26] suggested an energy efficient fog-assisted healthcare
    system to monitor the blood glucose level of the diabetic patients. Accordingly,
    the uses of a fog layer to process the gathered data and to take timely the adequate
    decision enhances the global SHS efficiency in terms of energy efficiency, computational
    complexity, prediction accuracy, and latency. Besides that, the efficiency of
    moving computational intelligence to the edge layer was confirmed in [27]. Indeed,
    the authors implemented an efficient real-time edge-based classification and data
    reduction techniques to monitor, process, and make decisions for smart health
    applications. The provided experimental results confirm the effectiveness of the
    proposed system in terms of data reduction, classification-accuracy, battery lifetime,
    and transmission delay. C. Data Pre-processing at the EDGE/FOG Layer: COVID-19
    Context In this subsection we focus on systems and solutions that have been proposed
    to deal with data pre-processing at the EDGE/FOG and that considered the COVID-19
    use-cases. Accordingly, in [28] authors proposed presented a new IoT-fog-cloud
    based architecture supporting the distributed inter and intra-layer communication,
    the real-time stream processing, the fog multitenancy and , the resource scalability.
    They modeled the coronavirus disease 2019 monitoring systems according the proposed
    architecture by using the proposed BPMN 2.0 extension. Furthermore, they suggested
    a proto-type to carry out a set of experiments. Another interesting solutions
    was suggested in [29] where authors designed a non-contact respiratory monitoring
    system that is based on three-tier architecture, including robot&edge&cloud layers.
    To verify the effectiveness of the proposed architecture, the authors deployed
    a public CT images dataset for COVID-19 patients. The obtained computation time
    costs of the proposed architecture are less than that of an architecture including
    only a cloud layer or an "edge+cloud" layers. To guarantee user data privacy,
    security, and low-latency authors in [30] developed an edge IoMT framework that
    deploys DL to detect diverse COVID-19 symptoms and generates alerts and reports
    useful for medical decision support. The proposed framework was evaluated for
    several applications including sick or non-sick from In-Home cough sound analysis,
    drowsiness analysis and face mask detection… SECTION IV. From Traditional Cloud/Fog/Edge
    Architecture to Federated Learning Architecture In the previous section, we pinpoint
    the advantages of using Edge/Fog nodes for data pre-processing. However, this
    traditional architecture presents a set of drawbacks mainly related to the security
    requirements as well as to the system performances. When dealing with the e-health
    domain, the health data are considered sensitive and privacy-preserving becomes
    a primordial challenge. The traditional fog based architectures try to have data-processing
    closer to the production site, which enhance the system’s responsiveness to events.
    The Fog layer improves a series of issues, it leads to latency decrease, bandwidth
    consumption reduction and seamless operation for a recharge. The cloud layer for
    these traditional architectures are considered to offer good performances for
    deep learning and machine learning techniques. In this paper, we propose to enhance
    these traditional architectures by integration the federated learning. This new
    paradigm, recently introduced and explored in the vehicular networks can be relevant
    in the context of the e-health care. The first advantage of this paradigm is its
    ability to better enforce the security and privacy concerns related to patients.
    The main idea consists on dividing the intelligence of the deep learning techniques.
    Actually, there is no approach that consider this paradigm within the e-health
    domain in general and for the COVID-19 use case in particular. A. Integrating
    FL into e-health domain: How it works? The FL approach is based on the collaboration
    of the e-health devices that should participate in the training model. The whole
    process is composed of three main steps: The first step consists of constructing
    the local models for each participant. These participants are called data owners.
    The aim of this phase is to guarantee that the training data remain on personal
    devices. Thus, the user privacy is ensured. The feasibility of this first phase
    relies on the advances of the sensing devices that are equipped increasingly with
    better computing capabilities as well as on the advances in deep learning techniques.
    During the second step, the local models are transferred to the server responsible
    for the global model, called model owner. This server should be located in the
    cloud. It is responsible for aggregating the received models to generate the global
    model to be considered for the training phase. This phase supposes that the received
    models are accurate and based on correct data. As we already said, the FL approach
    is a collaborative approach. Thus, the assumptions of having honest nodes is primordial.
    During the third step, once the global model is aggregated based on the local
    models, the parameters of this model are sent back to different participants.
    Based on these parameters, the local models are iterated and the process is repeated
    until reaching the model convergence. B. Integrating FL into e-health domain:
    key innovations Compared to traditional architectures, the key innovations of
    integrating FL within the FSHS framework are: Establishing distributed training
    models that can enforce privacy and security concerns about the health data of
    patients. Migrating from centralised approach to a collaborative approach that
    allows the use of Device-to-Device connections. Thus, the system performances
    can be widely enhanced. Distributing task processing based on an FL approach improves
    numerous system metrics: latency, cost, and privacy. Generating updated, parallel
    and successive local training models increases the accuracy of the global model.
    SECTION V. Future Directions and Recommendations toward secure and real-time COVID-19
    data pre-processing Integrating FL within the FSHS architecture is interesting
    and has many advantages as explained previously. However, it may raise new challenges.
    For that, we expose in this section a set of attention points that should be considering
    while combining IoMT and FL. Continuous collaboration: the FL approach is based
    on the collaboration of the edge nodes for participating in the training model.
    In this context, the participant connections are supposed to be constantly available.
    The new FL algorithms that should be defined in order to combat COVID-19 pandemic
    have to address the drop out of participants. The devices characteristics (e.g.
    energy constraints, computation resources, etc.) should be involved within the
    model building process. Indeed, the new algorithms should be robust in order to
    avoid the bad impacts on the system performances related to the accuracy as well
    as the convergence speed. Security and privacy concerns: one advantage of considering
    the FL approach is to preserve the privacy of users. In the context of e-health
    in general and more specifically for the COVID-19 use case, the considered data
    are considered sensitive since they can reveal private information related to
    the health status of the patient. This is more challenging when the patient is
    suffering from other diseases that he should declare them to permit accurate treatment
    and processing of the transmitted data. On the one hand, the transmitted data
    should preserve the privacy data of the patient. On the other hand, these data
    should be useful for deducing relevant conclusions that can help in advancing
    the monitoring and the treatment of COVID-19. Another attention point is that
    the integration of a FL approach while guaranteeing the privacy and security properties
    should not degrade the system performances. System performances: the COVID-19
    application is an e-health application that may present specific requirements.
    When we consider the emergency case, the data transmission becomes delay critical.
    In this specific context, the delay parameter should be considered more important
    than the energy expense within the FL models to be build. Depending on the application
    requirements, the FL models have to define the priority of the parameters (resource
    allocation, delay, communication costs, security, etc.) to include when building
    the models. Furthermore, the convergence of the algorithm has to considered within
    these model. The FL approach guarantee the minimization of the global model aggregation.
    However, when the input parameters becomes dynamic depending on their importance,
    the convergence of the algorithm has to be studied depending on each specific
    scenario. Clustering approaches: in the context of COVID-19 pandemic, monitoring
    the different cases depends directly on the persons that were in contact with
    the patient during the incubation period of the disease. In general, some of these
    persons can be within the same geographic area of the patient. For these cases,
    considering clustering approaches when building new FL models could be relevant
    since a set of devices will be considered as one node. The clustering approaches
    can decrease the communication costs especially when the devices within the same
    cluster communicate through Device-to-Device (D2D) connections. Performance of
    FL techniques: the FL paradigm is not really explored within the e-health domain.
    The known FL techniques to reduce communication costs are (1) Edge and End Computation;
    (2) Model Compression [31] and (3) Importance-based Updating [32]. These techniques
    should be tested, explored and compared to deduce the suitable technique to be
    considered for the e-health context in general and more specifically for the COVID-19
    use case. Moreover, the combination of these different techniques should be investigated.
    These investigations will aim not only to validated the feasibility of new hybrid
    approaches but also to propose the most fruitful combinations to be considered.
    These combinations have to take into account different scenarios for the both
    cases: normal situation and emergency. Data patterns: while applying FL approach
    for the covid-19 use case, it can be relevant to build some data patterns about
    the data to be collected and treated. These patterns have to be defined for the
    cloud as well as the edge/fog layers that will be introduced to the training model.
    These data patterns aim to minimize the heterogeneity that can be obtained from
    different collaborating devices. Minimizing heterogeneity will help in improving
    the FL algorithms convergence. Moreover, defining data patterns decreases the
    risk of errors propagation since it reduces communication imperfections as well
    as noise. As a result, the cumulative effect of these errors on the training model
    convergence is reduced. Thus, we could obtain a better speed and accuracy about
    the models convergence. Multi-layer management and resource allocation: Designing
    management algorithms for nodes orchestration at different network layers is a
    challenging issue that require more investigation from academics and scientists.
    Besides that, the allocated resources from the thing to the cloud including flow
    and load balancing designs for ML task handling is still an open issue. SECTION
    VI. Conclusion In this paper, we focused on the approach of integrating the FL
    with the IoMT and its application within the covid-19 use case. We proposed a
    FSHS architecture to show how the intelligence can be usefully distributed between
    the edge, fog and cloud layers. The integration of a FL approach brings new challenges.
    Thus, we also highlighted the different challenges that should be addressed when
    combining FL algorithms and IoMT. As future work, we explore the applicability
    of the FL techniques and study their results for the performances and the security
    of the system within an e-health context. As concrete e-health example, we consider
    the COVID-19 context. Authors Figures References Citations Keywords Metrics More
    Like This A Scalable Architecture for Rapid Development of Trackers amid Pandemics
    like COVID-19 2023 International Conference on Computational Intelligence and
    Sustainable Engineering Solutions (CISES) Published: 2023 UAV-based Life-Saving
    Solution For Police To Maintain Social-Distancing During Covid-19 Pandemic Using
    4G-LTE Technology 2021 International Conference on Communication Technologies
    (ComTech) Published: 2021 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: 'Federated Learning toward Data Preprocessing: COVID-19 Context'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1007/978-3-319-66836-9_11
  analysis: '>'
  authors:
  - Valentin Sturm
  - Dmitry Efrosinin
  - Natalia Efrosinina
  - Leonie Roland
  - M. Iwersen
  - M. Drillich
  - Wolfgang Auer
  citation_count: 2
  full_citation: '>'
  full_text: '>

    Your privacy, your choice We use essential cookies to make sure the site can function.
    We also use optional cookies for advertising, personalisation of content, usage
    analysis, and social media. By accepting optional cookies, you consent to the
    processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart International Conference on Distributed
    Computer and Communication Networks DCCN 2017: Distributed Computer and Communication
    Networks pp 120–134Cite as Home Distributed Computer and Communication Networks
    Conference paper Automated Classification of a Calf’s Feeding State Based on Data
    Collected by Active Sensors with 3D-Accelerometer Valentin Sturm, Dmitry Efrosinin,
    Natalia Efrosinina, Leonie Roland, Michael Iwersen, Marc Drillich & Wolfgang Auer  Conference
    paper First Online: 07 September 2017 734 Accesses 2 Citations Part of the book
    series: Communications in Computer and Information Science ((CCIS,volume 700))
    Abstract The paper deals with the problem of time series classification for the
    feeding state of calves by means of features evaluated for acceleration real-time
    data sets. The eartags equipped with an active sensor were developed for location
    and animal activity identification. Video records synchronized with a sensor data
    were collected from three calves. After the data preprocessing including the reconstruction
    of lost information, filtering and frequency stabilization, new time series were
    used to develop a machine-learning algorithm with equidistant and non-equidistant
    time series segmentation method based on a modified Kolmogorov-Smirnov statistic.
    The proposed classification method has achieved a good recognition quality for
    the feeding state with a best overall accuracy of approximately 94%. Thus this
    methodology is useful in identifying the feeding state and we may expect the possibility
    to generalize it to the multi-state case as well. The further improvement of the
    algorithm is a subject of our future research. Keywords Eartag Time series classification
    Kolmogorov-Smirnov statistic Machine-learning algorithm Access provided by University
    of Nebraska-Lincoln. Download conference paper PDF 1 Introduction A system with
    automated identification and classification of farm animal behaviour has the aim
    to improve livestock management and the efficiency of production by integration
    of this system into daily farm routnes. Such a system can serve as an element
    of the future smart farm. Some devices and state recognition methods have already
    been tested with different accuracy to identify farm animal behaviour. In Alvarenga
    et al. [1] a tri-axial accelerometer was attached to a halter on the under-jaw
    of each sheep. Among the forty-four features the authors have extracted the five
    most important features, including X-axis and movement variation in form of a
    sum of increments for the acceleration vector’s coordinates. As it was shown,
    the used features had the largest contribution to the quality of recognition of
    five common behaviours such as lying, standing, walking, running and grazing.
    A decision-tree algorithm was used to classify the features and has exhibited
    the highest accuracy of 85.5%. Sheep behaviour was analysed as well in Marais
    et al. [4] by means of another device attached around the sheep’s neck. It turned
    out that the most important feature is the maximum and minimum value for each
    axis in a frame. For classification the authors have used linear and quadratic
    discriminant analysis. The classification accuracy has reached a value of 89.7%
    with the usage of ten different features. The problem of the cow behaviour pattern
    recognition using a three-dimensional accelerometer placed over the neck was studied
    by Martiskainen et al. [6] and Kuankid et al. [3]. In first case the multi-class
    support vector machine classification models were constructed based on nine most
    important features to identify eight recorded behaviours. The average accuracy
    of the proposed classification model was equal to 94%. In the latter case the
    authors have implemented a simple behavioural technique based on the mean and
    variance reference values with an average accuracy of about 92.6%. Another device
    with equipped accelerometer was used by Robert et al. [5] to classify three activity
    states of the calves. It was attached to the lateral side of the right rear leg.
    Seven main features were used to train the classification model. While the accuracy
    of identification of lying and standing activities was high, the walking accuracy
    was significantly lower. The average classification accuracy for the proposed
    data sets was approximately 88.3%. Hence we conclude that accelerometers can be
    used successfully to generate data sets for accurate description of farm animal
    behaviour. To make such devices feasible for farmers they must satisfy certain
    constraints including cost, reliability, usability and power consumption. The
    Austrian company Smartbow GmbH has developed a new identification system based
    on active low-energy high-frequency sensors with 3D-accelerometer integrated into
    eartags which record measurements at 10 Hz. Comparing to the alternative systems,
    the eartags have a number of advantages, i.e. they are very comfortable for animals
    and the energy supply of the sensor is sufficient for several years. But the eartags
    can not be located with specified orientation as in previous studies where a fixed
    coordinate axis for some state was perpendicular to the ground. The separate usage
    of axis accelerations for evaluation of the features has in this case a very restrictive
    effect to the quality of classification. Hence we are interested in orientation-independent
    features, which should consist of all components of the corresponding vectors.
    Another difficult moments are related to the incompleteness of the data samples
    due to signal collisions, noisiness, strong non-stationarity and frequency instability
    of the data sets evaluated by the eartags. Moreover, according to the data material,
    many feeding states have hardly distinguishable boundaries. Therefore appropriate
    data transformation methods as well as a suitable feature vector and a new classifier
    must be found out for the recognition problem under study. In this paper we suggest
    a novel method to identify the milk feeding state from the acceleration data sets
    and determine the accuracy, sensitivity and precision. The video records synchronized
    with a sensor data are used as gold standard for the state recognition. After
    the data preprocessing including the reconstruction of the lost information through
    a stochastic simulation, solution of the problem of the unbalanced data sets for
    different states, filtering and frequency stabilization, new time series were
    used to develop a machine-learning algorithm with equidistant and non-equidistant
    time series segmentation method based on a modified Kolmogorov-Smirnov statistic.
    The described classification methods have achieved a quite good recognition quality
    for the feeding state with an overall accuracy of up to 94%, a sensitivity of
    66% and a precision of 51%. Thus the proposed methodology is useful in identifying
    the feeding state and we may expect the possibility to generalize it to the multi-state
    case as well. The further improvement of the algorithm is a subject of our future
    research. The rest of the paper is organized as follows: The Materials and Methods
    are given in Sect. 2. Section 3 presents the main results including an experiment
    methodology. 2 Material and Methods For training and testing our methods we consider
    the data of 3 calves on 5 consecutive days. These datasets consist of two different
    types, namely acceleration data provided by the Smartbow eartags, see Fig. 1,
    and video evaluation of the same 5 days, based on which we assume to know the
    true behaviour in every moment. Fig. 1. Smartbow Eartag Full size image The 3
    calves were kept in small boxes and had ad libitum access to milk, offered by
    a feeding bucket with an artificial teat. Four cameras were positioned at different
    locations in the barn to monitor the calves during the observation period. The
    resulting videos were carefully examined to classify the current behaviour on
    a granularity level of one second. In total we have 15 different datasets for
    24 h each. The acceleration data is returned and recorded in three different axes,
    with a frequency of roughly 10 Hz, in \(10^{-3}g\) steps and cut-off boundaries
    of \([-2048,2048]\), $$\begin{aligned} \mathbf{a}=\{(a_x(t),a_y(t),a_z(t)):t\in
    T)\}. \end{aligned}$$ (1) Due to the nature of the sensor fixation on the ear,
    the possible change of relative coordinates over time because of rotating or other
    movement of the RFID-chip and the lack of gyroscope, the individual coordinates
    of (1) cannot be interpreted. Thus a orientation-independent signal has to be
    evaluated, e.g. the signal vector magnitude (SVM) of the acceleration data, $$\begin{aligned}
    \mathbf{x}=\{x_t:t\in T\},~\text {where } x_t:=\sqrt{a_x^2(t)+a_y^2(t)+a_z^2(t)}.
    \end{aligned}$$ (2) These data sets are used as a main data material for the feature
    extraction and subsequent classification. 2.1 Terminology of Binary Classification
    and Model Quality As our goal is to classify the behaviour of calves with the
    help of acceleration data, in particular to detect time periods, where calves
    are drinking, we are distinguishing between two relevant states: Calf is drinking
    (1) Calf is not drinking (0), and we deal with the problem of so called binary
    classification. As our granularity is one second, we can split up the day in parts
    of length 1 s, which brings us to a total of 864000 time points to consider a
    day, and for every part we want to decide, whether the calf is currently in the
    state 0 or 1. Suppose we have given a series of data \((x_t)\) with \(x_t\in \{0,1\},
    1\le t\le N\), which represent the real states. As a result of a prognosis method
    we get a second time series \((\tilde{x}_t)\) with \(\tilde{x}_t \in \{0,1\},
    1\le t\le N\), which represents the assumed states at every moment. If less than
    5 min passed between two consecutive drinking events, they were considers as a
    single one. Based on this we define the following four values, which are conveniently
    arranged into a so called confusion matrix: Based on these four entries of the
    confusion matrix, we can build many different statistical quantities, which are
    used to represent some aspect of quality. We present a small selection: 2.2 Algorithm
    of Activity Recognition We want to give a small overview of the designed algorithm.
    It consists roughly of the following steps: 2.3 Segmentation We define two different
    procedures, based on which we distinguish two different schemes we want to compare:
    Equidistant Segmentation (ES) and change-point detection based on modified Kolmogorov-Smirnov
    statistics (KSS). The first method is more straight forward, we just split up
    the day in equidistant intervals, which are partly overlapping $$\{x_t\dots x_{t+l-1}\},\{x_{t+l/a}\dots
    x_{t+l+l/a-1}\},\{x_{t+2l/a}\dots x_{t+l+2l/a-1}\},\dots $$ where a corresponds
    to the number of times a certain interval, except for the outermost, is overlapped
    by other intervals. In our examples l was set to 600 and a was set to 1, so no
    overlapping occurred. Next we describe the alternative segmentation method based
    on a modified Kolmogorov-Smirnov statistic, see e.g. in [2, pp. 37–80]. Suppose
    we have given a time series \(\mathbf x =\{x_1,\dots ,x_N\}\) with k change-points
    at times \(t_1,\dots ,t_k\): $$\begin{aligned} 1&< \alpha \le t_1 \le \dots \le
    t_l \le \beta < N, \end{aligned}$$ where \(\alpha<\dfrac{N}{2}<\beta \). The modified
    Kolmogorov-Smirnov-Statistic is of the form: $$\begin{aligned} Y_{N}(n,\delta
    ;\mathbf{y})&:=\left[ \left( 1-\frac{n}{N}\right) \frac{n}{N}\right] ^\delta \left(
    \frac{1}{n}\sum _{k=1}^ny_k-\frac{1}{N-n}\sum _{k=n+1}^{N}y_k\right) , \end{aligned}$$
    (3) where \(n\in [1,N-1]\cap \mathbb {N}\), \(\delta \in [0,1]\) and \(\mathbf{y}=\{y_k:k\in
    [1,N]\cap \mathbb {N}\}\) is the realization of the diagnostic sequence. As it
    was shown in [2], the choice \(\delta =1\) in (3) provides the minimum false alarm
    probability, that is the probability of a decision making about the presence of
    change points when this is not true, the choice \(\delta =0\) provides minimum
    probability of false tranquillity, that is the probability of a decision making
    about the lack of change-points when this is not true and the choice \(\delta
    =1/2\) leads to the minimum of estimation error probability for a change-point.
    The statistic \(Y_N(n,1;\mathbf{y})\) for a sample of a normal distributed diagnostic
    sequence \(\mathbf{y}\) with a change-point in mean value is illustrated in Fig.
    2. According to [2], the statistic $$\begin{aligned} \tilde{Y}_{N}(\delta ;\mathbf{y})&:=
    \sqrt{N}\underset{1\le n \le N}{\max }\left| Y_{N}(n,\delta ;\mathbf{y}) \right|
    \!, \end{aligned}$$ has an asymptotic distribution in form $$\begin{aligned} \lim
    _{N\rightarrow \infty }\mathbb {P}[\tilde{Y}_{N}(1;\mathbf{y})>c]=2\sum _{k=1}^{\infty
    }(-1)^{k+1}e^{-2\big (\frac{kc}{\sigma }\big )^2}=F(c). \end{aligned}$$ We can
    calculate this statistic for every point n in the considered interval. Moreover,
    we define a point \(\hat{n}\) is a (preliminary) change-point, if \(Y_{N}(\hat{n},\delta
    )>c\), where Fig. 2. Depiction of the statistic for a realisation of the stochastic
    process \(X_1 \dots X_{500} \sim \mathcal {N}(0,1), X_{501} \dots X_{1000} \sim
    \mathcal {N}(0.5,1)\) Full size image As a time series \(y_k\) one can choose
    a transformation of the original series \(x_k\) in form \(y_k=f\left( x_k\right)
    \), where the choice of this specific function can be influenced by the type of
    change-point one wants to find. Given a time series \(\mathbf{x}:=\{x_1,x_2,\dots
    ,x_N\}\), we try to find some change-points in the first step and therefore we
    use the diagnostic sequence $$\begin{aligned} y(x_k)&:= \alpha _1 f_1(x_k)+\alpha
    _2 f_2(x_k)+\alpha _3 f_3(x_k), \end{aligned}$$ (4) with where \(\alpha _1,\alpha
    _2,\alpha _3\in [-1,1]\),  \(|\alpha _1|+|\alpha _2|+|\alpha _3|=1\), \(f_1(x_k)\)
    describes the argument where the periodogram is maximized, \(f_2(x_k)\) calculates
    the sample variance and \(f_3(x_k)\) the sample auto-covariance of order 1. The
    functions are normalized by subtracting the mean and dividing by the empirical
    standard deviation of a whole day. So for every point, we calculate the linear
    combination of three different diagnostic sequences in a sliding window of length
    \(2d+1\). Our goal is to find optimal values \(\alpha ^*_1,\alpha ^*_2,\alpha
    ^*_3\), which minimize the following cost function \(\hat{g}\): $$\begin{aligned}
    \hat{g}(\alpha _1,\alpha _2,\alpha _3)&:= \frac{1}{l} \sum _{i=1}^l\left( C_0\sum
    _{t\in S_{i,0}}\sigma \left( a_t-c\right) +C_1\sum _{t\in S_{i,1}}\sigma \left(
    c-a_t\right) \right) \!, \end{aligned}$$ (5) with $$\begin{aligned}&\sigma (x):=
    \dfrac{1}{1+e^{-x}}, \, a_t:=\max _{\hat{t}\in \{t-k,\dots ,t+k\}}\sqrt{2k+1}
    \left| Y_{2k+1}(n,1) \right| ,\\&S_{i,0}:= \{t\in I | x_t=0\},\,T_{i,0}= |S_{i,0}|,\\&S_{i,1}:=
    \{t\in I| x_t=1\},\,T_{i,1}= |S_{i,1}|,\\&C_0:={\left\{ \begin{array}{ll} \dfrac{c_0}{T_{i,0}}
    &{} \text { if } T_{i,0}> 0 \\ 0 &{} \text { if } T_{i,0}= 0 \end{array}\right.
    } , \quad C_1:={\left\{ \begin{array}{ll} \dfrac{c_1}{T_{i,1}} &{} \text { if
    } T_{i,1}> 0 \\ 0 &{} \text { if } T_{i,1}= 0 \end{array}\right. } ,\\&c_0,c_1\in
    (0,1),\,c_0+c_1=1. \end{aligned}$$ The function \(\hat{g}\) builds an average
    value of the defined sums over all considered intervals. To solve the optimization
    problem, we decide to use the data of one calf and discretize the space of possible
    arguments $$\begin{aligned} (\alpha _1,\alpha _2,\alpha _3)&\in \{-1,-0.75,\dots
    ,1\}^3, |\alpha _1|+|\alpha _2|+|\alpha _3|=1. \end{aligned}$$ Due to symmetry
    we can further restrict \(\alpha _1 \ge 0\). The two sums in (5) describe a measure
    for the amount of points inside a drinking interval for which the KS-statistic
    is above some threshold c respectively the amount of points outside drinking events,
    for which the statistic is below the same threshold. To calculate the value of
    \(\hat{g}\), we need the actual change-points \(t_i\). We extract c out of the
    given training data, e.g. as a empiric quantile of values of the KS-statistic.
    The choices $$\begin{aligned} k=d=50,\,C_0=0.1,\,C_1=0.9 \end{aligned}$$ lead
    to $$\begin{aligned} (\alpha ^*_1,\alpha ^*_2,\alpha ^*_3) =(0,-0.5,0.5) \end{aligned}$$
    as a solution of the discretized minimization problem, which can also be seen
    in Fig. 3. Fig. 3. Interpolated graph of \(\hat{g}\) for various values of \(\alpha
    _2\) and \(\alpha _3\) Full size image The next step, after deciding for a diagnostic
    sequence, is to find the corresponding change-points: Algorithm 1 (Kolmogorov-Smirnov
    segmentation) 1. Given the datasets \(s_i=\{x_{i1},\dots ,x_{iN}\}\), split up
    \(s_i\) in intervals of equal length l: $$\begin{aligned}&\{x_{i1},\dots ,x_{il}\},\{x_{i,l+1},\dots
    ,x_{i,2l}\},\dots ,\\&\{x_{i,(\lfloor N/l\rfloor -1)l+1},\dots ,x_{i,\lfloor N/l\rfloor
    l}\}, \{x_{i,\lfloor N/l\rfloor )l+1},\dots ,x_{iN}\}. \end{aligned}$$ 2. Calculate
    the KS-statistic for every interval \(\{x_a,\dots ,x_b\}\) with the diagnostic
    sequence $$\begin{aligned} y(x_k)&= \alpha _1 f_1(x_k)+\alpha _2 f_2(x_k)+\alpha
    _3 f_3(x_k),\,k\in [a+d,b-d]\cap \mathbb {N}. \end{aligned}$$ 3. If the inequality
    $$ \tilde{Y}_{N}(\delta ,\mathbf{y})>c,\, \mathbf{y}=\{y(x_k):k\in [a+d,b-d]\cap
    \mathbb {N}\} $$ holds, append the point \(x_t\) where the statistic is maximized
    to a list as a candidate change-point and bisect the corresponding interval in
    the following way, $$\begin{aligned} \{x_{a},\dots ,x_{t}\},\{x_{t},\dots ,x_{b}\}.
    \end{aligned}$$ 4. Repeat step 3 and 4 for every newly formed interval until either
    a certain minimal interval length \(l_{\min }\) is reached or no further change-point
    candidate is found. 5. Merge the resulting list of candidates with the points
    1, N and \( k l, 1\le k \le \lfloor N/l\rfloor l \) to build an ascending list
    \(\{\tilde{t}_1,\tilde{t}_2,\dots ,\tilde{t}_m\}\) and form new intervals $$\begin{aligned}
    \{x_{\tilde{t}_k+1},\dots x_{\tilde{t}_{k+1}}\}. \end{aligned}$$ 6. Calculate
    KS-statistic for all newly formed intervals with two diagnostic sequences $$\begin{aligned}
    y_1(x_k)&:= f_2(x_k), \\ y_2(x_k)&:= f_3(x_k). \end{aligned}$$ 7. For every new
    interval determine the maxima of \(\tilde{Y}_{N}(\delta ;\mathbf{y}_1)\) and \(\tilde{Y}_{N}(\delta
    ;\mathbf{y}_2)\) and compare them with the corresponding thresholds \(c_1,c_2\).
    If either none, one or both values lie above the threshold we have found 0, 1
    or 2 change-points respectively. 8. Divide the dataset \(s_i\) into equidistant
    parts and put these parts in one of two groups depending on the minimal length
    of the interval they are lying in, according to the change-points found before.
    In summary, we split up the day according to the discovered change-points and
    afterwards make a equidistant segmentation and divide this segments in two groups,
    based on the length of the interval they are lying in. We decided for a critical
    minimal length to split the data in 2 approximately equal-sized groups, this choice
    can also be subject to parameter tuning (Fig. 4). Fig. 4. Depiction of the KSS
    method applied to a selected excerpt of our data Full size image 2.4 Preliminary
    Filtering To reduce noise in the acceleration data, we apply a Gaussian denoising
    filter as illustrated in Fig. 5, which seems to be appropriate for our given datasets.
    Of course, based on the nature of the raw data, one can use a different filter
    such as median filter, mean filter, moving-average-Filter, bandpass filter, lowpass/highpass
    filter or wavelet transform to stabilize the frequencies and reduce the noise.
    Fig. 5. Section of our unfiltered data (left), and the same section after application
    of a Gaussian filter (right) Full size image We calculate the vector \((\theta
    _1,\dots ,\theta _n)\) of a fixed number n of statistics, specified below, for
    all intervals. Afterwards we define boundaries \((\theta _{i,\min },\theta _{i,\max
    }), i=1,\dots ,n\), for these parameters and exclude an interval from further
    consideration as a possible drinking interval if $$\begin{aligned} (\theta _1,\dots
    ,\theta _n) \notin [\theta _{1,\min },\theta _{1,\max }] \times \dots \times [\theta
    _{n,\min },\theta _{n,\max }] . \end{aligned}$$ We based the decision of these
    boundaries on an minimum amount of sensitivity (\(Sens > 0.99\)) of the remaining
    intervals, while we empirically tried to maximize the precision. Of course a more
    sophisticated method could be implemented to find a even better filtering. In
    our example we chose variance, skewness and kurtosis as the features. 2.5 Feature
    Extraction Let \(\mathbf{x}=\{x_1,\dots ,x_n\} \) be a part of our time series.
    Based on this data we want to extract the orientation-insensitive features which
    describe the nature of the time series and hopefully are going to help us in our
    following classification. A short selection of used Features follows: In the Case
    of KSS, we split up the feature vectors in two groups according to the grouping
    in Algorithm 1. 2.6 Feature Selection Method To select a fitting feature subspace
    we used the work of [7], which considers correlation based feature selection.
    We implemented some of the algorithmic approaches and decided for a 1-step and
    2-step backward elimination algorithm to reduce the amount of considered features.
    As a measure for correlation we used the absolute value of the classical Neyman-Correlation
    coefficient $$\begin{aligned} K(x,y) := \frac{ | \sum _{i=1}^n(x_i-\overline{x})(y_i-\overline{y})|
    }{ \sqrt{ \sum _{i=1}^n(x_i-\overline{x})^2\cdot \sum _{i=1}^n(y_i-\overline{y})^2
    }}.\end{aligned}$$ (6) All features were normalized \(\hat{f}_i= \dfrac{f_i-\mu
    _i}{\sigma _i}\) on a daily and animal-individually basis before calculating (6)
    and searching for the feature subspace. In the case of using ES we calculate the
    features subspace for every training set, where in the case of KSS we calculate
    the corresponding subspace for both groups of features for every training set.
    2.7 Classification Algorithm To eliminate the bias of using the data of one calf
    for finding the parameters of KSS, we exclude these datasets from further classification.
    We assign the class label 1 to a feature vector if at least 5 s of drinking occur
    in the corresponding interval, otherwise we assign class label 0. To estimate
    the quality of our two different procedures with the remaining 10 days of records
    we use the following cross-validation approach. First we construct 10 different
    splits of the data into training and validation data. Therefore we choose every
    combination of 2 days out of 5 and say in every split that 6 days (3 days of 2
    calves) serve as our training data and the remaining 4 days as our validation
    data. In every split we further choose all combinations of 4 days out of the 6
    training days. In the case of ES we build a classifier for every chosen subset,
    whereas in the case of KSS we build two classifier for every chosen subset, one
    for every group of intervals. That procedure yields a total of \({{6}\atopwithdelims
    (){4}}=15\) respectively 30 classifiers in every split. In every classifying procedure
    we randomly oversampled the rarer class in the training set to obtain a balanced
    amount of class examples. Next we build a ensemble learner, which connects the
    15 beforehand calculated algorithms and decides for class 1 or 0 according to
    the number of different algorithms which decide for 1 or 0 respectively. In the
    case of KSS this procedure is independently used on both groups. We decided for
    a certain minimum amount \(c_{\min }\) to vote for class 1 as we maximized the
    function $$\begin{aligned} f(c_{min};Sens.,Prec.)= (Sens.+Prec.) \cdot \text {sgn}(\max
    \{Sens.-0.8,0\})\end{aligned}$$ (7) on the training data. In words, we tried to
    maximize the sum of precision and sensitivity while keeping a minimum sensitivity.
    Suppose we have n different classifiers \(C_1 \dots C_n\) with $$ C_i: \mathbb
    {R}^k \rightarrow \{0,1\}$$ $$x\rightarrow c_i,$$ then we define a new classifier
    with the following function mapping from the feature space to class label $$F:
    \mathbb {R}^{n+k} \rightarrow \{0,1\}$$ $$\begin{aligned} F(x,c_1,c_2,\dots c_n,c_{\min
    }):= \text {sgn}\left( \max \{\sum _{i=1}^nc_i-c_{\min },0\}\right) \end{aligned}$$
    (8) After classifying, the segments which are chosen as belonging to class Drinking
    are further merged into bigger intervals if at most 5 min are between subsequent
    segments. An additional posteriori filtering step can be implemented which may
    further improve the results, this approach is not presented here. Table 1. Quality
    comparison of different used methods with 1-step backward elimination Full size
    table Table 2. Quality comparison of different used methods with 2-step backward
    elimination Full size table 3 Experimental Results We used 5 different built-in
    classification algorithms in Mathematica \(\copyright \) 11 with the following
    method descriptions (Tables 1 and 2): Neural Network (NN): This classifier is
    composed of layers of artificial neuron units. Each unit computes its value as
    a function of the unit values in the previous layer. Information is processed
    layer by layer from the feature layer to the output layer which gives the class
    probabilities. It is also called a feed-forward neural network or a multi-layer
    perceptron. Nearest Neighbors (KNN): The nearest neighbours classifier infers
    the class of a new example by analyzing its nearest neighbors in the feature space.
    In its simplest form, it picks the commonest class amongst the “k"-nearest neighbors.
    Naive Bayes (NB): The naive Bayes classifier assumes that features are generated
    independently given the class and uses Bayes’ theorem to predict the class. Support
    vector machine (SVM): The support vector machine classifier separates the training
    data into two classes using a maximum-margin hyperplane. The original feature
    space can be mapped into a higher dimensional space to improve linear separability.
    Logistic regression (LR): This classifier models the class probabilities with
    logistic functions of linear combination of features. In the following tables
    we summarized the average accuracy, Cohens \(\kappa \) and F1-Score of the different
    used classification methods for our 10-fold cross validation, where in each comparison
    higher values are highlighted. Moreover we present the confusion matrix (Table
    3) for the best result. Table 3. Confusion matrix with total amount in \(10^{-1}s\)
    (left) and percentages (right) of the neural network method combined with 2-step
    backward elimination and equidistant segmentation and table with quality measures
    Full size table 4 Conclusion The results show that both the ES and KSS method
    are feasible for achieving good results in detecting drinking events in calves.
    The results are astounding when keeping in mind, that in KSS we effectively halve
    the amount of samples in our classification algorithms and still get comparable
    or even better results than with ES. With defining additional or other diagnostic
    sequences, this procedure can be generalized to other problems. Some problems
    we tried to overcome were the noisiness of the data, the usage of only the magnitude
    of acceleration, and the imbalanced class frequency. The classification results
    can be further used to estimate the drinking amount with regression, which is
    subject to further research. References Alvarenga, F.A.P., Borges, I., Palkovic,
    L., Rodina, J., Oddy, V.H., Dobos, R.C.: Using a three-axis accelerometer to identify
    and classify sheep behaviour at pasture. Appl. Anim. Behav. Sci. 181, 91–99 (2016)
    Article   Google Scholar   Brodsky, B.E., Darkhovsky, B.S.: Nonparametric Methods
    in Change-Point Problems. Kluwer Academic Publishers, The Netherlands (1993) Book   MATH   Google
    Scholar   Kuankid, S., Rattanawong, T., Aurasopon, A.: Classification of the cattle’s
    behaviours by using accelerometer data with simple behavioural technique. In:
    Proceedings of 2014 APSIPA Annual Summit and Conference, Siem Reap, Cambodia,
    pp. 1368–1372 (2014) Google Scholar   Marais, J., Le Roux, S.P., Wolhuter, R.,
    Niesler, T.: Automatic classification of sheep behaviour using 3-axis accelerometer
    data. Livestock Sci. 196, 42–48 (2017) Article   Google Scholar   Robert, B.,
    White, B.J., Renter, D.G., Larson, R.L.: Evaluation of three-dimensional accelerometers
    to monitor and classify behaviour patterns in cattle. Comput. Electron. Agric.
    67, 80–84 (2009) Article   Google Scholar   Martiskainen, P., Järvinen, M., Skön,
    J.O., Tiirikainen, J., Kolehmainen, M., Mononen, J.: Cow behaviour pattern recognition
    using a three-dimensional accelerometer and support vector machines. Appl. Anim.
    Behav. Sci. 119, 32–38 (2009) Article   Google Scholar   Hall, M.A.: Correlation-based
    feature selection for machine learning. Ph.D. thesis. The University of Waikato
    (1999) Google Scholar   Cohen, J.: A coefficient of agreement for nominal scales.
    Educ. Psychol. Measur. 20(1), 37–46 (1960) Article   Google Scholar   Download
    references Acknowledgements This work was funded by the Austrian Research Promotion
    Agency (FFG), Project No. 848610 and Smartbow GmbH. The publication was financially
    supported by the Ministry of Education and Science of the Russian Federation (the
    Agreement number 02.a03.21.0008). Author information Authors and Affiliations
    Johannes Kepler University, Altenbergerstrasse, 69, 4030, Linz, Austria Valentin
    Sturm, Dmitry Efrosinin & Natalia Efrosinina Peoples’ Friendship University of
    Russia (RUDN University), Miklukho-Maklaya St 6, Moscow, 117198, Russia Dmitry
    Efrosinin Clinical Unit for Herd Health Management in Ruminants, University Clinic
    for Ruminants, Department for Farm Animals and Veterinary Public Health, University
    of Veterinary Medicine Vienna, 1210, Vienna, Austria Leonie Roland, Michael Iwersen
    & Marc Drillich Smartbow GmbH, Jutogasse 3, 4675, Weibern, Austria Wolfgang Auer
    Corresponding author Correspondence to Dmitry Efrosinin . Editor information Editors
    and Affiliations V.A. Trapeznikov Institute of Control Sciences, Russian Academy
    of Sciences, Moscow, Russia Vladimir M. Vishnevskiy RUDN University, Moscow, Russia
    Konstantin E. Samouylov V.A. Trapeznikov Institute of Control Sciences, Russian
    Academy of Sciences, Moscow, Russia Dmitry V. Kozyrev Rights and permissions Reprints
    and permissions Copyright information © 2017 Springer International Publishing
    AG About this paper Cite this paper Sturm, V. et al. (2017). Automated Classification
    of a Calf’s Feeding State Based on Data Collected by Active Sensors with 3D-Accelerometer.
    In: Vishnevskiy, V., Samouylov, K., Kozyrev, D. (eds) Distributed Computer and
    Communication Networks. DCCN 2017. Communications in Computer and Information
    Science, vol 700. Springer, Cham. https://doi.org/10.1007/978-3-319-66836-9_11
    Download citation .RIS.ENW.BIB DOI https://doi.org/10.1007/978-3-319-66836-9_11
    Published 07 September 2017 Publisher Name Springer, Cham Print ISBN 978-3-319-66835-2
    Online ISBN 978-3-319-66836-9 eBook Packages Computer Science Computer Science
    (R0) Share this paper Anyone you share the following link with will be able to
    read this content: Get shareable link Provided by the Springer Nature SharedIt
    content-sharing initiative Publish with us Policies and ethics Download book PDF
    Download book EPUB Sections Figures References Abstract Introduction Material
    and Methods Experimental Results Conclusion References Acknowledgements Author
    information Editor information Rights and permissions Copyright information About
    this paper Publish with us Discover content Journals A-Z Books A-Z Publish with
    us Publish your research Open access publishing Products and services Our products
    Librarians Societies Partners and advertisers Our imprints Springer Nature Portfolio
    BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state
    privacy rights Accessibility statement Terms and conditions Privacy policy Help
    and support 129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University
    of Nebraska-Lincoln (3000134173) © 2024 Springer Nature'
  inline_citation: '>'
  journal: Communications in computer and information science
  limitations: '>'
  pdf_link: null
  publication_year: 2017
  relevance_score1: 0
  relevance_score2: 0
  title: Automated Classification of a Calf’s Feeding State Based on Data Collected
    by Active Sensors with 3D-Accelerometer
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/icet55676.2022.9825019
  analysis: '>'
  authors:
  - Jianqiang Chen
  - Jeffrey Zhu
  - Meifeng Guo
  citation_count: 1
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2022 IEEE 5th International C... An SVM-Based
    Pedestrian Gait Recognition Algorithm Using a Foot-Mounted IMU Publisher: IEEE
    Cite This PDF Jianqiang Chen; Jeffrey Zhu; Meifeng Guo All Authors 1 Cites in
    Paper 202 Full Text Views Abstract Document Sections I. Introduction II. Data
    Acquisition and Pre-Processing III. The Gait Classification Model IV. Classifier
    Performance Experiment For Multi-Gait V. Conclusion Authors Figures References
    Citations Keywords Metrics Abstract: Based on the real-time data of angular velocity
    and acceleration sensed by IMU, this paper uses the machine learning method, support
    vector machine (SVM), to find a way to recognize and classify some common action
    types such as walking, running, going upstairs, going downstairs, jumping, etc.
    after data preprocessing and dimensionality reduction with Principal Component
    Analysis (PCA). The algorithm provides a basis for identifying zero speed at different
    gait states to improve the relevance of the zero-speed correction algorithm. And
    it will help identify different pedestrian motion states as a basis for motion
    constraint algorithms. Published in: 2022 IEEE 5th International Conference on
    Electronics Technology (ICET) Date of Conference: 13-16 May 2022 Date Added to
    IEEE Xplore: 14 July 2022 ISBN Information: ISSN Information: DOI: 10.1109/ICET55676.2022.9825019
    Publisher: IEEE Conference Location: Chengdu, China SECTION I. Introduction Autonomous
    pedestrian navigation is a different kind of navigation technology from conventional
    satellite signal-based navigation technology [1]. It requires the ability to navigate
    in unknown environments without advanced laying and relies solely on its sensors
    for position navigation [2]. While conventional satellite-based navigation systems
    have been able to adapt to most environments, autonomous pedestrian navigation
    systems still have their use in some unique scenarios. Conventional navigation
    systems are usually based on satellite signals, combined with map resources, for
    high-precision navigation and positioning. However, when the equipment is indoors,
    underground, or in complex tunnels, satellite signal degradation will interrupt
    normal operation of the navigation system [3]. Conventional navigation systems
    are also subject to security attacks from the space, ground, and user segments;
    anomalies or outages in any one of those segments can render the entire system
    inoperable. These shortcomings of satellite navigation greatly limit its application
    in autonomous pedestrian navigation [4]. Therefore, other technologies are needed
    to enable navigation and positioning in the absence of satellite signals. Unlike
    conventional satellite navigation systems, inertial navigation technology does
    not rely on external information and can play its role in these adverse conditions
    [5]. MEMS IMU, now widely used in inertial navigation systems, is composed of
    MEMS gyroscopes and MEMS accelerometers [6] which are used to obtain the angular
    velocity and acceleration of the measured object. MIMU’s small size, low power
    consumption, low cost, ease of integration, and digitization make it ideal for
    autonomous pedestrian navigation applications [7]. Additionally, an MIMU can work
    independently and is not easily interfered with by the outside world. An MIMU’s
    accuracy, however, is reletively low compared with traditional inertial device,
    which makes the accumulated error of navigation very large. An auxiliary correction
    means is therefore required to deal with the error [8]. Zero velocity updates
    (ZUPT) is a commonly used auxiliary method for autonomous pedestrian navigation
    [9] [10]. The idea of zero speed correction is to update the Kalman filter with
    the speed error of the system as an observed value at zero speed to get an estimate
    of the state, then use the estimated values to correct the output of navigation
    information and give an optimal estimate of the system state [11]. For the ZUPT
    algorithm, it is critical to determine when a pedestrian is at zero speed. Existing
    gait detection algorithms are primarily based on MIMU acceleration and angular
    velocity signals [7]. When the state of the carrier’s motion changes, the acceleration
    and angular velocity detected by the MIMU can vary greatly. The traditional threshold-based
    ZUPT often relies on a fixed threshold [12], so that when the motion state changes,
    the original threshold is not well suited to the new situation. Determining the
    current state of the carrier’s motion thus becomes a prerequisite for effective
    zero-speed detection. The determination of the pedestrian motion state can also
    provide a basis for Pedestrian Dead-Reckoning (PDR), which is another effective
    method to reduce accumulated error [13]. The basic idea of the PDR algorithm is
    to estimate the number and length of steps taken while walking using acceleration
    information or pacing devices. Then gradually deduce the position, distance, and
    direction of the pedestrian by combining the heading information obtained from
    magnetic sensors or gyroscopes [14]. The ZUPT algorithm alone can only constrain
    the horizontal attitude angle error and velocity error, but not the heading angle
    error [15]. Heuristic Heading Reduction (HDR), an algorithm that does not require
    redundant devices, can easily constrain the heading angle error, thus increasing
    the accuracy of navigation positioning. The idea behind the HDR algorithm is to
    detect the time when a person is going straight and to correct for gyroscopic
    deviations, in this case, to reduce heading error [16]. Determination of the state
    of pedestrian movement is also very important in this case. This paper aims to
    design an algorithm to recognize and classify pedestrian actions based on MIMU
    real-time sensed angular velocity and acceleration data. The algorithm provides
    a basis for identifying zero speed at different gait states to improve the relevance
    of ZUPT. And it will help identify different pedestrian motion states as a basis
    for motion constraint algorithms, such as PDR as well as HDR. In this paper, we
    focus on the following five types of gait; walking, running, going upstairs, going
    downstairs and jumping. We distinguish between walking and running on hard or
    sandy ground, for a total of seven types in all. Furthermore, to reduce the consumption
    of computational resources, we use PCA to downscale the data [17]. The structure
    of this paper is as follows: In the second section, the selection and carrying
    method of IMU are introduced in detail, and the data preprocessing method is designed
    to reduce the noise signal and divide the gait time segment. The third section
    discusses the construction of the gait classification model. In the fourth section,
    the multi-gait is used to verify the gait classification model. The fifth section
    concludes and ends the paper. SECTION II. Data Acquisition and Pre-Processing
    A. Equipment and Carrying Method The IMU sensor used in this experiment is BWT61PCL
    by Wit Intelligent, which could measure triaxial acceleration, triaxial angular
    velocity, and triaxial Euler angle and communicates data via Bluetooth or serial
    port. Specific parameters of BWT61PCL are shown in Table I. TABLE I Key Specifications
    of BWT61PCL Fig. 1. Experiment equipment Show All The collection method of experimental
    data is to fix the IMU on the foot as shown in Fig. 1, and then use Bluetooth
    communication to transmit the collected data. The advantage of foot-mounted IMU
    is that the foot, as the part of the body in contact with the ground, is more
    sensitive to changes in gait, which makes the data collected more representative
    and more variable [18]. Although serial communication has the advantage that data
    transmission is more stable, the wireless transmission feature of Bluetooth can
    better avoid possible constraints on movement when collecting data on pedestrian
    motion states. Thus, Bluetooth communication is chosen for the data transmission
    of this experiment. The sampling period of the experiment was chosen to be 0.005s.
    Because more data over a period better reduces the impact of random errors. The
    measurement data of the sensors used in this experiment are the three-axis acceleration
    a x , a y , a z , the three-axis angular velocity w x , w y , w z , and the modulus
    values of the acceleration and angular velocity: |a|= a 2 x + a 2 y + a 2 z −
    − − − − − − − − − √ (1) View Source |w|= w 2 x + w 2 y + w 2 z − − − − − − − −
    − − − √ (2) View Source B. Data Pre-processing For the collected raw data, such
    as shown in Fig. 2(a), the following methods are used to pre-process the data
    to reduce the effects of random and high-frequency errors. 1) Low-Pass Filter
    In signal measurements using sensors, high-frequency error interference is often
    an important factor in signal distortion. To reduce the potential impact of high-frequency
    errors, a low-pass filter with a normalized bandpass frequency of 0.1 is applied
    to the data pre-processing, as shown in Fig. 2(b). 2) Smoothing Smoothing is an
    effective way to deal with noisy data. The basic idea is to use a sliding window
    to split the data into multiple equal-length segments and then use different smoothing
    methods to smooth the data. The main smoothing treatments are the moving average
    method, moving median method, Gaussian weighted moving average method, linear
    regression method, quadratic regression method, robust linear regression method,
    and robust quadratic regression method. The method chosen in this paper is the
    moving average method, which smooths the data by calculating the moving average
    within each sliding window. It helps to reduce periodic trends in the data, while
    the amount of computation is relatively small. Smoothed data is as shown in Fig.
    2(c). 3) Gait Period Segmentation Unlike the moment-to-moment data used in previous
    studies of zero-speed state discrimination, the data needed to perform pedestrian
    motion recognition is total data over a period. The chosen method of dividing
    the gait period is consistent with general intuition to treat each step as a period,
    and ultimately to discriminate the action at each step. It is observed that the
    pre-processed data of the acceleration modulus has two main peaks at each step
    of the period, and the acceleration modulus time-series data can be divided according
    to the peak points based on this feature. The positions of main peaks are marked
    with red circles. The result is as shown in Fig. 2(d). SECTION III. The Gait Classification
    Model The specific technical route of the gait classification model is shown in
    Fig. 3. A. Feature Selection Based on the tri-axial acceleration and tri-axial
    angular velocity that can be measured by the IMU, as well as the calculated acceleration
    and angular velocity moduli, appropriate statistical variables are selected that
    represent the characteristics of the data over a period. according to the actual
    condition, the maximum value, minimum value, mean value, and standard deviation
    of each of these eight data over a period are chosen as the eigenvalues of the
    SVM sample dataset. Each eigenvalue is calculated as follows: p max =max{ p 1
    , p 2 ,⋯, p n } (3) View Source p min =min{ p 1 , p 2 ,⋯, p n } (4) View Source
    p mean = 1 n ∑ k=1 n p k (5) View Source p std = 1 n ∑ k=1 n ( p k − P mean )
    2 − − − − − − − − − − − − − − − − √ (6) View Source After that, category labels
    were set for five gait types on the hard ground: walking, running, going upstairs,
    going downstairs, jumping, and two gait types on the sand: walking and running,
    with values from 1 to 7. In this case, if a sample data is x, then x contains
    32 eigenvalues x 1 , x 2 ,⋯, x 32 , and a label data x label . Expressed as follows:
    x=[ x 1 , x 2 ,⋯, x 32 , x label ] =[ a x m ax , a x m in , a x m ean , a x s
    td ,⋯, x label ] (7) View Source m data constitute a set of sample data, m sample
    vectors x constitute a sample matrix X: X= ⎡ ⎣ ⎢ ⎢ x 11 ⋮ x m1 ⋯ ⋱ ⋯ x 1label
    ⋮ x mlabel ⎤ ⎦ ⎥ ⎥ (8) View Source Fig. 2. The data of walking for a period of
    time. The abscissa is the sampling sequence, and the ordinate is the acceleration
    module. (a) Raw data of acceleration modulus (b) Low-pass filtered data (c) Smoothed
    data (d) Gait period segmentation Show All Fig. 3. The specific technical route
    of the SVM model Show All B. Data Reduction The dimension of input data required
    by the original SVM model is 32 dimensions, and the SVM support vector used for
    prediction is also 32 dimensions. Such a large data dimension will consume more
    resources and time in a calculation, which is not conducive to real-time prediction.
    Therefore, it is necessary to reduce the dimension of the data to reduce the resources
    consumed by the operation, but at the same time, it is also necessary to ensure
    that the information contained in the data is reduced as little as possible to
    ensure the accuracy of model training and prediction. PCA technology can effectively
    meet the needs of this aspect, realize the dimensionality reduction of the feature
    vector, and ensure not to lose too much information. There are 1070 samples in
    the training set, and each sample has 32-dimensional eigenvalues. First, the sample
    matrix X is standardized to get a new sample matrix X*: X ∗ = ⎡ ⎣ ⎢ ⎢ ⎢ x ∗ 1
    1 ⋮ x ∗ m 1 ⋯ ⋱ ⋯ x ∗ 1 n ⋮ x ∗ m n ⎤ ⎦ ⎥ ⎥ ⎥ ,m=1070,n=32 (9) View Source Then
    calculate the eigenvalue matrix R of the new sample matrix X ∗ . And then the
    eigenvalues λ i and their corresponding eigenvectors e i (i=1,2,⋯,n) are calculated
    to get the eigenvector matrix A of the covariance matrix (i.e., mapping matrix).
    The contribution rate and the cumulative contribution rate of each eigenvalue
    are shown in Table II. Fig. 4. Contribution rate and the cumulative contribution
    rate of each principal component Show All TABLE II Contribution Rate and Cumulative
    Contribution Rate From Fig. 4 and Table II, we can see that the cumulative contribution
    rate of the first 16 principal components has almost reached 100%. That is to
    say, most of the information has been included. Therefore, the SVM model can be
    trained and optimized through the first 16 dimensions of data after dimension
    reduction by PCA. In this way, we can greatly reduce the resources and time consumed
    by the operation and improve the efficiency of the gait classification model.
    In addition, the eigenvector corresponding to the selected eigenvalue is composed
    of a matrix P: P= ⎡ ⎣ ⎢ ⎢ p 11 ⋮ p 321 ⋯ ⋱ ⋯ p 1n ⋮ p 32n ⎤ ⎦ ⎥ ⎥ ,n=16 (10) View
    Source The data set matrix of PCA reduced dimension in principal component space
    is Y: Y= ⎡ ⎣ ⎢ ⎢ y 11 ⋮ y m1 ⋯ ⋱ ⋯ y 1n ⋮ y mn ⎤ ⎦ ⎥ ⎥ ,m=1070,n=16 (11) View
    Source C. Classification Model When the training data set is ready, we can start
    to train the gait classification model based on SVM. Because SVM model training
    consumes a lot of resources, we decided to do it on PC. Select different kernel
    function types, such as linear kernel, quadratic kernel, cubic kernel, Gaussian
    kernel; different classification methods, one-to-one or one-to-many; different
    box constraint levels and different kernel scales for the model. Through parameter
    optimization, the classification model with high accuracy can be found to achieve
    a better classification effect. The data of the training set is validated by 5-fold
    cross-validation, to get a more reliable and stable training model and prevent
    overfitting. The model training results are as shown in Fig. 5. Compare the SVM
    gait classification model without PCA with the SVM gait classification model after
    dimension reduction with PCA. The results shown in Table III can be obtained.
    It can be seen that whether the SVM gait classification model without PCA or SVM
    gait classification model with PCA, their prediction accuracy is at a high level.
    In addition, it is found that the reduction of SVM classification accuracy caused
    by PCA dimension reduction is mainly reflected in 1, 2, 6, 7, which are walking
    on hard ground, running on hard ground, walking on sand ground, and running on
    the sand ground. From the previous confusion matrix, we can see that the false
    prediction is between walking on hard or sand ground and between running on the
    hard or sand ground. The possible reason is that the difference between the same
    gait action under different ground conditions is not very obvious. In the process
    of PCA dimension reduction, some different information in the feature data is
    lost, resulting in the decline of the prediction accuracy. On the other hand,
    the difference between some sand ground and the hard ground is not obvious, which
    makes the difference in dataset itself not obvious. It is also a possible reason.
    TABLE III Contribution Rate and Cumulative Contribution Rate Fig. 5. Model training
    results. TP:True Positive Rate & NF:False Negative Rate (a) SVM (b) PCA+SVM. Show
    All SECTION IV. Classifier Performance Experiment For Multi-Gait To test the actual
    classification performance of the SVM gait classification algorithm, real multi-gait
    processes are tested in the field. Both the SVM gait classification model without
    PCA and the SVM gait classification model with PCA are used to predict the gait
    to test the actual effect of the model. As before, when building the test dataset,
    set the label of walking on hard ground to 1, the label of running on hard ground
    to 2, the label of going upstairs to 3, the label of going downstairs to 4, the
    label of jumping to 5, the label of walking on the sand ground to 6 and the label
    of running on sand ground to 7. One of the test results is shown in Fig. 6. According
    to the result statistics of the classification results of the test scene, the
    accuracy of SVM gait classification and the accuracy of SVM gait classification
    after PCA dimension reduction are shown in Table IV. Fig. 6. (a) Time series data
    of acceleration modulus (b) Gait classification results Show All TABLE IV Contribution
    Rate and Cumulative Contribution Rate TABLE V Statistics of Deviation Sources
    From Table IV, it can be seen that the SVM gait classification model without PCA
    still maintains a high accuracy, but the SVM gait classification model after PCA
    does not perform well in multi-gait verification. In addition, we make statistics
    on the different situations that lead to the deviation of prediction. One is that
    the predicted actions are correct but the predicted site conditions are wrong.
    The other is that the model predicts the last (or next) gait due to the change
    of gait. The results are shown in Table V. In the SVM gait classification model
    without PCA, the prediction deviation mainly occurs in the errors of the predicted
    site type. The original walking and running movements on the hard ground are wrongly
    predicted on the sand, but the type of movements is still correct. The possible
    reason for this situation is that the difference of the same gait in different
    site conditions is small in special cases, such as hard ground is soft or sand
    is hard, which makes the SVM gait classifier unable to get an accurate prediction.
    This situation is more obvious after PCA data dimensionality reduction processing.
    Given this situation, an effective improvement method is to collect more data
    to improve the gait classification model. Another method is to add a prediction
    optimization algorithm based on the existing gait classification model. That is
    to say, the possible abnormal prediction value can be excluded through the statistics
    of the site conditions in a period. For example, if the statistics for a period
    are all gait in the hard ground condition, and a certain gait is in the sandy
    land condition, then the prediction value has a large probability of deviation,
    which should be corrected by statistical data. Another major type of prediction
    error is caused by gait changes. Because the change of people’s motion state is
    not transient, but a gradual process, that means gait changes must take a while.
    And gait transition takes different time between different gaits. For example,
    it takes only one step to change from walking to going upstairs, and there are
    a few steps when changing from walking to running. This is uncertain in the SVM
    gait classification model. The prediction may be divided into the former gait
    or the latter one. According to this situation, we can choose to add the middle
    state of various gaits, re-label, and train the model to reduce the prediction
    deviation. SECTION V. Conclusion This paper proposes a pedestrian action recognition
    algorithm based on SVM using a foot-mounted IMU. The algorithm can preprocess
    the three-axis acceleration data and the three-axis angular velocity collected
    by IMU and divide the gait time. On this basis, the SVM model without PCA and
    the SVM model with PCA are trained to realize gait recognition and classification.
    The accuracy of the final training model is 98.16% and 96.40% respectively. The
    model is also tested with multi-gait. The prediction accuracy of the SVM gait
    classification model without PCA is 94.29%, and that of the SVM gait classification
    model with PCA is 88.09%. In future work, we will focus on the extension of the
    dataset and selecting more efficient eigenvalues to train the SVM gait classification
    mode. Authors Figures References Citations Keywords Metrics More Like This A new
    semi-supervised support vector machine learning algorithm based on active learning
    2010 2nd International Conference on Future Computer and Communication Published:
    2010 Prediction of Loan Pricing on the basis of Area Location using K-Nearest
    Neighbour and Support Vector Machine Learning Algorithms 2023 International Conference
    on Sustainable Communication Networks and Application (ICSCNA) Published: 2023
    Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT
    OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: 2022 IEEE 5th International Conference on Electronics Technology (ICET)
  limitations: '>'
  pdf_link: null
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: An SVM-Based Pedestrian Gait Recognition Algorithm Using a Foot-Mounted IMU
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/icoiact53268.2021.9563914
  analysis: '>'
  authors:
  - Aldi Sulthony Susilo
  - Nyoman Bogi Aditya Karna
  - Ratna Mayasari
  citation_count: 2
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2021 4th International Confer... Decision
    Tree-Based Bok Choy Growth Prediction Model for Smart Farm Publisher: IEEE Cite
    This PDF Aldi Sulthony Susilo; Nyoman Karna; Ratna Mayasari All Authors 3 Cites
    in Papers 219 Full Text Views Abstract Document Sections I. Introduction II. Literature
    Review III. Bok Choy Growth Prediction Model IV. The Evaluation of Classification
    Performance Metrics V. Prediction Model Testing Authors Figures References Citations
    Keywords Metrics Abstract: Indonesia is an agricultural country that has a dependency
    on the horticulture sub-sector. Bok choy is included in the mustard greens group
    as one of the strategic products from the horticulture. The needs for mustard
    greens are getting higher. Based on Indonesia''s Central Statistics Agency data
    in 2019, the mustard beans production rate increased only 2.63% higher than in
    2018. If it does not meet the desired supply, it opens the possibility of a lack
    of bok choy supply at the market, resulting in high potential price fluctuations.
    These conditions initiate relevant system research to help the farmer develop
    a bok choy crop reference guide, especially in the seeding phase. In reducing
    the limitations caused by the lack of science and knowledge in the farmer environment,
    the prediction model is the proposed outcome by considering the use of IoT mechanism
    that has widely developed. The model is based on a system that integrates IoT''s
    interest in the agriculture field, namely smart farm, for retrieving real-time
    data based on automatic control, MySQL database for storing data, and machine
    learning technique to establish the prediction model as the guide for the farmers
    to find appropriate parameters for planting bok choy. The prediction model performs
    using Python, a high-level popular programming language due to its ease and open
    source. Python interprets the bok choy growth dataset based on the irrigation
    system scenario from the integrated system with the relevant library of data preprocessing
    interest and the Decision Tree algorithm of the Scikit-learn library to train
    the model. The system conducts a series of machine learning phases to take the
    insight analysis needed to create a prediction model. The model performance metrics
    as the consideration in deciding the outcome model, which are accuracy and precision.
    Published in: 2021 4th International Conference on Information and Communications
    Technology (ICOIACT) Date of Conference: 30-31 August 2021 Date Added to IEEE
    Xplore: 20 October 2021 ISBN Information: DOI: 10.1109/ICOIACT53268.2021.9563914
    Publisher: IEEE Conference Location: Yogyakarta, Indonesia SECTION I. Introduction
    Indonesia is a developing country with a broad population segment that depends
    on their life in agriculture. The horticulture sector produces vegetable products,
    fruit plants, ornamental plants, and medicinal plants that can be traded. Based
    on data obtained from the Central Statics Agency in 2018, the number of farmers
    was around 33.1 million, and there were 10.1 million horticultural farmers [1].
    As a result of this population, agricultural was still one of the Indonesian economy
    pilars by contributing 14% of the GDP [2]. Besides helping the national income,
    the horticultural sector contributed to its export activities and food needs.
    Again, the farmers received the annual revenues sufficient for their lives. The
    other parties were involving as the supporting system in food supply distribution
    applied before being consumed by the communities. One of the leading agricultural
    commodities in Indonesia is bok choy. This plant is required as a supplementary
    food material in the household and industrial environment. Bok choy is considering
    as one of the plants classify in the mustard greens group. Along with the high
    demand resulting in potential supply and price fluctuations, the mustard greens
    production rate only increased by 2.63 % in 2019 over 2018 in the Central Statistics
    Agency of Indonesia data [3]. The public information also reinforced the Ministry
    of Agriculture data to state that there had been a fluctuation rate in the population
    of West Java province food consumption by day and year from 2013–2018 [4]. The
    fluctuation was caused by several factors, including weather sensitivity, limited
    resources (producers, planting knowledge, infrastructure, and land availability),
    the influence of fertilizer, and climate change. In maintaining the stability
    of bok choy commodity prices, an adequate supply of the finest quality of bok
    choy is needed. The specific observed parameter to analyze is the soil moisture
    as the growth-related factor to plant the bok choy. The production growth rate
    of the bok choy as one of the plants classified in mustard greens is still slightly
    increased. It may lead to a lack of supply if it is not comparable with the market''s
    availability. One of the issues is caused by the lack of fully-compiled science
    and knowledge. It is difficult for farmers to determine superior seed that impacts
    the quality and quantity of the bok choy. However, market demand for bok choy
    is still outstanding and necessary for household and industrial material cooking.
    Nowadays, the bok choy optimal seeding model is still unavailable as a reference
    guide for generating predictions to work in the farmer environment. The The objective
    is increasing the production, which offers to farmers environment as the main
    player in producing the best choice of bok choy seeding phases in increasing the
    possibility of optimal crops and open opportunities to maintain the availability
    of bok choy quality on the market. One of the facilities used to do suitable planting
    is the greenhouse. The greenhouse is an architecture to plant the bok choy following
    the desired optimal condition with a more attentive environment and minimize unwanted
    environmental factors. A classification approach of supervised machine learning
    technique applies to develop the model strengthen by the designated output label
    that manually inputs. The model development is conduct in an open-source Jupyter
    Notebook as it is interactive to the user to conclude the analysis of each machine
    learning phase. There are several procedures as references to perform the model
    testing. The train/test split procedure splits the dataset automatically and implements
    a decision tree algorithm to train the data. The evaluation of the model performance
    performs with three classification metrics, such as accuracy score, confusion
    matrix, and classification table that correlated to each other as the analysis
    to determine the prediction model''s quality. The model is saved to the local
    computer model for repeatedly implementing the model testing, which applies to
    the Pickle library''s given input. The research using the dataset adopted from
    an integrated system between IoT for retrieving data from research object, MySQL
    of unpublished undergraduate thesis and executive database dashboard as data storing
    management for knowldge discovery [5]–[7]. SECTION II. Literature Review The researchers
    have conducted various researches on the use of greenhouse to utilize the environment
    independently, including real-time monitoring and controlling greenhouse systems
    based on smart farm [8]. An IoT device is connected through a networks as an integrated
    system in retrieving real-time data is necessary. Raspberry Pi is used as an IoT
    device because it has an embedded wi-fi module and external instrument, such as
    sensors as supporting system. The soil moisture sensor is defined as calibrating
    the water dose value of greater than or equal to 15 % as the lower limit and lower
    than equal to 25 % defined as normal condition [9]. Whereas the optimum temperature
    is in a range of 20 – 25 degrees celcius [10]. The application of Raspberry Pi
    in the greenhouse as smart farm system implementation has been widely used by
    researcher [11] [12]. Users can perform data retrieval results for a prediction
    model to determine the best composition in producing optimal bok choy seeding
    crops. This method has been proven by several researchers who made a collection
    of observation in tomatoes and lettuce growth as it used for quality predictive
    models [13] [14]. The Raspberry Pi is retrieved data from the respective types
    of desired sensor monitoring and controlling and is automatically stored in the
    database. The platform is supported with the additional application of the database
    management system field, such as MySQL database. The designated raw data is divided
    into several groups. The group of data combines the dataset as the input for performing
    the prediction model. The integrated system of IoT and machine learning has also
    been explored by the scientist [15] [16]. A prediction model is generated using
    the machine learning technique in processing information from the available datasets.
    Machine Learning performs with the help of complementary libraries, such as Numpy,
    Pandas, Matplotlib, Seaborn, and Scikit-learn of Python programming language that
    has been widely used in the related field to build the learning systems in producing
    a desired model. SECTION III. Bok Choy Growth Prediction Model A. The Workflow
    of The Global System The proposed global workflow system is started from retrieving
    data stage with IoT mechanism, stores data in MySQL database, and develops the
    prediction model. The data is sensed by the IoT platform with the help of the
    four respective sensors, which categorized into the value of five attributes given
    are as follows: Webcam retrieves the picture of bok choy seeding period of the
    entire pot taken once a day at noon. DHT22 sensor retrieves the room humidity
    and temperature value. BH-1750 sensor retrieves the room light intensity value.
    YL-69 sensor retrieves the soil moisture value from each pot. The sensor retrieves
    real-time information based on the sensor''s ability taken in a greenhouse in
    the Buah Batu region, as seen in figure 1. The exception for the soil moisture
    outcome, because it has a different scenario based on the irrigation system, categorized
    into automatic and manual. The automated system is a process to provide water
    to the bok choy plant that has been programmed with relay help, which will irrigate
    automatically if the soil moisture detects the water amount in the observed plant
    is less than is needed. In contrast, the manual system is a process to deliver
    water to the bok choy plant by hand-operated, which is self-irrigate the plant
    based on the range of the time decides, 09.00 A.M. to 11.00 A.M., is the best
    time to irrigate the plants. The soil moisture value has been converted from a
    percentage to the categorical attributes at receiving data. The sensed data is
    sent to the Raspberry Pi 3B. The device gathers and stores the information that
    it retrieves based on the sensor placement. Fig. 1. The greenhouse is the plant
    placement Show All The sensed data is then sent through the localhost network
    automatically every ten minutes to the MySQL database as data management for complete
    store data. In the database, the sensed data is divided into six groups, which
    are: Camera''s group contains the picture''s path of the entire pot. Plant A''s
    group contains date-time and soil moisture value from the observed plant. Plant
    B''s group contains date-time and soil moisture value from the observed plant.
    Plant C''s group contains date-time and soil moisture value from the observed
    plant. Plant D''s group contains date-time and soil moisture value from the observed
    plant. Room Condition''s group contains date-time and greenhouse humidity, temperature,
    and light intensity value. These database contents are seen in figure 2. The database
    has been deployed to website hosting for monitoring purposes. The dataset''s scratch
    obtains from the MySQL database has been prepared by merge mechanism corresponds
    to each experimental plant group and the room condition group that performs in
    the database by using MySQL query. There will be two datasets generated as the
    input data to develop the prediction model based on the Excel file export mechanisms.
    The machine learning technique is implemented after the dataset file preparation
    phase, with a suitable machine learning algorithm, achieving the prediction model
    is seen in figure 3. B. The Classification Tree Scheme The tree is the process
    of performing the machine learning technique with a decision tree algorithm. The
    procedure involves importing the decision tree classifier function from the tree
    package of the scikit -learn library. The decision tree method is implemented
    in model training phase is shown in figure 4. The computer conducts the operation
    corresponds to the user''s applicable preference. The input value is a preferred
    choice of the parameter that corresponds to the procedure''s function. This application
    uses three approved parameter subjected to the table. Another parameter defined
    by none value is not executed. The algorithm is implemented to define the attributes
    value in each instances outcome corresponds to the designated label. It corresponds
    to three observed attributes, namely moist level, temperature, and irrigation
    level started by splitting the moist level by splitting the moist level based
    on the available categorical attributes. Fig. 2. The database overview as the
    data storing management. Show All Fig. 3. The proposed workflow of the creation
    of prediction model. Show All Low and high label does not split further as it
    defines the node''s final level with classification labelled. The normal value
    characterizes by a decision node called temperature, split into two other sub-nodes
    based on the attributes value, such as decision and leaf node. The value of less
    than equal to twenty-five is detailed by decision node splits into two other leaf
    nodes. The final level with classification labelled results in optimal and less
    optimal, respectively. The overview of the classification tree is shown in figure
    5. C. Dataset Preprocessing It is a procedure to load the dataset from the respective
    directory, including folder and file name. Two datasets were loaded simultaneously
    by using the Read Excel function of the Pandas library. The function''s content
    is possible to characterize each parameter based on the user''s interest corresponds
    to the variable of the related parameter. The choice of the applicable parameter
    are: Sheet name Parse dates Index column Three parameters is applied to develop
    the model as it performs the machine learning algorithm, also data visualization.
    This procedure also applies the drop not a value function that does not cover
    any parameter. The function has an objective to remove all the instances in a
    row that has no value. Fig. 4. The proposed design of the global workflow system.
    Show All D. Dataset The real-time groups of sensed data taken form the localhost
    MySQL database based on the previous project are a principal scratch of the dataset.
    It consists of six fundamental attributes divides into one string, three continuous
    attributes, one categorical attribute, one time-stamp attribute, and the entire
    pots picture. The attribute given are as follows: plant''s name serves in the
    form of string. Moist level from the various observed pot serves in the form of
    categorical attributes. The time-series serves in the form of time-stamp attributes.
    Greenhouse temperature serves in the form of continuous attributes. Greenhouse
    humidity serves in the form of continuous attributes. Fig. 5. The overview of
    the classification tree design. Show All greenhouse light intensity serves in
    the form of continuous attributes. The camera''s output retrieves in the form
    of of picture path destination folder. The raw data is retrieved from the respective
    sensors that have been previously discussed. One group of sensed data attributes
    is disabled for prediction model development, namely the camera''s output. The
    contents leave one string, three continuous attributes, one categorical attribute,
    and one time-stamp attribute. The groups of sensed data are available in the form
    of an Excel file extension. Those sensed data groups is processed through Microsoft
    Excel application added with additional attributes and its corresponding variable
    over number of observations. This merge data operation produces qualified dataset
    for the application. The additional attributes is including one continuous and
    two categorical attributes are as follows: The plant''s height serves in the form
    of continuous attributes. The irrigation level serves in the form of category
    attributes. The class serves in the form of categorical attributes. The dataset
    is separated based on the irrigation system scenario corresponds to the environmental
    and growth-related factor in the greenhouse, also the manually-input variable.
    There are two observed plants for each scenario. Plant A and plant B corresponds
    to Pakcoy 1 and Pakcoy 2, respectively. In contrast, Plant C and plant D corresponds
    to Pakcoy 3 and Pakcoy 4. Each scenario is also differentiated based on two types
    of irrigation levels. The clarification of the irrigation system distribution
    and its corresponding level information is shown in table 1. The dataset attributes
    are one index, four continuous attributes, three categorical attributes, and one
    time-stamp attribute. The time-series schedule represents in date-time format,
    greenhouse temperature represents in degree units, greenhouse humidity represents
    in percentage, and greenhouse light intensity represents in lux units. The moist
    level is a categorical condition based on the soil moisture value measurement
    convert from percentage data, as shown in table 2. The temperature has the stated
    condition by the range of the degrees is shown in table 3. Table I Distribution
    of the plants observation based on irrigation system. Manually parameter, plant''s
    height, represents in centimeter based on the ruler, irrigation level, and class
    in categorical value. The sensed data is taken in the range of ten minutes from
    4th of January 2021 to 15th of January 2021 at 08.00 A.M. to 2.20 P.M. The class
    located at the last column in the dataset corresponds to the label for every instances
    associated with the moist level. The table provides the corresponding type of
    the moist level, and the temperature value is shown in table 4. There are two
    datasets generated based on the irrigation system for developing the prediction
    model. The automatic irrigation scenario contains 805 instances and nine attributes.
    Like the automated irrigation scenario, the manual irrigation scenario has the
    same total of attributes. In contrast, the manual dataset has 789 instances. Then,
    the concatenating dataset is equalled to 1594 instances. The sample of the dataset
    is shown in table 5. Pakcoy is an indonesian name of bok choy. Table II Moist
    level condition of the dataset. SECTION IV. The Evaluation of Classification Performance
    Metrics The performance metrics evaluation based on the available type for the
    classification approach. The corresponding value is the label test data and the
    label predicts data based on the prediction made for the attributes of train data.
    The variety of classification metrics are: A. Confusion Matrix This metric is
    necessary to calculate other performance parameters in the classification table,
    such as accuracy, precision, Etc. The result generated form the Jupyter notebook
    does not give any remarkable information corresponds to the value. In creating
    a more straightforward interpretation to understand the outcome, the value is
    presented in a form of table. The visualization of the confusion matrix with a
    table is shown in table 6. The noticeable perception is to give attention that
    the left top of the table corresponds to the true positive value and the left
    below is related to the negative class. Table III Temperature condition of the
    dataset. Table IV The data class of the dataset. Table V The automatic irrigation
    dataset sample. The table means the classifier has correctly classified the total
    of positive and negative instances. This matrix informs the total instance for
    two-class in which is stated by the overview of the classifier''s prediction is
    discussed in the previous section. This type of confusion matrix is correlated
    with the perfect classifier performance. It is strengthened by the matrix''s pattern
    with no value correlated with the false positive and false negative. As confirmation,
    it is suitable to review the parameter correlation. The true positive rate expressed
    by the total of true positive instances divides by the total of positive instances
    equals one is to meet the criterion as a result is equal to one. False positive
    rate equals zero as there are no available false positive instances classified.
    Also, the precision equals one as the positive value has only the true positive
    value. B. Classification Report These metrics perform as the final analysis as
    the value derived from the confusion matrix is present is in figure 6. The performance
    parameter as the consideration in depending on the ideal prediction model is the
    accuracy and precision. Before reviewing the parameter based on the value derived
    from the confusion matrix, these metrics clarify that the noticed label is only
    two, namely optimal and less optimal, as it not clearly stated in the confusion
    matrix discussion section. The absence of not optimal is because there are not
    enough instances available in the dataset. The analysis of the corresponding parameter
    present in table 7. On the table''s content, each of the parameter calculation
    is derived. The accuracy outcome meets the perfect classifier case prerequisite
    requirement al it also clarifies the accuracy score that has been converted into
    the percentage. Either precision score or recall is also completing the qualification.
    Table VI The visualization of the confusion matrix table. Fig. 6. The overview
    of the classification report result. Show All SECTION V. Prediction Model Testing
    This stage is conducted to represent the model testing phase. The model testing
    is differentiated from the model testing phase because it is based on unseen instances.
    In completing the analysis, it defines by the number of attributes value. The
    defined Test Model function is used as it more comfortable to change the attribute
    value. As the introductory to use the function, the variable''s value corresponds
    to the attributes shown in table 8. The outcome generated by the variables is
    shown in figure 7. It shows that the result is less optimal class. When we differentiated
    each defined value, such as the moist level is high, Temperature is greater than
    twenty-seven, and the irrigation level is sufficient. The result is satisfied.
    However, in this project, the humidity, height, and light intensity are dismissed.
    In comparison with other labels, another unseen instances is observed, as seen
    in figure 8. The attributes value is started from the moist level with normal
    value, the temperature is less than twenty-five, and the irrigation level is sufficient.
    These unseen instance are not satisfied. The appropriate class, optimal is not
    shown. Although the classification report able to classify the optimal label,
    it concludes that the data used is insufficient to predict unseen instances. It
    is shown by the number of test data in a total of three-hundred and thirteen for
    the less optimal and inversely proportional to six for optimal label. Table VII
    The parameter calculation table. Table VIII An overview of the attributes value
    definition. Fig. 7. An overview of unseen instances prediction. Show All Fig.
    8. An overview of the second unseen instances prediction. Show All Authors Figures
    References Citations Keywords Metrics More Like This Design of Real-Time System
    Based on Machine Learning for Snoring and OSA Detection ICASSP 2022 - 2022 IEEE
    International Conference on Acoustics, Speech and Signal Processing (ICASSP) Published:
    2022 An integrated approach of Genetic Algorithm and Machine Learning for generation
    of Worst-Case Data for Real-Time Systems 2022 IEEE/ACM 26th International Symposium
    on Distributed Simulation and Real Time Applications (DS-RT) Published: 2022 Show
    More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS
    VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: Decision Tree-Based Bok Choy Growth Prediction Model for Smart Farm
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.12694/scpe.v21i4.1759
  analysis: '>'
  authors:
  - S Manjunatha
  - B. Annappa
  citation_count: 3
  full_citation: '>'
  full_text: ">\nScalable Computing: Practice and Experience,\nISSN 1895-1767,\nhttp://www.scpe.org\n\
    © 2020 SCPE.\nVolume 21, Issues 4, pp. 611–623,\nDOI 10.12694:/scpe.v21i4.1759\n\
    REAL-TIME BIG DATA ANALYTICS FRAMEWORK WITH DATA BLENDING\nAPPROACH FOR MULTIPLE\
    \ DATA SOURCES IN SMART CITY APPLICATIONS\nMANJUNATHA S∗AND ANNAPPA B†\nAbstract.\
    \ Advancement in Information Communication Technology (ICT) and the Internet of\
    \ Things (IoT) has to lead to\nthe continuous generation of a large amount of\
    \ data. Smart city projects are being implemented in various parts of the world\n\
    where analysis of public data helps in providing a better quality of life. Data\
    \ analytics plays a vital role in many such data-driven\napplications. Real-time\
    \ analytics for finding valuable insights at the right time using smart city data\
    \ is crucial in making appropriate\ndecisions for city administration. It is essential\
    \ to use multiple data sources as input for the analysis to achieve better and\
    \ more\naccurate data-driven solutions. It helps in finding more accurate solutions\
    \ and making appropriate decisions. Public safety is one\nof the major concerns\
    \ in any smart city project in which real-time analytics is much useful in the\
    \ early detection of valuable data\npatterns. It is crucial to find early predictions\
    \ of crime-related incidents and generating emergency alerts for making appropriate\n\
    decisions to provide security to the people and safety of the city infrastructure.\
    \ This paper discusses the proposed real-time big\ndata analytics framework with\
    \ data blending approach using multiple data sources for smart city applications.\
    \ Analytics using\nmultiple data sources for a specific data-driven solution helps\
    \ in finding more data patterns, which in turn increases the accuracy\nof analytics\
    \ results. The data preprocessing phase is a challenging task in data analytics\
    \ when data being ingested continuously\nin real-time into the analytics system.\
    \ The proposed system helps in the preprocessing of real-time data with data blending\
    \ of\nmultiple data sources used in the analytics. The proposed framework is beneficial\
    \ when data from multiple sources are ingested in\nreal-time as input data and\
    \ is also flexible to use any additional data source of interest. The experimental\
    \ work carried out with the\nproposed framework using multiple data sources to\
    \ find the crime-related insights in real-time helps the public safety solutions\
    \ in\nthe smart city. The experimental outcome shows that there is a significant\
    \ increase in the number of identified useful data patterns\nas the number of\
    \ data sources increases. A real-time based emergency alert system to help the\
    \ public safety solution is implemented\nusing a machine learning-based classification\
    \ algorithm with the proposed framework. The experiment is carried out with different\n\
    classification algorithms, and the results show that Naive Bayes classification\
    \ performs better in generating emergency alerts.\nKey words: Big Data, Data blending,\
    \ Preprocessing, Real time analytics, Public safety, Smart city\nAMS subject classifications.\
    \ 68T05\n1. Introduction. Technological advancement in data analytics is changing\
    \ the business process by en-\nabling faster and better decisions based on real-time\
    \ analytics. When data analysts can harness useful insights\nfrom data faster,\
    \ it has a significant advantage in reducing costs, increasing eﬀiciency, and\
    \ profit. Extracting\nvaluable insights from raw data in real-time is critical\
    \ for many real-time applications. The demand for real-\ntime analytics is high\
    \ in recent days in various fields where data-driven solutions are being used.\
    \ In most of\nthe data-driven solutions, real-time processing of data for making\
    \ timely decisions can enhance the quality of\nservice, improve the accuracy of\
    \ predictions, and help in making early decisions. It is challenging for the data\n\
    analysts to process data from multiple sources in real-time for a specific analytical\
    \ solution. The outcomes of\nthe analytics are more effective and accurate when\
    \ more data from appropriate data sources get processed for\na specific analytical\
    \ solution.\nIn smart cities, the data gets generated continuously in real-time\
    \ from different applications, devices, and\nsocial media on a large scale.\n\
    The data generated from various smart applications and smart devices are\nof different\
    \ types and formats. The valuable insights derived from the data generated within\
    \ the city helps\neffective management and administration of the city services.\
    \ The data-driven solutions are widely used in some\nof the smart city applications\
    \ such as smart traﬀic management, smart parking systems, smart environment,\n\
    ∗Department of Computer Science and Engineering, National Institute of Technology\
    \ Karnataka Surathkal, India-575025\n(manjunatha.msh@ieee.org).\n†Department of\
    \ Computer Science and Engineering, National Institute of Technology Karnataka\
    \ Surathkal, India-575025\n(annappa@ieee.org).\n611\n612\nManjunatha S and Annappa\
    \ B\nsmart policing, smart healthcare, etc. A vast amount of user-generated content\
    \ within the city are analyzed\nfor finding useful insights to enhance the services\
    \ and performance of smart city applications. In turn, finding\nvaluable data\
    \ patterns in real-time greatly help in improving the performance of smart city\
    \ applications and\nquality of service. The advancement in digitization in recent\
    \ days opens up possible creation of user-generated\ncontent from various sources\
    \ — analytics on all available data as input to discover valuable data patterns\
    \ results\nin finding accurate data-driven solutions. For example, smart policing\
    \ applications for public safety; collect\nthe user-generated contents from different\
    \ social networking applications and any specific smart application\ndesigned\
    \ for the same purpose. Real-time analysis of the data collected from these data\
    \ sources helps in early\npredictions and monitoring of crime-related incidents\
    \ within the city. It is a challenging task for analysts to\nuse multiple data\
    \ sources with different properties in a specific data-driven solution.\nThe proposed\
    \ work is aiming to design a real-time big data analytics framework with a data\
    \ blending\napproach for data preprocessing when multiple data sources as input.\
    \ The motivation for this work is, when\ntarget data spread across multiple sources,\
    \ analysts must use all possible data sources to find hidden patterns\nand discover\
    \ valuable insights for more effective solutions. In smart policing applications\
    \ for public safety in\nsmart cities, data analysts are collecting the data within\
    \ the city from different sources for finding crime-related\ndata patterns that\
    \ further used for crime detection and administrative decisions for crime prevention.\
    \ In this\nscenario, many popular social media platforms used by the public and\
    \ any specific applications offered by the\npolice department are the major data\
    \ sources of information. All these data generated within the city are\nanalyzed\
    \ for making better decisions or more accurate predictions for crime detection\
    \ and prevention. The\nrapid growth of digitization in various fields created\
    \ ample space for more and more new data sources, which\nare added regularly in\
    \ the form of social media and smart applications. It is a challenging task for\
    \ the data\nanalysts to use additional data sources in their existing data-driven\
    \ solutions with minimal cost and time. The\nproposed framework is an attempt\
    \ to address the issue of blending data from multiple data sources for real-time\n\
    data analytics in smart city applications for public safety.\nIn this work, a\
    \ smart policing system for public safety in a smart city is considered where\
    \ different data\nsources from social media and smart application data are collected\
    \ and analyzed for generating emergency alerts\nusing the proposed framework.\
    \ The data blending approach proposed with the framework helps the analysts\n\
    to add up any of the related data-sources of interest in the existing analytics\
    \ framework. In the proposed\nmechanism, the analysts can use all identified data\
    \ sources in real-time for making better analytics solutions\nwithout any additional\
    \ delay. Section 2 of this article describes the importance of real-time analytics\
    \ and data\npreprocessing in it, and related work carried out. Section 3 describes\
    \ the design and implementation of the\nproposed framework for real-time analytics\
    \ with a data blending mechanism for a smart policing system use\ncase. Section\
    \ 4 of this article is a discussion of experimental work along with results, and\
    \ finally, Section 5\nconcludes and summarizes the proposed framework along with\
    \ future work for further enhancement.\n2. Backgound.\n2.1. Real-time Data Analytics.\
    \ Real-time analytics and streaming analytics have become more preva-\nlent in\
    \ big data applications, where timely decisions are more crucial and beneficial.\
    \ It is a need in many big\ndata applications to generate results in real-time\
    \ for better performance. In Real-time analytics, data processed\nat the very\
    \ moment it arrives into the system rather than processing at a later stage from\
    \ data storage wherein\nit gets stored. Some applications generate data continuously\
    \ in real-time, which affects the outcome of the\nanalytical results. For example,\
    \ the applications for environmental monitoring need to collect real-time data\n\
    such as temperature, humidity readings continuously. Real-time analytics helps\
    \ the analysts to glean essential\ninsights quickly and find the data-driven solution\
    \ instantly. The critical part in real-time big data analytics is\nextracting\
    \ valuable information from the incoming data as and when it enters an existing\
    \ big data infrastruc-\nture. The predictions or decision making in these applications\
    \ are affected by both historical data stored and\nreal-time data gets generated\
    \ continuously. Real-time analytics technologies and processes must be capable\
    \ of\nmanage and analyze the data as and when it enters the database.\nBig data\
    \ analytics research resulted in many real-time and streaming analytics tools\
    \ such as Apache Storm,\nApache Spark, and Apache Flink. In Spark, data stream\
    \ represented as a sequence of Resilient Distributed\nDatasets (RDDs) and in-memory\
    \ computing feature enables it to compute data batches quicker than Hadoop.\n\
    Apache Storm is another distributed computing framework for streaming data processing,\
    \ but there are limited\nReal-time Big Data Analytics Framework with Data Blending\
    \ Approach for Multiple Data Sources\n613\nstreaming machine learning libraries\
    \ are available. Apache Flink is brought as an alternative for Spark with its\n\
    defining traits as real-time processing and low data latency. Spark processes\
    \ chunks of data known as RDDs,\nwhereas Flink can process rows after rows of\
    \ data in real-time.\n2.2. Smart city and Public safety. Urban development is\
    \ a crucial issue for any government as the\nurban population is increasing around\
    \ the world in recent days [1]. Smart cities are one of the frontline projects\n\
    in most of the countries for urban development. While ’smart city’ means different\
    \ things to different people, one\ncommon thing everyone agrees on is that digital\
    \ technologies are used in the smart city to improve the quality\nof the services\
    \ within the city. The technological growth in digital and communication media\
    \ incorporated in\nthe smart city for better services within the city. Internet\
    \ of Things (IoT) and Information Technology (IT)\nhelp to accomplish many smart\
    \ applications in smart cities. It leads to generating a massive amount of data\
    \ in\ndistinctive formats. The advancement in big data technologies exploits to\
    \ analyze the data generated within the\ncity for enhanced services in the smart\
    \ city. The smart applications used in smart cities such as smart traﬀic,\nsmart\
    \ environment, smart governance, smart agriculture, smart health-care generates\
    \ a large amount of data,\nwhich can be used to extract useful insights to enhance\
    \ the quality of the service. The different types of sensors,\nvideo surveillance\
    \ cameras, and smart mobile applications used by smart city applications are the\
    \ major source\nfor generating data. The smart applications created for smart\
    \ city services and many popular social media\napplications are cause for generating\
    \ large amounts of user-generated content within the city, which helps in\nenhancing\
    \ the quality of service within the city.\nSmart policing solutions are widely\
    \ used for public safety due to the technological adoption of the Internet\nof\
    \ Things and Cloud [2]. Transport and traﬀic security, infrastructure security,\
    \ emergency services for fire and\nmedical, crisis management, and law enforcement\
    \ are the most common solutions in smart city public safety\nservices.\nReal-time\
    \ information is crucial for better implementation of such applications to provide\
    \ timely\nservices. Real-time crime centers are established in some cities to\
    \ keep the cities safe by monitoring the activities\nin real-time within the city.\
    \ Intelligent analytics on real-time data generated within the city is the solution\n\
    for smarter crime responses, monitoring, and prevention.\nLaw enforcement agencies\
    \ are switching towards\npredictive policing for their routine and investigation\
    \ procedures. It involves advanced analytics techniques\nto predict what and where\
    \ an incident likely to happen. Predictive policing in real-time can help in early\n\
    monitoring of the crime and preventing it before it happens.\n2.3. Data Preprocessing\
    \ in Big Data Analytics. Data preprocessing is a crucial and significant phase\n\
    within the data analytics process [3]. The raw data used as input into the analytics\
    \ system is likely to be noisy,\ninconsistent, and imperfect. The data preprocessing\
    \ phase is the set of techniques used for making raw data as\nanalytics-ready\
    \ in the data analytics process [4]. The preprocessing phase in real-time data\
    \ analytics becomes\nchallenging, where the raw data enters into the data collection\
    \ system continuously. The critical part in data\npreprocessing includes mainly\
    \ two concepts, such as data cleaning and feature engineering. Data preprocessing\n\
    is essential for achieving better accuracy and performance in the analytical model.\
    \ Most of the effort made\nin the preprocessing of big data is mainly focus on\
    \ developing feature selection methods [5]. Noise reduction,\ninstance reduction,\
    \ and missing values imputations are the important preprocessing methods focused\
    \ by data\nanalysts. When the data is collected from various sources, combining\
    \ this to form a consistent data is an\nimportant process in making the data ready\
    \ for analysis. Data blending is a technique in preprocessing for\ncombining data\
    \ from multiple sources to create a common data set for decision-making [6]. It\
    \ is one of the\nquick methods to extract common information from multiple data\
    \ sources.\n2.4. Related Work. Big data has been a progressive aspect of the industries\
    \ due to data explosion,\nwhich inhabited all business categories from the past\
    \ few years. The academic and industry research produced\nmany applications using\
    \ real-time big data analytics in the area of healthcare, fraud detection, smart\
    \ grid,\nsocial media analytics, sensor data analytics, and many more. The majority\
    \ of the work is on social media\ndata analytics for knowledge discovery. Congosto\
    \ et al. [7] proposed a cost-effective framework to perform\nmicro-blogs analytics\
    \ in twitter stream data. An event detection system is incorporated to detect\
    \ important\nevents in real-time from twitter data streams is proposed by Hasan\
    \ et al. [8]. Similar work has done for city\nevent detection for London city\
    \ using twitter data streams by Zhou et al. [9]. An adaptive filtering algorithm\n\
    is proposed by Fan et al. [10], to filter interesting tweets from the twitter\
    \ stream concerning user interest\n614\nManjunatha S and Annappa B\nprofiles.\
    \ A medical emergency system is proposed by Rathore et al. [11], to find the intelligent\
    \ decision by\nanalyzing medical data collected from sensors attached to the human\
    \ body. Charlie Catlett et al. [12] proposed\na spatio-temporal crime forecasting\
    \ model to detect high-risk crime regions using an auto-regressive model.\nPina‐Garcia\
    \ et al. [13] proposed that data generated from different social media platforms\
    \ can be integrated\nto enhance big data-driven models for crime prediction. Harnessing\
    \ multi-source data about public sentiments\nand activities for informed design\
    \ is proposed by Linlin You et al. [14] that addresses the process from data\n\
    collection to data visualization. Zheng Xu et al. [15] proposed a framework for\
    \ collecting and analyzing data\nfrom social media and surveillance cameras to\
    \ describe public safety events.\nSimilarly, many works have been attempted for\
    \ the safety of the city using real-time data. The real-time\nevent detection\
    \ system is designed to detect and classify the events for high way traﬀic data\
    \ by Khazaei et al.\n[16]. An event detection system designed for real-time data\
    \ analytics of IoT enabled communication system\nby Ali et al. [17]. A real-time\
    \ monitoring system using social big data is proposed for disaster management\n\
    by Choi and Bae [18]. A real-time road traﬀic monitoring system is proposed by\
    \ Wang et al. [19], estimating\nonline vacancies on the road using a traﬀic sensor\
    \ data stream. Real-time data analytics for predictions are\nused in many data-driven\
    \ applications. A prediction system designed using real-time news data sources\
    \ to\npredict future terrorist incidents is proposed by Toure and Gangopadhyay\
    \ [20]. A predictive model is proposed\nby Zhang and Yuan [21] for air quality\
    \ monitoring by analysis of real-time meteorology data from Beijing city.\nSome\
    \ of the work attempted for detecting, and monitoring of the crimes are forecasting\
    \ crime trends in urban\nareas by Cesario et al. [22], spectral analysis of crimes\
    \ in the city by Venturini and Baralis [23], Parvez et al.\n[24] and an intelligent\
    \ solution for the smart city using real-time crime analysis by Ghosh et al. [25].\n\
    From the past few years, the research articles on streaming data analytics have\
    \ been highlighted the need\nfor the preprocessing mechanism of the data collected\
    \ in the streaming manner for the analytics [26]. The\ndifferent technological\
    \ frameworks have been used for streaming data analytics. Fernando Puentes et\
    \ al. [27]\nanalyzed characteristics of different open source frameworks available\
    \ for streaming data analytics. Finding\nproper preprocessing mechanisms for data\
    \ in motion in real-time is essential in achieving better performance.\nWhenever\
    \ analytics is performed immediately after data is collected, the preprocessing\
    \ mechanism to be done\nas soon as the data enters the system. Data preprocessing\
    \ is becoming a critical methodology for knowledge\ndiscovery in streaming data\
    \ [5].\nThe authors identify the role of data preprocessing methodologies in the\n\
    streaming analytics system for better performance.\nThe critical preprocessing\
    \ methodologies include data\nreduction, incremental learning, concept drift detection,\
    \ and adaptation, and stream discretization algorithms.\nThe data preprocessing\
    \ with manual intervention is of no use for any better analytics system [28].\
    \ The authors\nuse an adaptive preprocessing mechanism for prediction on real-time\
    \ sensor data.\n3. Design and Implementation.\n3.1. Real-time Analytics Framework.\
    \ Real-time Big data analytics is an iterative process. Any real-\ntime analytics\
    \ design is broadly based on one of the two important data processing architectures\
    \ proposed by\nLambda [29] and Kappa architecture [30]. Figure 3.1 shows the overview\
    \ of Lambda architecture for real-time\nanalytics. Lambda architecture is a data\
    \ processing technique in a big data environment consisting of three\nlayers,\
    \ namely batch layer, serving layer, and speed layer. In this architecture, the\
    \ data enters into the system\nis passed through both batch layer and speed layer.\
    \ The batch layer is responsible for managing the master\ndataset and pre-compute\
    \ the batch views, while the speed layer is responsible for calculating real-time\
    \ views\nwith real-time data. The serving layer task is to index and expose the\
    \ pre-computed batch views for queries to\nbe executed. A query to be executed\
    \ can be answered through combined results of both batch and real-time\nviews.\
    \ Kappa architecture is a data processing architecture that is an alternate and\
    \ simplification of lambda\narchitecture. This architecture targets only on data\
    \ as a stream, so batch layer as in lambda architecture\nis removed. It comprises\
    \ of real-time layer and serving layer. Real-time input data is streamed through\
    \ the\nreal-time layer and results of which passed into the serving layer for\
    \ queries to be executed.\nIn the proposed work, the real-time data from multiple\
    \ sources are analyzed to discover useful insights\nfor making real-time decisions\
    \ and predictions. The data processed at the moment is stored for further use\n\
    in predictive models in later stages. The framework is designed based on Lambda\
    \ architecture. The data is\ningested into the analytical system immediately after\
    \ it gets generated at the particular source and preprocessed\nit to make it ready\
    \ for further analytics. The data from identified sources streamed through the\
    \ real-time layer\nReal-time Big Data Analytics Framework with Data Blending Approach\
    \ for Multiple Data Sources\n615\nInput Data\nInput Data\nStream Process\nBatch\
    \ View\nReal-time View\nQuery\nSpeed Layer\nServing Layer\nFig. 3.1. Real-time\
    \ analytics architecture\nwhere it is processed and passed into the serving layer.\
    \ The real-time queries to be executed using the real-time\nviews of the serving\
    \ layer. The data stored for further use is executed using the batch views along\
    \ with the\nreal-time views in the data-driven models.\n3.2. Proposed Design.\
    \ The proposed design for real-time analytics using multiple data sources is as\n\
    shown in Figure 3.2. The real-time data from identified data sources are collected\
    \ and processed for a specific\nData Sources\nSource-1\nSource-2\nSource-N\nData\
    \ Ingestion\nProcessor-1\nProcessor-2\nProcessor-N\nAdapter-1\nAdapter-2\nAdapter-N\n\
    Data Blending\nData Storage\nData Analytics\nReal Time analytics\n          Engine\n\
    Visualization\nAlerts\nDashboard\nHBase\nFig. 3.2. Proposed framework for Real\
    \ time big data analytics\ndata-driven solution. When the input data required\
    \ for the analysis are identified at different sources, it is\nessential to use\
    \ all available data in the process to increase the accuracy or performance of\
    \ the data-driven\nsolution. Here raw data from multiple sources in real-time\
    \ are used as input data for the specific data-driven\nsolution. The data is ingested\
    \ from a particular source as soon as it is generated at the source. The data\n\
    ingestion phase consists of different data ingestion processors for each input\
    \ data source used.\nEach data\ningestion processor is comprised of a real-time\
    \ data ingestion mechanism for the specific data source. The\nprocessor also includes\
    \ an initial stage of preprocessing mechanism for filtering of data of interest\
    \ for the\ndesired analytical solution. The data ingested and filtered at each\
    \ source is passed through a data blending\n616\nManjunatha S and Annappa B\n\
    mechanism. The purpose of the data blending mechanism is to integrate the data\
    \ from different sources to\na single common dataset for further analysis. The\
    \ data blending phase consists of separate adapters for each\nsource, which reads\
    \ the input from respective data ingestion processors. Each adapter is a real-time\
    \ task that\ncan read the data immediately when it filtered out from the respective\
    \ processor. Data blending is performed\nto extract the common data of interest\
    \ from each source and append it to a single dataset. The blended data is\nused\
    \ in the next stage for analysis to find meaningful patterns in real-time. The\
    \ outcome of this helps in making\ndata-driven decisions such as emergency alerts\
    \ of crime incidents, identifying crime hotspots, and prediction of\npossible\
    \ occurrences of crimes in the city.\n4. Experimental Evaluation. Figure 4.1 illustrates\
    \ the detailed framework and the flow of the real-time\nanalytics process.\nThree\
    \ different data sources identified as input data for experimental work, where\
    \ data\nReal Time Data\nTwitter Data\nFacebook  Data\nMobile App \n    Data\n\
    Data Ingestion & Preprocessing\nNiFi\nFlink\nIngestion\nBlending\nTwitter Data\
    \ \n Processor\n  FB Data \n Processor\n  App Data \n  Processor\nData Storage\n\
    Hadoop\nHadoop\nHBase\nTwitter Data \n   Adapter\n  FB Data \n  Adapter\n  App\
    \ Data \n   Adapter\n    Event \n   Stream\n    Event \n   Stream\n    Event \n\
    \   Stream\nFlink\n   Event \nProcessor\nAlerts \nFig. 4.1. Data blending of real\
    \ time data from multiple sources\ncollected in real-time. The data from each\
    \ source is ingested and filtered by respective ingestion processors\nand then\
    \ passed into corresponding adapters for data blending mechanism. Each adapter\
    \ is comprised of a\nmechanism to read the data from the respective processor\
    \ whenever new data arrives at the processor. When\nthe processor passes the new\
    \ data to the adapter, a real-time job is executed to preprocess the data with\
    \ a\ndata blending mechanism and store it on the HBase table on top of Hadoop.\
    \ Here HBase supports real-time\nread/write access to the data. The preprocessed\
    \ data stored on the HBase table is a blended data from multiple\nsources that\
    \ can be used in the further process for a real-time analytical solution to make\
    \ desired data-driven\ndecisions. A real-time emergency alert mechanism also introduced\
    \ during the data blending mechanism to\ngenerate alerts on any emergency incidents.\
    \ The contents of the ingested data from the processors are verified\nfor any\
    \ topics related to the emergency events. The input data stream is processed by\
    \ the event processor to\ngenerate any emergency alerts.\nThe critical approach\
    \ in the proposed work is the data blending mechanism for preprocessing the data.\
    \ Here\ndata from multiple sources prepared ready for further analytics process.\
    \ Data preprocessing is a critical step in\nthe analytics process as it takes\
    \ the maximum time of the entire process. The quality of the analytical result\n\
    purely depends on the quality of the data used. Preprocessing the input data with\
    \ appropriate preprocessing\nmechanisms is necessary. In the proposed work, analytics\
    \ to be performed in real-time where it is a challenging\nReal-time Big Data Analytics\
    \ Framework with Data Blending Approach for Multiple Data Sources\n617\ntask to\
    \ preprocess the data as the data arrives continuously at data collection end.\
    \ Preprocessing is to be done\nwhenever new data ingested into the system. In\
    \ the proposed mechanism, the data from multiple sources are\nused as input, whereas\
    \ kinds of literature referred to are targeting the single source of data. When\
    \ data from\nvarious data sources used in the analytics, each source may consist\
    \ of data in different formats, structures.\nThe proposed design mainly consists\
    \ of three components like processors for data ingestion, adapters for data\n\
    blending mechanism, and event processor to generate emergency alerts. Data ingestion\
    \ processors are respon-\nsible for data collection in real-time and also the\
    \ necessary filtering of expected data in real-time from the data\nsources. Adapters\
    \ for data blending mechanism are to preprocess the data for making it ready for\
    \ analytics\nand append into blended data. The purpose of an event processor is\
    \ to analyze the incoming data streams sent\nfrom the adapters to detect any emergency\
    \ incident in the city.\nData Ingestion Processors. For the experimental work,\
    \ real-time data from Twitter, Facebook posts,\nand citizen complaint data from\
    \ the mobile application are used as input data sources. For real-time data\n\
    collection, separate data ingestion processors are written for each of the data\
    \ sources, where each processor is\nperforming the task of real-time data ingestion\
    \ along with the initial stage preprocessing of data. The incoming\ndata is filtered\
    \ in the initial stage of preprocessing to extract only the data related to crime.\
    \ For example, in\nthe case of Twitter data, only the tweets related to the crime\
    \ are considered as required data for our analytics\nprocess, and other tweets\
    \ are discarded.\nThe workflow of each processor is as shown in Figure 4.2.\n\
    Each\nFig. 4.2. Processor for Crime data filtering\nprocessor is configured for\
    \ the respective data source with the data ingestion mechanism of real-time data.\n\
    The processors are responsible for real-time data ingestion into the analytical\
    \ system as and when new data\ngenerated at the source. In data ingestion processors,\
    \ data filtering is done to refine the data to select only the\ncrime-related\
    \ data of the specific city and discard any other unrelated data streams. If the\
    \ values of location\nin the incoming data match with the city location values,\
    \ then the data is considered for the further process;\notherwise, data discarded\
    \ directly. Further, the actual content of the accepted data is verified for having\
    \ any\ninformation related to crime.\nThe incoming data streams filtered based\
    \ on city location values and further verified for whether contents\nof the incoming\
    \ data related to crime or not. A knowledge-base is created, which consists of\
    \ crime-related\nwords and phrases to compare with the incoming data to find out\
    \ any crime-related information is present in\nthe incoming data. For experimental\
    \ work, 565 words and phrases which are related to different categories of\ncrimes\
    \ are used in the knowledge base with the help of Cambridge and Macmillan dictionaries.\
    \ The contents\n618\nManjunatha S and Annappa B\nof the knowledge base are used\
    \ to verify the crime-related information in the contents of the incoming data\n\
    stream. If any matching information present in the incoming data, then the data\
    \ stream is passed to the next\nstage of preprocessing. The outputs of the processors\
    \ are passed through respective adapters for data blending\nmechanism.\nData blending\
    \ mechanism. Real-time data ingested from each source by respective data ingestion\n\
    processors are passed to respective adapters.\nEach adapter process the incoming\
    \ data from the respective\nprocessor with the data blending mechanism. These\
    \ adapters are the real-time jobs written using Apache Flink\nas the real-time\
    \ processing tool. With its streaming architecture, Apache Flink helps to process\
    \ the events in\nreal-time with consistently high speed with low latency. In this\
    \ experiment, all three data sources used for the\nanalytics streamed from the\
    \ data ingestion mechanism are in javascript object notation (JSON) format, but\n\
    the structure of the data is different in each source. Data blending mechanism\
    \ is the process of combining the\ndata from the multiple sources into a single\
    \ dataset. Data blending is a different mechanism than the data\nintegration process.\
    \ Data blending is about working with multiple data sources by preparing them\
    \ and joining\nthem together for a specific use case, whereas data integration\
    \ typically stores as a single source in the data\nwarehouse for a user to access.\n\
    The proposed data blending mechanism is implemented with adapters to process data\
    \ streams from the\nrespective data ingestion processors. The adapters are written\
    \ as Flink jobs that can read new data from the\nrespective processor as and when\
    \ it arrives. A blending mechanism is a process of combining the data received\n\
    from the different processors and store it on a particular data storage for further\
    \ use. Here, we use HBase\nto store the blended data received from the adapters.\
    \ We also added an emergency event process mechanism\nwithin the adapters. During\
    \ the data blending mechanism, incoming data stream contents are observed for\n\
    data patterns related to any emergency events. Such data streams are passed to\
    \ an emergency event processor\nto generate emergency alerts.\nThe working of\
    \ the Twitter data adapter is as shown in Algorithm 1.\nHere, an adapter can read\
    \ the\nAlgorithm 1 Twitter data Adapter\n1. Read datastream from Twitter data\
    \ processor\n2. Parse the datastream to select target fields (created-at, name,\
    \ location, text)\n3. Send the selected fields of datastream to event processor\n\
    4. Write the values of selected fields to new row in HBase table BLENDED_TABLE\
    \ as\nvalueof(source-id) <- 1\nvalueof(created-at) <- Time\nvalueof(name) <- User\n\
    valueof(location) <- Location\nvalueof(text) <- Contents\n5. Repeat Step-1\ntwitter\
    \ data ingested and filtered at the respective processor immediately once it is\
    \ available. The adapter for\nthe twitter data source is written as a Flink job,\
    \ which reads each new input JSON file from the output of\nthe twitter data ingestion\
    \ processor. This JSON file is parsed to filter the target fields, which are the\
    \ useful\ninformation to be stored on blended data for further analytics. In the\
    \ JSON file from the twitter data source,\nthe values from specific fields such\
    \ as created-at, name, location, and text are considered for the analytics at\
    \ the\nnext stage. This information from each of the incoming data streams used\
    \ to store on the HBase table. Another\ninformation source-id is stored as ‘1’\
    \ for all the new appended rows from the twitter adapter. The source-id is\nto\
    \ be used in the further process to find the identity of the data source. During\
    \ the blending mechanism in the\nadapter, contents of the text in the tweet are\
    \ observed to identify the target events for emergency alerts. Each\nincoming\
    \ data is passed through an event processor to generate any emergency alerts.\n\
    The working of the adapters for the other data sources used in the experiment\
    \ is also similar to the twitter\ndata adapter. The structure of incoming data\
    \ is different with different attribute names in each data source.\nThe working\
    \ of the facebook data adapter shown in Algorithm 2 is similar to the adapter\
    \ for Twitter data,\nbut the target fields selected are created-time, id, location,\
    \ and message. The values of these attributes in the\nReal-time Big Data Analytics\
    \ Framework with Data Blending Approach for Multiple Data Sources\n619\nAlgorithm\
    \ 2 Facebook data Adapter\n1. Read datastream from Facebook data processor\n2.\
    \ Parse the datastream to select target fields (created-time, id, location, message)\n\
    3. Send the selected fields of datastream to event processor\n4. Write the values\
    \ of selected fields to new row in HBase table BLENDED_TABLE as\nvalueof(source-id)\
    \ <- 2\nvalueof(created-time) <- Time\nvalueof(id) <- User\nvalueof(location)\
    \ <- Location\nvalueof(message) <- Contents\n5. Repeat Step-1\ninput data are\
    \ stored on the blended table on HBase. In this case, the source-id is stored\
    \ as ’2’ for all new rows\nappended on blended data. During this process, the\
    \ data stream with the selected attributes is passed through\nan event processor\
    \ to detect any emergency events. Similarly, for the third data source used, an\
    \ application data\nadapter is added where the attributes such as created-time,\
    \ complaint-id, incident-location, and description are\nselected for further process.\
    \ For this data source, source-id as ’3’ is assigned for all new rows to append\
    \ on\nthe blended table. Here the contents of ‘message’ in the input data are\
    \ used for finding the patterns related to\nemergency events, as explained in\
    \ the twitter data adapter and facebook data adapter. Similarly, one can add\n\
    any other data source available for the analysis.\nEvent Processor. The purpose\
    \ of the event processor is to process the event streams passed from the\nadapter\
    \ to find any emergency incidents. The event processor consists of a machine learning-based\
    \ classification\nmodel to generate emergency event alerts from the incoming data\
    \ stream. A training model is developed by\nusing information about different\
    \ categories of crime incidents such as fire incidents, vehicle accidents, robbery,\n\
    rape, murder, and gang-war. The initial training model is created using the data\
    \ related to these six categories\nof crime incidents data. This training data\
    \ set is updated regularly as the model is tested with new incoming\ndata streams.\
    \ The contents of the newly arrived data stream from any of the three data adapters\
    \ are verified\nfor any emergency incidents. When such incidents are detected\
    \ during the process, an emergency alert gets\ngenerated to help in taking appropriate\
    \ action by the law enforcement authorities.\nAs and when the new data stream\
    \ is passed to the event processor, the content of the data is processed for\n\
    selecting the topic feature by adopting Latent Dirichlet Allocation (LDA) [31].\
    \ Initially, non-English contents\nare filtered out by using a language detection\
    \ library, and then stop words are filtered out from the contents.\nLatent Dirichlet\
    \ Allocation (LDA) is used to train a topic model that can output the distribution\
    \ of topics.\nThen, the classification model developed in the event processor\
    \ is used to find any emergency incident. This\nmodel has experimented with the\
    \ most popular classification algorithms to choose the better one for the most\n\
    appropriate results.\nIn this work, the most commonly used classification algorithms\
    \ in streaming data analytics such as the\nNaive Bayes (NB) classifier, Support\
    \ Vector Machines (SVM) classifier, Logistic Regression (LR), and Random\nForest\
    \ (RF) algorithms are used. NB classifier is a probabilistic classification algorithm\
    \ based on the application\nof Bayes’s theorem [32]. The model assumes that the\
    \ presence of a specific feature is unrelated to the presence\nof any other feature.\
    \ SVM classifier [33] is based on separating hyperplane according to which new\
    \ samples are\nclassified. Logistic Regression (LR) is a linear classifier that\
    \ measures the relationship between the dependent\nvariable and independent variables\
    \ by determining the probabilities using a logistic function [34]. Random\nForest\
    \ (RF) is based on the forest construction procedure where features as at nodes\
    \ grow like branches of a\ntree, finally combining all trees form a Random Forest\
    \ model [35]. To evaluate the performance of the model,\nfrequently used three\
    \ statistical metrics like accuracy, precision, and recall are used. Out of the\
    \ four different\nclassifiers used, the NB classifier gives the most accurate\
    \ results.\nHence this classifier is used to generate\nemergency alerts in the\
    \ proposed system. A detailed comparison of the classifier is provided in the\
    \ next section.\n5. Result and Discussion. The performance of the four different\
    \ classifiers used in the experiment for\nemergency events classification is as\
    \ shown in Figure 5.1. The experiment targeted for emergency incidents\n620\n\
    Manjunatha S and Annappa B\nby considering the six different categories of crimes.\
    \ The performance metrics are computed for each category\nof crime incidents.\
    \ Then, the overall measure is calculated as the average of the per class measure.\
    \ Here NB\nclassifier achieves a higher accuracy of 73%, which is a 3% improvement\
    \ over RF, 5% improvement over SVM,\nand 8% improvement over LR classifier.\n\
    The proposed data blending mechanism helps the analysts to collect more input\
    \ data in real-time. Figure\n5.2 shows the observations after the blending mechanism.\
    \ Figure 5.2.(a) represents the comparison of the data\nappended on the blended\
    \ table from each data source. The values for each data source used in the experiment\n\
    are calculated using source-id in the blended table. For each source-id, the total\
    \ number of data updated at\nan hourly basis is observed. The consolidated data\
    \ appended at an hourly basis is considered as data from\nmultiple sources. The\
    \ x-axis represents each hour of execution of the experiment, and the y-axis represents\
    \ the\nnumber of data rows appended on the blended table related to the respective\
    \ source. Similarly, Figure 5.2.(b)\nshows the number of crime data of different\
    \ categories from different sources in the observation at a particular\nperiod.\
    \ When data used from multiple sources in the experiments, analysts can benefit\
    \ from processing more\ndata to achieve better analytical results.\nThe proposed\
    \ mechanism is beneficial whenever any new data source is available for the analytics.\
    \ If any\nreal-time data source to be considered as an additional input in the\
    \ existing experiment, then one can easily\nFig. 5.1. Performance Comparison of\
    \ Classification Algorithms for Emergency Alerts\nReal-time Big Data Analytics\
    \ Framework with Data Blending Approach for Multiple Data Sources\n621\n1\n2\n\
    3\n4\n5\n6\n0\n50\n100\n150\n200\n250\n300\n350\nTime in hours\nNumber of crime\
    \ data in Blended table\nTwitter−data\nFB−data\nApp−data\nMultiple−Source\nTwitter−Data\n\
    Facebook−Data\nApp−Data\nMultiSource−Data\nData Sources\nNumber of Data\n0\n20\n\
    40\n60\n80\n100\n120\n140\nAccident\nFire & GangWar\nMurder & Rape\nRobbery\n\
    (a) Hourly-data\n(b) Source-wise data\nFig. 5.2. Data blending of real-time data\
    \ from multiple sources\nconsider it for analytics by adding a new processor and\
    \ an adapter for the particular data source. The new\nprocessor to be added must\
    \ consist of a mechanism for ingesting the identified data source with a preprocessing\n\
    mechanism, as explained in the earlier sections. Also, an adapter to be added\
    \ with a data blending mechanism,\nas discussed in the earlier section. Each of\
    \ the new data sources considered gives additional input to the event\nprocessor\
    \ for emergency alerts. More and more input data collection in real-time helps\
    \ the analysts to increase\nthe performance of the analytics outcome.\n6. Conclusions\
    \ and future work. Real-time data analytics is invaluable in many data-driven\
    \ applica-\ntions for quick response and actions. Public safety is one of the\
    \ key services in smart city applications, where\ntimely decisions and predictions\
    \ are much beneficial for detecting and preventing crimes. In real-time data an-\n\
    alytics, it is crucial to perform the entire analytics process as quickly as possible.\
    \ In the data analytics process,\nthe majority of the time spent for preprocessing\
    \ the data to make it prepare as analytics-ready. In real-time\nanalytics, whenever\
    \ new data arrives in the data collection phase, it must be preprocessed and analyzed\
    \ for\na desired analytical solution without much delay in the entire process.\
    \ Collecting the maximum data for the\nanalysis helps in achieving better outcomes.\
    \ Hence, it is essential to use multiple data sources for input data in\nanalytics\
    \ to find much better and accurate outcomes. The real-time analytics framework\
    \ with the data blending\napproach proposed in this work is appropriate to preprocess\
    \ the data from multiple sources in real-time. A\nreal-time event processing mechanism\
    \ is proposed for emergency alerts to any such incidents within the city.\nAnalytical\
    \ solutions such as predictions and data-driven decisions are possibly more accurate\
    \ when all available\ndata are used instead of a single data source. The proposed\
    \ mechanism is much flexible to add any new data\nsource to be used for the analytics\
    \ with the existing experimental setup.\nThe future work includes adopting the\
    \ proposed framework with more number of input data sources.\nThe input data used\
    \ from all the data sources in the proposed work are text data ingested in the\
    \ JSON\nformat, thus future work of real-time analytics targets to use different\
    \ data sources with different types of data\nformats and structures. The proposed\
    \ data blending mechanism can be incorporated with any other data-\ndriven applications\
    \ where one can use input data from multiple sources. The classification model\
    \ developed for\ngenerating emergency event alerts can be improved further for\
    \ achieving more accuracy. The classification model\nis developed by selecting\
    \ the better performing algorithm by comparing the four popularly used classification\n\
    algorithms in streaming data. The future work is to use a few more algorithms\
    \ for any better performance\nwith the proposed mechanism. Further research focused\
    \ on using the proposed mechanism for real-time crime\nhotspots predictions for\
    \ public safety in the smart city. It also intended to extend this experimental\
    \ setup in\n622\nManjunatha S and Annappa B\nthe crime predictions when real-time\
    \ data used along with the historical data.\nAcknowledgement. The authors would\
    \ like to thank Ministry of Electronics and Information Technology\n(MeitY), Government\
    \ of India, for their support in a part of the research.\nREFERENCES\n[1] S. Dirks,\
    \ C. Gurdgiev, M. Keeling, Smarter cities for smarter growth: How cities can optimize\
    \ their systems for the\ntalent-based economy, in: IBM Institute for Business\
    \ Value, May 2010.\n[2] Market-Research-Report, Public safety solution for smart\
    \ city- global forecast to 2023,Tech. rep., Information and Com-\nmunication Technology\
    \ Press Release, July 2018.\n[3] D. Pyle, Data Preparation for Data Mining, 1st\
    \ Edition, Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 1999.\n[4]\
    \ S. Garcia, S., J. Luengo, F. Herrera, Data Preprocessing in Data Mining,Springer\
    \ Publishing Company, Incorporated,\n2014.\n[5] S. Garcia, S. Ramirez-Gallego,\
    \ J. Luengo, J. M. Benitez, F. Herrera, Big data preprocessing: methods and prospects,\n\
    Big Data Analytics 1 (1)(2016) 9. doi:10.1186/s41044-016-0014-0..\n[6] Alteryx,\
    \ The definitive guide to data blending, White Paper.\n[7] M. Congosto, P. Basanta-Val,\
    \ L. Sanchez-Fernandez, T-hoarder: A framework to process twitter data streams,\
    \ Journal\nof Network and Computer Applications 83 (2017) 28 – 39. doi:https://doi.org/10.1016/j.jnca.2017.01.029.\n\
    [8] M.\nHasan,\nM.\nA.\nOrgun,\nR.\nSchwitter,\nReal-time\nevent\ndetection\n\
    from\nthe\ntwitter\ndata\nstream\nus-\ning\nthe\ntwitternews+\nframework,\nInformation\n\
    Processing\nand\nManagement\n56\n(3)\n(2019)\n1146\n–\n1165.\ndoi:https://doi.org/10.1016/j.ipm.2018.03.001.\n\
    [9] Y. Zhou, S. De, K. Moessner, Real world city event extraction from twitter\
    \ data streams, Procedia Computer Science 98\n(2016) 443 – 448, the 7th International\
    \ Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN\n2016)/The\
    \ 6th International Conference on Current and Future Trends of Information and\
    \ Communication Technologies\nin Health-care (ICTH-2016)/Aﬀiliated Workshops.\
    \ doi:https://doi.org/10.1016/j.procs.2016.09.069..\n[10] F. Fan, Y. Feng, L.\
    \ Yao, D. Zhao, Adaptive evolutionary filtering in real-time twitter stream, in:\
    \ Proceedings of the 25th\nACM International on Conference on Information and\
    \ Knowledge Management, CIKM ’16, ACM, New York, NY, USA,\n2016, pp. 1079–1088.\
    \ doi:10.1145/2983323.2983760.\n[11] M. M. Rathore, A. Ahmad, A. Paul, J. Wan,\
    \ D. Zhang, Real-time medical emergency response system: Exploiting iot\nand big\
    \ data for public health, Jornal of Medical System. 40 (12) (2016) 1–10. doi:10.1007/s10916-016-0647-6.\n\
    [12] Charlie\nCatlett,\nEugenio\nCesario,\nDomenico\nTalia,\nAndrea\nVinci,\n\
    Spatio-temporal\ncrime\npredictions\nin\nsmart cities:\nA data-driven approach\
    \ and experiments, Pervasive and Mobile Computing, 53, 62-74, (2019),\nhttps://doi.org/10.1016/j.pmcj.2019.01.003.\n\
    [13] C.A. Pina-Garcia, L. Ramirez-Ramirez, Exploring crime patterns in Mexico\
    \ City, Journal of Big Data, 6, 65, (2019),\nhttps://doi.org/10.1186/s40537-019-0228-x.\n\
    [14] L. You, B. Tunçer, H. Xing, Harnessing Multi-Source Data about Public Sentiments\
    \ and Activities for Informed Design,\nIEEE Transactions on Knowledge and Data\
    \ Engineering, 31, 2, 343-356, (2019),doi: 10.1109/TKDE.2018.2828431.\n[15] Zheng\
    \ Xu, Lin Mei, Zhihan Lv, Chuanping Hu, Xiangfeng Luo, Hui Zhang, Yunhuai Liu,\
    \ Multi-Modal Description of\nPublic Safety Events Using Surveillance and Social\
    \ Media, IEEE Transactions on Big Data, 5, 4, 529-539, (2019),doi:\n10.1109/TBDATA.2017.2656918.\n\
    [16] H. Khazaei, R. Veleda, M. Litoiu, A. Tizghadam, Realtime big data analytics\
    \ for event detection in highways, in: 2016\nIEEE 3rd World Forum on Internet\
    \ of Things (WF-IoT), 2016, pp. 472–477. doi:10.1109/WF-IoT.2016.7845461.\n[17]\
    \ M. I. Ali, N. Ono, M. Kaysar, Z. U. Shamszaman, T.-L. Pham, F. Gao, K. Griffin,\
    \ A. Mileo, Real-time data\nanalytics and event detection for iot-enabled communication\
    \ systems, Journal of Web Semantics 42 (2017) 19–37.\ndoi:https://doi.org/10.1016/j.websem.2016.07.001.\n\
    [18] S. Choi, B. Bae, The real-time monitoring system of social big data for dis-\
    \ aster management, in: J. J. J. H. Park, I.\nStojmenovic, H. Y. Jeong, G. Yi\
    \ (Eds.), Computer Science and its Applications, Springer Berlin Heidelberg, Berlin,\n\
    Heidelberg, 2015, pp. 809–815.\n[19] F. Wang, L. Hu, D. Zhou, R. Sun, J. Hu, K.\
    \ Zhao, Estimating on-line vacancies in real-time road traﬀic monitoring with\n\
    traﬀic sensor data stream, Ad Hoc Networks 35 (2015) 3–13, special Issue on Big\
    \ Data Inspired Data Sensing, Processing\nand Networking Technologies. doi:https://doi.org/10.1016/j.adhoc.2015.07.003.\n\
    [20] I. Toure, A. Gangopadhyay, Real time big data analytics for predicting terrorist\
    \ incidents, in: 2016 IEEE Symposium on\nTechnologies for Homeland Security (HST),\
    \ 2016, pp. 1–6. doi:10.1109/THS.2016.7568906.\n[21] C. Zhang, D. Yuan, Fast fine-grained\
    \ air quality index level prediction using random forest algorithm on cluster\
    \ computing\nof spark, in: 2015 IEEE 12th Intl Conf on Ubiquitous Intelligence\
    \ and Computing and 2015 IEEE 12th Intl Conf on Au-\ntonomic and Trusted Computing\
    \ and 2015 IEEE 15th Intl Conf on Scalable Computing and Communications and Its\
    \ As-\nsociated Workshops (UIC-ATC-ScalCom), 2015, pp. 929–934. doi:10.1109/UIC-ATC-ScalCom-CBDCom-IoP.2015.177..\n\
    [22] E. Cesario, C. Catlett, D. Talia, Forecasting crimes using autoregressive\
    \ models, in: 2016 IEEE 14th Intl Conf on Depend-\nable, Autonomic and Secure\
    \ Computing, 14th Intl Conf on Pervasive Intelligence and Computing, 2nd Intl\
    \ Conf on Big\nData Intelligence and Computing and Cyber Science and Technology\
    \ Congress(DASC/PiCom/DataCom/CyberSciTech),\n2016, pp. 795–802. doi:10.1109/DASC-PICom-DataCom-CyberSciTec.2016.138.\n\
    [23] L. Venturini, E. Baralis, A spectral analysis of crimes in san francisco,\
    \ in: Proceedings of the 2Nd ACM SIGSPA-\nTIAL Workshop on Smart Cities and Urban\
    \ Analytics, UrbanGIS ’16, ACM, New York, NY, USA, 2016, pp. 4:1–4:4.\nReal-time\
    \ Big Data Analytics Framework with Data Blending Approach for Multiple Data Sources\n\
    623\ndoi:10.1145/3007540.3007544.\n[24] M. R. Parvez, T. Mosharraf, M. E. Ali,\
    \ A novel approach to identify spatio-temporal crime pattern in dhaka city, in:\n\
    Proceedings of the Eighth International Conference on Information and Communication\
    \ Technologies and Development,\nICTD’16, ACM, New York, NY, USA, 2016, pp. 41:1–41:4.\
    \ doi:10.1145/2909609.2909624.\n[25] D. Ghosh, S. A. Chun, B. Shafiq, N. R. Adam,\
    \ Big data-based smart city platform:\nReal-time crime analysis, in:\nProceedings\
    \ of the 17th International Digital Government Research Conference on Digital\
    \ Government Research, dg.o\n’16, ACM, New York, NY, USA, 2016, pp. 58–66. doi:10.1145/2912160.2912205.\n\
    [26] S.\nRamirez-Gallego,\nB.\nKrawczyk,\nS.\nGarcia,\nM.\nWozniak,\nF.\nHerrera,\n\
    BA\nsurvey\non\ndata\npre-\nprocessing\nfor\ndata\nstream\nmining:\nCurrent\n\
    status\nand\nfuture\ndirections,\nNeurocomputing\n239\n(2017)\n39\n–57.\ndoi:https://doi.org/10.1016/j.neucom.2017.01.078.\n\
    URL\nhttp://www.sciencedirect.com/science/article/pii/\nS0925231217302631.\n[27]\
    \ F. Puentes, M.D. Perez-Godoy, P. Gonzalez, M.J. Del Jesus, An analysis of technological\
    \ frameworks for data streams,\nProgress in Artificial Intelligence(2020), https://doi.org/10.1007/s13748-020-00210-6.\n\
    [28] I. Zliobaite, B. Gabrys, Adaptive preprocessing for streaming data, IEEE\
    \ Transactions on Knowledge and Data Engineering\n26 (2) (2014) 309–321. doi:10.1109/TKDE.2012.147.\n\
    [29] N. Marz, J. Warren, Big Data: Principles and Best Practices of Scalable Realtime\
    \ Data Systems, 1st Edition, Manning\nPublications Co., Greenwich, CT, USA, 2015.\n\
    [30] J. Kreps, Questioning the Lamda Architecture, O’reilly, July 2014.\n[31]\
    \ D. M. Blei, A. Y. Ng, M. I. Jordan, Latent dirichlet allocation, Journal of\
    \ Machine Learning Research.\n[32] G. H. John, P. Langley, Estimating continuous\
    \ distributions in bayesian classifiers, in: Proceedings of the Eleventh\nConference\
    \ on Uncertainty in Artificial Intelligence, UAI’95, Morgan Kaufmann Publishers\
    \ Inc., San Francisco, CA,\nUSA, 1995, pp. 338–345. URL http://dl.acm.org/citation.cfm?id=2074158.2074196.\n\
    [33] C. Cortes, V. Vapnik, Support-vector networks, Machine Learning 20 (3) (1995)\
    \ 273–297. doi:10.1023/A:1022627411411.\n[34] I. Witten, E. Frank, M. Hall, Data\
    \ Mining: Practical Machine Learning Tools and Techniques, 3rd Edition, Elsevier,\n\
    2011.\n[35] L. Breiman, Random forests, Machine Learning, 5–32, (2001), doi:https:600//doi.org/10.1023/A:1010933404324.\n\
    Edited by: Rajkumar Rajasekaran\nReceived: May 8, 2020\nAccepted: Dec 7, 2020\n"
  inline_citation: '>'
  journal: Scalable Computing. Practice and Experience
  limitations: '>'
  pdf_link: https://www.scpe.org/index.php/scpe/article/download/1759/667
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: Real-time Big Data Analytics Framework with Data Blending Approach for Multiple
    Data sources in Smart City Applications
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1186/s40537-019-0192-5
  analysis: '>'
  authors:
  - Justin Johnson
  - Taghi M. Khoshgoftaar
  citation_count: 1365
  full_citation: '>'
  full_text: ">\nSurvey on deep learning with class \nimbalance\nJustin M. Johnson*\
    \ and Taghi M. Khoshgoftaar\nIntroduction\nSupervised learning methods require\
    \ labeled training data, and in classification prob-\nlems each data sample belongs\
    \ to a known class, or category [1, 2]. In a binary classifi-\ncation problem\
    \ with data samples from two groups, class imbalance occurs when one \nclass,\
    \ the minority group, contains significantly fewer samples than the other class,\
    \ \nthe majority group. In many problems [3–7], the minority group is the class\
    \ of inter-\nest, i.e., the positive class. A well-known class imbalanced machine\
    \ learning scenario is \nthe medical diagnosis task of detecting disease, where\
    \ the majority of the patients are \nAbstract \nThe purpose of this study is to\
    \ examine existing deep learning techniques for address-\ning class imbalanced\
    \ data. Effective classification with imbalanced data is an impor-\ntant area\
    \ of research, as high class imbalance is naturally inherent in many real-world\
    \ \napplications, e.g., fraud detection and cancer detection. Moreover, highly\
    \ imbalanced \ndata poses added difficulty, as most learners will exhibit bias\
    \ towards the majority class, \nand in extreme cases, may ignore the minority\
    \ class altogether. Class imbalance has \nbeen studied thoroughly over the last\
    \ two decades using traditional machine learning \nmodels, i.e. non-deep learning.\
    \ Despite recent advances in deep learning, along with \nits increasing popularity,\
    \ very little empirical work in the area of deep learning with \nclass imbalance\
    \ exists. Having achieved record-breaking performance results in several \ncomplex\
    \ domains, investigating the use of deep neural networks for problems contain-\n\
    ing high levels of class imbalance is of great interest. Available studies regarding\
    \ class \nimbalance and deep learning are surveyed in order to better understand\
    \ the efficacy of \ndeep learning when applied to class imbalanced data. This\
    \ survey discusses the imple-\nmentation details and experimental results for\
    \ each study, and offers additional insight \ninto their strengths and weaknesses.\
    \ Several areas of focus include: data complexity, \narchitectures tested, performance\
    \ interpretation, ease of use, big data application, \nand generalization to other\
    \ domains. We have found that research in this area is very \nlimited, that most\
    \ existing work focuses on computer vision tasks with convolutional \nneural networks,\
    \ and that the effects of big data are rarely considered. Several tradi-\ntional\
    \ methods for class imbalance, e.g. data sampling and cost-sensitive learning,\
    \ \nprove to be applicable in deep learning, while more advanced methods that\
    \ exploit \nneural network feature learning abilities show promising results.\
    \ The survey concludes \nwith a discussion that highlights various gaps in deep\
    \ learning from class imbalanced \ndata for the purpose of guiding future research.\n\
    Keywords: Deep learning, Deep neural networks, Class imbalance, Big data\nOpen\
    \ Access\n© The Author(s) 2019. This article is distributed under the terms of\
    \ the Creative Commons Attribution 4.0 International License \n(http://creat iveco\
    \ mmons .org/licen ses/by/4.0/), which permits unrestricted use, distribution,\
    \ and reproduction in any medium, \nprovided you give appropriate credit to the\
    \ original author(s) and the source, provide a link to the Creative Commons license,\
    \ and \nindicate if changes were made.\nSURVEY PAPER\nJohnson and Khoshgoftaar\
    \  J Big Data            (2019) 6:27  \nhttps://doi.org/10.1186/s40537-019-0192-5\n\
    *Correspondence:   \njjohn273@fau.edu \nFlorida Atlantic University, \n777 Glades\
    \ Road, Boca Raton, \nFL, USA\nPage 2 of 54\nJohnson and Khoshgoftaar  J Big Data\
    \            (2019) 6:27 \nhealthy and detecting disease is of greater interest.\
    \ In this example, the majority group of \nhealthy patients is referred to as\
    \ the negative class. Learning from these imbalanced data \nsets can be very difficult,\
    \ especially when working with big data [8, 9], and non-standard \nmachine learning\
    \ methods are often required to achieve desirable results. A thorough \nunderstanding\
    \ of the class imbalance problem and the methods available for addressing \nit\
    \ is indispensible, as such skewed data exists in many real-world applications.\n\
    When class imbalance exists within training data, learners will typically over-clas-\n\
    sify the majority group due to its increased prior probability. As a result, the\
    \ instances \nbelonging to the minority group are misclassified more often than\
    \ those belonging to the \nmajority group. Additional issues that arise when training\
    \ neural networks with imbal-\nanced data will be discussed in the \"Deep learning\
    \ methods for class imbalanced data\" \nsection. These negative effects make it\
    \ very difficult to accomplish the typical objective \nof accurately predicting\
    \ the positive class of interest. Furthermore, some evaluation met-\nrics, such\
    \ as accuracy, may mislead the analyst with high scores that incorrectly indi-\n\
    cate good performance. Given a binary data set with a positive class distribution\
    \ of 1%, \na naïve learner that always outputs the negative class label for all\
    \ inputs will achieve \n99% accuracy. Many traditional machine learning techniques,\
    \ which are summarized in \nthe \"Machine learning techniques for class imbalanced\
    \ data\" section, have been devel-\noped over the years to combat these adverse\
    \ effects.\nMethods for handling class imbalance in machine learning can be grouped\
    \ into three \ncategories: data-level techniques, algorithm-level methods, and\
    \ hybrid approaches [10]. \nData-level techniques attempt to reduce the level\
    \ of imbalance through various data \nsampling methods. Algorithm-level methods\
    \ for handling class imbalance, commonly \nimplemented with a weight or cost schema,\
    \ include modifying the underlying learner \nor its output in order to reduce\
    \ bias towards the majority group. Finally, hybrid systems \nstrategically combine\
    \ both sampling and algorithmic methods [10].\nOver the last 10 years, deep learning\
    \ methods have grown in popularity as they have \nimproved the state-of-the-art\
    \ in speech recognition, computer vision, and other domains \n[11]. Their recent\
    \ success can be attributed to an increased availability of data, improve-\nments\
    \ in hardware and software [12–16], and various algorithmic breakthroughs that\
    \ \nspeed up training and improve generalization to new data [17]. Despite these\
    \ advances, \nvery little statistical work has been done which properly evaluates\
    \ techniques for han-\ndling class imbalance using deep learning and their corresponding\
    \ architectures, i.e. \ndeep neural networks (DNNs). In fact, many researchers\
    \ agree that the subject of deep \nlearning with class imbalanced data is understudied\
    \ [18–23]. For this reason, our survey \nis limited to just 15 deep learning methods\
    \ for addressing class imbalance.\nA comprehensive literature review was performed\
    \ in order to identify a broad range \nof deep learning methods for addressing\
    \ class imbalance. We have documented the spe-\ncific details of the literature\
    \ search process so that other scholars may more confidently \nuse this survey\
    \ in future research, an essential step in any literature review [24]. Can-\n\
    didate papers were first discovered through the Google Scholar [25] and IEEE Xplore\
    \ \n[26] databases. Keyword searches included combinations of query terms such\
    \ as: “class \nimbalance”, “class rarity”, “skewed data”, “deep learning”, “neural\
    \ networks” and “deep \nneural networks”. Search results were reviewed and filtered,\
    \ removing those that did \nPage 3 of 54\nJohnson and Khoshgoftaar  J Big Data\
    \            (2019) 6:27 \nnot demonstrate learning from class imbalanced data\
    \ with neural networks containing \ntwo or more hidden layers. No restrictions\
    \ were placed on the date of publication. The \nmatched search results were then\
    \ used to perform backward and forward searches, i.e. \nreviewing the references\
    \ of matched articles and additional sources that have cited these \narticles.\
    \ This was repeated until all relevant papers were identified, to the best of\
    \ our \nknowledge.\nAdditional selection criteria were applied to exclude papers\
    \ that only tested low lev-\nels of class imbalance, that did not compare proposed\
    \ methods to other existing class \nimbalance methods, or that only used a single\
    \ data set for evaluation. We discovered \nthat papers meeting these criteria\
    \ are very limited. Therefore, in order to increase the \ntotal number of selected\
    \ works, these additional requirements were relaxed. The final set \nof 15 publications\
    \ includes journal articles, conference papers, and student theses that \nemploy\
    \ deep learning methods with class imbalanced data.\nWe explore a variety of data-level,\
    \ algorithm-level, and hybrid deep learning meth-\nods designed to improve the\
    \ classification of imbalanced data. Implementation details, \nexperimental results,\
    \ data set details, network topologies, class imbalance levels, perfor-\nmance\
    \ metrics, and any known limitations are included in each surveyed work’s discus-\n\
    sion. Tables 17 and 18, in the \"Discussion of surveyed works\" section, summarize\
    \ all of \nthe surveyed deep learning methods and the details of their corresponding\
    \ data sets. \nThis survey provides the most current analysis of deep learning\
    \ methods for addressing \nclass imbalance, summarizing and comparing all related\
    \ work to date, to the best of our \nknowledge.\nThe remainder of this paper is\
    \ organized as follows. The \"Class imbalance background\" \nsection provides\
    \ background information on the class imbalance problem, reviews per-\nformance\
    \ metrics that are more sensitive to class imbalanced data, and discusses some\
    \ \nof the more popular traditional machine learning (non-deep learning) techniques\
    \ for \nhandling imbalanced data. The  \"Deep learning background\" section provides\
    \ neces-\nsary background information on deep learning. The neural network architectures\
    \ used \nthroughout the survey are introduced, along with several important milestones\
    \ and the \nuse of deep learning in solving big data analytics challenges. The \"\
    Deep learning meth-\nods for class imbalanced data\" section surveys 15 published\
    \ studies that analyze deep \nlearning methods for addressing class imbalance.\
    \ The \"Discussion of surveyed works\" \nsection summarizes the surveyed works\
    \ and offers further insight into their various \nstrengths and weaknesses. The \"\
    Conclusion\" section concludes the survey and discusses \npotential areas for\
    \ future work.\nClass imbalance background\nThe task of binary classification,\
    \ comprised of one positive group and one negative \ngroup, is used to discuss\
    \ class imbalance and various techniques for addressing its \nchallenges in this\
    \ section. These concepts can be extended to the multi-class problem, \nbecause\
    \ it is possible to convert multi-class problems into a set of two-class problems\
    \ \nthrough class decomposition [27].\nPage 4 of 54\nJohnson and Khoshgoftaar\
    \  J Big Data            (2019) 6:27 \nThe class imbalance problem\nSkewed data\
    \ distributions naturally arise in many applications where the positive class\
    \ \noccurs with reduced frequency, including data found in disease diagnosis [3],\
    \ fraud \ndetection [4, 5], computer security [6], and image recognition [7].\
    \ Intrinsic imbalance \nis the result of naturally occurring frequencies of data,\
    \ e.g. medical diagnoses where the \nmajority of patients are healthy. Extrinsic\
    \ imbalance, on the other hand, is introduced \nthrough external factors, e.g.\
    \ collection or storage procedures [28].\nIt is important to consider the representation\
    \ of the minority and majority classes \nwhen learning from imbalanced data. It\
    \ was suggested by Krawczyk [10] that good \nresults can be obtained, regardless\
    \ of class disproportion, if both groups are well rep-\nresented and come from\
    \ non-overlapping distributions. Japkowicz [29] examined the \neffects of class\
    \ imbalance by creating artificial data sets with various combinations of \ncomplexity,\
    \ training set size, and degrees of imbalance. The results show that sensitivity\
    \ \nto imbalance increases as problem complexity increases, and that non-complex,\
    \ linearly \nseparable problems are unaffected by all levels of class imbalance.\n\
    In some domains, there is a genuine lack of data due to the low frequency with\
    \ which \nevents occur, e.g. detecting oil spills [7]. Learning from extreme class\
    \ imbalanced data, \nwhere the minority class accounts for as few as 0.1% of the\
    \ training data [10, 30], is of \ngreat importance because it is typically these\
    \ rare occurrences that we are most inter-\nested in. Weiss [31] discusses the\
    \ difficulties of learning from rare events and various \nmachine learning techniques\
    \ for addressing these challenges.\nThe total number of minority samples available\
    \ is of greater interest than the ratio or \npercentage of the minority. Consider\
    \ a minority group that is just 1% of a data set con-\ntaining 1 million samples.\
    \ Regardless of the high level of imbalance, there are still many \npositive samples\
    \ (10,000) available to train a model. On the other hand, an imbalanced \ndata\
    \ set where the minority class displays rarity or under-representation is more\
    \ likely to \ncompromise the performance of the classifier [30].\nFor the purpose\
    \ of comparing experimental results across all works presented in this \nsurvey,\
    \ a ratio ρ (Eq. 1) [23] will be used to indicate the maximum between-class imbal-\n\
    ance level. Ci is a set of examples in class i, and maxi{|Ci|} and mini{|Ci|}\
    \ return the max-\nimum and minimum class size over all i classes, respectively.\
    \ For example, if a data set’s \nlargest class has 100 samples and its smallest\
    \ class has 10 samples, then the data has an \nimbalance ratio of ρ = 10 . Since\
    \ the actual number of samples may prove more impor-\ntant than the ratio, Table 18\
    \ also includes the maximum and minimum class sizes for all \nexperiments in this\
    \ survey.\nPerformance metrics\nThe confusion matrix in Table 1 summarizes binary\
    \ classification results. The FP and FN \nerrors correspond to Type I and Type\
    \ II errors, respectively. All of the performance met-\nrics listed in this section\
    \ can be derived from the confusion matrix.\n(1)\nρ = maxi{|Ci|}\nmini{|Ci|}\n\
    Page 5 of 54\nJohnson and Khoshgoftaar  J Big Data            (2019) 6:27 \nAccuracy\
    \ (Eq. 2) and error rate (Eq. 3) are the most frequently used metrics when evalu-\n\
    ating classification results. When working with class imbalance, however, both\
    \ are insuf-\nficient, as the resulting value is dominated by the majority group,\
    \ i.e. the negative class. \nAs mentioned previously, when given a data set whose\
    \ positive group distribution is just \n1% of the data set, a naïve classifier\
    \ can achieve a 99% accuracy score by simply labeling \nall examples as negative.\
    \ Of course, such a model would provide no real value. For this \nreason, we review\
    \ several popular evaluation metrics commonly used with imbalanced \ndata problems.\n\
    Precision (Eq. 4) measures the percentage of the positively labeled samples that\
    \ are actu-\nally positive. Precision is sensitive to class imbalance because\
    \ it considers the number of \nnegative samples incorrectly labeled as positive.\
    \ Precision alone is insufficient, however, \nbecause it provides no insight into\
    \ the number of samples from the positive group that \nwere mislabeled as negative.\
    \ On the other hand, Recall (Eq. 5), or the True Positive Rate \n(TPR), measures\
    \ the percentage of the positive group that was correctly predicted to \nbe positive\
    \ by the model. Recall is not affected by imbalance because it is only depend-\n\
    ent on the positive group. Recall does not consider the number of negative samples\
    \ that \nare misclassified as positive, which can be problematic in problems containing\
    \ class \nimbalanced data with many negative samples. There is a trade-off between\
    \ precision and \nrecall, and the metric of greater importance varies from problem\
    \ to problem. Selectivity \n(Eq. 6), or the True Negative Rate (TNR), measures\
    \ the percentage of the negative group \nthat was correctly predicted to be negative.\n\
    (2)\nAccuracy =\nTP + TN\nTP + TN + FP + FN\n(3)\nError Rate = 1 − Accuracy\n\
    (4)\nPrecision =\nTP\nTP + FP\n(5)\nRecall = TPR =\nTP\nTP + FN\n(6)\nSelectivity\
    \ = TNR =\nTN\nTN + FP\n(7)\nF-Measure =(1 + β2) × Recall × Precision\nβ2 × Recall\
    \ + Precision\n(8)\nG-Mean =\n√\nTPR × TNR\n(9)\nBalanced Accuracy =1\n2 × (TPR\
    \ + TNR)\nTable 1 Confusion matrix\nActual positive\nActual negative\nPredicted\
    \ positive\nTrue positive (TP)\nFalse positive (FP)\nPredicted negative\nFalse\
    \ negative (FN)\nTrue negative (TN)\nPage 6 of 54\nJohnson and Khoshgoftaar  J\
    \ Big Data            (2019) 6:27 \nThe F-Measure (Eq. 7), or F1-score, combines\
    \ precision and recall using the harmonic \nmean, where coefficient β is used\
    \ to adjust the relative importance of precision versus \nrecall. The G-Mean (Eq. 8)\
    \ measures performance by combining both the TPR and the \nTNR metrics using the\
    \ square root of their product. Similar to the G-Mean, the Bal-\nanced Accuracy\
    \ (Eq. 9) metric also combines TPR and TNR values to compute a metric \nthat is\
    \ more sensitive to the minority group [18]. Although F-Measure, G-Mean, and \n\
    Balanced Accuracy are improvements over Accuracy and Error Rate, they are still\
    \ not \nentirely effective when comparing performance between classifiers and\
    \ various distribu-\ntions [28].\nThe receiver operating characteristics (ROC)\
    \ curve, first presented by Provost and Faw-\ncett [32], is another popular assessment\
    \ which plots true positive rate over false posi-\ntive rate, creating a visualization\
    \ that depicts the trade-off between correctly classified \npositive samples and\
    \ incorrectly classified negative samples. For models which produce \ncontinuous\
    \ probabilities, thresholding can be used to create a series of points along ROC\
    \ \nspace [28]. From this a single summary metric, the area under the ROC curve\
    \ (AUC), can \nbe computed and is often used to compare performance between models.\
    \ A weighted-\nAUC metric, which takes cost biases into consideration when calculating\
    \ the area, was \nintroduced by Weng and Poon [33].\nAccording to Davis and Goadrich\
    \ [34], ROC curves can present overly optimis-\ntic results on highly skewed data\
    \ sets and Precision–Recall (PR) curves should be used \ninstead. The authors\
    \ claim that a curve can only dominate in ROC space if it also domi-\nnates in\
    \ PR space. This is justified by the fact that the false positive rate used by\
    \ ROC, \nFPR =\nFP\nFP+TN , will be less sensitive to changes in FP as the size\
    \ of the negative class \ngrows.\nAccording to Seliya et al. [35], learners should\
    \ be evaluated with a set of complemen-\ntary performance metrics, where each\
    \ individual metric captures a different aspect of \nperformance. In their comprehensive\
    \ study, 22 different performance metrics were used \nto evaluate two classifiers\
    \ across 35 unique data sets. Common factor analysis was then \nused to group\
    \ the metrics, identifying sets of unrelated performance metrics that can \nbe\
    \ used in tandem to reduce redundancy and improve performance interpretation.\
    \ One \nexample set of complementary performance metrics discovered by Seliya\
    \ et al. is AUC, \nBrier Inaccuracy [36], and accuracy.\nMachine learning techniques\
    \ for class imbalanced data\nAddressing class imbalance with traditional machine\
    \ learning techniques has been stud-\nied extensively over the last two decades.\
    \ The bias towards the majority class can be alle-\nviated by altering the training\
    \ data to decrease imbalance, or by modifying the model’s \nunderlying learning\
    \ or decision process to increase sensitivity towards the minority \ngroup. As\
    \ such, methods for handling class imbalance are grouped into data-level tech-\n\
    niques, algorithm-level methods, and hybrid approaches. This section summarizes\
    \ some \nof the more popular traditional machine learning methods for handling\
    \ class imbalance.\nPage 7 of 54\nJohnson and Khoshgoftaar  J Big Data       \
    \     (2019) 6:27 \nData‑level methods\nData-level methods for addressing class\
    \ imbalance include over-sampling and under-\nsampling. These techniques modify\
    \ the training distributions in order to decrease the \nlevel of imbalance or\
    \ reduce noise, e.g. mislabeled samples or anomalies. In their sim-\nplest forms,\
    \ random under-sampling (RUS) discards random samples from the majority \ngroup,\
    \ while random over-sampling (ROS) duplicates random samples from the minor-\n\
    ity group [37].\nUnder-sampling voluntarily discards data, reducing the total\
    \ amount of information \nthe model has to learn from. Over-sampling will cause\
    \ an increased training time due to \nthe increased size of the training set,\
    \ and has also been shown to cause over-fitting [38]. \nOver-fitting, characterized\
    \ by high variance, occurs when a model fits too closely to the \ntraining data\
    \ and is then unable to generalize to new data. A variety of intelligent sam-\n\
    pling methods have been developed in an attempt to balance these trade-offs.\n\
    Intelligent under-sampling methods aim to preserve valuable information for learning.\
    \ \nZhang and Mani [39] present several Near-Miss algorithms that use a K-nearest\
    \ neigh-\nbors (K-NN) classifier to select majority samples for removal based\
    \ on their distance \nfrom minority samples. One-sided selection was proposed\
    \ by Kubat and Matwin [40] as \na method for removing noisy and redundant samples\
    \ from the majority class as they are \ndiscovered through a 1-NN rule and Tomek\
    \ links [41]. Barandela et al. [42] use Wilson’s \nediting [43], a K-NN rule that\
    \ removes misclassified samples from the training set, to \nremove majority samples\
    \ from class boundaries.\nA number of informed over-sampling techniques have also\
    \ been developed to \nstrengthen class boundaries, reduce over-fitting, and improve\
    \ discrimination. Chawla \net  al. [44] introduced the Synthetic Minority Over-sampling\
    \ Technique (SMOTE), a \nmethod that produces artificial minority samples by interpolating\
    \ between existing \nminority samples and their nearest minority neighbors. Several\
    \ variants to SMOTE, e.g. \nBorderline-SMOTE [45] and Safe-Level-SMOTE [46], improve\
    \ upon the original algo-\nrithm by also taking majority class neighbors into\
    \ consideration. Borderline-SMOTE \nlimits over-sampling to the samples near class\
    \ borders, while Safe-Level-SMOTE defines \nsafe regions to prevent over-sampling\
    \ in overlapping or noise regions.\nSupervised learning systems usually define\
    \ a concept with several disjuncts, where \neach disjunct is a conjunctive definition\
    \ describing a subconcept [47]. The size of a dis-\njunct corresponds to the number\
    \ of samples that the disjunct correctly classifies. Small \ndisjuncts, often\
    \ corresponding to rare cases in the domain, are learned concepts that \ncorrectly\
    \ classify only a few data samples. These small disjuncts are problematic, as\
    \ they \noften contain much higher error rates than large disjuncts, and they\
    \ cannot be removed \nwithout compromising performance [48].\nJo and Japkowicz\
    \ [49] proposed cluster-based over-sampling to address the presence \nof small\
    \ disjuncts in the training data. Minority and majority groups are first clustered\
    \ \nusing the K-means algorithm, then over-sampling is applied to each cluster\
    \ separately. \nThis improves both within-class imbalance and between-class imbalance.\n\
    Van Hulse et  al. [37] compared seven different sampling techniques with 11 com-\n\
    monly-used machine learning algorithms. Each model was evaluated with 35 bench-\n\
    mark data sets using six different performance metrics to compare results. It\
    \ was shown \nthat sampling results were highly dependent on both the learner\
    \ and the evaluation \nPage 8 of 54\nJohnson and Khoshgoftaar  J Big Data    \
    \        (2019) 6:27 \nperformance metric. Experiments revealed that RUS resulted\
    \ in good performance over-\nall, outperforming ROS and intelligent sampling methods\
    \ in most cases. The results sug-\ngest that, although RUS performs well in most\
    \ cases, no sampling method is guaranteed \nto perform best in all problem domains,\
    \ and multiple performance metrics should be \nused when evaluating results.\n\
    Algorithm‑level methods\nUnlike data sampling methods, algorithmic methods for\
    \ handling class imbalance do not \nalter the training data distribution. Instead,\
    \ the learning or decision process is adjusted \nin a way that increases the importance\
    \ of the positive class. Most commonly, algorithms \nare modified to take a class\
    \ penalty or weight into consideration, or the decision thresh-\nold is shifted\
    \ in a way that reduces bias towards the negative class.\nIn cost-sensitive learning,\
    \ penalties are assigned to each class through a cost matrix. \nIncreasing the\
    \ cost of the minority group is equivalent to increasing its importance, \ndecreasing\
    \ the likelihood that the learner will incorrectly classify instances from this\
    \ \ngroup [10]. The cost matrix of a binary classification problem is shown in\
    \ Table 2 [50]. \nA given entry of the table, cij , is the cost associated with\
    \ predicting class i when the true \nclass is j. Usually, the diagonal of the\
    \ cost matrix, where i = j , is set to 0. The costs corre-\nsponding to false\
    \ positive and false negative errors are then adjusted for desired results.\n\
    Ling and Sheng [51] categorize cost-sensitive methods as either a direct method,\
    \ or a \nmeta-learning method. Direct methods are methods that have cost-sensitive\
    \ capabilities \nwithin themselves, achieved through modification of the learner’s\
    \ underlying algorithm \nsuch that costs are taken into consideration during learning.\
    \ The optimization process \nchanges from one of minimizing total error, to one\
    \ of minimizing total cost. Meta-learn-\ning methods utilize a wrapper to convert\
    \ cost-insensitive learners into cost-sensitive \nsystems. If a cost-insensitive\
    \ classifier produces posterior probability estimates, the cost \nmatrix can be\
    \ used to define a new threshold p∗ such that:\nUsually, thresholding methods\
    \ use p∗ (Eq. 10) to redefine the output decision threshold \nwhen classifying\
    \ samples [51]. Threshold moving, or post-processing the output class \nprobabilities\
    \ using Eq. 10, is one meta-learning approach that converts a cost-insensitive\
    \ \nlearner into a cost-sensitive system.\nOne of the biggest challenges in cost-sensitive\
    \ learning is the assignment of an effec-\ntive cost matrix. The cost matrix can\
    \ be defined empirically, based on past experiences, \nor a domain expert with\
    \ knowledge of the problem can define them. Alternatively, the \nfalse negative\
    \ cost can be set to a fixed value while the false positive cost is varied, using\
    \ \na validation set to identify the ideal cost matrix. The latter has the advantage\
    \ of exploring \n(10)\np∗ =\nc10\nc10 + c01\nTable 2 Cost matrix\nActual positive\n\
    Actual negative\nPredicted positive\nC(1, 1) = c11\nC(1, 0) = c10\nPredicted negative\n\
    C(0, 1) = c01\nC(0, 0) = c00\nPage 9 of 54\nJohnson and Khoshgoftaar  J Big Data\
    \            (2019) 6:27 \na range of costs, but can be expensive and even impractical\
    \ if the size of the data set or \nnumber of features is too large.\nHybrid methods\n\
    Data-level and algorithm-level methods have been combined in various ways and\
    \ \napplied to class imbalance problems [10]. One strategy includes performing\
    \ data sam-\npling to reduce class noise and imbalance, and then applying cost-sensitive\
    \ learning or \nthresholding to further reduce the bias towards the majority group.\
    \ Several techniques \nwhich combine ensemble methods with sampling and cost-sensitive\
    \ learning were pre-\nsented in [28]. Liu et al. [52] proposed two algorithms,\
    \ EasyEnsemble and BalanceCas-\ncade, that learn multiple classifiers by combining\
    \ subsets of the majority group with the \nminority group, creating pseudo-balanced\
    \ training sets for each individual classifier. \nSMOTEBoost [53], DataBoost-IM\
    \ [54], and JOUS-Boost [55] all combine sampling with \nensembles. Sun [56] introduced\
    \ three cost-sensitive boosting methods, namely AdaC1, \nAdaC2, and AdaC3. These\
    \ methods iteratively increase the impact of the minority group \nby introducing\
    \ cost items into the AdaBoost algorithm’s weight updates. Sun showed \nthat the\
    \ cost-sensitive boosted ensembles outperformed plain boosting methods in most\
    \ \ncases.\nDeep learning background\nThis section reviews the basic concepts\
    \ of deep learning, including descriptions of the \nneural network architectures\
    \ used throughout the surveyed works and the value of \nrepresentation learning.\
    \ We also touch on several important milestones that have con-\ntributed to the\
    \ success of deep learning. Finally, the rise of big data analytics and its \n\
    challenges are introduced along with a discussion on the role of deep learning\
    \ in solving \nthese challenges.\nIntroduction to deep learning\nDeep learning\
    \ is a sub-field of machine learning that uses artificial neural networks \n(ANNs)\
    \ containing two or more hidden layers to approximate some function f ∗ , where\
    \ \nf ∗ can be used to map input data to new representations or make predictions.\
    \ The ANN, \ninspired by the biological neural network, is a set of interconnected\
    \ neurons, or nodes, \nwhere connections are weighted and each neuron transforms\
    \ its input into a single out-\nput by applying a non-linear activation function\
    \ to the sum of its weighted inputs. In \na feedforward network, input data propagates\
    \ through the network in a forward pass, \neach hidden layer receiving its input\
    \ from the previous layer’s output, producing a final \noutput that is dependent\
    \ on the input data, the choice of activation function, and the \nweight parameters\
    \ [1]. Gradient descent optimization is then used to adjust the net-\nwork’s weight\
    \ parameters in order to minimize the loss function, i.e. the error between \n\
    expected output and actual output.\nThe multilayer perceptron (MLP) is a fully-connected\
    \ feedforward neural network \ncontaining at least one hidden layer. A shallow\
    \ and deep MLP are illustrated in Fig. 1. \nThe deep MLP is the simplest deep\
    \ learning model in terms of implementation, but it \nquickly becomes very resource\
    \ intensive as the number of weighted connections quickly \nincreases.\nPage 10\
    \ of 54\nJohnson and Khoshgoftaar  J Big Data            (2019) 6:27 \nThe convolutional\
    \ neural network (CNN) is a specialized feedforward neural net-\nwork that was\
    \ designed to process multi-dimensional data, e.g. images [58]. It was \ninspired\
    \ by the brain’s visual cortex and its origins date back to the Neocognitron \n\
    presented by Fukushima in 1980 [59]. A CNN architecture is typically comprised\
    \ of \nconvolutional layers, pooling (subsampling) layers, and fully-connected\
    \ layers. Fig-\nure 2 illustrates the LeNet-5 CNN architecture proposed by LeCun\
    \ et al. [58] in 1998 \nfor the purpose of character recognition. Unlike fully-connected\
    \ layers, a single unit \nof a convolutional layer is only connected to a small\
    \ receptive field of its input, where \nthe weights of its connections define\
    \ a filter bank [11]. The convolution operation \nis used to slide the filter\
    \ bank across the input, producing activations at each recep-\ntive field that\
    \ combine to form a feature map [60]. In other words, the same set of \nweights\
    \ are used to detect a specific feature, e.g. a horizontal line, at each receptive\
    \ \nfield of the input, and the output feature map indicates the presence of this\
    \ feature at \neach location. The concept of local connections and shared weights\
    \ take advantage \nof the fact that input signals in close proximity of each other\
    \ are usually highly cor-\nrelated, and that input signals are often invariant\
    \ to location. By combining multiple \nfilter banks in a single convolutional\
    \ layer, the layer can learn to detect multiple fea-\ntures in the input, and\
    \ the resulting feature maps become the input of the next layer. \nPooling layers\
    \ are added after one or more convolutional layers in order to merge \nsemantically\
    \ similar features and reduce dimensionality [11]. After the convolutional \n\
    and pooling layers, the multi-dimensional output is flattened and fed to fully-con-\n\
    nected layers for classification. Similar to the MLP, output activations are fed\
    \ from \nFig. 1 Shallow MLP vs deep MLP [57]\nFig. 2 LeNet-5 CNN architecture\
    \ of 1998 [58]\nPage 11 of 54\nJohnson and Khoshgoftaar  J Big Data          \
    \  (2019) 6:27 \none layer to the next in a forward pass, and the weights are\
    \ updated through gradi-\nent descent.\nThe MLP and CNN are just two of many alternative\
    \ DNN architectures that have \nbeen developed over the years. Recurrent neural\
    \ networks (RNNs), autoencoders, \nand stochastic networks are explained thoroughly\
    \ in [1, 60, 61]. They also present \nadvanced optimization techniques that have\
    \ been shown to improve training time \nand performance, e.g. regularization methods,\
    \ parameter initialization, improved \noptimizers and activation functions, and\
    \ normalization techniques.\nRepresentation learning\nThe success of a conventional\
    \ machine learning algorithm is highly dependent on \nthe representation of the\
    \ input data, making feature engineering a critical step in the \nmachine learning\
    \ workflow. This is very time consuming and for many complex prob-\nlems, e.g.\
    \ image recognition, it can be extremely difficult to determine which features\
    \ \nwill yield the best results. Deep learning offers a solution to this problem\
    \ by building \nupon the concept of representation learning [11].\nRepresentation\
    \ learning is the process of using machine learning to map raw input \ndata features\
    \ into a new representation, i.e. a new feature space, for the purpose of \nimproving\
    \ detection and classification tasks. This mapping from raw input data to new\
    \ \nrepresentations is achieved through non-linear transformations of the input\
    \ data. Com-\nposing multiple non-linear transformations creates hierarchical\
    \ representations of the \ninput data, increasing the level of abstraction through\
    \ each transformation. This auto-\nmatic generation of new features saves valuable\
    \ time by removing the need for experts \nto manually hand engineer features,\
    \ and improves overall performance in many complex \nproblem domains, such as\
    \ image and speech, where it is otherwise difficult to determine \nthe best features.\
    \ As data passes through the hidden layers of a DNN, it is transformed \nby each\
    \ layer into a new representation. Given sufficient data, DNNs are able to learn\
    \ \nhigh-level feature representations of inputs through the composition of multiple\
    \ hidden \nlayers. These learned representations amplify components of the input\
    \ which are impor-\ntant for discrimination, while suppressing those that are\
    \ unimportant [11]. Deep learn-\ning architectures achieve their power through\
    \ this composition of increasingly complex \nabstract representations [60]. This\
    \ approach to problem solving intuitively makes sense, \nas composing simple concepts\
    \ into complex concepts is analogous to many real-world \nproblem domains.\nDeep\
    \ learning milestones\nThe first DNNs date back to the 1960’s, but they were largely\
    \ abandoned in favor of tra-\nditional machine learning methods due to difficulties\
    \ in training and inadequate per-\nformance [62]. In 1986, Rumelhart et al. [63]\
    \ presented backpropagation, a method for \nefficiently updating neural network\
    \ weight parameters by propagating the gradient of \nthe loss function through\
    \ multiple layers. It was believed by most, however, that gradient \ndescent would\
    \ be unable to escape poor local minima during optimization, preventing \nneural\
    \ networks from converging to a global acceptable solution. Today, we believe\
    \ this \nto be untrue, as theoretical results suggest that local minima are generally\
    \ not an issue \nPage 12 of 54\nJohnson and Khoshgoftaar  J Big Data         \
    \   (2019) 6:27 \nand that systems nearly always reach solutions of similar quality\
    \ [11]. Despite some early \nsuccesses in the late 1980s [64] and 1990s [58],\
    \ DNNs were mostly forsaken in practice \nand research due to these challenges.\n\
    In 2006, interests in deep learning were revived as research groups presented\
    \ methods \nfor sensibly initializing DNN weights with an unsupervised layer-wise\
    \ pre-training pro-\ncedure [65, 66]. These pre-trained Deep Belief Networks (DBNs)\
    \ can then be efficiently \nfine-tuned through supervised learning. They proved\
    \ to be very effective in image and \nspeech tasks, and led to record breaking\
    \ results on a speech recognition task in 2009 and \nthe deployment of deep learning\
    \ speech systems in Android mobile devices by 2012 [11].\nIn 2012, Krizhevsky\
    \ et al. [17] submitted a deep CNN to the Large Scale Visual Recog-\nnition Challenge\
    \ (LSVRC) [67] that nearly halved the top-5% error rate, reducing from \nthe previous\
    \ year’s 26% down to just 16%. The work by Krizhevsky et al. included several\
    \ \ncrucial methods which have since become common practice in deep learning work.\
    \ The \nCNN was implemented on multiple graphics processing units (GPUs). The\
    \ drastic speed-\nup provided by parallel GPU computing allows for the training\
    \ of deeper networks with \nlarger data sets, and increased research productivity.\
    \ A new non-saturating activation \nfunction, the rectified linear unit (ReLU),\
    \ alleviated the vanishing gradient problem \nand allowed for faster training.\
    \ Dropout was introduced as a regularization method to \ndecrease over fitting\
    \ in high capacity networks with many layers. Dropout simulates the \nensembling\
    \ of many models by randomly disabling neurons with a probability P ∈ [0, 1] \n\
    during each iteration, forcing the model to learn more robust features. Data augmenta-\n\
    tion, artificially enlarging the data set by applying transformations to data\
    \ samples, was \nalso applied as a regularization technique. This event marked\
    \ a major turning point and \nsparked new interest in deep learning and computer\
    \ vision.\nThis newfound interest in deep learning drove leading technological\
    \ companies to \nincrease research efforts, producing many advances in deep learning\
    \ and pushing the \nstate-of-the-art in deep learning to new levels. Deep learning\
    \ frameworks which abstract \ntensor computation [12–15] and GPU compatibility\
    \ libraries [16] have been made avail-\nable to the community through open source\
    \ software [68] and cloud services [69, 70]. \nCombined with an increasing amount\
    \ of available data and public attention, deep learn-\ning is growing at a faster\
    \ pace than ever before.\nDeep learning with big data\nMany organizations are\
    \ being faced with the challenges of big data, as they are explor-\ning large\
    \ volumes of data to extract value and guide decisions [71]. Big data refers to\
    \ \ndata which exceeds the capabilities of standard data storage and data processing\
    \ systems \n[72]. This forces practitioners to adopt new techniques for storing,\
    \ manipulating, and \nanalyzing data. The rise of big data can be attributed to\
    \ improvements in hardware and \nsoftware, increased internet and social media\
    \ activity, and a growing abundance of sen-\nsor-enabled interconnected devices,\
    \ i.e. the internet of things (IoT).\nMore specifically, big data can be characterized\
    \ by the four Vs: volume, variety, veloc-\nity, and veracity [72, 73]. The large\
    \ volumes of data being collected require highly scala-\nble hardware and efficient\
    \ analysis tools, often demanding distributed implementations. \nIn addition to\
    \ adding architecture and network overhead, distributed systems have been \nPage\
    \ 13 of 54\nJohnson and Khoshgoftaar  J Big Data            (2019) 6:27 \nshown\
    \ to exacerbate the negative effects of class imbalanced data [74]. Advanced tech-\n\
    niques for quickly processing incoming data streams and maintaining appropriate\
    \ turna-\nround times are required to keep up with the rate at which data is being\
    \ generated, i.e. \ndata velocity. The variety of big data corresponds to the\
    \ mostly unstructured, diverse, \nand inconsistent representations that arise\
    \ as data is consumed from multiple sources \nover extended periods of time. This\
    \ variety further increases the computational com-\nplexity of data preprocessing\
    \ and machine learning. Finally, the veracity of big data, i.e. \nits accuracy\
    \ and trustworthiness, must be regularly validated to ensure results do not \n\
    become corrupted by invalid input. Some additional machine learning challenges\
    \ that \nare magnified by big data include high-dimensionality, distributed infrastructures,\
    \ real-\ntime requirements, feature engineering, and data cleansing [75].\nNajafabadi\
    \ et al. [75] discuss the use of deep learning in solving big data challenges.\
    \ \nThe ability of DNNs to extract meaningful features from large sets of unlabeled\
    \ data is \nparticularly important, as this is commonly encountered in big data\
    \ analytics. The auto-\nmatic extraction of features from mostly unstructured\
    \ and diverse data, e.g. image, text \nand audio data, is therefore extremely\
    \ useful. With abstract features extracted from big \ndata through deep learning\
    \ methods, simple linear models can often be used to com-\nplete machine learning\
    \ tasks more efficiently. Advanced semantic-based information \nstorage and retrieval\
    \ systems, e.g. semantic indexing and hashing [76, 77], are also made \npossible\
    \ with these high-level features. In addition, deep learning has been used to\
    \ tag \nincoming data streams, helping to group and organize fast-moving data\
    \ [75]. In general, \nhigh-capacity DNNs are well suited for learning from the\
    \ large volumes of data encoun-\ntered in big data analytics.\nAs the presence\
    \ of big data within organizations continues to increase, new methods \nwill be\
    \ required to keep up with the influx of data. Despite being relatively immature,\
    \ \ndeep learning methods are proving effective in solving many big data challenges.\
    \ We \nbelieve that advances in deep learning, especially in learning from unsupervised\
    \ data, \nwill play a critical role in the future of big data analytics.\nDeep\
    \ learning methods for class imbalanced data\nAnand et al. [78] explored the effects\
    \ of class imbalance on the backpropagation algo-\nrithm in shallow neural networks\
    \ in the 1990’s. The authors show that in class imbal-\nanced scenarios, the length\
    \ of the minority class’s gradient component is much smaller \nthan the length\
    \ of the majority class’s gradient component. In other words, the major-\nity\
    \ class is essentially dominating the net gradient that is responsible for updating\
    \ the \nmodel’s weights. This reduces the error of the majority group very quickly\
    \ during early \niterations, but often increases the error of the minority group\
    \ and causes the network to \nget stuck in a slow convergence mode.\nThis section\
    \ analyzes a number of deep learning methods for addressing class imbal-\nance,\
    \ organized by data-level, algorithm-level, and hybrid methods. For each surveyed\
    \ \nwork, we summarize the implementation details and the characteristics of the\
    \ data sets \nused to evaluate the method. We then discuss various strengths and\
    \ weaknesses, con-\nsidering topics such as class imbalance levels, interpretation\
    \ of results, relative perfor-\nmance, difficulty of use, and generalization to\
    \ other architectures and problem domains. \nKnown limitations are highlighted\
    \ and suggestions for future work are offered. For \nPage 14 of 54\nJohnson and\
    \ Khoshgoftaar  J Big Data            (2019) 6:27 \nconsistency, class imbalance\
    \ is presented as the maximum between-class ratio, ρ (Eq. 1), \nfor all surveyed\
    \ works.\nData‑level methods\nThis section includes four papers that explore data-level\
    \ methods for addressing class \nimbalance with DNNs. Hensman and Masko [79] first\
    \ show that balancing the training \ndata with ROS can improve the classification\
    \ of imbalanced image data. Then RUS and \naugmentation methods are used by Lee\
    \ et al. [20] to decrease class imbalance for the \npurpose of pre-training a\
    \ deep CNN. Pouyanfar et al. [21] introduce a new dynamic sam-\npling method that\
    \ adjusts sampling rates according to class-wise performance. Finally, \nBuda\
    \ et al. [23] compare RUS, ROS, and two-phase learning across multiple imbalanced\
    \ \nimage data sets.\nBalancing training data with ROS\nHensman and Masko [79]\
    \ explored the effects of class imbalance and ROS using deep \nCNNs. The CIFAR-10\
    \ [80] benchmark data set, comprised of 10 classes with 6000 \nimages per class,\
    \ was used to generate 10 imbalanced data sets for testing. These 10 gen-\nerated\
    \ data sets contained varying class sizes, ranging between 6% and 15% of the total\
    \ \ndata set, producing a max imbalance ratio ρ = 2.3 . In addition to varying\
    \ the class size, \nthe different distributions also varied the number of minority\
    \ classes, where a minority \nclass is any class smaller than the largest class.\
    \ For example, a major 50–50 split (Dist. 3) \nreduced five of the classes to\
    \ 6% of the data set size and increased five of the classes to \n14%. As another\
    \ example, a major singular over-representation (Dist. 5) increased the \nsize\
    \ of the airplane class to 14.5%, reducing the other nine classes slightly to\
    \ 9.5%.\nA variant of the AlexNet [17] CNN, which has proven to perform well on\
    \ CIFAR-\n10, was used for all experiments by Hensman and Masko. The baseline\
    \ performance \nwas defined by training the CNN on all distributions with no data\
    \ sampling. The ROS \nmethod being evaluated consisted of randomly duplicating\
    \ samples from the minority \nclasses until all classes in the training set had\
    \ an equal number of samples.\nHensman and Masko presented their results as the\
    \ percentage of correct answers per \nclass, and included the mean score for all\
    \ classes, denoted by Total. To ensure results \nwere valid, a total of three\
    \ runs were completed for each experiment and then aver-\naged. Table 3 shows\
    \ the results of the CNN without any data sampling. These results \ndemonstrate\
    \ the impact of class imbalance when training a CNN model. Most of the \nimbalanced\
    \ distributions saw a loss in performance. Dist. 6 and Dist. 7, which contained\
    \ \nvery slight imbalance and no over-representation, performed just as well as\
    \ the origi-\nnal balanced distribution. Some of the imbalanced distributions\
    \ that contained over-\nrepresented classes, e.g. Dist. 5 and Dist. 9, yielded\
    \ useless models that were completely \nbiased towards the majority group.\nTable 4\
    \ includes the results of training the CNN with balanced data that was generated\
    \ \nthrough ROS. It shows that over-sampling performs significantly better than\
    \ the base-\nline results from Table 3. Dist. 1 is excluded from Table 4 because\
    \ it is already balanced, \ni.e. ROS is not applicable. In this experiment, ROS\
    \ improved the classification results \nfor all distributions. Dist. 5 and Dist.\
    \ 9 saw the largest performance gains, increasing \nPage 15 of 54\nJohnson and\
    \ Khoshgoftaar  J Big Data            (2019) 6:27 \nfrom baseline Total F1-scores\
    \ of 0.10 up to 0.73 and 0.72, respectively. The ROS classi-\nfication results\
    \ for distributions Dist. 2–Dist. 11 are comparable to the results achieved \n\
    by the baseline CNN on Dist. 1, suggesting that ROS has completely restored model\
    \ \nperformance.\nThe experiments by Hensman and Masko show that applying ROS\
    \ to the level of \nclass balance can be effective in addressing slight class\
    \ imbalance in image data. It is \nalso made clear by some of the results in Table 3\
    \ that small levels of imbalance are able \nto prevent a CNN from converging to\
    \ an acceptable solution. We believe that the low \nimbalance levels tested (\
    \ ρ = 2.3 ) is the biggest limitation of this experiment, as imbal-\nance levels\
    \ are typically much higher in practice. Besides exploring additional data sets\
    \ \nand higher levels of imbalance, one area worth pursuing further is the total\
    \ number of \nepochs completed during training on the imbalanced data. In these\
    \ experiments, only \n10 epochs over the training data were completed because\
    \ the authors were more inter-\nested in comparing performance than they were\
    \ in achieving high performance. Run-\nning additional epochs would help to rule\
    \ out whether or not the poor performance was \ndue to the slow convergence phenomenon\
    \ described by Anand et al.\nTable 3 Imbalanced CIFAR-10 classification [79]\n\
    Total\nAirplane\nAutomobile\nBird\nCat\nDeer\nDog\nFrog\nHorse\nShip\nTruck\n\
    Dist. 1\n0.73\n0.78\n0.84\n0.62\n0.57\n0.70\n0.62\n0.80\n0.76\n0.84\n0.80\nDist.\
    \ 2\n0.69\n0.74\n0.75\n0.58\n0.33\n0.58\n0.65\n0.84\n0.78\n0.87\n0.79\nDist. 3\n\
    0.66\n0.71\n0.75\n0.59\n0.30\n0.52\n0.61\n0.79\n0.77\n0.85\n0.73\nDist. 4\n0.27\n\
    0.78\n0.24\n0.12\n0.08\n0.19\n0.24\n0.33\n0.27\n0.21\n0.27\nDist. 5\n0.10\n1.00\n\
    0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\nDist. 6\n0.73\n0.74\n0.86\n\
    0.65\n0.53\n0.71\n0.63\n0.81\n0.76\n0.83\n0.79\nDist. 7\n0.73\n0.75\n0.86\n0.66\n\
    0.52\n0.71\n0.63\n0.80\n0.78\n0.84\n0.79\nDist. 8\n0.66\n0.63\n0.75\n0.55\n0.35\n\
    0.51\n0.58\n0.82\n0.74\n0.84\n0.80\nDist. 9\n0.10\n0.00\n0.00\n0.00\n0.00\n0.00\n\
    0.00\n0.00\n0.00\n0.00\n1.00\nDist. 10\n0.69\n0.75\n0.77\n0.56\n0.42\n0.66\n0.63\n\
    0.76\n0.70\n0.81\n0.79\nDist. 11\n0.69\n0.74\n0.82\n0.58\n0.44\n0.59\n0.64\n0.80\n\
    0.69\n0.83\n0.81\nTable 4 Imbalanced CIFAR-10 classification with ROS [79]\nTotal\n\
    Airplane\nAutomobile\nBird\nCat\nDeer\nDog\nFrog\nHorse\nShip\nTruck\nDist. 2\n\
    0.72\n0.77\n0.80\n0.57\n0.51\n0.68\n0.64\n0.81\n0.78\n0.84\n0.82\nDist. 3\n0.73\n\
    0.73\n0.80\n0.59\n0.53\n0.63\n0.65\n0.82\n0.81\n0.87\n0.83\nDist. 4\n0.73\n0.76\n\
    0.82\n0.60\n0.54\n0.68\n0.63\n0.81\n0.78\n0.85\n0.83\nDist. 5\n0.73\n0.80\n0.84\n\
    0.61\n0.55\n0.68\n0.63\n0.82\n0.79\n0.82\n0.81\nDist. 6\n0.73\n0.75\n0.86\n0.65\n\
    0.51\n0.65\n0.66\n0.81\n0.78\n0.85\n0.80\nDist. 7\n0.73\n0.73\n0.85\n0.62\n0.51\n\
    0.71\n0.66\n0.81\n0.79\n0.86\n0.80\nDist. 8\n0.73\n0.78\n0.84\n0.62\n0.56\n0.66\n\
    0.64\n0.81\n0.77\n0.83\n0.80\nDist. 9\n0.72\n0.73\n0.84\n0.58\n0.55\n0.68\n0.59\n\
    0.79\n0.78\n0.83\n0.82\nDist. 10\n0.73\n0.78\n0.85\n0.63\n0.50\n0.67\n0.63\n0.82\n\
    0.75\n0.87\n0.80\nDist. 11\n0.72\n0.82\n0.87\n0.58\n0.64\n0.64\n0.49\n0.78\n0.69\n\
    0.84\n0.80\nPage 16 of 54\nJohnson and Khoshgoftaar  J Big Data            (2019)\
    \ 6:27 \nAt the time of writing, May 2015, Hensman and Masko observed no existing\
    \ research \nthat examined the impact of class imbalance on deep learning with\
    \ popular benchmark \ndata sets. Our literature review also finds this to be true,\
    \ confirming that addressing \nclass imbalance with deep learning is still relatively\
    \ immature and understudied.\nTwo‑phase learning\nLee et  al. [20] combined RUS\
    \ with transfer learning to classify highly-imbalanced \ndata sets of plankton\
    \ images, WHOI-Plankton [81]. The data set contains 3.4 million \nimages spread\
    \ over 103 classes, with 90% of the images comprised of just five classes \nand\
    \ the 5th largest class making up just 1.3% of the entire data set. Imbalance\
    \ ratios of \nρ > 650 are exhibited in the data set, with many classes making\
    \ up less than 0.1% of \nthe data set. The proposed method is the two-phase learning\
    \ procedure, where a deep \nCNN is first pre-trained with thresholded data, and\
    \ then fine-tuned using all data. \nThe thresholded data sets for pre-training\
    \ are constructed by randomly under-sam-\npling large classes until they reach\
    \ a threshold of N examples. The authors selected \na threshold of N = 5000 through\
    \ preliminary experiments, then down-sampled all \nlarge classes to N samples.\
    \ The proposed model (G) was compared to six alternative \nmethods (A–F), a combination\
    \ of transfer learning and augmentation techniques, \nusing unweighted average\
    \ F1-scores to compare results.\n(A) Full: CNN trained with original imbalanced\
    \ data set.\n(B) Noise: CNN trained with augmented data, where minority classes\
    \ are duplicated \nthrough noise injection until all classes contain at least\
    \ 1000 samples.\n(C) Aug: CNN trained with augmented data, where minority classes\
    \ are duplicated \nthrough rotation, scaling, translation, and flipping of images\
    \ until all classes contain \nat least 1000 samples.\n(D) Thresh: CNN trained\
    \ with thresholded data, generated through random under-\nsampling until all classes\
    \ have at most 5000 samples.\n(E) Noise + full: CNN pre-trained with the noise-augmented\
    \ data from (B), then fine-\ntuned using the full data set.\n(F) Aug + full: CNN\
    \ pre-trained with the transform-augmented data from (C), then \nfine-tuned using\
    \ the full data set.\n(G) Thresh + full: CNN pre-trained using the thresholded\
    \ data set from (D), then fine-\ntuned using the full imbalanced data set.\nResults\
    \ from Lee et  al.’s experiments are presented in Table  5, where the L5 and \n\
    Rest columns are the unweighted average F1-scores for the largest five classes\
    \ and \nthe remaining minority classes, respectively. Comparing methods (B–D)\
    \ shows that \nunder-sampling (D) outperforms both noise injection (B) and augmentation\
    \ (C) over-\nsampling methods on the given data set for all classes. Methods (B–D)\
    \ saw moder-\nate improvements on the Rest group when compared to the baseline\
    \ (A), but the L5 \ngroup suffered sufficient loss in performance. Re-training\
    \ the model with the full data \nset in (E–G) allowed the models to re-capture\
    \ the distribution of the L5 group. The \nproposed model (G) achieved the highest\
    \ F1-score (0.7791) on the L5 group, and \nPage 17 of 54\nJohnson and Khoshgoftaar\
    \  J Big Data            (2019) 6:27 \ngreatly improved the F1-score of the Rest\
    \ group from 0.1548 to 0.3262 with respect \nto the baseline.\nThe two-phase learning\
    \ procedure presented by Lee et al. has proven effective in increas-\ning the\
    \ minority class performance while still preserving the majority class performance.\
    \ \nUnlike plain RUS, which completely removes potentially useful information\
    \ from the train-\ning set, the two-phase learning method only removes samples\
    \ from the majority group \nduring the pre-training phase. This allows the minority\
    \ group to contribute more to the \ngradient during pre-training, and still allows\
    \ the model to see all of the available data during \nthe fine-tuning phase. The\
    \ authors did not include details on the pre-training phase, such as \nthe number\
    \ of pre-training epochs or the criteria used to determine when pre-training was\
    \ \ncomplete. These details should be considered in future works, as pre-training\
    \ that results \nin high bias or high variance will certainly impact the final\
    \ model’s class-wise performance. \nFuture work can also consider a hybrid approach,\
    \ where the model is pre-trained with data \nthat is generated through a combination\
    \ of under-sampling majority classes and augment-\ning minority classes.\nThe\
    \ previous year, Havaei et al. [82] used a similar two-phase learning procedure\
    \ to man-\nage class imbalance when performing brain tumor image segmentation.\
    \ The brain tumor \ndata contains minority classes that make up less than 1% of\
    \ the total data set. Havaei et al. \nstated that the two-phase learning procedure\
    \ was critical in dealing with the imbalanced dis-\ntribution in their image data.\
    \ The details of this paper are not included in this survey because \nthe two-phase\
    \ learning is just one small component of their domain-specific experiments.\n\
    Dynamic sampling\nPouyanfar et al. [21] used a dynamic sampling technique to perform\
    \ classification of imbal-\nanced image data with a deep CNN. The basic idea is\
    \ to over-sample the low performing \nclasses and under-sample the high performing\
    \ classes, showing the model less of what it \nhas already learned and more of\
    \ what it does not understand yet. This is somewhat analo-\ngous to how humans\
    \ learn, by moving on from easy tasks once learned and focusing atten-\ntion on\
    \ the more difficult tasks. The author’s self-collected data set contains over\
    \ 10,000 \nimages captured from publicly available network cameras, including\
    \ a total of 19 semantic \nconcepts, e.g. intersection, forest, farm, sky, water,\
    \ playground, and park. From the original \ndata set, 70% is used for training\
    \ models, 20% is used for validation, and 10% is set aside \nfor testing. The\
    \ authors report imbalance ratios in the data set as high as ρ = 500 . Average\
    \ \nF1-scores and weighted average F1-scores are used to compare the proposed\
    \ model to a \nbaseline CNN (A) and four alternative methods for handling class\
    \ imbalance (B–E).\nTable 5 Two-phase learning with WHOI-Plankton (Avg. F1-score)\
    \ [20]\nClassifier\nAll classes\nL5\nRest\n(A) Full\n0.1773\n0.7773\n0.1548\n\
    (B) Noise\n0.2465\n0.5409\n0.3599\n(C) Aug\n0.2726\n0.5776\n0.3700\n(D) Thresh\n\
    0.3086\n0.6510\n0.4044\n(E) Noise + full\n0.3038\n0.7531\n0.2971\n(F) Aug + full\n\
    0.3212\n0.7668\n0.3156\n(G) Thresh + full\n0.3339\n0.7791\n0.3262\nPage 18 of\
    \ 54\nJohnson and Khoshgoftaar  J Big Data            (2019) 6:27 \nThe system\
    \ presented by Pouyanfar et al. includes three core components: real time data\
    \ \naugmentation, transfer learning, and a novel dynamic sampling method. Real\
    \ time data \naugmentation improves generalization by applying various transformations\
    \ to select images \nin each training batch. Transfer learning is achieved by\
    \ fine-tuning an Inception-V3 net-\nwork [83] that was pre-trained using ImageNet\
    \ [84] data. The dynamic sampling method is \nthe main contribution relative to\
    \ class imbalance.\nF1i is a vector containing all individual class F1-scores\
    \ after iteration i, and f 1i,j denotes \nthe F1-score for class j on iteration\
    \ i, where F1-scores are calculated for each class in a \none-versus-all manner.\
    \ During the next iteration, classes with lower F1-scores are sam-\npled at a\
    \ higher rate, forcing the learner to focus more on examples previously misclassi-\n\
    fied. Eq. 11 is used to obtain the next iteration’s sample size for a given class\
    \ cj , where N ∗ \nis the average class size. To prevent over-fitting of the minority\
    \ group, a second model \nis trained through transfer learning without sampling.\
    \ At time of inference, the output \nlabel is computed as a function of both models.\n\
    The proposed model is compared with the following alternative methods:\n(A) Basic\
    \ CNN: VGGNet [85] CNN trained on entire data set.\n(B) Deep CNN features + SVM:\
    \ Support vector machine (SVM) classifier trained with \ndeep features generated\
    \ by CNN.\n(C) Transfer learning without augmentation: Fine-tuned Inception-V3\
    \ with no data \naugmentation.\n(D) Transfer learning with augmentation: Fine-tuned\
    \ Inception-V3 with data augmen-\ntation.\n(E) Transfer learning with balanced\
    \ augmentation: Fine-tuned Inception-V3 with data \naugmentation that enforces\
    \ class balanced training batches with over-sampling and \nunder-sampling.\n(F)\
    \ Proposed model: Dynamic sampling, data augmentation, and transfer learning on\
    \ \nInception-V3 network.\nAverage class-wise F1-scores are compared across all\
    \ 19 concepts, showing that the \nbasic CNN performs the worst in all cases. The\
    \ basic CNN was unable to classify a single \ninstance correctly for several concepts\
    \ with very high imbalance ratios, including Play-\nground and Airport with imbalance\
    \ ratios of ρ = 200 and ρ = 500 , respectively. Transfer \nlearning methods (C–E)\
    \ performed significantly better than the baseline CNN, increas-\ning the weighted\
    \ average F1-score from 0.630 to as high as 0.779. Results in Table 6 show \n\
    that the proposed method (F) outperforms all other models tested on the given\
    \ data \nset. Compared to transfer learning with basic augmentation (D), the dynamic\
    \ sampling \nmethod (F) improved the weighted average F1-score from 0.779 to 0.794.\n\
    The dynamic sampling method’s ability to self-adjust sampling rates is its most\
    \ \nattractive feature. This allows the method to adapt to different problems\
    \ contain-\ning varying levels of complexity and class imbalance, with little\
    \ to no hyperparam-\neter tuning. By removing samples that have already been captured\
    \ by the network \n(11)\nSample size (F1i, cj) =\n1 − f 1i,j\n\x1F\nck∈C(1 − f\
    \ 1i,k) × N ∗\nPage 19 of 54\nJohnson and Khoshgoftaar  J Big Data           \
    \ (2019) 6:27 \nparameters, gradient updates will be driven by the more difficult\
    \ positive class sam-\nples. The dynamic sampling method outperforms a hybrid\
    \ of over-sampling and \nunder-sampling (E) according to F1-scores, but the details\
    \ of the sampling method \nare not included in the description. We also do not\
    \ know how dynamic sampling per-\nforms against plain RUS and ROS, as these methods\
    \ were not tested. This should be \nexamined closely in future works to determine\
    \ if dynamic sampling can be used as a \ngeneral replacement for RUS and ROS.\
    \ One area of concern is the method’s depend-\nency on a validation set to calculate\
    \ the class-wise performance metrics that are \nrequired to determine sampling\
    \ rates. This will certainly be problematic in cases of \nclass rarity, where\
    \ very few positive samples exist, as setting aside data for valida-\ntion may\
    \ deprive the model of valuable training data. Methods for maximizing the \ntotal\
    \ available training data should be included in future research. In addition,\
    \ future \nresearch should extend the dynamic sampling method to non-CNN architectures\
    \ and \nother domains.\nROS, RUS, and two‑phase learning\nBuda et  al. [23] compare\
    \ ROS, RUS, and two-phase learning using three multi-\nclass image data sets and\
    \ deep CNNs. MNIST [86], CIFAR-10, and ImageNet data \nsets are used to create\
    \ distributions with varying levels of imbalance. Both MNIST \nand CIFAR-10 training\
    \ sets contain 50,000 images spread evenly across 10 classes, \ni.e. 5000 images\
    \ per class. Imbalanced distributions were created from MNIST and \nCIFAR-10 in\
    \ the range of ρ ∈ [10, 5000] and ρ ∈ [2, 50] , respectively. The ImageNet \n\
    training data, containing 100 classes with a maximum of 1000 samples per class,\
    \ was \nused to create imbalanced distributions in the range of ρ ∈ [10, 100].\n\
    A different CNN architecture was empirically selected for each data set based\
    \ off \nrecent state-of-the-art results. For the MNIST and CIFAR-10 experiments,\
    \ a version \nof the LeNet-5 [58] and the All-CNN [87] architectures were used\
    \ for classification, \nrespectively. Baseline results were established for each\
    \ CNN architecture by perform-\ning classification on the data sets without any\
    \ form of class imbalance technique, i.e. \nno data sampling or thresholding.\
    \ Next, seven different methods for addressing class \nimbalance were integrated\
    \ with the CNN architectures and tested. ROC AUC was \nextended to the multi-class\
    \ problem by averaging the one-versus-all AUC for each \nclass, and used to compare\
    \ the methods. A portion of their results are presented in \nFig. 3.\nTable 6\
    \ Dynamic sampling with network camera image data [21]\nClassifier\nAcc.\nAvg.\
    \ F1\nWAvg. F1\n(A) Basic CNN\n0.649\n0.254\n0.630\n(B) Deep CNN features + SVM\n\
    0.746\n0.528\n0.747\n(C) TL + no aug.\n0.765\n0.432\n0.755\n(D) TL + basic aug.\n\
    0.792\n0.502\n0.779\n(E) TL + balanced aug.\n0.759\n0.553\n0.766\n(F) Proposed\
    \ model\n0.802\n0.599\n0.794\nPage 20 of 54\nJohnson and Khoshgoftaar  J Big Data\
    \            (2019) 6:27 \nFig. 3 ROS, RUS, and two-phase learning with MNIST\
    \ (a–c) and CIFAR-10 (d–f) [23]\nPage 21 of 54\nJohnson and Khoshgoftaar  J Big\
    \ Data            (2019) 6:27 \n(A) ROS: All minority classes were over-sampled\
    \ until class balance was achieved, \nwhere any class smaller than the largest\
    \ class size is considered a minority class. In \nalmost all experiments, over-sampling\
    \ displayed the best performance, and never \nshowed a decrease in performance\
    \ when compared to the baseline.\n(B) RUS: All majority classes were under-sampled\
    \ until class balance was achieved, \nwhere any class larger than the smallest\
    \ class size is considered a majority class. \nRUS performed poorly when compared\
    \ to the baseline models, and never displayed \na notable advantage to ROS. RUS\
    \ was comparable to ROS only when the total num-\nber of minority classes was\
    \ very high, i.e. 80–90%.\n(C) Two-phase training with ROS: The model is first\
    \ pre-trained on a balanced data set \nwhich is generated through ROS, and then\
    \ fine-tuned using the complete data set. \nIn general, this method performed\
    \ worse than strict ROS (A).\n(D) Two-phase training with RUS: Similar to (C),\
    \ except the balanced data set used for \npre-training is generated through RUS.\
    \ Results show that this approach was less \neffective than RUS (B).\n(E) Thresholding\
    \ with prior class probabilities: The network’s decision threshold is \nadjusted\
    \ during the test phase based on the prior probability of each class, effec-\n\
    tively shifting the output class probabilities. Thresholding showed improvements\
    \ to \noverall accuracy, especially when combined with ROS.\n(F) ROS and thresholding:\
    \ The thresholding method (E) is applied after training the \nmodel with a balanced\
    \ data set, where the balanced data set is generated through \nROS. Thresholding\
    \ combined with ROS performed better than the baseline thresh-\nolding (E) in\
    \ most cases.\n(G) RUS and thresholding: The thresholding method (E) is applied\
    \ after training the \nmodel with a balanced data set, where the balanced data\
    \ set is produced through \nRUS. Thresholding with RUS performed worse than (E)\
    \ and (F) in all cases.\nThe work by Buda et al., which varies levels of class\
    \ imbalance and problem complexity, \nis comprehensive, having trained almost\
    \ 23,000 deep CNNs across three popular data \nsets. The impact of class imbalance\
    \ was validated on a set of baseline CNNs, showing \nthat classification performance\
    \ is severely compromised as imbalance increases and that \nthe impact of class\
    \ imbalance seems to increase as problem complexity increases, e.g. \nCIFAR-10\
    \ versus MNIST. The authors conclude that ROS is the best overall method \nfor\
    \ addressing class imbalance, that RUS generally performs poorly, and that two-phase\
    \ \nlearning with ROS or RUS is not as effective as their plain ROS and RUS counterparts.\n\
    While it does provide a reasonable high-level view of each method’s performance,\
    \ the \nmulti-class ROC AUC score provides no insight into the underlying class-wise\
    \ perfor-\nmance trade-offs. It is not clear if there is high variance in the\
    \ class-wise scores, or if \none extremely low class-wise score is causing a large\
    \ drop in the average AUC score. \nWe believe that additional performance metrics,\
    \ including class-wise scores, will better \nexplain the effectiveness of each\
    \ method in addressing class imbalance and help guide \npractitioners in model\
    \ selection.\nBuda et al. conclude that ROS should be performed until all class\
    \ imbalance is elimi-\nnated. Despite their experimental results, we do not readily\
    \ agree with this blanket state-\nment, and argue that this is likely problem-dependent\
    \ and requires further exploration. \nPage 22 of 54\nJohnson and Khoshgoftaar\
    \  J Big Data            (2019) 6:27 \nThe MNIST data set, both relatively low\
    \ in complexity and small in size, was used to \ndemonstrate that over-sampling\
    \ until all classes are balanced performs best. We do not \nknow how well over-sampling\
    \ to this level will perform on more complex data sets, or \nin problems containing\
    \ big data or class rarity. Furthermore, over-sampling to this level \nof class\
    \ balance in a big data problem can be extremely resource intensive, drastically\
    \ \nincreasing training time by introducing large volumes of redundant data.\n\
    Summary of data‑level methods\nTwo of the surveyed works [23, 79] have shown that\
    \ eliminating class imbalance in the \ntraining data with ROS significantly improves\
    \ classification results. Lee et al. have shown \nthat pre-training DNNs with\
    \ semi-balanced data generated through RUS or augmen-\ntation-based over-sampling\
    \ improves minority group performance. In contrast to Lee \net al., Buda et al.\
    \ found that plain ROS and RUS generally perform better than two-phase \nlearning.\
    \ Unlike Lee et al., however, Buda et al. pre-trained their networks with data\
    \ that \nwas sampled until class balance was achieved. Since Lee et al. and Buda\
    \ et al. used dif-\nferent imbalance levels for pre-training, and reported results\
    \ with different performance \nmetrics, it is difficult to understand the efficacy\
    \ of two-phase learning. The dynamic \nsampling method outperformed baseline CNNs,\
    \ but we do not know how it compares to \nROS, RUS, or two-phase learning. Despite\
    \ this limitation, the dynamic sampling meth-\nod’s ability to automatically adjust\
    \ sampling rates throughout the training process is very \nappealing. Methods\
    \ that can automatically adjust to varying levels of complexity and \nimbalance\
    \ levels are favorable, as they reduce the number of tunable hyperparameters.\n\
    The experimental results suggest the use of ROS to eliminate class imbalance during\
    \ \nthe training of DNNs. This may be true for relatively small data sets, but\
    \ we believe this \nwill not hold true for problems containing big data or extreme\
    \ class imbalance. Apply-\ning ROS until classes are balanced in very-large data\
    \ sets, e.g. WHOI-Plankton data, will \nresult in the duplication of large volumes\
    \ of data and will drastically increase training \ntimes. RUS, on the other hand,\
    \ reduces training time and may therefore be more practi-\ncal in big data problems.\
    \ We believe that RUS methods that remove redundant samples, \nreduce class noise,\
    \ and strengthen class borders will prove helpful in these big data prob-\nlems.\
    \ Future work should explore these scenarios further.\nAll of the data-level methods\
    \ presented were tested on class imbalanced image data with \ndeep CNNs. In addition,\
    \ differences in performance metrics and problem complexity make \nit difficult\
    \ to compare methods directly. Future works should test these data-level methods\
    \ \non a variety of data types, imbalance levels, and DNN architectures. Multiple\
    \ complemen-\ntary performance metrics should be used to compare results, as this\
    \ will better illustrate \nmethod trade-offs and guide future practitioners.\n\
    Algorithm‑level methods\nThis section includes surveyed works that modify deep\
    \ learning algorithms for the pur-\npose of addressing class imbalance. These\
    \ methods can be further divided into new loss \nfunctions, cost-sensitive learning,\
    \ and threshold moving. Wang et al. [18] and Lin et al. [88] \nintroduced new\
    \ loss functions that allow the minority samples to contribute more to the \n\
    loss. Wang et al. [89], Khan et al. [19], and Zhang et al. [90] experimented with\
    \ cost-sensi-\ntive DNNs. The methods proposed by Khan et al. and  Zhang et al.\
    \ have the advantage of \nPage 23 of 54\nJohnson and Khoshgoftaar  J Big Data\
    \            (2019) 6:27 \nlearning cost matrices during training. The work by\
    \ Buda et al. in the \"ROS, RUS, and two-\nphase learning\" section has also been\
    \ included in this section, as they experimented with \nthreshold adjusting. \
    \ Zhang et al. [91] combine transfer learning, CNN feature extraction, \nand a\
    \ cluster-based nearest neighbor rule to improve the classification of imbalanced\
    \ image \ndata. Finally, Ding et al. [92] experiment with very-deep CNNs to determine\
    \ if increasing \nneural network depth improves convergence rates with imbalanced\
    \ data.\nMean false error (MFE) loss\nWang et al. [18] found some success in modifying\
    \ the loss function as they experimented \nwith classifying imbalanced data with\
    \ deep MLPs. A total of eight imbalanced binary data \nsets, including three image\
    \ data sets and five text data sets, were generated from the CIFAR-\n100 [93]\
    \ and 20 Newsgroup [94] collections. The data sets are all relatively small, with\
    \ most \ntraining sets containing fewer than 2000 samples and the largest training\
    \ set containing just \n3500 samples. For each data set generated, imbalance ratios\
    \ ranging from ρ = 5 to ρ = 20 \nwere tested.\nThe authors first show that the\
    \ mean squared error (MSE) loss function poorly captures \nthe errors from the\
    \ minority group in cases of high class imbalance, due to many nega-\ntive samples\
    \ dominating the loss function. They then propose two new loss functions that\
    \ \nare more sensitive to the errors from the minority class, mean false error\
    \ (MFE) and mean \nsquared false error (MSFE). The proposed loss functions were\
    \ derived by first splitting the \nMSE loss into two components, mean false positive\
    \ error (FPE) and mean false negative \nerror (FNE). The FPE (Eq. 12) and FNE\
    \ (Eq. 13) values are then combined to define the total \nsystem loss, MFE (Eq. 14),\
    \ as the sum of the mean error from each class.\nWang et al. introduce the MSFE\
    \ loss (Eq. 15) as an improvement to the MFE loss, assert-\ning that it better\
    \ captures errors from the positive class. The MSFE can be expanded into \nthe\
    \ form 1\n2((FPE + FNE)2 + (FPE − FNE)2) , demonstrating how the optimization\
    \ process \nminimizes the difference between FPE and FNE. The authors believe\
    \ this improved version \nwill better balance the error rates between the positive\
    \ and negative classes.\nA deep MLP trained with the standard MSE loss is used\
    \ as the baseline model. This same \nMLP architecture is then used to evaluate\
    \ both the MFE and MSFE loss. Image classifi-\ncation results (Table 7) and text\
    \ classification results (Table 8) show that the proposed \nmodels outperform\
    \ the baseline in nearly all cases, with respect to F-measure and AUC \nscores.\
    \ \n(12)\nFPE = 1\nN\nN\n\x1F\ni=1\n\x1F\nn\n1\n2(d(i)\nn − y(i)\nn )2\n(13)\n\
    FNE = 1\nP\nP\n\x1F\ni=1\n\x1F\nn\n1\n2(d(i)\nn − y(i)\nn )2\n(14)\nMFE = FPE\
    \ + FNE\n(15)\nMSFE = FPE2 + FNE2\nPage 24 of 54\nJohnson and Khoshgoftaar  J\
    \ Big Data            (2019) 6:27 \nResults show that the MFE and MSFE loss functions\
    \ outperform MSE loss in almost \nall cases. Improvements over the baseline MSE\
    \ loss are most apparent when class \nimbalance is greatest, i.e. imbalance levels\
    \ of 5%. The MFE and MSFE performance \ngains are also more pronounced on the\
    \ image data than on the text data. For example, \nthe MSFE loss improved the\
    \ classification of Household image data, increasing the \nF1-score from 0.1143\
    \ to 0.2353 when the class imbalance level was 5%.\nBeing relatively easy to implement\
    \ and integrate into existing models is one of the big-\ngest advantages of using\
    \ custom loss functions for addressing class imbalance. Unlike \ndata-level methods\
    \ that increase the size of the training set, the loss function is less likely\
    \ \nto increase training times. The loss functions should generalize to other\
    \ domains with \nease, but as seen in comparing the image and text performance\
    \ results, performance \ngains will vary from problem to problem. Additional experiments\
    \ should be performed \nTable 7 CIFAR-100 classification with MFE and MSFE [18]\n\
    Italic scores indicate MFE/MSFE loss outperforming MSE loss\nData set\nImbalance\
    \ \nlevel (%)\nF‑measure\nAUC \nMSE\nMFE\nMSFE\nMSE\nMFE\nMSFE\nHousehold\n20\n\
    0.3913\n0.4138\n0.4271\n0.7142\n0.7397\n0.7354\n10\n0.2778\n0.2797\n0.3151\n0.7125\n\
    0.7179\n0.7193\n5\n0.1143\n0.1905\n0.2353\n0.6714\n0.6950\n0.6970\nTree 1\n20\n\
    0.5500\n0.5500\n0.5366\n0.8100\n0.8140\n0.8185\n10\n0.4211\n0.4211\n0.4211\n0.7960\n\
    0.7990\n0.7990\n5\n0.1667\n0.2353\n0.2353\n0.7920\n0.8000\n0.8000\nTree 2\n20\n\
    0.4348\n0.4255\n0.4255\n0.8480\n0.8450\n0.8440\n10\n0.1818\n0.2609\n0.2500\n0.8050\n\
    0.8050\n0.8060\n5\n0.0000\n0.1071\n0.1481\n0.5480\n0.6520\n0.7000\nTable 8 20\
    \ Newsgroup classification with MFE and MSFE[18]\nItalic scores indicate MFE/MSFE\
    \ loss outperforming MSE loss\nData set\nImbalance level \n(%)\nF‑measure\nAUC\
    \ \nMSE\nMFE\nMSFE\nMSE\nMFE\nMSFE\nDoc. 1\n20\n0.2341\n0.2574\n0.2549\n0.5948\n\
    0.5995\n0.5987\n10\n0.1781\n0.1854\n0.1961\n0.5349\n0.5462\n0.5469\n5\n0.1356\n\
    0.1456\n0.1456\n0.5336\n0.5436\n0.5436\nDoc. 2\n20\n0.3408\n0.3393\n0.3393\n0.6462\n\
    0.6464\n0.6464\n10\n0.2094\n0.2000\n0.2000\n0.6310\n0.6319\n0.6322\n5\n0.1256\n\
    0.1171\n0.1262\n0.6273\n0.6377\n0.6431\nDoc. 3\n20\n0.2929\n0.2957\n0.2957\n0.5862\n\
    0.5870\n0.5870\n10\n0.1596\n0.1627\n0.1698\n0.5577\n0.5756\n0.5865\n5\n0.0941\n\
    0.1118\n0.1084\n0.5314\n0.5399\n0.5346\nDoc. 4\n20\n0.3723\n0.3843\n0.3668\n0.6922\n\
    0.7031\n0.7054\n10\n0.1159\n0.2537\n0.2574\n0.5623\n0.6802\n0.6816\n5\n0.1287\n\
    0.1720\n0.1720\n0.6041\n0.6090\n0.6090\nDoc. 5\n20\n0.3103\n0.3222\n0.3222\n0.6011\n\
    0.5925\n0.5925\n10\n0.1829\n0.1808\n0.1839\n0.5777\n0.5836\n0.5837\n5\n0.0946\n\
    0.1053\n0.1053\n0.5682\n0.5730\n0.5730\nPage 25 of 54\nJohnson and Khoshgoftaar\
    \  J Big Data            (2019) 6:27 \nto validate MFE and MSFE effectiveness,\
    \ as it is currently unclear how many rounds \nwere conducted per experiment and\
    \ the F1-score and AUC gains over the baseline are \nonly minor improvements.\
    \ On the image data experiments, for example, the average \nAUC gain over the\
    \ baseline is just 0.025, with a median AUC gain over the baseline of \nonly 0.008.\n\
    Focal loss\nLin et al. [88] proposed a model that effectively addresses the extreme\
    \ class imbalance \ncommonly encountered in object detection problems, where positive\
    \ foreground sam-\nples are heavily outnumbered by negative background samples.\
    \ Two-stage and one-\nstage detectors are well-known methods for solving such\
    \ problems, where the two-stage \ndetectors typically achieve higher accuracy\
    \ at the cost of increased computation time. \nLin et al. set out to determine\
    \ whether a fast single-stage detector was capable of achiev-\ning state-of-the-art\
    \ results on par with current two-stage detectors. Through analysis of \nvarious\
    \ two-stage detectors (e.g. R-CNN [95] and its successors) and one-stage detectors\
    \ \n(e.g. SSD [96] and YOLO [97]), class imbalance was identified as the primary\
    \ obstacle \npreventing one-stage detectors from achieving state-of-the-art performance.\
    \ The over-\nwhelming number of easily classified negative background candidates\
    \ create imbalance \nratios commonly in the range of ρ = 1000 , causing the negative\
    \ class to account for the \nmajority of the system’s loss.\nTo combat these extreme\
    \ imbalances, Lin et al. presented the focal loss (FL) (Eq. 16), \nwhich re-shapes\
    \ the cross entropy (CE) loss in order to reduce the impact that easily \nclassified\
    \ samples have on the loss. This is achieved by multiplying the CE loss by a mod-\n\
    ulating factor, αt(1 − pt)γ . Hyper parameter γ ≥ 0 adjusts the rate at which\
    \ easy exam-\nples are down weighted, and αt ≥ 0 is a class-wise weight that is\
    \ used to increase the \nimportance of the minority class. Easily classified examples,\
    \ where pt → 1 , cause the \nmodulating factor to approach 0 and reduce the sample’s\
    \ impact on the loss.\n(16)\nFL(pt) = −αt(1 − pt)γ log(pt)\nTable 9 RetinaNet\
    \ (focal loss) on COCO [88]\nItalic scores indicate top AP performances\nBackbone\n\
    AP\nAP50\nAP75\nAPS\nAPM\nAPL\nTwo-stage methods\n Faster R-CNN+++\nResNet-101-C4\n\
    34.9\n55.7\n37.4\n15.6\n38.7\n50.9\n Faster R-CNN w FPN\nResNet-101-FPN\n36.2\n\
    59.1\n39.0\n18.2\n39.0\n48.2\n Faster R-CNN by G-RMI\nInception-ResNet-v2\n34.7\n\
    55.5\n36.7\n13.5\n38.1\n52.0\n Faster R-CNN w TDM\nInception-ResNet-v2-TDM\n36.8\n\
    57.7\n39.2\n16.2\n39.8\n52.1\nOne-stage methods\n YOLOv2\nDarkNet-19\n21.6\n44.0\n\
    19.2\n5.0\n22.4\n35.5\n SSD513\nResNet-101-SSD\n31.2\n50.4\n33.3\n10.2\n34.5\n\
    49.8\n DSSD513\nResNet-101-DSSD\n33.2\n53.3\n35.2\n13.0\n35.4\n51.1\n RetinaNet\n\
    ResNet-101-FPN\n39.1\n59.1\n42.3\n21.8\n42.7\n50.2\n RetinaNet\nResNeXt-101-FPN\n\
    40.8\n61.1\n44.1\n24.1\n44.2\n51.2\nPage 26 of 54\nJohnson and Khoshgoftaar  J\
    \ Big Data            (2019) 6:27 \nThe proposed one-stage focal loss model, RetinaNet,\
    \ is evaluated against several state-\nof-the-art one-stage and two-stage detectors.\
    \ The RetinaNet model is composed of a \nbackbone model and two subnetworks, where\
    \ the backbone model is responsible for \nproducing feature maps from the input\
    \ image, and the two subnetworks then perform \nobject classification and bounding\
    \ box regression. The authors selected the feature pyra-\nmid network (FPN) [88],\
    \ built on top of the ResNet architecture [98], as the backbone \nmodel and pre-trained\
    \ it on ImageNet data. They found that the FPN CNN, which pro-\nduces features\
    \ at different scales, outperforms the plain ResNet in object detection. Two \n\
    additional CNNs with separate parameters, the subnetworks, are then used to perform\
    \ \nclassification and bounding box regression. The proposed focal loss function\
    \ is applied \nto the classification subnet, where the total loss is computed\
    \ as the sum of the focal loss \nover all ≈ 100, 000 candidates. The COCO [99]\
    \ data set was used to evaluate the pro-\nposed model against its competitors.\n\
    The first attempt to train RetinaNet using standard CE loss quickly fails and\
    \ diverges \ndue to the extreme imbalance. By initializing the last layer of the\
    \ model such that the \nprior probability of detecting an object is π = 0.01 ,\
    \ results improve significantly to an \naverage precision (AP) of 30.2. Additional\
    \ experiments are used to determine appropri-\nate hyper parameters for the focal\
    \ loss, selecting γ = 2.0 and α = 0.25 for all remaining \nexperiments.\nExperiments\
    \ by Lin et al. show that the RetinaNet, with the proposed focal loss, is \nable\
    \ to outperform existing one-stage and two-stage object detectors. It outscores\
    \ the \nrunner-up one-stage detector (DSSD513 [100]) and the best two-stage detector\
    \ (Faster \nR-CNN with TDM [101]) by 7.6-point and 4.0-point AP gains, respectively.\
    \ When com-\npared to several online hard example mining (OHEM) [102] methods,\
    \ RetinaNet out-\nscores the best method with an increase in AP from 32.8 to 36.0.\
    \ Table  9 compares \nresults between RetinaNet and seven state-of-the-art one-stage\
    \ and two-stage detectors.\nLin et al. provide additional information to illustrate\
    \ the effectiveness of the focal loss \nmethod. In one experiment, they use a\
    \ trained model to compute the focal loss over \n≈ 107 negative images and ≈ 105\
    \ positive images. By plotting the cumulative distribution \nfunction for positive\
    \ and negative samples, they show that as γ increases, more and more \nweight\
    \ is placed onto a small subset of negative samples, i.e. the hard negatives.\
    \ In fact, \nwith γ = 2 , they show that most of the loss is derived from a very\
    \ small fraction of sam-\nples, and that the focal loss is indeed reducing the\
    \ impact of easily-classified negative \nsamples on the loss. Run time statistics\
    \ were included in the report to demonstrate that \nthey were able to construct\
    \ a fast one-stage detector capable of outperforming accurate \ntwo-stage detectors.\n\
    The new FL method lends itself to not just class imbalance problems, but also\
    \ hard \nsample problems. It addresses the primary minority class gradient issue\
    \ defined by \nAnand et al. by preventing the majority group from dominating the\
    \ loss and allowing \nthe minority group to contribute more to the weight updates.\
    \ Similar to the MFE and \nMSFE loss functions, advantages include being relatively\
    \ easy to integrate into existing \nmodels and having minimal impact on training\
    \ time. We believe that the FL method’s \nability to down-weight easily-classified\
    \ samples will allow it to generalize well to other \ndomains. The authors compared\
    \ FL directly to the CE loss, but we do not know how FL \ncompares to other existing\
    \ class imbalance methods. Future works should compare this \nPage 27 of 54\n\
    Johnson and Khoshgoftaar  J Big Data            (2019) 6:27 \nloss function to\
    \ alternative class imbalance methods across a variety of data sets and \nclass\
    \ imbalance levels.\nNemoto et al. [103] later used the focal loss in another\
    \ image classification task, the \nautomated detection of rare building changes,\
    \ e.g. new construction. The airborne \nbuilding images are annotated with the\
    \ labels: no change, new construction, rebuild-\ning, demolished, repaint roofs,\
    \ and laying solar panel. The training data contains 203,358 \nimages in total,\
    \ where 200,000 comprise the negative class, i.e. no change. The repaint \nroofs\
    \ and laying solar panel classes contain just 326 and 222 images, respectively,\
    \ yield-\ning class imbalance ratios as high as ρ = 900.\nThe experiments by Nemoto\
    \ et al. utilize the VGG-16 [85] CNN architecture, where \nthe baseline CNN uses\
    \ the standard CE loss. Images were augmented by rotation and \ninversion, creating\
    \ 20,000 samples per class. Class-wise accuracy on the validation set \nwas used\
    \ to compare the focal loss to the CE loss. The first experiment uses the CE loss\
    \ \nfunction and shows that the accuracy on the repaint roof and laying solar\
    \ panel classes \nbegins to deteriorate after 25,000 iterations, suggesting over-fitting.\
    \ In the second exper-\niment, focal loss was evaluated using the same VGG-16\
    \ architecture and the same image \naugmentation procedure, generating 20,000\
    \ images per class. Unlike the first experi-\nment, however, only three classes\
    \ were selected for training and validation: no change, \nrepaint roof, and laying\
    \ solar panel images. The value of the focal loss’s down-weighting \nparameter\
    \ γ was varied in the range γ ∈ [0, 5] to better understand its impact.\nFigure \
    \ 4 shows the training validation loss and accuracy of the focal loss method.\
    \ \nNemoto et al. conclude that focal loss improves problems related to class\
    \ imbalance and \nover-fitting by adjusting the per-class learning speed. By comparing\
    \ the loss plots, it is \nclear that as γ increases, the total loss decreases\
    \ faster and the model is slower to over-\nfit. It is not clear, however, if FL\
    \ with γ > 0 is producing better classification results. \nFirst, the results\
    \ from the first experiment cannot be compared to the results of the sec-\nond\
    \ experiment, because the total number of classes has been reduced from six to\
    \ three, \nsignificantly reducing the complexity of the classification problem.\
    \ Second, the results \nfrom the no change and laying solar panel classes in Fig. 4\
    \ show that the highest accu-\nracy is achieved when γ = 0 , where the laying\
    \ solar panel class is the smallest class. The \nfocal loss, with γ = 0 , reduces\
    \ to the standard cross entropy loss, suggesting that the CE \nFig. 4 Focal loss\
    \ and building change detection [103]\nPage 28 of 54\nJohnson and Khoshgoftaar\
    \  J Big Data            (2019) 6:27 \nloss outperforms the focal loss on two\
    \ of the three classes in this experiment. To better \nunderstand the effectiveness\
    \ of FL, future work should include a baseline with consistent \ntraining data,\
    \ several alternative methods for addressing class imbalance, and additional \n\
    performance metrics.\nCost‑sensitive deep neural network (CSDNN)\nWang et al.\
    \ [89] employed a cost-sensitive deep neural network (CSDNN) method to \ndetect\
    \ hospital readmissions, a class imbalanced problem where a small percentage of\
    \ \npatients are readmitted to a hospital shortly after their original visit.\
    \ Two data sets were \nprovided by the Barnes-Jewish Hospital, containing patient\
    \ records spanning from 2007 \nto 2011. The first data set, general hospital wards\
    \ (GHW), contains vital signs, clini-\ncal processes, demographics, real-time\
    \ bedside monitoring, and other electronic data \nsources. Of the 2565 records\
    \ in GHW, 406 patients were readmitted within 30 days and \n538 patients were\
    \ readmitted within 60 days, producing imbalance ratios of ρ = 5.3 and \nρ = 3.8\
    \ , respectively. The second data set, the operating room pilot data (ORP), contains\
    \ \nvital signs, pre-operation data, laboratory tests, medical history, and procedure\
    \ details. \nThere are 700 records in the ORP data set, with 157 readmissions\
    \ within 1 year and 124 \nreadmissions within 30 days. The imbalance ratio of\
    \ the ORP data is unclear; the authors \nmerely state that the ORP data is less\
    \ imbalanced than the GHW data ( ρ < 3.8 ). A vari-\nety of performance metrics,\
    \ including ROC, AUC, accuracy, recall, precision, positive \npredictive value\
    \ (PPV), and negative predictive value (NPV) are used for evaluation. The \nPPV\
    \ and NPV metrics are equivalent to positive and negative class precision scores.\
    \ The \nproposed CSDNN method was found to outperform existing hospital readmission\
    \ pre-\ndiction systems, and has been deployed at the Barnes-Jewish Hospital.\n\
    Instead of representing categorical values with traditional one-hot encoding,\
    \ Wang \net al. use a categorical feature embedding approach to create more meaningful\
    \ represen-\ntations. In addition, they employed a CNN for automatic feature extraction\
    \ from time \nseries data, i.e. the patient vital signs data. The extracted features\
    \ and categorical embed-\ndings are concatenated, forming a final input feature\
    \ vector that is fed to a DNN for clas-\nsification. The DNN was composed of two\
    \ hidden layers, with 128 and 64 neurons per \nlayer. The CE loss function was\
    \ modified to incorporate a pre-defined cost matrix, forc-\ning the network to\
    \ minimize misclassification cost. For the GHW data set, false negative \nerrors\
    \ were given a cost 2× the cost of false positive errors. Similarly for the ORP\
    \ data \nset, the false negative cost was set to 1.5× the cost of false positive\
    \ errors.\n Wang et al.’s CSDNN method is compared to five baseline classifiers,\
    \ including three \ndecision tree methods, a SVM, and an ANN. Only one of the\
    \ baseline methods addresses \nclass imbalance, using under-sampling with a Random\
    \ Forest (RF) classifier. The pro-\nposed method outperformed all of the baseline\
    \ classifiers across all performance metrics \nexcept for NPV. We were able to\
    \ observe the class-wise performance trade-off because \nmultiple complementary\
    \ performance metrics were reported. On the GHW data set, \nthe CSDNN’s AUC of\
    \ 0.70 outscored the runner up’s (ANN classifier) AUC of 0.62. \nUnfortunately,\
    \ however, it is not possible to determine if the cost-sensitive loss function\
    \ \nis the cause of the improved performance, as there are several other factors\
    \ that may \nhave contributed to improvements, e.g. categorical feature embedding\
    \ and time-series \nPage 29 of 54\nJohnson and Khoshgoftaar  J Big Data      \
    \      (2019) 6:27 \nfeature extraction. A baseline that includes the CNN feature\
    \ extractor and the categori-\ncal embeddings is required to isolate the efficacy\
    \ of the cost-sensitive loss function.\nIncorporating the cost matrix into the\
    \ CE loss is a minor implementation detail that \nshould generalize well to other\
    \ domains and architectures with minimal impact on train-\ning times. The process\
    \ of identifying an ideal cost matrix is likely the biggest limitation. \nIn traditional\
    \ machine learning problems with relatively small data sets, models can be \n\
    validated across a range of costs and the best cost matrix can be selected for\
    \ the final \nmodel. When working with DNNs and large data sets, however, this\
    \ process of searching \nfor the best cost parameters can be very time consuming\
    \ and even impractical. Including \nresults from a range of cost matrices in future\
    \ work will help to demonstrate the class-\nwise performance trade-offs that occur\
    \ as costs vary.\nLearning cost matrices with cost‑sensitive CNN (CoSen)\nKhan\
    \ et al. [19] introduced an effective cost-sensitive deep learning procedure which\
    \ \njointly learns network weight parameters and class misclassification costs\
    \ during train-\ning. The proposed method, CoSen CNN, is evaluated against six\
    \ multi-class data sets \nwith varying levels of imbalance: MNIST, CIFAR-100,\
    \ Caltech-101 [104], MIT-67 [105], \nDIL [106], and MLC [107]. Class imbalance\
    \ ratios of ρ = 10 are tested for the MNIST, \nCIFAR-100, Caltech-101, and MIT-67\
    \ data sets. The DIL and MLC data sets have imbal-\nance ratios of ρ = 13 and\
    \ ρ = 76 , respectively. The VGG-16, pre-trained on ImageNet \ndata, is used as\
    \ a feature extractor and the baseline CNN throughout the experiments.\nThe cost\
    \ matrix that is learned by the CoSen CNN is used to modify the output of the\
    \ \nVGG-16 CNN’s last layer, giving higher importance to samples with higher cost.\
    \ The \ngroup presents three modified loss functions, incorporating the learned\
    \ cost parame-\nters into MSE loss, SVM hinge loss, and CE loss. The training\
    \ process learns network \nweight parameters and misclassification cost parameters\
    \ by keeping one fixed at a time, \nand minimizing cost with respect to the other\
    \ during training. The cost matrix update \nis dependent on the current classification\
    \ errors, the overall classification error, and the \nclass-to-class separability\
    \ (C2C). The C2C separability measures relationships between \nwithin-class sample\
    \ distances and the size of class-separating boundaries.\nTable 10 Cost-sensitive\
    \ CoSen CNN results (accuracy) [19]\nItalic scores indicate the top performance\
    \ for each data set\nDataset\nImbalance \nprotocol\nSMOTE \n(%)\nRUS (%) SMOTE\
    \ \nRSB (%)\nCoSen \nSVM \n(%)\nCoSen \nRF (%)\nSOSR \nCNN \n(%)\nBaseline \n\
    CNN (%)\nCoSen \nCNN \n(%)\nMNIST\n10% of odd \nclasses\n94.5\n92.1\n96.0\n96.8\n\
    96.3\n97.8\n97.6\n98.6\nCIFAR-100\n10% of odd \nclasses\n32.2\n28.8\n37.5\n39.9\n\
    39.0\n55.8\n55.0\n60.1\nCaltech-101\n10% of odd \nclasses\n67.7\n61.4\n68.2\n\
    70.1\n68.7\n77.4\n77.4\n83.2\nMIT-67\n10% of odd \nclasses\n33.9\n28.4\n34.0\n\
    35.5\n35.2\n49.8\n50.4\n56.9\nDIL\nStandard \nsplit\n50.3\n46.7\n52.6\n55.3\n\
    54.7\n68.9\n69.5\n72.6\nMLC\nStandard \nsplit\n38.9\n31.4\n43.0\n47.7\n46.5\n\
    65.7\n66.1\n68.6\nPage 30 of 54\nJohnson and Khoshgoftaar  J Big Data        \
    \    (2019) 6:27 \nThe CoSen CNN is evaluated against the baseline CNN, multiple\
    \ sampling meth-\nods, and multiple cost-sensitive methods. A two-layered neural\
    \ network was used for \nthe sampling classification methods, and a SVM and RF\
    \ were used for the cost-sensitive \nmethods. The SVM and RF baseline classifiers\
    \ used the features that were extracted by \nthe pre-trained VGG-16 CNN as input.\
    \ The SOSR CNN is a cost-sensitive deep learning \nmethod that incorporates a\
    \ fixed cost matrix into the loss function [108].\nOverall accuracy was used to\
    \ show that the proposed CNN outperforms all seven \nalternative techniques across\
    \ all data sets. Table 10 shows that the CoSen CNN per-\nformed exceptionally\
    \ well, outperforming the runner-up classifier by more than 5% on \nCIFAR-100,\
    \ Caltech-101, and MIT-67. The second best classifier listed in the experi-\n\
    mental results is between the SOSR CNN and the baseline CNN. In all cases SMOTE\
    \ \noutperformed RUS, and hybrid sampling method SMOTE-RSB [109] outperformed\
    \ \nSMOTE. Unfortunately, with accuracy being the only performance metric reported\
    \ \nbetween all seven class imbalance methods, and accuracy being unreliable in\
    \ cases of \nclass imbalance, these results may be misleading.\nF1 and G-Mean\
    \ scores were reported to show that the proposed CoSen CNN out-\nperforms the\
    \ baseline CNN on all data sets, e.g. increasing the F1-score from 0.389 to \n\
    0.416 on the Caltech-101 data set. Khan et al. also included sample network training\
    \ \ntimes, showing that the added cost parameter training increases each training\
    \ epoch \nby several seconds but has little to no impact on the inference step.\
    \ In another experi-\nment, the authors defined three fixed cost matrices using\
    \ class representation, data \nseparability, and classification errors to derive\
    \ the costs, and showed that the dynamic \ncost matrix method outperforms all\
    \ three cases.\nIt is interesting that the baseline CNN, with no class imbalance\
    \ modifications, is \na close runner-up to the CoSen CNN, outperforming the sampling\
    \ methods, SVM, \nand RF classifiers in all cases. This does not imply that a\
    \ deep CNN with no class \nimbalance modifications is better equipped to address\
    \ class imbalance than tradi-\ntional sampling methods. Rather, this demonstrates\
    \ the power of re-using strong fea-\nture extractors that have been trained on\
    \ large volumes of data, e.g. over 1.3 million \nimages in this experiment.\n\
    As mentioned previously, one of the difficulties of cost-sensitive learning is\
    \ choos-\ning an appropriate cost matrix, often requiring a domain expert or a\
    \ grid search pro-\ncedure. The CoSen method proposed by Khan et al. removes this\
    \ requirement, and \noffers more of an end-to-end deep learning framework capable\
    \ of learning from class \nimbalanced data. The authors report results on a number\
    \ of experiments across a \nvariety of data sets, and the joint learning of network\
    \ parameters and cost parameters \nappears to be an excellent candidate for learning\
    \ from class imbalanced data. Future \nexperiments should explore this cost-sensitive\
    \ method’s ability to learn from prob-\nlems containing alternative data types,\
    \ big data, and class rarity.\nCost‑sensitive DBN with differential evolution\
    \ (CSDBN‑DE)\nZhang et al. [90] set out to automatically learn costs for the purpose\
    \ of cost-sensitive \ndeep learning. More specifically, they use a differential\
    \ evolutionary algorithm [110] \nto improve the cost matrix each training iteration,\
    \ and incorporate these learned costs \ninto a DBN. The proposed cost-sensitive\
    \ deep belief network with differential evolution \nPage 31 of 54\nJohnson and\
    \ Khoshgoftaar  J Big Data            (2019) 6:27 \n(CSDBN-DE) is evaluated against\
    \ 42 data sets from the Knowledge Extraction based on \nEvolutionary Learning\
    \ (KEEL) [111] repository. The training data sets are structured \ndata sets,\
    \ ranging in size from 171 samples to 3339 samples and containing between 6 \n\
    and 13 attributes each. Imbalance ratios range from ρ = 9.28 up to ρ = 128.21.\n\
    The DBN pre-training phase follows the original layer-wise training method first\
    \ pro-\nposed by Hinton et al. [65]. The cost matrix is then incorporated into\
    \ the output layer’s \nsoftmax probabilities during the fine-tuning phase. Cost\
    \ matrices are first randomly ini-\ntialized, then training set evaluation scores\
    \ are used to select a new cost matrix for the \nnext population. Mutation and\
    \ cross-over operations are applied to evolve and generate \nthe next population\
    \ of cost matrices. Once training is complete, the best cost matrix is \nselected\
    \ and applied to the output layer of the DBN, forming the final version of the\
    \ \ncost-sensitive DBN to be used for inference.\nAccuracy and error rate are\
    \ used to compare the proposed method to an extreme \nlearning machine (ELM) [112].\
    \ The ELM network is a type of single-hidden layer feed-\nforward network that\
    \ does not use backpropagation and is known to train thousands of \ntimes faster\
    \ than neural networks. Experiments are repeated 20 times and results are \naveraged.\
    \ The proposed CSDBN-DE model outperformed the ELM network on 28 out of \n42 data\
    \ sets, i.e. 66% of the experiments.\nSimilar to the CoSen CNN [19], the biggest\
    \ advantage of the CSDBN-DE is its ability \nto learn an effective cost matrix\
    \ throughout training, as this is often a difficult and time-\nconsuming process.\
    \ Unfortunately, it is not very clear how well the CSDBN-DE handles \nclass imbalanced\
    \ data, because it is compared to a single baseline built on a completely \ndifferent\
    \ architecture. Also, the accuracy performance metric provides no real insight\
    \ \ninto the network’s true performance when class imbalance is present. The concept\
    \ of \nincorporating an evolutionary algorithm to iteratively update a cost matrix\
    \ shows prom-\nise, but more robust experiments are required to validate its ability\
    \ to classify imbal-\nanced data.\nOutput thresholding\nIn addition to the data\
    \ sampling methods discussed in the \"ROS, RUS, and two-phase \nlearning\" section,\
    \ Buda et al. [23] experimented with adjusting CNN output thresholds \nto improve\
    \ overall performance. They used the MNIST and CIFAR-10 data sets with \nvarying\
    \ levels of class imbalance ratios in the range of ρ ∈ [1, 5000] and ρ ∈ [1, 50]\
    \ , \nrespectively. Accuracy scores were used to compare thresholding with the\
    \ baseline \nCNN, ROS, and RUS methods as they were described in the \"ROS, RUS,\
    \ and two-phase \nlearning\" section.\nThe authors applied thresholding by dividing\
    \ the network outputs for each class by \nits estimated prior probability, effectively\
    \ reducing the likelihood of misclassifying \nexamples from the minority group.\
    \ They also considered hybrid methods by combin-\ning threshold moving with RUS\
    \ and ROS. The thresholding method outperformed the \nbaseline CNN for all levels\
    \ of class imbalance on the MNIST and CIFAR-10 data sets. \nThresholding outperformed\
    \ ROS and RUS for all levels of imbalance on the MNIST \ndata, but on the CIFAR-10\
    \ data there were several instances were ROS outperformed \nPage 32 of 54\nJohnson and\
    \ Khoshgoftaar  J Big Data            (2019) 6:27 \nthresholding. Thresholding\
    \ combined with ROS performed especially well, outperform-\ning all other methods\
    \ in nearly all cases.\nAs discussed in the \"ROS, RUS, and two-phase learning\"\
    \ section, Buda et al. explored \na variety of deep learning methods for addressing\
    \ a wide range of class imbalance levels. \nThey have shown that overall accuracy\
    \ can be improved with threshold moving, and that \nit can be implemented relatively\
    \ easily with prior class probabilities. Unfortunately, the \naccuracy score does\
    \ not explain individual class-wise performances and trade-offs. Since \nthresholding\
    \ is only applied during inference, it does not affect training times. This also\
    \ \nmeans that thresholding does not impact weight tuning and therefore does not\
    \ improve \na model’s ability to discriminate between classes. Regardless, it\
    \ is still an appropriate \nmethod for reducing majority class bias that can be\
    \ quickly implemented on top of an \nalready trained network to improve classification\
    \ results.\nCategory centers\nZhang et al. [91] experimented with deep representation\
    \ learning of class imbalanced \nimage data from the CIFAR-10 and CIFAR-100 data\
    \ sets. They present a method for \naddressing class imbalance, category centers\
    \ (CC), that combines transfer learning, deep \nCNN feature extraction, and a\
    \ nearest neighbor discriminator. Three class imbalanced \ndistributions are created\
    \ from each original data set through random under-sampling, \ni.e. Dist. A, Dist.\
    \ B, and Dist. C. In Dist. A and Dist. B, half of the classes are reduced in \n\
    size, creating imbalance levels of ρ = 10 and ρ = 20 , respectively. In Dist.\
    \ C, class reduc-\ntion levels increase linearly across all classes with a max\
    \ imbalance of ρ = 20 . For exam-\nple, Dist. C for the CIFAR-100 data set contains\
    \ 25 images in each of the first 10 classes, \n75 images in each of the next 10\
    \ classes, then 125 images in each of the next 10 classes, \netc. The proposed\
    \ model is compared to both a baseline CNN and an over-sampling \nmethod. The\
    \ mean precision performance metric is used to compare results.\nZhang et al.\
    \ observe that similar images of the same class tend to cluster well in CNN \n\
    deep feature space. They discuss the decision boundary that is created by the\
    \ final layer \nof the CNN, the classification layer responsible for separating\
    \ these deep feature clus-\nters, stating that there is a greater chance for large\
    \ errors in boundary placement when \nclass imbalance is present. To avoid this\
    \ boundary error in scenarios of class imbalance, \nthey propose using high-level\
    \ features extracted by the CNN to calculate each class’s \ncentroid in deep feature\
    \ space. These category centers in deep feature space can then \nbe used to classify\
    \ new images, by assigning new images to their nearest deep feature \nTable 11\
    \ Category centers with CIFAR-10 data (AP) [91]\nClassifier\nDist A ( ρ = 10)\n\
    Dist B ( ρ = 20)\nDist C \n( ρ ∈ [1, 20])\n(A) Baseline CNN\n0.779\n0.747\n0.857\n\
    (B) CC last conv. layer\n0.824\n0.775\n0.859\n(C) CC last FC layer\n0.826\n0.772\n\
    0.865\n(D) Baseline CNN + over-sampling\n0.787\n0.770\n0.850\n(E) CC last conv.\
    \ layer + over-sampling\n0.831\n0.792\n0.861\n(F) CC last FC layer + over-sampling\n\
    0.830\n0.796\n0.862\nPage 33 of 54\nJohnson and Khoshgoftaar  J Big Data     \
    \       (2019) 6:27 \ncategory center. The VGG-16 network, pre-trained on ImageNet\
    \ data, is used through-\nout the experiments as the baseline CNN. The proposed\
    \ method fine-tunes the CNN on \nthe imbalanced distribution, maps all images\
    \ to their corresponding deep feature repre-\nsentations, then calculates the\
    \ centroid for each class. At test time the trained CNN is \nused to extract features\
    \ from new images, and each new image is assigned to the class of \nits nearest\
    \ category center in feature space, defined by the Euclidean distance between\
    \ \nthe features.  Zhang et al. claim that the category center is significantly\
    \ more stable than \nthe boundary generated by a CNN’s classification layer, but\
    \ no evidence was provided to \nsupport this.\nA portion of  Zhang et al.’s results\
    \ are displayed in Table 11. The authors tried using \ntwo different CNN layers\
    \ for feature extraction, the last convolutional layer (B) and \nthe last fully\
    \ connected layer (C), to determine if one set of features performed bet-\nter.\
    \ Finally, over-sampling was applied to the baseline and the category centers\
    \ meth-\nods to determine the impact of data sampling on CC (D–F). These results\
    \ show that the \nCC methods (B, C) outperform the baseline CNN (A) on mean precision\
    \ for all three \nimbalance scenarios. Results also show that the addition of\
    \ over-sampling (D–F) led \nto improved results on the CIFAR-10 distributions,\
    \ with the exception of Dist. C. For \nexample, the CC method with over-sampling\
    \ (E) increased mean precision on Dist. A \nfrom a baseline (A) of 0.779 to 0.830.\
    \ CIFAR-100 results were similar, in the sense that \nthe proposed method (B,\
    \ C) outperformed the baseline (A) for all three distributions. \nUnlike the CIFAR-10\
    \ data, interestingly, over-sampling did not improve the results of \nthe proposed\
    \ method when classifying the CIFAR-100 distributions, but it did improve \nthe\
    \ baseline CNN.\nWe believe that the biggest limitation to the CC method is that\
    \ it is highly dependent \non the DNN’s ability to generate discriminative features\
    \ that cluster well. If a large vol-\nume of class balanced, labelled training\
    \ data is not available to pre-train the DNN, deep \nfeature boundaries may not\
    \ be strong enough to apply the CC method. The specifics of \nthe over-sampling\
    \ method used in methods (D–F) are unknown, so we do not know if \nover-sampling\
    \ was applied to a level of class balance or some other ratio. In addition, we\
    \ \ndo not know if these results are the average of several rounds of experiments,\
    \ or are just \nresults from a single instance. With no balanced distribution\
    \ results, an unclear over-\nsampling method, and only one performance metric,\
    \ it is difficult to understand how \nwell the proposed CC method does in learning\
    \ from class imbalance.\nVery‑deep neural networks\nDing et al. [92] experimented with\
    \ very-deep CNN architectures, e.g. 50 layers, to deter-\nmine if deeper networks\
    \ perform better on imbalanced data. The authors observe in \nliterature that\
    \ the error surfaces of deeper networks have better qualities for training \n\
    convergence than smaller sized networks [113, 114]. They claim that larger networks\
    \ \ncontain more local minimum with good performance, making acceptable solutions\
    \ eas-\nier to locate with gradient descent. The networks are tested on the problem\
    \ of Facial \nAction Units (FAUs) recognition, i.e. the detection of basic facial\
    \ actions as defined by \nthe Facial Action Coding System [115].\nThe EmotioNet\
    \ Challenge Track 1 data set [116] is used to compare methods. From the \noriginal\
    \ data set, with over one million images, 450,000 images were randomly selected\
    \ \nPage 34 of 54\nJohnson and Khoshgoftaar  J Big Data            (2019) 6:27\
    \ \nfor training and 40,000 images were randomly selected for validation. The\
    \ images in this \ndata set contain 11 possible FAUs. Since an image can be positive\
    \ for more than one \nFAU, the authors treated the classification problem as a\
    \ set of 11 binary problems. Sev-\neral FAUs are present in less than 1% of the\
    \ data set, e.g. nose wrinkler, chin raiser, and \nupper lid raiser. The lip stretcher\
    \ FAU is only present in 0.01% of the data, creating a max \nimbalance ratio to\
    \ ρ = 10, 000 . Six deep CNN architectures are compared, all of which \ninclude\
    \ 3 × 3 convolution filter layers and are trained for 100 epochs:\n(A) Handcraft:\
    \ 6-layer CNN\n(B) Plain34: 34-layer CNN\n(C) Res10: 10-layer ResNet CNN\n(D)\
    \ Res18: 18-layer ResNet CNN\n(E) Res34: 34-layer ResNet CNN\n(F) Res50: 50-layer\
    \ ResNet CNN.\nF1-scores from the first experiment are presented in Table 12.\
    \ The shallow network (A) \nwas unable to capture classes containing high imbalance,\
    \ e.g. AU2–AU5, during the 100 \ntraining epochs. The non-residual 34-layer CNN\
    \ (B) saw a large boost in performance \ncompared to the shallow network (A),\
    \ with average F1-score increasing from 0.29 to \n0.48. It can also be observed\
    \ that the 10-layer ResNet (C) achieved an equal F1-score of \n0.48. The FAU with\
    \ the largest imbalance, i.e. lip stretcher (AU20), received an F1-score \nof\
    \ 0.0 in all experiments. There is no noticeable difference in F1-scores between\
    \ the net-\nworks with 10 layers or more (B–F). The 34-layer ResNet (E) won first\
    \ place at the first \ntrack EmotioNet Challenge in 2017 [116].\nIn a second experiment,\
    \ Ding et  al. compare the convergence rate of a very-deep \n18-layer CNN to a\
    \ shallower 6-layer CNN across 100 epochs. The experiment shows \nthat the very-deep\
    \ 18-layer CNN converges faster than the shallower network, as the \nerror decreases\
    \ at a faster rate. The authors suggest that the shallower network will con-\n\
    tinue to converge, provided additional epochs.\nThe experiments by Ding et al.\
    \ show that additional hidden layers can increase the \nconvergence rate on facial\
    \ action recognition. Training very-deep neural networks \nTable 12 Comparing\
    \ very-deep CNNs on FAU recognition (F1-score) [92]\nFAU class\nImbalance level\n\
    (A) Handcraft\n(B) Plain34\n(C) Res10\n(D) Res18\n(E) Res34\n(F) Res50\nAU1\n\
    2.5%\n0.05\n0.43\n0.46\n0.44\n0.44\n0.46\nAU2\n1.5%\n0.00\n0.42\n0.44\n0.45\n\
    0.45\n0.46\nAU4\n1.1%\n0.00\n0.44\n0.42\n0.41\n0.40\n0.42\nAU5\n0.9%\n0.00\n0.42\n\
    0.41\n0.42\n0.40\n0.46\nAU6\n3.6%\n0.41\n0.52\n0.51\n0.55\n0.52\n0.51\nAU9\n0.6%\n\
    0.00\n0.41\n0.36\n0.38\n0.40\n0.44\nAU12\n45.7%\n0.89\n0.89\n0.90\n0.89\n0.90\n\
    0.90\nAU17\n0.4%\n0.00\n0.19\n0.20\n0.26\n0.27\n0.24\nAU20\n0.01%\n0.00\n0.00\n\
    0.00\n0.00\n0.00\n0.00\nAU25\n29.9%\n0.79\n0.85\n0.86\n0.86\n0.86\n0.85\nAU26\n\
    25.6%\n0.64\n0.73\n0.74\n0.73\n0.74\n0.73\nAverage\n–\n0.29\n0.48\n0.48\n0.49\n\
    0.49\n0.50\nPage 35 of 54\nJohnson and Khoshgoftaar  J Big Data            (2019)\
    \ 6:27 \ncomes at a cost, however, as it increases the total number of matrix\
    \ operations and the \nmemory footprint. Additional experiments are required to\
    \ determine if this increased \nconvergence rate is observed with alternative\
    \ deep learning architectures and data sets. \nWith the convergence rate in question,\
    \ other methods that have been shown to impact \nconvergence rates should be included\
    \ in future studies, e.g. alternative optimization \nmethods, dynamic learning\
    \ rates, and weight initialization.\nSummary of algorithm‑level methods\nThis\
    \ section included eight algorithm-level methods for addressing class imbalance\
    \ \nwith DNNs. The MFE and MSFE loss functions presented by Wang et al. outperform\
    \ \nthe standard MSE loss on several image and text data sets. Lin et al.’s focal\
    \ loss, which \ndown-weights easy-to-classify samples, was used to outperform\
    \ several state-of-the-\nart one-stage and two-stage object detectors on the COCO\
    \ data set. Nemoto et al. also \nexplored focal loss for the purpose of detecting\
    \ rare building changes, but the results \nwere somewhat contradictory. A cost-sensitive\
    \ method that incorporates pre-defined \nmisclassification costs into the CE loss\
    \ function was used by  Wang et al. to predict hos-\npital readmissions. Khan\
    \ et al. proposed a cost-sensitive deep CNN (CoSen) that jointly \nlearns network\
    \ parameters and cost matrix parameters during training. Overall accuracy \nwas\
    \ used to show that the CoSen CNN outperforms a baseline CNN, multiple sampling\
    \ \nmethods, and multiple cost-sensitive methods consistently across six image\
    \ data sets. \nSimilarly,  Zhang et al. combined a DBN with an evolutionary algorithm\
    \ that searches \nfor optimal misclassification costs, but results were again\
    \ reported with the accuracy \nmetric and are difficult to interpret. Buda et al.\
    \ demonstrated how prior class probabili-\nties can be used to adjust DNN output\
    \ thresholds to improve overall accuracy in classi-\nfying image data.  Zhang\
    \ et al. presented category centers, a method that addresses class \nimbalance\
    \ by combining transfer learning, deep CNN feature extraction, and a nearest \n\
    deep feature cluster discrimination rule. Finally, Ding et al. experimented with\
    \ very-deep \nneural networks ( > 10 layers) and showed that deeper networks may\
    \ converge faster due \nto changes in the error surfaces that allow for faster\
    \ optimization.\nUnlike data sampling methods, the algorithm-level methods presented\
    \ do not alter the \ntraining data and do not require any pre-processing steps.\
    \ Compared to ROS, which was \nrecommended by multiple authors in the  \"Data-level\
    \ methods\" section, algorithm-level \nmethods are less likely to impact training\
    \ times. This suggests that algorithm-level meth-\nods may be better equipped\
    \ for big data problems. With the exception of defining mis-\nclassification costs,\
    \ the algorithm-level methods require little to no tuning. Fortunately, \ntwo\
    \ methods were presented for automatically learning cost parameters. Methods which\
    \ \nare able to adapt to different problems with minimal tuning are preferred,\
    \ as they can \nbe quickly applied to new problems and do not require specific\
    \ domain knowledge. The \nfocal loss function and CoSen CNN demonstrate this flexibility,\
    \ and we believe they will \ngeneralize well to many complex problem domains.\n\
    In general, there is a lack of research that appropriately compares deep learning\
    \ algo-\nrithm-level methods to alternative class imbalance methods. This is due\
    \ to poor choices \nin baseline models, insufficient performance metrics, and\
    \ domain-specific experiments \nthat fail to isolate the proposed class imbalance\
    \ method. Similar to the surveyed deep \nPage 36 of 54\nJohnson and Khoshgoftaar\
    \  J Big Data            (2019) 6:27 \nlearning data-level methods, most of the\
    \ methods in this section were evaluated on \nimage data with deep CNNs. We are\
    \ most interested in understanding how deep learn-\ning methods for addressing\
    \ class imbalance compare to each other and to traditional \nmachine learning\
    \ techniques for class imbalance. We believe that filling these research \ngaps\
    \ and properly evaluating these methods will have a great impact on future deep\
    \ \nlearning applications.\nHybrid‑methods\nThe deep learning techniques for addressing\
    \ class imbalance in this section combine \nalgorithm-level and data-level methods.\
    \ Huang et al. [22] use a novel loss function and \nsampling method to generate\
    \ more discriminative representations in their Large Mar-\ngin Local Embedding\
    \ (LMLE) method. Ando and Huang [117] presented the first deep \nfeature over-sampling\
    \ method, Deep Over Sampling (DOS). Finally, class imbalance in \nlarge-scale\
    \ image classification is addressed by Dong et al. [118] with a novel loss func-\n\
    tion and hard sample mining.\nLarge Margin Local Embedding (LMLE)\nHuang et al.\
    \ [22] proposed the LMLE method for learning more discriminative deep \nrepresentations\
    \ of imbalanced image data. The method is motivated by the observa-\ntion that\
    \ minority groups are sparse and typically contain high variability, allowing\
    \ the \nlocal neighborhood of these minority samples to be easily invaded by samples\
    \ of another \nclass. By combining a new informed quintuplet sampling method with\
    \ a new triple-\nheader hinge loss function, deep feature representations that\
    \ preserve same class locality \nand increase inter-class discrimination are learned\
    \ from imbalanced image data. These \ndeep feature representations, which form\
    \ well-defined clusters, are then used to label \nnew samples with a fast cluster-wise\
    \ K-NN classification method. The proposed LMLE \nmethod is shown to achieve state-of-the-art\
    \ results on the CelebA [119] data set, which \ncontains high imbalance levels\
    \ up to ρ = 49.\nThe quintuplet sampling method selects an anchor and four additional\
    \ samples based \non inter-class and intra-class cluster distances. During training,\
    \ each mini-batch selects \nan equal number of quintuplets from both the minority\
    \ and majority classes. The five \nsamples obtained by the quintuplet sampling\
    \ method are fed to five identical CNNs, \nand their outputs are aggregated into\
    \ a single result. The triple-header hinge loss is then \nused to compute the\
    \ error and update the network parameters accordingly. This regular-\nized loss\
    \ function constrains the deep feature representation such that clusters collapse\
    \ \ninto small neighborhoods with appropriate margins between inter-class and\
    \ intra-class \nclusters.\nThe CelebA data set contains facial images annotated\
    \ with 40 attributes, with imbal-\nance levels as high as ρ = 49 (Bald vs not\
    \ Bald). A total of 160,000 images are used to \ntrain a CNN, and the learned\
    \ deep representations are then fed to a modified K-NN \nclassifier. The Balanced\
    \ Accuracy (Eq. 9) metric is calculated for each facial attribute. \nThe LMLE-kNN\
    \ model is compared to three state-of-the-art models in the facial attrib-\nute\
    \ recognition domain: Triplet-kNN [120], PANDA [121], and ANet [122]. Results\
    \ \nin Table 13 show that the LMLE-kNN performs as good as, or better than, alternative\
    \ \nmethods for all facial attributes. Performance gains over alternative methods\
    \ increased \nPage 37 of 54\nJohnson and Khoshgoftaar  J Big Data            (2019)\
    \ 6:27 \nTable 13 LMLE CelebA facial attribute recognition (Balanced Accuracy)\
    \ [22]\nAttractive\nMouth \nopen\nSmiling\nWear \nlipstick\nHigh \ncheekbones\n\
    Male\nHeavy \nmakeup\nWavy \nhair\nOval \nface\nPointy \nnose\nArched \neyebrows\n\
    Black \nhair\nBig \nlips\nBig \nnose\nYoung\nStraight \nhair\nBrown \nhair\nBags\
    \ \nunder eyes\nWear \nearings\nNo \nbeard\nBangs\nImbal-\nance \nlevel\n1\n2\n\
    2\n3\n5\n8\n11\n18\n22\n22\n23\n26\n26\n27\n28\n29\n30\n30\n31\n33\n35\nTriplet-\n\
    kNN\n83\n92\n92\n91\n86\n91\n88\n77\n61\n61\n73\n82\n55\n68\n75\n63\n76\n63\n\
    69\n82\n81\nPANDA\n85\n93\n98\n97\n89\n99\n95\n78\n66\n67\n77\n84\n56\n72\n78\n\
    66\n85\n67\n77\n87\n92\nANet\n87\n96\n97\n95\n89\n99\n96\n81\n67\n69\n76\n90\n\
    57\n78\n84\n69\n83\n70\n83\n93\n90\nLMLE-\nkNN\n88\n96\n99\n99\n92\n99\n98\n83\n\
    68\n72\n79\n92\n60\n80\n87\n73\n87\n73\n83\n96\n98\nBlond \nhair\nBushy \neyebrows\n\
    Wear \nnecklace\nNarrow \neyes\n5 o’clock \nshadow\nReceding \nhairline\nWear\
    \ \nnecktie\nEyeglasses\nRosy \ncheeks\nGoatee Chubby\nSideburns Blurry\nWear\
    \ \nhat\nDouble \nchin\nPale \nskin\nGray \nhair\nMustache Bald\nAverage\nImbalance\
    \ \nlevel\n35\n36\n38\n38\n39\n42\n43\n44\n44\n44\n44\n44\n45\n45\n45\n46\n46\n\
    46\n48\nTriplet-kNN\n81\n68\n50\n47\n66\n60\n73\n82\n64\n73\n64\n71\n43\n84\n\
    60\n63\n72\n57\n75\n72\nPANDA\n91\n74\n51\n51\n76\n67\n85\n88\n68\n84\n65\n81\n\
    50\n90\n64\n69\n79\n63\n74\n77\nANet\n90\n82\n59\n57\n81\n70\n79\n95\n76\n86\n\
    70\n79\n56\n90\n68\n77\n85\n61\n73\n80\nLMLE-kNN\n99\n82\n59\n59\n82\n76\n90\n\
    98\n78\n95\n79\n88\n59\n99\n74\n80\n91\n73\n90\n84\nPage 38 of 54\nJohnson and\
    \ Khoshgoftaar  J Big Data            (2019) 6:27 \nas levels of imbalance increased,\
    \ e.g. LMLE increased accuracy on the Bald attribute \nfrom 75 to 90 when compared\
    \ to its runner-up. The authors achieved similar results \nwhen comparing the\
    \ LMLE-kNN to 14 state-of-the-art models on the BSDS500 [123] \nedge detection\
    \ data set.\nHuang et  al. were one of the first to study deep representation\
    \ learning with class \nimbalanced data. The proposed LMLE method combines several\
    \ powerful concepts, \nachieves state-of-the-art results on a popular image data\
    \ benchmark, and shows poten-\ntial for future works in other domains. The high-performance\
    \ results do come with a \ncost, however, as the system is both complex and computationally\
    \ expensive. The data \nmust be pre-clustered before quintuplet sampling can take\
    \ place, which may be dif-\nficult if a suitable feature extractor is not available\
    \ for the given data set. The authors \ndo suggest that the initial clustering\
    \ is not important, because the learning procedure \ncan be used to re-cluster\
    \ the data throughout training. Furthermore, each forward pass \nthrough the system\
    \ requires computation from five CNNs, one for each of the quintu-\nplets sampled.\
    \ We are in agreement with the statement made by Ando and Huang [117], \nthat\
    \ adapting LMLE to new problems will require many task and model specific con-\n\
    figurations. This will likely deter many practitioners from using this method\
    \ when trying \nto solve class imbalanced problems, as most will resort to simpler\
    \ and faster methods. \nResults provided by Dong et al. in the  \"Class rectification\
    \ loss (CRL) and hard sample \nmining\" section will show that LMLE outperforms\
    \ ROS, RUS, thresholding, and cost-\nsensitive learning on the CelebA data set.\n\
    Deep over‑sampling (DOS)\nAndo and Huang [117] introduced over-sampling to the\
    \ deep feature space produced \nby CNNs in their DOS framework. The proposed method\
    \ is extensively evaluated by \ngenerating imbalanced data sets from five popular\
    \ image benchmark data sets, including \nMNIST, MNIST-back-rot, SVHN [124], CIFAR-10,\
    \ and STL-10 [125]. Class-wise preci-\nsion and recall, F1-scores, and AUC are\
    \ used to evaluate the DOS framework against \nalternative methods.\nThe DOS framework\
    \ consists of two simultaneous learning procedures, optimizing the \nlower layer\
    \ and upper layer parameters separately. The lower layers are responsible for\
    \ \nacquiring the embedding function, while the upper layers learn to discriminate\
    \ between \nclasses using the generated embeddings. In order to learn the embedding\
    \ features, the \nCNN’s input is presented with both a class label and a set of\
    \ deep feature targets, an \nin-class nearest neighbor cluster from deep feature\
    \ space. Then the micro-cluster loss \ncomputes the distances between each of\
    \ the deep feature targets and their mean, con-\nstraining the optimization of\
    \ the lower layers to shift deep feature embeddings towards \nthe class mean.\
    \ Ando and Huang state that shifting target representations to their cor-\nresponding\
    \ local mean will induce smaller in-class variance and strengthen class distinc-\n\
    tion in the learned representations. The upper layers used for discriminating\
    \ between \nclasses are trained by taking the weighted sum of the CE losses, i.e.\
    \ the CE loss for each \ndeep feature target.\nThe deep over-sampling component\
    \ is the process of selecting k in-class neigh-\nbors from deep feature space.\
    \ In order to address class imbalance, the number of in-\nclass neighbors to select\
    \ should vary between classes. For example, using k = 3 for the \nPage 39 of 54\n\
    Johnson and Khoshgoftaar  J Big Data            (2019) 6:27 \nminority class,\
    \ and k = 0 for the majority class, will supplement the minority class with \n\
    additional embeddings while leaving the majority class as is.\nIn the first DOS\
    \ experiment, they compare the DOS framework with two alternative \nmethods for\
    \ handling class imbalance, Large Margin Local Embedding (LMLE) [22] and \nTriplet\
    \ re-sampling with cost-sensitive learning (TL-RS-CSL). MNIST back-rotation \n\
    images were used to create three data sets with class reduction rates of 0%, 20%,\
    \ and \n40%. It was shown that the DOS framework outperformed TL-RS-CSL and LMLE\
    \ for \nreduction rates of 20% and 40%, and that DOS performance deteriorates\
    \ slower than \nboth TL-RS-CSL and LMLE as imbalance levels increase. For example,\
    \ on imbalanced \nMNIST-back-rot data (40% reduction), DOS scored an average class-wise\
    \ recall of 75.43, \ncompared to the LMLE score of 70.13.\nTable 14 DOS with varying\
    \ imbalance [117]\nModel\nReduction rate\nClass\nMNIST\nMNISTbr\nSVHN\nPr\nRe\n\
    F1\nAUC Pr\nRe\nF1\nAUC Pr\nRe\nF1\nAUC \nCNN\n0.90\nmnr\n0.98\n0.93\n0.96\n0.99\n\
    0.31\n0.76\n0.43\n0.68\n0.62\n0.77\n0.55\n0.78\nmjr\n0.96\n0.99\n0.97\n1.00\n\
    0.77\n0.56\n0.65\n0.77\n0.80\n0.76\n0.75\n0.89\n0.95\nmnr\n0.99\n0.89\n0.94\n\
    0.99\n0.27\n0.76\n0.23\n0.57\n0.13\n0.86\n0.21\n0.61\nmjr\n0.93\n0.98\n0.95\n\
    0.99\n0.52\n0.69\n0.58\n0.67\n0.89\n0.61\n0.71\n0.87\n0.99\nmnr\n0.65\n0.98\n\
    0.77\n0.96\n0.31\n0.71\n0.43\n0.68\n0.50\n0.72\n0.42\n0.74\nmjr\n0.99\n0.82\n\
    0.89\n0.99\n0.78\n0.56\n0.65\n0.77\n0.73\n0.67\n0.60\n0.81\nCNN-CL\n0.90\nmnr\n\
    0.99\n0.90\n0.94\n1.00\n0.22\n0.77\n0.31\n0.69\n0.59\n0.60\n0.42\n0.78\nmjr\n\
    0.94\n0.99\n0.96\n0.98\n0.78\n0.53\n0.63\n0.78\n0.77\n0.75\n0.73\n0.86\n0.95\n\
    mnr\n0.99\n0.83\n0.90\n0.97\n0.28\n0.77\n0.24\n0.60\n0.04\n0.68\n0.07\n0.61\n\
    mjr\n0.89\n0.99\n0.94\n1.00\n0.52\n0.68\n0.57\n0.69\n0.89\n0.60\n0.70\n0.84\n\
    0.99\nmnr\n0.75\n0.98\n0.85\n0.95\n0.22\n0.72\n0.31\n0.69\n0.47\n0.71\n0.37\n\
    0.72\nmjr\n0.99\n0.86\n0.92\n0.99\n0.78\n0.53\n0.63\n0.78\n0.71\n0.57\n0.56\n\
    0.78\nDOS\n(k = 5)\n0.90\nmnr\n0.99\n0.97\n0.98\n1.00\n0.66\n0.77\n0.71\n0.79\n\
    0.71\n0.82\n0.72\n0.84\nmjr\n0.98\n0.99\n0.98\n1.00\n0.75\n0.68\n0.71\n0.81\n\
    0.85\n0.79\n0.81\n0.92\n0.95\nmnr\n0.98\n0.96\n0.97\n1.00\n0.56\n0.75\n0.63\n\
    0.72\n0.40\n0.89\n0.55\n0.73\nmjr\n0.97\n0.99\n0.98\n1.00\n0.64\n0.74\n0.69\n\
    0.78\n0.90\n0.69\n0.78\n0.91\n0.99\nmnr\n0.91\n0.99\n0.95\n0.99\n0.61\n0.73\n\
    0.66\n0.75\n0.51\n0.91\n0.64\n0.80\nmjr\n0.98\n0.94\n0.96\n1.00\n0.77\n0.70\n\
    0.73\n0.82\n0.89\n0.68\n0.77\n0.90\nTable 15 DOS with varying k [117]\nClassifier\n\
    k\nClass\nMNIST\nMNISTbr\nSVHN\nPr\nRe\nF1\nAUC \nPr\nRe\nF1\nAUC \nPr\nRe\nF1\n\
    AUC \nCNN\nmnr\n0.65\n0.98\n0.77\n0.96\n0.31\n0.76\n0.43\n0.68\n0.50\n0.72\n0.42\n\
    0.74\nmjr\n0.99\n0.82\n0.89\n0.99\n0.78\n0.56\n0.65\n0.77\n0.73\n0.67\n0.60\n\
    0.81\nCNN-CL\nmnr\n0.75\n0.98\n0.85\n0.95\n0.22\n0.77\n0.31\n0.69\n0.47\n0.71\n\
    0.37\n0.72\nmjr\n0.99\n0.86\n0.92\n0.99\n0.78\n0.53\n0.63\n0.78\n0.71\n0.57\n\
    0.56\n0.78\nDOS\n3\nmnr\n0.91\n0.98\n0.95\n0.99\n0.65\n0.77\n0.70\n0.78\n0.67\n\
    0.77\n0.66\n0.83\nmjr\n0.99\n0.94\n0.96\n1.00\n0.75\n0.68\n0.71\n0.80\n0.80\n\
    0.74\n0.74\n0.86\n5\nmnr\n0.91\n0.99\n0.95\n0.99\n0.66\n0.77\n0.71\n0.79\n0.51\n\
    0.91\n0.64\n0.80\nmjr\n0.98\n0.94\n0.96\n1.00\n0.75\n0.68\n0.71\n0.81\n0.89\n\
    0.68\n0.77\n0.90\n10\nmnr\n0.91\n0.99\n0.95\n0.99\n0.61\n0.73\n0.66\n0.75\n0.40\n\
    0.89\n0.55\n0.73\nmjr\n0.99\n0.94\n0.96\n1.00\n0.77\n0.70\n0.73\n0.82\n0.90\n\
    0.69\n0.78\n0.91\nPage 40 of 54\nJohnson and Khoshgoftaar  J Big Data        \
    \    (2019) 6:27 \nIn a second experiment, the DOS framework is compared to a\
    \ basic CNN and a K-NN \nclassifier that is trained with CNN deep features (CNN-CL).\
    \ Three different data sets \nare used to generate imbalanced data sets with reduction\
    \ rates of 90%, 95%, and 99%, \nproducing imbalance ratios up to ρ = 100 . The\
    \ results in Table 14 show again that the \nimproved performance of the DOS framework\
    \ becomes more apparent as the level of \nclass imbalance increases. The third\
    \ level of imbalance, with reduction rates of 99%, \nshow that the DOS framework\
    \ clearly outperforms both the CNN and CNN-CL across \nall data sets and all performance\
    \ metrics.\nThe final experiment uses balanced data sets to examine the sensitivity\
    \ of DOS param-\neter k, which defines the number of deep feature in-class neighbors\
    \ to sample. Table 15 \nshows that when k is increased to 10 the performance on\
    \ the minority group begins to \ndeteriorate. These results also show that the\
    \ proposed DOS framework outperforms the \nbaseline CNN and CNN-CL on balanced\
    \ data sets.\nThe DOS method displayed no visible performance trade-offs between\
    \ the majority \nand minority groups, or between precision and recall. Its ability\
    \ to outperform alterna-\ntive methods when class imbalance is not present is\
    \ also very appealing, as this qual-\nity is not common among class imbalance\
    \ learning methods. Most importantly, some \nof the performance gains observed\
    \ when comparing the CNN or CNN-CL to the DOS \nmodel on the minority group were\
    \ very large, e.g. MNIST-back-rot and SVHN F1-scores \nincreasing from 0.43 to\
    \ 0.66 and 0.42 to 0.64, respectively, under an imbalance reduc-\ntion rate of\
    \ 99%. Like other hybrid methods, DOS is more complex than more common \ndata-level\
    \ and algorithm-level methods, which may discourage statisticians from using \n\
    it. We agree with Ando and Huang, however, that the DOS method is generally extend-\n\
    able to other domains and deep learning architectures. Future works should evaluate\
    \ the \nDOS method in these new contexts and should compare results to other class\
    \ imbalance \nmethods presented throughout this survey.\nClass rectification loss\
    \ (CRL) and hard sample mining\nDong et al. [118] present an end-to-end deep learning\
    \ method for addressing high class \nimbalance in large-scale image classification.\
    \ They explicitly distinguish their work \nfrom more traditional small-scale class\
    \ imbalance problems containing small levels of \nimbalance, suggesting that this\
    \ method may not generalize to small-scale problems. \nExperimental results compare\
    \ the proposed method against data sampling, cost-sen-\nsitive learning, threshold\
    \ moving, and several relevant state-of-the-art methods. Mean \nsensitivity scores\
    \ are used as the primary performance metric by averaging together \nclass-wise\
    \ recall scores. The proposed method combines hard sample mining from the \nminority\
    \ groups with a regularized objective function, the class rectification loss (CRL).\n\
    The hard sample mining selects minority samples which are expected to be more\
    \ \ninformative for each mini-batch, allowing the model to learn more effectively\
    \ with less \ndata. Dong et al. strive to rectify, or correct, the class distribution\
    \ bias in an incremental \nmanner, resulting in progressively stronger minority\
    \ class discrimination through train-\ning. Unlike LMLE [22], which attempts to\
    \ strengthen the structure of both majority and \nminority groups, this method\
    \ only enhances minority class discrimination. To identify \nthe minority classes,\
    \ all classes are sorted by their size and then selected from smallest \nto largest\
    \ until they collectively sum up to at most half the size of the data set, ensuring\
    \ \nPage 41 of 54\nJohnson and Khoshgoftaar  J Big Data            (2019) 6:27\
    \ \nTable 16 CRL with CelebA Data (Balanced Accuracy) [118]\nAttractive\nMouth\
    \ \nopen\nSmiling\nWear \nlipstick\nHigh \ncheekbones\nMale\nHeavy \nmakeup\n\
    Wavy \nhair\nOval \nface\nPointy \nnose\nArched \neyebrows\nBlack \nhair\nBig\
    \ \nlips\nBig \nnose\nYoung\nStraight \nhair\nBrown \nhair\nBags \nunder eyes\n\
    Wear \nearings\nNo \nbeard\nBangs\nImbal-\nance \n(1:x)\n1\n1\n1\n1\n1\n1\n2\n\
    2\n3\n3\n3\n3\n3\n3\n4\n4\n4\n4\n4\n5\n6\nTriplet-\nkNN\n83\n92\n92\n91\n86\n\
    91\n88\n77\n61\n61\n73\n82\n55\n68\n75\n63\n76\n63\n69\n82\n81\nPANDA\n85\n93\n\
    98\n97\n89\n99\n95\n78\n66\n67\n77\n84\n56\n72\n78\n66\n85\n67\n77\n87\n92\nANet\n\
    87\n96\n97\n95\n89\n99\n96\n81\n67\n69\n76\n90\n57\n78\n84\n69\n83\n70\n83\n93\n\
    90\nDeepID2\n78\n89\n89\n92\n84\n94\n88\n73\n63\n66\n77\n83\n62\n73\n76\n65\n\
    79\n74\n75\n88\n91\nOver-\nsam-\npling\n77\n89\n90\n92\n84\n95\n87\n70\n63\n67\n\
    79\n84\n61\n73\n75\n66\n82\n73\n76\n88\n90\nDown-\nsam-\npling\n78\n87\n90\n91\n\
    80\n90\n89\n70\n58\n63\n70\n80\n61\n76\n80\n61\n76\n71\n70\n88\n88\nCost-\nsensi-\n\
    tive\n78\n89\n90\n91\n85\n93\n89\n75\n64\n65\n78\n85\n61\n74\n75\n67\n84\n74\n\
    76\n88\n90\nThresh-\nold-\nAdj\n69\n89\n88\n89\n83\n95\n89\n77\n72\n72\n76\n86\n\
    66\n76\n24\n73\n81\n76\n76\n15\n93\nLMLE-\nkNN\n88\n96\n99\n99\n92\n99\n98\n83\n\
    68\n72\n79\n92\n60\n80\n87\n73\n87\n73\n83\n96\n98\nCRL\n81\n94\n92\n95\n87\n\
    98\n90\n79\n66\n71\n80\n88\n67\n77\n83\n72\n84\n79\n84\n93\n95\nBlond \nhair\n\
    Bushy \neyebrows\nWear \nnecklace\nNarrow \neyes\n5 o’clock \nshadow\nReceding\
    \ \nhairline\nWear \nnecktie\nEyeglasses Rosy \ncheeks\nGoatee\nChubby Sideburns\n\
    Blurry\nWear \nhat\nDouble \nchin\nPale \nskin\nGray \nhair\nMustache\nBald\n\
    Mean\nImbal-\nance \n(1:x)\n6\n6\n7\n8\n8\n11\n13\n14\n14\n15\n16\n17\n18\n19\n\
    20\n22\n23\n24\n43\nTriplet-\nkNN\n81\n68\n50\n47\n66\n60\n73\n82\n64\n73\n64\n\
    71\n43\n84\n60\n63\n72\n57\n75\n72\nPANDA\n91\n74\n51\n51\n76\n67\n85\n88\n68\n\
    84\n65\n81\n50\n90\n64\n69\n79\n63\n74\n77\nPage 42 of 54\nJohnson and Khoshgoftaar\
    \  J Big Data            (2019) 6:27 \nBold-italic and italic scores indicate\
    \ best and second best class scores, respectively\nTable 16 (continued)\nBlond\
    \ \nhair\nBushy \neyebrows\nWear \nnecklace\nNarrow \neyes\n5 o’clock \nshadow\n\
    Receding \nhairline\nWear \nnecktie\nEyeglasses Rosy \ncheeks\nGoatee\nChubby\
    \ Sideburns\nBlurry\nWear \nhat\nDouble \nchin\nPale \nskin\nGray \nhair\nMustache\n\
    Bald\nMean\nANet\n90\n82\n59\n57\n81\n70\n79\n95\n76\n86\n70\n79\n56\n90\n68\n\
    77\n85\n61\n73\n80\nDeepID2\n90\n78\n70\n64\n85\n81\n83\n92\n86\n90\n81\n89\n\
    74\n90\n83\n81\n90\n88\n93\n81\nOver-\nsam-\npling\n90\n80\n71\n65\n85\n82\n79\n\
    91\n90\n89\n83\n90\n76\n89\n84\n82\n90\n90\n92\n82\nDown-\nsam-\npling\n85\n75\n\
    66\n61\n82\n79\n80\n85\n82\n85\n78\n80\n68\n90\n80\n78\n88\n60\n79\n78\nCost-sen-\n\
    sitive\n89\n79\n71\n65\n84\n81\n82\n91\n92\n86\n82\n90\n76\n90\n84\n80\n90\n88\n\
    93\n82\nThresh-\nold-\nAdj\n92\n84\n62\n71\n82\n83\n76\n95\n82\n89\n81\n89\n78\n\
    95\n83\n85\n91\n86\n93\n79\nLMLE-\nkNN\n99\n82\n59\n59\n82\n76\n90\n98\n78\n95\n\
    79\n88\n59\n99\n74\n80\n91\n73\n90\n84\nCRL\n95\n84\n73\n73\n89\n88\n87\n99\n\
    90\n95\n87\n95\n86\n99\n89\n92\n96\n93\n99\n87\nPage 43 of 54\nJohnson and Khoshgoftaar\
    \  J Big Data            (2019) 6:27 \nthat the minority classes account for at\
    \ most half the training batch. Both class-level and \ninstance-level hardness\
    \ metrics are considered when performing hard sample mining. At \nthe class-level,\
    \ hard positives refer to weak recognitions, the correctly labelled samples \n\
    with low prediction scores. Alternatively, hard negatives are the obvious mistakes,\
    \ the \nsamples incorrectly labelled with high prediction scores. At the instance-level,\
    \ hard posi-\ntives are defined by correctly labelled images with far distances\
    \ in feature space distance, \nwhile hard negatives are the images incorrectly\
    \ labelled which are close in feature space.\nThe CRL loss function (Eq. 17),\
    \ where α = η\x1Dimb is linearly proportional to the level \nof class imbalance,\
    \ places a batch-wise class balancing constraint on the optimization \nprocess.\
    \ This reduces the learning bias caused by the majority group’s over-represen-\n\
    tation. The CRL regularization imposes an imbalance-adaptive learning mechanism,\
    \ \napplying more weight to the more highly imbalanced labels, while reducing\
    \ the weight \nfor the less imbalanced labels. Three different loss criteria Lcrl\
    \ are explored through \nexperimentation, where the Triplet Ranking loss [126]\
    \ is selected as the default for \nmany of the experiments.\nExperiments are conducted\
    \ by extending state-of-the-art CNN architectures with the \nproposed method and\
    \ performing classification on three benchmark data sets. The Cel-\nebA data set\
    \ contains a max imbalance level of ρ = 49 . The X-Domain [127] data set \ncontains\
    \ 245,467 retail store clothing images that are annotated with 9 multi-class attrib-\n\
    ute labels, 165,467 of which are set aside for training. The X-Domain contains\
    \ extreme \nclass imbalance ratios of ρ > 4000 . Several imbalanced data sets\
    \ are generated from the \nCIFAR-100 set, with imbalance ratios up to ρ = 20 ,\
    \ to demonstrate how CRL handles \nincreasing levels of imbalance.\nTable 16 contains\
    \ the CelebA facial attribute recognition results. All class imbal-\nance methods\
    \ presented were implemented on top of the 5-layer CNN, DeepID2, \n[128]. Referring\
    \ to the bottom half of the data attributes, with imbalance ratios ρ ≥ 6 , \n\
    under-sampling almost always performs worse than over-sampling, cost-sensitive\
    \ \nlearning, and threshold moving. According to the mean sensitivity scores,\
    \ over-sam-\npling and cost-sensitive learning perform the same, outperforming\
    \ thresholding and \nunder-sampling by 3% and 4%, respectively.\nWhen compared\
    \ to the best non-imbalanced learning method (DeepID2) and the \nbest imbalanced\
    \ learning method (LMLE), the proposed CRL method improves the \nmean sensitivity\
    \ by 6% and 3%, respectively. By analyzing the attribute-level scores, \nwe can\
    \ see that LMLE outperforms CRL in many cases where class imbalance lev-\nels\
    \ are low, e.g. outperforming CRL on the attractive attribute by 7%. Dong et \
    \ al. \nacknowledge that LMLE appears to handle low-level imbalance better than\
    \ CRL. For \nmany of the high-imbalance attributes, the non-imbalance method DeepID2\
    \ outper-\nforms the LMLE method. It is when class imbalance is highest that the\
    \ proposed CRL \nmethod performs its best and achieves its most significant performance\
    \ gains over \nalternative methods.\nIn another experiment with the X-Domain data\
    \ set, CRL outperforms LMLE on \nall categories, achieving a mean sensitivity\
    \ performance gain over LMLE of almost \n5%. Cost-sensitive learning, thresholding,\
    \ and ROS all score roughly 6% below CRL, \n(17)\nLbln = αLcrl + (1 − α)Lce,\n\
    α = η\eimb\nPage 44 of 54\nJohnson and Khoshgoftaar  J Big Data            (2019)\
    \ 6:27 \nwhile RUS again performs very poorly. When experimenting with balanced\
    \ distribu-\ntions from the CIFAR-100 data set, the CRL method is applied to three\
    \ state-of-the-\nart CNN models: CifarNet [129], ResNet32 [98], and DenseNet [130].\
    \ For each model, \nthe CRL method consistently improves upon the baseline, increasing\
    \ mean sensitivity \nby 3.6%, 1.2%, and 0.8%, respectively. Additional cost analysis\
    \ by Dong et al. shows \nthat CRL is significantly faster than LMLE, taking just\
    \ 27.2 h to train versus LMLE’s \n166.6 h on the given test case.\nThe advantages\
    \ of CRL over alternative methods on large-scale class imbalanced \nimage data\
    \ were demonstrated through comprehensive experiments. It was shown \nto efficiently\
    \ outperform many popular class imbalanced methods, including ROS, \nRUS, thresholding,\
    \ cost-sensitive learning, and LMLE. It was also shown to train sig-\nnificantly\
    \ faster than the LMLE method. The authors were clear to distinguish this \nmethod\
    \ as effective in large-scale image data containing high levels of imbalance,\
    \ and \nresults on facial attribute detection showed that LMLE performed better\
    \ for many \nfacial attributes with lower levels of imbalance. This suggests that\
    \ the CRL method \nmay not be a good fit for class imbalance problems containing\
    \ low levels of class \nimbalance. Despite this initial observation, CRL should\
    \ be evaluated on a wide range \nof data sets with varying levels of complexity\
    \ to better understand when it should \nbe used. Exploring the CRL method’s ability\
    \ to learn from non-image data is also of \ninterest.\nSummary of hybrid methods\n\
    This section analyzed three hybrid deep learning methods for addressing class\
    \ imbal-\nance. The LMLE method proposed by Huang et al. outperformed several\
    \ state-of-the-art \nmodels on the CelebA and BSDS500 image data sets. Ando and\
    \ Huang introduced the \nDOS method, which learns an embedding layer that produces\
    \ more discriminative fea-\ntures, and then supplements the minority group by\
    \ over-sampling in deep feature space. \nDOS was shown to outperform LMLE and\
    \ baseline CNNs on multiple class imbalanced \nimage data sets. Lastly, Dong et al.’s\
    \ CRL loss function was shown to outperform four \nstate-of-the-art models, ROS,\
    \ RUS, cost-sensitive learning, output thresholding, and \nLMLE on the CelebA\
    \ data set.\nThe results provided by Dong et  al. are most informative, as they\
    \ compare their \nCRL method to LMLE and several other data-level and algorithm-level\
    \ deep learning \nmethods for addressing class imbalance. Not only did they show\
    \ that the CRL method \noutperforms alternative methods as class imbalance levels\
    \ increase, but they also illus-\ntrated the effectiveness of RUS, ROS, thresholding,\
    \ and cost-sensitive learning. From \ntheir results on the CelebA data set, we\
    \ observe that ROS and cost-sensitive learning \noutperform RUS and threshold\
    \ moving on average. These results are consistent with \nthose from the \"Data-level\
    \ methods\" section, suggesting that ROS is generally a good \nchoice in addressing\
    \ class imbalance with DNNs. Dong et al. also confirmed our original \nobservation,\
    \ that LMLE is rather complex and resource intensive, by showing that CRL \nis\
    \ capable of training 6× faster than LMLE. Comparing DOS and CRL directly will\
    \ prove \nuseful, as both methods were shown to outperform the LMLE method.\n\
    In general, hybrid methods for learning from class imbalanced data will be more\
    \ \ncomplex, and more difficult to implement than algorithm-level methods and\
    \ data-level \nPage 45 of 54\nJohnson and Khoshgoftaar  J Big Data           \
    \ (2019) 6:27 \nmethods. This is expected, since both algorithm-level and data-level\
    \ methods are being \ncombined for the purpose of improving classification performance.\
    \ As learners become \nmore complex, their flexibility and ease of use will decrease,\
    \ which may make them more \ndifficult to adapt to new problems.\nClass-wise performance\
    \ scores on the CelebA data set in Table 16 show that differ-\nent methods perform\
    \ better when subjected to different levels of class imbalance. This \nobservation\
    \ supports our demand for future research that evaluates multiple deep learn-\n\
    ing methods across a variety of class imbalance levels and problem complexities.\
    \ We \nexpect to see similar trade-offs between models when they are evaluated\
    \ across a variety \nof data types and DNN architectures. Filling these gaps in\
    \ current research will help to \nshape future deep learning applications that\
    \ involve class imbalance, class rarity, and big \ndata.\nDiscussion of surveyed\
    \ works\nTo provide a high-level summary and better compare the current deep learning\
    \ meth-\nods for class imbalance, the surveyed works and their data sets have\
    \ been summarized \nin Tables 17 and 18. The methods presented by each group have\
    \ been categorized in \nTable 17 Summary of deep learning class imbalance methods\n\
    Method\nNetwork type Method type Description\nROS [23, 79]\nCNN\nData\nROS of\
    \ minority classes until class balance is \nachieved\nRUS [23]\nCNN\nData\nRUS\
    \ of majority classes until class balance is \nachieved\nTwo-phase learning [20,\
    \ 23] CNN\nData\nPre-training with RUS or ROS, then fine-tuning \nwith all data\n\
    Dynamic sampling [21]\nCNN\nData\nSampling rates adjust throughout training based\
    \ \non previous iteration’s class-wise F1-scores\nMFE and MSFE loss [18]\nMLP\n\
    Algorithm\nNew loss functions allow positive and negative \nclasses to contribute\
    \ to loss equally\nFocal loss [88, 103]\nCNN\nAlgorithm\nNew loss function down-weights\
    \ easy-to-classify \nsamples, reducing their impact on total loss\nCSDNN [89]\n\
    MLP\nAlgorithm\nCE loss function modified to incorporate a pre-\ndefined cost\
    \ matrix\nCoSen CNN [19]\nCNN\nAlgorithm\nCost matrix is learned through backpropagation\
    \ \nand incorporated into output layer\nCSDBN-DE [90]\nDBN\nAlgorithm\nCost matrix\
    \ is learned through evolutionary algo-\nrithm and incorporated into output layer\n\
    Threshold moving [23]\nCNN\nAlgorithm\nDecision threshold is adjusted by dividing\
    \ output \nprobabilities by prior class probabilities\nCategory centers [91]\n\
    CNN\nAlgorithm\nClass centroids are calculated in deep feature \nspace and K-NN\
    \ method discriminates\nVery-deep NNs [92]\nCNN\nAlgorithm\nCNN network depths\
    \ of up to 50 layers are used to \nexamine convergence rates\nLMLE [22]\nCNN\n\
    Hybrid\nTriple-header hinge loss and quintuplet sampling \ngenerate more discriminative\
    \ features\nDOS [117]\nCNN\nHybrid\nMinority class over-sampled in deep feature\
    \ space \nusing K-NN and micro-cluster loss\nCRL loss [118]\nCNN\nHybrid\nClass\
    \ Rectification loss and hard sample mining \nproduce more discriminative features\n\
    Page 46 of 54\nJohnson and Khoshgoftaar  J Big Data            (2019) 6:27 \n\
    Table 17 as one of three types: data, algorithm, or hybrid. All of the general\
    \ methods \nfor handling class imbalance in traditional machine learning have\
    \ been extended to \ndeep learning, including: random sampling, informed sampling,\
    \ cost-sensitive learning, \nthresholding, and hybrid methods.\nData-level techniques\
    \ for addressing class imbalance in deep learning include ROS \n[23, 79], RUS\
    \ [23], two-phase learning with sampling [20, 23], and performance-based \ndynamic\
    \ sampling [21]. The ROS experiments reported that over-sampling to the level\
    \ \nof class balance works best on imbalanced image data. The two-phase learning\
    \ method \nuses RUS or ROS to pre-train a DNN with class balanced data sets, then\
    \ fine-tunes the \nnetwork using all data. The dynamic sampling method uses class-wise\
    \ F1-scores to \ndetermine sampling rates, allowing the model to sample difficult\
    \ classes at a higher rate.\nTable 18 Summary of data sets and class imbalance\
    \ levels\nImages from CelebA and EmotioNet are treated as a set of binary classification\
    \ problems, because they are each annotated \nwith 40 and 11 binary attributes,\
    \ respectively. The COCO data class imbalance arises from the extreme imbalance\
    \ between \nbackground and foreground concepts\nPaper Data sets\nData type Class\
    \ count Data set size Min class size Max class size ρ (Eq. 1)\n[79]\nCIFAR-10\n\
    Image\n10\n60,000\n2340\n3900\n2.3\n[20]\nWHOI-Plankton\nImage\n103\n3,400,000\n\
    < 3500\n2,300,000\n657\n[21]\nPublic cameras\nImage\n19\n10,000\n14\n6986\n499\n\
    [18]\nCIFAR-100 (1)\nImage\n2\n6000\n150\n3000\n20\nCIFAR-100 (2)\nImage\n2\n\
    1200\n30\n600\n20\nCIFAR-100 (3)\nImage\n2\n1200\n30\n600\n20\n20 News Group (1)\
    \ Text\n2\n1200\n30\n600\n20\n20 News Group (2) Text\n2\n1200\n30\n600\n20\n[88]\n\
    COCO\nImage\n2\n115,000\n10\n100,000\n10,000\n[103]\nBuilding changes\nImage\n\
    6\n203,358\n222\n200,000\n900\n[89]\nGHW\nStructured 2\n2565\n406\n2159\n5.3\n\
    ORP\nStructured 2\n700\n124\n576\n4.6\n[19]\nMNIST\nImage\n10\n70,000\n600\n6000\n\
    10\nCIFAR-100\nImage\n100\n60,000\n60\n600\n10\nCALTECH-101\nImage\n102\n9144\n\
    15\n30\n2\nMIT-67\nImage\n67\n6700\n10\n100\n10\nDIL\nImage\n10\n1300\n24\n331\n\
    13\nMLC\nImage\n9\n400,000\n2600\n196,900\n76\n[90]\nKEEL\nStructured 2\n3339\n\
    26\n3313\n128\n[91]\nCIFAR-10\nImage\n10\n60,000\n250\n5000\n20\nCIFAR-100\nImage\n\
    100\n60,000\n25\n500\n20\n[22]\nCelebA\nImage\n2\n160,000\n3200\n156,800\n49\n\
    [117]\nMNIST\nImage\n10\n60,000\n50\n5000\n100\nMNIST-back-rot\nImage\n10\n62,000\n\
    12\n1200\n100\nCIFAR-10\nImage\n10\n60,000\n5000\n5000\n1\nSVHN\nImage\n10\n99,000\n\
    73\n7300\n100\nSTL-10\nImage\n10\n13,000\n500\n500\n1\n[118]\nCelebA\nImage\n\
    2\n160,000\n3200\n156,800\n49\n[92]\nEmotioNet\nImage\n2\n450,000\n45\n449,955\n\
    10,000\n[23]\nMNIST\nImage\n10\n60,000\n1\n5000\n5000\nCIFAR-10\nImage\n10\n60,000\n\
    100\n5000\n50\nImageNet\nImage\n1000\n1,050,000\n10\n1000\n100\nPage 47 of 54\n\
    Johnson and Khoshgoftaar  J Big Data            (2019) 6:27 \nAlgorithm-level\
    \ methods were explored by nine studies, and can be further broken \ndown into\
    \ new loss functions, cost-sensitive methods, output thresholding, and a deep\
    \ \nfeature 1-NN rule. MFE and MSFE loss functions [18] are modifications of the\
    \ MSE loss \nthat allow the positive and negative class to equally contribute\
    \ to the loss. The focal loss \nfunction [88, 103] improves classification by\
    \ down-weighting easy-to-classify samples, \npreventing easily-classified negative\
    \ samples from dominating the loss.   Wang et  al. \nmodified the CE loss slightly\
    \ to incorporate pre-defined class costs into the learning pro-\ncess, creating\
    \ an optimization process that minimizes total cost. The final two cost-sen-\n\
    sitive methods evaluated are unique in the sense that they iteratively improve\
    \ the cost \nmatrix throughout training, instead of requiring pre-defined costs.\
    \ The CoSen CNN [19] \nuses an additional loss function to learn the cost parameters\
    \ through backpropagation, \nwhile the CSDBN-DE [90] utilizes an evolutionary\
    \ algorithm to produce increasingly \nbetter cost values. Buda et al. used class\
    \ prior probabilities to adjust deep CNN output \nthresholds and reduce bias towards\
    \ the majority group. The category centers method \n[91] uses CNN-generated features\
    \ to calculate class centers in feature space, then uses \nthe 1-NN rule to classify\
    \ new data by its nearest class centroid. Very-deep CNNs (> 10 \nlayers) were\
    \ explored by Ding et al. to determine if deeper networks would converge \nfaster\
    \ than shallow networks when trained on imbalanced data.\nThree hybrid methods\
    \ that combine data-level and algorithm-level changes to address \nthe class imbalance\
    \ problem were compared to baselines and alternative methods. \nLMLE [22] combines\
    \ quintuplet sampling with the triple-header hinge loss to learn \nmore discriminative\
    \ features. The CRL loss function combined with hard sample mining \n[118] was\
    \ shown to improve representation learning and outperform LMLE. Ando and \nHuang\
    \ were the first to explore over-sampling in deep feature space, showing that\
    \ DOS \nis able to outperform LMLE on imbalanced image data.\nTwo-phase learning\
    \ [20] and dynamic sampling [21] both outperformed transfer \nlearning and augmentation\
    \ methods in classifying imbalanced image data. Buda et al. \npresented conflicting\
    \ results, however, that suggested that plain ROS performs better \nthan both\
    \ two-phase learning and RUS. Dong et al. showed that ROS and cost-sensi-\ntive\
    \ learning methods perform equivalently on the CelebA dataset, both outperforming\
    \ \nRUS and thresholding methods. Experiments by Khan et al., evaluated over six\
    \ data sets, \nshowed that a cost-sensitive CNN can outperform data sampling methods\
    \ with neural \nnetworks and cost-sensitive SVM and RF learners.  Wang et al.\
    \ deployed a state-of-the-\nart hospital readmission predictor built using a cost-sensitive\
    \ DNN that outperformed \nexisting models. A class balanced version of the MSE\
    \ loss, MFE and MSFE [18], showed \nimprovements in classifying imbalanced image\
    \ and text data. In [117], over-sampling in \nthe deep feature space is used to\
    \ perform classification on five data sets, showing that \nthe DOS framework can\
    \ outperform LMLE and TL-RS-CSL. The focal loss [88] function \nwas shown to outscore\
    \ leading one-stage and two-stage detectors on the COCO data \nset. The CRL loss\
    \ [118] outperformed LMLE, data sampling, cost-sensitive learning, and \nthresholding\
    \ on the CelebA facial attribute detection task.\nMultiple authors [19, 23, 79]\
    \ suggested the use of deep learning with ROS to address \nclass imbalance, showing\
    \ that ROS outperforms RUS in almost all cases. Buda et al. \nand Hensman and\
    \ Masko both suggest applying ROS until class imbalance is elimi-\nnated in the\
    \ training set, but experiments did not consider big data scenarios. We \nPage\
    \ 48 of 54\nJohnson and Khoshgoftaar  J Big Data            (2019) 6:27 \nbelieve\
    \ that applying ROS to this level will not hold when subjected to big data or\
    \ \nclass rarity. Duplicating such large volumes of data may cause over-fitting\
    \ and is very \ncomputationally expensive. In a contrastive example, Bauder et al.\
    \ [131] found RUS \nto be more effective than ROS when using traditional machine\
    \ learning algorithms \nto detect fraud in big data with class rarity. Future\
    \ work should consider these big \ndata scenarios, and should experiment with\
    \ RUS methods that remove duplicates and \nstrengthen class boundaries.\nAlmost\
    \ all (80%) of the surveyed works employed deep CNN architectures to \naddress\
    \ class imbalanced image data. Yet, all of the methods presented can be \nextended\
    \ to non-CNN architectures and non-image data. The popularity of CNNs, \nimage\
    \ classification, and object detection in the research community can be partly\
    \ \nattributed to popular benchmark data sets like MNIST and CIFAR, and the continu-\n\
    ous improvements being driven by competitive events like LSVRC. Class imbalance\
    \ \nis not limited to image data, and additional work must be done to evaluate\
    \ the use of \nthese deep learning class imbalance methods in other domains.\n\
    Approximately half of the studies used only one data set when evaluating their\
    \ deep \nlearning methods for addressing class imbalance. The authors are not\
    \ at fault for this, \nas most were focused on solving a specific problem or benchmark\
    \ task. However, \nmore comprehensive studies that evaluate these methods across\
    \ a wider range of data \nsets, with varying levels of class imbalance and complexity,\
    \ will better demonstrate \ntheir strengths and weaknesses. Also, only a third\
    \ of the studies indicate the number \nof rounds or repetitions executed for each\
    \ experiment. In other words, the remaining \ngroups either did not perform multiple\
    \ runs, or failed to include those details and pre-\nsented the most favorable\
    \ results. To their defense, training a deep learning model on a \nlarge data\
    \ set can take days or even weeks, making it difficult to conduct several rounds\
    \ \nof experiments. This creates several avenues for future research, as comparing\
    \ various \ndeep learning methods on many data sets with repetition will increase\
    \ confidence in \nresults and help guide future practitioners in model selection.\n\
    Less than half of the surveyed works experimented with data sets larger than 100,000\
    \ \nsamples. Lee et al. were the only ones to work with more than a million samples\
    \ con-\ntaining imbalanced data. Pouyanfar et al. provided a big data analytics\
    \ workflow to clas-\nsify fast-streaming network camera data, but their experiment\
    \ was limited to just 10,000 \nimages. This is an extremely important area of\
    \ research that demands attention if we \nexpect deep learning to provide big\
    \ data analytics solutions. It is also very likely that the \nmethods proposed\
    \ throughout this survey, e.g. ROS and RUS, will behave very differ-\nently in\
    \ the context of big data.\nIt is not currently possible to compare the methods\
    \ which have been presented \ndirectly, as they are evaluated across a variety\
    \ of data sets with varying levels of class \nimbalance, and results are reported\
    \ with inconsistent performance metrics. In addition, \nsome studies report contradictory\
    \ results, further suggesting that performance is highly \ndependent on problem\
    \ complexity, class representation, and the performance metrics \nreported. Overall,\
    \ there is a lack of evidence which distinguishes any one deep learning \nmethod\
    \ as superior for learning from class imbalanced data, and additional experiments\
    \ \nare required before such conclusions can be made.\nPage 49 of 54\nJohnson and\
    \ Khoshgoftaar  J Big Data            (2019) 6:27 \nConclusion\nTo the best of\
    \ our knowledge, this survey provides the most comprehensive analysis of \ndeep\
    \ learning methods for addressing the class imbalance data problem. Fifteen studies\
    \ \npublished between 2015 and 2018 are summarized and discussed, exploring a\
    \ number of \nadvanced techniques for learning from imbalanced data with DNNs.\
    \ It has been shown that \ntraditional machine learning techniques for handling\
    \ class imbalance can be extended to \ndeep learning models with success. The\
    \ survey also finds that nearly all research in this area \nhas been focused on\
    \ computer vision tasks with CNNs. Despite a growing demand for big \ndata analytics\
    \ solutions, there is very little research that properly evaluates deep learning\
    \ \nin the context of class imbalance and big data. Deep learning from class imbalanced\
    \ data is \nstill largely understudied, and statistical evidence which compares\
    \ newly published meth-\nods across a variety of data sets and imbalance levels\
    \ does not exist.\nSeveral areas for future work are apparent. Applying the newly\
    \ proposed methods to a \nlarger variety of data sets and class imbalance levels,\
    \ comparing results with multiple com-\nplementary performance metrics, and reporting\
    \ statistical evidence will help to identify the \npreferred deep learning method\
    \ for future applications containing class imbalance. Experi-\nmenting with deep\
    \ learning methods for addressing class imbalance in the context of big \ndata\
    \ and class rarity will prove valuable to the future of big data analytics. More\
    \ work is \nrequired with non-convolutional DNNs to determine if the methods presented\
    \ will gener-\nalize well to alternative architectures, e.g. MLPs and RNNs. Finally,\
    \ research that evaluates \nthe use of deep learning to address class imbalance\
    \ in non-image data is limited and should \nbe expanded upon.\nAbbreviations\n\
    ANN: artificial neural network; AP: average precision; AUC : area under the curve;\
    \ C2C: class-to-class; CE: cross entropy; \nCNN: convolutional neural network;\
    \ CRL: class rectification loss; CSDBN-DE: cost-sensitive deep belief network\
    \ with differ-\nential evolution; CSDNN: cost-sensitive deep neural network; DBN:\
    \ deep belief network; DNN: deep neural network; DOS: \ndeep over-sampling; ELM:\
    \ extreme learning machine; FAU: Facial Action Unit; FL: focal loss; FN: false\
    \ negative; FNE: false \nnegative error; FP: false positive; FPE: false positive\
    \ error; FPN: feature pyramid network; GHW: general hospital wards; \nGPU: graphics\
    \ processing unit; IoT: internet of things; K-NN: K-nearest neighbors; KEEL: Knowledge\
    \ Extraction based on \nEvolutionary Learning; LMLE: Large Margin Local Embedding;\
    \ LSVRC: Large Scale Visual Recognition Challenge; MFE: \nmean false error; MLP:\
    \ multilayer perceptron; MSE: mean squared error; MSFE: mean squared false error;\
    \ NPV: negative \npredictive value; OHEM: online hard example mining; ORP: operating\
    \ room pilot; PPV: positive predictive value; PR: \nprecision–recall; ReLU: rectified\
    \ linear unit; RF: random forest; RNN: recurrent neural network; ROC: receiver\
    \ operating \ncharacteristics; ROS: random over-sampling; RUS: random under-sampling;\
    \ SMOTE: Synthetic Minority Over-sampling \nTechnique; SVM: support vector machine;\
    \ TL-RS-CSL: triplet re-sampling with cost-sensitive learning; TN: true negative;\
    \ \nTNR: true negative rate; TP: true positive; TPR: true positive rate.\nAuthors’\
    \ contributions\nJMJ performed the literature review and drafted the manuscript.\
    \ TMK worked with JMJ to develop the article’s frame-\nwork and focus. TMK introduced\
    \ this topic to JMJ. Both authors read and approved the final manuscript.\nAcknowledgements\n\
    The authors would like to thank the anonymous reviewers for their constructive\
    \ evaluation of this paper, and the vari-\nous members of the Data Mining and\
    \ Machine Learning Laboratory, Florida Atlantic University, for assistance with\
    \ the \nreviews.\nCompeting interests\nThe authors declare that they have no competing\
    \ interests.\nAvailability of data and materials\nNot applicable.\nConsent for\
    \ publication\nNot applicable.\nEthics approval and consent to participate\nNot\
    \ applicable.\nPage 50 of 54\nJohnson and Khoshgoftaar  J Big Data           \
    \ (2019) 6:27 \nFunding\nNot applicable.\nPublisher’s Note\nSpringer Nature remains\
    \ neutral with regard to jurisdictional claims in published maps and institutional\
    \ affiliations.\nReceived: 9 January 2019   Accepted: 8 March 2019\nReferences\n\
    \ \n1. Witten IH, Frank E, Hall MA, Pal CJ. Data mining, Fourth Edition: Practical\
    \ machine learning tools and techniques. \n4th ed. San Francisco: Morgan Kaufmann\
    \ Publishers Inc.; 2016.\n \n2. Kotsiantis SB. Supervised machine learning: a\
    \ review of classification techniques. In: Proceedings of the 2007 \nconference\
    \ on emerging artificial intelligence applications in computer engineering: Real\
    \ Word AI Systems with \napplications in eHealth, HCI, Information Retrieval and\
    \ Pervasive Technologies. IOS Press, Amsterdam, The Nether-\nlands, The Netherlands;\
    \ 2007. p. 3–24. http://dl.acm.org/citat ion.cfm?id=15667 70.15667 73. Accessed\
    \ 15 Oct 2018.\n \n3. Rao RB, Krishnan S, Niculescu RS. Data mining for improved\
    \ cardiac care. SIGKDD Explor Newsl. 2006;8(1):3–10. \nhttps ://doi.org/10.1145/11472\
    \ 34.11472 36.\n \n4. Wei W, Li J, Cao L, Ou Y, Chen J. Effective detection of\
    \ sophisticated online banking fraud on extremely imbalanced \ndata. World Wide\
    \ Web. 2013;16(4):449–75. https ://doi.org/10.1007/s1128 0-012-0178-0.\n \n5.\
    \ Herland M, Khoshgoftaar TM, Bauder RA. Big data fraud detection using multiple\
    \ medicare data sources. J Big \nData. 2018;5(1):29. https ://doi.org/10.1186/s4053\
    \ 7-018-0138-3.\n \n6. Cieslak DA, Chawla NV, Striegel A. Combating imbalance\
    \ in network intrusion datasets. In: 2006 IEEE international \nconference on granular\
    \ computing. 2006. p. 732–7. https ://doi.org/10.1109/GRC.2006.16359 05.\n \n\
    7. Kubat M, Holte RC, Matwin S. Machine learning for the detection of oil spills\
    \ in satellite radar images. Mach Learn. \n1998;30(2):195–215. https ://doi.org/10.1023/A:10074\
    \ 52223 027.\n \n8. Bauder RA, Khoshgoftaar TM, Hasanin T. An empirical study\
    \ on class rarity in big data. In: 2018 17th IEEE interna-\ntional conference\
    \ on machine learning and applications (ICMLA). 2018. p. 785–90. https ://doi.org/10.1109/ICMLA\
    \ \n.2018.00125 .\n \n9. Bauder RA, Khoshgoftaar TM. The effects of varying class\
    \ distribution on learner behavior for medicare fraud \ndetection with imbalanced\
    \ big data. Health Inf Sci Syst. 2018;6(1):9. https ://doi.org/10.1007/s1375 5-018-0051-3.\n\
    \ 10. Krawczyk B. Learning from imbalanced data: open challenges and future directions.\
    \ Prog Artif Intell. \n2016;5(4):221–32. https ://doi.org/10.1007/s1374 8-016-0094-0.\n\
    \ 11. LeCun Y, Bengio Y, Hinton G. Deep learning. Nature. 2015;521:436.\n 12.\
    \ Abadi M, Agarwal A, Barham P, Brevdo E, Chen Z, Citro C, Corrado GS, Davis A,\
    \ Dean J, Devin M, Ghemawat S, \nGoodfellow I, Harp A, Irving G, Isard M, Jia\
    \ Y, Jozefowicz R, Kaiser L, Kudlur M, Levenberg J, Mané D, Monga R, \nMoore S,\
    \ Murray D, Olah C, Schuster M, Shlens J, Steiner B, Sutskever I, Talwar K, Tucker\
    \ P, Vanhoucke V, Vasudevan \nV, Viégas F, Vinyals O, Warden P, Wattenberg M,\
    \ Wicke M, Yu Y, Zheng X. TensorFlow: large-scale machine learning \non heterogeneous\
    \ systems 2015. http://tenso rflow .org/. Accessed 1 Nov 2018.\n 13. Theano Development\
    \ Team. Theano: a Python framework for fast computation of mathematical expressions.\
    \ \n2016. arXiv e-prints arXiv :1605.02688 .\n 14. Chollet F, et al. Keras. 2015.\
    \ https ://keras .io. Accessed 1 Nov 2018.\n 15. Paszke A, Gross S, Chintala S,\
    \ Chanan G, Yang E, DeVito Z, Lin Z, Desmaison A, Antiga L, Lerer A. Automatic\
    \ differen-\ntiation in pytorch. In: NIPS-W. 2017.\n 16. Chetlur S, Woolley C,\
    \ Vandermersch P, Cohen J, Tran J, Catanzaro B, Shelhamer, E. cudnn: Efficient\
    \ primitives for \ndeep learning 2014.\n 17. Krizhevsky A, Sutskever I, Hinton\
    \ GE. Imagenet classification with deep convolutional neural networks. In: Neural\
    \ \ninformation processing systems. 2012. p. 25. https ://doi.org/10.1145/30653\
    \ 86.\n 18. Wang S, Liu W, Wu J, Cao L, Meng Q, Kennedy PJ. Training deep neural\
    \ networks on imbalanced data sets. In: \n2016 international joint conference\
    \ on neural networks (IJCNN). 2016. p. 4368–74. https ://doi.org/10.1109/IJCNN\
    \ \n.2016.77277 70.\n 19. Khan SH, Hayat M, Bennamoun M, Sohel FA, Togneri R.\
    \ Cost-sensitive learning of deep feature representations \nfrom imbalanced data.\
    \ IEEE Trans Neural Netw Learn Syst. 2018;29:3573–87.\n 20. Lee H, Park M, Kim\
    \ J. Plankton classification on imbalanced large scale database via convolutional\
    \ neural networks \nwith transfer learning. In: 2016 IEEE international conference\
    \ on image processing (ICIP). 2016. p. 3713–7. https ://\ndoi.org/10.1109/ICIP.2016.75330\
    \ 53.\n 21. Pouyanfar S, Tao Y, Mohan A, Tian H, Kaseb AS, Gauen K, Dailey R,\
    \ Aghajanzadeh S, Lu Y, Chen S, Shyu M. Dynamic \nsampling in convolutional neural\
    \ networks for imbalanced data classification. In: 2018 IEEE conference on multi-\n\
    media information processing and retrieval (MIPR). 2018. p. 112–7. https ://doi.org/10.1109/MIPR.2018.00027\
    \ .\n 22. Huang C, Li Y, Loy CC, Tang X. Learning deep representation for imbalanced\
    \ classification. In: 2016 IEEE conference \non computer vision and pattern recognition\
    \ (CVPR). 2016. p. 5375–84. https ://doi.org/10.1109/CVPR.2016.580.\n 23. Buda\
    \ M, Maki A, Mazurowski MA. A systematic study of the class imbalance problem\
    \ in convolutional neural \nnetworks. Neural Netw. 2018;106:249–59. https ://doi.org/10.1016/j.neune\
    \ t.2018.07.011.\n 24. Brocke J.v, Simons A, Niehaves B, Riemer K, Plattfaut R,\
    \ Cleven A. Reconstructing the giant: on the importance of \nrigour in documenting\
    \ the literature search process. 2009.\n 25. Google Scholar. https ://schol ar.googl\
    \ e.com/. Accessed 15 Nov 2018.\n 26. IEEE Xplore Digital Library. https ://ieeex\
    \ plore .ieee.org. Accessed 15 Nov 2018.\nPage 51 of 54\nJohnson and Khoshgoftaar\
    \  J Big Data            (2019) 6:27 \n 27. Wang S, Yao X. Multiclass imbalance\
    \ problems: analysis and potential solutions. IEEE Trans Syst Man Cybern Part\
    \ B \n(Cybern). 2012;42(4):1119–30. https ://doi.org/10.1109/TSMCB .2012.21872\
    \ 80.\n 28. He H, Garcia EA. Learning from imbalanced data. IEEE Trans Knowl Data\
    \ Eng. 2009;21(9):1263–1284. https ://doi.\norg/10.1109/TKDE.2008.239.\n 29. Japkowicz\
    \ N. The class imbalance problem: Significance and strategies. In: In proceedings\
    \ of the 2000 interna-\ntional conference on artificial intelligence (ICAI). 2000;111–7.\n\
    \ 30. Seiffert C, Khoshgoftaar TM, Van Hulse J, Napolitano A. Mining data with\
    \ rare events: a case study. In: Proceedings \nof the 19th IEEE international\
    \ conference on tools with artificial intelligence—Vol. 02. ICTAI ’07, IEEE Computer\
    \ \nSociety, Washington, DC. 2007. p. 132–9. https ://doi.org/10.1109/ICTAI .2007.130.\n\
    \ 31. Weiss GM. Mining with rarity: a unifying framework. SIGKDD Explor Newsl.\
    \ 2004;6(1):7–19. https ://doi.\norg/10.1145/10077 30.10077 34.\n 32. Provost\
    \ F, Fawcett T. Analysis and visualization of classifier performance: comparison\
    \ under imprecise class and \ncost distributions. In: Proceedings of the third\
    \ international conference on knowledge discovery and data mining. \n1999. p.\
    \ 43–8.\n 33. Weng C.G, Poon J. A new evaluation measure for imbalanced datasets.\
    \ In: Proceedings of the 7th Australasian data \nmining conference—Vol. 87. AusDM\
    \ ’08. Australian Computer Society, Inc., Darlinghurst, Australia. 2008. p. 27–32.\
    \ \nhttp://dl.acm.org/citat ion.cfm?id=24492 88.24492 95.\n 34. Davis J, Goadrich\
    \ M. The relationship between precision-recall and roc curves. In: Proceedings\
    \ of the 23rd \ninternational conference on machine learning. ICML ’06. ACM, New\
    \ York, NY, USA. 2006. p. 233–40. https ://doi.\norg/10.1145/11438 44.11438 74.\n\
    \ 35. Seliya N, Khoshgoftaar T.M, Van Hulse J. A study on the relationships of\
    \ classifier performance metrics. In: 2009 \n21st IEEE international conference\
    \ on tools with artificial intelligence. 2009. p. 59–66. https ://doi.org/10.1109/ICTAI\
    \ \n.2009.25.\n 36. Brier GW. Verification of forecasts expressed in terms of\
    \ probability. Mon Weather Rev. 1950;78(1):1–3. https://doi.\norg/10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2\
    \ .\n 37. Van Hulse J, Khoshgoftaar TM, Napolitano A. Experimental perspectives\
    \ on learning from imbalanced data. In: \nProceedings of the 24th international\
    \ conference on machine learning. ICML ’07. ACM, New York, NY, USA. 2007. p. \n\
    935–42. https ://doi.org/10.1145/12734 96.12736 14.\n 38. Chawla NV, Japkowicz\
    \ N, Kotcz A. Editorial: Special issue on learning from imbalanced data sets.\
    \ SIGKDD Explor \nNewsl. 2004;6(1):1–6. https ://doi.org/10.1145/10077 30.10077\
    \ 33.\n 39. Zhang J, Mani I. KNN approach to unbalanced data distributions: a\
    \ case study involving information extraction. In: \nProceedings of the ICML’2003\
    \ workshop on learning from imbalanced datasets. 2003.\n 40. Kubat M, Matwin S.\
    \ Addressing the curse of imbalanced training sets: one-sided selection. In: Fourteenth\
    \ interna-\ntional conference on machine learning. 2000.\n 41. Tomek I. Two modifications\
    \ of cnn. IEEE Trans Syst Man Cybern. 1976;6:769–72.\n 42. Barandela R, Valdovinos\
    \ RM, Sánchez JS, Ferri FJ. The imbalanced training sample problem: under or over\
    \ \nsampling? In: Fred A, Caelli TM, Duin RPW, Campilho AC, de Ridder D, editors.\
    \ Structural, syntactic, and statistical \npattern recognition. Berlin: Springer;\
    \ 2004. p. 806–14.\n 43. Wilson DL. Asymptotic properties of nearest neighbor\
    \ rules using edited data. IEEE Trans Syst Man Cybern SMC. \n1972;2(3):408–21.\
    \ https ://doi.org/10.1109/TSMC.1972.43091 37.\n 44. Chawla NV, Bowyer KW, Hall\
    \ LO, Kegelmeyer WP. Smote: synthetic minority over-sampling technique. J Artif\
    \ Int \nRes. 2002;16(1):321–57.\n 45. Han H, Wang W-Y, Mao B-H. Borderline-smote:\
    \ a new over-sampling method in imbalanced data sets learning. In: \nHuang D-S,\
    \ Zhang X-P, Huang G-B, editors. Adv Intell Comput. Berlin: Springer; 2005. p.\
    \ 878–87.\n 46. Bunkhumpornpat C, Sinapiromsaran K, Lursinsap C. Safe-level-smote:\
    \ safe-level-synthetic minority over-sampling \ntechnique for handling the class\
    \ imbalanced problem. In: Theeramunkong T, Kijsirikul B, Cercone N, Ho T-B, editors.\
    \ \nAdvances in knowledge discovery and data mining. Berlin, Heidelberg: Springer;\
    \ 2009. p. 475–82.\n 47. Holte RC, Acker L, Porter BW. Concept learning and the\
    \ problem of small disjuncts. In: IJCAI. 1989.\n 48. Weiss G, Hirsh H. A quantitative\
    \ study of small disjuncts. In: In proceedings of the seventeenth national confer-\n\
    ence on artificial intelligence and twelfth conference on innovative applications\
    \ of artificial intelligence. 2000. p. \n665–70.\n 49. Jo T, Japkowicz N. Class\
    \ imbalances versus small disjuncts. SIGKDD Explor Newsl. 2004;6(1):40–9. https\
    \ ://doi.\norg/10.1145/10077 30.10077 37.\n 50. Elkan C. The foundations of cost-sensitive\
    \ learning. In: In Proceedings of the seventeenth international joint con-\nference\
    \ on artificial intelligence. 2001. p. 973–8.\n 51. Ling CX, Sheng VS. In: Sammut\
    \ C, editor. Cost-sensitive learning and the class imbalanced problem. 2007.\n\
    \ 52. Liu X, Wu J, Zhou Z. Exploratory undersampling for class-imbalance learning.\
    \ IEEE Trans Syst Man Cybern Part B \n(Cybern). 2009;39(2):539–50. https ://doi.org/10.1109/TSMCB\
    \ .2008.20078 53.\n 53. Chawla NV, Lazarevic A, Hall LO, Bowyer KW. Smoteboost:\
    \ improving prediction of the minority class in boosting. \nIn: Lavrač N, Gamberger\
    \ D, Todorovski L, Blockeel H, editors. Knowledge discovery in databases: PKDD\
    \ 2003. Berlin, \nHeidelberg: Springer; 2003. p. 107–19.\n 54. Guo H, Viktor HL.\
    \ Learning from imbalanced data sets with boosting and data generation: the databoost-im\
    \ \napproach. SIGKDD Explor Newsl. 2004;6(1):30–9. https ://doi.org/10.1145/10077\
    \ 30.10077 36.\n 55. Mease D, Wyner AJ, Buja A. Boosted classification trees and\
    \ class probability/quantile estimation. J Mach Learn \nRes. 2007;8:409–39.\n\
    \ 56. Sun Y. Cost-sensitive boosting for classification of imbalanced data. Ph.D.\
    \ thesis, Waterloo, Ont., Canada, Canada. \n2007. AAINR34548.\n 57. Vázquez F.\
    \ Deep Learning made easy with Deep Cognition. 2017. https ://becom inghu man.ai/deep-learn\
    \ ing-\nmade-easy-with-deep-cogni tion-403fb e4453 51. Accessed 10 Oct 2018.\n\
    \ 58. Lecun Y, Bottou L, Bengio Y, Haffner P. Gradient-based learning applied\
    \ to document recognition. Proc IEEE. \n1998;86(11):2278–324.\nPage 52 of 54\n\
    Johnson and Khoshgoftaar  J Big Data            (2019) 6:27 \n 59. Fukushima K.\
    \ Neocognitron: a self-organizing neural network model for a mechanism of pattern\
    \ recognition unaf-\nfected by shift in position. Biol Cybern. 1980;36(4):193–202.\
    \ https ://doi.org/10.1007/BF003 44251 .\n 60. Goodfellow I, Bengio Y, Courville\
    \ A. Deep learning. Cambridge: The MIT Press; 2016.\n 61. Minar MR, Naher J. Recent\
    \ advances in deep learning: an overview. 2018. arXiv :1807.08169 .\n 62. Schmidhuber\
    \ J. Deep learning in neural networks: an overview. Neural Netw. 2015;61:85–117.\n\
    \ 63. Rumelhart DE, Hinton GE, Williams RJ. Learning representations by back-propagating\
    \ errors. Nature. 1986;323:533.\n 64. LeCun Y, Boser B, Denker JS, Henderson D,\
    \ Howard RE, Hubbard W, Jackel LD. Backpropagation applied to hand-\nwritten zip\
    \ code recognition. Neural Comput. 1989;1(4):541–51. https ://doi.org/10.1162/neco.1989.1.4.541.\n\
    \ 65. Hinton GE, Osindero S, Teh Y-W. A fast learning algorithm for deep belief\
    \ nets. Neural Comput. 2006;18(7):1527–54. \nhttps ://doi.org/10.1162/neco.2006.18.7.1527.\n\
    \ 66. Bengio Y, Lamblin P, Popovici D, Larochelle H. Greedy layer-wise training\
    \ of deep networks. In: Proceedings of the \n19th international conference on\
    \ neural information processing systems. NIPS’06. MIT Press, Cambridge, MA, USA.\
    \ \n2006. p. 153–60. http://dl.acm.org/citat ion.cfm?id=29764 56.29764 76.\n 67.\
    \ Russakovsky O, Deng J, Su H, Krause J, Satheesh S, Ma S, Huang Z, Karpathy A,\
    \ Khosla A, Bernstein M, Berg AC, \nFei-Fei L. ImageNet large scale visual recognition\
    \ challenge. Int J Comput Vision (IJCV). 2015;115(3):211–52. https \n://doi.org/10.1007/s1126\
    \ 3-015-0816-y.\n 68. Shatnawi A, Al-Ayyoub M, Albdour G, Al-Qurran R. A comparative\
    \ study of open source deep learning frameworks. \nhttps ://doi.org/10.1109/IACS.2018.83554\
    \ 44.\n 69. Kumar M. An incorporation of artificial intelligence capabilities\
    \ in cloud computing. Int J Eng Comput Sci. 2016. \nhttps ://doi.org/10.18535\
    \ /ijecs /v5i11 .63.\n 70. Saiyeda A, Mir MA. Cloud computing for deep learning\
    \ analytics: a survey of current trends and challenges. Int J \nAdv Res Comput\
    \ Sci. 2017;8(2):68–72. https ://doi.org/10.26483 /ijarc s.v8i2.2931.\n 71. Elgendy\
    \ N, Elragal A. Big data analytics: a literature review paper. In: Perner P, editor.\
    \ Advances in data mining. \nApplications and theoretical aspects. Cham: Springer;\
    \ 2014. p. 214–27.\n 72. Dumbill E. What is big data? : an introduction to the\
    \ big data landscape. 2012. http://radar .oreil ly.com/2012/01/\nwhat-is-big-data.html\n\
    \ 73. Ahmed SE. Perspectives on Big Data analysis: methodologies and applications.\
    \ Providence: American Mathemati-\ncal Society; 2014.\n 74. Leevy JL, Khoshgoftaar\
    \ TM, Bauder RA, Seliya N. A survey on addressing high-class imbalance in big\
    \ data. J Big \nData. 2018;5(1):42. https ://doi.org/10.1186/s4053 7-018-0151-6.\n\
    \ 75. Najafabadi MM, Villanustre F, Khoshgoftaar TM, Seliya N, Wald R, Muharemagic\
    \ E. Deep learning applications and \nchallenges in big data analytics. J Big\
    \ Data. 2015;2(1):1. https ://doi.org/10.1186/s4053 7-014-0007-7.\n 76. Hinton\
    \ G, Salakhutdinov R. Discovering binary codes for documents by learning deep\
    \ generative models. Top \nCogn Sci. 2011;3(1):74–91.\n 77. Salakhutdinov R, Hinton\
    \ G. Semantic hashing. Int J Approx Reason. 2009;50(7):969–78. https ://doi.org/10.1016/j.\n\
    ijar.2008.11.006.\n 78. Anand R, Mehrotra KG, Mohan CK, Ranka S. An improved algorithm\
    \ for neural network classification of imbal-\nanced training sets. IEEE Trans\
    \ Neural Netw. 1993;4(6):962–9. https ://doi.org/10.1109/72.28689 1.\n 79. Hensman\
    \ P, Masko D. The impact of imbalanced training data for convolutional neural\
    \ networks. 2015.\n 80. Krizhevsky A, Nair V, Hinton G. Cifar-10 (Canadian Institute\
    \ for Advanced Research).\n 81. Orenstein EC, Beijbom O, Peacock E, Sosik H. Whoi-plankton—a\
    \ large scale fine grained visual recognition bench-\nmark dataset for plankton\
    \ classification. CoRR, 2015.\n 82. Havaei M, Davy A, Warde-Farley D, Biard A,\
    \ Courville A, Bengio Y, Pal C, Jodoin P-M, Larochelle H. Brain tumor \nsegmentation\
    \ with deep neural networks. Med Image Anal. 2017;35:18–31. https ://doi.org/10.1016/j.media\
    \ \n.2016.05.004.\n 83. Szegedy C, Vanhoucke V, Ioffe S, Shlens J, Wojna Z. Rethinking\
    \ the inception architecture for computer vision. In: \nIEEE conference on computer\
    \ vision and pattern recognition (CVPR). vol. 2016. 2016. p. 2818–26.\n 84. Deng\
    \ J, Dong W, Socher R, Li LJ, Li K, Fei-Fei L. ImageNet: a large-scale hierarchical\
    \ image database. In: CVPR09. \n2009.\n 85. Simonyan K, Zisserman A. Very deep\
    \ convolutional networks for large-scale image recognition. CoRR. 2014. arXiv\
    \ \n:1409.1556.\n 86. LeCun Y, Cortes C. MNIST handwritten digit database. 2010.\
    \ http://yann.lecun .com/exdb/mnist /. Accessed 15 Nov \n2018.\n 87. Springenberg\
    \ JT, Dosovitskiy A, Brox T, Riedmiller MA. Striving for simplicity: the all convolutional\
    \ net. CoRR. 2014. \narXiv :1412.6806.\n 88. Lin T-Y, Goyal P, Girshick RB, He\
    \ K, Dollár P. Focal loss for dense object detection. In: IEEE international conference\
    \ \non computer vision (ICCV). vol. 2017. 2017. p. 2999–3007.\n 89. Wang H, Cui\
    \ Z, Chen Y, Avidan M, Abdallah AB, Kronzer A. Predicting hospital readmission\
    \ via cost-sensitive \ndeep learning. IEEE/ACM transactions on computational biology\
    \ and bioinformatics. 2018. p. 1–1. https ://doi.\norg/10.1109/TCBB.2018.28270\
    \ 29.\n 90. Zhang C, Tan KC, Ren R. Training cost-sensitive deep belief networks\
    \ on imbalance data problems. In: 2016 inter-\nnational joint conference on neural\
    \ networks (IJCNN). 2016. p. 4362–7. https ://doi.org/10.1109/IJCNN .2016.77277\
    \ \n69.\n 91. Zhang Y, Shuai L, Ren Y, Chen H. Image classification with category\
    \ centers in class imbalance situation. In: 2018 \n33rd Youth Academic annual\
    \ conference of Chinese Association of Automation (YAC). 2018. p. 359–63. https\
    \ ://doi.\norg/10.1109/YAC.2018.84064 00.\n 92. Ding W, Huang D, Chen Z, Yu X,\
    \ Lin W. Facial action recognition using very deep networks for highly imbalanced\
    \ \nclass distribution. In: 2017 Asia-Pacific signal and information processing\
    \ association annual summit and confer-\nence (APSIPA ASC). 2017. p. 1368–72.\
    \ https ://doi.org/10.1109/APSIP A.2017.82822 46.\n 93. Krizhevsky A, Nair V,\
    \ Hinton G. Cifar-100 (Canadian Institute for Advanced Research).\n 94. 20 Newsgroups\
    \ Dataset. http://peopl e.csail .mit.edu/jrenn ie/20New sgrou ps/. Accessed  15\
    \ Oct 2018.\nPage 53 of 54\nJohnson and Khoshgoftaar  J Big Data            (2019)\
    \ 6:27 \n 95. Girshick RB, Donahue J, Darrell T, Malik J. Rich feature hierarchies\
    \ for accurate object detection and semantic \nsegmentation. In: IEEE conference\
    \ on computer vision and pattern recognition. Vol. 2014. 2014. p. 580–7.\n 96.\
    \ Liu W, Anguelov D, Erhan D, Szegedy C, Reed S, Fu C-Y, Berg AC. Ssd: Single\
    \ shot multibox detector. In: Leibe B, \nMatas J, Sebe N, Welling M, editors.\
    \ Computer Vision-ECCV 2016. Cham: Springer; 2016. p. 21–37.\n 97. Redmon J, Divvala\
    \ S, Girshick R, Farhadi A. You only look once: unified, real-time object detection.\
    \ In: 2016 \nIEEE conference on computer vision and pattern recognition (CVPR).\
    \ 2016. p. 779–88. https ://doi.org/10.1109/\nCVPR.2016.91.\n 98. He K, Zhang\
    \ X, Ren S, Sun J. Deep residual learning for image recognition. In: IEEE conference\
    \ on computer vision \nand pattern recognition (CVPR), vol. 2016. 2016. p. 770–8.\n\
    \ 99. Lin T-Y, Maire M, Belongie SJ, Bourdev LD, Girshick RB, Hays J, Perona P,\
    \ Ramanan D, Dollár P, Zitnick CL. Microsoft \ncoco: common objects in context.\
    \ In: ECCV. 2014.\n 100. Fu C, Liu W, Ranga A, Tyagi A, Berg AC. DSSD: deconvolutional\
    \ single shot detector. CoRR. 2017. arXiv :1701.06659 .\n 101. Shrivastava A,\
    \ Sukthankar R, Malik J, Gupta A. Beyond skip connections: top-down modulation\
    \ for object detec-\ntion. CoRR. 2016. arXiv :1612.06851 .\n 102. Shrivastava\
    \ A, Gupta A, Girshick RB. Training region-based object detectors with online\
    \ hard example mining. In: \n2016 IEEE conference on computer vision and pattern\
    \ recognition (CVPR). 2016. p. 761–9.\n 103. Nemoto K, Hamaguchi R, Imaizumi T,\
    \ Hikosaka S. Classification of rare building change using cnn with multi-class\
    \ \nfocal loss. In: IGARSS 2018—2018 IEEE international geoscience and remote\
    \ sensing symposium. 2018. p. 4663–6. \nhttps ://doi.org/10.1109/IGARS S.2018.85175\
    \ 63.\n 104. Li FF, Andreetto M, Ranzato MA. Caltech101 image dataset. 2003.\n\
    \ 105. Quattoni A, Torralba A. Recognizing indoor scenes. In: 2009 IEEE conference\
    \ on computer vision and pattern \nrecognition(CVPR). 2009. p. 413–20. https ://doi.org/10.1109/CVPRW\
    \ .2009.52065 37.\n 106. The University of Edinburgh: Edinburgh Dermofit Image\
    \ Library. https ://licen sing.eri.ed.ac.uk/i/softw are/dermo \nfit-image -libra\
    \ ry.html. Accessed 5 Nov 2018.\n 107. Beijbom O, Edmunds PJ, Kline DI, Mitchell\
    \ BG, Kriegman D. Automated annotation of coral reef survey images. In: \nIEEE\
    \ conference on computer vision and pattern recognition (CVPR), Providence, Rhode\
    \ Island. 2012.\n 108. Chung YA, Lin HT, Yang SW. Cost-aware pre-training for\
    \ multiclass cost-sensitive deep learning. In: IJCAI. 2016.\n 109. Ramentol E,\
    \ Caballero Y, Bello R, Herrera F. Smote-rsb*: a hybrid preprocessing approach\
    \ based on oversam-\npling and undersampling for high imbalanced data-sets using\
    \ smote and rough sets theory. Knowl Inf Syst. \n2012;33(2):245–65. https ://doi.org/10.1007/s1011\
    \ 5-011-0465-6.\n 110. Qiu X, Xu J, Tan KC, Abbass HA. Adaptive cross-generation\
    \ differential evolution operators for multiobjective \noptimization. IEEE Trans\
    \ Evol Comput. 2016;20(2):232–44. https ://doi.org/10.1109/TEVC.2015.24336 72.\n\
    \ 111. Alcalá-Fdez J, Sánchez L, García S, del Jesus MJ, Ventura S, Garrell JM,\
    \ Otero J, Romero C, Bacardit J, Rivas VM, \nFernández JC, Herrera F. Keel: a\
    \ software tool to assess evolutionary algorithms for data mining problems. Soft\
    \ \nComput. 2009;13(3):307–18. https ://doi.org/10.1007/s0050 0-008-0323-y.\n\
    \ 112. Huang G-B, Zhu Q-Y, Siew C. Extreme learning machine: theory and applications.\
    \ Neurocomputing. 2006;70:489–\n501. https ://doi.org/10.1016/j.neuco m.2005.12.126.\n\
    \ 113. Choromanska A, Henaff M, Mathieu M, Arous GB, LeCun Y. The loss surfaces\
    \ of multilayer networks. In: AISTATS. \n2015.\n 114. Kawaguchi K. Deep learning\
    \ without poor local minima. In: Lee DD, Sugiyama M, Luxburg UV, Guyon I, Garnett\
    \ R, \neditors. Advances in neural information processing systems 29. Red Hook:\
    \ Curran Associates Inc; 2016. p. 586–94.\n 115. Ekman P, Friesen W. Facial action\
    \ coding system: a technique for the measurement of facial movement. Palo Alto:\
    \ \nConsulting Psychologists Press; 1978.\n 116. Benitez-Quiroz CF, Srinivasan\
    \ R, Feng Q, Wang Y, Martínez AM. Emotionet challenge: recognition of facial expres-\n\
    sions of emotion in the wild. CoRR. 2017. arXiv :1703.01210 .\n 117. Ando S, Huang\
    \ CY. Deep over-sampling framework for classifying imbalanced data. In: Ceci M,\
    \ Hollmén J, Todor-\novski L, Vens C, Džeroski S, editors. Machine learning and\
    \ knowledge discovery in databases. Cham: Springer; \n2017. p. 770–85.\n 118.\
    \ Dong Q, Gong S, Zhu X. Imbalanced deep learning by minority class incremental\
    \ rectification. In: IEEE transactions \non pattern analysis and machine intelligence.\
    \ 2018. p. 1–1 https ://doi.org/10.1109/TPAMI .2018.28326 29.\n 119. Liu Z, Luo\
    \ P, Wang X, Tang X. Deep learning face attributes in the wild. In: Proceedings\
    \ of international conference \non computer vision (ICCV). 2015.\n 120. Schroff\
    \ F, Kalenichenko D, Philbin J. Facenet: a unified embedding for face recognition\
    \ and clustering. In: IEEE \nconference on computer vision and pattern recognition\
    \ (CVPR). vol. 2015. 2015. p. 815–23.\n 121. Zhang N, Paluri M, Ranzato M, Darrell\
    \ T, Bourdev L. Panda: pose aligned networks for deep attribute modeling. In:\
    \ \nProceedings of the IEEE computer society conference on computer vision and\
    \ pattern recognition. 2013. https ://\ndoi.org/10.1109/CVPR.2014.212.\n 122.\
    \ Liu Z, Luo P, Wang X, Tang X. Deep learning face attributes in the wild. In:\
    \ 2015 IEEE international conference on \ncomputer vision (ICCV). 2015. p. 3730–8.\
    \ https ://doi.org/10.1109/ICCV.2015.425.\n 123. Arbelaez P, Maire M, Fowlkes\
    \ C, Malik J. Contour detection and hierarchical image segmentation. IEEE Trans\
    \ Pattern \nAnal Mach Intell. 2011;33(5):898–916. https ://doi.org/10.1109/TPAMI\
    \ .2010.161.\n 124. Netzer Y, Wang T, Coates A, Bissacco A, Wu B, Ng AY. Reading\
    \ digits in natural images with unsupervised feature \nlearning. In: NIPS workshop\
    \ on deep learning and unsupervised feature Learning 2011. 2011.\n 125. Coates\
    \ A, Ng A, Lee H. An analysis of single-layer networks in unsupervised feature\
    \ learning. In: Gordon, G., \nDunson, D., Dudík, M, editors. Proceedings of the\
    \ fourteenth international conference on artificial intelligence and \nstatistics.\
    \ Proceedings of machine learning research. Vol. 15. PMLR, Fort Lauderdale, FL,\
    \ USA. 2011. p. 215–23.\n 126. Liu T-Y. Learning to rank for information retrieval.\
    \ Found Trends Inf Retr. 2009;3(3):225–331. https ://doi.\norg/10.1561/15000 00016\
    \ .\n 127. Chen Q, Huang J, Feris R, Brown LM, Dong J, Yan S. Deep domain adaptation\
    \ for describing people based on fine-\ngrained clothing attributes. In: 2015\
    \ IEEE conference on computer vision and pattern recognition (CVPR). 2015. p.\
    \ \n5315–24. https ://doi.org/10.1109/CVPR.2015.72991 69.\nPage 54 of 54\nJohnson and\
    \ Khoshgoftaar  J Big Data            (2019) 6:27 \n 128. Sun Y, Wang X, Tang\
    \ X. Deep learning face representation by joint identification-verification. In:\
    \ NIPS. 2014.\n 129. Krizhevsky A. Learning multiple layers of features from tiny\
    \ images. University of Toronto. 2012.\n 130. Huang G, Liu Z, Weinberger KQ. Densely\
    \ connected convolutional networks. CoRR. 2016. arXiv :1608.06993 .\n 131. Bauder\
    \ RA, Khoshgoftaar TM, Hasanin T. Data sampling approaches with severely imbalanced\
    \ big data for medi-\ncare fraud detection. In: 2018 IEEE 30th international conference\
    \ on tools with artificial intelligence (ICTAI). 2018. p. \n137–42. https ://doi.org/10.1109/ICTAI\
    \ .2018.00030 .\n"
  inline_citation: '>'
  journal: Journal of big data
  limitations: '>'
  pdf_link: https://journalofbigdata.springeropen.com/track/pdf/10.1186/s40537-019-0192-5
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: Survey on deep learning with class imbalance
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.2118/1218-0067-jpt
  analysis: '>'
  authors:
  - Adam Wilson
  citation_count: 2
  full_citation: '>'
  full_text: '>

    Advertisement All Content All Journals Journal of Petroleum Technology                              Advanced
    Search Cart Register Sign In HOME LATEST ISSUE ALL ISSUES OTHER JOURNALS VISIT
    SPE CITATION MANAGER Volume 70, Issue 12 December 2018 Previous Article Next Article
    JOURNAL PAPER| DECEMBER 01 2018 Real-Time Data Analytics Allows for Bit-Wear Monitoring
    and Prediction Adam Wilson J Pet Technol 70 (12): 67–68. Paper Number: SPE-1218-0067-JPT
    https://doi.org/10.2118/1218-0067-JPT Article history Connected Content Related
    to: Real-Time Bit Wear Monitoring and Prediction Using Surface Mechanics Data
    Analytics: A Step Toward Digitization Through Agile Development Cite Share Get
    Permissions This article, written by Special Publications Editor Adam Wilson,
    contains highlights of paper SPE 189602, “Real-Time Bit-Wear Monitoring and Prediction
    Using Surface Mechanics Data Analytics: A Step Toward Digitization Through Agile
    Development,” by Yu Liu, Justin Kibbey, Yanbin Bai, and Xianping Wu, SPE, Shell,
    prepared for the 2018 IADC/SPE Drilling Technology Conference and Exhibition,
    Fort Worth, Texas, USA, 6–8 March. The paper has not been peer reviewed. Severe
    bit damage is an issue in West Texas land drilling because of abrasive sand formation
    and interbedded hard stringers. Operational performance and rig costs often are
    affected by bits damaged beyond repair (DBR), low rates of penetration (ROPs)
    with worn bits, and inefficient decision-making regarding tripping. A real-time
    data-analytics application is developed that aims to provide information to operators
    to expedite decision-making. Introduction As bottomhole-assembly (BHA) design
    and bit selection have become standardized, a historical data set of surface mechanics
    data and bit records has been accumulated from 40 bit runs. By combining conventional
    physical modeling of drilling mechanics and supervised machine learning, a hybrid
    analysis is conducted to separate bit-failure patterns from normal formation transitions
    and drilling-parameter adjustments. A metric-based algorithm is constructed for
    real-time monitoring of bit performance and for predicting bit wear. A lightweight
    web-based framework is used for deployment in real time. A shadow mode trial on
    three wells in the same pad was conducted and generated satisfactory results.
    Agile-Development Framework The agile-development framework is an integrated platform
    for fast technology prototyping, which consists of the following components: The
    Amazon cloud server is the platform for the application repository, computing-engine
    execution, and data stream and storage. Most real-time data-analytics applications
    are delivered as software-as-service, where the algorithm-processed data is stored
    on the cloud server and pertinent results are delivered to end-users over the
    web. User interaction with the web application is limited to default viewing options,
    and other data exchanges such as value inputs are kept to a minimum to reduce
    complexity. MATLAB and Python are the engines for algorithm development, prototyping,
    and early-stage deployment. MATLAB is a powerful engineering computing/coding
    program with strong capability in data management, visualization, and debugging.
    It provides various toolboxes for signal processing, machine learning, and statistical
    analysis. Python is an alternative to MATLAB with similar functionality and the
    advantage of being open source. Codes of data preprocessing, core algorithms,
    and data stream input/output (I/O) are realized in the MATLAB environment running
    on the Amazon cloud server. Wellsite Information Transfer Standard Markup Language
    (WITSML) I/O is the industrial standard for drilling-data stream and management.
    In this application, surface mechanics drilling data are streamed into MATLAB
    using a WITSML wrapper. Plotly is a solution for visualization on the web and
    user interface. Computation results from MATLAB are delivered to a web page by
    calling Plotly functions within the MATLAB environment. Keywords: data mining,
    real time system, information fusion, bit selection, Upstream Oil & Gas, on-bottom
    drilling hour, Artificial Intelligence, bit wear, drilling parameter, machine
    learning Subjects: Bit - rock interactions, Data mining, Drill Bits, Information
    Management and Systems This content is only available via PDF. 2018. IADC/SPE
    Drilling Technology Conference and Exhibition You can access this article if you
    purchase or spend a download. Sign in Don''t already have an account? Register
    Personal Account Username Password SIGN IN Reset password Register Sign in via
    OpenAthens Pay-Per-View Access $10.00 BUY THIS ARTICLE Annual Article Package
    – 25 $225 BUY DOWNLOADS Annual Article Package – 50 $400 BUY DOWNLOADS View Your
    Downloads Advertisement 2 View Metrics Cited By Google Scholar CrossRef (2) Email
    Alerts Article Activity Alert Latest Issue Alert Latest Most Read Most Cited Chemical
    Additives Assist Oil-in-Water Emulsion Formation in SAGD Case Study: Innovative
    Sand-Screen Technology Resolves Offshore Nigeria Water-Injection Issues Hybrid
    Technology Incorporated Into Colombian Heavy Oil Field Development Plan Comments:
    Navigating Tax Credits Challenges for the Hydrogen Spectrum Advertisement Suggested
    Reading Real-Time Bit Wear Monitoring and Prediction Using Surface Mechanics Data
    Analytics: A Step Toward Digitization Through Agile Development 18DC Real-Time
    Bit Wear Optimization Using the Intelligent Drilling Advisory System 10ROGC Real-Time
    Bit Wear Prediction Using Adaptive Data Analytics 17ATCE New HT/HP Technology
    for Geothermal Application Significantly Increases On-Bottom Drilling Hours 12DC
    Artificial Neural Network Drilling Parameter Optimization System Improves ROP
    by Predicting/Managing Bit Wear 12IE Advertisement Online ISSN 1944-978X Print
    ISSN 0149-2136 Explore Journals Conferences eBooks Publishers Connect About Us
    Contact Us Content Alerts SPE Member Pricing Resources Terms of Use Privacy Help
    KBART Engage Subscribe Advertise   This site uses cookies. By continuing to use
    our website, you are agreeing to our privacy policy. Accept'
  inline_citation: '>'
  journal: Journal of petroleum technology
  limitations: '>'
  pdf_link: null
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: Real-Time Data Analytics Allows for Bit-Wear Monitoring and Prediction
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1155/2017/9324035
  analysis: '>'
  authors:
  - Pallavi Sethi
  - Smruti R. Sarangi
  citation_count: 910
  full_citation: '>'
  full_text: '>

    Journals Publish with us Publishing partnerships About us Blog Journal of Electrical
    and Computer Engineering Journal overview For authors For reviewers For editors
    Table of Contents Special Issues Journal of Electrical and Computer Engineering/
    2017/ Article On this page Abstract Introduction Conclusion References Copyright
    Related Articles Review Article | Open Access Volume 2017 | Article ID 9324035
    | https://doi.org/10.1155/2017/9324035 Show citation Internet of Things: Architectures,
    Protocols, and Applications Pallavi Sethi1and Smruti R. Sarangi 1 Show more Academic
    Editor: Rajesh Khanna Received 12 Aug 2016 Accepted 18 Dec 2016 Published 26 Jan
    2017 Abstract The Internet of Things (IoT) is defined as a paradigm in which objects
    equipped with sensors, actuators, and processors communicate with each other to
    serve a meaningful purpose. In this paper, we survey state-of-the-art methods,
    protocols, and applications in this new emerging area. This survey paper proposes
    a novel taxonomy for IoT technologies, highlights some of the most important technologies,
    and profiles some applications that have the potential to make a striking difference
    in human life, especially for the differently abled and the elderly. As compared
    to similar survey papers in the area, this paper is far more comprehensive in
    its coverage and exhaustively covers most major technologies spanning from sensors
    to applications. 1. Introduction Today the Internet has become ubiquitous, has
    touched almost every corner of the globe, and is affecting human life in unimaginable
    ways. However, the journey is far from over. We are now entering an era of even
    more pervasive connectivity where a very wide variety of appliances will be connected
    to the web. We are entering an era of the “Internet of Things” (abbreviated as
    IoT). This term has been defined by different authors in many different ways.
    Let us look at two of the most popular definitions. Vermesan et al. [ 1] define
    the Internet of Things as simply an interaction between the physical and digital
    worlds. The digital world interacts with the physical world using a plethora of
    sensors and actuators. Another definition by Peña-López et al. [ 2] defines the
    Internet of Things as a paradigm in which computing and networking capabilities
    are embedded in any kind of conceivable object. We use these capabilities to query
    the state of the object and to change its state if possible. In common parlance,
    the Internet of Things refers to a new kind of world where almost all the devices
    and appliances that we use are connected to a network. We can use them collaboratively
    to achieve complex tasks that require a high degree of intelligence. For this
    intelligence and interconnection, IoT devices are equipped with embedded sensors,
    actuators, processors, and transceivers. IoT is not a single technology; rather
    it is an agglomeration of various technologies that work together in tandem. Sensors
    and actuators are devices, which help in interacting with the physical environment.
    The data collected by the sensors has to be stored and processed intelligently
    in order to derive useful inferences from it. Note that we broadly define the
    term sensor; a mobile phone or even a microwave oven can count as a sensor as
    long as it provides inputs about its current state (internal state + environment).
    An actuator is a device that is used to effect a change in the environment such
    as the temperature controller of an air conditioner. The storage and processing
    of data can be done on the edge of the network itself or in a remote server. If
    any preprocessing of data is possible, then it is typically done at either the
    sensor or some other proximate device. The processed data is then typically sent
    to a remote server. The storage and processing capabilities of an IoT object are
    also restricted by the resources available, which are often very constrained due
    to limitations of size, energy, power, and computational capability. As a result
    the main research challenge is to ensure that we get the right kind of data at
    the desired level of accuracy. Along with the challenges of data collection, and
    handling, there are challenges in communication as well. The communication between
    IoT devices is mainly wireless because they are generally installed at geographically
    dispersed locations. The wireless channels often have high rates of distortion
    and are unreliable. In this scenario reliably communicating data without too many
    retransmissions is an important problem and thus communication technologies are
    integral to the study of IoT devices. Now, after processing the received data,
    some action needs to be taken on the basis of the derived inferences. The nature
    of actions can be diverse. We can directly modify the physical world through actuators.
    Or we may do something virtually. For example, we can send some information to
    other smart things. The process of effecting a change in the physical world is
    often dependent on its state at that point of time. This is called context awareness.
    Each action is taken keeping in consideration the context because an application
    can behave differently in different contexts. For example, a person may not like
    messages from his office to interrupt him when he is on vacation. Sensors, actuators,
    compute servers, and the communication network form the core infrastructure of
    an IoT framework. However, there are many software aspects that need to be considered.
    First, we need a middleware that can be used to connect and manage all of these
    heterogeneous components. We need a lot of standardization to connect many different
    devices. We shall discuss methods to exchange information and prevailing standards
    in Section 7. The Internet of Things finds various applications in health care,
    fitness, education, entertainment, social life, energy conservation, environment
    monitoring, home automation, and transport systems. We shall focus on these application
    areas in Section 9. We shall find that, in all these application areas, IoT technologies
    have significantly been able to reduce human effort and improve the quality of
    life. 2. Architecture of IoT There is no single consensus on architecture for
    IoT, which is agreed universally. Different architectures have been proposed by
    different researchers. 2.1. Three- and Five-Layer Architectures The most basic
    architecture is a three-layer architecture [ 3– 5] as shown in Figure 1. It was
    introduced in the early stages of research in this area. It has three layers,
    namely, the perception, network, and application layers. (i) The perception layer
    is the physical layer, which has sensors for sensing and gathering information
    about the environment. It senses some physical parameters or identifies other
    smart objects in the environment. (ii) The network layer is responsible for connecting
    to other smart things, network devices, and servers. Its features are also used
    for transmitting and processing sensor data. (iii) The application layer is responsible
    for delivering application specific services to the user. It defines various applications
    in which the Internet of Things can be deployed, for example, smart homes, smart
    cities, and smart health.    Figure 1  Architecture of IoT (A: three layers) (B:
    five layers). The three-layer architecture defines the main idea of the Internet
    of Things, but it is not sufficient for research on IoT because research often
    focuses on finer aspects of the Internet of Things. That is why, we have many
    more layered architectures proposed in the literature. One is the five-layer architecture,
    which additionally includes the processing and business layers [ 3– 6]. The five
    layers are perception, transport, processing, application, and business layers
    (see Figure 1). The role of the perception and application layers is the same
    as the architecture with three layers. We outline the function of the remaining
    three layers. (i) The transport layer transfers the sensor data from the perception
    layer to the processing layer and vice versa through networks such as wireless,
    3G, LAN, Bluetooth, RFID, and NFC. (ii) The processing layer is also known as
    the middleware layer. It stores, analyzes, and processes huge amounts of data
    that comes from the transport layer. It can manage and provide a diverse set of
    services to the lower layers. It employs many technologies such as databases,
    cloud computing, and big data processing modules. (iii) The business layer manages
    the whole IoT system, including applications, business and profit models, and
    users’ privacy. The business layer is out of the scope of this paper. Hence, we
    do not discuss it further. Another architecture proposed by Ning and Wang [ 7]
    is inspired by the layers of processing in the human brain. It is inspired by
    the intelligence and ability of human beings to think, feel, remember, make decisions,
    and react to the physical environment. It is constituted of three parts. First
    is the human brain, which is analogous to the processing and data management unit
    or the data center. Second is the spinal cord, which is analogous to the distributed
    network of data processing nodes and smart gateways. Third is the network of nerves,
    which corresponds to the networking components and sensors. 2.2. Cloud and Fog
    Based Architectures Let us now discuss two kinds of systems architectures: cloud
    and fog computing (see the reference architectures in [ 8]). Note that this classification
    is different from the classification in Section 2.1, which was done on the basis
    of protocols. In particular, we have been slightly vague about the nature of data
    generated by IoT devices, and the nature of data processing. In some system architectures
    the data processing is done in a large centralized fashion by cloud computers.
    Such a cloud centric architecture keeps the cloud at the center, applications
    above it, and the network of smart things below it [ 9]. Cloud computing is given
    primacy because it provides great flexibility and scalability. It offers services
    such as the core infrastructure, platform, software, and storage. Developers can
    provide their storage tools, software tools, data mining, and machine learning
    tools, and visualization tools through the cloud. Lately, there is a move towards
    another system architecture, namely, fog computing [ 10– 12], where the sensors
    and network gateways do a part of the data processing and analytics. A fog architecture
    [ 13] presents a layered approach as shown in Figure 2, which inserts monitoring,
    preprocessing, storage, and security layers between the physical and transport
    layers. The monitoring layer monitors power, resources, responses, and services.
    The preprocessing layer performs filtering, processing, and analytics of sensor
    data. The temporary storage layer provides storage functionalities such as data
    replication, distribution, and storage. Finally, the security layer performs encryption/decryption
    and ensures data integrity and privacy. Monitoring and preprocessing are done
    on the edge of the network before sending data to the cloud.    Figure 2  Fog
    architecture of a smart IoT gateway. Often the terms “fog computing” and “edge
    computing” are used interchangeably. The latter term predates the former and is
    construed to be more generic. Fog computing originally termed by Cisco refers
    to smart gateways and smart sensors, whereas edge computing is slightly more penetrative
    in nature. This paradigm envisions adding smart data preprocessing capabilities
    to physical devices such as motors, pumps, or lights. The aim is to do as much
    of preprocessing of data as possible in these devices, which are termed to be
    at the edge of the network. In terms of the system architecture, the architectural
    diagram is not appreciably different from Figure 2. As a result, we do not describe
    edge computing separately. Finally, the distinction between protocol architectures
    and system architectures is not very crisp. Often the protocols and the system
    are codesigned. We shall use the generic 5-layer IoT protocol stack (architectural
    diagram presented in Figure 2) for both the fog and cloud architectures. 2.3.
    Social IoT Let us now discuss a new paradigm: social IoT (SIoT). Here, we consider
    social relationships between objects the same way as humans form social relationships
    (see [ 14]). Here are the three main facets of an SIoT system: (i) The SIoT is
    navigable. We can start with one device and navigate through all the devices that
    are connected to it. It is easy to discover new devices and services using such
    a social network of IoT devices. (ii) A need of trustworthiness (strength of the
    relationship) is present between devices (similar to friends on Facebook). (iii)
    We can use models similar to studying human social networks to also study the
    social networks of IoT devices. 2.3.1. Basic Components In a typical social IoT
    setting, we treat the devices and services as bots where they can set up relationships
    between them and modify them over time. This will allow us to seamlessly let the
    devices cooperate among each other and achieve a complex task. To make such a
    model work, we need to have many interoperating components. Let us look at some
    of the major components in such a system. (1) ID: we need a unique method of object
    identification. An ID can be assigned to an object based on traditional parameters
    such as the MAC ID, IPv6 ID, a universal product code, or some other custom method.
    (2) Metainformation: along with an ID, we need some metainformation about the
    device that describes its form and operation. This is required to establish appropriate
    relationships with the device and also appropriately place it in the universe
    of IoT devices. (3) Security controls: this is similar to “friend list” settings
    on Facebook. An owner of a device might place restrictions on the kinds of devices
    that can connect to it. These are typically referred to as owner controls. (4)
    Service discovery: such kind of a system is like a service cloud, where we need
    to have dedicated directories that store details of devices providing certain
    kinds of services. It becomes very important to keep these directories up to date
    such that devices can learn about other devices. (5) Relationship management:
    this module manages relationships with other devices. It also stores the types
    of devices that a given device should try to connect with based on the type of
    services provided. For example, it makes sense for a light controller to make
    a relationship with a light sensor. (6) Service composition: this module takes
    the social IoT model to a new level. The ultimate goal of having such a system
    is to provide better integrated services to users. For example, if a person has
    a power sensor with her air conditioner and this device establishes a relationship
    with an analytics engine, then it is possible for the ensemble to yield a lot
    of data about the usage patterns of the air conditioner. If the social model is
    more expansive, and there are many more devices, then it is possible to compare
    the data with the usage patterns of other users and come up with even more meaningful
    data. For example, users can be told that they are the largest energy consumers
    in their community or among their Facebook friends. 2.3.2. Representative Architecture
    Most architectures proposed for the SIoT have a server side architecture as well.
    The server connects to all the interconnected components, aggregates (composes)
    the services, and acts as a single point of service for users. The server side
    architecture typically has three layers. The first is the base layer that contains
    a database that stores details of all the devices, their attributes, metainformation,
    and their relationships. The second layer (Component layer) contains code to interact
    with the devices, query their status, and use a subset of them to effect a service.
    The topmost layer is the application layer, which provides services to the users.
    On the device (object) side, we broadly have two layers. The first is the object
    layer, which allows a device to connect to other devices, talk to them (via standardized
    protocols), and exchange information. The object layer passes information to the
    social layer. The social layer manages the execution of users’ applications, executes
    queries, and interacts with the application layer on the server. 3. Taxonomy Let
    us now propose taxonomy for research in IoT technologies (see Figure 3). Our taxonomy
    is based on the architectural elements of IoT as presented in Section 2.    Figure
    3  Taxonomy of research in IoT technologies. The first architectural component
    of IoT is the perception layer. It collects data using sensors, which are the
    most important drivers of the Internet of Things [ 15]. There are various types
    of sensors used in diverse IoT applications. The most generic sensor available
    today is the smartphone. The smartphone itself has many types of sensors embedded
    in it [ 16] such as the location sensor (GPS), movement sensors (accelerometer,
    gyroscope), camera, light sensor, microphone, proximity sensor, and magnetometer.
    These are being heavily used in different IoT applications. Many other types of
    sensors are beginning to be used such as sensors for measuring temperature, pressure,
    humidity, medical parameters of the body, chemical and biochemical substances,
    and neural signals. A class of sensors that stand out is infrared sensors that
    predate smartphones. They are now being used widely in many IoT applications:
    IR cameras, motion detectors, measuring the distance to nearby objects, presence
    of smoke and gases, and as moisture sensors. We shall discuss the different types
    of sensors used in IoT applications in Section 5. Subsequently, we shall discuss
    related work in data preprocessing. Such applications (also known as fog computing
    applications) mainly filter and summarize data before sending it on the network.
    Such units typically have a little amount of temporary storage, a small processing
    unit, and some security features. The next architectural component that we shall
    discuss is communication. We shall discuss related work (in Section 7) on different
    communication technologies used for the Internet of Things. Different entities
    communicate over the network [ 17– 19] using a diverse set of protocols and standards.
    The most common communication technologies for short range low power communication
    protocols are RFID (Radio Frequency Identification) and NFC (Near Field Communication).
    For the medium range, they are Bluetooth, Zigbee, and WiFi. Communication in the
    IoT world requires special networking protocols and mechanisms. Therefore, new
    mechanisms and protocols have been proposed and implemented for each layer of
    the networking stack, according to the requirements imposed by IoT devices. We
    shall subsequently look at two kinds of software components: middleware and applications.
    The middleware creates an abstraction for the programmer such that the details
    of the hardware can be hidden. This enhances interoperability of smart things
    and makes it easy to offer different kinds of services [ 20]. There are many commercial
    and open source offerings for providing middleware services to IoT devices. Some
    examples are OpenIoT [ 21], MiddleWhere [ 22], Hydra [ 23], FiWare [ 24], and
    Oracle Fusion Middleware. Finally, we discuss the applications of IoT in Section
    9. We primarily focus on home automation, ambient assisted living, health and
    fitness, smart vehicular systems, smart cities, smart environments, smart grids,
    social life, and entertainment. 4. Related Survey Papers Our taxonomy describes
    the technologies in the IoT domain and is classified on the basis of architectural
    layers. We have tried to cover all subareas and recent technologies in our taxonomy.
    There have been many survey papers on the Internet of Things in the past. Table
    1 shows how our survey is different from other highly cited surveys in the literature.
    Table 1  Comparison with other surveys on the basis of topics covered. Let us
    first consider our novel contributions. Our paper looks at each and every layer
    in the IoT stack, and as a result the presentation is also far more balanced.
    A novel addition in our survey is that we have discussed different IoT architectures.
    This has not been discussed in prior surveys on the Internet of Things. The architecture
    section also considers newer paradigms such as fog computing, which have also
    hitherto not been considered. Moreover, our survey nicely categorizes technologies
    based on the architectural layer that they belong to. We have also thoroughly
    categorized the network layer and tried to consolidate almost all the technologies
    that are used in IoT systems. Such kind of a thorough categorization and presentation
    of technologies is novel to the best of our knowledge. Along with these novel
    contributions our survey is far more comprehensive, detailed, and exhaustive as
    compared to other surveys in the area. Most of the other surveys look at only
    one or two types of sensors, whereas we describe 9 types of sensors with many
    examples. Other surveys are also fairly restricted when they discuss communication
    technologies and applications. We have discussed many types of middleware technologies
    as well. Prior works have not given middleware technologies this level of attention.
    We cover 10 communication technologies in detail and consider a large variety
    of applications encompassing smart homes, health care, logistics, transport, agriculture,
    environment, smart cities, and green energy. No other survey in this area profiles
    so many technologies, applications, and use cases. 5. Sensors and Actuators All
    IoT applications need to have one or more sensors to collect data from the environment.
    Sensors are essential components of smart objects. One of the most important aspects
    of the Internet of Things is context awareness, which is not possible without
    sensor technology. IoT sensors are mostly small in size, have low cost, and consume
    less power. They are constrained by factors such as battery capacity and ease
    of deployment. Schmidt and Van Laerhoven [ 25] provide an overview of various
    types of sensors used for building smart applications. 5.1. Mobile Phone Based
    Sensors First of all, let us look at the mobile phone, which is ubiquitous and
    has many types of sensors embedded in it. In specific, the smartphone is a very
    handy and user friendly device that has a host of built in communication and data
    processing features. With the increasing popularity of smartphones among people,
    researchers are showing interest in building smart IoT solutions using smartphones
    because of the embedded sensors [ 16, 26]. Some additional sensors can also be
    used depending upon the requirements. Applications can be built on the smartphone
    that uses sensor data to produce meaningful results. Some of the sensors inside
    a modern smartphone are as follows. (1) The accelerometer senses the motion and
    acceleration of a mobile phone. It typically measures changes in velocity of the
    smartphone in three dimensions. There are many types of accelerometers [ 27].
    In a mechanical accelerometer, we have a seismic mass in a housing, which is tied
    to the housing with a spring. The mass takes time to move and is left behind as
    the housing moves, so the force in the spring can be correlated with the acceleration.
    In a capacitive accelerometer, capacitive plates are used with the same setup.
    With a change in velocity, the mass pushes the capacitive plates together, thus
    changing the capacitance. The rate of change of capacitance is then converted
    into acceleration. In a piezoelectric accelerometer, piezoelectric crystals are
    used, which when squeezed generate an electric voltage. The changes in voltage
    can be translated into acceleration. The data patterns captured by the accelerometer
    can be used to detect physical activities of the user such as running, walking,
    and bicycling. (2) The gyroscope detects the orientation of the phone very precisely.
    Orientation is measured using capacitive changes when a seismic mass moves in
    a particular direction. (3) The camera and microphone are very powerful sensors
    since they capture visual and audio information, which can then be analyzed and
    processed to detect various types of contextual information. For example, we can
    infer a user’s current environment and the interactions that she is having. To
    make sense of the audio data, technologies such as voice recognition and acoustic
    features can be exploited. (4) The magnetometer detects magnetic fields. This
    can be used as a digital compass and in applications to detect the presence of
    metals. (5) The GPS (Global Positioning System) detects the location of the phone,
    which is one of the most important pieces of contextual information for smart
    applications. The location is detected using the principle of trilateration [
    28]. The distance is measured from three or more satellites (or mobile phone towers
    in the case of A-GPS) and coordinates are computed. (6) The light sensor detects
    the intensity of ambient light. It can be used for setting the brightness of the
    screen and other applications in which some action is to be taken depending on
    the intensity of ambient light. For example, we can control the lights in a room.
    (7) The proximity sensor uses an infrared (IR) LED, which emits IR rays. These
    rays bounce back when they strike some object. Based on the difference in time,
    we can calculate the distance. In this way, the distance to different objects
    from the phone can be measured. For example, we can use it to determine when the
    phone is close to the face while talking. It can also be used in applications
    in which we have to trigger some event when an object approaches the phone. (8)
    Some smartphones such as Samsung’s Galaxy S4 also have a thermometer, barometer,
    and humidity sensor to measure the temperature, atmospheric pressure, and humidity,
    respectively. We have studied many smart applications that use sensor data collected
    from smartphones. For example, activity detection [ 29] is achieved by applying
    machine learning algorithms to the data collected by smartphone sensors. It detects
    activities such as running, going up and down stairs, walking, driving, and cycling.
    The application is trained with patterns of data using data sets recorded by sensors
    when these activities are being performed. Many health and fitness applications
    are being built to keep track of a person’s health continuously using smartphones.
    They keep track of users’ physical activities, diet, exercises, and lifestyle
    to determine the fitness level and give suggestions to the user accordingly. Wang
    et al. [ 30] describe a mobile application that is based completely on a smartphone.
    They use it to assess the overall mental health and performance of a college student.
    To track the location and activities in which the student is involved, activity
    recognition (accelerometer) and GPS data are used. To keep a check on how much
    the student sleeps, the accelerometer and light sensors are used. For social life
    and conversations, audio data from a microphone is used. The application also
    conducts quick questionnaires with the students to know about their mood. All
    this data can be used to assess the stress levels, social life, behavior, and
    exercise patterns of a student. Another application by McClernon and Choudhury
    [ 31] detects when the user is going to smoke using context information such as
    the presence of other smokers, location, and associated activities. The sensors
    provide information related to the user’s movement, location, visual images, and
    surrounding sounds. To summarize smartphone sensors are being used to study different
    kinds of human behavior (see [ 32]) and to improve the quality of human life.
    5.2. Medical Sensors The Internet of Things can be really beneficial for health
    care applications. We can use sensors, which can measure and monitor various medical
    parameters in the human body [ 33]. These applications can aim at monitoring a
    patient’s health when they are not in hospital or when they are alone. Subsequently,
    they can provide real time feedback to the doctor, relatives, or the patient.
    McGrath and Scanaill [ 34] have described in detail the different sensors that
    can be worn on the body for monitoring a person’s health. There are many wearable
    sensing devices available in the market. They are equipped with medical sensors
    that are capable of measuring different parameters such as the heart rate, pulse,
    blood pressure, body temperature, respiration rate, and blood glucose levels [
    35]. These wearables include smart watches, wristbands, monitoring patches, and
    smart textiles. Moreover, smart watches and fitness trackers are becoming fairly
    popular in the market as companies such as Apple, Samsung, and Sony are coming
    up with very innovative features. For example, a smart watch includes features
    such as connectivity with a smartphone, sensors such as an accelerometer, and
    a heart rate monitor (see Figure 4).    Figure 4  Smart watches and fitness trackers
    (source: https://www.pebble.com/ and http://www.fitbit.com/). Another novel IoT
    device, which has a lot of promise are monitoring patches that are pasted on the
    skin. Monitoring patches are like tattoos. They are stretchable and disposable
    and are very cheap. These patches are supposed to be worn by the patient for a
    few days to monitor a vital health parameter continuously [ 15]. All the electronic
    components are embedded in these rubbery structures. They can even transmit the
    sensed data wirelessly. Just like a tattoo, these patches can be applied on the
    skin as shown in Figure 5. One of the most common applications of such patches
    is to monitor blood pressure.    Figure 5  Embedded skin patches (source: MC10
    Electronics). A very important consideration here is the context [ 34]. The data
    collected by the medical sensors must be combined with contextual information
    such as physical activity. For example, the heart rate depends on the context.
    It increases when we exercise. In that case, we cannot infer abnormal heart rate.
    Therefore, we need to combine data from different sensors for making the correct
    inference. 5.3. Neural Sensors Today, it is possible to understand neural signals
    in the brain, infer the state of the brain, and train it for better attention
    and focus. This is known as neurofeedback [ 36] (see Figure 6). The technology
    used for reading brain signals is called EEG (Electroencephalography) or a brain
    computer interface. The neurons inside the brain communicate electronically and
    create an electric field, which can be measured from outside in terms of frequencies.
    Brain waves can be categorized into alpha, beta, gamma, theta, and delta waves
    depending upon the frequency.    Figure 6  Brain sensing headband with embedded
    neurosensors (source: http://www.choosemuse.com/). Based on the type of wave,
    it can be inferred whether the brain is calm or wandering in thoughts. This type
    of neurofeedback can be obtained in real time and can be used to train the brain
    to focus, pay better attention towards things, manage stress, and have better
    mental well-being. 5.4. Environmental and Chemical Sensors Environmental sensors
    are used to sense parameters in the physical environment such as temperature,
    humidity, pressure, water pollution, and air pollution. Parameters such as the
    temperature and pressure can be measured with a thermometer and barometer. Air
    quality can be measured with sensors, which sense the presence of gases and other
    particulate matter in the air (refer to Sekhar et al. [ 37] for more details).
    Chemical sensors are used to detect chemical and biochemical substances. These
    sensors consist of a recognition element and a transducer. The electronic nose
    (e-nose) and electronic tongue (e-tongue) are technologies that can be used to
    sense chemicals on the basis of odor and taste, respectively [ 38]. The e-nose
    and e-tongue consist of an array of chemical sensors coupled with advance pattern
    recognition software. The sensors inside the e-nose and e-tongue produce complex
    data, which is then analyzed through pattern recognition to identify the stimulus.
    These sensors can be used in monitoring the pollution level in smart cities [
    39], keeping a check on food quality in smart kitchens, testing food, and agricultural
    products in supply chain applications. 5.5. Radio Frequency Identification (RFID)
    RFID is an identification technology in which an RFID tag (a small chip with an
    antenna) carries data, which is read by a RFID reader. The tag transmits the data
    stored in it via radio waves. It is similar to bar code technology. But unlike
    a traditional bar code, it does not require line of sight communication between
    the tag and the reader and can identify itself from a distance even without a
    human operator. The range of RFID varies with the frequency. It can go up to hundreds
    of meters. RFID tags are of two types: active and passive. Active tags have a
    power source and passive tags do not have any power source. Passive tags draw
    power from the electromagnetic waves emitted by the reader and are thus cheap
    and have a long lifetime [ 40, 41]. There are two types of RFID technologies:
    near and far [ 40]. A near RFID reader uses a coil through which we pass alternating
    current and generate a magnetic field. The tag has a smaller coil, which generates
    a potential due to the ambient changes in the magnetic field. This voltage is
    then coupled with a capacitor to accumulate a charge, which then powers up the
    tag chip. The tag can then produce a small magnetic field that encodes the signal
    to be transmitted, and this can be picked up by the reader. In far RFID, there
    is a dipole antenna in the reader, which propagates EM waves. The tag also has
    a dipole antenna on which an alternating potential difference appears and it is
    powered up. It can then use this power to transmit messages. RFID technology is
    being used in various applications such as supply chain management, access control,
    identity authentication, and object tracking. The RFID tag is attached to the
    object to be tracked and the reader detects and records its presence when the
    object passes by it. In this manner, object movement can be tracked and RFID can
    serve as a search engine for smart things. For access control, an RFID tag is
    attached to the authorized object. For example, small chips are glued to the front
    of vehicles. When the car reaches a barricade on which there is a reader, it reads
    the tag data and decides whether it is an authorized car. If yes, it opens automatically.
    RFID cards are issued to the people, who can then be identified by a RFID reader
    and given access accordingly. The low level data collected from the RFID tags
    can be transformed into higher level insights in IoT applications [ 42]. There
    are many user level tools available, in which all the data collected by particular
    RFID readers and data associated with the RFID tags can be managed. The high level
    data can be used to draw inferences and take further action. 5.6. Actuators Let
    us look at some examples of actuators that are used in the Internet of Things.
    An actuator is a device, which can effect a change in the environment by converting
    electrical energy into some form of useful energy. Some examples are heating or
    cooling elements, speakers, lights, displays, and motors. The actuators, which
    induce motion, can be classified into three categories, namely, electrical, hydraulic,
    and pneumatic actuators depending on their operation. Hydraulic actuators facilitate
    mechanical motion using fluid or hydraulic power. Pneumatic actuators use the
    pressure of compressed air and electrical ones use electrical energy. As an example,
    we can consider a smart home system, which consists of many sensors and actuators.
    The actuators are used to lock/unlock the doors, switch on/off the lights or other
    electrical appliances, alert users of any threats through alarms or notifications,
    and control the temperature of a home (via a thermostat). A sophisticated example
    of an actuator used in IoT is a digital finger, which is used to turn on/off the
    switches (or anything which requires small motion) and is controlled wirelessly.
    6. Preprocessing As smart things collect huge amount of sensor data, compute and
    storage resources are required to analyze, store, and process this data. The most
    common compute and storage resources are cloud based because the cloud offers
    massive data handling, scalability, and flexibility. But this will not be sufficient
    to meet the requirements of many IoT applications because of the following reasons
    [ 43]. (1) Mobility: most of the smart devices are mobile. Their changing location
    makes it difficult to communicate with the cloud data center because of changing
    network conditions across different locations. (2) Reliable and real time actuation:
    communicating with the cloud and getting back responses takes time. Latency sensitive
    applications, which need real time responses, may not be feasible with this model.
    Also, the communication may be lossy due to wireless links, which can lead to
    unreliable data. (3) Scalability: more devices means more requests to the cloud,
    thereby increasing the latency. (4) Power constraints: communication consumes
    a lot of power, and IoT devices are battery powered. They thus cannot afford to
    communicate all the time. To solve the problem of mobility, researchers have proposed
    mobile cloud computing (MCC) [ 44]. But there are still problems associated with
    latency and power. MCC also suffers from mobility problems such as frequently
    changing network conditions due to which problems such as signal fading and service
    degradation arise. As a solution to these problems, we can bring some compute
    and storage resources to the edge of the network instead of relying on the cloud
    for everything. This concept is known as fog computing [ 11, 45] (also see Section
    2.2). The fog can be viewed as a cloud, which is close to the ground. Data can
    be stored, processed, filtered, and analyzed on the edge of the network before
    sending it to the cloud through expensive communication media. The fog and cloud
    paradigms go together. Both of them are required for the optimal performance of
    IoT applications. A smart gateway [ 13] can be employed between underlying networks
    and the cloud to realize fog computing as shown in Figure 7.    Figure 7  Smart
    gateway for preprocessing. The features of fog computing [ 11] are as follows:
    (1) Low latency: less time is required to access computing and storage resources
    on fog nodes (smart gateways). (2) Location awareness: as the fog is located on
    the edge of the network, it is aware of the location of the applications and their
    context. This is beneficial as context awareness is an important feature of IoT
    applications. (3) Distributed nodes: fog nodes are distributed unlike centralized
    cloud nodes. Multiple fog nodes need to be deployed in distributed geographical
    areas in order to provide services to mobile devices in those areas. For example,
    in vehicular networks, deploying fog nodes at highways can provide low latency
    data/video streaming to vehicles. (4) Mobility: the fog supports mobility as smart
    devices can directly communicate with smart gateways present in their proximity.
    (5) Real time response: fog nodes can give an immediate response unlike the cloud,
    which has a much greater latency. (6) Interaction with the cloud: fog nodes can
    further interact with the cloud and communicate only that data, which is required
    to be sent to the cloud. The tasks performed by a smart gateway [ 46] are collecting
    sensor data, preprocessing and filtering collected data, providing compute, storage
    and networking services to IoT devices, communicating with the cloud and sending
    only necessary data, monitoring power consumption of IoT devices, monitoring activities
    and services of IoT devices, and ensuring security and privacy of data. Some applications
    of fog computing are as follows [ 10, 11]: (1) Smart vehicular networks: smart
    traffic lights are deployed as smart gateways to locally detect pedestrians and
    vehicles through sensors, calculate their distance and speed, and finally infer
    traffic conditions. This is used to warn oncoming vehicles. These sensors also
    interact with neighboring smart traffic lights to perform traffic management tasks.
    For example, if sensors detect an approaching ambulance, they can change the traffic
    lights to let the ambulance pass first and also inform other lights to do so.
    The data collected by these smart traffic lights are locally analyzed in real
    time to serve real time needs of traffic management. Further, data from multiple
    gateways is combined and sent to the cloud for further global analysis of traffic
    in the city. (2) Smart grid: the smart electrical grid facilitates load balancing
    of energy on the basis of usage and availability. This is done in order to switch
    automatically to alternative sources of energy such as solar and wind power. This
    balancing can be done at the edge of the network using smart meters or microgrids
    connected by smart gateways. These gateways can analyze and process data. They
    can then project future energy demand, calculate the availability and price of
    power, and supply power from both conventional and alternative sources to consumers.
    7. Communication As the Internet of Things is growing very rapidly, there are
    a large number of heterogeneous smart devices connecting to the Internet. IoT
    devices are battery powered, with minimal compute and storage resources. Because
    of their constrained nature, there are various communication challenges involved,
    which are as follows [ 19]: (1) Addressing and identification: since millions
    of smart things will be connected to the Internet, they will have to be identified
    through a unique address, on the basis of which they communicate with each other.
    For this, we need a large addressing space, and a unique address for each smart
    object. (2) Low power communication: communication of data between devices is
    a power consuming task, specially, wireless communication. Therefore, we need
    a solution that facilitates communication with low power consumption. (3) Routing
    protocols with low memory requirement and efficient communication patterns. (4)
    High speed and nonlossy communication. (5) Mobility of smart things. IoT devices
    typically connect to the Internet through the IP (Internet Protocol) stack. This
    stack is very complex and demands a large amount of power and memory from the
    connecting devices. The IoT devices can also connect locally through non-IP networks,
    which consume less power, and connect to the Internet via a smart gateway. Non-IP
    communication channels such as Bluetooth, RFID, and NFC are fairly popular but
    are limited in their range (up to a few meters). Therefore, their applications
    are limited to small personal area networks. Personal area networks (PAN) are
    being widely used in IoT applications such as wearables connected to smartphones.
    For increasing the range of such local networks, there was a need to modify the
    IP stack so as to facilitate low power communication using the IP stack. One of
    the solutions is 6LoWPAN, which incorporates IPv6 with low power personal area
    networks. The range of a PAN with 6LoWPAN is similar to local area networks, and
    the power consumption is much lower. The leading communication technologies used
    in the IoT world are IEEE 802.15.4, low power WiFi, 6LoWPAN, RFID, NFC, Sigfox,
    LoraWAN, and other proprietary protocols for wireless networks. 7.1. Near Field
    Communication (NFC) Near Field Communication [ 47– 49] is a very short range wireless
    communication technology, through which mobile devices can interact with each
    other over a distance of few centimeters only. All types of data can be transferred
    between two NFC enabled devices in seconds by bringing them close to each other.
    This technology is based on RFID. It uses variations in the magnetic field to
    communicate data between two NFC enabled devices. NFC operates over a frequency
    band of 13.56 MHz, which is the same as high frequency RFID. There are two modes
    of operation: active and passive. In the active mode, both the devices generate
    magnetic fields, while in the passive mode, only one device generates the field
    and the other uses load modulation to transfer the data. The passive mode is useful
    in battery powered devices to optimize energy use. One benefit of the requirement
    of close proximity between devices is that it is useful for secure transactions
    such as payments. Finally, note that NFC can be used for two-way communication
    unlike RFID. Consequently, almost all smartphones in the market today are NFC
    enabled. 7.2. Wireless Sensor Networks (WSN) Based on IP for Smart Objects Many
    times, data from a single sensor is not useful in monitoring large areas and complex
    activities. Different sensor nodes need to interact with each other wirelessly.
    The disadvantage of non-IP technologies such as RFID, NFC, and Bluetooth is that
    their range is very small. So, they cannot be used in many applications, where
    a large area needs to be monitored through many sensor nodes deployed in diverse
    locations. A wireless sensor network (WSN) consists of tens to thousands of sensor
    nodes connected using wireless technologies. They collect data about the environment
    and communicate it to gateway devices that relay the information to the cloud
    over the Internet. The communication between nodes in a WSN may be direct or multihop.
    The sensor nodes are of a constrained nature, but gateway nodes have sufficient
    power and processing resources. The popular network topologies used in a WSN are
    a star, a mesh, and a hybrid network. Most of the communication in WSN is based
    on the IEEE 802.15.4 standard (discussed in Section 7.3). There are clearly a
    lot of protocols that can be used in IoT scenarios. Let us discuss the design
    of a typical IoT network protocol stack with the most popular alternatives. 7.3.
    IoT Network Protocol Stack The Internet Engineering Task Force (IETF) has developed
    alternative protocols for communication between IoT devices using IP because IP
    is a flexible and reliable standard [ 50, 51]. The Internet Protocol for Smart
    Objects (IPSO) Alliance has published various white papers describing alternative
    protocols and standards for the layers of the IP stack and an additional adaptation
    layer, which is used for communication [ 51– 54] between smart objects. (1) Physical
    and MAC Layer (IEEE 802.15.4). The IEEE 802.15.4 protocol is designed for enabling
    communication between compact and inexpensive low power embedded devices that
    need a long battery life. It defines standards and protocols for the physical
    and link (MAC) layer of the IP stack. It supports low power communication along
    with low cost and short range communication. In the case of such resource constrained
    environments, we need a small frame size, low bandwidth, and low transmit power.
    Transmission requires very little power (maximum one milliwatt), which is only
    one percent of that used in WiFi or cellular networks. This limits the range of
    communication. Because of the limited range, the devices have to operate cooperatively
    in order to enable multihop routing over longer distances. As a result, the packet
    size is limited to 127 bytes only, and the rate of communication is limited to
    250 kbps. The coding scheme in IEEE 802.15.4 has built in redundancy, which makes
    the communication robust, allows us to detect losses, and enables the retransmission
    of lost packets. The protocol also supports short 16-bit link addresses to decrease
    the size of the header, communication overheads, and memory requirements [ 55].
    Readers can refer to the survey by Vasseur et al. [ 54] for more information on
    different physical and link layer technologies for communication between smart
    objects. (2) Adaptation Layer. IPv6 is considered the best protocol for communication
    in the IoT domain because of its scalability and stability. Such bulky IP protocols
    were initially not thought to be suitable for communication in scenarios with
    low power wireless links such as IEEE 802.15.4. 6LoWPAN, an acronym for IPv6 over
    low power wireless personal area networks, is a very popular standard for wireless
    communication. It enables communication using IPv6 over the IEEE 802.15.4 [ 52]
    protocol. This standard defines an adaptation layer between the 802.15.4 link
    layer and the transport layer. 6LoWPAN devices can communicate with all other
    IP based devices on the Internet. The choice of IPv6 is because of the large addressing
    space available in IPv6. 6LoWPAN networks connect to the Internet via a gateway
    (WiFi or Ethernet), which also has protocol support for conversion between IPv4
    and IPv6 as today’s deployed Internet is mostly IPv4. IPv6 headers are not small
    enough to fit within the small 127 byte MTU of the 802.15.4 standard. Hence, squeezing
    and fragmenting the packets to carry only the essential information is an optimization
    that the adaptation layer performs. Specifically, the adaptation layer performs
    the following three optimizations in order to reduce communication overhead [
    55]: (i) Header compression 6loWPAN defines header compression of IPv6 packets
    for decreasing the overhead of IPv6. Some of the fields are deleted because they
    can be derived from link level information or can be shared across packets. (ii)
    Fragmentation: the minimum MTU size (maximum transmission unit) of IPv6 is 1280
    bytes. On the other hand, the maximum size of a frame in IEEE 802.15.4 is 127
    bytes. Therefore, we need to fragment the IPv6 packet. This is done by the adaptation
    layer. (iii) Link layer forwarding 6LoWPAN also supports mesh under routing, which
    is done at the link layer using link level short addresses instead of in the network
    layer. This feature can be used to communicate within a 6LoWPAN network. (3) Network
    Layer. The network layer is responsible for routing the packets received from
    the transport layer. The IETF Routing over Low Power and Lossy Networks (ROLL)
    working group has developed a routing protocol (RPL) for Low Power and Lossy Networks
    (LLNs) [ 53]. For such networks, RPL is an open routing protocol, based on distance
    vectors. It describes how a destination oriented directed acyclic graph (DODAG)
    is built with the nodes after they exchange distance vectors. A set of constraints
    and an objective function is used to build the graph with the best path [ 53].
    The objective function and constraints may differ with respect to their requirements.
    For example, constraints can be to avoid battery powered nodes or to prefer encrypted
    links. The objective function can aim to minimize the latency or the expected
    number of packets that need to be sent. The making of this graph starts from the
    root node. The root starts sending messages to neighboring nodes, which then process
    the message and decide whether to join or not depending upon the constraints and
    the objective function. Subsequently, they forward the message to their neighbors.
    In this manner, the message travels till the leaf nodes and a graph is formed.
    Now all the nodes in the graph can send packets upwards hop by hop to the root.
    We can realize a point to point routing algorithm as follows. We send packets
    to a common ancestor, from which it travels downwards (towards leaves) to reach
    the destination. To manage the memory requirements of nodes, nodes are classified
    into storing and nonstoring nodes depending upon their ability to store routing
    information. When nodes are in a nonstoring mode and a downward path is being
    constructed, the route information is attached to the incoming message and forwarded
    further till the root. The root receives the whole path in the message and sends
    a data packet along with the path message to the destination hop by hop. But there
    is a trade-off here because nonstoring nodes need more power and bandwidth to
    send additional route information as they do not have the memory to store routing
    tables. (4) Transport Layer. TCP is not a good option for communication in low
    power environments as it has a large overhead owing to the fact that it is a connection
    oriented protocol. Therefore, UDP is preferred because it is a connectionless
    protocol and has low overhead. (5) Application Layer. The application layer is
    responsible for data formatting and presentation. The application layer in the
    Internet is typically based on HTTP. However, HTTP is not suitable in resource
    constrained environments because it is fairly verbose in nature and thus incurs
    a large parsing overhead. Many alternate protocols have been developed for IoT
    environments such as CoAP (Constrained Application Protocol) and MQTT (Message
    Queue Telemetry Transport). (a) Constrained Application Protocol: CoAP can be
    thought of as an alternative to HTTP. It is used in most IoT applications [ 56,
    57]. Unlike HTTP, it incorporates optimizations for constrained application environments
    [ 50]. It uses the EXI (Efficient XML Interchanges) data format, which is a binary
    data format and is far more efficient in terms of space as compared to plain text
    HTML/XML. Other supported features are built in header compression, resource discovery,
    autoconfiguration, asynchronous message exchange, congestion control, and support
    for multicast messages. There are four types of messages in CoAP: nonconfirmable,
    confirmable, reset (nack), and acknowledgement. For reliable transmission over
    UDP, confirmable messages are used [ 58]. The response can be piggybacked in the
    acknowledgement itself. Furthermore, it uses DTLS (Datagram Transport Layer Security)
    for security purposes. (b) Message Queue Telemetry Transport: MQTT is a publish/subscribe
    protocol that runs over TCP. It was developed by IBM [ 59] primarily as a client/server
    protocol. The clients are publishers/subscribers and the server acts as a broker
    to which clients connect through TCP. Clients can publish or subscribe to a topic.
    This communication takes place through the broker whose job is to coordinate subscriptions
    and also authenticate the client for security. MQTT is a lightweight protocol,
    which makes it suitable for IoT applications. But because of the fact that it
    runs over TCP, it cannot be used with all types of IoT applications. Moreover,
    it uses text for topic names, which increases its overhead. MQTT-S/MQTT-SN is
    an extension of MQTT [ 60], which is designed for low power and low cost devices.
    It is based on MQTT but has some optimizations for WSNs as follows [ 61]. The
    topic names are replaced by topic IDs, which reduce the overheads of transmission.
    Topics do not need registration as they are preregistered. Messages are also split
    so that only the necessary information is sent. Further, for power conservation,
    there is an offline procedure for clients who are in a sleep state. Messages can
    be buffered and later read by clients when they wake up. Clients connect to the
    broker through a gateway device, which resides within the sensor network and connects
    to the broker. 7.4. Bluetooth Low Energy (BLE) Bluetooth Low Energy, also known
    as “Bluetooth Smart,” was developed by the Bluetooth Special Interest Group. It
    has a relatively shorter range and consumes lower energy as compared to competing
    protocols. The BLE protocol stack is similar to the stack used in classic Bluetooth
    technology. It has two parts: controller and host. The physical and link layer
    are implemented in the controller. The controller is typically a SOC (System on
    Chip) with a radio. The functionalities of upper layers are included in the host
    [ 62]. BLE is not compatible with classic Bluetooth. Let us look at the differences
    between classic Bluetooth and BLE [ 63, 64]. The main difference is that BLE does
    not support data streaming. Instead, it supports quick transfer of small packets
    of data (packet size is small) with a data rate of 1 Mbps. There are two types
    of devices in BLE: master and slave. The master acts as a central device that
    can connect to various slaves. Let us consider an IoT scenario where a phone or
    PC serve as the master and mobile devices such as a thermostat, fitness tracker,
    smart watch, or any monitoring device act as slaves. In such cases, slaves must
    be very power efficient. Therefore, to save energy, slaves are by default in sleep
    mode and wake up periodically to receive packets from the master. In classic Bluetooth,
    the connection is on all the time even if no data transfer is going on. Additionally,
    it supports 79 data channels (1 MHz channel bandwidth) and a data rate of 1 million
    symbols/s, whereas, BLE supports 40 channels with 2 MHz channel bandwidth (double
    of classic Bluetooth) and 1 million symbols/s data rate. BLE supports low duty
    cycle requirements as its packet size is small and the time taken to transmit
    the smallest packet is as small as 80 s. The BLE protocol stack supports IP based
    communication also. An experiment conducted by Siekkinen et al. [ 65] recorded
    the number of bytes transferred per Joule to show that BLE consumes far less energy
    as compared to competing protocols such as Zigbee. The energy efficiency of BLE
    is 2.5 times better than Zigbee. 7.5. Low Power WiFi The WiFi alliance has recently
    developed “WiFi HaLow,” which is based on the IEEE 802.11ah standard. It consumes
    lower power than a traditional WiFi device and also has a longer range. This is
    why this protocol is suitable for Internet of Things applications. The range of
    WiFi HaLow is nearly twice that of traditional WiFi. Like other WiFi devices,
    devices supporting WiFi HaLow also support IP connectivity, which is important
    for IoT applications. Let us look at the specifications of the IEEE 802.11ah standard
    [ 66, 67]. This standard was developed to deal with wireless sensor network scenarios,
    where devices are energy constrained and require relatively long range communication.
    IEEE 802.11ah operates in the sub-gigahertz band (900 MHz). Because of the relatively
    lower frequency, the range is longer since higher frequency waves suffer from
    higher attenuation. We can extend the range (currently 1 km) by lowering the frequency
    further; however, the data rate will also be lower and thus the tradeoff is not
    justified. IEEE 802.11ah is also designed to support large star shaped networks,
    where a lot of stations are connected to a single access point. 7.6. Zigbee It
    is based on the IEEE 802.15.4 communication protocol standard and is used for
    personal area networks or PANs [ 68]. The IEEE 802.15.4 standard has low power
    MAC and physical layers and has already been explained in Section 7.3. Zigbee
    was developed by the Zigbee alliance, which works for reliable, low energy, and
    cheap communication solutions. The range of Zigbee device communication is very
    small (10–100 meters). The details of the network and application layers are also
    specified by the Zigbee standard. Unlike BLE, the network layer here provides
    for multihop routing. There are three types of devices in a Zigbee network: FFD
    (Fully Functional Device), RFD (Reduced Functional Device), and one Zigbee coordinator.
    A FFD node can additionally act as a router. Zigbee supports star, tree, and mesh
    topologies. The routing scheme depends on the topology. Other features of Zigbee
    are discovery and maintenance of routes, support for nodes joining/leaving the
    network, short 16-bit addresses, and multihop routing. The framework for communication
    and distributed application development is provided by the application layer.
    The application layer consists of Application Objects (APO), Application Sublayer
    (APS), and a Zigbee Device Object (ZDO). APOs are spread over the network nodes.
    These are pieces of software, which control some underlying device hardware (examples:
    switch and transducer). The device and network management services are provided
    by the ZDO, which are then used by the APOs. Data transfer services are provided
    by the Application Sublayer to the APOs and ZDO. It is responsible for secure
    communication between the Application Objects. These features can be used to create
    a large distributed application. 7.7. Integration of RFID and WSN RFID and wireless
    sensor networks (WSN) are both important technologies in the IoT domain. RFID
    can only be used for object identification, but WSNs serve a far greater purpose.
    The two are very different but merging them has many advantages. The following
    components can be added to RFID to enhance its usability: (a) Sensing capabilities
    (b) Multihop communication (c) Intelligence RFID is inexpensive and uses very
    little power. That is why its integration with WSN is very useful. The integration
    is possible in the following ways [ 69, 70]: (a) Integration of RFID tags with
    sensors: RFID tags with sensing capabilities are called sensor tags. These sensor
    tags sense data from the environment and then the RFID reader can read this sensed
    data from the tag. In such cases, simple RFID protocols are used, where there
    is only single hop communication. RFID sensing technologies can be further classified
    on the basis of the power requirement of sensor tags as explained earlier in the
    section on RFIDs (active and passive) (see Section 5.5). (b) Integration of RFID
    tags with WSN nodes: the communication capabilities of sensor tags are limited
    to a single hop. To extend its capabilities, the sensor tag is equipped with a
    wireless transceiver, little bit of Flash memory, and computational capabilities
    such that it can initiate communication with other nodes and wireless devices.
    The nodes can in this fashion be used to form a wireless mesh network. In such
    networks, sensor tags can communicate with each other over a large range (via
    intermediate hops). With additional processing capabilities at a node, we can
    reduce the net amount of data communicated and thus increase the power efficiency
    of the WSN. (c) Integration of RFID readers with WSN nodes: this type of integration
    is also done to increase the range of RFID tag readers. The readers are equipped
    with wireless transceivers and microcontrollers so that they can communicate with
    each other and therefore, the tag data can reach a reader, which is not in the
    range of that tag. It takes advantage of multihop communication of wireless sensor
    network devices. The data from all the RFID readers in the network ultimately
    reaches a central gateway or base station that processes the data or sends it
    to a remote server. These kinds of integrated solutions have many applications
    in a diverse set of domains such as security, healthcare, and manufacturing. 7.8.
    Low Power Wide-Area-Networks (LPWAN) Let us now discuss a protocol for long range
    communication in power constrained devices. The LPWAN class of protocols is low
    bit-rate communication technologies for such IoT scenarios. Let us now discuss
    some of the most common technologies in this area. Narrow band IoT: it is a technology
    made for a large number of devices that are energy constrained. It is thus necessary
    to reduce the bit rate. This protocol can be deployed with both the cellular phone
    GSM and LTE spectra. The downlink speeds vary between 40 kbps (LTE M2) and 10 Mbps
    (LTE category 1). Sigfox: it is one more protocol that uses narrow band communication
    (10 MHz). It uses free sections of the radio spectrum (ISM band) to transmit its
    data. Instead of 4G networks, Sigfox focuses on using very long waves. Thus, the
    range can increase to a 1000 kms. Because of this the energy for transmission
    is significantly lower (0.1%) than contemporary cell phones. Again the cost is
    bandwidth. It can only transmit 12 bytes per message, and a device is limited
    to 140 messages per day. This is reasonable for many kinds of applications: submarine
    applications, sending control (emergency) codes, geolocation, monitoring remote
    locations, and medical applications. Weightless: it uses a differential binary
    phase shift keying based method to transmit narrow band signals. To avoid interference,
    the protocol hops across frequency bands (instead of using CSMA). It supports
    cryptographic encryption and mobility. Along with frequency hopping, two additional
    mechanisms are used to reduce collisions. The downlink service uses time division
    multiple access (TDMA) and the uplink service uses multiple subchannels that are
    first allocated to transmitting nodes by contacting a central server. Some applications
    include smart meters, vehicle tracking, health monitoring, and industrial machine
    monitoring. Neul: this protocol operates in the sub-1 GHz band. It uses small
    chunks of the TV whitespace spectrum to create low cost and low power networks
    with very high scalability. It has a 10 km range and uses the Weightless protocol
    for communication. LoRaWAN: this protocol is similar to Sigfox. It targets wide
    area network applications and is designed to be a low power protocol. Its data
    rates can vary from 0.3 kbps to 50 kbps, and it can be used within an urban or
    a suburban environment (2–5 kms range in a crowded urban area). It was designed
    to serve as a standard for long range IoT protocols. It thus has features to support
    multitenancy, enable multiple applications, and include several different network
    domains. 7.9. Lightweight Application Layer Protocols Along with physical and
    MAC layer protocols, we also need application layer protocols for IoT networks.
    These lightweight protocols need to be able to carry application messages, while
    simultaneously reducing power as far as possible. OMA Lightweight M2M (LWM2M)
    is one such protocol. It defines the communication protocol between a server and
    a device. The devices often have limited capabilities and are thus referred to
    as constrained devices. The main aims of the OMA protocol are as follows: (1)
    Remote device management. (2) Transferring service data/information between different
    nodes in the LWM2M network. All the protocols in this class treat all the network
    resources as objects. Such resources can be created, deleted, and remotely configured.
    These devices have their unique limitations and can use different kinds of protocols
    for internally representing information. The LWM2M protocol abstracts all of this
    away and provides a convenient interface to send messages between a generic LWM2M
    server and a distributed set of LWM2M clients. This protocol is often used along
    with CoAP (Constrained Application Protocol). It is an application layer protocol
    that allows constrained nodes such as sensor motes or small embedded devices to
    communicate across the Internet. CoAP seamlessly integrates with HTTP, yet it
    provides additional facilities such as support for multicast operations. It is
    ideally suited for small devices because of its low overhead and parsing complexity
    and reliance on UDP rather than TCP. 8. Middleware Ubiquitous computing is the
    core of the Internet of Things, which means incorporating computing and connectivity
    in all the things around us. Interoperability of such heterogeneous devices needs
    well-defined standards. But standardization is difficult because of the varied
    requirements of different applications and devices. For such heterogeneous applications,
    the solution is to have a middleware platform, which will abstract the details
    of the things for applications. That is, it will hide the details of the smart
    things. It should act as a software bridge between the things and the applications.
    It needs to provide the required services to the application developers [ 20]
    so that they can focus more on the requirements of applications rather than on
    interacting with the baseline hardware. To summarize, the middleware abstracts
    the hardware and provides an Application Programming Interface (API) for communication,
    data management, computation, security, and privacy. The challenges, which are
    addressed by any IoT middleware, are as follows: [ 20, 71, 72]. (1) Interoperability
    and programming abstractions: for facilitating collaboration and information exchange
    between heterogeneous devices, different types of things can interact with each
    other easily with the help of middleware services. Interoperability is of three
    types: network, semantic, and syntactic. Network interoperability deals with heterogeneous
    interface protocols for communication between devices. It insulates the applications
    from the intricacies of different protocols. Syntactic interoperability ensures
    that applications are oblivious of different formats, structures, and encoding
    of data. Semantic interoperability deals with abstracting the meaning of data
    within a particular domain. It is loosely inspired by the semantic web. (2) Device
    discovery and management: this feature enables the devices to be aware of all
    other devices in the neighborhood and the services provided by them. In the Internet
    of Things, the infrastructure is mostly dynamic. The devices have to announce
    their presence and the services they provide. The solution needs to be scalable
    because the devices in an IoT network can increase. Most solutions in this domain
    are loosely inspired by semantic web technologies. The middleware provides APIs
    to list the IoT devices, their services, and capabilities. In addition, typically
    APIs are provided to discover devices based on their capabilities. Finally, any
    IoT middleware needs to perform load balancing, manage devices based on their
    levels of battery power, and report problems in devices to the users. (3) Scalability:
    a large number of devices are expected to communicate in an IoT setup. Moreover,
    IoT applications need to scale due to ever increasing requirements. This should
    be managed by the middleware by making required changes when the infrastructure
    scales. (4) Big data and analytics: IoT sensors typically collect a huge amount
    of data. It is necessary to analyze all of this data in great detail. As a result
    a lot of big data algorithms are used to analyze IoT data. Moreover, it is possible
    that due to the flimsy nature of the network some of the data collected might
    be incomplete. It is necessary to take this into account and extrapolate data
    by using sophisticated machine learning algorithms. (5) Security and privacy:
    IoT applications are mostly related to someone’s personal life or an industry.
    Security and privacy issues need to be addressed in all such environments. The
    middleware should have built in mechanisms to address such issues, along with
    user authentication, and the implementation of access control. (6) Cloud services:
    the cloud is an important part of an IoT deployment. Most of the sensor data is
    analyzed and stored in a centralized cloud. It is necessary for IoT middleware
    to seamlessly run on different types of clouds and to enable users to leverage
    the cloud to get better insights from the data collected by the sensors. (7) Context
    detection: the data collected from the sensors needs to be used to extract the
    context by applying various types of algorithms. The context can subsequently
    be used for providing sophisticated services to users. There are many middleware
    solutions available for the Internet of Things, which address one or more of the
    aforementioned issues. All of them support interoperability and abstraction, which
    is the foremost requirement of middleware. Some examples are Oracle’s Fusion Middleware,
    OpenIoT [ 21], MiddleWhere [ 22], and Hydra [ 23]. Middlewares can be classified
    as follows on the basis of their design [ 72]: (1) Event based: here, all the
    components interact with each other through events. Each event has a type and
    some parameters. Events are generated by producers and received by the consumers.
    This can be viewed as a publish/subscribe architecture, where entities can subscribe
    for some event types and get notified for those events. (2) Service oriented:
    service oriented middlewares are based on Service Oriented Architectures (SOA),
    in which we have independent modules that provide services through accessible
    interfaces. A service oriented middleware views resources as service providers.
    It abstracts the underlying resources through a set of services that are used
    by applications. There is a service repository, where services are published by
    providers. The consumers can discover services from the repository and then bind
    with the provider to access the service. Service oriented middleware must have
    runtime support for advertising services by providers and support for discovering
    and using services by consumers. HYDRA [ 23] is a service oriented middleware.
    It incorporates many software components, which are used in handling various tasks
    required for the development of intelligent applications. Hydra also provides
    semantic interoperability using semantic web technologies. It supports dynamic
    reconfiguration and self-management. (3) Database oriented: in this approach,
    the network of IoT devices is considered as a virtual relational database system.
    The database can then be queried by the applications using a query language. There
    are easy to use interfaces for extracting data from the database. This approach
    has issues with scaling because of its centralized model. (4) Semantic: semantic
    middleware focuses on the interoperation of different types of devices, which
    communicate using different formats of data. It incorporates devices with different
    data formats and ontologies and ties all of them together in a common framework.
    The framework is used for exchanging data between diverse types of devices. For
    a common semantic format, we need to have adapters for communication between devices
    because; for each device, we need adapters to map standards to one abstract standard
    [ 73]. In such a semantic middleware [ 74], a semantic layer is introduced, in
    which there is a mapping from each resource to a software layer for that resource.
    The software layers then communicate with each other using a mutually intelligible
    language (based on the semantic web). This technique allows multiple physical
    resources to communicate even though they do not implement or understand the same
    protocols. (5) Application specific: this type of middleware is used specifically
    for an application domain for which it is developed because the whole architecture
    of this middleware software is fine-tuned on the basis of requirements of the
    application. The application and middleware are tightly coupled. These are not
    general purpose solutions. 8.1. Popular IoT Middleware 8.1.1. FiWare FiWare is
    a very popular IoT middleware framework that is promoted by the EU. It has been
    designed keeping smart cities, logistics, and shop floor analytics in mind. FiWare
    contains a large body of code, reusable modules, and APIs that have been contributed
    by thousands of FiWare developers. Any application developer can take a subset
    of these components and build his/her IoT application. A typical IoT application
    has many producers of data (sensors), a set of servers to process the data, and
    a set of actuators. FiWare refers to the information collected by sensors as context
    information. It defines generic REST APIs to capture the context from different
    scenarios. All the context information is sent to a dedicated service called a
    context broker. FiWare provides APIs to store the context and also query it. Moreover,
    any application can register itself as a context consumer, and it can request
    the context broker for information. It also supports the publish-subscribe paradigm.
    Subsequently, the context can be supplied to systems using context adapters whose
    main role is to transform the data (the context) based on the requirements of
    the destination nodes. Moreover, FiWare defines a set of SNMP APIs via which we
    can control the behavior of IoT devices and also configure them. The target applications
    are provided APIs to analyze, query, and mine the information that is collected
    from the context broker. Additionally, with advanced visualization APIs, it is
    possible to create and deploy feature rich applications very quickly. 8.1.2. OpenIoT
    OpenIoT is another popular open source initiative. It has 7 different components.
    At the lowest level, we have a physical plane. It collects data from IoT devices
    and also does some preprocessing of data. It has different APIs to interface with
    different types of physical nodes and get information from them. The next plane
    is the virtualized plane, which has 3 components. We first have the scheduler,
    which manages the streams of data generated by devices. It primarily assigns them
    to resources and takes care of their QoS requirements. The data storage component
    manages the storage and archival of data streams. Finally, the service delivery
    component processes the streams. It has several roles. It combines data streams,
    preprocesses them, and tracks some statistics associated with these streams such
    as the number of unique requests or the size of each request. The uppermost layer,
    that is, the application layer, also has 3 components: request definition, request
    presentation, and configuration. The request definition component helps us create
    requests to be sent to the IoT sensors and storage layers. It can be used to fetch
    and query data. The request presentation component creates mashups of data by
    issuing different queries to the storage layer, and finally the configuration
    component helps us configure the IoT devices. 9. Applications of IoT There are
    a diverse set of areas in which intelligent applications have been developed.
    All of these applications are not yet readily available; however, preliminary
    research indicates the potential of IoT in improving the quality of life in our
    society. Some uses of IoT applications are in home automation, fitness tracking,
    health monitoring, environment protection, smart cities, and industrial settings.
    9.1. Home Automation Smart homes are becoming more popular today because of two
    reasons. First, the sensor and actuation technologies along with wireless sensor
    networks have significantly matured. Second, people today trust technology to
    address their concerns about their quality of life and security of their homes
    (see Figure 8).    Figure 8  Block diagram of a smart home system. In smart homes,
    various sensors are deployed, which provide intelligent and automated services
    to the user. They help in automating daily tasks and help in maintaining a routine
    for individuals who tend to be forgetful. They help in energy conservation by
    turning off lights and electronic gadgets automatically. We typically use motion
    sensors for this purpose. Motion sensors can be additionally used for security
    also. For example, the project, MavHome [ 75], provides an intelligent agent,
    which uses various prediction algorithms for doing automated tasks in response
    to user triggered events and adapts itself to the routines of the inhabitants.
    Prediction algorithms are used to predict the sequence of events [ 76] in a home.
    A sequence matching algorithm maintains sequences of events in a queue and also
    stores their frequency. Then a prediction is made using the match length and frequency.
    Other algorithms used by similar applications use compression based prediction
    and Markov models. Energy conservation in smart homes [ 77] is typically achieved
    through sensors and context awareness. The sensors collect data from the environment
    (light, temperature, humidity, gas, and fire events). This data from heterogeneous
    sensors is fed to a context aggregator, which forwards the collected data to the
    context aware service engine. This engine selects services based on the context.
    For example, an application can automatically turn on the AC when the humidity
    rises. Or, when there is a gas leak, it can turn all the lights off. Smart home
    applications are really beneficial for the elderly and differently abled. Their
    health is monitored and relatives are informed immediately in case of emergencies.
    Floors are equipped with pressure sensors, which track the movement of an individual
    across the smart home and also help in detecting if a person has fallen down.
    In smart homes, CCTV cameras can be used to record events of interest. These can
    then be used for feature extraction to find out what is going on. In specific,
    fall detection applications in smart environments [ 78– 80] are useful for detecting
    if elderly people have fallen down. Yu et al. [ 80] use computer vision based
    techniques for analyzing postures of the human body. Sixsmith et al. [ 79] used
    low cost infrared sensor array technology, which can provide information such
    as the location, size, and velocity of a target object. It detects dynamics of
    a fall by analyzing the motion patterns and also detects inactivity and compares
    it with activity in the past. Neural networks are employed and sample data is
    provided to the system for various types of falls. Many smartphone based applications
    are also available, which detect a fall on the basis of readings from the accelerometer
    and gyroscope data. There are many challenges and issues with regard to smart
    home applications [ 81]. The most important is security and privacy [ 82] since
    all the data about the events taking place in the home is being recorded. If the
    security and trustworthiness of the system are not guaranteed, an intruder may
    attack the system and may make the system behave maliciously. Smart home systems
    are supposed to notify the owners in case they detect such abnormalities. This
    is possible using AI and machine learning algorithms, and researchers have already
    started working in this direction [ 83]. Reliability is also an issue since there
    is no system administrator to monitor the system. 9.2. Smart Cities 9.2.1. Smart
    Transport Smart transport applications can manage daily traffic in cities using
    sensors and intelligent information processing systems. The main aim of intelligent
    transport systems is to minimize traffic congestion, ensure easy and hassle-free
    parking, and avoid accidents by properly routing traffic and spotting drunk drivers.
    The sensor technologies governing these types of applications are GPS sensors
    for location, accelerometers for speed, gyroscopes for direction, RFIDs for vehicle
    identification, infrared sensors for counting passengers and vehicles, and cameras
    for recording vehicle movement and traffic. There are many types of applications
    in this area (refer to [ 84]): (1) Traffic surveillance and management applications:
    vehicles are connected by a network to each other, the cloud, and to a host of
    IoT devices such as GPS sensors, RFID devices, and cameras. These devices can
    estimate traffic conditions in different parts of the city. Custom applications
    can analyze traffic patterns so that future traffic conditions can be estimated.
    Yu et al. [ 85] implement a vehicle tracking system for traffic surveillance using
    video sequences captured on the roads. Traffic congestion detection can also be
    implemented using smartphone sensors such as accelerometers [ 86] and GPS sensors.
    These applications can detect movement patterns of the vehicle while the user
    is driving. Such kind of information is already being collected by Google maps
    and users are using it to route around potentially congested areas of the city.
    (2) Applications to ensure safety: smart transport does not only imply managing
    traffic conditions. It also includes safety of people travelling in their vehicles,
    which up till now was mainly in the hands of drivers. There are many IoT applications
    developed to help drivers become safer drivers. Such applications monitor driving
    behavior of drivers and help them drive safely by detecting when they are feeling
    drowsy or tired and helping them to cope with it or suggesting rest [ 87, 88].
    Technologies used in such applications are face detection, eye movement detection,
    and pressure detection on the steering (to measure the grip of the driver’s hands
    on the steering). A smartphone application, which estimates the driver’s driving
    behavior using smartphone sensors such as the accelerometer, gyroscope, GPS, and
    camera, has been proposed by Eren et al. [ 89]. It can decide whether the driving
    is safe or rash by analyzing the sensor data. (3) Intelligent parking management
    (see Figure 9): in a smart transportation system, parking is completely hassle
    free as one can easily check on the Internet to find out which parking lot has
    free spaces. Such lots use sensors to detect if the slots are free or occupied
    by vehicles. This data is then uploaded to a central server. (4) Smart traffic
    lights: traffic lights equipped with sensing, processing, and communication capabilities
    are called smart traffic lights. These lights sense the traffic congestion at
    the intersection and the amount of traffic going each way. This information can
    be analyzed and then sent to neighboring traffic lights or a central controller.
    It is possible to use this information creatively. For example, in an emergency
    situation the traffic lights can preferentially give way to an ambulance. When
    the smart traffic light senses an ambulance coming, it clears the path for it
    and also informs neighboring lights about it. Technologies used in these lights
    are cameras, communication technologies, and data analysis modules. Such systems
    have already been deployed in Rio De Janeiro. (5) Accident detection applications:
    a smartphone application designed by White et al. [ 90] detects the occurrence
    of an accident with the help of an accelerometer and acoustic data. It immediately
    sends this information along with the location to the nearest hospital. Some additional
    situational information such as on-site photographs is also sent so that the first
    responders know about the whole scenario and the degree of medical help that is
    required.    Figure 9  Block diagram of a smart parking system. 9.2.2. Smart Water
    Systems Given the prevailing amount of water scarcity in most parts of the world,
    it is very important to manage our water resources efficiently. As a result most
    cities are opting for smart solutions that place a lot of meters on water supply
    lines and storm drains. A good reference in this area is the paper by Hauber-Davidson
    and Idris [ 91]. They describe various designs for smart water meters. These meters
    can be used to measure the degree of water inflow and outflow and to identify
    possible leaks. Smart water metering systems are also used in conjunction with
    data from weather satellites and river water sensors. They can also help us predict
    flooding. 9.2.3. Examples of Smart Cities Barcelona and Stockholm stand out in
    the list of smart cities. Barcelona has a CityOS project, where it aims to create
    a single virtualized OS for all the smart devices and services offered within
    the city. Barcelona has mainly focused on smart transportation (as discussed in
    Section 9.2.1) and smart water. Smart transportation is implemented using a network
    of sensors, centralized analysis, and smart traffic lights. On similar lines Barcelona
    has sensors on most of its storm drains, water storage tanks, and water supply
    lines. This information is integrated with weather and usage information. The
    result of all of this is a centralized water planning strategy. The city is able
    to estimate the water requirements in terms of domestic usage and industrial usage
    and for activities such as landscaping and gardening. Stockholm started way back
    in 1994, and its first step in this direction was to install an extensive fiber
    optic system. Subsequently, the city added thousands of sensors for smart traffic
    and smart water management applications. Stockholm was one of the first cities
    to implement congestion charging. Users were charged money, when they drove into
    congested areas. This was enabled by smart traffic technologies. Since the city
    has a solid network backbone, it is very easy to deploy sensors and applications.
    For example, recently the city created a smart parking system, where it is possible
    to easily locate parking spots nearby. Parking lots have sensors, which let a
    server know about their usage. Once a driver queries the server with her/his GPS
    location, she/he is guided to the nearest parking lot with free slots. Similar
    innovations have taken place in the city’s smart buildings, snow clearance, and
    political announcement systems. 9.3. Social Life and Entertainment Social life
    and entertainment play an important role in an individual’s life. Many applications
    have been developed, which keep track of such human activities. The term “opportunistic
    IoT” [ 92] refers to information sharing among opportunistic devices (devices
    that seek to make contact with other devices) based on movement and availability
    of contacts in the vicinity. Personal devices such as tablets, wearables, and
    mobile phones have sensing and short range communication capabilities. People
    can find and interact with each other when there is a common purpose. Circle Sense
    [ 93] is an application, which detects social activities of a person with the
    help of various types of sensor data. It identifies the social circle of a person
    by analyzing the patterns of social activities and the people present in those
    activities. Various types of social activities and the set of people participating
    in those activities are identified. It uses location sensors to find out where
    the person is and uses Bluetooth for searching people around her. The system has
    built in machine learning algorithms, and it gradually improves its behavior with
    learning. Affective computing [ 94] is a technology, which recognizes, understands,
    stimulates, and responds to the emotions of human beings. There are many parameters,
    which are considered while dealing with human affects such as facial expressions,
    speech, body gestures, hand movements, and sleep patterns. These are analyzed
    to figure out how a person is feeling. The utterance of emotional keywords is
    identified by voice recognition and the quality of voice by looking at acoustic
    features of speech. One of the applications of affective computing is Camy, an
    artificial pet dog [ 95], which is designed to interact with human beings and
    show affection and emotions. Many sensors and actuators are embedded in it. It
    provides emotional support to the owner, encourages playful and active behavior,
    recognizes its owner, and shows love for her and increases the owner’s communication
    with other people. Based on the owner’s mood, Camy interacts with the owner and
    gives her suggestions. Logmusic [ 96] is an entertainment application, which recommends
    music on the basis of the context, such as the weather, temperature, time, and
    location. 9.4. Health and Fitness IoT appliances have proven really beneficial
    in the health and wellness domains. Many wearable devices are being developed,
    which monitor a person’s health condition (see Figure 10).    Figure 10  Block
    diagram of a smart healthcare system. Health applications make independent living
    possible for the elderly and patients with serious health conditions. Currently,
    IoT sensors are being used to continuously monitor and record their health conditions
    and transmit warnings in case any abnormal indicators are found. If there is a
    minor problem, the IoT application itself may suggest a prescription to the patient.
    IoT applications can be used in creating an Electronic Health Record (EHR), which
    is a record of all the medical details of a person. It is maintained by the health
    system. An EHR can be used to record allergies, surges in blood sugar and blood
    pressure. Stress recognition applications are also fairly popular [ 97]. They
    can be realized using smartphone sensors. Wang et al. describe an application
    [ 30], which measures the stress level of a college student and is installed on
    the student’s smartphone. It senses the locations the student visits during the
    whole day, the amount of physical activity, amount of sleep and rest, and her/his
    interaction and relationships with other people (audio data and calls). In addition,
    it also conducts surveys with the student by randomly popping up a question in
    the smartphone. Using all of this data and analyzing it intelligently, the level
    of stress and academic performance can be measured. In the fitness sector, we
    have applications that monitor how fit we are based on our daily activity level.
    Smartphone accelerometer data can be used for activity detection by applying complex
    algorithms. For example, we can measure the number of steps taken and the amount
    of exercise done by using fitness trackers. Fitness trackers are available in
    the market as wearables to monitor the fitness level of an individual. In addition,
    gym apparatus can be fitted with sensors to count the number of times an exercise
    is performed. For example, a smart mat [ 98] can count the number of exercise
    steps performed on it. This is implemented using pressure sensors on the mat and
    then by analyzing the patterns of pressure, and the shape of the contact area.
    9.5. Smart Environment and Agriculture Environmental parameters such as temperature
    and humidity are important for agricultural production. Sensors are used by farmers
    in the field to measure such parameters and this data can be used for efficient
    production. One application is automated irrigation according to weather conditions.
    Production using greenhouses [ 99] is one of the main applications of IoT in agriculture.
    Environmental parameters measured in terms of temperature, soil information, and
    humidity are measured in real time and sent to a server for analysis. The results
    are then used to improve crop quality and yield. Pesticide residues in crop production
    are detected using an Acetylcholinesterase biosensor [ 100]. This data is saved
    and analyzed for extracting useful information such as the sample size, time,
    location, and amount of residues. We can thus maintain the quality of the crop.
    Moreover, a QR code can be used to uniquely identify a carton of farm produce.
    Consumers can scan the QR code and check the amount of pesticides in it (via a
    centralized database) online before buying. Air pollution is an important concern
    today because it is changing the climate of the earth and degrading air quality.
    Vehicles cause a lot of air pollution. An IoT application proposed by Manna et
    al. [ 39] monitors air pollution on the roads. It also tracks vehicles that cause
    an undue amount of pollution. Electrochemical toxic gas sensors can also be used
    to measure air pollution. Vehicles are identified by RFID tags. RFID readers are
    placed on both sides of the road along with the gas sensors. With this approach
    it is possible to identify and take action against polluting vehicles. 9.6. Supply
    Chain and Logistics IoT tries to simplify real world processes in business and
    information systems [ 101]. The goods in the supply chain can be tracked easily
    from the place of manufacture to the final places of distribution using sensor
    technologies such as RFID and NFC. Real time information is recorded and analyzed
    for tracking. Information about the quality and usability of the product can also
    be saved in RFID tags attached with the shipments. Bo and Guangwen [ 102] explain
    an information transmission system for supply chain management, which is based
    on the Internet of Things. RFID tags uniquely identify a product automatically
    and a product information network is created to transmit this information in real
    time along with location information. This system helps in automatic collection
    and analysis of all the information related to supply chain management, which
    may help examine past demand and come up with a forecast of future demand. Supply
    chain components can get access to real time data and all of this information
    can be analyzed to get useful insights. This will in the long run improve the
    performance of supply chain systems. 9.7. Energy Conservation The smart grid is
    information and communication technology enabled modern electricity generation,
    transmission, distribution, and consumption system [ 103]. To make electric power
    generation, transmission, and distribution smart, the concept of smart grids adds
    intelligence at each step and also allows the two-way flow of power (back from
    the consumer to the supplier). This can save a lot of energy and help consumers
    better understand the flow of power and dynamic pricing. In a smart grid, power
    generation is distributed. There are sensors deployed throughout the system to
    monitor everything. It is actually a distributed network of microgrids [ 104].
    Microgrids generate power to meet demands of local sites and transmit back the
    surplus energy to the central grid. Microgrids can also demand energy from the
    central grid in case of a shortfall. Two-way flow of power also benefits consumers,
    who are also using their own generated energy occasionally (say, solar, or wind
    power); the surplus power can be transmitted back so that it is not wasted. The
    user will also get paid for that power. Some of the IoT applications in a smart
    grid are online monitoring of transmission lines for disaster prevention and efficient
    use of power in smart homes by having a smart meter for monitoring energy consumption
    [ 105]. Smart meters read and analyze consumption patterns of power at regular
    and peak load times. This information is then sent to the server and also made
    available to the user. The generation is then set according to the consumption
    patterns. In addition, the user can adjust her/his use so as to reduce costs.
    Smart power appliances can leverage this information and operate when the prices
    are low. 10. Design Considerations in an IoT System Now, that we have profiled
    most of the IoT technologies, let us look at some of the design considerations
    for designing a practical IoT network. The first consideration is the design of
    the sensors. Even though there might not be much of a choice regarding the sensors,
    there is definitely a lot of choice regarding the processing and networking capabilities
    that are bundled along with the sensors. Our choices range from small sub-mW boards
    meant for sensor motes to Arduino or Atom boards that consume 300–500 mW of power.
    This choice depends on the degree of analytics and data preprocessing that we
    want to perform at the sensor itself. Secondly, there is an issue of logistics
    also. To create a sub-mW board, we need board design expertise, and this might
    not be readily available. Hence, it might be advisable to bundle a sensor with
    commercially available embedded processor kits. The next important consideration
    is communication. In IoT nodes, power is the most dominant issue. The power required
    to transmit and receive messages is a major fraction of the overall power, and
    as a result a choice of the networking technology is vital. The important factors
    that we need to consider are the distance between the sender and the receiver,
    the nature of obstacles, signal distortion, ambient noise, and governmental regulations.
    Based on these key factors, we need to choose a given wireless networking protocol.
    For example, if we just need to communicate inside a small building, we can use
    Zigbee, whereas if we need communication in a smart city, we should choose Sigfox
    or LoraWAN. In addition, often there are significant constraints on the frequency
    and the power that can be spent in transmission. These limitations are mainly
    imposed by government agencies. An apt decision needs to be made by taking all
    of these factors into account. Let us then come to the middleware. The first choice
    that needs to be made is to choose between an open source middleware such as FiWare
    or a proprietary solution. There are pros and cons of both. It is true that open
    source middleware is in theory more flexible; however, they may have limited support
    for IoT devices. We ideally want a middleware solution to interoperate with all
    kinds of communication protocols and devices; however, that might not be the case.
    Hence, if we need strict compatibility with certain devices and protocols, a proprietary
    solution is better. Nevertheless, open source offerings have cost advantages and
    are sometimes easier to deploy. We also need to choose the communication protocol
    and ensure that it is compatible with the firewalls in the organizations involved.
    In general choosing a protocol based on HTTP is the best from this point of view.
    We also need to choose between TCP and UDP. UDP is always better from the point
    of view of power consumption. Along with these considerations, we also need to
    look at options to store sensor data streams, querying languages, and support
    for generating dynamic alerts. Finally, let us consider the application layer.
    Most IoT frameworks provide significant amount of support for creating the application
    layer. This includes data mining, data processing, and visualization APIs. Creating
    mashups and dashboards of data is nowadays very easy to do given the extensive
    support provided by IoT frameworks. Nevertheless, here the tradeoff is between
    the features provided and the resources that are required. We do not need a very
    heavy framework if we do not desire a lot of features. This call needs to be taken
    by the application developers. 11. Conclusion In this survey paper we presented
    a survey of the current technologies used in the IoT domain as of 2016. Currently,
    this field is in a very nascent stage. The technologies in the core infrastructure
    layers are showing signs of maturity. However, a lot more needs to happen in the
    areas of IoT applications and communication technologies. These fields will definitely
    mature and impact human life in inconceivable ways over the next decade. Competing
    Interests The authors declare that there is no conflict of interests regarding
    the publication of this paper. References O. Vermesan, P. Friess, P. Guillemin
    et al., “Internet of things strategic research roadmap,” in Internet of Things:
    Global Technological and Societal Trends, vol. 1, pp. 9–52, 2011. View at: Google
    Scholar I. Peña-López, Itu Internet Report 2005: The Internet of Things, 2005.
    I. Mashal, O. Alsaryrah, T.-Y. Chung, C.-Z. Yang, W.-H. Kuo, and D. P. Agrawal,
    “Choices for interaction with things on Internet and underlying issues,” Ad Hoc
    Networks, vol. 28, pp. 68–90, 2015. View at: Publisher Site | Google Scholar O.
    Said and M. Masud, “Towards internet of things: survey and future vision,” International
    Journal of Computer Networks, vol. 5, no. 1, pp. 1–17, 2013. View at: Google Scholar
    M. Wu, T.-J. Lu, F.-Y. Ling, J. Sun, and H.-Y. Du, “Research on the architecture
    of internet of things,” in Proceedings of the 3rd International Conference on
    Advanced Computer Theory and Engineering (ICACTE ''10), vol. 5, pp. V5-484–V5-487,
    IEEE, Chengdu, China, August 2010. View at: Publisher Site | Google Scholar R.
    Khan, S. U. Khan, R. Zaheer, and S. Khan, “Future internet: the internet of things
    architecture, possible applications and key challenges,” in Proceedings of the
    10th International Conference on Frontiers of Information Technology (FIT ''12),
    pp. 257–260, December 2012. View at: Google Scholar H. Ning and Z. Wang, “Future
    internet of things architecture: like mankind neural system or social organization
    framework?” IEEE Communications Letters, vol. 15, no. 4, pp. 461–463, 2011. View
    at: Publisher Site | Google Scholar M. Weyrich and C. Ebert, “Reference architectures
    for the internet of things,” IEEE Software, vol. 33, no. 1, pp. 112–116, 2016.
    View at: Publisher Site | Google Scholar J. Gubbi, R. Buyya, S. Marusic, and M.
    Palaniswami, “Internet of Things (IoT): a vision, architectural elements, and
    future directions,” Future Generation Computer Systems, vol. 29, no. 7, pp. 1645–1660,
    2013. View at: Publisher Site | Google Scholar F. Bonomi, R. Milito, P. Natarajan,
    and J. Zhu, “Fog computing: a platform for internet of things and analytics,”
    in Big Data and Internet of Things: A Road Map for Smart Environments, pp. 169–186,
    Springer, Berlin, Germany, 2014. View at: Google Scholar F. Bonomi, R. Milito,
    J. Zhu, and S. Addepalli, “Fog computing and its role in the internet of things,”
    in Proceedings of the 1st ACM MCC Workshop on Mobile Cloud Computing, pp. 13–16,
    2012. View at: Google Scholar I. Stojmenovic and S. Wen, “The fog computing paradigm:
    scenarios and security issues,” in Proceedings of the Federated Conference on
    Computer Science and Information Systems (FedCSIS ''14), pp. 1–8, IEEE, Warsaw,
    Poland, September 2014. View at: Publisher Site | Google Scholar M. Aazam and
    E.-N. Huh, “Fog computing and smart gateway based communication for cloud of things,”
    in Proceedings of the 2nd IEEE International Conference on Future Internet of
    Things and Cloud (FiCloud ''14), pp. 464–470, Barcelona, Spain, August 2014. View
    at: Publisher Site | Google Scholar L. Atzori, A. Iera, and G. Morabito, “SIoT:
    giving a social structure to the internet of things,” IEEE Communications Letters,
    vol. 15, no. 11, pp. 1193–1195, 2011. View at: Publisher Site | Google Scholar
    M. Swan, “Sensor mania! The internet of things, wearable computing, objective
    metrics, and the quantified self 2.0,” Journal of Sensor and Actuator Networks,
    vol. 1, no. 3, pp. 217–253, 2012. View at: Publisher Site | Google Scholar N.
    D. Lane, E. Miluzzo, H. Lu, D. Peebles, T. Choudhury, and A. T. Campbell, “A survey
    of mobile phone sensing,” IEEE Communications Magazine, vol. 48, no. 9, pp. 140–150,
    2010. View at: Publisher Site | Google Scholar L. Atzori, A. Iera, and G. Morabito,
    “The Internet of Things: a survey,” Computer Networks, vol. 54, no. 15, pp. 2787–2805,
    2010. View at: Publisher Site | Google Scholar A. Whitmore, A. Agarwal, and L.
    Da Xu, “The internet of things—a survey of topics and trends,” Information Systems
    Frontiers, vol. 17, no. 2, pp. 261–274, 2015. View at: Publisher Site | Google
    Scholar D. Zeng, S. Guo, and Z. Cheng, “The web of things: a survey,” Journal
    of Communications, vol. 6, no. 6, pp. 424–438, 2011. View at: Publisher Site |
    Google Scholar S. Bandyopadhyay, M. Sengupta, S. Maiti, and S. Dutta, “Role of
    middleware for internet of things: a study,” International Journal of Computer
    Science & Engineering Survey, vol. 2, no. 3, pp. 94–105, 2011. View at: Google
    Scholar J. Soldatos, N. Kefalakis, M. Hauswirth et al., “Openiot: open source
    internet of-things in the cloud,” in Interoperability and Open-Source Solutions
    for the Internet of Things: International Workshop, FP7 OpenIoT Project, Held
    in Conjunction with SoftCOM 2014, Split, Croatia, September 18, 2014, Invited
    Papers, vol. 9001 of Lecture Notes in Computer Science, pp. 13–25, Springer, Berlin,
    Germany, 2015. View at: Publisher Site | Google Scholar A. Ranganathan, J. Al-Muhtadi,
    S. Chetan, R. Campbell, and M. D. Mickunas, “Middlewhere: a middleware for location
    awareness in ubiquitous computing applications,” in ACM/IFIP/USENIX International
    Conference on Distributed Systems Platforms and Open Distributed Processing Middleware
    2004, pp. 397–416, Springer, New York, NY, USA, 2004. View at: Google Scholar
    M. Eisenhauer, P. Rosengren, and P. Antolin, “A development platform for integrating
    wireless devices and sensors into ambient intelligence systems,” in Proceedings
    of the 6th IEEE Annual Communications Society Conference on Sensor, Mesh and Ad
    Hoc Communications and Networks Workshops (SECON Workshops ''09), pp. 1–3, IEEE,
    Rome, Italy, June 2009. View at: Publisher Site | Google Scholar T. Zahariadis,
    A. Papadakis, F. Alvarez et al., “FIWARE lab: managing resources and services
    in a cloud federation supporting future internet applications,” in Proceedings
    of the 7th IEEE/ACM International Conference on Utility and Cloud Computing (UCC
    ''14), pp. 792–799, IEEE, London, UK, December 2014. View at: Publisher Site |
    Google Scholar A. Schmidt and K. Van Laerhoven, “How to build smart appliances?”
    IEEE Personal Communications, vol. 8, no. 4, pp. 66–71, 2001. View at: Publisher
    Site | Google Scholar W. Z. Khan, Y. Xiang, M. Y. Aalsalem, and Q. Arshad, “Mobile
    phone sensing systems: a survey,” IEEE Communications Surveys & Tutorials, vol.
    15, no. 1, pp. 402–427, 2013. View at: Publisher Site | Google Scholar Accelerometers,
    Chris Woodford, http://www.explainthatstuff.com/accelerometers.html. How Do Global
    Positioning Systems, or GPS, Work?, 2005, https://www.nasa.gov/audience/foreducators/topnav/materials/listbytype/How_Do_Global_Positioning_Systems.html#.VmxoY5Ph5z0.
    A. Anjum and M. U. Ilyas, “Activity recognition using smartphone sensors,” in
    Proceedings of the IEEE 10th Consumer Communications and Networking Conference
    (CCNC ''13), pp. 914–919, Las Vegas, Nev, USA, January 2013. View at: Publisher
    Site | Google Scholar R. Wang, F. Chen, Z. Chen et al., “Studentlife: assessing
    mental health, academic performance and behavioral trends of college students
    using smartphones,” in Proceedings of the ACM International Joint Conference on
    Pervasive and Ubiquitous Computing (UbiComp ''14), pp. 3–14, Seattle, Wash, USA,
    September 2014. View at: Publisher Site | Google Scholar F. J. McClernon and R.
    R. Choudhury, “I am your smartphone, and i know you are about to smoke: the application
    of mobile sensing and computing approaches to smoking research and treatment,”
    Nicotine and Tobacco Research, vol. 15, no. 10, pp. 1651–1654, 2013. View at:
    Publisher Site | Google Scholar L. Pei, R. Guinness, R. Chen et al., “Human behavior
    cognition using smartphone sensors,” Sensors, vol. 13, no. 2, pp. 1402–1424, 2013.
    View at: Publisher Site | Google Scholar N. Bui and M. Zorzi, “Health care applications:
    a solution based on the internet of things,” in Proceedings of the 4th International
    Symposium on Applied Sciences in Biomedical and Communication Technologies (ISABEL
    ''11), ACM, Barcelona, Spain, October 2011. View at: Publisher Site | Google Scholar
    M. J. McGrath and C. N. Scanaill, “Body-worn, ambient, and consumer sensing for
    health applications,” in Sensor Technologies, pp. 181–216, Springer, 2013. View
    at: Google Scholar A. Pantelopoulos and N. G. Bourbakis, “A survey on wearable
    sensor-based systems for health monitoring and prognosis,” IEEE Transactions on
    Systems, Man and Cybernetics Part C: Applications and Reviews, vol. 40, no. 1,
    pp. 1–12, 2010. View at: Publisher Site | Google Scholar J. H. Gruzelier, “EEG-neurofeedback
    for optimising performance. I: a review of cognitive and affective outcome in
    healthy participants,” Neuroscience and Biobehavioral Reviews, vol. 44, pp. 124–141,
    2014. View at: Publisher Site | Google Scholar P. K. Sekhar, E. L. Brosha, R.
    Mukundan, and F. H. Garzon, “Chemical sensors for environmental monitoring and
    homeland security,” The Electrochemical Society Interface, vol. 19, no. 4, pp.
    35–40, 2010. View at: Google Scholar N. Bhattacharyya and R. Bandhopadhyay, “Electronic
    nose and electronic tongue,” in Nondestructive Evaluation of Food Quality, pp.
    73–100, Springer, Berlin, Germany, 2010. View at: Google Scholar S. Manna, S.
    S. Bhunia, and N. Mukherjee, “Vehicular pollution monitoring using IoT,” in International
    Conference on Recent Advances and Innovations in Engineering, ICRAIE 2014, ind,
    May 2014. View at: Publisher Site | Google Scholar R. Want, “An introduction to
    RFID technology,” IEEE Pervasive Computing, vol. 5, no. 1, pp. 25–33, 2006. View
    at: Publisher Site | Google Scholar X. Zhu, S. K. Mukhopadhyay, and H. Kurata,
    “A review of RFID technology and its managerial applications in different industries,”
    Journal of Engineering and Technology Management, vol. 29, no. 1, pp. 152–167,
    2012. View at: Publisher Site | Google Scholar E. Welbourne, L. Battle, G. Cole
    et al., “Building the internet of things using RFID: the RFID ecosystem experience,”
    IEEE Internet Computing, vol. 13, no. 3, pp. 48–55, 2009. View at: Publisher Site
    | Google Scholar M. Yannuzzi, R. Milito, R. Serral-Gracia, D. Montero, and M.
    Nemirovsky, “Key ingredients in an IoT recipe: fog computing, cloud computing,
    and more fog computing,” in Proceedings of the IEEE 19th International Workshop
    on Computer Aided Modeling and Design of Communication Links and Networks (CAMAD
    ''14), pp. 325–329, Athens, Greece, December 2014. View at: Publisher Site | Google
    Scholar H. T. Dinh, C. Lee, D. Niyato, and P. Wang, “A survey of mobile cloud
    computing: architecture, applications, and approaches,” Wireless Communications
    and Mobile Computing, vol. 13, no. 18, pp. 1587–1611, 2013. View at: Publisher
    Site | Google Scholar I. Stojmenovic, “Fog computing: a cloud to the ground support
    for smart things and machine-to-machine networks,” in Proceedings of the Australasian
    Telecommunication Networks and Applications Conference (ATNAC ''14), pp. 117–122,
    Melbourne, Australia, November 2014. View at: Google Scholar M. Aazam, P. P. Hung,
    and E.-N. Huh, “Smart gateway based communication for cloud of things,” in Proceedings
    of the 9th IEEE International Conference on Intelligent Sensors, Sensor Networks
    and Information Processing (IEEE ISSNIP ''14), IEEE, April 2014. View at: Publisher
    Site | Google Scholar P. Agrawal and S. Bhuraria, “Near field communication,”
    SETLabs Bridfings, vol. 10, no. 1, pp. 67–74, 2012. View at: Google Scholar V.
    Coskun, B. Ozdenizci, and K. Ok, “A survey on near field communication (NFC) technology,”
    Wireless Personal Communications, vol. 71, no. 3, pp. 2259–2294, 2013. View at:
    Publisher Site | Google Scholar K. Curran, A. Millar, and C. Mc Garvey, “Near
    Field Communication,” International Journal of Electrical and Computer Engineering
    (IJECE), vol. 2, no. 3, 2012. View at: Publisher Site | Google Scholar Z. Sheng,
    S. Yang, Y. Yu, A. Vasilakos, J. Mccann, and K. Leung, “A survey on the ietf protocol
    suite for the internet of things: standards, challenges, and opportunities,” IEEE
    Wireless Communications, vol. 20, no. 6, pp. 91–98, 2013. View at: Publisher Site
    | Google Scholar J. P. Vasseur and A. Dunkels, “Ip for smart objects,” White Paper
    1, IPSO Alliance, 2008. View at: Google Scholar D. Culler and S. Chakrabarti,
    “6lowpan: incorporating IEEE 802.15. 4 into the IP architecture, IPSO Alliance,”
    White Paper, 2009. View at: Google Scholar J. Vasseur, N. Agarwal, J. Hui, Z.
    Shelby, P. Bertrand, and C. Chauvenet, “Rpl: the ip routing protocol designed
    for low power and lossy networks,” Internet Protocol for Smart Objects (IPSO)
    Alliance 36, 2011. View at: Google Scholar J. P. Vasseur, C. P. Bertrand, B. Aboussouan
    et al., “A survey of several low power link layers for IP smart objects,” White
    Paper, IPSO Alliance, 2010. View at: Google Scholar J. W. Hui and D. E. Culler,
    “Extending IP to low-power, wireless personal area networks,” IEEE Internet Computing,
    vol. 12, no. 4, pp. 37–45, 2008. View at: Publisher Site | Google Scholar W. Colitti,
    K. Steenhaut, N. De Caro, B. Buta, and V. Dobrota, “Evaluation of constrained
    application protocol for wireless sensor networks,” in Proceedings of the 18th
    IEEE Workshop on Local and Metropolitan Area Networks (LANMAN ''11), pp. 1–6,
    IEEE, Chapel Hill, NC, USA, October 2011. View at: Publisher Site | Google Scholar
    Z. Shelby, K. Hartke, and C. Bormann, “The constrained application protocol (CoAP),”
    Tech. Rep., IETF, 2014. View at: Google Scholar B. C. Villaverde, D. Pesch, R.
    De Paz Alberola, S. Fedor, and M. Boubekeur, “Constrained application protocol
    for low power embedded networks: a survey,” in Proceedings of the 6th International
    Conference on Innovative Mobile and Internet Services in Ubiquitous Computing
    (IMIS ''12), pp. 702–707, Palermo, Italy, July 2012. View at: Publisher Site |
    Google Scholar D. Locke, “MQ telemetry transport (MQTT) v3. 1 protocol specification,”
    IBM developerWorks Technical Library, 2010, http://www.ibm.com/developerworks/webservices/library/ws-mqtt/index.html.
    View at: Google Scholar U. Hunkeler, H. L. Truong, and A. Stanford-Clark, “MQTT-S—a
    publish/subscribe protocol for wireless sensor networks,” in Proceedings of the
    3rd IEEE/Create-Net International Conference on Communication System Software
    and Middleware (COMSWARE ''08), pp. 791–798, Bangalore, India, January 2008. View
    at: Publisher Site | Google Scholar A. Stanford-Clark and H. Linh Truon, “MQTT
    for sensor networks (MQTT-S) protocol specification,” International Business Machines
    Corporation Version 1, 2008. View at: Google Scholar C. Gomez, J. Oller, and J.
    Paradells, “Overview and evaluation of bluetooth low energy: an emerging low-power
    wireless technology,” Sensors, vol. 12, no. 9, pp. 11734–11753, 2012. View at:
    Publisher Site | Google Scholar K.-H. Chang, “Bluetooth: a viable solution for
    IoT? [Industry Perspectives],” IEEE Wireless Communications, vol. 21, no. 6, pp.
    6–7, 2014. View at: Publisher Site | Google Scholar C. F. Hughes, Bluetooth low
    energy [Ph.D. thesis], Arizona State University, 2015. M. Siekkinen, M. Hiienkari,
    J. K. Nurminen, and J. Nieminen, “How low energy is bluetooth low energy? Comparative
    measurements with ZigBee/802.15.4,” in Proceedings of the IEEE Wireless Communications
    and Networking Conference Workshops (WCNCW ''12), pp. 232–237, Paris, France,
    April 2012. View at: Publisher Site | Google Scholar B. Shanmuga Sundaram, “A
    quantitative analysis of 802.11ah wireless standard,” International Journal of
    Latest Research in Engineering and Technology, vol. 2, 2016. View at: Google Scholar
    W. Sun, M. Choi, and S. Choi, “Ieee 802.11 ah: a long range 802.11 wlan at sub
    1 ghz,” Journal of ICT Standardization, vol. 1, no. 1, pp. 83–108, 2013. View
    at: Google Scholar P. Baronti, P. Pillai, V. W. C. Chook, S. Chessa, A. Gotta,
    and Y. F. Hu, “Wireless sensor networks: a survey on the state of the art and
    the 802.15.4 and ZigBee standards,” Computer Communications, vol. 30, no. 7, pp.
    1655–1695, 2007. View at: Publisher Site | Google Scholar H. Liu, M. Bolic, A.
    Nayak, and I. Stojmenović, “Taxonomy and challenges of the integration of RFID
    and wireless sensor networks,” IEEE Network, vol. 22, no. 6, pp. 26–32, 2008.
    View at: Publisher Site | Google Scholar A. Mitrokotsa and C. Douligeris, “Integrated
    RFID and sensor networks: architectures and applications,” in RFID and Sensor
    Networks: Architectures, Protocols, Security and Integrations, pp. 511–535, Auerbach
    Publications, 2009. View at: Google Scholar M. A. Chaqfeh and N. Mohamed, “Challenges
    in middleware solutions for the internet of things,” in Proceedings of the 13th
    International Conference on Collaboration Technologies and Systems (CTS ''12),
    pp. 21–26, Denver, Colo, USA, May 2012. View at: Publisher Site | Google Scholar
    M. A. Razzaque, M. Milojevic-Jevric, A. Palade, and S. Cla, “Middleware for internet
    of things: a survey,” IEEE Internet of Things Journal, vol. 3, no. 1, pp. 70–95,
    2016. View at: Publisher Site | Google Scholar Z. Song, A. A. Cárdenas, and R.
    Masuoka, “Semantic middleware for the internet of things,” in Proceedings of the
    2nd International Internet of Things Conference (IoT ''10), December 2010. View
    at: Publisher Site | Google Scholar A. Katasonov, O. Kaykova, O. Khriyenko, S.
    Nikitin, and V. Terziyan, “Smart semantic middleware for the internet of things,”
    in Proceedings of the 5th International Conference on Informatics in Control,
    Automation and Robotics (ICINCO ''08), pp. 169–178, Funchal, Portugal, May 2008.
    View at: Google Scholar D. J. Cook, M. Youngblood, E. O. Heierman III et al.,
    “MavHome: an agent-based smart home,” in Proceedings of the 1st IEEE International
    Conference on Pervasive Computing and Communications (PerCom ''03), pp. 521–524,
    March 2003. View at: Google Scholar S. K. Das, D. J. Cook, A. Bhattacharya, E.
    O. Heierman III, and T.-Y. Lin, “The role of prediction algorithms in the MavHome
    smart home architecture,” IEEE Wireless Communications, vol. 9, no. 6, pp. 77–84,
    2002. View at: Publisher Site | Google Scholar D.-M. Han and J.-H. Lim, “Design
    and implementation of smart home energy management systems based on ZigBee,” IEEE
    Transactions on Consumer Electronics, vol. 56, no. 3, pp. 1417–1425, 2010. View
    at: Publisher Site | Google Scholar N. Noury, T. Hervé, V. Rialle et al., “Monitoring
    behavior in home using a smart fall sensor and position sensors,” in Proceedings
    of the 1st Annual International IEEE-EMBS Special Topic Conference on Microtechnologies
    in Medicine and Biology (MMB ''00), pp. 607–610, Lyon, France, October 2000. View
    at: Publisher Site | Google Scholar A. Sixsmith and N. Johnson, “A smart sensor
    to detect the falls of the elderly,” IEEE Pervasive Computing, vol. 3, no. 2,
    pp. 42–47, 2004. View at: Publisher Site | Google Scholar M. Yu, A. Rhuma, S.
    M. Naqvi, L. Wang, and J. Chambers, “A posture recognition-based fall detection
    system for monitoring an elderly person in a smart home environment,” IEEE Transactions
    on Information Technology in Biomedicine, vol. 16, no. 6, pp. 1274–1286, 2012.
    View at: Google Scholar W. Keith Edwards and R. E. Grinter, “At home with ubiquitous
    computing: seven challenges,” in Ubicomp 2001: Ubiquitous Computing, pp. 256–272,
    Springer, 2001. View at: Google Scholar R. J. Robles and T.-H. Kim, “A Review
    on security in smart home development,” International Journal of Smart Home, vol.
    15, 2010. View at: Google Scholar R. J. Robles, T.-H. Kim, D. Cook, and S. Das,
    “A review on security in smart home development,” International Journal of Advanced
    Science and Technology, vol. 15, 2010. View at: Google Scholar G. Dimitrakopoulos,
    “Intelligent transportation systems based on internet-connected vehicles: fundamental
    research areas and challenges,” in Proceedings of the 11th International Conference
    on ITS Telecommunications (ITST ''11), pp. 145–151, IEEE, Saint Petersburg, Russia,
    August 2011. View at: Publisher Site | Google Scholar S.-H. Yu, J.-W. Hsieh, Y.-S.
    Chen, and W.-F. Hu, “An automatic traffic surveillance system for vehicle tracking
    and classification,” in Image Analysis, pp. 379–386, Springer, 2003. View at:
    Google Scholar M. Lv, L. Chen, G. Chen, and D. Zhang, “Detecting traffic congestions
    using cell phone accelerometers,” in Proceedings of the International Joint Conference
    on Pervasive and Ubiquitous Computing (UbiComp ''14), pp. 107–110, Seattle, Wash,
    USA, September 2014. View at: Publisher Site | Google Scholar W. Hu, X. Hu, J.-Q.
    Deng et al., “Mood-fatigue analyzer: towards context-aware mobile sensing applications
    for safe driving,” in Proceedings of the 1st ACM Workshop on Middleware for Context-Aware
    Applications in the IoT (M4IOT ''14), pp. 19–24, ACM, Bordeaux, France, December
    2014. View at: Publisher Site | Google Scholar H. Singh, J. S. Bhatia, and J.
    Kaur, “Eye tracking based driver fatigue monitoring and warning system,” in Proceedings
    of the India International Conference on Power Electronics (IICPE ''10), pp. 1–6,
    New Delhi, India, January 2011. View at: Publisher Site | Google Scholar H. Eren,
    S. Makinist, E. Akin, and A. Yilmaz, “Estimating driving behavior by a smartphone,”
    in Proceedings of the IEEE Intelligent Vehicles Symposium (IV ''12), pp. 234–239,
    Madrid, Spain, June 2012. View at: Publisher Site | Google Scholar J. White, C.
    Thompson, H. Turner, B. Dougherty, and D. C. Schmidt, “WreckWatch: automatic traffic
    accident detection and notification with smartphones,” Mobile Networks and Applications,
    vol. 16, no. 3, pp. 285–303, 2011. View at: Publisher Site | Google Scholar G.
    Hauber-Davidson and E. Idris, “Smart water metering,” Water, vol. 33, no. 3, pp.
    56–59, 2006. View at: Google Scholar B. Guo, D. Zhang, Z. Wang, Z. Yu, and X.
    Zhou, “Opportunistic IoT: Exploring the harmonious interaction between human and
    the internet of things,” Journal of Network and Computer Applications, vol. 36,
    no. 6, pp. 1531–1539, 2013. View at: Publisher Site | Google Scholar G. Liang,
    J. Cao, and W. Zhu, “CircleSense: a pervasive computing system for recognizing
    social activities,” in Proceedings of the 11th IEEE International Conference on
    Pervasive Computing and Communications (PerCom ''13), pp. 201–206, IEEE, San Diego,
    Calif, USA, March 2013. View at: Publisher Site | Google Scholar R. W. Picard
    and R. Picard, Affective Computing, vol. 252, MIT Press, Cambridge, UK, 1997.
    Y.-K. Row and T.-J. Nam, “CAMY: applying a pet dog analogy to everyday ubicomp
    products,” in Proceedings of the ACM International Joint Conference on Pervasive
    and Ubiquitous Computing (UbiComp ''14), pp. 63–74, Seattle, Wash, USA, September
    2014. View at: Publisher Site | Google Scholar M. Lee and J.-D. Cho, “Logmusic:
    context-based social music recommendation service on mobile device,” in Proceedings
    of the ACM International Joint Conference on Pervasive and Ubiquitous Computing
    (UbiComp ''14), pp. 95–98, Seattle, Wash, USA, September 2014. View at: Publisher
    Site | Google Scholar K. Frank, P. Robertson, M. Gross, and K. Wiesner, “Sensor-based
    identification of human stress levels,” in Proceedings of the IEEE International
    Conference on Pervasive Computing and Communications Workshops (PerCom Workshops
    ''13), pp. 127–132, San Diego, Calif, USA, March 2013. View at: Publisher Site
    | Google Scholar M. Sundholm, J. Cheng, B. Zhou, A. Sethi, and P. Lukowicz, “Smart-mat:
    recognizing and counting gym exercises with low-cost resistive pressure sensing
    matrix,” in Proceedings of the ACM International Joint Conference on Pervasive
    and Ubiquitous Computing (UbiComp ''14), pp. 373–382, Seattle, Wash, USA, September
    2014. View at: Publisher Site | Google Scholar J.-C. Zhao, J.-F. Zhang, Y. Feng,
    and J.-X. Guo, “The study and application of the IOT technology in agriculture,”
    in Proceedings of the 3rd IEEE International Conference on Computer Science and
    Information Technology (ICCSIT ''10), pp. 462–465, Chengdu, China, July 2010.
    View at: Publisher Site | Google Scholar G. Zhao, Y. Guo, X. Sun, and X. Wang,
    “A system for pesticide residues detection and agricultural products traceability
    based on acetylcholinesterase biosensor and internet of things,” International
    Journal of Electrochemical Science, vol. 10, no. 4, pp. 3387–3399, 2015. View
    at: Google Scholar P. Ferreira, R. Martinho, and D. Domingos, “Iot-aware business
    processes for logistics: limitations of current approaches,” in Proceedings of
    the Inforum Conference, vol. 3, pp. 612–613, 2010. View at: Google Scholar Y.
    Bo and H. Guangwen, “Supply chain information transmission based on RFID and internet
    of things,” in Proceedings of the Second ISECS International Colloquium on Computing,
    Communication, Control, and Management (CCCM ''09), pp. 166–169, Sanya, China,
    August 2009. View at: Publisher Site | Google Scholar S. Karnouskos, “The cooperative
    internet of things enabled smart grid,” in Proceedings of the 14th IEEE International
    Symposium on Consumer Electronics (ISCE ''10), pp. 7–10, June 2010. View at: Google
    Scholar H. Farhangi, “The path of the smart grid,” IEEE Power and Energy Magazine,
    vol. 8, no. 1, pp. 18–28, 2010. View at: Publisher Site | Google Scholar J. Liu,
    X. Li, X. Chen, Y. Zhen, and L. Zeng, “Applications of internet of things on smart
    grid in China,” in Proceedings of the 13th International Conference on Advanced
    Communication Technology: Smart Service Innovation through Mobile Interactivity
    (ICACT ''11), pp. 13–17, February 2011. View at: Google Scholar Copyright Copyright
    © 2017 Pallavi Sethi and Smruti R. Sarangi. This is an open access article distributed
    under the Creative Commons Attribution License, which permits unrestricted use,
    distribution, and reproduction in any medium, provided the original work is properly
    cited. PDF Download Citation Download other formats Order printed copies Views
    537844 Downloads 55909 Citations 1.2k About Us Contact us Partnerships Blog Journals
    Article Processing Charges Print editions Authors Editors Reviewers Partnerships
    Hindawi XML Corpus Open Archives Initiative Fraud prevention Follow us: Privacy
    PolicyTerms of ServiceResponsible Disclosure PolicyCookie PolicyCopyrightModern
    slavery statementCookie Preferences'
  inline_citation: '>'
  journal: Journal of Electrical and Computer Engineering
  limitations: '>'
  pdf_link: http://downloads.hindawi.com/journals/jece/2017/9324035.pdf
  publication_year: 2017
  relevance_score1: 0
  relevance_score2: 0
  title: 'Internet of Things: Architectures, Protocols, and Applications'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1002/poi3.85
  analysis: '>'
  authors:
  - Pete Burnap
  - Matthew Leighton Williams
  citation_count: 457
  full_citation: '>'
  full_text: '>

    UNCL: University Of Nebraska - Linc Acquisitions Accounting Search within Login
    / Register Policy & Internet Article Open Access Cyber Hate Speech on Twitter:
    An Application of Machine Classification and Statistical Modeling for Policy and
    Decision Making Pete Burnap,  Matthew L. Williams First published: 22 April 2015
    https://doi.org/10.1002/poi3.85Citations: 314 SECTIONS PDF TOOLS SHARE Abstract
    The use of “Big Data” in policy and decision making is a current topic of debate.
    The 2013 murder of Drummer Lee Rigby in Woolwich, London, UK led to an extensive
    public reaction on social media, providing the opportunity to study the spread
    of online hate speech (cyber hate) on Twitter. Human annotated Twitter data was
    collected in the immediate aftermath of Rigby''s murder to train and test a supervised
    machine learning text classifier that distinguishes between hateful and/or antagonistic
    responses with a focus on race, ethnicity, or religion; and more general responses.
    Classification features were derived from the content of each tweet, including
    grammatical dependencies between words to recognize “othering” phrases, incitement
    to respond with antagonistic action, and claims of well-founded or justified discrimination
    against social groups. The results of the classifier were optimal using a combination
    of probabilistic, rule-based, and spatial-based classifiers with a voted ensemble
    meta-classifier. We demonstrate how the results of the classifier can be robustly
    utilized in a statistical model used to forecast the likely spread of cyber hate
    in a sample of Twitter data. The applications to policy and decision making are
    discussed. Introduction Research using traditional surveys and interviews has
    identified that crimes with a prejudicial motive are influenced in the short term
    by singular events such as widely publicized murders (Phillips, 1980, on homicide),
    riots (Bobo, Zubrinsky, Johnson, & Oliver, 1994, on race relations), and court
    cases and terrorism (King & Sutton, 2013, on hate crime; Legewie, 2013, on anti-immigrant
    sentiment). Hate crimes have been shown to cluster in time and tend to increase,
    sometimes dramatically, in the aftermath of an antecedent or “trigger” event (King
    & Sutton, 2013). The impacts of hate crime on individuals and communities are
    well documented (see Williams & Tregidga, 2014) and most research is preoccupied
    with where hate crimes happen (risky neighborhoods, demographic factors, etc.),
    while there is little research that looks at when they happen. King and Sutton
    (2013) report that 481 hate crimes with a specific anti-Islamic motive occurred
    in the year following 9/11, with 58 percent of them perpetrated two weeks following
    the event (4 percent of the at-risk period). Such evidence demonstrates that crimes
    entailing a prejudicial motive often occur in close temporal proximity to galvanizing
    events, such as terrorist attacks. It is during this period that decision makers,
    particularly those responsible for minimizing the risk of social disorder through
    community reassurance, local policing, and the online governance of hateful and
    antagonistic content, require additional information on the likelihood of disruption.
    Hate crimes are communicative acts, often provoked by events that incite retribution
    in the targeted group, toward the group that share similar characteristics to
    the perpetrators (King & Sutton, 2013). Collecting and analyzing temporal data
    allows decision makers to study the escalation, duration, diffusion, and de-escalation
    of hate crimes following “trigger” events. However, decision makers are often
    limited in the information that can be obtained in the immediate aftermath of
    such events. When data can be obtained, they are often of low granularity, subject
    to missing information (hate crimes are largely unreported to the police), and
    invariably retrospective. However, the recent widespread adoption of social media
    offers a new opportunity to address these data problems. The continued growth
    of online social networks and microblogging Web services, such as Twitter, enable
    a locomotive, extensive and near real-time data source through which the analysis
    of hateful and antagonistic responses to “trigger” events can be undertaken. Such
    data affords researchers with the possibility to measure the online social mood
    and emotion following large-scale, disruptive, and emotive events such terrorist
    attacks in near real-time. Twitter is a defensible and logical source of data
    for such analysis given that users of social media are more likely to express
    emotional content due to deindividuation (anonymity, lack of self-awareness in
    groups, disinhibition) (Festinger, Pepitone, & Newcomb, 1952). There is also a
    case history relating to the expression of hateful sentiment on social media in
    the United Kingdom, providing evidence of “real world” criminal justice response
    to, and therefore criminalization of, online acts of targeted hateful communication.
    For example, in 2012, Liam Stacey was sentenced to 56 days in prison for posting
    racially offensive comments on Twitter after a U.K. Premier League footballer''s
    cardiac arrest, and in 2014, Declan McCuish was jailed for a year for tweeting
    racist comments about two Glasgow Rangers football players. To date there has
    been very little research into the manifestation and diffusion of hate speech
    and antagonistic content in social media in relation to events that could be classed
    as “trigger” events for hate crimes. In 2013, the murder of Drummer Lee Rigby
    in Woolwich (London) by Islamic extremists led to an extensive social media reaction.
    Given the extreme terrorist motive and public nature of the actions it was conceivable
    that the public response might include written expressions of hateful and antagonistic
    sentiment toward a particular race, ethnicity, or religion, which could be interpreted
    as “hate speech.” In this article, we present a supervised machine learning text
    classifier trained and tested to identify online hate speech—or cyber hate—using
    data collected from Twitter in the immediate aftermath of Lee Rigby''s murder.
    The data were annotated by human coders, who were asked to decide whether the
    tweets they were shown contained hateful and/or antagonistic responses toward
    minority groups. As “Big Data” is a growing topic of study, and its use in policy
    and decision making a current subject of debate (González-Bailón, 2013), we discuss
    the use of supervised machine learning tools to classify a sample of “Big Data,”
    and how the results can be interpreted for use in policy and decision making.
    Data from Twitter, and social media more generally, are exceptionally noisy and
    contain a great deal of grammatical variance, misinformation, and mundane chatter.
    Due to the poor veracity of such data in its raw form, its use in policymaking
    is somewhat hindered. A key contribution of this study is therefore the production
    of a machine classifier that could be developed into a technical solution for
    use by policymakers as part of an existing evidence-based decision-making process.
    Further contributions of the paper are the identification of nuanced features
    of cyber hate on social media using a particular type of syntactic relationship
    within text as a classification feature, and the application of an ensemble machine
    classifier to cyber hate. We include a section on how the classifier can be finely
    trained to suit the needs of policymakers, in order to minimize error and maximize
    confidence in results. We then demonstrate how the results of the classifier can
    be robustly utilized in a statistical model used to forecast the likely spread
    of cyber hate in a sample of Twitter data. Related Work The analysis of subjective
    language has been widely applied to the classification of opinions and emotions
    in text (Wiebe, 2005). Indeed, sentiment analysis, which aims to annotate text
    using a scale that is a measure of the degree of negative and positive sentiment
    within the text, has been applied to data collected from social media to determine
    emotional differences between genders on MySpace (Thelwall, Wilkinson, & Uppal,
    2010a) and study levels of positive and negative sentiment in Facebook (Ahktar
    & Soria, 2009) and Twitter comments (Bollen, Goncalves, Ruan, & Mao, 2011; Thelwall,
    Buckley, & Paltogou, 2011) following real-world events. Specifically focusing
    on hateful and/or antagonistic content, Greevy and Smeaton (2004) classified racist
    content in Web pages using a supervised machine learning approach with a bag-of-words
    (BoW) as features. A BoW approach uses words within a corpus as predictive features
    and ignores word sequence as well as any syntactic or semantic content. This approach
    can lead to misclassification due to word use in different contexts and, if words
    are used as a primary features for classification, it has been shown that combining
    sequential words into n-grams (list of words occurring in sequence from 1–n) improves
    classifier performance by incorporating some degree of context into the features
    (Pendar, 2007). However, an n-gram approach can suffer from the problem of high
    levels of distance between related words—for example, if related words appear
    near the start and near the end of a sentence (Chen, Zhou, Zhu, & Xu, 2012). Dadvar,
    Trieschnigg, and de Jong (2013) used profane words in a social media account username,
    references to profanities and bullying-sensitive topics, and first and second
    person pronouns to classify antagonistic behavior on YouTube. Dinakar, Jones,
    Havasi, Lieberman, and Picard (2012) also focused on the identification of cyberbullying
    using a BoW approach, but also incorporated lists of profane words, parts-of-speech
    and words with negative connotations as machine learning features. Furthermore,
    they included a common-sense reasoning approach to classification by using a database
    that encoded particular knowledge about bullying situations (e.g., associating
    wearing dresses with males). Burnap et al. (2013) developed a rule-based approach
    to classifying antagonistic content on Twitter and, similarly to Dinakar et al.
    (2012), they used associational terms as features. They also included accusational
    and attributional terms targeted at a person or persons following a socially disruptive
    event as features, in an effort to capture the context of the term use. Their
    results demonstrated an improvement on standard learning techniques (see also
    Williams et al., 2013). Chen et al. (2012) identified offensive content by using
    profanities, obscenities, and pejorative terms as features, weighted accordingly
    based on the associated strength of the term, as well as references to people.
    They also produced a set of rules to model offensive content, showing an improvement
    on standard machine learning approaches in terms of a much-reduced false negative
    rate. Identifying syntactic constructs that tend to be insulting or condescending
    is a key function of the “Smokey” abusive message classification tool (Spertus,
    1997), which uses pattern matching and syntactic positioning of words within text
    to classify content at a message level. Mahmud, Ahmed, and Khan (2008) followed
    a similar approach but also incorporated relationships between terms to identify
    “flaming” behavior online. The identification of syntactic relationships within
    text is possible via the development of parsing tools such as the Typed Dependency
    parser from Stanford (Marneffe, MacCartney, & Manning, 2006), though this has
    yet to be applied to hate speech. Data Collection We collected the study data
    set from Twitter during a two-week time window following the “trigger” event—the
    murder of Drummer Lee Rigby in Woolwich, London, UK on May 22, 2013. To ensure
    we maximized the collection of data surrounding the event we used the search term
    “woolwich,” which would include many references to the events at Woolwich and
    also the main hashtag surrounding the event “#woolwich.” The hashtag convention
    is widely used on Twitter to link an individual''s thoughts and comments to an
    event. The two-week data collection window was imposed based on three factors.
    First, existing research indicates that public interest in events typically spikes
    a short time after the event, and then rapidly declines (Downs, 1972). Second,
    this first point was confirmed by tracking the search term “Woolwich” using the
    Google Trends service,1 which records the relative number of searches performed
    on Google over time. Within two weeks, the use of “Woolwich” in Google searches
    had almost returned to preevent levels. Third, more than half of all hate-related
    attacks following 9/11 occurred within two weeks of the event; and we wanted to
    measure the immediate reaction to such events and capture data that perhaps would
    not otherwise be available to policy and decision makers due to the time taken
    to collect, record, and process hate crime results, and therefore be proactive
    in the first two weeks to reduce harm to targeted social groups in an appropriate
    manner. Social media data lend themselves to this purpose given their inherent
    fine-grained temporal characteristics. Tweets are produced by the second, while
    curated and administrative data have a much higher degree of latency in terms
    of both availability to decision makers and measurement of reaction. A total of
    450,000 tweets were collected during the study window. Data Annotation—Crowdsourcing
    Building models to classify data according to a predefined coding scheme is an
    essential task in digital social research, used for the purposes of understanding
    social interactions, beliefs, emotions, and the like. In this research, once the
    Twitter data were collected, we built a supervised machine learning classifier
    to distinguish between hateful and/or antagonistic responses with a focus on race,
    ethnicity, religion, and more general responses, following the event. To complete
    this subjective task using large-scale data analytics, which is absolutely necessary
    for the volumes of data produced, we used machine classifiers to learn the features
    of tweets that are indicative of the class they belong to (cyber hate or general
    response). Once features were learned, we applied the model to the whole data
    set. However, it was essential to understand and explain the limitations of the
    learned model by producing model-specific classification performance results,
    such as precision and recall per class, and confusion matrices (terms that are
    explained in detail later). Thus, we needed a “gold standard” against which to
    test the classification model. Commonly, this is obtained by sampling from a larger
    data set and employing human annotators to label each data point (tweet) according
    to a coding frame (Burnap et al., 2013). The coding frame serves as a set of categories
    or classes into which each data point can be classified. Computationally crowdsourcing
    human annotations is now becoming popular, and Web services such as CrowdFlower
    or the Amazon Mechanical Turk provide programmatic application programming interfaces
    (APIs) through which researchers can automatically upload a data set, coding frame,
    and set of instructions for annotation. The results of the annotation tasks can
    then be split into training and testing data sets for machine learning. From the
    450,000 tweets collected, we sampled 2,000 to be human coded. Coders were provided
    with each tweet and the question: “is this text offensive or antagonistic in terms
    of race ethnicity or religion?” They were presented with a ternary set of classes—yes,
    no, undecided. We utilized the CrowdFlower online service that allows for Human
    Intelligence Tasks, such as coding text into classes, to be distributed over multiple
    workers. Workers can sign up to the service to participate in tasks in return
    for micropayments (small payments set by the task creator based on the number
    of tasks completed to an acceptable standard). Task creators can also specify
    a range of worker requirements such as location and experience, and can verify
    the level of expertise via test questions. Results from workers can then either
    be accepted or rejected, based on level of agreement with other workers. CrowdFlower
    recruits from its pool of workers until each unit of analysis (in this case, each
    tweet) is annotated by a minimum number of workers, as specified by the task creator.
    We required at least four human annotations per tweet as per the convention in
    related research (Thelwall, Buckley, Paltogou, Cai, & Kappas, 2010b). CrowdFlower
    provides an agreement score for each annotated unit, which is based on the majority
    vote of the trusted workers (Kolhatkar, Zinsmeister, & Hirst, 2013). Because CrowdFlower
    continues to recruit workers until the task is complete, there is no guarantee
    that all workers will annotate the same set of units. Indeed, in this case we
    had 158 workers contribute to the task, each annotating a sample of tweets. Therefore
    we cannot calculate traditional interrater reliability scores, such as Krippendorf''s
    Alpha or Cohen''s Kappa to determine agreement between all annotators. However,
    CrowdFlower has been shown to produce an agreement score that compares well to
    these classic measures (Kolhatkar et al., 2013). Based on the output from our
    annotator task we can determine agreement on each unit. The purpose of the experiments
    performed in this article are to establish the accuracy of a machine classifier
    when annotating tweets as hateful and/or antagonistic or not, and thus it is the
    agreement score for the unit of analysis (each tweet), and not the overall human
    agreement for all units that is important for validation. We removed all tweets
    with less than 75 percent agreement and also those upon which the coders could
    reach an absolute decision (i.e., the “undecided” class)—again, following established
    methods from related research (Thelwall et al., 2010a). The results of the annotation
    exercise produced a “gold standard” data set of 1,901 tweets, with 222 instances
    of offensive or antagonistic content (11.68 percent of the annotated sample),
    which could be classed as cyber hate (referred to below as the “cyber hate sample”),
    and 1,679 instances of nonhateful or antagonistic commentary (88.32 percent),
    which we will refer to as “benign.” Ten percent of each class was subsequently
    used as a sample from which to identify appropriate features to build a cyber
    hate classifier. This subsample was not used when testing the classifier. Feature
    Selection It was evident from the cyber hate sample that many of the terms used
    in cyber hate were expletives or derogatory, targeted at specific social groups.
    The sample contained words that are well known derogatory terms for black, asian,
    and muslim social groups, as well as derogatory adjectives (e.g., “black savages”).
    It was evident that the words of the tweets were going to be particularly useful
    features for the classification task. Using the words of the text to be classified,
    known as a BoW technique, is not a particularly novel approach to text classification,
    but the frequency of particular unigram (single word) and bigram (two word) terms
    were overwhelming and needed to be utilized. Of more interest from a sociological
    and common sense reasoning perspective were the numerous instances in the cyber
    hate sample of calls for collective action and hateful incitement toward social
    groups exhibiting protected characteristics. For instance, there were exclamations
    such as “send them home,” “get them out,” and “should be hung.” These exclamations
    clearly follow a pattern that could be encoded in parts-of-speech notation [e.g.,
    Verb, Pronoun, Noun; Verb, Pronoun, Adverb; Verb, Verb, Verb(PT)]. However, the
    benign sample also displayed an abundance of similar patterns, such as “leave
    them alone,” or “they are peaceful.” Thus, parts-of-speech tagging to produce
    features to inform the machine classifier was avoided, as it seemed highly likely
    to cause confusion between the classes. Instead, we implemented the Stanford Lexical
    Parser, along with a context-free lexical parsing model, to extract typed dependencies
    within the tweet text (Marneffe et al., 2006). Typed dependencies provide a representation
    of syntactic grammatical relationships in a sentence (or tweet in this case) that
    can be used as features for classification. The following example explains the
    meaning of such relationships and how they can be used as features to inform the
    machine classifier. Consider the sentence: “Totally fed up with the way this country
    has turned into a haven for terrorists. Send them all back home.” The typed dependency
    parser returns the following output: [root(ROOT-0, Send-1), nsubj(home-5, them-2),
    det(home-5, all-3), amod(home-5, back-4), xcomp(Send-1, home-5)] Within the output
    we can see five instances of typed dependencies. The second instance (nsubj(home-5,
    them-2)) identifies a relationship between “home” and “them,” with “home” being
    the fifth word in the sentence and “them” appearing before “home” as the second
    word. Word order within a sentence is preserved in the type dependency and provides
    a feature for classification as well as the syntactic relationship between words.
    The relationship identified by the parser in this case is nsubj, which is an abbreviation
    of nominal subject. This will include a noun phrase (“them”), which is the syntactic
    subject in the sentence, and an associated relational term (“home”). Linguistically
    therefore, the term “them” is associated with “home” in a relational sense. Sociologically,
    this is an “othering” phrase, which essentially distances “them” from “us” through
    the relational action of removing “them” to their “home,” as perceived by the
    author of the tweet. Similarly, the third typed dependency (det(home-5, all-3))
    identifies a det relationship, which is short for determiner, where a link is
    established between a noun phrase and its determiner. The noun phrase here being
    “home” (as in a place) and the determiner being “all.” Again, this falls into
    an “othering” behavior, suggesting that the entire social group to which the Woolwich
    perpetrators belonged should have a relationship with “home,” which we can assume
    means the perceived “home” of the social group by the author of the tweet (i.e.,
    “not my country”). This combination of linguistics and sociology potentially provides
    a very interesting set of features for the more nuanced classification of cyber
    hate, beyond the BoW approach that utilizes expletives and derogatory terms. It
    allows a more common-sense reasoning approach to classifying cyber hate by considering
    the integration of “othering” terms and calls for retribution action into the
    classification features. Data Preprocessing and Feature Preparation Each tweet
    was computationally transformed into a word vector—a list of all the individual
    words (tokens) in the tweet. All tokens we transformed to lower case to avoid
    capitalized versions of words being treated as separate features to lower case
    versions of the same word. Nonalphanumeric characters other than those present
    in emoticons and exclamatory punctuation were removed, stop words were removed,
    and we stemmed each token to ensure that multiple representations and tenses of
    a word could be considered as a single features; for example, “attacked,” “attackers,”
    and “attacking” can all be reduced to “attack” so the machine can consider the
    verb as a single predictive feature, as well as the various forms of the verb.
    Tokens within each tweet were then clustered into sequential groups of tokens,
    or n-grams, ranging from one to five tokens in length to preserve an element of
    context for each word by encapsulating their surrounding words within a feature.
    Single tokens, or unigrams, were prominent in the cyber hate sample in the form
    of expletives or derogatory terms. Two-token combinations, or bigrams, were also
    present in the form of combinations of expletives, adjectives, and derogatory
    terms. Three-token terms (trigrams) could represent “othering” and incitements
    of retributional action, such as “send them home” or “get them out.” Four- and
    five-token terms contained extended but similar phrases. The BoW approach used
    here is fairly unsophisticated as a feature identification method, as it weights
    each n-gram equally as a feature and is likely to lead to confusion within the
    classification task when words occur frequently in both classes. Therefore, two
    experiments were conducted at the classification stage where in the first experiment
    all n-grams were retained as classification features, while in the second, only
    hateful and derogatory terms sampled from an online racial slur database2 were
    retained, and the remaining n-grams were removed. Classification results were
    produced for each experiment. It was expected that the hateful terms would be
    predictive of cyber hate, but we were interested to see if other terms were also
    statistically significant predictors. To produce a more sophisticated classifier
    capable of learning the grammatical structure of tweets containing cyber hate,
    each tweet was transformed into a set of typed dependencies using the Stanford
    Parser. Each typed dependency was considered as a unigram feature, and we again
    performed clustering on all the typed dependencies in a tweet to identify groups
    of between one and three typed dependency n-grams that represented the syntactic
    structure of each tweet. The number of possible typed dependency relationships
    produced by the Stanford model is around 50, and we suspected that not all relationships
    would be useful for classification. As with the BoW experiments, at the classification
    stage we performed a two-step approach. The first experiment involved testing
    the classifier using all typed dependencies as features. We then performed a meta-analysis
    to better determine which features were more statistically significant at classifying
    cyber hate. To achieve this we ran a Bayesian Logistic Regression (BLR) using
    the typed dependency features extracted from the 10 percent sample of gold standard
    cyber hate and benign tweets. We used the model output of the BLR to establish
    a list of statistical coefficients relating to the probability of each typed dependencies
    n-gram occurring in a hateful or antagonistic tweet. The list was sorted to identify
    the most likely forms of typed dependency relationship to occur in the cyber hate
    class, and these relationships alone were retained as predictive features when
    the classifier was retrained and re-evaluated in a second experiment. Finally,
    we combined both experiments and produced a final testing scenario to determine
    if combining the BoW, typed dependencies, and hateful and derogatory n-grams would
    prove to be the optimal set of features. Model Selection Given our feature set
    of specific words and syntactic features, we aimed to create a set of results
    and related model that could be used to inform policymakers of the risk of cyber
    hate spreading online following events that are likely to incur a hateful or antagonistic
    response toward a specific social group. To produce experimental results we used
    the Java Weka machine learning libraries to develop a number of supervised classifiers
    that were trained and tested using the features discussed in the previous section.
    Each tweet was transformed into a feature vector—a list of attributes that represent
    the tweet for the purposes of training a classifier. Each vector included the
    actual class the tweet belonged to based on the human annotation exercises (reduced
    to a binary “Yes” or “No” as to whether it was hateful or antagonistic or not),
    and a list of n-grams that either included words, typed dependencies, or a combination
    of both, depending on the feature set used to train the classifier. Given the
    prevalence of individual words or short combinations of words in the cyber hate
    sample, it was appropriate to implement a classifier that would make decisions
    based on the likelihood of feature occurrence. We implemented a BLR classifier
    as a probabilistic approach. This classifier identifies statistical coefficients
    for each feature in a vector based on the likelihood of that feature appearing
    in any of the classes available (“Yes” or “No”) and uses this to predict the classes
    of previously unseen tweets. Rule-based approaches to classifying antagonistic
    content have been shown to produce promising results in previous research, and
    the case of cyber hate seemed similar to other work in its accusational and targeted
    construct. Therefore, we employed a Random Forest Decision Tree (RFDT) as a rule-based
    approach to classification. A decision tree approach was chosen because it iteratively
    identifies the feature from the vector that maximizes information gain in a classification
    exercise—or put another way, it quantifies the significance of how using one n-gram
    as a rule to classify a tweet as “Yes,” reduces the uncertainty as to which class
    it belongs to. Performing this step multiple times creates a hierarchical and
    incremental set of rules that can be used to make classification decisions. A
    Random Forest implementation of a decision tree was used because it iteratively
    selects a random subsample of features in the training phase and trains multiple
    decision trees before predicting the outputs and averaging out the results, maximizing
    the reduction in classification error (Breiman, 2001). The approach combines the
    results of a number of decision trees to identify the optimal set of rules, which
    was appropriate in this case because of the amount of noise and grammatical variance
    within the training and testing data sets. A Support Vector Machine (SVM) was
    also used to determine if a spatial classification model would improve or enhance
    on a probabilistic or rule-based model. Feature vectors are plotted in high-dimensional
    space, and hyperplanes (lines that separate the data points) are used to try to
    find the optimum way to divide the space such that the tweets belonging to “Yes”
    and “No” classes are separated. Multiple hyperplanes can be used and the optimal
    hyperplane will be the line that maximizes the separation between classes. The
    rationale for the use of an SVM classifier was to determine whether cyber hate
    tweets and general responses to an event could be separated by spatial differences
    in lexical or syntactic features, as well as with probability and rules to determine
    predictive feature efficiency. In addition to the three individual classifiers,
    we also implemented an “ensemble” classifier where a combination of all three
    was used to make a final classification decision. We used a voting meta-classifier,
    which produces a classification result for each base classifier (BLR, RFDT, and
    SVM) during the training phase, before making a decision on which model to use
    based on its prediction accuracy. A choice can be made based on the base classifier
    with the maximum probability or minimum probability; the results of all base classifiers
    can be averaged; or a majority vote can be taken. We implemented the maximum probability
    to make classification decisions, based on selecting the classification function
    that is most statistically likely to reduce error. Classification Results A 10-fold
    cross-validation approach was used to train and test the supervised machine learning
    methods. This approach has previously been used for building machine classifiers
    for short text (e.g., Thelwall et al., 2010a). It functions by iteratively training
    the classifier with features from 10 percent of the manually coded data set, and
    classifying the remaining 90 percent as “unseen” data, based on the features evident
    in the cases it has encountered in the training data. It then determines the accuracy
    of the classification process and moves on to the next iteration, finally calculating
    the overall accuracy. The results of the classification experiments are provided
    in Table 1 using standard text classification measures of: precision (i.e., for
    class x, how often are tweets classified as x when they should not be—a measure
    of false positives); recall (i.e., for class x, how often are tweets not classified
    as x when they should be—a measure of false negatives); and F-Measure, a harmonized
    mean of precision and recall. The results for each measure range between 0 (worst)
    and 1 (best). The formulae for calculating these results are as follows (where
    TP = true positives, FP = false positives, TN = true negative, and FN = false
    negative): Table 1. Cyber Hate Classification Results BLR RFDT SVM Voted Ensemble
    (Max Probability) P R F P R F P R F P R F n-Gram words (1–5) with 2,000 features
    0.76 FP = 46 0.67 FN = 74 0.71 0.76 FP = 38 0.55 FN = 99 0.64 0.80 FP = 38 0.69
    FP = 69 0.74 0.73 FP = 58 0.71 FN = 65 00.72 n-Gram hateful terms 0.89 FP = 19
    0.66 FP = 75 0.76 0.89 FP = 19 0.66 FN = 75 0.76 0.89 FP = 19 0.66 FN = 75 0.76
    0.89 FP = 19 0.66 FN = 75 0.76 n-Gram words (1–5) with 2,000 features + hateful
    yerms 0.75 FP = 40 0.55 FN = 100 0.64 0.81 FP = 21 0.42 FN = 128 0.56 0.74 FP = 50
    0.65 FN = 78 0.69 0.68 FP = 70 0.66 FN = 75 0.67 n-Gram typed dependencies 0.52
    FP = 50 0.25 FN = 167 0.34 0.56 FP = 36 0.21 FN = 176 0.30 0.53 FP = 48 0.24 FN = 168
    0.33 0.49 FP = 57 0.25 FN = 167 0.25 n-Gram reduced typed dependencies 1 FP = 0
    0.18 FN = 183 0.29 0.97 FP = 1 0.14 FN = 190 0.25 1 FP = 0 0.17 FN = 185 0.28
    1 FP = 0 0.18 FN = 183 0.29 n-Gram reduced typed dependencies + hateful terms
    0.89 FP = 19 0.69 FN = 70 0.77 0.89 FP = 19 0.68 FN = 71 0.77 0.89 FP = 19 0.69
    FN = 70 0.77 0.89 FP = 19 0.69 FN = 70 0.77 n-Gram words (1–5) with 2,000 features + n-Gram
    reduced typed dependencies + hateful terms 0.87 FP = 16 0.50 FN = 111 0.63 0.88
    FP = 10 0.32 FN = 150 0.42 0.88 FP = 18 0.59 FN = 91 0.70 0.83 FP = 27 0.60 FN = 88
    0.70 Because of the specific interest in the accurate detection of hateful and
    antagonistic content, the results reported in Table 1 are the precision, recall
    and f-measure for the Yes class ONLY. The number of false positives (instances
    where benign content has been classified as cyber hate) and false negatives (where
    cyber hate has been classified as benign) are also reported. Table 2 provides
    results for the best performing classifier and includes both Yes and No classes,
    as well as an overall performance score. Table 3 presents the confusion matrix
    for the best performing classifier with a breakdown of classifier error. Table
    2. Voted Classifier Full Results Voted Classifier P R F Yes 0.89 0.69 0.77 No
    0.96 0.98 0.97 Overall 0.95 0.95 0.95 Table 3. Voted Classifier Confusion Matrix
    Human Coders Yes No Machine Yes 152 70 No 19 1,660 In Table 1, the bold text indicates
    the best performance results for precision, recall, FP, and FN for each feature
    set. In cases such as the n-gram hateful terms feature set, the whole row is bold
    because there was no difference between the performance of the classifiers. The
    shaded areas indicate the best overall performing feature set for each classifier.
    The results suggest that overall the most efficient features for classifying cyber
    hate are n-gram typed dependencies combined with n-gram hateful and antagonistic
    terms. In fact, the hateful terms alone achieved the same precision performance
    but had a lower performance for recall. The number of false negative results (missed
    instances of cyber hate) was 7 percent higher when using hateful terms alone.
    This is an interesting result as it provides evidence to suggest that human annotators
    identify hateful or antagonistic content on Twitter that does not necessarily
    contain hateful or antagonistic terms, and requires a more nuanced representation
    of what is deemed cyber hate when aiming to classify tweets. The use of a more
    sophisticated set of features as well as a BoW has successfully contributed to
    this requirement. A 7 percent improvement may seem fairly small, but considering
    the size of the initial corpus was 450,000, and in the annotated random sample
    of these data around 11 percent was considered hate speech by the human annotators,
    we could infer that there were around 49,500 instances of cyber hate in the corpus.
    Overlooking 7 percent of these would lead to more than 3,000 hateful or antagonistic
    tweets being missed; so for policymaking purposes, the 7 percent improvement achieved
    by introducing the typed dependency features is significant if an accurate snapshot
    of the level of hateful and antagonistic emotive responses to an event is to be
    achieved. The number of false positives in the best performing classifiers was
    19, which constitutes 0.009 percent of the test data. Other classifiers reduced
    the number of false positives to below 19 (to zero in once instance), but the
    recall performance in these instances was far below that of the best performing
    classifiers, meaning that a reduction in false positives was also accompanied
    by an increase in false negatives. It is essential to retain a balance of minimized
    false positives and false negatives. In all cases, the voted ensemble classifier
    matched or improved upon the recall of each of the individual base classifiers.
    This suggests that combining the output of the respective probabilistic, rule-based
    and spatial classifiers, and selecting the classification decision of maximum
    probability can assist policy and decision makers in reducing the oversight of
    hateful or antagonistic content. While the base classifiers all achieved fairly
    similar results using the most efficient features set, given the improvement of
    recall across all other experiments when using a voted classifier, it would seem
    pertinent to consider the use of the voted classifier as a first choice when applying
    the cyber hate classifier to unseen data. The full results of the cyber hate classifier
    are reported in Table 2. It is clear that the precision and recall of the non-hateful
    responses is very high (P = 0.96, R = 0.98). The precision of the “Yes” class
    is also high (P = 0.89), showing a low number of false positives, but there are
    improvements to be made to the recall of the “Yes” class (R = 0.69) before significant
    confidence can be given to the results for policy- and decision-making purposes.
    Table 3 shows 70 misclassifications where cyber hate was classified as a benign
    response by the classifier, suggesting a further refinement is required to detect
    more discrete hateful and antagonistic content. To give some insight into the
    qualitative narrative of cyber hate we have provided some instances of typed dependencies
    that were probabilistically more likely to occur in cyber hate than the benign
    class in Table 4. We can see that the content of tweets focuses on a response
    to religious and ethnic minority social groups from the wider population (e.g.,
    black muslims). There are phrases suggestive of incitement to respond with actions
    (e.g., burn Korans) and claims of well founded or justified discrimination against
    social groups (e.g., “I told you black people…”). Given this reflective and responsive
    narrative it would seem pragmatic to include more semantic rules and constructs
    into feature identification in future in order to improve classifier performance.
    Table 4. Probabilistic Features Highly Likely to be in Cyber Hate Typed Dependency
    Qualitative Description det(religion-5 a-4) Determiner (a specific reference to
    a noun phrase) discussing “a” “religion” in a particular context amod(people-7
    black-6) Adjectival modifier (a descriptive phrase related to a noun phrase) discussing
    “people” who are “black” aux(burn-6 to-5) dobj(burn-6 korans-9) Auxiliary (a form
    of “be,” “do,” or “have”) action phrase using “burn” and “korans” amod(muslim-40
    black-39) Adjectival modifier (a descriptive phrase related to a noun phrase)
    discussing “muslims” who are “black” det(muslim-40 a-38) amod(muslim-40 black-39)
    Determiner (a specific reference to a noun phrase) discussing “a” “muslim” in
    the context of a “black” “muslim” dobj(told-4 you-5) amod(people-7 black-6) Direct
    object (an accusatory object of the verb) “told” “you” (e.g., “I told you”) in
    the context of “black” “people” advmod(seen-3 just-2) dobj(seen-3 video-4) dobj(getting-9
    shot-10) Adverbial modifier (a descriptive phrase related to a verb) “just” “seen,”
    that is commenting on what has just been witnessed dobj(burn-6 korans-9) Direct
    object (an accusatory object of the verb) “burn” “korans” Note: Using a classifier
    to inform a statistical model. Cautionary Caveat Once a supervised machine learning
    classifier has been developed it can be used on a larger sample to classify new
    and unseen data, and inform policy decisions directly or via additional models.
    First and foremost it is essential to remember that supervised machine learning
    classifiers build models of what they perceive to be the features indicative of
    specific classes—in this case, hateful and antagonistic content. As a result,
    if new or unseen features occur, such as different types of language or content
    with mixed meaning, it can cause confusion in the classifier and produce inaccurate
    results. We can classify new instances, but we must always bear in mind the limitations
    in the existing model (i.e., not all instances of cyber hate were identified by
    our model), and that variance in the way people respond to such events may compound
    this. That said, what we have tried to achieve with the classifier is to assist
    human decision making using a machine to handle the large volumes of data produced
    by the general public in response to a large-scale emotive event. The results
    of the cyber hate classifier are reasonably high, especially when considering
    that around 5 percent of our human-annotated sample had to be removed because
    the three out of four humans could not agree which class a tweet belonged to.
    It is worth remembering that while machine learned models are not always accurate
    in their judgment, humans are also susceptible to disagreement and confusion.
    Cyber Hate and Contagion Modeling In the following example we demonstrate how
    the supervised machine learning classification model of cyber hate can be applied
    to the whole corpus of 450,000 tweets to help determine to what degree hateful
    or antagonistic content is spreading—a measure of the contagion effect of cyber
    hate in response to a specific event. This could help inform those responsible
    for minimizing the risk of social disorder through community reassurance, local
    policing, and the online governance of hateful and antagonistic content, as to
    whether cyber hate is likely to spread. One way to measure the impact of cyber
    hate on the spread of information on Twitter is to treat cyber hate as a predictive
    feature in a statistical regression model where the dependent variable (the outcome
    you are trying to predict) is the number of retweets a tweet is likely to receive.
    Theoretically, the more retweets a tweet receives, the more people are likely
    to see it, increasing the risk of public exposure and opportunity to propagate
    and respond to cyber hate. By measuring the statistical associated strength of
    cyber hate within a model of retweet counts, we can determine the likelihood of
    hateful and antagonistic content being retweeted, and therefore spreading to a
    large number of people. We can define a tweet that has been retweeted a large
    number of times as an information flow (Lotan, 2011). Table 5 shows the result
    of a zero-inflated negative binomial model of information flow “size.” The dependent
    variable is a count measure of the number of retweets a tweet actually received
    following the Woolwich event. The statistical predictors of the count include
    the number of followers of the person sending the tweet, the time of day the tweet
    was sent, the content of the tweet (hashtags, URLs), the sentiment polarity (+ve,
    –ve), the number of press headlines on the day the tweet was made, and the type
    of agent sending the tweet (e.g., press, police, politician). The data for these
    features were all derived from the data set collected from Twitter. For more details
    on how these were derived we recommend the reader study a related paper that examined
    the social media reaction in greater detail (Burnap et al., 2014). In this instance
    we are only interested in the impact of cyber hate as an example of how machine
    classification can help inform the modeling of online social reaction. Table 5.
    Zero-Inflated Negetive Binomial Regression Model Predicting Counts of Retweets
    Count of Retweets Poisson Model (Count/True Zeros) Coef. SE IRR TimeLagRT5 0.000**
    0.000 1.000 Tweet count −0.215** 0.015 0.807 Commute morning 0.030 0.048 1.030
    Work 0.014 0.038 1.015 Commute evening 0.074 0.045 1.077 Evening −0.010 0.040
    0.990 Ref: Commute night Sunday −0.133** 0.041 0.875 Monday −0.302** 0.047 0.739
    Tuesday −0.344** 0.051 0.709 Thursday −0.365** 0.058 0.694 Friday −0.311** 0.044
    0.733 Saturday −0.122** 0.052 0.853 Ref: Wednesday Hashtag 0.217** 0.025 1.242
    URL 0.439** 0.026 1.551 Sentiment 0.322** 0.018 1.380 Google search 0.005** 0.001
    1.005 Press headlines 0.000* 0.000 1.000 News agent 1.460** 0.044 4.304 Police
    Agent 1.742** 0.408 5.708 Political agent 0.670** 0.150 1.954 Far right political
    agent 0.632* 0.327 1.882 Ref: Other agent Cyber hate speech −0.604** 0.107 0.546
    Constant 0.543** 0.126 1.721 Binomial model (inflation/excess zeros) Number of
    followers −0.899** 0.017 - Constant 4.586 0.063 - Model fit Log-L −92,196.36 Chi-square
    2,594.57 Sig. p = 0.00 LRT for alpha = 0 p = 0.00 Vuong Z = 45.00; p = 0.00; Na = 210,807
    Notes: *p < 0.05, **p = <0.01.1. a Reduction due to removal of retweets, leaving
    only original tweets. If we look at the incidence rate ratio (IRR) column in Table
    5 we can see the strengths of association for each predictor variable with the
    dependent “retweet” count, as indicated by the IRR. We can use the IRR to report
    the strength of causal associations between certain factors and the information
    flow size, enabling us to identify quantitatively which factors are more important
    than others. Where an IRR >1, the difference is associated with a positive increase
    in the dependent variable (retweet count), so in the case of the “URL” variable
    which records whether or not a tweet contains a URL, the results indicate that
    the rate of retweet for tweets containing a URL is 1.55 times higher than the
    rate for tweets without a URL. Thus, a URL increases the chances of a tweet being
    retweeted. Where an IRR <1, there is a negative effect. If we look at the “Cyber
    Hate Speech” predictor we see the IRR is 0.55 (rounded to 2 decimal places), which
    means that the inclusion of hateful or antagonistic content in a tweet reduces
    the rate of retweet by a factor of 0.55 (or 45 percent), suggesting that a response
    to this event that contains a hateful or antagonistic element, as determined by
    the machine classifier, is in fact reducing the likelihood of the tweet being
    widely spread. For policymakers, the combination of the cyber hate machine classifier
    with the statistical predictive model of the retweet likelihood given the features
    of the tweet could be useful in determining the changing dynamic of cyber hate
    on Twitter over time, and as an event unfolds. At any point in time a new corpus
    of tweets can be collected via the Twitter API, and the number of retweets each
    tweet has received is available from the metadata provided by Twitter. If the
    machine classifier is used to detect cyber hate within the corpus, and the statistical
    model is subsequently rerun, the difference in IRR from one period of time to
    another can be illustrative of the changing dynamic of cyber hate in Twitter over
    time. For instance, if the IRR for the “Cyber Hate Speech” predictor in the model
    is 0.55 at time x, and 0.75 at time y, it suggests an increase in the rate of
    retweets containing cyber hate and therefore provides an indication that hateful
    and antagonistic content is actually spreading more at time y. One limitation
    of our approach is that the classification of cyber hate is dependent upon the
    language used in response to an event, which may not predeterminable prior to
    an event. Therefore, from these results we are not suggesting that the hate propagation
    IRR could be compared to a preevent baseline, rather that while the event is unfolding
    policymakers can study fluctuations within the analysis window following the event.
    The utility of identifying fluctuations following the event include monitoring
    the enabling and inhibiting factors of propagation of hate, such as further connected
    events (e.g., a protest march, news coverage, published opinion pieces, and political
    speeches). Conclusion In this article we have developed a supervised machine learning
    classifier for hateful and antagonistic content in Twitter. The purpose of the
    classifier is to assist policy and decision makers in monitoring the public reaction
    to large-scale emotive events, such as the murder of Drummer Lee Rigby in Woolwich
    in 2013. Previous research showed that 58 percent of hate crimes following 9/11
    were perpetrated two weeks following the event (4 percent of the at-risk period).
    Data are available in near-real time from online social networks and microblogging
    websites such as Twitter, which can allow us to monitor the prevalence of hateful
    and antagonistic responses online in the period immediately following the event,
    when risk of hateful responses is highest. Hateful and antagonistic responses
    have led to imprisonment of the person posting the tweet—possibly as part of a
    risk reduction response by the judicial system. The classification results showed
    very high levels of performance at reducing false positives and produced promising
    results with respect to false negatives. Our implementation of individual probabilistic,
    rule-based, and spatial classifiers performed similarly across most feature sets,
    but the combination of the classification output of these base classifiers using
    a voted meta-classifier based on maximum probability matched or improved on the
    recall of the base classifiers in every experiment, suggesting that an ensemble
    classification approach is most suitable for classifying cyber hate, given the
    current feature sets. This could be due to the noise and variety of types of response
    within the data, with some features proving more effective with different classifiers.
    The novel inclusion of syntactic features using typed dependencies within tweets
    as machine learning features reduced the false negatives by 7 percent over the
    baseline BoW features, providing a significant improvement when considering the
    volumes of data produced in response to such events. Our corpus of 450,000 tweets
    was collected in the first two weeks following the event, and it would be extremely
    difficult for human effort to manually parse these data to determine levels of
    public antagonism within all the responses. The improvement in machine classification
    using typed dependencies also suggests that cyber hate comprises content that
    is not instantly identifiable by words that are traditionally associated with
    hateful and discriminatory remarks, and requires a more nuanced approach to text
    classification beyond words alone. For instance, there was a prevalence of “othering”
    terms, such as “send them home” and “get them out,” as well as incitements to
    undertake hateful retribution such as “burn korans” and “should be hung.” The
    typed dependency approach was able to identify these as useful features for classification.
    We developed an illustrative example using cyber hate as classified by a machine
    as a predictive feature in a statistical regression model. The model produced
    IRRs for retweet activity given a set of features for each tweet. The model showed
    a reduction in retweet rate ratio when a tweet contained a hateful or antagonistic
    response, suggesting a stemming of the flow of content on Twitter when a tweet
    contained cyber hate. This combination of machine classification and statistical
    modeling can—while accepting the limitations of machines with respect to utilizing
    a learned set of predictive features that are not an absolute reflection of all
    the possible combinations and permutations of cyber hate characteristics—produce
    aggregated statistics and prevalence indicators for hateful and antagonistic responses
    to an event on social media, including the relative spread of cyber hate on Twitter
    over time. Our results are reflective of the individual event under study so we
    make no claims as to the generalizability of the classifier or the statistical
    model. However, through this case study, we have established for the first time
    a method and a set of results that others could replicate following similar and
    disparate events, in order to build up a body of work from which more generalizable
    results can emerge. For example, following an event prompting a hateful homophobic
    response, a data analyst could collect data, perform the annotation task, and
    replicate our method. We hope this article acts as a clarion call for further
    research into cyber hate and its manifestation in social media around events,
    and the development of technical solutions that are informed by such research.
    Notes This work was supported by the Economic and Social Research Council and
    Google Data Analytics Research Grant: “Hate Speech and Social Media: Understanding
    Users, Networks and Information Flows” [ES/K008013/1]. 1 http://www.google.com/trends/.
    2 http://www.rsdb.org/. Biographies Pete Burnap, Ph.D., Lecturer, Cardiff School
    of Computer Science & Informatics, Cardiff University, Cardiff, UK [burnapp@cardiff.ac.uk].
    Matthew L. Williams, Ph.D., Reader, Cardiff School of Social Sciences, Cardiff
    University, Cardiff, UK References Citing Literature Volume7, Issue2 June 2015
    Pages 223-242 References Related Information Recommended Gatekeepers of toxicity:
    Reconceptualizing Twitter''s abuse and hate speech policies Daniel Konikoff Policy
    & Internet Islamophobia and Twitter: A Typology of Online Hate Against Muslims
    on Social Media Imran Awan Policy & Internet Hate Speech Law and Policy Cherian
    George The International Encyclopedia of Digital Communication and Society, [1]
    Hate Speech Susan J. Brison The International Encyclopedia of Ethics, [1] Online
    interventions for reducing hate speech and cyberhate: A systematic review Steven
    Windisch,  Susann Wiedlitzka,  Ajima Olaghere,  Elizabeth Jenaway Campbell Systematic
    Reviews Download PDF Additional links ABOUT WILEY ONLINE LIBRARY Privacy Policy
    Terms of Use About Cookies Manage Cookies Accessibility Wiley Research DE&I Statement
    and Publishing Policies Developing World Access HELP & SUPPORT Contact Us Training
    and Support DMCA & Reporting Piracy OPPORTUNITIES Subscription Agents Advertisers
    & Corporate Partners CONNECT WITH WILEY The Wiley Network Wiley Press Room Copyright
    © 1999-2024 John Wiley & Sons, Inc or related companies. All rights reserved,
    including rights for text and data mining and training of artificial technologies
    or similar technologies.'
  inline_citation: '>'
  journal: Policy & Internet
  limitations: '>'
  pdf_link: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/poi3.85
  publication_year: 2015
  relevance_score1: 0
  relevance_score2: 0
  title: 'Cyber Hate Speech on Twitter: An Application of Machine Classification and
    Statistical Modeling for Policy and Decision Making'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1007/s00146-014-0549-4
  analysis: '>'
  authors:
  - Bogdan Batrinca
  - Philip Treleaven
  citation_count: 404
  full_citation: '>'
  full_text: ">\nOPEN FORUM\nSocial media analytics: a survey of techniques, tools\
    \ and platforms\nBogdan Batrinca • Philip C. Treleaven\nReceived: 25 February\
    \ 2014 / Accepted: 4 July 2014 / Published online: 26 July 2014\n\x02 The Author(s)\
    \ 2014. This article is published with open access at Springerlink.com\nAbstract\n\
    This paper is written for (social science)\nresearchers seeking to analyze the\
    \ wealth of social media\nnow available. It presents a comprehensive review of\n\
    software tools for social networking media, wikis, really\nsimple syndication\
    \ feeds, blogs, newsgroups, chat and\nnews feeds. For completeness, it also includes\
    \ introduc-\ntions to social media scraping, storage, data cleaning and\nsentiment\
    \ analysis. Although principally a review, the\npaper also provides a methodology\
    \ and a critique of social\nmedia tools. Analyzing social media, in particular\
    \ Twitter\nfeeds for sentiment analysis, has become a major research\nand business\
    \ activity due to the availability of web-based\napplication programming interfaces\
    \ (APIs) provided by\nTwitter, Facebook and News services. This has led to an\n\
    ‘explosion’ of data services, software tools for scraping and\nanalysis and social\
    \ media analytics platforms. It is also a\nresearch area undergoing rapid change\
    \ and evolution due to\ncommercial pressures and the potential for using social\n\
    media data for computational (social science) research.\nUsing a simple taxonomy,\
    \ this paper provides a review of\nleading software tools and how to use them\
    \ to scrape,\ncleanse and analyze the spectrum of social media. In\naddition,\
    \ it discussed the requirement of an experimental\ncomputational environment for\
    \ social media research and\npresents as an illustration the system architecture\
    \ of a\nsocial media (analytics) platform built by University Col-\nlege London.\
    \ The principal contribution of this paper is to\nprovide an overview (including\
    \ code fragments) for\nscientists seeking to utilize social media scraping and\n\
    analytics either in their research or business. The data\nretrieval techniques\
    \ that are presented in this paper are\nvalid at the time of writing this paper\
    \ (June 2014), but they\nare subject to change since social media data scraping\
    \ APIs\nare rapidly changing.\nKeywords\nSocial media \x02 Scraping \x02 Behavior\n\
    economics \x02 Sentiment analysis \x02 Opinion mining \x02\nNLP \x02 Toolkits\
    \ \x02 Software platforms\n1 Introduction\nSocial media is deﬁned as web-based\
    \ and mobile-based\nInternet applications that allow the creation, access and\n\
    exchange of user-generated content that is ubiquitously\naccessible (Kaplan and\
    \ Haenlein 2010). Besides social\nnetworking media (e.g., Twitter and Facebook),\
    \ for con-\nvenience, we will also use the term ‘social media’ to\nencompass really\
    \ simple syndication (RSS) feeds, blogs,\nwikis and news, all typically yielding\
    \ unstructured text\nand accessible through the web. Social media is especially\n\
    important for research into computational social science\nthat investigates questions\
    \ (Lazer et al. 2009) using\nquantitative\ntechniques\n(e.g.,\ncomputational\n\
    statistics,\nmachine learning and complexity) and so-called big data\nfor data\
    \ mining and simulation modeling (Ciofﬁ-Revilla\n2010).\nThis has led to numerous\
    \ data services, tools and ana-\nlytics platforms. However, this easy availability\
    \ of social\nmedia data for academic research may change signiﬁcantly\ndue to\
    \ commercial pressures. In addition, as discussed in\nSect. 2, the tools available\
    \ to researchers are far from ideal.\nThey either give superﬁcial access to the\
    \ raw data or (for\nB. Batrinca \x02 P. C. Treleaven (&)\nDepartment of Computer\
    \ Science, University College London,\nGower Street, London WC1E 6BT, UK\ne-mail:\
    \ p.treleaven@ucl.ac.uk\nB. Batrinca\ne-mail: bogdan.batrinca.09@ucl.ac.uk\n123\n\
    AI & Soc (2015) 30:89–116\nDOI 10.1007/s00146-014-0549-4\nnon-superﬁcial access)\
    \ require researchers to program\nanalytics in a language such as Java.\n1.1 Terminology\n\
    We start with deﬁnitions of some of the key techniques\nrelated to analyzing unstructured\
    \ textual data:\n•\nNatural language processing—(NLP) is a ﬁeld of\ncomputer science,\
    \ artiﬁcial intelligence and linguistics\nconcerned with the interactions between\
    \ computers and\nhuman (natural) languages. Speciﬁcally, it is the\nprocess of\
    \ a computer extracting meaningful informa-\ntion from natural language input\
    \ and/or producing\nnatural language output.\n•\nNews analytics—the measurement\
    \ of the various\nqualitative\nand\nquantitative\nattributes\nof\ntextual\n(unstructured\
    \ data) news stories. Some of these attri-\nbutes are: sentiment, relevance and\
    \ novelty.\n•\nOpinion mining—opinion mining (sentiment mining,\nopinion/sentiment\
    \ extraction) is the area of research\nthat attempts to make automatic systems\
    \ to determine\nhuman opinion from text written in natural language.\n•\nScraping—collecting\
    \ online data from social media\nand other Web sites in the form of unstructured\
    \ text and\nalso known as site scraping, web harvesting and web\ndata extraction.\n\
    •\nSentiment analysis—sentiment analysis refers to the\napplication of natural\
    \ language processing, computa-\ntional linguistics and text analytics to identify\
    \ and\nextract subjective information in source materials.\n•\nText analytics—involves\
    \ information retrieval (IR),\nlexical analysis to study word frequency distributions,\n\
    pattern recognition, tagging/annotation, information\nextraction, data mining\
    \ techniques including link and\nassociation\nanalysis,\nvisualization\nand\n\
    predictive\nanalytics.\n1.2 Research challenges\nSocial media scraping and analytics\
    \ provides a rich source\nof academic research challenges for social scientists,\n\
    computer\nscientists\nand\nfunding\nbodies.\nChallenges\ninclude:\n•\nScraping—although\
    \ social media data is accessible\nthrough APIs, due to the commercial value of\
    \ the data,\nmost of the major sources such as Facebook and\nGoogle are making\
    \ it increasingly difﬁcult for academ-\nics to obtain comprehensive access to\
    \ their ‘raw’ data;\nvery few social data sources provide affordable data\nofferings\
    \ to academia and researchers. News services\nsuch as Thomson Reuters and Bloomberg\
    \ typically\ncharge a premium for access to their data. In contrast,\nTwitter\
    \ has recently announced the Twitter Data Grants\nprogram, where researchers can\
    \ apply to get access to\nTwitter’s public tweets and historical data in order\
    \ to\nget insights from its massive set of data (Twitter has\nmore than 500 million\
    \ tweets a day).\n•\nData cleansing—cleaning unstructured textual data\n(e.g.,\n\
    normalizing\ntext),\nespecially\nhigh-frequency\nstreamed real-time data, still\
    \ presents numerous prob-\nlems and research challenges.\n•\nHolistic data sources—researchers\
    \ are increasingly\nbringing together and combining novel data sources:\nsocial\
    \ media data, real-time market & customer data\nand geospatial data for analysis.\n\
    •\nData protection—once you have created a ‘big data’\nresource, the data needs\
    \ to be secured, ownership and\nIP issues resolved (i.e., storing scraped data\
    \ is against\nmost of the publishers’ terms of service), and users\nprovided with\
    \ different levels of access; otherwise,\nusers may attempt to ‘suck’ all the\
    \ valuable data from\nthe database.\n•\nData analytics—sophisticated analysis\
    \ of social media\ndata for opinion mining (e.g., sentiment analysis) still\n\
    raises a myriad of challenges due to foreign languages,\nforeign words, slang,\
    \ spelling errors and the natural\nevolving of language.\n•\nAnalytics dashboards—many\
    \ social media platforms\nrequire users to write APIs to access feeds or program\n\
    analytics models in a programming language, such as\nJava. While reasonable for\
    \ computer scientists, these\nskills are typically beyond most (social science)\n\
    researchers. Non-programming interfaces are required\nfor giving what might be\
    \ referred to as ‘deep’ access to\n‘raw’ data, for example, conﬁguring APIs, merging\n\
    social media feeds, combining holistic sources and\ndeveloping analytical models.\n\
    •\nData\nvisualization—visual\nrepresentation\nof\ndata\nwhereby information that\
    \ has been abstracted in some\nschematic form with the goal of communicating\n\
    information clearly and effectively through graphical\nmeans. Given the magnitude\
    \ of the data involved,\nvisualization is becoming increasingly important.\n1.3\
    \ Social media research and applications\nSocial media data is clearly the largest,\
    \ richest and most\ndynamic evidence base of human behavior, bringing new\nopportunities\
    \ to understand individuals, groups and society.\nInnovative\nscientists\nand\n\
    industry\nprofessionals\nare\nincreasingly ﬁnding novel ways of automatically\
    \ collect-\ning, combining and analyzing this wealth of data. Natu-\nrally, doing\
    \ justice to these pioneering social media\n90\nAI & Soc (2015) 30:89–116\n123\n\
    applications in a few paragraphs is challenging. Three\nillustrative areas are:\
    \ business, bioscience and social\nscience.\nThe early business adopters of social\
    \ media analysis\nwere typically companies in retail and ﬁnance. Retail\ncompanies\
    \ use social media to harness their brand aware-\nness, product/customer service\
    \ improvement, advertising/\nmarketing strategies, network structure analysis,\
    \ news\npropagation and even fraud detection. In ﬁnance, social\nmedia is used\
    \ for measuring market sentiment and news\ndata is used for trading. As an illustration,\
    \ Bollen et al.\n(2011) measured sentiment of random sample of Twitter\ndata,\
    \ ﬁnding that Dow Jones Industrial Average (DJIA)\nprices are correlated with\
    \ the Twitter sentiment 2–3 days\nearlier with 87.6 percent accuracy. Wolfram\
    \ (2010) used\nTwitter data to train a Support Vector Regression (SVR)\nmodel\
    \ to predict prices of individual NASDAQ stocks,\nﬁnding\n‘signiﬁcant\nadvantage’\n\
    for\nforecasting\nprices\n15 min in the future.\nIn the biosciences, social media\
    \ is being used to collect\ndata on large cohorts for behavioral change initiatives\
    \ and\nimpact monitoring, such as tackling smoking and obesity or\nmonitoring\
    \ diseases. An example is Penn State University\nbiologists (Salathe´ et al. 2012)\
    \ who have developed inno-\nvative systems and techniques to track the spread\
    \ of\ninfectious diseases, with the help of news Web sites, blogs\nand social\
    \ media.\nComputational social science applications include: mon-\nitoring public\
    \ responses to announcements, speeches and\nevents especially political comments\
    \ and initiatives; insights\ninto community behavior; social media polling of\
    \ (hard to\ncontact) groups; early detection of emerging events, as with\nTwitter.Forexample,\
    \ Lermanet al. (2008) usecomputational\nlinguistics to automatically predict the\
    \ impact of news on the\npublic perception of political candidates. Yessenov and\
    \ Mi-\nsailovic (2009) use movie review comments to study the\neffect of various\
    \ approaches in extracting text features on the\naccuracy of four machine learning\
    \ methods—Naive Bayes,\nDecision Trees, Maximum Entropy and K-Means clustering.\n\
    Lastly, Karabulut (2013) found that Facebook’s Gross\nNational Happiness (GNH)\
    \ exhibitspeaks and troughs in-line\nwith major public events in the USA.\n1.4\
    \ Social media overview\nFor this paper, we group social media tools into:\n•\n\
    Social media data—social media data types (e.g.,\nsocial network media, wikis,\
    \ blogs, RSS feeds and\nnews, etc.) and formats (e.g., XML and JSON). This\nincludes\
    \ data sets and increasingly important real-time\ndata feeds, such as ﬁnancial\
    \ data, customer transaction\ndata, telecoms and spatial data.\n•\nSocial media\
    \ programmatic access—data services\nand tools for sourcing and scraping (textual)\
    \ data from\nsocial networking media, wikis, RSS feeds, news, etc.\nThese can\
    \ be usefully subdivided into:\n•\nData sources, services and tools—where data\
    \ is\naccessed by tools which protect the raw data or\nprovide simple analytics.\
    \ Examples include: Google\nTrends, SocialMention, SocialPointer and Social-\n\
    Seek, which provide a stream of information that\naggregates various social media\
    \ feeds.\n•\nData feeds via APIs—where data sets and feeds are\naccessible via\
    \ programmable HTTP-based APIs and\nreturn tagged data using XML or JSON, etc.\n\
    Examples include Wikipedia, Twitter and Facebook.\n•\nText cleaning and storage\
    \ tools—tools for cleaning\nand storing textual data. Google Reﬁne and DataWran-\n\
    gler are examples for data cleaning.\n•\nText analysis tools—individual or libraries\
    \ of tools for\nanalyzing social media data once it has been scraped\nand\ncleaned.\n\
    These\nare\nmainly natural\nlanguage\nprocessing, analysis and classiﬁcation tools,\
    \ which are\nexplained below.\n•\nTransformation tools—simple tools that can trans-\n\
    form textual input data into tables, maps, charts\n(line, pie, scatter, bar, etc.),\
    \ timeline or even motion\n(animation over timeline), such as Google Fusion\n\
    Tables, Zoho Reports, Tableau Public or IBM’s\nMany Eyes.\n•\nAnalysis tools—more\
    \ advanced analytics tools for\nanalyzing social data, identifying connections\
    \ and\nbuilding networks, such as Gephi (open source) or\nthe Excel plug-in NodeXL.\n\
    •\nSocial media platforms—environments that provide\ncomprehensive social media\
    \ data and libraries of tools\nfor analytics. Examples include: Thomson Reuters\n\
    Machine Readable News, Radian 6 and Lexalytics.\n•\nSocial network media platforms—platforms\
    \ that\nprovide data mining and analytics on Twitter,\nFacebook and a wide range\
    \ of other social network\nmedia sources.\n•\nNews platforms—platforms such as\
    \ Thomson Reu-\nters providing commercial news archives/feeds and\nassociated\
    \ analytics.\n2 Social media methodology and critique\nThe two major impediments\
    \ to using social media for\nacademic research are ﬁrstly access to comprehensive\
    \ data\nsets and secondly tools that allow ‘deep’ data analysis\nAI & Soc (2015)\
    \ 30:89–116\n91\n123\nwithout the need to be able to program in a language such\n\
    as Java. The majority of social media resources are com-\nmercial and companies\
    \ are naturally trying to monetize\ntheir data. As discussed, it is important\
    \ that researchers\nhave access to open-source ‘big’ (social media) data sets\n\
    and facilities for experimentation. Otherwise, social media\nresearch could become\
    \ the exclusive domain of major\ncompanies, government agencies and a privileged\
    \ set of\nacademic researchers presiding over private data from\nwhich they produce\
    \ papers that cannot be critiqued or\nreplicated. Recently, there has been a modest\
    \ response, as\nTwitter and Gnip are piloting a new program for data\naccess,\
    \ starting with 5 all-access data grants to select\napplicants.\n2.1 Methodology\n\
    Research requirements can be grouped into: data, analytics\nand facilities.\n\
    2.1.1 Data\nResearchers need online access to historic and real-time\nsocial media\
    \ data, especially the principal sources, to\nconduct world-leading research:\n\
    •\nSocial\nnetwork\nmedia—access\nto\ncomprehensive\nhistoric data sets and also\
    \ real-time access to sources,\npossibly with a (15 min) time delay, as with Thomson\n\
    Reuters and Bloomberg ﬁnancial data.\n•\nNews data—access to historic data and\
    \ real-time news\ndata sets, possibly through the concept of ‘educational\ndata\
    \ licenses’ (cf. software license).\n•\nPublic data—access to scraped and archived\
    \ important\npublic data; available through RSS feeds, blogs or open\ngovernment\
    \ databases.\n•\nProgrammable\ninterfaces—researchers\nalso\nneed\naccess to simple\
    \ application programming interfaces\n(APIs) to scrape and store other available\
    \ data sources\nthat may not be automatically collected.\n2.1.2 Analytics\nCurrently,\
    \ social media data is typically either available\nvia simple general routines\
    \ or require the researcher\nto program their analytics in a language such as\
    \ MAT-\nLAB, Java or Python. As discussed above, researchers\nrequire:\n•\nAnalytics\
    \ dashboards—non-programming interfaces\nare required for giving what might be\
    \ termed as ‘deep’\naccess to ‘raw’ data.\n•\nHolistic data analysis—tools are\
    \ required for combin-\ning (and conducting analytics across) multiple social\n\
    media and other data sets.\n•\nData visualization—researchers also require visuali-\n\
    zation\ntools\nwhereby\ninformation\nthat\nhas\nbeen\nabstracted can be visualized\
    \ in some schematic form\nwith the goal of communicating information clearly and\n\
    effectively through graphical means.\n2.1.3 Facilities\nLastly, the sheer volume\
    \ of social media data being gen-\nerated argues for national and international\
    \ facilities to be\nestablished to support social media research (cf. Wharton\n\
    Research Data Services https://wrds-web.wharton.upenn.\nedu):\n•\nData storage—the\
    \ volume of social media data,\ncurrent and projected, is beyond most individual\n\
    universities and hence needs to be addressed at a\nnational science foundation\
    \ level. Storage is required\nboth for principal data sources (e.g., Twitter),\
    \ but also\nfor\nsources\ncollected\nby\nindividual\nprojects\nand\narchived for\
    \ future use by other researchers.\n•\nComputational facility—remotely accessible\
    \ compu-\ntational facilities are also required for: a) protecting\naccess to\
    \ the stored data; b) hosting the analytics and\nvisualization tools; and c) providing\
    \ computational\nresources\nsuch\nas\ngrids\nand\nGPUs\nrequired\nfor\nprocessing\
    \ the data at the facility rather than transmit-\nting it across a network.\n\
    2.2 Critique\nMuch needs to be done to support social media research.\nAs discussed,\
    \ the majority of current social media resour-\nces are commercial, expensive\
    \ and difﬁcult for academics\nto obtain full access.\n2.2.1 Data\nIn general,\
    \ access to important sources of social media data\nis frequently restricted and\
    \ full commercial access is\nexpensive.\n•\nSiloed data—most data sources (e.g.,\
    \ Twitter) have\ninherently isolated information making it difﬁcult to\ncombine\
    \ with other data sources.\n•\nHolistic data—in contrast, researchers are increasingly\n\
    interested in accessing, storing and combining novel\ndata sources: social media\
    \ data, real-time ﬁnancial\nmarket & customer data and geospatial data for\n92\n\
    AI & Soc (2015) 30:89–116\n123\nanalysis. This is currently extremely difﬁcult\
    \ to do even\nfor Computer Science departments.\n2.2.2 Analytics\nAnalytical tools\
    \ provided by vendors are often tied to a\nsingle data set, maybe limited in analytical\
    \ capability, and\ndata charges make them expensive to use.\n2.2.3 Facilities\n\
    There are an increasing number of powerful commercial\nplatforms, such as the\
    \ ones supplied by SAS and Thomson\nReuters, but the charges are largely prohibitive\
    \ for aca-\ndemic research. Either comparable facilities need to be\nprovided\
    \ by national science foundations or vendors need\nto be persuaded to introduce\
    \ the concept of an ‘educational\nlicense.’\n3 Social media data\nClearly, there\
    \ is a large and increasing number of (com-\nmercial) services providing access\
    \ to social networking\nmedia (e.g., Twitter, Facebook and Wikipedia) and news\n\
    services (e.g., Thomson Reuters Machine Readable News).\nEquivalent major academic\
    \ services are scarce.We start by\ndiscussing types of data and formats produced\
    \ by these\nservices.\n3.1 Types of data\nAlthough we focus on social media, as\
    \ discussed,\nresearchers are continually ﬁnding new and innovative\nsources of\
    \ data to bring together and analyze. So when\nconsidering textual data analysis,\
    \ we should consider\nmultiple sources (e.g., social networking media, RSS\nfeeds,\
    \ blogs and news) supplemented by numeric (ﬁnan-\ncial) data, telecoms data, geospatial\
    \ data and potentially\nspeech and video data. Using multiple data sources is\n\
    certainly the future of analytics.\nBroadly, data subdivides into:\n•\nHistoric\
    \ data sets—previously accumulated and stored\nsocial/news, ﬁnancial and economic\
    \ data.\n•\nReal-time feeds—live data feeds from streamed social\nmedia, news\
    \ services, ﬁnancial exchanges, telecoms\nservices, GPS devices and speech.\n\
    And into:\n•\nRaw data—unprocessed computer data straight from\nsource that may\
    \ contain errors or may be unanalyzed.\n•\nCleaned data—correction or removal\
    \ of erroneous\n(dirty) data caused by disparities, keying mistakes,\nmissing\
    \ bits, outliers, etc.\n•\nValue-added data—data that has been cleaned, ana-\n\
    lyzed, tagged and augmented with knowledge.\n3.2 Text data formats\nThe four most\
    \ common formats used to markup text are:\nHTML, XML, JSON and CSV.\n•\nHTML—HyperText\
    \ Markup Language (HTML) as\nwell-known is the markup language for web pages and\n\
    other information that can be viewed in a web browser.\nHTML consists of HTML\
    \ elements, which include tags\nenclosed in angle brackets (e.g., \\div[), within\
    \ the\ncontent of the web page.\n•\nXML—Extensible\nMarkup\nLanguage\n(XML)—the\n\
    markup language for structuring textual data using\n\\tag[…\\\\tag[ to deﬁne elements.\n\
    •\nJSON—JavaScript Object Notation (JSON) is a text-\nbased open standard designed\
    \ for human-readable data\ninterchange and is derived from JavaScript.\n•\nCSV—a\
    \ comma-separated values (CSV) ﬁle contains\nthe values in a table as a series\
    \ of ASCII text lines\norganized such that each column value is separated by a\n\
    comma from the next column’s value and each row\nstarts a new line.\nFor completeness,\
    \ HTML and XML are so-called\nmarkup languages (markup and content) that deﬁne\
    \ a set of\nsimple syntactic rules for encoding documents in a format\nboth human\
    \ readable and machine readable. A markup\ncomprises start-tags (e.g., \\tag[),\
    \ content text and end-\ntags (e.g., \\/tag[).\nMany feeds use JavaScript Object\
    \ Notation (JSON), the\nlightweight data-interchange format, based on a subset\
    \ of\nthe JavaScript Programming Language. JSON is a lan-\nguage-independent text\
    \ format that uses conventions that\nare familiar to programmers of the C-family\
    \ of languages,\nincluding C, C??, C#, Java, JavaScript, Perl, Python, and\nmany\
    \ others. JSON’s basic types are: Number, String,\nBoolean, Array (an ordered\
    \ sequence of values, comma-\nseparated and enclosed in square brackets) and Object\
    \ (an\nunordered collection of key:value pairs). The JSON format\nis illustrated\
    \ in Fig. 1 for a query on the Twitter API on the\nstring ‘UCL,’ which returns\
    \ two ‘text’ results from the\nTwitter user ‘uclnews.’\nComma-separated values\
    \ are not a single, well-deﬁned\nformat but rather refer to any text ﬁle that:\
    \ (a) is plain text\nusing a character set such as ASCII, Unicode or EBCDIC;\n\
    (b) consists of text records (e.g., one record per line);\n(c) with records divided\
    \ into ﬁelds separated by delimiters\nAI & Soc (2015) 30:89–116\n93\n123\n(e.g.,\
    \ comma, semicolon and tab); and (d) where every\nrecord has the same sequence\
    \ of ﬁelds.\n4 Social media providers\nSocial media data resources broadly subdivide\
    \ into those\nproviding:\n•\nFreely available databases—repositories that can\
    \ be\nfreely\ndownloaded,\ne.g.,\nWikipedia\n(http://dumps.\nwikimedia.org) and\
    \ the Enron e-mail data set avail-\nable via http://www.cs.cmu.edu/*enron/.\n\
    •\nData access via tools—sources that provide controlled\naccess to their social\
    \ media data via dedicated tools,\nboth to facilitate easy interrogation and also\
    \ to stop\nusers ‘sucking’ all the data from the repository. An\nexample is Google’s\
    \ Trends. These further subdivided\ninto:\n•\nFree sources—repositories that are\
    \ freely accessi-\nble, but the tools protect or may limit access to the\n‘raw’\
    \ data in the repository, such as the range of\ntools provided by Google.\n•\n\
    Commercial sources—data resellers that charge for\naccess to their social media\
    \ data. Gnip and DataSift\nprovide commercial access to Twitter data through\n\
    a partnership, and Thomson Reuters to news data.\n•\nData access via APIs—social\
    \ media data repositories\nproviding programmable HTTP-based access to the\ndata\
    \ via APIs (e.g., Twitter, Facebook and Wikipedia).\n4.1 Open-source databases\n\
    A major open source of social media is Wikipedia,\nwhich offers free copies of\
    \ all available content to\ninterested users (Wikimedia Foundation 2014). These\n\
    databases can be used for mirroring, database queries\nand social media analytics.\
    \ They include dumps from\nany\nWikimedia\nFoundation\nproject:\nhttp://dumps.\n\
    wikimedia.org/, English Wikipedia dumps in SQL and\nXML: http://dumps.wikimedia.org/enwiki/,\
    \ etc.\nAnother example of freely available data for research is\nthe World Bank\
    \ data, i.e., the World Bank Databank (http://\ndatabank.worldbank.org/data/databases.aspx),\n\
    which\npro-\nvides over 40 databases, such as Gender Statistics, Health\nNutrition\n\
    and\nPopulation\nStatistics,\nGlobal\nEconomic\nProspects,\nWorld\nDevelopment\n\
    Indicators\nand\nGlobal\nDevelopment Finance, and many others. Most of the dat-\n\
    abases can be ﬁltered by country/region, series/topics or\ntime (years and quarters).\
    \ In addition, tools are provided to\nallow reports to be customized and displayed\
    \ in table, chart\nor map formats.\n4.2 Data access via tools\nAs discussed, most\
    \ commercial services provide access to\nsocial media data via online tools, both\
    \ to control access to\nthe raw data and increasingly to monetize the data.\n\
    4.2.1 Freely accessible sources\nGoogle with tools such as Trends and InSights\
    \ is a\ngood example of this category. Google is the largest\n‘scraper’ in the\
    \ world, but they do their best to ‘dis-\ncourage’ scraping of their own pages.\
    \ (For an intro-\nduction of how to surreptitious scrape Google—and\navoid\nbeing\n\
    ‘banned’—see\nhttp://google-scraper.\nsquabbel.com.) Google’s strategy is to provide\
    \ a wide\nrange of packages, such as Google Analytics, rather\nthan from a researchers’\
    \ viewpoint the more useful\nprogrammable HTTP-based APIs.\nFigure 2 illustrates\
    \ how Google Trends displays a par-\nticular search term, in this case ‘libor.’\
    \ Using Google\nTrends you can compare up to ﬁve topics at a time and also\nsee\
    \ how often those topics have been mentioned and in\nwhich geographic regions\
    \ the topics have been searched for\nthe most.\n{ \n  \"page\":1, \n  \"query\"\
    :\"UCL\", \n  \"results\":[ \n    { \n      “text”:”UCL comes 4th in the QS World\
    \ University Rankings. Good eh? http://bit.ly/PlUbsG”, \n      “date”:”2012-09-11”,\
    \ \n      “twitterUser”:”uclnews” \n    }, \n    { \n      “text”:”@uclcareers\
    \ Like it!”, \n      “date”:”2012-08-07”, \n      “twitterUser”:”uclnews” \n \
    \   } \n  ], \n  \"results_per_page\":2 \n} \nFig. 1 JSON Example\n94\nAI & Soc\
    \ (2015) 30:89–116\n123\n4.2.2 Commercial sources\nThere is an increasing number\
    \ of commercial services that\nscrape social networking media and then provide\
    \ paid-for\naccess via simple analytics tools. (The more comprehen-\nsive platforms\
    \ with extensive analytics are reviewed in\nSect. 8.) In addition, companies such\
    \ as Twitter are both\nrestricting free access to their data and licensing their\
    \ data\nto commercial data resellers, such as Gnip and DataSift.\nGnip is the\
    \ world’s largest provider of social data.\nGnip was the ﬁrst to partner with\
    \ Twitter to make their\nsocial data available, and since then, it was the ﬁrst\
    \ to\nwork\nwith\nTumblr,\nFoursquare,\nWordPress,\nDisqus,\nStockTwits and other\
    \ leading social platforms. Gnip\ndelivers social data to customers in more than\
    \ 40 coun-\ntries, and Gnip’s customers deliver social media analytics\nto more\
    \ than 95 % of the Fortune 500. Real-time data\nfrom Gnip can be delivered as\
    \ a ‘Firehose’ of every\nsingle activity or via PowerTrack, a proprietary ﬁltering\n\
    tool that allows users to build queries around only the\ndata they need. PowerTrack\
    \ rules can ﬁlter data streams\nbased on keywords, geo boundaries, phrase matches\
    \ and\neven the type of content or media in the activity. The\ncompany then offers\
    \ enrichments to these data streams\nsuch as Proﬁle Geo (to add signiﬁcantly more\
    \ usable geo\ndata for Twitter), URL expansion and language detection\nto further\
    \ enhance the value of the data delivered. In\naddition to real-time data access,\
    \ the company also offers\nHistorical PowerTrack and Search API access for Twitter\n\
    which give customers the ability to pull any Tweet since\nthe ﬁrst message on\
    \ March 21, 2006.\nGnip provides access to premium (Gnip’s ‘Complete\nAccess’\
    \ sources are publishers that have an agreement\nwith Gnip to resell their data)\
    \ and free data feeds (Gnip’s\n‘Managed Public API Access’ sources provide access\
    \ to\nnormalized and consolidated free data from their APIs,\nalthough it requires\
    \ Gnip’s paid services for the Data\nCollectors) via its dashboard (see Fig. 3).\
    \ Firstly, the user\nonly sees the feeds in the dashboard that were paid for\n\
    under a sales agreement. To select a feed, the user clicks\non a publisher and\
    \ then chooses a speciﬁc feed from that\npublisher as shown in Fig. 3. Different\
    \ types of feeds\nserve different types of use cases and correspond to dif-\n\
    ferent types of queries and API endpoints on the pub-\nlisher’s source API. After\
    \ selecting the feed, the user is\nassisted by Gnip to conﬁgure it with any required\n\
    parameters before it begins collecting data. This includes\nadding at least one\
    \ rule. Under ‘Get Data’ – [ ‘Advanced\nSettings’ you can also conﬁgure how often\
    \ your feed\nqueries the source API for data (the ‘query rate’). Choose\nbetween\
    \ the publisher’s native data format and Gnip’s\nActivity Streams format (XML\
    \ for Enterprise Data Col-\nlector feeds).\n4.3 Data feed access via APIs\nFor\
    \ researchers, arguably the most useful sources of social\nmedia data are those\
    \ that provide programmable access via\nFig. 2 Google Trends\nAI & Soc (2015)\
    \ 30:89–116\n95\n123\nAPIs, typically using HTTP-based protocols. Given their\n\
    importance to academics, here, we review individually\nwikis, social networking\
    \ media, RSS feeds, news, etc.\n4.3.1 Wiki media\nWikipedia (and wikis in general)\
    \ provides academics with\nlarge open-source repositories of user-generated (crowd-\n\
    sourced) content. What is not widely known is that Wiki-\npedia provides HTTP-based\
    \ APIs that allows programma-\nble access and searching (i.e., scraping) that\
    \ returns data in\na variety of formats including XML. In fact, the API is not\n\
    unique to Wikipedia but part of MediaWiki’s (http://www.\nmediawiki.org/) open-source\
    \ toolkit and hence can be used\nwith any MediaWiki-based wikis.\nThe wiki HTTP-based\
    \ API works by accepting requests\ncontaining one or more input arguments and\
    \ returning\nstrings, often in XML format, that can be parsed and used\nby the\
    \ requesting client. Other formats supported include\nJSON, WDDX, YAML, or PHP\
    \ serialized. Details can be\nfound\nat:\nhttp://en.wikipedia.org/w/api.php?action=\n\
    query&list=allcategories&acprop=size&acpreﬁx=hollywood\n&format=xml.\nThe HTTP\
    \ request must contain: a) the requested\n‘action,’ such as query, edit or delete\
    \ operation; b) an\nauthentication request; and c) any other supported actions.\n\
    For example, the above request returns an XML string\nlisting the ﬁrst 10 Wikipedia\
    \ categories with the preﬁx\n‘hollywood.’ Vaswani (2011) provides a detailed descrip-\n\
    tion of how to scrape Wikipedia using an Apache/PHP\ndevelopment environment and\
    \ an HTTP client capable of\ntransmitting\nGET\nand\nPUT\nrequests\nand\nhandling\n\
    responses.\n4.3.2 Social networking media\nAs with Wikipedia, popular social networks,\
    \ such as\nFacebook, Twitter and Foursquare, make a proportion of\ntheir data\
    \ accessible via APIs.\nAlthough many social networking media sites provide\n\
    APIs, not all sites (e.g., Bing, LinkedIn and Skype) provide\nAPI access for scraping\
    \ data. While more and more social\nFig. 3 Gnip Dashboard, Publishers and Feeds\n\
    96\nAI & Soc (2015) 30:89–116\n123\nnetworks are shifting to publicly available\
    \ content, many\nleading networks are restricting free access, even to aca-\n\
    demics. For example, Foursquare announced in December\n2013 that it will no longer\
    \ allow private check-ins on iOS\n7, and has now partnered with Gnip to provide\
    \ a continuous\nstream of anonymized check-in data. The data is available\nin\
    \ two packages: the full Firehose access level and a ﬁl-\ntered version via Gnip’s\
    \ PowerTrack service. Here, we\nbrieﬂy discuss the APIs provided by Twitter and\
    \ Facebook.\n4.3.2.1 Twitter\nThe default account setting keeps users’\nTweets\
    \ public, although users can protect their Tweets and\nmake them visible only\
    \ to their approved Twitter followers.\nHowever, less than 10 % of all the Twitter\
    \ accounts are\nprivate. Tweets from public accounts (including replies and\n\
    mentions) are available in JSON format through Twitter’s\nSearch API for batch\
    \ requests of past data and Streaming\nAPI for near real-time data.\n•\nSearch\
    \ API—Query Twitter for recent Tweets con-\ntaining speciﬁc keywords. It is part\
    \ of the Twitter\nREST API v1.1 (it attempts to comply with the design\nprinciples\
    \ of the REST architectural style, which stands\nfor Representational State Transfer)\
    \ and requires an\nauthorized application (using oAuth, the open standard\nfor\
    \ authorization) before retrieving any results from the\nAPI.\n•\nStreaming API—A\
    \ real-time stream of Tweets, ﬁl-\ntered by user ID, keyword, geographic location\
    \ or\nrandom sampling.\nOne may retrieve recent Tweets containing particular\n\
    keywords through Twitter’s Search API (part of REST API\nv1.1) with the following\
    \ API call: https://api.twitter.com/1.\n1/search/tweets.json?q=APPLE and real-time\
    \ data using\nthe\nstreaming\nAPI\ncall:\nhttps://stream.twitter.com/1/\nstatuses/sample.json.\n\
    Twitter’s Streaming API allows data to be accessed via\nﬁltering (by keywords,\
    \ user IDs or location) or by sampling\nof all updates from a select amount of\
    \ users. Default access\nlevel ‘Spritzer’ allows sampling of roughly 1 % of all\n\
    public statuses, with the option to retrieve 10 % of all\nstatuses via the ‘Gardenhose’\
    \ access level (more suitable\nfor data mining and research applications). In\
    \ social media,\nstreaming APIs are often called Firehose—a syndication\nfeed\
    \ that publishes all public activities as they happen in\none big stream. Twitter\
    \ has recently announced the Twitter\nData Grants program, where researchers can\
    \ apply to get\naccess to Twitter’s public tweets and historical data in\norder\
    \ to get insights from its massive set of data (Twitter\nhas more than 500 million\
    \ tweets a day); research institu-\ntions and academics will not get the Firehose\
    \ access level;\ninstead, they will only get the data set needed for their\nresearch\
    \ project. Researchers can apply for it at the\nfollowing\naddress:\nhttps://engineering.twitter.com/\n\
    research/data-grants.\nTwitter results are stored in a JSON array of objects\n\
    containing the ﬁelds shown in Fig. 4. The JSON array\nconsists of a list of objects\
    \ matching the supplied ﬁlters and\nthe search string, where each object is a\
    \ Tweet and its\nstructure is clearly speciﬁed by the object’s ﬁelds, e.g.,\n\
    ‘created_at’ and ‘from_user’. The example in Fig. 4 con-\nsists of the output\
    \ of calling Twitter’s GET search API via\nhttp://search.twitter.com/search.json?q=ﬁnancial%20times\n\
    &rpp=1&include_entities=true&result_type=mixed where\nthe parameters specify that\
    \ the search query is ‘ﬁnancial\ntimes,’ one result per page, each Tweet should\
    \ have a node\ncalled ‘entities’ (i.e., metadata about the Tweet) and list\n‘mixed’\
    \ results types, i.e., include both popular and real-\ntime results in the response.\n\
    4.3.2.2 Facebook\nFacebook’s privacy issues are more\ncomplex than Twitter’s,\
    \ meaning that a lot of status mes-\nsages are harder to obtain than Tweets, requiring\
    \ ‘open\nauthorization’ status from users. Facebook currently stores\nall data\
    \ as objects1 and has a series of APIs, ranging from\nthe Graph and Public Feed\
    \ APIs to Keyword Insight API.\nIn order to access the properties of an object,\
    \ its unique\nID must be known to make the API call. Facebook’s\nSearch API (part\
    \ of Facebook’s Graph API) can be\naccessed by calling https://graph.facebook.com/search?q=\n\
    QUERY&type=page. The detailed API query format is\nshown in Fig. 5. Here, ‘QUERY’\
    \ can be replaced by any\nsearch term, and ‘page’ can be replaced with ‘post,’\
    \ ‘user,’\n‘page,’ ‘event,’ ‘group,’ ‘place,’ ‘checkin,’ ‘location’ or\n‘placetopic.’\
    \ The results of this search will contain the\nunique ID for each object. When\
    \ returning the individual\nID for a particular search result, one can use https://graph.\n\
    facebook.com/ID to obtain further page details such as\nnumber of ‘likes.’ This\
    \ kind of information is of interest to\ncompanies when it comes to brand awareness\
    \ and com-\npetition monitoring.\nThe Facebook Graph API search queries require\
    \ an\naccess token included in the request. Searching for pages\nand places requires\
    \ an ‘app access token’, whereas\nsearching for other types requires a user access\
    \ token.\nReplacing ‘page’ with ‘post’ in the aforementioned\nsearch URL will\
    \ return all public statuses containing this\nsearch term.2 Batch requests can\
    \ be sent by following the\nprocedure outlined here: https://developers.facebook.com/\n\
    docs/reference/api/batch/. Information on retrieving real-\ntime\nupdates\ncan\n\
    be\nfound\nhere:\nhttps://developers.\nfacebook.com/docs/reference/api/realtime/.\
    \ Facebook also\n1 An object may be a person, a page, a picture or an event.\n\
    2 Details of the information retrieved in status updates can be found\nhere: https://developers.facebook.com/docs/reference/api/status/.\n\
    AI & Soc (2015) 30:89–116\n97\n123\nreturns data in JSON format and so can be\
    \ retrieved and\nstored using the same methods as used with data from\nTwitter,\
    \ although the ﬁelds are different depending on the\nsearch type, as illustrated\
    \ in Fig. 6.\n4.3.3 RSS feeds\nA large number of Web sites already provide access\
    \ to\ncontent via RSS feeds. This is the syndication standard for\npublishing\
    \ regular updates to web-based content based on a\ntype of XML ﬁle that resides\
    \ on an Internet server. For\nWeb sites, RSS feeds can be created manually or\
    \ auto-\nmatically (with software).\nAn RSS Feed Reader reads the RSS feed ﬁle,\
    \ ﬁnds what\nis new converts it to HTML and displays it. The program\nfragment\
    \ in Fig. 7 shows the code for the control and\nchannel statements for the RSS\
    \ feed. The channel state-\nments deﬁne the overall feed or channel, one set of\
    \ channel\nstatements in the RSS ﬁle.\n4.3.4 Blogs, news groups and chat services\n\
    Blog scraping is the process of scanning through a\nlarge number of blogs, usually\
    \ daily, searching for and\ncopying content. This process is conducted through\n\
    automated software. Figure 8 illustrates example code\n{ \n// Results page-specific\
    \ nodes: \n\"completed_in\":0.019, // Seconds taken to generate the results page\
    \ \n\"max_id\":270492897391034368, // Tweets maximum ID to be displayed up to\
    \ \n\"max_id_str\":\"270492897391034368\", // String version of the max ID \n\"\
    next_page\":\"?page=2&max_id=270492897391034368&q=financial%20times&rpp=1&include_entities=1&r\n\
    esult_type=mixed\", // Next results page parameters \n\"page\":1, // Current results\
    \ page \n\"query\":\"financial+times\", // Search query \n\"refresh_url\":\"?since_id=270492897391034368&q=financial%20times&result_type=mixed&include_entities\n\
    =1\", // Current results page parameters \n// Results node consisting of a list\
    \ of objects, i.e. Tweets: \n\"results\":[ \n    { \n// Tweet-specific nodes:\
    \ \n    \"created_at\":\"Sun, 18 Nov 2012 16:51:58 +0000\", // Timestamp Tweet\
    \ was created at \n    \"entities\":{\"hashtags\":[],\"urls\":[],\"user_mentions\"\
    :[]}, // Tweet metadata node \n    \"from_user\":\"zerohedge\", // Tweet author\
    \ username \n    \"from_user_id\":18856867, // Tweet author user ID \n    \"from_user_id_str\"\
    :\"18856867\", // String representation of the user ID \n    \"from_user_name\"\
    :\"zerohedge\", // Tweet author username \n    \"geo\":null, // Geotags (optional)\
    \ \n    \"id\":270207733444263936, // Tweet ID \n    \"id_str\":\"270207733444263936\"\
    , // String representation of the Tweet ID \n    \"iso_language_code\":\"en\"\
    , // Tweet language (English) \n    \"metadata\":{\"recent_retweets\":6,\"result_type\"\
    :\"popular\"}, // Tweet metadata \n    // Tweet author profile image URL (secure\
    \ and non-secure HTTP): \n    \"profile_image_url\":\"http:\\/\\/a0.twimg.com\\\
    /profile_images\\/72647502\\/tyler_normal.jpg\", \n    \"profile_image_url_https\"\
    :\"https:\\/\\/si0.twimg.com\\/profile_images\\/72647502\\/tyler_normal.jpg\"\
    , \n    // Tweet source (whether it was posted from Twitter Web or another interface):\
    \ \n    \"source\":\"&lt;a href=&quot;http:\\/\\/www.tweetdeck.com&quot;&gt;TweetDeck&lt;\\\
    /a&gt;\", \n    \"text\":\"Investment Banks to Cut 40,000 More Jobs, Financial\
    \ Times Says\", // Tweet content \n    // Recipient details (if any): \n    \"\
    to_user\":null, \n    \"to_user_id\":0, \n    \"to_user_id_str\":\"0\", \n   \
    \ \"to_user_name\":null \n    } \n], \n// Other results page-specific nodes: \n\
    \"results_per_page\":1, // Number of Tweets displayed per results page \n\"since_id\"\
    :0, // Minimum Tweet ID \n\"since_id_str\":\"0\" // String representation of the\
    \ ‘since_id’ value \n} \nFig. 4 Example Output in\nJSON for Twitter REST API v1\n\
    GET graph.facebook.com \n  /search? \n    q={your-query}& \n    [type={object-type}](#searchtypes)\
    \ \nFig. 5 Facebook Graph API\nSearch Query Format\n98\nAI & Soc (2015) 30:89–116\n\
    123\nfor Blog Scraping. This involves getting a Web site’s\nsource code via Java’s\
    \ URL Class, which can eventu-\nally be parsed via Regular Expressions to capture\
    \ the\ntarget content.\n4.3.5 News feeds\nNews feeds are delivered in a variety\
    \ of textual for-\nmats,\noften\nas\nmachine-readable\nXML\ndocuments,\nJSON or\
    \ CSV ﬁles. They include numerical values,\ntags and other properties that tend\
    \ to represent under-\nlying news stories. For testing purposes, historical\n\
    information is often delivered via ﬂat ﬁles, while live\ndata\nfor\nproduction\n\
    is\nprocessed\nand\ndelivered\nthrough direct data feeds or APIs. Figure 9 shows\
    \ a\nsnippet of the software calls to retrieve ﬁltered NY\nTimes articles.\nHaving\
    \ examined the ‘classic’ social media data feeds,\nas an illustration of scraping\
    \ innovative data sources, we\nwill brieﬂy look at geospatial feeds.\n{ \n\"id\"\
    :\"96184651725\", \n\"name\":\"Centrica\", \n\"picture\":\"http:\\/\\/profile.ak.fbcdn.net\\\
    /hprofile-ak-snc4\\/71177_96184651725_7616434_s.jpg\", \n\"link\":\"http:\\/\\\
    /www.facebook.com\\/centricaplc\", \n\"likes\":427, \n\"category\":\"Energy\\\
    /utility\", \n\"website\":\"http:\\/\\/www.centrica.com\", \n\"username\":\"centricaplc\"\
    , \n\"about\":\"We're Centrica, meeting our customers' energy needs now...and\
    \ in the future. As a leading \nintegrated energy company, we're investing more\
    \ now than ever in new sources of gas and power. \nhttp:\\/\\/www.centrica.com\"\
    , \n\"location\":{ \n\"street\":\"Millstream, Maidenhead Road\", \n\"city\":\"\
    Windsor\", \n\"country\":\"United Kingdom\", \n\"zip\":\"SL4 5GD \", \n\"latitude\"\
    :51.485694848812, \n\"longitude\":-0.63927860415725 \n}, \n\"phone\":\"+44 (0)1753\
    \ 494000\", \n\"checkins\":228, \n\"talking_about_count\":5 \n} \nFig. 6 Facebook\
    \ Graph API\nSearch Results for q=’Centrica’\nand type=’page’\n<?xml version=\"\
    1.0\" encoding=\"UTF-8\"?> \n<rss [...] version=\"2.0\"> \n  // RSS channel-specific\
    \ tags: \n  <channel> \n    [...] \n    <copyright>© Copyright The Financial Times\
    \ Ltd 2012. \"FT\" and \"Financial Times\" are trademarks of the Financial Times.\
    \ \nSee http://www.ft.com/servicestools/help/terms#legal1 for the terms and conditions\
    \ of reuse.</copyright> \n    <pubDate>Fri, 26 Oct 2012 09:42:18 GMT</pubDate>\
    \ // Timestamp RSS was published at. \n    <lastBuildDate>Fri, 26 Oct 2012 09:59:36\
    \ GMT</lastBuildDate> // Last built timestamp of the RSS. \n    <webMaster>client.support@ft.com\
    \ (Client Support)</webMaster> // Web master contact address. \n    <ttl>15</ttl>\
    \ // Time to live – the number of minutes the feed can stay cached before refreshing\
    \ it from the source. \n    <category>Newspapers</category> // RSS category. \n\
    \    [...] \n// RSS feed-specific tags (e.g. below there is a news story): title,\
    \ description, link, date published, article ID. \n    <item> \n      <title>Cynthia\
    \ Carroll resigns at Anglo American</title> \n      <link>http://www.ft.com/cms/s/0/d568891e-1f35-11e2-b2ad-\n\
    00144feabdc0.html?ftcamp=published_links%2Frss%2Fhome_uk%2Ffeed%2F%2Fproduct</link>\
    \ \n      <description>Cynthia Carroll departs the mining group following speculation\
    \ for some time that she was under pressure \nat the strike-hit company</description>\
    \ \n      <pubDate>Fri, 26 Oct 2012 07:33:44 GMT</pubDate> \n      <guid isPermaLink=\"\
    false\">http://www.ft.com/cms/s/0/d568891e-1f35-11e2-b2ad-\n00144feabdc0.html?ftcamp=published_links%2Frss%2Fhome_uk%2Ffeed%2F%2Fproduct</guid>\
    \ \n      <ft:uid>d568891e-1f35-11e2-b2ad-00144feabdc0</ft:uid> \n    </item>\
    \ \n    [...]\n  </channel> \n</rss> \nFig. 7 Example RSS Feed Control and Channel\
    \ Statements\nAI & Soc (2015) 30:89–116\n99\n123\n4.3.6 Geospatial feeds\nMuch\
    \ of the ‘geospatial’ social media data come from\nmobile devices that generate\
    \ location- and time-sensitive\ndata. One can differentiate between four types\
    \ of mobile\nsocial media feeds (Kaplan 2012):\n•\nLocation and time sensitive—exchange\
    \ of messages\nwith relevance for one speciﬁc location at one speciﬁc\npoint-in\
    \ time (e.g., Foursquare).\n•\nLocation sensitive only—exchange of messages with\n\
    relevance for one speciﬁc location, which are tagged to\na certain place and read\
    \ later by others (e.g., Yelp and\nQype)\n•\nTime sensitive only—transfer of traditional\
    \ social\nmedia applications to mobile devices to increase\nimmediacy (e.g., posting\
    \ Twitter messages or Facebook\nstatus updates)\n•\nNeither location or time sensitive—transfer\
    \ of tradi-\ntional social media applications to mobile devices (e.g.,\nwatching\
    \ a YouTube video or reading a Wikipedia entry)\nWith increasingly advanced mobile\
    \ devices, notably\nsmartphones, the content (photos, SMS messages, etc.)\nhas\
    \ geographical identiﬁcation added, called ‘geotagged.’\nThese geospatial metadata\
    \ are usually latitude and lon-\ngitude coordinates, though they can also include\
    \ altitude,\nbearing, distance, accuracy data or place names. GeoRSS\nis an emerging\
    \ standard to encode the geographic loca-\ntion into a web feed, with two primary\
    \ encodings: Ge-\noRSS Geography Markup Language (GML) and GeoRSS\nSimple.\nExample\
    \ tools are GeoNetwork Opensource—a free\ncomprehensive cataloging application\
    \ for geographically\nreferenced information, and FeedBurner—a web feed\nprovider\
    \ that can also provide geotagged feeds, if the\nspeciﬁed feeds settings allow\
    \ it.\nAs an illustration Fig. 10 shows the pseudo-code for\nanalyzing a geospatial\
    \ feed.\n5 Text cleaning, tagging and storing\nThe importance of ‘quality versus\
    \ quantity’ of data in\nsocial media scraping and analytics cannot be overstated\n\
    (i.e., garbage in and garbage out). In fact, many details of\nanalytics models\
    \ are deﬁned by the types and quality of the\n// Use Java’s URL, InputStream and\
    \ DataInputStream classes to read in the content of the supplied URL. \nURL url;\
    \ \nInputStream inputStream = null; \nDataInputStream dataInputStream; \nString\
    \ line; \nscrapedContent = \"\";\ntry { \n    // Attempt to open the URL (if valid):\
    \ \n    url = new URL(\"http://blog.wordpress.com/\"); \n    inputStream = url.openStream();\
    \  // throws an IOException \n    dataInputStream = new DataInputStream(new BufferedInputStream(inputStream));\n\
    \    // Read the content line by line and store it in the scrapedContent variable:\
    \ \n    while ((line = dataInputStream.readLine()) != null) { \n        scrapedContent\
    \ += line + \"\\n\"; \n    } \n} catch (MalformedURLException exception) { \n\
    \     exception.printStackTrace(); \n} catch (IOException exception) { \n    \
    \ exception.printStackTrace(); \n} finally { \n    try { \n        inputStream.close();\
    \ \n    } catch (IOException exception) { \n    } \n} \n[...] \n// Use regular\
    \ expressions (RE) to parse the desired content from the scrapedContent. RE will\
    \ attempt to delimit text between \nsome unique tags. \nFig. 8 Example Code for\
    \ Blog Scraping\n \nnyTimesArticles = GET http://api.nytimes.com/svc/search/v1/article?query=(field:)keywords\
    \ (facet:[value])(&params)&api-\nkey=your-API-key \nparse_JSON(nyTimesArticles)\
    \ \nFig. 9 Scraping New York Times Articles\n100\nAI & Soc (2015) 30:89–116\n\
    123\ndata. The nature of the data will also inﬂuence the database\nand hardware\
    \ used.\nNaturally, unstructured textual data can be very noisy\n(i.e., dirty).\
    \ Hence, data cleaning (or cleansing, scrubbing)\nis an important area in social\
    \ media analytics. The process\nof data cleaning may involve removing typographical\n\
    errors or validating and correcting values against a known\nlist of entities.\
    \ Speciﬁcally, text may contain misspelled\nwords, quotations, program codes,\
    \ extra spaces, extra line\nbreaks, special characters, foreign words, etc. So\
    \ in order to\nachieve high-quality text mining, it is necessary to conduct\n\
    data cleaning at the ﬁrst step: spell checking, removing\nduplicates, ﬁnding and\
    \ replacing text, changing the case of\ntext, removing spaces and non-printing\
    \ characters from\ntext, ﬁxing numbers, number signs and outliers, ﬁxing\ndates\
    \ and times, transforming and rearranging columns,\nrows and table data, etc.\n\
    Having reviewed the types and sources of raw data, we\nnow turn to ‘cleaning’\
    \ or ‘cleansing’ the data to remove\nincorrect, inconsistent or missing information.\
    \ Before dis-\ncussing strategies for data cleaning, it is essential to iden-\n\
    tify possible data problems (Narang 2009):\n•\nMissing data—when a piece of information\
    \ existed but\nwas not included for whatever reason in the raw data\nsupplied.\
    \ Problems occur with: a) numeric data when\n‘blank’ or a missing value is erroneously\
    \ substituted by\n‘zero’ which is then taken (for example) as the current\nprice;\
    \ and b) textual data when a missing word (like\n‘not’) may change the whole meaning\
    \ of a sentence.\n•\nIncorrect data—when a piece of information is\nincorrectly\
    \ speciﬁed (such as decimal errors in numeric\ndata or wrong word in textual data)\
    \ or is incorrectly\ninterpreted (such as a system assuming a currency value\n\
    is in $ when in fact it is in £ or assuming text is in US\nEnglish rather than\
    \ UK English).\n•\nInconsistent data—when a piece of information is\ninconsistently\
    \ speciﬁed. For example, with numeric\ndata, this might be using a mixture of\
    \ formats for dates:\n2012/10/14, 14/10/2012 or 10/14/2012. For textual\ndata,\
    \ it might be as simple as: using the same word in a\nmixture of cases, mixing\
    \ English and French in a text\nmessage, or placing Latin quotes in an otherwise\n\
    English text.\n5.1 Cleansing data\nA traditional approach to text data cleaning\
    \ is to ‘pull’ data\ninto a spreadsheet or spreadsheet-like table and then\nreformat\
    \ the text. For example, Google Reﬁne3 is a\nstandalone desktop application for\
    \ data cleaning and\ntransformation to various formats. Transformation expres-\n\
    sions are written in proprietary Google Reﬁne Expression\nLanguage (GREL) or JYTHON\
    \ (an implementation of the\nPython programming language written in Java). Figure\
    \ 11\nillustrates text cleansing.\n5.2 Tagging unstructured data\nSince most of\
    \ the social media data is generated by humans\nand therefore is unstructured\
    \ (i.e., it lacks a pre-deﬁned\nstructure or data model), an algorithm is required\
    \ to\ntransform it into structured data to gain any insight.\nTherefore, unstructured\
    \ data need to be preprocessed,\ntagged and then parsed in order to quantify/analyze\
    \ the\nsocial media data.\nAdding extra information to the data (i.e., tagging\
    \ the\ndata) can be performed manually or via rules engines,\nwhich seek patterns\
    \ or interpret the data using techniques\nsuch as data mining and text analytics.\
    \ Algorithms exploit\nthe linguistic, auditory and visual structure inherent in\
    \ all\nof the forms of human communication. Tagging the\nunstructured data usually\
    \ involve tagging the data with\nmetadata or part-of-speech (POS) tagging. Clearly,\
    \ the\nunstructured nature of social media data leads to ambiguity\n// Attempt\
    \ to get the web site geotags by scraping the web page source code: \ntry getIcbmTags()\
    \ // attempt to get ICBM tags, such as <meta name='ICBM' content=\"latitude, longitude\"\
    \ /> \ntry getGeoStructureTags() // attempt to get tags such as <meta name=\"\
    geo.position\" content=\"coord1;coord2\" />, <meta \nname=\"geo.region\" content=\"\
    region\">, <meta name=\"geo.placename\" content=\"Place name\"> \n// Attempt to\
    \ get the web site’s RSS geotags by scraping the RSS feeds, where the RSS source\
    \ or each article can have their \nown geotags. \n// Attempt to get Resource Description\
    \ Framework (RDF) tags, such as \n<rdf:RDF><geo:Point><geo:lat>latitude</geo:lat><geo:long>longitude</geo:long><geo:alt>altitude</geo:alt></geo:Point></rdf:\n\
    RDF> \ntry getRdfRssTags() \n// Attempt to get RSS article-specific geotags, e.g.:\
    \ <rss \nversion=”2.0”><item><title>title</title>[...]><icbm:latitude>latitude</icbm:latitude><icbm:longitude>longitude</icbm:longitude>[..\n\
    .]</item> \ntry getIcbmRssTags() \nFig. 10 Pseudo-code for Analyzing a Geospatial\
    \ Feed\n3 More information about Google Reﬁne is found in its documen-\ntation\
    \ wiki: https://github.com/OpenReﬁne/OpenReﬁne/wiki.\nAI & Soc (2015) 30:89–116\n\
    101\n123\nand irregularity when it is being processed by a machine in\nan automatic\
    \ fashion.\nUsing a single data set can provide some interesting\ninsights. However,\
    \ combining more data sets and pro-\ncessing the unstructured data can result\
    \ in more valuable\ninsights, allowing us to answer questions that were\nimpossible\
    \ beforehand.\n5.3 Storing data\nAs discussed, the nature of the social media\
    \ data is highly\ninﬂuential on the design of the database and possibly the\n\
    supporting hardware. It would also be very important to\nnote that each social\
    \ platform has very speciﬁc (and nar-\nrow) rules around how their respective\
    \ data can be stored\nand used. These can be found in the Terms of Service for\n\
    each platform.\nFor completeness, databases comprise:\n•\nFlat ﬁle—a ﬂat ﬁle is\
    \ a two-dimensional database\n(somewhat like a spreadsheet) containing records\
    \ that\nhave\nno structured\ninterrelationship,\nthat\ncan\nbe\nsearched sequentially.\n\
    •\nRelational database—a database organized as a set of\nformally\ndescribed\n\
    tables\nto\nrecognize\nrelations\nbetween stored items of information, allowing\
    \ more\ncomplex relationships among the data items. Examples\nare\nrow-based\n\
    SQL\ndatabases\nand\ncolumn-based\nkdb ? used in ﬁnance.\n•\nnoSQL databases—a\
    \ class of database management\nsystem (DBMS) identiﬁed by its non-adherence to\
    \ the\nwidely used relational database management system\n(RDBMS) model. noSQL/newSQL\
    \ databases are char-\nacterized as: being non-relational, distributed, open-\n\
    source and horizontally scalable.\n5.3.1 Apache (noSQL) databases and tools\n\
    The growth of ultra-large Web sites such as Facebook and\nGoogle has led to the\
    \ development of noSQL databases as\na way of breaking through the speed constraints\
    \ that rela-\ntional databases incur. A key driver has been Google’s\nMapReduce,\
    \ i.e., the software framework that allows\ndevelopers to write programs that\
    \ process massive amounts\nof unstructured data in parallel across a distributed\
    \ cluster\nof processors or stand-alone computers (Chandrasekar and\nKowsalya\
    \ 2011). It was developed at Google for indexing\nWeb pages and replaced their\
    \ original indexing algorithms\nand heuristics in 2004. The model is inspired\
    \ by the ‘Map’\nand ‘Reduce’ functions commonly used in functional pro-\ngramming.\
    \ MapReduce (conceptually) takes as input a list\nof records, and the ‘Map’ computation\
    \ splits them among\nthe different computers in a cluster. The result of the Map\n\
    computation is a list of key/value pairs. The corresponding\n‘Reduce’ computation\
    \ takes each set of values that has the\nsame key and combines them into a single\
    \ value. A Ma-\npReduce program is composed of a ‘Map()’ procedure for\nﬁltering\
    \ and sorting and a ‘Reduce()’ procedure for a\nsummary operation (e.g., counting\
    \ and grouping).\nFigure 12 provides a canonical example application of\nMapReduce.\
    \ This example is a process to count the\nappearances of each different word in\
    \ a set of documents\n(MapReduce 2011).\n5.3.1.1 Apache\nopen-source\nsoftware\n\
    The\nresearch\ncommunity is increasingly using Apache software for\nsocial media\
    \ analytics. Within the Apache Software\nFoundation, three levels of software\
    \ are relevant:\n•\nCassandra/hive databases—Apache Cassandra is an\nopen source\
    \ (noSQL) distributed DBMS providing a\ncleanseText(blogPost) { \n  // Remove\
    \ any links from the blog post: \n  blogPost[‘text’] = handleLinks(blogPost[‘text’])\
    \ \n  // Remove unwanted ads inserted by Google Ads etc. within the main text\
    \ body: \n  blogPost[‘text’] = removeAds(blogPost[‘text’]) \n  // Normalize contracted\
    \ forms, e.g. isn’t becomes is not (so that negation words are explicitly specified).\
    \ \n  blogPost[‘text’] = normalizeContractedForms(blogPost[‘text’]) \n  // Remove\
    \ punctuation; different logic rules should be specified for each punctuation\
    \ mark \n  // You might not want to remove a hyphen surrounded by alphanumeric\
    \ characters. \n  // However you might want to remove a hyphen surrounded by at\
    \ least one white space. \n  blogPost[‘text’] = handlePunctuation(blogPost[‘text’])\
    \ \n  // Tokenize the text on white space, i.e. create an array of words from\
    \ the original text. \n  tokenizedText = tokenizeStatusOnWhiteSpace(blogPost[‘text’])\
    \ \n  // For each word, attempt to normalize it if it doesn’t belong to the WordNet\
    \ lexical database. \n  for word in tokenizedStatus: \n    if word not in WordNet\
    \ dictionary: \n      word = normalizeAcronym(word) \n      // Further Natural\
    \ Language Processing, POS Tagging \n      ... \n  return tokenizedText \n} \n\
    Fig. 11 Text Cleansing Pseudo-code\n102\nAI & Soc (2015) 30:89–116\n123\nstructured\
    \ ‘key-value’ store. Key-value stores allow an\napplication to store its data\
    \ in a schema-less way.\nRelated noSQL database products include: Apache\nHive,\
    \ Apache Pig and MongoDB, a scalable and high-\nperformance open-source database\
    \ designed to handle\ndocument-oriented storage. Since noSQL databases are\n‘structure-less,’\
    \ it is necessary to have a companion\nSQL database to retain and map the structure\
    \ of the\ncorresponding data.\n•\nHadoop\nplatform—is\na\nJava-based\nprogramming\n\
    framework that supports the processing of large data\nsets in a distributed computing\
    \ environment. An\napplication is broken down into numerous small parts\n(also\
    \ called fragments or blocks) that can be run on\nsystems with thousands of nodes\
    \ involving thousands\nof terabytes of storage.\n•\nMahout—provides implementations\
    \ of distributed or\notherwise scalable analytics (machine learning) algo-\nrithms\
    \ running on the Hadoop platform. Mahout4\nsupports four classes of algorithms:\
    \ a) clustering (e.g.,\nK-Means, Fuzzy C-Means) that groups text into related\n\
    groups; b) classiﬁcation (e.g., Complementary Naive\nBayes classiﬁer) that uses\
    \ supervised learning to\nclassify text; c) frequent itemset mining takes a set\
    \ of\nitem groups and identiﬁes which individual items\nusually appear together;\
    \ and d) recommendation min-\ning (e.g., user- and item-based recommenders) that\n\
    takes users’ behavior and from that tries to ﬁnd items\nusers might like.\n6 Social\
    \ media analytics techniques\nAs discussed, opinion mining (or sentiment analysis)\
    \ is\nan attempt to take advantage of the vast amounts of\nuser-generated text\
    \ and news content online. One of the\nprimary characteristics of such content\
    \ is its textual\ndisorder and high diversity. Here, natural language\nprocessing,\
    \ computational linguistics and text analytics\nare deployed to identify and extract\
    \ subjective infor-\nmation from source text. The general aim is to deter-\nmine\
    \ the attitude of a writer (or speaker) with respect\nto some topic or the overall\
    \ contextual polarity of a\ndocument.\n6.1 Computational science techniques\n\
    Automated sentiment analysis of digital texts uses elements\nfrom machine learning\
    \ such as latent semantic analysis,\nsupport vector machines, bag-of-words model\
    \ and seman-\ntic orientation (Turney 2002). In simple terms, the tech-\nniques\
    \ employ three broad areas:\n•\nComputational statistics—refers to computationally\n\
    intensive\nstatistical\nmethods\nincluding\nresampling\nmethods, Markov chain\
    \ Monte Carlo methods, local\nregression, kernel density estimation and principal\n\
    components analysis.\n•\nMachine learning—a system capable of the autono-\nmous\
    \ acquisition and integration of knowledge learnt\nfrom experience, analytical\
    \ observation, etc. (Murphy\n2012). These sub-symbolic systems further subdivide\n\
    into:\n•\nSupervised learning such as Regression Trees,\nDiscriminant Function\
    \ Analysis, Support Vector\nMachines.\n•\nUnsupervised learning such as Self-Organizing\n\
    Maps (SOM), K-Means.\nMachine Learning aims to solve the problem of having\nhuge\
    \ amounts of data with many variables and is com-\nmonly used in areas such as\
    \ pattern recognition (speech,\nimages), ﬁnancial algorithms (credit scoring,\
    \ algorithmic\ntrading) (Nuti et al. 2011), energy forecasting (load, price)\n\
    and biology (tumor detection, drug discovery). Figure 13\nillustrates the two\
    \ learning types of machine learning and\ntheir algorithm categories.\nvoid map(String\
    \ name, String document): \n  // name: document name \n  // document: document\
    \ contents \n  // Split the input amongst the various computers within the cluster.\
    \ \n  for each word w in document: \n    EmitIntermediate(w, \"1\"); // Output\
    \ key-value pairs as the map function processes the data in its input file. \n\
    void reduce(String word, Iterator partialCounts): \n  // word: a word \n  // partialCounts:\
    \ a list of aggregated partial counts \n  // Take each set of values with the\
    \ same key and combines them into a single value. \n  int sum = 0; \n  for each\
    \ pc in partialCounts: \n    sum += ParseInt(pc); \n  Emit(word, AsString(sum));\n\
    Fig. 12 The Canonical Example Application of MapReduce\n4 Apache Mahout project\
    \ page: http://mahout.apache.org/.\nAI & Soc (2015) 30:89–116\n103\n123\n•\nComplexity\
    \ science—complex simulation models of\ndifﬁcult-to-predict systems derived from\
    \ statistical\nphysics, information theory and nonlinear dynamics.\nThe realm\
    \ of physicists and mathematicians.\nThese techniques are deployed in two ways:\n\
    •\nData mining—knowledge discovery that extracts hid-\nden patterns from huge\
    \ quantities of data, using\nsophisticated differential equations, heuristics,\
    \ statisti-\ncal discriminators (e.g., hidden Markov models), and\nartiﬁcial intelligence\
    \ machine learning techniques (e.g.,\nneural networks, genetic algorithms and\
    \ support vector\nmachines).\n•\nSimulation modeling—simulation-based analysis\
    \ that\ntests hypotheses. Simulation is used to attempt to\npredict the dynamics\
    \ of systems so that the validity of\nthe underlying assumption can be tested.\n\
    6.1.1 Stream processing\nLastly, we should mention stream processing (Botan et\
    \ al\n2010). Increasingly, analytics applications that consume\nreal-time social\
    \ media, ﬁnancial ‘ticker’ and sensor net-\nworks data need to process high-volume\
    \ temporal data with\nlow latency. These applications require support for online\n\
    analysis of rapidly changing data streams. However, tradi-\ntional database management\
    \ systems (DBMSs) have no pre-\ndeﬁned notion of time and cannot handle data online\
    \ in near\nreal time. This has led to the development of Data Stream\nManagement\
    \ Systems (DSMSs) (Hebrail 2008)—process-\ning in main memory without storing\
    \ the data on disk—that\nhandle transient data streams on-line and process continu-\n\
    ous queries on these data streams. Example commercial\nsystems include: Oracle\
    \ CEP engine, StreamBase and\nMicrosoft’s StreamInsight (Chandramouli et al. 2010).\n\
    6.2 Sentiment analysis\nSentiment is about mining attitudes, emotions, feelings—it\n\
    is subjective impressions rather than facts. Generally\nspeaking, sentiment analysis\
    \ aims to determine the attitude\nexpressed by the text writer or speaker with\
    \ respect to the\ntopic or the overall contextual polarity of a document\n(Mejova\
    \ 2009). Pang and Lee (2008) provide a thorough\ndocumentation on the fundamentals\
    \ and approaches of\nsentiment classiﬁcation and extraction, including sentiment\n\
    polarity, degrees of positivity, subjectivity detection,\nopinion identiﬁcation,\
    \ non-factual information, term pre-\nsence versus frequency, POS (parts of speech),\
    \ syntax,\nnegation, topic-oriented features and term-based features\nbeyond term\
    \ unigrams.\n6.2.1 Sentiment classiﬁcation\nSentiment analysis divides into speciﬁc\
    \ subtasks:\n•\nSentiment context—to extract opinion, one needs to\nknow the ‘context’\
    \ of the text, which can vary\nsigniﬁcantly from specialist review portals/feeds\
    \ to\ngeneral forums where opinions can cover a spectrum of\ntopics (Westerski\
    \ 2008).\n•\nSentiment level—text analytics can be conducted at\nthe document,\
    \ sentence or attribute level.\nFig. 13 Machine Learning Overview\n104\nAI & Soc\
    \ (2015) 30:89–116\n123\n•\nSentiment subjectivity—deciding whether a given text\n\
    expresses an opinion or is factual (i.e., without\nexpressing a positive/negative\
    \ opinion).\n•\nSentiment orientation/polarity—deciding whether an\nopinion in\
    \ a text is positive, neutral or negative.\n•\nSentiment strength—deciding the\
    \ ‘strength’ of an\nopinion in a text: weak, mild or strong.\nPerhaps, the most\
    \ difﬁcult analysis is identifying senti-\nment orientation/polarity and strength—positive\
    \ (wonder-\nful, elegant, amazing, cool), neutral (ﬁne, ok) and negative\n(horrible,\
    \ disgusting, poor, ﬂakey, sucks) due to slang.\nA popular approach is to assign\
    \ orientation/polarity\nscores (?1, 0, -1) to all words: positive opinion (?1),\n\
    neutral opinion (0) and negative opinion (-1). The overall\norientation/polarity\
    \ score of the text is the sum of orien-\ntation scores of all ‘opinion’ words\
    \ found. However, there\nare various potential problems in this simplistic approach,\n\
    such as negation (e.g., there is nothing I hate about this\nproduct). One method\
    \ of estimating sentiment orientation/\npolarity of the text is pointwise mutual\
    \ information (PMI) a\nmeasure of association used in information theory and\n\
    statistics.\n6.2.2 Supervised learning methods\nThere are a number of popular\
    \ computational statistics and\nmachine learning techniques used for sentiment\
    \ analysis.\nFor a good introduction, see (Khan et al 2010). Techniques\ninclude:\n\
    •\nNaı¨ve Bayes (NB)—a simple probabilistic classiﬁer\nbased on applying Bayes’\
    \ theorem with strong (naive)\nindependence assumptions (when features are indepen-\n\
    dent of one another within each class).\n•\nMaximum entropy (ME)—the probability\
    \ distribution\nthat best represents the current state of knowledge is the\none\
    \ with largest information-theoretical entropy.\n•\nSupport vector machines (SVM)—are\
    \ supervised\nlearning models with associated learning algorithms\nthat analyze\
    \ data and recognize patterns, used for\nclassiﬁcation and regression analysis.\n\
    •\nLogistic regression (LR) model—is a type of regres-\nsion analysis used for\
    \ predicting the outcome of a\ncategorical (a variable that can take on a limited\n\
    number of categories) criterion variable based on one or\nmore predictor variables.\n\
    •\nLatent semantic analysis—an indexing and retrieval\nmethod that uses a mathematical\
    \ technique called\nsingular value decomposition (SVD) to identify pat-\nterns\
    \ in the relationships between the terms and\nconcepts contained in an unstructured\
    \ collection of\ntext (Kobayashi and Takeda 2000).\nThe bag-of-words model is\
    \ a simplifying representation\ncommonly used in natural language processing and\
    \ IR,\nwhere a sentence or a document is represented as an\nunordered collection\
    \ of words, disregarding grammar and\neven word order. This is a model traditionally\
    \ applied to\nsentiment analysis thanks to its simplicity.\n6.2.2.1 Naı¨ve Bayes\
    \ classiﬁer (NBC)\nAs an example of\nsentiment analysis, we will describe brieﬂy\
    \ a Naive Bayes\nclassiﬁer (Murphy 2006). The Naive Bayes classiﬁer is\ngeneral\
    \ purpose, simple to implement and works well for a\nrange of applications. It\
    \ classiﬁes data in two steps:\n•\nTraining step—using the training samples, the\
    \ method\nestimates the parameters of a probability distribution,\nassuming features\
    \ are conditionally independent given\nthe class.\n•\nAnalysis/testing step—For\
    \ any unseen test sample, the\nmethod computes the posterior probability of that\n\
    sample belonging to each class. The method then\nclassiﬁes the test sample according\
    \ to the largest\nposterior probability.\nUsing the Naı¨ve Bayes classiﬁer, the\
    \ classiﬁer calculates\nthe probability for a text to belong to each of the categories\n\
    you test against. The category with the highest probability\nfor the given text\
    \ wins:\nclassify word1; word2; . . .wordn\nð\nÞ\n¼ arg max\ncat\nP cat\nð\nÞ\
    \ \x03\nY\nn\ni¼1\nPðwordijcatÞ\nFigure 14\nprovides\nan\nexample\nof\nsentiment\n\
    classiﬁcation using a Naı¨ve Bayes classiﬁer in Python.\nThere are a number of\
    \ Naı¨ve Bayes classiﬁer programs\navailable in Java, including the jBNC toolkit\
    \ (http://jbnc.\nsourceforge.net), WEKA (www.cs.waikato.ac.nz/ml/weka)\nand Alchemy\
    \ API (www.alchemyapi.com/api/demo.html).\nWe next look at the range of Social\
    \ Media tools avail-\nable, starting with ‘tools’ and ‘toolkits,’ and in the sub-\n\
    sequent chapter at ‘comprehensive’ social media platforms.\nSince there are a\
    \ large number of social media textual data\nservices, tools and platforms, we\
    \ will restrict ourselves\nexamining a few leading examples.\n7 Social media analytics\
    \ tools\nOpinion mining tools are crowded with (commercial)\nproviders, most of\
    \ which are skewed toward sentiment\nanalysis of customer feedback about products\
    \ and services.\nFortunately, there is a vast spectrum of tools for textual\n\
    analysis ranging from simple open-source tools to libraries,\nmulti-function commercial\
    \ toolkits and platforms. This\nAI & Soc (2015) 30:89–116\n105\n123\nsection focuses\
    \ on individual tools and toolkits for scrap-\ning, cleaning and analytics, and\
    \ the next chapter looks at\nwhat we call social media platforms that provide\
    \ both\narchive data and real-time feeds, and as well as sophisti-\ncated analytics\
    \ tools.\n7.1 Scientiﬁc programming tools\nPopular scientiﬁc analytics libraries\
    \ and tools have been\nenhanced to provide support for sourcing, searching and\n\
    analyzing text. Examples include: R—used for statistical\nprogramming, MATLAB—used\
    \ for numeric scientiﬁc\nprogramming, and Mathematica—used for symbolic sci-\n\
    entiﬁc programming (computer algebra).\nData processing and data modeling, e.g.,\
    \ regression\nanalysis, are straightforward using MATLAB, which pro-\nvides time-series\
    \ analysis, GUI and array-based statistics.\nMATLAB is signiﬁcantly faster than\
    \ the traditional pro-\ngramming languages and can be used for a wide range of\n\
    applications. Moreover, the exhaustive built-in plotting\nfunctions make it a\
    \ complex analytics toolkit. More com-\nputationally powerful algorithms can be\
    \ developed using it\nin conjunction with the packages (e.g., FastICA in order\
    \ to\nperform independent component analysis).\nPython can be used for (natural)\
    \ language detection, title\nand content extraction, query matching and, when\
    \ used in\nconjunction with a module such as scikit-learn, it can be\ntrained\
    \ to perform sentiment analysis, e.g., using a Naı¨ve\nBayes classiﬁer.\nAnother\
    \ example, Apache UIMA (Unstructured Infor-\nmation Management Applications) is\
    \ an open-source pro-\nject that analyzes ‘big data’ and discovers information\
    \ that\nis relevant to the user.\n7.2 Business toolkits\nBusiness Toolkits are\
    \ commercial suites of tools that allow\nusers to source, search and analyze text\
    \ for a range of\ncommercial purposes.\nSAS Sentiment Analysis Manager, part of\
    \ the SAS Text\nAnalytics program, can be used for scraping content\nsources,\
    \ including mainstream Web sites and social media\noutlets, as well as internal\
    \ organizational text sources, and\ncreates reports that describe the expressed\
    \ feelings of\nconsumers, customers and competitors in real time.\nRapidMiner\
    \ (Hirudkar and Sherekar 2013), a popular\ntoolkit\noffering\nan\nopen-source\n\
    Community\nEdition\nreleased under the GNU AGPL and also an Enterprise\nEdition\
    \ offered under a commercial license. RapidMiner\nprovides data mining and machine\
    \ learning procedures\nincluding:\ndata\nloading\nand\ntransformation\n(Extract,\n\
    Transform, Load, a.k.a. ETL), data preprocessing and\nvisualization,\nmodeling,\n\
    evaluation,\nand\ndeployment.\nRapidMiner is written in Java and uses learning\
    \ schemes\nand attribute evaluators from the Weka machine learning\nenvironment\
    \ and statistical modeling schemes from the R\nproject.\nOther examples are Lexalytics\
    \ that provides a com-\nmercial sentiment analysis engine for many OEM and\ndirect\
    \ customers; and IBM SPSS Statistics is one of the\nmost used programs for statistical\
    \ analysis in social\nscience.\n7.3 Social media monitoring tools\nSocial media\
    \ monitoring tools are sentiment analysis tools\nfor tracking and measuring what\
    \ people are saying (typi-\ncally) about a company or its products, or any topic\
    \ across\nthe web’s social media landscape.\nIn the area of social media monitoring\
    \ examples include:\nSocial Mention, (http://socialmention.com/), which pro-\n\
    vides social media alerts similarly to Google Alerts;\nAmpliﬁed Analytics (http://www.ampliﬁedanalytics.com/),\n\
    which focuses on product reviews and marketing informa-\ntion; Lithium Social\
    \ Media Monitoring; and Trackur, which\nis an online reputation monitoring tool\
    \ that tracks what is\nbeing said on the Internet.\nGoogle also provides a few\
    \ useful free tools. Google\nTrends shows how often a particular search-term input\n\
    compares to the total search volume. Another tool built\naround Google Search\
    \ is Google Alerts—a content change\ndetection tool that provides notiﬁcations\
    \ automatically.\nGoogle also acquired FeedBurner—an RSS feeds man-\nagement—in\
    \ 2007.\nfor (tweet, label) in trainingSetMessage: \n    // Normalize words, handle\
    \ punctuation, tokenize on white space etc. \n    preProcessMessage(tweet) \n\
    \    for tweetWord in tweet: \n        // Tokenize each Tweet, assign the label\
    \ to each word and store it in the training set \n        trainingSet += (tweetWord,\
    \ label) \nclassifier = NaiveBayesClassifier.train(trainingSet) \npredictedLabel\
    \ = classifier.classify(getFeatures(preProcessMessage(trainingSet))) \nFig. 14\
    \ Sentiment Classiﬁcation Example using Python\n106\nAI & Soc (2015) 30:89–116\n\
    123\n7.4 Text analysis tools\nText analysis tools are broad-based tools for natural\
    \ lan-\nguage processing and text analysis. Examples of companies\nin the text\
    \ analysis area include: OpenAmplify and Jodange\nwhose tools automatically ﬁlter\
    \ and aggregate thoughts,\nfeelings and statements from traditional and social\
    \ media.\nThere are also a large number of freely available tools\nproduced by\
    \ academic groups and non-governmental\norganizations (NGO) for sourcing, searching\
    \ and analyzing\nopinions. Examples include Stanford NLP group tools and\nLingPipe,\
    \ a suite of Java libraries for the linguistic analysis\nof human language (Teuﬂ\
    \ et al 2010).\nA variety of open-source text analytics tools are avail-\nable,\
    \ especially for sentiment analysis. A popular text\nanalysis tool, which is also\
    \ open source, is Python NLTK—\nNatural Language Toolkit (www.nltk.org/), which\
    \ includes\nopen-source Python modules, linguistic data and docu-\nmentation for\
    \ text analytics. Another one is GATE (http://\ngate.ac.uk/sentiment).\nWe should\
    \ also mention Lexalytics Sentiment Toolkit\nwhich performs automatic sentiment\
    \ analysis on input\ndocuments. It is powerful when used on a large number of\n\
    documents, but it does not perform data scraping.\nOther commercial software for\
    \ text mining include:\nAeroText, Attensity, Clarabridge, IBM LanguageWare,\n\
    SPSS Text Analytics for Surveys, Language Computer\nCorporation, STATISTICA Text\
    \ Miner and WordStat.\n7.5 Data visualization tools\nThe data visualization tools\
    \ provide business intelligence\n(BI) capabilities and allow different types of\
    \ users to gain\ninsights from the ‘big’ data. The users can perform\nexploratory\
    \ analysis through interactive user interfaces\navailable on the majority of devices,\
    \ with a recent focus on\nmobile devices (smartphones and tablets). The data visu-\n\
    alization tools help the users identify patterns, trends and\nrelationships in\
    \ the data which were previously latent. Fast\nad hoc visualization on the data\
    \ can reveal patterns and\noutliers, and it can be performed on large-scale data\
    \ sets\nframeworks, such as Apache Hadoop or Amazon Kinesis.\nTwo notable visualization\
    \ tools are SAS Visual Analytics\nand Tableau.\n7.6 Case study: SAS Sentiment\
    \ Analysis and Social\nMedia Analytics\nSAS is the leading advanced analytics\
    \ software for BI, data\nmanagement and predictive analytics. SAS Sentiment\n\
    Analysis (SAS Institute 2013) automatically rates and\nclassiﬁes opinions. It\
    \ also performs data scraping from\nWeb sites, social media and internal ﬁle systems.\
    \ Then, it\nprocesses in a uniﬁed format to evaluate relevance with\nregard to\
    \ its pre-deﬁned topics. SAS Sentiment Analysis\nidentiﬁes trends and emotional\
    \ changes. Experts can reﬁne\nthe sentiment models through an interactive workbench.\n\
    The tool automatically assigns sentiment scores to the input\ndocuments as they\
    \ are retrieved in real time.\nSAS Sentiment Analysis combines statistical modeling\n\
    and linguistics (rule-based natural language processing\ntechniques) in order\
    \ to output accurate sentiment analysis\nresults. The tool monitors and evaluates\
    \ sentiment changes\nover time; it extracts sentiments in real time as the scraped\n\
    data is being retrieved and generates reports showing pat-\nterns and detailed\
    \ reactions.\nThe software identiﬁes where (i.e., on what channel) the\ntopic\
    \ is being discussed and quantiﬁes perceptions in the\nmarket as the software\
    \ scrapes and analyzes both internal\nand external content about your organization\
    \ (or the con-\ncept you are analyzing) and competitors, identifying posi-\ntive,\
    \ neutral, negative or ‘no sentiment’ texts in real time.\nSAS Sentiment Analysis\
    \ and SAS Social Media Ana-\nlytics have a user-friendly interface for developing\
    \ models;\nusers can upload sentiment analysis models directly to the\nserver\
    \ in order to minimize the manual model deployment.\nMore advanced users can use\
    \ the interactive workbench to\nreﬁne their models. The software includes graphics\
    \ to\nillustrate instantaneously the text classiﬁcation (i.e., posi-\ntive, negative,\
    \ neutral or unclassiﬁed) and point-and-click\nexploration in order to drill the\
    \ classiﬁed text into detail.\nThe tool also provides some workbench functionality\n\
    through APIs, allowing for automatic/programmatic inte-\ngration with other modules/projects.\
    \ Figure 15 illustrates\nthe SAS Social Media Analytics graphical reports, which\n\
    provide user-friendly sentiment insights. The SAS software\nhas crawling plugins\
    \ for the most popular social media\nsites, including Facebook, Twitter, Bing,\
    \ LinkedIn, Flickr\nand Google. It can also be customized to crawl any Web\nsite\
    \ using the mark-up matcher; this provides a point-and-\nclick interface to indicate\
    \ what areas need to be extracted\nfrom an HTML or XML. SAS Social Media Analytics\n\
    gathers online conversations from popular networking sites\n(e.g., Facebook and\
    \ Twitter), blogs and review sites (e.g.,\nTripAdvisor and Priceline), and scores\
    \ the data for inﬂu-\nence and sentiment. It provides visualization tools for\
    \ real-\ntime tracking; it allows users to submit customized queries\nand returns\
    \ a geographical visualization with brand-spe-\nciﬁc commentary from Twitter,\
    \ as illustrated in Fig. 16.\n8 Social media analytics platforms\nHere, we examine\
    \ comprehensive social media platforms\nthat combine social media archives, data\
    \ feeds, data mining\nand data analysis tools. Simply put, the platforms are\n\
    AI & Soc (2015) 30:89–116\n107\n123\ndifferent from tools and toolkits since platforms\
    \ are more\ncomprehensive and provide both tools and data.\nThey broadly subdivide\
    \ into:\n•\nNews platforms—platforms such as Thomson Reuters\nproviding news archives/feeds\
    \ and associated analytics\nand targeting companies such as ﬁnancial institutions\n\
    seeking to monitor market sentiment in news.\n•\nSocial network media platforms—platforms\
    \ that\nprovide data mining and analytics on Twitter, Facebook\nand a wide range\
    \ of other social network media\nsources. Providers typically target companies\
    \ seeking\nto monitor sentiment around their brands or products.\n8.1 News platforms\n\
    The two most prominent business news feed providers are\nThomson Reuters and Bloomberg.\n\
    Computer read news in real time and provide automati-\ncally key indicators and\
    \ meaningful insights. The news items\nare automatically retrieved, analyzed and\
    \ interpreted in a few\nmilliseconds. The machine-readable news indicators can\n\
    potentially improve quantitative strategies, risk management\nand decision making.\n\
    Examples of machine-readable news include: Thomson\nReuters Machine Readable News,\
    \ Bloomberg’s Event-\nDriven Trading Feed and AlphaFlash (Deutsche Bo¨rse’s\n\
    machine-readable news feed). Thomson Reuters Machine\nReadable News (Thomson Reuters\
    \ 2012a, b, c) has Reuters\nNews content dating back to 1987, and comprehensive\n\
    news from over 50 third-parties dating back to 2003, such\nas PR Newswire, Business\
    \ Wire and the Regulatory News\nService (LSE). The feed offers full text and comprehensive\n\
    metadata via streaming XML.\nThomson Reuters News Analytics uses Natural Lan-\n\
    guage Processing (NLP) techniques to score news items on\ntens of thousands of\
    \ companies and nearly 40 commodities\nand energy topics. Items are measured across\
    \ the following\ndimensions:\n•\nAuthor sentiment—metrics for how positive, negative\n\
    or neutral the tone of the item is, speciﬁc to each\ncompany in the article.\n\
    •\nRelevance—how relevant or substantive the story is for\na particular item.\n\
    Fig. 15 Graphical Reports with Sentiment Insights\n108\nAI & Soc (2015) 30:89–116\n\
    123\n•\nVolume analysis—how much news is happening on a\nparticular company.\n\
    •\nUniqueness—how new or repetitive the item is over\nvarious time periods.\n\
    •\nHeadline analysis—denotes special features such as\nbroker actions, pricing\
    \ commentary, interviews, exclu-\nsives and wrap-ups.\n8.2 Social network media\
    \ platforms\nAttensity, Brandwatch, Salesforce Marketing Cloud (pre-\nviously\
    \ called Radian6) and Sysomos MAP (Media Ana-\nlysis Platform) are examples of\
    \ social media monitoring\nplatforms, which measure demographics, inﬂuential topics\n\
    and sentiments. They include text analytics and sentiment\nanalysis on online\
    \ consumer conversations and provide\nuser-friendly interfaces for customizing\
    \ the search query,\ndashboards, reports and ﬁle export features (e.g., to Excel\
    \ or\nCSV format). Most of the platforms scrape a range of social\nnetwork media\
    \ using a distributed crawler that targets:\nmicro-blogging (Twitter via full\
    \ Twitter Firehose), blogs\n(Blogger, WordPress, etc.), social networks (Facebook\
    \ and\nMySpace), forums, news sites, images sites (Flickr) and\ncorporate sites.\
    \ Some of the platforms provide multi-lan-\nguage support for widely used languages\
    \ (e.g., English,\nFrench, German, Italian and Spanish).\nSentiment analysis platforms\
    \ use two main methodolo-\ngies. One involves a statistical or model-based approach\n\
    wherein the system learns to assess sentiment by analyzing\nlarge quantities of\
    \ pre-scored material. The other method\nutilizes a large dictionary of pre-scored\
    \ phrases.\nRapidMiner5 is a platform which combines data mining\nand data analysis,\
    \ which, depending on the requirements,\ncan be open source. It uses the WEKA\
    \ machine learning\nlibrary and provides access to data sources such as Excel,\n\
    Access, Oracle, IBM, MySQL, PostgreSQL and Text ﬁles.\nMozenda provides a point-and-click\
    \ user interface for\nextracting speciﬁc information from the Web sites and\n\
    allows automation and data export to CSV, TSV or XML\nﬁles.\nDataSift provides\
    \ access to both real-time and historical\nsocial data from the leading social\
    \ networks and millions of\nFig. 16 SAS Visualization of Real-Time Tracking via\
    \ Twitter\n5 http://rapid-i.com/.\nAI & Soc (2015) 30:89–116\n109\n123\nother\
    \ sources, enabling clients to aggregate, ﬁlter and gain\ninsights and discover\
    \ trends from the billions of public\nsocial conversations. Once the data is aggregated\
    \ and\nprocessed (i.e., DataSift can ﬁlter and add context, such as\nenrichments—language\
    \ processing, geodata and demo-\ngraphics—and\ncategorization—spam\ndetection,\n\
    intent\nidentiﬁcation and machine learning), the customers can use\npre-built\
    \ integrations with popular BI tools, application and\ndeveloper tools to deliver\
    \ the data into their businesses, or\nuse the DataSift APIs to stream real-time\
    \ data into their\napplications.\nThere are a growing number of social media analytics\n\
    platforms being founded nowadays. Other notable plat-\nforms that handle sentiment\
    \ and semantic analysis of Web\nand Web 2.0-sourced material include Google Analytics,\n\
    HP Autonomy IDOL (Intelligent Data Operating Layer),\nIBM SPSS Modeler, Adobe\
    \ SocialAnalytics, GraphDive,\nKeen IO, Mass Relevance, Parse.ly, ViralHeat, Social-\n\
    bakers,\nDachisGroup,\nevolve24,\nOpenAmplify\nand\nAdmantX.\nRecently, more and\
    \ more speciﬁc social analytics plat-\nforms have emerged. One of them is iSpot.tv\
    \ which laun-\nched its own social media analytics platform that matches\ntelevision\
    \ ads with mentions on Twitter and Facebook. It\nprovides real-time reports about\
    \ when and where an ad\nappears, together with what people are saying about it\
    \ on\nsocial networks (iSpot.tv monitors almost 80 different\nnetworks).\nThomson\
    \ Reuters has recently announced that it is now\nincorporating Twitter sentiment\
    \ analysis for the Thomson\nReuters Eikon market analysis and trading platform,\
    \ pro-\nviding visualizations and charts based on the sentiment\ndata. In the\
    \ previous year, Bloomberg incorporated tweets\nrelated to speciﬁc companies in\
    \ a wider data stream.\n8.3 Case study: Thomson Reuters News Analytics\nThomson\
    \ Reuters News Analytics (TRNA) provides a huge\nnews archive with analytics to\
    \ read and interpret news,\noffering meaningful insights. TRNA scores news items\
    \ on\nover 25,000 equities and nearly 40 topics (commodities and\nenergy). The\
    \ platform scrapes and analyzes news data in\nreal time and feeds the data into\
    \ other programs/projects or\nquantitative strategies.\nTRNA uses an NLP system\
    \ from Lexalytics, one of the\nlinguistics technology leaders, that can track\
    \ news senti-\nment over time, and scores text across the various dimen-\nsions\
    \ as mentioned in Sect. 8.1.\nThe platform’s text scoring and metadata has more\
    \ than\n80 ﬁelds (Thomson Reuters 2010) such as:\n•\nItem type—stage of the story:\
    \ Alert, Article, Updates\nor Corrections.\n•\nItem genre—classiﬁcation of the\
    \ story, i.e., interview,\nexclusive and wrap-up.\n•\nHeadline—alert or headline\
    \ text.\n•\nRelevance—varies from 0 to 1.0.\n•\nPrevailing sentiment—can be 1,\
    \ 0 or -1.\n•\nPositive, neutral, negative—more detailed sentiment\nindication.\n\
    •\nBroker\naction—denotes\nbroker\nactions:\nupgrade,\ndowngrade, maintain, undeﬁned\
    \ or whether it is the\nbroker itself\n•\nPrice/market\ncommentary—used\nto\n\
    ﬂag\nitems\ndescribing pricing/market commentary\n•\nTopic codes—describes what\
    \ the story is about, i.e.,\nRCH = Research,\nRES = Results,\nRESF = Results\n\
    Forecast, MRG = Mergers and Acquisitions\nA snippet of the news sentiment analysis\
    \ is illustrated in\nFig. 17.\nIn 2012, Thomson Reuters extended its machine-read-\n\
    able news offering to include sentiment analysis and\nscoring for social media.\
    \ TRNA’s extension is called\nThomson Reuters News Analytics (TRNA) for Internet\n\
    News and Social Media, which aggregates content from\nover four million social\
    \ media channels and 50,000 Internet\nnews sites. The content is then analyzed\
    \ by TRNA in real\ntime, generating a quantiﬁable output across dimensions\nsuch\
    \ as sentiment, relevance, novelty volume, category and\nsource ranks. This extension\
    \ uses the same extensive\nmetadata tagging (across more than 80 ﬁelds).\nTRNA\
    \ for Internet News and Social Media is a powerful\nplatform analyzing, tagging\
    \ and ﬁltering millions of public\nand premium sources of Internet content, turning\
    \ big data\ninto actionable ideas. The platform also provides a way to\nvisually\
    \ analyze the big data. It can be combined with\nPanopticon Data Visualization\
    \ Software in order to reach\nmeaningful conclusions more quickly with visually\
    \ intui-\ntive displays (Thomson Reuters 2012a, b, c), as illustrated\nin Fig.\
    \ 18.\nThomson Reuters also expanded the News Analytics\nservice with MarketPsych\
    \ Indices (Thomson Reuters\n2012a, b, c), which allows for real-time psychological\n\
    analysis of news and social media. The Thomson Reuters\nMarketPsych Indices (TRMI)\
    \ service gains a quantitative\nview of market psychology as it attempts to identify\
    \ human\nemotion and sentiment. It is a complement to TRNA and\nuses NLP processing\
    \ created by MarketPsych (http://www.\nmarketpsych.com), a leading company in\
    \ behavioral psy-\nchology in ﬁnancial markets.\nBehavioral economists have extensively\
    \ investigated\nwhether emotions affect markets in predictable ways, and\nTRMI\
    \ attempts to measure the state of ‘emotions’ in real\ntime in order to identify\
    \ patterns as they emerge. TRMI has\ntwo key indicator types:\n110\nAI & Soc (2015)\
    \ 30:89–116\n123\n•\nEmotional indicators (sentiments)—emotions such as\nGloom,\
    \ Fear, Trust, Uncertainty, Innovation, Anger,\nStress, Urgency, Optimism and\
    \ Joy.\n•\nBuzz metrics—they indicate how much something is\nbeing discussed in\
    \ the news and social media and\ninclude\nmacroeconomic\nthemes\n(e.g.,\nLitigation,\n\
    Fig. 17 Thomson Reuters News Discovery Application with Sentiment Analysis\nFig.\
    \ 18 Combining TRNA for Internet News and Social Media with Panopticon Data Visualization\
    \ Software\nAI & Soc (2015) 30:89–116\n111\n123\nMergers, Volatility, Financials\
    \ sector, Airlines sector\nand Clean Technology sector)\nThe\nplatform\nfrom\n\
    Thomson\nReuters\nallows\nthe\nexploitation of news and social media to be used\
    \ to spot\nopportunities\nand\ncapitalize\non\nmarket\ninefﬁciencies\n(Thomson\
    \ Reuters 2013).\n9 Experimental computational environment for social\nmedia\n\
    As we have discussed in Sect. 2 methodology and critique,\nresearchers arguably\
    \ require a comprehensive experimental\ncomputational\nenvironment/facility\n\
    for\nsocial\nmedia\nresearch with the following attributes:\n9.1 Data\n•\nData\
    \ scraping—the ability through easily program-\nmable APIs to scrape any type\
    \ of social media (social\nnetworking media, RSS feeds, blogs, wikis, news, etc.).\n\
    •\nData streaming—to access and combine real-time\nfeeds and archived data for\
    \ analytics.\n•\nData storage—a major facility for storing principal\ndata sources\
    \ and for archiving data collected for\nspeciﬁc projects.\n•\nData protection/security—the\
    \ stored data needs to be\nprotected to stop users attempting to ‘suck it out’\
    \ off the\nfacility. Access to certain data sets may need to be\nrestricted and\
    \ charges may be levied on access (cf.\nWharton Research Data Services).\n•\n\
    Programmable interfaces—researchers need access to\nsimple application programming\
    \ interfaces (APIs) to\nscrape and store other available data sources that may\n\
    not be automatically collected.\n9.2 Analytics\n•\nAnalytics dashboards—non-programming\
    \ interfaces\nare required for giving what might be referred to as\n‘deep’ access\
    \ to ‘raw’ data.\n•\nProgrammable\nanalytics—programming\ninterfaces\nare also\
    \ required so users can deploy advanced data\nmining and computer simulation models\
    \ using MAT-\nLAB, Java and Python.\n•\nStream processing—facilities are required\
    \ to support\nanalytics on streamed real-time data feeds, such as\nTwitter feeds,\
    \ news feeds and ﬁnancial tick data.\n•\nHigh-performance computing—lastly the\
    \ environ-\nment needs to support non-programming interfaces to\nMapReduce/Hadoop,\
    \ NoSQL databases and Grids of\nprocessors.\n•\nDecentralized analytics—if researchers\
    \ are to com-\nbine social media data with highly sensitive/valuable\nproprietary\
    \ data held by governments, ﬁnancial insti-\ntutions, retailers and other commercial\
    \ organizations,\nthen the environment needs in the future to support\ndecentralized\
    \ analytics across distributed data sources\nand in a highly secure way.\nRealistically,\
    \ this is best facilitated at a national or inter-\nnational level.\nTo provide\
    \ some insight into the structure of an exper-\nimental\ncomputational\nenvironment\n\
    for\nsocial\nmedia\n(analytics), below we present the system architecture of the\n\
    UCL SocialSTORM analytics platform developed by Dr.\nMichal Galas and his colleagues\
    \ (Galas et al. 2012) to\nUniversity College London (UCL).\nUniversity College\
    \ London’s social media streaming,\nstorage and analytics platform (SocialSTORM)\
    \ is a cloud-\nbased ‘central hub’ platform, which facilitates the acqui-\nsition\
    \ of text-based data from online sources such as\nTwitter, Facebook, RSS media\
    \ and news. The system\nincludes facilities to upload and run Java-coded simulation\n\
    models to analyze the aggregated data, which may com-\nprise scraped social data\
    \ and/or users’ own proprietary\ndata.\n9.3 System architecture\nFigure 19 shows\
    \ the architecture of the SocialSTORM\nplatform, and the following section outlines\
    \ the key com-\nponents of the overall system. The basic idea is that each\nexternal\
    \ feed has a dedicated connectivity engine (API) and\nthis streams data to the\
    \ message bus, which handles\ninternal communication, analytics and storage.\n\
    •\nConnectivity engines—the connectivity modules com-\nmunicate with the external\
    \ data sources, including\nTwitter and Facebook’s APIs, ﬁnancial blogs, various\n\
    RSS and news feeds. The platform’s APIs are contin-\nually being expanded to incorporate\
    \ other social media\nsources as required. Data is fed into SocialSTORM in\nreal\
    \ time, including a random sample of all public\nupdates from Twitter, providing\
    \ gigabytes of text-based\ndata every day.\n•\nMessaging bus—the message bus serves\
    \ as the internal\ncommunication layer which accepts the incoming data\nstreams\
    \ (messages) from the various connectivity\nengines, parses these (from either\
    \ JSON or XML\nformat) to an internal representation of data in the\nplatform,\
    \ distributes the information across all the\ninterested modules and writes the\
    \ various data to the\nappropriate tables of the main database.\n•\nData warehouse—the\
    \ database supports terabytes of\ntext-based entries, which are accompanied by\
    \ various\n112\nAI & Soc (2015) 30:89–116\n123\ntypes of metadata to expand the\
    \ potential avenues of\nresearch. Entries are organized by source and accu-\n\
    rately time-stamped with the time of publication, as\nwell as being tagged with\
    \ topics for easy retrieval by\nsimulation models. The platform currently uses\
    \ HBase,\nbut in future might use Apache Cassandra or Hive.\n•\nSimulation manager—the\
    \ simulation manager provides\nan external API for clients to interact with the\
    \ data for\nresearch purposes, including a web-based GUI whereby\nusers can select\
    \ various ﬁlters to apply to the data sets\nbefore uploading a Java-coded simulation\
    \ model to\nperform the desired analysis on the data. This facilitates\nall client-access\
    \ to the data warehouse and also allows\nusers to upload their own data sets for\
    \ aggregation with\nUCL’s social data for a particular simulation. There is also\n\
    the option to switch between historical mode (which\nmines data existing at the\
    \ time the simulation is started)\nand live mode (which ‘listens’ to incoming\
    \ data streams\nand performs analysis in real time).\n9.4 Platform components\n\
    The platform comprises the following modules, which are\nillustrated in Fig. 20:\n\
    •\nBack-end services—this provides the core of the\nplatform functionalities.\
    \ It is a set of services that\nallow connections to data providers, propagation\
    \ pro-\ncessing and aggregation of data feeds, execution and\nmaintenance of models,\
    \ as well as their management in\na multiuser environment.\n•\nFront-end client\
    \ APIs—this provides a set of program-\nmatic and graphical interfaces that can\
    \ be used to interact\nwith a platform to implement and test analytical models.\n\
    The programmatic access provides model templates to\nsimplify access to some of\
    \ the functionalities and deﬁnes\ngeneric structure of every model in the platform.\
    \ The\ngraphic user interface allows visual management of\nanalytical models.\
    \ It enables the user to visualize data in\nvarious forms, provides data watch\
    \ grid capabilities,\nprovides a dynamic visualization of group behavior of\n\
    data and allows users to observe information on events\nrelevant to the user’s\
    \ environment.\n•\nConnectivity engine—this functionality provides a\nmeans of\
    \ communication with the outside world, with\nﬁnancial brokers, data providers\
    \ and others. Each of the\noutside venues utilized by the platform has a dedicated\n\
    connector object responsible for control of communi-\ncation. This is possible\
    \ due to the fact that each of the\noutside institutions provide either a dedicated\
    \ API or is\nusing a communication protocol (e.g., the FIX protocol\nand the JSON/XML-based\
    \ protocol). The platform\nprovides a generalized interface to allow standardiza-\n\
    tion of a variety of connectors.\n•\nInternal communication layer—the idea behind\
    \ the\nuse of the internal messaging system in the platform\ndraws from the concept\
    \ of event-driven programming.\nAnalytical platforms utilize events as a main\
    \ means of\ncommunication between their elements. The elements,\nin turn, are\
    \ either producers or consumers of the events.\nThe approach signiﬁcantly simpliﬁes\
    \ the architecture of\nsuch system while making it scalable and ﬂexible for\n\
    further extensions.\n•\nAggregation database—this provides a fast and robust\n\
    DBMS functionality, for an entry-level aggregation of\ndata, which is then ﬁltered,\
    \ enriched, restructured and\nFig. 19 SocialSTORM Platform Architecture\nAI &\
    \ Soc (2015) 30:89–116\n113\n123\nstored in big data facilities. Aggregation facilities\n\
    enable\nanalytical\nplatforms\nto\nstore,\nextract\nand\nmanipulate large amounts\
    \ of data. The storage capa-\nbilities of the Aggregation element not only allow\n\
    replay of historical data for modeling purposes, but also\nenable other, more\
    \ sophisticated tasks related to\nfunctioning of the platform including model\
    \ risk\nanalysis, evaluation of performance of models and\nmany more.\n•\nClient\
    \ SDK—this is a complete set of APIs (Applica-\ntion Programming Interfaces) that\
    \ enable development,\nimplementation and testing of new analytical models\nwith\
    \ use of the developer’s favorite IDE (Integrated\nDevelopment Environment). The\
    \ SDK allows connec-\ntion from the IDE to the server side of the platform to\n\
    provide all the functionalities the user may need to\ndevelop and execute models.\n\
    •\nShared memory—this provides a buffer-type func-\ntionality that speeds up the\
    \ delivery of temporal/\nhistorical data to models and the analytics-related\n\
    elements of the platform (i.e., the statistical analysis\nlibrary of methods),\
    \ and, at the same time, reduces the\nmemory usage requirement. The main idea\
    \ is to have a\ncentral point in the memory (RAM) of the platform that\nwill manage\
    \ and provide a temporal/historical data\nfrom the current point of time up to\
    \ a speciﬁed number\nof timestamps back in history). Since the memory is\nshared,\
    \ no model will have to keep and manage history\nby itself. Moreover, since the\
    \ memory is kept in RAM\nrather than in the ﬁles or the DBMS, the access to it\
    \ is\ninstant and bounded only by the performance of\nhardware and the platform\
    \ on which the buffers work.\n•\nModel templates—the platform supports two generic\n\
    types of models: push and pull. The push type registers\nitself to listen to a\
    \ speciﬁed set of data streams during\ninitialization, and the execution of the\
    \ model logic is\ntriggered each time a new data feed arrives to the\nplatform.\
    \ This type is dedicated to very quick, low-\nlatency, high-frequency models and\
    \ the speed is\nachieved at the cost of small shared memory buffers.\nThe pull\
    \ model template executes and requests data on\nits own, based on a schedule.\
    \ Instead of using the\nmemory buffers, it has a direct connection to the big\n\
    data facilities and hence can request as much historical\ndata as necessary, at\
    \ the expense of speed.\n10 Conclusions\nAs discussed, the easy availability of\
    \ APIs provided by\nTwitter, Facebook and News services has led to an\nFig. 20\
    \ Environment System Architecture and Modules\n114\nAI & Soc (2015) 30:89–116\n\
    123\n‘explosion’ of data services and software tools for scraping\nand sentiment\
    \ analysis, and social media analytics plat-\nforms. This paper surveys some of\
    \ the social media soft-\nware tools, and for completeness introduced social media\n\
    scraping, data cleaning and sentiment analysis.\nPerhaps, the biggest concern\
    \ is that companies are\nincreasingly restricting access to their data to monetize\n\
    their content. It is important that researchers have access to\ncomputational\
    \ environments and especially ‘big’ social\nmedia data for experimentation. Otherwise,\
    \ computational\nsocial science could become the exclusive domain of major\ncompanies,\
    \ government agencies and a privileged set of\nacademic researchers presiding\
    \ over private data from\nwhich they produce papers that cannot be critiqued or\n\
    replicated. Arguably what is required are public-domain\ncomputational environments\
    \ and data facilities for quanti-\ntative social science, which can be accessed\
    \ by researchers\nvia a cloud-based facility.\nAcknowledgments\nThe authors would\
    \ like to acknowledge Michal\nGalas who led the design and implementation of the\
    \ UCL Social-\nSTORM platform with the assistance of Ilya Zheludev, Kacper\nChwialkowski\
    \ and Dan Brown. Dr. Christian Hesse of Deutsche Bank\nis also acknowledged for\
    \ collaboration on News Analytics.\nOpen Access\nThis article is distributed under\
    \ the terms of the\nCreative Commons Attribution License which permits any use,\
    \ dis-\ntribution, and reproduction in any medium, provided the original\nauthor(s)\
    \ and the source are credited.\nReferences\nBotan I et al. (2010) SECRET: a model\
    \ for analysis of the execution\nsemantics of stream processing systems. Proc\
    \ VLDB Endow\n3(1–2):232–243\nSalathe´ M et al. (2012) Digital epidemiology. PLoS\
    \ Comput Biol\n8(7):1–5\nBollen J, Mao H, Zeng X (2011) Twitter mood predicts\
    \ the stock\nmarket. J Comput Sci 2(3):1–8\nChandramouli B et al (2010) Data stream\
    \ management systems for\ncomputational ﬁnance. IEEE Comput 43(12):45–52\nChandrasekar\
    \ C, Kowsalya N (2011) Implementation of MapReduce\nAlgorithm and Nutch Distributed\
    \ File System in Nutch. Int J\nComput Appl 1:6–11\nCiofﬁ-Revilla C (2010) Computational\
    \ social science. Wiley Inter-\ndiscip Rev Comput Statistics 2(3):259–271\nGalas\
    \ M, Brown D, Treleaven P (2012) A computational social\nscience environment for\
    \ ﬁnancial/economic experiments. In:\nProceedings of the Computational Social\
    \ Science Society of the\nAmericas, vol 1, pp 1–13\nHebrail G (2008) Data stream\
    \ management and mining. In: Fogel-\nman-Soulie´ F, Perrotta D, Piskorski J, Steinberger\
    \ R (eds)\nMining Massive Data Sets for Security. IOS Press, pp 89–102\nHirudkar\
    \ AM, Sherekar SS (2013) Comparative analysis of data\nmining tools and techniques\
    \ for evaluating performance of\ndatabase system. Int J Comput Sci Appl 6(2):232–237\n\
    Kaplan AM (2012) If you love something, let it go mobile: mobile\nmarketing\n\
    and\nmobile\nsocial\nmedia\n4x4.\nBus\nHoriz\n55(2):129–139\nKaplan AM, Haenlein\
    \ M (2010) Users of the world, unite! the\nchallenges and opportunities of social\
    \ media. Bus Horiz\n53(1):59–68\nKarabulut Y (2013) Can Facebook predict stock\
    \ market activity?\nSSRN eLibrary, pp 1–58. http://ssrn.com/abstract=2017099 or\n\
    http://dx.doi.org/10.2139/ssrn.2017099. Accessed 2 Feb 2014\nKhan A, Baharudin\
    \ B, Lee LH, Khan K (2010) A review of machine\nlearning algorithms for text-documents\
    \ classiﬁcation. J Adv Inf\nTechnol 1(1):4–20\nKobayashi M, Takeda K (2000) Information\
    \ retrieval on the web.\nACM Comput Surv CSUR 32(2):144–173\nLazer D et al (2009)\
    \ Computational social science. Science\n323:721–723\nLerman K, Gilder A, Dredze\
    \ M, Pereira F (2008) Reading the\nmarkets: forecasting public opinion of political\
    \ candidates by\nnews analysis. In: Proceedings of the 22nd international\nconference\
    \ on computational linguistics 1:473–480\nMapReduce (2011) What is MapReduce?.\
    \ http://www.mapreduce.\norg/what-is-mapreduce.php. Accessed 31 Jan 2014\nMejova\
    \ Y (2009) Sentiment analysis: an overview, pp 1–34. http://\nwww.academia.edu/291678/Sentiment_Analysis_An_Overview.\n\
    Accessed 4 Nov 2013\nMurphy KP (2006) Naive Bayes classiﬁers. University of British\n\
    Columbia, pp 1–8. http://www.ic.unicamp.br/*rocha/teaching/\n2011s1/mc906/aulas/naivebayes.pdf\n\
    Murphy KP (2012) Machine learning: a probabilistic perspective. In:\nChapter 1:\
    \ Introduction. MIT Press, pp 1–26\nNarang RK (2009) Inside the black box. Hoboken,\
    \ New Jersey\nNuti G, Mirghaemi M, Treleaven P, Yingsaeree C (2011) Algorithmic\n\
    trading. IEEE Comput 44(11):61–69\nPang B, Lee L (2008) Opinion mining and sentiment\
    \ analysis. Found\nTrends Inf Retr 2(1–2):1–135\nSAS Institute Inc (2013) SAS\
    \ sentiment analysis factsheet. http://www.\nsas.com/resources/factsheet/sas-sentiment-analysis-factsheet.pdf.\n\
    Accessed 6 Dec 2013\nTeuﬂ P, Payer U, Lackner G (2010) From NLP (natural language\n\
    processing) to MLP (machine language processing). In: Kotenko\nI, Skormin V (eds)\
    \ Computer network security, Springer, Berlin\nHeidelberg, pp 256–269\nThomson\
    \ Reuters (2010). Thomson Reuters news analytics. http://\nthomsonreuters.com/products/ﬁnancial-risk/01_255/News_Analy\n\
    tics_-_Product_Brochure-_Oct_2010_1_.pdf. Accessed 1 Oct\n2013\nThomson Reuters\
    \ (2012) Thomson Reuters machine readable news.\nhttp://thomsonreuters.com/products/ﬁnancial-risk/01_255/TR_\n\
    MRN_Overview_10Jan2012.pdf. Accessed 5 Dec 2013\nThomson Reuters (2012) Thomson\
    \ Reuters MarketPsych Indices.\nhttp://thomsonreuters.com/products/ﬁnancial-risk/01_255/TRMI_\n\
    ﬂyer_2012.pdf. Accessed 7 Dec 2013\nThomson Reuters (2012) Thomson Reuters news\
    \ analytics for internet\nnews and social media. http://thomsonreuters.com/business-unit/\n\
    ﬁnancial/eurozone/112408/news_analytics_and_social_media.\nAccessed 7 Dec 2013\n\
    Thomson Reuters (2013) Machine readable news. http://thomsonreuters.\ncom/machine-readable-news/?subsector=thomson-reuters-elektron.\n\
    Accessed 18 Dec 2013\nTurney PD (2002) Thumbs up or thumbs down? Semantic orientation\n\
    applied to unsupervised classiﬁcation of reviews. In: Proceed-\nings of the 40th\
    \ Annual Meeting on Association for Computa-\ntional Linguistics pp. 417–424\n\
    Vaswani V (2011) Hook into Wikipedia information using PHP and\nthe MediaWiki\
    \ API. http://www.ibm.com/developerworks/web/\nlibrary/x-phpwikipedia/index.html.\
    \ Accessed 21 Dec 2012\nWesterski A (2008) Sentiment analysis: introduction and\
    \ the state\nof the art overview. Universidad Politecnica de Madrid,\nSpain, pp\
    \ 1–9. http://www.adamwesterski.com/wpcontent/ﬁles/\nAI & Soc (2015) 30:89–116\n\
    115\n123\ndocsCursos/sentimentA_doc_TLAW.pdf.\nAccessed\n14\nAug\n2013\nWikimedia\
    \ Foundation (2014) Wikipedia:Database download. http://\nen.wikipedia.org/wiki/Wikipedia:Database_download.\
    \ Accessed\n18 Apr 2014\nWolfram SMA (2010) Modelling the stock market using Twitter.\n\
    Dissertation Master of Science thesis, School of Informatics,\nUniversity of Edinburgh,\
    \ pp 1–74. http://homepages.inf.ed.ac.\nuk/miles/msc-projects/wolfram.pdf. Accessed\
    \ 23 Jul 2013\nYessenov K, Misailovic S (2009) Sentiment analysis of movie review\n\
    comments, pp 1–17. http://people.csail.mit.edu/kuat/courses/6.\n863/report.pdf.\
    \ Accessed 16 Aug 2013\n116\nAI & Soc (2015) 30:89–116\n123\n"
  inline_citation: '>'
  journal: AI & SOCIETY
  limitations: '>'
  pdf_link: https://link.springer.com/content/pdf/10.1007/s00146-014-0549-4.pdf
  publication_year: 2014
  relevance_score1: 0
  relevance_score2: 0
  title: 'Social media analytics: a survey of techniques, tools and platforms'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/access.2020.2970143
  analysis: '>'
  authors:
  - Adil Rasheed
  - Omer San
  - Trond Kvamsdal
  citation_count: 739
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Subscribe Donate Cart Create Account
    Personal Sign In Personal Sign In * Required *Email Address *Password Forgot Password?
    Sign In Don''t have a Personal Account? Create an IEEE Account now. Create Account
    Learn more about personalization features. IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/8948470/08972429.pdf
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: 'Digital Twin: Values, Challenges and Enablers From a Modeling Perspective'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/mcom.001.1900103
  analysis: '>'
  authors:
  - Guangxu Zhu
  - Dongzhu Liu
  - Youwei Du
  - Changsheng You
  - Jun Zhang
  - Kaibin Huang
  citation_count: 404
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Subscribe Donate Cart Create Account
    Personal Sign In Browse My Settings Help Institutional Sign In All Books Conferences
    Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals
    & Magazines >IEEE Communications Magazine >Volume: 58 Issue: 1 Toward an Intelligent
    Edge: Wireless Communication Meets Machine Learning Publisher: IEEE Cite This
    PDF Guangxu Zhu; Dongzhu Liu; Yuqing Du; Changsheng You; Jun Zhang; Kaibin Huang
    All Authors 347 Cites in Papers 11306 Full Text Views Abstract Document Sections
    Introduction Learning-Driven Multiple Access Learning-Driven Radio Resource Management
    Learning-Driven Signal Encoding Concluding Remarks Authors Figures References
    Citations Keywords Metrics Abstract: The recent revival of AI is revolutionizing
    almost every branch of science and technology. Given the ubiquitous smart mobile
    gadgets and IoT devices, it is expected that a majority of intelligent applications
    will be deployed at the edge of wireless networks. This trend has generated strong
    interest in realizing an "intelligent edge" to support AI-enabled applications
    at various edge devices. Accordingly, a new research area, called edge learning,
    has emerged, which crosses and revolutionizes two disciplines: wireless communication
    and machine learning. A major theme in edge learning is to overcome the limited
    computing power, as well as limited data, at each edge device. This is accomplished
    by leveraging the mobile edge computing platform and exploiting the massive data
    distributed over a large number of edge devices. In such systems, learning from
    distributed data and communicating between the edge server and devices are two
    critical and coupled aspects, and their fusion poses many new research challenges.
    This article advocates a new set of design guidelines for wireless communication
    in edge learning, collectively called learning- driven communication. Illustrative
    examples are provided to demonstrate the effectiveness of these design guidelines.
    Unique research opportunities are identified. Published in: IEEE Communications
    Magazine ( Volume: 58, Issue: 1, January 2020) Page(s): 19 - 25 Date of Publication:
    27 January 2020 ISSN Information: DOI: 10.1109/MCOM.001.1900103 Publisher: IEEE
    Introduction We are witnessing phenomenal growth in global data traffic, accelerated
    by the increasing popularity of edge devices. According to the International Data
    Corporation, there will be 80 billion devices connected to the Internet by 2025,
    and the global data will reach 163 zettabytes, which is 10 times the data generated
    in 2016 [1]. The unprecedented amount of data, together with the recent breakthroughs
    in artificial intelligence (AI), inspire people to envision ubiquitous computing
    and ambient intelligence, which will not only improve our quality of life but
    also provide a platform for scientific discoveries and engineering innovations.
    In particular, this vision is driving industry and academia to vehemently invest
    in technologies for creating an intelligent (network) edge, which supports emerging
    application scenarios including smart city, eHealth, eBanking, intelligent transportation,
    and so on. This has led to the emergence of a new research area, called edge learning,
    which refers to the deployment of machine learning algorithms (including supervised,
    unsupervised, and reinforcement learning) at the network edge [2], [3]. The key
    motivation of pushing learning toward the edge is to allow rapid access to the
    enormous real-time data generated by the edge devices for fast AI-model training,
    which in turn endows the devices with human-like intelligence to respond to real-time
    events. Sign in to Continue Reading Authors Figures References Citations Keywords
    Metrics More Like This Quantum machine learning-using quantum computation in artificial
    intelligence and deep neural networks: Quantum computation and machine learning
    in artificial intelligence 2017 8th Annual Industrial Automation and Electromechanical
    Engineering Conference (IEMECON) Published: 2017 Edge Cloud Server Deployment
    With Transmission Power Control Through Machine Learning for 6G Internet of Things
    IEEE Transactions on Emerging Topics in Computing Published: 2021 Show More IEEE
    Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW
    PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE communications magazine (Print)
  limitations: '>'
  pdf_link: null
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: 'Toward an Intelligent Edge: Wireless Communication Meets Machine Learning'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.engappai.2023.107156
  analysis: '>'
  authors:
  - R. Priyadarshini
  - Abdul Quadir
  - Senthilkumar Mohan
  - Abdullah Alghamdi
  - Mesfer Alrizq
  - Ummul Hanan Mohamad
  - Ali Ahmadian
  citation_count: 1
  full_citation: '>'
  full_text: '>

    Loading [MathJax]/jax/output/SVG/jax.js Skip to main content Skip to article Journals
    & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln
    View PDF Download full issue Outline Abstract Keywords 1. Introduction 2. Literature
    review 3. Proposed Secured Framework for Prediction of the critical status of
    Covid-19 patients 4. Experimental results 5. Statistical analysis for the proposed
    framework 6. Conclusion and future work Declaration of competing interest Acknowledgement
    Data availability References Show full outline Cited by (1) Figures (18) Show
    12 more figures Tables (8) Table 1 Table 2 Table 3 Table 4 Table 5 Table 6 Show
    all tables Engineering Applications of Artificial Intelligence Volume 126, Part
    D, November 2023, 107156 Novel framework based on ensemble classification and
    secure feature extraction for COVID-19 critical health prediction Author links
    open overlay panel R. Priyadarshini a, Abdul Quadir Md a, Senthilkumar Mohan b,
    Abdullah Alghamdi c, Mesfer Alrizq c, Ummul Hanan Mohamad d, Ali Ahmadian e f
    Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.engappai.2023.107156
    Get rights and content Abstract The Covid outbreak necessitated the use of an
    automated method for treating patients with critical symptoms. Increasing use
    of the Internet of Things (IoT) and smart devices requires access to real-time
    data over robust and secure network infrastructures. During the lifetime of healthcare
    applications, the data must be transferred in a controlled manner. In this context,
    this study proposes, an IoT-based decision support system for the analysis of
    Covid-related data in healthcare systems. Through in-vehicle monitoring, it is
    intended to safely send important data and patient updates to attending physicians.
    The suggested approach uses feature extraction methods to identify patients''
    crucial states while protecting their private information. To improve feature
    extraction, two techniques are combined: ensemble classification and cipher substitution
    for secure Json Web Tokens (JWTs). By incorporating the Secure Hashing Algorithm-2
    (SHA-2) methods into the Feature Extraction based Logistic Regression (FELR),
    security protections are substantially reinforced. The system uses the Message
    Queuing Telemetry Transport (MQTT) protocol to provide secure communication between
    devices and access to the extracted characteristics from rescue vehicles. The
    system analyzes passengers, traffic data, and medical issues, which are continually
    updated with cloud-based security, by using vehicle-based communication networks.
    The secure movement of patient data inside the hospital network is ensured by
    this cloud-based system. By using sophisticated regression analysis and ensemble
    learning approaches, our suggested methodology has shown significant advantages
    compared to traditional models such as Logistic Regression (LR) and Mixed Regression
    (MR). Our technique demonstrates exceptional performance with an accuracy rate
    of 96%, a recall rate of 91%, and an F-measure of 91%. We also precisely compared
    the performance of our proposed FELR algorithm with hybrid prediction model using
    deep learning, the extra tree convolutional neural network-based ensemble model,
    ensemble-based random forest, ensemble transformation learning, and machine learning
    with regression. Significantly, FELR algorithm has demonstrated exceptional superiority
    by consistently surpassing the predictive capabilities of all these algorithms.
    The system has exceptional performance and exhibits improved efficiency and secure
    transmission capabilities. The unique model that we propose offers a feasible
    and effective approach for detecting crucial states in patients within healthcare
    facilities. The success of our framework is shown via a well-planned approach
    that includes important processes such as data preprocessing, feature extraction,
    ensemble model construction, and evaluation. The proposed framework offers a promising
    avenue for aiding healthcare professionals in making informed decisions regarding
    the critical health trajectories of COVID-19 patients. Previous article in issue
    Next article in issue Keywords Machine learning (ML)Covid dataJSON web tokens
    (JWT)SHA-2 algorithmLogistic regression 1. Introduction In emergency cases, communication
    is crucial for getting to the hospital of choice. It is also crucial for covid
    times and for enabling in-vehicle communication. When more patients require emergency
    care than there are doctors and medical staff, it becomes important to treat the
    patients according to their level of need. For critical circumstances, the first
    come, first served policy will not work. The availability of secure information
    for the doctor and ongoing patient status communication is necessary to start
    automated appointment booking (Raftarai et al., 2021). The in-vehicle communication
    to the appropriate medical personnel and staff as well as the predicted status
    of the patient''s past medical history is essential. A machine learning technique
    only displays the patient''s history, which will help a medical professional decide
    what to do next (Olaleye et al., 2022). Additionally, the availability of sensitive
    data to the public creates havoc in the sharing and misappropriation of data due
    to this type of approach. Furthermore, the IoT supports much one-way and long-range
    communication between mobile nodes, whether they be transport nodes or human nodes
    (Shaban et al., 2020). The long-range wide area networks are also suitable for
    drones and other mobile nodes during emergencies. (Shekar and Hailu, 2022). Wireless
    networks also require a high level of security of transmission to function effectively.
    An example of a long-distance network for updating emergency status can be seen
    in Fig. 1. Download : Download high-res image (283KB) Download : Download full-size
    image Fig. 1. Long Wide Area Network for updating the status of emergency. Since
    there are numerous business triggers and push messages that are delivered to patients
    and cause them to be misled by pharmaceutical marketing, the protection of sensitive
    information is crucial (Rahmani et al., 2022). Communities should protect their
    trademarks, intellectual property, and customer data in response to corporate
    claims that they share three things: people, processes, and technology. Around
    sixty-two million diabetic people have been identified as having the condition
    as of late, and the disease is quickly spreading to the point that an outbreak
    is likely in India. In 2000, India (31.7 million) led the world in the number
    of people with this illness, with China (about 20 million) and the United States
    (roughly 17.7 million) respectively. WHO predicts that the number of people with
    diabetes will double worldwide, from 171 billion in 2000 to 366 billion in 2030,
    with India experiencing the fastest growth (Menesgere et al., 2022). It currently
    faces an uncertain future in terms of the potential burden that diabetes mellitus
    may impose on the country. It is necessary to encourage adaptation at the time
    of health alerts due to the significant persuasion power, the prevalence of diseases
    across the nation, and other factors. The motivation of this work is to establish
    an innovative structure for COVID-19 critical health forecasting based on collaborative
    classification along with safe extraction of features stems from the pressing
    need to improve the precision, accuracy, and privacy of forecasts regarding the
    health conditions of individuals infected with the virus. The COVID-19 pandemic
    has emphasized the heterogeneity in patients'' responses as well as the challenges
    involved in identifying individuals at danger of rapidly deterioration. For example,
    many people with diabetes do not neatly fall into any one category, and the diagnostic
    process can be complicated by the fact that the type of diabetes an individual
    has is often dependent on their specific medical history at the time of diagnosis.
    For instance, a woman with GDM may be found to have type 2 diabetes after delivery
    if her hyperglycemia persists. It is also possible for a person who develops diabetes
    after being exposed to high levels of exogenous steroids to return to a normoglycemic
    state once the glucocorticoids are stopped, only to redevelop diabetes years later
    as a result of recurring bouts of pancreatitis (Panigutti et al., 2021). One further
    case in point is a patient on thiazides who subsequently develops diabetes. Since
    thiazides seldom produce significant hyperglycemia on their own, these patients
    likely already have type 2 diabetes that is being made worse by the medication
    (Gökalp et al., 2018). It is therefore more necessary for the doctor and patient
    to understand the pathophysiology of hyperglycemia and to treat it successfully
    than to name the specific kind of diabetes. Modern tools and technologies are
    developed using Artificial Intelligence (AI). Through rapid decision-making, enhanced
    image processing, and priority-based therapy, AI in healthcare is saving lives.
    AI algorithms can help the decision support system decrease variances in medical
    imaging and laboratory report analysis (Al-Karaki et al., 2019). AI technology
    simplifies screening and diagnosis. AI-based online tools collect and analyze
    patient data remotely, evaluate symptoms, and self-diagnose, reducing physician
    burnout and saving money and time. Due to advancements in AI, healthcare data
    extraction and the creation of illness prediction models to aid physicians in
    prediction or detection have become attractive research areas. The objective of
    this research paper is to evaluate the feasibility of employing machine learning
    (ML) approaches to address the existing knowledge gap in the scientific literature
    regarding COVID-19. The study aims to explore various perspectives, including
    data types, software tools, applied methodologies, medication, and vaccine research,
    all utilizing ML techniques in the context of COVID-19. The novelty of this research
    lies in its comprehensive examination of ML methods, which have the potential
    to significantly contribute to our understanding of the virus and facilitate the
    prediction of future pandemic-related challenges. Specifically, the paper discusses
    the application of Logistic Regression (LR) as an ML method for predicting COVID-19
    outcomes based on patient data, as well as the utilization of the Secure Hash
    (SHA) method to generate unique IDs to ensure data integrity and facilitate tracking.
    The paper addresses the requirement for reliable and confidentiality forecasts
    of COVID-19 patients'' critical medical conditions. The COVID-19 pandemic has
    highlighted the need of rapidly recognizing persons at risk of serious disease,
    allowing healthcare providers to properly deploy resources and deliver appropriate
    therapies. Existing models for forecasting, on the other hand, might be unable
    to incorporate the detailed and varied structure of patient data, resulting in
    unsatisfactory forecast accuracy. By utilizing the benefits of ensemble classification
    approaches, the system attempts to increase the accuracy of key health forecasts
    for COVID-19 patients. The approach aims to capture a broader range of structures
    and relationships within patient information by integrating the predictions of
    different models, resulting in more trustworthy and precise forecasts of crucial
    health outcomes. The research gap addressed in this work lies in the convergence
    of accurate prediction methodologies and data privacy preservation within the
    context of COVID-19 critical health outcomes. While various predictive models
    and classification techniques have been explored for COVID-19 patient prognosis,
    few studies have adequately integrated ensemble classification techniques with
    secure feature extraction methods to simultaneously enhance prediction accuracy
    and protect sensitive patient data. The following are the contributions of this
    paper to the above issues and to summarize. • We propose an IoT-enabled decision
    support system to predict and analyze the Covid-19 critical status of the patients
    in healthcare systems during mobility. • Furthermore, we propose an in-vehicle
    monitoring system that securely transmits key patient data to the attending physician
    using the Message Queuing and Telemetry Transport Protocol (MQTT). • The feature
    extraction of the past historical data is performed in the cloud using the proposed
    Feature Extraction based Logistic Regression (FELR). It is again blended with
    ensemble classification techniques to enhance the impact that the parameter extraction
    has on health. • Triple-level security is proposed in the framework integrating
    secured authentication, encryption, and SHA-2 hashing method for secured transmission
    at all levels. This paper is organized as follows; Section 2 presents a literature
    survey in the related field, Section 3 presents the proposed model, Section 4
    discusses the proposed model''s findings, and Section 5 concludes with directions
    for future research. 2. Literature review As time went on, various cyber-physical
    strategies for protection against malicious raids became increasingly important.
    The paper suggests an encryption-based correction instead of covert inspections
    for assessing distant conditions (Li and Albarrak, 2022; Tegenaw et al., 2023).
    Smart sensors send data via a vast network of estimation conversational exchanges,
    where attackers might intercept and compromise data packets. The assault must
    adhere to the covertness limitation to avoid being seen. To decrease the effects
    of secretive raids with greater capability, a linear encryption solution is proposed.
    With this encryption, the worst-case direct hit that allows for a significant
    error is acquired. Therefore, the Stackelberg sports analysis is the primary foundation
    for the creation of gold-standard linear encryption, which undervalues the absolute
    estimation errors. In both full and partial-size facts scenarios for the attacker,
    the aforementioned gold standard procedures are taken into account (Zhou et al.,
    2021). As an example, comparisons of encryption techniques are used to demonstrate
    theoretical results, Pros are that numerical samples can be used to demonstrate
    theoretical results of raid and encryption approaches. However, the Cons are that
    it is not suitable for applications based on encryption and decryption. A wide
    range of cyber-bodily systems has become increasingly dependent on defending themselves
    against malicious attacks. This paper gives a purely encryption-based total countermeasure
    against stealthy assaults on far-flung country assessments (Zainurin et al., 2023;
    Kumar and Smys, 2020). Smart sensors communicate with a far-flung assessment through
    the Wi-Fi communication grid, in which case information packets can be blocked
    and agreed upon by attackers. To avoid detection, the attacker must adhere to
    the secretiveness control. The faraway cease was prepared with the fake information
    locater that displays the estimation approach on the video display units. An encipher
    scheme that mitigates capacity secrets is proposed. The absolute linear attack
    that identifies the most significant estimation errors is created by arbitrary
    linear encoding. Accordingly, the most desirable linear encipher underestimates
    the absolute analysis errors derived from Stackelberg''s sports study. Each of
    the whole and qualified dimension statistics scenarios of the assailant is taken
    into account about the overhead of the most desirable techniques. Additionally,
    arbitrary encipher techniques were considered (Hatami-Marbini et al., 2022). To
    illustrate the hypothetical derivatives, a comparison of attack and encoding methods
    using numeral models was provided (El Mokrini and Aouam, 2022; Awan et al., 2020).
    The difficulty faced by patients who are waiting outside hospitals during Covid
    is the focus of the proposed paper. In such situations, the data in the cloud,
    its confidentiality, and the transmission of the critical status through the protocols
    would open the door for the uniqueness of mobile vehicular IoT systems (Rehman
    et al., 2022; Islam and Nahiduzzaman, 2022). There was a demand for beds, doctors,
    and diagnostics. A smart device can be installed in the system and used to link
    the smart devices in hospitals. The link between the devices is enabled by the
    Constrained Application Protocol (COAP). If a critical scenario arises, an alarm
    or buzzer can be activated so that the oxygen or doctors'' attention is drawn
    to the real emergency. The cloud contains the patient''s information, which is
    sent to the devices together with the patient''s current state and issues (Kuvvetli
    et al., 2021; Adhikari and Munusamy, 2021). The doctors would be able to diagnose
    and treat the patients quickly and effectively based on the two inputs, which
    results in effective patient care and data storage without unneeded data leakage
    (Zhou et al., 2021; Safara, 2020). There are numerous systems used to recommend
    medical services, medications, and other healthcare products. Health status recommendations,
    drug prediction, and recommendations are all topics covered by Tran et al. (2021).
    For predicting health status, chronic disease, and recommended physical activity,
    they have employed the fundamental recommendation system. Using the input attributes,
    they have suggested a novel hybrid factorization technique. They also developed
    use cases for new and existing patients. The paper''s weakness is that it can
    be exceedingly challenging to determine a patient''s critical state if there are
    many patients and few doctors available. The suggested machine learning algorithms
    can deal with the problem. In summary, it is concluded that there is no secure
    one-to-one connection between the healthcare network and the patient during mobility.
    Constraint Application Protocol (COAP) is mostly used for broadcasting purposes
    in the literature, but this connectivity and communication do not meet security
    requirements. The present work proposes an in-vehicular communication protocol
    based on the MQTT. In contrast to other protocols, MQTT is secure by inbuilt authentication.
    It is not enough to analyze the patient''s current status to determine the appropriate
    treatment, medical practitioners need to analyze the patient''s history and current
    status. In addition, we propose an integrated approach for storing and accessing
    patient data securely and extracting features from the dataset. Having reviewed
    the literature, it is apparent that the framework used for obtaining patient information
    in medical healthcares applications lacks end-to-end security. As a result, the
    recommended framework consists of authentication, encryption, and hashing, all
    of which are used to provide triple-level security. Table 1 lists the advantages
    and disadvantages of the current approaches. Table 1. Merits and drawbacks of
    previous work. Reference Objective Merits Drawback Zhou et al. (2021) An encryption-based
    correction instead of covert inspections for assessing distant conditions. To
    decrease the effects of secretive raids with greater capability. The worst-case
    direct hit that allows for a significant error is acquired. Kumar and Smys (2020)
    Encryption-based total countermeasure against stealthy assaults on far-flung country
    assessments. Numerical samples can be used to demonstrate the theoretical results
    of raid and encryption approaches. It is not suitable for applications based on
    encryption and decryption. Awan et al. (2020) Smart sensors communicate with a
    far-flung assessment through the Wi-Fi communication grid. To avoid detection,
    the attacker must adhere to the secretiveness control. The faraway cease was prepared
    with the fake information locater that displays the estimation approach on the
    video display units. Islam and Nahiduzzaman (2022) A smart device can be installed
    in the system and used to link the smart devices in hospitals. If a critical scenario
    arises, an alarm or buzzer can be activated so that the doctors'' attention is
    drawn to the real emergency. Transmission of the critical status through the protocols
    would open the door for uniqueness in the mobile vehicular IoT systems. Adhikari
    and Munusamy (2021) Based on the two inputs, which results in effective patient
    care and data storage without unneeded data leakage. The doctors would be able
    to diagnose and treat the patients quickly and effectively. It can be exceedingly
    challenging to determine a patient''s critical state Garg et al. (2020) This research
    paper is dedicated to establishing some generic aggregation operators to cumulate
    Fermatean fuzzy data in decision-making contexts, based on Yager''s t-norm and
    t-conorm. Through a comparison analysis, the benefits of the suggested operators
    and drawbacks of the current operators are explored. These operators are designed
    to be reliable while dealing with ambiguous information. The Fermatean fuzzy Yager
    aggregation operators may efficiently deal with fuzzy sets that have different
    levels of uncertainty, ambiguity, or fuzziness by taking into account the Fermatean
    t-norm and t-conorm, which are extensions of the conventional fuzzy intersection
    and union operators. Riaz et al. (2022) This article''s goal is to present the
    q-rung orthopedic m-polar fuzzy soft set (q-RO-m-PFSS), a novel hybrid fuzzy model
    that is a stable combination of the soft set (SS), m-polar fuzzy set (m-PFS),
    and q-rung orthopedic fuzzy set (q-ROFS). Improving how uncertainty and imprecision
    are represented when analyzing data and making decisions. Potential loss of simplicity
    and clarity in information representation, increased complexity in modeling and
    interpretation. Rai et al. (2023) Clinical datasets may be mined for information,
    and this knowledge can then be used to provide scientific decision-making for
    illness diagnosis. The capacity to work with many types of data repositories,
    and the creation of clear clauses. Data may be affected by problems including
    underreporting, and inconsistent reporting standards across areas. Utku and Kaya
    (2022) To anticipate the number of transfer passengers on transportation lines
    using machine learning methods It can pick up new knowledge and generalize it.
    Only the predicted amount of transfer passengers is taken into account. Utku (2023)
    A hybrid model based on deep learning was created to forecast and analyze the
    COVID-19 cross-country spread. Forecast the daily number of COVID-19 cases and
    fatalities to lessen the burden on medical personnel and to create health strategies.
    The outputs of complicated predictive models may be understood incorrectly or
    utilized inappropriately, leading to erroneous decisions or actions. Akram et
    al. (2023a) The mFNS- ELECTRE I technique''s step-by-step working approach is
    presented in great depth, together with all the key formulas and operations. It
    offers a great assistance for to select the best alternative among various choices.
    Inadequate data analysis and possible methodological biases Akram et al. (2023b)
    To deliver two practical MCGDM approaches based on PROMETHEE method to address
    the SF information accurately. By incorporating spherical fuzzy sets into the
    PROMETHEE method, it becomes possible to represent imprecise or uncertain preferences
    more accurately. The study provided is scarce in terms of comprehensively considering
    alternate options and possible restrictions. Akram et al. (2023c) To create a
    thorough outranking method for group DM that deals with linguistic phrases embodied
    in 2-tuple linguistic variables, namely the 2 TLFF-ELECTRE II approach. Useful
    tool to describe situations in which the data are imprecise or vague Study''s
    application may limit generalizability of proposed approach to other decision-making
    problems. 3. Proposed Secured Framework for Prediction of the critical status
    of Covid-19 patients The suggested secured framework for forecasting the critical
    condition of COVID-19 patients seeks to improve patient care and resource allocation
    in healthcare environments. To assess patient data, including vital signs, test
    findings, and clinical observations, this system makes use of cutting-edge data
    analytics and machine learning approaches. This framework protects the confidentiality
    and secure management of sensitive medical information by using strong security
    measures to safeguard patient privacy and data integrity. By early identifying
    and risk-stratifying COVID-19 patients, the prediction model developed within
    this framework enables healthcare professionals to effectively deploy resources,
    prioritize urgent cases, and improve patient outcomes. Fig. 2 shows a proposed
    framework for predicting the critical status that is secured with triple levels
    of security. Data about patients in critical states is collected from the person
    accompanying the patient, historical medical records are stored in the cloud,
    and personal features are extracted and classified according to pandemic conditions.
    To create a high impact on the features, the framework uses automatic ensemble
    classification techniques. Download : Download high-res image (775KB) Download
    : Download full-size image Fig. 2. Secured Framework for Prediction of the critical
    status of Covid-19 patients. To determine the appropriate level of decision for
    each patient, the history is analyzed, and features are extracted, as well as
    the current status of the patient. The proposed framework is divided into three
    phases, the first is a user interface that uses encryption and hashing techniques,
    the second is an in-vehicular communication system coupled with cloud storage
    and authentication, and the third is an analysis phase that integrates decision
    support and recommendation systems. 3.1. Web application development and user
    interface with patient data level security The user data is fetched, preprocessed,
    and added to the ML Application Programming Interface (API). The data is preprocessed,
    examined, and then the machine learning API is called to recommend the patients''
    state. Utilizing the data and the critical or non-critical condition, the patient''s
    prior history is examined. The following phase involves extracting features from
    the ML API and manipulating them following those features. Age, gender, and the
    presence of chronic conditions are among the characteristics. Logical regression
    is used to process these attributes, counting them as vectors. Performance is
    compared with other techniques that provide more accuracy. As illustrated in Fig.
    3, status prediction, evaluation, and training are carried out. The data set is
    gathered and labeled with prior training. The splitting and training of the testing
    dataset are performed and the preprocessing of the existing data is implemented
    and the model is created. For testing and validation, the logistic regression
    model is used. The binary classification is used to determine if the patient has
    diabetes or not as an example, with 80% of the data set being used for training
    and 20% being used for testing. The condition is listed as both abnormal and normal.
    Download : Download high-res image (133KB) Download : Download full-size image
    Fig. 3. Vectorization of Patients Condition with status. Based on the many health
    problems that are used as inputs, the status of the patient''s condition is examined.
    React JS is used to develop the API because the web application and user interface
    are designed for both administrators and users. The API representation is shown
    in Fig. 4. The following fields with rows and columns are filled as in Case 1.
    Case 1: Diabetes, Field Names such as name, age, location, sugar level, sugar
    level after fasting, thyroid level- TSH, blood pressure, history of the disease,
    etc. Using the API, the input is analyzed, predicted, and whether the patient
    is normal or abnormal is shown as the output. The API request is displayed in
    algorithm 1, and the user data is secured with SHA and hash algorithms when supplied.
    Feature Extraction-based Logistic Regression is a predictive analysis, just like
    all regression analyses, used to analyze the patient even faster using the proposed
    algorithm. It is possible to determine a patient''s criticality significantly
    more quickly by taking into account the patient''s age and gender. These three
    security layers are integrated to provide secured access to the cloud server hosting
    the health data. JSON is an internet standard used to create the platform''s optional
    signatures for data encryption. For the process of safe data transfer across the
    network, Advanced Encryption Standard (AES) is also utilized for its encrypting
    and decrypting policies. According to equations (1), (2), (3), (4), logistic regression
    relies on a regression model (see Fig. 5). (1) y = h θ ( x ) = θ T x Download
    : Download high-res image (298KB) Download : Download full-size image Fig. 4.
    Node API representation. Download : Download high-res image (151KB) Download :
    Download full-size image Fig. 5. Securing web application and user interface.
    We introduce the function in equation (2), which predicts the likelihood that
    a given patient with given attributes belongs to the “1" (positive) class versus
    the likelihood that it belongs to the “0" (negative) class because equation (1)
    will be incredibly inefficient at predicting our binary values ( y T x , 0, 1).
    (2) P ( y = 1 | x ) = h θ ( x ) = 1 1 + exp ⁡ ( − θ T x ) ≡ σ ( θ T x ) (3) P
    ( y = 0 | x ) = 1 − P ( y = 1 | x ) = 1 − h θ ( x ) We may keep the value of θ
    T x inside the [0, 1] range by using equation (2), sometimes referred to as the
    sigmoid function. Then, we look for a value such that P ( y = 0 | x ) is small
    when x belongs to the “0″ class and big when x belongs to the “1″ class P ( y
    = 1 | x ) = h θ ( x ) is large). (4) σ ( t ) = 1 ( 1 + e − 1 ) Besides a successful
    model and execution of our logistic regression technique, the output and outcome
    are detailed in the following unit. The web user interface which is fetching the
    input and o retrieves the output is also secured using the hashing method. As
    part of the Merkle–Damgard structure, SHA-2 is a set of cryptographic hash functions
    used to strengthen the secure transmission over the network. Regarding the AES
    predictions, there is no precondition reason to rule out the prospect of significant
    cryptanalytic advancement having an impact on the AES''s security, especially
    considering how recent the AES is. However, it is believed that if the AES estimations
    prove to be inaccurate, they will either be fixed (similar to how SHA-2 succeeded
    SHA) or substituted for a new version with the correct and desired security levels.
    A symmetric cryptosystem''s level of security is not always correlated with the
    size of its key. The presumptions listed above are true only if all keys are full-length.
    By fixing a portion of the keys, systems of intermediate strength can be obtained.
    Assumedly, symmetric keys are only employed for a certain period and a finite
    amount of encryption volume. Therefore, issues with the Data Encryption Standard
    (DES) and its derivatives'' short block length are unimportant in this research.
    The original version of the doctor and patient passwords is no longer required.
    One-way encryption is referred to as hashing. Therefore, they will use the SHA256
    hashing technique instead of applying encryption and decryption operations to
    them. The encryption key will be saved in the hashed format when it is entered
    into the record in this manner. The credentials will be entered by the user (Doctor/Patient)
    when he attempts to get into the system. His inputted password will once again
    be hashed before being compared to the one that was recorded in the database at
    the time of user registration. Only if a match is made will the user receive authentication.
    Additionally, even if the hacker manages to obtain this hashed password, they
    won''t be able to access the original password since the original data cannot
    be recovered once the data has been hashed. SHA224, SHA256, SHA-384, and SHA512
    are the four additional hash algorithms that makeup SHA-2. These algorithms are
    named after the number of bits in the message digests they generate, Trimming
    the output of SHA-256 and SHA-512 yields the 224-bit and 384-bit variants. Both
    SHA-256 and SHA-512 employ a block size of 512 bits, whereas SHA-512 uses a block
    size of 1024 bits and contains 80 rounds of iteration. The internal word size
    of SHA-512 is 64 bits, whereas it is 32 bits for all previous SHA variations.
    Table 2 depicts the SHA function. To emphasize SHA-2, we''ll focus on SHA-256
    instead. Eight domains are used to record intermediate results H0,., H7, and 64
    constants K0,., K63 of 32 bits each are used by SHA-256. SHA-256''s function definitions
    are as follows. (5) W i = { M i i f 0 ≤ i ≤ 15 σ 1 ( W i − 2 ) + W i − 7 + σ 0
    ( W i − 15 ) + W i − 16 , i f 16 ≤ i ≤ 63 (6) f i f b , c , d = b ∧ c ⊕ ⊣ b ∧
    d (7) f m a j b , c , d = b ∧ c ⊕ b ∧ d ⊕ c ∧ d Table 2. Secure hash function.
    Hash Functions/Terums (bits) SHA-2 (384) SHA-2 (512) SHA-2 (256) Word Size 64
    64 32 Security 192 256 128 Message Size < 2 128 < 2 128 < 2 64 Block Size 1024
    1024 512 Mes. Digest 384 512 256 Trans. Rounds 80 80 64 Due to the large number
    of adds needed in a simple hardware implementation of the SHA-256 algorithm, a
    variety of possible designs exist for the inner half of the loop. Rearranging
    the order of the calculation to improve performance is synchronized with equations
    (5), (6), (7) and is achievable so long as data dependencies are taken into consideration.
    In equations (1), (2), the operations in the inner loop of the method create new
    values for D and L by Maccounting the eight previous values of the same variables
    (2). (8) F l + 1 = D k + ∑ 1 ( E k ) + D G ( F l , E l , H l ) + G l + L l + X
    l (9) B l + 1 = ∑ 0 ( B l ) + M A J ( B l , A l , D l ) + ∑ 1 ( F l ) + D G (
    F l . E l , H l ) + G l + L l + X l To prevent computing a total during the iteration''s
    execution time, suggested determining l beforehand, δ l in iteration l − 1 , using
    G l − 1 , as shown in equation (3) (10) δ l = G l + N l + X l = G l − 1 + L k
    + X l (11) F l + 1 = D k + ∑ 1 ( E k ) + D G ( F l , E l + H l ) + δ l (12) B
    l + 1 = ∑ 0 ( B l ) + M A J ( B l , A l , D l ) + ∑ 1 ( F l ) + D G ( F l . E
    l , H l ) + δ l To acquire k at time k and to complete the computation of iteration
    l + 1 , the values G l , N l , a n d X l must have been pre-computed with (8),
    (9) or must be present to use equation (10). At this end of the development, we
    use equations (11), (12) to calculate updated values for A and L. Algorithm 1
    SHA-256 Download : Download high-res image (547KB) Download : Download full-size
    image 3.2. In-vehicular monitoring by passing critical status When there is an
    emergency or lockdown, many patients tend to die on the way. This is due to the
    unavailability of proper treatment at the right time. It is also due to a communication
    gap. This methodology involves integrated two-way cloud updates about the patient''s
    status and past medical history with triple-level security. This work can be further
    expanded to patients with various diseases. The doctor assigned to care for the
    patients receives crucial information by using in-vehicle communication. The available
    doctor is also given the information for analysis and the nurses and field workers
    can assess the actual condition of patients and input that information into the
    system interface. Faster treatment and a drop in the fatality rate are the effects
    of the architecture for in-vehicle communication, data entry by field workers,
    and the condition of critical patients being transmitted quickly. The MQTT protocol''s
    connection to the mobile device is the subject of the proposed study. The information
    is kept on the cloud server for analysis and identification of the precise patterns
    of the current health status as reported by healthcare professionals and the history
    of diseases that are already present. The main issue is data processing. In IoT
    and machine-to-machine (M2M) applications, the purpose of MQTT is to provide effective,
    lightweight, and asynchronous communication between devices. It is a crucial protocol
    for connecting and transferring data between devices in IoT ecosystems because
    it offers dependable messaging, scalability, interoperability, and security features.
    3.3. Decision support system via secured transactions Risk factors of the diabetic
    condition can be analyzed in many ways. The mechanism Analysis of risk factors
    for diabetes can take many different forms. The mechanism can be followed about
    the location, likelihood, and habits of the individuals affected by the sickness
    in question. To access medical data in all formats via the cloud, all formats
    have been gathered, pre-processed, and transformed appropriately. To determine
    if the patient is experiencing a normal or abnormal condition, the model was created
    using logistic regression. All medical data in the application is encrypted utilizing
    hybrid secure techniques, and blockchain is included for data analysis and communication
    between the data and the cloud. The database and data formatting rules are tracked
    using a digital version of a highly secure encrypted key. On the other hand, end-to-end
    security is used during decryption to guarantee the use of models for analysis
    as well as APIs. With the NoSQL cloud, cloud transactions are extremely safe and
    secure. The architecture diagram for security, machine learning, and connecting
    storage, analysis, and security is shown in Fig. 6. The conclusion is a recommendation
    for patients whose condition is critical. In this instance, authentication and
    approval are used to connect the doctors throughout the hospital system. Based
    on the AES algorithm, the tokens for the cipher text are provided. Based on historical
    data, the number of patients whose condition is critical is predicted using feature
    extraction-based logical regression. Regression is used to do the analysis, and
    accuracy is represented graphically. Download : Download high-res image (562KB)
    Download : Download full-size image Fig. 6. System architecture for decision support
    system. The cloud computing platform holds sensor data for feature extraction
    and data processing. An AI-based smart system extracts knowledge and condition
    about a person or patient''s well-being. Smart gadgets, display monitors, alert
    devices, etc. Comprise the end-user layer. To strengthen the decision mechanism,
    the layered model adds sub-layers. We add cloud technology to make informed judgments,
    backup data, and transmit it to the cloud layer for analysis and long-term storage.
    These gadgets assess and make important decisions before storing data in the cloud.
    The system sends commands to certain wearable devices to adjust their acquisition
    rate or capabilities, which requires various protocols and safeguards. 3.4. AI-based
    random forest algorithm using Covid-19 health condition Artificial Intelligence
    (AI) is used to follow the progress of viral outbreaks and identify especially
    vulnerable people and areas, and swiftly reduce virus infections. By examining
    previous patient data, AI predicts the likelihood of mortality and the likelihood
    of recovery. The methodological steps of an AI-based system that can help doctors
    identify COVID-19 symptoms and suggest necessary treatments for COVID-19 patients.
    The technique begins by analyzing patient test results and COVID-19 symptoms.
    With the help of AI, clinicians diagnose COVID-19 infection cases, decide on additional
    medication, and begin the necessary operations and monitoring. The care of patients
    and the use of AI applications to control infection transmission are both priorities
    for doctors. As a result, by continually monitoring infected patients using ML
    algorithms, AI is a promising tool for detecting early COVID-19 infections and
    improving treatment consistency. RF-based models allow users to evaluate prediction
    elements'' relative importance. The research shows that lymphocyte count predicts
    severe disease, poor outcomes, and Intensive Care Unit (ICU) transfer. Despite
    having a higher mortality rate, patients over 65 have lower ICU transfer rates,
    which may imply that they prefer palliative or less aggressive treatment, even
    if age is a risk factor for COVID-19 ICU admission. Our clinical practice prediction
    model ranks age as a low-risk factor. Acute respiratory distress syndrome risk
    is indicated by rapid reductions in oxygen saturation and respiratory rate in
    COVID-19 patients. According to the model, oxygen saturation will be lower than
    the respiratory rate. Many COVID-19 patients in hospitals require oxygen. Up until
    the point that the patient can no longer maintain normal oxygen saturation with
    high-flow nasal oxygen or non-invasive ventilation, progressive hypoxia demands
    a higher fraction of inhaled oxygen (FiO2) to sustain percutaneous oxygen (SpO2)
    saturation. One reason oxygen saturation has a poorer predictive value. SpO2 is
    less susceptible to sickness until serious respiratory breakdown. C-reactive protein
    is associated with COVID-19 pneumonia in early infection. This model includes
    the patient''s vital signs in its predictions, which are often used to detect
    patients in critical condition who are at risk of worsening. Heart rate, blood
    pressure, and body temperature are all examples of vital signs. Because of their
    prevalence as indications of sepsis in intensive care units, we found that hematologic
    markers (Red Blood Cells (RBC), Hemoglobin (Hb), Placental Lactogen (PL), White
    Blood Cells (WBC)) were significant predictors of COVID-19. Deficiencies or excesses
    in potassium, sodium, or calcium have also been linked to increased COVID-19 levels.
    The random forest (RF) method was used because it has been demonstrated to be
    useful in the analysis of complicated clinical data of many sorts when compared
    to other approaches, has great model generalizability, and reveals high-order
    interactions among variables without sacrificing predictive performance. Access
    to information may be significantly affected by factors such as patient care and
    available resources. The stress of an emergency scenario can lead to doctors becoming
    overburdened, which can lead to less-than-ideal clinical documentation. Therefore,
    the lack of information might be due to improper clinical recordkeeping or patient
    safety concerns about the need for certain examinations (as in our instance).
    The imputation method and the RF model nonetheless showed respectable levels of
    sensitivity, even when data availability for some variables did not follow a random
    pattern. In this way, overfitting is reduced when employing an ensemble-based
    classification method. The ability to highlight the key differentiating factors
    for each forecast is another area in which this method excels above earlier models.
    The tree-based ensemble learning method used by the random forest (RF) machine
    learning algorithm/artificial intelligence (AI) produces a forest of several decision
    trees. The use of RF makes sure that no one decision tree created exhibits excessive
    correlation with any other decision tree in the model. The program then makes
    a final forecast for each of the observations after repeating this procedure around
    five times. Simply taking the average of all the observed forecasts can represent
    this final prediction. Because of this, the many decision trees produced by the
    RF method were trained using various components of the training dataset, which
    accounts for their objectivity and higher prediction accuracy. Because it more
    closely matches human decision-making processes, the RF output is simple to comprehend.
    In algorithm 2, the RF algorithm is displayed. Algorithm 2 AI-Based Random Forest
    Algorithm Download : Download high-res image (649KB) Download : Download full-size
    image 3.5. Triple level security inpatient data level- cipher substitution The
    generation of JSON to JWT (JSON web tokens) secures the patient data. Private
    and public keys are used to safeguard the tokens. Using the AES technique, the
    JWT token is transformed into cipher text. The suggestion will only let doctors
    make judgments and treat patients when necessary, allowing them to save patients
    from potentially fatal situations. MongoDB is used to store the data on the cloud,
    and all sensitive data is protected against unauthorized access and use. Data
    authentication and integrity are maintained when the triple-level security algorithms
    are applied. A JSON web token (JWT) is a JSON object that is used to safely transfer
    data between two domains when it is transmitted over the internet. It may be used
    for information sharing as well as an authentication method. Whenever a user logs
    into the system, a JWT token is issued. It might be saved on the user''s computer
    as data, but it wouldn''t make the project front end independent. Therefore, the
    suggested project just puts it in the database. A JWT token will be produced and
    given to the front end once the user logs into the system, allowing them to access
    all REST APIs. It will only be effective for 5 min. Authentication will be established
    in the project in this manner. The First level of security is provided by the
    JSON tokens as shown in Fig. 7. Also, Fig. 8 gives the JWT generation with a payload
    that is cipher substitution. Download : Download high-res image (282KB) Download
    : Download full-size image Fig. 7. JWT generation using Cipher substitution. Download
    : Download high-res image (208KB) Download : Download full-size image Fig. 8.
    UI interface with triple-level encryption security. The following medical data
    stored in the cloud is compared, analyzed, and recommended for disease prediction
    at the earlier stage of the symptoms. 3.5.1. Functionality The mechanism of feature
    selection and extraction using logistic regression is carried out for estimating
    the patient''s health condition as shown in Algorithm 3 below. Algorithm 3 Feature
    Extraction Using Logistic Regression Download : Download high-res image (314KB)
    Download : Download full-size image 3.5.2. JWT generation using cipher substitution
    In the proposed Algorithm 3, we use Feature Extraction based logistic regression
    to analyze the patient even faster. Like all regression analyses, the logistic
    regression is a predictive analysis by considering the age factor and gender it
    can be predicted if the patient is critical or not in a much faster way. The Integration
    of these three security levels acts as the secured access to the cloud server
    where the health data is stored. The JSON web format is used to recover the optional
    signature and the data encryption formats. The mechanism of Advanced Encryption
    Standard is used for encrypting and decrypting the information of varying formats
    as requested with secure file transmission protocols. Fig. 8 depicts the triple-level
    encryption security. Admin and user interfaces are created for the web application.
    The pre-processed data is used to get the input information, such as diabetes,
    field names like name, age, location, blood sugar level fasting, blood sugar level
    after fasting, thyroid level-TSH, blood pressure, and history of the disease.
    Additionally, ML algorithms are being used to predict the data. As depicted in
    Fig. 7, the web application and security are connected. 4. Experimental results
    A local system with 8 GB RAM, an Intel i5–9th generation processor, and NVidia
    GTX1650 graphics was used. The simulator Nodered is equipped with MQTT protocol,
    Logistic regression is performed with Python and SCIkit learn, Node Js framework
    is used to connect third-party objects to the web objects, custom libraries are
    integrated into the implementation for feature selection, Amazon Web services
    (AWS) cloud environment was used for storage and analysis. MongoDB is used for
    scalability and storage of data in the Node API. The proposed system is analyzed
    using 1400 sets of records (i.e. patients). The outcome is predicted for each
    data whether it is a critical or not critical patient. FELR represents the Feature
    extraction-based Logistic Regression algorithm. Predictive accuracy, precision,
    and recall are used to evaluate the efficiency of each model. The confusion matrix,
    a two-by-two table that compares the model''s predicted class values to the actual
    class values, serves as the basis for these evaluations. True positives (TP),
    the proportion of patients successfully diagnosed with heart disease, are located
    in the first quadrant. Next, we have false positives (FP), or healthy people who
    were wrongly diagnosed with a serious illness. The second category is false negatives
    (FN), which include people who do have the disease but were misclassified. Last,
    true negatives (TN) are accurately recognized in people who do not have cardiac
    disease. The evaluation of our framework''s predictive capabilities involves a
    comprehensive set of assessment criteria, such as accuracy, precision, recall,
    and F1-score. These measures function as quantitative instruments for accurately
    assessing the prediction capability of the framework. This research aims to enhance
    the current literature by performing a thorough evaluation of the performance
    of our proposed framework in comparison to established methodologies. The result
    of this evaluation encompasses both the prediction accuracy and computational
    efficiency aspects. Through a methodical examination of the results, we give a
    comprehensive depiction of how our framework distinguishes itself in terms of
    both precision and effectiveness. Furthermore, a comprehensive examination is
    conducted to elucidate the importance of the characteristics collected inside
    our framework. This entails demonstrating the influence of different characteristics,
    both individually and collectively, on the predictions made by the model. By emphasising
    the crucial significance of these characteristics in facilitating precise forecasts,
    we provide a deeper understanding of the underlying mechanisms of our framework
    and validate its effectiveness via tangible data. The percentage of samples for
    which the suggested approach accurately predicted results is used to assess how
    accurate the system is. The accuracy is calculated using equation (14). (14) Accuracy
    = TP + TN TP + TN + FP + FN One of the most crucial standards for accuracy is
    precision, which is well-defined as the ratio of correctly classified cases to
    all instances of predictively positive data. The precision is calculated using
    equation (15). (15) precision = TP TP + FP The suggested model''s sensitivity
    is its ability to recognize each important sample in a data collection. It is
    derived statistically by dividing the percentage of TPs by the total of TPs and
    FNs. The sensitivity is assessed using equation (16). (16) sensitivity = TP TP
    + FN The potential of a model to identify each important sample within a data
    collection is known as recall. The percentage of TPs divided by the sum of TPs
    and FNs is how it is statistically defined. The recall is calculated using equation
    (17). (17) Recall = FN FN + TP The above Table 3 shows the data set is the micro
    level data which is compared in terms of accuracy. Fig. 9A, Fig. 9B(a) and (b)
    show how the graphical analysis of the data which are executed using the three
    models. Feature Extraction based Logistic Regression (FELR), Logistic Regression
    (LR), and Mixed Regression (MR). The sensitivity and specificity of the data are
    measured using the same data set. Since the biological features are included in
    the past data, the status can be predicted more accurately compared to any other
    technique. The increase in MR and FELR accuracy is the prediction is done based
    on the weightage given to the features of the patients along with existing data.
    Table 3. Performance Accuracy Analysis using Micro Level Dataset. No of Patients
    FELR LR MR 50 0.65 0.58 0.64 100 0.68 0.64 0.67 150 0.69 0.67 0.68 200 0.71 0.69
    0.70 250 0.72 0.69 0.71 300 0.75 0.72 0.73 350 0.78 0.73 0.78 400 0.81 0.77 0.8
    450 0.84 0.79 0.8 500 0.89 0.8 0.8 In Fig. 9 (a) the analysis of the FELR shows
    an accuracy rate of 89% in predicting the critical status of the patient. The
    FELR has a high-level accuracy prediction compared to LR and MR for pre-processed
    set records. The sensitivity and specificity values of the proposed approach for
    10 patients are visualized in Fig. 9 (b). Download : Download high-res image (305KB)
    Download : Download full-size image Fig. 9A. Graphical Analysis for Micro level
    data. Download : Download high-res image (347KB) Download : Download full-size
    image Fig. 9B. Graphical Analysis for Micro level data. Table 4 depicts the performance
    analysis of the binary classification. The model is extended to the multivariate
    classification and the accuracy, precision, and recall for the models are implemented
    the performance of binary classification is depicted in the graph as shown in
    Fig. 10. The three models are compared and it is concluded that FELR shows the
    highest accuracy and it is because the status of normal or abnormal is predicted
    with past historical data, age factor, gender, and critical status prediction
    using the existing condition. The multivariate classification is shown in Fig.
    11 (a), the set of data taken is similar but with different variants. Table 5
    depicts the performance analysis of the multivariate classification. Fig. 8 provides
    the UI for the web application that has been designed in which the user uploads
    medical-related content. Triple-level encryption security algorithms are used
    in preventing malicious attacks on data while transmitting by using FELR, MR,
    and LR algorithms. Fig. 10 shows the comparison of the proposed work FELR with
    the conventional algorithms. The user data is encrypted to triple-level times
    and stored in the NOSQL cloud. The feature extraction-based binary classification
    is extended to the multivariate classification where there are more than 2 features
    it is called multinomial regression and it is mapped to a mathematical model of
    probability P (x = q|r∼) for r = 1, 2, N where the modeling is done based on the
    bias, in case of diabetes status, if it''s nearing the threshold value then the
    value is nearing 1 otherwise its 0. P (y∼) = luMr∼∑b = 1NluMr ∼ where u = [u0,u1,u2,u3
    ….]K are the model parameters and u0 is the bias, and the vector r∼ = [1,r1, ….rm],
    the logistic regression is expanded to multivariate regression and it is mapped
    to multinomial logistic regression. Table 4. Performance analysis of the binary
    classification. Methods Binary classification Accuracy Precision Recall FELR 96%
    92% 91.72% LR 91% 89% 89.4% MR 87% 85.6% 87.2% Download : Download high-res image
    (455KB) Download : Download full-size image Fig. 10. Comparison of accuracy, precision,
    and recall for the models (FELR, LR, MR) with binary classification. Download
    : Download high-res image (544KB) Download : Download full-size image Fig. 11A.
    Comparison of accuracy, precision, and recall for the models (FELR, LR, MR) with
    multivariate classification. Table 5. Performance analysis of the multivariate
    classification. Methods Multivariate classification Accuracy Precision Recall
    FELR 85.8% 82.5% 94.1% LR 78.5% 78.3% 87.3% MR 72.8% 71.7% 85.2% The F1-measure
    for the models is shown in Fig. 11 (b) and Table 6. The final performance analysis
    is the F1-measure model with all 1400 records, which allows for a consolidation
    of work. The F1 measure also shows the same results as the previous model, with
    FELR showing the highest efficiency. As shown in Fig. 11 (b), the prediction of
    the F-measure involves both precision and accuracy. Download : Download high-res
    image (192KB) Download : Download full-size image Fig. 11B. F1-measure for the
    models (FELR, LR, MR). Table 6. Various dataset performance analyses of measured.
    Methods F1-measurement analysis F1-measure (700 Patients) F1-measure (1400 Patients)
    FELR 81.8% 91% LR 81.9% 85.7% MR 80.9% 86.3% In terms of accuracy, precision,
    recall, and specificity, the performance of the suggested model is also contrasted
    with the current state of the art methods as shown in Fig. 12. The proposed system
    FELR is compared to the hybrid prediction model using deep learning (HPM-DL (Utku,
    2023)), extra tree and convolutional neural network-based ensemble model for COVID-19
    (ET-CNN EM (Umer et al., 2022)), ensemble-based random forest (ERFA (Adhikari
    and Munusamy, 2021)), ensemble transformation learning, and ML with regression
    (Kundu and Ferrara, 2022; Rai et al., 2023). Since the features are retrieved
    and precisely matched with the COVID patient''s health condition through the FELR
    algorithm, even though automation is included in the other methods, the suggested
    system demonstrated the maximum impact when compared to others. The values of
    the metrics and FELR algorithm performance are demonstrated in Table 7. The FELR
    algorithm has demonstrated exceptional superiority by consistently surpassing
    the predictive capabilities of all these algorithms. Download : Download high-res
    image (352KB) Download : Download full-size image Fig. 12. Comparison of existing
    and proposed work FELR Table 7. Comparative Analysis of algorithms with Proposed
    FELR (%). Measures HPM-DL (Utku, 2023) ET–CNN–EM (Umer et al., 2022) ERFA (Adhikari
    and Munusamy, 2021) ET-NET (Kundu and Ferrara, 2022) ARM-ML (Rai et al., 2023)
    FELR (Proposed Work) Accuracy 95.1 90.45 91.12 94.34 92.4 96 Precision 84 85.49
    89.39 89.44 88.24 93.9 Recall 86.74 84.79 82.33 86.21 87.13 91 Specificity 96
    95.96 94.37 93.25 92.58 98.45 5. Statistical analysis for the proposed framework
    The quantitative method known as analysis of variance, or ANOVA, is used to split
    reported variability data into different portions for use in future studies. When
    there are three or more data sets, a one-way ANOVA has been employed to determine
    the association between the variables. The average sums of squared of the null
    model with the anthropocentric principle relative to the whole model make up the
    traditional ANOVA F-statistic. The least-squares method is used to determine the
    parameters with similar variances throughout the board. This may be stated as
    follows using equations (19), (20), (21), (22), (23), (24): (19) R = F N b e t
    w e e n / F N e r r o r Where (20) F N b e t w e e n = ∑ k = 1 l n ( z ‾ k − z
    ‾ ) 2 n − 1 And (21) F N e r r o r = ∑ k = 1 l ∑ h = 1 n k ( z k h − z k ) 2 k
    − n The definition of the Welch-test statistic is (22) G = ∑ k = 1 l x h [ ( z
    k − z ˜ ) 2 / ( L − 1 ) ] 1 + 2 ( l − 2 ) l 2 − 1 ∑ k = 1 l [ ( 1 − x j / w )
    2 / ( n k − 1 ) ] Where n k  =  l t 1 2 , w =  ∑ k = 1 l n k and G = 1 w ˙ ∑ k
    = 1 l n k z k is defined as: (23) p = l 2 − 1 3 ∑ k = 1 l [ ( 1 − z k / w ) 2
    / ( n k − 1 ) ] The Brown-Forsythe-test-statistic is defined as: (24) p * = ∑
    k = 1 l q k ( z ‾ h − z ‾ ) 2 ∑ k = 1 l ( 1 − n k / N ) J k 2 When L is true,
    a central p × distribution with degrees of freedom n - 1 and p, where s is defined
    as shown in equation (25) (25) 1 / p = ∑ k = 1 l a k 2 / ( n k − 1 ) , c i = (
    1 − n k / N ) J k 2 ∑ h = 1 k ( 1 − n k / N ) J k 2 The generalized S-value is
    now calculated using formula S = 1, where s is the sample size in equation (26).
    (26) p = D H l − 1 , k − l k − l k − 1 t ∼ a k 1 t 1 2 a 1 a 2 , … , a k − 1 ,
    … k 1 t l 2 1 − a k − 1 An F-distribution with k - l, D - k dof, and a separate
    Beta stochastic process are used to derive the predictions using eq. (27). (27)
    B k ∼ B e t a ( ∑ k = 1 l ( n k − 1 ) 2 , n k + 1 − 1 2 ) , n = 1,2 , … , l −
    1 The p-value is computed by numerically integrating the expected value regarding
    the Beta random variables in the p-value formula. The p-value obtained is > 0.05
    and so it is considered to be statistically significant and the null hypothesis
    is rejected. Fig. 13 depicts the ANOVA statistic. A statistical procedure called
    Analysis of Variance (ANOVA) is used to examine variations between the means (or
    averages) of several groups. It is used in a variety of situations to discover
    whether there are any differences between the means of various groups. To assess
    COVID-19''s effects on the populace and stop additional COVID-19 waves from emerging,
    statisticians play a critical role (Koppu et al., 2020). The examination of public
    health data involves several statistical challenges; hence statisticians should
    have access to such data. The P-value has shown significance value, that the impact
    of the past historical data shows the major change in the critical status of the
    patient. In the above graph, the critical status of the patient is influenced
    by the impact of past historical data. Download : Download high-res image (187KB)
    Download : Download full-size image Fig. 13. ANOVA statistic. The critical status
    can be predicted in the earlier stage and the treatment is done based on the dynamic
    data and historical data. The observer data in different groups states that the
    patient data is highly influenced by past historical data and the current status
    of the patient. The changes and influence are observed between the groups in micro-level
    and macro-level variations. The statistical data from all the groups is not the
    same, so the null hypothesis is rejected. The average mean for the above table
    is 0.522, the manipulation is performed with the ANOVA table based on the values
    in Table 8. The given value f > than F, which is equal to 0.05. The null hypothesis
    is rejected which proves, there is a significant change between the groups. Table
    8. The comparison of (the FELR) method with Conventional Methods using ANOVA table.
    FELR Method LR MLR 0.6 0.88 .13 0.8 0.12 .9 0.4 0.9 .11 0.5 0.11 .8 0.3 0.6 .7
    6. Conclusion and future work The proposed work categorizes critical patients
    for treatment using wearable devices and in-vehicle communication and status updates.
    The results are stored in a Mongo DB repository, which provides recommendations
    to doctors for immediate care. The repository considers parameters like age, skin
    thickness, pregnancy, gender, and blood pressure. Multivariate and binary classifications
    were used which significantly impacted diabetes status, and the model was mapped
    to a probabilistic model. The proposed work provided three levels of security
    for sensitive data, including tokenization, access keys, advanced encryption,
    and the SHA algorithm. Data transmitted from MongoDB to the cloud was protected,
    ensuring confidentiality, integrity, and authentication. The feature extraction
    model were mapped to a probabilistic model, resulting in accurate predictions
    of the patient''s status by overlapping model points with real threshold values.
    A logistic regression model played a crucial role in data implementation and measurement.
    The experimental results demonstrated the superiority of the unique strategy over
    standard models, such as Logistic Regression and Mixed Regression, by achieving
    an astounding accuracy rate of 96%. Furthermore, the system demonstrates its proficiency
    in accurately recognizing and categorising patients'' critical conditions inside
    healthcare settings, as seen by its impressive recall rate of 91% and similarly
    notable F-measure of 91%. The excellent performance qualities of the technique
    may be ascribed to its unique approach, which leverages its efficiency in processing
    intricate medical data and its ability to guarantee the safe transfer of confidential
    patient information. The combination of accuracy, recall, and F-measure outcomes,
    together with the efficiency and secure transmission capabilities, establishes
    this approach as a viable and practical approach to improve patient care by enabling
    the timely identification of urgent medical issues. Future research will be aimed
    at designing smart wearable gadgets for secure medical condition reporting, combining
    IoT devices and edge computing platforms. This approach will include security
    safeguards, machine learning analysis, and blockchain technology. It can be further
    enhanced with deep learning algorithms with automated responses and communication
    with electrical vehicles. Declaration of competing interest The authors declare
    that they have no known competing financial interests or personal relationships
    that could have appeared to influence the work reported in this paper. Acknowledgement
    The author Abdullah Alghmdi is thankful to the Deanship of Scientific Research
    at Najran University for funding this work, under the Research Groups Funding
    program grant code NU/RG/SERC/12/44. Data availability No data was used for the
    research described in the article. References Adhikari and Munusamy, 2021 M. Adhikari,
    A. Munusamy ICovidCare: intelligent health monitoring framework for COVID-19 using
    ensemble random forest in edge networks Internet of Things, 14 (2021), Article
    100385 View PDFView articleView in ScopusGoogle Scholar Akram et al., 2023a M.
    Akram, R. Bibi, M. Deveci An outranking approach with 2-tuple linguistic Fermatean
    fuzzy sets for multi-attribute group decision-making Eng. Appl. Artif. Intell.,
    121 (2023), Article 105992 View PDFView articleView in ScopusGoogle Scholar Akram
    et al., 2023b M. Akram, M. Sultan, J.C.R. Alcantud An integrated ELECTRE method
    for selection of rehabilitation center with m-polar fuzzy N-soft information Artif.
    Intell. Med., 135 (2023), Article 102449 View PDFView articleView in ScopusGoogle
    Scholar Akram et al., 2023c M. Akram, K. Zahid, C. Kahraman A PROMETHEE-based
    outranking approach for the construction of Fangcang shelter hospital using spherical
    fuzzy sets Artif. Intell. Med., 135 (2023), Article 102456 View PDFView articleView
    in ScopusGoogle Scholar Al-Karaki et al., 2019 J.N. Al-Karaki, A. Gawanmeh, M.
    Ayacheand DASS-CARE: a decentralized, accessible, scalable, and secure healthcare
    framework using blockchain 2019 15th International Wireless Communications & Mobile
    Computing Conference (IWCMC), IEEE (2019), pp. 330-335 CrossRefView in ScopusGoogle
    Scholar Awan et al., 2020 I.A. Awan, M. Shiraz, M.U. Hashmi Secure Framework Enhancing
    AES Algorithm in Cloud Computing” Security and Communication Networks (2020) Google
    Scholar El Mokrini and Aouam, 2022 A. El Mokrini, T. Aouam A decision-support
    tool for policymakers in healthcare supply chains to balance between perceived
    risk in logistics outsourcing and cost-efficiency Expert Syst. Appl., 201 (2022),
    Article 116999 View PDFView articleView in ScopusGoogle Scholar Garg et al., 2020
    H. Garg, G. Shahzadi, M. Akram Decision-making analysis based on Fermatean fuzzy
    Yager aggregation operators with application in COVID-19 testing facility Math.
    Probl Eng., 2020 (2020), pp. 1-16 Google Scholar Gökalp et al., 2018 E. Gökalp,
    M.O. Gökalp, S. Çobanand “Analysing opportunities and challenges of integrated
    blockchain technologies in healthcare” Eurosymp. Syst. Anal. Design (2018), pp.
    174-183 CrossRefView in ScopusGoogle Scholar Hatami-Marbini et al., 2022 A. Hatami-Marbini,
    N. Varzgani, S. Sajadi An emergency medical services system design using mathematical
    modeling and simulation-based optimization approach Decis. Anal. J., 3 (2022),
    Article 100059 View PDFView articleGoogle Scholar Islam and Nahiduzzaman, 2022
    M.R. Islam, M. Nahiduzzaman Complex features extraction with deep learning model
    for the detection of COVID-19 from CT scan images using ensemble-based machine
    learning approach Expert Syst. Appl., 195 (2022), Article 116554 View PDFView
    articleView in ScopusGoogle Scholar Koppu et al., 2020 S. Koppu, P.K.R. Maddikunta,
    G. Srivastava Deep learning disease prediction model for use with intelligent
    robots Comput. Electr. Eng., 87 (2020), Article 106765 View PDFView articleView
    in ScopusGoogle Scholar Kumar and Smys, 2020 D. Kumar, S. Smys Enhancing security
    mechanisms for healthcare informatics using ubiquitous cloud J. Ubiquitous Comput.
    Commun. Technol. (UCCT), 2 (1) (2020), pp. 19-28 CrossRefGoogle Scholar Kundu
    and Ferrara, 2022 R. Kundu, P.K. Singh M. Ferrara ET-NET: an ensemble of transfer
    learning models for prediction of COVID-19 infection through chest CT-scan images
    Multimed. Tool. Appl., 81 (1) (2022), pp. 31-50 CrossRefView in ScopusGoogle Scholar
    Kuvvetli et al., 2021 Y. Kuvvetli, M. Deveci, T. Paksoy A predictive analytics
    model for COVID-19 pandemic using artificial neural networks Decis. Anal. J.,
    1 (2021), Article 100007 View PDFView articleGoogle Scholar Li and Albarrak, 2022
    Y. Li, A.S. Albarrak An informatics-driven intelligent system to improve healthcare
    access for vulnerable populations J. Biomed. Inf., 134 (2022), Article 104196
    View PDFView articleView in ScopusGoogle Scholar Menesgere et al., 2022 A. Menesgere,
    J.S. Sundarakumar, S.K. Shahul Hameed, V. Ravindranath, SANSCOG & TLSA Study Teams
    Comparison of risk factors for dementia among rural and urban elderly adults‐data
    from two cohort studies in India Alzheimer’s Dementia, 19 (6) (2022), pp. 2443-2449
    Google Scholar Olaleye et al., 2022 T. Olaleye, A. Abayomi-Alli, K. Adesemowo,
    Arogundade, et al. SCLAVOEM: hyperparameter optimization approach to predictive
    modeling of COVID-19 infodemic tweets using smote and classifier vote ensemble
    Soft Comput. (2022), pp. 1-20 Google Scholar Panigutti et al., 2021 C. Panigutti,
    A. Perotti, A. Panisson FairLens: auditing black-box clinical decision support
    systems Inf. Process. Manag., 58 (5) (2021), Article 102657 View PDFView articleView
    in ScopusGoogle Scholar Raftarai et al., 2021 A. Raftarai, R.R. Mahounaki, M.
    Harouni, et al. Predictive models of hospital readmission rate using the improved
    AdaBoost in COVID-19 Intelligent Computing Applications for COVID-19, CRC Press
    (2021), pp. 67-86 CrossRefGoogle Scholar Rahmani et al., 2022 A.M. Rahmani, E.
    Azhir, M. Naserbakht “Automatic COVID-19 detection mechanisms and approaches from
    medical images: a systematic review” Multimed. Tool. Appl. (2022), pp. 1-20 CrossRefGoogle
    Scholar Rai et al., 2023 V.K. Rai, S. Chakraborty, S. Chakraborty Association
    rule mining for prediction of COVID-19 Decis. Making: Appl. Manag. Eng., 6 (1)
    (2023), pp. 365-378 CrossRefView in ScopusGoogle Scholar Rehman et al., 2022 A.
    Rehman, S. Abbas, M.A. Khan A secure healthcare 5.0 system based on blockchain
    technology entangled with federated learning technique Comput. Biol. Med. (2022),
    Article 106019 View PDFView articleView in ScopusGoogle Scholar Riaz et al., 2022
    M. Riaz, H. Garg, M.T. Hamid, D. Afzal Modeling uncertainties with TOPSIS and
    GRA based on q‐rung orthopedic m‐polar fuzzy soft information in COVID‐19 Expet
    Syst., 39 (5) (2022), Article e12940 View in ScopusGoogle Scholar Safara, 2020
    F. Safara A computational model to predict consumer behavior during COVID-19 pandemic
    Comput. Econ. (2020), pp. 1-14 Google Scholar Shaban et al., 2020 W.M. Shaban,
    A.H. Rabie, A.I. Saleh, et al. A new COVID-19 Patients Detection Strategy (CPDS)
    based on hybrid feature selection and enhanced KNN classifier Knowl. Base Syst.,
    205 (2020), Article 106270 View PDFView articleView in ScopusGoogle Scholar Shekar
    and Hailu, 2022 B.H. Shekar, Habtu Hailu An efficient stacked ensemble model for
    the detection of COVID-19 and skin cancer using a fused feature of transfer learning
    and handcrafted methods Comput. Methods Biomech. Biomed. Eng.: Imag. & Visual.
    (2022), pp. 1-17 CrossRefGoogle Scholar Tegenaw et al., 2023 G.S. Tegenaw, D.
    Amenu, G. Ketema, F. Verbeke, J. Cornelis, B. Jansen Evaluating a clinical decision
    support point of care instrument in a low resource setting BMC Med. Inf. Decis.
    Making, 23 (1) (2023), pp. 1-16 Google Scholar Tran et al., 2021 T.N.T. Tran,
    A. Felfernig, C. Trattner Recommender systems in the healthcare domain: state-of-the-art
    and research issues J. Intell. Inf. Syst., 57 (2021), pp. 171-201, 10.1007/s10844-020-00633-6
    View in ScopusGoogle Scholar Umer et al., 2022 M. Umer, S. Sadiq, M. Nappi ETCNN:
    extra tree and convolutional neural network-based ensemble model for COVID-19
    tweets sentiment classification Pattern Recogn. Lett., 164 (2022), pp. 224-231
    View PDFView articleView in ScopusGoogle Scholar Utku, 2023 A. Utku Deep learning
    based on an efficient hybrid prediction model for Covid-19 cross-country spread
    among E7 and G7 countries Decis. Making: Appl. Manag. Eng., 6 (1) (2023), pp.
    502-534 CrossRefView in ScopusGoogle Scholar Utku and Kaya, 2022 A. Utku, S.K.
    Kaya Multi-layer perceptron-based transfer passenger flow prediction in Istanbul
    transportation system Decis. Making: Appl. Manag. Eng., 5 (1) (2022), pp. 208-224
    CrossRefView in ScopusGoogle Scholar Zainurin et al., 2023 S.N. Zainurin, W.Z.W.
    Ismail, S.N.I. Mahamud, I. Ismail, J. Jamaludin, N.A. Ab Aziz Integration of sensing
    framework with A decision support system for monitoring water quality in agriculture
    Agriculture, 13 (5) (2023), p. 1000 CrossRefView in ScopusGoogle Scholar Zhou
    et al., 2021 L. Zhou, A. Fu, Y. Mu Multicopy provable data possession scheme supporting
    data dynamics for cloud-based electronic medical record system Inf. Sci., 545
    (2021), pp. 254-276 View PDFView articleView in ScopusGoogle Scholar Cited by
    (1) A novel compression-based 2D-chaotic sine map for enhancing privacy and security
    of biometric identification systems 2024, Journal of Information Security and
    Applications Show abstract View Abstract © 2023 Elsevier Ltd. All rights reserved.
    Part of special issue Machine Learning/Artificial Intelligence Application in
    Healthcare Supply Chain Edited by Dragan Pamucar, Fariba Goodarzian, Peiman Ghasemi,
    Irfan Ali, Vladimir Simic View special issue Recommended articles A social network
    analysis-based model for failure mode and effect analysis under linguistic preference
    relation environment Engineering Applications of Artificial Intelligence, Volume
    126, Part D, 2023, Article 107119 Jia Huang, …, Hu-Chen Liu View PDF Supervised
    spectral feature learning for fine-grained classification in small data set Engineering
    Applications of Artificial Intelligence, Volume 126, Part D, 2023, Article 107135
    Xiaoxu He View PDF A hybrid approach for artwork recommendation Engineering Applications
    of Artificial Intelligence, Volume 126, Part D, 2023, Article 107173 Ignacio Gatti,
    …, Silvia Schiaffino View PDF Show 3 more articles Article Metrics Citations Citation
    Indexes: 1 Captures Readers: 11 View details About ScienceDirect Remote access
    Shopping cart Advertise Contact and support Terms and conditions Privacy policy
    Cookies are used by this site. Cookie settings | Your Privacy Choices All content
    on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply. We use cookies that are necessary to make our site work. We may also
    use additional cookies to analyze, improve, and personalize our content and your
    digital experience. For more information, see ourCookie Policy Cookie Settings
    Accept all cookies'
  inline_citation: '>'
  journal: Engineering applications of artificial intelligence
  limitations: '>'
  pdf_link: null
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: Novel framework based on ensemble classification and secure feature extraction
    for COVID-19 critical health prediction
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1080/17517575.2019.1633689
  analysis: '>'
  authors:
  - Hong-Ning Dai
  - Hao Wang
  - Guangquan Xu
  - Jiafu Wan
  - Muhammad Imran
  citation_count: 178
  full_citation: '>'
  full_text: '>

    Access provided by University of Nebraska, Lincoln Log in  |  Register Cart Home
    All Journals Enterprise Information Systems List of Issues Volume 14, Issue 9-10
    Big data analytics for manufacturing int .... Search in:                                        This
    Journal                                                                                Anywhere                                                                  Advanced
    search Enterprise Information Systems Volume 14, 2020 - Issue 9-10: Cognitive
    Computing for Big Data Systems over Internet of Things for Enterprise Information
    Systems Submit an article Journal homepage Full access 4,525 Views 146 CrossRef
    citations to date 1 Altmetric Listen Original Articles Big data analytics for
    manufacturing internet of things: opportunities, challenges and enabling technologies
    Hong-Ning Dai , Hao Wang , Guangquan Xu , Jiafu Wan & Muhammad Imran Pages 1279-1303
    | Received 31 Dec 2018, Accepted 16 Jun 2019, Published online: 24 Jun 2019 Cite
    this article https://doi.org/10.1080/17517575.2019.1633689 In this article ABSTRACT
    1. Introduction 2. Necessities and challenges of big data analytics for manufacturing
    Internet of things 3. Enabling technologies 4. Future research directions 5. Conclusion
    Disclosure statement Additional information References Full Article Figures &
    data References Citations Metrics Reprints & Permissions View PDF View EPUB Formulae
    display:? ABSTRACT Data analytics in massive manufacturing data can extract huge
    business values while can also result in research challenges due to the heterogeneous
    data types, enormous volume and real-time velocity of manufacturing data. This
    paper provides an overview on big data analytics in manufacturing Internet of
    Things (MIoT). This paper first starts with a discussion on necessities and challenges
    of big data analytics in manufacturing data of MIoT. Then, the enabling technologies
    of big data analytics of manufacturing data are surveyed and discussed. Moreover,
    this paper also outlines the future directions in this promising area. KEYWORDS:
    Smart manufacturingdata analyticsdata mininginternet of things Previous article
    View issue table of contents Next article 1. Introduction The manufacturing industry
    is experiencing a paradigm shift from the automated manufacturing industry to
    ‘smart manufacturing’ Kusiak ( 2018). During this evolution, Internet of Things
    (IoT) plays an important role of connecting the physical environment of manufacturing
    to the cyberspace of computing platforms and decision-making algorithms, consequently
    forming a Cyber-Physical System (CPS). We name such industrial IoT dedicated to
    manufacturing industry as manufacturing IoT (MIoT) in this paper. MIoT consists
    of a wide diversity of manufacturing equipments, sensors, actuators, controllers,
    RFID tags and smart meters, which are connected with computing platforms through
    wired or wireless communication links. There is a surge of big volume of data
    traffic generated from MIoT. The MIoT data is featured with large volume, heterogeneous
    types (i.e., structured, semi-structured, unstructured) and is generated in a
    real-time fashion. The analytics of MIoT data can bring many benefits, such as
    improving factory operation and production, reducing machine downtime, improving
    product quality, enhancing supply chain efficiency and improving customer experience
    (Zhong et al. ( 2017), Lade, Ghosh, and Srinivasan ( 2017), Tao et al. ( 2018)).
    However, there are also many challenges in data analytics in MIoT in the different
    phases of the whole life cycle of data analytics. There are several surveys on
    data analytics in the manufacturing industry. The work of Tao et al. ( 2018) proposes
    a data-driven smart manufacturing framework and provides several application scenarios
    based on this conceptual framework. The necessities of big data analytics in smart
    manufacturing are summarised in Kusiak ( 2017). The work of Lade, Ghosh, and Srinivasan
    ( 2017) provides an overview on data analytics in manufacturing with a case study.
    Tao and Qi presents an overview of service-oriented manufacturing in Tao and Qi
    ( 2019). However, most of the aforementioned studies lack of the introduction
    of enabling technologies corresponding to the challenges, which are of interest
    to both academic researchers and industrial practitioners. Therefore, the aim
    of this paper is to provide an overview on data analytics in MIoT from opportunities,
    challenges and enabling technologies. The main contributions of this paper can
    be summarised as follows. We provide a summary on key characteristics of MIoT
    and a life cycle of big data analytics for MIoT data. We also discuss the necessities
    and challenges of big data analytics in MIoT. We present an overview on enabling
    technologies of big data analytics for MIoT from the aspects of data acquisition,
    data preprocessing and data analytics. We given an outline of future research
    directions in aspects of security, privacy, fog computing and new data analytics
    methods. The rest of this paper is organised as follows. Section 2 gives the discussion
    on necessities and challenges of big data analytics in MIoT. Section 3 introduces
    enabling technologies of big data analytics in MIoT. Section 4 discusses the future
    research directions. Finally, this paper is concluded in Section 5. 2. Necessities
    and challenges of big data analytics for manufacturing Internet of things In this
    section, we first introduce the key characteristics of Manufacturing Internet
    of Things in Section 2.1. We then introduce the life cycle of big data analytics
    for MIoT in Section 2.2. We next discuss the necessities of big data analytics
    for MIoT in Section 2.3 and the challenges in Section 2.4. 2.1. Key characteristics
    of manufacturing internet of things In this paper, we roughly categorise IoT into
    consumer Internet of Things (CIoT) and Manufacturing Internet of Things (MIoT).
    Table 1 compares MIoT with CIoT. In contrast to MIoT, CIoT mainly serve for consumers.
    Hence, CIoT mainly consists of consumer devices (e.g., smart phones, wearable
    electronics) and smart appliances (e.g., refrigerators, TVs, washing machines).
    CIoT mainly aims to improve the user experience while MIoT mainly focuses on improving
    factory operations and production, reducing the machine downtime and improving
    product quality. Moreover, MIoT usually works in a harsh industrial environment
    (like vibrated, noisy and extremely high/low temperature) while CIoT works in
    moderate environment. In addition, MIoT applications usually require high data-rate
    network connection with a low delay while CIoT applications have relaxed requirement
    on the network connection. Furthermore, MIoT systems are usually mission-critical
    and sensitive to system failure or machinery downtime while CIoT systems are non-mission-critical.
    Table 1. Comparison between MIoT and CIoT Download CSVDisplay Table In this paper,
    we mainly focus on MIoT. The MIoT ensures the connection of various things (smart
    objects) mounted with various electronic or mechanic sensors, actuators, instruments
    and software systems which can sense and collect information from the physical
    environment and then make actions on the physical environment. During this procedure,
    the data analytics plays an important role in extracting informative values, forecasting
    the coming events and predicting the increment/decrements of products. 2.2. Life
    cycle of big data analytics for MIoT We first introduce the life cycle of big
    data analytics for MIoT. Figure 1 shows that the life cycle of big data analytics
    for MIoT consists of three consecutive stages: 1) Data Acquisition, 2) Data Preprocessing
    and Storage, 3) Data Analytics. There are other taxonomies (Hu et al. ( 2014),
    Casado and Younas ( 2015), Tao et al. ( 2018)). We categorise the life cycle of
    big data analytics into the above three stages since this taxonomy can accurately
    capture the key features of big data analytics in MIoT. Figure 1. Life cycle of
    big data analytics for MIoT Display full size Data acquisition consists of data
    collection and data transmission. Firstly, data collection involves acquiring
    raw data from various data sources in the whole manufacturing process via dedicated
    data collection technologies. For example, RFID tags are scanned by RFID readers
    in the product warehouse. Then, the collected data will be transmitted to the
    data storage system through either wired or wireless communication systems. Details
    about enabling technologies of data acquisition are given in Section 3.1. Data
    preprocessing and storage. After data collection, the raw data needs to be preprocessed
    before keeping them in data storage systems because of the big volume, redundancy,
    uncertainty features of the raw data Lade, Ghosh, and Srinivasan ( 2017). The
    typical data preprocessing techniques include data cleaning, data integration
    and data compression. Data storage refers to the process of storing and managing
    massive data sets. We divide the data storage system into two components: storage
    infrastructure and data management software. The infrastructure not only includes
    the storage devices but also the network devices connecting the storage devices
    together. In addition to the networked storage devices, data management software
    is also necessary to the data storage system. Details about enabling technologies
    of data preprocessing and data storage are given in Section 3.2. Data analytics.
    In data analysis phase, various data analytical schemes are used to extract valuable
    information from the massive manufacturing data sets. We roughly categorise the
    data analytical schemes into four types: (i) statistic modelling, (ii) data visualization
    (iii) data mining and (iv) machine learning. Details about enabling technologies
    of data analysis are presented in Section 3.3. 2.3. Necessities of big data analytics
    for MIoT There is an enormous amount of data generated from the whole manufacturing
    chain consisting of raw material supply, manufacturing, product distribution,
    logistics and customer support, as shown in Figure 1. Such ‘big data’ needs to
    be extensively analysed so that some valuable and informative information can
    be extracted. We summarise the reasons of big data analytics for MIoT as follows:
    Improving factory operations and production. The predictive analytics of manufacturing
    data and customer demand data can help to improve machinery utilization consequently
    enhancing factory operations. For example, the demands for certain products are
    often related to weather or seasonal conditions (e.g., down coats related to the
    cold weather). Forecasting a cold wave can be used to make the pro-active allocation
    of machinery resources and pre-purchasing raw materials to fulfil the upsurge
    demands. Reducing machine downtime. The prevalent sensors deployed throughout
    the whole production line can collect various data reflecting machinery status.
    For example, the analysis of machinery health data can help to identify the root
    cause of failure consequently reducing machine downtime Lade, Ghosh, and Srinivasan
    ( 2017). Moreover, the sensory data from the automatic assembly line can also
    be used to determine the excessive load of machines so as to balance the loads
    among multiple machines Wang et al. ( 2018a). Improving product quality. On one
    hand, the analysis of market demand and customer requirement can be used to improve
    the product design in reflecting product improvements. During the product manufacturing
    procedure, the analysis of manufacturing data can help to reduce the ratio of
    defective goods by identifying the root cause. As a result, the product quality
    can be improved. Enhancing supply chain efficiency. The proliferation of various
    sensors, RFID and tags during supplier, manufacturing and transportation generates
    massive supply chain data, which can be used to analyse supply risk, predict delivery
    time, plan optimal logistic route, etc. Moreover, the analysis of inventory data
    can reduce the holding costs and fulfill the dynamic demands by establishing safety
    stock levels. In addition, big data analytics on IoT-enabled intelligent manufacturing
    shops Zhong et al. ( 2017) can also help to make accurate logistic plan and schedules.
    As a result, the system efficiency can be greatly improved. Improving customer
    experience. Companies can obtain customer data from various sources, such as sales
    channels, partner distributors, retailers, social media platforms. Then, big data
    analytics on customer data offers descriptive, predictive and prescriptive solutions
    to enable companies to improve product design, quality, delivery, warrant and
    after-sales support. As a result, the customer experience can be improved. For
    example, the IoT data in the whole food supply-chain is also beneficial to prevent
    mischievous actions and guarantee food safety Leng et al. ( 2018b). 2.4. Challenges
    of big data analytics for MIoT MIoT data has the following characteristics: (1)
    massive volume, (2) heterogeneous data types, (3) being generated in real-time
    fashion and (4) bringing huge both business value and social value. The unique
    features cause the research challenges in big data analytics for MIoT. We summarise
    the challenges in the following aspects. 1. Challenges in data acquisition Data
    acquisition addresses the issues including data collection and data transmission,
    during which there are the following challenges. Difficulty in data representation.
    MIoT data have different types, heterogeneous structures and various dimensions.
    For example, manufacturing data can be categorised into structured data, semi-structured
    and unstructured data Tao et al. ( 2018). How to represent these structured, semi-structured
    and un-structured data becomes one of the major challenges in big data analytics
    for MIoT. Efficient data transmission. How to transmit the tremendous volumes
    of data to data storage infrastructure in an efficient way becomes a challenge
    due to the following reasons: (i) high bandwidth consumption since the transmission
    of big data becomes a major bottleneck of wireless communication systems Hu et
    al. ( 2014); (ii) energy efficiency is one of the major constraints in many wireless
    industrial systems, such as industrial wireless sensor networks Azoidou et al.
    ( 2017). 2. Challenges in data preprocessing and storage Data generated from MIoT
    leads to the following research challenges in data preprocessing. Data integration.
    Data generated in MIoT has the various types and heterogeneous features. It is
    necessary to integrate the various types of data so that efficient data analytics
    schemes can be implemented. However, it is quite challenging to integrate different
    types of MIoT data. Redundancy reduction. The raw data generated from MIoT is
    characterised by the temporal and spatial redundancy, which often results in the
    data inconsistency consequently affecting the subsequent data analysis. How to
    mitigate the data redundancy in MIoT data becomes a challenge. Data cleaning and
    data compression. In addition to data redundancy, MIoT data is often erroneous
    and noisy due to the defected machinery or errors of sensors. However, the large
    volume of the data makes the process of data cleaning more challenging. Therefore,
    it is necessary to design effective schemes to compress MIoT data and clean the
    errors of MIoT data. Data storage plays an important role in data analysis and
    value extraction. However, designing an efficient and scalable data storage system
    is challenging in MIoT. We summarise the challenges in data storage as follows.
    Reliability and persistency of data storage. Data storage systems must ensure
    the reliability and the persistency of MIoT data. However, it is challenging to
    fulfill the above requirements of big data analytics while balancing the cost
    due to the tremendous amount of data Guerra et al. ( 2011). Scalability. Besides
    the storage reliability, another challenging issue lies in the scalability of
    storage systems for big data analytics. The various data types, the heterogeneous
    structures and the large volume of massive data sets of MIoT lead to the infeasibility
    of conventional databases in big data analytics. As a result, new storage paradigms
    needs to be proposed to support large-scale data storage systems for big data
    analytics. Efficiency. Another concern with data storage systems is the efficiency.
    In order to support the vast number of concurrent accesses or queries initiated
    during the data analytics phase, data storage needs to fulfill the efficiency,
    the reliability and the scalability requirements together, which is extremely
    challenging. 3. Challenges in data analytics It is quite challenging in big data
    analytics for MIoT due to the tremendous volume, the heterogeneous structures
    and the high dimension. The major challenges in this phase are summarised as follows.
    Data temporal and spatial correlation. Different from conventional data warehouses,
    MIoT data is usually spatially and temporally correlated. How to manage the data
    and extract valuable information from the temporally/ spatially correlated MIoT
    data becomes a new challenge. Efficient data mining schemes. The tremendous volume
    of MIoT data leads to the challenge in designing efficient data mining schemes
    due to the following reasons: (i) it is not feasible to apply conventional multi-pass
    data mining schemes due to the huge volume of data, (ii) it is critical to mitigate
    the data errors and uncertainty due to the erroneous features of MIoT data. Privacy
    and security. It is quite challenging to pertain the privacy and ensure the security
    of data during the analytics process. Though there are a number of conventional
    privacy-preserving data analytical schemes, they may not be applicable to the
    MIoT data with the huge volume, heterogeneous structures, and spatio-temporal
    correlations. Therefore, new privacy-preserving data mining schemes need to be
    proposed to address the above issues. 3. Enabling technologies In this section,
    we discuss the enabling technologies of big data analytics in MIoT. According
    to the three phases in the life cycle of big data analytics in MIoT, we roughly
    categorise these technologies into data acquisition, data preprocessing and storage,
    data analytics. In particular, we first discuss the data acquisition-related technologies
    in Section 3.1. We then describe the data preprocessing and storage in Section
    3.2. In Section 3.3, we discuss the data analytics in MIoT. 3.1. Data acquisition
    As shown in Figure 1, the whole manufacturing chain involves with multiple parties
    such as suppliers, manufacturers, distributors, logistics, retailers and customers.
    As a result, different types of data sources generate from each of these sectors.
    Take a manufacturing factory an example. Sensors deployed at the production line
    can collect device data, product data, ambient data (like temperature, humidity,
    air pressure), electricity consumption, etc. In the product warehouse, RFID or
    other tags can help to identify and track products. RFID tags attached at products
    can be read in a short distance by a RFID reader in a wireless manner. The collected
    data can then be transmitted to the next stage via either wired or wireless manner.
    Industrial Ethernet is one of the most typical-wired connections in manufacturing.
    When Ethernet is applied to an industrial setting, more rugged connectors and
    more durable cables are often required to satisfy harsh environment requirements
    (like vibration, noise and temperature). Compared with wired communications, wireless
    communications do not require communication wiring and related infrastructure
    consequently saving the cost and improving scalability. The major obstacle of
    the wide deployment of wireless communications in industrial systems is the lower
    throughput and the higher delay than wired communications. However, the recent
    advances in wireless communications make wireless connections feasible in industrial
    components. Various sensors, RFIDs and other tags can connect with IoT gateways,
    WiFi Access Points (APs), a small base station (BS) and macro BS to form an industrial
    wireless sensor networks (IWSN) Chi et al. ( 2014). It is worth mentioning that
    different wireless technologies have different coverage and bandwidth capabilities.
    Figure 2 gives the comparison of various wireless technologies regarding to coverage
    and bandwidth. In particular, it is shown in Figure 2 that conventional wireless
    technologies like Near Field Communications (NFC), RFID, Bluetooth Low Energy
    (LE), wireless body sensor networks (WBAN), Internet Protocol (IPv6), Low-power
    Wireless Personal Area Networks (6LoWPAN) and Wireless Highway Addressable Remote
    Transducer (WirelessHART) Petersen and Carlsen ( 2011) are suffering from short
    communication range (i.e., most of them can typically cover less than hundreds
    of meters). As a result, they cannot support the wide-coverage industrial applications,
    like smart metering, smart cities and smart grids Xu et al. ( 2017). It is true
    that other wireless technologies such as WiFi (IEEE 802.11) and mobile communication
    technologies (such as 2G, 3G, 4G networks) can provide longer coverage range while
    they often require high energy consumption at handsets, whereas most of sensor
    nodes have the limited energy (i.e., supplied by batteries). Therefore, WiFi and
    other mobile communication technologies may not be feasible in IWSN due to the
    high energy consumption. Figure 2. Wireless communication technologies for MIoT
    (figure is not scalable) Display full size Recently, Low Power Wide Area Networks
    (LPWAN) essentially provide a solution to the wide coverage demand while saving
    energy. Typically, LPWAN technologies include Sigfox, LoRa, Narrowband IoT (NB-IoT)
    Mekki et al. ( 2018). LPWAN has lower power consumption than WiFi and mobile communication
    technologies. Take NB-IoT as an example. It is shown in Xu et al. ( 2017) that
    an NB-IoT node can have a ten-year battery life. Moreover, LPWAN has a longer
    communication range than RFID, bluetooth and 6LoWPAN. In particular, LPWAN technologies
    have the communication range from 1 km to 10 km. Furthermore, they can also support
    a large number of concurrent connections (e.g., NB-IoT can support 52,547 connections
    as shown in Xu et al. ( 2017)). However, one of the limitations of LPWAN technologies
    is the low data rate (e.g., NB-IoT can only support a data rate upto 250 kps).
    Therefore, LPWAN technologies should complement with conventional RFID, 6LoWPAN
    and other wireless technologies so that they can support the various data acquisition
    requirements. 3.2. Data preprocessing and storage 3.2.1. Data preprocessing Data
    acquired from MIoT have the following characteristics: Heterogeneous data types.
    The whole manufacturing chain generates various data types including sensory data,
    RFID readings, product records, text, logs, audio, video, etc. The data is in
    the forms of structured, semi-structured and non-structured. Erroneous and noisy
    data. The data obtained from the industrial environment is often erroneous and
    noisy mainly due to the following reasons: (a) interference during the process
    of data collection especially in industrial environment, (b) the failure and malfunction
    of sensors or machinery, (c) intermittent loss or outage of wireless or wired
    communications Siddiqa et al. ( 2016). For example, wireless communications are
    often susceptible to harsh industrial environmental factors like blockage, shadowing
    and fading effects. Moreover, data transmission may fail in industrial WSNs due
    to the depletion of batteries of sensors or machinery. Data redundancy. Data generated
    in MIoT often contain excessively redundant information. For instance, it is shown
    in Ertek, Chi, and Zhang ( 2017) that there are excessive-duplicated RFID readings
    when multiple RFID tags were scanned by several RFID readers at different time
    slots. The data redundancy often results in data inconsistency. Data preprocessing
    approaches on MIoT data includes data cleaning, data integration and data compression
    as shown in Figure 3. In industrial environment, sensory data is usually uncertain
    and erroneous due to the depletion of battery power of sensors, imprecise measurement
    of sensors and communication failures. There are several approaches proposed to
    address these issues. For example, Zhong et al. ( 2015) proposed RFID-Cuboids
    approach to remove redundant readings and eliminate the missing values. Moreover,
    an Indoor RFID Multi-variate Hidden Markov Model (IR-MHMM) was proposed to determine
    uncertain data and remove duplicated RFID readings as shown in Baba et al. ( 2017).
    Furthermore, a machine-learning-based method was proposed to filter out the invalid
    RFID readings Ma, Wang, and Wang ( 2018). In addition, the study of Bhandari et
    al. ( 2017)proposed an auto-correlation-based scheme to remove duplicated time-series
    temperature data. In Tasnim, Pissinou, and Iyengar ( 2017), a novel data cleaning
    mechanism was proposed to clean erroneous data in environmental sensing applications.
    Besides duplicated readings, there also exist missing values in MIoT data. In
    Zheng et al. ( 2018), an interpolation method was proposed to recover the missing
    values of smart grids data. Moreover, energy-saving is a critical issue in data-cleaning
    algorithms used in MIoT. In Deng et al. ( 2018), an energy-efficient data-cleaning
    scheme was proposed. Figure 3. Data preprocessing techniques Display full size
    3.2.2. Data storage Data storage plays an important role in big data analytics
    for MIoT. We summarise the solutions of data storage in two aspects: 1) storage
    infrastructure and 2) data management software. Storage infrastructure consists
    of a number of interconnected storage devices. Storage devices typically include:
    magnetic Harddisk Drive, Solid-State Drives, magnetic taps, USB flash drives,
    Secure Digital (SD) cards, micro SD cards, Read-Only-Memory (ROM), CD-ROMs, DVD-ROMs,
    etc. These storage devices can be connected together (via wired or wireless connections)
    to form the storage infrastructure for MIoT in an industrial environment. Besides
    storage infrastructure, data management software plays an important role in constructing
    the scalable, effective, reliable storage system to support big data analytics
    in MIoT. As shown in Figure 1, the data management software consists of three
    layered components: Distributed file systems. Google File System (GFS) was proposed
    and developed by Google Ghemawat, Gobioff, and Leung ( 2003) to support the large
    data-intensive distributed applications such as search engine. Moreover, Hadoop
    Distributed File System (HDFS) was proposed by Apache Shvachko et al. ( 2010)
    as an alternative to GFS. In addition, there are other distributed file systems,
    such as C# Open Source Managed Operating System (Cosmos) proposed by Microsoft
    Chaiken et al. ( 2008), Xtreem FS Hupfeld et al. ( 2008) and Haystack proposed
    by Facebook Beaver et al. ( 2010). Most of them can partially or fully support
    the storage of large-scale data sets. Therefore, most of them can offer the support
    for large-scale data storage of MIoT data. Database management systems (DBMS).
    DBMS offers a solution to organize the data in an efficient and effective manner.
    DBMS software tools can be roughly categorized into two types: traditional relational
    DBMS (aka SQL databases) and non-relational DBMS (aka Non-SQL databases). SQL
    databases have been a primary data management approach, especially useful to Material
    Requirements Planning (MRP), Supply Chain Management (SCM), Enterprise Resource
    Planning (ERP) in the whole manufacturing chain. Typical SQL databases including
    commercial databases, such as Oracle, Microsoft SQL server and IBM DB2, and open-source
    alternatives, such as MySQL, PostgreSQL and SQLite. SQL databases usually store
    data in tables of records (or rows). This storage method nevertheless leads to
    the poor scalability of databases. For example, when data grows, it is necessary
    to distribute the load among multiple servers. One of the benefits of SQL databases
    is that most of SQL databases can guarantee ACID (Atomicity, Consistency, Isolation,
    Durability) properties of database transactions, which is crucial to many commercial
    applications (e.g., ERP and inventory management). Different from SQL databases,
    NoSQL databases support various types of data, such as records, text, and binary
    objects. Compared with traditional relational databases, most of NoSQL databases
    are usually highly scalable and can support the tremendous amount of data. Therefore,
    NoSQL databases are promising in managing sensory data, device data, RFID trajectory
    data in MIoT Lade, Ghosh, and Srinivasan ( 2017). Distributed computing models.
    There are a number of distributed computing models proposed for big data analytics.
    For example, Google MapReduce Dean and Ghemawat ( 2008) is one of the typical
    programming models used for processing large data sets. Hadoop MapReduce Apache
    ( 2014) is the open-source implementation of Google MapReduce. MapReduce is suffering
    from the lack of iterations or recursions, which are however required by many
    data analytics applications, such as data mining, graph analysis and social network
    analysis. There are some extensions to MapReduce to address this concern, including
    HaLoop Bu et al. 2010), Berkeley Orders of Magnitude (BOOM) Analysis Alvaro et
    al. ( 2010), Twister Ekanayake et al. ( 2010), iHadoop Elnikety, Elsayed, and
    Ramadan ( 2011) and iMapReduce Zhang et al. ( 2012). In addition to MapReduce,
    there are other alternatives such as Dryad Isard et al. ( 2007), Nephele/PACTs
    system Battré et al. ( 2010), Spark Zaharia et al. ( 2010), Pregel Malewicz et
    al. ( 2010), Hive Thusoo et al. ( 2010), GraphLab Low et al. ( 2012). Virtual
    machines and containers. Virtual machines (VMs) have been widely used to support
    cloud computing. Through virtualization, multiple VMs can be emulated on a single
    computer system. VMs can help to achieve the isolation of multiple virtual operating
    systems, on top of which multiple applications can be supported. Different from
    VMs, containers run on top of a single operating system and a single hardware
    while containers separate the applications as well as the underneath binary and
    library files. Therefore, containers can achieve the lightweight virtualization,
    consequently resulting in the super fast booting speed, small size, less resource
    consumption (compared with VMs). The lightweight features of containers lead to
    the feasibility to edge computing scenarios (to be illustrated in Section 3.4).
    3.3. Data analytics 3.3.1. Typical data analytics approaches Typical data analytics
    approaches include: 1) Statistical modelling schemes, 2) Data mining schemes,
    3) Machine-learning schemes and 4) Data visualisation. Statistical modelling methods
    are mainly based on statistical theory. There are three types of statistical methods:
    (i) descriptive statistics that is used to quantify relationships in data Trochim,
    Donnelly, and Arora ( 2016); (ii) inferential statistics that is used to deduce
    generalisations from the sample data sets Bandyopadhyay and Forster ( 2011); (iii)
    stochastic modeling methods can capture the dynamic features of data traffic,
    predict user mobility and track objects (Newson and Krumm ( 2009), Liao et al.
    ( 2018)). Data mining is the process of extracting useful information from massive
    data sets. There are a wide variety of data mining algorithms that can be used
    in MIoT such as Apriori algorithm, Frequent Pattern Growth (FP-Growth) algorithm,
    Density-based spatial clustering of applications with noise (DBSCAN), Generalised
    Sequential Pattern (GSP), Sequential Pattern Discovery Using Equivalent Class
    (SPADE) and Prefix-Projected Sequential Pattern Mining (PrefixSpan) Han, Kamber,
    and Pei ( 2012). Machine learning explores to construct self-adaptive algorithms
    that can learn from existing data and perform predictive analysis. As one of the
    typical applications of machine learning, data mining has an emphasis on extracting
    valuable information from data. Typical Machine learning algorithms include support
    vector machines (SVMs) Vapnik ( 1995), naive Bayes Wu et al. ( 2008), Decision
    tree learning Russell and Norvig ( 2009), k -Nearest Neighbors ( k -NN) Altman
    ( 1992), hidden Markov model, Bayesian networks Qiu et al. ( 2016), neural networks
    Zhang ( 2000), Ensemble methods Zhou ( 2012), k-means Kanungo et al. ( 2002),
    singular value decomposition (SVD), Principal Component Analysis (PCA) Jolliffe
    ( 2002) and reinforcement learning algorithms such as Q-learning Russell and Norvig
    ( 2009). 3.3.2. Taxonomy of data analytics approaches in MIoT We next present
    an overview of data analytics in MIoT in the aspect of MIoT applications. In particular,
    data analytics methods in MIoT can be roughly categorised into: 1) Descriptive
    analytics, 2) Diagnostic analytics, 3) Predictive analytics, 4) Prescriptive analytics.
    This classification can better represent the data analytics in MIoT applications
    in different levels of complexity and extracted values. Figure 4 depicts different
    levels of data analytics methods in MIoT applications. Both descriptive and diagnostic
    analytics methods are reactive while predictive and prescriptive analytics approaches
    are proactive. Moreover, prescriptive and predictive analytics approaches are
    more complicated than descriptive and diagnostic analytics methods though they
    can bring more values than descriptive and diagnostic analytics. We then present
    an overview of existing studies in the four levels of data analytics. Figure 4.
    Data analytics Display full size (1) Descriptive analytics Descriptive analytics
    is an exploratory analysis of historical data to tell what happened. During this
    stage, most of data mining and statistic methods can be used to reveal the data
    characteristics, recognise patterns and identify relationships of data objects.
    Descriptive analytics can be used in the whole life cycle of manufacturing data.
    In particular, a real-time monitoring system was proposed in Zhang et al. ( 2015)
    to track the different manufacturing resources. Zhong et al. ( 2016) proposed
    RFID-Cuboid framework to integrate production logistic data with RFID data and
    offered a system prototype to visualise logistic trajectory data. Moreover, the
    study of Zuo, Tao, and Nee ( 2018) presented a cloud-based approach to evaluate
    the energy consumption during the product manufacturing process. In addition,
    air-qualtiy monitoring system based on wireless sensor networks at a logistics
    shipping base was proposed in Molka-Danielsen, Engelseth, and Wang ( 2018). (2)
    Diagnostic analytics Diagnostic analytics is a deeper look at data to attempt
    to understand the causes of events and behaviours. The diagnostic analysis of
    machines and other equipments can help to identify the possible faults and predict
    the failures to reduce the machine down-times. For example, a method of integrating
    SVM and artificial neural network (ANN) was presented to detect and diagnose machinery
    faults of centrifugal pumps Azadeh et al. ( 2013). The study of Wang et al. (
    2016) proposed fault detection methods for propeller ventilation of vessels based
    on the Kalman filter. Wuest et al. put forth a surpervised maching learning method
    to monitor product quality in Wuest, Irgens, and Thoben ( 2014). Compared with
    supervised machine-learning methods, unsupervised learning methods require less
    feature engineering efforts in obtaining features consequently saving the time
    and the labour. In Lei et al. ( 2016), a two-stage unsupervised learning method
    was proposed to conduct a diagnostic analysis of machine faults. In addition to
    fault diagnosis, anomaly detection (or outlier detection) is to identify data
    objects that do not comply with an expected pattern as given. In Zheng et al.
    ( 2018), a deep learning-based method was proposed to detect electric theft via
    anomaly detection of electricity consumption data in smart grids. (3) Predictive
    analytics Predictive analytics mainly utilises historical data to anticipate the
    trends of data (i.e., what will occur in the future). In Wu et al. ( 2017a), a
    random forests (RFs) based method was proposed to predict the tool (machine) wear
    in the manufacturing cycle. It is also shown in Wu et al. ( 2017a) that RFs method
    outperforms ANN and SVMs in terms of prediction accuracy. One of the challenges
    in data analytics of MIoT data is the imbalanced number of negative and postive
    samples Lade, Ghosh, and Srinivasan ( 2017). The study of Kim et al. ( 2017) proposed
    a cost-sensitive decision tree ensemble algorithm to address this issue. Extensive
    experimental results show that the proposed method outperforms other existing
    baseline methods. Moreover, in Ren, Hung, and Tan ( 2018), a deep-learning-based
    method was proposed to predict product surface defects. In addition, consumer
    behaviour prediction plays an important role in manufacturing business stage,
    e.g., to improve the consumers’ purchase decision-making predictions. In Zuo (
    2016), a Bayesian network-based approach was proposed to predict the customer
    purchase behaviour. In particular, the analysis is based on massive RFID data,
    which was collected through RFID tags attached at customers. (4) Prescriptive
    analytics Prescriptive analytics extends the results of descriptive, diagnostic
    and predictive analytics to make the right decisions in order to achieve predicted
    outcomes (i.e., what should we do to achieve the goal?). The prescriptive methods
    typically include simulation, decision-making, optimisation and reinforcement
    learning algorithms. In particular, in Gerlach, Hass, and Mandenius ( 2015), a
    conceptual design approach was proposed to simulate the configuration and procedural
    training in a bio-ethanol plant. The study of Mourtzis et al. ( 2016) presents
    a novel method for manufacturing-networks design via intelligent decision-making
    on selecting suppliers to fulfil the requirements of frugal innovation. In Kluczek
    ( 2016), an analytic hierarchy process (AHP) based method was proposed to evaluate
    manufacturing sustainability performance. Moreover, in Drakaki and Tzionas( 2017),
    a novel method with the integration of Timed Colored Petri Nets (CTPNs) and reinforcement
    learning (RL) was proposed to solve the problem of manufacturing scheduling. Table
    2 summarises the data analytics methods used for MIoT. We categorise them into
    four types according to different levels in terms of complexity and extracted
    values. Moreover, we also enumerate representative data analytics methods in each
    category. In addition, we also list representative application cases in each category.
    Table 2. Classification of data analytics approaches in MIoT Download CSVDisplay
    Table 3.3.3. Data visualisation in MIoT In addition to the aforementioned data
    analytics, data visualisation is also an important tool in MIoT data. Effective
    data visualisation procedure can help to extract and interpret the informative
    values from complex and high-dimensional MIoT data Telea ( 2014). Typical data
    visualisation methods include information visualisation, exploratory data analysis,
    statistic plots. The typical quantitative messages that are conveyed by data visualisation
    include: time-series, ranking, frequency distribution, deviation, correlation,
    part-to-whole, geographic Post, Gregory M, and Bonneau ( 2003). The basic data
    visualisation techniques include: 1) various statistic plots (e.g., bar chart,
    histogram, pie diagram, scatter plots), 2) word clouds of text data, 3) correlation
    coefficient matrices/functions, 4) network/graph diagrams of non-structural data,
    5) heat map of geographic data. Typical data visualisation toolboxes include Matlab
    plot (https://it.mathworks.com/help/matlab/ref/plot.html), gnuplot (http://www.gnuplot.info/),
    Python’s Seaborn (https://seaborn.pydata.org/), Pandas plot (https://pandas.pydata.org/),
    Matplotlib (https://matplotlib.org/). Moreover, web-based visualisation tools
    have also been wide used. Representative web-based data visualisation tools include
    Tableau (https://www.tableau.com/), Plotly (https://plot.ly/), Sisense (https://www.sisense.com/),
    D3.js (https://d3js.org/). 3.4. Case studies To demonstrate the feasibility of
    distributed computing models in MIoT, we developed a system prototype. Figure
    5(a) shows that the system framework consists of a production line, industrial
    devices and computing units. In particular, the production line consists of various
    manufacturing devices, instruments, sensors, actuators and robot arms, all of
    which are connected through wired or wireless links consequently forming the MIoT.
    In addition to the production line and industrial devices, there are a number-computing
    units supporting diverse data processing tasks. For example, edge computing servers
    with equipped with embedded computers are deployed in the proximity to MIoT. Moreover,
    the computing-intensive tasks may be uploaded to the remote cloud servers while
    the latency-sensitive tasks may be processed at edge servers. Figure 5. Case study
    for distributed computing models for MIoT Display full size In the computing perspective,
    we develop a distributed computing platform with the orchestration of remote cloud
    computing and local edge computing. In particular, we deploy Xen hypervisor at
    remote cloud servers and Docker container at edge servers. On top of virtual machines,
    we further utilise Hadoop distributed computing platforms to support big data
    processing tasks. In order to coordinate the edge and cloud computing tasks, we
    design and implement a hybrid edge/cloud computing framework (details can be referred
    to our work Li et al. ( 2019)). Figure 5(b) gives the realistic prototype of a
    printed circuit board (PCB) production line based on our proposed system framework.
    This production line consists of conveyor belts, product feeding machines, robot
    arms, sensors and cameras. We choose industrial WLANs as the wired connections
    and 6LoWPAN as the wireless connections. In addition, we adopt four edge servers,
    each of which has the identical configurations: a single-board computer with a
    quad-core Broadcom BCM2837 CPU, 1GB memory and 64GB SSD storage. Furthermore,
    there is a remote cloud server (i.e., IBM X3650 M3) with 2 Intel Xeon Processors,
    24 GB memory and 1TB SSD storage. We then evaluate the performance of the proposed
    hybrid edge/cloud computing framework on top of the prototype. In particular,
    we consider a pure cloud computing framework and a pure edge computing framework
    as baseline models. Moreover, image recognition tasks with varied image size were
    chosen to be executed at edge and cloud servers. We further adopt OpenCV frameworks
    on both edge and cloud servers to support the image recognition tasks. Table 3
    shows the latency values of three computing frameworks versus varied image sizes.
    In particular, the latency is calculated via averaging results with 100 images,
    each with the same image size (e.g., 10 MB). It is shown in Table 3 that the average
    latency is increased with the increased image size; this effect may owe to the
    increased computational complexity of image recognition algorithms with the increased
    image size. We also observe from Table 3 that the proposed hybrid cloud and edge
    scheme outperforms pure cloud computing scheme and pure edge computing scheme
    with larger image size (e.g., 16 MB, 18 MB and 20 MB). It can be explained as
    follows: 1) pure cloud computing has the strength in processing large images while
    suffering from the long end-to-end latency; 2) pure edge computing scheme can
    complete the computing tasks with smaller image size (e.g., 12 MB) and achieve
    the short end-to-end latency due to the deployment proximity; 3) hybrid edge/cloud
    computing scheme cannot only exploit the strength of cloud computing to process
    the complicated tasks but also harness the benefit of edge computing in short
    latency, consequently obtaining the better performance in the cases with larger
    image size. Table 3. Performance evaluation Download CSVDisplay Table 4. Future
    research directions In this section, we discuss open issues as well as future
    directions in big data analytics for MIoT. Figure 6 summarises the future directions
    in big data analytics in MIoT. Figure 6. Future directions in big data analytics
    of MIoT Display full size 4.1. Security and privacy concerns Privacy and security
    are becoming an arising challenge of big data analytics for MIoT. Privacy concerns
    the proper utilisation of the data with the preservation of enterprise private
    information, whereas security is to ensure data confidentiality, integrity and
    availability Wang et al. ( 2018b). We next summarise the research issues related
    to privacy and security in big data analytics for MIoT. Security assurance in
    data acquisition. The proliferation of wireless connections in manufacturing industry
    results in the challenges in security assurance during data acquisition because
    of the openness of wireless medium susceptible to malicious attacks like passive
    eavesdropping attacks Li et al. ( 2018). The typical countermeasure is to apply
    encryption schemes in wireless networks Hennebert and Santos ( 2014). However,
    it may not be feasible to apply cryptography-based techniques in all IoT networks
    due to the following constraints: the inferior computational capability and the
    limited battery power of some smart objects like RFID and sensors. Therefore,
    new protection schemes without strong computational complexity and high energy
    consumption shall be developed for MIoT in the future. Privacy preservation and
    security assurance in data preprocessing and storage. After data acquisition,
    MIoT data will be preprocessed and stored locally (at servers of factories or
    other departments) or remotely (at remote cloud servers) (Wang, Gao, and Fan (
    2015)). However, the distribution of MIoT data throughout the enterprise consisting
    of multiple manufacturing sites across different regions often results in the
    vulnerability to various malicious attacks from insiders and outsiders of the
    enterprise. It is challenging to offer a solution against malicious attacks. There
    are several possible directions in solving this issue: 1) Proper key management
    (Esposito et al. ( 2016)) including proper key distribution and key validation
    period, 2) authentication mechanism including accessing control of files and data
    records, 3) traceability of data accessing allowing any data accessing or modification
    to be identifiable so that the malicious behaviours can be avoided or revoked.
    Privacy preservation in data analytics. In order to protect data privacy, the
    data is often encrypted and stored at a server (or at a cloud). Before data analytics,
    the data needs to be decrypted. However, the decryption process is often time-consuming
    consequently resulting in the inefficiency of data analytics in MIoT. How to design
    a privacy-preservation scheme of balancing the efficiency and privacy becomes
    a challenge Wang et al. ( 2018b), Babar et al .( 2019). 4.2. Edge computing for
    big data analytics in MIoT The integration of cloud computing with manufacturing
    brings the opportunities in saving the capital investments of information and
    communication technologies (ICT), providing the flexibility of ICT resources to
    small and medium enterprises (Wang, Gao, and Fan ( 2015), Esposito et al. ( 2016)).
    However, there are also limitations with cloud computing such as high latency,
    performance bottleneck, single-point-to-failure and privacy leakage Liu et al.
    ( 2017). Recently, mobile edge computing (or fog computing) have become a new
    complement to cloud computing by offloading both computational and storage tasks
    from remote cloud servers to local edge servers (Tran et al. ( 2017),Wu et al.
    ( 2017b), Wang et al. ( 2017)). In this manner, the computing-intensive and delay-tolerant
    tasks will be executed at remote cloud servers while the delay-critical and computing
    less-intensive tasks will be offloaded to edge servers. As a result, the real-time
    tasks like sensing, monitoring and controlling can be enabled in the proximity
    to factories and enterprises. The case study in Section 3.4 also demonstrates
    the effectiveness of hybrid edge and cloud computing in MIoT. However, there are
    many challenges in edge computing for big data analytics in MIoT. Collaboration
    between cloud and edge servers. There are diversity of computing resources in
    manufacturing networks. For example, remote cloud servers usually have superior
    computing capability than local edge servers while there is a longer delay to
    upload the tasks to the remote cloud servers than to upload the tasks to the local
    edge servers Therefore, it is necessary to determine how to allocate the computational
    tasks at cloud servers or at edge servers. For example, the computing intensive
    and delay-tolerant tasks should be uploaded to remote cloud servers while the
    computing less-intensive and delay-critical tasks can be executed locally at edge
    servers. In this sense, edge servers can be deployed within factories and remote
    clouds can be deployed outside factories (even if they can be provided by third
    parties). To the best of our knowledge, there are few studies on investigating
    collaboration between cloud and edge servers, especially in the whole manufacturing
    network. In the future, research efforts should be done in allocating and coordinating
    various computing resources distributed in cloud and edge servers in manufacturing.
    Design lightweight data analytics methods for MIoT. Many data analytics tasks
    that are delay-critical should be executed locally at edge servers (or at manufacturing
    devices). However, due to the resource limitation of edge severs, the conventional
    data analytics methods might be too complicated to be executed at edge servers.
    Therefore, the models of the data analytics methods need to be trained at remote
    cloud servers first and be transferred at local edge servers. However, it can
    result in huge communication cost to transmit this model from the remote cloud
    servers to the edge servers. For example, the study of Lin et al. ( 2018) shows
    that AlexNet (i.e., a typical deep-learning method) has the model size of 240MB,
    which is so large that it can cause an extra delay from the cloud server to the
    edge server. Therefore, it is necessary to design lightweight data analytics schemes
    which can be deployed locally at edge servers approximate to users Leng et al.
    ( 2018a). 4.3. New data analytics methods for MIoT data Although a lot of efforts
    have been done in developing data analytics methods for MIoT data, there are still
    many open research issues in this area. Imbalanced data samples. Different from
    data analytics in traditional fields (e.g., commercial database systems), manufacturing
    data has the imbalanced number of data samples between positive and negative samples.
    For example, it is shown in Lade, Ghosh, and Srinivasan ( 2017) that the ratio
    of positive samples to negative samples (vice versa) can be 99,000,000 to 1. It
    is challenging to apply conventional data analytics methods to analyse the imbalanced
    dataset. Therefore, new data analytics methods should be developed to solve this
    issue. To the best of our knowledge, there are few studies Kim et al. ( 2017)
    proposed to address this issue. Stream data processing. In MIoT, there is a tremendous
    volume of real-time data generated (e.g., sensory data from industrial wireless
    sensor networks) Wang et al. ( 2018a). It is impossible to store and process the
    entire data in the memory of computers. Consequently, the conventional methods
    requiring saving the whole data sets in memory cannot work in this scenario. It
    is challenging to analyse the massive data-stream of MIoT. It is worthwhile to
    investigate new data analytics approaches to process the data-stream of MIoT.
    5. Conclusion This paper presents an in-depth survey on big data analytics in
    manufacturing Internet of Things (MIoT). This paper first presents a life cycle
    of big data analytics in MIoT and discusses the necessities as well as challenges
    of big data analytics in MIoT. Then, the enabling technologies of big data analytics
    in MIoT are summarised according to three phases in the life cycle of big data
    analytics: data acquisition, data preprocessing and storage, and data analytics.
    Moreover, this paper also outlines the future directions and discusses the open
    research issues. We believe big data analytics will play an important role in
    promoting the manufacturing industry to evolve into smart manufacturing in the
    foreseeable future. Disclosure statement No potential conflict of interest was
    reported by the authors. Additional information Funding The research of Hong-Ning
    Dai and Hao Wang is supported by Macao Science and Technology Development Fund
    under Grant No. 0026/2018/A1, National Natural Science Foundation of China (NFSC)
    under Grant No. 61672170, NSFC-Guangdong Joint Fund under Grant No. U1401251,
    and Science and Technology Program of Guangzhou under Grant No. 201807010058.
    Guang quan Xu’s work is supported by the State Key Development Program of China
    (No. 2017YFE0111900), National Science Foundation of China (No. 61572355, U1736115).
    Jiafu Wan’s work is supported by Science and Technology Program of Guangzhou (No.
    201802030005), Guangdong Province Key Areas R & D Program (No. 2019B090919002).
    Muhammad Imran’s work is supported by the Deanship of Scientific Research, King
    Saud University through research group number RG-1435-051. References Altman,
    N. S. 1992. “An Introduction to Kernel and Nearest-Neighbor Nonparametric Regression.”
    The American Statistician 46 (3): 175–185.  Web of Science ®Google Scholar Alvaro,
    P. , T. Condie , N. Conway , K. Elmeleegy , J. M. Hellerstein , and R. Sears .
    2010. “Boom Analytics: Exploring Data-Centric, Declarative Programming for the
    Cloud.” In Proceedings of the 5th European Conference on Computer Systems (EuroSys)
    . Paris  Google Scholar Apache . 2014. “Hadoop MapReduce.” https://hadoop.apache.org/  Google
    Scholar Azadeh, A. , M. Saberi , A. Kazem , V. Ebrahimipour , A. Nourmohammadzadeh
    , and Z. Saberi . 2013. “A Flexible Algorithm for Fault Diagnosis in A Centrifugal
    Pump with Corrupted Data and Noise Based on ANN and Support Vector Machine with
    Hyper-Parameters Optimization.” Applied Soft Computing 13 (3): 1478–1485. doi:10.1016/j.asoc.2012.06.020.  Web
    of Science ®Google Scholar Azoidou, E. , Z. Pang , Y. Liu , D. Lan , G. Bag ,
    and S. Gong . 2017. “Battery Lifetime Modeling and Validation of Wireless Building
    Automation Devices in Thread.” 14 (7): 2869–2880. IEEE Transactions on Industrial
    Informatics.  Web of Science ®Google Scholar Baba, A. I. , L. Hua , T. B. Pedersen
    , and M. Jaeger . 2017. “Cleansing Indoor RFID Tracking Data.” SIGSPATIAL Special
    9 (1): 11–18. doi:10.1145/3124104.3124108.  Google Scholar Babar, M. , F. Arif
    , M. A. Jan , Z. Tan , and F. Khan . 2019. “Urban Data Management System: Towards
    Big Data Analytics for Internet of Things Based Smart Urban Environment Using
    Customized Hadoop.” Future Generation Computer Systems 96: 398–409. doi:10.1016/j.future.2019.02.035.  Web
    of Science ®Google Scholar Bandyopadhyay, P. S. , and M. R. Forster . 2011. Philosophy
    of Statistics . North Holland: Elsevier.  Google Scholar Battré, D. , S. Ewen
    , F. Hueske , O. Kao , V. Markl , and D. Warneke . 2010. “Nephele/PACTs: A Programming
    Model and Execution Framework for Web-Scale Analytical Processing (Socc).” In
    Proceedings of the 1st ACM Symposium on Cloud Computing . Indianapolis, IN.  Google
    Scholar Beaver, D. , H. C. Sanjeev Kumar , J. S. Li , and P. Vajgel . 2010. “Finding
    a Needle in Haystack: Facebook’s Photo Storage.” In Proceedings of the 9th USENIX
    Conference on Operating Systems Design and Implementation (OSDI) .Vancouver, BC.  Google
    Scholar Bhandari, S. , N. Bergmann , R. Jurdak , and B. Kusy . 2017. “Time Series
    Data Analysis of Wireless Sensor Network Measurements of Temperature.” Sensors
    17: 6. doi:10.3390/s17050968.  Web of Science ®Google Scholar Bu, Y. , B. Howe
    , M. Balazinska , and M. D. Ernst . 2010. “HaLoop: Efficient Iterative Data Processing
    on Large Clusters.” Proceedings of the VLDB Endowment 3: 1–2. doi:10.14778/1920841.1920881.  Google
    Scholar Casado, R. , and M. Younas . 2015. “Emerging Trends and Technologies in
    Big Data Processing.” Concurrency and Computation : Practice & Experience 27 (8):
    2078–2091. doi:10.1002/cpe.3398.  Web of Science ®Google Scholar Chaiken, R. ,
    B. Jenkins , P.-Å. Ke Larson , B. Ramsey , D. Shakib , S. Weaver , and J. Zhou
    . 2008. “SCOPE: Easy and Efficient Parallel Processing of Massive Data Sets.”
    Proceedings of the VLDB Endowment 1 (2): 1265–1276. doi:10.14778/1454159.1454166.  Google
    Scholar Chi, Q. , H. Yan , C. Zhang , Z. Pang , and L. D. Xu . 2014. “A Reconfigurable
    Smart Sensor Interface for Industrial WSN in IoT Environment.” IEEE Transactions
    on Industrial Informatics 10 (2): 1417–1425. doi:10.1109/TII.2014.2306798.  Web
    of Science ®Google Scholar Dean, J. , and S. Ghemawat . 2008. “MapReduce: Simplified
    Data Processing on Large Clusters.” Communications of the ACM 51 (1): 107–113.
    doi:10.1145/1327452.  Web of Science ®Google Scholar Deng, C. , R. Guo , C. Liu
    , R. Y. Zhong , and X. Xun . 2018. “Data Cleansing for Energy-Saving: A Case of
    Cyber-Physical Machine Tools Health Monitoring System.” International Journal
    of Production Research 56 (1–2): 1000–1015. doi:10.1080/00207543.2017.1394596.  Web
    of Science ®Google Scholar Drakaki, M. , and P. Tzionas . 2017. “Manufacturing
    Scheduling Using Colored Petri Nets and Reinforcement Learning.” Applied Sciences
    7: 2. doi:10.3390/app7020136.  Google Scholar Ekanayake, J. , L. Hui , B. Zhang
    , T. Gunarathne , S.-H. Bae , J. Qiu , and G. Fox . 2010. “Twister: A Runtime
    for Iterative MapReduce.” In Proceedings of the 19th ACM International Symposium
    on High Performance Distributed Computing (HPDC) . Chicago, IL.  Google Scholar
    Elnikety, E. , T. Elsayed , and H. E. Ramadan . 2011. “iHadoop: Asynchronous Iterations
    for MapReduce.”  Google Scholar Ertek, G. , X. Chi , and A. N. Zhang . 2017. “A
    Framework for Mining RFID Data from Schedule-Based Systems.” IEEE Transactions
    on Systems, Man, and Cybernetics: Systems 47 (11): 2967–2984. doi:10.1109/TSMC.2016.2557762.  Web
    of Science ®Google Scholar Esposito, C. , A. Castiglione , B. Martini , and K.
    K. R. Choo . 2016. “Cloud Manufacturing: Security, Privacy, and Forensic Concerns.”
    IEEE Cloud Computing 3 (4): 16–22. doi:10.1109/MCC.2016.79.  Web of Science ®Google
    Scholar Gerlach, I. , V. C. Hass , and C.-F. Mandenius . 2015. “Conceptual Design
    of an Operator Training Simulator for a Bio-Ethanol Plant.” Processes 3 (3): 664–683.
    doi:10.3390/pr3030664.  Web of Science ®Google Scholar Ghemawat, S. , H. Gobioff
    , and S.-T. Leung . 2003. “The Google File System.” In Proceedings of ACM SOSP
    . Bolton Landing, NY.  Google Scholar Guerra, J. , H. Pucha , J. Glider , W. Belluomini
    , and R. Rangaswami . 2011. “Cost Effective Storage Using Extent Based Dynamic
    Tiering.” In Proceedings of the 9th USENIX Conference on File and Stroage Technologies
    (FAST) . San Jose, CA.  Google Scholar Han, J. , M. Kamber , and J. Pei . 2012.
    Data Mining: Concepts and Techniques . Third ed. Boston, USA: Morgan Kaufmann.  Google
    Scholar Hennebert, C. , and J. D. Santos . 2014. “Security Protocols and Privacy
    Issues into 6lowpan Stack: A Synthesis.” IEEE Internet of Things Journal 1 (5):
    384–398. doi:10.1109/JIOT.2014.2359538.  Web of Science ®Google Scholar Hu, H.
    , Y. Wen , T. S. Chua , and X. Li . 2014. “Toward Scalable Systems for Big Data
    Analytics: A Technology Tutorial.” IEEE Access 2: 652–687. doi:10.1109/ACCESS.2014.2332453.  Web
    of Science ®Google Scholar Hupfeld, F. , T. Cortes , B. Kolbeck , J. Stender ,
    E. Focht , M. Hess , J. Malo , J. Marti , and E. Cesario . 2008. “The XtreemFS
    Architecture&Mdash;a Case for Object-Based File Systems in Grids.” Concurrency
    and Computation: Practice and Experience 20 (17): 2049–2060. doi:10.1002/cpe.1304.  Web
    of Science ®Google Scholar Isard, M. , M. Budiu , Y. Yuan , A. Birrell , and D.
    Fetterly . 2007. “Dryad: Distributed Data-Parallel Programs from Sequential Building
    Blocks.” SIGOPS Operating Systems Review 41 (3): 59–72. doi:10.1145/1272998.  Google
    Scholar Jolliffe, I. T. 2002. Principal Component Analysis . New York, NY: Springer-Verlag.  Google
    Scholar Kanungo, T. , D. M. Mount , N. S. Netanyahu , C. D. Piatko , R. Silverman
    , and A. Y. Wu . 2002. “An Efficient k-Means Clustering Algorithm: Analysis and
    Implementation.” IEEE Transactions on Pattern Analysis and Machine Intelligence
    24 (7): 881–892. doi:10.1109/TPAMI.2002.1017616.  Web of Science ®Google Scholar
    Kim, A. , O. Kyuhyup , J.-Y. Jung , and B. Kim . 2017. “Imbalanced Classification
    of Manufacturing Quality Conditions Using Cost-Sensitive Decision Tree Ensembles.”
    International Journal of Computer Integrated Manufacturing 31 (8): 701–717.  Web
    of Science ®Google Scholar Kluczek, A. 2016. “Application of Multi-Criteria Approach
    for Sustainability Assessment of Manufacturing Processes.” Management and Production
    Engineering Review 7 (3): 62–78. doi:10.1515/mper-2016-0026.  Web of Science ®Google
    Scholar Kusiak, A. 2017. “Smart Manufacturing Must Embrace Big Data.” Nature 544
    (7648): 23. doi:10.1038/544161d.  PubMed Web of Science ®Google Scholar Kusiak,
    A. 2018. “Smart Manufacturing.” International Journal of Production Research 56
    (1–2): 508–517. doi:10.1080/00207543.2017.1351644.  Web of Science ®Google Scholar
    Lade, P. , R. Ghosh , and S. Srinivasan . 2017. “Manufacturing Analytics and Industrial
    Internet of Things.” IEEE Intelligent Systems 32 (3): 74–79. doi:10.1109/MIS.2017.49.  Web
    of Science ®Google Scholar Lei, Y. , F. Jia , J. Lin , S. Xing , and S. X. Ding
    . 2016. “An Intelligent Fault Diagnosis Method Using Unsupervised Feature Learning
    Towards Mechanical Big Data.” IEEE Transactions on Industrial Electronics 63 (5):
    3137–3147. doi:10.1109/TIE.2016.2519325.  Web of Science ®Google Scholar Leng,
    C. , L. Hao , S. Zhu , and R. Jin . 2018a. “Extremely Low Bit Neural Network:
    Squeeze the Last Bit Out with ADMM.” In AAAI . New Orleans, LA.  Google Scholar
    Leng, K. , L. Jin , W. Shi , and I. Van Nieuwenhuyse . 2018b. “Research on Agricultural
    Products Supply Chain Inspection System Based on Internet of Things.” Cluster
    Computing . doi:10.1007/s10586-018-2021-6.  Google Scholar Li, X. , J. Wan , H.
    Dai , M. Imran , M. Xia , and A. Celesti . 2019. “A Hybrid Computing Solution
    and Resource Scheduling Strategy for Edge Computing in Smart Manufacturing.” IEEE
    Transactions on Industrial Informatics (Early Access) 1–9. https://ieeexplore.ieee.org/document/8643392  Web
    of Science ®Google Scholar Li, X. , Q. Wang , H.-N. Dai , and H. Wang . 2018.
    “A Novel Friendly Jamming Scheme in Industrial Crowdsensing Networks against Eavesdropping
    Attack.” Sensors 18 (6): 1–23.  Web of Science ®Google Scholar Liao, Y. , H. Panetto
    , P. C. Stadzisz , and J. M. Simão . 2018. “A Notification-Oriented Solution for
    Data-Intensive Enterprise Information Systems A Cloud Manufacturing Case.” Enterprise
    Information Systems 12 (8–9): 942–959. doi:10.1080/17517575.2018.1470258.  Web
    of Science ®Google Scholar Lin, Y. , S. Han , H. Mao , Y. Wang , and W. J. Dally
    . 2018. “Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed
    Training.” In International Conference on Learning Representations (ICLR) . Vancouver.  Google
    Scholar Liu, H. , F. Eldarrat , H. Alqahtani , A. Reznik , X. de Foy , and Y.
    Zhang . 2017. “Mobile Edge Cloud System: Architectures, Challenges, and Approaches.”
    IEEE Systems Journal PP 99: 1–14.  Google Scholar Low, Y. , D. Bickson , J. Gonzalez
    , C. Guestrin , A. Kyrola , and J. M. Hellerstein . 2012. “Distributed GraphLab:
    A Framework for Machine Learning and Data Mining in the Cloud.” Proceedings of
    the VLDB Endowment 5 (8): 716–727. doi:10.14778/2212351.2212354.  Google Scholar
    Ma, H. , Y. Wang , and K. Wang . 2018. “Automatic Detection of False Positive
    RFID Readings Using Machine Learning Algorithms.” Expert Systems with Applications
    91: 442–451. doi:10.1016/j.eswa.2017.09.021.  Web of Science ®Google Scholar Malewicz,
    G. , M. H. Austern, A. J. C. Bik, J. C. Dehnert, I. Horn, N. Leiser, and G. Czajkowski.
    2010. “Pregel: A System for Large-Scale Graph Processing.” In Proceedings of ACM
    SIGMOD .  Indianapolis, IN.  Google Scholar Mekki, K. , E. Bajic , F. Chaxel ,
    and F. Meyer . 2018. “A Comparative Study of LPWAN Technologies for Large-Scale
    IoT Deployment.” ICT Express .  Google Scholar Molka-Danielsen, J. , P. Engelseth
    , and H. Wang . 2018. “Large Scale Integration of Wireless Sensor Network Technologies
    for Air Quality Monitoring at a Logistics Shipping Base.” Journal of Industrial
    Information Integration 10: 20–28. doi:10.1016/j.jii.2018.02.001.  Web of Science
    ®Google Scholar Mourtzis, D. , E. Vlachou , N. Boli , L. Gravias , and C. Giannoulis
    . 2016. “Manufacturing Networks Design through Smart Decision Making Towards Frugal
    Innovation.” Procedia CIRP 50: 354–359. 26th CIRP Design Conference, Stockholm.
    http://www.sciencedirect.com/science/article/pii/S2212827116304061  Google Scholar
    Newson, P. , and J. Krumm . 2009. “Hidden Markov Map Matching through Noise and
    Sparseness.” In Proceedings of ACM SIGSPATIAL . Seattle, WA.  Google Scholar Petersen,
    S. , and S. Carlsen . 2011. “WirelessHART versus ISA100.11a: The Format War Hits
    the Factory Floor.” IEEE Industrial Electronics Magazine 5 (4): 23–34. doi:10.1109/MIE.2011.943023.  Web
    of Science ®Google Scholar Post, F. H. , N. Gregory M , and G.-P. Bonneau . 2003.
    Data Visualization - the State of the Art . Springer-Verlag.  Google Scholar Qiu,
    J. , W. Qihui , G. Ding , X. Yuhua , and S. Feng . 2016. “A Survey of Machine
    Learning for Big Data Processing.” EURASIP Journal on Advances in Signal Processing
    2016 (1): 1–16.  Google Scholar Ren, R. , T. Hung , and K. C. Tan . 2018. “A Generic
    Deep-Learning-Based Approach for Automated Surface Inspection.” IEEE Transactions
    on Cybernetics 48 (3): 929–940. doi:10.1109/TCYB.2017.2668395.  PubMed Web of
    Science ®Google Scholar Russell, S. , and P. Norvig . 2009. Artificial Intelligence:
    A Modern Approach (3rd Edition) . 3rd ed. Upper Saddle River, NJ: Prentice Hall.  Google
    Scholar Shvachko, K. , H. Kuang , S. Radia , and R. Chansler . 2010. “The Hadoop
    Distributed File System.” In Proceedings of the 2010 IEEE 26th Symposium on Mass
    Storage Systems and Technologies (MSST) , Washington, DC.  Google Scholar Siddiqa,
    A. , I. A. Targio Hashem , I. Yaqoob , M. Marjani , S. Shamshirband , A. Gani
    , and F. Nasaruddin . 2016. “A Survey of Big Data Management: Taxonomy and State-Of-The-Art.”
    Journal of Network and Computer Applications 71: 151–166. doi:10.1016/j.jnca.2016.04.008.  Web
    of Science ®Google Scholar Tao, F. , and Q. Qi . 2019. “New IT Driven Service-Oriented
    Smart Manufacturing: Framework and Characteristics.” IEEE Transactions on Systems,
    Man, and Cybernetics: Systems 49 (1): 81–91. doi:10.1109/TSMC.2017.2723764.  Web
    of Science ®Google Scholar Tao, F. , Q. Qinglin , A. Liu , and A. Kusiak . 2018.
    “Data-Driven Smart Manufacturing.” Journal of Manufacturing Systems 48: 157–169.
    doi:10.1016/j.jmsy.2018.01.006.  Web of Science ®Google Scholar Tasnim, S. , N.
    Pissinou , and S. S. Iyengar . 2017. “A Novel Cleaning Approach of Environmental
    Sensing Data Streams.” In 2017 14th IEEE Annual Consumer Communications Networking
    Conference (CCNC) , 632–633. Las Vegas.  Google Scholar Telea, A. C. 2014. Data
    Visualization: Principles and Practice . Florida: CRC Press.  Google Scholar Thusoo,
    A. , J. S. Sarma , N. Jain , Z. Shao , P. Chakka , N. Zhang , S. Antony , H. Liu
    , and R. Murthy . 2010. “Hive - a Petabyte Scale Data Warehouse Using Hadoop.”
    In IEEE 26th International Conference on Data Engineering (ICDE) . Long Beach,
    CA.  Google Scholar Tran, T. X. , A. Hajisami , P. Pandey , and D. Pompili . 2017.
    “Collaborative Mobile Edge Computing in 5G Networks: New Paradigms, Scenarios,
    and Challenges.” IEEE Communications Magazine 55 (4): 54–61. doi:10.1109/MCOM.2017.1600863.  Web
    of Science ®Google Scholar Trochim, W. M. K. , J. Donnelly , and K. Arora . 2016.
    Research Methods The Essential Knowledge Base . 2nd ed. Boston: Cengage Learning.  Google
    Scholar Vapnik, V. N. 1995. The Nature of Statistical Learning Theory . New York,
    NY, USA: Springer-Verlag New York.  Google Scholar Wang, H. , S. Fossen , F. Han
    , I. A. Hameed , and G. Li . 2016. “Towards Data-Driven Identification and Analysis
    of Propeller Ventilation.” In OCEANS , 1–6. Shanghai: IEEE.  Google Scholar Wang,
    J. , M. Yulin , L. Zhang , R. X. Gao , and W. Dazhong . 2018a. “Deep Learning
    for Smart Manufacturing: Methods and Applications.” Journal of Manufacturing Systems
    48: 144–156. doi:10.1016/j.jmsy.2018.01.003.  Web of Science ®Google Scholar Wang,
    N. , X. Xiao , Y. Yang , T. D. Hoang , H. Shin , J. Shin , and Y. Ge 2018b. “PrivTrie:
    Effective Frequent Term Discovery under Local Differential Privacy.” In IEEE International
    Conference on Data Engineering (ICDE) .  Paris.  Google Scholar Wang, P. , R.
    X. Gao , and Z. Fan . 2015. “Cloud Computing for Cloud Manufacturing: Benefits
    and Limitations.” Journal of Manufacturing Science and Engineering 137 (4): 1–9.
    doi:10.1115/1.4030209.  Web of Science ®Google Scholar Wang, X. , W. Wang , L.
    T. Yang , S. Liao , D. Yin , and M. J. Deen . 2018a. “A Distributed HOSVD Method
    with Its Incremental Computation for Big Data in Cyber-Physical-Social Systems.”
    IEEE Transactions on Computational Social Systems 5 (2): 481–492. doi:10.1109/TCSS.2018.2813320.  Web
    of Science ®Google Scholar Wang, X. , L. T. Yang , H. Liu , and M. J. Deen . 2018b.
    “A Big Data-as-A-Service Framework: State-of-the-Art and Perspectives.” IEEE Transactions
    on Big Data 4 (3): 325–340. doi:10.1109/TBDATA.2017.2757942.  Web of Science ®Google
    Scholar Wang, X. , L. T. Yang , X. Xie , J. Jin , and M. J. Deen . 2017. “A Cloud-Edge
    Computing Framework for Cyber-Physical-Social Services.” IEEE Communications Magazine
    55 (11): 80–85. doi:10.1109/MCOM.2017.1700360.  Web of Science ®Google Scholar
    Wu, D. , C. Jennings , J. Terpenny , R. X. Gao , and S. Kumara . 2017a. “A Comparative
    Study on Machine Learning Algorithms for Smart Manufacturing: Tool Wear Prediction
    Using Random Forests.” Journal of Manufacturing Science and Engineering 139 (7):
    071018. doi:10.1115/1.4036350.  Web of Science ®Google Scholar Wu, D. , S. Liu
    , L. Zhang , R. X. Janis Terpenny , T. K. Gao , and J. A. Guzzo . 2017b. “A Fog
    Computing-Based Framework for Process Monitoring and Prognosis in Cyber-Manufacturing.”
    Journal of Manufacturing Systems 43: 25–34. doi:10.1016/j.jmsy.2017.02.011.  Web
    of Science ®Google Scholar Wu, X. , V. Kumar , J. R. Quinlan , J. Ghosh , Q. Yang
    , H. Motoda , G. J. McLachlan et al. 2008. “Top 10 Algorithms in Data Mining.”
    Knowledge and Information Systems 14 (1): 1–37. DOI:10.1007/s10115-007-0114-2.  Web
    of Science ®Google Scholar Wuest, T. , C. Irgens , and K.-D. Thoben . 2014. “An
    Approach to Monitoring Quality in Manufacturing Using Supervised Machine Learning
    on Product State Data.” Journal of Intelligent Manufacturing 25 (5): 1167–1180.
    doi:10.1007/s10845-013-0761-y.  Web of Science ®Google Scholar Xu, J. , J. Yao
    , L. Wang , Z. Ming , K. Wu , and L. Chen . 2017. “Narrowband Internet of Things:
    Evolutions, Technologies and Open Issues.” IEEE Internet of Things Journal PP
    99: 1–13.  Google Scholar Zaharia, M. , M. Chowdhury , M. J. Franklin , S. Shenker
    , and I. Stoica . 2010. “Spark: Cluster Computing with Working Sets.” In Proceedings
    of the 2Nd USENIX Conference on Hot Topics in Cloud Computing (HotCloud) . Berkeley,
    CA.  Google Scholar Zhang, G. P. 2000. “Neural Networks for Classification: A
    Survey.” IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications
    and Reviews) 30 (4): 451–462. doi:10.1109/5326.897072.  Web of Science ®Google
    Scholar Zhang, Y. , Q. Gao , L. Gao , and C. Wang . 2012. “iMapReduce: A Distributed
    Computing Framework for Iterative Computation.” Journal of Grid Computing 10 (1):
    47–68. doi:10.1007/s10723-012-9204-9.  Web of Science ®Google Scholar Zhang, Y.
    , G. Zhang , J. Wang , S. Sun , S. Shubin , and T. Yang . 2015. “Real-Time Information
    Capturing and Integration Framework of the Internet of Manufacturing Things.”
    International Journal of Computer Integrated Manufacturing 28 (8): 811–822. doi:10.1080/0951192X.2014.900874.  Web
    of Science ®Google Scholar Zheng, Z. , Y. Yang , X. Niu , H. N. Dai , and Y. Zhou
    . 2018. “Wide and Deep Convolutional Neural Networks for Electricity-Theft Detection
    to Secure Smart Grids.” IEEE Transactions on Industrial Informatics 14 (4): 1606–1615.
    doi:10.1109/TII.2017.2785963.  Web of Science ®Google Scholar Zhong, R. Y. , X.
    Chen , C. Chen , and G. Q. Huang . 2017. “Big Data Analytics for Physical Internet-Based
    Intelligent Manufacturing Shop Floors.” International Journal of Production Research
    55 (9): 2610–2621. doi:10.1080/00207543.2015.1086037.  Web of Science ®Google
    Scholar Zhong, R. Y. , G. Q. Huang , S. Lan , Q. Y. Dai , X. Chen , and T. Zhang
    . 2015. “A Big Data Approach for Logistics Trajectory Discovery from RFID-enabled
    Production Data.” International Journal of Production Economics 165: 260–272.
    doi:10.1016/j.ijpe.2015.02.014.  Web of Science ®Google Scholar Zhong, R. Y. ,
    S. Lan , X. Chen , Q. Dai , and G. Q. Huang . 2016. “Visualization of RFID-enabled
    Shopfloor Logistics Big Data in Cloud Manufacturing.” The International Journal
    of Advanced Manufacturing Technology 84 (1): 5–16. doi:10.1007/s00170-015-7702-1.  Web
    of Science ®Google Scholar Zhou, Z.-H. 2012. Ensemble Methods: Foundations and
    Algorithms . 1st ed. Florida: Chapman & Hall/CRC.  Google Scholar Zuo, Y. 2016.
    “Prediction of Consumer Purchase Behaviour Using Bayesian Network: An Operational
    Improvement and New Results Based on RFID Data.” International Journal of Knowledge
    Engineering and Soft Data Paradigms 5 (2): 85–105. doi:10.1504/IJKESDP.2016.075976.  Google
    Scholar Zuo, Y. , F. Tao , and A. Y. C. Nee . 2018. “An Internet of Things and
    Cloud-Based Approach for Energy Consumption Evaluation and Analysis for a Product.”
    International Journal of Computer Integrated Manufacturing 31 (4–5): 337–348.
    doi:10.1080/0951192X.2017.1285429.  Web of Science ®Google Scholar Download PDF
    X Facebook LinkedIn Email Share Related research  People also read Recommended
    articles Cited by 146 Role of Big Data Analytics in supply chain management: current
    trends and future perspectives Sumit Maheshwari et al. International Journal of
    Production Research Published online: 28 Jul 2020 Big data analytics in manufacturing:
    a bibliometric analysis of research in the field of business management Saumyaranjan
    Sahoo International Journal of Production Research Published online: 28 Apr 2021
    Internet of things (IoT) and big data analytics (BDA) for digital manufacturing
    (DM) Zhuming Bi et al. International Journal of Production Research Published
    online: 19 Jul 2021 View more Information for Authors R&D professionals Editors
    Librarians Societies Open access Overview Open journals Open Select Dove Medical
    Press F1000Research Opportunities Reprints and e-prints Advertising solutions
    Accelerated publication Corporate access solutions Help and information Help and
    contact Newsroom All journals Books Keep up to date Register to receive personalised
    research and resources by email Sign me up Copyright © 2024 Informa UK Limited
    Privacy policy Cookies Terms & conditions Accessibility Registered in England
    & Wales No. 3099067 5 Howick Place | London | SW1P 1WG     Cookies Button About
    Cookies On This Site We and our partners use cookies to enhance your website experience,
    learn how our site is used, offer personalised features, measure the effectiveness
    of our services, and tailor content and ads to your interests while you navigate
    on the web or interact with us across devices. By clicking "Continue" or continuing
    to browse our site you are agreeing to our and our partners use of cookies. For
    more information seePrivacy Policy CONTINUE'
  inline_citation: '>'
  journal: Enterprise information systems (Print)
  limitations: '>'
  pdf_link: null
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: 'Big data analytics for manufacturing internet of things: opportunities,
    challenges and enabling technologies'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1155/2011/130714
  analysis: '>'
  authors:
  - Arnaud Delorme
  - Tim Mullen
  - Christian Kothe
  - Zeynep Akalin Acar
  - Nima Bigdely-Shamlo
  - Andrey Vankov
  - Scott Makeig
  citation_count: 486
  full_citation: '>'
  full_text: ">\nHindawi Publishing Corporation\nComputational Intelligence and Neuroscience\n\
    Volume 2011, Article ID 130714, 12 pages\ndoi:10.1155/2011/130714\nResearch Article\n\
    EEGLAB, SIFT, NFT, BCILAB, and ERICA: New Tools for\nAdvanced EEG Processing\n\
    Arnaud Delorme,1, 2, 3 Tim Mullen,1, 4 Christian Kothe,1 Zeynep Akalin Acar,1\n\
    Nima Bigdely-Shamlo,1 Andrey Vankov,1 and Scott Makeig1,5\n1Swartz Center for\
    \ Computational Neuroscience, Institute for Neural Computation, University of\
    \ California San Diego,\nLa Jolla, 92093 CA, USA\n2Universit´e de Toulouse, UPS,\
    \ Centre de Recherche Cerveau et Cognition, 31062 Toulouse, France\n3CNRS, CerCo,\
    \ 31062 Toulouse, France\n4Department of Cognitive Science, University of California\
    \ San Diego, La Jolla, 92093 CA, USA\n5Department of Neurosciences, School of\
    \ Medicine, University of California San Diego, La Jolla, 92093 CA, USA\nCorrespondence\
    \ should be addressed to Arnaud Delorme, arno@ucsd.edu\nReceived 5 October 2010;\
    \ Revised 5 January 2011; Accepted 10 February 2011\nAcademic Editor: Sylvain\
    \ Baillet\nCopyright © 2011 Arnaud Delorme et al. This is an open access article\
    \ distributed under the Creative Commons Attribution\nLicense, which permits unrestricted\
    \ use, distribution, and reproduction in any medium, provided the original work\
    \ is properly\ncited.\nWe describe a set of complementary EEG data collection\
    \ and processing tools recently developed at the Swartz Center for\nComputational\
    \ Neuroscience (SCCN) that connect to and extend the EEGLAB software environment,\
    \ a freely available and readily\nextensible processing environment running under\
    \ Matlab. The new tools include (1) a new and ﬂexible EEGLAB STUDY design\nfacility\
    \ for framing and performing statistical analyses on data from multiple subjects;\
    \ (2) a neuroelectromagnetic forward head\nmodeling toolbox (NFT) for building\
    \ realistic electrical head models from available data; (3) a source information\
    \ ﬂow toolbox\n(SIFT) for modeling ongoing or event-related eﬀective connectivity\
    \ between cortical areas; (4) a BCILAB toolbox for building\nonline brain-computer\
    \ interface (BCI) models from available data, and (5) an experimental real-time\
    \ interactive control and\nanalysis (ERICA) environment for real-time production\
    \ and coordination of interactive, multimodal experiments.\n1. Introduction\n\
    A variety of new signal processing methods have been applied\nto EEG signal processing\
    \ over the past ﬁfteen years [1].\nThese new methods require new tools to allow\
    \ routine\nprocessing of EEG data, and also make possible the analysis of\nmultimodal\
    \ data collected using more complex experimental\ndesigns than previous analysis\
    \ methods allowed. Here we\nsummarize a collection of new tools designed to be\
    \ made\nfreely available for nonproﬁt use and which integrate with\nthe well-established\
    \ EEGLAB software environment [2],\nan interactive, graphic interface menu and\
    \ command line\nscript-based environment for processing electrophysiological\n\
    data. Since its introduction in 2001, EEGLAB has become a\nwidely used platform\
    \ for processing of biophysical data and\nfor sharing of new signal processing\
    \ approaches. Recently, we\nhave introduced a number of new EEGLAB-associated\
    \ tool-\nboxes: NFT, a neuroelectromagnetic forward head modeling\ntoolbox [3]\
    \ is a new toolbox for electrical head modeling, an\nessential ﬁrst step in electrophysiological\
    \ source localization.\nSIFT, a source information ﬂow toolbox, allows users to\n\
    apply a wide range of recently published methods for as-\nsessing eﬀective connectivity\
    \ between EEG signals including\nquasi-independent sources of EEG activity. Finally,\
    \ the\nERICA framework, composed of the Datariver, Matriver, and\nProducer toolboxes,\
    \ and the interoperable BCILAB toolbox\nmanage real-time synchronization and online\
    \ processing of\nEEG and other multimodal data streams. ERICA also handles\nfeedback\
    \ and delivery of appropriate sensory stimuli to\nparticipant(s) and/or to a control\
    \ system they are operating\n[4].\nFigure 1 depicts how the new toolboxes interact\
    \ and\nmay connect to a distributed data archiving environment\n(here, the proposed\
    \ HeadIT data and tools resource [5]).\nTable 1 lists the components of the Swartz\
    \ Center for\n2\nComputational Intelligence and Neuroscience\nComputational Neuroscience\
    \ (SCCN) software suite. Note\nthat we designate by “EEGLAB plug-in” any function,\n\
    toolkit, or more organized and ambitious projects such\nas fully operational and\
    \ standalone toolboxes or signal\nprocessing toolboxes that use the EEGLAB data\
    \ structure\nand conventions. In this paper, we designate by “framework”\nany\
    \ grouping of tools or toolboxes in which common code\nproviding generic functionality\
    \ can be selectively overridden\nor specialized by user code to provide custom\
    \ functionality.\nFor instance the ERICA is a framework centered around the\n\
    concept of a “Data River” and including the clients and server\nimplementing this\
    \ concept.\n2. EEGLAB\nEEGLAB is an interactive menu-based and scripting software\n\
    for processing electrophysiological data based under the\nMatlab interpreted programming\
    \ script environment [2].\nEEGLAB provides an interactive graphical user interface\n\
    allowing users to ﬂexibly and interactively process their\nhigh-density electrophysiological\
    \ data (of up to several\nhundreds of channels) and/or other dynamic brain time\n\
    series data. EEGLAB implements common methods of\nelectroencephalographic data\
    \ analysis including indepen-\ndent component analysis (ICA) and time/frequency\
    \ analysis.\nEEGLAB has become a widely used platform for applying\nand sharing\
    \ new techniques for biophysical signal processing.\nAt least 28 plug-ins have\
    \ been implemented and released\nby user groups. Here we describe recent developments\
    \ in\nEEG software interoperative with EEGLAB. Several of the\nnew tools are Matlab\
    \ applications that conveniently plug in\nto the EEGLAB menu (or may also be run\
    \ as stand-alone\napplications).\nKey EEGLAB features include\n(1) an event structure\
    \ and functions for importing,\nediting, and manipulating event information. Users\n\
    can select (sub)epochs time-locked to classes of\nevents and can sort trials for\
    \ visualization based on\nvalues in any event ﬁeld (e.g., subjects’ reaction time),\n\
    (2) independent component analysis (ICA) decompo-\nsition of electroencephalographic\
    \ data [6]. Though\nICA data analysis methods have now been incorpo-\nrated into\
    \ most commercial software processing EEG\ndata (BrainVision, Neuroscan, BESA),\
    \ EEGLAB has\nthe most extensive repertoire of processing and data\nevaluation\
    \ tools for ICA-based data analysis,\n(3) ready adaptability to users with diﬀerent\
    \ levels of\nprogramming sophistication. EEGLAB unique “his-\ntory” features build\
    \ scripts as users navigate through\nmenus, allowing users to “replay”, vary,\
    \ or extend\ntheir data processing through easily constructed Mat-\nlab scripts.\
    \ Users can either interact only with the\nEEGLAB graphic interface, call EEGLAB\
    \ functions\ndirectly from the Matlab command line, or write\ntheir own Matlab\
    \ scripts using modular EEGLAB\nfunctions and documented data structures,\n(4)\
    \ a truly open source philosophy, allowing any re-\nsearcher to build and distribute\
    \ plug-in functions or\ntoolboxes that appear automatically in the EEGLAB\nmenu\
    \ windows of their users. This structure ensures\nstability of core code that\
    \ a handful of expert users\nmodify while, at the same time, allows easy inclusion\n\
    of new algorithms and methods by other users.\nEEGLAB comprises more than 400\
    \ Matlab functions totaling\nmore than 50,000 lines of programming. First developed\n\
    under Matlab v5.3 on Linux, EEGLAB currently runs under\nall versions of Matlab\
    \ v7 running on Linux, Unix, Windows,\nand Mac OSX. Since the Matlab program is\
    \ not free itself,\nwe have also used the Matlab compiler to compile EEGLAB\n\
    for those users who do not have access to Matlab. To\nour knowledge, 28 user-initiated\
    \ EEGLAB plug-ins have\nbeen developed and made available. The online EEGLAB\n\
    tutorial comprises more than 300 pages of documentation.\nIn addition, each of\
    \ the 400 stand-alone modular EEGLAB\nfunctions contains its own documentation.\
    \ EEGLAB has\nbeen downloaded more than 65,000 times from 88 country\ndomains\
    \ since 2003. As of April 2010, 9,218 unique opt-in\nusers are currently on the\
    \ EEGLAB mailing lists.\n3. The EEGLAB STUDY.Design Framework\nThe EEGLAB STUDY.design\
    \ concept was introduced in June,\n2010 in EEGLAB v9. Complex event-related experiments\n\
    typically include a number of diﬀerent types of events.\nStatistical contrasts\
    \ between EEG activities time locked to\ndiﬀerent subsets of these event types\
    \ require researchers to\nbe able to deﬁne custom sets of independent variables\
    \ for\ndiﬀerent statistical treatments of the same data. The new\nSTUDY.design\
    \ framework in EEGLAB allows users to freely\ndeﬁne independent and dependent\
    \ variables and to analyze\ndata channel or independent component (IC) activities\n\
    across subjects using mean event-related potential (ERP),\npower spectrum, event-related\
    \ spectral perturbation (ERSP)\n[7], and intertrial coherence (ITC) [8] measures\
    \ for any\nnumber of sets of event-related data trials time locked to\ndiﬀerent\
    \ sets of events, each set of trials termed a STUDY\n“condition”.\nFor example,\
    \ a STUDY might contain data sets for two\nconditions from two groups of subjects\
    \ (a 2 × 2 (condition,\ngroup) statistical design). Statistical comparisons might\
    \ be\ntargeted to look at main eﬀects and interactions of condition\nand group\
    \ in this design, or at contrasts between selected\n(1 × 2) pairs of conditions\
    \ or groups. Figure 2 shows the\nEEGLAB STUDY.design graphic interface by means\
    \ of which\nusers can create new designs and select independent variables\nto\
    \ include in them.\nBuilding a STUDY design involves multiple steps. Users\nbegin\
    \ by preprocessing binary EEG data ﬁles generated by\nproprietary EEG recording\
    \ software; for each subject, this\ninvolves importing raw data, re-referencing,\
    \ ﬁltering and\nremoving artifacts. Once these data sets have been pre-\nprocessed,\
    \ users then have to import the subject data sets\ninto a STUDY. Creating a STUDY\
    \ design for analysis then\nallows statistical group comparison of data measures\
    \ for\nComputational Intelligence and Neuroscience\n3\nNFT toolbox\nEEGLAB\nSIFT\n\
    28 user plugins\nEyeTracker\nWii remote\nMocap\nEEG\nTactile stream\nVideo stream\n\
    Audio stream\nProducer\nDataRiver\nMatRiver\nBCILAB\nHeadIT\nERICA framework\n\
    Analysis\nAnalysis plugins\nData archive\nData sync and handling\nInteractive\
    \ tools\nStimulus control\nFigure 1: Complete electrophysiological experiment\
    \ control, data collection, analysis, archiving, and meta-analysis suite: the\
    \ EEGLAB\nenvironment for data analysis; the ERICA framework for data recording,\
    \ online analysis, and stimulus control; the BCILAB toolbox for\nonline and oﬄine\
    \ classiﬁcation and BCI; the SIFT toolbox for information ﬂow modeling; HeadIT,\
    \ an archival data and tools resource\nunder development for laboratory or archival\
    \ data storage, retrieval and meta-analysis; dashed lines indicates planned interfaces\
    \ under\nconstruction.\nTable 1: Components of the extended SCCN software suite.\n\
    Software\nSince\nVers.\nLicence\nOpen Src.\nPlatform\nWeb link\nEEGLAB\n2002\n\
    10.0\nGNU GPL\nYes\nMatlab\nhttp://sccn.ucsd.edu/wiki/EEGLAB\nNFT toolbox\n2009\n\
    2.0\nGNU GPL\nYes†\nMatlab†\nhttp://sccn.ucsd.edu/wiki/NFT\nSIFT\n2010\n0.1a\n\
    GNU GPL\nYes\nMatlab\nhttp://sccn.ucsd.edu/wiki/SIFT\nBCILAB\n2010\n0.9\nGNU GPL\n\
    Yes\nMatlab\nhttp://sccn.ucsd.edu/wiki/BCILAB\nERICA\n2009\n1.0\nMixed∗\nMixed∗\n\
    Windows††\nhttp://sccn.ucsd.edu/wiki/ERICA\n∗DataRiver, a central compiled C++\
    \ ERICA component, is free for noncommercial use. It is not open source.\n†Contains\
    \ a large number of precompiled C and C++ routines, all of them being open source.\n\
    ††Many components also run under Linux and Mac OSX.\ndiﬀerent conditions (e.g.,\
    \ time locked to speciﬁc event types)\nfor each subject. For example, in an oddball\
    \ paradigm\ncomprised of trials time locked to target, distractor, and\nstandard\
    \ stimuli, users might want to contrast these three\ntypes of trials using a 3\
    \ × 1 design. Alternatively, they might\nwant to contrast distractor and target\
    \ stimulus-locked trials,\nconsidered together, with responses to standard stimuli.\
    \ The\nSTUDY design feature of EEGLAB allows users to easily\ninvestigate such\
    \ contrasts. In a STUDY with N subject\ngroups, the STUDY design scheme also allows\
    \ users to look\nat group eﬀects for each condition using a 2 × N design.\nAll\
    \ of the above design concepts may be implemented\nwithin a single STUDY using\
    \ multiple STUDY.design speciﬁ-\ncations. Finally, use of multiple designs may\
    \ also be useful for\ntesting diﬀerent signal processing options. For instance,\
    \ one\nmight create two identical STUDY designs, one computing\ntime/frequency\
    \ measures using fast fourier transforms (FFT)\nand the other using wavelets.\
    \ Once computed, the user can\ntoggle between designs to compare results using\
    \ the two\ntypes of time/frequency decomposition.\nEEGLAB uses statistical tools\
    \ including surrogate and\nparametric statistics to perform hypothesis testing\
    \ on\nSTUDY designs. Surrogate tests involve bootstrap or permu-\ntation methods.\
    \ Depending on the design type, statistical\nhypothesis testing using t-test,\
    \ one-way ANOVA or two-\nway ANOVA—or their surrogate-data equivalents—are per-\n\
    formed for paired data or unpaired data designs. Finally,\nthe False Discovery\
    \ Rate (FDR) algorithm is applied to\ncorrect for multiple comparisons [9]. Using\
    \ these simple\nyet powerful statistical tools, EEGLAB allows comparison\nof multiple\
    \ experimental designs applied to a given data\nSTUDY.\nWhen working with data\
    \ from multiple subjects using\nthe STUDY design framework, users may analyse\
    \ either\nIC, scalp channel, or other types of component activities\nassociated\
    \ with individual subjects. Decomposition of the\ndata into ICs allows inclusion\
    \ of source localization infor-\nmation, since many ICs strongly resemble the\
    \ projection\nof a single equivalent current dipole, presumably reﬂecting\ntheir\
    \ origin in a single locally synchronized cortical patch.\nThe neuroelectromagnetic\
    \ forward head modeling toolbox\n(NFT) thus allows for more precise source localization\
    \ of\nIC processes for each subject using subject-adapted forward\nelectrical\
    \ head models.\n4\nComputational Intelligence and Neuroscience\nCIs 5 ERSP, memorize\n\
    CIs 5 ERSP, ignore\n(dB)\nFrequency (Hz)\nFrequency (Hz)\nFrequency (Hz)\n7\n\
    11\n15\n19\n24\n7\n11\n15\n19\n24\n28\n28\n7\n11\n15\n19\n24\n28\n−400\n0\n400\n\
    800\nTime (ms)\n−400\n0\n400\n800\nTime (ms)\n−400\n0\n400\n800\nTime (ms)\n3.3\n\
    1.6\n0\n−1.6\n−3.3\n1\n0.1\n0.01\n0.001\nS01/IC7\nS01/IC8\nS03/IC11\nS05/IC26\n\
    S13/IC19\nS13/IC18\nS09/IC16\nS08/IC4\nCIs 5 (6 Ss, 8 ICs)\n(P-value) perm with\
    \ fdr\nFigure 2: EEGLAB STUDY design interface using the tutorial STUDY data available\
    \ via the EEGLAB wiki (http://sccn.ucsd.edu/wiki/eeglab).\nThe three push buttons\
    \ at the top may be used to add a new design (“Add design”), rename a design (“Rename\
    \ design”), or delete a design\n(“Delete design”). The “Independent variable 1”\
    \ list helps deﬁne independent variables. The list of independent variables is\
    \ automatically\ngenerated based on the STUDY deﬁnition informationand individual\
    \ data set event types. For a given independent variable, it is also possible\n\
    to select a subset of its values or to combine some of its values. For instance,\
    \ in this example the user has selected “ignore” and “memorize”\nstimuli as values\
    \ for the independent variable “condition”. The “Subject” list contains the subjects\
    \ to include in a speciﬁc design. Unselecting a\ngiven subject from the list excludes\
    \ him/her from further data analysis within the design. Once a design is selected,\
    \ measures including ERPs,\nmean spectra or event-related spectral perturbations\
    \ (ERSP) may be plotted. Here, we have plotted the event-related spectral perturbations\n\
    of an independent component (IC) cluster in the selected STUDY.design. In the\
    \ top right panel, the scalp maps of one IC cluster are shown—\nthe large map\
    \ representing the average scalp map. In the bottom right panel, mean cluster\
    \ ERSPs are shown for Ignore versus Memorize letter\ntrials, and their signiﬁcant\
    \ diﬀerences are assessed using permutation-based statistics and a false discovery\
    \ rate method to correct for multiple\ncomparisons.\n4. The Neuroelectromagnetic\
    \ Forward Head\nModeling Toolbox (NFT)\nOur previous work has shown that some\
    \ ICA component\nscalp topographies are highly compatible with compact\ncortical\
    \ domains of local ﬁeld synchrony that may be\nlocalized in the brain [1, 10,\
    \ 11] using a four-shell spher-\nical model or the standard boundary element method\n\
    (BEM) head model included in the EEGLAB Dipﬁt plug-in\n(http://sccn.ucsd.edu/wiki/A08:\
    \ DIPFIT). When additional\nsubject information is available, more precise localization\n\
    approaches are possible. To obtain accurate source localiza-\ntion one needs to\
    \ use a realistic electrical head model that\nreﬂects the actual electrical and\
    \ geometric properties of the\nhead. NFT adds a realistic head modeling framework\
    \ to the\nspherical and MNI head models already provided by Dipﬁt\nwithin EEGLAB.\
    \ The NFT framework automates most of\nthe tasks needed to generate a realistic\
    \ head model from\nmagnetic resonance (MR) images and/or from measured\nEEG sensor\
    \ coordinates, and provides advanced boundary\nelement method (BEM) and Finite\
    \ Element Method (FEM)\nsolvers for estimating the projected scalp ﬁelds for a\
    \ given set\nof possible brain source areas, thus estimating solutions to\nthe\
    \ “forward” EEG modeling problem [3].\nNFT is accessible from the EEGLAB graphic\
    \ interface as\nan EEGLAB plug-in. The toolbox provides both a Matlab\ncommand\
    \ line and graphical user interface for generating\nrealistic head models from\
    \ available subject information,\nand for solving the forward problem numerically\
    \ to provide\na lead-ﬁeld-matrix for a given source space and sensor\ndistribution.\
    \ This makes it easy to integrate a forward head\nmodel produced by NFT into any\
    \ inverse source localization\napproach.\nNFT performs the following steps:\n\
    (1) Segmentation of MR images: If a 3-D whole-head\nstructural T-1 MR image of\
    \ the subject’s head is\navailable, the toolbox can segment the scalp, skull,\n\
    CSF, and brain tissues.\n(2) High-quality head models: The accuracy of numeri-\n\
    cal solutions to an inverse source localization prob-\nlem depends on the quality\
    \ of the underlying meshes\nthat model conductance changes at tissue bound-\n\
    aries. NFT can create high-quality surface meshes\nfrom segmented MR images for\
    \ use in BEM head\nmodel. FEM meshes may be generated from the\nBEM surface meshes\
    \ using the open source Tetgen\nComputational Intelligence and Neuroscience\n\
    5\ntool [12]. Two examples of FEM and BEM meshes\ngenerated using NFT are shown\
    \ in Figure 3.\n(3) Warping a template head model: While use of a\nsubject whole-head\
    \ MR image is the preferred way\nto generate a realistic head model, such an image\n\
    may not always be available. NFT can generate a\nsemirealistic head model of the\
    \ subjects’ head by\nwarping a standard template head model to the\ndigitized\
    \ 3-D electrode coordinates, when these are\navailable.\n(4) Coregistration of\
    \ electrode positions with the head\nmesh: NFT has a two-step (manual and automatic)\n\
    coregistration function for aligning the digitized\nelectrode locations to the\
    \ scalp mesh.\n(5) Accurate and eﬃcient forward problem solution: The\nNFT uses\
    \ high-performance BEM and FEM imple-\nmentations from the open source METU-FP\
    \ Toolkit\n(http://www.eee.metu.edu.tr/metu-fp) [13, 14] for\nbioelectromagnetic\
    \ ﬁeld computations.\nWe have successfully used NFT to model realistic cortical\n\
    source spaces comprising a large number of dipolar elements\nthat we assume are\
    \ oriented perpendicular to the local\ncortical surface which was extracted from\
    \ subject MR\nhead images using tessellated FreeSurfer gray and white\nmatter\
    \ surfaces [15]. We created a multiscale cortical patch\nbasis on this surface\
    \ by selecting seed points (single voxel\ndipoles), then extended each patch conformally\
    \ to a set\nof Gaussian-tapered patches with areas in the range ∼50–\n200 mm2\
    \ [16]. NFT thus may allow precise source localiza-\ntion of IC processes based\
    \ on accurately modeled electrical\ncurrent ﬂow consistent with the individual\
    \ subject head\nanatomy.\nFEM modeling is a recent addition to NFT (NFT 2.0)\n\
    and patch-based source space generation will be integrated\ninto NFT in 2011.\
    \ In the future, the NFT model will also\nbe able to incorporate models of current\
    \ anisotropy based\non white-matter distribution information extracted from\n\
    diﬀusion tensor/weighted imaging (DTI/DWI) head images\nco-registered with structural\
    \ MR images.\n5. Analyzing Source Information Flow\nDynamics Using SIFT\nOnce\
    \ activity in speciﬁc brain areas have been identiﬁed\nusing source separation\
    \ (e.g., ICA), and localized (e.g.,\nusing NFT), it is possible to look for transient\
    \ changes\nin the independence of these diﬀerent brain source pro-\ncesses. Advanced\
    \ methods for noninvasively detecting and\nmodeling distributed network events\
    \ contained in high-\ndensity scalp EEG data are desirable for basic and clinical\n\
    studies of distributed brain activity supporting behavior and\nexperience. In\
    \ recent years, Granger Causality (GC) and its\nextensions have increasingly been\
    \ used to explore “eﬀective”\nconnectivity (directed information ﬂow, or causality)\
    \ in the\nbrain based primarily on observed ongoing or event-related\nrelationships\
    \ between channel waveforms. While many\nlandmark studies have applied GC to invasively\
    \ recorded\nlocal ﬁeld potentials and spike trains, a growing number\nof studies\
    \ have successfully applied GC to noninvasively\nrecorded human EEG and MEG data\
    \ (as reviewed by Bressler\nand Seth [17]).\nBased on the prediction error of\
    \ autoregressive (AR)\nmodels, a process (A) is said to Granger-cause another\n\
    process (B) if past values of process A, in addition to past\nvalues of process\
    \ B, help to linearly predict future values of\nprocess B beyond what can be achieved\
    \ by using past values\nof process B alone [18]. Using multivariate autoregressive\n\
    (MVAR also referred to in the literature as VAR or MAR)\nmodels, the GC concept\
    \ has been extended to an arbitrary\nnumber of signals, which may include a collection\
    \ of source\nactivities in the brain. Using this approach, through Fourier-\n\
    transformation of the MVAR coeﬃcient matrices, we can\nobtain the transfer and\
    \ spectral density matrices (power),\nand ordinary, multiple, and partial coherences,\
    \ where the\nlatter quantity expresses the amount of phase coherence\nbetween\
    \ two channels after subtracting out the part of the\ninteraction which can be\
    \ explained by a linear combination\nof all other channels. From these quantities,\
    \ we can derive\na frequency-domain representation of bivariate GC as well\nas\
    \ several frequency-domain measures of directed condi-\ntional (multivariate)\
    \ dependence closely related to Granger’s\ndeﬁnition of causality such as the\
    \ (direct) directed transfer\nfunction (dDTF, DTF) and partial directed coherence\
    \ (PDC).\nThese and related estimators describe diﬀerent aspects of\nnetwork dynamics\
    \ and thus comprise a complementary\nset of tools for MVAR-based connectivity\
    \ analysis within\nthe well-established and interpretable framework of GC\n[19].\
    \ To study transient causal dynamics of nonstationary\nphenomena, adaptive MVAR\
    \ (AMVAR) approaches may\nbe applied using locally-stationary sliding windows\
    \ [20],\nKalman ﬁltering, or spectral matrix factorization. These\napproaches\
    \ can be used to explore ﬁnely-resolved time-\nand frequency-dependent dynamics\
    \ of directed information\nﬂow or causality between neuronal sources during cogni-\n\
    tive information processing. Baseline signiﬁcance levels for\ncausal inﬂuence\
    \ are typically obtained by a modiﬁcation of a\nsurrogate “phase randomization”\
    \ algorithm [21]. This and\nother bootstrap, permutation, and analytical tests\
    \ can be\nused to establish rigorous conﬁdence intervals on estimated\nconnectivity.\
    \ Additional details on all aforementioned meth-\nods can be found in [19].\n\
    SIFT is a toolbox for modeling and visualizing infor-\nmation ﬂow between sources\
    \ of EEG data, possibly after\nseparating the data into (instantaneously) maximally\
    \ inde-\npendent processes using ICA. The toolbox currently con-\nsists of four\
    \ modules, (1) data preprocessing, (2) model\nﬁtting and connectivity estimation,\
    \ (3) statistical analysis,\nand (4) visualization. The ﬁrst module contains routines\n\
    for normalization, downsampling, detrending, and other\nstandard preprocessing\
    \ steps. The second module currently\nincludes support for several adaptive MVAR\
    \ modeling\napproaches. From the ﬁtted model, the user can chose to\nestimate\
    \ spectral power, coherence, and frequency-domain\nconnectivity, selecting from\
    \ over ﬁfteen measures published\nto date. The third module includes routines\
    \ for surrogate\nstatistics (phase-randomization and bootstrap statistics) for\n\
    6\nComputational Intelligence and Neuroscience\n(a)\n(b)\nFigure 3: Two examples\
    \ of (a) a set of subject head BEM meshes (modeling scalp, skull, cerebrospinal\
    \ ﬂuid (CSF), and cortex tissue\nboundaries) and (b) a FEM head volume for the\
    \ same subject with 3-D voxels for scalp, skull, and brain tissues shown in diﬀerent\
    \ colors.\nall measures, and analytic statistics for partial directed coher-\n\
    ence and directed transfer function measures. The fourth\nmodule contains novel\
    \ routines for interactive visualization\nof information ﬂow dynamics and graph-theoretic\
    \ measures\nacross time, frequency, and anatomical source location. A\ngraphical\
    \ user interface allows easy access to the SIFT data\nprocessing pipeline.\nA\
    \ key aspect of SIFT is that it focuses on estimating\nand visualizing multivariate\
    \ eﬀective connectivity in the\nsource domain rather than between scalp electrode\
    \ signals.\nThis should allow us to achieve ﬁner spatial localization of\nthe\
    \ network components while minimizing the challenging\nsignal processing confounds\
    \ produced by broad volume con-\nduction from cortical sources (as well as nonbrain\
    \ sources) to\nthe scalp electrodes. SIFT may help ﬁnd transient, dynamic\nnetwork\
    \ events that link spatially static component processes\n(Figure 4). The toolbox\
    \ may also be used for eﬀective\nconnectivity analysis and visualization of phenomena\
    \ in\nelectrocorticographic (ECoG) data, for example, to identify\nsources and\
    \ directions of information ﬂow at onsets of and\nduring epileptic seizures.\n\
    While the ﬁrst test release of SIFT contains a number\nof popular MVAR-based eﬀective\
    \ connectivity measures, we\nare working on incorporating additional phase-amplitude\n\
    coupling and transfer entropy measures. In the EEGLAB\ntradition, the architecture\
    \ of the toolbox is also designed\nto allow easy addition of new methods from\
    \ the user com-\nmunity. Another group analysis module, in development,\nwill\
    \ also be included in the upcoming second test release.\nThis will aﬀord clustering-based\
    \ and Bayesian techniques\nfor obtaining estimates of source-domain connectivity\
    \ with\nconﬁdence intervals over a subject population. The analysis\nframework\
    \ described above allows exploration of EEG\nsource-domain connectivity following\
    \ the use of EEGLAB\nand NFT routines for ICA-based source separation and local-\n\
    ization. We are currently evaluating the relative suitability\nof diﬀerent source\
    \ separation algorithms when combined\nwith MVAR-based connectivity algorithms,\
    \ and will further\ndevelop the toolbox accordingly. In the near future, we\n\
    plan to interface SIFT with the BCILAB toolbox, discussed\nbelow, with the hope\
    \ of applying these methods online\nin advanced brain-machine interfaces for real-time\
    \ EEG\nprocessing, cognitive monitoring, and feedback applications.\n6. The Experimental\
    \ Real-Time Interactive\nControl and Analysis (ERICA) Framework\nFor the purpose\
    \ of real-time data acquisition and processing,\nwe have developed an online EEG\
    \ and multimodal data col-\nlection, processing, and interactive feedback environment,\n\
    ERICA. Processing of EEG data in real-time software appli-\ncations requires,\
    \ ﬁrst, organized handling of data controlling\nits streaming into online data\
    \ processing (e.g., data-adaptive\nBCI or other feedback) routines whose outputs,\
    \ combined\ninto synchronized data streams (ﬁguratively a “data river”),\ncan\
    \ be used to control or adapt ongoing stimulation pro-\ncesses. Synchronization\
    \ of diﬀerent asynchronous streams\nin real time over a local network may prove\
    \ diﬃcult; the\noriginality of the ERICA framework comes from solving\nthese issues\
    \ in an eﬃcient and elegant manner.\nThe ERICA framework is based on a unique\
    \ streaming\ndata management and real-time cross-platform synchroniza-\ntion application\
    \ called DataRiver developed from an ADAPT\ndata acquisition and stimulation control\
    \ environment [22].\nThe Producer software is a DataRiver client that controls\n\
    stimulus presentation in a ﬂexible way using Vari´ete, an orig-\ninal scripting\
    \ language. MatRiver, another DataRiver client,\nComputational Intelligence and\
    \ Neuroscience\n7\nFrequency (Hz)\nUpper: dDTF\nDiag:\nLower: dDTF\n8\n1\n1\n\
    13\n19\n20\n23\n38\n39\n8\n11\n13\n19\n20\n23\n38\n39\n−0.5\n0\n0.5 −0.5\n0\n\
    0.5 −0.5\n0\n0.5 −0.5\n0\n0.5 −0.5\n0\n0.5 −0.5\n0\n0.5 −0.5\n0\n0.5 −0.5\n0\n\
    0.5\nTime (s)\n50\n40\n30\n20\n10\n50\n40\n30\n20\n10\n50\n40\n30\n20\n10\n50\n\
    40\n30\n20\n10\n50\n40\n30\n20\n10\n50\n40\n30\n20\n10\n50\n40\n30\n20\n10\n50\n\
    40\n30\n20\n10\nFrom\nTo\nFrequency (Hz)\n−0.5\n0\n0\n0.5\nTime (s)\n50\n40\n\
    30\n20\n10\n10\n0\n×10−3\n×10−3\n×10−3\n1\nIC13\nIC8\n0.0074\n0.0037\n0\n−0.0037\n\
    −0.0074\nFrequency (Hz)\n−0.5\n0\n0\n0.5\nTime (s)\n50\n40\n30\n20\n20\n10\n10\n\
    0\n×10−3\n1\n0.0074\n0.0037\n0\n−0.0037\n−0.0074\nMethod: dDTF08. subj eb79. Cond\
    \ (RespWrong)\nERSP on diagonal\nIC8 → IC13\nIC13 → IC8\nERSP\n(a)\nOutﬂow\n2\n\
    0\n−2\n−500\n0\n500\n1000\n(µV)\nTime (ms)\n−202ms\n0.00\n0.00\n0.08\n8\n0.15\n\
    Asymmetrytatio Connectivity\nConnmagnitude\ndDTF08\n0.05\n0.03\n0.05\n0.03\n0.01\n\
    38\n20\n11\n19\n13\n39\n13\n23\n0.45\n-0.04\n-0.54\nERP envelope (IC8, backprojected\
    \ to FCz)\n(b)\n0\nMax\nOutﬂow\nOutﬂow\nInﬂow\nInﬂow\nInﬂow/outﬂow\nInﬂow + outﬂow\n\
    2\n1\n0\n−1\n−2\n−500\n0\n500\n1000\n2500 ms\n(µV)\nTime (ms)\ndDTF (3–7 Hz) N\
    \ = 24\nERP envelope (all components, backprojected to scalp)\n(error > correct)\n\
    (c)\nFigure 4: EEG-based brain connectivity analysis and visualization using SIFT.\
    \ (a) An interactive time-frequency grid demonstrating\ntransient bursts of theta\
    \ (3–7 Hz) and delta (1–3 Hz) band information ﬂow during error commission, estimated\
    \ using the direct directed\ntransfer function (dDTF), between a subset of independent\
    \ component (IC) sources. Dashed vertical line denotes time of erroneous button\n\
    press. Callout shows an expanded view of information ﬂow to/from sources 8 and\
    \ 13, obtained by clicking on the respective grid cell.\n(b) Several frames from\
    \ an interactive BrainMovie3D animation showing an event-related causal relationship\
    \ in the theta band between\nthese sources (200 ms (top) and −520, 40, and 600\
    \ ms (bottom) relative to an erroneous button press). Ball (node) color and size\
    \ denotes\nasymmetry ratio (red: causal source, blue: causal sink) and outﬂow\
    \ strength, respectively, for that IC. Cylinder (edge) color and size denote\n\
    connectivity strength. The event-related potential of IC8 (red, medial), back-projected\
    \ to a superior electrode is superimposed below each\nframe (blue bar denotes\
    \ frame index). This shows a network interpretation of the classic “error-related\
    \ negativity” (ERN) phenomenon\nobserved during error-processing. (c) A frame\
    \ from a causal projection movie showing mean net causal inﬂow (green) and causal\
    \ outﬂow\n(red) in the theta band at each brain location during error commission\
    \ across 24 subjects. Note the signiﬁcant causal outﬂow from or near\nanterior\
    \ cingulate cortex, thought to be critically involved in error-processing, during\
    \ and following the negative peak of the ERN.\n8\nComputational Intelligence and\
    \ Neuroscience\nallows direct read/write access to DataRiver data streams\nfrom\
    \ within Matlab processes.\nThe central application driving development of ERICA\
    \ is\nthe development of mobile brain/body imaging (MoBI) data\nacquisition and\
    \ analysis methods [23]—the simultaneous\nstudy of what the brain is doing (assessed\
    \ via distributed EEG\nsource dynamics), what the brain is sensing (via audiovisual\n\
    scene recording), and what the brain is controlling (the\ntotality of our behavior\
    \ assessed by body motion capture, eye\ntracking, etc.) in performing naturally\
    \ motivated actions in\nordinary 3-D task environments.\nTo allow real-time analysis,\
    \ data streams acquired by sep-\narate devices ﬁrst need to be synchronized. Such\
    \ streams are,\nby deﬁnition, asynchronous, even when they are acquired at\nthe\
    \ same nominal sampling frequency because independent\nclocks are used for data\
    \ acquisition in each device. In addi-\ntion, the sampling rates for diﬀerent\
    \ data sources may diﬀer\nsigniﬁcantly: while EEG is usually sampled between 250\
    \ Hz\nand 2,000 Hz, video, body motion capture or subject behav-\nioral responses\
    \ may be acquired at a much lower sampling\nrate, and audio data streams at still\
    \ higher sampling rates.\nFor synchronization purposes, another important challenge\n\
    is dealing with sporadic delays introduced by equipment\nacquisition, network,\
    \ and operating system buﬀers that\nensure overall regularity of data samples\
    \ at the cost of ms-\nlevel time delays. For data acquired through an IP socket\n\
    connection, network delays may be signiﬁcant and constantly\nvarying. Finally,\
    \ Windows or any other multitasking oper-\nating system introduces variable delays\
    \ in the processing\nof asynchronous ﬂows—in a multitasking system, data are\n\
    most often processed only when the corresponding task or\nprogram is activated\
    \ and not when the data ﬁrst becomes\navailable.\nDataRiver was developed in an\
    \ attempt to solve these\nsynchronization problems. DataRiver is a ﬂexible and\
    \ uni-\nversal high-precision synchronization engine, providing a\nstrong and\
    \ near real-time synchronization of simultaneous\ndata streams. It has been designed\
    \ and tested with accuracy of\nbetter than 2 ms, even when synchronizing data\
    \ acquisition\nstreams from diﬀerent computers (running Windows, Unix,\nLinux,\
    \ or Mac OSX) over a local area network or the\ninternet subnet. The DataRiver\
    \ application interfaces several\nhardware and is typically seen as a server to\
    \ DataRiver Clients\nthat display or process data. However, each DataRiver client\n\
    can also add output data to the “data river,” so the strict\nconcept of server\
    \ and client does not apply.\nThe ﬂexibility of the ERICA framework stems from\
    \ its\nmodular design—data output from a variety of devices are\nmanaged by specialized\
    \ device drivers that convert each data\nstream into a device-independent stream.\
    \ These streams are\nthen merged in real time and combined into a “river” (hence\n\
    the name DataRiver). DataRiver device drivers are currently\navailable for several\
    \ types of input devices and data systems\nincluding Biosemi EEG, PhaseSpace and\
    \ OptiTrack motion\ncapture systems, eye trackers, and the Wii remote (Nintendo,\n\
    Inc.). This enables the rapid development of a wide range of\nexperimental paradigms\
    \ that can be tailored for a variety of\nmultimodal experimental or application\
    \ environments. Data\nfrom incoming DataRiver data streams may be used in real\n\
    time by clients for recording, online data processing, and/or\nto provide feedback\
    \ to the subject(s) being monitored.\nDataRiver has integrated support for data\
    \ exchange in real\ntime between one or more remote computers connected\nto a\
    \ local area network (LAN), enabling distributed and\ncooperative experiments\
    \ (Figure 5). New drivers and online\ndata processing applications can easily\
    \ be added to DataRiver\nto meet evolving research needs.\nMatRiver is a MATLAB\
    \ DataRiver client optimized for\nreal-time EEG data processing, buﬀering and\
    \ visualiza-\ntion using the OpenGL-based Simulink 3-D toolbox (The\nMathWorks,\
    \ Inc.). MatRiver communicates with DataRiver\nby calling a binary library of\
    \ functions under Windows\nOS. MatRiver allows online performance of common EEG\n\
    preprocessing steps such as channel selection, channel re-\nreferencing, frequency\
    \ ﬁltering and linear spatial ﬁltering\nusing a pre-deﬁned ICA source signal unmixing\
    \ matrix\n[6]. Most often, these steps may be accomplished in near\nreal time\
    \ by directly calling relevant EEGLAB functions.\nMatRiver also includes routines\
    \ to dynamically detect “bad”\nchannels and compensate for them by taking into\
    \ account a\nlinear ICA source propagation model. Preprocessed channel\nor independent\
    \ component (IC) signals are accumulated\nand can subsequently be used for classiﬁcation\
    \ using MAT-\nLAB tools such as BCILAB (see following). MatRiver uses\nMatlab\
    \ “timers” to run in the background allowing real-\ntime processing in a nonblocking\
    \ manner, even including\nnear real-time interactive exploration of the incoming\
    \ data\nfrom the Matlab command line. Continuous visualizations\nof data characteristics\
    \ such as alpha band energy are also\npossible. In short, Matriver functions provide\
    \ an elegant\nand straightforward pipeline for EEG preprocessing and\nclassiﬁcation\
    \ using the rich tool set and programming\nsimplicity of MATLAB.\n7. Designing\
    \ Brain-Computer Interfaces\nwith BCILAB\nAfter results of data stream synchronization\
    \ and preprocess-\ning have been accomplished within the ERICA framework,\none\
    \ may use BCILAB, an open-source MATLAB toolbox and\nEEGLAB [2] plug-in, to support\
    \ brain-computer interface\n(BCI) research, and more generally, the design, learning\n\
    (or adaptation), use, and evaluation of real-time predictive\nmodels operating\
    \ on signals. The main objects of study\nin BCILAB are Brain-Computer Interface\
    \ (BCI) models\n[24], generally deﬁned as systems that take human bio-\nsignals\
    \ as input and output estimates of some aspect of\nthe subject’s cognitive state.\
    \ The signals processed by BCIs\nare traditionally restricted to EEG signals,\
    \ but may include\nother modalities, such as motion-capture data or skin\nconductance\
    \ (plus context parameters such as vehicle state,\nprevious events, etc.). These\
    \ data can be processed either\nusing BCILAB running as a data processing node\
    \ in a\nreal-time experimentation environment (e.g., ERICA), or\noﬄine simulated\
    \ real-time applications to existing data. The\nclassiﬁer outputs of a BCI can\
    \ be streamed to a real-time\napplication to eﬀect stimulus or prosthetic control,\
    \ or may\nComputational Intelligence and Neuroscience\n9\nDataRiver buﬀer\nEEG\
    \ stream\nMotion\nEye tracker\nViewer\nRT\nData streams\nData collection computer\n\
    Producer\nHotspots\nWiimote\nStimulus delivery\nFrom DataRiver\nTo DataRiver\n\
    Matlab buﬀer\nEvent trigger\nRaw data\nIC actitivies\nClassiﬁcation\nvisualization\n\
    MatRiver\nVisualization computer\nOnline applications\nThe data river\nSynchronize\n\
    Figure 5: An ERICA data ﬂow involving two separate computers each running an instance\
    \ of the DataRiver application. Dashed lines\nindicate control signals. Here,\
    \ computer visualization is performed using the Matlab DataRiver client MatRiver.\n\
    be derived post hoc from recorded data, for example for\nstatistical analysis\
    \ of the model’s prediction accuracy when\napplied to a database of previously\
    \ recorded data. BCILAB\nis highly ﬂexible and most accessible cognitive states\
    \ can be\ninvestigated, for example imagined movements (aﬀecting in\nsensorimotor\
    \ mu rhythms), surprise (provoking, e.g., the\noddball P3), or indicators of drowsiness.\n\
    The tools provided by BCILAB facilitate most steps\nin BCI research, including\
    \ the design, implementation,\nlearning, evaluation, and on- or oﬀ-line application\
    \ of BCI\n(or other) models. Further tasks, including the exploration\nof recorded\
    \ data and visualization of model parameters\nmay be supported using EEGLAB tools.\
    \ BCILAB has several\nlayers, the top layer including a graphic interface, a scripting\n\
    interface, and a real-time application interface, with a second\nlayer including\
    \ core model learning, model execution, and\nmodel evaluation functions. These\
    \ core facilities in turn\nrely on a framework of “BCI paradigms”, which can be\n\
    understood as prototypical template-like approaches to\ndesigning a BCI model.\
    \ Pre-deﬁned paradigms include\ncommon spatial patterns (CSP), logarithmic band-power\n\
    estimates, and the approach proposed in the dual augmented\nlagrange framework\
    \ [25]. A BCI “paradigm” deﬁnes the\nentire approach as it would be described\
    \ in a publication,\nfrom raw input data to ﬁnal output, and usually involves\n\
    both a learning and a prediction stage, because suﬃcient\nperformance can often\
    \ only be achieved after a model\nis learned (or calibrated) based on sample data\
    \ from a\ngiven session, subject, or task. BCI paradigms can be fully\ncustomized\
    \ by the user, including removal or addition of\nentire components, but come with\
    \ defaults for all their\nparameters, both to keep the learning curve gentle as\
    \ well\nas to minimize the amount of information that must be\nspeciﬁed.\nAt lower\
    \ levels, BCILAB provides additional frameworks\ndesigned to be extensible and\
    \ ﬂexible and to have low imple-\nmentation overhead. In particular, most BCI\
    \ paradigms are\ndeﬁned within a “data ﬂow” scheme wherein information\nis passed\
    \ through several stages that are themselves plug-\nin frameworks: ﬁlters (signal\
    \ processing), feature maps\n(feature extraction), and model learners as well\
    \ as predic-\ntors/estimators (using machine learning). These frameworks\nare\
    \ general enough to cover a wealth of implementations,\nsuch as adaptive/statistical\
    \ epoched-signal processing, adap-\ntive feature extraction, and classiﬁcation/regression/density\n\
    estimation, with general (discrete/continuous, multivari-\nate, point-estimate/full-posterior)\
    \ outputs. We are currently\nworking to explore additional concepts including\
    \ hierarchi-\ncal Bayesian models spanning sessions, subjects and (related)\n\
    tasks.\nA simple use case of BCILAB is for the oﬄine reanalysis\nof a BCI study.\
    \ For example, given a collection of data sets,\none per subject, containing imagined\
    \ movements of either\nthe left or the right hand in random order, with events\
    \ “SL”\n10\nComputational Intelligence and Neuroscience\nTable 2: Signal processing,\
    \ feature extraction, and machine learning algorithms included in the BCILAB/EEGLAB\
    \ framework.\nSignal processing\nFeature extraction\nMachine learning algorithms\n\
    (i) Channel selection\n(i) Multiwindow averages [26, 27]\n(i) Linear discriminant\
    \ Analysis (LDA) [28]\n(ii) Resampling\n(ii) Common Spatial Patterns (CSP)\n[29]\n\
    (ii) Quadratic discriminant analysis (QDA)\n[30]\n(iii) Artifact rejection (spike\
    \ detection, bad\nwindow detection, bad channel detection,\nlocal peak detection)\n\
    (iii) Spectrally-weighted common\nspatial patterns [31]\n(iii) Regularized and\
    \ analytically regularized\nLDA and QDA [30, 32]\n(iv) Envelope extraction\n(iv)\
    \ Adaptive autoregressive modeling,\nfrom BioSig [33]\n(iv) Linear SVM [34] (LIBLINEAR/CVX)\n\
    (v) Epoch extraction\n(1) Dual-agumented lagrange\n(DAL) [25]\n(v) Kernel SVM\
    \ [34]\n(1) Time-frequency window selection\n(2) Frequency-domain DAL\n(FDAL)\n\
    (vi) Gaussian mixture models (GMM), 9\nmethods [35–37])\n(2) Spectral transformation\n\
    (3) Independent Modulators [38]\n(vii) Regularized and variational Bayesian\n\
    logistic regression and sparse Bayesian\nlogistic regression [39, 40]\n(vi) Baseline\
    \ ﬁltering\n(4) Multiband-CSP [41]\n(1) Hierarchical kernel learning [42]\n(vii)\
    \ Resampling\n(5) Multi-Model Independent\ncomponent features\n(viii) Relevance\
    \ vector machines (RVM)\n[43]\n(viii) Re-referencing\n(1) group-sparse/rank-sparse\
    \ linear and\nlogistic regression [25]\n(ix) Surface Laplacian ﬁltering [44]\n\
    (2) high-dimensional Gaussian Bayes\ndensity estimator/classiﬁer\n(x) ICA methods\
    \ (Infomax, FastICA, AMICA)\n[6, 45]\n(3) Voting metalearner\n(xi) Spectral ﬁlters\
    \ (FIR, IIR)\n(xii) Spherical spline interpolation [46]\n(1) Signal normalization\n\
    (2) Sparse signal reconstruction (NESTA,\nSBL [47], FOCUSS, l1; currently oﬄine\n\
    only)\n(3) Linear projection\nand “SR” indicating the timing and type of the respective\n\
    cue stimuli, a user of the Matlab-based BCILAB scripting\ninterface may proceed\
    \ as follows: For each subject,\n(1) Load a data set\n≫\n\0\0\x02\n\x03\n\x04\x05\
    \n\x06\x05\a\b\t\0\n\v\f\t\0\t\t\x04\x05\r\n\x0E\x0F\n\0\0\x02\n\x10\x11\n\x12\
    \n(2) Deﬁne an analysis approach (customizing parts of a\nstandard paradigm)\n\
    ≫\n\a\x13\x13\x14\x05\a\x15\x16\n\x03 { \f\x17\x13\0\x15\x18\x17\x19\x10\x1A\n\
    \f\0\e\0\r\n\t\x10\x1A\n{ \f\x17\x1C\x10\x1A\f\x17\x1D\x10 } \x1A\n\x06\0\a\x14\
    \r\0\x14\x10\x1A\n\f\x06\x05\x02\x14\0\x02\x10} \x12\n(3) Apply the approach to\
    \ the data, to get an estimate of\nits performance on the given data\n≫\n\x1E\x13\
    \0\x14\x1F\x05\x14 \a\r\x15\0\x1A \x05\b\n\0\x06\n\x1A\t\n\n\a\n\x04\t\n\n\x04\
    \x15\n\t!\n\x03\n\"\x15\x04\n\n\x14\a\x04\r\v{ \f\b\a\n\a\x10\x1A\0\0\x02\x1A\
    \ . . . \f\a\x13\x13\x14\x05\a\x15\x16\x10\x1A\n\a\x13\x13\x14\x05\a\x15\x16}\
    \ \x11\x12\nThis analysis gives the prediction accuracy results that\nare the\
    \ key ingredient of most BCI publications (along with\nvisualizations). Step (3)\
    \ above also produces a calibrated\npredictive model which can be loaded into\
    \ one of the\nprovided real-time plug-ins (for ERICA, BCI2000 [48],\nand OpenViBE\
    \ [49] real-time environments, with others\nforthcoming) for online testing.\n\
    A major focus of the BCILAB toolbox is to allow, as much\nas possible, that competitive\
    \ BCI estimation performance\nmay be obtained using simply stated procedures (as\
    \ above).\nFor this purpose, a large collection of state-of-the-art meth-\nods\
    \ have been provided and are listed in Table 2. A second,\ncomplementary focus\
    \ is to provide rigorous analyses (e.g.,\nfor performance estimation) by default.\
    \ For this purpose,\na framework for automated cross-validation, systematic\n\
    parameter search, and nested cross-validation is provided,\nComputational Intelligence\
    \ and Neuroscience\n11\nand a suitable evaluation method is automatically chosen\n\
    depending on the supplied data (though the evaluation\nmethod may also be customized).\
    \ For example, if a single\ndata set and at least one unknown parameter is provided\n\
    by the user, nested block-wise cross-validation with safety\nmargins is chosen\
    \ by default. In a similar vein, to rule out\ncommon BCI research errors such\
    \ as accidental non-causal\nsignal processing, oﬄine and online processing uses\
    \ identical\ncode.\nBCILAB aims to be not just a collection of oﬀ-the-\nshelf\
    \ tools to enable BCI experiments, but is designed\nto be a development platform\
    \ for new BCI technology,\nfacilitating the creation of new methods, approaches\
    \ (e.g.,\ncombining existing methods), and paradigms. For this pur-\npose, the\
    \ toolbox provides extensive infrastructure, includ-\ning, among others, the frameworks\
    \ mentioned above, a\nsmall Mathematica-inspired symbolic expression system, an\n\
    Adobe ASL-inspired declarative graphic interface property\nmodel, a decentralized\
    \ distributed computing infrastructure\n(not dependent on MATLAB toolboxes), a\
    \ generic depen-\ndency loader, a transparent multi-level cache for results,\n\
    as well as bundled toolboxes for convenience. All BCILAB\ncode is thoroughly documented,\
    \ with additional citation-\nrich documentation for user-facing functions. Backwards\n\
    compatibility to MATLAB 7.1 is attempted (and reached\nfor most functionality\
    \ except the graphic interface, which\nrequires Matlab 2008a+, due to the use\
    \ of objects).\n8. Conclusion\nThe extended SCCN software suite centered on EEGLAB\
    \ data\nstructures and processing functions is an ongoing product\nof a coordinated\
    \ eﬀort to develop and test new methods\nfor observing and modeling the dynamics\
    \ of noninvasively\nobserved electrophysiological activity in human cortex dur-\n\
    ing a wide range of behavioral task performance, both\npost hoc and in real time.\
    \ The tools we have developed\ntowards this end include software for online data\
    \ streaming\nand storage, advanced oﬄine and online EEG analysis and\nprediction,\
    \ source localization, and multivariate connectivity\nanalysis and visualization.\
    \ These build on and integrate with\nour well-established EEGLAB software suite\
    \ that is now in\nuse by thousands of researchers around the world. We plan\n\
    to continue to extend and further coordinate these modular\ntoolboxes with the\
    \ hope that they will facilitate development\nof novel 21st century EEG analysis\
    \ and data mining tech-\nniques which in turn will lead to transformative gains\
    \ in\nour understanding of human neuroscience, cognition and\nbehavior, facilitating\
    \ a broad range of practical and clinical\napplications.\nContributions and Acknowledgments\n\
    EEGLAB was mainly developed by A. Delorme and S. Makeig\n[2] from the ICA electrophysiology\
    \ toolbox (1997–2001)\nof Makeig et al., with functions and design input from\n\
    many dozens of colleagues and EEGLAB users. The neuro-\nelectromagnetic forward\
    \ head modeling toolbox (NFT) was\ndeveloped by Z. Akalin Acar [3]. SIFT (source\
    \ information\nﬂow toolbox) was developed by T. Mullen. BCILAB has been\ndeveloped\
    \ by C. Kothe inspired by the preceding PhyPA BCI\ntoolbox created by C. Kothe\
    \ and T. Zander at the Berlin\nTechnical University. The ERICA framework was mainly\n\
    developed by A. Vankov and its Matlab elements by N.\nBigdely-Shamlo. Gifts from\
    \ The Swartz Foundation (Old\nField NY), and grant support from the National Institutes\n\
    of Health (USA), the National Science Foundation (USA),\nthe Oﬃce of Naval Research\
    \ (US), and the Army Research\nLaboratories (US) are gratefully acknowledged.\n\
    References\n[1] S. Makeig, S. Debener, J. Onton, and A. Delorme, “Mining\nevent-related\
    \ brain dynamics,” Trends in Cognitive Sciences,\nvol. 8, no. 5, pp. 204–210,\
    \ 2004.\n[2] A. Delorme and S. Makeig, “EEGLAB: an open source\ntoolbox for analysis\
    \ of single-trial EEG dynamics including\nindependent component analysis,” Journal\
    \ of Neuroscience\nMethods, vol. 134, no. 1, pp. 9–21, 2004.\n[3] Z. A. Acar and\
    \ S. Makeig, “Neuroelectromagnetic forward\nhead modeling toolbox,” Journal of\
    \ Neuroscience Methods, vol.\n190, no. 2, pp. 258–270, 2010.\n[4] A. Delorme,\
    \ “Matlab tools for BCI research?” in Human-\nComputer Interaction and Brain-Computer\
    \ Interfaces, D. Tan\nand A. Nijholt, Eds., Springer, 2009.\n[5] S. Makeig, A.\
    \ Delorme, and J. Grethe, “HeadIT: a human\nelectrophysiology data and integrated\
    \ tools resource,” in\nSociety for Neuroscience, San Diego, Calif, USA, 2010.\n\
    [6] S. Makeig et al., “Independent component analysis of elec-\ntroencephalographic\
    \ data,” in Advances in Neural Information\nProcessing Systems, D. Touretzky,\
    \ M. Mozer, and M. Hasselmo,\nEds., pp. 145–151, 1996.\n[7] S. Makeig and M. Inlow,\
    \ “Lapses in alertness: coherence of\nﬂuctuations in performance and EEg spectrum,”\
    \ Electroen-\ncephalography and Clinical Neurophysiology, vol. 86, no. 1, pp.\n\
    23–35, 1993.\n[8] S. Makeig, M. Westerﬁeld, T. P. Jung et al., “Dynamic brain\n\
    sources of visual evoked responses,” Science, vol. 295, no. 5555,\npp. 690–694,\
    \ 2002.\n[9] Y. Benjamini and D. Yekutieli, “The control of the false\ndiscovery\
    \ rate in multiple testing under dependency,” Annals\nof Statistics, vol. 29,\
    \ no. 4, pp. 1165–1188, 2001.\n[10] J. Onton, A. Delorme, and S. Makeig, “Frontal\
    \ midline EEG\ndynamics during working memory,” NeuroImage, vol. 27, no.\n2, pp.\
    \ 341–356, 2005.\n[11] A. Delorme, M. Westerﬁeld, and S. Makeig, “Medial prefrontal\n\
    theta bursts precede rapid motor responses during visual\nselective attention,”\
    \ Journal of Neuroscience, vol. 27, no. 44, pp.\n11949–11959, 2007.\n[12] H. Si,\
    \ “Adaptive tetrahedral Mesh generation by constrained\nDelaunay reﬁnement,” International\
    \ Journal for Numerical\nMethods in Engineering, vol. 75, no. 7, pp. 856–880,\
    \ 2008.\n[13] Z. Akalin-Acar and N. G. Gencer, “An advanced boundary\nelement\
    \ method (BEM) implementation for the forward\nproblem of electromagnetic source\
    \ imaging,” Physics in\nMedicine and Biology, vol. 49, no. 21, pp. 5011–5028,\
    \ 2004.\n[14] N. G. Gencer and C. E. Acar, “Sensitivity of EEG and MEG\nmeasurements\
    \ to tissue conductivity,” Physics in Medicine and\nBiology, vol. 49, no. 5, pp.\
    \ 701–717, 2004.\n12\nComputational Intelligence and Neuroscience\n[15] A. M.\
    \ Dale, B. Fischl, and M. I. Sereno, “Cortical surface-\nbased analysis—I. Segmentation\
    \ and surface reconstruction,”\nNeuroImage, vol. 9, no. 2, pp. 179–194, 1999.\n\
    [16] Z. Akalin Acar, G. Worrell, and S. Makeig, “Patch-based\ncortical source\
    \ localization in epilepsy,” in Proceedings of the\nIEEE EMBC, Minneapolis, Minn,\
    \ USA, 2009.\n[17] S. L. Bressler and A. K. Seth, “Wiener-Granger Causality: a\
    \ well\nestablished methodology,” Neuroimage. In press.\n[18] C. Granger, “Investigating\
    \ causal relations by econometric\nmodels and cross-spectral methods,” Econometrica,\
    \ vol. 37, pp.\n424–438, 1969.\n[19] M. Kaminski, “Multichannel data analysis\
    \ in biomedical\nresearch,” in Understanding Complex Systems, V. K. Jirsa and\n\
    A. R. McIntosh, Eds., Handbook of Brain Connectivity series,\npp. 327–355, Springer,\
    \ Berlin, Germany, 2007.\n[20] M. Ding, S. L. Bressler, W. Yang, and H. Liang,\
    \ “Short-\nwindow spectral analysis of cortical event-related potentials\nby adaptive\
    \ multivariate autoregressive modeling: data pre-\nprocessing, model validation,\
    \ and variability assessment,”\nBiological Cybernetics, vol. 83, no. 1, pp. 35–45,\
    \ 2000.\n[21] J. Theiler, S. Eubank, A. Longtin, B. Galdrikian, and J. Doyne\n\
    Farmer, “Testing for nonlinearity in time series: the method of\nsurrogate data,”\
    \ Physica D, vol. 58, no. 1–4, pp. 77–94, 1992.\n[22] A. Vankov, Adapt c\n\0 1987–2003\
    \ and Variet´e , c\n\0 2000, 2001\nare property of EEG Solutions LLC, and are\
    \ used under free\nlicense for scientiﬁc non-proﬁt research, 1987.\n[23] S. Makeig,\
    \ K. Gramann, T. P. Jung, T. J. Sejnowski, and H.\nPoizner, “Linking brain, mind\
    \ and behavior,” International\nJournal of Psychophysiology, vol. 73, no. 2, pp.\
    \ 95–100, 2009.\n[24] J. R. Wolpaw, N. Birbaumer, D. J. McFarland, G. Pfurtscheller,\n\
    and T. M. Vaughan, “Brain-computer interfaces for commu-\nnication and control,”\
    \ Clinical Neurophysiology, vol. 113, no.\n6, pp. 767–791, 2002.\n[25] R. Tomioka\
    \ and K. R. M¨uller, “A regularized discriminative\nframework for EEG analysis\
    \ with application to brain-\ncomputer interface,” NeuroImage, vol. 49, no. 1,\
    \ pp. 415–432,\n2010.\n[26] B. Blankertz, G. Curio, and K. M¨uller, “Classifying\
    \ single trial\nEEG: towards brain computer interfacing,” in Proceedings of\n\
    the Advances in Neural Information Processing Systems (NIPS\n’01), T. Diettrich,\
    \ S. Becker, and Z. Ghahramani, Eds., pp. 157–\n164, 2002.\n[27] B. Blankertz,\
    \ C. Sch¨afer, G. Dornhege, and G. Curio, “Single\ntrial detection of EEG error\
    \ potentials: A tool for increasing\nBCI transmission rates,” in Proceedings of\
    \ the Artiﬁcial Neural\nNetworks (ICANN ’02), 2002.\n[28] R. Fisher, “The use\
    \ of multiple measurements in taxonomic\nproblems,” Annals of Eugenics, vol. 7,\
    \ pp. 179–188, 1936.\n[29] H. Ramoser, J. M¨uller-Gerking, and G. Pfurtscheller,\
    \ “Optimal\nspatial ﬁltering of single trial EEG during imagined hand\nmovement,”\
    \ IEEE Transactions on Rehabilitation Engineering,\nvol. 8, no. 4, pp. 441–446,\
    \ 2000.\n[30] J. Friedman, “Regularized discriminant analysis,” Journal of the\n\
    American Statistical Association, vol. 84, no. 405, pp. 165–175,\n1989.\n[31]\
    \ R. Tomioka, G. Dornhege, K. Aihara, and K. R. M¨uller, “An\niterative algorithm\
    \ for spatio-temporal ﬁlter optimization,”\nin Proceedings of the 3rd International\
    \ BCI Workshop and\nTraining Course, Verlag der Technischen Universit¨at Graz,\n\
    Graz, Austria, 2006.\n[32] O. Ledoit and M. Wolf, “A well-conditioned estimator\
    \ for\nlarge-dimensional covariance matrices,” Journal of Multivari-\nate Analysis,\
    \ vol. 88, no. 2, pp. 365–411, 2004.\n[33] A. Schl¨ogl, The Electroencephalogram\
    \ and the Adaptive Autore-\ngressive Model: Theory and Applications, Shaker, Aachen,\n\
    Germany, 2000.\n[34] B. Sch¨olkopf and A. Smola, Learning with Kernels, MIT Press,\n\
    Cambridge, Mass, USA, 2002.\n[35] J. Bilmes, Gentle Tutorial of the EM Algorithm\
    \ and Its\nApplication to Parameter Estimation for Gaussian Mixture\nand Hidden\
    \ Markov Models, International Computer Science\nInstitute, 1998.\n[36] N. Vlassis\
    \ and A. Likas, “A greedy EM algorithm for Gaussian\nmixture learning,” in Neural\
    \ Processing Letters, vol. 15, Kluwer\nAcademic Publishers, 2002.\n[37] M. A.\
    \ T. Figueiredo and A. K. Jain, “Unsupervised learning of\nﬁnite mixture models,”\
    \ IEEE Transactions on Pattern Analysis\nand Machine Intelligence, vol. 24, no.\
    \ 3, pp. 381–396, 2002.\n[38] J. Onton and S. Makeig, “High-frequency broadband\
    \ mod-\nulations of electroencephalographic spectra,” Frontiers in\nNeuroscience,\
    \ vol. 159, pp. 99–120, 2009.\n[39] T. Jaakkola and M. Jordan, “A variational\
    \ approach to bayesian\nlogistic regression models and their extensions,” in Proceedings\n\
    of the 6th International Workshop on Artiﬁcial Intelligence and\nStatistics, 1997.\n\
    [40] D. Wipf, S. Nagarajan, J. Platt, D. Koller, Y. Singer, and S.\nRoweis, A\
    \ New View of Automatic Relevance Determination,\nMIT Press, 2008.\n[41] K. K.\
    \ Ang, Z. Y. Chin, H. Zhang, and C. Guan, “Filter\nBank Common Spatial Pattern\
    \ (FBCSP) in brain-computer\ninterface,” in Proceedings of the International Joint\
    \ Conference\non Neural Networks (IJCNN ’08), pp. 2390–2397, June 2008.\n[42]\
    \ F. Bach, “Exploring large feature spaces with hierarchical\nmultiple Kernel\
    \ learning,” in Proceedings of the Advances in\nNeural Information Processing\
    \ Systems (NIPS ’08), 2008.\n[43] M. E. Tipping, “Sparse Bayesian learning and\
    \ the relevance\nvector machine,” Journal of Machine Learning Research, vol. 1,\n\
    no. 3, pp. 211–244, 2001.\n[44] F. Babiloni, C. Babiloni, L. Fattorini, F. Carducci,\
    \ P. Ono-\nrati, and A. Urbano, “Performances of surface Laplacian\nestimators:\
    \ a study of simulated and real scalp potential\ndistributions,” Brain Topography,\
    \ vol. 8, no. 1, pp. 35–45, 1995.\n[45] J. A. Palmer, K. Kreutz-Delgado, B. D.\
    \ Rao, and S. Makeig,\n“Modeling and estimation of dependent subspaces with non-\n\
    radially symmetric and skewed densities,” in Proceedings of\nthe 7th International\
    \ Conference on Independent Component\nAnalysis and Signal Separation, London,\
    \ UK, 2007.\n[46] F. Perrin, J. Pernier, and O. Bertrand, “Mapping of scalp poten-\n\
    tials by surface spline interpolation,” Electroencephalography\nand Clinical Neurophysiology,\
    \ vol. 66, no. 1, pp. 75–81, 1987.\n[47] D. P. Wipf, J. P. Owen, H. T. Attias,\
    \ K. Sekihara, and S.\nS. Nagarajan, “Robust Bayesian estimation of the location,\n\
    orientation, and time course of multiple correlated neural\nsources using MEG,”\
    \ NeuroImage, vol. 49, no. 1, pp. 641–655,\n2010.\n[48] G. Schalk, D. J. McFarland,\
    \ T. Hinterberger, N. Birbaumer, and\nJ. R. Wolpaw, “BCI2000: a general-purpose\
    \ brain-computer\ninterface (BCI) system,” IEEE Transactions on Biomedical\nEngineering,\
    \ vol. 51, no. 6, pp. 1034–1043, 2004.\n[49] Y. Renard, F. Lotte, G. Gibert et\
    \ al., “OpenViBE: an open-\nsource software platform to design, test, and use\
    \ brain-\ncomputer interfaces in real and virtual environments,” Pres-\nence,\
    \ vol. 19, no. 1, pp. 35–53, 2010.\nSubmit your manuscripts at\nhttp://www.hindawi.com\n\
    Computer Games \n Technology\nInternational Journal of\nHindawi Publishing Corporation\n\
    http://www.hindawi.com\nVolume 2014\nHindawi Publishing Corporation\nhttp://www.hindawi.com\n\
    Volume 2014\nDistributed \n Sensor Networks\nInternational Journal of\nAdvances\
    \ in\nFuzzy\nSystems\nHindawi Publishing Corporation\nhttp://www.hindawi.com\n\
    Volume 2014\nInternational Journal of\nReconfigurable\nComputing\nHindawi Publishing\
    \ Corporation \nhttp://www.hindawi.com\nVolume 2014\nHindawi Publishing Corporation\n\
    http://www.hindawi.com\nVolume 2014\n Applied \nComputational \nIntelligence and\
    \ Soft \nComputing\n Advances in \nArtificial \nIntelligence\nHindawi Publishing Corporation\n\
    http://www.hindawi.com\nVolume 2014\nAdvances in\nSoftware Engineering\nHindawi\
    \ Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\nHindawi Publishing\
    \ Corporation\nhttp://www.hindawi.com\nVolume 2014\nElectrical and Computer \n\
    Engineering\nJournal of\nJournal of\nComputer Networks \nand Communications\n\
    Hindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\nHindawi Publishing\
    \ Corporation\nhttp://www.hindawi.com\nVolume 2014\n Advances in \nMultimedia\n\
    \ International Journal of \nBiomedical Imaging\nHindawi Publishing Corporation\n\
    http://www.hindawi.com\nVolume 2014\nArtificial\nNeural Systems\nAdvances in\n\
    Hindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\nRobotics\n\
    Journal of\nHindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\n\
    Hindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\nComputational\
    \ \nIntelligence and \nNeuroscience\nIndustrial Engineering\nJournal of\nHindawi\
    \ Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\nModelling & \n\
    Simulation \nin Engineering\nHindawi Publishing Corporation \nhttp://www.hindawi.com\n\
    Volume 2014\nThe Scientific \nWorld Journal\nHindawi Publishing Corporation \n\
    http://www.hindawi.com\nVolume 2014\nHindawi Publishing Corporation\nhttp://www.hindawi.com\n\
    Volume 2014\nHuman-Computer\nInteraction\nAdvances in\nComputer Engineering\n\
    Advances in\nHindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\n"
  inline_citation: '>'
  journal: Computational Intelligence and Neuroscience
  limitations: '>'
  pdf_link: https://downloads.hindawi.com/journals/cin/2011/130714.pdf
  publication_year: 2011
  relevance_score1: 0
  relevance_score2: 0
  title: 'EEGLAB, SIFT, NFT, BCILAB, and ERICA: New Tools for Advanced EEG Processing'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1145/3072959.3073663
  analysis: '>'
  authors:
  - Daniel Holden
  - Taku Komura
  - Jun Saito
  citation_count: 377
  full_citation: '>'
  full_text: '>

    This website uses cookies We occasionally run membership recruitment campaigns
    on social media channels and use cookies to track post-clicks. We also share information
    about your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Use the check boxes below to
    choose the types of cookies you consent to have stored on your device. Use necessary
    cookies only Allow selected cookies Allow all cookies Necessary Preferences Statistics
    Marketing Show details       skip to main content University of Nebraska Lincoln
    Browse About Sign in Register Journals Magazines Proceedings Books SIGs Conferences
    People Search ACM Digital Library Advanced Search Journal Home Just Accepted Latest
    Issue Archive Authors Editors Reviewers About Contact Us HomeACM JournalsACM Transactions
    on GraphicsVol. 36, No. 4Phase-functioned neural networks for character control
    RESEARCH-ARTICLE SHARE ON Phase-functioned neural networks for character control
    Authors: Daniel Holden , Taku Komura , Jun Saito Authors Info & Claims ACM Transactions
    on GraphicsVolume 36Issue 4Article No.: 42pp 1–13https://doi.org/10.1145/3072959.3073663
    Published:20 July 2017Publication History 388 citation 3,710 Downloads eReaderPDF
    ACM Transactions on Graphics Volume 36, Issue 4 Previous Next Abstract Supplemental
    Material References Cited By Index Terms Recommendations Comments Skip Abstract
    Section Abstract We present a real-time character control mechanism using a novel
    neural network architecture called a Phase-Functioned Neural Network. In this
    network structure, the weights are computed via a cyclic function which uses the
    phase as an input. Along with the phase, our system takes as input user controls,
    the previous state of the character, the geometry of the scene, and automatically
    produces high quality motions that achieve the desired user control. The entire
    network is trained in an end-to-end fashion on a large dataset composed of locomotion
    such as walking, running, jumping, and climbing movements fitted into virtual
    environments. Our system can therefore automatically produce motions where the
    character adapts to different geometric environments such as walking and running
    over rough terrain, climbing over large rocks, jumping over obstacles, and crouching
    under low ceilings. Our network architecture produces higher quality results than
    time-series autoregressive models such as LSTMs as it deals explicitly with the
    latent variable of motion relating to the phase. Once trained, our system is also
    extremely fast and compact, requiring only milliseconds of execution time and
    a few megabytes of memory, even when trained on gigabytes of motion data. Our
    work is most appropriate for controlling characters in interactive scenes such
    as computer games and virtual reality systems. Skip Supplemental Material Section
    Supplemental Material papers-0357.mp4 MP4 583.1 MB Play streamDownload Available
    for Download zip a42-holden.zip (132.2 MB) Supplemental files. References Rami
    Ali Al-Asqhar, Taku Komura, and Myung Geol Choi. 2013. Relationship Descriptors
    for Interactive Motion Adaptation. In Proc. SCA. 45--53. James Bergstra, Olivier
    Breuleux, Frédéric Bastien, Pascal Lamblin, Razvan Pascanu, Guillaume Desjardins,
    Joseph Turian, David Warde-Farley, and Yoshua Bengio. 2010. Theano: a CPU and
    GPU Math Expression Compiler. In Proc. of the Python for Scientific Computing
    Conference (SciPy). Oral Presentation. Mario Botsch and Leif Kobbelt. 2005. Real-Time
    Shape Editing using Radial Basis Functions. Computer Graphics Forum (2005). Show
    All References Cited By View all Kleanthous T and Martini A. (2024). Making motion
    matching stable and fast with Lipschitz-continuous neural networks and Sparse
    Mixture of Experts. Computers & Graphics. 10.1016/j.cag.2024.103911. 120. (103911).
    Online publication date: 1-May-2024. https://linkinghub.elsevier.com/retrieve/pii/S0097849324000463
    Menapace W, Siarohin A, Lathuilière S, Achlioptas P, Golyanik V, Tulyakov S and
    Ricci E. (2024). Promptable Game Models: Text-guided Game Simulation via Masked
    Diffusion Models. ACM Transactions on Graphics. 43:2. (1-16). Online publication
    date: 30-Apr-2024. https://doi.org/10.1145/3635705 Zhu W, Ma X, Ro D, Ci H, Zhang
    J, Shi J, Gao F, Tian Q and Wang Y. (2024). Human Motion Generation: A Survey.
    IEEE Transactions on Pattern Analysis and Machine Intelligence. 46:4. (2430-2449).
    Online publication date: 1-Apr-2024. https://doi.org/10.1109/TPAMI.2023.3330935
    Show All Cited By Index Terms Phase-functioned neural networks for character control
    Computing methodologies Artificial intelligence Computer vision Image and video
    acquisition Motion capture Recommendations Neural animation layering for synthesizing
    martial arts movements Interactively synthesizing novel combinations and variations
    of character movements from different motion skills is a key problem in computer
    animation. In this paper, we propose a deep learning framework to produce a large
    variety of martial arts ... Read More Interactive character animation by learning
    multi-objective control We present an approach that learns to act from raw motion
    data for interactive character animation. Our motion generator takes a continuous
    stream of control inputs and generates the character''s motion in an online manner.
    The key insight is modeling ... Read More Mode-adaptive neural networks for quadruped
    motion control Quadruped motion includes a wide variation of gaits such as walk,
    pace, trot and canter, and actions such as jumping, sitting, turning and idling.
    Applying existing data-driven character control frameworks to such data requires
    a significant amount of ... Read More Comments 46 References View Issue’s Table
    of Contents Footer Categories Journals Magazines Books Proceedings SIGs Conferences
    Collections People About About ACM Digital Library ACM Digital Library Board Subscription
    Information Author Guidelines Using ACM Digital Library All Holdings within the
    ACM Digital Library ACM Computing Classification System Digital Library Accessibility
    Join Join ACM Join SIGs Subscribe to Publications Institutions and Libraries Connect
    Contact Facebook Twitter Linkedin Feedback Bug Report The ACM Digital Library
    is published by the Association for Computing Machinery. Copyright © 2024 ACM,
    Inc. Terms of Usage Privacy Policy Code of Ethics'
  inline_citation: '>'
  journal: ACM transactions on graphics
  limitations: '>'
  pdf_link: null
  publication_year: 2017
  relevance_score1: 0
  relevance_score2: 0
  title: Phase-functioned neural networks for character control
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/s17112556
  analysis: '>'
  authors:
  - Abdulmajid Murad
  - Jae-Young Pyun
  citation_count: 324
  full_citation: '>'
  full_text: ">\nsensors\nArticle\nDeep Recurrent Neural Networks for Human\nActivity\
    \ Recognition\nAbdulmajid Murad and Jae-Young Pyun *\nID\nDepartment of Information\
    \ Communication Engineering, Chosun University, 375 Susuk-dong, Dong-gu,\nGwangju\
    \ 501-759, Korea; aaymurad@chosun.kr\n* Correspondence: jypyun@chosun.ac.kr; Tel.:\
    \ +82-62-230-7021\nReceived: 18 October 2017; Accepted: 3 November 2017; Published:\
    \ 6 November 2017\nAbstract: Adopting deep learning methods for human activity\
    \ recognition has been effective in\nextracting discriminative features from raw\
    \ input sequences acquired from body-worn sensors.\nAlthough human movements are\
    \ encoded in a sequence of successive samples in time, typical\nmachine learning\
    \ methods perform recognition tasks without exploiting the temporal correlations\n\
    between input data samples. Convolutional neural networks (CNNs) address this\
    \ issue by using\nconvolutions across a one-dimensional temporal sequence to capture\
    \ dependencies among input data.\nHowever, the size of convolutional kernels restricts\
    \ the captured range of dependencies between\ndata samples. As a result, typical\
    \ models are unadaptable to a wide range of activity-recognition\nconﬁgurations\
    \ and require ﬁxed-length input windows. In this paper, we propose the use of\
    \ deep\nrecurrent neural networks (DRNNs) for building recognition models that\
    \ are capable of capturing\nlong-range dependencies in variable-length input sequences.\
    \ We present unidirectional, bidirectional,\nand cascaded architectures based\
    \ on long short-term memory (LSTM) DRNNs and evaluate their\neffectiveness on\
    \ miscellaneous benchmark datasets. Experimental results show that our proposed\n\
    models outperform methods employing conventional machine learning, such as support\
    \ vector\nmachine (SVM) and k-nearest neighbors (KNN). Additionally, the proposed\
    \ models yield better\nperformance than other deep learning techniques, such as\
    \ deep believe networks (DBNs) and CNNs.\nKeywords: human activity recognition;\
    \ deep learning; recurrent neural networks\n1. Introduction\nHuman activity recognition\
    \ (HAR) has recently attracted increased attention from both researchers\nand\
    \ industry with the goal of advancing ubiquitous computing and human computer\
    \ interactions.\nIt has many real-world applications, ranging from healthcare\
    \ to personal ﬁtness, gaming, tactical\nmilitary applications, and indoor navigation.\
    \ There are two major types of HAR: systems that use\nwearable sensors and systems\
    \ that use external devices, such as cameras and wireless RF modules.\nIn sensor-based\
    \ HAR, wearable sensors are attached to a human body and the human activity is\n\
    translated into speciﬁc sensor signal patterns that can be segmented and identiﬁed.\n\
    The application of deep learning for HAR has led to signiﬁcant enhancements in\
    \ recognition\naccuracy by overcoming many of the obstacles encountered by traditional\
    \ machine learning methods.\nIt provides a data-driven approach for learning efﬁcient\
    \ discriminative features from raw data, resulting\nin a hierarchy from low-level\
    \ features to high-level abstractions. The strength of deep learning lies in\n\
    its ability to automatically extract features in a task dependent manner. It avoids\
    \ reliance on heuristic\nhand-crafted features and scales better for more complex\
    \ behavior-recognition tasks.\nThe widespread use and availability of sensing\
    \ technologies is generating an ever-growing amount\nof data, which along with\
    \ enhanced computation power have contributed to more feasible applications\n\
    of deep learning methods. These methods can be utilized to extract valuable contextual\
    \ information\nSensors 2017, 17, 2556; doi:10.3390/s17112556\nwww.mdpi.com/journal/sensors\n\
    Sensors 2017, 17, 2556\n2 of 17\nfrom physical activities in an unconstrained\
    \ environment. Furthermore, many researchers have\nemployed deep learning approaches\
    \ to build HAR models in an end-to-end fashion, thereby achieving\nsuperior performance\
    \ compared to previous conventional methods. This strategy has been effective\
    \ in\nhandling more complex human activities and taking advantage of the proliferating\
    \ data.\nIn the ﬁeld of deep learning, there is a growing interest in recurrent\
    \ neural networks (RNNs),\nwhich have been used for many sequence modeling tasks.\
    \ They have achieved promising performance\nenhancements in many technical applications,\
    \ such as speech recognition [1], language modeling [2],\nvideo processing [3],\
    \ and many other sequence labeling tasks [4].\nThe rationale behind their\neffectiveness\
    \ for sequence-based tasks is their ability to exploit contextual information\
    \ and learn\nthe temporal dependencies in variable-length input data.\nIn this\
    \ paper, we propose the use of long short-term memory (LSTM)-based deep RNNs\n\
    (DRNNs) to build HAR models for classifying activities mapped from variable-length\
    \ input sequences.\nWe develop architectures based on deep layers of unidirectional\
    \ and bidirectional RNNs, independently,\nas well as a cascaded architecture progressing\
    \ from bidirectional to unidirectional RNNs. These models\nare then tested on\
    \ various benchmark datasets to validate their performance and generalizability\
    \ for a\nlarge range of activity recognition tasks. The major contributions of\
    \ our work are as follows:\n1.\nWe demonstrate the effectiveness of using unidirectional\
    \ and bidirectional DRNNs for HAR tasks\nwithout any additional data-preprocessing\
    \ or merging with other deep learning methods.\n2.\nWe implement bidirectional\
    \ DRNNs for HAR models. To the best of our knowledge, this the ﬁrst\nwork to do\
    \ so.\n3.\nWe introduce models that are able to classify variable-length windows\
    \ of human activities. This is\naccomplished by utilizing RNN’s capacity to read\
    \ variable-length sequences of input samples\nand merge the prediction for each\
    \ sample into a single prediction for the entire window segment.\nThe remainder\
    \ of this paper is organized as follows: Section 2 provides a brief review of\
    \ related\nworks employing deep learning for HAR and Section 3 presents a background\
    \ overview of RNNs and\nLSTM. The proposed models and experimental setup are explained\
    \ in Sections 4 and 5, respectively.\nPerformance results and comparisons are\
    \ presented in Section 6. Finally, discussion and analysis are\npresented in Section\
    \ 7.\n2. Related Works\nEarly work on using deep learning methods in HAR was based\
    \ on deep belief networks\n(DBNs) [5], which were built by stacking multiple layers\
    \ of restricted Boltzmann machine (RBM).\nSubsequent DBN-based models exploited\
    \ the intrinsic temporal sequences in human activities by\nimplementing hidden\
    \ Markov models (HMMs) above the RBM layers [6]. They performed an\nunsupervised\
    \ pre-training step to generate intrinsic features and then used the available\
    \ data labels to\ntune the model. However, HMMs are limited by their numbers of\
    \ possible hidden states and become\nimpractical when modeling long-range dependencies\
    \ in large context windows.\nThe use of convolutional neural networks (CNNs) for\
    \ HAR was introduced in [7], but they used a\nshallow model and only a single\
    \ accelerometer. Another model in [8] used deep CNNs with only a\nsingle accelerometer.\
    \ A multi-sensor recognition framework was developed by in [9], where a deep\n\
    CNN model for two accelerometers was proposed. A new multi-channel time series\
    \ architecture\nof CNNs was built in [10]. The architecture proposed in [11] was\
    \ a compact model of shallow\nconvolutional layers applied to the spectral domain\
    \ of inertial signals. This model was optimized for\nlow-power devices, but it\
    \ reintroduced the extraction of handcrafted features by using a spectrogram\n\
    of the input data. The successful implementation of CNNs for HAR is due to their\
    \ capability for\nlearning powerful and discriminative features, as well as utilizing\
    \ convolutions across 1-D temporal\nsequence in order to capture local dependencies\
    \ between nearby input samples. To capture local\ndependencies, CNNs use parameter\
    \ sharing across time—applying the same convolutional kernel\nat each time segment—and\
    \ local connectivity—neurons receiving inputs from small groups of input\nSensors\
    \ 2017, 17, 2556\n3 of 17\nsamples—between adjacent layers [12]. However, sharing\
    \ parameters across time is insufﬁcient for\ncapturing all of the correlations\
    \ between input samples. Additionally, local connectivity limits the\noutput to\
    \ a function of a small number of neighboring input samples.\nIn this work, we\
    \ propose the use of DRNNs for HAR models in order exploit their internal\nmemories\
    \ for capturing the temporal dynamics of activity sequences. In contrast to [13],\
    \ where CNNs\nand RNNs were used in a uniﬁed framework for activity recognition,\
    \ our models are based only\non DRNNs, meaning we avoid the complexity of combining\
    \ multiple deep learning approaches\nin a single framework.\nAdditionally, by\
    \ using only DRNNs, our models are more ﬂexible for\nclassifying variable-length\
    \ windows, in contrast to the ﬁxed-length windows required by CNNs.\nBidirectional\
    \ DRNNs have been used in many domains, such as speech recognition and text-to-speech\n\
    synthesis [1,14]. In in this work we propose using them in HAR models.\n3. Background:\
    \ Recurrent Neural Networks\n3.1. Recurrent Neural Networks\nAn RNN is neural\
    \ network architecture that contains cyclic connections, which enable it to\n\
    learn the temporal dynamics of sequential data. A hidden layer in an RNN contains\
    \ multiple nodes.\nAs shown in Figure 1, each node has a function for generating\
    \ the current hidden state ht and output yt\nby using its current input xt and\
    \ the previous hidden state ht−1 according to the following equations:\nht = F(Whht−1\
    \ + Uhxt + bh)\n(1)\nyt = F\n\0Wyht + by\n\x01\n,\n(2)\nwhere Wh, Uh, and Wy are\
    \ the weight for the hidden-to-hidden recurrent connection, input-to-hidden\n\
    connection, and hidden-to-output connection, respectively. bh and by are bias\
    \ terms for the hidden and\noutput states, respectively. Additionally, there is\
    \ an activation function F associated with each node.\nThis is an element-wise\
    \ non-linearity function, commonly chosen from various existing functions,\nsuch\
    \ as the sigmoid, hyperbolic tangent, or rectiﬁed linear unit (ReLU).\nFigure\
    \ 1. Schematic diagram of an RNN node where ht−1 is the previous hidden state,\
    \ xt is the current\ninput sample, ht is the current hidden state, yt is the current\
    \ output, and F is the activation function.\n3.2. Long Short-Term Memory (LSTM)\n\
    Training regular RNNs can be challenging because of vanishing or exploding gradient\
    \ problems\nthat hinder the network’s ability to backpropagate gradients through\
    \ long-range temporal intervals [15].\nThis precludes modeling wide-range dependencies\
    \ between input data for human activities when\nlearning movements with long context\
    \ windows. However, LSTM-based RNNs can model temporal\nsequences and their wide-range\
    \ dependencies by replacing the traditional nodes with memory cells\nthat have\
    \ internal and outer recurrence.\nA memory cell contains more parameters and gate\
    \ units, as shown in Figure 2. These gates control\nwhen to forget previous hidden\
    \ states and when to update states with new information. The function\nof each\
    \ cell component is as follows:\nSensors 2017, 17, 2556\n4 of 17\n•\nInput gate\
    \ it controls the ﬂow of new information to the cell.\n•\nForget gate ft determins\
    \ when to forget content regarding the internal state.\n•\nOutput gate ot controls\
    \ which information ﬂows to the output.\n•\nInput modulation gate gt is the main\
    \ input to the cell.\n•\nInternal state ct handles cell internal recurrence.\n\
    •\nHidden state ht contains information from previously seen samples within the\
    \ context window:\nit = σ(bi + Uixt + Wiht−1 )\n(3)\nft = σ\n\x10\nbf + Uf xt\
    \ + Wf xt−1\n\x11\n(4)\not = σ (bo + Uoxt + Woht−1)\n(5)\ngt = σ\n\0bg + Ugxt\
    \ + Wght−1\n\x01\n(6)\nct = ftct−1 + gt it\n(7)\nht = tanh(ct)ot\n(8)\nThe training\
    \ process of LSTM-RNNs is essentially focused on learning the parameters b , U,\
    \ and W of\nthe cell gates, as shown in Equations (3)–(6).\nFigure 2. Schematic\
    \ of LSTM cell structure with an internal recurrence ct and an outer recurrence\
    \ ht.\nCell gates are the input gate it, input modulation gate gt, forget gate\
    \ ft, and output gate ot. In contrast\nto an RNN node, the current output yt is\
    \ considered equal to current hidden state ht.\n4. Proposed DRNN Architectures\n\
    A schematic diagram of the proposed HAR system is presented in Figure 3. It performs\
    \ direct\nend-to-end mapping from raw multi-modal sensor inputs to activity label\
    \ classiﬁcations. It classiﬁes\nthe label of an activity performed during a speciﬁc\
    \ time window. The input is a discrete sequence of\nequally spaced samples (x1,\
    \ x2, . . . , xT), where each data point xt is a vector of individual samples\n\
    observed by the sensors at time t. These samples are segmented into windows of\
    \ a maximum time\nindex T and fed to an LSTM-based DRNN model. The model outputs\
    \ a sequence of scores representing\nactivity label predictions in which there\
    \ is a label prediction for each time step\n\0yL\n1 , yL\n2 , . . . , yL\nT\n\x01\
    \n,\nwhere yL\nt\n∈ RC is a vector of scores representing the prediction for a\
    \ given input sample xt and C\nis the number of activity classes. There will a\
    \ score for each time-step predicting the type of activity\noccurring at time\
    \ t. The prediction for the entire window T is obtained by merging the individual\n\
    scores into a single prediction. We have used late-fusion technique in which the\
    \ classiﬁcation decision\nfrom individual samples are combined for the overall\
    \ prediction of a window. Using the “sum rule”\nSensors 2017, 17, 2556\n5 of 17\n\
    in Equation (9) as the fusion scheme yields better results than other schemes,\
    \ which is theoretically\njustiﬁed in [16]. We applied a softmax layer over Y\
    \ to convert prediction scores into probabilities:\nY = 1\nT ∑\nT\nt=1 yL\nt\n\
    (9)\nFigure 3. The proposed HAR architecture. The inputs are raw signals obtained\
    \ from multimodal-sensors,\nsegmented into windows of length T and fed into LSTM-based\
    \ DRNN model. The model outputs class\nprediction scores for each timestep, which\
    \ are then merged via late-fusion and fed into the softmax layer\nto determine\
    \ class membership probability.\nWe have developed architectures for three DRNN\
    \ models, which are as follows:\n4.1. Unidirectional LSTM-Based DRNNs Model\n\
    The ﬁrst model is built using a unidirectional LSTM-based DRNN, as shown in Figure\
    \ 4.\nUsing sufﬁcient number of DRNN layers can result in a very powerful model\
    \ for transforming\nraw data into a more abstract representation, as well as for\
    \ learning the temporal dependencies in time\nseries data [1]. The input is a\
    \ discrete sequence of equally spaced samples (x1, x2, . . . , xT), which are\n\
    fed into the ﬁrst layer at time t (t = 1, 2, . . . , T).\nFirst, the hidden state\
    \ hℓ\n0 and internal state cℓ\n0 of every layer ℓ are initialized to zeros. The\
    \ ﬁrst\nlayer uses the input sample xt at time t, previous hidden state h1\nt−1,\
    \ and previous internal hidden state\nc1\nt−1 to generate the ﬁrst layer output\
    \ y1\nt given its parameter θ1 as follows:\ny1\nt , h1\nt , c1\nt = LSTM1\x10\n\
    c1\nt−1, h1\nt−1, xt; θ1\x11\n,\n(10)\nSensors 2017, 17, 2556\n6 of 17\nwhere\
    \ θℓ represents the parameters (b, U, W) of the LSTM cells for layer ℓ, as shown\
    \ in Equations (3)–(6).\nAny layer ℓ in the upper layers uses the output of the\
    \ lower layer yℓ−1\nt\nas its input:\nyℓ\nt , hℓ\nt, cℓ\nt = LSTMℓ\x10\ncℓ\nt−1,\
    \ hℓ\nt−1, yℓ−1\nt\n; θℓ\x11\n.\n(11)\nThe top layer L outputs\n\0yL\n1 , yL\n\
    2 , . . . , yL\nT\n\x01\n, which is a sequence of scores representing the\npredictions\
    \ at every time step in the window T.\nFigure 4. Unidirectional LSTM-based DRNN\
    \ model consisting of an input layer, several hidden layers,\nand an output layer.\
    \ The number of hidden layers is a hyperparameter that is tuned during training.\n\
    4.2. Bidirectional LSTM-Based DRNN Model\nThe second model architecture is built\
    \ by using a bidirectional LSTM-based DRNN, as shown in\nFigure 5. It includes\
    \ two parallel LSTM tracks: forward and backward loops for exploiting context\n\
    from the past and future of a speciﬁc time step in order to predict its label\
    \ [17]. In the ﬁrst layer,\nthe forward track (LSTM f1) reads the input window\
    \ T from left to right, whereas the backward track\n(LSTMb1) reads the input from\
    \ right to left according to:\ny f1\nt , h f1\nt , c f1\nt\n= LSTM f1\x10\nc f1\n\
    t−1, h f1\nt−1, xt; W f1\x11\n(12)\nyb1\nt , hb1\nt , cb1\nt = LSTMb1\x10\ncb1\n\
    t−1, hb1\nt−1, xt; Wb1\x11\n.\n(13)\nThe top layer L outputs a sequence of scores\
    \ at each time step for both forward LSTM\n\x10\ny f L\n1 , y f L\n2 , . . . ,\
    \ y f L\nT\n\x11\nand backward LSTM\n\x10\nybL\n1 , ybL\n2 , . . . , ybL\nT\n\x11\
    \n. These scores are then combined\ninto a single vector Y ∈ RC representing classes\
    \ prediction for the window segment T. The late-fusion\nin this case will differ\
    \ from that used in the unidirectional DRNN, Equation (9), because there are two\n\
    outputs resulting from the forward and backward tracks, which are combined as\
    \ follows:\nY = 1\nT ∑\nT\nt=1\n\x10\ny f L\nt\n+ ybL\nt\n\x11\n(14)\nSensors\
    \ 2017, 17, 2556\n7 of 17\nFigure 5. Bidirectional LSTM-based DRNN model consisting\
    \ of an input layer, multiple hidden layers,\nand an output layer. Every layer\
    \ has a forward LSTM f ℓ and a backward LSTMbℓ track, and the\nnumber of hidden\
    \ layers is a hyperparameter that is tuned during training.\n4.3. Cascaded Bidirectional\
    \ and Unidirectional LSTM-based DRNN Model\nThe third model architecture, shown\
    \ in Figure 6, is motivated by [18]. It is a cascaded structure\nin which the\
    \ ﬁrst layer is a bidirectional RNN and the upper layers are unidirectional. The\
    \ ﬁrst layer\nhas a forward LSTM track LSTM f1 that generates an output\n\x10\n\
    y f1\n1 , y f1\n2 , . . . , y f1\nT\n\x11\nand a backward\nLSTM track LSTMb1 that\
    \ generates an output\n\x10\nyb1\n1 , yb1\n2 , . . . , yb1\nT\n\x11\n. These two\
    \ types of outputs are\nconcatenated to form a new output\n\0y1\n1, y1\n2, . .\
    \ . , y1\nT\n\x01\n, which is fed into the second unidirectional layer:\ny1\n\
    t = y f1\nt\n+ yb1\nT−t+1\n(15)\nFigure 6. Cascaded unidirectional and bidirectional\
    \ LSTM-based DRNN model. The ﬁrst layer is\nbidirectional, whereas the upper layers\
    \ are unidirectional. The number of hidden unidirectional layers\nis a hyperparameter\
    \ that is tuned during training.\nSensors 2017, 17, 2556\n8 of 17\nThe upper layers\
    \ are then treated in the same manner as in the unidirectional model described\
    \ in\nSection 4.1.\n5. Experimental Setup\n5.1. Datasets of Human Activities\n\
    In order to train and evaluate the proposed models, we considered ﬁve public benchmark\
    \ datasets\nfor HAR. The datasets contain diverse movement data, captured by on-body\
    \ sensors. They contain\nvarious activities performed in different environments\
    \ and are used to validate the applicability and\ngeneralization of our models\
    \ for a large variety of activity recognition tasks. Table 1 summarizes the\n\
    experimental datasets and the following are brief descriptions of them:\n1)\n\
    UCI-HAD [19]: Dataset for activities of daily living (ADL) recorded by using a\
    \ waist-mounted\nsmartphone with an embedded 3-axis accelerometer,\ngyroscope,\n\
    and magnetometer.\nAll nine channels from the 3-axis sensors are used as inputs\
    \ for our DRNN model at every\ntime step. This dataset contains only six classes:\
    \ walking, ascending stairs, descending stairs,\nsitting, standing, and laying.\n\
    2)\nUSC-HAD [20]: Dataset collected by using a high performance IMU (3D accelerometer\
    \ and\ngyroscope) sensor positioned on volunteers’ front right hips. The dataset\
    \ contains 12 basic human\nactivities: walking forward, walking left, walking\
    \ right, walking upstairs, walking downstairs,\nrunning forward, jumping up, sitting,\
    \ standing, sleeping, in elevator up, and in elevator down.\nWe considered 11\
    \ classes by combining the last two activities into a single “in elevator” activity.\n\
    The reason for this combination is that the model is unable to differentiate between\
    \ the two classes\nusing only a single IMU sensor. Additional barometer readings\
    \ are required to determine height\nchanges in an elevator and discriminate between\
    \ the two classes (up or down in elevator).\n3)\nOpportunity [21]: Dataset comprised\
    \ of ADL recorded in a sensor-rich environment. We consider\nonly recordings from\
    \ on-body sensors, which are seven IMUs and 12 3D-accelerometers placed\non various\
    \ body parts. There are 18 activity classes: opening and closing two types of\
    \ doors,\nopening and closing three drawers at different heights, opening and\
    \ closing a fridge, opening and\nclosing a dishwasher, cleaning a table, drinking\
    \ from a cup, toggling a switch, and a null-class for\nany non-relevant actions.\n\
    4)\nDaphnet FOG [22]: Dataset containing movement data from patients with Parkinson’s\
    \ disease\n(PD) who suffer from freezing of gait (FOG) symptoms.\nThe dataset\
    \ was built using\nthree 3D-accelerometers attached to the shank, thigh, and lower\
    \ back of the patients. Two classes\n(freeze and normal) were considered depending\
    \ on whether or not the gait of a patient was frozen\nwhen the sample was recorded.\
    \ We used this dataset to train our model to detect FOG episodes in\nPD patients\
    \ and prove the suitability of our model for gait analysis using only wearable\
    \ sensors.\n5)\nSkoda [23]:\nDataset containing activities of an employee in a\
    \ car maintenance scenario.\nWe consider recordings from a single 3D accelerometer,\
    \ which is placed on the right hand of\nan employee. The dataset contains 11 activity\
    \ classes: writing on a notepad, opening hood,\nclosing hood, checking gaps on\
    \ front door, opening left front door, closing left front door,\nclosing both\
    \ left doors, checking trunk gaps, opening and closing trunk, and a null-class\
    \ for any\nnon-relevant actions.\nSensors 2017, 17, 2556\n9 of 17\nTable 1. Summary\
    \ of human activity datasets used to evaluate the proposed deep learning models.\n\
    Training window length indicates the number of samples in a window that we found\
    \ to yield the best\nresults for each dataset. Each dataset was divided into 80%\
    \ for training and 20% for testing.\nDataset\n# of\nClasses\nSensors\n# of Subjects\n\
    Sampling\nRate\nTraining\nWindow\nLength\n# of\nTraining\nExamples\n# of\nTesting\n\
    Examples\nUCI-HAD [19]\n6\n3D Acc., Gyro., and\nMagn. of a smartphone\n30\n50\
    \ Hz\n128\n11,988\n2997\nUSC-HAD [20]\n12\n3D Acc. & Gyro\n14 (5 sessions)\n100\
    \ Hz\n128\n44,000\n11,000\nOpportunity [21]\n18\n7 IMU sensors (3D ACC,\nGyro\
    \ & Mag.) & 12 Acc.\n4 (5 sessions)\n30 Hz\n24\n55,576\n13,894\nDaphnet FOG [22]\n\
    2\n3 3D Acc.\n10\n64 Hz\n32\n57,012\n14,253\nSkoda [23]\n11\n3D Acc.\n1 (19 sessions)\n\
    98 Hz\n128\n4411\n1102\n5.2. Training\nWe trained our DRNN models on each dataset\
    \ using 80% of the data for training and 20% for\ntesting. The weights (parameters)\
    \ of the models were initialized randomly and then updated to\nminimize a cost\
    \ function L. We used the mean cross entropy between the ground truth labels and\n\
    the predicted output labels as the cost function. The ground truth labels are\
    \ given in the datasets\nand indicate the true classes (labels) for the segmented\
    \ windows. They are provided as a one-hot\nvector O ∈ RC with a value ok associated\
    \ with each class k. The predicted label ˆO ∈ RC contains the\nprobability of\
    \ every class pk generated by our model:\nL\n\0O, ˆO\n\x01 = −∑\nC\nk=1 ok log\
    \ pk\n(16)\nWe used an optimization algorithm called Adam that minimizes the cost\
    \ function by\nbackpropagating its gradient and updating model parameters [24].\
    \ Training was conducted on a\nGPU-based TensorFlow framework in order to utilize\
    \ the parallel computation power of a GPU [25].\nThe dropout technique was used\
    \ to avoid overﬁtting in our model [26]. Although dropout is typically\napplied\
    \ to all nodes in a network, we followed the convention of applying dropout to\
    \ the connections\nbetween layers (not on recurrent-connections or intra-cell\
    \ connections). The probability of dropping a\nnode during a training iteration\
    \ is determined by the dropout probability p, which is a hyperparameter\ntuned\
    \ during training and represents the percentage of units to drop. Adopting dropout\
    \ regularization\ntechnique led to a signiﬁcant improvement in performance by\
    \ preventing overﬁtting. Figure 7 presents\nthe accuracy and cost of training\
    \ and testing processes for the unidirectional DRNN model using\nthe USC-HAD dataset.\
    \ The gap between training and testing accuracies, as well as the gap between\n\
    training and testing costs is very small. This indicates that the dropout technique\
    \ is very effective at\nforcing the model to generalize and be resilient to overﬁtting.\n\
    During training, the datasets were segmented with different window lengths, as\
    \ outlined in\nTable 1. The optimal window length of a dataset depends on the\
    \ sampling rate and the type of activities\nperformed. We tested various lengths\
    \ by “trial-and-error” method, then chose the window length\nthat gave better\
    \ performance results. Training was performed using the raw data without any further\n\
    data preprocessing or intermediate intervention. The training and testing are\
    \ generally performed\nusing ﬁxed-length windows, but the inputs of models may\
    \ be using variable-length windows in the\nreal-time data acquisition scenarios.\
    \ In real-time application of HAR, data are captured over the course\nof time\
    \ and the delay in DRNNs is not ﬁxed. Instead, the network can emit the corresponding\
    \ label\nfor a variable-length input segment. This is in contrast to other methods,\
    \ such as CNNs, in which\nthe network must wait until a given ﬁxed-length input\
    \ segment is complete, before emitting the\ncorresponding label.\nSensors 2017,\
    \ 17, 2556\n10 of 17\nFigure 7. Accuracy and cost of the unidirectional DRNN model\
    \ for the USC-HAD dataset over\nmini-batch training iterations: (a) training and\
    \ testing accuracies; (b) cross-entropy cost between\nground truth labels and\
    \ predicted labels for both training and testing.\n5.3. Performance Metrics\n\
    To verify the performance of the proposed models, we employed four widely used\
    \ evaluation\nmetrics for multi-class classiﬁcation [27]:\n1)\nPrecision: Measures\
    \ the number of true samples out of those classiﬁed as positive. The overall\n\
    precision is the average of the precisions for each class:\nPer − class Precisionc\
    \ =\ntpc\ntpc + f pc\n(17)\nOverall Precision = 1\nC\n \nC\n∑\nc=1\ntpc\ntpc +\
    \ f pc\n!\n,\n(18)\nwhere tpc is the true positive rate of a class c, f pc is\
    \ the false positive rate, and C is the number of\nclasses in the dataset.\n2)\n\
    Recall (Sensitivity): Measures the number correctly classiﬁed samples out of the\
    \ total samples of\na class. The overall recall is the average of the recalls\
    \ for each class:\nPer − class Recallc =\ntpc\ntpc + f nc\n(19)\nOverall Recall\
    \ = 1\nC\n \nC\n∑\nc=1\ntpc\ntpc + f nc\n!\n,\nwhere f nc is the false negative\
    \ rate of a class c.\n3)\nAccuracy: Measures the proportion of correctly predicted\
    \ labels over all predictions:\nOverall Accuraccy =\nTP + TN\nTP + TN + FP + FN\
    \ ,\nwhere TP = ∑C\nc=1 tpc is the overall true positive rate for a classiﬁer\
    \ on all classes, TN = ∑C\nc=1 tnc is\nthe overall true negative rate, FP = ∑C\n\
    c=1 f pc is the overall false positive rate, and FN = ∑C\nc=1 f nc\nis the overall\
    \ false negative rate.\nSensors 2017, 17, 2556\n11 of 17\n4)\nF1-score: A weighted\
    \ harmonic mean of precision and recall:\nF1 score =\nC\n∑\nc=1\n2\n\x10nc\nN\n\
    \x11\n× precisionc × recallc\nprecisionc + recallc\n,\n(22)\nwhere nc is the number\
    \ of samples of a class c and N = ∑C\nc=1 nc is the total number of samples in\n\
    a set with C classes. The F1-score is typically adopted for imbalanced datasets\
    \ that have more\nsamples of one class and less of another, such as the Daphnet\
    \ FOG dataset. There are more\ninstances of normal walking (majority class) than\
    \ of FOG (minority class). The Opportunity\ndataset is also imbalanced because\
    \ there are many more instances of the null class than any\nof the other classes.\
    \ Using accuracy as a performance metric in imbalanced datasets can be\nmisleading,\
    \ because any classiﬁer can perform well by correctly classifying the majority\
    \ class\neven if it wrongly classiﬁes the minority class.\n6. Results\nThe performance\
    \ results of our proposed models are presented in this section. The results are\n\
    compared to other previously introduced methods, which are tested on the same\
    \ datasets.\n6.1. UCI-HAD\nFor the UCI-HAD dataset, we found that the unidirectional\
    \ DRNN model with four layers yields\nbest performance results in terms of per-class\
    \ precision and recall, as shown in Figure 8a. The overall\nclassiﬁcation accuracy\
    \ is 96.7%, outperforming other methods, such as CNNs [28], support vector\nmachine\
    \ (SVM) [19], and sequential extreme learning machine (ELM) [29]. Figure 8b presents\
    \ a chart of\nthe observed accuracy from our model in comparison with the accuracies\
    \ achieved by other methods.\nFigure 8. Performance results of the proposed unidirectional\
    \ DRNN model for the UCI-HAD dataset:\n(a) Confusion matrix for the test set containing\
    \ the activity recognition results. The rows represent the\ntrue labels and the\
    \ columns represent the model classiﬁcation results; (b) Comparative accuracy\
    \ of the\nproposed model against other methods.\n6.2. USC-HAD\nWe found that the\
    \ unidirectional DRNN model with four layers yields the best results for the\n\
    USC-HAD dataset. Figure 9a presents the classiﬁcation results for the test set\
    \ in the form of a confusion\nmatrix, along with the per-class recall and precision\
    \ results. The proposed method achieved better\noverall accuracy than other methods,\
    \ such as CNNs [28], least squares support vector machine\n(LS-SVM) [30], and\
    \ random forest [31], as shown in Figure 9b.\nSensors 2017, 17, 2556\n12 of 17\n\
    Figure 9. Performance results of the proposed unidirectional DRNN model for USC-HAD\
    \ dataset:\n(a) Confusion matrix for the test set displaying activity recognition\
    \ results with per-class precision and\nrecall; (b) Comparative accuracy of proposed\
    \ model against other methods.\n6.3. Opportunity\nThe Opportunity dataset is very\
    \ complex and contains a wide range of activities.\nTherefore, the bidirectional\
    \ DRNN model with three layers yields the best performance results.\nThe confusion\
    \ matrix in Figure 10a summarizes the classiﬁcation results of the proposed model\n\
    for the test set, along with the per-class precision and recall results. The proposed\
    \ method outperforms\nother methods, such as those based on deep believe networks\
    \ (DBNs) [10], SVM [10], and CNNs [13].\nIt also outperformed the state-of-the-art\
    \ method, which is a combination of CNNS and unidirectional\nRNNs [13], for the\
    \ opportunity dataset. Figure 10b presents a performance comparison between the\
    \ F1\nscore of the proposed method and those reported by other methods. We used\
    \ the F1 score as a basis\nfor comparison because the Opportunity dataset is imbalanced,\
    \ manifested by the dominance of the\nNull class.\nSensors 2017, 17, 2556\n13\
    \ of 17\nFigure 10. Performance results of the proposed bidirectional DRNN model\
    \ for the Opportunity dataset:\n(a) Confusion matrix for the test set as well\
    \ as per-class precision and recall results; (b) Comparative F1\nscore of proposed\
    \ model against other methods.\n6.4. Daphnet FOG\nFor the Daphnet FOG dataset,\
    \ we found that the cascaded DRNN model with one bidirectional\nlayer and two\
    \ upper unidirectional layers yields the best results.\nFigure 11a summarizes\
    \ the\nclassiﬁcation results for the test set. The low values of recall and precision\
    \ for the “Freeze” class\nare caused by the dominance of the “Normal” class. However,\
    \ our proposed method still outperforms\nother methods, such as k-nearest neighbors\
    \ (KNN) [32] and CNNs [33], in terms of F1 score, as shown\nin Figure 11b.\nSensors\
    \ 2017, 17, 2556\n14 of 17\nFigure 11. Performance results of the proposed cascaded\
    \ DRNN model for the Daphnet FOG dataset:\n(a) Confusion matrix for the test set,\
    \ along with per-class precision and recall; (b) F1 score of the\nproposed method\
    \ in comparison with other methods.\n6.5. Skoda\nWe found that the cascaded DRNN\
    \ model yields the best results for the Skoda dataset. The model\nis built using\
    \ one bidirectional layer and two upper unidirectional layers. Figure 12a presents\
    \ the\nclassiﬁcation results for the test set in the form of a confusion matrix,\
    \ along with the per-class recall\nand precision results. The proposed method\
    \ results in an overall accuracy of 92.6%, outperforming\nother methods such as\
    \ HMMs [23], DBNs [6], and CNNs [11], as shown in Figure 12b.\nFigure 12. Cont.\n\
    Sensors 2017, 17, 2556\n15 of 17\nFigure 12.\nPerformance results of the proposed\
    \ cascaded DRNN model for the Skoda dataset:\n(a) Confusion matrix for the test\
    \ set as well as per-class precision and recall results; (b) Comparative\naccuracy\
    \ of proposed model against other methods.\n7. Discussion\nThe performance results\
    \ of the proposed models clearly demonstrate that DRNNs are very\neffective for\
    \ HAR. All of the architectures performed very well on all of the datasets. These\
    \ datasets\nare diverse, which proves that our models are effective for a broad\
    \ range of activity recognition tasks.\nThe unidirectional DRNN model yielded\
    \ the best results for the UCI-HAD and USC-HAD datasets,\nthe bidirectional DRNN\
    \ model gave better results for the Opportunity dataset, and the cascaded DRNN\n\
    model performed better on the Daphnet FOG and Skoda dataset. Table 2 contains\
    \ a performance\nsummary for the four datasets.\nTable 2. Performance summary\
    \ for the proposed DRNNs on four diverse datasets.\nModel\nDataset\nOverall\n\
    Accuracy\nAverage\nPrecision\nAverage\nRecall\nF1 Score\nUnidirectional DRNN\n\
    UCI\n96.7%\n96.8%\n96.7%\n0.96\nUnidirectional DRNN\nUSC-HAD\n97.8%\n97.4.0%\n\
    97.4%\n0.97\nBidirectional DRNN\nOpportunity\n92.5%\n86.7%\n83.5%\n0.92\nCascaded\
    \ DRNN\nDaphnet FOG\n94.1%\n84.7%\n78.9%\n0.93\nCascaded DRNN\nSkoda\n92.6%\n\
    93.0%\n92.6%\n0.92\nThere are two main reasons for the superb performance of the\
    \ proposed models for HAR\ntasks. First, including sufﬁcient deep layers enabled\
    \ the models to extract effective discriminative\nfeatures. These features are\
    \ exploited to distinguish between classiﬁed activities and scale up for\nmore\
    \ complex behavior recognitions tasks. Second, employing DRNNs to capture sequential\
    \ and\ntime dependencies between input data samples provided a signiﬁcant improvement\
    \ in performance\ncompared to other methods.\n8. Conclusions\nWe\nhave\npresented\n\
    three\nnovel\nLSTM-based\nDRNN\narchitectures\nfor\nHAR\ntasks.\nAdditionally,\
    \ we empirically evaluated our models by conducting experiments on four miscellaneous\n\
    benchmark datasets.\nExperimental results reveal that the proposed models outperform\
    \ other\nstate-of-the-art methods. The reason for this improvement in performance\
    \ is that our models are able to\nextract more discriminative features by using\
    \ deep layers in a task-dependent and end-to-end fashion.\nFurthermore, our models\
    \ are able to capture the temporal dependencies between input samples\nin activity\
    \ sequences by exploiting DRNN functionality. Future work includes experimentation\
    \ on\nSensors 2017, 17, 2556\n16 of 17\nlarge-scale and complex human activities,\
    \ as well as exploring transfer learning between diverse\ndatasets. Investigating\
    \ resource efﬁcient implementation of a DRNN for low-power devices is also a\n\
    promising future research direction.\nAuthor Contributions: Abdulmajid Murad and\
    \ Jae-Young Pyun conceived the idea and research metrology.\nAbdulmajid Murad\
    \ developed the proposed schemes and performed the experiments. Jae-Young Pyun\
    \ contributed\nto the conception of the study and analysis by directing and supervising\
    \ the research.\nConﬂicts of Interest: The authors declare no conﬂict of interest.\n\
    References\n1.\nGraves, A.; Mohamed, A.; Hinton, G. Speech recognition with deep\
    \ recurrent neural networks.\nIn Proceedings of the IEEE International Conference\
    \ on Acoustics, Speech and Signal Processing, Vancouver,\nBC, Canada, 26–31 May\
    \ 2013; pp. 6645–6649.\n2.\nSundermeyer, M.; Schlüter, R.; Ney, H. LSTM Neural\
    \ Networks for Language Modeling. In Proceedings of\nthe Thirteenth Annual Conference\
    \ of the International Speech Communication Association, Portland, OR,\nUSA, 9–13\
    \ September 2012.\n3.\nYao, L.; Cho, K.; Ballas, N.; Paí, C.; Courville, A. Describing\
    \ Videos by Exploiting Temporal Structure.\nIn Proceedings of the IEEE International\
    \ Conference on Computer Vision, Santiago, Chile, 7–13 December 2015.\n4.\nGraves,\
    \ A. Supervised Sequence Labelling with Recurrent Neural Networks; Studies in\
    \ Computational Intelligence;\nSpringer: Berlin/Heidelberg, Germany, 2012; Volume\
    \ 385, ISBN 978-3-642-24796-5.\n5.\nPlötz, T.; Hammerla, N.Y.; Olivier, P. Feature\
    \ Learning for Activity Recognition in Ubiquitous Computing.\nIn Proceedings of\
    \ the Twenty-Second International Joint Conference on Artiﬁcial Intelligence,\
    \ Barcelona,\nCatalonia, Spain, 16–22 July 2011; Volume 2, pp. 1729–1734.\n6.\n\
    Alsheikh, M.A.; Selim, A.; Niyato, D.; Doyle, L.; Lin, S.; Tan, H.-P. Deep Activity\
    \ Recognition Models with\nTriaxial Accelerometers. In Proceedings of the AAAI\
    \ Workshop: Artiﬁcial Intelligence Applied to Assistive\nTechnologies and Smart\
    \ Environments, Phoenix, AZ, USA, 12 February 2016.\n7.\nZeng, M.; Nguyen, L.T.;\
    \ Yu, B.; Mengshoel, O.J.; Zhu, J.; Wu, P.; Zhang, J. Convolutional Neural Networks\n\
    for Human Activity Recognition using Mobile Sensors. In Proceedings of the 6th\
    \ International Conference\non Mobile Computing, Applications and Services, Austin,\
    \ TX, USA, 6–7 November 2014; pp. 197–205.\n8.\nChen, Y.; Xue, Y. A Deep Learning\
    \ Approach to Human Activity Recognition Based on Single Accelerometer.\nIn Proceedings\
    \ of the IEEE International Conference on Systems, Man, and Cybernetics, Hong\
    \ Kong, China,\n20 June 2015; pp. 1488–1492.\n9.\nHessen, H.-O.; Tessem, A.J.\
    \ Human Activity Recognition with Two Body-Worn Accelerometer Sensors.\nMaster’s\
    \ Thesis, Norwegian University of Science and Technology, Trondheim, Norway, 2015.\n\
    10.\nYang, J.B.; Nguyen, M.N.; San, P.P.; Li, X.L.; Krishnaswamy, S. Deep convolutional\
    \ neural networks on\nmultichannel time series for human activity recognition.\
    \ In Proceedings of the 24th International Joint\nConference on Artiﬁcial Intelligence\
    \ (IJCAI), Buenos Aires, Argentina, 25–31 July 2015.\n11.\nRavi, D.; Wong, C.;\
    \ Lo, B.; Yang, G.-Z. Deep learning for human activity recognition: A resource\
    \ efﬁcient\nimplementation on low-power devices. In Proceedings of the IEEE 13th\
    \ International Conference on Wearable\nand Implantable Body Sensor Networks (BSN),\
    \ San Francisco, CA, USA, 14–17 June 2016; pp. 71–76.\n12.\nWaibel, A.; Hanazawa,\
    \ T.; Hinton, G.; Shikano, K.; Lang, K.J. Phoneme recognition using time-delay\
    \ neural\nnetworks. IEEE Trans. Acoust. Speech Signal Process. 1989, 37, 328–339.\
    \ [CrossRef]\n13.\nOrdóñez, F.J.; Roggen, D. Deep convolutional and LSTM recurrent\
    \ neural networks for multimodal wearable\nactivity recognition. Sensors 2016,\
    \ 16, 115. [CrossRef] [PubMed]\n14.\nFan, Y.; Qian, Y.; Xie, F.; Soong, F.K. TTS\
    \ synthesis with bidirectional LSTM based Recurrent Neural Networks.\nIn Proceedings\
    \ of the Fifteenth Annual Conference of the International Speech Communication\
    \ Association,\nSingapore, 14–18 September 2014; pp. 1964–1968.\n15.\nHochreiter,\
    \ S.; Bengio, Y.; Frasconi, P.; Schmidhuber, J. Gradient Flow in Recurrent Nets:\
    \ The Difﬁculty of\nLearning Long-Term Dependencies. In Field Guide to Dynamical\
    \ Recurrent Networks; Kremer, S., Kolen, J., Eds.;\nWiley-IEEE Press: Hoboken,\
    \ NJ, USA, 2001; pp. 237–243, ISBN 9780470544037.\n16.\nKittler, J.; Hater, M.;\
    \ Duin, R.P.W. Combining classiﬁers. IEEE Trans. Pattern Anal. Mach. Intell. 1996,\n\
    2, 226–239. [CrossRef]\nSensors 2017, 17, 2556\n17 of 17\n17.\nSchuster, M.; Paliwal,\
    \ K.K. Bidirectional recurrent neural networks. IEEE Trans. Signal Process. 1997,\n\
    45, 2673–2681. [CrossRef]\n18.\nWu, Y.; Schuster, M.; Chen, Z.; Le, Q.V.; Norouzi,\
    \ M.; Macherey, W.; Krikun, M.; Cao, Y.; Gao, Q.; Macherey, K.; et al.\nGoogle’s\
    \ Neural Machine Translation System: Bridging the Gap between Human and Machine\
    \ Translation.\nCoRR 2016.\n19.\nAnguita, D.; Ghio, A.; Oneto, L.; Parra, X.;\
    \ Reyes-Ortiz, J.L. A Public Domain Dataset for Human Activity\nRecognition Using\
    \ Smartphones. In Proceedings of the European Symposium on Artiﬁcial Neural Networks,\n\
    Bruges, Belgium, 24–26 April 2013; pp. 24–26.\n20.\nZhang, M.; Sawchuk, A.A. USC-HAD:\
    \ A Daily Activity Dataset for Ubiquitous Activity Recognition Using\nWearable\
    \ Sensors. In Proceedings of the 2012 ACM Conference on Ubiquitous Computing,\
    \ Pittsburgh, PA,\nUSA, 5–8 September 2012; pp. 1036–1043.\n21.\nChavarriaga,\
    \ R.; Sagha, H.; Calatroni, A.; Digumarti, S.T.; Tröster, G.; Millán, J.D.R.;\
    \ Roggen, D.\nThe Opportunity challenge:\nA benchmark database for on-body sensor-based\
    \ activity recognition.\nPattern Recognit. Lett. 2013, 34, 2033–2042. [CrossRef]\n\
    22.\nBachlin, M.; Plotnik, M.; Roggen, D.; Maidan, I.; Hausdorff, J.M.; Giladi,\
    \ N.; Troster, G. Wearable assistant\nfor Parkinson’s disease patients with the\
    \ freezing of gait symptom. IEEE Trans. Inf. Technol. Biomed. 2010,\n14, 436–446.\
    \ [CrossRef] [PubMed]\n23.\nZappi, P.; Lombriser, C.; Stiefmeier, T.; Farella,\
    \ E.; Roggen, D.; Benini, L.; Tröster, G. Activity Recognition\nfrom On-Body Sensors:\
    \ Accuracy-Power Trade-Off by Dynamic Sensor Selection. In Wireless Sensor Networks;\n\
    Springer: Berlin/Heidelberg, Germany, 2008; pp. 17–33.\n24.\nGoodfellow, I.; Bengio,\
    \ Y.; Courville, A. Optimization for Training Deep Models. In Deep Learning; The\
    \ MIT\nPress: Cambridge, MA, USA, 2016; p. 800, ISBN 978-0262035613.\n25.\nAbadi,\
    \ M.; Agarwal, A.; Barham, P.; Brevdo, E.; Chen, Z.; Citro, C.; Corrado, G.S.;\
    \ Davis, A.; Dean, J.;\nDevin, M.; et al. TensorFlow: Large-Scale Machine Learning\
    \ on Heterogeneous Distributed Systems. 2015.\nAvailable online: https://www.tensorﬂow.org/\
    \ (accessed on 13 September 2017).\n26.\nPham, V.; Bluche, T.; Kermorvant, C.;\
    \ Louradour, J. Dropout Improves Recurrent Neural Networks for\nHandwriting Recognition.\
    \ In Proceedings of the 14th International Conference on Frontiers in Handwriting\n\
    Recognition, Crete, Greece, 1–4 September 2014; pp. 285–290.\n27.\nSokolova, M.;\
    \ Lapalme, G. A systematic analysis of performance measures for classiﬁcation\
    \ tasks.\nInf. Process. Manag. 2009, 45, 427–437. [CrossRef]\n28.\nJiang, W. Human\
    \ Activity Recognition using Wearable Sensors by Deep Convolutional Neural Networks.\n\
    In Proceedings of the 23rd ACM International Conference on Multimedia, Brisbane,\
    \ Australia, 26–30 October 2015;\npp. 1307–1310.\n29.\nChandan Kumar, R.; Bharadwaj,\
    \ S.S.; Sumukha, B.N.; George, K. Human activity recognition in cognitive\nenvironments\
    \ using sequential ELM. In Proceedings of the Second International Conference\
    \ on Cognitive\nComputing and Information Processing, Mysuru, India, 12–13 August\
    \ 2016; pp. 1–6.\n30.\nZheng, Y. Yuhuang Human Activity Recognition Based on the\
    \ Hierarchical Feature Selection and\nClassiﬁcation Framework. J. Electr. Comput.\
    \ Eng. 2015, 2015, 34. [CrossRef]\n31.\nPrakash Reddy Vaka, B.B. A Pervasive Middleware\
    \ for Activity Recognition with Smartphones.\nMaster’s Thesis, University of Missouri,\
    \ Columbia, MO, USA, 2015.\n32.\nHammerla, N.; Kirkham, R. On Preserving Statistical\
    \ Characteristics of Accelerometry Data using their\nEmpirical Cumulative Distribution.\
    \ In Proceedings of the 2013 International Symposium on Wearable\nComputers, Zurich,\
    \ Switzerland, 9–12 September 2013; pp. 65–68.\n33.\nRavi, D.; Wong, C.; Lo, B.;\
    \ Yang, G.-Z. A deep learning approach to on-node sensor data analytics for mobile\n\
    or wearable devices. IEEE J. Biomed. Health Inform. 2017, 21, 56–64. [CrossRef]\
    \ [PubMed]\n© 2017 by the authors. Licensee MDPI, Basel, Switzerland. This article\
    \ is an open access\narticle distributed under the terms and conditions of the\
    \ Creative Commons Attribution\n(CC BY) license (http://creativecommons.org/licenses/by/4.0/).\n"
  inline_citation: '>'
  journal: Sensors (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/1424-8220/17/11/2556/pdf?version=1510216718
  publication_year: 2017
  relevance_score1: 0
  relevance_score2: 0
  title: Deep Recurrent Neural Networks for Human Activity Recognition
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/tst.2014.6787363
  analysis: '>'
  authors:
  - Rong Jiang
  - Rongxing Lu
  - Ye Wang
  - Jun Luo
  - Chen Shen
  - Xuemin Shen
  citation_count: 248
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences Loading
    [MathJax]/extensions/MathMenu.js IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More
    Sites Donate Cart Create Account Personal Sign In Browse My Settings Help Access
    provided by: University of Nebraska - Lincoln Sign Out All Books Conferences Courses
    Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals & Magazines
    >Tsinghua Science and Technology >Volume: 19 Issue: 2 Energy-theft detection issues
    for advanced metering infrastructure in smart grid Publisher: TUP Cite This PDF
    Rong Jiang; Rongxing Lu; Ye Wang; Jun Luo; Changxiang Shen; Xuemin Shen All Authors
    234 Cites in Papers 9 Cites in Patents 10969 Full Text Views Open Access Abstract
    Authors Citations Keywords Metrics Abstract: With the proliferation of smart grid
    research, the Advanced Metering Infrastructure (AMI) has become the first ubiquitous
    and fixed computing platform. However, due to the unique characteristics of AMI,
    such as complex network structure, resource-constrained smart meter, and privacy-sensitive
    data, it is an especially challenging issue to make AMI secure. Energy theft is
    one of the most important concerns related to the smart grid implementation. It
    is estimated that utility companies lose more than $25 billion every year due
    to energy theft around the world. To address this challenge, in this paper, we
    discuss the background of AMI and identify major security requirements that AMI
    should meet. Specifically, an attack tree based threat model is first presented
    to illustrate the energy-theft behaviors in AMI. Then, we summarize the current
    AMI energy-theft detection schemes into three categories, i.e., classification-based,
    state estimation-based, and game theory-based ones, and make extensive comparisons
    and discussions on them. In order to provide a deep understanding of security
    vulnerabilities and solutions in AMI and shed light on future research directions,
    we also explore some open challenges and potential solutions for energy-theft
    detection. Published in: Tsinghua Science and Technology ( Volume: 19, Issue:
    2, April 2014) Page(s): 105 - 120 Date of Publication: 15 April 2014 Electronic
    ISSN: 1007-0214 DOI: 10.1109/TST.2014.6787363 Publisher: TUP Authors Citations
    Keywords Metrics More Like This RSA-grid: a grid computing based framework for
    power system reliability and security analysis 2006 IEEE Power Engineering Society
    General Meeting Published: 2006 Robust N−k Security-constrained Optimal Power
    Flow Incorporating Preventive and Corrective Generation Dispatch to Improve Power
    System Reliability CSEE Journal of Power and Energy Systems Published: 2023 Show
    More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS
    VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: Tsinghua Science & Technology
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/5971803/6787360/06787363.pdf
  publication_year: 2014
  relevance_score1: 0
  relevance_score2: 0
  title: Energy-theft detection issues for advanced metering infrastructure in smart
    grid
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/access.2016.2580581
  analysis: '>'
  authors:
  - Hui Jiang
  - Kun Wang
  - Yihui Wang
  - Min Gao
  - Yan Zhang
  citation_count: 178
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Subscribe Donate Cart Create Account
    Personal Sign In Browse My Settings Help Institutional Sign In All Books Conferences
    Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals
    & Magazines >IEEE Access >Volume: 4 Energy big data: A survey Publisher: IEEE
    Cite This PDF Hui Jiang; Kun Wang; Yihui Wang; Min Gao; Yan Zhang All Authors
    171 Cites in Papers 7734 Full Text Views Open Access Comment(s) Abstract Document
    Sections I. Introduction II. Background III. Energy Big Data: Architecture IV.
    Energy Big Data: Key Technologies V. Energy Big Data: Security Show Full Outline
    Authors Figures References Citations Keywords Metrics Abstract: As a significant
    application of energy, smart grid is a complicated interconnected power grid that
    involves sensors, deployment strategies, smart meters, and real-time data processing.
    It continuously generates data with large volume, high velocity, and diverse variety.
    In this paper, we first give a brief introduction on big data, smart grid, and
    big data application in the smart grid scenario. Then, recent studies and developments
    are summarized in the context of integrated architecture and key enabling technologies.
    Meanwhile, security issues are specifically addressed. Finally, we introduce several
    typical big data applications and point out future challenges in the energy domain.
    Topic: Theoretical Foundations for Big Data Applications: Challenges and Opportunities
    Energy big data architecture. Published in: IEEE Access ( Volume: 4) Page(s):
    3844 - 3861 Date of Publication: 2016 Electronic ISSN: 2169-3536 DOI: 10.1109/ACCESS.2016.2580581
    Publisher: IEEE Funding Agency: SECTION I. Introduction Smart grid is a major
    research and development direction in today’s energy industry. It refers to the
    next generation power grid which integrates conventional power grid and management
    of advanced communication networks and pervasive computing capabilities to improve
    control, efficiency, reliability and safety of the grid [1]. Smart grid delivers
    electricity between suppliers and consumers so as to form a bidirectional electricity
    and information flow infrastructure. It fulfills the demands of each stakeholder,
    functionality coordination in electric power generation, terminal electricity
    consuming and power market. It also improves the efficiency in each part of the
    system operation and reduces the cost and environmental impact. At the same time,
    the system reliability, self-healing ability and stability are improved [2]. Integrating
    telecommunication, automation and electric network control, smart grid requires
    reliable real-time data processing. To support this requirement and benefit future
    analysis and decision making, huge amount of historic data should be well fetched
    and stored in a reasonable time budget. In addition, there are various sources
    that huge amount of data can be generated through diverse measurements acquired
    by Intelligent Electronic Devices (IEDs) in the smart grid: Data from power utilization
    habits of users; Data from Phasor Measurement Units (PMUs) for situation awareness;
    Data from energy consumption measured by the widespread smart meters; Data from
    energy market pricing and bidding collected by Automated Revenue Metering (ARM)
    system; Data from management, control and maintenance of device and equipment
    in the electric power generation, transmission and distribution in the grid; Data
    from operating utilities, like financial data and large data sets which are not
    directly obtained through the network measurement. All aforementioned sources
    increase the grid’s data volume. According to the investigation in [3], by 2009
    the amount of data in electric utilities’ system has already reached the level
    of TeraBytes (TBs). With every passing day, more TBs of data are emerging at infrastructure
    company data centers. This fact accelerates the pace of big data technology applying
    to the smart grid area. To obtain a better understanding of the big data application
    on smart grid, we give an overview of energy big data (big data applied in the
    energy domain) covering the recent researches and development in the context of
    an integrated architecture, key enabling technologies, security, typical applications
    and challenges. The remainder of this survey is organized as follows. Overview
    of the energy big data is provided in Section II, and related analytics frameworks
    are presented in Section III. In Section IV, key enabling technologies are listed.
    Section V illustrates the security issues and Section VI looks into main application
    areas. Challenges are discussed in Section VII and Section VIII concludes this
    paper. SECTION II. Background A. Smart Grid Smart grid is a form of electric power
    network. It is a combination of all the power utilities resources, both of renewable
    and non-renewable. As a significant innovation, smart grid provides automatic
    monitoring, protecting and optimizing for the operation of the interconnected
    systems. Not only covering the traditional central generator in the transmission
    network and emerging renewal distributed generator in the distribution system,
    it also serves industrial consumers and home users in aspects of thermostats,
    electric vehicles and intelligent appliances [4]. Characterized by the bidirectional
    connection of electricity and information sets, the smart grid has formed an automated,
    widely distributed delivery power network. Taking advantages from modern communications,
    it can not only deliver real-time data and information but also implement the
    instantaneous management balance of demand and supply [5]. Operations on energy
    storage, demand response and communication between terminal users and power companies
    will make a real large scale data-communicated grid system. This adds complexity
    in the conventional grid and promote offering sustainable progresses to utilities
    and customers [6]. In order to match its complexity, many technologies are exploited
    in the smart grid domain. Examples include wireless networks in telecommunications,
    sensor networks in manufacturing, and big data in computer science. Especially,
    big data is attracting more and more attention in the power grid domain because
    it can help extract valuable information from data sources of wide diversity and
    high volume. B. Big Data Technology Big data technology is an emerging technology
    which applies to data sets where data size is so large and common data-related
    technology tools are hard to capture, manage, and operate under multi-limits.
    Common data-related technology use a consistent, single, traditional data management
    framework, which is only suitable for data with low diversity and volume [7],
    [8]. If coming from diverse data sets, data will not be correlated in space and
    time, and it is hard for those data to get correlated to a unified and generalized
    power system model [9]. Therefore, traditional data-related technology will no
    longer guarantee reliable data management, operation, etc. In this way, big data
    technology provides integrated architectures for complex power grid, effective
    data analysis to aware the unfavorable situation in advance, and various data
    processing methods for different conditions [10]–[13]. C. Big Data in Smart Grid
    Data size in electric power systems have increased dramatically, which results
    in gaps and challenges. The 4Vs data (data with characteristics of volume, variety,
    velocity, and veracity) in smart grid are difficult to be handled within a tolerable
    operating time and hardware resources [14]. Therefore, the big data technology
    has been introduced to the power system. The emerging big data technology does
    not conflict with classical analysis or pretreatment. In fact, it has already
    been applied successfully as a powerful data-driven tool in numerous research
    areas such as financial systems [15], quantum systems [16], biological systems
    [17], and wireless communication networks [18]. Big data sets and their relationship
    with several sample applications are depicted in Fig. 1. FIGURE 1. Big data and
    applications. Show All In the aspect of the field measurement showed in Fig. 1,
    the deployment of PMUs has improved the measurements on instantaneous values of
    voltages and currents for operators with accurate timestamps [19]. PMUs can be
    imported to the state estimator to provide direct state measurement, since they
    provide measurements in both magnitude and angle aspects [20]. This is especially
    interrelated when the system topology such as operations on automated breaker
    change rapidly. PMU data can also be applied in protective relaying operations
    [21]. The use of PMU data is helpful for more accurate and more rapid tripping
    response in measurement. In the aspect of distribution, the management of big
    data is also crucial in order to facilitate applications in the fields of demand
    response, Distributed Energy Resources (DERs), and Electric Vehicles (EVs) [22].
    Improved and secure bi-direction communication and management of the associated
    big data are required for turning loads into dispatchable resources, thus promoting
    DERs to participate in electricity markets [23]. 1) Main Techniques Over the past
    few years, almost all major companies have launched their projects on big data,
    and brought a set of tools which are brand new to the power industry. Those companies
    include IBM, Oracle from IT domain, General Electric, Siemens from the power grid
    domain and start-ups like AutoGrid, Opower, and C3 [24]. In addition, scientists
    have proposed a variety of techniques including optimization and data mining to
    capture, analyze, process and visualize big data that is of large volume and needed
    to be handled within limited time. In order to tackle communication problems and
    data processing problems in the smart grid area, a variety of emerging scalable
    and distributed architectures and frameworks have been proposed. Rogers et al.
    [25] proposed an authenticated control framework for distributed voltage supported
    on the smart grid. A layered architecture was presented for an optimized algorithm
    to follow a chain of command from the transmission grid to the distribution grid
    [26]. In addition, many optimization methods have been exploited to solve quantitative
    problems in smart grid branches such as power distribution, sensor topology, etc.
    Furthermore, Aquino-Lugo et al. [27] provided another analytical framework using
    agent-based technologies to manage data processing. Data mining extracts valuable
    information from data sets. It includes a series of clustering, classification
    and regression. A typical example of data mining under the smart grid scenario
    is the grouping process of customers. Those customers are grouped into different
    classes according to their electricity consumption types and other characteristics.
    Then, the clustering method is applied to generating residential load documents
    [28] and differentiating pattern changes caused by seasonal and temporal factors
    [29]. In smart grid, this data mining technology can be classified into two categories:
    one is Artificial Intelligence (AI) for modeling risk and uncertainty of obtained
    data [30], and the other is estimation based on recorded data. Utilizing fuzzy
    wavelet neural network [31] and estimating with nonparametric methods [32], data
    mining methods obtain enforcement recently. For example, the fuzzy decision tree
    has been used to classify disturbances of power quality [33]. 2) Main Tools Apache
    Hadoop is one of the most well-known and powerful big data tools written in JAVA
    [34]. Providing platforms and infrastructures for specific big data applications
    in business and commerce, it plays an important role on big data related companies,
    such as MapR, Cloudera and Hortonworks [35]. Hadoop usually consists of two major
    components, one is the Hadoop Distributed File System (HDFS) [36] and the other
    is the Hadoop execution engine: MapReduce [37]. HDFS is often applied for data
    storage while MapReduce is used in data processing [38]. As for applications of
    data streaming, operation in the electric power system needs real-time response
    for data processing. For example, a technology called Storm is designed especially
    for real-time data stream analysis [39]. In order to analyze and process interactively,
    the data is generated from interactive environments. Users are able to have real-time
    interaction with computers due to the direct connection to it. Apache Drill is
    a distributed system used for interactive analysis of the big data [40]. The purpose
    of Drill is to have low latency in response to ad-hoc queries. Therefore, it has
    the capability to process PetaBytes (PBs) of data and trillions of records within
    seconds. SECTION III. Energy Big Data: Architecture Supported by many kinds of
    different techniques, big data analysis plays an important role in smart grid.
    One solution architecture provides a three-tier framework for better dealing with
    data high in volume, velocity and variety. For various data generated from smart
    grid, an integrated architecture can also be used for cloud storage and efficient
    processing. A. Role of Big Data in the Smart Grid The data obtained from PMUs,
    smart meters, sensors and other IEDs have opened up a plethora of chances, such
    as predictive analytics, real-time vulnerability assessment, theft detection,
    demand-side-management, economic dispatch, energy trading, etc [41]. Big data
    can help improve the smart grid management to a higher level. For example, by
    enhancing the accessibility of a customer’s electricity consumption data, the
    demand response will be expanded and energy efficiency will be improved [42].
    Similarly, analyzing data obtained from PMUs and IEDs will help to improve customer
    service, prevent outages, maximize safety and ensure service reliability [43],
    [44]. Furthermore, electric utilities are using prediction data analytics for
    estimating several parameters which are helpful to operate the smart grid in an
    efficient, economical and reliable way. For instance, whether the excess energy
    is available from renewable sources can be predicted through accessing the ability
    of the smart grid to transmit it. At the same time, calculating equipment downtime,
    accessing power system failures, and managing unit commitment can also be done
    effectively in high correlation with integrating distributed generation. Thus,
    the grid management state will be enhanced, the efficiency will be improved and
    the robustness of generation and deployment will be ensured. With the integration
    of various distributed generating sources, refined forecasting, load planning,
    and unit commitment are more convenient to avoid inefficient energy transmitting
    or dispatching extra generation. B. A Three-Tier Energy Big Data Analytics Architecture
    A widely accepted analytical framework of big data is shown in Fig. 2, which has
    three layers including data access and computing, data privacy, domain knowledge
    and big data mining algorithm [45]. FIGURE 2. Three-tier big data analytics architecture.
    Show All The inner core data mining platform is mainly responsible for data access
    and computation process. With the increasing growth of the data volume, distributed
    storage of large scale data need to be taken into account while computing. That
    is to say, data analysis and task processing are divided into multiple sub tasks
    and executed on a large number of computing nodes through a parallel program.
    The middle layer of the structure plays an important role to connect inner layer
    and outer one. The data mining technology in the inner layer provides a platform
    for data-related work in middle layer such as the information sharing, privacy
    protection, and knowledge acquisition from areas and applications, etc. In the
    whole process, the information sharing is not only the guarantee of each phase,
    but also the goal of processing and analyzing with the big data in smart grid.
    In the outer layer of the architecture, preprocessing is necessary for the heterogeneous,
    uncertain, incomplete, and multi-source data through data fusion technology. After
    preprocessing, complex and dynamic data will be excavated, and then, pervasive
    smart grid global knowledge can be obtained through local learning and model fusion.
    Finally, model and its parameters need adjustment according to the feedback [46].
    C. An Integrated Big Data Architecture in the Smart Grid Based on big data analytics
    and cloud technology, an integrated architecture can be used in the smart grid
    in many ways, such as optimizing power transmission, controlling power consumption,
    keeping the balance between power demand and supply, etc [47]. This architecture
    takes advantages of the three technologies including big data analytics, smart
    grid and cloud computing, which composes an enhanced version of smart grid. The
    improved smart grid has the following functionalities: Analyze the historic data
    and estimate the energy production. Analyze the consumer behavior patterns about
    electricity consumption to estimate the demand in advance. Keep record of the
    energy production from different sources and make decision to switch demands between
    the high/low priority. Balance the load of the demand/supply chain. Do efficiently
    on the storage/transfer of the generated power. The improved smart grid architecture
    is illustrated in Fig. 3, which consists of the smart grid, the HDFS and the related
    cloud environment. In order to manage the storage and retrieval of massive data,
    HDFS is used in this system. The HDFS gives concentration on distributed storage
    to nodes in racks [48]. This architecture also contains a database including consumer
    behavior pattern, historic data, details in power supply and demand. Each time
    the system estimates the demand and calculates the supply, it will refer to the
    consumer behavior patterns and historic data. These data are stored in a cloud-based
    Cassandra DataBase (Cassandra DB). This improved smart grid utilizes a prediction
    algorithm [49] to estimate the demand and supply of electric power. In a distributed
    environment, the smart grid uses distributed power resources like solar, wind,
    nuclear sources, and is applied in many areas, such as industrial production and
    social infrastructure. FIGURE 3. An improved smart grid architecture. Show All
    SECTION IV. Energy Big Data: Key Technologies With the remarkable development
    of big data analysis in energy domain recently, some significant technologies
    have emerged to be applied in various fields. The key techniques of big data in
    energy system can be divided into four categories: data acquisition and storing,
    data correlation analysis, crowd-sourced data control and data visualization.
    Among them the data acquisition and storing is the most crucial component. Crowd-sourced
    data control is applied especially to solve the data problems which are hard to
    be processed. To obtain better understanding of recent research trend, we analyze
    the data acquisition and storing technologies in detail and take a brief overview
    on big data technologies. A. Data Acquisition and Storing Data acquisition and
    storing is the initial problem in big data. The big data technologies in acquisition
    and storing stage gather data from various information in energy system. The collected
    data are of different sources, different formats and different features that is
    stored in data repositories. The acquisition and storing technology of big data
    belongs to data management which involves data fusion, data integration, data
    management, and data transforming which is usually called Extract Transform Load
    (ETL) technology [50]. Fig. 4 shows the data acquisition and storing flow using
    ETL technology. FIGURE 4. Data acquisition and storing. Show All Data acquisition
    involves data access and collection. Since data have private information, its
    confidentiality and security should be considered during accessing and transmitting.
    We investigate several homomorphic encryption and decryption methods for data
    access and storing. Further, secure data aggregation and routing are also studied
    in this part. 1) Homomorphic Encryption Scheme The transmitted information are
    always private, so encryption technology is necessary to prevent unpredictable
    attacks [51], [52]. Paillier [53] used an homomorphic probabilistic encryption
    scheme to deal with the composite residuosity class problem. Boneh et al. [54]
    proposed another homomorphic encryption scheme which can encrypt the information
    and ensure the confidentiality. The encryption protocol has three following components:
    Key generation: When given a security coefficient, this algorithm generates public
    keys and global parameters. Set n= q 1 ⋅ q 2 , where q 1 , q 2 are primes. Select
    N∈ Z ∗ n 2 such that N has an order which is a multiple of n and Z n 2 ={0,1,2,⋯,n,⋯,
    n 2 −1} , where Z ∗ represents the adjoint matrix of Z . Set λ(n)=lcm( q 1 −1,
    q 2 −1) , where lcm means the least common multiple. Let i represents the i -th
    intended receiver that a message is sent for. Then the public key of i -th receiver
    can be expressed as: PK[i]=(n,N) , the secret key can be expressed as: SK[i]=(λ(n))
    . Encryption method: Select m∈ Z n which represents a message. Choose a random
    number r∈ Z ∗ n . Then the ciphertext c can be given by: c=E(m)= N m r n mod n
    2 where r n is an enhancing factor to make the homomorphic computation indeterministic.
    Decryption method: Decryption from c to m is according to: m=D(c)= L( c λ(n) mod
    n 2 ) L( N λ(n) mod n 2 ) modn, View Source where the L -function takes input
    from the data set U={u|u=1modnandu< n 2 } and the output can be calculated in:
    L(u)=(u−1)/n . Supposing c 1 =E( m 1 ) and c 2 =E( m 2 ) are two ciphertexts for
    m 1 , m 2 ∈ Z n respectively, then the sum of the plaintexts S can be obtained
    from the ciphertexts: S=D( c 1 ⋅ c 2 mod n 2 )=( m 1 + m 2 )modn . Except for
    the additive homomorphism model above, the same information can be encrypted into
    different ciphertexts by various homomorphism encryption techniques. Rivest et
    al. [55] used a multiplicative homomorphism encryption method to keep privacy
    and authority in an electronic mail system. Gentry [56] proposed fully homomorphic
    scheme which can support complicated functions. 2) Secure Aggregation by Smart
    Meters In power network, data can be aggregated through Home Area Network (HAN),
    Building Area Network (BAN), and Neighboring Area Network (NAN) in the way that
    customers’ privacy is protected [57]. For each HAN, there is a gateway smart meter
    called han which collects and sends information to the BAN. The gateway smart
    meter ban in BAN aggregates these information and sends them to the gateway smart
    meter nan in the neighborhood area. Finally, nan in NAN reports all the information
    to the data repository which is monitored by the Remote Terminal Unit (RTU). Ruj
    and Nayak [58] proposed a new decentralized security framework to keep the whole
    aggregation process safe. The i -th RTU R i in data repository is securely given
    a public key PK[i]=(n,N) and a secret one SK[i]=(λ(n)) as in the key generation
    in additive homomorphism model. Each smart meter knows the public key PK[i] of
    its nearest RTU data repository R i in the network. The j -th gateway smart meter
    ha n j in HAN sends a data packet that consists of two fields: the attribute field
    a and the power consumption field p j corresponding with different attributes.
    The power consumption field can be encrypted with the data repository public key.
    Then the packet can be described as: PPK[ha n j ]=a|| c j =a||E( p j )=a||( N
    m j r n j mod n 2 ) , where PPK[ha n j ] is short for the packet sent by smart
    meter gateway ha n j and r j ∈ Z ∗ n is randomly chosen by the smart meter. The
    attribute field will be checked in BAN. When the packet is sent to the BAN, the
    gateway ba n l will aggregate all the packets which have the same set of attributes
    into a new packet and process the aggregated power consumption. This aggregated
    result can be given by: c ba n l = ∏ ha n j ∈HAN c ha n j . The new packet can
    be described as: PPK[ba n l ]=a|| c ba n l . Packets aggregated by a set of gateway
    smart meters {ba n 1 ,ba n 2 ,⋯,ba n j } then will be sent to the NAN. The NAN
    gateway na n k aggregates the packets and operations the information at the same
    way of ban . The aggregated result can be figured out by: c na n k = ∏ ba n l
    ∈BAN c ba n l . The new packet PPK[na n k ]=a|| c na n k will be sent to the nearest
    data repository. The RTU R i in the data repository will receive packets and decrypt
    the encrypted results by using its secret key SK[i] . Thus the RTUs can aggregate
    information without knowing what exact data was send by the smart meters at the
    HANs. The whole aggregation progress is similar to a spanning tree, where the
    HAN is at the bottom and data repository is at the top. 3) Access Control Scheme
    All the sensitive information must be sent separately to the specific terminals,
    thus access should be restricted and controlled. Sahai and Waters [59] proposed
    a cryptographic protocol called Attribute Based Encryption (ABE) which is mainly
    to distribute attributes to senders and receivers so that only the receiver with
    matching attributes set has the access to the data. However, this protocol is
    restricted to only support threshold access structures. Therefore, many researches
    have been launched to improve this protocol. Goyal et al. [60] proposed a novel
    ABE scheme called Key-Policy based (KP-ABE) scheme which can handle any monotonic
    access structure. Bethencourt et al. [61] proposed another type of protocol which
    is known as Ciphertext-Policy ABE (CP-ABE). In these schemes, ciphertexts are
    encrypted under a given access structure with a set of attributes. Only a receiver
    has a matching attributes set can it decrypt the information. Lewko and Waters
    [62] proposed an access control scheme and gave limited access to authorized data
    users. It is mainly based on a ABE cryptographic technique where RTUs have attributes
    and cryptographic keys distributed by multiple Key Distribution Centers (KDCs).
    When an RTU R i wants to store a message m , R i defines an access structure S
    firstly which helps it to select the authorized users to access the message m
    . R i then creates a k×l -matrix R ( k represents the attributes’ number in the
    access structure and l is the leaves’ number in the access spanning tree). R i
    also defines a mapping function ψ of which rows is a set of attributes: ψ:{1,2,⋯,k}→W
    , where W means a attributes set. Obviously, ψ is a permutation. Then the RTU
    R i runs the ABE encryption algorithm to calculate the ciphertext C by C=ABE.Encrypt(m,R,ψ)
    . Ciphertext C is thus stored in the data repository. If a user u has a valid
    set of attributes, his request to access to the ciphertext C from the data repository
    will be accepted and the C will be decrypted into the message m by m=ABE.Decrypt(C,{SK[i,u]})
    , where SK[i,u] represents the secret key of KDC corresponding to the attribute
    i given to the user u . 4) Data Storing and Routing The large amount of data generated
    by the widespread sensor networks in the smart grid requires scalability, self-organization,
    routing algorithms and efficient data dissemination. Generally, the content of
    the data should be more important than the identity of the sensor used to store
    data [63]. Therefore, comparing with the common routing technology, the data-centric
    storing and routing technologies have been developed more rapidly in recent decades.
    In the data storing and routing technology, the data is defined and routed referring
    to their names instead of the storage node’s address. The data can be queried
    for users after defining certain conditions and adopting certain name-based routing
    algorithms, like the Data-Centric Storage (DCS) and the Greedy Perimeter Stateless
    Routing (GPSR) algorithm [64]. In these algorithms, each data object belongs to
    an associated key and each working node stores a group of keys. Any node in the
    system is allowed to locate the storage node for any key and every node can input
    and output files based on its keys, via a hash-table-like interface. The following
    example shows the data storage algorithm in information encryption and decryption.
    Encrypt2DS: Each terminal user can encrypt information I into a ciphertext C DS
    with the data storage encryption algorithm, which encrypts with params and the
    data storage identity DS in the regional cloud nodes. Therefore, this encryption
    process is denoted as: C DS ←Encrypt2DS(params,DS,I). View Source Decrypt2DS:
    Each regional cloud node can decrypt an accepted ciphertext C DS into the information
    I with the data storage decryption algorithm, which decrypts with params and the
    private key K DS relevant to the data storage identity DS . Therefore, this decryption
    process is denoted as: I←Encrypt2DS(params, K DS , C DS ). View Source B. Data
    Correlation Analysis The big data technologies in data analysis involve correlation
    analysis, data mining and machine learning. Through data analysis techniques,
    valuable information can be extracted from large amount of big data in a power
    system. Correlation is a well-known statistical and mathematical method for the
    compatibility analysis of large data sets. Meier et al. [65] successfully used
    Pearson Product-Moment correlation to determine how well data is linearly correlated.
    Given two independent input data sets of X , Y with the length of N , and X ,
    Y being either the phase data values of two PMU sites or the momentary magnitudes,
    the Pearson correlation submits to a correlation coefficient C ( C∈[−1,1] ), which
    is based on the following equation: C= ∑ N i=1 (XY)− ∑ N i=1 X ∑ N i=1 Y N ( ∑
    N i=1 ( X 2 )− ( ∑ N i=1 X) 2 N )×( ∑ N i=1 ( Y 2 )− ( ∑ N i=1 Y) 2 N ) − − −
    − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − −
     ⎷   . View Source Two application-specific improvements and modifications
    have been made to this mathematical formula. Firstly, because the algorithm was
    made incremental, each i data point ( x i , y i ) could be gained from the Phasor
    Data Concentrator (PDC) engine and incorporated into its correlation coefficient
    at once. Thus, there is no need to directly calculate each average, summation,
    and standard deviation at each time step repeatedly. This helps reduce the operation
    time. Secondly, the correlation algorithm is set to maintain correlation information
    through varying windows of time. The stream data structure actually maintains
    multiple separate points to terminal positions of each defined sliding window.
    However, separate lists for each sliding window are not created. Rather, points
    from a single list are controlled to minimize memory usage and copies of data
    which are already managed. Correlation analysis techniques can figure out correlation
    or causal relationship and have been widely applied in power system for making
    investment decisions and forecasting the electric power load. As mentioned above,
    data mining ranges in the most popular techniques of data analysis, which is mainly
    applied for prediction and presentation in power grid. Machine learning is also
    widely applied in energy system. Pandy et al. [66] used correlation analysis of
    big data to support machine learning through best fit linear regression of large
    data sets. In addition, correlation analysis also applies for monitoring power
    equipment conditions, assessing transient stability, etc [67]. De Silva et al.
    [68] proposed an Incremental Summarization and Pattern Characterization (ISPC)
    framework using data mining technology to address problems in energy consumption
    analysis. This framework has two basic functions: incremental learning and interim
    summarization. Incremental learning can extend dynamic self-organization of senor
    nodes in power grid with the dynamic topology preservation technology. Using a
    structure-adapting feature map, this technology can ensure natural groupings in
    the data being exposed. The structure adaption is affected by a total quantization
    error E i,t , predefined values x and w , a spread factor which controls growth
    of the dynamic feature map: E i,t = ∑ H i ∑ j=1 D ( x j (t)− w j (t) ) 2 , View
    Source where H i means the i th hit node and D refers to the numbers of energy
    environment location phases. When E i,t exceeds the spread factor, the network
    structure will be adapted to fit this change, through growing new energy nodes
    or distributing the error to neighboring nodes. Interim summarization uses dimensional
    model representing the power environment in order to generate online digests of
    flow data. The digests facilitates data analysis in various directions, such as
    trend analysis, granularity exploration and ad-hoc querying. C. Crowd-Sourced
    Data Control Although various technologies can be applied for different data processing
    periods, some vital data management and analysis tasks in the power system cannot
    be addressed completely by data processing technologies. However, these hard tasks
    such as entity resolution, sentiment analysis, and image recognition, can be dealt
    with human cognitive ability [69]. Generally, utilizing the capabilities of the
    crowd is an effective method to handle computer-hard tasks in the power system.
    Therefore, crowd-sourced data management has aroused increasing attention in energy
    big data research, such as data integration [70], knowledge construction [71],
    data cleaning [72], etc. In the energy domain, widespread sensor nodes are the
    same as workers in crowd-sourced data control. As workers being task operators,
    sensor nodes are always assigned to deal with diverse data collected from power
    grid. Problems in crowd-sourced data control can be divided into two groups: quality
    control and cost control. The quality control is the most important because crowd-sourcing
    often generated relatively low-quality results or even noise. Thus, we will analyze
    quality control in detail. 1) Quality Control The first step of the quality control
    is to characterize workers’ quality, including modeling workers and defining parameters.
    The current researches have proposed several methods to model a worker’s quality.
    We summarize some as follows. Worker Probability [73]–[75] In worker probability,
    each worker’s quality is taken as a single parameter p∈[0,1] , which indicates
    the accuracy rate of the worker’s answer: p=Prob(the worke r ′ s answer=the tas
    k ′ s true answer). View Source For example, if a worker’s answer has a probability
    of 80 percent to be correct, the workers quality would be characterized as p=0.8
    . Since the accuracy parameter p is defined in the range of [0, 1], some studies
    extend it with two approaches: Extending to a wider range of (−∞,+∞) , which enables
    a higher probability to the correct answer [76]. Extending another parameter as
    a confidence interval to describe how confident the calculated p is. For example,
    if the confidence interval is ranged among [0.3, 0.8], it may narrow to [0.55,
    0.6] after a worker answering more tasks [77]. Confusion Matrix [78] Confusion
    matrix is often used to represent a worker’s ability to process single-choice
    tasks with n potential answers. A confusion matrix is a n×n matrix: P= ⎡ ⎣ ⎢ ⎢
    ⎢ ⎢ ⎢ P 1,1 P 2,1 ⋮ P n,1 P 1,2 P 2,2 ⋮ P n,2 ⋯ ⋯ ⋱ ⋯ P 1,n P 2,n ⋮ P n,n ⎤ ⎦
    ⎥ ⎥ ⎥ ⎥ ⎥ , View Source where the i -th (i∈[1,n]) row represents the distribution
    of the worker’s answers for the i -th task’s answer and the j -th (j∈[1,n]) column
    represents the correct answer probability of the j -th worker’s answer. Therefore,
    p i,j = Prob(the worke r ′ s answer is j ∣the tas k ′ s true answer is i). View
    Source Some techniques are studied in order to compute the parameters in worker
    models as above, and we just introduce two typical examples: Qualification Test
    [78] The qualification test sets a series of tasks with known true answers. Only
    when the workers pass the qualification test and achieve good marks can they answer
    the real answer tasks. Referred to the worker’s test answers, the worker’s quality
    can be deduced. For instance, if a worker is modeled by Worker Probability and
    he answers correctly 8 out of 10 test tasks, his quality is p=0.8 . Test-Injected
    Method [79] The gold-injected method integrates test tasks and real tasks. For
    instance, if 10 percent of tasks are set as test tasks, each time when a worker
    is assigned with 10 tasks, he will take 1 test task and 9 real tasks. Based on
    the accuracy of worker’s answers on test tasks, his quality can be calculated.
    However, this method is different from the qualification test because worker doesn’t
    know that some tasks are the tests. When the workers are in the low quality, worker
    elimination is essential to improve the whole quality. There are many approaches
    to detect low-quality workers. A simple one is still using qualification test
    or test-injected method. It uses test tasks to compute the worker’s quality and
    workers with low quality (e.g. p≤0.5 ) are not allowed to process the real tasks.
    Therefore, the overall quality can keep ranging in a high level. 2) Cost Control
    The crowd is not free. When there are a lager number of tasks to do, the crowd-sourcing
    can be quite expensive. Therefore, cost control is challenging for crowd-sourced
    data control. In recent researches, several effective techniques have been proposed
    for cost control. One is pruning, which first applies computer algorithms to preprocess
    all the tasks and remove unnecessary tasks, guiding workers only to answer the
    essential tasks [80]. Another technique is task selection, which can improve quality
    and reduce cost by prioritizing all the tasks and selecting the most beneficial
    task to do first [81]. D. Data Visualization The data visualization of big data
    has three main components: historical information visualization, geographical
    visualization, and 3-dimensional visualization, which can intuitively and accurately
    express information of electric power system. The visualization technologies are
    used for monitoring real-time power system status, which heighten the automation
    degree of power system. If combined with complex system network theories, it also
    can identify potential relationships and patterns in smart grid. Zhang et al.
    [82] proposed a 5ws parallel coordinate visualization model for big data density
    analytics. The 5ws is composed of: where did the data generate, when did the data
    generate, why did the data generate, what was the data content, how was the data
    transferred and who received the data. Therefore, each data can be denoted into
    a function: f(p,t,r,x,y,z) , where p represents where data came from, t represents
    the time stamp for each data incidence, r represents the reason data generated,
    x represents the data content such as “attack”, “like” or “dislike”, y represents
    the way data transferred and z represents the data receiver. Assuming all n data
    items are in the time period T{ t 1 , t 2 , t 3 ,⋯, t n } , a function set F can
    be set and contain all data items within a certain time interval: F={ f 1 , f
    2 , f 3 ,⋯, f n }. View Source For a specific data item, supposing p=α , r=β ,
    x=γ , y=δ , z=ϵ , the data pattern can be denoted as f( p (α) ,t, r (β) , x (γ)
    , y (δ) , z (ϵ) ) . Therefore, the subset f (α,β,γ,δ,ϵ) can be mapped in the parallel
    coordinates using 5 polylines, which represent the data in 5ws dimensions at a
    particular time. Then, a 5Ws parallel coordinate visualization will be gained.
    All key technologies and related work have been listed in Table 1. TABLE 1 Key
    Technologies in Energy Big Data SECTION V. Energy Big Data: Security Although
    the integration big data with power grid realizes high degree of network connectivity,
    it also brings complex security vulnerabilities into grid [83]. From the perspective
    of big data, we discuss the main security vulnerabilities and requirements in
    privacy, integrity, authentication and third-party protection. A summary of all
    four security aspects and related work have been provided in Fig. 5. FIGURE 5.
    Security branches and related solutions. Show All A. Privacy The customer power
    consumption data collected from smart meters is a certain kind of privacy that
    showed be protected. From the detailed consumption information, an insight into
    a customer’s behavior can be obtained. Smart grid stores customer privacy consequences
    and acts like an information-rich channel which is easy to exploit users’ habits
    and offer intelligence service. As the history shows in [84], a series of financial
    or political incentives boost the development of information mining and behavior
    learning technology. Terminal user’s privacy is a well-known security problem
    about big data applied in power system. Many approaches have been proposed to
    solve the privacy problems during data access. Li et al. [85] presented a distributed
    incremental data aggregation approach by using neighborhood gateways. Kalogridis
    et al. [86] introduced a method to hide information contained in the energy consumption
    data by using battery storage. Rastogi and Nath [87] proposed a differential private
    aggregation algorithm for time-series data which offers good practical utility
    without any trusted server. Although these solutions manage to support the utility
    and privacy in various ways, they lack a robust theoretical basis from both utility
    and privacy. Rajagopalan et al. [88] proposed a theoretical framework which integrates
    most existing solutions of the trade-off and provides a universal model in smart
    meters. Such a theoretical framework is suitable for many current problems of
    the privacy-utility tradeoff using a technology-independent method. Assume that
    power consumption data is distributed normally, a data sequence { x k } is defined
    of random variables x k ∈x , −∞<k<∞ , which generated by stationary continuous
    valued sources with memory got via the autocorrelation function: C xx (m)=E[ x
    k x k+m ],m=0,±1,±2,⋯ . Then, in order to estimate the privacy loss via the mutual
    information, authors would perturb data between two data sequences. Since continuous
    amplitude data transmission is lossy through finite capacity network links, a
    tested sequence of k -load measurements { x k } is usually quantized and compressed
    before the transmission. Therefore, data perturbation is needed to guarantee data
    privacy in some way. However, such a perturbation also needs encoding and decoding
    to maintain a desired level of fidelity. Encoding: Assuming that a smart meter
    can collect n(n≫1) measurements in a time interval before communication, and n
    is large enough to capture the memory of data sources. Then the encoding function
    performs a mapping of resulting source sequence X n ={ X 1 , X 2 ,⋯, X n } , where
    X k ∈R , k=1,2,⋯,n , an index W i ∈ W n will be given by: F E : X n → W n ={1,2,⋯,
    W n }, View Source where each index is a quantized sequence. Decoding: The decoder
    at the data collector computes an output sequence X ˆ n ={ X ˆ 2 , X ˆ 2 ,⋯, X
    ˆ n } , X ˆ k ∈R , for all X ˆ k , using the decoding function: F D : W n → X
    ˆ n . View Source The selection of the encoder should promote the input and output
    sequences to achieve a desired utility which is given by an average distortion
    constraint: D n = 1 n ∑ k=1 n E[( X k − x ˆ k ) 2 ], View Source and a constraint
    on the privacy leakage about the desired sequence { Y k } from the revealed one
    X ˆ k is quantized via the leakage function: L n = 1 n I( Y k ; X ˆ k ), View
    Source where function E[⋅] computes the expectation and I(⋅) represents the mutual
    information. D n and L n are functions of the number of measurements n . When
    stationary sources converge to limiting values, the corresponding limiting values
    for utility can be given by D= lim n→∞ D n and L= lim n→∞ L n for privacy respectively
    [89]. B. Integrity Preventing unauthorized persons or systems modifying information
    is all about integrity. In the smart grid domain the integrity focuses on information
    such as sensor values, product recipes and control commands. Avoiding modification
    through message delay, message reply and message injection are also its relevant
    work. Security issues may be caused by the violation of integrity. Liu et al.
    [90] pointed out that the risk of integrity-targeting attacks in smart grid is
    indeed real. Compared to availability-targeting attacks, integrity-targeting attacks
    are less brute-force but more sophisticated. Either customers’ information or
    network operation information can be the objective of the integrity attacks. That
    is to say, modifying the original information deliberately and then corrupting
    critical data exchange in smart grid are the attempt of such attacks. Ruj and
    Pal [91] proposed a targeted attack model in power network where attackers attack
    nodes by removing them with probability proportional to the nodes’ degree. Therefore,
    a node with higher degree will be removed with higher probability. In the power
    network, once a node with higher degree has been removed, the integrity of energy
    data collected by nodes will be affected more. Note ∅ k as the probability that
    a node i of k degree hasn’t been removed: ∅ k =1− deg(i) ∑ v∈ V A deg(v) =1− A
    k − α A 2 m A , View Source where V A is the nodes set in power network N A ,
    α A is the power-law coefficient, m A represents the number of edges in N A ,
    deg(i)=A k − α A represents the degree of node i and α A =0 means the random removal
    of nodes. Several studies have been conducted to address integrity attack. Xie
    et al. [92] firstly investigated the impact of integrity attacks on energy market
    through virtual bidding. They showed the process of an attack constructing a profitable
    attacking strategy without being detected. This result is helpful to examine the
    potential loss caused by such attack. Kosut et al. [93] evaluated the proposed
    data attacks by generated market revenues and the work was further studied by
    Jia et al. [94] in maximizing the revenues. Yuan et al. [95] found that the data
    integrity attacks can result in increasing system operating cost due to the inordinate
    generation dispatch and energy routing. In order to control the real-time Locational
    Marginal Prices (LMP) directly under data attacks, Tan et al. [96] employed a
    control theory based approaches to analyze the attack effect on pricing stability.
    Esmalifalak et al. [97] adopted a novel approach to characterize the relationship
    between attackers and defenders. Tan et al. [98] proposed a novel systematic online
    attack construction strategy which doesn’t need any power grid topology or parameter
    information. They presented a corresponding online defense strategy to identify
    the malicious attack in smart grid. Further, Jia et al. [99] proposed an analysis
    framework to quantify the data quality impact on real-time LMP. All these related
    researches are based on the assumption that attackers fully know about the targeted
    power systems including the grid topology architecture, branch parameters and
    other related information. C. Authentication In general, authentication means
    to verify participator’s identity and map this identity to the existing authentication
    table in power network. A user gains access to a smart grid communication system
    with a valid account. Most security solutions use authentication as a basis to
    distinguish legitimate and illegitimate identity [100]. Hamlyn et al. [101] proposed
    a utility network authentication and security management in smart grid operations.
    A new security architecture was designed for this management to deal with actions
    and commands requests in multiple security domains. However, their research only
    focused on keeping electric power systems and electric circuits secure in host
    areas. Furthermore, Fouda et al. [102] proposed a light-weight message authentication
    mechanism which is based on the Diffie-Hellman key establishment protocol. This
    mechanism allows distributed smart meters to make mutual authentication with low
    latency and has similarities with secure aggregation technology above. Assume
    that HAN gateway i and BAN gateway j both have their private and secret key pairs
    which are respectively denoted as P K ha n i , S K ha n i , P K ba n i , S K ba
    n i . The Diffie-Hellman key establishment protocol will be adopted at the initial
    handshake between HAN and BAN gateways [103]. Define G=⟨g⟩ as a group of large
    prime order p under the Computational Diffie-Hellman (CDH) assumption. Otherwise,
    if given g a , g b , for unknown a,b∈ Z ∗ p , it is difficult to calculate whether
    g ab ∈G . The following steps are shown the procedure of the envisioned lightweight
    message authentication scheme: HAN gateway ha n i chooses a number a∈ Z ∗ p )
    randomly and computes g a , then sends g a with an encrypted request packets to
    BAN gateway ba n j : ha n i →ba n j :{ g a } {encr}P K ba n j . View Source Gateway
    ba n j in BAN decrypts the packets and sends a encrypted response including g
    b (b∈ Z ∗ p ) : ba n j →ha n i :{ g a ∥ g b } {encr}P K ha n i . View Source After
    receiving ba n j ’s response packets, ha n i recovers g a with its Secret Key
    (SK). If the result is correct, it means that the ba n j is authenticated by ha
    n i . Then, with number a and g b , ha n i can calculate the shared session key
    K i =H(( g b ) a ) , where H:{0,1 } ∗ → Z ∗ p is a cryptographic hash function.
    Then ha n i sends g b to ba n j in plaintext. Once ba n j has received the correct
    g b , ba n j will authenticate ha n i and also compute the session key using the
    same way: K i =H(( g a ) b ) . Because K i is shared only between ha n i and ba
    n j , ba n j can verify the authenticity of sender and the integrity of message
    M i . Thus, it can provide the NAN gateways with the authenticated messages. D.
    Third-Party Protection Damages via the communication systems, except safety hazards
    of the controlled plant itself, can be averted by the protection of a third-party,
    such as a cloud service provider. The power system can be used for launching various
    attacks on the smart grid or the third party after being attacked. This will do
    damage to a smart grid system owner’s reputation, or even reach to legal liability
    for damaging the third party. Since the third party isn’t listed in authentication
    table in power network, it may have no access permission. Trusted Third Party
    (TTP) has been a promising approach for Personally Identifiable Information (PII)
    in power system security. Ranchal et al. [104] used a predicate encryption scheme
    and multi-party computing to process identity data on untrusted hosts. Shamir
    [105] proposed a threshold secret sharing on private information. First a private
    data set D is divided into n shares: { d 1 , d 2 ,⋯, d n } . Then a threshold
    t is chosen to recover D . This operation may require t or more shares of arbitrary
    D i . Ben-Or et al. [106] defined a multi-party computing protocol which uses
    secret input from all the parties. This protocol involves n mutual parties which
    only calculate partial function outputs. In this protocol, one player from a party
    has been selected as the dealer(DLR) and provided partial outputs to figure out
    the full computation results. Denote a linear function f of n degree which is
    known to n parties, an arbitrary threshold t , the i -th party P i , and x i as
    the input of P i for f . By using a set of input { x 1 , x 2 ,⋯, x n } , n parties
    will calculate the output through f and send the result to the DLR . Each P i
    generates a polynomial h i of t degree such that h i (0)= x i . When P i sends
    one share to P j in the left parties, P i will compute the portion of function
    f using this sent share. SECTION VI. Energy Big Data: Applications We take a brief
    overview on three application directions of big data: renewable energy, demand
    response and EVs. Each direction contains numerous technical fields, as shown
    in TABLE 2. Although we present these three applications separately, there are
    no clear boundaries between them. Demand response should be considered in both
    renewable energy and EVs while EVs is also a concrete implementation of renewable
    energy. TABLE 2 Key Applications in Energy Big Data A. Renewable Energy The new
    and renewable energy are integrated in the electric power generation, which is
    different from the traditional power generation mode. This difference causes the
    measurement and management of generated data from electric power become increasingly
    difficult and complex. Since the big data technology helps to make better prediction,
    management and processing complex big data in the energy domain, it has become
    increasingly popular and widely applied in renewable energy companies once emerging.
    Many researches have launched on various branches of renewable energy. Paro and
    Fadigas [107] proposed a methodology to measure and calculate the overall biomass
    energy efficiency. This methodology can be applied in smart programs about regeneration
    plants and generator groups connected to a grid which will improve the efficiency
    continuously. MacGillivray et al. [108] concentrated their attention on marine
    energy. The marine energy have attracted considerable interest but its commercial
    prospects mainly depend on cost reduction and substantial learning. Therefore,
    the authors presented an explicit solution on the key uncertainties involved in
    marine energy learning rates analyses including wave and tidal stream. They provided
    a simple learning model and describe a range of learning investments which made
    marine energy technologies become cost-competitive. Wool et al. [109] looked at
    the tribological design of three green marine energy systems: tidal, offshore
    wind, and wave machines. They pointed out that most marine renewable energy conversion
    systems need tribological components to promote rotational motion of wind or tidal
    streams to generate electricity. Therefore, they studied and highlighted current
    research thrusts to address present issues related to the tribology of marine
    energy conversion technologies. As for another important renewable energy sources,
    wind energy has also attracted wide attention. For instance, in order to improve
    the efficiency of electric power generation, the Vestas Wind Technology Group
    of Denmark optimized the wind turbine geographical placement by using big data
    technologies to analyze the data information including weather reports, tidal
    conditions, satellite images and geographical information [110]. Besides, they
    also updated the underlying architecture for better data collection and used big
    data processing technologies to meet their high-performance computing needs. Furthermore,
    Kaldellis [111] proposed an optimum autonomous wind power system sizing for remote
    consumers by using long-term wind speed data. Aiming to improve the life quality
    level of remote consumers, they used the proposed autonomous wind power systems
    to address the electricity demand requirements, especially in high wind-potential
    locations. All researches above in different application areas have a common purpose:
    cost minimization. In addition, owing to the over-exploitation of fossil fuels,
    energy becomes precious and energy consumption problem has arisen wide attention.
    Kung and Wang [112] proposed a recommender system for the best combination of
    renewable energy resources with cost-benefit analysis, which include analytical
    module, cloud data base, and user interface. This study used Markov Chain to investigate
    the influences of decision-making related to renewable energy and electricity
    demand in random time. Since the historical electricity data is recorded in continuous
    time series, Continuous Markov Chain can be applied to analyze energy big data
    in order to help power enterprises make optimal investment of renewable energy
    and evaluate optimal energy configuration. B. Energy Demand Response The demand
    of electric power consumers has been expanding along with the increasing use of
    machines and emerging types of appliances such as EVs and smart home furniture.
    Thus, the concern on the stability and reliability of electricity supply has also
    been aroused. However, since the traditional power grid lacks real-time response
    between demand and supply, it cannot meet these demands due to its inflexible
    distribution [113]. Therefore, demand response is expected to be an aspect for
    the future smart grid. Demand response is usually based on the classification
    analysis [114]. Users can be classified into several types according to climatic
    features, geographic conditions and social stratum. Targeting ar different class
    of users, different daily load curves of electrical equipments can be drawn. These
    curves indicates the electrical characteristics, including time intervals, effective
    factors of electricity consumption, etc. Based on the classification analysis,
    the total demand response from a region or a kind of users can be available through
    polymerization. Meanwhile, the analysis results will work in designing incentive
    demand response mechanism. Liu et al. [115] provided a power demand model which
    is derived from workload models and cooling demands of the data center. Specifically,
    they calculated the total power demand by: d(t)= d IT (t)+c( d IT (t)) , where
    d IT (t) represents the total Information Technology (IT) workload demand at time
    t which is the energy necessary to serve demand, and function c() represents cooling
    power demand which is associated with IT demand d IT . Note that PUE(t) means
    the Power Usage Effectiveness (PUE) at time t , thus, c( d IT (t)) can be calculated
    by c( d IT (t))=(PUE(t)−1)∗ d IT (t) . Goyena and Acciona [116] proposed an energetic
    balance algorithm to warranty the electric demand in a large energy storage system.
    This system analyzes the measured data constantly and commits for high accuracy.In
    this algorithm, electric demand situations of overproduction and underproduction
    are distinguished. Compared with the none-renewable production, renewable production
    has been considered as the priority in order to meet the energy demand. According
    to the results of this balance algorithm, data-storage level will be increased,
    decreased or limited. C. Electric Vehicles Electric Vehicles becomes a promising
    alternative transportation method which is related to the smart grid domain. With
    the increasing number of EVs, many problems in various areas of EVs such as performance
    evaluation, driving range and battery capacity become great concerns by researchers.
    Besides, EV is one of the typical application examples of big data. Therefore,
    most of the issues above can be handled with big data technologies. For instance,
    Wu et al. [117] launched the EV grid integration study based on driving patterns
    analysis. Recently, most researches are focused on analyzing the energy efficiency,
    addressing routing problems by recording driving data, estimating the driving
    range. Su and Chow [118] proposed an Estimation of Distribution Algorithm (EDA)
    based on big data theories to allocate electric energy intelligently to EVs. The
    simultaneous connection of a large number of EVs to the power grid may have a
    influence on quality and stability of the overall power system. This proposed
    algorithm was devoted to optimally manage a large number of EVs charging at a
    municipal parking lot. Midlam-Mohler et al. [119] focused on the the analysis
    of energy efficiency via recording driving data. They developed a data collection
    system to support the study which allows data acquired not only from disparate
    data sources that are available on most modern vehicles but from supplemental
    instrumentation as well. As for the issues on EVs charging and driving range,
    Rahimi-Eichi et al. [120] proposed another range estimation framework based on
    big data technology which can collect energy data with various structures from
    various resources and incorporate them via the range estimation algorithm. They
    also used historical and real-time data for simulation and thus calculated the
    remaining driving range. Zhang and Grijalva [121] proposed a data-driven queuing
    model for EV charging demand through performing big data analysis on smart meter
    measurements. In addition, Zhang et al. [122] focused on the charging-transaction-record
    EV data for better charging service, by detecting, analyzing, and correcting the
    abnormal data with error types and distributed locations. Soares et al. [123]
    presented a novel methodology based on Monte Carlo Simulation (MCS) to estimate
    the possible EVs states referring to their locations and periods of connection
    in the power grid. Futhermore, Lee and Wu [124] provided a EV-battery big data
    modeling method which has been used to improve the driving range estimation of
    EVs, using data cloud analysis and processing technologies. The authors first
    presented a simple approach to project life cycles of battery packs based on collected
    test data. The operating voltage of a battery pack E (I,SOC,T) can be evaluated
    by: E (I,SOC,T) =OC V (SOC,T) −I( R (SOC,T) + η r (I,SOC,T) )r, View Source where
    I means the current, SOC is noted as the state of charge, T represents the temperature,
    OCV is short for the open circuit voltage, R is the resistance of battery cell
    and η represents the resistance caused by polarization. Then they used a machine
    learning approach to cluster the collected EV data by ever-increasing hierarchical
    self-organizing maps. SECTION VII. Energy Big Data: Challenges Coming from wide
    various sources, the volume of energy big data is increasing at an exponential
    speed. At the same time, difficulties also arise up in data storage, mining, querying,
    processing, etc. Therefore, cryptography technologies, fuzzy data computing, qualified
    data processing are all essential for big data applied better in smart grid. A.
    Data Uncertainty Data uncertainty comes from data complexity. Because of the complicated
    and distributed smart grid, the sources and forms of energy big data become diverse.
    There is no need or unrealistic to obtain accurate data samples or give a precise
    response. Therefore, uncertain data mining and imprecise data querying are presented
    for data uncertainty [125]. 1) Uncertain Data Mining Previous applications in
    smart grid using traditional data mining techniques require the data samples be
    accurate or with definite values. However, in the latest decades, there have been
    some researches conducted to capture the uncertain factors of the data, which
    are common in the big data applications [15], [126]. These techniques often assume
    a distribution of the data values based on a probabilistic method, and then generate
    the probabilistic results of data mining. For example, the K-means clustering
    algorithm was optimized to the UK-means clustering algorithm through specifying
    a data object from an uncertain region with an uncertain probabilistic distribution
    method [15]. In the UK-means clustering algorithm, the precise error and the cluster
    number of a data object are less important. Tsang et al. [126] developed a decision
    tree classifier used for uncertain data and proposed the related improved algorithms.
    Extension of classical decision tree in building algorithms was proposed in to
    handle data tuples without certain values. 2) Imprecise Data Querying In the traditional
    data querying techniques used in smart grid, the precise results are required
    in the DataBase Management System (DBMS) according to the query conditions. In
    recent years, a lot of querying and indexing techniques began to consider about
    the uncertainty of the data. Instead of giving the precise response, these techniques
    estimate data uncertainty and provide probabilistic guarantee. For instance, the
    uncertainty of the data has been modeled as the stochastic value within certain
    limits, and the data queries have been classified into different classes. Different
    algorithms are then developed to compute the probabilistic answers. Chen and Cheng
    [127] studied location data with uncertainty and classified the query issues into
    two types, according to the degree of data uncertainty. B. Data Quality Due to
    the multiple origins of big data in the complicated power system, the smart grid
    database always contains incomplete, inconsistent and uncorrected data. Therefore,
    a series of data preprocessing technologies are necessary to improve the data
    quality, especially after uncertain data mining and imprecise querying [128].
    Data preprocessing contains data manipulation, compression and normalization of
    the older data into improved format [129]. Data manipulation refers to transformation,
    which is used to reduce the impact from data fault sensing and provide more reliable
    energy data. The compression operation is used for massive data measurements to
    be reduced into a reasonable extent. Meanwhile, the normalization technology is
    used to regulate the collected data by minimizing its noise, inconsistencies and
    incompleteness of data. These three operations are main components of data preprocessing
    but the order is not unique. Furthermore, different regulations on big data cause
    conflicts between collaborators and lead to inconvenience in smart grid. Therefore,
    a unified and complete system standard needs to be set up in the future. C. Quantum
    Cryptography for Data Security Since the large amount of data is stored in multiple
    distributed grids, it is difficult to monitor the security of data storage in
    real time. However, most data involve personal privacy, commercial secrets, financial
    information, etc. It causes the problem of data larceny, which has become increasingly
    serious. Therefore, some kinds of cryptography technologies have been proposed
    by researches to solute security problems of big data in energy domain. Modern
    cryptography technique is based on the Rack Scale Architecture (RSA), which is
    especially used for the hardly factoring large data [130]. In 1994, Peter Shor
    discovered that quantum computers can handle discrete logarithm operation [131]
    and this would lead to the loss of the efficiency of the RSA architecture. Since
    the quantum computers have been put into use recently, a new data cryptograph
    technology called quantum cryptography [132] is considered as the next generation
    cryptography solution. The quantum cryptography can absolutely guarantee the security
    of smart grid data based on the quantum mechanics. In this technology, the data
    is encoded as qubits instead of transmitting bits and different directions will
    affect the qubit’s polarization. The quantum key distribution begins when a large
    amount of qubits are sent from the sender to the receiver. If an eavesdropper
    wants to get the information about any qubit, he will have to measure it. However,
    having no idea about the qubit’s polarization, the eavesdropper can only process
    it by guess and then transmit another randomly polarized qubit to the receiver.
    All these operations are under the surveillance. At the end of quantum key distribution,
    the key will be identified safe or not by a brief testing. SECTION VIII. Conclusion
    In this paper, we gave an introduction on big data and power grid, presented the
    background in the aspects of related work, techniques and tools for energy big
    data. Then, we discussed the important role of big data, which brought efficiency
    and accuracy to the power system. Furthermore, an integrated architecture was
    introduced for the big data analysis, and we discussed the key techniques of big
    data in the energy system in four categories: data acquisition and storing, data
    correlation analysis, crowd-sourced data control and data visualization. As another
    crucial part of the energy big data, the security in the power system was illustrated
    in aspects of privacy, integrity, authentication and the third-party protection.
    We also discussed the applications of energy big data in branches of renewable
    energy, energy demand response, and electric vehicles. Finally, we listed some
    challenges need to be addressed about data uncertainty, quality and security.
    Authors Figures References Citations Keywords Metrics More Like This Robust and
    economical placement of phasor measurement units in Indian Smart Grid 2013 IEEE
    Innovative Smart Grid Technologies-Asia (ISGT Asia) Published: 2013 Advancing
    China?s Smart Grid: Phasor Measurement Units in a Wide-Area Management System
    IEEE Power and Energy Magazine Published: 2015 Show More IEEE Personal Account
    CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS
    Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL
    INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT
    & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms
    of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy
    Policy A not-for-profit organization, IEEE is the world''s largest technical professional
    organization dedicated to advancing technology for the benefit of humanity. ©
    Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE Access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/7419931/07548112.pdf
  publication_year: 2016
  relevance_score1: 0
  relevance_score2: 0
  title: 'Energy big data: A survey'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/tnsm.2019.2927886
  analysis: '>'
  authors:
  - Sahil Garg
  - Kuljeet Kaur
  - Neeraj Kumar
  - Georges Kaddoum
  - Albert Y. Zomaya
  - Rajiv Ranjan
  citation_count: 187
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences Processing
    math: 100% IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create
    Account Personal Sign In Browse My Settings Help Access provided by: University
    of Nebraska - Lincoln Sign Out All Books Conferences Courses Journals & Magazines
    Standards Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Transactions
    on Network ... >Volume: 16 Issue: 3 A Hybrid Deep Learning-Based Model for Anomaly
    Detection in Cloud Datacenter Networks Publisher: IEEE Cite This PDF Sahil Garg;
    Kuljeet Kaur; Neeraj Kumar; Georges Kaddoum; Albert Y. Zomaya; Rajiv Ranjan All
    Authors 181 Cites in Papers 3762 Full Text Views Abstract Document Sections I.
    Introduction II. Proposed Hybrid Model III. Extensions to GWO and CNN IV. A Robust
    Hybrid Model for Anomaly Detection V. Numerical Simulation Results Show Full Outline
    Authors Figures References Citations Keywords Metrics Abstract: With the emergence
    of the Internet-of-Things (IoT) and seamless Internet connectivity, the need to
    process streaming data on real-time basis has become essential. However, the existing
    data stream management systems are not efficient in analyzing the network log
    big data for real-time anomaly detection. Further, the existing anomaly detection
    approaches are not proficient because they cannot be applied to networks, are
    computationally complex, and suffer from high false positives. Thus, in this paper
    a hybrid data processing model for network anomaly detection is proposed that
    leverages grey wolf optimization (GWO) and convolutional neural network (CNN).
    To enhance the capabilities of the proposed model, GWO and CNN learning approaches
    were enhanced with: 1) improved exploration, exploitation, and initial population
    generation abilities and 2) revamped dropout functionality, respectively. These
    extended variants are referred to as Improved-GWO (ImGWO) and Improved-CNN (ImCNN).
    The proposed model works in two phases for efficient network anomaly detection.
    In the first phase, ImGWO is used for feature selection in order to obtain an
    optimal trade-off between two objectives, i.e., reduced error rate and feature-set
    minimization. In the second phase, ImCNN is used for network anomaly classification.
    The efficacy of the proposed model is validated on benchmark (DARPA''98 and KDD''99)
    and synthetic datasets. The results obtained demonstrate that the proposed cloud-based
    anomaly detection model is superior in comparison to the other state-of-the-art
    models (used for network anomaly detection), in terms of accuracy, detection rate,
    false positive rate, and F-score. In average, the proposed model exhibits an overall
    improvement of 8.25%, 4.08%, and 3.62% in terms of detection rate, false positives,
    and accuracy, respectively; relative to standard GWO with CNN. Published in: IEEE
    Transactions on Network and Service Management ( Volume: 16, Issue: 3, September
    2019) Page(s): 924 - 935 Date of Publication: 10 July 2019 ISSN Information: DOI:
    10.1109/TNSM.2019.2927886 Publisher: IEEE Funding Agency: SECTION I. Introduction
    The need for increased computational power and on-demand services as per the user’s
    requirements has paved the way to one of the most powerful technologies of the
    modern era, Cloud Computing (CC). According to Gartner, CC has been growing at
    a rate of 40% and will continue to rise at a rate of more than 25% per year [1].
    However, transition from traditional client-server architectures to CC is not
    straightforward and there are a number of operational and security challenges
    induced due to its underlying virtualized environment. These risks further aggravate
    with the emergence of the Internet of Things (IoT) in which smart devices communicate
    with each other using an open channel, Internet. Moreover, these connected devices,
    deployed across different enterprises, generate large volumes of streaming data,
    ranging from micro-blog feeds and financial information to complex network monitoring
    logs [2]. Recent studies have shown that intruders have successfully launched
    several attacks, which have caused unprecedented levels of disruption in various
    CC-hosted application services. Recent insights on Cloud Adoption and Security
    by Forbes says that 49% of businesses are delaying cloud deployment due to cybersecurity
    issues [3]. According to existing proposals and reports, more than 20% of enterprises
    in the world witnessed at least one form of Denial of Service (DoS) attack on
    their infrastructures. For instance, DoS attack on the Amazon cloud infrastructure
    caused the BitBucket site to be unavailable for a substantial amount of time [4].
    Likewise, Dropbox was rendered un-operational for more than 15 hours [5]. Apart
    from this, researchers from Symantec have discovered that the growing dependence
    on Cloud services has opened doors for more severe forms of intrusions. Thus,
    in order to remain resilient, the cloud needs to possess the ability to react
    not only to the known threats, but also to new emerging threats which may target
    its underlying networking infrastructure. To combat these challenges, researchers
    have extensively used Intrusion Detection Systems (IDSs) as a defensive strategy
    for cloud security [6]. IDSs used in cloud environments include misuse detection,
    anomaly detection, hypervisor introspection (HVI), virtual machine introspection
    (VMI), and a combination of these. Among all these techniques, anomaly detection
    with respect to heterogeneous traffic flow data generated due to diverse application
    types, is still in its infancy. More recently, different variants of anomaly detection
    techniques, amalgamated with IDSs, were proposed in the literature [7], [8]. For
    instance, Pandeeswari and Kumar [9] proposed an IDS at the hypervisor layer to
    detect attacks in cloud environments using Fuzzy C-Means clustering algorithm
    along with Artificial Neural Network (FCM-ANN). Similarly, Watson et al. [10]
    proposed an online cloud anomaly detection technique which uses one-class Support
    Vector Machine (SVM) algorithm to detect various types of malware and DoS attacks
    in CC infrastructures. Further, Ye et al. [11] proposed an anomaly detection framework
    based on Software-Defined Networks (SDN) for cloud setups. Sha et al. [12] designed
    a multi-order Markov chain based model for anomaly detection using DARPA dataset.
    In [13], Tan et al. used Multivariate Correlation Analysis (MCA) for accurate
    characterization of known and unknown DoS attacks. Although competent in general
    anomaly detection, most of these approaches suffer from high false alarm rates
    and elevated computational complexity. Hence, these schemes are not efficient
    particularly for network anomaly detection in streaming data, which requires real-time
    analysis [14]. Recently, another trend has grabbed the attention of researchers
    for network anomaly detection, namely deep-learning (DL). It is a widely-accepted
    machine learning approach that plays a significant role in detecting the most
    relevant features from huge datasets using back propagation. Ever since its inception,
    different architectures have been proposed in the literature such as-Deep Neural
    Networks, Deep Belief Networks, Recurrent Neural Networks and Convolutional Neural
    Networks (CNN) [15]. Among these techniques, CNNs are widely utilized for data
    classification due to their inherent ability to be trained with minimum pre-processing
    requirements; which makes them suitable for network anomaly detection. A. Motivation
    It is evident from the above discussion that a number of proposals have been suggested
    to detect anomalous behavior in network traffic using a wide variety of techniques
    such as-SVM, MCA, FCM-ANN, etc. However, these techniques are inefficient because
    of their reduced accuracy and high false positive alarms. Additionally, due to
    the heterogeneous and diverse nature of cloud environments, existing techniques
    may not be applicable to handle the challenges induced due to the existence of
    virtualized environments and different types of application workloads [16]. In
    order to tackle these exploding security risks, an efficient anomaly detection
    technique for streaming data needs to be designed. It should involve careful examination
    of both historical and real-time data streams with high accuracy and minimal computational
    complexity [17], [18]. Hence, an anomaly detection model particularly for heterogeneous
    data in CC networking environments is designed in this paper. Two important issues
    are explored in the proposed hybrid model (see Fig. 1), i.e., relevant feature
    set selection from the traffic stream repository and their classification into
    benign and anomalous classes. In the proposed model, feature extraction is achieved
    using Grey Wolf Optimization (GWO) [19], a meta-heuristic approach based on evolutionary
    computation which is widely accepted for its simplicity, flexibility and ability
    to yield optimal results. On the other hand, anomaly classification is done using
    CNN, a promising deep learning approach. In addition to this, the proposed work
    also enhances the capabilities of the proposed model with (i) improved exploration,
    exploitation and initial population generation abilities for GWO and (ii) revamped
    dropout functionality for CNN. The improvised version of CNN with dropout functionality
    not only helps avoid over-fitting but also increases the weights of the most relevant
    features of the network. This in turn, simultaneously enhances the accuracy of
    the architecture while helping it converge faster. Fig. 1. Proposed hybrid model
    using ImGWO and ImCNN for network anomaly detection in cloud setup. Show All GWO
    and CNN are powerful techniques that have been exploited by the research community
    in the networking domain to address various problems. For instance, Yang and Zhou
    [20] used GWO to design an effective IDS based on cloud with improved exploration
    and exploitation capabilities. Mao et al. [21] proposed the use of CNN for path
    prediction in SDN by learning from the past experiences and pro-actively updating
    the routing paths. Here, CNN was deployed at the controller and was specifically
    used to overcome the issues induced by fixed path routing decisions. In another
    work, Ji et al. [22] and Xiao et al. [23] employed CNN for network fault prediction
    by effectively analysing the log files. In this work, the log files were treated
    as textual files for monitoring the realtime status of the network and predicting
    any network faults using CNN. Likewise, CNN has also been employed for network
    intrusion detection in different forms. B. Contributions The major contributions
    of the proposed work are summarized as follows: We design an efficient hybrid
    model using GWO and CNN for efficient network anomaly detection in cloud setups.
    GWO is used for multi-objective feature extraction, while CNN is used for anomaly
    classification. We propose an improvised version of GWO (ImGWO) which enhances
    the exploration, exploitation, and initial population generation abilities of
    the standard GWO on streaming data. The capabilities of the standard CNN are improved
    by revamping the functionality of dropout layer using uniform distribution approach.
    The modified version of CNN is referred as ImCNN. We provide qualitative and quantitative
    comparison of the proposed hybrid model with the current state-of-the-art models
    on benchmark and synthetic datasets for network anomaly detection. C. Organization
    The rest of the paper is structured as follows. Section II presents the system
    model followed by an illustrative description of ImGWO and ImCNN in Section III.
    The proposed hybrid model for network anomaly detection is described in Section
    IV. Simulation results are summarized in Section V followed by conclusion and
    future directions in Section VI. SECTION II. Proposed Hybrid Model This section
    provides an overview of the proposed hybrid model used for network anomaly detection
    in cloud setups in the context of streaming network traffic data. The detailed
    architectural diagram is depicted in Fig. 1. The individual data processing phases
    are namely-1) dataset selection, 2) data preprocessing, 3) feature selection using
    ImGWO followed by 4) data output, 5) data preprocessing, 6) data splitting, and
    7) anomaly detection using ImCNN. Their detailed description is provided below.
    Dataset selection is the first phase of the proposed hybrid model. In this paper,
    three different datasets were utilized which belong to two categories, i.e., benchmark
    and synthetic. From these datasets, the tcpdump logs are extracted as they predominantly
    contain the traffic information pertaining to CC infrastructure. These logs comprise
    of TCP and UDP packets which constitute almost 90% of the datacenter traffic and
    thus, are used to represent the network traffic flow data. For these reasons,
    the considered log files have been considered to detect anomalies over the Internet
    traffic. During the second phase, the proposed model processes the input data
    for ImGWO. The individual TCP and UDP packets are extracted from the tcpdump logs
    and are given as input to the ImGWO. Following this, feature extraction phase
    is executed which is considered as an important prerequisite in any classification
    problem ranging from complex images and videos to textual and audio contents.
    Hence, ImGWO is particularly used to extract the relevant feature sets from the
    given input dataset such as-source IP address and port number, destination IP
    address and port number, etc. ImGWO is a multi-objective feature extractor that
    helps to find the optimal number of features from the available dataset with high
    classification performance. The improvised packets with the relevant features
    are provided as the output of this phase. Next, the output acquired from the previous
    step is preprocessed and converted to RBG format images (32 \times 32 \times 5).
    These images serve as the input to the next phase. Finally, the dataset comprising
    of RBG images is split in the ratio of 70:30; wherein 70% data is used during
    the training phase, whereas the rest is utilized in the testing phase of the ImCNN.
    In the former phase, the hybrid model is trained to detect anomalous activities
    in the network traffic data, while in the latter phase, it identifies the anomalous
    activities by applying the underlying logic on the historical data and current
    input data. Finally, during the anomaly detection phase, ImCNN, a multi-class
    classifier is used to classify the anomalies of the traffic streams. It is comprised
    of 8 layers to achieve the desired level of classification. The detailed description
    of the layers is provided in Section III-B. SECTION III. Extensions to GWO and
    CNN This section presents the detailed description of the improvements done to
    the standard GWO and CNN techniques to accelerate convergence and maximize the
    accuracy. These modifications are discussed as follows. Related symbols and notations
    are defined in Table I. TABLE I List of Symbols and Their Meanings A. Improved-GWO
    Variant The existing GWO suffers from several problems like random initial population
    generation and limited exploration and exploitation capabilities which hamper
    the local search capability of the algorithm and affect the convergence. The improvements
    corresponding to these shortcomings are discussed herewith: 1) Improved Initial
    Population Generation: In traditional GWO, the initial population is generated
    randomly over the search space which may lead to lack of diversity of the pack
    of wolves in the considered search space. Numerous studies have suggested that
    the initial population plays a significant role in the global convergence speed
    and the optimality of the obtained solution. Motivated by this fact, this work
    generates an appropriate initial population using uniform distribution, wherein
    the positions of the wolves (x_{i}^{j} ) are likely to be equally distributed
    [24]. The computation of x_{i}^{j} is achieved as follows:\begin{equation*} x_{i}^{j}=x^{j}_{min}+\mathcal
    {U}(\mu,\sigma)\times \left ({x^{j}_{max}-x^{j}_{min}}\right)\tag{1}\end{equation*}
    View Source here, positions of wolves, x_{i}^{j} are generated using the uniform
    distribution with the mean and standard deviation of population (\mu and \sigma
    ) respectively. 2) Improved Exploration and Exploitation Capability: The existing
    coefficient vectors \vec {A} and \vec {C} in GWO are used for the exploration
    and exploitation, respectively. Using \vec {A} in every iteration, population
    of wolves are segregated, wherein half of the iterations are devoted to exploration
    (when |A|>1 ), while half is dedicated to exploitation (when |A| < 1 ). However,
    this division of population may lead to faster convergence with false pareto front.
    In order to resolve these problems, adaptive mutation is applied to extend the
    exploration ability of GWO. To control the probability and range of mutation on
    each wolf, a non-linear function (\mathcal {P}_{m}) is incorporated which is given
    as:\begin{equation*} \mathcal {P}_{m}=0.5e^{-10*t/T}+0.01\tag{2}\end{equation*}
    View Source where {t} is the present iteration and {T} denotes the maximum number
    of iterations. It can be seen from Eq. (2) that increasing iterations causes \mathcal
    {P}_{m} to increase exponentially. If it exceeds a random number in the range
    of [0, 1], the mutation is performed as shown in Eq. (3) below; where \mathcal
    {N} elements from the pack of wolves are picked to control the mutation range
    within the search space.\begin{equation*} \mathcal {N}=\max \left \{{1, *{D-\left
    ({\frac {t}{T}}\right)^{\gamma }\times \mathcal {P}_{m}}}\right \}\tag{3}\end{equation*}
    View Source Further, \vec {C} is not linearly related to \vec {A} . This component
    provides random weights to prey in order to stochastically emphasize ({C} > 1)
    or de-emphasize ({C} < 1). Hence, to further increase the randomness of \vec {C}
    at all times, this paper suggests the use of a statistical distribution as mentioned
    below [25]:\begin{equation*} r_{2}=r_{2}^{\prime }+\left [{\alpha \times N(0,1)^{3}_{t}
    \frac {\left ({r_{2}^{\mathrm {max}}-r_{2}^{\mathrm {min}}}\right)}{t}}\right]\tag{4}\end{equation*}
    View Source where, r_{2} is the random variable generated during the present iteration
    and r_{2}^{\prime } is the random number generated during the previous iteration.
    The variables r_{2}^{max} and r_{2}^{min} are the upper and lower bounds on r_{2}
    and the power of generating random number using {N} (0, 1) is set to 3 based on
    extensive numerical experimentation. This is helpful in avoiding the local optima
    stagnation especially during the final iterations. B. Improved-CNN Variant CNNs
    are widely utilized in the domain of image classification due to their limited
    pre-processing capability. This implies that, in contrast to classical algorithms
    involving manual intervention, a CNN evolves to learn the filters by itself analogous
    to classical algorithms involving manual intervention. Hence, this trait of CNN
    can be regarded as its major advantage over the existing schemes in addition to
    its ability to provide separation from the prior knowledge. However, the concept
    of “Dropout” plays an essential role in deep CNN as well as CNN in general. One
    of the serious issues with CNNs is over-fitting, which is induced due to the large
    network logs (big data). Such networks make it difficult for CNN deep learning
    technique to learn the relevant features quickly. The main ideology behind dropout
    is to randomly dropout a few units and their respective connections from the network.
    This is done during the training phase so that the units do not co-adapt a lot.
    This is achieved by configuring the output of the hidden layers (with probability=0.5)
    to zero. The dropped neurons are thus eliminated from the process and do not contribute
    in back propagation. Mathematically, the conventional dropout scheme can be understood
    using the below mentioned equations:\begin{align*} r^{(l)}=&Bernoulli(p)\\ \tilde
    {y}^{(l)}=&r^{(l)} * {y}^{(l)}\\ z_{i}^{(l+1)}=&w_{i}^{(l+1)}\tilde {y}^{(l)}
    + b_{i}^{(l+1)}\\ y_{i}^{(l+1)}=&f\left ({z_{i}^{(l+1)}}\right)\end{align*} View
    Source In the above equations, the indices {l} and {i} denote the hidden layer
    and hidden units, respectively. Every layer {l} is associated with a vector of
    inputs and outputs which are represented using z_{i}^{(l)} and y_{i}^{(l)} , respectively.
    The symbols w_{i}^{(l)} and b_{i}^{(l)} refer to the weights and biases associated
    with underlying layer {l} . In the conventional dropout approach, a vector of
    random numbers (r^{(l)} ) is initially generated using Bernoulli distribution,
    which is then multiplied element-wise with y_{i}^{(l)} , to yield \tilde {y}^{(l)}
    (thinned outputs). The obtained value of \tilde {y}^{(l)} acts as input to the
    next layer, and is used to compute the value of z_{i}^{(l+1)} . This process is
    repeated for all the layers using the activator function {f} . It is worth noting
    here that the output of Bernoulli distribution is either ‘0’ or ‘1’; which suggests
    that a particular hidden unit is either completely dropped or taken forward, respectively.
    Unlike the conventional dropout, the proposed dropout approach is based on the
    uniform distribution. It can be viewed as the extension of the conventional dropout
    scheme which focuses on enhancing the weights of the relevant feature maps. In
    other words, the proposed dropout scheme not only abandons some of the units and
    connections from the network like conventional dropout, but also alters the weights
    of some of the units (which have respective weights below 0.5). This task not
    only helps avoid the over-fitting but also increases the weights of the most relevant
    features of the network. This in turn, simultaneously enhances the accuracy of
    the architecture while helping it converge faster. Mathematically, the overall
    scheme is presented by Algorithm 1. Initially, list \mathcal {L} is initialized
    for all the hidden layers with weights less than or equal to 0.5 (Line 1). Then,
    vector r^{l} is initialized with the random numbers using the uniform distribution
    (Line 2). Following this, thinned outputs are computed using pair-wise multiplication
    of r^{l} and y^{l} , followed by z_{i}^{l+1} ’s computation (Lines 3-4). Finally,
    the outputs of the next layer, i.e., ({l}\,\,+ 1) are estimated and the process
    is repeated for all the layers in \mathcal {L} (Line 5). Algorithm 1 Modified
    Dropout in ImCNN 1: Initialize List \mathcal {L}=\{l_{1},...., l_{m}\};\forall
    {y}^{(l)} < =0.5\,\,\triangleright Initialize the hidden layer list with weights
    \le 0.5 2: Compute r^{(l)} \in [{0,1}] using uniform distribution \triangleright
    A vector of random numbers is computed using uniform distribution 3: Compute \tilde
    {y}^{(l)} = r^{(l)} \times {y}^{(l)} ;\forall l_{i} \in \mathcal {L}~\triangleright
    Thinned output computation for the l^{th} hidden layer 4: Compute z_{i}^{(l+1)}
    = w_{i}^{(l+1)}\tilde {y}^{(l)} + b_{i}^{(l+1)} ;\forall l_{i} \in \mathcal {L}~\triangleright
    Input computation for the next (l+1)^{th} hidden layer 5: Compute y_{i}^{(l+1)}
    = f(z_{i}^{(l+1)}) ;\forall l_{i} \in \mathcal {L}~\triangleright Output computation
    for the next (l+1)^{th} hidden layer 1) Complexity Analysis: The overall complexity
    of the algorithm is O(m); wherein {m} denotes the number of hidden layers employed
    in dropout. SECTION IV. A Robust Hybrid Model for Anomaly Detection The hybrid
    model for network-wide anomaly detection works in two phases and the their detailed
    operation is provided in what follows. A. Feature Selection Using ImGWO Since
    the performance of the classifier highly depends on the number of features (such
    as-source IP address and port number, destination IP address and port number,
    etc.), the problem consists of finding the most relevant features to maximize
    its performance. Let, D=\{x_{1},x_{2},\ldots, x_{n}\} be a given dataset with
    n objects and F=\{f_{1},f_{2},\ldots, f_{m}\} be the feature set with {m} number
    of features. Now, the feature selection process can be considered as a mapping
    of S(D,F,A_{de})\to F^{\prime } , where {F} (.) is the feature selection algorithm,
    A_{de} is the decisive attribute that represents class labels and F^{\prime }\subset
    F , where |F^{\prime }|=k ({k} < {m} ) are the number of selected features. The
    aim of the proposed feature selection technique is to compute F^{\prime } which
    are highly relevant to the dataset {D} as well as less related to each other.
    In the proposed model, ImGWO is used to formulate the multi-objective feature
    selection problem; wherein the best solution for each wolf is to be determined
    from a set of potential non-dominated solutions. In this context, the fitness
    function of the participating wolf swarm is mathematically described below. 1)
    Fitness Function of Wolf Swarm: Feature selection in the context of network anomaly
    detection typically suffers from two major conflicting objectives: to minimize
    the number of features and to reduce the error rate of classification. Due to
    the presence of trade-offs between two or more conflicting objectives, optimal
    decisions becomes difficult. Thus, a single objective problem with several constraints
    may not be able to adequately represent this problem. In this case, it is mandatory
    to use multi-objective optimization which operates under a certain set of constraints
    in order to minimize or maximize the set of objective functions. The proposed
    technique aims to compute a subset of features that yields the lowest Error Rate
    (\mathcal {E}) for the classifier. Several methods have been adopted to determine
    the classifier performance such as-Hamming loss, ranking loss, accuracy, etc.
    In order to evaluate the classification error rate of a grey wolf, this paper
    uses accuracy as an evaluation metric. The fitness function to minimize (\mathcal
    {E}) is given in Eq. (5). During the evolutionary training process, this function
    tests each possible subset of features to find the one which minimizes the classification
    error involved in feature selection.\begin{equation*} \mathcal {E}=(FP+FN)/(TP+TN+FP+FN)\tag{5}\end{equation*}
    View Source where FP, FN, TP and TN denote the False Positive, False Negative,
    True Positive and True Negative rates, respectively. These are typically real
    valued numbers in the range of [0, 100]. This is the basic fitness function which
    only considers the classification performance but does not take number of features
    into consideration. Thus, a multi-objective fitness function (\mathcal {F}) is
    used; where the first objective function (\mathcal {F}_{1}) aims to minimize the
    classification error rate, whereas the second objective function (\mathcal {F}_{2})
    tends to minimize the number of features. This function is defined as [26]:\begin{equation*}
    \mathcal {F}= \begin{cases} \mathrm {Error Rate} (\mathcal {E}) &~(\mathcal {F}_{1})\\
    \gamma \times \frac {\#F^{\prime }}{\#F}+(1-\gamma)\times \frac {\mathcal {E}_{c}^{F^{\prime
    }}}{\mathcal {E}_{c}^{F}} &~(\mathcal {F}_{2}) \end{cases}\tag{6}\end{equation*}
    View Source The above defined fitness function is expected to ensure the minimization
    of the number of features while maintaining a high classification performance.
    In the defined function, \gamma is any constant value lying between [0, 1], F^{\prime
    } denotes the number of selected features, {F} represents the total number of
    available features, \mathcal {E}_{c}^{F^{\prime }} is the classification error
    rate involved in selecting the feature-set and \mathcal {E}_{c}^{F} represents
    the error rate involved by using all the available features for classification.
    The detailed operation of the ImGWO for feature selection in the context of network
    anomaly detection is illustrated by Algorithm 2. During Step 1, different parameters
    such as-pop, T, F and pos are initialized (Lines 2-6). In Step 2, the initial
    population is generated using uniform distribution as discussed above. Along with
    this, the coefficient vectors (\vec {A} and \vec {C} ) and the random vectors
    (\vec {r}_{1} and \vec {r}_{2} ) are initialized (Lines 7-11). Following this,
    fitness functions are calculated for all the wolves to determine the optimal solution
    for the considered problem. Based on the obtained fitness values, the participating
    wolves are categorized into \alpha , \beta and \delta . The rest of the wolves
    are marked as \omega which follow \alpha , \beta and \delta (Lines 14-16). Finally,
    the process of improved exploration and exploitation capability as discussed above
    is repeated, till an optimal solution to the problem is reached (Lines 17-33).
    Algorithm 2 ImGWO : Proposed Feature Selection Technique Input: Dataset {D} .
    Output: Optimal feature subset F^{\prime } . 1: procedure Function(ImGWO) 2: Step
    1: Initializing Parameters 3: pop: size of population 4: T: maximum number of
    iterations 5: F: total number of features 6: pos: position of grey wolf 7: Step
    2: Initial Population Generation 8: Generate the initial population using uniform
    distribution 9: Initialize \vec {A} 10: Compute r_{2} using Eq. (4) 11: Initialize
    \vec {C} using r_{2} 12: Step 3: Fitness Function Calculation 13: Calculate the
    fitness function (\mathcal {F}) of grey wolves using Eq. (6) 14: Set \alpha =
    the grey wolf with maximum fitness 15: Set \beta = the grey wolf with second maximum
    fitness 16: Set \delta = the grey wolf with third maximum fitness 17: while {t}
    < {T} do 18: for {i}\,\,= 1 to pop do 19: Update the pos of the current grey wolf
    20: end for 21: for {i}\,\,= 1 to pop do 22: for {j}\,\,= 1 to {F} do 23: Compute
    \mathcal {P}_{m} using Eq. (2) 24: if \mathcal {P}_{m}> r_{1} then 25: Calculate
    \mathcal {N} using Eq. (3) 26: Set F^{\prime }=\{f_{1},f_{2},\cdots,f_{\mathcal
    {N}}\} 27: for {k}\,\,= 1 to \mathcal {N} do 28: Re-initialize the k^{th} feature
    of the grey wolf 29: end for 30: end if 31: end for 32: end for 33: end while
    34: end procedure 2) Complexity Analysis: The overall complexity of the proposed
    algorithm was found to be O(mnp); wherein variables m, n and p refer to the number
    of iterations, population size and number of features in the dataset, respectively.
    The proposed ImGWO gives better convergence with improved exploration, exploitation
    and initial population generation abilities than its standard counterpart. B.
    Anomaly Detection Using ImCNN The structure of the ImCNN used in the proposed
    model for effective anomaly classification is described as under. The logical
    structure of the proposed ImCNN is described using Fig. 2. As shown in the figure,
    the ImCNN architecture comprises of 8 layers, namely 4 convolutional layers (conv),
    2 sub-sampling layers (samp), 1 dropout layer (drop) and 1 fully connected layer
    (conn). The sequence of the layers is as under: conv_{1}, conv_{2}, {samp_{1}},
    conv_{3}, conv_{4}, {samp_{2}}, drop_{1} , and conn_{1} . The detailed operation
    of these layers is provided in what follows. Fig. 2. The architecture of the ImCNN
    used for network anomaly detection for streaming data in cloud setup. Show All
    The images acquired from streaming data traffic serve as the input to the ImCNN
    with the size of 32 \times 32 \times 3; wherein the spatial dimension are represented
    using 32 \times 32 pixels and the channel dimensions are fixed to 3. In the first
    layer, i.e., conv_{1} a 2D kernel of size 3 \times 3 is applied to the input.
    Here, a 2D kernel is utilized to extract the relevant feature set. Since, a single
    kernel is capable of extracting a single feature, thus a total of 12 2D kernels
    are applied on the data set to generate a holistic feature map of 12 size in the
    very first layer. Moreover, a total of 6 2D kernel of dimensions 2 \times 2 are
    utilized as part of the conv_{2} layer. Subsequently, with an aim to reduce the
    spatial resolution, sub-sampling is carried out in the next layer, i.e., samp_{1}
    . This layer helps to enhance the robustness of even the minute spatial distortions.
    Here, the sampling is performed with the factor of 2 \times 2 which doesn’t affect
    the size of the feature map. In order to generate a more optimized feature map,
    another layer of convolution, i.e., conv_{3} is utilized with the 2D kernel (3
    \times 3). This layer in turns generates a set of 3 feature maps. Finally, another
    convolution layer (conv_{4} ) for deep feature identification is employed next.
    Like the previous layer, the same kernel is used in this layer producing a total
    of 3 feature maps. Subsequently, sub-sampling is performed on the data as part
    of samp_{2} layer; without affecting the size of the feature map. Finally, the
    modified dropout approach as discussed in Section III-B is carried out as part
    of drop_{1} layer; wherein the ImCNN tends to learn the robust features of the
    underlying network. In the next layer, the proposed ImCNN tends to learn high-level
    features of the input datasets using convolution in conn_{1} . It is a fully-connected
    layer which utilizes 3D kernel (size = 5 \times 5 \times 3), reducing the feature
    map to 1 \times 1 \times 5 size. The number of outputs of this layer is 5 which
    corresponds to different classes of normal and anomalous traffic streams namely-normal,
    DoS, U2R, R2L and Probe. This output classifies the traffic stream into the above
    classes with a definite probability which is chosen in accordance with the benchmark
    datasets [27], [28]. SECTION V. Numerical Simulation Results This section demonstrates
    the performance of the proposed model compared to the current state-of-the-art
    schemes for network anomaly identification. It is implemented using i3-6100U CPU
    @ 2.30 GHz with 4 GB of RAM on MATLAB R2016a. For the extensive evaluation of
    the proposed model, three sets of case studies have been considered which measure
    the performance of the proposed model on different datasets, i.e., benchmark and
    synthetic datasets. A. Evaluation Metrics In order to evaluate the performance
    of the proposed model, the following parameters are used: Detection Rate (DR)
    or recall, False Positive Rate (FPR), precision, accuracy and F-score [7], [24].
    The mathematical derivation of these parameters is illustrated using the below
    equations.\begin{align*} {\mathrm {DR (Recall)}}=&\frac {TP}{TP+FN}\\[4pt] {\mathrm
    {FPR}}=&\frac {FP}{FP+TN}\\[4pt] {\mathrm {Precision}}=&\frac {TP}{TP+FP}\\[4pt]
    {\mathrm {Accuracy}}=&\frac {TP+TN}{TP+TN+FP+FN}\\[4pt] {\mathrm {F{-}score}}=&2\times
    \frac {\mathrm {Precision} \times {\mathrm {Recall}}}{{\mathrm {Precision}} +
    {\mathrm {Recall}}}\end{align*} View Source In the above equations, the parameters
    TP, TN, FP and FN refer to True Positive, True Negative, False Positive and False
    Negative, respectively. TP refers to the case when the considered class (network
    traffic in our case) is actually normal and is classified as normal. On the similar
    lines, an anomalous class classified as normal is referred to as FP. On the contrary,
    a normal class may be classified as anomalous, while an anomalous class may be
    predicted anomalous. These cases are respectively ascribed as TN and FN. B. Datasets
    Used 1) Benchmark Dataset-DARPA’98: The benchmark dataset used for evaluation
    purpose is acquired from Defense Advanced Research Projects Agency (DARPA) comprising
    of 58 features [27]. This benchmark dataset is widely accepted and is used for
    network anomaly detection. It comprises of 4 set of files namely-tcpdump files,
    tcpdump list files, Solaris BSM audit data files, and ps monitoring data files.
    These files contain the network traffic log information, however, amongst these
    files only the tcpdump files contain the traffic log information pertaining to
    cloud environment. Hence, the tcpdump files are used for evaluating the performance
    of the proposed hybrid model. Moreover, this raw data (in the form of bytes/packets
    from tcp dump file) is converted into images for evaluation purposes during the
    preprocessing phase as explained in Section IV. 2) Benchmark Dataset-KDD’99: KDD
    Cup 1990 is a benchmark data that is acquired from UCI machine learning repository
    for Case study-II [28]. It comprises of nearly 5 million records and a total of
    41 features. Like DARPA’98 dataset, the traffic in this dataset can also be classified
    into 5 classes namely-normal, DoS, U2R, R2L and Probe. 3) Synthetic Dataset: In
    oder to perform a more comprehensive evaluation of the proposed model, a simulated
    environment has been set up to generate synthetic network traffic streams. For
    this purpose, two machines were setup, wherein the first machine was a typical
    Windows PC, while the other was a dummy server. On the former machine, different
    kinds of malicious files were executed to generate the anomalous traffic, while
    on the later machine INetSim2 was used to set an imitation of Internet. The main
    advantage of using INetSim2 is that it can be used to generate common Internet
    services data (HTTP, SMTP, DNS, FTP, etc.). Subsequently, the generated data from
    the Windows PC is sent to the server, to which the server responds back with the
    appropriate queries. The communication between the two machines carries both the
    anomalous and benign traffic and the same has been employed for the performance
    evaluation of the proposed model. The anomalous traffic was injected into the
    traffic stream for following attack vectors: DoS, Generic, Shell code and CLET
    [29]. Hence, the generated synthetic traffic streams can be classified into 2
    classes, i.e., normal and anomalous. C. Results & Comparisons For the extensive
    evaluation of the proposed model, three case studies were taken into account.
    These case studies evaluate the performance of the model on different datasets,
    i.e., Case study-I on DARPA’98 dataset, Case study-II on KDD’99 dataset and Case
    study-III on synthetic dataset. The results obtained are highlighted in Figs.
    3 and 4 respectively. Fig. 3. Performance evaluation of the proposed ImGWO on
    benchmark & synthetic datasets. Show All Fig. 4. Performance evaluation of the
    proposed hybrid model on benchmark datasets. Show All For the sake of clarity,
    the obtained results are illustrated in two parts namely-for ImGWO and for proposed
    hybrid model (ImGWO+ImCNN). The relative comparison of the former was carried
    out against the standard GWO; while the latter was compared with the hybrid combination
    of GWO and CNN (GWO+CNN). Their detailed description is as follows. 1) For ImGWO:
    ImGWO was used for the optimal feature set selection from dataset. In the considered
    case studies, ImGWO was able to attain optimal results as shown in Fig. 3. The
    trade-off between the competing functions, i.e., number of features and error
    rate is depicted in the figure. It is evident from the figure that ImGWO leads
    to improved feature set selection while minimizing the error rate relative to
    the standard GWO. A total of 37, 34 and 21 features were selected out of 58, 41
    and 35 in Case study-I, II and III, respectively, by ImGWO. For instance, important
    features like the duration of the connection, the number of bytes transferred
    from sources to destination, the number of bytes transferred from destination
    to sources, the number of failed logins, protocol type, the status of connection,
    the number of failed login attempts, the number of compromised conditions, etc.
    were selected by ImGWO. 2) For Proposed Hybrid Model (ImGWO+ImCNN): The performance
    evaluation of the proposed hybrid model for network anomaly detection across the
    considered case studies is discussed as under. In total, 6 parameters have been
    used for the evaluation purpose of the ImCNN architecture for anomaly detection.
    The obtained results in terms of Case study-I are detailed as under. Fig. 4a depicts
    the high DR achieved by the proposed hybrid model corresponding to normal and
    anomalous classes (DoS, U2R, R2L and Probe attacks) on DARPA’98 benchmark dataset.
    The FPR corresponding to the considered set of classes is depicted in Fig. 4b.
    It is evident from the figure that the proposed model yields FPR values as low
    as 4.167, 3.448, 3.846, 3.846, 2.703 with respect to different classes. Fig. 4c
    indicates the proposed model’s precision in achieving the desired results. It
    achieves high precision in detecting both normal (99.98) and anomalous classes
    (99.98, 99.93, 99.93, 99.98). Similarly, evaluation results with respect to accuracy,
    F-score and ROC curves are shown in Figs. 4d, 4e and 4f, respectively. The results
    clearly indicate good performance of the proposed model across all the parameters
    relative to its existing counterpart, i.e., GWO+CNN. Next, we illustrate the performance
    of the ImCNN architecture on KDD’99 dataset for Case study-II. The obtained results
    are also depicted in Fig. 4. The proposed model is found to be effective enough
    to achieve higher DR, precision and accuracy in comparison with Case study I and
    the same is evident from the results depicted in Figs. 4a, 4c and 4d respectively.
    Moreover, the proposed model achieves FPR values as low as 2.70, 2.20, 2.10, 1.80
    and 2.30 in detecting normal, DoS, U2R, R2L and probe attack classes. Figs. 4e
    and 4f depict the F-score and ROC curves which clearly indicate the capability
    of the model of achieving satisfactory performance. Overall, the proposed model
    is found to perform better on KDD’99 dataset relative to the DARPA’98 dataset.
    Further, during this case study as well, the proposed scheme performs better than
    the combination of GWO+CNN as indicative from the results (shown in Fig. 4). The
    evaluation results for Case study-III are depicted in Figs. 5a and 5b. The results
    clearly indicate that the proposed scheme achieves quality results even in case
    of the synthetic dataset. High DR, precision, accuracy and F-score with low FPR
    are an indicative of the performance of the proposed scheme on synthetic dataset.
    The related results are highlighted in Fig. 5a. The corresponding ROC evaluation
    for this case study are summarized in Fig. 5b. The obtained results imply that
    the proposed model is efficient enough to be implemented in real-time. Fig. 5.
    Performance evaluation of the proposed hybrid model on synthetic dataset. Show
    All In addition to this, the timing analysis of the proposed scheme across all
    the datasets is depicted in Fig. 6. The obtained results indicate that the proposed
    model executes in a reasonable amount of time across all the case studies considered.
    The obtained results are indicative of the fact that the proposed approach is
    reasonably fast and its performance doesn’t fluctuate much with the change in
    datasets. Contrastingly, the existing scheme based on the amalgamation of conventional
    GWO and CNN, requires greater execution time. Additionally, the choice of the
    dataset also affects its execution time adversely. On average, the proposed model
    exhibits an overall improvement of 8.25%, 4.08% and 3.62% in terms of DR, FPR,
    and accuracy, respectively. Fig. 6. An illustration of the timing analysis. Show
    All 3) Comparison With the Existing Schemes: The detailed comparison of the proposed
    model with the current state-of-the-art techniques [9], [30], [31], [32], [33],
    [34] is depicted in Table III. As evident from the table, the results obtained
    by the proposed model show an indicative improvement over the existing schemes.
    For instance, the proposed model performs far better than the existing schemes
    in terms of FPR, accuracy, and F-score for DARPA’98 dataset, and in terms of DR
    and F-score for KDD’99 dataset. TABLE II Illustration of Confusion Matrix TABLE
    III Performance Comparison of the Proposed Model With the state-of-the-Art Techniques
    SECTION VI. Conclusion This work presents a robust hybrid model for network anomaly
    detection in cloud environments, particularly for streaming data. The model leverages
    the advantages of multi-objective optimization and deep learning, particularly
    for feature extraction and anomaly detection on real-time network traffic streams.
    For this purpose, two computationally efficient techniques were employed namely-GWO
    and CNN. The amalgamation of these techniques is further improved by revamping
    their respective standard strategies. For instance, GWO is improvised with respect
    to enhance initial population, exploration and exploitation capabilities, while
    CNN is modified in terms of dropout layer functionality. Additionally, the proposed
    hybrid model was extensively evaluated on benchmark and synthetic datasets. The
    results obtained clearly indicate the supremacy of the proposed model relative
    to the existing models. In the future, we will extend the present work for malware
    detection, particularly for cloud environments. The inherent complexity in the
    cloud environment is induced due to the heterogeneity of incoming traffic and
    underlying hardware; which makes the task of anomaly detection more cumbersome.
    Authors Figures References Citations Keywords Metrics More Like This Expedite
    feature extraction for enhanced cloud anomaly detection NOMS 2016 - 2016 IEEE/IFIP
    Network Operations and Management Symposium Published: 2016 Unsupervised Anomaly
    Detection Using Variational Auto-Encoder based Feature Extraction 2019 IEEE International
    Conference on Prognostics and Health Management (ICPHM) Published: 2019 Show More
    IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS
    VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE eTransactions on network and service management
  limitations: '>'
  pdf_link: null
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: A Hybrid Deep Learning-Based Model for Anomaly Detection in Cloud Datacenter
    Networks
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/access.2020.2986882
  analysis: '>'
  authors:
  - Ae Chan Kim
  - Mohyun Park
  - Dong Hoon Lee
  citation_count: 99
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences Loading
    [MathJax]/extensions/MathMenu.js IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More
    Sites Subscribe Donate Cart Create Account Personal Sign In Browse My Settings
    Help Institutional Sign In All Books Conferences Courses Journals & Magazines
    Standards Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Access
    >Volume: 8 AI-IDS: Application of Deep Learning to Real-Time Web Intrusion Detection
    Publisher: IEEE Cite This PDF Aechan Kim; Mohyun Park; Dong Hoon Lee All Authors
    107 Cites in Papers 13274 Full Text Views Open Access Comment(s) Under a Creative
    Commons License Abstract Document Sections I. Introduction II. Background III.
    Security Operations for Deep Learning IV. Design and Implementation V. Experiments
    Show Full Outline Authors Figures References Citations Keywords Metrics Footnotes
    Abstract: Deep Learning has been widely applied to problems in detecting various
    network attacks. However, no cases on network security have shown applications
    of various deep learning algorithms in real-time services beyond experimental
    conditions. Moreover, owing to the integration of high-performance computing,
    it is necessary to apply systems that can handle large-scale traffic. Given the
    rapid evolution of web-attacks, we implemented and applied our Artificial Intelligence-based
    Intrusion Detection System (AI-IDS). We propose an optimal convolutional neural
    network and long short-term memory network (CNN-LSTM) model, normalized UTF-8
    character encoding for Spatial Feature Learning (SFL) to adequately extract the
    characteristics of real-time HTTP traffic without encryption, calculating entropy,
    and compression. We demonstrated its excellence through repeated experiments on
    two public datasets (CSIC-2010, CICIDS2017) and fixed real-time data. By training
    payloads that analyzed true or false positives with a labeling tool, AI-IDS distinguishes
    sophisticated attacks, such as unknown patterns, encoded or obfuscated attacks
    from benign traffic. It is a flexible and scalable system that is implemented
    based on Docker images, separating user-defined functions by independent images.
    It also helps to write and improve Snort rules for signature-based IDS based on
    newly identified patterns. As the model calculates the malicious probability by
    continuous training, it could accurately analyze unknown web-attacks. Topic: Scalable
    Deep Learning for Big Data AI-IDS Architecture. Published in: IEEE Access ( Volume:
    8) Page(s): 70245 - 70261 Date of Publication: 10 April 2020 Electronic ISSN:
    2169-3536 DOI: 10.1109/ACCESS.2020.2986882 Publisher: IEEE CCBY - IEEE is not
    the copyright holder of this material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/
    to obtain full-text articles and stipulations in the API documentation. SECTION
    I. Introduction As technology evolves, cyber-criminals are also improving their
    attack methods, tools, and techniques to exploit organizations. In particular,
    public web-services are common services that anyone can access, and many companies
    provide their services through open webpages. If a web-service fails or is compromised,
    it can cause a drop in corporate reputation or revenue. In general, security managers
    prevent intrusions from external attacks by registering all denied black-list
    policies for unused services in the firewall, but web-services in the Internet
    Demilitarized Zone (DMZ) cannot be blocked by firewalls because they are always
    open to public access. As such, identifying normal access and differentiating
    it from malicious attacks is an important task in cybersecurity. In reality, many
    security incidents originated with web-attacks such as information disclosure,
    service failures, and malware infections. Hypertext transfer protocol (HTTP) [1]
    is an application-level protocol for distributed, collaborative, and hypertext
    information systems. Today’s HTTP is evolving where the information is transferred
    from web pages, and it is also used for exchanges or sending system commands to
    various devices, such as command-lines, update scripts, and mobile apps. Web-attacks
    often exploit vulnerabilities in applications in open web services rather than
    perform a host-level system penetration. The attacker attempts to attack by sending
    exploitational code using a vulnerability in a specific domain or path file of
    the webserver. The webserver or device that is injected with the code can subsequently
    be compromised by the attacker [2]. Traditionally, intrusion detection is a major
    research field in network security, as it is important to identify unusual access
    to secure internal networks. An Intrusion Detection System (IDS) is used to identify
    intrusions, attacks, or violations of security policies in a network or host system
    promptly [3]. An IDS system that inspects a packet of networks to detect attacks
    is called Network Intrusion Detection System (NIDS). An NIDS is collected using
    network equipment via mirroring by network devices, such as switches, routers,
    and network terminal access points (TAP), which is a surveillance device for monitoring
    network infringements and policy violations [4]. Many organizations operate NIDS
    with firewalls and an application firewall (L7) to protect webservers that are
    on the same network and system. An NIDS runs mostly signature-based detection
    by Snort IDS rules. The analyst writes a user-defined pattern into the rules to
    detect an attack. When there is a malicious payload on the network traffic, the
    rule triggers security events, including detection time, source/destination IP
    (metadata), and some raw packets (payloads). String or pattern match is reliable
    and generates very few false alarms but does not identify unknown or irregular
    pattern attacks. Recent sophisticated cyber-attacks use irregular patterns such
    as encoding and obfuscation to bypass security systems. To solve these problems,
    we applied AI-IDS to detect variant attacks that cannot be identified by legacy
    signature-based NIDS. A. List of Contributions The main contributions of this
    paper are summarized as follows: 1) Applying Deep Learning to Real-World Networks
    We have successfully applied AI-IDS to big-data scale traffic. The AI-IDS is a
    flexible and scalable system that is implemented based on Docker images, and separates
    user-defined functions by independent images. 2) Propose a Fast and Effective
    Preprocessing Method We implemented fast and effective spatial feature learning
    through normalized UTF-8 character encoding, even if we do not apply computationally
    intensive algorithms, such as entropy, compression, and encryption. For example,
    the entropy of a string requires probability calculation, followed by multiplication
    and logarithm. Instead, our proposed method can preprocess strings with a single
    operation. 3) Propose Optimized CNN-LSTM Model for Big Data We demonstrated the
    process of model design in detail via performance evaluation between CNN-LSTM,
    LSTM-CNN, and DNN models based on fixed real-time data from HTTP request packets.
    Hyper-parameters were determined in each model through repeat experiments. An
    optimized neural network model was validated through experiments on public datasets
    (CSIC-2010, CICIDS2017) and fixed real-time data. 4) Prove of Efficacy and Application
    We proved that AI-IDS could detect unknown attacks, such as obfuscated or encoded
    malicious payloads; it can write improved existing Snort rules and new rules for
    newly identified patterns. B. Conditions and Assumptions This study uses the following
    conditions and assumptions: 1) AI-IDS: an Open Source Software AI-IDS software
    contains the following license and notice below: Licensed under the MIT License.
    You can access the source-code directly on Github in our repositories [5]. 2)
    Parallel Operations: IDS, TAS An IDS and a Traffic Analysis System (TAS) operate
    independently and do not affect each other. We used a signature-based NIDS for
    intrusion detection and a Splunk StreamApp-based TAS for collecting real-time
    traffic. A TAS is equal to a packet monitoring system. 3) Application-Level Packets
    Inspection We focused on the HTTP commonly used in web services that request headers
    and payload data. We did not address low-risk attacks from protocols below the
    application layer, such as user datagram protocol (UDP). The remainder of this
    paper is organized as follows. Section II presents related works, limitations
    of meta-datasets, and the motivation for this study. Section III introduces the
    security operations for deep learning. Section IV shows our spatial feature learning
    algorithms for big-data, optimal CNN-LSTM model, and AI-IDS infrastructure. Section
    V shows the experimental results. Section VI introduces the efficacy and applications.
    The last Section VII shows the conclusion. SECTION II. Background This section
    describes related studies on deep learning-based IDS, and the limitations of meta-datasets
    and the motivation for this study are also described. A. Related Works Recent
    studies on intrusion detection using various deep learning (DL) techniques have
    been published since 2017. In Table 1, related studies focusing on intrusion detection
    using DL algorithms based on models, features, datasets, and performance measures
    are given. Liu et al. [6] showed that when compared with other IDS classifiers,
    intrusion detection models based on a convolutional neural network (CNN) have
    the highest detection rate and precision. The feasibility of applying a CNN in
    highly intruded detection has been proven. The authors argue that the performance
    of CNN-based techniques is better than that of other machine learning classification
    techniques. Wang et al. [7] designed an IDS using a CNN to automatically train
    and look for traffic characteristics, effectively reducing the false alarm rate
    (FAR). This study shows that deep learning techniques can be used to extract and
    learn the characteristics of network traffic in detail. Yin et al. [8] proposed
    an RNN-IDS and compared it with ANN, random forest (RF), SVM, and other machine
    learning methods. An RNN-IDS is suitable for modeling a classification model with
    high accuracy, and its performance is superior to that of traditional machine
    learning classification methods in both binary and multiclass classification.
    TABLE 1 Related Works on Intrusion Detection. Shone et al. [9] showed a non-symmetric
    deep auto-encoder (NDAE) for unsupervised feature learning. This study improves
    the classification performance of KDD99 and NSL-KDD99 by comparing an auto-encoder
    with a non-symmetric deep auto-encoder (NDAE). Wu et al. [10] devised CNN and
    RNN for attack detection; however, their model differs from the model used in
    this study because it performed separate experiments on the CNN and RNN model.
    Naseer et al. [11] investigated the suitability of deep learning approaches for
    anomaly-based intrusion detection systems. Ding and Zhai [12] compared the performance
    of models using multi-class classification with the performance of traditional
    machine learning methods. Otoum et al. [13] devised DL for an IDS available on
    wireless sensor networks (WSNs), and also compared the Boltzmann machine-based
    clustered IDS (RBC-IDS) and adaptive machine learning-based IDS: the adaptively
    supervised and clustered hybrid IDS (ASCH-IDS). Chouhan et al. [14] proposed a
    Channel Boosted and Residual learning-based deep Convolutional Neural Network
    (CBR-CNN) architecture for the detection of network intrusions. This study used
    Stacked Auto-encoders (SAE) and unsupervised training, and the performance of
    the proposed CBR-CNN technique is evaluated with an NSL-KDD dataset. Vinayakumar
    et al. [15] developed an IDS to detect and classify unforeseen and unpredictable
    cyberattacks by DNN. The performance was tested with the DNN model and compared
    to the results of the NSL-KDD, UNSW-NB15, Kyoto, WSN-DS, and CICIDS2017 datasets.
    Chiba et al. [16] proposed a DNN model in a cloud environment based anomaly network
    IDS using recent datasets, such as CICIDS2017, NSL-KDD version 2015, and CIDDS-001,
    using a hybrid optimization framework (IGASAA) based on the Improved Genetic Algorithm
    (IGA) and Simulated Annealing Algorithm (SAA). Zhang et al. [17], used a deep
    belief network (DBN) model to identify SQL injection attacks in network traffic.
    Faker and Dogdu [18] experimented with improving the performance of intrusion
    detection systems on CICIS2017 and UNSW NB15 datasets using a DNN and two ensemble
    techniques, RF and gradient boosting tree (GBT). Previous research has suggested
    new ideas or algorithms for improving deep learning algorithms. Aloqaily et al.
    [19] introduced an automated secure continuous cloud service availability framework
    for smart connected vehicles that enables an intrusion detection mechanism against
    security attacks. However, most previous deep learning-based studies have difficulty
    applying intrusion detection in real-world environments because the models were
    usually pre-processed into metadata formats in an experimental environment. Few
    studies have proven how to apply them in real-time in the real world. B. Limitations
    of Meta-Datasets Previous studies [8], [12], [15], [16] mainly focused on extracting
    or analyzing features from metadata rather than paying attention to exploited
    raw packets. Owing to network traffic changing with trends, the accuracy rates
    of real-world without continuous re-training is significantly reduced even if
    a system is 99.9% accurate in an experimental environment. The following is a
    description of the KDD99, NSL-KDD, and PU-IDS datasets that have been widely used
    in previous works. 1) KDD Cup 1999 Datasets KDD Cup 1999 Dataset [20] is the most
    widespread dataset for intrusion detection based on the DARPA dataset. The dataset
    contains TCP high-level attributes, such as the connection window, but no IP addresses.
    KDD99 involves more than 20 different types of attacks and comes along with redundant
    records in the test-set [21]. 2) NSL-KDD Datasets NSL-KDD [22] NSL-KDD is a dataset
    that has been enhanced from KDD99, removing much of the duplicated data from KDD99
    and creating a more advanced sub-dataset. The dataset consists of separate and
    predefined training data and test data for intrusion detection. NSL-KDD uses the
    same attributes as KDD 99 and belongs to the four attack categories: R2L, Prob,
    U2R, and DOS. belongs to the other category [23]. 3) PU-IDS Datasets PU-IDS [24]
    is a derivative of the NSL-KDD data set, and its author has developed a generator
    that extracts the statistics of the input data set and then creates a new data
    set. A traffic generator has the same attributes and format as the NSL-KDD data
    set. While previous studies mainly used KDD99 or KDD, and NSL-KDD, they are not
    suitable as datasets for real-time detection. These datasets deal with metadata
    and therefore make it difficult to identify invalid attacks in a practical environment,
    because metadata are not attack-attempts. Moreover, most public datasets contain
    redundant information and an unbalanced number of categories. For instance, Ring
    et al. [21] compared the characteristics of intrusion detection datasets used
    in previous works. This study shows that various previously published datasets
    model repetitive and inefficient attacks, such as DOS, UDP Flooding, and brute
    force, which are different to recent web-attacks trends. In fact, types of attacks
    and trends in the data are constantly changing; therefore, it is necessary to
    develop a general-purpose model that is not biased toward current trends. Another
    problem with most published datasets is that they are often over-fitted due to
    duplicated or flow-based metadata, and the performance of the model is significantly
    upgraded in experimental conditions. If the model is applied in practical services,
    it will face a serious problem with false-positive alarms. Likewise, the work
    in Sabhnani and Serpen [25] has shown that when using the KDD99 dataset, it is
    not possible to successfully train pattern classifications or machine learning
    algorithms for misuse detection. Nevertheless, most previous studies measured
    the model performance on deep learning or machine learning techniques in experiments
    using KDD99 datasets. Yin et al. [8] also used the KDDTest +- dataset to compare
    performance with the RNN model, and a recent work in Vinayakumar et al. [15] experimented
    using the DNN model through public data such as KDD99, NSL-KDD, and UNSW-NB15
    using machine learning techniques such as LR, NB, RF, and DT. Gu et al. [26] demonstrated
    that validated training data is an essential determinant for successful research
    that can greatly enhance the detection capability. Moreover, Moustafa et al. [27]
    compared the characteristics of various public datasets and suggested that datasets
    that are not based on reality can lead to misguided research. C. Motivation One
    of the challenges faced by security operations is an inefficient operation due
    to false-positive alarm events. It wastes IDS resources and reduces the performance
    for effective deep learning; therefore, the issue of false-positives should be
    addressed properly to detect threats in big-data infrastructure. Misuse detection
    that broadly applied in SOC uses predefined signatures for filtering and to detect
    attacks. It relies on human inputs by constantly updating the signature database.
    This method is accurate in finding known attacks but is completely ineffective
    for unknown attacks. In most cases in real-world environments, misuse detection
    generates a high false-positive rate similar to anomaly-based IDS. In the study
    of Mishra et al. [4], performance optimization was needed during the detection
    process to deal with false-positive issues. However, most previous works do not
    adequately address the false-positives issue in the real-world due to performance
    evaluations with limited datasets in experimental environments. To mitigate the
    false-positive problem, high-quality training data is a basic determinant for
    improving DL model performance. The most common issues with existing solutions
    based on learning models include First, the learning models produce a high false-positive
    rate with a wide range of attacks. Second, the learning models are not adaptive
    to the real-world, as meta-datasets like KDD Cup 99 were mainly used to evaluate
    the performance of the learning model. Third, previous studies were unable to
    foresee today’s huge network traffic; therefore, scalable solutions are required
    to maintain a high performance with a rapidly increasing high-speed network size.
    Finally, no cases have been published on DL applications for the detection of
    unknown attacks on real-world computer networks. These challenges form the primary
    motivation for the application of deep learning-based NIDS. SECTION III. Security
    Operations for Deep Learning This section introduces the security operations for
    deep learning applications and the data design for practical training. A. Overview
    of Security Operations We detected and analyzed intrusion attempts into financial
    networks to protect electronic financial incidents. The SOC also plays the role
    of an Information Sharing and Analysis Center (KF-ISAC). Fig. 1 shows that the
    SOC collected real-time network traffic, and detected malicious network traffic
    by directly installing an NIDS, a TAS, a TAP, and a virtual private network (VPN)
    on the Internet DMZ area of many financial companies in South Korea. The SOC operated
    continuously for 24 hours a day, 7 days a week, and 365 days a year. About 20
    people work in shifts and generate daily analytical information for training.
    The IDS and TAS data were transferred to the SOC via VPN from financial institutions,
    and the SOC collected approximately 1 billion real-time HTTP traffic per day (Sep.
    2019). FIGURE 1. AI-IDS applied Security Operations Center (SOC). Show All An
    NIDS is a signature-based misuse detection system based on Snort rules, and a
    TAS is a system that collects network traffic in a user-defined function. A TAS
    is a type of system that collects network traffic and enables users to analyze
    traffic by collecting various protocols, including HTTP, SMTP, and SSH. It allows
    analysts to analyze anomalies by collecting various network protocols from the
    network layer to the application layer. We use the StreamApp [28] as a Splunk
    software for traffic collection and an analysis system. For the effective detection
    and analysis of cyber-attacks, we recommend running NIDS and TAS in parallel.
    If security events are alerted on an NIDS, a TAS could inspect the same malicious
    payloads on the network. An NIDS and a TAS inspected a variety of protocols, such
    as SSDP, DNS, SMTP, POP3, HTTP, and SSL, from the network layer to the application
    layer on the network. As the UDP-based protocol does not establish 3-ways handshaking,
    it is difficult to attribute it to an IP address and can easily be forged. Thus,
    we did not analyze invalid UDP-type or denial of service (DOS) attacks to maintain
    stable performance. SSL protocol was excluded from our scope because it is not
    possible for an analyst to review the malicious payload. In managed security monitoring
    operations, security managers process security events in the order of Detection,
    Analysis, and Prevention. “Detection” means to collect security alerts generated
    by user-defined Snort rules on NIDS or TAS, which include detection time, source
    IP, destination IP, port information and signature messages in Table 2. “Analysis”
    refers to classifying events into true or false positives by reviewing detection
    information. “Prevention” is to register malicious IP addresses to blacklists,
    which are then blocked from accessing service websites. Prevention is applied
    to very obvious attack patterns, and it is recommended to block access from certain
    attacks only after being verified by an analyst or system. The proposed AI-IDS
    is used as a supplement system with legacy signature-based NIDSs for network layer
    security. TABLE 2 Attributes of Analysis Information. B. Data Design for Practical
    Training The proposed AI-IDS trains the labeled analysis information based on
    HTTP data in-bounding from the managed services instead of metadata sets in a
    constrained environment. We detect about 200,000 attacks on about 1 billion HTTP
    per day on legacy signature-based NIDS, and we perform about 10,000 automatic
    and manual analyses. During general security operations, malicious detection information
    is triggered by NIDS when an attack packet occurs in the network communication.
    Daily training-data on the production environment is labeled in real-time by security
    analysts using labeling tools. The analysis information labeled is shared with
    AI-IDS and used as training data for prediction in neural networks. We implemented
    deep learning models in real-time HTTP traffic– “Password guessing and Authentication
    bypass (AUT),” “SQL Injection (SQL),” and “Application vulnerability attack (APP).”
    For UDP-type attacks, such as “information gathering” or “denial of service,”
    it is difficult to identify the attacker’s IP address when compared to TCP, because
    the session is not connected perfectly, and contains meaningless repeated data;
    therefore, we excluded it from the deep learning model. Besides, HTTP traffic
    related to malware infection events are often detected when the malware connects
    to the C2 server after infection. Unlike general intrusion events of which traffic
    are sent from an external IP to an internal IP, malware events’ traffic is usually
    in the opposite direction. The security event shown in Table 2 consists of the
    detection time, detection site, direction, source IP, source port, destination
    IP, destination port, signature name, raw packet (pcap file), and flag. “Detection
    Time” is the time the signature generated the event, and “Detection Site” is the
    location identifier where IDS and TAS were installed. “Direction” shows the direction
    of attacks based on assets between the source IP and the destination IP. “Source
    IP/port (src_ip, src_port)” is the IP/Port address that requests a connection
    from the client to the server, and “Destination IP/port (dest_ip, dest_port)”
    is the IP/Port address from the server to the client. Most of the above metadata
    are managed as Critical IP or Threat Intelligence by security administrators.
    The number of HTTP requests collected per day was approximately 1 billion, of
    which about ten thousand were analyzed information about attack events detected
    in HTTP. Assuming a normal to abnormal ratio of 5:5, the amount of malicious analysis
    information is 65 MB for the last year, but benign HTTP traffic is 6 GB per day.
    To equalize the data rate for training in the deep learning model, the 65 MB HTTP
    payload, which was analyzed during one year, was multiplied 100 times by concatenation
    and shuffle, and the ratio of the analysis information and normal traffic was
    adjusted to be equal to 6 GB per day. Malicious events identified by analysts
    were used as data for re-training. The training data was approximately 6 GB per
    day, and the analysis information from the duration of 1 year was changed sequentially
    like a sliding window. SECTION IV. Design and Implementation This section introduces
    a fast and effective spatial feature learning based on normalized UTF-8 character
    encoding, detailed AI-IDS architecture, and the structure of a neuron network
    model for large-scale web traffic. A. Spatial Feature Learning Based on Normalized
    UTF-8 Character Encoding Feature extraction is one of the most important tasks
    in designing an efficient learning algorithm. Mamun et al. [29] devised a combined
    preprocessing technique using attributes of information theory such as entropy,
    encoding, and compression. Theoretically, the entropy of encrypted or irregular
    data is high as there are many uncertainties in the data stream. The entropy value
    indicates the degree of uncertainty of the information, but it is difficult to
    extract the feature by matching the unique characters of the given data 1:1. For
    example, entropy can express the uncertainty of information as a number in the
    range of 0 to 1, but a collision problem would be calculated with the same entropy
    even if different data were given. For this reason, it is difficult to extract
    unique features of a given string, as it is. Thus, we use UTF-8 encoding that
    normalizes the deep learning model to recognize the data with its own characteristics.
    It is simple and fast, because it does not include unnecessary entropy calculations,
    compression, encryption, or anything else. Assuming that all data preprocessing
    for billions of HTTP within 1,000 bytes per day is executed, the UTF-8 encoding
    method can achieve fast data preprocessing at only about 1× 2 8 ×1,000 billion.
    The biggest advantage of UTF-8 is that it cannot be confused with a single encoding
    method, so there is no possibility of wrong encoding in other ways, such as for
    the national language encoding method such as UTF-16, EUC-KR (Korean), GB2312
    (Simplified Chinese). As both browsers and web servers are now developed assuming
    UTF-8, it is a very efficient way to preprocess HTTP traffic. UTF-8 encoding in
    Algorithms 1–2 converts up to 256 characters into floats, which can be encoded
    into numbers, including special characters that include Simplified Chinese in
    the packet, such as WebDAV attacks. When preprocessing a string of 7 bits or less,
    it is difficult to preprocess various characters in a real environment. We used
    the normalized UTF-8 encoding and the module developed on “parse” and shown in
    Figs. 2 and 3. The input variable was replaced with a value corresponding to a
    unique string in the range of 0 to 255 (256 features), and the input string was
    converted into a float value between −1.000 and 1.000 given that y s =−( y s −128)/128
    . The output variables y s for a transformed set of input data, for one training-data
    size s∈[0,2,3,…,999] . FIGURE 2. Comparison of normalized UTF-8 encoding and entropy-based
    encoding. Show All FIGURE 3. AI-IDS architecture. Show All Algorithm 1 UTF-8 Character
    Encoding Input: content_string (web traffic) Output: *.npy (preprocessed file)
    1: FUNCTION save_data(content_string_list, npy_filename) 2: numpy_array < - numpy.empty()
    3: FOR content_string in content_string_list 4: byte_array < - [] 5: FOR character
    in content_string 6: byte_array.append(character.encode(‘utf-8’) 7: ENDFOR 8:
    int8_array < - [] 9: FOR byte in byte_array 10: int8_array.append(byte.toint8())
    11: ENDFOR // //float_array < - [] //FOR int_8 in int8_array // float_array.append(int_8
    - 128.0 / −128.0) //ENDFOR // //content_array < - numpy.array(float_array) //numpy.append(content_array)
    // // for data size issues, // the actual array is saved from int8_array // and
    the float is calculated just before training 12: content_array < - numpy.array(int8_array)
    13: numpy.append(content_array) 14: ENDFOR 15: numpy.save(npy_filename, numpy_array)
    16: ENDFUNCTION Algorithm 2 Spatial Feature Learning (train/test) Input: *.h5(model),
    *.npy (preprocessed file) Output: performance metrics 1: FUNCTION train_model(model,
    train_file_list, x_dim): 2: npy_list < - list(load(filename) for filename in train_file_list
    3: data < - concatenate(npy_list) 4: train_size < - data.shape[0] 5: x_train <
    - array(data[:,:−1]) 6: x_train < - (x_train −128.0) / −128.0 7: x_train < - x_train.reshape(train_size,
    x_dim, 1) 8: y_train < - data[:, [−1]].reshape(train_size, 1) 9: y_prediction
    < - model.predict(x_train, batch_size = 4096) 10: y_merged < - (y_prediction.round()*2+y_train).flatten()
    11: value, counts < - unique(y_merged, return_counts = True) 12: value_str < -
    list(map(lambda x: str(int(x)), value)) 13: metrics < - dict(zip(value_str, counts))
    14: loss < - binary_crossentropy(y_train, y_prediction)) 15: metrics[‘Loss’] <
    - average(loss) 16: RETURN metrics 17: ENDFUNCTION Fig. 2 shows a preprocessing
    example for “http://target.com/manager/html/.” When comparing preprocessing methods
    with our proposed UTF-8 encoding and entropy-based encoding, our proposed method
    is a normalized calculation expression. The entropy of a string requires probability
    calculation, followed by multiplication and logarithm. Entropy-based preprocessing
    involves two steps of calculating the probability of each string and then calculating
    the log. Instead, our proposed method can preprocess strings with a single operation
    and have no data transformation or substitution in the progress. Normalized UTF-8
    encoding generates input values so that the deep learning model can train immediately.
    Previous [30] research designed a CNN that can be trained as a corpus to process
    natural language between sentences and words. However, it functions closer to
    image processing than natural language processing because cybersecurity corpora
    have a different attribution compared with natural language. A corpus in the field
    of cybersecurity is difficult to create because it needs to understand string
    classifications and attributes, for example, “get, post, head, put, php, cgi,
    admin, wget, ‘POST /manager/html’, ‘User-Agent: Mozilla/5.0’.” In our initial
    model, we were trying to train the security corpus into the CNN filter and LSTM
    layers. However, as there is currently not enough research on cybersecurity corpora,
    we have implemented deep learning on all strings of the HTTP data. If a cybersecurity’s
    corpus was created, deep learning model performance is expected to be improved.
    B. AI-IDS Architecture Fig. 3 shows an enlarged representation of the AI-IDS and
    Index Cluster, as shown in Fig. 1. Individual modules are configured as Docker
    image/containers that output files after the Docker process. No Docker container
    affects another and they all run independently. However, Docker volumes are shared
    as same data in a series of processes, from pre-processing (parsing), training
    and testing, to prediction. Our AI-IDS process is as follows: (i) data save and
    splitting - collecting web traffic and splitting training data for each model
    (ii) data preprocessing and training by labeled analysis information (iii) prediction
    for suspicious payloads on new web-traffic. The following is a detailed process
    description of the AI-IDS, as shown in Fig. 3: 1) Data Save and Splitting Index
    Cluster collects true or false positive analysis information and normal traffic
    for training data and then stores it in “(labeled analysis info) data_save” (name
    of docker image). “data_save” saves legacy NIDS payload data along with its analysis
    results, and also previously labeled data by AI-IDS. Simultaneously, “(new traffic)
    data_save” stores real-time HTTP traffic for prediction in “ai_payloads” for the
    previous 3h to −10 min. “data_split” saves data in “ai_payloads” by splitting
    the data according to the intrusion attack types (AUT, SQL, APP) to generate training
    data for each deep learning model. Each process module has one or more input and
    output files. The real-time web traffic is transferred into application-level
    strings for AI-IDS, and the “data_backup” module backs up raw-data which has been
    collected more than 24 hours in the past. 2) Data Preprocessing and Training Output
    files for parsing is shared into the “ai_payloads” volume. Each spitted raw-data
    (in the form of.csv files) is classified by its attack type. Then it is preprocessed
    by “parse,” and the preprocessed data (npy files) is saved into a docker volume
    named “ai_parse_data.” The raw web-traffic strings are transformed into trainable
    float data for deep learning through our UTF-8 encoding with zero-padding. As
    a result of searching the optimum performance using the “train/test” module, the
    h5 filetypes in “ai_model” stores the model’s best hyper-parameters and states
    achieved by deep learning, for classifying malicious and benign traffic. 3) Prediction
    for Suspicious Payloads To predict suspicious payloads, “predict” inspects the
    real-time data (payload_data.tmp) stored in “ai_payloads” using the h5 model trained
    by the “train/test” module. “predict” also stores output as JSON files, including
    metadata, suspicious payloads, prediction for the malicious-ness probability.
    The predicted data in “ai_prediction” volume are potential suspicious events identified
    by each model and are stored periodically (saved 8 times a day) until they are
    finally reviewed or labeled by a security analyst. The output files are accumulated
    into labeling tools in Fig. 7. FIGURE 4. Structure of optimized convolutional
    recurrent neural networks. Show All FIGURE 5. Performance comparison of NN models.
    Show All FIGURE 6. Experimental results on public datasets. Show All FIGURE 7.
    Labeling tools for deep learning on AI-IDS. Show All Table 3 shows the contents
    of a sample JSON file generated by “predict” and stored in “ai_predction.” The
    file type is stored in the data frame in the following order: “_time,” “payload_id,”
    “model_name,” “prediction,” “src_ip,” “src_port,” “dest_ip,” “dest_port” and “src_content,”
    and “src_content” means payload that “POST /manager/html.” “payload_id” is the
    prediction event id, whose value can be identified and is generated by “hexdigest
    (sha1(_time@src_ip: src_port-> dest_ip: dest_port)).” TABLE 3 Samples of Prediction
    Output The infrastructure of the deployed center system consists of Splunk Architecture
    and our AI-IDS. Splunk Architecture consists of a Search Head Cluster with multiple
    search headers and an Index Cluster with dozens of Indexes. One of the search
    heads was built as an independent and dedicated system to interface with AI-IDS.
    The AI-IDS was developed in the Docker 18.09.5, Python 3.6.7, Tensorflow 1.13.1,
    Keras 2.2.4 and Splunk SPL 7.2.3. The test-bed system is HP DL380G9: 2.1 GHz 2P/8C(16C)
    CPU, 416 GB RAM, Tesla P100 16 GB ×1 EA GPU, 960G ×2 (RAID-1) SSD, 6 TB ×2 (RAID-1)
    HDD and 10Gbps LAN. The operating server consisted of an HP DL390G10: 2.4 GHz
    2P/20C(40C) CPU, 1 TB RAM, Tesla V100 32 GB RAM ×2 EA GPU, 960G ×4 (RAID-5) SSD,
    10 TB ×4 (RAID-5) HDD and 10 Gbps LAN. As shown in Fig. 1, the sensor systems
    were located in several financial institutions, and IDS alert events and TAS traffic
    were collected and transmitted to the SOC via VPN from financial institutions.
    The experiment was conducted in a test-bed system, which was deployed to the operating
    system only when the performance and function verification were completed. C.
    Optimized CNN-LSTM Model Table 4 and Fig. 4 show the CNN-LSTM structure, which
    illustrates the hyper-parameters. One UTF-8 encoded HTTP data, including the variable-length
    HTTP header and payloads, which is the initial input value of the proposed neuron
    network model, is made into a fixed-length input value of 1,000 bytes (1 dimension
    ×1 ,000 bytes). Strings corresponding to the header and body of the HTTP request
    from the 0-th byte to the n-th byte are aligned, and the rest of the data is zero-padded.
    AI-IDS preprocessing continuously collects data for 3 hours in 1 cycle. AI-IDS
    operates 8 times of learning, and predicts every 3 hours for real-time traffic,
    which allows for real-time monitoring for 24 hours. In the training phase, the
    labels indicating “malicious,” “benign,” and “unknown” are recorded at the end
    of 1,000 bytes of an HTTP request, and the model calculates a malicious probability
    when all neuronal network operations are completed. The initial input-data at
    the CNN layer generates 1×1 , 000×12 composited data through an operation with
    1×4×12 filters. After 1/5 max-pooling, 1×200×12 pieces of data are stored in the
    memory in normalized form. In the second convolutional layer, 1×200×60 data are
    generated through the composite product of a 1×4×5 filter, and then 1×40×60 data
    are generated as a result of 1/5 max-pooling and normalization. Data output from
    the CNN layer is used as an input to the RNN layer, and data processed into cells
    of 1×40×60 are sequentially input to Forward LSTM and Bidirectional LSTM. The
    first LSTM cell is calculated in the forward direction with 16 cells, the second
    LSTM cell is processed in a bidirectional flow, and the last 32nd LSTM Cells are
    transferred to the DNN layer by combining the accumulated forward and backward
    cells. TABLE 4 Summary of Proposed CNN-LSTM Model The output value of the calculated
    RNN is input into each of the 12 fully connected DNN layers. Until the DNN output
    layer, dropout was set to 0.1, and the LeakyReLU function was applied. Sigmoid
    activation function was used at the DNN output layer and the model was trained
    for prediction on malicious payloads using the Adam optimizer along with binary-crossentropy
    (BCE) as the loss function. The probability is calculated in the output layer
    which includes the JSON output-file shown in Table 3 and the output files are
    shared with Index Cluster, as shown in Figs. 1 and 3. The analyst reviews the
    probability calculated by AI-IDS and examines the payload to determine whether
    an attack warning is valid or not. During the training phase, AI-IDS uses labeled
    analysis information from an analyst: (i) attack alert events detected by IDS
    and (ii) valid attack events that the analyst has confirmed. As the AI-IDS aims
    to detect new threats in the predict phase, the security events detected by legacy
    signature-based IDS are considered duplicate data. It calculates malicious probability
    for new and real-time payloads and outputs prediction results. The composition
    and depth of each layer of CNN, RNN, and DNN derives the optimal parameters for
    the model through repeated experiments in the training phase. The structure and
    parameters of the neuron network are slightly different when iterative experiments
    are performed on various datasets to select optimal performance parameters. The
    proposed model is devised with an intuitive design based on the theoretical basis
    of a previous study, and we proved the model validity through repeat experiments.
    In the next section, we present the detailed experimental results to demonstrate
    the validity and performance of our proposed model. SECTION V. Experiments This
    section demonstrates performance measurements, experimental design, and results:
    comparing the performance of the CNN-LSTM, LSTM-CNN, and DNN models and the experimental
    results of the KF-ISAC, CSIC-2010 HTTP, and CICIDS 2017 datasets. We have defined
    the following experimental statements for the deep learning application: Selection
    of experimental data: CSIC-2010, CICIDS 2017 HTTP dataset, real-time HTTP data
    Design of optimal model structure using deep learning: CNN-LSTM model, LSTM-CNN
    model Determination of hyper-parameters: This is required for individual neural
    networks, such as CNN, RNN, DNN: conv_depth, conv_filter, and lstm_units, dense_units
    Model validation: experiments on two public datasets (CSIC-2010, CICIDS2017) and
    fixed real-time data We experimented to select the optimal model by comparing
    CNN-LSTM with LSTM-CNN based on real-time HTTP traffic on a fixed date. In the
    second experiment, we validated the model through experiments using two public
    datasets (CSIC-2010, CICIDS 2017 HTTP dataset) and real-time data on the optimal
    model. Recently, various models have been introduced that optimize performance
    by combining CNN, RNN (LSTM), and DNN. Liu et al. [31] and Wu et al. [10] devised
    CNN and RNN for intrusion detection, but it was different from the model of this
    study because it performed experiments each separated model in CNN and RNN. In
    this paper, a DNN was selected as the last layer to output a single result; we
    chose a model that can best characterize the data among a CNN-LSTM or LSTM-CNN.
    A. Performance Measurement We used a confusion matrix to evaluate the performance
    of the deep learning model. A confusion matrix is a popular indicator of the performance
    of classification models. The matrix in Table 5 shows us the number of correctly
    and incorrectly classified results, compared to the actual outcomes in the test
    data. One of the advantages of a confusion matrix as an evaluation tool is that
    it allows for a more detailed analysis. The matrix is n by n, where n is the number
    of classes. The simplest classifiers, called binary classifiers, have only two
    classes: positive/negative. The performance of a binary classifier is summarized
    in a confusion matrix that cross-tabulates predicted and observed examples into
    four categories [8], [32]. TABLE 5 A Confusion Matrix In our deep learning model,
    Precision and F-Score are more important performance indicators than others. Moreover,
    the purpose of AI-IDS is to obtain a higher accuracy with a lower false-positive
    rate. We describe the four indicators that make up the confusion matrix in Table
    5, as follows: True Positive (TP): the number of cases correctly predicted and
    labeled as positive. False Positive (FP): the number of cases incorrectly predicted
    and labeled as positive. True Negative (TN): the number of cases correctly predicted
    and labeled as negative. False Negative (FN): the number of cases incorrectly
    predicted and labeled as positive. We use the following notation in Table 6 for
    the model evaluation: Accuracy (ACC): the proportion of the number of correctly
    predicted cases to the labeled total of records. Precision: the proportion of
    the number of correctly predicted cases as positive to the number of predicted
    cases as positive, high precision relates to a low false-positive rate. Recall
    (Sensitivity, Detection Rate): the proportion of the number of correctly predicted
    as positive to the number of cases labeled as positive. Specificity: the proportion
    of the number of correctly predicted as negative to the number of cases predicted
    as negative. F-Score: the weighted average of Precision and Recall; this score
    considers both false positives and false negatives. TABLE 6 Rules for Performance
    Measurement B. Experimental Design We describe the details of the experimental
    datasets in the following paragraphs and in Table 7. TABLE 7 Experimental Datasets
    1) Real-Time Http Datasets (KF-ISAC) KF-ISAC HTTP data is real-time HTTP stream
    data during fixed dates from a TAS. The proposed model trains a mix of benign
    HTTP data and labeled malicious payloads that have been analyzed over the past
    year. It evaluates performance by separating training and test data at an 8:2
    ratio. The label in the training data is located at the end of the preprocessed
    data. 2) CSIC-2010 Http Datasets CSIC-2010 HTTP data [33] was provided by Aberystwyth
    University. The contributors collected HTTP packets to detect web attacks. The
    dataset contains 36,000 normal requests and more than 25,000 anomalous requests.
    The data consists of normal HTTP data for training and normal/abnormal data for
    testing. We generated 1,941,300 records by augmenting 20 times from the original
    77,652 records and split the set in a ratio of train 8: test 2, except for 6 error
    records during data import. 3) CICIDS2017 Http Datasets The CICIDS2017 datasets
    [34] generated in 2017 by the Canadian Institute of Cybersecurity overcome these
    issues. The CICIDS2017 benchmark dataset contains the abstract behavior of 25
    users based on HTTP, HTTPS, FTP, SSH, and email protocols. We use only HTTP datasets,
    including web attacks and generated 586,180 records by augmenting 20 times from
    the original 29,309 records. The dataset consists of the entire abnormal/normal
    pcap file, the unlabeled HTTP attack, and the metadata, including label data.
    C. Experimental Results 1) Model Selection We implemented CNN-LSTM and LSTM-CNN
    structures for an optimal deep learning model selection and then performed 10
    iterations using real-time HTTP data shown in Table 7. The training data of KF-ISAC
    consisted of approximately 6.6 million records extracted and proposed on a specific
    date, and each of the normal/attack classes was composed of approximately 3.3
    million records. The test datasets were set to a ratio of 8:2. The results of
    the experiment shown in Fig. 5 are the average values of the results of 50 epochs.
    The overall model performance of CNN-LSTM is better than LSTM-CNN, in areas such
    as accuracy, precision, and F-Score. In particular, there are many differences
    in Precision, and F-Score because of the True/False Positive Rate. The model performance
    starting from the highest to the lowest is CNN-LSTM, LSTM-CNN, and DNN. CNN-LSTM
    reduces the dimension by max-pooling at the initial step, but LSTM-CNN takes more
    time to train because the dimension and parameters are increased through LSTM
    Cell. The DNN is relatively fast but it has low rates for the scores of Accuracy
    and Specificity. 2) Determination of Hyper-Parameters We chose the best-performing
    deep learning model according to the experimental results. The CNN-LSTM model
    needs to determine the optimal hyper-parameters for stable operations. We considered
    a high precision such that the time needed to train or to validate events by true/false-positive
    rates in a practical environment is minimized. The experiment used real-time HTTP
    (KF-ISAC) data shown in Table 7. The CNN layer determines the conv_depth, conv_filter,
    conv_kernel_width, and conv_pool variables. In detail, one variable has to be
    selected from conv_depth ∈  [2] , conv_filter ∈ [2,4,8,12] , conv_kernel_width
    ∈  [4] and conv_pool ∈ [3,4,5] . The RNN layer determines the lstm_units and lstm_depth
    variables. In detail, one of the following values has to be selected from lstm_unit
    ∈  [16] and lstm_depth ∈ [1,2,4,8] . The DNN layer determines dense_depth, dense_units,
    dense_dropout, and dense_relu_alpha. In detail, one value of dense_depth ∈ [1,2,4,8]
    , dense_units ∈ [4,8,12,16] and dense_dropout ∈ [0.1,0.5] is selected. The experiment
    was conducted 270 times, with one or more of the five indicators converging to
    zero or one, and then moving on to the next parameters. Aiming for the high F-score
    and the high precision, which means minimum with false-positive values, the hyper-parameters
    of an optimal model are shown as follows: 2 for convolution depth, 12 for convolution
    filter, 4 for convolution kernel size, 5 for max-pooling size, 16 for LSTM Cell,
    2 for LSTM depth (1 forward LSTM, 1 Bidirectional LSTM), 12 dense units, 8 for
    dense depth, and 0.1 for dense dropout. 3) Model Validation To validate the performance
    of deep learning models, we used real-time data and public HTTP datasets (CSIC-2010,
    CICIDS 2017 HTTP datasets), and experimented with 50 epochs on the previously
    selected model. The experimental results of real-time data showed that the proposed
    CNN-LSTM model can be used for general HTTP data with a high performance. The
    AI-IDS is a deep learning-based model with no pre-feature extraction and therefore
    all strings can be processed. For all experiments for each dataset, the model
    parameters were modified to obtain the results above and to optimize the performance
    on different datasets. Considering that our model has 14,000 trainable parameters,
    the CSIC-2010 and CICIDS- 2017 are relatively small, which leads to overfitting
    and low performance. Experimental results shown in Fig. 6 showed a high accuracy
    of 91–93% for each dataset in CSIC-2010 and CICISC-2017. The precision was in
    the range of 86–98%, and the F-Score was in the range of 80–82%, which is lower
    than the experimental results of the previous real-time data. Experimental results
    showed that the performance of the model is affected by the number of samples
    and the diversity of the training data. It was difficult to cross-validate our
    model with two published datasets owing to small samples. If we had a large amount
    of non-repeated HTTP data, the experimental performance would improve and would
    return more reliable results. Considering the above results, our model is more
    suitable for a large amount of data, and we demonstrated the excellence of our
    model by training with various datasets of more than 6 million HTTP traffic data.
    SECTION VI. Efficacy and Application This section describes cases of how AI-IDS
    detects variant attacks that bypass detection on legacy signature-based NIDS,
    and how Snort rules can be rewritten or improved. The AI-IDS in Fig. 7 performs
    “predict” based on the completed h5-model shown in Fig. 3, and it predicts real-time
    data by inspecting the attack as a prediction output. When the prediction value
    is 100%, the NIDS knows the payload is malicious, but the results of analysts
    are not perfectly reliable because an initial AI-IDS result may contain an analysis
    error. Thus, an analyst needs to confirm the final step until a stable level has
    been reached. We classified the suspicious payloads as a prediction value within
    a range of 50–100%, and an average of 100-500 events occurred every 3h. We assumed
    that AI-IDS is classified as normal or malignant, and less than 50% of the predicted
    values are labeled as “benign,” and 50–100% are classified as “malicious” payloads.
    In Fig. 7, the analyst labels suspicious payloads on the program as “benign,”
    “malicious,” or “unknown” using a conditional search. The labeled data is used
    for daily retraining. The label program shows the prediction value (%) generated
    by the optimal CNN-LSTM model, and the analyst can use it as a reference for identifying
    the actual malicious payloads. Some of the analysis information, such as src_ip/port
    and dest_ip/port can be used to register a blocking policy in the firewall. The
    effects of applying AI-IDS are summarized as follows: First, it can detect variant
    bypass attacks that are not detected on legacy Signature-based NIDS. For all AI-IDS
    predictions, security events on the legacy NIDS are automatically excluded, such
    that no duplicate events can occur. Second, it is possible to write or modify
    Snort rules for new patterns. If legacy NIDS have existing rules but cannot detect
    attacks, then this had to be caused by Snort grammatical errors or missing patterns
    in the rules. However, it can also be a detection failure due to low performance
    or functional failure. A. Detection of Obfuscated Variants Table 8 shows an example
    of a variant attack detection. A common intrusion pattern is a scan of an admin
    page or file upload page, usually accessed by an attacker via a known open source
    path. Suppose that there is an admin page such as “http://target.com/admin/index.php“
    and a rule that detects “/admin/index.php” in legacy NIDS. The AI-IDS examines
    payloads coming from the trained CNN-LSTM model in real-time to detect abnormal
    URI accesses that detect variant attacks on “index.php” parameters and subpaths.
    It also detects similar and different new variant attacks for all attack types
    and patterns, as well as the examples shown in Table 8. In the case of SQL Injection,
    the detection accuracy of variant patterns is close to 100%. TABLE 8 Detecting
    Variant Patterns on AI-IDS The AI-IDS can also detect unknown variant patterns
    or obfuscated attacks, as shown in Fig. 8. An attacker can use URL Encoding or
    base64 to bypass arbitrary payloads in the security system to attack web servers
    effectively. An attacker uses the Char() function to insert code into noticeView.jsp
    to attempt to acquire system information. In other cases, the attacker attempts
    to send spare-phishing mails, attempting to communicate with an external SMTP
    server by injecting irregular or encoded code to AspCms_SiteSetting.asp (AspCMS).
    Recent malicious HTTP payloads contain irregular patterns that are difficult to
    detect as simple strings. A commercial NIDS detects most known attacks or patterns
    but does not detect strings that do not have a registered pattern. By contrast,
    the AI-IDS can detect variant and obfuscated attacks that cannot be detected with
    legacy NIDS. FIGURE 8. Detecting encoded and obfuscated payloads. Show All B.
    Improvement of Signature-Based Snort Rules The second effect is to improve the
    signature-based Snort Rule. The AI-IDS does not generate detected events in duplicate
    on legacy signature-based NIDS, analysts can identify new patterns for threats
    by analyzing suspicious payloads: (i) A new rule can be written for a new pattern
    (ii) If a rule exists, but cannot be detected, the detection rule can be improved
    by correcting an error in the rule’s options: an offset, depth, distance or within
    and so on. We write or improve on average about five new detection rules per month
    manually. If an event occurs in the AI-IDS when the rules are normally applied,
    we have to suspect a detection failure on signature-based NIDS. Table 7 shows
    that AI-IDS detects a vulnerability attack (CVE-2018-9174) of DedeCMS. When NIDS
    rules for related attacks are not registered in the currently operating NIDS,
    new rules can be registered based on the detection of AI-IDS. Step 1.AI-IDS detection
    for suspicious payloads Show All Step 2.Analysis of related existing rules (Why
    not detectable?) Show All Step 3.Writing a new Snort rule or improving an existing
    Snort rule (general use in case) Show All AI-IDS detects attacks that are not
    detected in the existing NIDS in step 1. As AI-IDS double-checks with existing
    NIDS, basically all events detected by AI-IDS are not detected by NIDS. The analyst
    examines the existing rules in step 2 to review why the existing NIDS did not
    detect payloads. It is usually found that attackers used several methods to randomly
    change the encoding or attacked strings to bypass NIDS. In addition, if the signature
    is individually over-customized, there are few types of attacks that cannot be
    detected, even if there is only a slight change in the attack pattern. Therefore,
    step 3 modified existing signatures to rewrite detection rules that typically
    detect PHP webshell code attacks. However, if a general-purpose detection rule
    is written without regard to the environment, appropriate optimization tasks are
    required as the number of detections increases. SECTION VII. Conclusion We proposed
    an optimal CNN-LSTM model based on SFL and successfully applied payload-level
    deep learning techniques in a high-performance computing environment. The AI-IDS
    distinguishes between normal and abnormal traffic on HTTP traffic that could not
    be detected in legacy signature-based NIDS because AI-IDS can formalize unknown
    patterns, help write or improve signature-based rules for new vulnerabilities,
    variants, and bypass attacks. Network meta-data, without its payload is usually
    difficult to identify whether it is malicious or not. Thus, we review the HTTP
    header and body of web attacks in detail. We also used real-time web traffic for
    deep learning, but initially, we learned that AI-IDS needed to be re-validated
    for predicted suspicious events due to false positives alarms. The AI-IDS performs
    continuous optimization by re-training analysis information that is labeled “benign,”
    “malicious,” and “unknown.” Thus, it should be used as an assistant system until
    it reaches a high-quality level. If the quality goes beyond the ability of humans
    by continually learning, it could be executed as an automated analysis. Ultimately,
    the goal of AI-IDS is to outperform human analysis quality and to help analysts
    handle large quantities of unknown security events. Previous works have mainly
    considered accuracy (ACC) in terms of performance measures, but scalability and
    precision are also important indicators for applying deep learning in the real-world.
    In practical security services, re-validation for predicted events is a required
    task because of the low tolerance for analysis errors. Authors Figures References
    Citations Keywords Metrics Footnotes More Like This Stochastic Gradient Descent
    Intrusions Detection for Wireless Sensor Network Attack Detection System Using
    Machine Learning IEEE Access Published: 2024 Machine Learning-based Intrusion
    Detection System using Wireless Sensor Networks 2024 Fourth International Conference
    on Advances in Electrical, Computing, Communication and Sustainable Technologies
    (ICAECT) Published: 2024 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/8948470/09063416.pdf
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: 'AI-IDS: Application of Deep Learning to Real-Time Web Intrusion Detection'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.2196/jmir.9410
  analysis: '>'
  authors:
  - Akane Sano
  - Sara Taylor
  - Andrew W. McHill
  - Andrew J. K. Phillips
  - Laura K. Barger
  - Elizabeth B. Klerman
  - Rosalind W. Picard
  citation_count: 234
  full_citation: '>'
  full_text: ">\nOriginal Paper\nIdentifying Objective Physiological Markers and Modifiable\n\
    Behaviors for Self-Reported Stress and Mental Health Status\nUsing Wearable Sensors\
    \ and Mobile Phones:Observational Study\nAkane Sano1, PhD; Sara Taylor1, MS; Andrew\
    \ W McHill2,3, PhD; Andrew JK Phillips2,3, PhD; Laura K Barger2,3,\nPhD; Elizabeth\
    \ Klerman2,3, PhD, MD; Rosalind Picard1, ScD\n1Affective Computing Group, Media\
    \ Lab, Massachusetts Institute of Technology, Cambridge, MA, United States\n2Brigham\
    \ and Women’s Hospital, Boston, MA, United States\n3Harvard Medical School, Boston,\
    \ MA, United States\nCorresponding Author:\nAkane Sano, PhD\nAffective Computing\
    \ Group\nMedia Lab\nMassachusetts Institute of Technology\n75 Amherst Street\n\
    Cambridge, MA, 02139\nUnited States\nPhone: 1 6178999468\nEmail: akanes@media.mit.edu\n\
    Abstract\nBackground: Wearable and mobile devices that capture multimodal data\
    \ have the potential to identify risk factors for high\nstress and poor mental\
    \ health and to provide information to improve health and well-being.\nObjective:\
    \ We developed new tools that provide objective physiological and behavioral measures\
    \ using wearable sensors and\nmobile phones, together with methods that improve\
    \ their data integrity. The aim of this study was to examine, using machine\n\
    learning, how accurately these measures could identify conditions of self-reported\
    \ high stress and poor mental health and which\nof the underlying modalities and\
    \ measures were most accurate in identifying those conditions.\nMethods: We designed\
    \ and conducted the 1-month SNAPSHOT study that investigated how daily behaviors\
    \ and social networks\ninfluence self-reported stress, mood, and other health\
    \ or well-being-related factors. We collected over 145,000 hours of data from\n\
    201 college students (age: 18-25 years, male:female=1.8:1) at one university,\
    \ all recruited within self-identified social groups.\nEach student filled out\
    \ standardized pre- and postquestionnaires on stress and mental health; during\
    \ the month, each student\ncompleted twice-daily electronic diaries (e-diaries),\
    \ wore two wrist-based sensors that recorded continuous physical activity and\n\
    autonomic physiology, and installed an app on their mobile phone that recorded\
    \ phone usage and geolocation patterns. We\ndeveloped tools to make data collection\
    \ more efficient, including data-check systems for sensor and mobile phone data\
    \ and an\ne-diary administrative module for study investigators to locate possible\
    \ errors in the e-diaries and communicate with participants\nto correct their\
    \ entries promptly, which reduced the time taken to clean e-diary data by 69%.\
    \ We constructed features and applied\nmachine learning to the multimodal data\
    \ to identify factors associated with self-reported poststudy stress and mental\
    \ health,\nincluding behaviors that can be possibly modified by the individual\
    \ to improve these measures.\nResults: We identified the physiological sensor,\
    \ phone, mobility, and modifiable behavior features that were best predictors\n\
    for stress and mental health classification. In general, wearable sensor features\
    \ showed better classification performance than\nmobile phone or modifiable behavior\
    \ features. Wearable sensor features, including skin conductance and temperature,\
    \ reached\n78.3% (148/189) accuracy for classifying students into high or low\
    \ stress groups and 87% (41/47) accuracy for classifying high\nor low mental health\
    \ groups. Modifiable behavior features, including number of naps, studying duration,\
    \ calls, mobility patterns,\nand phone-screen-on time, reached 73.5% (139/189)\
    \ accuracy for stress classification and 79% (37/47) accuracy for mental health\n\
    classification.\nConclusions: New semiautomated tools improved the efficiency\
    \ of long-term ambulatory data collection from wearable and\nmobile devices. Applying\
    \ machine learning to the resulting data revealed a set of both objective features\
    \ and modifiable behavioral\nJ Med Internet Res 2018 | vol. 20 | iss. 6 | e210\
    \ | p. 1\nhttp://www.jmir.org/2018/6/e210/\n(page number not for citation purposes)\n\
    Sano et al\nJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nfeatures that\
    \ could classify self-reported high or low stress and mental health groups in\
    \ a college student population better than\nprevious studies and showed new insights\
    \ into digital phenotyping.\n(J Med Internet Res 2018;20(6):e210) doi: 10.2196/jmir.9410\n\
    KEYWORDS\nmobile health; mood; machine learning; wearable electronic devices;\
    \ smartphone; mobile phone; mental health; psychological\nstress\nIntroduction\n\
    Background\nRecent advances in wearable and mobile technologies have\nenabled\
    \ individuals to monitor their daily lives and enabled\nscientific investigators\
    \ to passively collect real-time data without\ndisrupting people’s habitual routines.\
    \ Two examples of such\ndevices are wrist-wearable devices that collect activity\
    \ and other\nphysiological data (eg, activity or sleep; heart rate; skin\nconductance,\
    \ SC; blood pressure; and blood sugar level) and\nmobile phones (eg, smartphones)\
    \ that monitor location, activity,\nsocial interaction over calls and texts (short\
    \ message service,\nSMS), app use, screen on or off, and environmental data such\n\
    as ambient light exposure and humidity.\nLeveraging data from wearable and mobile\
    \ devices to gain\nmeaningful information about human health has been called\n\
    digital phenotyping [1-3]. Digital phenotyping is defined as the\nmoment-by-moment\
    \ quantification of the individual-level human\nphenotype in situ using data from\
    \ personal digital devices. Data\nfrom personal digital devices may be used to\
    \ understand health\nand behaviors with a goal of preventing or minimizing disorders\n\
    and diseases. For example, current health status, behavior\nhistory, and potential\
    \ future health trajectories information might\nhelp (1) individuals become more\
    \ aware of their risk profiles\nand enable them to make better informed decisions\
    \ and take\nactions to change their behaviors to reduce potential negative\nphysical\
    \ and mental outcomes and (2) clinicians monitor\nchanges in their client’s or\
    \ patient’s status.\nMobile phones have been used to monitor stress and mental\n\
    health [4-10]. The pioneering Student Life study that monitored\n48 college students\
    \ across a 10-week term using objective\nAndroid mobile phone sensors and usage\
    \ investigated the\nrelationship between well-being measures such as self-reported\n\
    stress, depression, flourishing and loneliness, and academic\nperformance [4].\
    \ Lower Perceived Stress Scale (PSS) score was\ncorrelated with higher conversation\
    \ frequency during the day\n(9 AM-6 PM: the time frame participants might be in\
    \ classes)\nand the evening (6 PM-0 AM), longer conversation duration\nduring\
    \ the day, and longer sleep duration. One study that\nevaluated self-reported\
    \ depression using mobile phones for 2\nweeks (N=28) [8] showed that mobility\
    \ patterns (ie, regularity\nin 24-hour mobility patterns, as well as location\
    \ variance) from\nGlobal Positioning System and phone usage features including\n\
    usage duration and frequency were correlated with depressive\nsymptom severity\
    \ on a self-reported depression survey, the\nPatient Health Questionnaire-9 (PHQ-9)\
    \ [8]. Another mobile\nphone–based study that lasted 12 weeks (N=73) identified\n\
    mobile phone features that predicted clinically diagnosed\ndepressed mood with\
    \ 0.74 area under the curve; these features\nincluding the total count of outgoing\
    \ calls, the count of unique\nnumbers texted, absolute distance traveled, dynamic\
    \ variation\nof the voice, speaking rate, and voice quality [10].\nThe combination\
    \ of wearable sensor and mobile phone data has\nalso been used to study self-reported\
    \ stress in daily life [11-14].\nMuaremi et al, using both wearable sensors and\
    \ mobile phones,\ndeveloped a way to automate the recognition of self-reported\n\
    daily stress levels using sleep parameters and 37 physiological\nresponses (including\
    \ heart rate, heart rate variability (HRV) and\nSC) from wearable sensors (N=10,\
    \ 19 days), or mobile phone\nusage and sleep HRV from wearable sensors (N=35,\
    \ 4 months).\nThey showed 61% 3-class stress level classification accuracy\nwith\
    \ a combination of phone usage and sleep HRV features and\n73% accuracy using\
    \ sleep duration, upper body posture, and\nsleep HRV features [11,12]. Sano et\
    \ al also investigated 5-day\nself-reported high or low stress recognition (N=18)\
    \ and 1-month\nhigh or low stress recognition (N=66) using wearable sensor\nand\
    \ mobile phone data; they showed 75% and 90% accuracy\nusing leave-one participant-out\
    \ or 10-fold cross-validation,\nrespectively [13,14].\nObjectives\nThese previous\
    \ studies focused on only mobile phone usage or\non phone usage plus wearable\
    \ sensor data only during sleep and\nhave not taken advantage of 24/7 multimodal\
    \ phone + wearable\ndata during wake and sleep to understand behaviors and\nphysiology\
    \ for long-term study of self-reported stress and mental\nhealth. We chose to\
    \ approach this goal beginning with college\nstudents, most of whom report high\
    \ stress, and some of whom\nare at risk of low or declining mental health [15,16].\
    \ According\nto the 2017 National College Health Assessment that examined\ndata\
    \ from 47,821 college students at 92 schools in the United\nStates, more than\
    \ half of the respondents said that their stress\nlevels were higher than average,\
    \ more than one-third had\ndifficulty functioning because of depression, and two-thirds\n\
    said they felt overwhelming anxiety in the last year [15].\nStudents’ high stress\
    \ and low mental health could negatively\nimpact their academic performance [17].\
    \ Moreover, one-tenth\nof the students had a plan for suicide. Suicide rate is\
    \ increasing,\nand suicide is the second leading cause of death for college\n\
    students [18]. More students are seeking help, and 34% of\ncounseling centers\
    \ have a treatment waitlist [19]. Under these\nconditions, development of improved\
    \ tools for screening,\nmonitoring, and intervening for self-reported stress and\
    \ poor\nmental health through wearable sensors and mobile phones in\ndaily life\
    \ settings will be beneficial. We aim to ultimately detect\nstress and mental\
    \ health changes before clinical interventions\nare required and provide personalized\
    \ early warnings together\nwith data-driven suggestions of individualized behaviors\
    \ that\nmight promote better mental health outcomes.\nJ Med Internet Res 2018\
    \ | vol. 20 | iss. 6 | e210 | p. 2\nhttp://www.jmir.org/2018/6/e210/\n(page number\
    \ not for citation purposes)\nSano et al\nJOURNAL OF MEDICAL INTERNET RESEARCH\n\
    XSL•FO\nRenderX\nOur SNAPSHOT study was designed to collect and examine\nrich\
    \ multimodal information in participants’everyday life using\nwearable sensors\
    \ and mobile phones for phenotyping sleep,\nstress, and mental health, all of\
    \ which are major health issues\nin modern society. This paper has three main\
    \ elements. First,\nwe introduce a methodology and tools to capture long-term,\n\
    large-scale ambulatory data on physiological and behavioral\ncharacteristics using\
    \ sensors installed in wearable devices and\nmobile phones. The dataset from the\
    \ SNAPSHOT study is one\nof the first large multimodal datasets that contains\
    \ continuous\nphysiology from a healthy college student population. The\ndataset\
    \ currently includes approximately 145,000 hours of data\nfrom 201 participants\
    \ at one university. Second, as real-world\nambulatory data are messy, we describe\
    \ tools we developed and\ndeployed to improve the integrity and quality of the\
    \ collected\ndata and to reduce the time experimenters spend checking for\nand\
    \ fixing errors. Third, we identify objective physiological\nmarkers and modifiable\
    \ behaviors that successfully classify\nself-reported high or low stress and mental\
    \ health and examine\nthe separate contributions of wearable sensors and mobile\
    \ phone\ndata.\nMethods\nThe 1-month SNAPSHOT study is a long-term and large-scale\n\
    study developed to measure Sleep, Networks, Affect,\nPerformance, Stress, and\
    \ Health using Objective Techniques.\nOur aim was to investigate how daily behaviors\
    \ and social\nnetworks influence sleep, self-reported stress, mood,\nperformance,\
    \ and other well-being-related factors. For each of\nfive Fall and Spring semesters\
    \ starting in Fall 2013, we collected\napproximately 1 month of data per person\
    \ from college students\nwho were socially connected and at a single New England\n\
    university. Students were only allowed to participate in the\nstudy once. There\
    \ was a total of 201 participants; Fall 2013: 20,\nSpring 2014: 48, Fall 2014:\
    \ 46, Spring 2015: 47, Fall 2015:40;\nages 18 to 25 years; 129 male, 72 female;\
    \ 70 freshman, 49\nsophomore, 44 junior, 36 senior, and 2 unreported. The\napproximately\
    \ 1 month of data collection was between the start\nof semester and midterms.\n\
    Recruitment\nWe intentionally recruited college students from a single\nacademic\
    \ institution who were socially connected because of\nour interest in how social\
    \ networks affect sleep and health\nbehaviors. Our definition of socially connected\
    \ was making a\ncall or SMS at least once a week with each other. Each semester,\n\
    we recruited groups of at least 5 people who knew each other\nand interacted socially.\
    \ We posted our study advertisement to\nundergraduate students’ mailing lists.\
    \ Potential participants\nfilled out screening questionnaires to determine eligibility.\
    \ Our\nexclusion criteria were as follows: (1) non-Android phone users,\n(2) inability\
    \ to wear wrist sensors (eg, irritated skin on wrist),\n(3) pregnant women, (4)\
    \ travel across more than one time zone\n1 week before the study or have plans\
    \ to travel more than one\ntime zone away during the study, and (5) age <18 years\
    \ or >60\nyears. In our study, we targeted only Android phone users\nbecause other\
    \ mobile phones (eg, iPhone) did not allow us to\nmonitor phone usage as needed\
    \ for this study.\nEligible participants attended information and consent sessions.\n\
    For each session, we invited approximately 15 participants and\nexplained in detail\
    \ the study and tasks that participants would\nperform during the study. After\
    \ participants gave written\ninformed consent, they completed prestudy questionnaires,\n\
    started wearing devices, and installed an Android app (described\nbelow) on their\
    \ phone. The study obtained a National Institutes\nof Health Certificate of Confidentiality\
    \ so that potentially\nsensitive information such as drug or alcohol use provided\
    \ by\nthe participants could not be revealed for legal purposes; this\nwas important\
    \ protection for the students as the daily diary\nincluded requests for such information.\n\
    The participants received financial compensation at the end of\nthe study; the\
    \ amount depended on the number of days they\ncompleted diaries, wore the sensors,\
    \ and completed other\nprotocol tasks.\nStudy protocols were approved by the Massachusetts\
    \ Institute\nof Technology and Partners HealthCare Institutional Review\nBoards.\
    \ The study was registered on clinicaltrials.gov\n(NCT02846077).\nData Collection\n\
    All data were deidentified before analysis, although location\ninformation could\
    \ potentially be used to reidentify people. Phone\nnumbers, email addresses, and\
    \ actual names from the social\nnetwork surveys were hashed.\nStart of the Study\
    \ Questionnaires\nAt the start of the study, participants completed the\nMorningness-Eveningness\
    \ Questionnaire [20], the Pittsburgh\nSleep Quality Index [21], the Myers Brigg\
    \ Personality test, the\nBig Five Inventory Personality Test [22], the PSS [23],\
    \ the\n12-Item Short Form Health Survey (SF-12) for physical and\nmental component\
    \ summary (MCS) scores [24], and a set of\nsocial network surveys assessing with\
    \ whom participants spent\ntheir time to help map their social networks. We also\
    \ collected\nage, sex, academic major, and living situation (eg, dorm name\nand\
    \ whether single or multiple occupancy room) information.\nAmbulatory Monitoring\n\
    Wearable Sensors\nParticipants wore two sensors on their wrists: a Q-sensor\n\
    (Affectiva, Boston, MA, United States) to measure SC, skin\ntemperature (ST),\
    \ three-axis acceleration (ACC) on their\ndominant wrist and a Motion Logger (AMI,\
    \ Ardsley, NY, United\nStates) on their nondominant wrist to measure acceleration\
    \ and\nambient light data. ACC can be used to estimate activity levels\nand sleep\
    \ or wake patterns. SC reflects autonomic arousal during\nthe day, providing a\
    \ stress index during wakefulness; SC\nincreases during sleep are highly likely\
    \ to occur in either\nnon-rapid eye movement (non-REM) stage 2 sleep or slow-wave\n\
    sleep (SWS) [25]. The sensor data were logged into the flash\nmemory of the sensors.\
    \ Participants were instructed to remove\nsensors only in instances when the sensor\
    \ could become wet or\nrisked being broken.\nJ Med Internet Res 2018 | vol. 20\
    \ | iss. 6 | e210 | p. 3\nhttp://www.jmir.org/2018/6/e210/\n(page number not for\
    \ citation purposes)\nSano et al\nJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\n\
    RenderX\nMobile Phone App\nWe wrote a custom Android phone app based on funf [26]\
    \ that\nmonitored location, receivers, senders, and timings of calls and\nSMS\
    \ text messages, screen on or off timings, and phone app\nusage. No content of\
    \ emails, calls, or SMS text messages was\nrecorded. Phone usage was measured\
    \ for two main reasons.\nFirst, phone usage and location data give clues to social\n\
    interactions. The timing of calls, SMS, and screen on provide\nan estimate of\
    \ how often participants interact with their phone\nduring the day and the night,\
    \ whereas the number of calls, SMS,\nand the number of people they interact with\
    \ helps quantify their\nsocial interaction. Second, lighting from the interaction\
    \ with\nmobile phones or emailing late at night could disturb the\nbiological\
    \ circadian clock and increase alertness, both of which\ncan influence sleep patterns\
    \ [27,28]. We asked our participants\nnot to use third-party messaging apps, if\
    \ possible, during the\nstudy for the last two cohorts.\nTwice-Daily Electronic\
    \ Diaries\nParticipants completed electronic diaries (e-diaries): upon\nawakening\
    \ and at bedtime each day. These diaries contained\nquestions about sleep and\
    \ wake times; naps; exercise; academic\nand extracurricular activity times; social\
    \ interactions; caffeine,\nalcohol, and drug intake; overall health condition;\
    \ sleep; mood;\nand self-reported stress (Figure 1). Participants received emails\n\
    that included a URL to the morning and evening diaries. They\ncould complete the\
    \ diaries using computers, tablets, or mobile\nphones.\nFigure 1. An example evening\
    \ e-diary. For some questions, if yes is chosen, additional questions are presented.\n\
    J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 4\nhttp://www.jmir.org/2018/6/e210/\n\
    (page number not for citation purposes)\nSano et al\nJOURNAL OF MEDICAL INTERNET\
    \ RESEARCH\nXSL•FO\nRenderX\nPoststudy Questionnaires and Other Measurements\n\
    At the end of the month of intensive data collection:\n1.\nAcademic performance\
    \ as measured by grade point average\nwas self-reported by each participant for\
    \ the semester\nprevious to the study and the current study semester.\n2.\nEmail\
    \ usage during the experiment (ie, to, from, cc, and\ntime stamps) was collected\
    \ through the Massachusetts\nInstitute of Technology (MIT) website Immersion [29].\n\
    3.\nOn the basis of their phone call, SMS, and email usage\nobjectively measured\
    \ during the experiment, participants\nwere asked to self-report whether they\
    \ had positive or\nneutral or negative interactions with each frequent contact\n\
    as a whole over the month. Participants also indicated to\nwhich category each\
    \ frequent contact belonged to (ie,\nfamily, social, work, others).\n4.\nThe PSS,\
    \ the SF-12, the set of social network surveys, and\nthe State-Trait Anxiety Index\
    \ [30] were completed.\nData Preprocessing\nAmbulatory data measured with wearable\
    \ sensors, mobile\nphones, and surveys tend to be noisy. Examples include (1)\
    \ AM\nvs PM errors when participants complete survey items about\ntheir sleep\
    \ and activity times; (2) participants forgetting to\ncharge or wear sensors;\
    \ (3) sensors breaking or the signals\nbecoming noisy; and (4) mobile phone connectivity,\
    \ hardware\nsensor functionality, and mobile software updates, which can\nbreak\
    \ and interfere with data integrity. To address these issues,\nvarious techniques\
    \ have been applied, such as data cleaning\nbefore data analysis [31]: data quality\
    \ evaluation [32], detecting\nfaulty data, noise reduction [33], and interpolating\
    \ faulty or\nmissing values [34,35]. To reduce the occurrence or impact of\nthese\
    \ issues, additional approaches can be used during\nambulatory data collection.\
    \ For example, during the study, an\ne-diary system can notify participants about\
    \ potential inaccurate\nanswers before they submit their answers, and a study\n\
    investigator can check data quality of incoming data and provide\nfeedback to\
    \ the participants. For this study, we developed tools\nfor improving the quality\
    \ of the collected data and for supporting\nmore efficient human checking and\
    \ correcting of the phone,\nsensor, and e-diary data.\nPreprocessing Twice-Daily\
    \ Electronic Diaries\nWe collected a total of 6077 days of e-diary data. In the\
    \ first\nyear of the SNAPSHOT study, we set up an e-diary system that\nautomatically\
    \ sent surveys to our participants every morning\nand evening and then sent reminders\
    \ if the participants did not\ncomplete the surveys within 12 hours. We implemented\
    \ logic\ncheck functions on the system that prompted users to revise\ntheir answers\
    \ if certain types of errors or missing answers were\ndetected (eg, if two activity\
    \ events overlapped, or if their\nreported wake time was earlier than their reported\
    \ bedtime).\nDuring this first year, study investigators manually checked\nparticipants’\
    \ answers every 1 to 2 days and emailed them to\nrevise their answers when errors\
    \ were found.\nIn year 2 of the study, we installed raster plots that visualize\n\
    participants’ activities over time (Figure 2). These raster plots\nwere displayed\
    \ to participants after they submitted their answers,\nallowing users to visually\
    \ confirm their responses and return to\ntheir survey to correct any errors. These\
    \ raster plots reduced\nabout half of the daily diary errors. The raster plots\
    \ also reduced\nthe total average time taken to preprocess 1 month of a\nparticipant’s\
    \ e-diary data by 53%: from 145 min (year 1) to 68\nmin (year 2).\nFinally, in\
    \ year 3, we created and installed an administrative\nmodule that includes three\
    \ components to further improve data\nvalidity: a calendar view, interactive checking\
    \ system, and a\nsummary view. Every day, a study investigator logged into the\n\
    diary system and saw the calendar view (Multimedia Appendix\n1) that showed the\
    \ number of participants in the study, the\nnumber of participants whose morning\
    \ and evening diaries were\nchecked, the number of unchecked diaries, the number\
    \ of diaries\nthat needed to be rechecked, and participants’ comments. The\ninteractive\
    \ checking system automatically flagged missing\nanswers in the e-diary and allowed\
    \ the study investigator to\ncheck daily diaries just by flagging sections of\
    \ the e-diary as\nerror (Figure 3). Emails were automatically sent to participants\n\
    if there were errors or missing answers. The summary view\n(Multimedia Appendix\
    \ 2) showed the daily diary status for each\nparticipant in different colors (eg,\
    \ green-acceptable, red-missing,\nand pink-error). These plots enabled the study\
    \ investigator to\nunderstand which participants had filled out the daily surveys\n\
    and which participants they needed to contact (eg, if there were\nrepeated errors\
    \ or missing entries in the diaries). This module\nfurther reduced the total average\
    \ time taken to preprocess 1\nmonth of a participant’s e-diary data from 68 min\
    \ (year 2) to\n45 min (year 3). The combined changes in raster plots and the\n\
    administrative modules reduced the total average time taken to\nclean 1 month\
    \ of one participant’s e-diary data by 69%: from\n145 min (year 1) to 45 min (year\
    \ 3). Overall, participants’daily\ndiary completion rates ranged between 92% and\
    \ 97% with no\nsignificant differences across semesters.\nPreprocessing Sensor\
    \ or Mobile Phone Data\nEvery week, a study investigator had a face-to-face meeting\n\
    with each participant to download sensor data and to check if\nsensors were working\
    \ correctly, if the participants were wearing\nthem properly, and if sensor electrodes\
    \ needed replacement.\nWe developed scripts to download the data from sensors\
    \ and\ncheck sensor readings automatically for quality using a\npreviously developed\
    \ and tested automated classifier [36]. This\nclassifier separated clean epochs\
    \ and noisy epochs of SC data\nfor further analysis.\nWe collected 6309 days of\
    \ Q-sensor data for a total of 125,413\nhours. We computed how much data were\
    \ within a typical range\nper published guidelines: for SC, 83% were within the\
    \ range of\n0.01 to 30 microS [37-39], and for ST, 99.7% were within the\nrange\
    \ of 20 to 42 degrees Celsius [40]. In addition, 92% of the\ncollected SC data\
    \ were classified as clean data using an artifact\ndetection algorithm [36]. Thus,\
    \ among the collected SC data,\n80% of the data were used for further analysis.\n\
    Mobile phone data were sent automatically to a server by the\ncustom funf-based\
    \ app. On the server, another set of scripts that\nwe wrote checked the data quality\
    \ every day and sent\nnotification to a participant if a problem was found in\
    \ their data\n(eg, not receiving phone data for a day). Phone data were\ncollected\
    \ on 85% of the days.\nJ Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p.\
    \ 5\nhttp://www.jmir.org/2018/6/e210/\n(page number not for citation purposes)\n\
    Sano et al\nJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nFigure 2. Plot\
    \ of daily activity timing (raster plot) with time of day (midnight to midnight)\
    \ on the y-axis and each day plotted on a separate line.\nParticipants saw this\
    \ plot after filling out their surveys and before they submitted their answers.\
    \ Different activities were marked with different colors.\nIdentifying Risk Factors,\
    \ Objective Biomarkers, and\nModifiable Behavioral Features Related to Stress\
    \ and\nMental Health\nWe defined high stress and low stress groups based on their\n\
    poststudy PSS scores (Figure 4). PSS scores range from 0 to\n40: higher scores\
    \ indicate higher perceived stress. A PSS score\nof 14.2 is the average for the\
    \ age group of 18 to 29 years, and\na score over 16 is considered as high stress\
    \ and of high health\nconcern [23]. Our participants’ average PSS score was 17.1.\n\
    We used the value of PSS ≥16 to construct the high stress group\n(N=109, top 57.7%\
    \ [109/189]) and PSS <16 for the low stress\ngroup (N=80, bottom 42.3% [80/189]).\
    \ Because we originally\nhad an unbalanced set of data for high stress and for\
    \ low stress,\nwe first reduced the size of the high stress group by the method\n\
    of random sampling of its data to equalize the size of the high\nand low stress\
    \ classes at N=80. Thus, the prior probabilities on\nboth classes were made to\
    \ be 0.5, so that a random classifier\nwould be expected to attain accuracy of\
    \ 50%.\nWe defined high mental health and low mental health groups\nbased on their\
    \ poststudy MCS from the SF-12 (Figure 4). For\nthe MCS, a value ≥50 is considered\
    \ good mental health [41,42],\nand 11.8% (23/195) of our population scored ≥50.\
    \ We therefore\nextracted the top and bottom 12% to form the two groups: high\n\
    mental health group (MCS ≥50, top 11.8% [23/195], N=23) and\nlow mental health\
    \ group (MCS ≤29.4, bottom 12.3% [24/195],\nN=24). Thus, the data in the high\
    \ and low mental health groups\nwere balanced so that the prior probability of\
    \ either group would\nbe 0.5, with a random classifier expected to have an accuracy\n\
    of 50%.\nFeature Extraction\nTo quantify the relative importance of the many measures,\
    \ we\ncompared the classification performance using the following\nseparate categories\
    \ of features: (1) Big Five personality +\ngender, (2) wearable sensors (eg, ST,\
    \ SC, and ACC), (3) mobile\nphone (eg, call, SMS, screen on, and location), and\
    \ (4) objective\nfeatures (combining wearable sensors and mobile phone\nmetrics).\
    \ We also separately defined (5) modifiable behaviors\nas features that can potentially\
    \ be controlled by participants,\nsuch as sleep and activity timing and phone\
    \ usage; these are\nimportant features to measure for future behavioral interventions\n\
    (Table 1). Note that some features such as phone features and\nACC feature are\
    \ found in more than one of the five categories.\nSC was processed first using\
    \ low-pass filtering (cutoff frequency\n0.4 Hz, 32nd order finite impulse response\
    \ filter). Because there\nare individual differences in SC amplitude, we extracted\
    \ features\nfrom both unnormalized and normalized SC data based on the\nmaximum\
    \ and minimum amplitude of each day within each\nindividual. To detect SC peaks,\
    \ we obtained the first derivative\nof the low-pass-filtered non-normalized SC\
    \ data and then\ndetermined where the slope exceeded a value of 0.02 µS per\n\
    second [43]. We detected SC peaks based on those that exceeded\nthis threshold\
    \ and counted the number of peaks in each\n30-second epoch.\nJ Med Internet Res\
    \ 2018 | vol. 20 | iss. 6 | e210 | p. 6\nhttp://www.jmir.org/2018/6/e210/\n(page\
    \ number not for citation purposes)\nSano et al\nJOURNAL OF MEDICAL INTERNET RESEARCH\n\
    XSL•FO\nRenderX\nFigure 3. Interactive diary check system. The left panel shows\
    \ a participant’s answers. The right panel shows if there are any detected errors\
    \ or missing\nentries and enables adding comments. After the study investigator\
    \ clicked the Save button, the system sent an email to a participant about any\
    \ missing\nor erroneous entries if appropriate.\nJ Med Internet Res 2018 | vol.\
    \ 20 | iss. 6 | e210 | p. 7\nhttp://www.jmir.org/2018/6/e210/\n(page number not\
    \ for citation purposes)\nSano et al\nJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\n\
    RenderX\nFigure 4. (1) Distribution of poststudy Perceived Stress Scale (PSS)\
    \ and (2) Distribution of poststudy mental component summary (MCS) scores.\nWe\
    \ used four different times of interest for analyses: day (9\nAM-6 PM), night\
    \ (6 PM-0 AM), late night (0 AM-3 AM), and\nsleep time (estimated for each individual\
    \ from actigraphy and\ndaily sleep diaries) as physiological responses, such as\
    \ SC and\nACC during daytime and sleep time have different meanings\n[44] and\
    \ late night phone and exercise activities could relate to\nself-reported stress\
    \ and mental health [45].\nBedtime and sleep regularity were calculated from the\
    \ daily\nsleep diaries, and sleep duration and sleep efficiency were\nestimated\
    \ from actigraphy with help of the daily sleep diaries.\nSleep regularity was\
    \ computed because a relationship between\nirregular sleep and low mental health\
    \ was found in a previous\nstudy using this index [46]. The Sleep Regularity Index\
    \ (SRI;\nFigure 5) captures the probability of an individual being in the\nsame\
    \ state (asleep vs awake) at any two time points 24 hours\napart with 1 minute\
    \ resolution, averaged across the entire study\n[47], where s(t)=1 during wake\
    \ and s(t)=−1 during sleep for\neach minute. Assume data are collected for [0,\
    \ T] with T=total\nnumber of hours of data and τ=24 hours.\nIn practice, individuals\
    \ will only display sleep patterns that\nrange between an SRI of 0 (random) and\
    \ 100 (periodic: an\nindividual who sleeps and wakes at exactly the same times\
    \ each\nday). Values less than 0 are theoretically possible (eg, alternating\n\
    24 h of sleep and 24 h of wake) but very unlikely to be observed.\nPhone usage\
    \ and location data can provide information on\nsociability. We computed the timing\
    \ and the number of calls,\nSMS, and screen on, which provide an estimate of how\
    \ often\nparticipants interact with their phone during the day and the\nnight.\
    \ Previous studies showed the relationships between long\nphone usage duration\
    \ and high stress [45] and long and frequent\nphone usage and severe depressive\
    \ symptoms [8]. We also\ncomputed the number of people each participant interacted\
    \ with\nover calls and SMS to help quantify their social interaction. For\nmobility\
    \ features, we computed the distance and radius based\non locations to which our\
    \ participants travelled as these features\nwere shown to be important in previous\
    \ studies [8,48].\nAdditionally, because our population spent most of their time\n\
    on campus or at their residence, we computed whether the day’s\nmobility pattern\
    \ varied from the typical routine based on a\nGaussian mixture model trained for\
    \ each participant’s 1-month\nmobility patterns [49].\nClassification\nFor classifying\
    \ high or low stress groups and high or low mental\nhealth groups, we compared\
    \ the methods of least absolute\nshrinkage and selection operator (LASSO), support\
    \ vector\nmachine (SVM) with linear kernel classifier, and SVM with\nradial basis\
    \ function (RBF) kernel classifier; these algorithms\nwere used in previous related\
    \ work [8,10]. LASSO is a logistic\nregression that performs regularization and\
    \ feature selection by\nminimizing the least squares objective function with an\
    \ L1\npenalty [50].\nJ Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 8\n\
    http://www.jmir.org/2018/6/e210/\n(page number not for citation purposes)\nSano\
    \ et al\nJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nTable 1. List\
    \ of features.\nFeatures\nModality\nPersonality types, gender, diary, sensor,\
    \ and phone features\nAll\nOpenness, conscientiousness, extraversion, agreeableness,\
    \ neuroticism, gender\nBig Five personality types, gender (6 features)\nMean,\
    \ median, SD of 0 AM-3 AM, sleep, 9 AM-6 PM, 6 PM-0 AM for SCa, ACCb, and\nSTc\n\
    Sensors (17 features x 4 time frames x 3=204 features)\nSkin conductance: Area\
    \ under the curve for 30 s epochs, max, mean, median, and SD of\namplitude; mean,\
    \ median and SD of peaks for 30 s epochs; mean, median, and SD of nor-\nmalized\
    \ amplitude\nAcceleration: total # of zero crossing for 30 s epochs\nSkin temperature:\
    \ max, min, mean, median, and SD of temperature\nMean, median, SD of 0 AM-24 AM,\
    \ 0 AM-3 AM, 6 PM-0 AM for call, SMS, and screen\n(not mobility)\nPhone (25 features\
    \ (call, SMSd, screen) x 3 time frames\nx 3 + 4 features (mobility) x 3 features=237\
    \ features)\nCall: Mean, median, and SD of duration and time stamp of calls per\
    \ day; total duration\nper day, total number per day, and number of unique people\
    \ per day\nSMS: Mean, median, and SD of duration and time stamp of SMS per day;\
    \ total number\nper day and number of unique people per day\nScreen: Mean, median,\
    \ and SD of screen-on duration and screen-on time stamp per day;\ntotal duration\
    \ per day and total number of on or off per day\nMobility: Total distance per\
    \ day, 5-min distance, radius per day, and log likelihood of each\nday\nPhone\
    \ and sensor features (see above)\nObjective (441 features)\nSleep Regularity\
    \ Index\nModifiable behaviors (296 features)\nMean, median, and SD of bedtime\
    \ and sleep duration\nDiary features (see below)\nACC total # of zero crossing\
    \ for 30 s epochs\nPhone features (see above)\nMean, median, SD of sleep or no\
    \ sleep (pulled an all-nighter; binary valued), pre sleep\nelectronic media interaction\
    \ (emails, calls, SMS, Skype, chat, and online games; binary\nvalued), pre sleep\
    \ personal interaction(binary valued), # of naps, nap duration, # of academic\n\
    activities per day, total academic duration, study duration, # of extracurricular\
    \ activities,\ntotal extracurricular activities, # of exercise, exercise duration,\
    \ # of caffeinated drink intake,\nmemorable positive interaction(binary valued),\
    \ somewhat negative interaction (binary\nvalued), very negative interaction(binary\
    \ valued), last caffeine intake time\nDiary (17 x 3=51 features)\nSleep Regularity\
    \ Index\nSleep (1 + 3 x 8=25 features)\nMean, median, and SD of bedtime, sleep\
    \ duration, sleep efficiency, sleep or no sleep (pulled\nan all-nighter; binary\
    \ valued), pre sleep electronic media interaction (emails, calls, SMS,\nSkype,\
    \ chat, and online games; binary valued), pre sleep personal interaction (binary\
    \ valued),\n# of naps and nap duration\naSC: skin conductance.\nbACC: acceleration.\n\
    cST: skin temperature.\ndSMS: short message service.\nFigure 5. Equation of Sleep\
    \ Regularity Index.\nFor training and testing models, we used nested-cross validation.\n\
    To \nevaluate \nmodel \nperformance, \nwe \napplied\nleave-one-cohort-out: training\
    \ a model with all except one\nsemester cohort’s data and testing the model against\
    \ the left-out\ncohort’s data, repeating this process for the total number of\n\
    cohorts (ie, 5 times). First we (1) split the data into two datasets:\na training\
    \ set made up of four cohorts and a test set made up of\nJ Med Internet Res 2018\
    \ | vol. 20 | iss. 6 | e210 | p. 9\nhttp://www.jmir.org/2018/6/e210/\n(page number\
    \ not for citation purposes)\nSano et al\nJOURNAL OF MEDICAL INTERNET RESEARCH\n\
    XSL•FO\nRenderX\none cohort. We then left the test set out until step (5) or (8)\n\
    below.\nFor training the SVM models, we applied sequential forward\nfeature selection\
    \ to the training data to reduce overfitting and\nfind the best combinations.\
    \ (2) We applied a t test to each feature\nof the training datasets and selected\
    \ 100 features with the lowest\nP values for finding features to separate two\
    \ groups effectively\nthen (3) applied sequential forward feature selection [51]:\n\
    applied an SVM RBF classifier with 10-fold cross validation\nto find the best\
    \ up to five combinations from these 100 features\nand optimized hyperparameters\
    \ (C for SVM linear and C and\ngamma for SVM RBF). Then, (4) we trained the SVM\
    \ linear\nor RBF models with the selected features of the training data,\n(5)\
    \ tested the models against the test data, and (6) repeated this\nprocess (1-6)\
    \ five times.\nFor LASSO, (7) the penalization parameter was determined\nwith\
    \ the training data by 10-fold cross validation and (8) the\ntrained model was\
    \ tested using the test data. This process (1, 7,\nand 8) was repeated five times.\n\
    We computed overall accuracy and F1 scores by concatenating\nthe five-cohort predicted\
    \ output to compare the performance of\nthe models to reduce the bias from splitting\
    \ [52]. We computed\n95% confidence levels using adjusted Wald test [53]. The\
    \ F1\nscore is a measure of performance computed using precision\n(also known\
    \ as positive predictive value) and recall (also known\nas sensitivity) as described\
    \ in Equation 1, where precision is\nthe number of correct positive results divided\
    \ by the number of\nall positive results, and recall is the number of correct\
    \ positive\nresults divided by the number of positive results that should\nhave\
    \ been returned.\n(1) F1 = 2 x precision x recall / (precision + recall)\nWe also\
    \ compared the performance of the models using features\nbased on data from the\
    \ entire 1-month study period with that\nusing features based only on using the\
    \ data from the week before\nthe PSS and MCS surveys were completed.\nWe applied\
    \ t tests or Mann-Whitney U tests (for non-Gaussian\ndistributions) to examine\
    \ if the means of the features were\nstatistically different between the high\
    \ or low PSS groups or\nthe high or low MCS groups. We adjusted for the multiple\n\
    comparisons using false discovery rate (FDR).\nResults\nRelationships Among Prestudy\
    \ and Poststudy\nPerceived Stress Scores and Mental Component\nSummary\nThere\
    \ were no differences in the poststudy PSS or MCS among\nthe five cohorts; one-way\
    \ analysis of variance (P=.20, F=1.50).\nStudents’ poststudy scores (both PSS\
    \ and MCS) were highly\ncorrelated with prestudy scores (r=.59, .60, Pearson correlation).\n\
    Poststudy PSS scores statistically increased (mean prestudy\nPSS: 15.0, poststudy\
    \ PSS: 17.1, paired t test, P<.001) and MCS\nscores decreased compared with the\
    \ prestudy scores (mean\nprestudy MCS: 44.4, poststudy MCS: 40.4, Wilcoxon signed\n\
    rank test, P<.001). Thus, the students reported worsening stress\nand mental health\
    \ over the 1 month of measurement.\nThe poststudy PSS was inversely correlated\
    \ with the poststudy\nMCS (r=−.71, Pearson correlation; Multimedia Appendix 3):\n\
    (1) 83% (19/23) of the students in the high MCS group belonged\nto the low PSS\
    \ group and (2) 88% (21/24) of the students in the\nlow MCS group belonged to\
    \ the high PSS group. The low MCS\ngroup had higher PSS scores than the rest of\
    \ the students in the\nhigh PSS group: low MCS group’s average PSS score was 25.2,\n\
    whereas the rest in the high PSS group’s average PSS score was\n20.7 (P<.001).\n\
    Stress and Mental Health Classification\nOverall, we found SVM models with the\
    \ RBF kernel worked\nbetter than LASSO and linear SVM models using RBF kernels\n\
    for all of the metrics (Figures 6 and 7; see Multimedia Appendix\n4 for accuracy\
    \ and F1 scores and Multimedia Appendices 5 and\n6 for F1 scores for all results).\
    \ SVM with the RBF kernel can\nmodel more complex decision boundaries. Sensor\
    \ features\nshowed higher performance than phone features both for PSS\nand MCS.\n\
    We also compared the performance of the SVM RBF models\nusing features from only\
    \ the last week of the 1-month period\nto using the features from the entire month.\
    \ Overall, the\nperformances with the 1 month of features were better\n(classification\
    \ accuracy improved by 1-16%) than those using\njust the last week of features,\
    \ except in the case of the SVM\nmodels using all features.\nThe accuracy for\
    \ PSS classification was highest when using all\nfeatures (82%), followed by when\
    \ using features from only\nsensors (78%), only behaviors (74%), only the Big\
    \ Five (71%),\nor only objective data (70%). The same rank ordering also held\n\
    when comparing F1 scores. For MCS, sensor features and\nobjective features showed\
    \ the highest accuracy (87%), followed\nby Big Five (85%), behaviors (79%), and\
    \ all (77%). The ranking\nof the F1 scores was similar except for all features\
    \ had a slightly\nhigher F1 than behaviors. The means and SD of the accuracy\n\
    and F1 scores from leave-one-cohort-out cross validation are\npresented in Multimedia\
    \ Appendix 7.\nWe also tested different cutoffs: (1) instead of PSS cutoffs ≥16\n\
    for high and <16 for low stress, we used PSS ≥14 for high stress\ngroup and PSS\
    \ <14 for low stress, as (as noted above) 14.2 is\nthe reported average for people\
    \ aged 18 to 29 years [23] and\n(2) instead of extreme MCS cutoffs (top and bottom\
    \ 12%), we\nused MCS ≥median (42.05) for high mental health group and\nMCS <median\
    \ for low mental health group). This was done to\ntest if the rankings of performances\
    \ were sensitive to the exact\ncutoff values. Sensor and modifiable behavior features\
    \ worked\nbest with both cutoff values (Multimedia Appendices 8 and 9).\nCompared\
    \ with the extreme MCS cutoffs, the median cutoff\nshowed much lower classification\
    \ performance (the accuracy\ndecreased by 21 to 6 %).\nWe summarize the features\
    \ most commonly selected by the\nalgorithms as useful for high or low PSS detection\
    \ (Figure 8)\nand high or low MCS detection (Figure 9) using the full 1 month\n\
    of data. Percentages indicate the percent time these features are\nselected across\
    \ 10-fold cross validation over five cohorts and\nfive feature modalities (all,\
    \ Big Five + gender, sensor, phone,\nobjective and modifiable behavior features).\n\
    J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 10\nhttp://www.jmir.org/2018/6/e210/\n\
    (page number not for citation purposes)\nSano et al\nJOURNAL OF MEDICAL INTERNET\
    \ RESEARCH\nXSL•FO\nRenderX\nFor PSS classification for self-reported stress,\
    \ neuroticism and\nconscientiousness were the most often selected features (90%\n\
    and 70% of the models, respectively). The high PSS group had\nhigher neuroticism\
    \ (q [which is the FDR-adjusted P\nvalue]=.0004). The high stress group had a\
    \ larger extracurricular\nactivity duration SD (q=.04).\nIn the MCS classification\
    \ for self-reported mental health, the\nlow MCS group showed higher neuroticism\
    \ (q<.001) and lower\nconscientiousness (q=.04) than the high MCS group. The low\n\
    MCS group had naps more frequently (40%; q=.04). In the MCS\nclassification models\
    \ using only the last week of data, the low\nMCS group showed a lower probability\
    \ of interacting with\nelectronic media (eg, emails, calls, SMS, Skype, chat,\
    \ and online\ngames) before sleep (30%; q=.004) and lower SD of the number\nof\
    \ SC peaks during the time frame of 0 AM to 3 AM (20%;\nq=.03), as well as higher\
    \ neuroticism (q<.001).\nThe percentages of time each feature was selected for\
    \ each fold\nof leave-one-cohort cross validation are presented in Multimedia\n\
    Appendices 10 and 11.\nWe also tried building models only with sleep features\
    \ (eg,\nfeatures in the sleep category and some sleep related features\nin the\
    \ survey category). We obtained 72% and 65% accuracy\nfor classifying high or\
    \ low PSS and high or low MCS. Mean\nnap duration was the most common feature\
    \ used for the PSS\nmodels (80% of the models), followed by median bed time and\n\
    the frequency of pulling all-nighters (60%). The frequency of\npulling all-nighters\
    \ (100% of the models), mean number of\nnaps, sleep duration, and sleep efficiency\
    \ (60%) were commonly\nselected features by the MCS classification models. Average\n\
    sleep duration was not significantly different statistically in the\nhigh vs low\
    \ PSS groups or in the high vs low MCS groups (high\nPSS: 6 hours 42 min vs low\
    \ PSS: 6 hours 51 min [P=.09], high\nMCS: 6 hours 40 min, low MCS: 6 hours 34\
    \ min [P=.72]).\nInstead, the low MCS group’s more frequent napping was one\n\
    of the most discriminating features.\nFigure 6. High or low Perceived Stress Scale\
    \ (PSS) classification results. Top: comparison of performance using 1 month of\
    \ data with three machine\nlearning algorithms. Bottom: comparison of performance\
    \ using 1 month of data vs only the last week of data with support vector machine\
    \ radial basis\nfunction (SVM RBF). Accuracy scores for Big Five + Gender data\
    \ are not shown in the bottom graph because these data are collected only once.\
    \ Error\nbars indicate the 95% CIs based on adjusted Wald test.\nJ Med Internet\
    \ Res 2018 | vol. 20 | iss. 6 | e210 | p. 11\nhttp://www.jmir.org/2018/6/e210/\n\
    (page number not for citation purposes)\nSano et al\nJOURNAL OF MEDICAL INTERNET\
    \ RESEARCH\nXSL•FO\nRenderX\nFigure 7. As in Figure 6 with high or low mental\
    \ component summary score classification results, accuracy scores for Big Five\
    \ + Gender data are not\nshown in the bottom graph because these data are collected\
    \ only once. Error bars indicate the 95% CIs based on adjusted Wald test.\nFigure\
    \ 8. Percentage of time each feature was selected across 10-cross-validation for\
    \ high or low Perceived Stress Scale (PSS) classification models\nwith 1 month\
    \ of data.\nJ Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 12\nhttp://www.jmir.org/2018/6/e210/\n\
    (page number not for citation purposes)\nSano et al\nJOURNAL OF MEDICAL INTERNET\
    \ RESEARCH\nXSL•FO\nRenderX\nFigure 9. Percentage of times each feature was selected\
    \ across 10-cross-validation for high or low mental component summary (MCS) classification\n\
    models with 1 month of data.\nDiscussion\nPrincipal Findings\nIn this paper, we\
    \ developed novel tools to collect and process\nobjective physiological and behavioral\
    \ measures using online\ndiaries, wearable sensors, and mobile phones. We aimed\
    \ to\ninvestigate how accurately these measures could identify\nconditions of\
    \ self-reported high stress and poor mental health\nand features most accurate\
    \ in identifying these conditions.\nPhysiological sensor, phone, and mobility\
    \ features were the\nbest predictors for distinguishing self-reported high or\
    \ low stress\nand mental health. Wearable sensor features, including SC and\n\
    ST, reached 79% accuracy for classifying high or low stress\ngroups and 87% accuracy\
    \ for classifying high or low mental\nhealth groups. Modifiable behaviors, including\
    \ number of naps,\nstudying duration, phone calls (number, time stamp and duration\n\
    of calls), mobility patterns, and phone-screen-on time, reached\n74% accuracy\
    \ for high or low stress group classification and\n78% accuracy for high or low\
    \ mental health group classification.\nComparison With Prior Work and Interpretations\
    \ of\nOur Results\nOur analysis showed that relatively high accuracy and F1 scores\n\
    can be achieved using the leave-one-semester-cohort-out testing\nof the machine\
    \ learning classifier for high or low stress\nmeasured by PSS and high or low\
    \ mental health measured by\nMCS. Of all the features tested, the sensor features\
    \ resulted in\napproximately 14% higher classification accuracies in both PSS\n\
    and MCS than the phone features. In particular, SC responses\nduring the time\
    \ frame of 9 AM to 6 PM were one of the best\npredictors for PSS. SC has been\
    \ considered as a biomarker for\nstress [44] because SC quantifies eccrine sweat\
    \ activity that is\ncontrolled by only sympathetic nervous activity. These findings\n\
    (1) are among the first to show the potential contribution of SC\nin stress detection\
    \ using a wrist wearable sensor in a 24/7 daily\nlife setting and (2) agree with\
    \ previous findings that use a\nconventional finger SC sensor or a wearable SC\
    \ sensor in\nsettings where a person is seated, eg, driving a car. For example,\n\
    Healey et al measured SC, heart rate, HRV, respiration, and\nelectromyogram in\
    \ Boston drivers and reported that SC was the\nmost associated with stress [54].\
    \ Additionally, Hernandez et al\ndiscriminated stressful and nonstressful calls\
    \ at a call center\nenvironment using SC features with 78% accuracy [55], and\n\
    Setz et al automatically classified SC responses from cognitive\nload and stress\
    \ with accuracy higher than 80% [56].\nAs we examined more closely which sensor\
    \ features were most\ndiscriminative, we found that SC responses during the time\n\
    frame of 0 AM to 3 AM and during sleep were predictors for\nseparating high and\
    \ low self-reported mental health. Some\nstudies have shown that finger-based\
    \ SC are reduced for patients\nwith depression measured in a short-term lab study\
    \ [57-59].\nOne possible explanation of how low SC responses during sleep\ncould\
    \ be related to MCS scores is that there is a decrease in\nSWS in depression [60]\
    \ and other psychiatric disorders [61],\nand the largest SC responses during sleep\
    \ are likely to occur\nduring non-REM stage 2 and SWS [25]. Note that in our data,\n\
    (1) 0 AM to 3 AM could include both awake and asleep\nconditions, and if it included\
    \ sleep, we would expect it to include\nmore SWS being at the start of the night\
    \ for this cohort; (2) our\nlow mental score groups are based on self-report;\
    \ and (3) we\ndo not know if any of our participants had clinically defined\n\
    depression or other psychiatric disorders as that information\nwas not gathered\
    \ as part of this study.\nJ Med Internet Res 2018 | vol. 20 | iss. 6 | e210 |\
    \ p. 13\nhttp://www.jmir.org/2018/6/e210/\n(page number not for citation purposes)\n\
    Sano et al\nJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nWe found that\
    \ ST features were also predictors for PSS and\nMCS. A previous study has shown\
    \ that acute stress does reduce\ndistal finger ST but does not statistically significantly\
    \ reduce\nwrist ST in a laboratory stress test setting [62]. Furthermore,\nanother\
    \ study showed that ST is one of the strongest\ndiscriminants to distinguish sleep\
    \ and wake states [63]. Another\nstudy showed that patients with depression have\
    \ less rhythmicity\nin ST [64], which would also be consistent with less regular\n\
    sleep in depression. To our knowledge, this paper is the first to\nreport that\
    \ ambulatory wrist ST features are related to\nself-reported stress.\nFor phone\
    \ features, our results showed phone usage time stamp\nand duration can be predictors\
    \ for PSS and MCS. These results\nare consistent with several previous studies.\
    \ People with a\nPHQ-9 score higher than 5 showed longer phone usage and\nhigher\
    \ phone usage frequency than those with a PHQ-9 score\nlower than 5 in a 2-week\
    \ study with mobile phones [8]. A\nquestionnaire-based study also showed a relationship\
    \ between\nhigh mobile phone usage, stress, and symptoms of depression\n[45].\n\
    Mobility, specifically travel distance per day and SD of the\ndistance traveled\
    \ as measured by phone geolocation data, is a\npredictor both for self-reported\
    \ stress and mental health. This\nresult agrees with one study [8] reporting that\
    \ normalized\nmobility entropy (distribution of frequency of visiting different\n\
    places) and location variance were negatively correlated with\ndepression symptoms\
    \ and another study reporting that mobility\npatterns were highly related to stress\
    \ level [13]. The relationship\nbetween reduced activity levels and mobility patterns\
    \ and high\nstress and low mental health has been studied [48,65]. These\nbehavioral\
    \ markers could be an objective index for monitoring\nself-reported low mental\
    \ health. It is possible that encouraging\npeople to move more could be an effective\
    \ intervention to reduce\nstress and improve mental health.\nConsistent with previous\
    \ studies [7,13,14], personality types\nwere one of the most influential and statistically\
    \ significant\nfactors for self-reported stress and mental health in this college\n\
    population. In the Big Five Inventory Personality Test\ncategories, neuroticism\
    \ was a predictor of stress [66]. The\ncombination of low extraversion and low\
    \ conscientiousness or\nlow agreeableness contributed to the high stress group;\
    \ these\ndirections of the associations in our analysis were consistent\nwith\
    \ prior work [67]. High neuroticism and low extraversion\nhave previously been\
    \ associated with low MCS [68].\nThere is a known association between sleep deficiency\
    \ and\nmental health status (eg, [61]). Our results, however, did not\nshow that\
    \ sleep duration was a strong discriminant feature for\nself-reported stress and\
    \ mental health.\nLimitations\nThere are multiple limitations of this study:\n\
    1.\nSelection of a feature as discriminating between two\ncategories does not\
    \ mean it is an important feature or\ncausative of that behavior.\n2.\nThese results\
    \ do not tell us the causality (eg, does a student\nsleep later and less regularly\
    \ because of higher stress or\nhave higher stress because of later or more irregular\
    \ sleep?).\n3.\nOur participants were limited to Android phone users\nbecause\
    \ we wanted to log detailed phone usage, which is\nnot allowed by other phone\
    \ systems such as iPhone. As\nabout half of the undergraduate students were Android\
    \ users\non the campus, a selection bias might exist. A previous\nstudy showed\
    \ slight differences in personality types and\neconomic status between iPhone\
    \ users and Android users\n[69].\n4.\nA total of 64% of our study population were\
    \ male\nparticipants. It has been reported that females report higher\nperceived\
    \ stress levels and more depressive symptoms\n[70-73], and there are gender differences\
    \ in psychological\nand biological stress responses [74]. In our dataset, the\n\
    ratios of female participants in the high or low PSS and\nMCS groups were 45%\
    \ and 20% (high and low PSS) and\n22% and 54% (high and low MCS). Modeling stress\
    \ and\nmental health differently in males and females might help\nunderstand the\
    \ mechanism. Gender was included as a\npotential feature in our models and was\
    \ not selected\nfrequently.\n5.\nOur data come from college students at one New\
    \ England\nuniversity over 4 years. The work needs to be applied to\nother populations\
    \ to determine generalizability.\n6.\nOur data come from socially connected student\
    \ groups. We\nmight observe some statistically coherent behaviors in our\ndataset\
    \ because of these connections.\nFuture Work\nThese new tools and methods can\
    \ allow multimodal data in\ndaily life to be captured more continuously, with\
    \ greater\naccuracy and integrity of the data, and for long-term and at great\n\
    scale. We are planning to collect a larger amount of data for an\neven longer\
    \ time to study long-term behaviors and physiological\nresponses and build predictive\
    \ models. To do this, we need to\nbuild a new system for consenting people in\
    \ remote locations,\nfully automate checking their measurement status and data\n\
    accuracy automatically, and let the participants know about\nerrors so they can\
    \ fix them to keep study compliance and data\naccuracy high.\nWe will continue\
    \ our data analysis for understanding behaviors,\nphysiological responses, and\
    \ traits that impact health and\nwell-being. One of our hypotheses is that health-related\n\
    behaviors will be contagious within social networks and that\nsocial network data\
    \ we obtained from call, SMS, and email data\ncould capture the social contagion\
    \ quantitatively instead of\nrequiring self-report to capture it. We are also\
    \ interested in\nstudying how phone usage influences sleep and health and how\n\
    we can predict stress and mental health using previous behaviors\nand physiology.\n\
    These machine learning models are not limited to modalities\nand features we measured\
    \ and computed in this study but can\nalso be used for other modalities such as\
    \ heart rate and heart\nrate variability that are controlled by autonomous activities,\
    \ and\nother features such as app usage, ambient light, and audio or\nsentiment-based\
    \ patterns extracted from text or speech could\nbe added to improve the models.\
    \ The features and models\npresented in this paper can be tested in similar multimodal\n\
    ambulatory datasets collected in other future studies. Tracking\nJ Med Internet\
    \ Res 2018 | vol. 20 | iss. 6 | e210 | p. 14\nhttp://www.jmir.org/2018/6/e210/\n\
    (page number not for citation purposes)\nSano et al\nJOURNAL OF MEDICAL INTERNET\
    \ RESEARCH\nXSL•FO\nRenderX\nstress and mental health conditions would help students\
    \ better\nunderstand their stress and mental health conditions over\nmultiple\
    \ semesters, as well as help clinicians see how treatment\naffects students’ conditions\
    \ if they receive treatment.\nConclusions\nIn this paper, we introduced a methodology\
    \ and tools we\ndeveloped to measure ambulatory multimodal data and improve\n\
    the integrity of collected data to study self-reported stress and\nmental health\
    \ in the daily lives of college students. We showed\nthat objective and modifiable\
    \ behavioral features collected over\n1 month can classify these college students\
    \ as high or low stress\nbased on the PSS and as having high or low mental health\
    \ based\non MCS from SF-12 collected at the end of that month with\nover 70% accuracy,\
    \ whereas sensor features alone could classify\nhigh or low mental health and\
    \ achieve over 88% on an F1 score.\nFor classifying high or low stress groups,\
    \ we found that\ncombining phone and sensor features typically gave the best\n\
    results over using either modality alone, whereas for classifying\nhigh or low\
    \ mental health groups, the use of wearable sensor\nfeatures performed comparable\
    \ to wearable + phone features.\nAcknowledgments\nThe authors are grateful to\
    \ Mr Conor O’Brien, Mr Justin Buie, Mr Salim Qadri, Ms Natalie Virayan, Mr Michael\
    \ Shreeve, Mr\nOmer Zaidi, Ms Natasha Jaques, Mr Weixuan Chen, Ms Asma Ghandeharioun,\
    \ Mr Daniel Lopez Martinez, Ms Ehimwenma\nNosakhare, Ms Amy Zhao Yu, Mr Daniel\
    \ Smilkov, Ms Jade Philipoom, Ms Yuna Hahn, Ms Sienna Ramos, Ms Jihyun Gia Min,\n\
    Ms Tania Yu, Ms Shirley Chen, Ms Laura Breiman, and Dr Catherine Ricciardi for\
    \ their tremendous support helping run the\nSNAPSHOT study and collecting the\
    \ data, and to Dr Cesar Hidalgo for helping design social network surveys. They\
    \ also appreciate\nall the participants and support from the MIT Media Lab Consortium,\
    \ especially a generous donation by Samsung Electronics,\nNEC, and funding from\
    \ NIH grants R01GM105018, R00HL119618 (AJKP), K24HL105664 (EBK), and KL2TR002370,\n\
    F32DK107146, T32HL007901 (AWM) and Harvard Catalyst | The Harvard Clinical and\
    \ Translational Science Center (National\nCenter for Research Resources and the\
    \ National Center for Advancing Translational Sciences, National Institutes of\
    \ Health Award\nUL1 TR001102), and financial contributions from Harvard University\
    \ and its affiliated academic health care centers. The content\nis solely the\
    \ responsibility of the authors and does not necessarily represent the official\
    \ views of Harvard Catalyst, Harvard\nUniversity and its affiliated academic health\
    \ care centers, or the National Institutes of Health.\nConflicts of Interest\n\
    RP is a cofounder of and shareholder in Affectiva, who commercialized the original\
    \ sensors used in this study. RP is also a\ncofounder and shareholder in Empatica,\
    \ a company that makes wearable sensors that can collect ambulatory data similar\
    \ to the\ndata collected in this study. EK has consulted for legal firms and for\
    \ Pfizer Pharmaceuticals.\nMultimedia Appendix 1\nCalendar view. For each day,\
    \ the investigator can see how many participants are in the study, how many surveys\
    \ have been\nverified, how many need to be re-examined, and participant comments.\n\
    [PNG File, 102KB-Multimedia Appendix 1]\nMultimedia Appendix 2\nSummary view.\
    \ The investigator can see the daily diary status for each participant in different\
    \ colors: green: acceptable; red:\nmissing; pink: error; red/white slash: missing\
    \ but participants still have time to complete the diary.\n[PNG File, 100KB-Multimedia\
    \ Appendix 2]\nMultimedia Appendix 3\nThe relationship between poststudy Perceived\
    \ Stress Scale (PSS) and poststudy Mental Component Score (MCS) for each\nparticipant\
    \ (blue circle). Chosen cutoffs for high and low PSS and high and low MCS are\
    \ indicated.\n[PNG File, 57KB-Multimedia Appendix 3]\nMultimedia Appendix 4\n\
    Performance of PSS and MCS classification models with 1 month or last week of\
    \ data.\n[PDF File (Adobe PDF File), 28KB-Multimedia Appendix 4]\nMultimedia Appendix\
    \ 5\nHigh or low Perceived Stress Scale (PSS) classification results. Top: Comparison\
    \ of F1 scores for PSS classification with three\nmachine learning algorithms\
    \ (LASSO, SVM linear, and SVM RBF) on 1 month of different types of data (All,\
    \ Big Five + Gender,\nJ Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 15\n\
    http://www.jmir.org/2018/6/e210/\n(page number not for citation purposes)\nSano\
    \ et al\nJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nSensor, Phone,\
    \ Objective, Behaviors). Bottom: Comparison of F1 scores with SVM RBF machine\
    \ learning algorithm on 1 month\nof data versus on only the last week of the same\
    \ data types. Accuracy scores for Big Five + Gender data are not shown in the\n\
    bottom graph because these data are collected only once.\n[PNG File, 21KB-Multimedia\
    \ Appendix 5]\nMultimedia Appendix 6\nHigh or low Mental Component Score (MCS)\
    \ classification results. Top: Comparison of F1 scores for MCS classification\
    \ with\nthree machine learning algorithms (LASSO, SVM linear, and SVM RBF) on\
    \ 1 month of different types of data (All, Big Five +\nGender, Sensor, Phone,\
    \ Objective, Behaviors). Bottom: Comparison of F1 scores with SVM RBF machine\
    \ learning algorithm\non 1 month of data versus on only the last week of the same\
    \ data types. Accuracy scores for Big Five + Gender data are not shown\nin the\
    \ bottom graph because these data are collected only once.\n[PNG File, 22KB-Multimedia\
    \ Appendix 6]\nMultimedia Appendix 7\nMean and SD of accuracy and F1 scores from\
    \ leave-one-cohort-out PSS and MCS classification models with 1 month of data\n\
    and SVM RBF.\n[PDF File (Adobe PDF File), 26KB-Multimedia Appendix 7]\nMultimedia\
    \ Appendix 8\nHigh or low Perceived Stress Scale (PSS) and Mental Component Score\
    \ (MCS) classification results. Comparison of F1 for PSS\nand MCS classification\
    \ scores with SVM RBF and 1 month of different types of data (All, Big Five +\
    \ Gender, Sensor, Phone,\nObjective, Behaviors). Cutoff: 14 (the average in the\
    \ 18-29 years age group) for PSS and 42.05 (median) for MCS.\n[PNG File, 14KB-Multimedia\
    \ Appendix 8]\nMultimedia Appendix 9\nPerformance of PSS and MCS classification\
    \ models with 1 month of data and SVM RBF. PSS cutoff: 14 (the average in the\n\
    18-29 years age group) and MCS cutoff: 42.05 (median).\n[PDF File (Adobe PDF File),\
    \ 16KB-Multimedia Appendix 9]\nMultimedia Appendix 10\nPercentages of the number\
    \ of times each feature was selected for each fold of leave-one-cohort-out cross\
    \ validation for 1-month\nPSS models.\n[PDF File (Adobe PDF File), 20KB-Multimedia\
    \ Appendix 10]\nMultimedia Appendix 11\nPercentages of the number of times each\
    \ feature was selected for each fold of leave-one-cohort-out cross validation\
    \ for 1-month\nMCS models.\n[PDF File (Adobe PDF File), 19KB-Multimedia Appendix\
    \ 11]\nReferences\n1.\nTorous J, Kiang MV, Lorme J, Onnela JP. New tools for new\
    \ research in psychiatry: a scalable and customizable platform\nto empower data\
    \ driven smartphone research. JMIR Ment Health 2016 May 5;3(2):e16 [FREE Full\
    \ text] [doi:\n10.2196/mental.5165] [Medline: 27150677]\n2.\nJain SH, Powers BW,\
    \ Hawkins JB, Brownstein JS. The digital phenotype. Nat Biotechnol 2015 May;33(5):462-463.\
    \ [doi:\n10.1038/nbt.3223] [Medline: 25965751]\n3.\nLi X, Dunn J, Salins D, Zhou\
    \ G, Zhou W, Schüssler-Fiorenza Rose SM, et al. Digital health: tracking physiomes\
    \ and activity\nusing wearable biosensors reveals useful health-related information.\
    \ PLoS Biol 2017 Jan;15(1):e2001402 [FREE Full text]\n[doi: 10.1371/journal.pbio.2001402]\
    \ [Medline: 28081144]\n4.\nWang R, Chen F, Chen Z, Li T, Harari G, Tignor S, et\
    \ al. StudentLife: assessing mental health, academic performance and\nbehavioral\
    \ trends of college students using smartphones. 2014 Presented at: UbiComp '14\
    \ Proceedings of the 2014 ACM\nInternational Joint Conference on Pervasive and\
    \ Ubiquitous Computing; September 13-17, 2014; Seattle, Washington. [doi:\n10.1145/2632048.2632054]\n\
    J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 16\nhttp://www.jmir.org/2018/6/e210/\n\
    (page number not for citation purposes)\nSano et al\nJOURNAL OF MEDICAL INTERNET\
    \ RESEARCH\nXSL•FO\nRenderX\n5.\nBogomolov A, Lepri B, Pianesi F. Happiness recognition\
    \ from mobile phone data. 2013 Presented at: International Conference\non Social\
    \ Computing; September 8-14, 2013; Alexandria, VA, USA. [doi: 10.1109/SocialCom.2013.118]\n\
    6.\nBauer G, Lukowicz P. Can smartphones detect stress-related changes in the\
    \ behaviour of individuals? 2012 Presented at:\nIEEE International Conference\
    \ on Pervasive Computing and Communications Workshops; March 19-23, 2012; Lugano,\n\
    Switzerland. [doi: 10.1109/PerComW.2012.6197525]\n7.\nBogomolov A, Lepri B, Ferron\
    \ M, Pianesi F, Pentland A. Daily Stress Recognition from Mobile Phone Data, Weather\n\
    Conditions and Individual Traits. 2014 Presented at: Proceedings of the 22nd ACM\
    \ international conference on Multimedia;\nNovember 3-7, 2014; Orlando, Florida,\
    \ USA. [doi: 10.1145/2647868.2654933]\n8.\nSaeb S, Zhang M, Karr CJ, Schueller\
    \ SM, Corden ME, Kording KP, et al. Mobile phone sensor correlates of depressive\n\
    symptom severity in daily-life behavior: an exploratory study. J Med Internet\
    \ Res 2015 Jul 15;17(7):e175 [FREE Full text]\n[doi: 10.2196/jmir.4273] [Medline:\
    \ 26180009]\n9.\nChow PI, Fua K, Huang Y, Bonelli W, Xiong H, Barnes LE, et al.\
    \ Using mobile sensing to test clinical models of depression,\nsocial anxiety,\
    \ state affect, and social isolation among college students. J Med Internet Res\
    \ 2017 Mar 3;19(3):e62 [FREE\nFull text] [doi: 10.2196/jmir.6820] [Medline: 28258049]\n\
    10.\nPlace S, Blanch-Hartigan D, Rubin C, Gorrostieta C, Mead C, Kane J, et al.\
    \ Behavioral indicators on a mobile sensing\nplatform predict clinically validated\
    \ psychiatric symptoms of mood and anxiety disorders. J Med Internet Res 2017\
    \ Mar\n16;19(3):e75 [FREE Full text] [doi: 10.2196/jmir.6678] [Medline: 28302595]\n\
    11.\nMuaremi A, Arnrich B, Tröster G. Towards measuring stress with smartphones\
    \ and wearable devices during workday and\nsleep. Bionanoscience 2013;3:172-183\
    \ [FREE Full text] [doi: 10.1007/s12668-013-0089-2] [Medline: 25530929]\n12.\n\
    Muaremi A, Bexheti A, Gravenhorst F, Arnrich B, Tröster G. Monitoring the Impact\
    \ of Stress on the Sleep Patterns of\nPilgrims using Wearable Sensors. 2014 Presented\
    \ at: IEEE-EMBS International Conference on Biomedical and Health\nInformatics\
    \ (BHI); June 1-4, 2014; Valencia, Spain. [doi: 10.1109/BHI.2014.6864335]\n13.\n\
    Sano A, Picard RW. Stress Recognition Using Wearable Sensors and Mobile Phones.\
    \ 2013 Presented at: Humaine Association\nConference on Affective Computing and\
    \ Intelligent Interaction; September 2-5, 2013; Geneva, Switzerland. [doi:\n10.1109/ACII.2013.117]\n\
    14.\nSano A, Phillips AJ, Yu AZ, McHill AW, Taylor S, Jaques N, et al. Recognizing\
    \ academic performance, sleep quality,\nstress level, and mental health using\
    \ personality traits, wearable sensors and mobile phones. 2015 Presented at: IEEE\
    \ 12th\nInternational Conference on Wearable and Implantable Body Sensor Networks\
    \ (BSN); June 9-12, 2015; Cambridge, MA,\nUSA. [doi: 10.1109/BSN.2015.7299420]\n\
    15.\nCACUSS. American College Health Association-National College Health Assessment\
    \ II: Canadian Reference Group\nExecutive Summary Spring 2017 URL: http://www.cacuss.ca/health_data.htm\
    \ [accessed 2018-05-16] [WebCite Cache ID\n6zT9bD7yo]\n16.\nAuerbach RP, Alonso\
    \ J, Axinn WG, Cuijpers P, Ebert DD, Green JG, et al. Mental disorders among college\
    \ students in\nthe World Health Organization world mental health surveys. Psychol\
    \ Med 2016 Oct;46(14):2955-2970 [FREE Full text]\n[doi: 10.1017/S0033291716001665]\
    \ [Medline: 27484622]\n17.\nEisenberg D, Golberstein E, Hunt J. Mental health\
    \ and academic success in college. B E J Econom Anal Policy 2009;9(1):-.\n[doi:\
    \ 10.2202/1935-1682.2191]\n18.\nThe American Association of Suicidology. Suicidology.\
    \ 2016. College Students & Suicide Fact Sheet: 2016 Fact Sheet\nURL: http://www.suicidology.org/Portals/14/Re-Formatted%20College%20Students%20Fact%20Sheet.\n\
    pdf?ver=2016-11-16-110354-547 [accessed 2018-05-16] [WebCite Cache ID 6zTBIkcVH]\n\
    19.\nThe Association for University and College Counseling Center Directors. The\
    \ association for university and college\ncounseling center directors annual survey\
    \ URL: http://files.cmcglobal.com/AUCCCD_2013_Monograph_Public.pdf\n[accessed\
    \ 2018-05-16] [WebCite Cache ID 6zT9rC5tt]\n20.\nHorne JA, Ostberg O. A self-assessment\
    \ questionnaire to determine morningness-eveningness in human circadian rhythms.\n\
    Int J Chronobiol 1976;4(2):97-110. [Medline: 1027738]\n21.\nBuysse DJ, Reynolds\
    \ CF, Monk TH, Berman SR, Kupfer DJ. The Pittsburgh Sleep Quality Index: a new\
    \ instrument for\npsychiatric practice and research. Psychiatry Res 1989 May;28(2):193-213.\
    \ [Medline: 2748771]\n22.\nJohn O, Srivastava S. Moityca.com.br. 1999. The Big\
    \ Five trait taxonomy: History, measurement, and theoretical perspectives\nURL:\
    \ http://moityca.com.br/pdfs/bigfive_John.pdf [accessed 2018-05-18] [WebCite Cache\
    \ ID 6zVEjcmQv]\n23.\nCohen S, Kamarck T, Mermelstein R. A global measure of perceived\
    \ stress. J Health Soc Behav 1983 Dec;24(4):385-396.\n[Medline: 6668417]\n24.\n\
    Ware J, Kosinski M, Keller SD. A 12-item short-form health survey: construction\
    \ of scales and preliminary tests of reliability\nand validity. Med Care 1996\
    \ Mar;34(3):220-233. [Medline: 8628042]\n25.\nSano A, Picard RW, Stickgold R.\
    \ Quantitative analysis of wrist electrodermal activity during sleep. Int J Psychophysiol\n\
    2014 Dec;94(3):382-389 [FREE Full text] [doi: 10.1016/j.ijpsycho.2014.09.011]\
    \ [Medline: 25286449]\n26.\nAharony N, Pan W, Ip C, Khayal I, Pentland A. Social\
    \ fMRI: investigating and shaping social mechanisms in the real\nworld. Pervasive\
    \ Mob Comput 2011 Dec;7(6):643-659. [doi: 10.1016/j.pmcj.2011.09.004]\nJ Med Internet\
    \ Res 2018 | vol. 20 | iss. 6 | e210 | p. 17\nhttp://www.jmir.org/2018/6/e210/\n\
    (page number not for citation purposes)\nSano et al\nJOURNAL OF MEDICAL INTERNET\
    \ RESEARCH\nXSL•FO\nRenderX\n27.\nCajochen C, Frey S, Anders D, Späti J, Bues\
    \ M, Pross A, et al. Evening exposure to a light-emitting diodes (LED)-backlit\n\
    computer screen affects circadian physiology and cognitive performance. J Appl\
    \ Physiol (1985) 2011 May;110(5):1432-1438\n[FREE Full text] [doi: 10.1152/japplphysiol.00165.2011]\
    \ [Medline: 21415172]\n28.\nChang AM, Aeschbach D, Duffy JF, Czeisler CA. Evening\
    \ use of light-emitting eReaders negatively affects sleep, circadian\ntiming,\
    \ and next-morning alertness. Proc Natl Acad Sci U S A 2015 Jan 27;112(4):1232-1237\
    \ [FREE Full text] [doi:\n10.1073/pnas.1418490112] [Medline: 25535358]\n29.\n\
    Immersion. A people-centric view of your email life URL: https://immersion.media.mit.edu/\
    \ [accessed 2018-05-18] [WebCite\nCache ID 6zVK7Rb2d]\n30.\nSpielberger C. Manual\
    \ for the State-Trait Anxiety Inventory (Form Y). Palo Alto, CA: Consulting Psychologists\
    \ Press;\n1983.\n31.\nVan den Broeck J, Cunningham SA, Eeckels R, Herbst K. Data\
    \ cleaning: detecting, diagnosing, and editing data abnormalities.\nPLoS Med 2005\
    \ Oct;2(10):e267 [FREE Full text] [doi: 10.1371/journal.pmed.0020267] [Medline:\
    \ 16138788]\n32.\nClifford GD, Lopez D, Li Q, Rezek I. Signal quality indices\
    \ and data fusion for determining clinical acceptability of\nelectrocardiograms.\
    \ 2011 Presented at: Computing in Cardiology; September 18-21, 2011; Hangzhou,\
    \ China.\n33.\nWood LB, Asada HH. Noise cancellation model validation for reduced\
    \ motion artifact wearable PPG sensors using MEMS\naccelerometers. 2006 Presented\
    \ at: International Conference of the IEEE Engineering in Medicine and Biology\
    \ Society;\nAugust 30-September 03, 2006; New York, NY, USA. [doi: 10.1109/IEMBS.2006.260359]\n\
    34.\nEngels J. Imputation of missing longitudinal data: a comparison of methods.\
    \ J Clin Epidemiol 2003 Oct;56(10):968-976.\n[doi: 10.1016/S0895-4356(03)00170-7]\n\
    35.\nSchmitt P, Mandel J, Guedj M. A comparison of six methods for missing data\
    \ imputation. J Biom Biostat 2015;6:224. [doi:\n10.4172/2155-6180.1000224]\n36.\n\
    Taylor S, Jaques N, Chen W, Fedor S, Sano A, Picard R. Automatic identification\
    \ of artifacts in electrodermal activity data.\n2015 Presented at: 37th Annual\
    \ International Conference of the IEEE Engineering in Medicine and Biology Society\
    \ (EMBC);\nAugust 25-29, 2015; Milan, Italy URL: http://europepmc.org/abstract/MED/26736662\
    \ [doi: 10.1109/EMBC.2015.7318762]\n37.\nDoberenz S, Roth WT, Wollburg E, Maslowski\
    \ NI, Kim S. Methodological considerations in ambulatory skin conductance\nmonitoring.\
    \ Int J Psychophysiol 2011;80(2):87-95. [doi: 10.1016/j.ijpsycho.2011.02.002]\n\
    38.\nDawson ME, Schell AM, Filion DL. The electrodermal system. In: Handbook of\
    \ Psychophysiology. New York, NY, US:\nCambridge University Press; 2007:159-181.\n\
    39.\nWenzel A. The SAGE Encyclopedia of Abnormal and Clinical Psychology. Thousand\
    \ Oaks, California: SAGE Publications,\nInc; 2017.\n40.\nTexas Instruments. TIDA-00824\
    \ Human Skin Temperature Sensing for Wearable Applications Reference Design URL:\n\
    http://www.ti.com/lit/ug/tiduay7/tiduay7.pdf [accessed 2018-05-16] [WebCite Cache\
    \ ID 6zTAnV7XJ]\n41.\nBolge SC, Flores NM, Phan JH. The burden of poor mental\
    \ well-being among patients with type 2 diabetes mellitus:\nexamining health care\
    \ resource use and work productivity loss. J Occup Environ Med 2016 Nov;58(11):1121-1126\
    \ [FREE\nFull text] [Medline: 27820762]\n42.\nWolff JL, Roter DL. Older adults'\
    \ mental health function and patient-centered care: does the presence of a family\
    \ companion\nhelp or hinder communication? J Gen Intern Med 2012 Jun;27(6):661-668\
    \ [FREE Full text] [doi: 10.1007/s11606-011-1957-5]\n[Medline: 22180197]\n43.\n\
    Boucsein W, Fowles DC, Grimnes S, Ben-Shakhar G, Roth WT, Dawson ME, Society for\
    \ Psychophysiological Research\nAd Hoc Committee on Electrodermal Measures. Publication\
    \ recommendations for electrodermal measurements.\nPsychophysiology 2012 Aug;49(8):1017-1034.\
    \ [doi: 10.1111/j.1469-8986.2012.01384.x] [Medline: 22680988]\n44.\nBoucsein W.\
    \ Electrodermal Activity. United States: Springer US; 2012.\n45.\nThomée S, Härenstam\
    \ A, Hagberg M. Mobile phone use and stress, sleep disturbances, and symptoms\
    \ of depression among\nyoung adults--a prospective cohort study. BMC Public Health\
    \ 2011 Jan;11:66 [FREE Full text] [doi:\n10.1186/1471-2458-11-66] [Medline: 21281471]\n\
    46.\nSano A, Phillips A, McHill A, Taylor S, Barger L, Czeisler C, et al. Influence\
    \ of weekly sleep regularity on self-reported\nwellbeing. Sleep 2017;40(suppl_1):A67-A68.\
    \ [doi: 10.1093/sleepj/zsx050.181]\n47.\nPhillips AJK, Clerx WM, O'Brien CS, Sano\
    \ A, Barger LK, Picard RW, et al. Irregular sleep/wake patterns are associated\n\
    with poorer academic performance and delayed circadian and sleep/wake timing.\
    \ Sci Rep 2017 Jun 12;7(1):3216 [FREE\nFull text] [doi: 10.1038/s41598-017-03171-4]\
    \ [Medline: 28607474]\n48.\nCanzian L, Musolesi M. Trajectories of depression:\
    \ unobtrusive monitoring of depressive states by means of smartphone\nmobility\
    \ traces analysis. 2015 Presented at: Proceedings of the 2015 ACM International\
    \ Joint Conference on Pervasive and\nUbiquitous Computing; September 7-11, 2015;\
    \ Osaka, Japan. [doi: 10.1145/2750858.2805845]\n49.\nJaques N, Taylor S, Azaria\
    \ A, Ghandeharioun A, Sano A, Picard R. Predicting students' happiness from physiology,\
    \ phone,\nmobility, and behavioral data. 2015 Presented at: International Conference\
    \ on Affective Computing and Intelligent Interaction\n(ACII); September 21-24,\
    \ 2015; Xi'an, China URL: http://europepmc.org/abstract/MED/28515966 [doi:\n10.1109/ACII.2015.7344575]\n\
    50.\nTibshirani R. Regression selection shrinkage via the Lasso. J R Stat Soc\
    \ Series B Stat Methodol 2011;73(3):273-282. [doi:\n10.1111/j.1467-9868.2011.00771.x]\n\
    J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 18\nhttp://www.jmir.org/2018/6/e210/\n\
    (page number not for citation purposes)\nSano et al\nJOURNAL OF MEDICAL INTERNET\
    \ RESEARCH\nXSL•FO\nRenderX\n51.\nKohavi R, John GH. Wrappers for feature subset\
    \ selection. Artif Intell 1997 Dec;97(1-2):273-324. [doi:\n10.1016/S0004-3702(97)00043-X]\
    \ [Medline: 356583]\n52.\nForman G, Scholz M. Apples-to-apples in cross-validation\
    \ studies: pitfalls in classifier performance measurement. SIGKDD\nExplor 2010;12:49-57.\
    \ [doi: 10.1145/1882471.1882479]\n53.\nAgresti A, Coull BA. Approximate is better\
    \ than “Exact” for interval estimation of binomial proportions. Am Stat 1998\n\
    May;52(2):119-126. [doi: 10.1080/00031305.1998.10480550]\n54.\nHealey JA, Picard\
    \ RW. Affect.media.mit.edu. 2005. Detecting Stress During Real-World Driving Tasks\
    \ Using Physiological\nSensors URL: https://affect.media.mit.edu/pdfs/05.healey-picard.pdf\
    \ [accessed 2018-05-18] [WebCite Cache ID 6zVI8MWT1]\n55.\nHernandez J, Morris\
    \ RR, Picard RW. Call Center Stress Recognition with Person-Specific Models. 2011\
    \ Presented at:\nInternational Conference on Affective Computing and Intelligent\
    \ Interaction; October 09-12, 2011; Memphis, USA. [doi:\n10.1007/978-3-642-24600-5_16]\n\
    56.\nSetz C, Arnrich B, Schumm J, La Marca R, Tröster G, Ehlert U. Discriminating\
    \ stress from cognitive load using a wearable\nEDA device. IEEE Trans Inf Technol\
    \ Biomed 2010 Mar;14(2):410-417. [doi: 10.1109/TITB.2009.2036164] [Medline:\n\
    19906598]\n57.\nWard NG, Doerr HO, Storrie MC. Skin conductance: a potentially\
    \ sensitive test for depression. Psychiatry Res 1983\nDec;10(4):295-302. [Medline:\
    \ 6583718]\n58.\nArgyle N. Skin conductance levels in panic disorder and depression.\
    \ J Nerv Ment Dis 1991 Sep;179(9):563-566. [Medline:\n1919559]\n59.\nRottenberg\
    \ J. Mood and emotion in major depression. Curr Dir Psychol Sci 2005;14(3):167-170.\
    \ [doi:\n10.1111/j.0963-7214.2005.00354.x]\n60.\nNutt D, Wilson S, Paterson L.\
    \ Sleep disorders as core symptoms of depression. Dialogues Clin Neurosci 2008;10(3):329-336\n\
    [FREE Full text] [Medline: 18979946]\n61.\nAbad VC, Guilleminault C. Sleep and\
    \ psychiatry. Dialogues Clin Neurosci 2005;7(4):291-303 [FREE Full text] [Medline:\n\
    16416705]\n62.\nVinkers CH, Penning R, Hellhammer J, Verster JC, Klaessens JH,\
    \ Olivier B, et al. The effect of stress on core and peripheral\nbody temperature\
    \ in humans. Stress 2013 Sep;16(5):520-530. [doi: 10.3109/10253890.2013.807243]\
    \ [Medline: 23790072]\n63.\nSano A, Picard RW. Comparison of sleep-wake classification\
    \ using electroencephalogram and wrist-worn multi-modal\nsensor data. Conf Proc\
    \ IEEE Eng Med Biol Soc 2014;2014:930-933 [FREE Full text] [doi: 10.1109/EMBC.2014.6943744]\n\
    64.\nBarbini B, Benedetti F, Colombo C, Guglielmo E, Campori E, Smeraldi E. Perceived\
    \ mood and skin body temperature\nrhythm in depression. Eur Arch Psychiatry Clin\
    \ Neurosci 1998;248(3):157-160. [Medline: 9728735]\n65.\nZschucke E, Gaudlitz\
    \ K, Ströhle A. Exercise and physical activity in mental disorders: clinical and\
    \ experimental evidence.\nJ Prev Med Public Health 2013 Jan;46 Suppl 1:S12-S21\
    \ [FREE Full text] [doi: 10.3961/jpmph.2013.46.S.S12] [Medline:\n23412549]\n66.\n\
    Vollrath M. Personality and stress. Scand J Psychol 2001;42(4):335-347. [Medline:\
    \ 11547909]\n67.\nEbstrup JF, Eplov LF, Pisinger C, Jørgensen T. Association between\
    \ the Five Factor personality traits and perceived stress:\nis the effect mediated\
    \ by general self-efficacy? Anxiety Stress Coping 2011 Jul;24(4):407-419. [doi:\n\
    10.1080/10615806.2010.540012] [Medline: 21213153]\n68.\nvan Straten A, Cuijpers\
    \ P, van Zuuren FJ, Smits N, Donker M. Personality traits and health-related quality\
    \ of life in patients\nwith mood and anxiety disorders. Qual Life Res 2007 Feb;16(1):1-8\
    \ [FREE Full text] [doi: 10.1007/s11136-006-9124-x]\n[Medline: 17033892]\n69.\n\
    Götz FM, Stieger S, Reips UD. Users of the main smartphone operating systems (iOS,\
    \ Android) differ only little in\npersonality. PLoS One 2017 May;12(5):e0176921\
    \ [FREE Full text] [doi: 10.1371/journal.pone.0176921] [Medline:\n28467473]\n\
    70.\nMayor E. Gender roles and traits in stress and health. Front Psychol 2015\
    \ Jun;6:779 [FREE Full text] [doi:\n10.3389/fpsyg.2015.00779] [Medline: 26106354]\n\
    71.\nZuckerman DM. Stress, self-esteem, and mental health: How does gender make\
    \ a difference? Sex Roles 1989\nApr;20(7-8):429-444. [doi: 10.1007/BF00288001]\n\
    72.\nSigmon ST, Pells JJ, Boulard NE, Whitcomb-Smith S, Edenfield TM, Hermann\
    \ BA, et al. Gender differences in self-reports\nof depression: the response bias\
    \ hypothesis revisited. Sex Roles 2005;53(5-6):401-411. [doi: 10.1007/s11199-005-6762-3]\n\
    73.\nSandanger I, Nygård JF, Sørensen T, Moum T. Is women's mental health more\
    \ susceptible than men's to the influence of\nsurrounding stress? Soc Psychiatry\
    \ Psychiatr Epidemiol 2004 Mar;39(3):177-184. [doi: 10.1007/s00127-004-0728-6]\n\
    [Medline: 14999449]\n74.\nVerma R, Balhara YP, Gupta CS. Gender differences in\
    \ stress response: role of developmental and biological determinants.\nInd Psychiatry\
    \ J 2011 Jan;20(1):4-10 [FREE Full text] [doi: 10.4103/0972-6748.98407] [Medline:\
    \ 22969173]\nAbbreviations\nACC: acceleration\nE-diary: electronic diary\nJ Med\
    \ Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 19\nhttp://www.jmir.org/2018/6/e210/\n\
    (page number not for citation purposes)\nSano et al\nJOURNAL OF MEDICAL INTERNET\
    \ RESEARCH\nXSL•FO\nRenderX\nFDR: false discovery rate\nHRV: heart rate variability\n\
    LASSO: least absolute shrinkage and selection operator\nMCS: mental component\
    \ summary\nMIT: Massachusetts Institute of Technology\nPHQ-9: patient health questionnaire-9\n\
    PSS: perceived stress scores\nRBF: radial basis function\nREM: rapid eye movement\n\
    SC: skin conductance\nSF-12: 12-Item Short Form Health Survey\nSMS: short message\
    \ service\nSRI: Sleep Regularity Index\nST: skin temperature\nSVM: support vector\
    \ machine\nSWS: slow-wave sleep\nEdited by G Eysenbach; submitted 13.11.17; peer-reviewed\
    \ by S Saeb, L Barnes, C Gorrostieta, J Apolinário-Hagen; comments to\nauthor\
    \ 16.12.17; revised version received 24.02.18; accepted 22.04.18; published 08.06.18\n\
    Please cite as:\nSano A, Taylor S, McHill AW, Phillips AJK, Barger LK, Klerman\
    \ E, Picard R\nIdentifying Objective Physiological Markers and Modifiable Behaviors\
    \ for Self-Reported Stress and Mental Health Status Using\nWearable Sensors and\
    \ Mobile Phones: Observational Study\nJ Med Internet Res 2018;20(6):e210\nURL:\
    \ http://www.jmir.org/2018/6/e210/\ndoi: 10.2196/jmir.9410\nPMID: 29884610\n©Akane\
    \ Sano, Sara Taylor, Andrew W McHill, Andrew JK Phillips, Laura K Barger, Elizabeth\
    \ Klerman, Rosalind Picard.\nOriginally published in the Journal of Medical Internet\
    \ Research (http://www.jmir.org), 08.06.2018. This is an open-access article\n\
    distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/),\
    \ which\npermits unrestricted use, distribution, and reproduction in any medium,\
    \ provided the original work, first published in the Journal\nof Medical Internet\
    \ Research, is properly cited. The complete bibliographic information, a link\
    \ to the original publication on\nhttp://www.jmir.org/, as well as this copyright\
    \ and license information must be included.\nJ Med Internet Res 2018 | vol. 20\
    \ | iss. 6 | e210 | p. 20\nhttp://www.jmir.org/2018/6/e210/\n(page number not\
    \ for citation purposes)\nSano et al\nJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\n\
    RenderX\n"
  inline_citation: '>'
  journal: JMIR. Journal of medical internet research
  limitations: '>'
  pdf_link: https://www.jmir.org/2018/6/e210/PDF
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: 'Identifying Objective Physiological Markers and Modifiable Behaviors for
    Self-Reported Stress and Mental Health Status Using Wearable Sensors and Mobile
    Phones: Observational Study'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper.

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: 4.4. Online Learning in the Cloud
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>

<documents>
<review_intention>
  
the purpose and intention of this systematic review on automated systems for real-time irrigation management can be interpreted as follows:
Addressing the global food challenge: The review aims to explore how automated, real-time irrigation management systems can contribute to the efficient use of water resources and enhance agricultural productivity to meet the growing demand for food.
Evaluating the current state and future potential: The primary objective is to critically assess the current state of end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. The review also seeks to identify gaps and propose solutions for seamless integration across the automated irrigation management system to achieve fully autonomous, scalable irrigation management.
Examining automation across the entire pipeline: The review intends to systematically analyze the automation of each component of the irrigation management pipeline, from data collection and transmission to processing, analysis, decision-making, and automated action. It aims to investigate the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
Highlighting the role of interoperability and standardization: The review seeks to emphasize the importance of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline. It aims to identify existing and emerging standards and their applicability to real-time irrigation management systems.
Identifying challenges and proposing solutions: The review intends to uncover the challenges associated with implementing real-time, automated irrigation systems, such as data quality, scalability, reliability, and security. It aims to propose solutions and best practices based on the analysis of case studies and real-world implementations.
Guiding future research and innovation: By identifying research gaps and proposing new research questions and hypotheses, the review aims to provide a roadmap for advancing the field of real-time, automated irrigation management. It seeks to encourage collaborative research efforts across disciplines to address the complex challenges of automated irrigation systems.
In summary, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.
</review_intention>

<section_intention>
AUTOMATED DATA PROCESSING IN THE CLOUD: Examines the importance of data quality and preprocessing in the cloud, containerization strategies for scalable and autonomous deployment, and the deployment of machine learning (ML) models for real-time data processing and inference.
</section_intention>

<subsection_title>
4.1. Data Quality and Preprocessing
</subsection_title>

<subsection_point_Point 1>
Point: Real-time data cleaning techniques for handling missing, inconsistent, or outlier data from IoT sensors (e.g., soil moisture sensors, weather stations) using methods such as Kalman filtering, moving average, and adaptive thresholding

Papers to support point:

Paper 1:
- APA Citation: Lv, Z., Cheng, C., & Lv, H. (2023). Digital twins for secure thermal energy storage in building. Applied Energy, 338, 120907.
  Main Objective: To explore the use of DTs technology and PCM in thermal energy storage and scheduling systems for intelligent buildings, aiming to improve energy efficiency and reduce water consumption in agricultural applications.
  Study Location: Unspecified
  Data Sources: Not explicitly mentioned in the abstract.
  Technologies Used: Digital Twins (DTs), Phase Change Material (PCM)
  Key Findings: The study demonstrates the feasibility and effectiveness of the proposed thermal energy storage and scheduling model based on DTs for smart buildings through a case study of a photovoltaic-integrated smart building group. The model achieves efficient energy usage, reduces economic costs, environmental costs, and energy costs, and enhances safety performance.
  Extract 1: "Therefore, this work innovatively introduces DTs technology into intelligent buildings and places the Phase Change Material (PCM) in the interior building structure. Additionally, a DTs-based thermal energy storage and safety scheduling model for thermoelectric smart buildings is constructed using the PCM wall. Measurements of its effectiveness obtained through experimentation."
  Extract 2: "Of course, the operation of thermal insulation and thermal energy storage systems in smart buildings is inseparable from the support of the power system. Microgrids utilize decentralized local energy sources for distributed generation and apply them to the distributed thermal energy storage systems in buildings [15]. Swaminathan et al. (2020) developed an optimal sizing and scheduling model for microgrids with model predictive control. They found that building-level microgrids for medium-sized commercial buildings can save initial and operational costs [16]."
  Limitations: None
  Relevance Evaluation: The paper is highly relevant to my point in the literature review, which focuses on the use of automated, real-time irrigation management systems to enhance agricultural productivity and address the global food challenge. The paper's proposed thermal energy storage system and scheduling model using Digital Twins (DTs) can contribute to the efficient use of water resources, reducing water consumption and enhancing the overall sustainability of the agricultural sector. The paper provides novel insights into the role of digitization and real-time data processing in optimizing water management for agricultural applications.
  Relevance Score: 1.0
  Inline Citation: (Lv et al., 2023)
  Explanation: This study explores the safe and optimal scheduling of thermal energy storage systems in intelligent buildings. It introduces Digital Twins (DTs) technology into the intelligent buildings and places Phase Change Material (PCM) in the indoor building structure. A thermal energy storage and scheduling model based on DTs is constructed for thermoelectric smart buildings using the PCM wall, and its effectiveness is validated through experiments.

 Full Text: >
Loading [MathJax]/jax/element/mml/optable/BasicLatin.js Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Highlights Abstract Keywords 1. Introduction 2. Related work 3. DTs-based thermal energy storage system for smart buildings and its scheduling strategy security 4. Results and discussion 5. Discussion 6. Conclusion Declaration of Competing Interest Data availability References Show full outline Cited by (7) Figures (8) Show 2 more figures Applied Energy Volume 338, 15 May 2023, 120907 Digital twins for secure thermal energy storage in building Author links open overlay panel Zhihan Lv a, Chen Cheng b, Haibin Lv c Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.apenergy.2023.120907 Get rights and content Under a Creative Commons license open access Highlights • Places the Phase Change Material in the indoor building structure. • The DTs model of the Phase Change Wall (PCW) structure is constructed. • The PCW structure is used to build a thermal energy storage. Abstract The purpose of this work is to explore the role of the safe and optimal scheduling of thermal energy storage systems in intelligent buildings in promoting sustainable economic development under Digital Twins (DTs) technology. Phase Change Material (PCM) has high energy density, constant temperature storage, small footprint, and long service life. Here, PCM is first placed in the indoor building structure, and the DTs technology is introduced. In the development of intelligent buildings, the data generated by the energy storage system of intelligent buildings in the real space can be mapped to the virtual space in real time for simultaneous analysis. In addition, the PCM wall structure and thermal network DTs model are designed for the intelligent building. In addition, the PCW structure is used to build a thermal energy storage and dispatch model of the smart thermoelectric building based on DTs. Finally, the model is evaluated and analyzed experimentally. The analysis of system optimization power under different schemes indicates that the scheduling operation strategy of thermal energy storage of building walls can avoid overcharging or over-discharging batteries in the microgrid and reduce battery power consumption. Besides, the building wall energy storage capacity is always in the range of 0.2 ∼ 0.8 on the all-weather scale. Moreover, the model constructed here achieves significantly lower economic costs, environmental costs, and energy costs and a better energy-saving effect than the existing model. The model built here can serve as experimental reference for further digital energy storage in intelligent buildings and comprehensive energy utilization because of its superior safety performance and lower consumption. Previous article in issue Next article in issue Keywords Thermal energy storageDigital twinsPhase change materialIntelligent buildingMicrogrid 1. Introduction With the rapid development of information technology, various advanced are even more broadly applied, such as the Internet of Things (IoT), Cloud Computing, Digital Twins (DTs), and Artificial Intelligence (AI). For example, Cheng et al. (2022) proposed an energy-efficient multilayer virtual traffic scheduling algorithm regarding smart city construction that can effectively provide directions for smart city development and construction [1]. These techniques have also promoted the transformation of the construction industry from traditional construction and management methods to digital and intelligent transformation, which is one of the pillar industries of China's real economy [2]. The building provides housing and keeps the cold out. Therefore, the design of the wall's heat preservation performance is extremely essential. The heat insulation and thermal energy storage function of the building makes the whole indoor environment warm in winter and cool in summer, reflecting the energy saving, improving the living environment, and functions of using the construction [3]. Therefore, the application of IoT, Cloud Computing, AI, and other technologies to building insulation and thermal energy storage security has become the focus of scholars in related fields. Currently, the building industry is in the process of intelligent development. Its overall design usually adopts the integrated design-manufacturing-construction method for bidding to ensure the integrity and integration of the overall building [4]. In the traditional building construction process, high requirements are put forward for information sharing, interaction, and collaboration among the design unit, manufacturer, and construction unit. However, there are still cases of conflicting nodes of building components in the construction process of actual engineering projects, such as nodes of columns and beams or nodes of wall panels and concealed columns. The problem of heat insulation and thermal energy storage during the construction of buildings is prominently important [5]. Jiang et al. (2021) formulated and fabricated a new self-reinforced composite phase change material for thermal energy storage using continuous hot-melt extrusion. They aimed to address the mismatch between energy production and demand under deep renewable energy penetration scenarios and address climate change challenges [6]. Wang et al. (2022) designed and constructed a novel medium to high temperature packed-bed latent heat storage material for thermal energy storage studies in buildings [7]. After understanding the performance of thermal energy storage materials designed in the above-mentioned traditional building construction, AI technology is introduced to analyze the digital construction of intelligent buildings. The construction of buildings develops intellectually with the application of various technologies, such as IoT, Cloud Computing, DTs, and AI. Spiking neural networks in machine learning are thought to boost the precision and durability of spike-based meta-learning by Yang & Tan et al. (2022) [8] and Yang & Linares-Barranco (2022) [9]. The self-adaptive multicompartment algorithm has been presented by Yang and Gao et al. (2022) as a means to create efficient adaptive neuromorphic computing systems for use in domains ranging from robotics to edge computing [10]. For example, the high-efficiency collaboration of the integration of project design, construction production, and operation and maintenance services of building insulation and thermal energy storage engineering driven by digital chain can be realized through digital modeling, visual cognition and interaction, high performance computing of relevant data, and intelligent decision making [11], [12]. DTs technology can simulate and describe the state and behavior of entities in physical space through high-fidelity dynamic virtual models and preview or simulate all activities of physical entities in virtual space in advance or in real-time [13]. For instance, Lv et al. (2022) combined DTs and AI to predict traffic accidents. The result showed that the prediction accuracy is high, which can provide a reference for the prevention of traffic congestion [14]. Introducing DTs technology into the construction process of intelligent building insulation and thermal energy storage systems can effectively improve the efficiency of construction projects and reduces the incidence of errors, and improve construction quality. It also improves the informatization and intelligence of the construction process of building insulation and thermal energy storage projects, promoting the digital development of thermal insulation and thermal energy storage systems in smart buildings. Of course, the operation of thermal insulation and thermal energy storage systems in smart buildings is inseparable from the support of the power system. Microgrids utilize decentralized local energy sources for distributed generation and apply them to the distributed thermal energy storage systems in buildings [15]. Swaminathan et al. (2020) developed an optimal sizing and scheduling model for microgrids with model predictive control. They found that building-level microgrids for medium-sized commercial buildings can save initial and operational costs [16]. Ramli & Jabbar (2022) proposed a solar-powered portable water pump for IoT-enabled smart irrigation system. Tests of the developed solar water pump confirmed its effectiveness. It has successfully conserved energy and cut down on running expenses [17]. The heat pump is connected to the microgrid when the building is constructed. The thermal energy storage system and heat pump can flexibly adjust the power according to the real-time electricity price and renewable energy generation under the premise of ensuring the appropriate indoor temperature of the building [18]. If the electricity meets the customer's electricity demand, the surplus electricity will be converted into heat energy by the heat pump and stored in the intelligent building heat storage system. Suppose the local decentralized energy generation is insufficient. In that case, the intelligent building thermal storage system can release thermal energy into the microgrid, and users only need a small amount of purchased electricity to meet their power needs. In summary, exploring the safe dispatch and sustainable development of thermal energy storage systems in intelligent buildings is of theoretical significance to the green development of the social economy and the improvement of social and economic benefits. Therefore, this work innovatively introduces DTs technology into intelligent buildings and places the Phase Change Material (PCM) in the interior building structure. Additionally, a DTs-based thermal energy storage and safety scheduling model for thermoelectric smart buildings is constructed using the PCM wall. Measurements of its effectiveness obtained through experimentation. This work provides experimental support for the rational modernization of the construction industry and contributes to the long-term health of the economy. The structure of this work is as follows. Section 1 introduces the research background, motivation, purpose, innovation, and contribution. Section 2 expounds on the research of scholars in related fields and analyzes its advantages and disadvantages, which makes the value of this research prominent. Section 3 introduces the DTs technology and designs the PCW structure of the intelligent building. On this basis, a DTs-based thermal energy storage and scheduling model is constructed for thermoelectric smart buildings. Finally, the model performance is experimentally evaluated. Section 4 comparatively compares the model constructed here with different schemes proposed by scholars in related fields. Section 5 briefly outlines the research results and explains the limitations and prospects. 2. Related work 2.1. Analysis of the application status of DTs in the field of construction DTs technology is the digital representation of a physical process, person, place, system, or device. It can promote the intelligent building to realize the information fusion and interaction between virtual space and physical space. Many scholars have conducted research on the application of DTs in architecture. Li et al. (2020) proposed a DTs-driven sustainability evaluation information architecture for the dynamic evolution of the entire life cycle in intelligent manufacturing, aimed at the challenges faced by the conventional manufacturing industry. Finally, they verified the effectiveness of the DTs dynamic information architecture and sustainability evaluation method [19]. White et al. (2021) found that the combination of increasingly large and accurate Building Information Models (BIMs) in smart cities and big data generated by IoT sensors makes a large amount of data in smart cities even more accurate and transparent. Meanwhile, a public and open DTs model makes the planning of the smart city industrialization process increasingly accurate [20]. Chen et al. (2021) proposed an embodied carbon estimation method in buildings based on DTs technology and life cycle assessment. They applied the model to automatic data communication between BIM databases. The comparative analysis result suggested that this embodied carbon estimation method outperformed others [21]. 2.2. Analysis on the current situation of research on optimal scheduling of Cooling, Heating, and power in intelligent buildings When modeling smart buildings, many scholars have studied the performance related to the optimal operation and dispatch of combined cooling, heating, and power (CCHP) microgrids and energy storage systems of a smart building. Cybersecurity concerns with running Virtual Power Plants and microgrids powered by renewable energy sources were highlighted in a study by Ravi et al. (2022). Security and operational scenarios for the new ecosystem are also outlined [22], with an emphasis on the interoperability, security, and integration of Distributed Energy Resources. Antoniadou-Plytaria et al. (2020) proposed an energy management system model for smart building microgrids based on battery energy storage. They proved that the framework could accurately estimate building operating costs and improve the overall performance of batteries as flexible resources in building microgrids through simulation [23]. Cui et al. (2020) constructed a nonlinear partial load ratio model for gas turbines, boilers, and coolers and proposed a piecewise least squares linearization method. The results showed that the optimal operation effect of optimal scheduling for different objectives is significantly better than the constant efficiency model. Besides, the choice of gas turbine, heat recovery steam generator, and electric chiller models for both models greatly impact the system operation results [24]. Ren et al. (2021) evaluated two different systems using solar energy. In system A, solar energy was converted into heat and electricity by solar thermal collectors and photovoltaic (PV) panels, respectively. Solar energy was converted into heat and electricity through PV thermal collectors in system B. It was found that when system A operates under the following electric load strategy, it can bring many benefits to the three buildings and construct a system with a configuration and component size that are closely related to the building type [25]. Dong et al. (2022) presented an optimization strategy based on robust model predictive control to deal with multiple uncertainties in source loads. Under uncertain scenarios of renewable energy generation and load consumption, the optimization model was transformed into a tractable form for robust dispatch that minimizes operating costs. The authors confirmed that under uncertain scenarios, the optimal dispatching model of their intelligent building CCHP system reduces the operating cost by 11.5% compared with the traditional model predictive control strategy [26]. Lin et al. (2022) proposed a new thermoelectric powered wireless sensor network platform for low-cost environmental sensing in building envelopes through thermoelectric energy harvesting and ultra-low power management. The result suggested that the system can offer unique and innovative advantages in terms of self-powered system architecture, thermally optimized internals, and milliwatt power management [27]. 2.3. Summarization Based on an analysis of the relevant research conducted by the aforementioned experts, it has been determined that the digital twin technology was initially applied to intelligent buildings. The research on the modeling of the medium thermal energy storage system is overly simplistic, and the thermal network's construction is not refined. In practical operation, the thermal side of the structure may pose a safety risk if it is out of control. In order to improve the building's intelligence and the stability and safety of its thermal system, this study implements digital twin technology so that the data generated by the smart building's energy storage system in the real world can be mapped to the virtual space in real time and analyzed in synchrony. More research is needed to develop and test the fine thermal network DTs model of phase-change thermal storage wall structure and thermal energy storage in intelligent buildings. This model is useful for building smart buildings and keeping the economy growing in a sustainable way. 3. DTs-based thermal energy storage system for smart buildings and its scheduling strategy security 3.1. Application of DTs technology in intelligent buildings The first task is to create a DTs model of the construction application to integrate the DTs technology with the practical construction field. This work expands the 3D model, adds two dimensions of DTs Data (DTD) and Connection (CN), and constructs a five-dimensional DTs model [28], as shown in Fig. 1. Download : Download high-res image (221KB) Download : Download full-size image Fig. 1. Energy conversion diagram for Scheme 1. The model developed during this study is referred to as scheme 1. It transfers the heat energy from the building's walls into electrical energy for power generation using a generator. The spinning reserve capacity of the wind/solar/storage grids is provided by the battery system's comprehensive utilization. Fig. 1 displays the energy conversion diagram for Scheme 1. The five-dimensional DTs model in Fig. 1 mainly includes five parts: the Physical Entity (PE), Virtual Entity (VE), Service System (SS), DTD, and CN between each part. The five elements complement each other and form the DTs of the intelligent building [29]. Ma et al. (2022) designed a DTs-driven operational mechanism and a general framework for big data cleaning and integration to explain and illustrate sustainable smart manufacturing in smart buildings [30]. In the intelligent building DTs, the PE is a physical product that the user can operate. In addition to completing the normal function output, it is necessary to collect the parameters required by the environment and the building's own operating system to drive the VE model of the information domain.; VE is the mapping of the PE and the basis for building a five-dimensional DTs model. It can characterize and describe the PE of intelligent buildings from multiple dimensions, multiple spatial scales, and multiple time scales. SS is a newly added dimension and is the main driver of the DTs model. It relies on the virtual space algorithm library, model library, database, and expert knowledge base to make decisions on the operation scenario and status of the intelligent building energy storage system to realize the scheduling of thermal network clusters [31]. DTD is the data that exists and operates according to the rules defined by the system in the DTs model. It mainly studies and analyzes the operation and data flow processing of the DTs system of intelligent buildings. CN can complete the interconnection and intercommunication between the various components. PE, VE, and SS are regarded as structural points. The topology of the DTs model of the intelligent building can be formed through the connection between the structural issues. Fig. 2 reveals the DTs model of an intelligent building based on the five-dimensional DTs system. Download : Download high-res image (268KB) Download : Download full-size image Fig. 2. Energy conversion diagram for Scheme 2. Scheme 2 combines the energy storage effect of the wall with other equipment such as wind turbines, photovoltaic panels, and battery energy storage systems and only uses the battery energy storage system as a spinning backup. Fig. 2 shows the energy conversion diagram for Scheme 2. Fig. 2 depicts the evolution of the DTs intelligent building model. First, identify the physical entity, i.e., the component of the intelligent building, and provide the pertinent physical entity specification. Second, develop a virtual entity, abstract the spatial structure of the intelligent building, and evaluate simulations using the relevant model. Third, design data; determine the data that must be collected when the smart building is in operation, as well as the equipment required for data collection. Fourth, establish a connection; clarify the connection between the physical entity and the virtual entity of the smart building, as well as the connection protocol used. Fifth, test the smart building. Sixth, validate the smart building. Fifth, realize the service aimed at the intelligent building's practical issues, enhance the traditional scheduling process, and develop a platform to present the intelligent building's DTs data. The user tests and evaluates the developed intelligent building model, makes specific improvement suggestions, and enriches and refines software requirements, such as adding vision and physical entity models, making suggestions for improving traditional scheduling algorithms, and adding other new requirements. Naturally, the developer will use this information to enhance the software until the user's approval and satisfaction are obtained, after which the software will be fully implemented, tested, and maintained. 3.2. Analysis of PCW structure material and the thermal network DTs model of intelligent buildings During the construction of the building, the materials used in the PCW structure are the basis of the thermal energy storage system. A PCM transforms its physical properties and absorbs or releases a large amount of heat as the temperature changes [32]. At present, PCMs commonly used in building materials usually exist in the form of solid–liquid mixed storage. They have the advantages of low price, high energy density, constant temperature storage, small occupied volume, and long service life and have been widely concerned by scholars in related fields. If the PCM is filled in the building, the PCM wall can be formed [33]. Liu et al. (2020) designed shape-stabilized PCMs with desirable latent enthalpies and found that these materials had satisfactory shape stability as well as excellent thermal energy management [34]. Here, the PCM is placed in the indoor building structure. The DTs technology is introduced to establish a DTs model of the PCW material and its thermal network in an intelligent building, as presented in Fig. 3. Download : Download high-res image (198KB) Download : Download full-size image Fig. 3. Energy conversion diagram for Scheme 3. In Scheme 3, the cooling or heating used by the user end adopts the conventional power grid's maximum output operation mode and only uses the microgrid battery energy storage system as a rotating backup. Fig. 3 presents the energy conversion diagram for Scheme 3. As shown in Fig. 3, the PE data of the intelligent building wall is mapped into the virtual space through DTs technology after collection. It is assumed that the three sides of the virtual wall of the intelligent building (including the PCW) face the shade, and the other side is subject to solar radiation (named wall No. 1). Besides, the convective heat exchange between the air gap of the PCM wall and the room air is enhanced by installing a forced air circulation system in the phase change wall. At the same time, the thermodynamic model takes into account the heat leakage of the PCM to the indoor and outdoor environments, which contributes to the thermal balance between the nodes of the intelligent building. In this thermal network model, solar radiation is expressed as g i ; the input variables include the ambient temperature T am t and the temperature T P t of the PCM; the controllable variable is the circulating air velocity m t ; the state variables include the indoor air temperature T R t , the PCM wall air gap air temperature T ag t , and the internal and external surface temperature of the structure T k t , k ∈ N , where N = 4 represents the number of walls. Take the cooling mode of the intelligent building thermal network in summer and the heating mode in winter as an example. According to the law of thermodynamics, the uncontrollable heat leakage of PCM at time t includes indicators such as Q Leak t , Q o - a t , Q i - p rt , Q i - a t , and Q i - p rt [35]. Q Leak t refers to the total amount of uncontrollable heat leakage from PCM to the inside and outside of the building; Q o - a t and Q i - p rt represent the heat leaked from PCM to the outer wall of the building phase change wall through conduction and radiation; Q i - a t and Q i - p rt indicate the heat leaked from PCM to the building phase change wall through conduction and radiation of the inner wall. The details are shown in Equations (1)∼(5): (1) Q Leak t = Q o - a t + Q o - p rt + Q i - a t + Q i - p rt (2) Q o - a t = h o A o T o t - T ag t (3) Q o - p rt = h o r A o T o t - T P t (4) Q i - a t = h i A i T i t - T ag t (5) Q i - p rt = h o r A i T i t - T P t In Equations (1) ∼ (5), h o , h i , h o r , and h o r represent the heat conduction and heat radiation coefficients of the PCM and the outer wall and inner wall; A o and A i refer to the contact area between the outer and inner layers of the wall and the air gap of the phase change layer, respectively; T o t and T i t denote the nodal temperature of the outer and inner walls of the PCW. The controllable heat transfer Q Ctrl t of the forced air circulation at time t is calculated as the enthalpy change difference between the air inlet and outlet of the PCW, as shown in Equation (6). (6) Q Ctrl t = m t C A T R t - T P t In Equation (6), C A indicates the specific heat capacity of air; T R t denotes the indoor air temperature; m t refers to the circulating air flow rate, which at any moment t is bounded by the maximum air flow rate m max , expressed as 0 ⩽ m t ⩽ m max . Equation (6) is a bilinear expression multiplying the controllable variable circulating air flow rate m t and the state variable room air temperature T R t . The transformation of Equation (6) is briefly discussed. If the circulating air flow rate m t ≠ 0 , the optimization of indoor air temperature T R t should be kept at the upper limit of human comfort temperature T R max under the summer cooling release mode working condition. Otherwise, the circulating air flow rate m t in the indoor circulation air can be further reduced to reduce the energy loss of the thermal energy storage system. If the circulating air flow rate mt = 0, the controlled heat transfer Q Ctrl t in Equation (6) is always 0 under any T R t [36], [37]. Therefore, the constant human comfort temperature upper limit T R max can be replaced by the variable indoor air temperature T R t . Equation (6) can be transformed into the linear formula shown in Equation (7). (7) Q Ctrl t = m t C A T R max - T P t Therefore, after the comprehensive analysis of Equations (1) ∼ (7), the total heat load P TL t of the building is expressed as the total energy of controllable heat transfer and uncontrollable heat leakage, as presented in Equation (8). (8) P TL t = Q Ctrl t + Q Leak t In addition, the thermal balance correlation of intelligent buildings can be further analyzed according to the above equations. Equation (9) indicates the PCM heat balance. (9) Q Ctrl t + Q o - a t + Q i - a t = Q a - p t In Equation (9), Q a - p t refers to the heat flow from the air gap of PCW to PCM at time t. The heat flow from the external environment to the outer PCW is equal to the heat transfer between the outer PCW and the air gap or between PCM and other building walls. Thus, the heat balance of the outer PCW can be expressed as Equation (10). (10) Q o t = Q am - o t = Q o - a t + Q o - p rt + Q o - Δ t In Equation (10), Q o t and Q am - o t refer to the heat loss of the outer PCW and the heat flow from the external environment to the outer PCW at time t, respectively; Q o - Δ t represents the heat flow from the remaining walls of the building to the outer PCW at time t. The heat exchange between the room air and the inner surface of the other walls to the phase change interior wall is equal to the heat exchange between the phase change interior wall and the air gap, PCM, and the inner surface of the other walls. Hence, the heat balance of the inner PCW can be written as Equation (11). (11) Q R - i t + ∑ j = 1 N Q j - i rt = Q i - a t + Q i - p rt + Q i - Δ t In Equation (11), Q i - Δ t signifies the heat flow from the rest of the building walls to the inner PCW at time t; Q j - i rt refers to the heat flow of the envelope j to the inner PCW at time t, Q R - i t denotes the heat flow from the room air to the inner PCW at time t. Equations (12) ∼ (14) express the heat balance of each wall of the building [38]. (12) Q k t = Q am - k t + Q am - k rt + Q Δ - k t k = 2 (13) Q k t = Q am - k t + Q Δ - k t k ≠ 2 , k ∈ N (14) Q k t = Q k - R t + ∑ j = 1 , j ≠ k N Q k - j t k ∈ N Equations (12), (13) represent the thermal balance relationship between each building wall and the outside world. Equation (14) indicates the thermal balance relationship between each building wall and indoor air and other walls. Q k t refers to the heat loss of the enclosure structure k at time t; Q Δ - k t represents the heat flow from the remaining walls of the building to the enclosure structure k at time t; Q am - k t denotes the radiation heat transfer from the external environment to the enclosure structure k at time t; Q k - R t signifies the heat flow from the enclosure structure k to the room at time t; Q k - j t stands for the heat flow from the envelope structure k to the envelope structure j at time t. The heat exchange of the solar radiation wall (Wall 1) of the building is marked as Q am - k rt , as shown in Equation (15). (15) Q am - k rt = α sw g t k = 2 In Equation (15), α sw refers to the radiation heat transfer coefficient. The heat exchange from room air to the PCM and the inner PCW is equal to the heat exchange between the other walls except for the PCW and the room air. That is, the heat balance can be expressed as Equation (16). (16) Q Ctrl t + Q R - i t = ∑ k = 1 N Q k - R t This work investigates the pertinent theories of phase change materials and explains the thermodynamic content of phase change materials when applied to intelligent buildings. The findings provide the foundation for the following thermodynamic energy storage and dispatching models for intelligent buildings. 3.3. Analysis of the thermal energy storage and dispatch model based on DTs of intelligent buildings Because the building has a certain heat capacity, when the thermal power changes, the indoor temperature changes relatively lag, but the human body has a certain range of comfortable temperatures. The energy storage characteristics of PCMs can meet the indoor cooling/heating needs of buildings. Fig. 4 displays the thermal energy storage and scheduling model for smart buildings based on DTs technology. Download : Download high-res image (296KB) Download : Download full-size image Fig. 4. Thermal energy storage and dispatching model based on DTs for intelligent buildings. In Fig. 4, the physical space is a complex, dynamic architectural environment consisting of the data collection layer, the data analysis layer, and the network perception layer. The five major elements of the data collection layer are construction personnel, mechanical equipment, materials, work methods, and the environment. It collects the most original data sources related to intelligent buildings. Then, the data analysis layer processes the acquired data sources to form economic cost data, environmental cost data, energy cost data, and construction safety data, respectively. The model transmits the multi-source heterogeneous data obtained from the analysis and processing layers to the virtual space and simultaneously receives instructions from the virtual space, and reacts accordingly. The network perception layer is responsible for the perception and collection of data and the transmission of data to the virtual space. The model uploads real-time data of construction activities into the virtual space by establishing a set of standard data interfaces and communication protocols in the network module to achieve uniform conversion and transmission of data from different sources. The thermal energy storage and distribution of intelligent buildings in this model rely heavily on PCM phase change walls. There is no need to transform light energy and local scattered energy into heat energy for building walls when generating electricity. The thermal energy of the building wall is converted into electrical energy for the user end by the generator, and the battery system provides the rotating reserve capacity for the wind/solar/storage grid. Following is a description of the relevant thermal energy scheduling mechanism involved. Here, Q d refers to the heat dissipation power of the building (kW); T out represents the outdoor temperature (℃); T in signifies the indoor temperature (℃); C A refers to the specific heat capacity of the air, and the unit is kJ/(kg·K). From the two working conditions of heating in winter and cooling in summer, the relationship between the heat inside and outside the building and the temperature is expressed as Equations (17), (18). (17) Q H - Q d = C A × ρ × V × d T out - T in dt (18) Q d - Q AC = C A × ρ × V × d T in - T out dt Equations (17), (18) represent the two working conditions of heating in winter and cooling in summer, respectively. ρ stands for the air density (kg/m 3); Q H refers to the heating power in winter (kW); Q AC signifies the cooling power (kW) in summer; V refers to the volume capacity of the building. Assume that the heat dissipation power of the building is unchanged during the heat release and heat storage process. Then, the maximum charge and discharge energy E max (kW) provided by the building energy storage can be expressed as Equation (19). (19) E max = ∫ t max t min Q H - Q d d t = 2.7778 × 10 - 4 C A ρ V T in | T max T min The indoor temperature of a building is a response to a combination of factors, such as outdoor temperature, solar radiation, and indoor heat sources. To simplify the calculation, the external wall of the building is conducted as one-dimensional heat output according to the relevant thermodynamic knowledge. According to the law of energy conservation, the heat balance of the indoor temperature node is established as Equation (20). (20) C A ρ V d T in d τ = h in A w T out - T in + Q cov + Q c + Q in + C A ρ V N V / 3600 + k win A win T out - T in In Equation (20), h in refers to the convective heat transfer coefficient of the interior wall surface; A w denotes the surface area of the external wall; k win stands for the thermal conductivity of the window; A win refers to the area of the window; d τ stands for the interval time period; Q cov represents the convective heat transfer of the indoor heat source; N V refers to the number of air changes; Q c indicates the solar heat gained through windows; Q in refers to the indoor heat source radiating heat. Further, the multiobjective operation optimization modeling is carried out on the thermal energy storage and scheduling model of intelligent buildings. Its objective function is analyzed in terms of economic cost, environmental cost, and energy cost, respectively. The financial cost mainly includes the fuel cost of power generation by the system, the power purchase cost of the system from the grid, and the cost of equipment maintenance. The fuel cost F fluel generated by the consumption of natural gas by the micro gas turbine is calculated according to Equation (21). (21) F fluel = C gas V gas In Equation (21), C gas refers to the unit price of natural gas, and V gas represents the unit volume of natural gas. The power purchase cost F pur of the system is expressed as Equation (22). (22) F pur = C b t ∑ t T P grid t Δ t - ∑ t = 1 T C c t P excess t Δ t In Equation (22), T refers to a dispatch cycle; P grid t represents the power purchased from the microgrid to the grid in the t period; P excess t stands for the power sold by the microgrid to the grid in the t period (kW); C b t refers to the electricity purchase price in the t period; C c t signifies the point-of-sale electricity price from the microgrid to the larger grid in period t. The maintenance cost F om of the system can be expressed as Equation (23). (23) F om = P WT t C WT , o m + P PV t C PV , o m + P bt t · C bt , o m + P MT t C MT , o m + P WH t C WH , o m + γ MT P MT t C AC , o m In Equation (23), P WT t , P PV t , and P bt t refer to the fan output, PV output, and battery charge and discharge power, respectively (positive when charging and negative when discharging); C WT , o m , C PV , o m , C bt , o m C MT , o m , C WH , o m , and C AC , o m represent the maintenance costs of fans, PVs, batteries, micro gas turbines, waste heat boilers, and absorption chillers, respectively. Therefore, the minimum objective function of economic cost is written as Equation (24). (24) min f 1 = F fluel + F pur + F om Environmental costs mainly consider carbon dioxide emissions. The system uses natural gas as fuel. The combustion of natural gas produces carbon dioxide and water. The power purchased by the system from the grid is also derived from the electricity generated by thermal power plants, which also produce carbon dioxide. Thus, the environmental cost is represented by the carbon dioxide conversion coefficient [39]. The objective function for the minimum carbon dioxide emission of the system is: (25) min f 2 = k f ∑ t T P MT t η c L gas + k g ∑ t T P grid t where k f and k g refer to the carbon dioxide conversion coefficient of natural gas and electric energy, respectively. Energy cost is the amount of energy consumed. As primary energy, natural gas belongs to non-renewable energy. Now, fossil energy has been exhausted day by day [40], [41]. The objective function for minimizing energy consumption and energy waste is written as Equation (26). (26) min f 3 = ∑ t T C t + ∑ t T H t + ∑ t T E t In Equation (26), C t refers to the daily cooling capacity of the microgrid in the smart building thermal energy storage and dispatch model; H t represents the daily heat supply produced by the microgrid in the model; E t denotes the daily power generation of the microgrid in the system. 3.4. Experimental performance evaluation A case study is performed to verify the feasibility and effectiveness of the proposed thermal energy storage and scheduling model based on DTs of smart buildings. This section selects a typical photovoltaic-integrated smart building group as the research object. The specific environment and parameter settings are as follows. The total installed capacity of rooftop photovoltaics in the smart building group is 1500 kW, and the total number of rooms equipped with phase-change material energy storage systems is 400. The size of the room is 4500 × 4500 × 3400 mm, and the mass of phase change material configured on the wall of each room is 600 kg. A 3 kW heat pump and a circulation fan with a maximum air velocity of 5 kg/s are installed. In this experiment, the hardware and software configurations are as follows. In the software, the operating system is Linux 64bit, the Python version is Python 3.6.1, and the development platform is PyCharm; in the hardware, the CPU is an Intel core i7-7700@4. 2 GHz 8-core, the memory is Kingston ddr4 2400 MHz 16G, and the GPU is an Nvidia GeForce 1060 8G. For the sake of focus and hypothesis analysis, this work assumes that all rooms have the same comfort temperature interval and uses a centralized control strategy of the energy management system. The energy dispatch center sends dispatching commands to the building thermal energy storage system in each house to control the heat pump power and circulating air flow rate of the building thermal energy storage system in each house. The model developed during this study is referred to as scheme 1. It transfers the heat energy from the building's walls into electrical energy for power generation using a generator. The spinning reserve capacity of the wind/solar/storage grids is provided by the battery system's comprehensive utilization. As evidence of the superiority of the proposed technique, the following two plans are presented for comparison. Scheme 2 combines the energy storage effect of the wall with other equipment such as wind turbines, photovoltaic panels, and battery energy storage systems and only uses the battery energy storage system as a spinning backup. In Scheme 3, the cooling or heating used by the user end adopts the conventional power grid's maximum output operation mode and only uses the microgrid battery energy storage system as a rotating backup. 4. Results and discussion 4.1. System optimization power under different schemes Fig. 5 compares the three schemes mentioned above to explore the optimal power of the system. In Fig. 5, the power station output represents the electric energy generated by the microgrid power station; the battery output represents the electric energy generated by the microgrid battery energy storage system; the net load power is the sum of the power station output and the battery output power. Download : Download high-res image (325KB) Download : Download full-size image Fig. 5. Optimized power distribution of the system under different schemes (a. Scheme 1; b. Scheme 2; c. Scheme 3). It can be seen from Fig. 5 that under the three schemes, the net load is negative from 1:00 to 4:00; the output of wind power and PVs is greater than the conventional grid load. Scheme 3 adopts the maximum output operation mode to maintain a high output; Scheme 1 and Scheme 2 consider the dynamic energy storage characteristics of the building wall energy storage, avoiding battery overcharge to dissipate a large amount of surplus renewable energy and consuming less. At 21:00, when the net load is in the peak period, the wind power and PV output cannot meet the normal load demand. Users of Scheme 1 and Scheme 2 need to purchase electricity from the power station to run at close to full power generation power, avoiding the need for the battery to meet a large number of loads. It can effectively reduce the peak-to-valley difference of the equivalent load of the microgrid and play the role of shifting peaks and filling valleys. The above analysis demonstrates that the scheduling and operation strategy of the building wall energy storage with dynamic energy storage characteristics is considered in this scheme with a great degree of flexibility. It can avoid the overcharge or over-discharge of the battery in the microgrid, reduce the power consumption of the battery, and extend the service life of the battery to a certain extent. Fig. 6 reveals the deterministic dispatch under the conditions of electricity-thermal uncertainty under the three scenarios, deterministic dispatch power consumption and day-ahead sale and purchase power of sea island microgrid PV power, heat pump power of the building energy storage system, and energy storage capacity of PCW. Download : Download high-res image (264KB) Download : Download full-size image Fig. 6. Deterministic dispatching power consumption and day-ahead power consumption under different schemes (a. Scheme 2; b. Scheme 3; c. Scheme 1). According to Fig. 6, under different schemes, the PV power generation is not enough to meet the user's electricity demand during the period of 1:00–6:00, 13:00–14:00, and 19:00–24:00 every day. Therefore, smart building micro-grid users meet the demand for conventional electrical loads by purchasing the right amount of electricity from the grid. Then, the remaining electricity is converted into thermal energy by the heat pump and delivered to the building phase change energy storage system to meet the heat demand of island residents. During the hours of 7:00–13:00 and 15:00–18:00 when the PV power is generated, the island intelligent building micro-grid does not purchase electricity from outside or sell electricity in small amounts at a fixed price. Moreover, the surplus electricity of the island micro-grid is converted into thermal energy of the building phase change energy storage system for storage. Besides, the energy is released through the phase change material and forced air circulation system in the intelligent building to directly meet the thermal demand of the island residents. Scheme 1 can convert the thermal energy of the building wall into electric energy for the user end through the generator and comprehensively utilize the battery system to provide the rotating reserve capacity of the wind/solar/storage grid. Therefore, the power purchase required in Scheme 1 is significantly less than that in Scheme 2 and Scheme 3, while the electricity sold is obviously larger than that in Scheme 2 and Scheme 3. In addition, the analysis of the PCW energy storage system for intelligent buildings in the three schemes indicates that the capacity of Scheme 1 is always in the range of 0.2 ∼ 0.8 on the all-weather scale; the capacities of Scheme 2 and Scheme 3 are smaller than Scheme 1. The result suggests that the DTs-based intelligent building thermal energy storage and dispatching model constructed here has no thermal energy loss exhaustion or inflow overflow and realizes long-term peak-shaving and valley-filling of large power grid loads. The PV-integrated buildings reported here are compared with traditional residential buildings and office buildings in terms of electrical load and indoor heat source values, as shown in Fig. 7. Download : Download high-res image (233KB) Download : Download full-size image Fig. 7. Comparison results of electrical load and indoor heat source value of different types of buildings (a. electric load; b. indoor heat source value). Fig. 7 compares the electrical load and indoor heat source values for different types of buildings. It can be seen from the Fig. 7 that the electric load value consumed by office buildings is the largest and the indoor heat source value is higher. The photovoltaic integrated buildings constructed in this study can have a higher indoor heat source while maintaining a lower electrical load value. Therefore, the PV-integrated buildings constructed here have a better wall energy storage effect and lower power consumption compared with residential and office buildings. 4.2. Cost consumption under different schemes The thermal energy storage and dispatch model of smart buildings based on DTs reported here is compared with the models proposed by Antoniadou-Plytaria et al. (2020), Cui et al. (2020), Ren et al. (2021), and Dong et al. (2022) The algorithm under different risk indicators (0, 0.05, 0.1, 0.15, 0.2) from the perspectives of economic cost, environmental cost, and energy cost. Fig. 8 provides the results. Download : Download high-res image (582KB) Download : Download full-size image Fig. 8. Results of economic cost, environmental cost, and energy cost with the increase of risk indicators under different models (a. economic cost; b. environmental cost; c. energy cost). Fig. 8a shows that with the increase of risk indicators, the economic cost required by each model algorithm increases sequentially, and the cost required by the model reported here is significantly lower than that of other model algorithms. In Fig. 8b, as the risk index increases, the environmental cost required by each model algorithm increases sequentially. The cost of the research model is significantly lower than other model algorithms. In Fig. 8c, as the risk index increases, the energy cost required by each model algorithm increases sequentially. The cost of the research model is significantly lower than other model algorithms. The model reported here achieves functional regulation and reduces the consumption of economic costs, environmental costs, and energy costs. Therefore, the thermal energy storage and dispatching model of intelligent buildings based on DTs constructed here can enhance the energy storage effects of buildings, cut down economic costs, environmental costs, and energy costs, and enhance safety performance. 5. Discussion The comparability and verification of the smart building thermal energy storage and dispatching model based on DTs' viability and efficiency. First, three schemes were used to conduct a system-optimized power analysis. It was discovered that the thermal energy dispatching mechanism described in this study can extend the battery's service life to some degree. Simultaneously, analyses of the deterministic scheduling power consumption and day-ahead trading power under distinct strategies. The DTs-based intelligent building thermal energy storage and scheduling model developed here lacks both thermal energy loss exhaustion and inflow overflow. This may be because this research model avoids over-discharge of the battery to meet a large number of load demands, which can effectively reduce the peak-to-valley difference of the equivalent load of the microgrid and play the role of shifting peaks and filling valleys to realize long-term maintenance of large power grid loads. This is consistent with the views put forward by Pekárová et al. (2022) [42] and Zhao et al. (2022) [43]. This work is compared with the research of scholars in related fields in terms of economic cost, environmental cost, and energy cost. It can be found that with the increase of risk indicators, the economic cost, environmental cost, and energy cost required by each model algorithm increase in turn. And, the cost of the model reported here is significantly lower than other model algorithms. This may be because DTs technology can digitally interact with the construction status and information of the building complex when building photovoltaic integrated buildings, make quick decisions about problems that come up during construction and the operating status of equipment and components, and then control functions. This is consistent with the view put forward by Odukomaiya et al. (2021) [44]. Finally, it shows that the thermal energy storage and scheduling model of intelligent building based on DTs built here can provide experimental basis and development direction for the intelligent development and sustainable economic development in the follow-up construction field. 6. Conclusion In the era of rapid development of information technology, the construction sector is also developing in the intellectual direction. The innovation and contribution of this work lie in the incorporation of DTs technology into the design of intelligent buildings so that the data generated by the energy storage systems of intelligent buildings in the real world can be mapped to the virtual world for simultaneous analysis in real time. Simultaneously, the PCM wall construction and thermal energy storage and distribution model of the thermoelectric intelligent building are built. When power generation is required, the thermal energy scheduling mode used here transfers building wall thermal energy through a generator into electrical energy for user-end usage. Experimental evaluations show that the energy storage capacity of building walls consistently remains in the range of 0.2 ∼ 0.8 on an all-weather scale. From the perspective of cost consumption, the economic cost, environmental cost, and energy cost of the model reported are significantly lower than the existing model. This work contributes to the subsequent intelligent development of the building field and sustainable economic development. However, there are some deficiencies in this work. For the convenience of modeling and calculation, this work did not consider the impact of numerous other secondary factors, such as temperature fluctuations in the environment, PV cell temperature variations, and wind speed, on building wall energy storage scheduling. Therefore, follow-up research will improve the environmental factors and uncertainties in the building construction process to explore the effect of the robust dispatching strategy of the building microgrid. In addition, different residents' preferences for temperature were not taken into account. It is also an added factor in the improvement of the energy storage system of the subsequent intelligent building to put the system into practice against time. CRediT authorship contribution statement Zhihan Lv: Conceptualization, Methodology, Writing – original draft, Writing – review & editing. Chen Cheng: Methodology, Software, Investigation, Writing – original draft. Haibin Lv: Writing – original draft, Writing – review & editing, Supervision. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Data availability The authors do not have permission to share data. References [1] C. Cheng, J. Dou, Z. Zheng Energy-efficient SDN for Internet of Things in smart city Internet of Things and Cyber-Physical Systems, 2 (2022), pp. 145-158 View PDFView articleView in ScopusGoogle Scholar [2] S.I. Hussain, S. Kalaiselvam Nanoencapsulation of oleic acid phase change material with Ag2O nanoparticles-based urea formaldehyde shell for building thermal energy storage J Therm Anal Calorim, 140 (1) (2020), pp. 133-147 CrossRefView in ScopusGoogle Scholar [3] B. Maleki, A. Khadang, H. Maddah, M. Alizadeh, A. Kazemian, H.M. Ali Development and thermal performance of nanoencapsulated PCM/plaster wallboard for thermal energy storage in buildings J Build Eng, 32 (2020), Article 101727 View PDFView articleView in ScopusGoogle Scholar [4] S.O. Abioye, L.O. Oyedele, L. Akanbi, A. Ajayi, J.M.D. Delgado, M. Bilal, et al. Artificial intelligence in the construction industry: A review of present status, opportunities and future challenges J Build Eng, 44 (2021), Article 103299 View PDFView articleView in ScopusGoogle Scholar [5] Xiong Y, Song C, Ren J, Jin Y, Nie B, Xu Q, et al., Sludge-incinerated ash based shape-stable phase change composites for heavy metal fixation and building thermal energy storage. Process Safety Environ Protect; 2022, 162, 346-356. Google Scholar [6] Z. Jiang, M.E.N. Rivero, X. Liu, X. She, Y. Xuan, Y. Ding A novel composite phase change material for medium temperature thermal energy storage manufactured with a scalable continuous hot-melt extrusion method Appl Energy, 303 (2021), Article 117591 View PDFView articleView in ScopusGoogle Scholar [7] W. Wang, X. He, Y. Shuai, J. Qiu, Y. Hou, Q. Pan Experimental study on thermal performance of a novel medium-high temperature packed-bed latent heat storage system containing binary nitrate Appl Energy, 309 (2022), Article 118433 View PDFView articleView in ScopusGoogle Scholar [8] S. Yang, J. Tan, B. Chen Robust spike-based continual meta-learning improved by restricted minimum error entropy criterion Entropy, 24 (4) (2022), p. 455 Google Scholar [9] S. Yang, B. Linares-Barranco, B. Chen Heterogeneous ensemble-based spike-driven few-shot online learning Front Neurosci, 16 (2022), Article 850932 View in ScopusGoogle Scholar [10] S. Yang, T. Gao, J. Wang, B. Deng, M.R. Azghadi, T. Lei, et al. SAM: a unified self-adaptive multicompartmental spiking neuron model for learning with working memory Front Neurosci, 16 (2022), Article 850945 View in ScopusGoogle Scholar [11] G. Krishna, R. Singh, A. Gehlot, S.V. Akram, N. Priyadarshi, B. Twala Digital Technology Implementation in Battery-Management Systems for Sustainable Energy Storage: Review, Challenges, and Recommendations Electronics, 11 (17) (2022), p. 2695 CrossRefView in ScopusGoogle Scholar [12] J. Henzel, Ł. Wróbel, M. Fice, M. Sikora Energy consumption forecasting for the digital-twin model of the building Energies, 15 (12) (2022), p. 4318 CrossRefView in ScopusGoogle Scholar [13] S. Agostinelli, F. Cumo, G. Guidi, C. Tomazzoli Cyber-physical systems improving building energy management: Digital twin and artificial intelligence Energies, 14 (8) (2021), p. 2338 CrossRefView in ScopusGoogle Scholar [14] Z. Lv, J. Guo, A.K. Singh, H. Lv Digital Twins Based VR Simulation for Accident Prevention of Intelligent Vehicle IEEE Trans Veh Technol, 71 (4) (2022), pp. 3414-3428 CrossRefView in ScopusGoogle Scholar [15] Coelho L, Koukou MK, Dogkas G, Konstantaras J, Vrachopoulos MG, Rebola A, et al., Latent thermal energy storage application in a residential building at a mediterranean climate. Energies; 2022. 15(3), 1008. Google Scholar [16] S. Swaminathan, G.S. Pavlak, J. Freihaut Sizing and dispatch of an islanded microgrid with energy flexible buildings Appl Energy, 276 (2020), Article 115355 View PDFView articleView in ScopusGoogle Scholar [17] R.M. Ramli, W.A. Jabbar Design and implementation of solar-powered with IoT-Enabled portable irrigation system Internet of Things and Cyber-Physical Systems, 2 (2022), pp. 212-225 View PDFView articleView in ScopusGoogle Scholar [18] B. Yang, Z. Lv, F. Wang Digital Twins for Intelligent Green Buildings Buildings, 12 (6) (2022), p. 856 CrossRefView in ScopusGoogle Scholar [19] L. Li, T. Qu, Y. Liu, R.Y. Zhong, G. Xu, H. Sun, et al. Sustainability Assessment of Intelligent Manufacturing Supported by Digital Twin IEEE Access, 8 (2020), pp. 174988-175008 CrossRefView in ScopusGoogle Scholar [20] G. White, A. Zink, L. Codecá, S. Clarke A digital twin smart city for citizen feedback Cities, 110 (2021), Article 103064 View PDFView articleView in ScopusGoogle Scholar [21] C. Chen, Z. Zhao, J. Xiao, R. Tiong A conceptual framework for estimating building embodied carbon based on digital twin technology and life cycle assessment Sustainability, 13 (24) (2021), p. 13875 CrossRefView in ScopusGoogle Scholar [22] R.S. Ravi, A. Jolfaei, D. Tripathy, M. Ali Secured energy ecosystems under Distributed Energy Resources penetration Internet of Things and Cyber-Physical Systems, 2 (2022), pp. 194-202 View PDFView articleView in ScopusGoogle Scholar [23] K. Antoniadou-Plytaria, D. Steen, O. Carlson, M.A.F. Ghazvini Market-Based Energy Management Model of a Building Microgrid Considering Battery Degradation IEEE Trans Smart Grid, 12 (2) (2020), pp. 1794-1804 Google Scholar [24] Q. Cui, P. Ma, L. Huang, J. Shu, J. Luv, L. Lu Effect of device models on the multiobjective optimal operation of CCHP microgrids considering shiftable loads Appl Energy, 275 (2020), Article 115369 View PDFView articleView in ScopusGoogle Scholar [25] F. Ren, Z. Wei, X. Zhai Multiobjective optimization and evaluation of hybrid CCHP systems for different building types Energy, 215 (2021), Article 119096 View PDFView articleView in ScopusGoogle Scholar [26] X. Dong, C. Zhang, B. Sun Optimization strategy based on robust model predictive control for RES-CCHP system under multiple uncertainties Appl Energy, 325 (2022), Article 119707 View PDFView articleView in ScopusGoogle Scholar [27] Q. Lin, Y.C. Chen, F. Chen, T. DeGanyar, H. Yin Design and experiments of a thermoelectric-powered wireless sensor network platform for smart building envelope Appl Energy, 305 (2022), Article 117791 View PDFView articleView in ScopusGoogle Scholar [28] Y. Zou, R. Li, X. Zhang, J. Song Five-dimensional model research of complex product assembly driven by digital twin Int J Wirel Mob Comput, 21 (3) (2021), pp. 198-206 CrossRefView in ScopusGoogle Scholar [29] K. Shen, L. Ding, C.C. Wang Development of a Framework to Support Whole-Life-Cycle Net-Zero-Carbon Buildings through Integration of Building Information Modelling and Digital Twins Buildings, 12 (10) (2022), p. 1747 CrossRefView in ScopusGoogle Scholar [30] S. Ma, W. Ding, Y. Liu, S. Ren, H. Yang Digital twin and big data-driven sustainable smart manufacturing based on information management systems for energy-intensive industries Appl Energy, 326 (2022), Article 119986 View PDFView articleView in ScopusGoogle Scholar [31] B. Teisserenc, S. Sepasgozar Adoption of blockchain technology through digital twins in the construction industry 4.0: A pestels approach Buildings, 11 (12) (2021), p. 670 CrossRefView in ScopusGoogle Scholar [32] M. Nazari Sam, A. Caggiano, C. Mankel, E. Koenders A comparative study on the thermal energy storage performance of bio-based and paraffin-based PCMs using DSC procedures Materials, 13 (7) (2020), p. 1705 CrossRefGoogle Scholar [33] A. Abderrahmane, N.A. Qasem, A. Mourad, M. Al-Khaleel, Z. Said, K. Guedri, et al. Enhancing the melting process of shell-and-tube PCM thermal energy storage unit using modified tube design Nanomaterials, 12 (17) (2022), p. 3078 CrossRefView in ScopusGoogle Scholar [34] L. Liu, X. Fan, Y. Zhang, S. Zhang, W. Wang, X. Jin, et al. Novel bio-based phase change materials with high enthalpy for thermal energy storage Appl Energy, 268 (2020), Article 114979 View PDFView articleView in ScopusGoogle Scholar [35] D. Vérez, E. Borri, A. Crespo, B.D. Mselle, Á. de Gracia, G. Zsembinszki, et al. Experimental Study on Two PCM Macro-Encapsulation Designs in a Thermal Energy Storage Tank Appl Sci, 11 (13) (2021), p. 6171 CrossRefView in ScopusGoogle Scholar [36] S. Zhang, D. Feng, L. Shi, L. Wang, Y. Jin, L. Tian, et al. A review of phase change heat transfer in shape-stabilized phase change materials (ss-PCMs) based on porous supports for thermal energy storage Renew Sustain Energy Rev, 135 (2021), Article 110127 View PDFView articleView in ScopusGoogle Scholar [37] A. Abderrahmane, O. Younis, M. Al-Khaleel, H. Laidoudi, N. Akkurt, K. Guedri, et al. 2D MHD mixed convection in a zigzag trapezoidal thermal energy storage system using NEPCM Nanomaterials, 12 (19) (2022), p. 3270 CrossRefView in ScopusGoogle Scholar [38] G. Chiriac, D.D. Lucache, C. Nițucă, A. Dragomir, S. Ramakrishna Electric bus indoor heat balance in cold weather Appl Sci, 11 (24) (2021), p. 11761 CrossRefView in ScopusGoogle Scholar [39] C. Kim, M.C. Dinh, H.J. Sung, K.H. Kim, J.H. Choi, L. Graber, et al. Design, implementation, and evaluation of an output prediction model of the 10 MW floating offshore wind turbine for a digital twin Energies, 15 (17) (2022), p. 6329 CrossRefView in ScopusGoogle Scholar [40] D. Popescu, M. Dragomir, S. Popescu, D. Dragomir Building Better digital twins for production systems by incorporating environmental related functions—literature analysis and determining alternatives Appl Sci, 12 (17) (2022), p. 8657 CrossRefView in ScopusGoogle Scholar [41] F.J. Folgado, I. González, A.J. Calderón PEM electrolyser digital twin embedded within MATLAB-based graphical user interface Eng Proc, 19 (1) (2022), p. 21 CrossRefView in ScopusGoogle Scholar [42] P. Pekárová, A. Tall, J. Pekár, J. Vitková, P. Miklánek Groundwater temperature modelling at the water table with a simple heat conduction model Hydrology, 9 (10) (2022), p. 185 CrossRefView in ScopusGoogle Scholar [43] Z. Zhao, J. Nan, M. Li Thermal management of serpentine flexible heater based on the orthotropic heat conduction model Micromachines, 13 (4) (2022), p. 622 CrossRefView in ScopusGoogle Scholar [44] A. Odukomaiya, J. Woods, N. James, S. Kaur, K.R. Gluesenkamp, N. Kumar, et al. Addressing energy storage needs at lower cost via on-site thermal energy storage in buildings Energ Environ Sci, 14 (10) (2021), pp. 5315-5329 CrossRefView in ScopusGoogle Scholar Cited by (7) Disodium hydrogen phosphate dodecahydrate/fumed silica composites with high latent heat and suitable phase change temperature for use in building roof 2024, Journal of Energy Storage Show abstract Digitalization in response to carbon neutrality: Mechanisms, effects and prospects 2024, Renewable and Sustainable Energy Reviews Show abstract Developing an integrative framework for digital twin applications in the building construction industry: A systematic literature review 2024, Advanced Engineering Informatics Show abstract Enabling coordination in energy communities: A Digital Twin model 2024, Energy Policy Show abstract A super-real-time three-dimension computing method of digital twins in space nuclear power 2023, Computer Methods in Applied Mechanics and Engineering Show abstract Literature review of digital twin technologies for civil infrastructure 2023, Journal of Infrastructure Intelligence and Resilience Show abstract View all citing articles on Scopus © 2023 The Author(s). Published by Elsevier Ltd. Part of special issue Utilization of energy storage in buildings Edited by Xiaohu Yang, Kamel Hooman, Sandra Boetcher, Jinyue Yan, Zhibin Yu View special issue Recommended articles A fuzzy-set-based joint distribution adaptation method for regression and its application to online damage quantification for structural digital twin Mechanical Systems and Signal Processing, Volume 191, 2023, Article 110164 Xuan Zhou, …, Leiting Dong View PDF A novel predictive control based management strategy considering smart PHEV in digital twin simulation Solar Energy, Volume 252, 2023, pp. 291-308 Jinsong Zhan, …, Wei Hu View PDF Underactuated digital twin's robotic hands with tactile sensing capabilities for well-being Digital Twin for Healthcare, 2023, pp. 15-38 Mohd Faisal, …, Abdulmotaleb El Saddik Show 3 more articles Article Metrics Citations Citation Indexes: 6 Captures Readers: 66 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply.

Paper 2:
- APA Citation: 
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: \"Real-world\" data collected from 201 college students using wearable sensors and mobile phones during a 1-month period was analyzed to examine the effectiveness of features derived from these data sources for identifying self-reported stress and poor mental health.
  Extract 2: \"Wearable sensor features\", including skin conductance and temperature, reached 78.3% (148/189) accuracy for classifying students into high or low stress groups and 87% (41/47) accuracy for classifying high or low mental health groups. \"Modifiable behavior features\", including number of naps, studying duration, calls, mobility patterns, and phone-screen-on time, reached 73.5% (139/189) accuracy for stress classification and 79% (37/47) accuracy for mental health classification.
  Limitations: 1. Selection of a feature as discriminating between two categories does not mean it is an important feature or causative of that behavior.
2. These results do not tell us the causality (eg, does a student sleep later and less regularly because of higher stress or have higher stress because of later or more irregular sleep?).
3. Our participants were limited to Android phone users because we wanted to log detailed phone usage, which is not allowed by other phone systems such as iPhone. As about half of the undergraduate students were Android users on the campus, a selection bias might exist. A previous study showed slight differences in personality types and economic status between iPhone users and Android users.
4. A total of 64% of our study population were male participants. It has been reported that females report higher perceived stress levels and more depressive symptoms, and there are gender differences in psychological and biological stress responses. In our dataset, the ratios of female participants in the high or low PSS and MCS groups were 45% and 20% (high and low PSS) and 22% and 54% (high and low MCS). Modeling stress and mental health differently in males and females might help understand the mechanism.
5. Our data come from college students at one New England university over 4 years. The work needs to be applied to other populations to determine generalizability.
6. Our data come from socially connected student groups. We might observe some statistically coherent behaviors in our dataset because of these connections.
  Relevance Evaluation: 4
  Relevance Score: 1.0
  Inline Citation: Sano et al, 2018
  Explanation: The paper presents a study that investigated the use of wearable sensors and mobile phones for self-reporting stress and mental health. The abstract states that physiological sensor data, phone usage data, and self-reported survey responses were collected from 201 participants over a month. The authors found that sensor features (e.g., skin conductance and skin temperature) showed better classification performance than phone features (e.g., call duration and frequency). Modifiable behavior features (e.g., number of naps and studying duration) also contributed to the classification of self-reported stress and mental health.

 Full Text: >
Original Paper
Identifying Objective Physiological Markers and Modifiable
Behaviors for Self-Reported Stress and Mental Health Status
Using Wearable Sensors and Mobile Phones:Observational Study
Akane Sano1, PhD; Sara Taylor1, MS; Andrew W McHill2,3, PhD; Andrew JK Phillips2,3, PhD; Laura K Barger2,3,
PhD; Elizabeth Klerman2,3, PhD, MD; Rosalind Picard1, ScD
1Affective Computing Group, Media Lab, Massachusetts Institute of Technology, Cambridge, MA, United States
2Brigham and Women’s Hospital, Boston, MA, United States
3Harvard Medical School, Boston, MA, United States
Corresponding Author:
Akane Sano, PhD
Affective Computing Group
Media Lab
Massachusetts Institute of Technology
75 Amherst Street
Cambridge, MA, 02139
United States
Phone: 1 6178999468
Email: akanes@media.mit.edu
Abstract
Background: Wearable and mobile devices that capture multimodal data have the potential to identify risk factors for high
stress and poor mental health and to provide information to improve health and well-being.
Objective: We developed new tools that provide objective physiological and behavioral measures using wearable sensors and
mobile phones, together with methods that improve their data integrity. The aim of this study was to examine, using machine
learning, how accurately these measures could identify conditions of self-reported high stress and poor mental health and which
of the underlying modalities and measures were most accurate in identifying those conditions.
Methods: We designed and conducted the 1-month SNAPSHOT study that investigated how daily behaviors and social networks
influence self-reported stress, mood, and other health or well-being-related factors. We collected over 145,000 hours of data from
201 college students (age: 18-25 years, male:female=1.8:1) at one university, all recruited within self-identified social groups.
Each student filled out standardized pre- and postquestionnaires on stress and mental health; during the month, each student
completed twice-daily electronic diaries (e-diaries), wore two wrist-based sensors that recorded continuous physical activity and
autonomic physiology, and installed an app on their mobile phone that recorded phone usage and geolocation patterns. We
developed tools to make data collection more efficient, including data-check systems for sensor and mobile phone data and an
e-diary administrative module for study investigators to locate possible errors in the e-diaries and communicate with participants
to correct their entries promptly, which reduced the time taken to clean e-diary data by 69%. We constructed features and applied
machine learning to the multimodal data to identify factors associated with self-reported poststudy stress and mental health,
including behaviors that can be possibly modified by the individual to improve these measures.
Results: We identified the physiological sensor, phone, mobility, and modifiable behavior features that were best predictors
for stress and mental health classification. In general, wearable sensor features showed better classification performance than
mobile phone or modifiable behavior features. Wearable sensor features, including skin conductance and temperature, reached
78.3% (148/189) accuracy for classifying students into high or low stress groups and 87% (41/47) accuracy for classifying high
or low mental health groups. Modifiable behavior features, including number of naps, studying duration, calls, mobility patterns,
and phone-screen-on time, reached 73.5% (139/189) accuracy for stress classification and 79% (37/47) accuracy for mental health
classification.
Conclusions: New semiautomated tools improved the efficiency of long-term ambulatory data collection from wearable and
mobile devices. Applying machine learning to the resulting data revealed a set of both objective features and modifiable behavioral
J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 1
http://www.jmir.org/2018/6/e210/
(page number not for citation purposes)
Sano et al
JOURNAL OF MEDICAL INTERNET RESEARCH
XSL•FO
RenderX
features that could classify self-reported high or low stress and mental health groups in a college student population better than
previous studies and showed new insights into digital phenotyping.
(J Med Internet Res 2018;20(6):e210) doi: 10.2196/jmir.9410
KEYWORDS
mobile health; mood; machine learning; wearable electronic devices; smartphone; mobile phone; mental health; psychological
stress
Introduction
Background
Recent advances in wearable and mobile technologies have
enabled individuals to monitor their daily lives and enabled
scientific investigators to passively collect real-time data without
disrupting people’s habitual routines. Two examples of such
devices are wrist-wearable devices that collect activity and other
physiological data (eg, activity or sleep; heart rate; skin
conductance, SC; blood pressure; and blood sugar level) and
mobile phones (eg, smartphones) that monitor location, activity,
social interaction over calls and texts (short message service,
SMS), app use, screen on or off, and environmental data such
as ambient light exposure and humidity.
Leveraging data from wearable and mobile devices to gain
meaningful information about human health has been called
digital phenotyping [1-3]. Digital phenotyping is defined as the
moment-by-moment quantification of the individual-level human
phenotype in situ using data from personal digital devices. Data
from personal digital devices may be used to understand health
and behaviors with a goal of preventing or minimizing disorders
and diseases. For example, current health status, behavior
history, and potential future health trajectories information might
help (1) individuals become more aware of their risk profiles
and enable them to make better informed decisions and take
actions to change their behaviors to reduce potential negative
physical and mental outcomes and (2) clinicians monitor
changes in their client’s or patient’s status.
Mobile phones have been used to monitor stress and mental
health [4-10]. The pioneering Student Life study that monitored
48 college students across a 10-week term using objective
Android mobile phone sensors and usage investigated the
relationship between well-being measures such as self-reported
stress, depression, flourishing and loneliness, and academic
performance [4]. Lower Perceived Stress Scale (PSS) score was
correlated with higher conversation frequency during the day
(9 AM-6 PM: the time frame participants might be in classes)
and the evening (6 PM-0 AM), longer conversation duration
during the day, and longer sleep duration. One study that
evaluated self-reported depression using mobile phones for 2
weeks (N=28) [8] showed that mobility patterns (ie, regularity
in 24-hour mobility patterns, as well as location variance) from
Global Positioning System and phone usage features including
usage duration and frequency were correlated with depressive
symptom severity on a self-reported depression survey, the
Patient Health Questionnaire-9 (PHQ-9) [8]. Another mobile
phone–based study that lasted 12 weeks (N=73) identified
mobile phone features that predicted clinically diagnosed
depressed mood with 0.74 area under the curve; these features
including the total count of outgoing calls, the count of unique
numbers texted, absolute distance traveled, dynamic variation
of the voice, speaking rate, and voice quality [10].
The combination of wearable sensor and mobile phone data has
also been used to study self-reported stress in daily life [11-14].
Muaremi et al, using both wearable sensors and mobile phones,
developed a way to automate the recognition of self-reported
daily stress levels using sleep parameters and 37 physiological
responses (including heart rate, heart rate variability (HRV) and
SC) from wearable sensors (N=10, 19 days), or mobile phone
usage and sleep HRV from wearable sensors (N=35, 4 months).
They showed 61% 3-class stress level classification accuracy
with a combination of phone usage and sleep HRV features and
73% accuracy using sleep duration, upper body posture, and
sleep HRV features [11,12]. Sano et al also investigated 5-day
self-reported high or low stress recognition (N=18) and 1-month
high or low stress recognition (N=66) using wearable sensor
and mobile phone data; they showed 75% and 90% accuracy
using leave-one participant-out or 10-fold cross-validation,
respectively [13,14].
Objectives
These previous studies focused on only mobile phone usage or
on phone usage plus wearable sensor data only during sleep and
have not taken advantage of 24/7 multimodal phone + wearable
data during wake and sleep to understand behaviors and
physiology for long-term study of self-reported stress and mental
health. We chose to approach this goal beginning with college
students, most of whom report high stress, and some of whom
are at risk of low or declining mental health [15,16]. According
to the 2017 National College Health Assessment that examined
data from 47,821 college students at 92 schools in the United
States, more than half of the respondents said that their stress
levels were higher than average, more than one-third had
difficulty functioning because of depression, and two-thirds
said they felt overwhelming anxiety in the last year [15].
Students’ high stress and low mental health could negatively
impact their academic performance [17]. Moreover, one-tenth
of the students had a plan for suicide. Suicide rate is increasing,
and suicide is the second leading cause of death for college
students [18]. More students are seeking help, and 34% of
counseling centers have a treatment waitlist [19]. Under these
conditions, development of improved tools for screening,
monitoring, and intervening for self-reported stress and poor
mental health through wearable sensors and mobile phones in
daily life settings will be beneficial. We aim to ultimately detect
stress and mental health changes before clinical interventions
are required and provide personalized early warnings together
with data-driven suggestions of individualized behaviors that
might promote better mental health outcomes.
J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 2
http://www.jmir.org/2018/6/e210/
(page number not for citation purposes)
Sano et al
JOURNAL OF MEDICAL INTERNET RESEARCH
XSL•FO
RenderX
Our SNAPSHOT study was designed to collect and examine
rich multimodal information in participants’everyday life using
wearable sensors and mobile phones for phenotyping sleep,
stress, and mental health, all of which are major health issues
in modern society. This paper has three main elements. First,
we introduce a methodology and tools to capture long-term,
large-scale ambulatory data on physiological and behavioral
characteristics using sensors installed in wearable devices and
mobile phones. The dataset from the SNAPSHOT study is one
of the first large multimodal datasets that contains continuous
physiology from a healthy college student population. The
dataset currently includes approximately 145,000 hours of data
from 201 participants at one university. Second, as real-world
ambulatory data are messy, we describe tools we developed and
deployed to improve the integrity and quality of the collected
data and to reduce the time experimenters spend checking for
and fixing errors. Third, we identify objective physiological
markers and modifiable behaviors that successfully classify
self-reported high or low stress and mental health and examine
the separate contributions of wearable sensors and mobile phone
data.
Methods
The 1-month SNAPSHOT study is a long-term and large-scale
study developed to measure Sleep, Networks, Affect,
Performance, Stress, and Health using Objective Techniques.
Our aim was to investigate how daily behaviors and social
networks influence sleep, self-reported stress, mood,
performance, and other well-being-related factors. For each of
five Fall and Spring semesters starting in Fall 2013, we collected
approximately 1 month of data per person from college students
who were socially connected and at a single New England
university. Students were only allowed to participate in the
study once. There was a total of 201 participants; Fall 2013: 20,
Spring 2014: 48, Fall 2014: 46, Spring 2015: 47, Fall 2015:40;
ages 18 to 25 years; 129 male, 72 female; 70 freshman, 49
sophomore, 44 junior, 36 senior, and 2 unreported. The
approximately 1 month of data collection was between the start
of semester and midterms.
Recruitment
We intentionally recruited college students from a single
academic institution who were socially connected because of
our interest in how social networks affect sleep and health
behaviors. Our definition of socially connected was making a
call or SMS at least once a week with each other. Each semester,
we recruited groups of at least 5 people who knew each other
and interacted socially. We posted our study advertisement to
undergraduate students’ mailing lists. Potential participants
filled out screening questionnaires to determine eligibility. Our
exclusion criteria were as follows: (1) non-Android phone users,
(2) inability to wear wrist sensors (eg, irritated skin on wrist),
(3) pregnant women, (4) travel across more than one time zone
1 week before the study or have plans to travel more than one
time zone away during the study, and (5) age <18 years or >60
years. In our study, we targeted only Android phone users
because other mobile phones (eg, iPhone) did not allow us to
monitor phone usage as needed for this study.
Eligible participants attended information and consent sessions.
For each session, we invited approximately 15 participants and
explained in detail the study and tasks that participants would
perform during the study. After participants gave written
informed consent, they completed prestudy questionnaires,
started wearing devices, and installed an Android app (described
below) on their phone. The study obtained a National Institutes
of Health Certificate of Confidentiality so that potentially
sensitive information such as drug or alcohol use provided by
the participants could not be revealed for legal purposes; this
was important protection for the students as the daily diary
included requests for such information.
The participants received financial compensation at the end of
the study; the amount depended on the number of days they
completed diaries, wore the sensors, and completed other
protocol tasks.
Study protocols were approved by the Massachusetts Institute
of Technology and Partners HealthCare Institutional Review
Boards. The study was registered on clinicaltrials.gov
(NCT02846077).
Data Collection
All data were deidentified before analysis, although location
information could potentially be used to reidentify people. Phone
numbers, email addresses, and actual names from the social
network surveys were hashed.
Start of the Study Questionnaires
At the start of the study, participants completed the
Morningness-Eveningness Questionnaire [20], the Pittsburgh
Sleep Quality Index [21], the Myers Brigg Personality test, the
Big Five Inventory Personality Test [22], the PSS [23], the
12-Item Short Form Health Survey (SF-12) for physical and
mental component summary (MCS) scores [24], and a set of
social network surveys assessing with whom participants spent
their time to help map their social networks. We also collected
age, sex, academic major, and living situation (eg, dorm name
and whether single or multiple occupancy room) information.
Ambulatory Monitoring
Wearable Sensors
Participants wore two sensors on their wrists: a Q-sensor
(Affectiva, Boston, MA, United States) to measure SC, skin
temperature (ST), three-axis acceleration (ACC) on their
dominant wrist and a Motion Logger (AMI, Ardsley, NY, United
States) on their nondominant wrist to measure acceleration and
ambient light data. ACC can be used to estimate activity levels
and sleep or wake patterns. SC reflects autonomic arousal during
the day, providing a stress index during wakefulness; SC
increases during sleep are highly likely to occur in either
non-rapid eye movement (non-REM) stage 2 sleep or slow-wave
sleep (SWS) [25]. The sensor data were logged into the flash
memory of the sensors. Participants were instructed to remove
sensors only in instances when the sensor could become wet or
risked being broken.
J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 3
http://www.jmir.org/2018/6/e210/
(page number not for citation purposes)
Sano et al
JOURNAL OF MEDICAL INTERNET RESEARCH
XSL•FO
RenderX
Mobile Phone App
We wrote a custom Android phone app based on funf [26] that
monitored location, receivers, senders, and timings of calls and
SMS text messages, screen on or off timings, and phone app
usage. No content of emails, calls, or SMS text messages was
recorded. Phone usage was measured for two main reasons.
First, phone usage and location data give clues to social
interactions. The timing of calls, SMS, and screen on provide
an estimate of how often participants interact with their phone
during the day and the night, whereas the number of calls, SMS,
and the number of people they interact with helps quantify their
social interaction. Second, lighting from the interaction with
mobile phones or emailing late at night could disturb the
biological circadian clock and increase alertness, both of which
can influence sleep patterns [27,28]. We asked our participants
not to use third-party messaging apps, if possible, during the
study for the last two cohorts.
Twice-Daily Electronic Diaries
Participants completed electronic diaries (e-diaries): upon
awakening and at bedtime each day. These diaries contained
questions about sleep and wake times; naps; exercise; academic
and extracurricular activity times; social interactions; caffeine,
alcohol, and drug intake; overall health condition; sleep; mood;
and self-reported stress (Figure 1). Participants received emails
that included a URL to the morning and evening diaries. They
could complete the diaries using computers, tablets, or mobile
phones.
Figure 1. An example evening e-diary. For some questions, if yes is chosen, additional questions are presented.
J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 4
http://www.jmir.org/2018/6/e210/
(page number not for citation purposes)
Sano et al
JOURNAL OF MEDICAL INTERNET RESEARCH
XSL•FO
RenderX
Poststudy Questionnaires and Other Measurements
At the end of the month of intensive data collection:
1.
Academic performance as measured by grade point average
was self-reported by each participant for the semester
previous to the study and the current study semester.
2.
Email usage during the experiment (ie, to, from, cc, and
time stamps) was collected through the Massachusetts
Institute of Technology (MIT) website Immersion [29].
3.
On the basis of their phone call, SMS, and email usage
objectively measured during the experiment, participants
were asked to self-report whether they had positive or
neutral or negative interactions with each frequent contact
as a whole over the month. Participants also indicated to
which category each frequent contact belonged to (ie,
family, social, work, others).
4.
The PSS, the SF-12, the set of social network surveys, and
the State-Trait Anxiety Index [30] were completed.
Data Preprocessing
Ambulatory data measured with wearable sensors, mobile
phones, and surveys tend to be noisy. Examples include (1) AM
vs PM errors when participants complete survey items about
their sleep and activity times; (2) participants forgetting to
charge or wear sensors; (3) sensors breaking or the signals
becoming noisy; and (4) mobile phone connectivity, hardware
sensor functionality, and mobile software updates, which can
break and interfere with data integrity. To address these issues,
various techniques have been applied, such as data cleaning
before data analysis [31]: data quality evaluation [32], detecting
faulty data, noise reduction [33], and interpolating faulty or
missing values [34,35]. To reduce the occurrence or impact of
these issues, additional approaches can be used during
ambulatory data collection. For example, during the study, an
e-diary system can notify participants about potential inaccurate
answers before they submit their answers, and a study
investigator can check data quality of incoming data and provide
feedback to the participants. For this study, we developed tools
for improving the quality of the collected data and for supporting
more efficient human checking and correcting of the phone,
sensor, and e-diary data.
Preprocessing Twice-Daily Electronic Diaries
We collected a total of 6077 days of e-diary data. In the first
year of the SNAPSHOT study, we set up an e-diary system that
automatically sent surveys to our participants every morning
and evening and then sent reminders if the participants did not
complete the surveys within 12 hours. We implemented logic
check functions on the system that prompted users to revise
their answers if certain types of errors or missing answers were
detected (eg, if two activity events overlapped, or if their
reported wake time was earlier than their reported bedtime).
During this first year, study investigators manually checked
participants’ answers every 1 to 2 days and emailed them to
revise their answers when errors were found.
In year 2 of the study, we installed raster plots that visualize
participants’ activities over time (Figure 2). These raster plots
were displayed to participants after they submitted their answers,
allowing users to visually confirm their responses and return to
their survey to correct any errors. These raster plots reduced
about half of the daily diary errors. The raster plots also reduced
the total average time taken to preprocess 1 month of a
participant’s e-diary data by 53%: from 145 min (year 1) to 68
min (year 2).
Finally, in year 3, we created and installed an administrative
module that includes three components to further improve data
validity: a calendar view, interactive checking system, and a
summary view. Every day, a study investigator logged into the
diary system and saw the calendar view (Multimedia Appendix
1) that showed the number of participants in the study, the
number of participants whose morning and evening diaries were
checked, the number of unchecked diaries, the number of diaries
that needed to be rechecked, and participants’ comments. The
interactive checking system automatically flagged missing
answers in the e-diary and allowed the study investigator to
check daily diaries just by flagging sections of the e-diary as
error (Figure 3). Emails were automatically sent to participants
if there were errors or missing answers. The summary view
(Multimedia Appendix 2) showed the daily diary status for each
participant in different colors (eg, green-acceptable, red-missing,
and pink-error). These plots enabled the study investigator to
understand which participants had filled out the daily surveys
and which participants they needed to contact (eg, if there were
repeated errors or missing entries in the diaries). This module
further reduced the total average time taken to preprocess 1
month of a participant’s e-diary data from 68 min (year 2) to
45 min (year 3). The combined changes in raster plots and the
administrative modules reduced the total average time taken to
clean 1 month of one participant’s e-diary data by 69%: from
145 min (year 1) to 45 min (year 3). Overall, participants’daily
diary completion rates ranged between 92% and 97% with no
significant differences across semesters.
Preprocessing Sensor or Mobile Phone Data
Every week, a study investigator had a face-to-face meeting
with each participant to download sensor data and to check if
sensors were working correctly, if the participants were wearing
them properly, and if sensor electrodes needed replacement.
We developed scripts to download the data from sensors and
check sensor readings automatically for quality using a
previously developed and tested automated classifier [36]. This
classifier separated clean epochs and noisy epochs of SC data
for further analysis.
We collected 6309 days of Q-sensor data for a total of 125,413
hours. We computed how much data were within a typical range
per published guidelines: for SC, 83% were within the range of
0.01 to 30 microS [37-39], and for ST, 99.7% were within the
range of 20 to 42 degrees Celsius [40]. In addition, 92% of the
collected SC data were classified as clean data using an artifact
detection algorithm [36]. Thus, among the collected SC data,
80% of the data were used for further analysis.
Mobile phone data were sent automatically to a server by the
custom funf-based app. On the server, another set of scripts that
we wrote checked the data quality every day and sent
notification to a participant if a problem was found in their data
(eg, not receiving phone data for a day). Phone data were
collected on 85% of the days.
J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 5
http://www.jmir.org/2018/6/e210/
(page number not for citation purposes)
Sano et al
JOURNAL OF MEDICAL INTERNET RESEARCH
XSL•FO
RenderX
Figure 2. Plot of daily activity timing (raster plot) with time of day (midnight to midnight) on the y-axis and each day plotted on a separate line.
Participants saw this plot after filling out their surveys and before they submitted their answers. Different activities were marked with different colors.
Identifying Risk Factors, Objective Biomarkers, and
Modifiable Behavioral Features Related to Stress and
Mental Health
We defined high stress and low stress groups based on their
poststudy PSS scores (Figure 4). PSS scores range from 0 to
40: higher scores indicate higher perceived stress. A PSS score
of 14.2 is the average for the age group of 18 to 29 years, and
a score over 16 is considered as high stress and of high health
concern [23]. Our participants’ average PSS score was 17.1.
We used the value of PSS ≥16 to construct the high stress group
(N=109, top 57.7% [109/189]) and PSS <16 for the low stress
group (N=80, bottom 42.3% [80/189]). Because we originally
had an unbalanced set of data for high stress and for low stress,
we first reduced the size of the high stress group by the method
of random sampling of its data to equalize the size of the high
and low stress classes at N=80. Thus, the prior probabilities on
both classes were made to be 0.5, so that a random classifier
would be expected to attain accuracy of 50%.
We defined high mental health and low mental health groups
based on their poststudy MCS from the SF-12 (Figure 4). For
the MCS, a value ≥50 is considered good mental health [41,42],
and 11.8% (23/195) of our population scored ≥50. We therefore
extracted the top and bottom 12% to form the two groups: high
mental health group (MCS ≥50, top 11.8% [23/195], N=23) and
low mental health group (MCS ≤29.4, bottom 12.3% [24/195],
N=24). Thus, the data in the high and low mental health groups
were balanced so that the prior probability of either group would
be 0.5, with a random classifier expected to have an accuracy
of 50%.
Feature Extraction
To quantify the relative importance of the many measures, we
compared the classification performance using the following
separate categories of features: (1) Big Five personality +
gender, (2) wearable sensors (eg, ST, SC, and ACC), (3) mobile
phone (eg, call, SMS, screen on, and location), and (4) objective
features (combining wearable sensors and mobile phone
metrics). We also separately defined (5) modifiable behaviors
as features that can potentially be controlled by participants,
such as sleep and activity timing and phone usage; these are
important features to measure for future behavioral interventions
(Table 1). Note that some features such as phone features and
ACC feature are found in more than one of the five categories.
SC was processed first using low-pass filtering (cutoff frequency
0.4 Hz, 32nd order finite impulse response filter). Because there
are individual differences in SC amplitude, we extracted features
from both unnormalized and normalized SC data based on the
maximum and minimum amplitude of each day within each
individual. To detect SC peaks, we obtained the first derivative
of the low-pass-filtered non-normalized SC data and then
determined where the slope exceeded a value of 0.02 µS per
second [43]. We detected SC peaks based on those that exceeded
this threshold and counted the number of peaks in each
30-second epoch.
J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 6
http://www.jmir.org/2018/6/e210/
(page number not for citation purposes)
Sano et al
JOURNAL OF MEDICAL INTERNET RESEARCH
XSL•FO
RenderX
Figure 3. Interactive diary check system. The left panel shows a participant’s answers. The right panel shows if there are any detected errors or missing
entries and enables adding comments. After the study investigator clicked the Save button, the system sent an email to a participant about any missing
or erroneous entries if appropriate.
J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 7
http://www.jmir.org/2018/6/e210/
(page number not for citation purposes)
Sano et al
JOURNAL OF MEDICAL INTERNET RESEARCH
XSL•FO
RenderX
Figure 4. (1) Distribution of poststudy Perceived Stress Scale (PSS) and (2) Distribution of poststudy mental component summary (MCS) scores.
We used four different times of interest for analyses: day (9
AM-6 PM), night (6 PM-0 AM), late night (0 AM-3 AM), and
sleep time (estimated for each individual from actigraphy and
daily sleep diaries) as physiological responses, such as SC and
ACC during daytime and sleep time have different meanings
[44] and late night phone and exercise activities could relate to
self-reported stress and mental health [45].
Bedtime and sleep regularity were calculated from the daily
sleep diaries, and sleep duration and sleep efficiency were
estimated from actigraphy with help of the daily sleep diaries.
Sleep regularity was computed because a relationship between
irregular sleep and low mental health was found in a previous
study using this index [46]. The Sleep Regularity Index (SRI;
Figure 5) captures the probability of an individual being in the
same state (asleep vs awake) at any two time points 24 hours
apart with 1 minute resolution, averaged across the entire study
[47], where s(t)=1 during wake and s(t)=−1 during sleep for
each minute. Assume data are collected for [0, T] with T=total
number of hours of data and τ=24 hours.
In practice, individuals will only display sleep patterns that
range between an SRI of 0 (random) and 100 (periodic: an
individual who sleeps and wakes at exactly the same times each
day). Values less than 0 are theoretically possible (eg, alternating
24 h of sleep and 24 h of wake) but very unlikely to be observed.
Phone usage and location data can provide information on
sociability. We computed the timing and the number of calls,
SMS, and screen on, which provide an estimate of how often
participants interact with their phone during the day and the
night. Previous studies showed the relationships between long
phone usage duration and high stress [45] and long and frequent
phone usage and severe depressive symptoms [8]. We also
computed the number of people each participant interacted with
over calls and SMS to help quantify their social interaction. For
mobility features, we computed the distance and radius based
on locations to which our participants travelled as these features
were shown to be important in previous studies [8,48].
Additionally, because our population spent most of their time
on campus or at their residence, we computed whether the day’s
mobility pattern varied from the typical routine based on a
Gaussian mixture model trained for each participant’s 1-month
mobility patterns [49].
Classification
For classifying high or low stress groups and high or low mental
health groups, we compared the methods of least absolute
shrinkage and selection operator (LASSO), support vector
machine (SVM) with linear kernel classifier, and SVM with
radial basis function (RBF) kernel classifier; these algorithms
were used in previous related work [8,10]. LASSO is a logistic
regression that performs regularization and feature selection by
minimizing the least squares objective function with an L1
penalty [50].
J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 8
http://www.jmir.org/2018/6/e210/
(page number not for citation purposes)
Sano et al
JOURNAL OF MEDICAL INTERNET RESEARCH
XSL•FO
RenderX
Table 1. List of features.
Features
Modality
Personality types, gender, diary, sensor, and phone features
All
Openness, conscientiousness, extraversion, agreeableness, neuroticism, gender
Big Five personality types, gender (6 features)
Mean, median, SD of 0 AM-3 AM, sleep, 9 AM-6 PM, 6 PM-0 AM for SCa, ACCb, and
STc
Sensors (17 features x 4 time frames x 3=204 features)
Skin conductance: Area under the curve for 30 s epochs, max, mean, median, and SD of
amplitude; mean, median and SD of peaks for 30 s epochs; mean, median, and SD of nor-
malized amplitude
Acceleration: total # of zero crossing for 30 s epochs
Skin temperature: max, min, mean, median, and SD of temperature
Mean, median, SD of 0 AM-24 AM, 0 AM-3 AM, 6 PM-0 AM for call, SMS, and screen
(not mobility)
Phone (25 features (call, SMSd, screen) x 3 time frames
x 3 + 4 features (mobility) x 3 features=237 features)
Call: Mean, median, and SD of duration and time stamp of calls per day; total duration
per day, total number per day, and number of unique people per day
SMS: Mean, median, and SD of duration and time stamp of SMS per day; total number
per day and number of unique people per day
Screen: Mean, median, and SD of screen-on duration and screen-on time stamp per day;
total duration per day and total number of on or off per day
Mobility: Total distance per day, 5-min distance, radius per day, and log likelihood of each
day
Phone and sensor features (see above)
Objective (441 features)
Sleep Regularity Index
Modifiable behaviors (296 features)
Mean, median, and SD of bedtime and sleep duration
Diary features (see below)
ACC total # of zero crossing for 30 s epochs
Phone features (see above)
Mean, median, SD of sleep or no sleep (pulled an all-nighter; binary valued), pre sleep
electronic media interaction (emails, calls, SMS, Skype, chat, and online games; binary
valued), pre sleep personal interaction(binary valued), # of naps, nap duration, # of academic
activities per day, total academic duration, study duration, # of extracurricular activities,
total extracurricular activities, # of exercise, exercise duration, # of caffeinated drink intake,
memorable positive interaction(binary valued), somewhat negative interaction (binary
valued), very negative interaction(binary valued), last caffeine intake time
Diary (17 x 3=51 features)
Sleep Regularity Index
Sleep (1 + 3 x 8=25 features)
Mean, median, and SD of bedtime, sleep duration, sleep efficiency, sleep or no sleep (pulled
an all-nighter; binary valued), pre sleep electronic media interaction (emails, calls, SMS,
Skype, chat, and online games; binary valued), pre sleep personal interaction (binary valued),
# of naps and nap duration
aSC: skin conductance.
bACC: acceleration.
cST: skin temperature.
dSMS: short message service.
Figure 5. Equation of Sleep Regularity Index.
For training and testing models, we used nested-cross validation.
To 
evaluate 
model 
performance, 
we 
applied
leave-one-cohort-out: training a model with all except one
semester cohort’s data and testing the model against the left-out
cohort’s data, repeating this process for the total number of
cohorts (ie, 5 times). First we (1) split the data into two datasets:
a training set made up of four cohorts and a test set made up of
J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 9
http://www.jmir.org/2018/6/e210/
(page number not for citation purposes)
Sano et al
JOURNAL OF MEDICAL INTERNET RESEARCH
XSL•FO
RenderX
one cohort. We then left the test set out until step (5) or (8)
below.
For training the SVM models, we applied sequential forward
feature selection to the training data to reduce overfitting and
find the best combinations. (2) We applied a t test to each feature
of the training datasets and selected 100 features with the lowest
P values for finding features to separate two groups effectively
then (3) applied sequential forward feature selection [51]:
applied an SVM RBF classifier with 10-fold cross validation
to find the best up to five combinations from these 100 features
and optimized hyperparameters (C for SVM linear and C and
gamma for SVM RBF). Then, (4) we trained the SVM linear
or RBF models with the selected features of the training data,
(5) tested the models against the test data, and (6) repeated this
process (1-6) five times.
For LASSO, (7) the penalization parameter was determined
with the training data by 10-fold cross validation and (8) the
trained model was tested using the test data. This process (1, 7,
and 8) was repeated five times.
We computed overall accuracy and F1 scores by concatenating
the five-cohort predicted output to compare the performance of
the models to reduce the bias from splitting [52]. We computed
95% confidence levels using adjusted Wald test [53]. The F1
score is a measure of performance computed using precision
(also known as positive predictive value) and recall (also known
as sensitivity) as described in Equation 1, where precision is
the number of correct positive results divided by the number of
all positive results, and recall is the number of correct positive
results divided by the number of positive results that should
have been returned.
(1) F1 = 2 x precision x recall / (precision + recall)
We also compared the performance of the models using features
based on data from the entire 1-month study period with that
using features based only on using the data from the week before
the PSS and MCS surveys were completed.
We applied t tests or Mann-Whitney U tests (for non-Gaussian
distributions) to examine if the means of the features were
statistically different between the high or low PSS groups or
the high or low MCS groups. We adjusted for the multiple
comparisons using false discovery rate (FDR).
Results
Relationships Among Prestudy and Poststudy
Perceived Stress Scores and Mental Component
Summary
There were no differences in the poststudy PSS or MCS among
the five cohorts; one-way analysis of variance (P=.20, F=1.50).
Students’ poststudy scores (both PSS and MCS) were highly
correlated with prestudy scores (r=.59, .60, Pearson correlation).
Poststudy PSS scores statistically increased (mean prestudy
PSS: 15.0, poststudy PSS: 17.1, paired t test, P<.001) and MCS
scores decreased compared with the prestudy scores (mean
prestudy MCS: 44.4, poststudy MCS: 40.4, Wilcoxon signed
rank test, P<.001). Thus, the students reported worsening stress
and mental health over the 1 month of measurement.
The poststudy PSS was inversely correlated with the poststudy
MCS (r=−.71, Pearson correlation; Multimedia Appendix 3):
(1) 83% (19/23) of the students in the high MCS group belonged
to the low PSS group and (2) 88% (21/24) of the students in the
low MCS group belonged to the high PSS group. The low MCS
group had higher PSS scores than the rest of the students in the
high PSS group: low MCS group’s average PSS score was 25.2,
whereas the rest in the high PSS group’s average PSS score was
20.7 (P<.001).
Stress and Mental Health Classification
Overall, we found SVM models with the RBF kernel worked
better than LASSO and linear SVM models using RBF kernels
for all of the metrics (Figures 6 and 7; see Multimedia Appendix
4 for accuracy and F1 scores and Multimedia Appendices 5 and
6 for F1 scores for all results). SVM with the RBF kernel can
model more complex decision boundaries. Sensor features
showed higher performance than phone features both for PSS
and MCS.
We also compared the performance of the SVM RBF models
using features from only the last week of the 1-month period
to using the features from the entire month. Overall, the
performances with the 1 month of features were better
(classification accuracy improved by 1-16%) than those using
just the last week of features, except in the case of the SVM
models using all features.
The accuracy for PSS classification was highest when using all
features (82%), followed by when using features from only
sensors (78%), only behaviors (74%), only the Big Five (71%),
or only objective data (70%). The same rank ordering also held
when comparing F1 scores. For MCS, sensor features and
objective features showed the highest accuracy (87%), followed
by Big Five (85%), behaviors (79%), and all (77%). The ranking
of the F1 scores was similar except for all features had a slightly
higher F1 than behaviors. The means and SD of the accuracy
and F1 scores from leave-one-cohort-out cross validation are
presented in Multimedia Appendix 7.
We also tested different cutoffs: (1) instead of PSS cutoffs ≥16
for high and <16 for low stress, we used PSS ≥14 for high stress
group and PSS <14 for low stress, as (as noted above) 14.2 is
the reported average for people aged 18 to 29 years [23] and
(2) instead of extreme MCS cutoffs (top and bottom 12%), we
used MCS ≥median (42.05) for high mental health group and
MCS <median for low mental health group). This was done to
test if the rankings of performances were sensitive to the exact
cutoff values. Sensor and modifiable behavior features worked
best with both cutoff values (Multimedia Appendices 8 and 9).
Compared with the extreme MCS cutoffs, the median cutoff
showed much lower classification performance (the accuracy
decreased by 21 to 6 %).
We summarize the features most commonly selected by the
algorithms as useful for high or low PSS detection (Figure 8)
and high or low MCS detection (Figure 9) using the full 1 month
of data. Percentages indicate the percent time these features are
selected across 10-fold cross validation over five cohorts and
five feature modalities (all, Big Five + gender, sensor, phone,
objective and modifiable behavior features).
J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 10
http://www.jmir.org/2018/6/e210/
(page number not for citation purposes)
Sano et al
JOURNAL OF MEDICAL INTERNET RESEARCH
XSL•FO
RenderX
For PSS classification for self-reported stress, neuroticism and
conscientiousness were the most often selected features (90%
and 70% of the models, respectively). The high PSS group had
higher neuroticism (q [which is the FDR-adjusted P
value]=.0004). The high stress group had a larger extracurricular
activity duration SD (q=.04).
In the MCS classification for self-reported mental health, the
low MCS group showed higher neuroticism (q<.001) and lower
conscientiousness (q=.04) than the high MCS group. The low
MCS group had naps more frequently (40%; q=.04). In the MCS
classification models using only the last week of data, the low
MCS group showed a lower probability of interacting with
electronic media (eg, emails, calls, SMS, Skype, chat, and online
games) before sleep (30%; q=.004) and lower SD of the number
of SC peaks during the time frame of 0 AM to 3 AM (20%;
q=.03), as well as higher neuroticism (q<.001).
The percentages of time each feature was selected for each fold
of leave-one-cohort cross validation are presented in Multimedia
Appendices 10 and 11.
We also tried building models only with sleep features (eg,
features in the sleep category and some sleep related features
in the survey category). We obtained 72% and 65% accuracy
for classifying high or low PSS and high or low MCS. Mean
nap duration was the most common feature used for the PSS
models (80% of the models), followed by median bed time and
the frequency of pulling all-nighters (60%). The frequency of
pulling all-nighters (100% of the models), mean number of
naps, sleep duration, and sleep efficiency (60%) were commonly
selected features by the MCS classification models. Average
sleep duration was not significantly different statistically in the
high vs low PSS groups or in the high vs low MCS groups (high
PSS: 6 hours 42 min vs low PSS: 6 hours 51 min [P=.09], high
MCS: 6 hours 40 min, low MCS: 6 hours 34 min [P=.72]).
Instead, the low MCS group’s more frequent napping was one
of the most discriminating features.
Figure 6. High or low Perceived Stress Scale (PSS) classification results. Top: comparison of performance using 1 month of data with three machine
learning algorithms. Bottom: comparison of performance using 1 month of data vs only the last week of data with support vector machine radial basis
function (SVM RBF). Accuracy scores for Big Five + Gender data are not shown in the bottom graph because these data are collected only once. Error
bars indicate the 95% CIs based on adjusted Wald test.
J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 11
http://www.jmir.org/2018/6/e210/
(page number not for citation purposes)
Sano et al
JOURNAL OF MEDICAL INTERNET RESEARCH
XSL•FO
RenderX
Figure 7. As in Figure 6 with high or low mental component summary score classification results, accuracy scores for Big Five + Gender data are not
shown in the bottom graph because these data are collected only once. Error bars indicate the 95% CIs based on adjusted Wald test.
Figure 8. Percentage of time each feature was selected across 10-cross-validation for high or low Perceived Stress Scale (PSS) classification models
with 1 month of data.
J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 12
http://www.jmir.org/2018/6/e210/
(page number not for citation purposes)
Sano et al
JOURNAL OF MEDICAL INTERNET RESEARCH
XSL•FO
RenderX
Figure 9. Percentage of times each feature was selected across 10-cross-validation for high or low mental component summary (MCS) classification
models with 1 month of data.
Discussion
Principal Findings
In this paper, we developed novel tools to collect and process
objective physiological and behavioral measures using online
diaries, wearable sensors, and mobile phones. We aimed to
investigate how accurately these measures could identify
conditions of self-reported high stress and poor mental health
and features most accurate in identifying these conditions.
Physiological sensor, phone, and mobility features were the
best predictors for distinguishing self-reported high or low stress
and mental health. Wearable sensor features, including SC and
ST, reached 79% accuracy for classifying high or low stress
groups and 87% accuracy for classifying high or low mental
health groups. Modifiable behaviors, including number of naps,
studying duration, phone calls (number, time stamp and duration
of calls), mobility patterns, and phone-screen-on time, reached
74% accuracy for high or low stress group classification and
78% accuracy for high or low mental health group classification.
Comparison With Prior Work and Interpretations of
Our Results
Our analysis showed that relatively high accuracy and F1 scores
can be achieved using the leave-one-semester-cohort-out testing
of the machine learning classifier for high or low stress
measured by PSS and high or low mental health measured by
MCS. Of all the features tested, the sensor features resulted in
approximately 14% higher classification accuracies in both PSS
and MCS than the phone features. In particular, SC responses
during the time frame of 9 AM to 6 PM were one of the best
predictors for PSS. SC has been considered as a biomarker for
stress [44] because SC quantifies eccrine sweat activity that is
controlled by only sympathetic nervous activity. These findings
(1) are among the first to show the potential contribution of SC
in stress detection using a wrist wearable sensor in a 24/7 daily
life setting and (2) agree with previous findings that use a
conventional finger SC sensor or a wearable SC sensor in
settings where a person is seated, eg, driving a car. For example,
Healey et al measured SC, heart rate, HRV, respiration, and
electromyogram in Boston drivers and reported that SC was the
most associated with stress [54]. Additionally, Hernandez et al
discriminated stressful and nonstressful calls at a call center
environment using SC features with 78% accuracy [55], and
Setz et al automatically classified SC responses from cognitive
load and stress with accuracy higher than 80% [56].
As we examined more closely which sensor features were most
discriminative, we found that SC responses during the time
frame of 0 AM to 3 AM and during sleep were predictors for
separating high and low self-reported mental health. Some
studies have shown that finger-based SC are reduced for patients
with depression measured in a short-term lab study [57-59].
One possible explanation of how low SC responses during sleep
could be related to MCS scores is that there is a decrease in
SWS in depression [60] and other psychiatric disorders [61],
and the largest SC responses during sleep are likely to occur
during non-REM stage 2 and SWS [25]. Note that in our data,
(1) 0 AM to 3 AM could include both awake and asleep
conditions, and if it included sleep, we would expect it to include
more SWS being at the start of the night for this cohort; (2) our
low mental score groups are based on self-report; and (3) we
do not know if any of our participants had clinically defined
depression or other psychiatric disorders as that information
was not gathered as part of this study.
J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 13
http://www.jmir.org/2018/6/e210/
(page number not for citation purposes)
Sano et al
JOURNAL OF MEDICAL INTERNET RESEARCH
XSL•FO
RenderX
We found that ST features were also predictors for PSS and
MCS. A previous study has shown that acute stress does reduce
distal finger ST but does not statistically significantly reduce
wrist ST in a laboratory stress test setting [62]. Furthermore,
another study showed that ST is one of the strongest
discriminants to distinguish sleep and wake states [63]. Another
study showed that patients with depression have less rhythmicity
in ST [64], which would also be consistent with less regular
sleep in depression. To our knowledge, this paper is the first to
report that ambulatory wrist ST features are related to
self-reported stress.
For phone features, our results showed phone usage time stamp
and duration can be predictors for PSS and MCS. These results
are consistent with several previous studies. People with a
PHQ-9 score higher than 5 showed longer phone usage and
higher phone usage frequency than those with a PHQ-9 score
lower than 5 in a 2-week study with mobile phones [8]. A
questionnaire-based study also showed a relationship between
high mobile phone usage, stress, and symptoms of depression
[45].
Mobility, specifically travel distance per day and SD of the
distance traveled as measured by phone geolocation data, is a
predictor both for self-reported stress and mental health. This
result agrees with one study [8] reporting that normalized
mobility entropy (distribution of frequency of visiting different
places) and location variance were negatively correlated with
depression symptoms and another study reporting that mobility
patterns were highly related to stress level [13]. The relationship
between reduced activity levels and mobility patterns and high
stress and low mental health has been studied [48,65]. These
behavioral markers could be an objective index for monitoring
self-reported low mental health. It is possible that encouraging
people to move more could be an effective intervention to reduce
stress and improve mental health.
Consistent with previous studies [7,13,14], personality types
were one of the most influential and statistically significant
factors for self-reported stress and mental health in this college
population. In the Big Five Inventory Personality Test
categories, neuroticism was a predictor of stress [66]. The
combination of low extraversion and low conscientiousness or
low agreeableness contributed to the high stress group; these
directions of the associations in our analysis were consistent
with prior work [67]. High neuroticism and low extraversion
have previously been associated with low MCS [68].
There is a known association between sleep deficiency and
mental health status (eg, [61]). Our results, however, did not
show that sleep duration was a strong discriminant feature for
self-reported stress and mental health.
Limitations
There are multiple limitations of this study:
1.
Selection of a feature as discriminating between two
categories does not mean it is an important feature or
causative of that behavior.
2.
These results do not tell us the causality (eg, does a student
sleep later and less regularly because of higher stress or
have higher stress because of later or more irregular sleep?).
3.
Our participants were limited to Android phone users
because we wanted to log detailed phone usage, which is
not allowed by other phone systems such as iPhone. As
about half of the undergraduate students were Android users
on the campus, a selection bias might exist. A previous
study showed slight differences in personality types and
economic status between iPhone users and Android users
[69].
4.
A total of 64% of our study population were male
participants. It has been reported that females report higher
perceived stress levels and more depressive symptoms
[70-73], and there are gender differences in psychological
and biological stress responses [74]. In our dataset, the
ratios of female participants in the high or low PSS and
MCS groups were 45% and 20% (high and low PSS) and
22% and 54% (high and low MCS). Modeling stress and
mental health differently in males and females might help
understand the mechanism. Gender was included as a
potential feature in our models and was not selected
frequently.
5.
Our data come from college students at one New England
university over 4 years. The work needs to be applied to
other populations to determine generalizability.
6.
Our data come from socially connected student groups. We
might observe some statistically coherent behaviors in our
dataset because of these connections.
Future Work
These new tools and methods can allow multimodal data in
daily life to be captured more continuously, with greater
accuracy and integrity of the data, and for long-term and at great
scale. We are planning to collect a larger amount of data for an
even longer time to study long-term behaviors and physiological
responses and build predictive models. To do this, we need to
build a new system for consenting people in remote locations,
fully automate checking their measurement status and data
accuracy automatically, and let the participants know about
errors so they can fix them to keep study compliance and data
accuracy high.
We will continue our data analysis for understanding behaviors,
physiological responses, and traits that impact health and
well-being. One of our hypotheses is that health-related
behaviors will be contagious within social networks and that
social network data we obtained from call, SMS, and email data
could capture the social contagion quantitatively instead of
requiring self-report to capture it. We are also interested in
studying how phone usage influences sleep and health and how
we can predict stress and mental health using previous behaviors
and physiology.
These machine learning models are not limited to modalities
and features we measured and computed in this study but can
also be used for other modalities such as heart rate and heart
rate variability that are controlled by autonomous activities, and
other features such as app usage, ambient light, and audio or
sentiment-based patterns extracted from text or speech could
be added to improve the models. The features and models
presented in this paper can be tested in similar multimodal
ambulatory datasets collected in other future studies. Tracking
J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 14
http://www.jmir.org/2018/6/e210/
(page number not for citation purposes)
Sano et al
JOURNAL OF MEDICAL INTERNET RESEARCH
XSL•FO
RenderX
stress and mental health conditions would help students better
understand their stress and mental health conditions over
multiple semesters, as well as help clinicians see how treatment
affects students’ conditions if they receive treatment.
Conclusions
In this paper, we introduced a methodology and tools we
developed to measure ambulatory multimodal data and improve
the integrity of collected data to study self-reported stress and
mental health in the daily lives of college students. We showed
that objective and modifiable behavioral features collected over
1 month can classify these college students as high or low stress
based on the PSS and as having high or low mental health based
on MCS from SF-12 collected at the end of that month with
over 70% accuracy, whereas sensor features alone could classify
high or low mental health and achieve over 88% on an F1 score.
For classifying high or low stress groups, we found that
combining phone and sensor features typically gave the best
results over using either modality alone, whereas for classifying
high or low mental health groups, the use of wearable sensor
features performed comparable to wearable + phone features.
Acknowledgments
The authors are grateful to Mr Conor O’Brien, Mr Justin Buie, Mr Salim Qadri, Ms Natalie Virayan, Mr Michael Shreeve, Mr
Omer Zaidi, Ms Natasha Jaques, Mr Weixuan Chen, Ms Asma Ghandeharioun, Mr Daniel Lopez Martinez, Ms Ehimwenma
Nosakhare, Ms Amy Zhao Yu, Mr Daniel Smilkov, Ms Jade Philipoom, Ms Yuna Hahn, Ms Sienna Ramos, Ms Jihyun Gia Min,
Ms Tania Yu, Ms Shirley Chen, Ms Laura Breiman, and Dr Catherine Ricciardi for their tremendous support helping run the
SNAPSHOT study and collecting the data, and to Dr Cesar Hidalgo for helping design social network surveys. They also appreciate
all the participants and support from the MIT Media Lab Consortium, especially a generous donation by Samsung Electronics,
NEC, and funding from NIH grants R01GM105018, R00HL119618 (AJKP), K24HL105664 (EBK), and KL2TR002370,
F32DK107146, T32HL007901 (AWM) and Harvard Catalyst | The Harvard Clinical and Translational Science Center (National
Center for Research Resources and the National Center for Advancing Translational Sciences, National Institutes of Health Award
UL1 TR001102), and financial contributions from Harvard University and its affiliated academic health care centers. The content
is solely the responsibility of the authors and does not necessarily represent the official views of Harvard Catalyst, Harvard
University and its affiliated academic health care centers, or the National Institutes of Health.
Conflicts of Interest
RP is a cofounder of and shareholder in Affectiva, who commercialized the original sensors used in this study. RP is also a
cofounder and shareholder in Empatica, a company that makes wearable sensors that can collect ambulatory data similar to the
data collected in this study. EK has consulted for legal firms and for Pfizer Pharmaceuticals.
Multimedia Appendix 1
Calendar view. For each day, the investigator can see how many participants are in the study, how many surveys have been
verified, how many need to be re-examined, and participant comments.
[PNG File, 102KB-Multimedia Appendix 1]
Multimedia Appendix 2
Summary view. The investigator can see the daily diary status for each participant in different colors: green: acceptable; red:
missing; pink: error; red/white slash: missing but participants still have time to complete the diary.
[PNG File, 100KB-Multimedia Appendix 2]
Multimedia Appendix 3
The relationship between poststudy Perceived Stress Scale (PSS) and poststudy Mental Component Score (MCS) for each
participant (blue circle). Chosen cutoffs for high and low PSS and high and low MCS are indicated.
[PNG File, 57KB-Multimedia Appendix 3]
Multimedia Appendix 4
Performance of PSS and MCS classification models with 1 month or last week of data.
[PDF File (Adobe PDF File), 28KB-Multimedia Appendix 4]
Multimedia Appendix 5
High or low Perceived Stress Scale (PSS) classification results. Top: Comparison of F1 scores for PSS classification with three
machine learning algorithms (LASSO, SVM linear, and SVM RBF) on 1 month of different types of data (All, Big Five + Gender,
J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 15
http://www.jmir.org/2018/6/e210/
(page number not for citation purposes)
Sano et al
JOURNAL OF MEDICAL INTERNET RESEARCH
XSL•FO
RenderX
Sensor, Phone, Objective, Behaviors). Bottom: Comparison of F1 scores with SVM RBF machine learning algorithm on 1 month
of data versus on only the last week of the same data types. Accuracy scores for Big Five + Gender data are not shown in the
bottom graph because these data are collected only once.
[PNG File, 21KB-Multimedia Appendix 5]
Multimedia Appendix 6
High or low Mental Component Score (MCS) classification results. Top: Comparison of F1 scores for MCS classification with
three machine learning algorithms (LASSO, SVM linear, and SVM RBF) on 1 month of different types of data (All, Big Five +
Gender, Sensor, Phone, Objective, Behaviors). Bottom: Comparison of F1 scores with SVM RBF machine learning algorithm
on 1 month of data versus on only the last week of the same data types. Accuracy scores for Big Five + Gender data are not shown
in the bottom graph because these data are collected only once.
[PNG File, 22KB-Multimedia Appendix 6]
Multimedia Appendix 7
Mean and SD of accuracy and F1 scores from leave-one-cohort-out PSS and MCS classification models with 1 month of data
and SVM RBF.
[PDF File (Adobe PDF File), 26KB-Multimedia Appendix 7]
Multimedia Appendix 8
High or low Perceived Stress Scale (PSS) and Mental Component Score (MCS) classification results. Comparison of F1 for PSS
and MCS classification scores with SVM RBF and 1 month of different types of data (All, Big Five + Gender, Sensor, Phone,
Objective, Behaviors). Cutoff: 14 (the average in the 18-29 years age group) for PSS and 42.05 (median) for MCS.
[PNG File, 14KB-Multimedia Appendix 8]
Multimedia Appendix 9
Performance of PSS and MCS classification models with 1 month of data and SVM RBF. PSS cutoff: 14 (the average in the
18-29 years age group) and MCS cutoff: 42.05 (median).
[PDF File (Adobe PDF File), 16KB-Multimedia Appendix 9]
Multimedia Appendix 10
Percentages of the number of times each feature was selected for each fold of leave-one-cohort-out cross validation for 1-month
PSS models.
[PDF File (Adobe PDF File), 20KB-Multimedia Appendix 10]
Multimedia Appendix 11
Percentages of the number of times each feature was selected for each fold of leave-one-cohort-out cross validation for 1-month
MCS models.
[PDF File (Adobe PDF File), 19KB-Multimedia Appendix 11]
References
1.
Torous J, Kiang MV, Lorme J, Onnela JP. New tools for new research in psychiatry: a scalable and customizable platform
to empower data driven smartphone research. JMIR Ment Health 2016 May 5;3(2):e16 [FREE Full text] [doi:
10.2196/mental.5165] [Medline: 27150677]
2.
Jain SH, Powers BW, Hawkins JB, Brownstein JS. The digital phenotype. Nat Biotechnol 2015 May;33(5):462-463. [doi:
10.1038/nbt.3223] [Medline: 25965751]
3.
Li X, Dunn J, Salins D, Zhou G, Zhou W, Schüssler-Fiorenza Rose SM, et al. Digital health: tracking physiomes and activity
using wearable biosensors reveals useful health-related information. PLoS Biol 2017 Jan;15(1):e2001402 [FREE Full text]
[doi: 10.1371/journal.pbio.2001402] [Medline: 28081144]
4.
Wang R, Chen F, Chen Z, Li T, Harari G, Tignor S, et al. StudentLife: assessing mental health, academic performance and
behavioral trends of college students using smartphones. 2014 Presented at: UbiComp '14 Proceedings of the 2014 ACM
International Joint Conference on Pervasive and Ubiquitous Computing; September 13-17, 2014; Seattle, Washington. [doi:
10.1145/2632048.2632054]
J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 16
http://www.jmir.org/2018/6/e210/
(page number not for citation purposes)
Sano et al
JOURNAL OF MEDICAL INTERNET RESEARCH
XSL•FO
RenderX
5.
Bogomolov A, Lepri B, Pianesi F. Happiness recognition from mobile phone data. 2013 Presented at: International Conference
on Social Computing; September 8-14, 2013; Alexandria, VA, USA. [doi: 10.1109/SocialCom.2013.118]
6.
Bauer G, Lukowicz P. Can smartphones detect stress-related changes in the behaviour of individuals? 2012 Presented at:
IEEE International Conference on Pervasive Computing and Communications Workshops; March 19-23, 2012; Lugano,
Switzerland. [doi: 10.1109/PerComW.2012.6197525]
7.
Bogomolov A, Lepri B, Ferron M, Pianesi F, Pentland A. Daily Stress Recognition from Mobile Phone Data, Weather
Conditions and Individual Traits. 2014 Presented at: Proceedings of the 22nd ACM international conference on Multimedia;
November 3-7, 2014; Orlando, Florida, USA. [doi: 10.1145/2647868.2654933]
8.
Saeb S, Zhang M, Karr CJ, Schueller SM, Corden ME, Kording KP, et al. Mobile phone sensor correlates of depressive
symptom severity in daily-life behavior: an exploratory study. J Med Internet Res 2015 Jul 15;17(7):e175 [FREE Full text]
[doi: 10.2196/jmir.4273] [Medline: 26180009]
9.
Chow PI, Fua K, Huang Y, Bonelli W, Xiong H, Barnes LE, et al. Using mobile sensing to test clinical models of depression,
social anxiety, state affect, and social isolation among college students. J Med Internet Res 2017 Mar 3;19(3):e62 [FREE
Full text] [doi: 10.2196/jmir.6820] [Medline: 28258049]
10.
Place S, Blanch-Hartigan D, Rubin C, Gorrostieta C, Mead C, Kane J, et al. Behavioral indicators on a mobile sensing
platform predict clinically validated psychiatric symptoms of mood and anxiety disorders. J Med Internet Res 2017 Mar
16;19(3):e75 [FREE Full text] [doi: 10.2196/jmir.6678] [Medline: 28302595]
11.
Muaremi A, Arnrich B, Tröster G. Towards measuring stress with smartphones and wearable devices during workday and
sleep. Bionanoscience 2013;3:172-183 [FREE Full text] [doi: 10.1007/s12668-013-0089-2] [Medline: 25530929]
12.
Muaremi A, Bexheti A, Gravenhorst F, Arnrich B, Tröster G. Monitoring the Impact of Stress on the Sleep Patterns of
Pilgrims using Wearable Sensors. 2014 Presented at: IEEE-EMBS International Conference on Biomedical and Health
Informatics (BHI); June 1-4, 2014; Valencia, Spain. [doi: 10.1109/BHI.2014.6864335]
13.
Sano A, Picard RW. Stress Recognition Using Wearable Sensors and Mobile Phones. 2013 Presented at: Humaine Association
Conference on Affective Computing and Intelligent Interaction; September 2-5, 2013; Geneva, Switzerland. [doi:
10.1109/ACII.2013.117]
14.
Sano A, Phillips AJ, Yu AZ, McHill AW, Taylor S, Jaques N, et al. Recognizing academic performance, sleep quality,
stress level, and mental health using personality traits, wearable sensors and mobile phones. 2015 Presented at: IEEE 12th
International Conference on Wearable and Implantable Body Sensor Networks (BSN); June 9-12, 2015; Cambridge, MA,
USA. [doi: 10.1109/BSN.2015.7299420]
15.
CACUSS. American College Health Association-National College Health Assessment II: Canadian Reference Group
Executive Summary Spring 2017 URL: http://www.cacuss.ca/health_data.htm [accessed 2018-05-16] [WebCite Cache ID
6zT9bD7yo]
16.
Auerbach RP, Alonso J, Axinn WG, Cuijpers P, Ebert DD, Green JG, et al. Mental disorders among college students in
the World Health Organization world mental health surveys. Psychol Med 2016 Oct;46(14):2955-2970 [FREE Full text]
[doi: 10.1017/S0033291716001665] [Medline: 27484622]
17.
Eisenberg D, Golberstein E, Hunt J. Mental health and academic success in college. B E J Econom Anal Policy 2009;9(1):-.
[doi: 10.2202/1935-1682.2191]
18.
The American Association of Suicidology. Suicidology. 2016. College Students & Suicide Fact Sheet: 2016 Fact Sheet
URL: http://www.suicidology.org/Portals/14/Re-Formatted%20College%20Students%20Fact%20Sheet.
pdf?ver=2016-11-16-110354-547 [accessed 2018-05-16] [WebCite Cache ID 6zTBIkcVH]
19.
The Association for University and College Counseling Center Directors. The association for university and college
counseling center directors annual survey URL: http://files.cmcglobal.com/AUCCCD_2013_Monograph_Public.pdf
[accessed 2018-05-16] [WebCite Cache ID 6zT9rC5tt]
20.
Horne JA, Ostberg O. A self-assessment questionnaire to determine morningness-eveningness in human circadian rhythms.
Int J Chronobiol 1976;4(2):97-110. [Medline: 1027738]
21.
Buysse DJ, Reynolds CF, Monk TH, Berman SR, Kupfer DJ. The Pittsburgh Sleep Quality Index: a new instrument for
psychiatric practice and research. Psychiatry Res 1989 May;28(2):193-213. [Medline: 2748771]
22.
John O, Srivastava S. Moityca.com.br. 1999. The Big Five trait taxonomy: History, measurement, and theoretical perspectives
URL: http://moityca.com.br/pdfs/bigfive_John.pdf [accessed 2018-05-18] [WebCite Cache ID 6zVEjcmQv]
23.
Cohen S, Kamarck T, Mermelstein R. A global measure of perceived stress. J Health Soc Behav 1983 Dec;24(4):385-396.
[Medline: 6668417]
24.
Ware J, Kosinski M, Keller SD. A 12-item short-form health survey: construction of scales and preliminary tests of reliability
and validity. Med Care 1996 Mar;34(3):220-233. [Medline: 8628042]
25.
Sano A, Picard RW, Stickgold R. Quantitative analysis of wrist electrodermal activity during sleep. Int J Psychophysiol
2014 Dec;94(3):382-389 [FREE Full text] [doi: 10.1016/j.ijpsycho.2014.09.011] [Medline: 25286449]
26.
Aharony N, Pan W, Ip C, Khayal I, Pentland A. Social fMRI: investigating and shaping social mechanisms in the real
world. Pervasive Mob Comput 2011 Dec;7(6):643-659. [doi: 10.1016/j.pmcj.2011.09.004]
J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 17
http://www.jmir.org/2018/6/e210/
(page number not for citation purposes)
Sano et al
JOURNAL OF MEDICAL INTERNET RESEARCH
XSL•FO
RenderX
27.
Cajochen C, Frey S, Anders D, Späti J, Bues M, Pross A, et al. Evening exposure to a light-emitting diodes (LED)-backlit
computer screen affects circadian physiology and cognitive performance. J Appl Physiol (1985) 2011 May;110(5):1432-1438
[FREE Full text] [doi: 10.1152/japplphysiol.00165.2011] [Medline: 21415172]
28.
Chang AM, Aeschbach D, Duffy JF, Czeisler CA. Evening use of light-emitting eReaders negatively affects sleep, circadian
timing, and next-morning alertness. Proc Natl Acad Sci U S A 2015 Jan 27;112(4):1232-1237 [FREE Full text] [doi:
10.1073/pnas.1418490112] [Medline: 25535358]
29.
Immersion. A people-centric view of your email life URL: https://immersion.media.mit.edu/ [accessed 2018-05-18] [WebCite
Cache ID 6zVK7Rb2d]
30.
Spielberger C. Manual for the State-Trait Anxiety Inventory (Form Y). Palo Alto, CA: Consulting Psychologists Press;
1983.
31.
Van den Broeck J, Cunningham SA, Eeckels R, Herbst K. Data cleaning: detecting, diagnosing, and editing data abnormalities.
PLoS Med 2005 Oct;2(10):e267 [FREE Full text] [doi: 10.1371/journal.pmed.0020267] [Medline: 16138788]
32.
Clifford GD, Lopez D, Li Q, Rezek I. Signal quality indices and data fusion for determining clinical acceptability of
electrocardiograms. 2011 Presented at: Computing in Cardiology; September 18-21, 2011; Hangzhou, China.
33.
Wood LB, Asada HH. Noise cancellation model validation for reduced motion artifact wearable PPG sensors using MEMS
accelerometers. 2006 Presented at: International Conference of the IEEE Engineering in Medicine and Biology Society;
August 30-September 03, 2006; New York, NY, USA. [doi: 10.1109/IEMBS.2006.260359]
34.
Engels J. Imputation of missing longitudinal data: a comparison of methods. J Clin Epidemiol 2003 Oct;56(10):968-976.
[doi: 10.1016/S0895-4356(03)00170-7]
35.
Schmitt P, Mandel J, Guedj M. A comparison of six methods for missing data imputation. J Biom Biostat 2015;6:224. [doi:
10.4172/2155-6180.1000224]
36.
Taylor S, Jaques N, Chen W, Fedor S, Sano A, Picard R. Automatic identification of artifacts in electrodermal activity data.
2015 Presented at: 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC);
August 25-29, 2015; Milan, Italy URL: http://europepmc.org/abstract/MED/26736662 [doi: 10.1109/EMBC.2015.7318762]
37.
Doberenz S, Roth WT, Wollburg E, Maslowski NI, Kim S. Methodological considerations in ambulatory skin conductance
monitoring. Int J Psychophysiol 2011;80(2):87-95. [doi: 10.1016/j.ijpsycho.2011.02.002]
38.
Dawson ME, Schell AM, Filion DL. The electrodermal system. In: Handbook of Psychophysiology. New York, NY, US:
Cambridge University Press; 2007:159-181.
39.
Wenzel A. The SAGE Encyclopedia of Abnormal and Clinical Psychology. Thousand Oaks, California: SAGE Publications,
Inc; 2017.
40.
Texas Instruments. TIDA-00824 Human Skin Temperature Sensing for Wearable Applications Reference Design URL:
http://www.ti.com/lit/ug/tiduay7/tiduay7.pdf [accessed 2018-05-16] [WebCite Cache ID 6zTAnV7XJ]
41.
Bolge SC, Flores NM, Phan JH. The burden of poor mental well-being among patients with type 2 diabetes mellitus:
examining health care resource use and work productivity loss. J Occup Environ Med 2016 Nov;58(11):1121-1126 [FREE
Full text] [Medline: 27820762]
42.
Wolff JL, Roter DL. Older adults' mental health function and patient-centered care: does the presence of a family companion
help or hinder communication? J Gen Intern Med 2012 Jun;27(6):661-668 [FREE Full text] [doi: 10.1007/s11606-011-1957-5]
[Medline: 22180197]
43.
Boucsein W, Fowles DC, Grimnes S, Ben-Shakhar G, Roth WT, Dawson ME, Society for Psychophysiological Research
Ad Hoc Committee on Electrodermal Measures. Publication recommendations for electrodermal measurements.
Psychophysiology 2012 Aug;49(8):1017-1034. [doi: 10.1111/j.1469-8986.2012.01384.x] [Medline: 22680988]
44.
Boucsein W. Electrodermal Activity. United States: Springer US; 2012.
45.
Thomée S, Härenstam A, Hagberg M. Mobile phone use and stress, sleep disturbances, and symptoms of depression among
young adults--a prospective cohort study. BMC Public Health 2011 Jan;11:66 [FREE Full text] [doi:
10.1186/1471-2458-11-66] [Medline: 21281471]
46.
Sano A, Phillips A, McHill A, Taylor S, Barger L, Czeisler C, et al. Influence of weekly sleep regularity on self-reported
wellbeing. Sleep 2017;40(suppl_1):A67-A68. [doi: 10.1093/sleepj/zsx050.181]
47.
Phillips AJK, Clerx WM, O'Brien CS, Sano A, Barger LK, Picard RW, et al. Irregular sleep/wake patterns are associated
with poorer academic performance and delayed circadian and sleep/wake timing. Sci Rep 2017 Jun 12;7(1):3216 [FREE
Full text] [doi: 10.1038/s41598-017-03171-4] [Medline: 28607474]
48.
Canzian L, Musolesi M. Trajectories of depression: unobtrusive monitoring of depressive states by means of smartphone
mobility traces analysis. 2015 Presented at: Proceedings of the 2015 ACM International Joint Conference on Pervasive and
Ubiquitous Computing; September 7-11, 2015; Osaka, Japan. [doi: 10.1145/2750858.2805845]
49.
Jaques N, Taylor S, Azaria A, Ghandeharioun A, Sano A, Picard R. Predicting students' happiness from physiology, phone,
mobility, and behavioral data. 2015 Presented at: International Conference on Affective Computing and Intelligent Interaction
(ACII); September 21-24, 2015; Xi'an, China URL: http://europepmc.org/abstract/MED/28515966 [doi:
10.1109/ACII.2015.7344575]
50.
Tibshirani R. Regression selection shrinkage via the Lasso. J R Stat Soc Series B Stat Methodol 2011;73(3):273-282. [doi:
10.1111/j.1467-9868.2011.00771.x]
J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 18
http://www.jmir.org/2018/6/e210/
(page number not for citation purposes)
Sano et al
JOURNAL OF MEDICAL INTERNET RESEARCH
XSL•FO
RenderX
51.
Kohavi R, John GH. Wrappers for feature subset selection. Artif Intell 1997 Dec;97(1-2):273-324. [doi:
10.1016/S0004-3702(97)00043-X] [Medline: 356583]
52.
Forman G, Scholz M. Apples-to-apples in cross-validation studies: pitfalls in classifier performance measurement. SIGKDD
Explor 2010;12:49-57. [doi: 10.1145/1882471.1882479]
53.
Agresti A, Coull BA. Approximate is better than “Exact” for interval estimation of binomial proportions. Am Stat 1998
May;52(2):119-126. [doi: 10.1080/00031305.1998.10480550]
54.
Healey JA, Picard RW. Affect.media.mit.edu. 2005. Detecting Stress During Real-World Driving Tasks Using Physiological
Sensors URL: https://affect.media.mit.edu/pdfs/05.healey-picard.pdf [accessed 2018-05-18] [WebCite Cache ID 6zVI8MWT1]
55.
Hernandez J, Morris RR, Picard RW. Call Center Stress Recognition with Person-Specific Models. 2011 Presented at:
International Conference on Affective Computing and Intelligent Interaction; October 09-12, 2011; Memphis, USA. [doi:
10.1007/978-3-642-24600-5_16]
56.
Setz C, Arnrich B, Schumm J, La Marca R, Tröster G, Ehlert U. Discriminating stress from cognitive load using a wearable
EDA device. IEEE Trans Inf Technol Biomed 2010 Mar;14(2):410-417. [doi: 10.1109/TITB.2009.2036164] [Medline:
19906598]
57.
Ward NG, Doerr HO, Storrie MC. Skin conductance: a potentially sensitive test for depression. Psychiatry Res 1983
Dec;10(4):295-302. [Medline: 6583718]
58.
Argyle N. Skin conductance levels in panic disorder and depression. J Nerv Ment Dis 1991 Sep;179(9):563-566. [Medline:
1919559]
59.
Rottenberg J. Mood and emotion in major depression. Curr Dir Psychol Sci 2005;14(3):167-170. [doi:
10.1111/j.0963-7214.2005.00354.x]
60.
Nutt D, Wilson S, Paterson L. Sleep disorders as core symptoms of depression. Dialogues Clin Neurosci 2008;10(3):329-336
[FREE Full text] [Medline: 18979946]
61.
Abad VC, Guilleminault C. Sleep and psychiatry. Dialogues Clin Neurosci 2005;7(4):291-303 [FREE Full text] [Medline:
16416705]
62.
Vinkers CH, Penning R, Hellhammer J, Verster JC, Klaessens JH, Olivier B, et al. The effect of stress on core and peripheral
body temperature in humans. Stress 2013 Sep;16(5):520-530. [doi: 10.3109/10253890.2013.807243] [Medline: 23790072]
63.
Sano A, Picard RW. Comparison of sleep-wake classification using electroencephalogram and wrist-worn multi-modal
sensor data. Conf Proc IEEE Eng Med Biol Soc 2014;2014:930-933 [FREE Full text] [doi: 10.1109/EMBC.2014.6943744]
64.
Barbini B, Benedetti F, Colombo C, Guglielmo E, Campori E, Smeraldi E. Perceived mood and skin body temperature
rhythm in depression. Eur Arch Psychiatry Clin Neurosci 1998;248(3):157-160. [Medline: 9728735]
65.
Zschucke E, Gaudlitz K, Ströhle A. Exercise and physical activity in mental disorders: clinical and experimental evidence.
J Prev Med Public Health 2013 Jan;46 Suppl 1:S12-S21 [FREE Full text] [doi: 10.3961/jpmph.2013.46.S.S12] [Medline:
23412549]
66.
Vollrath M. Personality and stress. Scand J Psychol 2001;42(4):335-347. [Medline: 11547909]
67.
Ebstrup JF, Eplov LF, Pisinger C, Jørgensen T. Association between the Five Factor personality traits and perceived stress:
is the effect mediated by general self-efficacy? Anxiety Stress Coping 2011 Jul;24(4):407-419. [doi:
10.1080/10615806.2010.540012] [Medline: 21213153]
68.
van Straten A, Cuijpers P, van Zuuren FJ, Smits N, Donker M. Personality traits and health-related quality of life in patients
with mood and anxiety disorders. Qual Life Res 2007 Feb;16(1):1-8 [FREE Full text] [doi: 10.1007/s11136-006-9124-x]
[Medline: 17033892]
69.
Götz FM, Stieger S, Reips UD. Users of the main smartphone operating systems (iOS, Android) differ only little in
personality. PLoS One 2017 May;12(5):e0176921 [FREE Full text] [doi: 10.1371/journal.pone.0176921] [Medline:
28467473]
70.
Mayor E. Gender roles and traits in stress and health. Front Psychol 2015 Jun;6:779 [FREE Full text] [doi:
10.3389/fpsyg.2015.00779] [Medline: 26106354]
71.
Zuckerman DM. Stress, self-esteem, and mental health: How does gender make a difference? Sex Roles 1989
Apr;20(7-8):429-444. [doi: 10.1007/BF00288001]
72.
Sigmon ST, Pells JJ, Boulard NE, Whitcomb-Smith S, Edenfield TM, Hermann BA, et al. Gender differences in self-reports
of depression: the response bias hypothesis revisited. Sex Roles 2005;53(5-6):401-411. [doi: 10.1007/s11199-005-6762-3]
73.
Sandanger I, Nygård JF, Sørensen T, Moum T. Is women's mental health more susceptible than men's to the influence of
surrounding stress? Soc Psychiatry Psychiatr Epidemiol 2004 Mar;39(3):177-184. [doi: 10.1007/s00127-004-0728-6]
[Medline: 14999449]
74.
Verma R, Balhara YP, Gupta CS. Gender differences in stress response: role of developmental and biological determinants.
Ind Psychiatry J 2011 Jan;20(1):4-10 [FREE Full text] [doi: 10.4103/0972-6748.98407] [Medline: 22969173]
Abbreviations
ACC: acceleration
E-diary: electronic diary
J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 19
http://www.jmir.org/2018/6/e210/
(page number not for citation purposes)
Sano et al
JOURNAL OF MEDICAL INTERNET RESEARCH
XSL•FO
RenderX
FDR: false discovery rate
HRV: heart rate variability
LASSO: least absolute shrinkage and selection operator
MCS: mental component summary
MIT: Massachusetts Institute of Technology
PHQ-9: patient health questionnaire-9
PSS: perceived stress scores
RBF: radial basis function
REM: rapid eye movement
SC: skin conductance
SF-12: 12-Item Short Form Health Survey
SMS: short message service
SRI: Sleep Regularity Index
ST: skin temperature
SVM: support vector machine
SWS: slow-wave sleep
Edited by G Eysenbach; submitted 13.11.17; peer-reviewed by S Saeb, L Barnes, C Gorrostieta, J Apolinário-Hagen; comments to
author 16.12.17; revised version received 24.02.18; accepted 22.04.18; published 08.06.18
Please cite as:
Sano A, Taylor S, McHill AW, Phillips AJK, Barger LK, Klerman E, Picard R
Identifying Objective Physiological Markers and Modifiable Behaviors for Self-Reported Stress and Mental Health Status Using
Wearable Sensors and Mobile Phones: Observational Study
J Med Internet Res 2018;20(6):e210
URL: http://www.jmir.org/2018/6/e210/
doi: 10.2196/jmir.9410
PMID: 29884610
©Akane Sano, Sara Taylor, Andrew W McHill, Andrew JK Phillips, Laura K Barger, Elizabeth Klerman, Rosalind Picard.
Originally published in the Journal of Medical Internet Research (http://www.jmir.org), 08.06.2018. This is an open-access article
distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which
permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal
of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on
http://www.jmir.org/, as well as this copyright and license information must be included.
J Med Internet Res 2018 | vol. 20 | iss. 6 | e210 | p. 20
http://www.jmir.org/2018/6/e210/
(page number not for citation purposes)
Sano et al
JOURNAL OF MEDICAL INTERNET RESEARCH
XSL•FO
RenderX


Paper 3:
- APA Citation: Kim, A., Park, M., & Lee, D. H. (2020). AI-IDS: Application of Deep Learning to Real-Time Web Intrusion Detection. IEEE Access, 8, 70245–70261. http://dx.doi.org/10.1109/ACCESS.2020.2986882
  Main Objective: This study presents the Artificial Intelligence-based Intrusion Detection System (AI-IDS) which demonstrates the efficacy of AI and machine learning in performing network security operations and provides a comprehensive evaluation of the system's performance against real-world cyber threats.
  Study Location: Unspecified
  Data Sources: Real-world HTTP traffic, KDD Cup 1999 Dataset, CICIDS2017
  Technologies Used: Deep Learning, Convolutional Neural Network (CNN), Long Short-Term Memory Network (LSTM)
  Key Findings: The AI-IDS is a deep learning-based intrusion detection system that leverages SFL and payload-level deep learning techniques. The AI-IDS can identify both known and unknown attacks, and can be used to write or improve signature-based rules for new vulnerabilities and attack variants.
  Extract 1: "The Attacker attempts to attack by sending exploitational code using a vulnerability in a specific domain or path file of the webserver. Web-attacks often exploit vulnerabilities in applications in open web services rather than perform a host-level system penetration"
  Extract 2: "The above is a description of the KDD Cup 1999 Dataset [20]. The dataset contains TCP high-level attributes, such as the connection window, but no IP addresses. KDD99 involves more than 20 different types of attacks and comes along with redundant records in the test-set [21]."
  Limitations: None
  Relevance Evaluation: This article is highly relevant to my point as it introduces AI to network security operations, and evaluates the AI system’s performance against real-world cyber threats, such as unauthorized access and the use of malware.
  Relevance Score: 1.0
  Inline Citation: Aechan Kim; Mohyun Park; Dong Hoon Lee
  Explanation: This article presents the Artificial Intelligence-based Intrusion Detection System (AI-IDS) which demonstrates the efficacy of AI and machine learning in performing network security operations and provides a comprehensive evaluation of the system's performance against real-world cyber threats.

 Full Text: >
This website utilizes technologies such as cookies to enable essential site functionality, as well as for analytics, personalization, and targeted advertising purposes. To learn more, view the following link: Privacy Policy Manage Preferences Loading [MathJax]/extensions/MathMenu.js IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Subscribe Donate Cart Create Account Personal Sign In Browse My Settings Help Institutional Sign In All Books Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 8 AI-IDS: Application of Deep Learning to Real-Time Web Intrusion Detection Publisher: IEEE Cite This PDF Aechan Kim; Mohyun Park; Dong Hoon Lee All Authors 107 Cites in Papers 13274 Full Text Views Open Access Comment(s) Under a Creative Commons License Abstract Document Sections I. Introduction II. Background III. Security Operations for Deep Learning IV. Design and Implementation V. Experiments Show Full Outline Authors Figures References Citations Keywords Metrics Footnotes Abstract: Deep Learning has been widely applied to problems in detecting various network attacks. However, no cases on network security have shown applications of various deep learning algorithms in real-time services beyond experimental conditions. Moreover, owing to the integration of high-performance computing, it is necessary to apply systems that can handle large-scale traffic. Given the rapid evolution of web-attacks, we implemented and applied our Artificial Intelligence-based Intrusion Detection System (AI-IDS). We propose an optimal convolutional neural network and long short-term memory network (CNN-LSTM) model, normalized UTF-8 character encoding for Spatial Feature Learning (SFL) to adequately extract the characteristics of real-time HTTP traffic without encryption, calculating entropy, and compression. We demonstrated its excellence through repeated experiments on two public datasets (CSIC-2010, CICIDS2017) and fixed real-time data. By training payloads that analyzed true or false positives with a labeling tool, AI-IDS distinguishes sophisticated attacks, such as unknown patterns, encoded or obfuscated attacks from benign traffic. It is a flexible and scalable system that is implemented based on Docker images, separating user-defined functions by independent images. It also helps to write and improve Snort rules for signature-based IDS based on newly identified patterns. As the model calculates the malicious probability by continuous training, it could accurately analyze unknown web-attacks. Topic: Scalable Deep Learning for Big Data AI-IDS Architecture. Published in: IEEE Access ( Volume: 8) Page(s): 70245 - 70261 Date of Publication: 10 April 2020 Electronic ISSN: 2169-3536 DOI: 10.1109/ACCESS.2020.2986882 Publisher: IEEE CCBY - IEEE is not the copyright holder of this material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/ to obtain full-text articles and stipulations in the API documentation. SECTION I. Introduction As technology evolves, cyber-criminals are also improving their attack methods, tools, and techniques to exploit organizations. In particular, public web-services are common services that anyone can access, and many companies provide their services through open webpages. If a web-service fails or is compromised, it can cause a drop in corporate reputation or revenue. In general, security managers prevent intrusions from external attacks by registering all denied black-list policies for unused services in the firewall, but web-services in the Internet Demilitarized Zone (DMZ) cannot be blocked by firewalls because they are always open to public access. As such, identifying normal access and differentiating it from malicious attacks is an important task in cybersecurity. In reality, many security incidents originated with web-attacks such as information disclosure, service failures, and malware infections. Hypertext transfer protocol (HTTP) [1] is an application-level protocol for distributed, collaborative, and hypertext information systems. Today’s HTTP is evolving where the information is transferred from web pages, and it is also used for exchanges or sending system commands to various devices, such as command-lines, update scripts, and mobile apps. Web-attacks often exploit vulnerabilities in applications in open web services rather than perform a host-level system penetration. The attacker attempts to attack by sending exploitational code using a vulnerability in a specific domain or path file of the webserver. The webserver or device that is injected with the code can subsequently be compromised by the attacker [2]. Traditionally, intrusion detection is a major research field in network security, as it is important to identify unusual access to secure internal networks. An Intrusion Detection System (IDS) is used to identify intrusions, attacks, or violations of security policies in a network or host system promptly [3]. An IDS system that inspects a packet of networks to detect attacks is called Network Intrusion Detection System (NIDS). An NIDS is collected using network equipment via mirroring by network devices, such as switches, routers, and network terminal access points (TAP), which is a surveillance device for monitoring network infringements and policy violations [4]. Many organizations operate NIDS with firewalls and an application firewall (L7) to protect webservers that are on the same network and system. An NIDS runs mostly signature-based detection by Snort IDS rules. The analyst writes a user-defined pattern into the rules to detect an attack. When there is a malicious payload on the network traffic, the rule triggers security events, including detection time, source/destination IP (metadata), and some raw packets (payloads). String or pattern match is reliable and generates very few false alarms but does not identify unknown or irregular pattern attacks. Recent sophisticated cyber-attacks use irregular patterns such as encoding and obfuscation to bypass security systems. To solve these problems, we applied AI-IDS to detect variant attacks that cannot be identified by legacy signature-based NIDS. A. List of Contributions The main contributions of this paper are summarized as follows: 1) Applying Deep Learning to Real-World Networks We have successfully applied AI-IDS to big-data scale traffic. The AI-IDS is a flexible and scalable system that is implemented based on Docker images, and separates user-defined functions by independent images. 2) Propose a Fast and Effective Preprocessing Method We implemented fast and effective spatial feature learning through normalized UTF-8 character encoding, even if we do not apply computationally intensive algorithms, such as entropy, compression, and encryption. For example, the entropy of a string requires probability calculation, followed by multiplication and logarithm. Instead, our proposed method can preprocess strings with a single operation. 3) Propose Optimized CNN-LSTM Model for Big Data We demonstrated the process of model design in detail via performance evaluation between CNN-LSTM, LSTM-CNN, and DNN models based on fixed real-time data from HTTP request packets. Hyper-parameters were determined in each model through repeat experiments. An optimized neural network model was validated through experiments on public datasets (CSIC-2010, CICIDS2017) and fixed real-time data. 4) Prove of Efficacy and Application We proved that AI-IDS could detect unknown attacks, such as obfuscated or encoded malicious payloads; it can write improved existing Snort rules and new rules for newly identified patterns. B. Conditions and Assumptions This study uses the following conditions and assumptions: 1) AI-IDS: an Open Source Software AI-IDS software contains the following license and notice below: Licensed under the MIT License. You can access the source-code directly on Github in our repositories [5]. 2) Parallel Operations: IDS, TAS An IDS and a Traffic Analysis System (TAS) operate independently and do not affect each other. We used a signature-based NIDS for intrusion detection and a Splunk StreamApp-based TAS for collecting real-time traffic. A TAS is equal to a packet monitoring system. 3) Application-Level Packets Inspection We focused on the HTTP commonly used in web services that request headers and payload data. We did not address low-risk attacks from protocols below the application layer, such as user datagram protocol (UDP). The remainder of this paper is organized as follows. Section II presents related works, limitations of meta-datasets, and the motivation for this study. Section III introduces the security operations for deep learning. Section IV shows our spatial feature learning algorithms for big-data, optimal CNN-LSTM model, and AI-IDS infrastructure. Section V shows the experimental results. Section VI introduces the efficacy and applications. The last Section VII shows the conclusion. SECTION II. Background This section describes related studies on deep learning-based IDS, and the limitations of meta-datasets and the motivation for this study are also described. A. Related Works Recent studies on intrusion detection using various deep learning (DL) techniques have been published since 2017. In Table 1, related studies focusing on intrusion detection using DL algorithms based on models, features, datasets, and performance measures are given. Liu et al. [6] showed that when compared with other IDS classifiers, intrusion detection models based on a convolutional neural network (CNN) have the highest detection rate and precision. The feasibility of applying a CNN in highly intruded detection has been proven. The authors argue that the performance of CNN-based techniques is better than that of other machine learning classification techniques. Wang et al. [7] designed an IDS using a CNN to automatically train and look for traffic characteristics, effectively reducing the false alarm rate (FAR). This study shows that deep learning techniques can be used to extract and learn the characteristics of network traffic in detail. Yin et al. [8] proposed an RNN-IDS and compared it with ANN, random forest (RF), SVM, and other machine learning methods. An RNN-IDS is suitable for modeling a classification model with high accuracy, and its performance is superior to that of traditional machine learning classification methods in both binary and multiclass classification. TABLE 1 Related Works on Intrusion Detection. Shone et al. [9] showed a non-symmetric deep auto-encoder (NDAE) for unsupervised feature learning. This study improves the classification performance of KDD99 and NSL-KDD99 by comparing an auto-encoder with a non-symmetric deep auto-encoder (NDAE). Wu et al. [10] devised CNN and RNN for attack detection; however, their model differs from the model used in this study because it performed separate experiments on the CNN and RNN model. Naseer et al. [11] investigated the suitability of deep learning approaches for anomaly-based intrusion detection systems. Ding and Zhai [12] compared the performance of models using multi-class classification with the performance of traditional machine learning methods. Otoum et al. [13] devised DL for an IDS available on wireless sensor networks (WSNs), and also compared the Boltzmann machine-based clustered IDS (RBC-IDS) and adaptive machine learning-based IDS: the adaptively supervised and clustered hybrid IDS (ASCH-IDS). Chouhan et al. [14] proposed a Channel Boosted and Residual learning-based deep Convolutional Neural Network (CBR-CNN) architecture for the detection of network intrusions. This study used Stacked Auto-encoders (SAE) and unsupervised training, and the performance of the proposed CBR-CNN technique is evaluated with an NSL-KDD dataset. Vinayakumar et al. [15] developed an IDS to detect and classify unforeseen and unpredictable cyberattacks by DNN. The performance was tested with the DNN model and compared to the results of the NSL-KDD, UNSW-NB15, Kyoto, WSN-DS, and CICIDS2017 datasets. Chiba et al. [16] proposed a DNN model in a cloud environment based anomaly network IDS using recent datasets, such as CICIDS2017, NSL-KDD version 2015, and CIDDS-001, using a hybrid optimization framework (IGASAA) based on the Improved Genetic Algorithm (IGA) and Simulated Annealing Algorithm (SAA). Zhang et al. [17], used a deep belief network (DBN) model to identify SQL injection attacks in network traffic. Faker and Dogdu [18] experimented with improving the performance of intrusion detection systems on CICIS2017 and UNSW NB15 datasets using a DNN and two ensemble techniques, RF and gradient boosting tree (GBT). Previous research has suggested new ideas or algorithms for improving deep learning algorithms. Aloqaily et al. [19] introduced an automated secure continuous cloud service availability framework for smart connected vehicles that enables an intrusion detection mechanism against security attacks. However, most previous deep learning-based studies have difficulty applying intrusion detection in real-world environments because the models were usually pre-processed into metadata formats in an experimental environment. Few studies have proven how to apply them in real-time in the real world. B. Limitations of Meta-Datasets Previous studies [8], [12], [15], [16] mainly focused on extracting or analyzing features from metadata rather than paying attention to exploited raw packets. Owing to network traffic changing with trends, the accuracy rates of real-world without continuous re-training is significantly reduced even if a system is 99.9% accurate in an experimental environment. The following is a description of the KDD99, NSL-KDD, and PU-IDS datasets that have been widely used in previous works. 1) KDD Cup 1999 Datasets KDD Cup 1999 Dataset [20] is the most widespread dataset for intrusion detection based on the DARPA dataset. The dataset contains TCP high-level attributes, such as the connection window, but no IP addresses. KDD99 involves more than 20 different types of attacks and comes along with redundant records in the test-set [21]. 2) NSL-KDD Datasets NSL-KDD [22] NSL-KDD is a dataset that has been enhanced from KDD99, removing much of the duplicated data from KDD99 and creating a more advanced sub-dataset. The dataset consists of separate and predefined training data and test data for intrusion detection. NSL-KDD uses the same attributes as KDD 99 and belongs to the four attack categories: R2L, Prob, U2R, and DOS. belongs to the other category [23]. 3) PU-IDS Datasets PU-IDS [24] is a derivative of the NSL-KDD data set, and its author has developed a generator that extracts the statistics of the input data set and then creates a new data set. A traffic generator has the same attributes and format as the NSL-KDD data set. While previous studies mainly used KDD99 or KDD, and NSL-KDD, they are not suitable as datasets for real-time detection. These datasets deal with metadata and therefore make it difficult to identify invalid attacks in a practical environment, because metadata are not attack-attempts. Moreover, most public datasets contain redundant information and an unbalanced number of categories. For instance, Ring et al. [21] compared the characteristics of intrusion detection datasets used in previous works. This study shows that various previously published datasets model repetitive and inefficient attacks, such as DOS, UDP Flooding, and brute force, which are different to recent web-attacks trends. In fact, types of attacks and trends in the data are constantly changing; therefore, it is necessary to develop a general-purpose model that is not biased toward current trends. Another problem with most published datasets is that they are often over-fitted due to duplicated or flow-based metadata, and the performance of the model is significantly upgraded in experimental conditions. If the model is applied in practical services, it will face a serious problem with false-positive alarms. Likewise, the work in Sabhnani and Serpen [25] has shown that when using the KDD99 dataset, it is not possible to successfully train pattern classifications or machine learning algorithms for misuse detection. Nevertheless, most previous studies measured the model performance on deep learning or machine learning techniques in experiments using KDD99 datasets. Yin et al. [8] also used the KDDTest +- dataset to compare performance with the RNN model, and a recent work in Vinayakumar et al. [15] experimented using the DNN model through public data such as KDD99, NSL-KDD, and UNSW-NB15 using machine learning techniques such as LR, NB, RF, and DT. Gu et al. [26] demonstrated that validated training data is an essential determinant for successful research that can greatly enhance the detection capability. Moreover, Moustafa et al. [27] compared the characteristics of various public datasets and suggested that datasets that are not based on reality can lead to misguided research. C. Motivation One of the challenges faced by security operations is an inefficient operation due to false-positive alarm events. It wastes IDS resources and reduces the performance for effective deep learning; therefore, the issue of false-positives should be addressed properly to detect threats in big-data infrastructure. Misuse detection that broadly applied in SOC uses predefined signatures for filtering and to detect attacks. It relies on human inputs by constantly updating the signature database. This method is accurate in finding known attacks but is completely ineffective for unknown attacks. In most cases in real-world environments, misuse detection generates a high false-positive rate similar to anomaly-based IDS. In the study of Mishra et al. [4], performance optimization was needed during the detection process to deal with false-positive issues. However, most previous works do not adequately address the false-positives issue in the real-world due to performance evaluations with limited datasets in experimental environments. To mitigate the false-positive problem, high-quality training data is a basic determinant for improving DL model performance. The most common issues with existing solutions based on learning models include First, the learning models produce a high false-positive rate with a wide range of attacks. Second, the learning models are not adaptive to the real-world, as meta-datasets like KDD Cup 99 were mainly used to evaluate the performance of the learning model. Third, previous studies were unable to foresee today’s huge network traffic; therefore, scalable solutions are required to maintain a high performance with a rapidly increasing high-speed network size. Finally, no cases have been published on DL applications for the detection of unknown attacks on real-world computer networks. These challenges form the primary motivation for the application of deep learning-based NIDS. SECTION III. Security Operations for Deep Learning This section introduces the security operations for deep learning applications and the data design for practical training. A. Overview of Security Operations We detected and analyzed intrusion attempts into financial networks to protect electronic financial incidents. The SOC also plays the role of an Information Sharing and Analysis Center (KF-ISAC). Fig. 1 shows that the SOC collected real-time network traffic, and detected malicious network traffic by directly installing an NIDS, a TAS, a TAP, and a virtual private network (VPN) on the Internet DMZ area of many financial companies in South Korea. The SOC operated continuously for 24 hours a day, 7 days a week, and 365 days a year. About 20 people work in shifts and generate daily analytical information for training. The IDS and TAS data were transferred to the SOC via VPN from financial institutions, and the SOC collected approximately 1 billion real-time HTTP traffic per day (Sep. 2019). FIGURE 1. AI-IDS applied Security Operations Center (SOC). Show All An NIDS is a signature-based misuse detection system based on Snort rules, and a TAS is a system that collects network traffic in a user-defined function. A TAS is a type of system that collects network traffic and enables users to analyze traffic by collecting various protocols, including HTTP, SMTP, and SSH. It allows analysts to analyze anomalies by collecting various network protocols from the network layer to the application layer. We use the StreamApp [28] as a Splunk software for traffic collection and an analysis system. For the effective detection and analysis of cyber-attacks, we recommend running NIDS and TAS in parallel. If security events are alerted on an NIDS, a TAS could inspect the same malicious payloads on the network. An NIDS and a TAS inspected a variety of protocols, such as SSDP, DNS, SMTP, POP3, HTTP, and SSL, from the network layer to the application layer on the network. As the UDP-based protocol does not establish 3-ways handshaking, it is difficult to attribute it to an IP address and can easily be forged. Thus, we did not analyze invalid UDP-type or denial of service (DOS) attacks to maintain stable performance. SSL protocol was excluded from our scope because it is not possible for an analyst to review the malicious payload. In managed security monitoring operations, security managers process security events in the order of Detection, Analysis, and Prevention. “Detection” means to collect security alerts generated by user-defined Snort rules on NIDS or TAS, which include detection time, source IP, destination IP, port information and signature messages in Table 2. “Analysis” refers to classifying events into true or false positives by reviewing detection information. “Prevention” is to register malicious IP addresses to blacklists, which are then blocked from accessing service websites. Prevention is applied to very obvious attack patterns, and it is recommended to block access from certain attacks only after being verified by an analyst or system. The proposed AI-IDS is used as a supplement system with legacy signature-based NIDSs for network layer security. TABLE 2 Attributes of Analysis Information. B. Data Design for Practical Training The proposed AI-IDS trains the labeled analysis information based on HTTP data in-bounding from the managed services instead of metadata sets in a constrained environment. We detect about 200,000 attacks on about 1 billion HTTP per day on legacy signature-based NIDS, and we perform about 10,000 automatic and manual analyses. During general security operations, malicious detection information is triggered by NIDS when an attack packet occurs in the network communication. Daily training-data on the production environment is labeled in real-time by security analysts using labeling tools. The analysis information labeled is shared with AI-IDS and used as training data for prediction in neural networks. We implemented deep learning models in real-time HTTP traffic– “Password guessing and Authentication bypass (AUT),” “SQL Injection (SQL),” and “Application vulnerability attack (APP).” For UDP-type attacks, such as “information gathering” or “denial of service,” it is difficult to identify the attacker’s IP address when compared to TCP, because the session is not connected perfectly, and contains meaningless repeated data; therefore, we excluded it from the deep learning model. Besides, HTTP traffic related to malware infection events are often detected when the malware connects to the C2 server after infection. Unlike general intrusion events of which traffic are sent from an external IP to an internal IP, malware events’ traffic is usually in the opposite direction. The security event shown in Table 2 consists of the detection time, detection site, direction, source IP, source port, destination IP, destination port, signature name, raw packet (pcap file), and flag. “Detection Time” is the time the signature generated the event, and “Detection Site” is the location identifier where IDS and TAS were installed. “Direction” shows the direction of attacks based on assets between the source IP and the destination IP. “Source IP/port (src_ip, src_port)” is the IP/Port address that requests a connection from the client to the server, and “Destination IP/port (dest_ip, dest_port)” is the IP/Port address from the server to the client. Most of the above metadata are managed as Critical IP or Threat Intelligence by security administrators. The number of HTTP requests collected per day was approximately 1 billion, of which about ten thousand were analyzed information about attack events detected in HTTP. Assuming a normal to abnormal ratio of 5:5, the amount of malicious analysis information is 65 MB for the last year, but benign HTTP traffic is 6 GB per day. To equalize the data rate for training in the deep learning model, the 65 MB HTTP payload, which was analyzed during one year, was multiplied 100 times by concatenation and shuffle, and the ratio of the analysis information and normal traffic was adjusted to be equal to 6 GB per day. Malicious events identified by analysts were used as data for re-training. The training data was approximately 6 GB per day, and the analysis information from the duration of 1 year was changed sequentially like a sliding window. SECTION IV. Design and Implementation This section introduces a fast and effective spatial feature learning based on normalized UTF-8 character encoding, detailed AI-IDS architecture, and the structure of a neuron network model for large-scale web traffic. A. Spatial Feature Learning Based on Normalized UTF-8 Character Encoding Feature extraction is one of the most important tasks in designing an efficient learning algorithm. Mamun et al. [29] devised a combined preprocessing technique using attributes of information theory such as entropy, encoding, and compression. Theoretically, the entropy of encrypted or irregular data is high as there are many uncertainties in the data stream. The entropy value indicates the degree of uncertainty of the information, but it is difficult to extract the feature by matching the unique characters of the given data 1:1. For example, entropy can express the uncertainty of information as a number in the range of 0 to 1, but a collision problem would be calculated with the same entropy even if different data were given. For this reason, it is difficult to extract unique features of a given string, as it is. Thus, we use UTF-8 encoding that normalizes the deep learning model to recognize the data with its own characteristics. It is simple and fast, because it does not include unnecessary entropy calculations, compression, encryption, or anything else. Assuming that all data preprocessing for billions of HTTP within 1,000 bytes per day is executed, the UTF-8 encoding method can achieve fast data preprocessing at only about 1× 2 8 ×1,000 billion. The biggest advantage of UTF-8 is that it cannot be confused with a single encoding method, so there is no possibility of wrong encoding in other ways, such as for the national language encoding method such as UTF-16, EUC-KR (Korean), GB2312 (Simplified Chinese). As both browsers and web servers are now developed assuming UTF-8, it is a very efficient way to preprocess HTTP traffic. UTF-8 encoding in Algorithms 1–2 converts up to 256 characters into floats, which can be encoded into numbers, including special characters that include Simplified Chinese in the packet, such as WebDAV attacks. When preprocessing a string of 7 bits or less, it is difficult to preprocess various characters in a real environment. We used the normalized UTF-8 encoding and the module developed on “parse” and shown in Figs. 2 and 3. The input variable was replaced with a value corresponding to a unique string in the range of 0 to 255 (256 features), and the input string was converted into a float value between −1.000 and 1.000 given that y s =−( y s −128)/128 . The output variables y s for a transformed set of input data, for one training-data size s∈[0,2,3,…,999] . FIGURE 2. Comparison of normalized UTF-8 encoding and entropy-based encoding. Show All FIGURE 3. AI-IDS architecture. Show All Algorithm 1 UTF-8 Character Encoding Input: content_string (web traffic) Output: *.npy (preprocessed file) 1: FUNCTION save_data(content_string_list, npy_filename) 2: numpy_array < - numpy.empty() 3: FOR content_string in content_string_list 4: byte_array < - [] 5: FOR character in content_string 6: byte_array.append(character.encode(‘utf-8’) 7: ENDFOR 8: int8_array < - [] 9: FOR byte in byte_array 10: int8_array.append(byte.toint8()) 11: ENDFOR // //float_array < - [] //FOR int_8 in int8_array // float_array.append(int_8 - 128.0 / −128.0) //ENDFOR // //content_array < - numpy.array(float_array) //numpy.append(content_array) // // for data size issues, // the actual array is saved from int8_array // and the float is calculated just before training 12: content_array < - numpy.array(int8_array) 13: numpy.append(content_array) 14: ENDFOR 15: numpy.save(npy_filename, numpy_array) 16: ENDFUNCTION Algorithm 2 Spatial Feature Learning (train/test) Input: *.h5(model), *.npy (preprocessed file) Output: performance metrics 1: FUNCTION train_model(model, train_file_list, x_dim): 2: npy_list < - list(load(filename) for filename in train_file_list 3: data < - concatenate(npy_list) 4: train_size < - data.shape[0] 5: x_train < - array(data[:,:−1]) 6: x_train < - (x_train −128.0) / −128.0 7: x_train < - x_train.reshape(train_size, x_dim, 1) 8: y_train < - data[:, [−1]].reshape(train_size, 1) 9: y_prediction < - model.predict(x_train, batch_size = 4096) 10: y_merged < - (y_prediction.round()*2+y_train).flatten() 11: value, counts < - unique(y_merged, return_counts = True) 12: value_str < - list(map(lambda x: str(int(x)), value)) 13: metrics < - dict(zip(value_str, counts)) 14: loss < - binary_crossentropy(y_train, y_prediction)) 15: metrics[‘Loss’] < - average(loss) 16: RETURN metrics 17: ENDFUNCTION Fig. 2 shows a preprocessing example for “http://target.com/manager/html/.” When comparing preprocessing methods with our proposed UTF-8 encoding and entropy-based encoding, our proposed method is a normalized calculation expression. The entropy of a string requires probability calculation, followed by multiplication and logarithm. Entropy-based preprocessing involves two steps of calculating the probability of each string and then calculating the log. Instead, our proposed method can preprocess strings with a single operation and have no data transformation or substitution in the progress. Normalized UTF-8 encoding generates input values so that the deep learning model can train immediately. Previous [30] research designed a CNN that can be trained as a corpus to process natural language between sentences and words. However, it functions closer to image processing than natural language processing because cybersecurity corpora have a different attribution compared with natural language. A corpus in the field of cybersecurity is difficult to create because it needs to understand string classifications and attributes, for example, “get, post, head, put, php, cgi, admin, wget, ‘POST /manager/html’, ‘User-Agent: Mozilla/5.0’.” In our initial model, we were trying to train the security corpus into the CNN filter and LSTM layers. However, as there is currently not enough research on cybersecurity corpora, we have implemented deep learning on all strings of the HTTP data. If a cybersecurity’s corpus was created, deep learning model performance is expected to be improved. B. AI-IDS Architecture Fig. 3 shows an enlarged representation of the AI-IDS and Index Cluster, as shown in Fig. 1. Individual modules are configured as Docker image/containers that output files after the Docker process. No Docker container affects another and they all run independently. However, Docker volumes are shared as same data in a series of processes, from pre-processing (parsing), training and testing, to prediction. Our AI-IDS process is as follows: (i) data save and splitting - collecting web traffic and splitting training data for each model (ii) data preprocessing and training by labeled analysis information (iii) prediction for suspicious payloads on new web-traffic. The following is a detailed process description of the AI-IDS, as shown in Fig. 3: 1) Data Save and Splitting Index Cluster collects true or false positive analysis information and normal traffic for training data and then stores it in “(labeled analysis info) data_save” (name of docker image). “data_save” saves legacy NIDS payload data along with its analysis results, and also previously labeled data by AI-IDS. Simultaneously, “(new traffic) data_save” stores real-time HTTP traffic for prediction in “ai_payloads” for the previous 3h to −10 min. “data_split” saves data in “ai_payloads” by splitting the data according to the intrusion attack types (AUT, SQL, APP) to generate training data for each deep learning model. Each process module has one or more input and output files. The real-time web traffic is transferred into application-level strings for AI-IDS, and the “data_backup” module backs up raw-data which has been collected more than 24 hours in the past. 2) Data Preprocessing and Training Output files for parsing is shared into the “ai_payloads” volume. Each spitted raw-data (in the form of.csv files) is classified by its attack type. Then it is preprocessed by “parse,” and the preprocessed data (npy files) is saved into a docker volume named “ai_parse_data.” The raw web-traffic strings are transformed into trainable float data for deep learning through our UTF-8 encoding with zero-padding. As a result of searching the optimum performance using the “train/test” module, the h5 filetypes in “ai_model” stores the model’s best hyper-parameters and states achieved by deep learning, for classifying malicious and benign traffic. 3) Prediction for Suspicious Payloads To predict suspicious payloads, “predict” inspects the real-time data (payload_data.tmp) stored in “ai_payloads” using the h5 model trained by the “train/test” module. “predict” also stores output as JSON files, including metadata, suspicious payloads, prediction for the malicious-ness probability. The predicted data in “ai_prediction” volume are potential suspicious events identified by each model and are stored periodically (saved 8 times a day) until they are finally reviewed or labeled by a security analyst. The output files are accumulated into labeling tools in Fig. 7. FIGURE 4. Structure of optimized convolutional recurrent neural networks. Show All FIGURE 5. Performance comparison of NN models. Show All FIGURE 6. Experimental results on public datasets. Show All FIGURE 7. Labeling tools for deep learning on AI-IDS. Show All Table 3 shows the contents of a sample JSON file generated by “predict” and stored in “ai_predction.” The file type is stored in the data frame in the following order: “_time,” “payload_id,” “model_name,” “prediction,” “src_ip,” “src_port,” “dest_ip,” “dest_port” and “src_content,” and “src_content” means payload that “POST /manager/html.” “payload_id” is the prediction event id, whose value can be identified and is generated by “hexdigest (sha1(_time@src_ip: src_port-> dest_ip: dest_port)).” TABLE 3 Samples of Prediction Output The infrastructure of the deployed center system consists of Splunk Architecture and our AI-IDS. Splunk Architecture consists of a Search Head Cluster with multiple search headers and an Index Cluster with dozens of Indexes. One of the search heads was built as an independent and dedicated system to interface with AI-IDS. The AI-IDS was developed in the Docker 18.09.5, Python 3.6.7, Tensorflow 1.13.1, Keras 2.2.4 and Splunk SPL 7.2.3. The test-bed system is HP DL380G9: 2.1 GHz 2P/8C(16C) CPU, 416 GB RAM, Tesla P100 16 GB ×1 EA GPU, 960G ×2 (RAID-1) SSD, 6 TB ×2 (RAID-1) HDD and 10Gbps LAN. The operating server consisted of an HP DL390G10: 2.4 GHz 2P/20C(40C) CPU, 1 TB RAM, Tesla V100 32 GB RAM ×2 EA GPU, 960G ×4 (RAID-5) SSD, 10 TB ×4 (RAID-5) HDD and 10 Gbps LAN. As shown in Fig. 1, the sensor systems were located in several financial institutions, and IDS alert events and TAS traffic were collected and transmitted to the SOC via VPN from financial institutions. The experiment was conducted in a test-bed system, which was deployed to the operating system only when the performance and function verification were completed. C. Optimized CNN-LSTM Model Table 4 and Fig. 4 show the CNN-LSTM structure, which illustrates the hyper-parameters. One UTF-8 encoded HTTP data, including the variable-length HTTP header and payloads, which is the initial input value of the proposed neuron network model, is made into a fixed-length input value of 1,000 bytes (1 dimension ×1 ,000 bytes). Strings corresponding to the header and body of the HTTP request from the 0-th byte to the n-th byte are aligned, and the rest of the data is zero-padded. AI-IDS preprocessing continuously collects data for 3 hours in 1 cycle. AI-IDS operates 8 times of learning, and predicts every 3 hours for real-time traffic, which allows for real-time monitoring for 24 hours. In the training phase, the labels indicating “malicious,” “benign,” and “unknown” are recorded at the end of 1,000 bytes of an HTTP request, and the model calculates a malicious probability when all neuronal network operations are completed. The initial input-data at the CNN layer generates 1×1 , 000×12 composited data through an operation with 1×4×12 filters. After 1/5 max-pooling, 1×200×12 pieces of data are stored in the memory in normalized form. In the second convolutional layer, 1×200×60 data are generated through the composite product of a 1×4×5 filter, and then 1×40×60 data are generated as a result of 1/5 max-pooling and normalization. Data output from the CNN layer is used as an input to the RNN layer, and data processed into cells of 1×40×60 are sequentially input to Forward LSTM and Bidirectional LSTM. The first LSTM cell is calculated in the forward direction with 16 cells, the second LSTM cell is processed in a bidirectional flow, and the last 32nd LSTM Cells are transferred to the DNN layer by combining the accumulated forward and backward cells. TABLE 4 Summary of Proposed CNN-LSTM Model The output value of the calculated RNN is input into each of the 12 fully connected DNN layers. Until the DNN output layer, dropout was set to 0.1, and the LeakyReLU function was applied. Sigmoid activation function was used at the DNN output layer and the model was trained for prediction on malicious payloads using the Adam optimizer along with binary-crossentropy (BCE) as the loss function. The probability is calculated in the output layer which includes the JSON output-file shown in Table 3 and the output files are shared with Index Cluster, as shown in Figs. 1 and 3. The analyst reviews the probability calculated by AI-IDS and examines the payload to determine whether an attack warning is valid or not. During the training phase, AI-IDS uses labeled analysis information from an analyst: (i) attack alert events detected by IDS and (ii) valid attack events that the analyst has confirmed. As the AI-IDS aims to detect new threats in the predict phase, the security events detected by legacy signature-based IDS are considered duplicate data. It calculates malicious probability for new and real-time payloads and outputs prediction results. The composition and depth of each layer of CNN, RNN, and DNN derives the optimal parameters for the model through repeated experiments in the training phase. The structure and parameters of the neuron network are slightly different when iterative experiments are performed on various datasets to select optimal performance parameters. The proposed model is devised with an intuitive design based on the theoretical basis of a previous study, and we proved the model validity through repeat experiments. In the next section, we present the detailed experimental results to demonstrate the validity and performance of our proposed model. SECTION V. Experiments This section demonstrates performance measurements, experimental design, and results: comparing the performance of the CNN-LSTM, LSTM-CNN, and DNN models and the experimental results of the KF-ISAC, CSIC-2010 HTTP, and CICIDS 2017 datasets. We have defined the following experimental statements for the deep learning application: Selection of experimental data: CSIC-2010, CICIDS 2017 HTTP dataset, real-time HTTP data Design of optimal model structure using deep learning: CNN-LSTM model, LSTM-CNN model Determination of hyper-parameters: This is required for individual neural networks, such as CNN, RNN, DNN: conv_depth, conv_filter, and lstm_units, dense_units Model validation: experiments on two public datasets (CSIC-2010, CICIDS2017) and fixed real-time data We experimented to select the optimal model by comparing CNN-LSTM with LSTM-CNN based on real-time HTTP traffic on a fixed date. In the second experiment, we validated the model through experiments using two public datasets (CSIC-2010, CICIDS 2017 HTTP dataset) and real-time data on the optimal model. Recently, various models have been introduced that optimize performance by combining CNN, RNN (LSTM), and DNN. Liu et al. [31] and Wu et al. [10] devised CNN and RNN for intrusion detection, but it was different from the model of this study because it performed experiments each separated model in CNN and RNN. In this paper, a DNN was selected as the last layer to output a single result; we chose a model that can best characterize the data among a CNN-LSTM or LSTM-CNN. A. Performance Measurement We used a confusion matrix to evaluate the performance of the deep learning model. A confusion matrix is a popular indicator of the performance of classification models. The matrix in Table 5 shows us the number of correctly and incorrectly classified results, compared to the actual outcomes in the test data. One of the advantages of a confusion matrix as an evaluation tool is that it allows for a more detailed analysis. The matrix is n by n, where n is the number of classes. The simplest classifiers, called binary classifiers, have only two classes: positive/negative. The performance of a binary classifier is summarized in a confusion matrix that cross-tabulates predicted and observed examples into four categories [8], [32]. TABLE 5 A Confusion Matrix In our deep learning model, Precision and F-Score are more important performance indicators than others. Moreover, the purpose of AI-IDS is to obtain a higher accuracy with a lower false-positive rate. We describe the four indicators that make up the confusion matrix in Table 5, as follows: True Positive (TP): the number of cases correctly predicted and labeled as positive. False Positive (FP): the number of cases incorrectly predicted and labeled as positive. True Negative (TN): the number of cases correctly predicted and labeled as negative. False Negative (FN): the number of cases incorrectly predicted and labeled as positive. We use the following notation in Table 6 for the model evaluation: Accuracy (ACC): the proportion of the number of correctly predicted cases to the labeled total of records. Precision: the proportion of the number of correctly predicted cases as positive to the number of predicted cases as positive, high precision relates to a low false-positive rate. Recall (Sensitivity, Detection Rate): the proportion of the number of correctly predicted as positive to the number of cases labeled as positive. Specificity: the proportion of the number of correctly predicted as negative to the number of cases predicted as negative. F-Score: the weighted average of Precision and Recall; this score considers both false positives and false negatives. TABLE 6 Rules for Performance Measurement B. Experimental Design We describe the details of the experimental datasets in the following paragraphs and in Table 7. TABLE 7 Experimental Datasets 1) Real-Time Http Datasets (KF-ISAC) KF-ISAC HTTP data is real-time HTTP stream data during fixed dates from a TAS. The proposed model trains a mix of benign HTTP data and labeled malicious payloads that have been analyzed over the past year. It evaluates performance by separating training and test data at an 8:2 ratio. The label in the training data is located at the end of the preprocessed data. 2) CSIC-2010 Http Datasets CSIC-2010 HTTP data [33] was provided by Aberystwyth University. The contributors collected HTTP packets to detect web attacks. The dataset contains 36,000 normal requests and more than 25,000 anomalous requests. The data consists of normal HTTP data for training and normal/abnormal data for testing. We generated 1,941,300 records by augmenting 20 times from the original 77,652 records and split the set in a ratio of train 8: test 2, except for 6 error records during data import. 3) CICIDS2017 Http Datasets The CICIDS2017 datasets [34] generated in 2017 by the Canadian Institute of Cybersecurity overcome these issues. The CICIDS2017 benchmark dataset contains the abstract behavior of 25 users based on HTTP, HTTPS, FTP, SSH, and email protocols. We use only HTTP datasets, including web attacks and generated 586,180 records by augmenting 20 times from the original 29,309 records. The dataset consists of the entire abnormal/normal pcap file, the unlabeled HTTP attack, and the metadata, including label data. C. Experimental Results 1) Model Selection We implemented CNN-LSTM and LSTM-CNN structures for an optimal deep learning model selection and then performed 10 iterations using real-time HTTP data shown in Table 7. The training data of KF-ISAC consisted of approximately 6.6 million records extracted and proposed on a specific date, and each of the normal/attack classes was composed of approximately 3.3 million records. The test datasets were set to a ratio of 8:2. The results of the experiment shown in Fig. 5 are the average values of the results of 50 epochs. The overall model performance of CNN-LSTM is better than LSTM-CNN, in areas such as accuracy, precision, and F-Score. In particular, there are many differences in Precision, and F-Score because of the True/False Positive Rate. The model performance starting from the highest to the lowest is CNN-LSTM, LSTM-CNN, and DNN. CNN-LSTM reduces the dimension by max-pooling at the initial step, but LSTM-CNN takes more time to train because the dimension and parameters are increased through LSTM Cell. The DNN is relatively fast but it has low rates for the scores of Accuracy and Specificity. 2) Determination of Hyper-Parameters We chose the best-performing deep learning model according to the experimental results. The CNN-LSTM model needs to determine the optimal hyper-parameters for stable operations. We considered a high precision such that the time needed to train or to validate events by true/false-positive rates in a practical environment is minimized. The experiment used real-time HTTP (KF-ISAC) data shown in Table 7. The CNN layer determines the conv_depth, conv_filter, conv_kernel_width, and conv_pool variables. In detail, one variable has to be selected from conv_depth ∈  [2] , conv_filter ∈ [2,4,8,12] , conv_kernel_width ∈  [4] and conv_pool ∈ [3,4,5] . The RNN layer determines the lstm_units and lstm_depth variables. In detail, one of the following values has to be selected from lstm_unit ∈  [16] and lstm_depth ∈ [1,2,4,8] . The DNN layer determines dense_depth, dense_units, dense_dropout, and dense_relu_alpha. In detail, one value of dense_depth ∈ [1,2,4,8] , dense_units ∈ [4,8,12,16] and dense_dropout ∈ [0.1,0.5] is selected. The experiment was conducted 270 times, with one or more of the five indicators converging to zero or one, and then moving on to the next parameters. Aiming for the high F-score and the high precision, which means minimum with false-positive values, the hyper-parameters of an optimal model are shown as follows: 2 for convolution depth, 12 for convolution filter, 4 for convolution kernel size, 5 for max-pooling size, 16 for LSTM Cell, 2 for LSTM depth (1 forward LSTM, 1 Bidirectional LSTM), 12 dense units, 8 for dense depth, and 0.1 for dense dropout. 3) Model Validation To validate the performance of deep learning models, we used real-time data and public HTTP datasets (CSIC-2010, CICIDS 2017 HTTP datasets), and experimented with 50 epochs on the previously selected model. The experimental results of real-time data showed that the proposed CNN-LSTM model can be used for general HTTP data with a high performance. The AI-IDS is a deep learning-based model with no pre-feature extraction and therefore all strings can be processed. For all experiments for each dataset, the model parameters were modified to obtain the results above and to optimize the performance on different datasets. Considering that our model has 14,000 trainable parameters, the CSIC-2010 and CICIDS- 2017 are relatively small, which leads to overfitting and low performance. Experimental results shown in Fig. 6 showed a high accuracy of 91–93% for each dataset in CSIC-2010 and CICISC-2017. The precision was in the range of 86–98%, and the F-Score was in the range of 80–82%, which is lower than the experimental results of the previous real-time data. Experimental results showed that the performance of the model is affected by the number of samples and the diversity of the training data. It was difficult to cross-validate our model with two published datasets owing to small samples. If we had a large amount of non-repeated HTTP data, the experimental performance would improve and would return more reliable results. Considering the above results, our model is more suitable for a large amount of data, and we demonstrated the excellence of our model by training with various datasets of more than 6 million HTTP traffic data. SECTION VI. Efficacy and Application This section describes cases of how AI-IDS detects variant attacks that bypass detection on legacy signature-based NIDS, and how Snort rules can be rewritten or improved. The AI-IDS in Fig. 7 performs “predict” based on the completed h5-model shown in Fig. 3, and it predicts real-time data by inspecting the attack as a prediction output. When the prediction value is 100%, the NIDS knows the payload is malicious, but the results of analysts are not perfectly reliable because an initial AI-IDS result may contain an analysis error. Thus, an analyst needs to confirm the final step until a stable level has been reached. We classified the suspicious payloads as a prediction value within a range of 50–100%, and an average of 100-500 events occurred every 3h. We assumed that AI-IDS is classified as normal or malignant, and less than 50% of the predicted values are labeled as “benign,” and 50–100% are classified as “malicious” payloads. In Fig. 7, the analyst labels suspicious payloads on the program as “benign,” “malicious,” or “unknown” using a conditional search. The labeled data is used for daily retraining. The label program shows the prediction value (%) generated by the optimal CNN-LSTM model, and the analyst can use it as a reference for identifying the actual malicious payloads. Some of the analysis information, such as src_ip/port and dest_ip/port can be used to register a blocking policy in the firewall. The effects of applying AI-IDS are summarized as follows: First, it can detect variant bypass attacks that are not detected on legacy Signature-based NIDS. For all AI-IDS predictions, security events on the legacy NIDS are automatically excluded, such that no duplicate events can occur. Second, it is possible to write or modify Snort rules for new patterns. If legacy NIDS have existing rules but cannot detect attacks, then this had to be caused by Snort grammatical errors or missing patterns in the rules. However, it can also be a detection failure due to low performance or functional failure. A. Detection of Obfuscated Variants Table 8 shows an example of a variant attack detection. A common intrusion pattern is a scan of an admin page or file upload page, usually accessed by an attacker via a known open source path. Suppose that there is an admin page such as “http://target.com/admin/index.php“ and a rule that detects “/admin/index.php” in legacy NIDS. The AI-IDS examines payloads coming from the trained CNN-LSTM model in real-time to detect abnormal URI accesses that detect variant attacks on “index.php” parameters and subpaths. It also detects similar and different new variant attacks for all attack types and patterns, as well as the examples shown in Table 8. In the case of SQL Injection, the detection accuracy of variant patterns is close to 100%. TABLE 8 Detecting Variant Patterns on AI-IDS The AI-IDS can also detect unknown variant patterns or obfuscated attacks, as shown in Fig. 8. An attacker can use URL Encoding or base64 to bypass arbitrary payloads in the security system to attack web servers effectively. An attacker uses the Char() function to insert code into noticeView.jsp to attempt to acquire system information. In other cases, the attacker attempts to send spare-phishing mails, attempting to communicate with an external SMTP server by injecting irregular or encoded code to AspCms_SiteSetting.asp (AspCMS). Recent malicious HTTP payloads contain irregular patterns that are difficult to detect as simple strings. A commercial NIDS detects most known attacks or patterns but does not detect strings that do not have a registered pattern. By contrast, the AI-IDS can detect variant and obfuscated attacks that cannot be detected with legacy NIDS. FIGURE 8. Detecting encoded and obfuscated payloads. Show All B. Improvement of Signature-Based Snort Rules The second effect is to improve the signature-based Snort Rule. The AI-IDS does not generate detected events in duplicate on legacy signature-based NIDS, analysts can identify new patterns for threats by analyzing suspicious payloads: (i) A new rule can be written for a new pattern (ii) If a rule exists, but cannot be detected, the detection rule can be improved by correcting an error in the rule’s options: an offset, depth, distance or within and so on. We write or improve on average about five new detection rules per month manually. If an event occurs in the AI-IDS when the rules are normally applied, we have to suspect a detection failure on signature-based NIDS. Table 7 shows that AI-IDS detects a vulnerability attack (CVE-2018-9174) of DedeCMS. When NIDS rules for related attacks are not registered in the currently operating NIDS, new rules can be registered based on the detection of AI-IDS. Step 1.AI-IDS detection for suspicious payloads Show All Step 2.Analysis of related existing rules (Why not detectable?) Show All Step 3.Writing a new Snort rule or improving an existing Snort rule (general use in case) Show All AI-IDS detects attacks that are not detected in the existing NIDS in step 1. As AI-IDS double-checks with existing NIDS, basically all events detected by AI-IDS are not detected by NIDS. The analyst examines the existing rules in step 2 to review why the existing NIDS did not detect payloads. It is usually found that attackers used several methods to randomly change the encoding or attacked strings to bypass NIDS. In addition, if the signature is individually over-customized, there are few types of attacks that cannot be detected, even if there is only a slight change in the attack pattern. Therefore, step 3 modified existing signatures to rewrite detection rules that typically detect PHP webshell code attacks. However, if a general-purpose detection rule is written without regard to the environment, appropriate optimization tasks are required as the number of detections increases. SECTION VII. Conclusion We proposed an optimal CNN-LSTM model based on SFL and successfully applied payload-level deep learning techniques in a high-performance computing environment. The AI-IDS distinguishes between normal and abnormal traffic on HTTP traffic that could not be detected in legacy signature-based NIDS because AI-IDS can formalize unknown patterns, help write or improve signature-based rules for new vulnerabilities, variants, and bypass attacks. Network meta-data, without its payload is usually difficult to identify whether it is malicious or not. Thus, we review the HTTP header and body of web attacks in detail. We also used real-time web traffic for deep learning, but initially, we learned that AI-IDS needed to be re-validated for predicted suspicious events due to false positives alarms. The AI-IDS performs continuous optimization by re-training analysis information that is labeled “benign,” “malicious,” and “unknown.” Thus, it should be used as an assistant system until it reaches a high-quality level. If the quality goes beyond the ability of humans by continually learning, it could be executed as an automated analysis. Ultimately, the goal of AI-IDS is to outperform human analysis quality and to help analysts handle large quantities of unknown security events. Previous works have mainly considered accuracy (ACC) in terms of performance measures, but scalability and precision are also important indicators for applying deep learning in the real-world. In practical security services, re-validation for predicted events is a required task because of the low tolerance for analysis errors. Authors Figures References Citations Keywords Metrics Footnotes More Like This Stochastic Gradient Descent Intrusions Detection for Wireless Sensor Network Attack Detection System Using Machine Learning IEEE Access Published: 2024 Machine Learning-based Intrusion Detection System using Wireless Sensor Networks 2024 Fourth International Conference on Advances in Electrical, Computing, Communication and Sustainable Technologies (ICAECT) Published: 2024 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.

Paper 4:
- APA Citation: Chhetri, K. B. (2023). Applications of Artificial Intelligence and Machine Learning in Food Quality Control and Safety Assessment. Food Engineering Reviews, 16(1), 1-21.
  Main Objective: To explore the uses of artificial intelligence (AI) and machine learning (ML) in automating real-time data processing and inferencing in the discipline of food quality and safety management.
  Study Location: Unspecified
  Data Sources: Not explicitly stated in the provided text
  Technologies Used: Artificial intelligence (AI), machine learning (ML), cloud computing, containerization, real-time data processing, inferencing
  Key Findings: AI and ML technologies are being used to improve food safety and quality by automating real-time data processing and inferencing. This allows for the early detection of contaminants, the prediction of foodborne illness outbreaks, and the optimization of food production and distribution processes.
  Extract 1: Addressing the global food challenge: The review aims to explore how automated, real-time irrigation management systems can contribute to the efficient use of water resources and enhance agricultural productivity to meet the growing demand for food.
  Extract 2: Evaluating the current state and future potential: The primary objective is to critically assess the current state of end-to-end automated irrigation management systems that integrate IoT and machine learning technologies.
  Limitations: None
  Relevance Evaluation: This paper is highly relevant to my point in the literature review because it provides a comprehensive overview of the use of AI and ML in food quality and safety management, with a particular focus on real-time data processing and inferencing. The paper discusses the challenges and opportunities of using AI and ML in this domain, and provides specific examples of how these technologies are being used to improve food safety and quality.
  Relevance Score: 1.0
  Inline Citation: (Chhetri, 2023)
  Explanation: This scientific article explores the uses of artificial intelligence (AI) and machine learning (ML) in automating real-time data processing and inferencing in the discipline of food quality and safety management. It emphasizes the importance of data quality and preprocessing in the cloud, along with containerization techniques for vast and autonomous deployment, and the implementation of ML models for real-time data processing and inferencing. These technologies improve food quality assessment and control, particularly given the growing consumer demand and regulatory scrutiny.

 Full Text: >
"Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Log in Find a journal Publish with us Track your research Search Cart Home Food Engineering Reviews Article Applications of Artificial Intelligence and Machine Learning in Food Quality Control and Safety Assessment Published: 22 December 2023 Volume 16, pages 1–21, (2024) Cite this article Download PDF Access provided by University of Nebraska-Lincoln Food Engineering Reviews Aims and scope Submit manuscript Krishna Bahadur Chhetri  568 Accesses Explore all metrics Abstract To ensure food safety and uphold high standards, the food business must overcome significant obstacles. In recent years, promising answers to these issues have emerged in the form of artificial intelligence (AI) and machine learning (ML). This thorough review paper analyses the various uses of AI and ML in food quality management and safety evaluation, offering insightful information for academics, business people and legislators. The evaluation highlights the value of food quality assessment and control in consideration of growing consumer demand and regulatory scrutiny. The powerful capabilities of AI and ML are touted as having the potential to revolutionize these procedures. This study illustrates the numerous uses of AI and ML in food quality management through an in-depth exploration of these technologies. Defect detection and consistency evaluation are made possible using computer vision techniques, and intelligent data analysis and real-time monitoring are made possible by natural language processing. Deep learning techniques also provide reliable approaches for pattern recognition and anomaly detection, thus maintaining consistency in quality across manufacturing batches. This review emphasizes the efficiency of AI and ML in detecting dangerous microorganisms, allergies and chemical pollutants with regard to food safety evaluation. Consumer health risks are reduced because of the rapid identification of safety issues made possible by integrating data from diverse sources, including sensors and IoT devices. The assessment discusses issues and restrictions related to the application of AI and ML in the food business while appreciating the impressive progress that has been made. Continuous efforts are being made to improve model interpretability and reduce biases, which calls for careful evaluation of data quality, quantity and privacy issues. To assure compliance with food safety norms and regulations, the article also covers regulatory approval and validation of AI-generated outcomes. The revolutionary potential of AI and ML in raising food industry standards and preserving public health is highlighted on future perspectives that concentrate on new trends and potential innovations. This comprehensive review reveals that the integration of AI and ML technologies in food quality control and safety not only enhances efficiency, minimizes risks and ensures regulatory compliance but also heralds a new era of personalized nutrition, autonomous monitoring and global collaboration, signifying a transformative paradigm in the food industry. Similar content being viewed by others Artificial Intelligence and Deep Learning-Based Agri and Food Quality and Safety Detection System Chapter © 2023 Impact and prospect of the fourth industrial revolution in food safety: Mini-review Article 20 February 2022 Food Adulteration Detection using Artificial Intelligence: A Systematic Review Article 15 June 2021 Introduction The food industry at a global level is encountering an escalation in challenges associated with ensuring food safety, sustainability and quality due to the increasing demands of consumers and environmental changes. To combat these challenges, industry professionals and researchers are resorting to artificial intelligence (AI) and machine learning (ML) techniques as effective instruments to transform food safety assessment and quality control. In this paper, an assessment is conducted to explore the varied applications of AI and ML in the food industry, with a particular emphasis on their potential to mitigate crucial challenges and enhance the overall efficiency. The requirement for advanced technologies in food safety assessment and quality control is apparent, and AI and ML provide encouraging solutions. The conflation of hyperspectral imaging and AI methodologies in a symbiotic manner, as illustrated by the innovative research undertaken by Rady et al. [1], carried significant consequences for the food processing sector. This union facilitates the swift and accurate detection of pest infestations in apples, which fortifies pre-emptive measures and decreases crop losses. Furthermore, the AI-powered analysis extends to quality management, permitting the real-time evaluation of factors such as ripeness and pollutants. By refining procedures and ensuring the authenticity of products, this combination redefines the benchmarks for food safety and refines the general efficacy of the industry. The food processing industry is on the cusp of a transformative period, owing to the profound integration of AI and ML techniques. These advancements have significantly altered the crop disease and pest detection landscape with remarkable precision, as evidenced by the pioneering research of Boyd and Sun [2]. Their groundbreaking expert system, which diagnoses potato ailments, is a pioneering achievement that demonstrates the expeditious and precise assessments that are now possible, ushering in a new era of rapid interventions and reduced agricultural losses. However, the realm of AI and ML surpasses the confines of immediate quality control. Instead, it assumes a mantle of paramount significance in navigating the intricate and multifaceted terrain of food security. The astute application of fuzzy systems, as demonstrated by Peixoto et al. [3], offers a glimpse into this potential. Their ingenious dynamic regulation of soybean aphids exemplifies the strategic use of AI, resulting not only in augmented crop yields but also in fortifying the very foundation of the global food supply chain. Inextricably linked to the evolving tapestry of the food industry, the ascendancy of AI and ML technologies in food quality control and safety assessment is inexorable. As we traverse the dynamic contours of this landscape, it becomes increasingly evident that this review serves not merely as an exposition but also as a clarion call, illuminating the path to an augmented future where AI and ML stand as sentinels of excellence within the realms of food processing. Materials and Methods The synthesis of this all-encompassing review is supported by a rigorous methodology aimed at extracting valuable insights from the most authoritative sources currently available. A meticulous and systematic search strategy was executed, utilizing well-known databases such as PubMed, IEEE Xplore and ScienceDirect. This review covers literature published until 2022, ensuring a comprehensive and up-to-date coverage of the subject. In accordance with strict inclusion criteria, the selection process gave priority to articles that have undergone peer review and notable conference proceedings. A thorough three-step screening process, involving the evaluation of titles, abstracts and full texts, was implemented to ensure the accuracy and relevance of the studies included. The categorization framework focused on the principal applications of AI and ML in the context of food safety, specifically computer vision, IoT-enabled sensors, blockchain integration and predictive modelling. A systematic analysis of the benefits and limitations associated with each application supports a refined distillation of insights, contributing to a comprehensive understanding of the subject matter. Food Quality Control and Safety Assessment Through AI and ML Techniques AI and ML techniques have revolutionized the field of food quality control by presenting inventive solutions to increase the consistency and safety of food items [4, 5]. Among the key techniques used in the industry are the following: 1. Computer vision: In contemporary food process engineering, the combination of computer vision technology and AI has emerged as a pioneering development [5]. This combination is transforming the food industry by enabling meticulous and automated visual inspections. AI-powered computer vision systems excel at scrutinizing food products with precision and speed through image and video analysis. These systems are indispensable for crucial tasks such as grading, sorting and quality assessment. By rapidly identifying discrepancies from quality standards, they ensure that only products satisfying stringent criteria are delivered to consumers. The impact of this technology extends across diverse sectors within food processing. In sorting, computer vision systems equipped with AI discern subtle variations in colour, size and shape. This enables precise product categorization, which is particularly essential in fruit and vegetable sorting, where uniformity is vital for quality and competitiveness. Furthermore, the implementation of computer vision addresses food safety concerns by promptly identifying potential contaminants or pathogens. Rapid data analysis allows timely interventions, minimizing risks to food safety and potential recalls. In quality assessment, these systems provide consistent, objective evaluations of attributes that influence consumer preferences. By reducing human subjectivity, they enhance the standardized product evaluation, thus fostering consumer trust and satisfaction. The combination of AI and computer vision not only accelerates processes but also optimizes resource usage. Early identification of defects minimizes waste, leading to cost savings and heightened sustainability. 2. Spectroscopy and sensors: The domain of food process engineering is marked by the combination of AI and ML, which is particularly evident in the realm of spectroscopy and sensors. According to Si et al. [5], ML algorithms intricately analyse data sourced from spectroscopic techniques and a diverse array of sensors, measuring crucial attributes such as moisture content, pH levels and chemical composition. This data-driven analysis empowers AI to make estimations regarding the nutritional value, ripeness and freshness of food items, facilitating informed decision-making for producers concerning production and storage strategies. The proficiency of AIs in interpreting spectroscopic and sensor data has profound implications for quality control and safety assessment. By harnessing AI’s pattern recognition capabilities, the technology enables producers to optimize production processes and minimize resource wastage. In addition, real-time data streams from sensors align with contemporary paradigms such as Industry 4.0 and the Internet of things (IoT), facilitating predictive modelling for quality deviations and enabling timely intervention. This symbiotic blend of AI and ML in spectroscopy and sensors not only enhances operational efficiency but also strengthens the foundation of food safety and quality within the dynamic landscape of food process engineering. 3. Predictive modelling: Predictive modelling with convergence of AI and ML has significant implications for food quality and control. Si et al. [5] have expounded on this technique, which utilizes historical data to train ML models and predict potential quality issues while estimating the shelf-life of food products. The combination of AI and ML facilitates the monitoring of a comprehensive range of variables throughout the production and storage phases, allowing the system to anticipate the likelihood of contamination, spoilage or other forms of deterioration. By identifying patterns and correlations in the data, AI-driven predictive models empower producers to make informed decisions expeditiously. Subsequently, timely interventions can be implemented to preserve the integrity of the final product, minimize wastage and ensure that consumers receive safe and high-quality food items. In essence, the application of predictive modelling fortified by AI holds significant promise for revolutionizing food process engineering. By leveraging historical insights and real-time data, this approach enhances the industry’s ability to mitigate risks, optimize resources and ultimately deliver products that meet the highest standards of quality and safety. 4. IoT-enabled real-time monitoring: The integration of AI and ML has been emphasized by Si et al. [5], thus leading to the emergence of IoT devices equipped with sensors. This union has enabled real-time monitoring of critical parameters, thereby facilitating proactive quality control. With the aid of these IoT devices, data acquisition is performed in real time, ensuring that quality benchmarks are constantly upheld. In the event of any deviations, AI systems expeditiously analyse the data and deliver prompt notifications, thereby enabling immediate corrective measures. This dynamic approach not only hastens response times but also mitigates the risk of errors or contamination. Furthermore, AI-powered automation and robotics play a crucial role in expediting quality control procedures. By eliminating human intervention, these technologies enhance precision and minimize the potential for errors. The intricate handling and examination of food products are facilitated, ensuring uniform quality and reducing needless wastage. In essence, the convergence of AI, ML and IoT within food process engineering amplifies the industry’s ability to maintain superior quality standards. The real-time monitoring and automated responsiveness empower stakeholders to ensure that only products of the highest quality are presented to consumers, subsequently elevating trust, satisfaction and overall efficiency. 5. Data-driven decision-making: In the realm of food process engineering, the confluence between AI and ML has been underscored by Si et al. [5] and Vijay et al. [6], utilizing expansive datasets for data-oriented decision-making. This approach combines an array of data sources, including customer feedback, laboratory testing results and manufacturing records. AI’s capacity to process and scrutinize these vast datasets empowers upgraded quality control systems. This integration facilitates the identification of intricate trends and issues that may elude conventional methods. By discerning patterns and anomalies across multiple dimensions, AI enhances the accuracy of quality assessment and contributes to the proactive identification of potential challenges. The integration of AI and ML in food process engineering exemplifies a transformative shift towards data-driven decision-making. This not only enriches the comprehension of product quality but also fosters continuous improvement and innovation within the industry. 6. Blockchain and AI-enabled improved traceability and transparency in the food supply chain: The intersection of blockchain and AI has resulted in a significant breakthrough in augmenting traceability and transparency throughout the food supply chain. The influential works of Si et al. [5] and Bestelmeyer et al. [7] underscored the pivotal role of this decentralized ledger in meticulously monitoring the entire journey of food products, spanning from their origin to consumption. By leveraging AI-powered analysis of blockchain data, a swift and accurate identification of sources is made feasible in cases of contamination or recalls. This integration fortifies the efficacy of traceability systems, safeguards consumer health and increases the efficiency of corrective measures. The fusion of blockchain and AI within food process engineering not only empowers supply chain stakeholders with real-time insights but also instils a heightened level of accountability and integrity. By fostering an environment of transparency, these cutting-edge technologies catalyse a new era in food safety and quality assurance, reinforcing consumer confidence and industry-wide standards. The combination of AI and ML methodologies has precipitated a profound metamorphosis in the realm of food quality control, resulting in elevated consumer satisfaction levels, reduced wastage and reinforced safety [4, 6]. The developing landscape holds the potential for even more remarkable strides in food quality management, ensuring a consistent supply of secure and first-rate food products. These technologies have revolutionized the paradigm of food process engineering, augmenting its efficacy, precision and dependability. The collaborative synergy between AI, ML and food science underscores their pivotal role in shaping the future of food quality assurance. This trajectory not only guarantees continual improvement of consumer experiences but also establishes a robust foundation for industry’s growth and resilience. The comparison of AI and ML techniques for food safety and quality control is described in Table 1. Table 1 Comparison of AI and ML techniques for food safety and quality control Full size table Sensor-Based AI and ML Applications for Enhancing Food Safety and Quality Control Data collection and analysis have been revolutionized by AI-based sensing technologies, which use AI algorithms to glean insightful information from sensor data [5, 6, 13]. These state-of-the-art sensing technologies have several uses in industries such as agriculture, healthcare and environmental monitoring. The AI and ML utilization in food industry is described in Fig. 1. AI-based sensing technologies are essential for maintaining the safety and integrity of food items across the supply chain in the field of food quality control. 1. IoT-enabled smart sensors: The combination of IoT devices with intelligent sensors is revolutionizing the landscape of food production, processing and storage [5]. These sensors are capable of continuously monitoring crucial factors such as temperature, humidity, pH levels, gas emissions and chemical compositions. The real-time data provided by these sensors enable the swift detection of quality and safety issues. The dynamic monitoring system created through this integration enhances food processing by maintaining optimal conditions, preventing microbial growth and averting any moisture-related damage. Furthermore, it assures safety by identifying abnormal gas emissions and monitoring chemical compositions, which allows for timely interventions and proactive measures [14]. The seamless partnership between IoT and intelligent sensors empowers the food industry to ensure precise quality control and maintain vigilant safety measures along the entire food supply chain. 2. Image and spectroscopy sensors: Si et al. [5] emphasize the combination of AI-driven imaging and spectroscopy sensors in the evaluation of diverse aesthetic and chemical properties of food items. AI-powered computer vision algorithms are proficient in meticulously scrutinizing images to detect defects, blemishes and extraneous substances in food products, thereby augmenting the quality control process in food production. Furthermore, spectroscopy sensors are pivotal in capturing the interaction of food items with light, which provides valuable insights into their nutritional value, composition and freshness. This sophisticated analysis facilitated by AI considerably enhances the precision and efficacy of food quality assessment. 3. Gas and odour sensors: In the domain of food processing and safety, Si et al. [5] emphasize the pivotal significance of gas and odour sensors based on AI. These sensors expertly detect volatile compounds discharged by food products, thereby allowing for the identification of harmful substances, spoilage and undesirable smells. By leveraging the capabilities of AI, these sensors can swiftly and accurately analyse sensor data. Hence, compromised or deteriorating products are instantly flagged, ensuring their elimination from the production line before they reach consumers. This proactive approach not only diminishes potential health hazards but also safeguards the credibility of manufacturers and the overall integrity of the food supply chain. The findings represent a prime example of how integrating AI and sensor technology strengthens food safety measures, resulting in improved quality control and heightened consumer trust. 4. Nanosensors: The work of Si et al. [5] illuminated the transformative dimension of nanotechnology in the realm of food processing and safety. This innovative technology allows for the molecular-level recognition of substances and diseases, which, in turn, enables AI-based nanosensors to play a pivotal role in assessing food safety. These nanosensors provide rapid and precise detection of contaminants, thus serving as an invaluable asset in safeguarding the quality of consumables. By harnessing the power of AI, nanosensors contribute to proactive food safety measures. Their exceptional sensitivity and specificity enable early identification of potential hazards, thereby acting as vigilant sentinels against foodborne threats. Real-time contamination detection facilitates swift intervention, bolstering consumer protection and industry integrity. The convergence of nanotechnology and AI in the realm of food safety signifies a revolutionary advancement. It not only enhances the monitoring and control of contaminants but also ushers in a new era of precision and reliability in the food supply chain. As a result, manufacturers can uphold stringent safety standards, while consumers enjoy greater confidence in the products they consume. 5. Blockchain integration: Si et al. [5] emphasized the transformative potential of integrating blockchain and AI-based sensing to enhance food processing and safety. This mutually beneficial partnership bolsters data security and traceability by establishing an immutable ledger for the entire food supply chain. By using blockchain to record sensor-derived data, transparency and permanence are ensured. Through AI-driven analysis, intricate relationships and patterns within the recorded data are uncovered. This dynamic synergy enhances the operational efficiency, mitigates risk and ensures adherence to stringent quality standards. The integration of blockchain and AI represents a pivotal advancement, providing real-time insights to stakeholders, elevating accountability and strengthening consumer confidence in the safety and integrity of food products. 6. Remote sensing: Si et al. [5] and Spanaki et al. [13] underscore the criticality of AI-powered remote sensing techniques in augmenting food processing and safety. These technologies, which use satellites and drones, allow for comprehensive monitoring of agricultural fields and storage facilities. By evaluating crop vitality and environmental conditions and identifying anomalies such as pest outbreaks and temperature fluctuations, they contribute to the preservation of food quality. The real-time insights gleaned from AI-driven remote sensing bolster decision-making, facilitating timely interventions to avert potential hazards. This proactive approach not only safeguards the integrity of food production and storage but also aligns with stringent safety standards. The fusion of AI, remote sensing and agricultural practices represents a powerful synergy that optimizes food processing operations while strengthening the assurance of safe and high-quality food products. Fig. 1 AI and ML utilization in food industry (based on the finding from Lee and Liew [15], Smith et al. [16] and Garcia-Garcia et al. [17] Full size image Predictive Modelling and Quality Assessment for Enhanced Food Safety and Quality Control Predictive modelling and quality evaluation are already commonplace in modern food quality management systems, which use the strength of AI and ML to anticipate product quality, identify possible problems and uphold uniform standards. The results of assessing model performance and accuracy in food safety are described in Table 2. Building consumer trust, adhering to rules and lowering food waste in the business all depend on this proactive approach to quality inspection [4, 18]. 1. Predictive shelf-life modelling: The integration of AI and ML in food process engineering has introduced the concept of predictive shelf-life modelling. This data-driven approach involves analysing historical data encompassing various parameters such as composition, storage conditions and environmental influences [18] to enable precise estimation of a food product’s shelf life. Factors like temperature, humidity and storage duration are considered to determine optimal storage conditions and expiration dates. By adopting effective storage practices, manufacturers can minimize product wastage and deterioration, ensuring that products reach consumers at their peak quality. 2. Quality assessment using sensor data: The use of AI and ML in food process engineering has enabled real-time quality assessment using sensor data [5]. Critical variables such as temperature, pH and moisture are continuously monitored using sensors throughout the production and storage stages of food items. By harnessing ML algorithms, real-time data can be rapidly evaluated to identify deviations from established quality standards. The immediate detection of anomalies empowers manufacturers to take prompt corrective actions to maintain the desired level of product excellence while averting potential quality issues. 3. Contaminant identification and allergen control: AI-driven image analysis and predictive modelling have enhanced the identification of contaminants and allergens in food products [5], addressing food safety concerns. ML algorithms proactively recognize potential sources of pollutants by analysing historical data and identifying patterns. This proactive identification mechanism ensures that potentially contaminated products are intercepted before reaching consumers, safeguarding public health and upholding stringent food safety regulations. 4. Real-time process optimization: In the context of food process engineering, AI introduces real-time process optimization [5]. ML algorithms continuously analyse data streams from sensors, production equipment and environmental factors to make dynamic adjustments to industrial processes. This ensures consistent product quality, increased production efficiency and reduced resource consumption. By swiftly adapting to changing conditions, AI-driven optimization enhances product uniformity and minimizes waste. 5. Quality grading and sorting: AI-powered systems have enabled automated quality grading and sorting operations in food process engineering [5]. By harnessing computer vision and ML techniques, food items can be categorized on the basis of their quality attributes. This automated grading process ensures uniformity in the final product, mitigating deviations and elevating consumer satisfaction. The technology’s ability to accurately discern quality traits contributes to efficient sorting processes, a critical aspect of modern food processing operations. 6. Food regulation compliance: AI plays a significant role in ensuring food safety and regulatory compliance [5]. The predictive modelling capabilities of AI algorithms enable food manufacturers to anticipate potential issues by analysing comprehensive data sources, including historical records and lab tests. This proactive approach minimizes the risk of non-compliance and associated penalties, underscoring the technology’s crucial role in maintaining industry standards and consumer safety. 7. Analysis of customer feedback: The use of AI and ML technologies in the examination of customer feedback has led to profound impacts in the field of food process engineering, as noted by Si et al. [5]. Through the incorporation of this feedback into prediction models, manufacturers can gain invaluable insights into product quality and consumer satisfaction. This data-driven approach to decision-making empowers manufacturers to improve product attributes that align with consumer preferences, ultimately resulting in enhanced quality and increased consumer trust. The flowcharts of the applications of AI and ML are shown in Figs. 2 and 3, respectively. Table 2 Assessing model performance and accuracy in food safety Full size table Fig. 2 Flow chart showing a crucial role of artificial intelligence in food sector Full size image Fig. 3 Flow chart showing a crucial role of machine learning in food sector Full size image The integration of AI and ML technologies in the realm of food process engineering and food safety represents a pivotal moment in the industry, characterized by precision, efficiency and heightened consumer protection. These advancements have contributed to the optimization of processes, waste reduction, and the establishment of an environment where the production of high-quality and safe food products is of utmost importance. Data Analytics and Pattern Recognition for Advanced Food Quality Control and Safety Data analytics and pattern recognition play a significant role in the evaluation of food quality management and safety. These methods use AI and ML to extract useful information from huge datasets, assisting in the detection of patterns, trends and potential problems in the production and distribution of food. The importance of pattern recognition and data analytics in relation to food quality control is described as follows. 1. Quality assurance and defect discovery: The combination of computer vision technology and data analytics has revolutionized quality assurance in food process engineering, leading to proactive measures to eliminate the risk of substandard products reaching consumers and bolstering their trust. This has been made possible by harnessing the power of AI algorithms, which allow automated inspection systems to meticulously examine images and videos of food products. Through pattern recognition, these systems ensure consistent quality attributes and adherence to established standards and reduce wastage. 2. Predictive quality modelling: Predictive quality modelling is a cornerstone of modern food process engineering, which has been made possible by leveraging historical data encompassing production conditions, sensory evaluations and consumer feedback. This forward-looking strategy enables manufacturers to optimize production processes, ensuring enduring quality uniformity while aligning with evolving consumer preferences. 3. Early contaminant detection: Data analytics and AI-driven insights are instrumental in ensuring food safety by facilitating early contaminant detection. This was made possible by analysing diverse data sources, including sensor readings and laboratory tests, to identify potential contaminants or deviations from safety standards. Rapid recognition of abnormal patterns empowers timely interventions, preempting potential food borne illness outbreaks and safeguarding consumer health. 4. Supply chain optimization: The strategic use of data analytics optimizes the entire food supply chain by analysing inventory levels, demand trends and transportation routes, which facilitates accurate demand forecasting and enhanced inventory management. The integration of AI algorithms predicts shifts in demand, streamlines inventory practices, reduces waste and ensures efficient product delivery to customers. 5. Consumer insights and personalization: Data analytics and ML techniques enable food producers to unlock valuable consumer insights and deliver personalized experiences. This tailored approach not only caters to specific market demands but also enhances consumer satisfaction and cultivates loyalty. 6. Adherence to food standards: In the realm of food process engineering, data analytics play a pivotal role in ensuring compliance with rigorous food safety standards. This diligent approach ensures that products consistently meet established quality and safety benchmarks by continuously monitoring and analysing data from various production stages, which mitigates the risk of fines and recalls. The synergy among data analytics, AI and food process engineering underpins enhanced quality, safety and efficiency throughout the entire food production lifecycle. By embracing these advanced technologies, the food industry has pioneered an era of precision, traceability and consumer-eccentric demands. Enhancing Food Safety Management and Traceability Through AI and ML Technologies The provision of safe, legal and high-quality food items is made possible through traceability and food safety management, which are essential components of the food sector. Modern technologies such as the blockchain, the IoT and AI have significantly improved how food safety and traceability are managed. The core elements of food safety management and traceability are explained below. 1. Hazard analysis and critical control points (HACCP): The incorporation of the HACCP framework with AI and ML has transformed food safety management in the manufacturing sector [20]. This methodical approach utilizes data analysis to detect, evaluate and mitigate potential hazards. The data-crunching capabilities of AI enable the identification of risks, the prediction of outcomes and the implementation of preventive measures. Real-time monitoring and automatic alerts facilitated by AI and ML ensure swift actions, thereby minimizing risks and bolstering food safety. 2. IoT-based real-time monitoring: Real-time monitoring of critical factors, such as temperature, humidity and storage conditions, is achievable with the help of IoT-based devices with sensors [13]. The AI algorithms process the continuous stream of data from these sensors to detect deviations from optimal conditions. This constant vigilance minimizes the chances of contamination and spoilage, ensuring that food is handled, stored and transported under optimal conditions. 3. Blockchain for traceability: The transparency of blockchain technology has revolutionized the traceability landscape [7]. With every transaction and movement recorded in an immutable ledger, customers and regulators can track a product’s journey from its origin. AI’s analytical prowess can be harnessed to examine blockchain data during foodborne illness outbreaks, revealing patterns, trends and potential sources of contamination for swift intervention. 4. Product authentication and anti-counterfeiting: Spectroscopic analysis and AI-powered image recognition techniques are used for food product authentication [21]. The ability of AI to compare product images and spectral signatures with established patterns aids in identifying counterfeit or adulterated products. This technology safeguards consumers by mitigating the risk of fraud and ensuring product integrity. 5. Supplier verification and compliance: AI and ML algorithms play a critical role in supplier verification and compliance assessment [22]. By scrutinizing supplier data, certificates and historical performance, AI identifies potential risks, ensuring that only reputable and compliant vendors are integrated into the food supply chain. This proactive approach upholds food safety standards and minimizes potential risks. 6. Recall management: AI and ML technologies have revolutionized recall management, enabling targeted and efficient product recalls [23]. In cases of food safety concerns or contamination, AI swiftly identifies affected batches and issues’ precise recall notifications by analysing supply chain data. This precision reduces waste and minimizes the impact on consumers. 7. Data-driven decision-making: AI and ML algorithms process vast datasets from diverse sources, empowering data-driven decision-making in food safety management [24]. By analysing lab tests, customer feedback and factory records, these technologies provide insights, identify emerging trends and continuously enhance food safety procedures, thereby promoting proactive risk management. The incorporation of AI and ML into food process engineering has augmented food safety practices, ensuring proactive hazard management, real-time monitoring, traceability and informed decision-making. As these technologies continue to evolve, these advancements will elevate food safety to new heights, thereby enhancing consumer trust and well-being. Contaminant type detected and accuracy by AI and ML are shown in Fig. 4. Fig. 4 Contaminant type detected and accuracy by AI and ML (based on the finding from Martinez et al. [25] and Singh et al. [8] Full size image Regulatory Compliance and Certification in Food Safety Through AI and ML Innovations Assuring that food items adhere to the norms and regulations established by the appropriate authorities, regulatory compliance and certification play a critical role in evaluating the safety and quality of food. AI, data analytics and blockchain are examples of cutting-edge technologies that work together to optimize compliance processes, speed up audits and provide consumers with transparent information about food products. A closer look is warranted at the significance of certification and legal compliance in the food industry: 1. Ensuring food safety: Within the domain of food process engineering, ensuring the highest levels of food safety is of utmost importance. The implementation of regulatory compliance protocols ensures that food items comply with strict safety requirements, mitigating the risks of contamination, foodborne illnesses and product recalls. By utilizing AI-driven tools and techniques, food manufacturers can establish comprehensive food safety management systems that not only comply with legal mandates but also surpass them by ensuring the well-being of consumers. 2. Traceability and transparency: The application of blockchain technology in the context of food process engineering revolutionizes the concepts of traceability and transparency [7]. This innovation enables an unalterable record of a food product’s journey from its origin to its final distribution point. This level of traceability provides insights into each step of the supply chain, empowering food engineers to closely monitor and verify the conditions under which the product has been handled, stored and transported. The integration of AI further enhances this traceability, allowing for real-time data analysis to detect any anomalies that could jeopardize the safety of the product. 3. Product labelling and claims: The convergence of AI and food process engineering enhances the accuracy of product labelling and claims. AI-powered systems can comprehensively analyse product labels, ensuring that all information aligns with regulatory requirements. By examining nutritional content, allergen information and ingredient lists, AI can help prevent misleading or incorrect information, thereby safeguarding consumers’ health and maintaining the integrity of food products. 4. Simplifying audits and inspections: In the realm of food process engineering, adhering to regulatory standards often entails rigorous audits and inspections. Here, AI and data analytics offer significant advantage by automating data collection and analysis. This streamlines the audit process, enabling food engineers to quickly compile and present comprehensive compliance data. This data-driven approach enhances the efficiency, reduces the chances of oversight and facilitates smoother interactions with regulatory authorities. 5. Predictive compliance modelling: The complexity of modern food safety regulations demands proactive approaches [24]. AI’s ability to analyse historical compliance data can predict potential challenges and non-compliance trends. By identifying these patterns, food engineers can preemptively address issues and establish corrective measures to ensure continuous adherence to regulations. This anticipatory approach minimizes risks and reinforces a culture of safety in food process engineering. 6. Compliance with industry certifications and standards: AI’s analytical capabilities enhance the rigorous process of complying with industry certifications and standards. The intricate evaluation of vast datasets allows for more efficient certification processes, reducing the time and effort required to meet standards such as ISO, GMP and HACCP. This integration also supports the alignment of production processes with evolving industry benchmarks, underscoring a commitment to excellence. 7. Early warning systems: Early warning systems play a critical role in food process engineering. Prompt identification and resolution of compliance deviations are of utmost importance [13]. With the aid of AI-powered technology, early warning systems can analyse data in real time, enabling stakeholders to be immediately notified of any deviations from established norms. This capability promotes the timely implementation of corrective actions, which helps prevent potential compliance breaches, thereby ensuring the safety and quality of food products. 8. Secure document management and verification: Effective management of compliance records is a crucial component of food process engineering [7]. Blockchain technology, along with AI, provides a secure and tamper-proof method for storing important compliance records. This ensures the integrity of vital compliance records such as certificates, test results and other relevant documents. Moreover, it allows seamless access to regulators, consumers and other stakeholders while preventing any unauthorized alterations. Case studies demonstrating AI and ML applications in food safety are shown in Table 3. Table 3 Case studies demonstrating AI and ML applications in food safety Full size table Challenges and Future Directions It is crucial to solve the issues and consider other approaches if AI and ML are to be developed further and effectively used in food quality control and safety evaluation. Although these technologies have a lot of potential to enhance food quality and safety, some challenges must be overcome before they can reach their full potential. Looking at possible future possibilities can also provide insight into how these technologies will affect the food industry. Difficulties and possible directions are described as follows. Challenges Few challenges and limitations for the adoption of AI and ML are explained in the following texts and shown in Table 4. Table 4 Addressing challenges in AI and ML adoption for food safety Full size table Data Availability and Quality The dependence of AI and ML on extensive and high-quality datasets for precise predictions warrants critical appraisal, particularly in the context of trends in food science. While AI holds the promise of revolutionizing food safety, the challenge of sourcing comprehensive and reliable datasets, especially for emerging contaminants and rare quality issues, exposes a crucial limitation [27]. AI models rely on vast amounts of high-quality data for training and accurate prediction. In contrast, it can be challenging to find diverse and well-annotated data in the food industry. Data collection, labelling and storage issues must be carefully considered if reliable and representative datasets are to be guaranteed. The production of food necessitates the use of sensitive information regarding formulas, processes and quality control. Strong data privacy and security safeguards must be in place to protect private data from unauthorized access, breaches or misuse. Deep learning models can be complex and challenging to interpret. For food process engineering, understanding the reasoning behind AI-driven decisions is essential, especially regarding quality control, safety and regulatory compliance. Procedures for explainability and interpretability development are necessary for a model to be accepted and to gain trust. A few are explained in the following: Privacy and security concerns: Delving into the realm of AI and ML brings to the forefront a critical examination of the intricate web of privacy and security concerns, a topic of paramount significance in the evolving landscape of food science [28]. The assimilation of AI entails the inevitable acquisition and analysis of sensitive data, casting a shadow of uncertainty over the integrity of data privacy and security protocols. While the potential benefits of AI in food safety management are undeniable, the unresolved challenge lies in establishing impregnable fortifications against unauthorized data access and potential breaches. The intricate dance between harnessing the power of AI and safeguarding the sanctity of sensitive information demands not only careful vigilance but also innovative solutions that ensure the protection of consumer trust in the digital age. Integration with existing processes: The haunting specter of obsolescence looms large as the chasm between entrenched legacy systems, and the vanguard of AI technologies yawns wider, inviting a crucible of critical inquiry from the discerning purview of distinguished experts in the trends of food science [29]. Compatibility issues, system integration difficulties and scalability restrictions need to be resolved to ensure a smooth transition and effective application of AI and ML technologies. Interpretability and explainability: A vexing conundrum pervades the realm of AI and ML, particularly concerning the intricate labyrinth of interpretability and explainability inherent in complex models such as deep neural networks, a challenge that demands incisive scrutiny from the vantage point of the esteemed experts in the trends of food science [31]. The opacity shrouding the decision-making mechanisms of these advanced AI architectures casts a cloud of ambiguity, rendering the very bedrock of predictions elusive. Inextricably interwoven with the intricacies of food safety, the dichotomy between the inscrutability of AI and the compelling necessity for interpretability and explainability plays a profoundly critical role in the delicate tapestry of stakeholder trust and regulatory assurance [4]. The quest for effective solutions must navigate the treacherous terrain of unravelling AI’s enigmatic decision-making while safeguarding the indispensable confidence of the food industry’s custodians and gatekeepers. Regulatory compliance: The Byzantine labyrinth of regulatory acceptance looms as a herculean endeavour, a trial by fire for the vanguard of AI- and ML-generated data and its audacious claim to the throne of credibility within the hallowed halls of stringent food safety standards. A discerning eye cast upon this saga of persuasion and validation reveals a narrative fraught with complexities [30]. The food industry is subject to strict laws and regulations regarding food quality, safety, labelling and traceability. Making sure AI used in food process engineering complies with all relevant laws and standards is crucial. AI model performance evaluation and documentation should be done to demonstrate compliance with regulations. Collaboration between people and machines: AI tools should not be seen as a replacement for human labour, but rather as a tool to supplement human expertise. Ensuring effective collaboration and synergy between AI systems and human operators is essential. To fully benefit from AI technologies and enable seamless human-machine interaction, employees should receive adequate training and upskilling programmes. Applications for AI should be created and implemented ethically, considering issues of fairness, bias and transparency. Ethical issues become crucial when AI is used for processes such as product creation, quality control or supply chain management. Cost and return on investment: Initially, implementing AI technologies can be expensive due to the need for infrastructure, data collection and training. It is crucial to carefully assess the potential return on investment, accounting for factors such as increased productivity, lower waste, higher product quality and happier customers. Continuous monitoring and maintenance: AI models must be continuously monitored, updated and maintained to ensure optimal performance over time. Regular retraining, dataset updates and model adaptation to new situations or product modifications are required to keep AI systems accurate and effective. To address these issues and considerations, a multidisciplinary approach involving collaboration among food scientists, engineers, data scientists, regulatory specialists and stakeholders from the food business is required. By paying close attention to these aspects, AI can be successfully applied to food process engineering to promote innovation, increase productivity and ensure the production of high-quality, safe food items. The availability and quality of data are two significant barriers to incorporating AI into food process engineering. For training and accurate prediction, AI algorithms require high-quality data. In contrast, it can be challenging to find diverse and well-annotated data in the food industry. Data collection, labelling and storage issues must be carefully considered if reliable and representative datasets are to be guaranteed. To share data, establish criteria for data collection, and to address this problem, the food industry can collaborate with research institutions, business associations and regulatory bodies. Data quality assurance techniques should be implemented to ensure the accuracy and dependability of the data used for AI modelling. Validation, normalisation and data cleansing should all be part of these procedures. Additionally, efforts to collect data and annotate it may be made specifically for AI applications in food process engineering. Implications for Law and Ethics It is important to carefully consider the ethical and legal implications of incorporating AI into food process engineering. AI models may have an impact on quality control, safety, labelling and traceability in the food production process. It is essential to ensure that AI systems abide by legal requirements, industry norms and ethical standards. The ethical issues include dealing with issues of unfairness, transparency, privacy and bias. Biases in data and decision-making processes should be reduced by AI models throughout design and training to ensure fair treatment and equal opportunity for all people. Transparency in AI algorithms and decision-making should be supported for accountability and to foster trust. Privacy concerns must be resolved to safeguard sensitive data that AI systems collect and process. To manage ethical and regulatory issues, food corporations should establish solid governance frameworks that include stakeholders from all disciplines and areas of expertise. Close collaboration with legal experts, ethicists and regulatory organisations can aid in adherence to rules, norms and ethical principles. Interpretability and Explainability The interpretability and explainability of AI models are important aspects of food process engineering. Interpreting and explaining AI models, particularly complex deep learning models, can be challenging. In the food industry, particularly in areas such as quality control, safety and regulatory compliance, understanding the reasoning behind AI-driven decisions is crucial. An effort should be made to develop methods for model interpretability and explainability in the context of food process engineering. This may require the use of interpretable ML models, model-agnostic explanation techniques or visualisations to provide insights into the decision-making process of AI models. It is crucial to strike a balance between the demands for model accuracy and complexity, transparency and interpretability. Human-Machine Interaction This is required for the successful integration of AI into food process engineering. AI technologies should be viewed as tools to complement human skills rather than as a replacement for human labour. It is essential to ensure efficient interaction and coordination between AI systems and human operators. Employees should have access to training programmes to advance their familiarity with and competence using AI technologies. This includes understanding the limitations and potential biases of AI systems, applying AI-driven insights to decision-making and learning how to evaluate AI outputs. Collaborative interfaces and user-friendly solutions should be developed to enable the seamless interaction between humans and AI technologies. Open lines of communication and feedback between human operators and AI systems should be developed in order to solve problems, build trust and continuously improve the efficacy of AI technologies. Barriers to Adoption and Implementation There could be several issues with the adoption and use of AI in the engineering of food processes. Among the main challenges are as follows: Cost and return on investment: Initially, implementing AI technologies can be expensive due to the need for infrastructure, data collection and training. Businesses in the food industry must carefully assess the potential return on investment, considering factors such as increased productivity, decreased waste, higher product quality and happier customers. Employees who fear losing their jobs or are unclear about how AI systems operate may be resistant to the adoption of AI technologies. Businesses should invest in change management strategies that include training and communication to allay concerns and promote acceptance of AI technologies. Integration with existing processes: Introducing AI technology into the current food manufacturing and production processes requires careful planning and coordination. Compatibility issues, system integration difficulties and scalability restrictions must be resolved to ensure a smooth transition and effective application of AI technologies. Regulation and compliance requirements: The food industry is subject to strict laws and regulations regarding food quality, safety, labelling and traceability. Making sure AI used in food process engineering complies with all relevant laws and standards is crucial. AI model performance evaluation and documentation should be done to demonstrate compliance with regulations. Limited AI expertise: Due to the rapid development of AI, there are few professionals who are also knowledgeable in food process engineering. Finding or training employees with the necessary skills to develop, implement and maintain AI systems in the food industry may be challenging for businesses. To address these issues, food companies should set clear adoption goals and roadmaps for AI, collaborate with industry experts and partners and invest in ongoing training and internal AI knowledge development. The development of a culture that values innovation, experimentation and constant improvement will also help with the successful adoption and application of AI technology in food process engineering. Future Directions AI and ML personalize nutrition plans, improving health outcomes. Robotic systems and AI enhance quality control, boosting efficiency. Blockchain ensures traceability and transparency in the food supply chain. IoT and AI enable autonomous food safety monitoring, safeguarding artistry and consumer well-being (as mentioned in Table 5). Table 5 Future directions in AI and ML applications for food safety Full size table Conclusion The review study investigated the uses of AI and ML in determining the safety and quality of food. This study demonstrated how AI and ML technologies have transformed the food business, providing creative answers to improve food safety, uphold uniform quality and speed up compliance procedures. Overview of AI and ML applications in enhancing food safety, challenges and considerations in AI/ML applications for food safety and applications of AI and ML in various stages of agri-food processing is described in Tables 6 and 7 and Fig. 5, respectively. Table 6 Overview of AI and ML applications in enhancing food safety Full size table Table 7 Challenges and considerations in AI/ML applications for food safety Full size table Fig. 5 Flowchart of applications of AI and ML in various stages of agri-food processing Full size image The review paper exemplifies how AI and ML have the ability to completely alter how food safety and quality are assessed. These technologies have a significant impact on the food sector in the following ways: 1. Enhanced food safety through rapid contaminant detection: The integration of AI and ML technologies has enabled enhanced food safety through rapid contaminant detection. This integration has facilitated swift identification of contaminants, allergens and pathogens in food products, significantly reducing the risk of foodborne illnesses. Advanced algorithms analyse data from various sources, such as sensor readings and historical records to detect potential hazards and ensure the overall safety of the food supply chain [34]. 2. Elevated quality control via automated inspection: Automated inspection has contributed to elevated quality control, minimizing defects and waste while ensuring consistent product quality. AI and ML algorithms analyse real-time data from production lines, enabling early detection of deviations from quality standards and ensuring that only products meeting desired specifications reach consumers. 3. Proactive identification and management of risks: Proactive risk management is enabled through predictive modelling and early warning systems powered by AI and ML. These systems can forecast potential quality issues by analysing historical data and patterns, allowing manufacturers to take corrective actions before problems escalate. This safeguarding of product quality and consumer well-being is crucial [35]. 4. Enhanced transparency and trust with blockchain: The integration of blockchain technology into the food supply chain enhances traceability and transparency, thereby fostering trust and accountability. Tamper-proof and immutable records enable all stakeholders, including regulators, vendors and consumers, to verify the origin, handling and safety of food products [36]. 5. Streamlined regulatory compliance and auditing: Regulatory compliance processes are streamlined through AI and ML technologies, which expedite audits and inspections. These technologies facilitate data collection, analysis and reporting, enabling food industry players to adhere to rigorous food safety standards and meet compliance requirements efficiently. Significance of AI and ML in Food Quality Control and Safety The significance of AI and ML in revolutionizing the assessment of food quality control and safety cannot be overstated. These technologies have brought about a paradigm shift in the industry, driven by their remarkable ability to automate processes, provide data-driven insights and ensure consumer safety [10, 37]. The real-time and proactive nature of AI and ML facilitates rapid decision-making, effectively mitigating potential risks and preventing costly recalls [15]. Their integration into food processing operations enhances efficiency, reduces waste and increases transparency, thereby fostering consumer trust in the reliability of the entire food supply chain [38]. The culmination of these transformative effects is evident in the conclusions drawn from comprehensive review studies. AI and ML have emerged as indispensable tools with versatile applications and transformative potential in the realm of food quality control and safety assessment [39]. Their impact spans across safeguarding food safety, maintaining consistent product quality and ensuring compliance with stringent regulatory standards within the complex food industry landscape. Through the adoption of AI and ML, public health is preserved, and the global food supply chain attains elevated standards, reflecting the harmonious amalgamation of cutting-edge technology and the paramount goals of food processing and safety. Availability of Data and Materials All of the data that were analysed throughout the course of this study have been comprehensively incorporated within this published article. References Rady A, Ekramirad N, Adedeji AA, Li M, Alimardani R (2017) Hyperspectral imaging for detection of codling moth infestation in GoldRush apples. Postharvest Biol Technol 129:37–44. https://doi.org/10.1016/j.postharvbio.2017.03.007 Article   CAS   Google Scholar   Boyd DW, Sun MK (1994) Prototyping an expert system for diagnosis of potato diseases. Comput Electron Agric 10(3):259–267. https://doi.org/10.1016/0168-1699(94)90045-0 Article   Google Scholar   Peixoto MS, Barros LC, Bassanezi RC, Fernandes OA (2015) An approach via fuzzy systems for dynamics and control of the soybean aphid. In: Proceedings of the 2015 Conference of the International Fuzzy Systems Association and the European Society for Fuzzy Logic and Technology (IFSA-EUSFLAT-15). https://doi.org/10.2991/ifsa-eusflat-15.2015.183 Wolfert S, Ge L, Verdouw C, Bogaardt M-J (2017) Big data in smart farming – a review. Agric Syst 153:69–80. https://doi.org/10.1016/J.AGSY.2017.01.023 Article   Google Scholar   Si Y, Liu G, Lin J, Lv Q, Juan F (2007) Design of control system of laser levelling machine based on fussy control theory. In: Proceedings of the International Conference on Computer and Computing Technologies in Agriculture. Springer, Wuyishan, China, pp 1121–1127. https://doi.org/10.1007/978-0-387-77253-0_46 Kakani V, Nguyen VH, Kumar BP, Kim H, Pasupuleti VR (2020) A critical review on computer vision and artificial intelligence in food industry. J Agric Food Res 2:100033. https://doi.org/10.1016/J.JAFR.2020.100033 Bestelmeyer BT, Marcillo G, McCord SE et al (2020) Scaling up agricultural research with artificial intelligence. IT Professional 22(3):33–38. https://doi.org/10.1109/MITP.2020.2986062 Article   Google Scholar   Singh P, Jindal M, Khurana SMP (2020) Machine learning techniques in food safety. Trends Food Sci Technol 91(2):22–30 Google Scholar   Liu J, Cho DS (2021) A survey of machine intelligence. IEEE Access 9:16259–16279 Google Scholar   LeCun Y, Bengio Y, Hinton G (2015) Deep learning. Nature 521(7553):436–444. https://doi.org/10.1038/nature14539 Article   ADS   CAS   PubMed   Google Scholar   Young T, Hazarika D, Poria S, Cambria E (2018) Recent trends in deep learning based natural language processing. IEEE Comput Intell Mag 13(3):55–75. https://doi.org/10.1109/MCI.2018.2840738 Article   Google Scholar   Jurafsky D, Martin JH (2019) Speech and language processing, 3rd edn. https://web.stanford.edu/~jurafsky/slp3/ Spanaki K, Karafili E, Sivarajah U, Despoudi S, Irani Z (2021) Artificial intelligence and food security: swarm intelligence of agritech drones for smart agrifood operations. Prod Plan Control 1–19. https://hdl.handle.net/10454/17961 Zhang L, Zhang C, Jiang Z (2021) Research on food safety management system based on deep learning and IoT. Proceedings of the 2021 International Conference on Electronics, Communications and Information Technology (ECIT), pp 141–145 Google Scholar   Lee WS, Liew CV (2018) Data-driven modeling and predictive control of an industrial supercritical CO2 extraction process. Comput Chem Eng 116:1–14 ADS   Google Scholar   Smith J, Brown A, Johnson C (2020) Application of spectroscopy in food safety and quality control. Food Sci J 12(2):45–52 Garcia-Garcia A, Riquelme-Blondet A, Salloum C (2021) Predictive modeling in food manufacturing: challenges and opportunities. Food Technol Mag 75(3):50–55 Ojo TO, Baiyegunhi LJS, Adetoro AA, Ogundeji AA (2021) Adoption of soil and water conservation technology and its effect on the productivity of smallholder rice farmers in Southwest Nigeria. Heliyon 7(3):e06433. https://doi.org/10.1016/j.heliyon.2021.e06433 Lundberg SM, Lee SI (2017) A unified approach to interpreting model predictions. Adv Neural Inf Process Syst. https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf Widener MJ, Shannon J (2014) When are food deserts? Integrating time into research on food accessibility. Health Place 30:1–3. https://doi.org/10.1016/j.healthplace.2014.07.011 Article   PubMed   Google Scholar   Boissard OP, Martin V, Moisan S (2008) A cognitive vision approach to early pest detection in greenhouse crops. Comput Electron Agric 62(2):81–93. https://doi.org/10.1016/j.compag.2007.11.009 Article   Google Scholar   Pérez-Harguindeguy N, Díaz S, Garnier E et al (2016) Corrigendum to: new handbook for standardized measurement of plant functional traits worldwide. Aust J Bot 64(8):715–716 Article   Google Scholar   Marambe B, Silva P (2020) A sixty-day battle to tackle food security – response of the Sri Lankan government to the COVID-19 pandemic. Sri Lanka J Food Agric 6(1). https://doi.org/10.4038/sljfa.v6i1.77 Misra NN, Dixit Y, Al-Mallahi A, Bhullar MS, Upadhyay R, Martynenko A (2020) IoT, big data and artificial intelligence in agriculture and food industry. IEEE Internet Things J 1–1. https://doi.org/10.1109/JIOT.2020.2998584 Martinez S, Vaga M, Moltó E (2017) AI for pathogen detection in food. Food Microbiol 75(1):123–131 Google Scholar   Wang Y, Wu D, Li J (2018) Applications of artificial intelligence and machine learning in food safety and quality control. Food Control 86:352–362 Google Scholar   Chaudhary A, Kolhe S, Kamal R (2016) A hybrid ensemble for classification in multiclass datasets: an application to oilseed disease dataset. Comput Electron Agric 124:65–72. https://doi.org/10.1016/j.compag.2016.03.026 Article   Google Scholar   Narayanan A, Shmatikov V (2019) Robust de-anonymization of large sparse datasets: a decade later. https://www.cs.princeton.edu/~arvindn/publications/de-anonymization-retrospective.pdf Yang P, Chen Y (2017) A survey on sentiment analysis by using machine learning methods. In: IEEE 2nd Information Technology, Networking, Electronic and Automation Control Conference (ITNEC). Chengdu, China, pp 117–121. https://doi.org/10.1109/ITNEC.2017.8284920 Guidotti R, Monreale A, Ruggieri S, Turini F, Giannotti F, Pedreschi D (2018) A survey of methods for explaining black box models. ACM Comput Surv 51:1–42. https://doi.org/10.1145/3236009 Article   Google Scholar   Ribeiro MT, Singh S, Guestrin C (2016) Why should I trust you? Explaining the predictions of any classifier. In: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. San Francisco, CA, USA, pp 1135–1144. https://dl.acm.org/doi/pdf/10.1145/2939672.2939778? Khan WZ, Aalsalem MY, Khan MK, Arshad Q (2019) Data and privacy: getting consumers to trust products enabled by the internet of things. IEEE Consum Electron Mag 8(2):35–38. https://doi.org/10.1109/MCE.2018.2880807 Article   Google Scholar   Liu C, Wang X, Wang Y (2022) Blockchain technology in food safety and traceability. Trends Food Sci Technol 121:33–45 Google Scholar   Li Y, Zhu Y, Zhang Y (2021) Application of artificial intelligence in food safety detection. Front Nutr 8:640804 Google Scholar   Wang C, Huang L, Li P (2020) Early warning of food safety risk based on machine learning. Food Res Int 132:109071 Google Scholar   Zhong RY, Newman ST, Huang GQ (2021) Big data analytics and artificial intelligence pathways to deploy blockchain for sustainable food supply chains. Int J Prod Res 59(17):5337–5353 Google Scholar   Mottaleb KA, Rahut DB (2018) Impacts of modern rice varieties on farmers’ livelihood in Bangladesh and Nepal. PLoS ONE 13(8):e0201835 Google Scholar   Menard JP, Drèze X, Vibet MA (2019) Blockchain: a meta-technology for self-organization? Technol Forecast Soc Chang 146:68–80 Google Scholar   Liu Y, Miao L, Lu J, Li J, Chen L (2021) A comparative study of machine learning algorithms for shelf life prediction of pork. Food Control 120:107566 Google Scholar   Download references Acknowledgements The author is thankful to the Dr. RPCAU, Pusa, Samastipur, Bihar, India, for providing a research-oriented environment and constant encouragement for pursing this research. Funding No fund is provided for this research. Author information Authors and Affiliations Krishi Vigyan Kendra, Bhagwanpur Hat, Siwan, 841408, India Krishna Bahadur Chhetri Dr. RPCAU, Pusa, Samastipur, Bihar, India Krishna Bahadur Chhetri Contributions The author performed the conceptualization, literature review, data collection, data analysis, writing and visualisation and oversaw the entire review process, from conceptualization to the final manuscript. Corresponding author Correspondence to Krishna Bahadur Chhetri. Ethics declarations Ethical Approval Not applicable. Competing Interests The author declares no competing interests. Additional information Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Rights and permissions Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law. Reprints and permissions About this article Cite this article Chhetri, K.B. Applications of Artificial Intelligence and Machine Learning in Food Quality Control and Safety Assessment. Food Eng Rev 16, 1–21 (2024). https://doi.org/10.1007/s12393-023-09363-1 Download citation Received 01 August 2023 Accepted 07 December 2023 Published 22 December 2023 Issue Date March 2024 DOI https://doi.org/10.1007/s12393-023-09363-1 Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Keywords Artificial intelligence Machine learning Food quality control Food safety assessment Computer vision Deep learning Use our pre-submission checklist Avoid common mistakes on your manuscript. Sections Figures References Abstract Introduction Materials and Methods Significance of AI and ML in Food Quality Control and Safety Availability of Data and Materials References Acknowledgements Funding Author information Ethics declarations Additional information Rights and permissions About this article Advertisement Discover content Journals A-Z Books A-Z Publish with us Publish your research Open access publishing Products and services Our products Librarians Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy rights Accessibility statement Terms and conditions Privacy policy Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"

Paper 5:
- APA Citation: None
  Main Objective: This research develops a new IDS framework for IoT security systems using DRF and DBRF strategies to tackle the issues associated with data cleaning, feature selection, and attack classification.
  Study Location: None
  Data Sources: None
  Technologies Used: None
  Key Findings: None
  Extract 1: None
  Extract 2: None
  Limitations: None
  Relevance Evaluation: {'extract_1': None, 'extract_2': None, 'limitations': None, 'relevance_score': 1.0}
  Relevance Score: 1.0
  Inline Citation: None
  Explanation: Due to the varying data quality, time, and computational constraints, traditional approaches for real-time intrusion detection in IoT networks face obstacles. Traditional IDS systems may struggle with datasets with differing temporal and qualitative characteristics, but in contrast, the suggested method depends on a mix of optimization and categorization algorithms to automate processes, remove redundancy, and increase detection performance. The goal is to increase IDS's precision and effectiveness against harmful cyberattacks by employing the Decisive Red Fox (DRF) optimization approach to choose the most significant features from raw data and the Descriptive Back Propagated-Radial Basis Function (DBRF) classification model to classify various intrusion types. The performance of the proposed system is thoroughly analyzed using several evaluation metrics and widely used IoT benchmarking datasets, indicating its superior efficiency and effectiveness.

 Full Text: >
"Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Advertisement View all journals Search Log in Explore content About the journal Publish with us Sign up for alerts RSS feed nature scientific reports articles article Article Open access Published: 03 January 2024 A novel IoT intrusion detection framework using Decisive Red Fox optimization and descriptive back propagated radial basis function models Osama Bassam J. Rabie, Shitharth Selvarajan, Tawfiq Hasanin, Abdulrhman M. Alshareef, C. K. Yogesh & Mueen Uddin  Scientific Reports  14, Article number: 386 (2024) Cite this article 844 Accesses 1 Citations Metrics Abstract The Internet of Things (IoT) is extensively used in modern-day life, such as in smart homes, intelligent transportation, etc. However, the present security measures cannot fully protect the IoT due to its vulnerability to malicious assaults. Intrusion detection can protect IoT devices from the most harmful attacks as a security tool. Nevertheless, the time and detection efficiencies of conventional intrusion detection methods need to be more accurate. The main contribution of this paper is to develop a simple as well as intelligent security framework for protecting IoT from cyber-attacks. For this purpose, a combination of Decisive Red Fox (DRF) Optimization and Descriptive Back Propagated Radial Basis Function (DBRF) classification are developed in the proposed work. The novelty of this work is, a recently developed DRF optimization methodology incorporated with the machine learning algorithm is utilized for maximizing the security level of IoT systems. First, the data preprocessing and normalization operations are performed to generate the balanced IoT dataset for improving the detection accuracy of classification. Then, the DRF optimization algorithm is applied to optimally tune the features required for accurate intrusion detection and classification. It also supports increasing the training speed and reducing the error rate of the classifier. Moreover, the DBRF classification model is deployed to categorize the normal and attacking data flows using optimized features. Here, the proposed DRF-DBRF security model's performance is validated and tested using five different and popular IoT benchmarking datasets. Finally, the results are compared with the previous anomaly detection approaches by using various evaluation parameters. Similar content being viewed by others Firefly algorithm based WSN-IoT security enhancement with machine learning for intrusion detection Article Open access 02 January 2024 A balanced communication-avoiding support vector machine decision tree method for smart intrusion detection systems Article Open access 05 June 2023 Robust genetic machine learning ensemble model for intrusion detection in network traffic Article Open access 11 October 2023 Introduction Internet of Things (IoT) has recently drawn increased attention because of its innovative uses and support for various industries, including industrial applications, healthcare, transportation, ambient intelligence1, etc. IoT offers a vast range of applications and services but also confronts serious security risks and assaults. Since the IoT is a heterogeneous environment, traditional security techniques are not supported by its interoperability mechanism2. IoT security is improved in other ways, such as data authentication, secrecy, and access controls3. However, IoT networks are susceptible to numerous assaults that try to disrupt the web, even with these defenses. A separate module must therefore ensure the security of the IoT network. One such idea is the intrusion detection system (IDS)4,5, which is already utilized in wireless networks. Also, it helps to secure the network from assaults and other vulnerabilities by improving the IDS features of wireless networks. Specifically, the IDS6,7,8 is treated as the essential element in enhancing the cybersecurity of IoT networks, which is also highly suited for both fog and cloud platforms. Moreover, it uses the internet and real-time applications to offer users an efficient and convenient environment. Therefore, before deploying an IDS9,10, it is essential to analyze the security challenges in the network. Some of the significant properties used to ensure the security of IoT networks are as follows: data confidentiality, authentication, integrity, availability, and authorization11. The three primary functional mechanisms that most existing IDS12,13,14,15,16 use are as follows: Sources of information When determining if an intrusion has occurred, sources of information such as incoming packets or data are considered. Characterization The required method determines when the events gathered suggest that intrusions are happening or have already happened. The most popular analysis techniques are misuse detection and anomaly detection. Reaction When the system notices an intrusion, it sends a response. There are two types of reaction measures: active and passive. A functional response measure occurs when the system takes action on its own, whereas a passive response measure sends its findings to the administrator, who may take action based on these reports. Also, various machine learning and deep learning17,18 based AI mechanisms are used in the traditional works for developing an effective IDS. Machine learning is a kind of artificial intelligence that systematically uses algorithms to discover the underlying connections between data and information. It is categorized into the types of supervised learning, unsupervised learning, and reinforced learning. Similarly, the deep learning techniques19 are also increasingly used nowadays, which is an extended version of machine learning. However, the conventional classification methodologies4 face the challenges associated to the factors of increased time consumption, overfitting, reduced processing speed, high false positives, and difficulty in understanding. The IoT delivers innovative features and services to a large number of consumers, hence enhancing their lifestyles. Most IoT devices and objects don’t require a lot of capacity. The IoT has a limited amount of available storage and transmission capacity. As a result, clouds are used to store a vast amount of confidential documents. This increases the availability and accessibility of the services supplied while lowering the expenses and effort. This technology enables the users to access the applications and services at anywhere & anytime, which creates a significant challenges to the data security. Moreover, some other factors such as cost, performance, data scalability and availability are also considered as the IoT related challenges. Since, there is no standard format or protocol for the data transmission, storage, maintenance and etc in IoT, when it is dealing with vast amount of data. Some of these issues usually take the form of network anomalies, like a deviation from normal network action. The IoT devices are becoming more prevalent in today's world, yet the cloud has significant restrictions as listed below: More energy consumption Increased network bandwidth consumption High latency or delay Outage of internet High maintenance cost due to an unwanted data storage Minimal control over the applications or data Security breaches Due to the IoT features such as flexible data sharing and constant connectivity, there are a number of cybersecurity problems have been created with this development. To resolve this problem, many IDS are developed for assuring IoT security, which showed their effectiveness in mitigating cyber-threats. Specifically, the deep learning algorithms are increasingly used in the existing works for enhancing the attack detection rate in an IoT networks. However, the existing deep learning techniques are highly complex to interpret, and their prediction decisions are very difficult to understand by the cybersecurity experts. As a result, the corresponding users are unable to both understand and trust the decisions made by DL models and to optimize their own actions in light of those decisions. Therefore, the proposed work motivates to develop an efficient and highly secured IDS framework for IoT security. The main purpose of this research article to design and develop a novel IoT based intrusion detection framework for maximizing the security with lower computational burden. It also intends to maintain an improved detection performance and results while accurately predicting the type of intrusion from the large/huge dimensional intrusion datasets. For accomplishing these objectives, the different kinds of mining techniques including preprocessing, DRF based feature selection, and DBRF based classification are implemented in this study. The major research contributions of this paper are as follows: In order to generate a balanced dataset that will increase the detection rate and precision of IDS, data preprocessing is carried out, which includes handling of NaN values, the extraction of categorical features, and the identification of missing fields. A Decisive Red Fox (DRF) optimization approach is used to extract the pertinent features from the balanced IoT datasets, which improves the classifier's training process. The use of a Descriptive Back Propagated Radial Basis Function (DBRF) classification method allows the identification and categorization of intrusions in IoT systems based on the features of data. To validate and compare the results of proposed DRF-DBRF security framework, various evaluation indicators as well as the popular IoT IDS datasets are utilized in this work. The remaining sections of this article are divided into the following categories: The traditional approaches to enhancing the security of IoT networks are reviewed in “Related works” section. Additionally, it verifies the benefits and drawbacks of each mechanism in light of the effectiveness and outcomes of its attack detection. The suggested DRF-DBRF methodology is fully explained in “Methods” section together with the overall work flow and algorithms. Additionally, “Results” section compares and validates the performance and outcomes of the proposed technique using a variety of performance indicators. Finally, “Conclusion” section summarizes the entire work together with the conclusions and future scope. Related works The comprehensive literature review of the IDS frameworks currently in use for enhancing the security of IoT networks is presented in this part. Furthermore, it examines each model's benefits and drawbacks in context of its effectiveness and reliability in detection. Gu et al.20 utilized a Convolutional Neural Network (CNN) mechanism for developing an accurate IDS framework to ensure the security of IoT networks. Here, the Kitsune network attack database has been utilized to implement this system, which comprises the different types of network attacks. The CNN has the ability to automatically recognize the data packets for ensuring a secured end-to-end communication in IoT systems. However, the CNN model requires a lot of training data to predict an accurate results, and it has a reduced learning speed. Alsoufi et al.21 presented a comprehensive literature review to examine various deep learning techniques for designing an effective anomaly detection system. Also, it intends to increase the detection accuracy, and minimize the false alarm rate by solving the security problems in the IoT networks. Here, the 11 different types of attack datasets have been utilized to validate the system model using various parameters. According to this survey, it is observed that developing a lightweight anomaly detection mechanism could be highly beneficial for the IoT systems. According to this study work, it is noted that the majority of deep learning mechanisms facing challenges in high computational complexity while training samples for classification, increased time consumption for both training and testing operations, and overfitting outcomes. Mishra et al.22 presented a comprehensive literature review to analyze the security challenges, vulnerabilities, and attacks in the IoT networks. The authors of this paper intend to conduct a multi-fold survey for analyzing the security issues in the IoT layers. Typically, ensuring the parameters such as interoperability, connectivity, and standardization were considered as the major security challenges of IoT networks, which is graphically represented in Fig. 1. Figure 1 Challenges in IoT systems. Full size image The main focus of this paper is to study the different types of DDoS attacks with their mitigation strategies. Here, the various types such as volumetric attack, protocol based attack, and application layer attack are discussed with the goal of attacker and the preventive solutions. As its name implies, a DDoS attack aims to overload a target and stop services from functioning. IoT devices are highly suited for the DDoS attack because it needs a lot of devices to initiate an attack. Also, the users will typically not be aware that a device is compromised. The suggested work only focused on detecting DDoS attacks from the network, since some of the modern attacks could degrade the performance of wireless networks in present days. Fatani et al.23 utilized an aquila optimization technique integrated with the deep learning mode for developing an efficient IDS for IoT systems. Here, the CNN algorithm was utilized for extracting the relevant features from the given attack datasets. Then, the binary aquila optimization algorithm was deployed for choosing the optimal features with increased classification accuracy. Finally, the ML classification algorithm was deployed to categorize the type of attacks according to the reduced features. However, the suggested optimization technique having the specific drawbacks of local optimum, lower searching efficiency, and increased time for finding optimal solutions. Abd-Elaziz et al.24 developed a new capuchin search algorithm incorporated with the deep learning model for detecting intrusions from cloud-IoT systems. The purpose of this paper is to implement a new feature selection based deep learning algorithm for assuring the security of IoT systems. Here, various and recent Cloud-IoT datasets have been utilized to validate the performance of the suggested mechanism. The outcomes of this analysis depict that the suggested technique provides a competitive performance for all datasets utilized in this work. Nevertheless, the suggested deep learning algorithm requires lot of training samples to predict the accurate results. Aslam et al.25 introduced an adaptive machine learning based security methodology for protecting SDN from cyber-attacks. Here, an adaptive multi-layered feed forward mechanism is deployed to accurately spot the DDoS attacks by analyzing the features of the network traffic. Moreover, this framework provides an increased accuracy with low false alarm rate. But, it failed to focus some of the modern attacks or vulnerabilities that degrade the security of SDN. Smys et al.26 introduced a hybrid IDS for protecting IoT system against network vulnerabilities and harmful intrusions. The motive of this work was to guarantee the properties of data confidentiality, integrity, availability, authorization, and authentication for IoT security. Typically, the three different types of security schemes were used for IoT networks, which includes placement strategy, detection strategy, and validation strategy. In this work, the LSTM-RNN model was used to detect the network anomaly with improved performance. Moreover, this framework comprises the working stages of log file generation, feature extraction, encoring, matrix formation, classification, and intrusion categorization. However, the suggested methodology was not more suitable for handling the complex network datasets, which could be the major limitation of this work. Almiani et al.27 implemented a Deep Recurrent Neural Network (DRNN) for increasing the security of IoT networks. It encompasses the major operations of feature reduction, data normalization, over sampling, and intrusion detection. In the suggested framework, the common mining operations including sampling, normalization, feature elimination, and intrusion identification processes are performed. For classification, the DRNN technique is implemented here, which follows some complex mathematical models to accurately predict the type of intrusion. Hence, it may be difficult to understand the classification operations of the suggested technique. Verma et al.28 deployed an ensemble of machine learning classifiers for detecting intrusions from the IoT networks. It includes Random Forest (RF), Gradient Boosted Machine (GBM), Extreme Gradient Boost (EGB), Extremely Randomized Trees (ERT), Classification & Regression Trees (CART), and Multi-Layer Perceptron (MLP). Consequently, various benchmarking datasets have been used to validate the performance of these classifiers. Based on this investigation, it is identified that the CART outperforms the other machine learning models with improved attack detection accuracy. Yet, it follows some complex mathematical modeling for attack prediction and classification. Anthi et al.29 developed a three layered IDS framework using a supervised learning methodology for protecting IoT networks. This framework comprises the following operations: IoT device behavior analysis Malicious packet identification Attack class categorization Specifically, the authors intend to design and develop a lightweight security framework for detecting cyber-attacks in the smart home IoT networks. The advantages of this framework were increased attack detection accuracy, better efficacy, easy deployment, and reduced overfitting. However, the time required for training and testing the features while classifying the type of data need to be reduced. Al-Hadhrami et al.30 introduced a real time dataset generation framework for spotting intrusions in the IoT networks. In this work, the problems and limitations associated to the existing IDS datasets have been discussed. Moreover, the key components involved in this framework were capturing medium, data aggregation, feature extraction, and queuing unit. Benkhelifa et al.31 presented a critical review to protect the IoT networks against the network intrusions. The purpose of this paper was to develop a highly secure and robust IDS framework for analyzing the malicious behavior of nodes. The different types of detection methodologies reviews in this work were anomaly detection models, specification based detection methods, and hybrid detection models. Qureshi et al.32 introduced a heuristic based detection mechanisms for protecting IoT networks, which includes the modules of data preprocessing, classifier training and testing. During dataset processing, the attribute selection, one hot encoding, and normalization operations were performed to improve the training and testing processes. Moreover, it accurately predict the normal and attacking data traffic flows based on the features training features. Due to the increased dimensionality of features, the overall attack detection accuracy and efficiency of classification have been affected. Kumar et al.33 introduced a Unified IDS framework for strengthening the security IoT networks against four different types of attacks such as exploit, DoS, probe and generic. Here, the dataset clustering was performed at the initial stage for analyzing the behavior of attacks. Then, the rule generation and integration operations were performed to extract the relevant features for classifier training and testing. This framework is not capable of handling huge datasets with low time and computational complexity. This part presented the related works that review and outline intrusion detection strategies utilizing machine learning/deep learning algorithms in the IoT network by emphasizing their key contributions. In several studies, the topics of IoT security, privacy, and intrusion detection are addressed. Although several research studies34 on intrusion detection systems in IoT applications are still in the development phase. The study indicates that much of the existing research work faces several challenges while ensuring security in IoT. Hence, it is most important to resolve the following problems for developing an effective IDS: computational burden, increased amount of time for prediction, inability to handle a vast amount of data, and high false positives. As a result, the proposed study aims to create an intelligent and efficient IDS framework for enhancing IoT security against dangerous network intrusions. Methods This section provides the complete explanation for the proposed security model used to protect IoT systems. The IoT technologies are anticipated to provide a new level of communication with the use of smart devices, which can improve regular chores and enable smart decisions based on sensed data. The original contribution of the proposed work is to develop an intelligent IoT intrusion detection framework with the use of advanced DRF and DBRF techniques. By using the combination of these methodologies, the overall performance and efficacy of the intrusion detection system is greatly improved with high accuracy, lower training and testing time. Moreover, this eliminates the need of complex mathematical calculations for preprocessing, feature optimization, and classification operations. In order to determine its efficacy and superiority, the most recent and huge dimensional IoT intrusion datasets are taken into account for performance validation and assessment. The sensitive data collected by the IoT must be protected from assaults and privacy concerns. Moreover, the IoT security is a hotly debated topic in both academia and business in present days. In fact, attacks to IoT products and services could result in security breaches and information leakage. The purpose of this work is to design an IDS framework using machine learning technique, with the goal of detecting attempts to exploit IoT systems and to mitigate hostile occurrences. The original contribution of this work is to develop a highly efficient and accurate IDS framework for securing the IoT networks by using a novel data mining methodologies. For accomplishing this objective, a novel Decisive Red Fox optimization (DRF) and Descriptive Back Propagated-Radial Basis Function (DBRF) network classification models are deployed, which helps to strengthen the security of IoT networks. The overall work flow of the proposed system is shown in Fig. 2, which comprises the following operations: Data preprocessing & normalization Decisive Red Fox (DRF) optimization based feature selection Descriptive Back Propagated-Radial Basis Function (DBRF) network based classification Attack identification and categorization Performance evaluation Figure 2 Workflow model of the proposed security framework. Full size image Here, the popular IoT IDS datasets such as IoTID-20, NetFlow-BoT-IoT-v2, NF-ToN-IoT-v2, NSL-KDD, UNSW-NB 15 datasets have been used for system implementation. The raw network datasets are noisy, which holds some irrelevant attributes, and missing fields. As a result, it affects intrusion detection and classification performance and outcomes. Thus, the data normalization and preprocessing operations are performed in this framework, which holds the operations of handling Not a Number (NaN) values, handling categorical values, and missing values. In the proposed work, the imbalanced dataset is handled by using the random over-sampler to preprocess the incoming data, handling missing values, categorical features, NaN values, and unbalanced datasets. Data cleansing, visualization, feature engineering, and vectorization are typically done as part of the dataset preprocessing procedure. To extract data from the data collection, all of these methods have been applied. Two sets of these characteristic vectors have been generated, one for training and the other for testing, with 80:20 proportion between the two sets. An unbalanced dataset, missing values, categorical features, and NaN value handling are the four processes used in the proposed work to deal with the incoming data. Here, the NaN value handling is mainly performed to highly increase the accuracy of intrusion recognition and classification. After successfully handling NaN values, the next step in handling categorical features is processing those characteristics. This stage involves handling categorical data before it is fed into artificial intelligence learning models. Following that, the non-random missing values and the random missing values are handled. Randomly missing values are those that are absent from a subset of the data. Finally, the imbalanced data is balanced with complete attributes or information with the aid of random over sampler. Following preprocessing, the data is fed into the DRF feature selection algorithm, which retrieves features out of the dataset. The DBRF classification approach is used to classify the features and divide the data into attack and non-attack groups. Consequently, the DRF optimization model is used to select the most pertinent and advantageous features, hence enhancing the classifier's training speed and detection rate. The data flow is then classified as either an attacker or a normal flow based on an optimum collection of attributes using the DBRF classification model. The primary advantages of using the proposed DRF-DBRF IDS framework are increased training speed, minimal time consumption, reduced overfitting, accurate detection rate, and easy to deploy. Balanced dataset is referred to as the preprocessed or the normalized dataset that is used for subsequent intrusion detection operations. This dataset has the normalized attribute information, no missing values, and redundant information. By using the DRF algorithm, the most required subset of features are selected with its best optimum solution, which helps to train the classifier with reduced dimensionality of features. In the proposed study, there are 5 distinct and different intrusion datasets have been used for intrusion detection, and each of which having increased number of features or attributes. These are eliminated by optimally picking some selective attributes according to the best optimum solution obtained from the DRF technique. After feature reduction, the selected subset of features are passed to the DBRF classifier for training and testing operations. Based on this process, the accurate label is predicted as whether normal or attacker with high accuracy. In the proposed work, there are 5 distinct IoT intrusion datasets are used for system implementation and we are not combining these datasets together. Here, each dataset is separately used as the input for intrusion detection and classification. Preprocessing and normalization The original IoT datasets are preprocessed at first for normalizing the attributes before classification, which holds the operations of NaN values handling, categorical feature extraction, and identification of missing fields. Then, it produces the balanced and normalized dataset as the output for further operations. The data is first preprocessed, which involves dealing with NAN values, categorical characteristics, unbalanced datasets, and missing values that can happen both unintentionally and purposefully. The data is then processed further afterwards this process. Preprocessing helps to gain better quality data while also lowering the challenges that come with the data, which impedes the flow of data traffic. The abbreviation NaN, which stands for \"Not a Number,\" is one of the most frequently used symbols to denote a missing value in data when dealing with NaN numbers. The input data for an attack detection system must be free of NaN values in order to increase the accuracy of attack detection. After successfully managing NaN values, handling categorical characteristics is the next step for handling categorical features. Before categorical data is fed into the machine learning models, which is the final step, it must be processed in this stage. Machine learning models are unable to operate effectively with data that is saved in the texture format because they are regarded as mathematical models. Both randomly generated and non-randomly generated missing values are handled in the next phase of the missing value handling operation. Randomly missing values are those that are absent from certain subsamples of data. When data is absent but still has a defined structure, it's referred to as missing values. During this process, the operations such as NaN values handling, categorical attributes handling, and missing values handling at both random and not at random are performed. If the estimated ratio of both attack and non-attack samples are same, the features are directly extracted from the dataset for balancing; otherwise, the random over sampler is used to handle the imbalance information for producing the balanced dataset. The preprocessing phase handles both missing values that are not random and missing values that are missing at random. Missing values at random are those values that are absent from some subsamples of the data, which are identified when the missing data has a certain structure. Here, the NaN handling is performed to find out the missing values in the given data, which helps to increase the accuracy of intrusion detection. It is computed by using the following equation: $$ DS_{N}^{{handling{ }\\left( {NaN} \\right)}} = {\\Phi }_{{NaN_{handling} }} \\left( {DS_{N} } \\right) $$ (1) where \\(DS_{N}\\) indicates the input data, \\({\\Phi }_{{NaN_{handling} }}\\) represents the model used to handle the NaN values, and \\(DS_{N}^{{handling{ }\\left( {NaN} \\right)}}\\) indicates that is acquired after processing NaN values. Consequently, the categorical feature handling is performed NaN handling, since it is processed before being fed into the classification stage. The features are obtained by using the following models: $$ DS_{N}^{{handling{ }\\left( {CF} \\right)}} = \\varrho_{CF\\_handling} \\left( {DS_{N} } \\right) $$ (2) where \\(\\varrho_{CF\\_handling}\\) indicates the model used to handle the categorical data, \\(DS_{N}^{{handling{ }\\left( {CF} \\right)}}\\) is the output data retrieved after category processing. Moreover, the missing values are identified and handled for generating the normalized dataset. Missing values at random are those values that are absent from some subsamples of the data. Missing values—as opposed to missing data—are identified when the missing data has a certain structure. The missing values are identified by using the following equation; $$ DS_{N}^{{handling\\left( {Miss{ }Value} \\right)}} = \\delta_{{handling - missvalue{ }}}^{{\\left( {R,{ }NR} \\right)}} \\left( {DS_{N} } \\right) $$ (3) where \\(\\delta_{{handling - missvalue{ }}}^{{\\left( {R,{ }NR} \\right)}}\\) represents the method used to handle the missing values, and \\(DS_{N}^{{handling\\left( {Miss{ }Value} \\right)}}\\) is the output data obtained after handling missing values. Moreover, the preprocessed dataset is generated in the following form: $$ DS_{N}^{PD} = \\left\\{ {DS_{1} ,DS_{2} ,{ }DS_{3} \\ldots DS_{N} } \\right\\} $$ (4) where \\(DS_{N}^{PD}\\) denotes the preprocessed dataset, and N indicates the total number of data. The balanced and imbalanced dataset is obtained based on the ratio of attacking and non-attacking samples by using the following equation: $$ DS_{N}^{PD} = \\left\\{ {\\begin{array}{*{20}l} {DS_{N}^{B} } \\hfill & {if\\;\\left( {X\\left( {DS_{N}^{PD} } \\right) = Y\\left( {DS_{N}^{PD} } \\right)} \\right)} \\hfill \\\\ {DS_{N}^{IB} } \\hfill & {if\\;\\left( {X\\left( {DS_{N}^{PD} } \\right) \\ne Y\\left( {DS_{N}^{PD} } \\right)} \\right)} \\hfill \\\\ \\end{array} } \\right. $$ (5) where \\(DS_{N}^{B}\\) represents the balanced dataset, \\(DS_{N}^{IB}\\) denotes the imbalanced dataset, X and Y indicates the attacking and non-attacking data respectively. The balanced data from the collected information is added to the subsequent phase, while the imbalanced data is dealt with by a random over sampler. Here, an imbalanced dataset is handled by using a random oversampler to balance the data. By arbitrarily repeating instances from the minority class and applying them to the training input, the random oversampler creates balanced data by using the following equation: $$ DS_{N}^{IB} \\mathop{\\longrightarrow}\\limits^{Oversampling}DS_{N}^{B} . $$ (6) Finally, the balanced dataset is obtained after oversampling, which can be used for further optimization and classification processes. Decisive Red Fox (DRF) optimization After obtaining the balanced dataset from the previous stage, the DRF optimization algorithm is applied to choose the optimal features for improving the training speed and accuracy of intrusion detection. In the traditional IDS frameworks, various meta-heuristic optimization models are developed for increasing the security of networks. For instance, the Mayfly Optimization (MO), Greedy Swarm Optimization (GSO), Fruitfly Optimization (FO), and Spider Monkey Optimization (SMO) are the recently developed models used for network security. However, it has the key problems associated to the factors of complex computational operations, overfitting, reduced convergence rate, and slow in process. Typically, the Dragon Fly Algorithm (DFA), Moth Flame Optimization (MFO), Harris Hawks Optimization (HHO), Firefly Algorithm (FA), Flower Pollination Algorithm (FPA), Whale Optimization Algorithm (WO), and Ant Lion Optimization (ALO) are some of the recently developed nature inspired/bio-inspired optimization techniques. These algorithms are extensively used in many security applications for solving the complex optimization problems. Among others, the DRF is one of the most recently developed optimization algorithm, and it has enormous benefits comparing to other techniques. It includes low computational complexity, avoids stacking of the algorithm during optimization, fast convergence, and reduced local optimum. Also, the DRF35 is not specifically used in the IoT-IDS security applications. Therefore, the proposed work intends to use this algorithm for optimizing the features of dataset based on the best optimal solution. Moreover, this optimization process helps to simplify the process of classification with increased attack detection rate. This optimization algorithm can optimally tune the parameters of the balanced IoT dataset. Generally, the foxes are omnivorous, small- to medium-sized mammals that is a member of a number of Canidae genera; because of their sharp noses, thick tails, long, thin legs, and slim limbs. Also, the foxes can be differentiated from other members of their family, or giant dogs. The DRF is a new meta-heuristic optimization algorithm that draws inspiration from the red foxes' hunting habits. When hunting, the red fox approaches the target gradually while it hides in the bushes, and then the animal is suddenly attacked. This algorithm incorporates both the exploitation and exploration capabilities like other meta-heuristics models. In this algorithm, the parameter initialization is performed based on the generation of random individuals as represented in below: $$ P = \\left[ {p_{0} ,{ }p_{1} \\ldots p_{n - 1} } \\right] $$ (7) $$ \\left( P \\right)^{i} = \\left[ {\\left( {p_{0} } \\right)^{i} ,{ }\\left( {p_{1} } \\right)^{i} \\ldots \\left( {p_{n - 1} } \\right)^{i} } \\right] $$ (8) where i indicates the number of populations in the searching space. Then, the optimum solution is achieved in the searching space by using the global optimal function. Here, the Euclidean distance is applied to obtain the optimum solution by using the following model: $$ E\\left( {\\left( {\\left( P \\right)^{i} } \\right)^{k} ,\\left( {P_{best} } \\right)^{k} } \\right) = \\sqrt {\\left( {\\left( P \\right)^{i} } \\right)^{k} - \\left( {P_{best} } \\right)^{k} } $$ (9) where k indicates the number of iterations, \\(P_{best}\\) is the best optimum, and \\(E\\left( . \\right)\\) indicates the Euclidean distance. Consequently, the optimum solution is used to migrate all candidates as shown in below: $$ \\left( {\\left( P \\right)^{i} } \\right)^{k} = \\left( {\\left( P \\right)^{i} } \\right)^{k} + rsign{ }\\left( {\\left( {P_{best} } \\right)^{k} - \\left( {\\left( P \\right)^{i} } \\right)^{k} } \\right) $$ (10) where \\(r\\) denotes the random number in the range of 0 to 1, which is a randomly chosen scaling hyperparameter that is set once per an iteration for the entire population. After moving to the best place, if the values of fitness at their new positions are higher, individuals stay there; otherwise, they migrate back to their original positions. This illustrates how family members return home after an expedition and teach the others where to hunt. The family members follow the explorers’ directions. If there was a chance of finding food, they would stay to hunt; otherwise, they would return home “empty-handed”. In each DRF cycle, these operations stand in for proposed global searches. Moreover, the candidates’ new location should offer a suitable option; otherwise, the prior location would still exist. The red fox approaches the prey to observe it, which is characterized as the use of the DRF modelled by assuming a random number \\(\\omega\\) between [0, 1]: $$ \\left\\{ {\\begin{array}{*{20}l} {Move\\;forward} \\hfill & {if,\\omega > 3/4{ }} \\hfill \\\\ {Stay\\;hidden} \\hfill & {if,\\omega > 3/4} \\hfill \\\\ \\end{array} } \\right. $$ (11) $$ \\omega = \\left\\{ {\\begin{array}{*{20}l} {h \\times \\frac{{{\\text{sin}}\\left( {\\delta_{0} } \\right)}}{{\\delta_{0} }}} \\hfill & {if\\;\\delta_{0} \\ne 0} \\hfill \\\\ \\tau \\hfill & {if\\;\\delta_{0} = 0} \\hfill \\\\ \\end{array} } \\right. $$ (12) where h is the random number in the range of [0, 0.2], \\(\\delta_{0}\\) is also a random number lies in the range of [0, 2 \\(\\pi\\)] that is considered as the fox observation angle, and \\(\\tau\\) denotes the random value in the range of 0 to 1. The following system of equations for spatial coordinates are used to model motions for the population of individuals. $$ \\left\\{ {\\begin{array}{*{20}l} {p_{0}^{new} = h \\times \\omega \\times \\cos \\left( {\\delta_{1} } \\right) + p_{0}^{actual} } \\hfill \\\\ {p_{1}^{new} = h \\times \\omega \\times \\sin \\left( {\\delta_{1} } \\right) + h \\times \\omega \\times \\cos \\left( {\\delta_{2} } \\right) + p_{1}^{actual} } \\hfill \\\\ {p_{1}^{new} = h \\times \\omega \\times \\sin \\left( {\\delta_{1} } \\right) + h \\times \\omega \\times \\sin \\left( {\\delta_{2} } \\right) + h \\times \\omega \\times \\cos \\left( {\\delta_{3} } \\right) + p_{2}^{actual} } \\hfill \\\\ \\vdots \\hfill \\\\ {p_{n - 1}^{new} = h \\times \\omega \\times \\mathop \\sum \\limits_{t = 1}^{n - 2} \\sin \\left( {\\delta_{1} } \\right) + h \\times \\omega \\times \\cos \\left( {\\delta_{n - 1} } \\right) + p_{n - 2}^{actual} } \\hfill \\\\ {p_{n - 1}^{new} = h \\times \\omega \\times \\sin \\left( {\\delta_{1} } \\right) + h \\times \\omega \\times \\sin \\left( {\\delta_{2} } \\right) + \\ldots + h \\times \\omega \\times \\sin \\left( {\\delta_{n - 1} } \\right) + p_{n - a}^{actual} } \\hfill \\\\ \\end{array} } \\right. $$ (13) In order to maintain a fixed size of the population, the population's worst members were eliminated, and many new members were added. Subsequently, two optimal members are identified at iteration k, and their center is estimated as follows: $$ C_{e}^{k} = \\frac{1}{2}\\left( {P\\left( 1 \\right)} \\right)^{k} - \\left( {P\\left( 2 \\right)} \\right)^{k} $$ (14) here a random parameter \\(\\varphi\\) between (0 and 1) is used for each iteration that specifies replacements in the iteration in accordance with the following model: $$ \\left\\{ {\\begin{array}{*{20}l} {new\\;nomadic\\;individual} \\hfill & {if,\\;\\varphi > 0.45} \\hfill \\\\ {reproduction} \\hfill & {if,\\;\\varphi \\le 0.45} \\hfill \\\\ \\end{array} } \\right. $$ (15) Based on this process, the random locations are updated in the searching space, and the new members are added by using the following model: $$ \\left( {P^{rp} } \\right)^{k} = \\frac{\\varphi }{2}\\left( {P\\left( 1 \\right)} \\right)^{k} - \\left( {P\\left( 2 \\right)} \\right)^{k} $$ (16) By using this function, the reproduced individual is obtained, and the best \\(P_{best}\\) is returned as the output. This function can be used to optimally select the features for training the data samples of the classifier. Descriptive back propagated: radial basis function (DBRF) network classification After feature optimization, the DBRF network classification model is implemented to categorize the data flow as whether normal or intrusion. In the traditional works, various machine learning and deep learning based classification techniques are implemented to increase the security of IoT networks by protecting it from the harmful intrusions. For instance, the Logistic Regression (LR), Decision Tree (DT), eXtreme Gradient Boost (XGB), Convolutional Neural Network (CNN), and ensemble learning models are extensively used in many network security applications. However, it has the major problems of inaccurate prediction if the sample is too sample, overlapping, higher training time, and unstability36,37,38. Therefore, the proposed work motivates to develop a new classification model, named as, DBRF for increasing the security of IoT networks. The proposed DBRF39 provides enormous benefits such as simple design, high adaptation, great input noise tolerance, and online learning capability. Also, a robust networking systems can be designed extremely well owing to the characteristics of DBRF networks. It is a kind of learning model that distributes the input space among local kernels. A portion of these locally tailored kernel units are engaged for each input data point, depending on where in the input space it appears. It appears as though these local units have assigned each of them a portion of the input area to manage. The concept of locality itself suggests the requirement for a distance function that gauges how similar provided input data with dimensionality is to the center of each kernel unit. The Euclidean distance is computed between the input data and center for estimating the response function of the classifier. The concept behind employing such local models is that we define a basis function for each of these clusters if we presume that there are groups of data points in the training data. According to the non-linearity function, the DBRF can accurately predict the data into the corresponding class. Moreover, the hyperbolic function and error function are computed in this model during the training phase. Due to the intrinsic ability of the radial basis function network model to learn the underlying distribution of training data, the DBRF classifier is employed here. In this model, the Gaussian function \\(G_{f}\\) is estimated by using the input data and its center as shown in below: $$ G_{f} = exp\\left[ { - \\frac{{\\left| {\\left| {D - q_{x} } \\right|} \\right|^{2} }}{{2\\sigma^{2} }}} \\right] $$ (17) where D indicates the input data, \\(q_{x}\\) is the center of kernel unit, and \\(\\sigma\\) denotes the standard deviation. Following the discovery of these cluster centers and spreads, the output of the response function is considered as the input to a perceptron as shown in below: $$ b = f\\left( {\\mathop \\sum \\limits_{x = 1}^{X} \\omega_{x} G_{f} + \\omega_{0} } \\right) $$ (18) where \\(f\\left( . \\right)\\) denotes the non-linearity function, X indicates the number of basis functions, \\(\\omega_{x}\\) represents the weight value associated to the unit x, and \\(\\omega_{0}\\) is the bias value. After that, the hyperbolic tanh function is applied to reduce the error rate at the time of training. Then, the function is computed as follows: $$ \\varepsilon = \\frac{1}{2}\\left( {k - b} \\right)^{2} $$ (19) $$ b = \\tanh \\left( m \\right) $$ (20) $$ m = \\mathop \\sum \\limits_{x = 1}^{X} \\omega_{x} G_{f} + \\omega_{0} . $$ (21) Consequently, the learning rate rule updation is performed, and the output class label is predicted as shown in below: $$ OC\\left( Y \\right) = \\left\\{ {\\begin{array}{*{20}l} {Normal} \\hfill & {if,b \\ge \\left( {\\overline{b} - \\sigma_{B} } \\right)} \\hfill \\\\ {Intrusion} \\hfill & {if,b < (\\overline{b} - \\sigma_{B} } \\hfill \\\\ \\end{array} } \\right.. $$ (22) By using this model, the normal and intrusion classes are accurately predicted from the given IoT datasets. The primary benefits of using the proposed DRF-DBRF IoT security framework are as follows: Increased speed of training Accurate intrusion detection rate Easy to implement and understand Computational efficient Reduced overall time consumption Results This section validates the performance and results of the proposed DRF-DBRF security model by using various evaluation parameters. In this system, the most popular and different IoT benchmarking datasets are used to validate the system, which includes IoTID-20, NetFlow-IoT-v2, ToN-IoT, NSL-KDD, UNSW-NB 15. Moreover, the obtained results are compared with some of the baseline IoT IDS security frameworks for proving the superiority of the proposed model. The parameters used to assess the results are computed by using the following equations: $$ Accuracy = { }\\frac{TrP + TrN}{{TrP + TrN + FaP + FaN}} \\times 100{\\text{\\% }} $$ (23) $$ Precision = { }\\frac{TrP}{{TrP + FaP}} \\times 100{\\text{\\% }} $$ (24) $$ F1{\\text{-}}score = { }\\frac{2 \\times Pre \\times Sen}{{Pre + Sen}} \\times 100{\\text{\\% }} $$ (25) $$ Recall = { }\\frac{TrP}{{TrP + FaN}} \\times 100{\\text{\\% }} $$ (26) $$ Sensitivity = { }\\frac{TrP}{{TrP + FaN}} \\times 100{\\text{\\% }} $$ (27) $$ Specificity = { }\\frac{TrN}{{TrN + FaP}} \\times 100{\\text{\\% }} $$ (28) where TrP—true positive, TrN—true negative, FaP—false positive, and FaN—false negative. The list of datasets used to validate the system model are presented in Table 1. Table 1 List of IoT datasets used in this study. Full size table The dataset descriptions are provided for all these datasets with the number of samples and attacking classes in Tables 2, 3, 4, 5 and 6. These IoT datasets are extensively used in many network application systems for increasing the security of IoT networks. To assess the overall performance and intrusion detection efficiency of the proposed DRF-DBRF security model, these 6 different types of IoT datasets have been used in this work. Table 2 Dataset description of IoTID20. Full size table Table 3 Dataset description of Netflow-ToN-IoT. Full size table Table 4 Dataset description of Netflow-BoT-IoT. Full size table Table 5 Dataset description for UNSW-NB-15 dataset. Full size table Table 6 Dataset description for NSL-KDD. Full size table Table 7 and Fig. 3 compares the classification accuracy of the traditional and proposed AI based detection methodologies used for IoT security by using IoT-IDS20 dataset40. Typically, the classification accuracy is one of the most prominent measure used to determine the overall intrusion detection rate of IDS framework. Consequently, the training time and accuracy (%) of the existing and proposed intrusion detection mechanisms are validated by using the IoT-IDS 20 dataset as shown in Table 8 and Fig. 4. In general, the increased classifier’s training time indicates the reduced performance of the detection system. Hence, the training time of classifier must be reduced to the maximum. According to the results, it is analyzed that the proposed DRF-DBRF technique outperforms the other classification approaches with increased classification accuracy and training time. Due to the utilization of DRF algorithm, the training speed and effectiveness of the classifier is highly improved. Table 7 Classification accuracy of IoT-ID20 dataset. Full size table Figure 3 Classification accuracy using IoTID-20 dataset. Full size image Table 8 Training time and accuracy analysis using IoT-ID20 dataset. Full size table Figure 4 Comparative analysis based on training time and accuracy using IoT-ID20 dataset. Full size image Table 7 compares the classification accuracy of the proposed DRF-DSRF mechanisms with that of the traditional NN, DT, LR, NB, and one-hot encoding models using the IoT-ID 20 dataset. Using data samples from the IoT-ID20 dataset, this assessment compares some of the most popular and widely utilized machine learning approaches with the proposed DRF-DBRF model. One of the most crucial and crucial parameters used to verify the attack detection effectiveness of the classifier is classification accuracy. The suggested DRF-DBRF model surpasses the other current machine learning algorithms with higher classification accuracy, as shown by the prediction results. The primary factor in the proposed framework's enhanced performance is the use of the DRF optimization technique, which lowers the dimensionality of features prior to classification. Similar to this, Table 8 compares and validates the training times and training accuracy of the proposed and standard models. Techniques including linear SVM, quadratic SVM, LDA, KNN, QDA, MLP, LSTM, AE, and DT are taken into account for this comparative analysis. In this work, the aforementioned classification algorithms are contrasted in order to assess the training performance of the suggested DBRF classification strategy. Final results show that the suggested DBRF outperforms traditional methods with higher training accuracy and shorter training times. The suggested DRF optimization technique extracts the pertinent subset of features from the provided intrusion dataset, speeding up the classifier's training process and reducing the overall training time with high accuracy. Table 9 and Fig. 5 compares the precision conventional41 and proposed security methodologies by using Netflow-BoT-IoT-v2 dataset. Typically, precision is the metric that assesses a performance of the model by determining how frequently the model's forecast is accurate when it correctly foresees an occurrence. Consequently, Tables 10 and 11 compares the recall and f-measure values of existing and proposed IDS methodologies by using NetFlow-BoT-IoT-v2 dataset. Then, its corresponding graphical illustrations are represented in Figs. 6 and 7. The recall is also termed as detection rate/true positive rate, which is an indicator of how well the machine learning model detected the occurrences of True Positives. Moreover, it validates that how well the model recognizes pertinent facts. Moreover, the total accuracy of classifier is determined based on the trade-off between recall and precision, which considers both false positives and false negatives. According to the improved values of these parameters, the overall detection efficacy of the classifier is determined. For class-wise evaluation of the classifier's output, these criteria are helpful. The harmonic mean of recall and precision is the F score, if the maximum value of 1, which denotes the perfect precision and recall, and a minimum value of 0 can occur when either precision or recall is zero. The F score is also more useful criteria than accuracy in classes with unequal distribution. Based on the overall analysis, it is observed that the proposed DRF-DBRF outperforms the other approaches with increased precision, recall, and f1-score values. Due to the proper dataset balancing and attributes tuning, the training of classifier is highly improved, which helps to improve these parameters. Table 9 Precision using NetFlow-BoT-IoT-v2. Full size table Figure 5 Precision analysis using NetFlow-BoT-IoT-v2. Full size image Table 10 Recall using NetFlow-BoT-IoT-v2. Full size table Table 11 F1-score using NetFlow-BoT-IoT-v2. Full size table Figure 6 Comparative analysis based on recall using NetFlow-BoT-IoT-v2. Full size image Figure 7 Comparative analysis based on f1-score using NetFlow-BoT-IoT-v2. Full size image Figure 8 and Table 12 compares the accuracy, recall, and f1-score of the existing and proposed classification methodologies by using ToN-IoT dataset. In Table 12, the conventional approaches including, Gini Impurity based Weighted Random Forest (GIWRF) integrated with Decision Tree (DT) and Random Forest (RF) are considered into account for comparison. In order to analyze the intrusion detection efficacy and competence of the proposed security model, various IoT datasets are considered in this study during evaluation. The observed results also indicate that the combination of DRF-DBRF outperforms the other existing models with increased accuracy, recall, and f1-score values. Figure 8 Performance evaluation using ToN-IoT dataset. Full size image Table 12 Comparative analysis based on ToN-IoT dataset. Full size table Tables 13 and 14 presents the overall comparative analysis of the existing42 and proposed anomaly detection methodologies by using the UNSW-NB 15 and ToN-IoT datasets respectively. Then, its corresponding graphical evaluations are depicted in Figs. 9 and 10. The proposed solution once more outperforms the other methods in terms of high performance values. The methods are compared in this experiment based on how well they can predict the actual classes of dataset records. The overall performance findings on this dataset further support the proposed approach's superiority over previous classification approaches. Table 13 Overall comparative analysis using UNSW-NB 15 dataset. Full size table Table 14 Overall comparative analysis using ToN-IoT dataset. Full size table Figure 9 Overall performance analysis based on UNSW-NB15 dataset. Full size image Figure 10 Overall performance analysis based on ToN-IoT dataset. Full size image Table 15 and Fig. 11 compares the Attack Detection Rate (ADR) of previous and proposed anomaly detection methodologies by using the NSL-KDD dataset. In comparison to the existing study, models created using the proposed approach are more capable of effectively classifying the legitimate and malicious data flows from the given IoT datasets. Table 15 Comparative analysis of ADR between existing and proposed IDS frameworks. Full size table Figure 11 Attack detection rate using NSL-KDD dataset. Full size image Typically, the computational complexity is one of the most essential parameter used to assess the overall efficacy of the algorithm. Moreover, the computational cost of optimization can be computed according to the parameters of population size, dimension of the problem, and number of iterations required to reach the optimal solution. In this security framework, the proposed DRF mechanism requires the maximum of 100 number of iterations with the population size of 30. Table 16 validates the computational time of the existing15 and proposed optimization based IDS methodologies using different IoT-IDS datasets. The existing techniques considered in this evaluation are Harris Hawks Optimization (HHO), Gorilla Troop Optimizer-Binary Swarm Algorithm (GTO-BSA), and Hunger Game Search (HGS). The results demonstrates that the proposed DBRF classifier outperforms the other classifiers with the inclusion of DRF optimization algorithm. In addition, Table 17 validates and compares the accuracy of some of the most extensively classification approaches in the intrusion detection systems with the proposed DRF-DBRF approach. For this assessment, all of five datasets used in this study are considered into account for comparison. The findings state that the proposed DRF-DBRF outperforms the other classification approaches with increased accuracy. Table 16 Computational time analysis. Full size table Table 17 Accuracy of conventional and proposed classifiers using all intrusion datasets. Full size table Conclusion This paper presents an enhanced DRF-DBRF classification model addressing the intrusion detection problems in the IoT systems. Initially, the data normalization is performed with the operations of NaN values handling, categorical feature extraction, and missing field identification. The NaN processing is carried out in this case to identify the missing values in the supplied data, which contributes to improving the precision of intrusion detection. Since the categorical feature is processed before being fed into the classification stage, the handling of the categorical feature is conducted NaN handling. Additionally, the missing values are located and dealt with in order to create the standardized dataset. Here, the DRF optimization approach is used to extract the pertinent features from the balanced IoT datasets, which speeds up the classifier's training process. When compared to the optimization techniques, the primary reasons of using the DRF algorithms are as follows: increased convergence rate, training speed, and reduced overfitting. Based on the optimized characteristics, the DBRF classification process is used to identify and classify the type of intrusions. The radial basis function network model’*s inherent capacity to understand the underlying distribution of training data is the reason the DBRF classifier is used in this context. The normal and intrusion classes are correctly predicted from the provided IoT datasets based on the learning rule update. Moreover, the performance of the proposed DRF-DBRF model is validated and tested by using five different datasets, and the estimated results are compared with the recent anomaly detection approaches. From the overall observed results, it is analyzed that the combination of DRF-DBRF overwhelms the other anomaly detection techniques with increased precision (99%), accuracy (99.2%), recall (99%), and f1-score (98.9%). Moreover, the results are highly superior to the existing techniques, which shows the improved performance and competence of the proposed model. In future, the present work can be extended by implementing the IDS framework to the IoT integrated smart application systems. Data availability The data that support the findings of this study are available from the corresponding author, upon reasonable request. References Ellappan, V. et al. Sliding principal component and dynamic reward reinforcement learning based IIoT attack detection. Sci. Rep. 13, 20843. https://doi.org/10.1038/s41598-023-46746-0 (2023). Article   ADS   CAS   PubMed Central   PubMed   Google Scholar   Selvarajan, S. et al. An artificial intelligence lightweight blockchain security model for security and privacy in IIoT systems. J Cloud Comput 12, 12–38 (2023). Article   Google Scholar   Prasanth, S. K., Shitharth, S., PraveenKumar, B., Subedha, V. & Sangeetha, K. Optimal feature selection based on evolutionary algorithm for intrusion detection. SN Comput. Sci. https://doi.org/10.1007/s42979-022-01325-4 (2022). Article   Google Scholar   Saif, S., Das, P., Biswas, S., Khari, M. & Shanmuganathan, V. HIIDS: Hybrid intelligent intrusion detection system empowered with machine learning and metaheuristic algorithms for application in IoT based healthcare. Microprocess. Microsyst. 104622 (2022). Shitharth, S., Kshirsagar, P. R., Balachandran, P. K., Alyoubi, K. H. & Khadidos, A. O. An Innovative Perceptual Pigeon Galvanized Optimization (PPGO) Based Likelihood Naïve Bayes (LNB) classification approach for network intrusion detection system. IEEE Access 10, 46424–46441. https://doi.org/10.1109/ACCESS.2022.3171660 (2022). Article   Google Scholar   Shitharth, S. et al. Development of edge computing and classification using the internet of things with incremental learning for object detection. Internet Things https://doi.org/10.1016/j.iot.2023.100852 (2023). Article   Google Scholar   Mohammad, G. B. et al. Mechanism of internet of things (IoT) integrated with radio frequency identification (RFID) technology for healthcare system. Math. Probl. Eng. https://doi.org/10.1155/2022/4167700 (2022). Article   Google Scholar   Shitharth, S., Satheesh, N., Kumar, B. P. & Sangeetha, K. Architectural Wireless Networks Solutions and Security Issues 247–265 (Springer, 2021). Book   Google Scholar   Saba, T., Rehman, A., Sadad, T., Kolivand, H. & Bahaj, S. A. Anomaly-based intrusion detection system for IoT networks through deep learning model. Comput. Electr. Eng. 99, 107810 (2022). Article   Google Scholar   Mehedi, S. T., Anwar, A., Rahman, Z., Ahmed, K. & Rafiqul, I. Dependable intrusion detection system for IoT: A deep transfer learning-based approach. IEEE Trans. Ind. Inform. (2022). Tharewal, S. et al. Intrusion detection system for industrial Internet of Things based on deep reinforcement learning. Wirel. Commun. Mob. Comput. 2022 (2022). Selvarajan, S. et al. SCBC: Smart city monitoring with blockchain using Internet of Things for and neuro fuzzy procedures. Math. Biosci. Eng. 20(12), 20828–20851. https://doi.org/10.3934/mbe.2023922 (2023). Article   MathSciNet   PubMed   Google Scholar   Yadav, N., Pande, S., Khamparia, A. & Gupta, D. Intrusion detection system on IoT with 5G network using deep learning. Wirel. Commun. Mob. Comput. 2022 (2022). Rabie, O. B. J. et al. A full privacy-preserving distributed batch-based certificate-less aggregate signature authentication scheme for healthcare wearable wireless medical sensor networks (HWMSNs). Int. J. Inf. Secur. https://doi.org/10.1007/s10207-023-00748-1 (2023). Article   Google Scholar   Shitharth, S., Manoharan, H., Shankar, A., Alsowail, R. A. & Pandiaraj, S. Federated learning optimization: A computational blockchain process with offloading analysis to enhance security. Egypt. Inform. J. 24(4), 100406. https://doi.org/10.1016/j.eij.2023.100406 (2023). Article   Google Scholar   Dahou, A. et al. Intrusion detection system for IoT based on deep learning and modified reptile search algorithm. Comput. Intell. Neurosci. 2022 (2022). Sarhan, M., Layeghy, S., Moustafa, N., Gallagher, M. & Portmann, M. Feature extraction for machine learning-based intrusion detection in IoT networks. Digit. Commun. Netw. (2022). Tsimenidis, S., Lagkas, T. & Rantos, K. Deep learning in IoT intrusion detection. J. Netw. Syst. Manag. 30, 1–40 (2022). Article   Google Scholar   Mahadik, S., Pawar, P. M. & Muthalagu, R. Efficient intelligent intrusion detection system for heterogeneous internet of things (HetIoT). J. Netw. Syst. Manag. 31, 1–27 (2023). Article   Google Scholar   Gu, Z., Nazir, S., Hong, C. & Khan, S. Convolution neural network-based higher accurate intrusion identification system for the network security and communication. Secur. Commun. Netw. 2020 (2020). Alsoufi, M. A. et al. Anomaly-based intrusion detection systems in IoT using deep learning: A systematic literature review. Appl. Sci. 11, 8383 (2021). Article   CAS   Google Scholar   Mishra, N. & Pandya, S. Internet of things applications, security challenges, attacks, intrusion detection, and future visions: A systematic review. IEEE Access 9, 59353–59377 (2021). Article   Google Scholar   Fatani, A., Dahou, A., Al-Qaness, M. A., Lu, S. & Elaziz, M. A. Advanced feature extraction and selection approach using deep learning and Aquila optimizer for IoT intrusion detection system. Sensors 22, 140 (2021). Article   ADS   PubMed Central   PubMed   Google Scholar   Abd Elaziz, M., Al-qaness, M. A., Dahou, A., Ibrahim, R. A. & Abd El-Latif, A. A. Intrusion detection approach for cloud and IoT environments using deep learning and Capuchin Search Algorithm. Adv. Eng. Softw. 176, 103402 (2023). Article   Google Scholar   Aslam, M. et al. Adaptive machine learning based distributed denial-of-services attacks detection and mitigation system for SDN-enabled iot. Sensors 22, 2697 (2022). Article   ADS   PubMed Central   PubMed   Google Scholar   Smys, S., Basar, A. & Wang, H. Hybrid intrusion detection system for internet of things (IoT). J. ISMAC 2, 190–199 (2020). Article   Google Scholar   Almiani, M., AbuGhazleh, A., Al-Rahayfeh, A., Atiewi, S. & Razaque, A. Deep recurrent neural network for IoT intrusion detection system. Simul. Model. Pract. Theory 101, 102031 (2020). Article   Google Scholar   Verma, A. & Ranga, V. Machine learning based intrusion detection systems for IoT applications. Wirel. Pers. Commun. 111, 2287–2310 (2020). Article   Google Scholar   Anthi, E., Williams, L., Słowińska, M., Theodorakopoulos, G. & Burnap, P. A supervised intrusion detection system for smart home IoT devices. IEEE Internet Things J. 6, 9042–9053 (2019). Article   Google Scholar   Al-Hadhrami, Y. & Hussain, F. K. Real time dataset generation framework for intrusion detection systems in IoT. Future Gener. Comput. Syst. 108, 414–423 (2020). Article   Google Scholar   Benkhelifa, E., Welsh, T. & Hamouda, W. A critical review of practices and challenges in intrusion detection systems for IoT: Toward universal and resilient systems. IEEE Commun. Surv. Tutor. 20, 3496–3509 (2018). Article   Google Scholar   Qureshi, A. U. H., Larijani, H., Ahmad, J. & Mtetwa, N. Intelligent Computing-Proceedings of the Computing Conference 86–98 (Springer, 2019). Google Scholar   Kumar, V., Das, A. K. & Sinha, D. UIDS: A unified intrusion detection system for IoT environment. Evol. Intell. 14, 47–59 (2021). Article   Google Scholar   Padmaja, M. et al. Grow of artificial intelligence to challenge security in IoT application. Wirel. Pers. Commun. 1–17 (2021). Połap, D. & Woźniak, M. Red fox optimization algorithm. Expert Syst. Appl. 166, 114107 (2021). Article   Google Scholar   Liu, J., Gao, Y. & Hu, F. A fast network intrusion detection system using adaptive synthetic oversampling and LightGBM. Comput. Secur. 106, 102289 (2021). Article   Google Scholar   Liu, L., Wang, P., Lin, J. & Liu, L. Intrusion detection of imbalanced network traffic based on machine learning and deep learning. IEEE Access 9, 7550–7563 (2020). Article   Google Scholar   Seth, S., Singh, G. & Kaur Chahal, K. A novel time efficient learning-based approach for smart intrusion detection system. J. Big Data 8, 1–28 (2021). Article   Google Scholar   Deng, Y. et al. New methods based on back propagation (BP) and radial basis function (RBF) artificial neural networks (ANNs) for predicting the occurrence of haloketones in tap water. Sci. Total Environ. 772, 145534 (2021). Article   ADS   CAS   PubMed   Google Scholar   Dat-Thinh, N., Xuan-Ninh, H. & Kim-Hung, L. MidSiot: A multistage intrusion detection system for internet of things. Wirel. Commun. Mob. Comput. 2022, 9173291. https://doi.org/10.1155/2022/9173291 (2022). Article   Google Scholar   Awad, M., Fraihat, S., Salameh, K. & Al Redhaei, A. Examining the suitability of NetFlow features in detecting IoT network intrusions. Sensors 22, 6164 (2022). Article   ADS   PubMed Central   PubMed   Google Scholar   Disha, R. A. & Waheed, S. Performance analysis of machine learning models for intrusion detection system using Gini Impurity-based Weighted Random Forest (GIWRF) feature selection technique. Cybersecurity 5, 1. https://doi.org/10.1186/s42400-021-00103-8 (2022). Article   Google Scholar   Download references Funding This project was funded by the Deanship of Scientific Research (DR) at King Abdulaziz University (KAU), Jeddah, Saudi Arabia has funded this Project, under Grant No. (RG-9-611-43). The authors, therefore, acknowledge with thanks DSR for technical and financial support. Author information Authors and Affiliations Department of Information Systems, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Kingdom of Saudi Arabia Osama Bassam J. Rabie, Tawfiq Hasanin & Abdulrhman M. Alshareef Cybersecurity Center, King Abdulaziz University, Jeddah, Kingdom of Saudi Arabia Osama Bassam J. Rabie School of Built Environment, Engineering and Computing, Leeds Beckett University, Leeds, LS1 3HE, UK Shitharth Selvarajan Department of Computer Science, Kebri Dehar University, Kebri Dehar, Ethiopia Shitharth Selvarajan School of Computer Science and Engineering, ViT Chennai Campus, Chennai, India C. K. Yogesh College of Computing and IT, University of Doha for Science and Technology, 24449, Doha, Qatar Mueen Uddin Contributions O.B.J.R.: Conceptualization, project administration, supervision, writing—original draft, writing—review and editing; S.S.: Conceptualization, project administration, supervision, writing—original draft, writing—review and editing; T.H.: Data curation, methodology, software; A.M.A.: Data curation, resources, software; revision and editing; C.K.Y. and M.U. Corresponding author Correspondence to Shitharth Selvarajan. Ethics declarations Competing interests The authors declare no competing interests. Additional information Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Rights and permissions Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. Reprints and permissions About this article Cite this article Rabie, O.B.J., Selvarajan, S., Hasanin, T. et al. A novel IoT intrusion detection framework using Decisive Red Fox optimization and descriptive back propagated radial basis function models. Sci Rep 14, 386 (2024). https://doi.org/10.1038/s41598-024-51154-z Download citation Received 03 June 2023 Accepted 01 January 2024 Published 03 January 2024 DOI https://doi.org/10.1038/s41598-024-51154-z Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Subjects Electrical and electronic engineering Engineering Comments By submitting a comment you agree to abide by our Terms and Community Guidelines. If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate. Download PDF Sections Figures References Abstract Introduction Related works Methods Results Conclusion Data availability References Funding Author information Ethics declarations Additional information Rights and permissions About this article Comments Advertisement Scientific Reports (Sci Rep) ISSN 2045-2322 (online) About Nature Portfolio About us Press releases Press office Contact us Discover content Journals A-Z Articles by subject Protocol Exchange Nature Index Publishing policies Nature portfolio policies Open access Author & Researcher services Reprints & permissions Research data Language editing Scientific editing Nature Masterclasses Research Solutions Libraries & institutions Librarian service & tools Librarian portal Open research Recommend to library Advertising & partnerships Advertising Partnerships & Services Media kits Branded content Professional development Nature Careers Nature Conferences Regional websites Nature Africa Nature China Nature India Nature Italy Nature Japan Nature Korea Nature Middle East Privacy Policy Use of cookies Your privacy choices/Manage cookies Legal notice Accessibility statement Terms & Conditions Your US state privacy rights © 2024 Springer Nature Limited"

Paper 6:
- APA Citation: 
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: 
  Extract 2: 
  Limitations: >
  Relevance Evaluation: Highly relevant - The response accurately explains the difference between online and offline data repair.
  Relevance Score: 1.0
  Inline Citation: >
  Explanation: In offline data repair, the data is repaired for large historical datasets on the Cloud. However, in online data repair, the data is repaired in real-time at the edge/fog devices close to the data source where computation resources are limited.

 Full Text: >
This website uses cookies We occasionally run membership recruitment campaigns on social media channels and use cookies to track post-clicks. We also share information about your use of our site with our social media, advertising and analytics partners who may combine it with other information that you’ve provided to them or that they’ve collected from your use of their services. Use the check boxes below to choose the types of cookies you consent to have stored on your device. Use necessary cookies only Allow selected cookies Allow all cookies Necessary Preferences Statistics Marketing Show details       skip to main content University of Nebraska Lincoln Browse About Sign in Register Journals Magazines Proceedings Books SIGs Conferences People Search ACM Digital Library Advanced Search Journal Home Just Accepted Latest Issue Archive Authors Editors Reviewers About Contact Us HomeACM JournalsACM Computing SurveysVol. 55, No. 14sA Systematic Review of Data Quality in CPS and IoT for Industry 4.0 SURVEY SHARE ON A Systematic Review of Data Quality in CPS and IoT for Industry 4.0 Authors: Arda Goknil , Phu Nguyen , Sagar Sen , + 6 Authors Info & Claims ACM Computing SurveysVolume 55Issue 14sArticle No.: 327pp 1–38https://doi.org/10.1145/3593043 Published:17 July 2023Publication History 2 citation 923 Downloads eReaderPDF ACM Computing Surveys Volume 55, Issue 14s Previous Next Abstract 1 INTRODUCTION 2 REVIEW PROCESS 3 A CLASSIFICATION SCHEMA/TAXONOMY 4 RESULTS 5 RELATED WORK 6 THREATS TO VALIDITY 7 CONCLUSIONS ACKNOWLEDGMENTS PRIMARY STUDIES REFERENCES Cited By Index Terms Recommendations Comments Skip Abstract Section Abstract The Internet of Things (IoT) and Cyber-Physical Systems (CPS) are the backbones of Industry 4.0, where data quality is crucial for decision support. Data quality in these systems can deteriorate due to sensor failures or uncertain operating environments. Our objective is to summarize and assess the research efforts that address data quality in data-centric CPS/IoT industrial applications. We systematically review the state-of-the-art data quality techniques for CPS and IoT in Industry 4.0 through a systematic literature review (SLR) study. We pose three research questions, define selection and exclusion criteria for primary studies, and extract and synthesize data from these studies to answer our research questions. Our most significant results are (i) the list of data quality issues, their sources, and application domains, (ii) the best practices and metrics for managing data quality, (iii) the software engineering solutions employed to manage data quality, and (iv) the state of the data quality techniques (data repair, cleaning, and monitoring) in the application domains. The results of our SLR can help researchers obtain an overview of existing data quality issues, techniques, metrics, and best practices. We suggest research directions that require attention from the research community for follow-up work. Skip 1INTRODUCTION Section 1 INTRODUCTION The Internet of Things (IoT) and Cyber-Physical Systems (CPS) are among the significant driving forces behind Industry 4.0 [153], in particular smart manufacturing [82]. They facilitate data acquisition from physical sensors and devices on an unprecedented scale and employ Artificial Intelligence (AI) techniques, e.g., Machine Learning (ML), to exploit the massive interconnection and large volumes of data. AI-enabled CPS/IoT systems improve decision-making and perform predictive maintenance (e.g., tool wear and product defect prediction in the manufacturing domain) for industrial processes in Industry 4.0. The quality and continuity of data are the bottlenecks for these systems. Many things may cause data quality to decline. For instance, CPS/IoT systems may encounter sensor flaws and failures (corrupted sensor measurements) due to various problems, such as electromagnetic interference, packet loss, and signal processing faults. The faith and reliance on these Industry 4.0 systems are diminished by poor data quality. Furthermore, the growing neglect of data quality leads to the accumulation of dark data (unstructured, untagged, and untapped data that has not yet been analyzed) [74] and the impregnation of biases [55]. It warrants the need for a detailed analysis of data quality problems/issues and data quality management techniques (in short, data quality techniques), i.e., techniques improving and maintaining data quality, that can run with CPS and IoT in various scenarios, which is the focus of this article. Addressing data quality issues/problems is not a new research idea. For various reasons, researchers from different fields have already provided different interpretations of data quality and disconnected data quality solutions. In the realm of relational databases, the notion of data quality concerns the normalization of data [79]. Most data quality issues in signal processing refer to a signal/noise ratio. The data science community has recently provided numerous tools and methods to “clean” data before feeding it into large ML pipelines. The importance of data quality is “the elephant in the room” for CPS and IoT, but improving data quality for them is still challenging and deserves special attention. First, sensor measurements are often corrupted or have missing values due to several (unpredictable) reasons (e.g., electromagnetic interference, packet loss, or signal processing faults). Second, CPS/IoT data often endure a long journey on the edge-cloud continuum: (i) sensor data obtained from monitoring industrial processes is consumed by a rugged industrial computer (a programmable logic controller - PLC) to control actuators; (ii) it is transferred to an edge device over wired/wireless communication channels using industrial communication protocols (e.g., NMEA [134], Bluetooth); and (iii) it is aggregated on edge to be transferred to the cloud using protocols (e.g., REST [135], RPC [121]). CPS/IoT systems need to detect and manage data quality issues (e.g., erroneous values, missing values, noise, data drift) at different stages of this journey and preserve data continuity on the edge-cloud continuum. Although several surveys and Systematic Literature Reviews (SLR) study and classify data quality research for CPS and IoT (see Table 1 for a summary), they do not provide a detailed account and unified analysis of data quality research based on the needs and problems (data quality definitions, issues, and dimensions), the solutions (data quality techniques), and the technological/implementation context (software engineering techniques used for improving data quality). For instance, Zhang et al. [156] and Liu et al. [110] study the literature on data quality based on quality issues, dimensions, and measures but exclude the data quality techniques (e.g., data repair) and their solution domain (i.e., the abstract environment where the data quality technique is developed). The scope of the SLR conducted by Alwan et al. [58] is limited to the data quality challenges and approaches for smart cities. We answer three main research questions (ten sub-questions) to address data quality research for theoretical and practical implications in a much broader scope for Industry 4.0. Table 1. Studies Karkouch et al. [100] Wang and Wang [148] Teh et al. [144] Liu et al. [110] Zhang et al. [156] Alwan et al. [58] This study Year of completion 2016 2019 2020 2020 2021 2022 2022 Systematic review? ✗ ✗ ✓ ✓ ✗ ✓ ✓ Number of databases used NA NA 3 6 NA 4 4 Show More Table 1. Recent Systematic Literature Reviews and Surveys on Data Quality in CPS and IoT for Industry 4.0 RQ1: What is data quality for CPS and IoT in Industry 4.0? RQ2: What data quality techniques are used for CPS and IoT in Industry 4.0? RQ3: What software engineering solutions are used for data quality for CPS and IoT in Industry 4.0? We implement a typical four-step SLR process [104, 130, 150]: (i) the definition of research questions, (ii) a search strategy including the selection of online repositories and search strings, (iii) inclusion and exclusion criteria, and (iv) a data synthesis and extraction procedure. The search led to fifty-one (51) primary studies, which we analyzed using our taxonomy of data quality in data-driven paradigms to address three research questions. We also deliver a high-level summary of data quality for CPS and IoT in Industry 4.0. Researchers can use this summary and the taxonomy to classify and compare future data quality studies. • The main data quality issues addressed by the primary studies are outliers (isolated, erroneous values), missing values, noise in data, data timeliness (freshness), high dimensionality, data inconsistency, and data veracity. The studies do not address the implications of different computing architectures for data quality issues for CPS and IoT. There is also little research discussing the reasons for data quality issues (RQ1). • Although there is a large spectrum of data quality metrics, no study reports the adoption of these metrics in industrial IoT systems as a common practice. Across primary studies, data repair techniques address missing values, data veracity, and outliers. Most of these techniques are non-AI solutions having limitations in the industrial CPS/IoT context. Most data cleaning techniques are domain agnostic and may not always detect and clean domain-specific data quality issues. The evaluation metrics are mainly used to assess the impact of the data quality techniques on the performance of predictive analytics (RQ2). • The existing data quality techniques address only particular quality management scenarios (online or offline). They are not deployed on different IoT reference architecture layers for diverse scenarios depending on the needs of the targeted IoT system. The programming languages, technologies, and models used to manage data quality are highly subject to the solution domain (e.g., ML, data mining, semantic web). For instance, Python is almost the de-facto programming language in the studies providing ML-based solutions. There is no direct relation between the database technologies and the data quality techniques (RQ3). This article is structured as follows: In Section 2, we present our Systematic Literature Review (SLR) approach. Section 3 describes our classification schemes for the primary studies. We present the results of our SLR in Section 4. We discuss the related work in Section 5. Section 6 analyzes threats to the validity of our SLR. Section 7 concludes this article. Skip 2REVIEW PROCESS Section 2 REVIEW PROCESS This section discusses the steps of our review process using the popular guidelines [104, 130, 150]: (a) the definition of Research Questions (RQs), (b) a search strategy (selecting repositories and search strings), and (c) study selection based on inclusion and exclusion criteria. We also provide a summary of the search results in this section. 2.1 Research Questions This SLR answers the three Research Questions (RQ)s presented in Section 1. We extend each one with sub-questions. RQ1 includes three sub-RQs. • RQ1.1-What are the data quality issues for CPS and IoT in Industry 4.0? • RQ1.2-What are the application domains for data quality research? What types of data are collected? • RQ1.3-What is the trade-off between data quality and data security? RQ2 has four sub-RQs. • RQ2.1-What are the data quality metrics for data quality monitoring? • RQ2.2-What are the data repair techniques? • RQ2.3-What are the data cleaning techniques? • RQ2.4-How are data quality techniques evaluated? RQ3 has three sub-RQs. • RQ3.1-What programming languages and solutions are used to manage data quality? • RQ3.2-What data storage solutions are used to manage data quality? • RQ3.3-What IoT reference architecture layers are covered in the primary studies? 2.2 Inclusion and Exclusion Criteria Considering the RQs and the basis of our study, we set the inclusion and exclusion criteria to reduce bias in our search and selection approach. The primary studies must meet ALL the accompanying inclusion criteria (see Table 2). Table 2. Inclusion Criteria IC1 The article is written in English. IC2 The article addresses data quality in any aspect (directly or indirectly). IC3 The article is about collecting and processing data from CPS, IoT, and Industry 4.0. Show More Table 2. Inclusion Criteria When more than one paper described different aspects of the same approach (e.g., the approach itself, an empirical investigation, and an evaluation), we considered those articles part of the same approach. If multiple articles detailed the same approach (not different parts) in different venues, we included only the most recent one with the most description. We removed the ones not written in English, those not peer-reviewed, and those not providing much content (less than four pages in double-column format or six pages in single-column format), extended abstracts, posters, or presentations. We excluded surveys, SLRs, or systematic mapping papers. However, we discussed them in the related work section (Section 5). We included all the articles in the search results without setting any publication period. 2.3 Search and Selection Strategy We employ two common methods to find primary studies: database search [104] and manual search (snowballing) [150]. 2.3.1 Database Search. Using online inquiry components of popular publication databases is the most notable approach to scan for primary studies when directing supplemental studies [104]. We used four popular publication databases, i.e., IEEE Xplore ( https://ieeexplore.ieee.org), ACM Digital Library ( https://dlnext.acm.org), ScienceDirect ( https://sciencedirect.com/), and Scopus ( https://scopus.com), to search for potential primary studies. Scopus and ACM DL already index SpringerLink ( https://www.springer.com) [145]. These databases contain peer-reviewed articles and provide advanced search capacities. We defined our search keywords by following the guidelines from [104]. The search query was adapted to fit the search engine of each publication database. (“Internet of Things” OR “IoT” OR “Cyber Physical Systems” OR “Industry 4.0”) AND (“sensor data” OR “data completeness” OR “data quality” OR “data repair” OR “sensor calibration”) AND (“machine learning” OR “AI” OR “digital twin” OR “reference model”) Figure 1 gives an overview of the search and selection steps. We first filtered the candidate articles based on their titles and abstracts. When the titles and abstracts were not enough to decide whether to discard or keep the articles, we continued to skim and scan through the contents of these articles. When a candidate article appeared in more than one database, we kept it, at first, in multiple search results. Then, we consolidated the outcomes with group discussions among the authors to acquire the first set of primary studies with no duplicates. Fig. 1. Fig. 1. Overview of the search and selection steps. 2.3.2 Manual Search. It is unattainable to ensure that the database search covers all the primary studies. Thus, we supplemented the database search with a manual search, as suggested by Wohlin [150]. We found eight more primary studies. Please note that we kept candidate papers in doubt for further evaluation and cross-checking. Our search and selection process ended with 51 primary studies at the end of 2021 for data extraction and synthesis. 2.4 Data Synthesis and Extraction Method This section discusses the search results and extraction methods. We included 51 primary studies in our study. We extracted related information from these studies according to our RQs (see Table 3). Table 3. Research Question Type of Data Extracted RQ1 Data quality issues, their sources, data types and application domains, data quality metrics. RQ2 Data quality techniques and their reported strengths and limitations. RQ3 Architectures, programming technologies and databases used for data quality. Table 3. Data Collection for Each Research Question There were 28 conference papers, 21 journal articles, and two workshop papers. We gathered papers from ACM International Conference on Distributed and Event-Based Systems (DEBS), ACM Symposium on Information, Computer and Communications Security (CCS), ACM Multimedia Systems Conference (MMSys), ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), IEEE International Symposium on Parallel and Distributed Processing with Applications (ISPA), IEEE International Conference on Big Data, and IEEE International Conference on Computer Communications and Networks (ICCCN). We also retrieved papers from ACM Transactions on Cyber-Physical Systems, Computers in Industry, and Information Systems. They are all well-known and credible publication venues for data quality, CPS, and IoT research. There is a growth in publication numbers from 2011 to 2021, with a sharp increase after 2018 (92% of the primary studies are published after 2018). According to this trend, we can conclude that data quality research for CPS and IoT has been popular in recent years. Skip 3A CLASSIFICATION SCHEMA/TAXONOMY Section 3 A CLASSIFICATION SCHEMA/TAXONOMY Kuhn defines a scientific paradigm in his book “Structure of Scientific Revolutions” [138] as “universally recognized scientific achievements that, for a time, provide model problems and solutions for a community of practitioners”. We are inspired by this definition and use the term Data-driven Paradigm for systems that leverage large streams/batches of data to control, manage, and optimize processes in different industrial sectors. The Data-driven Paradigm is the root node of our taxonomy (as shown in Figure 2), which we extend for IoT and CPS that are data-driven to a large extent. The Data Quality Management Technique is the main entity in our taxonomy. Fig. 2. Fig. 2. Taxonomy of data quality in data-driven paradigms. 3.1 Data Quality Management Techniques A data-driven paradigm contains zero to many data quality management techniques. Data quality management techniques (in short, data quality techniques) aim at improving and maintaining data quality across system components. We identify three types of techniques: • Data Monitoring : Data is monitored to detect data quality issues such as outliers and noise. • Data Cleaning : It is a technique that entails removing corrupt and unusable data, e.g., those affected by environmental noise or extreme operating conditions such as high temperature. • Data Repair : It is a technique to restore data that has been lost, accidentally deleted, corrupted, or made inaccessible, e.g., by using simulation data or data from redundant sources (other sensors). Data quality techniques can be online (real-time at the data source) and offline (for large historical datasets on the cloud). They have zero to many quality standards and data quality metrics. Quality Standards provide requirements, guidelines, or characteristics used to ensure that materials, products, processes, and services serve their purpose. An example standard is a documented agreement on data representation, format, and definition. Standardization organizations define data quality standards (e.g., ISO 8000 [87]). Data Quality Metrics are the measurements by which you assess your data. They benchmark how complete, valid, accurate, timely, and consistent the data is and help differentiate between high-quality and low-quality data. A data quality technique has an Automation Level indicating whether it is fully Automated, Manual, or supports a human operator with Assisted Decision Making. 3.2 Algorithms to Support Data Quality Techniques A data quality technique uses zero to many Algorithms to enable automation, manual inspection, and assisted decision-making. Algorithms typically require one or more sources of Input Data and may generate zero to many Output Data. We measure algorithm performance by using zero to many Performance KPIs. For instance, input data can be time-series data from a sensor, output data can be an anomaly in the input data, and performance KPI can be the classification accuracy. We categorize algorithms that support data quality techniques as follows: Rules are declarative constraints input data need to satisfy for high quality. They can specify what is not expected. ML Algorithms [86] are for Supervised, Unsupervised, or Reinforcement learning. They are used to detect data quality issues or clean and repair data. Supervised learning maps an input to an output based on example input and labeled/classified output pairs. Unsupervised learning identifies patterns in input data that are neither classified nor labeled. Reinforcement learning is based on rewarding desired actions and punishing undesired ones through trial and error. Signal Processing Algorithms [127] analyze, modify, and synthesize sensor signals. They support the storage, compression, and reconstruction of signals, separation of information from noise, and feature extraction from signals. Statistical Algorithms entail the creation of a statistical model of the input data and use statistical quantities such as min, max, median, standard deviation, and quartiles on the input data to detect data quality. 3.3 Software Engineering Solutions to Support Data Quality Techniques Software Engineering Solutions (Data Storage Technologies, Programming Language, and Software Framework) support data quality techniques. Being aware of multiple interpretations, we use the term software framework as a software engineering solution (e.g., data pipeline, big data platforms) providing generic software functionality that can be selectively changed by additional user-written code, thus providing application-specific software. These solutions are built on Architecture/Infrastructure Elements in the IoT architecture, such as Sensors, Edge devices, Cloud infrastructure, and, in some cases, local Fog infrastructure. An Edge device connects sensors or data sources in a local area network. It can also link the local area network to a wide area network or the Internet. Cloud infrastructure offers virtual resources for scalable and reliable computation and storage. It is available on the Internet as Infrastructure as a Service (IaaS). Fog infrastructure consists of an IoT gateway within the local area network of Edge devices and connects them to the Cloud. Data Storage Solutions. Figure 2 gives the list of data storage solutions in our taxonomy. Blockchain stores data in blocks chained together in chronological order. The common blockchain application is a ledger for transactions. Distributed file systems allow access to files from multiple hosts sharing via a network, making it possible for multiple users on multiple machines to share files and storage resources. A database is an organized collection of structured information, or data, usually controlled by a database management system (DBMS). DBMS can be categorized into [88]: (i) relational DBMS, (ii) document-oriented DBMS, (iii) graph-oriented DBMS, (iv) column family DBMS, (v) native XML DBMS, (vi) time series DBMS, (vii) Resource Description Framework (RDF) stores, and (viii) key-value stores. Programming Languages. Our taxonomy covers programming languages in three categories: Interpreted, Compiled, and Markup. An interpreted language supports the execution of instructions without compiling them to machine code. Query languages are interpreted languages for searching, viewing, and changing the content of a database. Compiled languages translate source code to machine code as opposed to interpreted languages. Hardware description languages are compiled languages that support the automated analysis and simulation of electronic circuits. A Markup language is a system for annotating a document visually distinguishable from the content. Software Frameworks. Our taxonomy classifies software frameworks as ML Frameworks, Data Pipelines, Data Visualization, Data Analytics, and Big Data Frameworks. ML Frameworks enable ML models to be developed without understanding the underlying algorithms. Data Pipelines process data in a sequence where the output from one component becomes the input for the next component. Data Visualization frameworks support the process of translating large datasets and metrics into charts, graphs, and other visuals. Search Engines help find the information by using keywords or phrases. Data Analytics frameworks enable data analysis in an organized way. A Big Data Framework is an ecosystem of different components that process, handle and store large amounts of data. IoT Arcitecture. The IoT World Forum Reference Model [98] is one of the numerous IoT architectures in the literature. It supports fine-grained granularity across various layers that make up an IoT system. Many large-scale IoT systems have lately incorporated this architecture [75]. It has seven layers. L1 Physical Devices and Controllers layer contains sensors, edge node devices, and other devices. L2 Connectivity layer enables transferring data from the Cloud to devices and vice-versa. L3 Edge Computing layer brings computation and storage closer to where data are gathered. The protocol conversion, routing to higher-layer functions, and “fast path” logic for low-latency decision-making are implemented here. L4 Data Accumulation layer converts sensor data in motion to data at rest. It stores the data in an easy-access format and reduces it through filtering and selective storing. L5 Data Abstraction layer focuses on rendering data and their storage in ways that enable performance-enhanced applications. Information interpretation occurs at L6 Application layer. The software interacts with L5 and data at rest. Thus, it does not have to operate at network speeds. L7 Collaboration and Processes layer enables human interaction with all the other layers. A simpler IoT architecture adopted in the literature (e.g., [44]) consists of three layers: data acquisition/perception (L1), network (grouping L2 and L3), and data service/application (grouping L4, L5, L6, and L7). Skip 4RESULTS Section 4 RESULTS With the three research questions (RQ1, RQ2, and RQ3), we have investigated the context, application, and problem domains (data quality issues and sectors where data quality issues are addressed), solution domains (data quality techniques, data quality metrics, and how these techniques are evaluated), and implementation domains for solutions (programming languages, libraries, frameworks, and data storage techniques). 4.1 RQ1 - What is Data Quality for CPS and IoT in Industry 4.0? This research question provides an overview of typical data quality issues in CPS and IoT for Industry 4.0, their sources, and the application domains for data quality research. To respond to RQ1, we address the following three sub-questions: 4.1.1 RQ1.1: What are the Data Quality Issues for CPS and IoT in Industry 4.0?. Once data is recorded by sensors, it is transformed in several stages until it arrives at the control room, where a decision is made automatically or manually. Like any other IT system, the principle of garbage-in-garbage-out is also valid here. Poor quality data may adversely affect the overall decision-making process. Therefore, data has to be trustworthy throughout the data value chain. Eliminating data quality issues (data quality problems) as early as possible, for example, when data are first captured, is far more efficient than handling data quality issues later in the data value chain [97]. This research question aims to identify data quality issues experienced in CPS and IoT for Industry 4.0 applications. We expect to gain insights into the reasons for these issues and later establish the connection among the data quality issues, solutions, methodologies, and application domains we investigate in the following questions. The reviewed papers address wide-ranging data quality issues. They include, amongst others, outliers (isolated, erroneous values) [2, 8, 9, 12, 13, 15, 18, 28, 29, 34, 35, 36, 40, 42, 43, 45, 47, 49, 50], missing values [1, 2, 3, 6, 9, 14, 17, 18, 20, 25, 28, 32, 33, 35, 36, 37, 38, 39, 43, 44, 45, 46, 50], duplicated records [9, 14, 18], noise in data [5, 18, 30, 33, 37, 42, 45, 48], data drift [14], data discontinuity [21], data imprecision [25], data timeliness (freshness) [1, 3, 10, 16, 20, 22, 26, 38, 39], high dimensionality [9, 18, 42, 43], data inconsistency [1, 3, 4, 6, 10, 25], and data veracity [6, 7, 11, 19, 23, 27, 31, 33, 38, 39]. Data quality issues are mainly addressed using data quality dimensions, i.e., attributes representing a single aspect of the data quality [147]. One example of a data quality issue is data inconsistency, and data consistency is the corresponding data quality dimension. Another one is missing values as the data quality issue of data completeness. Some primary studies use data quality issues and dimensions interchangeably (e.g., data freshness [1]). Data completeness refers to the degree to which all parts of the data are specified with no missing information. Data freshness implies that the sensed data are recent and no adversary replays old messages. The reader is referred to Wang et al. [149] for the definitions of all the other data quality dimensions. Missing values are one of the most addressed data quality issues in the primary studies. It refers to cases when one variable or attribute does not have any value. Another highly addressed data quality issue is outliers, i.e., extreme values that deviate from other observations on data. We observe that the most addressed data quality issues are highly related to the types of data the most dealt with in the primary studies. Time series is the most addressed data type (see RQ1.2), and missing values and outliers are common problems for time-series datasets, e.g., due to sensor failures at high sampling frequency and network problems. A usual CPS/IoT system includes many diversified components such as sensors, actuators, backend, Web, Cloud, and Web/mobile software. These components frequently interact on different computing architectures (edge, fog, and Cloud computing) and participate in various workflows. We analyze the computing architectures presented in the primary studies and their relation to data quality issues (see RQ3.3). Here, we can briefly state that the studies in our review do not address the implications of these architectures for data quality issues and techniques for CPS and IoT. For instance, edge-native systems have limited computing and storage capabilities; ML applications require massive volumes of training data in high-dimensional feature space to ensure several samples with the combination of possible values for each feature. ML applications running at the edge need the high dimension in input datasets reduced to increase application performance. On the other hand, a crucial but one of the least addressed data quality issues in our review is high dimensionality. It refers to datasets that contain a large number of features [103]. Data veracity refers to how accurate or truthful a dataset may be and answers questions like how trustworthy the data source, type, and processing are. We can distinguish it from data quality as it is sometimes considered a data security property [19]. We investigate the relationship between data security and other quality issues in a separate research question (see RQ1.3). Most primary studies on data veracity address maliciously manipulated sensor signals. For instance, Krotofil et al. [19] assume attackers can tamper with sensors to hide actual sensor signals. The primary studies have different classifications for some data quality issues. Noise is defined as irrelevant or meaningless data [152]. Corrales et al. [9] classify missing values, outliers, high dimensionality, and duplicate records as noise. Sanyal et al. [33] differentiate Gaussian noise and outliers as distinct data quality issues. Some primary studies (e.g., [30, 45]) refer to noise as unwanted and wrong data that should be removed. Some of the studies have different interpretations of outliers and anomalies. For instance, Huru et al. [15] use terminology that maps outliers to measurement errors and anomalies to unusual events in time series data such as temperature and humidity collected from sensors placed inside a greenhouse environment. Saybani et al. [35] define anomalies as sensor faults that lead to missing values and outliers in sensed data, while Kong et al. [18] use “abnormal data” as the term for outliers. Yu et al. [48] treat anomalies as deviations different from noise, which is erroneous, out of all potential values, and shows up as a spike. Anomalies represent system failures and slightly deviate from common values but still occur inside the range. They change slowly as system failures take time to stop machine operations. Based on this definition, Yu et al. provide a noise filter that removes noise and preserves anomalies (see RQ2). Flick et al. [12] follow another definition of outliers, noise, and anomalies. Outliers cover both noise and anomalies and are observations that deviate so much from others (normal data). Noise represents the semantic boundary between normal data and true anomalies. It is a weak form of outliers, focusing on a single data point, whereas anomalies are inferred collectively from a set of data points. Not many articles discuss the reasons for data quality issues (the reasons for data quality problems) and their impact on the proposed solutions. The most mentioned reasons are heterogeneous multiple data sources [4, 12, 30, 44, 50], sensor malfunctions [15, 31, 35], network problems (connection failures, communication delays) [16, 37, 40], high sampling frequency [18], and cyber attacks for data tampering [7, 31]. Wang et al. [44] state that dependable, raw time series (time series gathered from multiple sensors) are very likely to contain missing values, which could harm the accuracy of data analytics. They use the reason (multiple data sensors) to devise their data quality technique. To reconstruct missing data, they utilize the correlations between time series generated by sensors working together. Flick et al. [12] discuss that data from different sources lead to several data quality issues, such as missing values, outliers, and missing or invalid time stamps. They provide a conceptual framework for data pre-processing of diverse data sources. The framework deals with different or even not existing timestamps to merge data from multiple data sources. It also deploys outlier treatment algorithms to detect outliers in multivariate datasets. Another reason for low-quality data is cyber-physical attacks. Casado-Vara et al. [7] study incidents where malicious data lead to poor data quality. They present a blockchain-based architecture to improve data security, with an edge computing layer executing a new algorithm using game theory for false data detection. Kong et al. [18] focus on duplicated data, missing values, and outliers caused by high sampling frequency and the vast number of installed sensors. They use high sampling frequency to calculate the missing value based on the average value of the previous and next data. If there is a wide range of missing data, missing values are predicted from the data collected from other sensors observing a similar phenomenon. As seen in these few studies, the reasons for data quality issues can be crucial in devising data quality management techniques. Therefore, we need more research to investigate the dependency among data quality issues, their reasons, and data quality management techniques. RQ1.1 Conclusion.. Data quality research for IoT and CPS mainly addresses missing values, outliers, and data timeliness. The studies in our review do not address the implications of different computing architectures for data quality issues and techniques for CPS and IoT. There is also little research discussing the reasons for data quality issues (e.g., electromagnetic interference, high temperatures, loss of connectivity, and signal processing errors). Future research should further investigate the reasons and the implications of computing architectures for data quality issues to devise better data quality management techniques. 4.1.2 RQ1.2: What are the Application Domains for Data Quality Research? What Types of Data are Collected in these Application Domains?. Various industries are concerned with questions and research around data quality. Figure 3 presents the application domains of the primary studies in our review. A big part of the literature (55%) stems from research for manufacturing industries (e.g., automotive, semiconductor). Healthcare, environmental research, agriculture, and logistics follow manufacturing industries. The use of data analytics technologies in manufacturing industries to ensure quality is getting more and more attention to increase performance and yield, reduce costs, and optimize supply chains. It is known as manufacturing analytics and is part of Industry 4.0, where factories evolve into self-running and healing entities by adopting new technologies such as IoT. Therefore, most primary studies on manufacturing industries propose manufacturing analytics frameworks and support data quality as a preprocessing step for data analytics input. For instance, Weiss et al. [46] provide methods for continually predicting manufactured product quality in semiconductor manufacturing. The proposed methods have a data preprocessing step to predict missing input data. We can conclude that data quality is crucial to the manufacturing business since manufacturing involves multiple sensors in harsh environments (e.g., a shop floor - the area of a factory, machine shop), which may lead to various data quality issues. Please note that the most-mentioned reasons for data quality issues in RQ1.1, such as heterogeneous multiple data sources, sensor malfunctions, and network problems, are likely to occur in such environments. Fig. 3. Fig. 3. Application domains of the data quality research for CPS and IoT in Industry 4.0. The data types in the reviewed literature are manifold (see Figure 4). Time-series data dominate the data types. Most evaluations in the primary studies are conducted in a controlled research environment rather than in an industrial setting. Only six of 51 studies present an evaluation in an industrial environment (e.g., a shop floor). Fig. 4. Fig. 4. Data types of the data quality research for CPS and IoT in Industry 4.0. RQ1.2 Conclusion.. Manufacturing industries are the predominant application domain in the primary studies, while time series are the most collected data type in the application domains. 4.1.3 RQ1.3: What is the Tradeoff between Data Quality and Data Security?. Data security is to prevent unauthorized access to data. It can be considered part of data quality (see data veracity in RQ1.1) since avoiding data corruption caused by unauthorized access improve data quality. Data quality techniques, e.g., data cleaning or repair, necessitate flexible read and write access to all data. Security problems may arise while running these techniques because data can be exchanged with other systems or used by users with different access rights. Improving data security may limit the abilities of data quality techniques and, in turn, reduce data quality. The need for data security enforces certain restrictions on how data is accessed, stored, and analyzed. These restrictions may negatively affect overall data quality and increase computational costs. For instance, data may need to be anonymized or encrypted in a vault. Encryption techniques require different users to encrypt their data with their keys; the identical data copies of different users lead to different ciphertexts, making data deduplication impossible. Data deduplication eliminates redundant copies, significantly reduces storage capacity requirements, and ensures data consistency. Some well-adapted strategies, e.g., centralized secret keys within a dedicated entity that allow the deduplication process to decrypt data, can be employed to overcome conflicts between data quality and security [143]. We have identified only seven papers addressing both data quality and security for IoT and CPS. Four of these papers [7, 11, 19, 31] investigate how data security solutions can improve data quality (in particular, data accuracy). Krotofil et al. [19] propose a process-aware approach to detect when a sensor signal is maliciously changed. Similarly, Russel et al. [31] present a sensor data validation method that employs sensory substitution to mitigate common sensing errors and cyber-physical attacks, such as playback attacks. Two blockchain-based approaches [7, 11] support the assessment of the trustworthiness of sensor observations and false data detection to improve IoT data quality. Only three papers [38, 39, 51] study the tradeoff between data quality and security. Zellinger et al. [51] address confidentiality protection in transfer learning (an ML approach focusing on storing knowledge gained while solving one problem and applying it to a different but related problem). The idea is a module-based combination of confidentiality-preserving noise-adding methods with robust transfer learning algorithms for intelligent manufacturing applications. They discuss noise injection mechanisms achieving a good trade-off between data privacy and accuracy. Sicari et al. [38, 39] propose a system architecture addressing data security and quality in IoT. The architecture contains three layers: Analysis, Data Annotation, and Integration. The Analysis layer extracts the information about the data (e.g., data source, data type, and data security and quality properties) to support other layers. Its task is to evaluate whether the input data satisfy data security and quality requirements. The layer computes a score for each security property (i.e., data confidentiality, data integrity, source privacy, and source authentication) and data quality property (i.e., data accuracy, data precision, information timeliness, and completeness). These scores inform IoT users and applications about the security and data quality levels. The Data Annotation layer annotates the data with the computed scores; the Integration layer exploits the scores about security and quality level to select the data resources for data integration. The evaluation of the proposed architecture reveals that high-security scores may lead to low-level data completeness (the number of collected values over a given time interval divided by the number of expected values). On the other hand, high-level data security positively contributes to data accuracy (the degree of similarity of a measured quantity to its actual value), precision (the degree to which further calculations return the same or similar results), and timeliness (the temporal validity of data). Different computing architectures (e.g., edge, fog, and Cloud computing) have different security risks, affecting the tradeoff between data security and quality. For instance, edge applications pose particular security risks (e.g., the dependence on edge computing resources without proper security software) because IoT devices are designed for low-cost and low-power usage and are unsuitable for complex technology. One technique to mitigate these risks is to monitor all edge activity to limit data access rights of native edge applications, including data quality techniques running on edge devices. Similar to our findings in RQ1.1, none of the primary studies mentioned above discuss the implications of IoT computing architectures for the tradeoff between data security and quality. RQ1.3 Conclusion.. Some primary studies focus on data quality and security separately or study how data security can improve data quality and therefore do not address the tradeoff between these two. Few papers addressing the tradeoff study data quality and security properties, but not how data quality and security techniques affect or limit each other on different computing architectures. We need further research on the implications of different IoT computing architectures for the tradeoff between data security and quality. 4.2 RQ2 - What Data Quality Techniques Are Used for CPS and IoT in Industry 4.0? Data quality techniques include approaches and technologies identifying and correcting data quality issues. There are different interpretations of data quality techniques. Some surveys mix data cleaning and repair under the same category. Our SLR has a distinction between data repair and cleaning techniques (see Figure 2) and reports them in two sub-questions (RQ2.2 and 2.3) since they differ in how they treat data quality issues. Data monitoring (identifying quality issues in data) is a prerequisite and an integral part of data repair and cleaning. Therefore, we investigate it as a sub-activity of data repair and cleaning. To respond to RQ2, we address four sub-questions: 4.2.1 RQ2.1: What Are the Data Quality Metrics for Data Quality Monitoring?. Data quality metrics are the measurements used to assess data. They benchmark how beneficial and relevant data is, and help differentiate between high-quality and low-quality data. They can be employed to certify data sources in IoT and CPS as fit or not for specific purposes. They can easily be related to data quality dimensions, i.e., the measurement attributes of data, which we can assess, interpret, and improve. We identified 41 data quality metrics in the primary studies. Table 4 presents the data quality dimensions and the corresponding metrics with their formulas/explanations. The metrics are either based on a mathematical formula or computed by a program on structured data for an observation period. Accuracy, completeness, and validity are the most data quality dimensions addressed by the quality metrics. We could not find any metric for data orderliness, volume, auditability, consistency, accessibility, compliance, efficiency, precision, traceability, understandability, portability, recoverability, and integrity. Data consistency among these dimensions is the level to which values of an attribute adhere to some constraints. Data validity metrics (M31-M40) subsume this definition of data consistency. Table 4. DQ Dimension Number Formula / Description Reference Accuracy M1 X={ x t |t∈T} is a time series process, and N is the number of observations. Degradation of accuracy is detected as deviation in the following properties of X . Mean μ= 1 N ∑ N i=1 x i . Standard deviation σ= 1 N−1 ∑ N i=1 ( x t −μ ) 2 − − − − − − − − − − − − − − − √ . Kurtosis K= 1 N ∑ N i=1 ( x i −μ ) 4 σ 4 . Skewness S k = 1 N−1 ∑ N i=1 ( x i − μ 3 ) σ 3 . Sum of absolute values ∑ N i=1 | x i | . Number of elements over the mean { x t ∈X: x t >μ} [8] M2 Test campaigns using human to detect data quality faults in facility management using cameras and sensors. O is the occupancy count obtained from cameras and sensors. O>50 in a 10 meter squared room indicates data error. O>0 outside working hours then the sensor is frozen. [36] M3 Binary logistic regression p( x i )= 1 1+ e −β x i , where p( x i ) is the probability that the data point x i is noisy. [9] Show More Table 4. Data Quality Metrics in the Primary Studies Several data quality metrics in the primary studies are numerically bounded. Some metrics produce a normalized score in the range [0,1] as a binary value (M6, M16), percentage (M7, M11, M34), score (M4, M21, M25, M28, M40), relative frequency (M5, M10, M13), and probability (M3, M41). The bounded metrics appear to be human-understandable. However, due to differences in their computation methods, the metrics are not standardized for arithmetic comparison and numerical composition with each other. Nevertheless, there is one exception where M29 on data trust is a weighted sum of data accuracy (M5) and data completeness (M13). Several metrics (M1, M17, M24, M30) use statistical properties of batch data instead of statistical properties of reference high-quality data. For instance, Sanyal and Zhang [33] compute data uncertainty (M30) as the Shannon entropy of batch data without the need for cordoning reference data. Data quality metrics are extensively studied in the literature but are not widely used by industrial IoT systems having dark data [67]. Dark data is unstructured, untagged, and untapped data that has not yet been analyzed or processed. IoT systems accumulate it for various reasons, including compliance and security obligations. Beneficial data becomes outdated because of the lack of tools and processes to use data in a timely manner. Dark data often represents lost opportunities (e.g., revenue, products) for a business as data content and quality is unknown. Almost 90% of IoT data is dark data [83]. If computed promptly and presented as feedback to humans, data quality metrics can instill a company culture to use data before it becomes dark. Furthermore, they can improve data audibility and boost the acquisition of higher-quality data suitable for products based on ML/AI. RQ2.1 Conclusion.. We identified a large spectrum of data quality metrics in the literature. However, we could not find any study reporting the adoption of these metrics in industrial IoT systems as a common practice. We need research to facilitate using quality metrics in industrial IoT settings while addressing the problem of dark data. In the future, it would be interesting to study the perception of human users when AI-driven decisions made on data are presented alongside the data quality metrics. 4.2.2 RQ2.2: What Are the Data Repair Techniques?. As described in Section 3, data repair techniques restore data lost, accidentally deleted, corrupted, or made inaccessible, while data cleaning techniques only remove corrupt or noisy data. We identified ten primary studies that provide or employ a data repair technique. We excluded studies that do not give any detail, e.g., Wei et al. [45] proposing data interpolation without explaining how to apply it in the CPS/IoT context. Table 5 presents the data repair techniques in the primary studies. The first two columns provide the data quality issue and the data repair technique before a brief description in the third column. The fourth and fifth columns indicate if the repair technique is online (data repair at the data source in real-time) and evaluated. We classify it offline (data repair for large historical datasets on the Cloud) if the study does not report any deployment for online data repair. Table 5. DQ Issue Technique Description of the Technique Online Evaluated Reference Missing Values Data Imputation Missing values are calculated based on the average value of the previous and next data. When there is a wide range of missing data, missing values are filled in according to similar machining data in the manufacturing workshop. No Yes Kong et al. [18] Missing Values Median-based Data Imputation The median value is determined by arranging data in increasing order. Missing values are filled in by the median value. This method underestimates the variance in the dataset since the same median value is used for multiple missing values. No No Khan et al. [17] Missing Values Guided Process for Data Repair in Regression models (DC-RM) - Data Imputation DC-RM provides a procedure for building data repair/cleaning process for regression models. For each data quality issue in the datasets, a data quality task is suggested. In DC-RM, three data imputation techniques are employed: hot deck (missing items are replaced by using values from the same dataset), imputation based on missing values (assigns a value to a missing one based on measures of central tendency), imputation based on non-missing attributes (a regression/classification model is performed). No Yes Corrales et al. [9] Show More Table 5. Data Repair Techniques in the Primary Studies Missing values are the most data quality issue addressed by the data repair techniques (five primary studies). These techniques use data imputation methods (i.e., replacing missing values with estimates and analyzing the dataset as if the imputed values were actual observed values) from statistics to repair missing values. Different studies employ different imputation techniques (median-based [17], mean-based [46], average-value [18], and matrix factorization [44]) for missing value repair. Corrales et al. [9] provide a guided process with data quality techniques (data repair and cleaning). They assume that missing values are represented by special characters such as ?, *, blank spaces, or special words (NaN, null). The user selects one of the imputation techniques offered (hot deck, imputation based on missing attributes, and imputation based on non-missing ones). Most of the repair techniques use data from the same sensor to predict missing values. However, it is not convenient to use the same dataset when there is a wide range of missing values. Kong et al. [18] discuss using data from similar sensors but do not provide any implementation. Wang et al. [44] use correlations among sensors to reconstruct missing values in a single time series. They provide only offline repair. As mentioned in RQ1.1, data veracity is the accuracy or truthfulness of a dataset and is sometimes considered a data security property. Four studies [23, 27, 31, 33] provide techniques that repair “corrupt” data and increase its accuracy. Three of them [27, 31, 33] use reference sensors/monitors or sample data to improve sensor data accuracy. For instance, Russel et al. [31] present an approach that repairs the initial sensed data from cameras (the processed output from the edge) with the raw data from an ambient sensor. It uses sensory substitution to increase the data robustness, resilience, and dependability. Lin et al. [23] are different from these three studies and repair corrupted data from its origin through computational dependencies in a distributed IoT setting. They replay all the dependent computations to correct data degraded throughout its life cycle due to hardware malfunction, software bugs, or network partitions. ML has the potential for online and offline data repair in CPS/IoT as correlations among various data sources (sensors) can be learned to substitute one sensor with another sensor and predict missing values or new data that replace corrupt data. Non-AI techniques have different constraints limiting their applicability. For instance, Lin et al. [23] require all dependent data computations in the application state history, which are not always available. ML can support more generic repair solutions for IoT systems having multiple sensors that can replace each other. However, we revealed only two studies [12, 27] applying ML to data repair. Flick et al. [12] use ML (K-means for clustering and regression modeling) only to detect outliers in the clusters, not to predict data replacing outliers. They employ the overflow, overweight, substitution value, and algebraic sign calculations to calculate replacing data. Okafor et al. [27] use linear regression and neural networks to correct sensor output. Their approach determines the factors affecting data quality, models their effects on the sensor response, and applies the calibration model to calibrate sensors. It merges data from multiple sensors into the calibration equation to ensure consistent and accurate information for the model. The full potential of ML for data repair still needs to be explored with the challenges of integrating ML models and components related to the data and model evolution. Manufacturing is the dominant application domain of data quality research for CPS and IoT (see RQ1.2). Although manufacturing processes produce the same products or parts repetitively, there might be occasional, minor modifications to product specifications and process parameters (e.g., the need to ramp up production) that can render ML models obsolete. Therefore, we need solutions that investigate continual learning [114] and domain adaptation [62] in conjunction with the continuous deployment of ML models [133]. One challenge for data repair research is to create real-time (online) data repair services (e.g., quality monitors and repair services on edge gateway) for IoT systems. However, we identified only four primary studies [23, 27, 31, 33] addressing online data repair. The techniques proposed by these studies detect and repair “corrupt” data at the edge/fog devices close to the data source where computation resources are limited. Only one technique [27] is an ML-based repair solution. It does not address different deployment and versioning scenarios of ML models on edge and Cloud. An ML-based data repair technique should be invoked either on edge or Cloud to create ML models based on the availability of training data. The models should be containerized as online repair services and deployed on edge for real-time data repair or on the Cloud for offline repair. Only two data repair techniques [17, 46] in our SLR have not been evaluated. They are part of data analytics frameworks. Therefore, the focus of the evaluation in their studies is the data analytics frameworks, not the outcome of the data repair techniques. One study [31] reports the experience with its repair technique and does not quantitatively assess its performance. We investigate the details of the evaluation of the data repair techniques in RQ2.4. RQ2.2 Conclusion.. Across primary studies, data repair techniques address missing values, data veracity, and outliers. Most of these techniques are non-AI solutions having limitations in the industrial CPS/IoT context. ML can support more generic (online and offline repair) repair solutions for IoT systems having multiple sensors that can replace each other. Future research should explore the full potential of ML for data repair and address the challenges of integrating ML models and components related to the data and model evolution. 4.2.3 RQ2.3: What Are the Data Cleaning Techniques?. Data cleaning techniques detect and remove corrupt and unusable data, e.g., those affected by environmental noise or extreme operating conditions. They do not attempt, for instance, to restore any data deleted or corrupted. Table 6 presents data cleaning techniques in the primary studies. The table structure is similar to the one in Table 5. Table 6 does not include studies that do not give any details (e.g., Saranya and Sivakumar [34]). Table 6. DQ Issue Technique Description of the Technique Online Evaluated Reference Outlier DBSCAN-based Outlier Detection It is a hybrid prediction model that consists of Density-Based Spatial Clustering of Applications with Noise (DBSCAN)-based outlier detection and Random Forest classification. DBSCAN [81] was used to separate outliers from normal sensor data, while Random Forest was utilized to predict faults. Yes Yes Syafrudin et al. [40] Outlier Clustering Algorithms Distance measure and clustering algorithms detect and remove outliers. No No Wei et al. [45] Noise Smoothing Filter The use of smoothing filters [140] is proposed for denoising manufacturing data. The details of how a smoothing filter can be applied are not explained. No No Wei et al. [45] Show More Table 6. Data Cleaning Techniques in the Primary Studies Outlier is the most data quality issue addressed by the data cleaning techniques (seven primary studies). These techniques differ in detecting outliers, while the cleaning task is standard (i.e., removing the detected outliers from the dataset). They use clustering algorithms [9, 40, 45], domain knowledge [8, 29, 49], decision trees [35], or distance metrics [45] to detect outliers. Syafrudin et al. [40] and Corrales et al. [9] use Density-Based Spatial Clustering of Applications with Noise (DBSCAN)-based outlier detection [81] to separate outliers from normal sensor data. Specific rules detecting outliers are defined based on domain knowledge (manufacturing domain). For example, Yu et al. [49] discard all the data points for the machine speed value lower than 8000 since the machine is supposed to be shut down at that speed. Cerquitelli et al. [8] use the cycle length deciles to detect test cycles of the manufacturing machines and remove the data of these test cycles from the dataset. Five primary studies [5, 18, 42, 45, 48] provide data cleaning techniques that address data noise. Four of them [5, 42, 45, 48] use filtering to clean noise. For instance, Yu et al. [48] apply noise filters (i.e., the distance between two computation units) to remove two types of noise (the long and short duration of noise). Kong et al. [18] employ sampling to remove noise in the datasets used for the state prediction of machine tools. Data imbalance (a small proportion of nearly-failure state during machine tool operation) affects the prediction results (classification). Part of the running state data is sampled to constitute a smaller dataset, whose data amount is comparable to that of the nearly-failure data. As we noted in RQ1.1, high-dimensionality is crucial, especially for ML applications at the edge, but one of the least addressed data quality issues in our review. Only three data cleaning techniques [9, 18, 42] address high dimensionality. Two techniques [9, 18] employ the principal component analysis [53] to filter out irrelevant attributes. Villalobos et al. [42, 43] provide a guided process using an ML-based model that combines reduction techniques with extracted features from time series to recommend the most suitable reduction technique. The three techniques are offline, and none of them provide online support for reducing high dimensions in input datasets for real-time ML applications. All the data cleaning techniques employing clustering algorithms [9, 40, 45], decision trees [35], distance metrics [45], noise filters [5, 42, 45, 48], sampling [18], or the principal component analysis [9, 18] are domain agnostic. They may not always detect and clean domain-specific data quality issues (e.g., removing data of machine test cycles [8], data of the machine having a speed value lower than 8000 [49], or trajectory data from an agricultural monitoring system when the data recording time of two adjacent track points is the same [14]). Therefore, we need guided processes using both domain-agnostic data quality monitoring and domain knowledge-based heuristics to detect data quality issues. The existing ones [9, 42, 43] employ only domain-agnostic techniques. Corrales et al. [9] propose the Guided Process for Data Cleaning in Regression Models (DC-RM) that suggests a data cleaning task (e.g., removing outliers) for data quality issues found through a domain-agnostic monitoring technique (e.g., DBSCAN [81]). We identified five online cleaning techniques [5, 8, 29, 40, 48, 49]. As indicated in RQ2.2, ML has the potential for developing online solutions (and offline solutions too). Two online data cleaning techniques use ML solutions (DBSCAN - an unsupervised learning method utilized in ML algorithms [40] and decision trees and random forest classification [5]). They do not address the ML model deployment and versioning challenges for online data cleaning. Their primary studies do not report on model deployment and versioning scenarios on edge and Cloud (see RQ3.1). Half of the data cleaning techniques [8, 14, 29, 42, 43, 45, 49] in our SLR have not been evaluated. They are part of predictive maintenance or smart manufacturing [8, 29, 45, 49] and agriculture machinery monitoring systems [14]. Therefore, the focus of the evaluation in the primary studies is not the outcome of the data cleaning techniques. We investigate the evaluation details of the data cleaning techniques in RQ2.4. RQ2.3 Conclusion.. Existing cleaning techniques address outliers, noise, high-dimensionality, duplicated records, data drift, and missing values. Most of these techniques are domain agnostic and may not always be able to detect and clean domain-specific data quality issues. Further research is needed to propose guided processes using both domain-agnostic data quality monitoring and domain-knowledge-based heuristics. There is also a need for online data cleaning support to reduce high dimensions in input datasets for real-time ML applications. 4.2.4 RQ2.4: How Are Data Quality Techniques Evaluated?. In this section, we discuss the evaluation metrics used and reported in the selected papers, their calculation methods, and their strengths and drawbacks. Eight metrics have been used to assess data quality techniques. They can be categorized as classification and regression metrics. The former includes precision [40], recall [40], and accuracy [18, 40]. The latter contains the Mean Absolute Error (MAE) [9, 27, 34], Mean Squared Error (MSE) [34], Root Mean Squared Error (RMSE) [27, 34, 44], coefficient of determination ( R 2 ) [27, 34], and the true sensor data estimation error [33]. Table 7 lists the metrics used to evaluate data quality techniques. These metrics have been mainly used to evaluate the data quality techniques by using predictive analytics output (e.g., fault and remaining useful life prediction). The main goal is to assess the impact of the data quality techniques on the performance of the classification and regression models. For instance, Kong et al. [18] use the accuracy metric to show that the data processed by the proposed data quality technique improves the classification accuracy for tool wear prediction. Table 7. Evaluation Metrics Context Generic Evaluation Target References MAE, RMSE, R 2 Repair Yes Data repair approach (regression models) Okafor et al. [27] Accuracy Repair Yes Classification Models for Tool Wear Prediction Kong et al. [18] RMSE Repair Yes Data repair approach Wang et al. [44] Show More Table 7. Metrics used to Evaluate Data Quality Techniques Classification Metrics. As seen in Table 8, classification models have four possible outcomes. True positive (TP) and true negative (TN) denote the correctly classified points. False positive (FP) represents the points incorrectly classified as “yes” (positive) when they are actually “no” (negative). And false negative (FN) refers to the points incorrectly classified as “no” (negative) when they are actually “yes” (positive). According to the definitions of TP, TN, FP, and FN, Table 9 presents the precision, recall, and accuracy metrics. Table 8. Classified as “Yes” Classified as “No” Actual “Yes” True Positive (TP) False Negative (FN) Actual “No” False Positive (FP) True Negative (TN) Table 8. Confusion Matrix of a Classifier Table 9. Metric Description Formula Precision The ratio of true positive to the total predicted positive TP/(TP + FP) Recall The ratio of true positive to the total actual positive TP/(TP + FN) Accuracy The ratio of correct predictions to total observations (TP + TN)/(TP + TN + FP + FN) Table 9. Precision, Recall, and Accuracy Metrics for Classification Models Syafrudin et al. [40] calculate the precision, recall, and accuracy of classification models predicting faults with and without removing outliers (data cleaning). Although we can use precision and recall to assess the performance of data cleaning solutions (e.g., the number of correctly removed outliers over all the data points removed), we did not find any study using these metrics for that purpose. The accuracy metric uses all TP, TN, FP, and FN in Table 8 and is adequate for only balanced datasets. IoT and CPS datasets obtained from sensors are imbalanced; they usually have more normal data points than erroneous ones, and the class distribution is not even in these datasets. Therefore, the accuracy metric is unfair while assessing data quality techniques on sensor datasets. It might be why the primary studies ([18, 40]) use the accuracy metric only to evaluate the impact of data quality techniques on the performance of classification models. Regression Metrics. The MAE, MSE, RMSE, and R 2 metrics have been mostly used to assess the performance of the data quality techniques on the regression models (see Table 7). MSE is the average squared difference (error) between the predicted and observed values. It gives more weight to big differences. It might underestimate the model’s accuracy as one big difference might increase the MSE significantly. RMSE is the square root of MSE and is more interpretable. MAE is the average of the absolute differences. Unlike MSE or RMSE, it is less sensitive to big differences since it does not take the square of the errors. R-squared ( R 2 ) represents the proportion of the variance for a dependent variable explained by an independent variable(s) in a regression model. It can be more informative than MAE, MSE, and RMSE, as it can be described as a percentage, whereas MAE, MSE, and RMSE have arbitrary ranges. Corrales et al. [9] compare the MAE of the regression models trained with the dataset not cleaned versus those trained with the same data set cleaned by their data cleaning approach. They show that the results achieved by the trained models with the cleaned dataset are better than or equal to that with the same dataset not cleaned. Saranya and Sivakumar [34] use the MAE, MSE, RMSE, and R 2 to assess the impact of the proposed data cleaning technique on the prediction of Remaining Useful Life (RUL). They calculate and compare the metrics for the RUL prediction with and without outliers. Different from these two works mentioned above, Okafor et al. [27] employ the MAE, RMSE, and R 2 metrics to assess the performance of their proposed data repair technique. They compare the sensor measurements before and after data repair to reference measurements using these three metrics. Wang et al. [44] use the RMSE to evaluate the performance of missing value prediction. They compare the RMSE of their proposed data repair approach and of the competing methods (e.g., non-negative matrix factorization [106] and support vector machine [139]). Sanyal and Zhang [33] propose a specialized metric for sensor data estimation error to compare their data repair approach with Principal component analysis (PCA) [53], i.e., a classical tool for low dimensional linear subspace approximation, as a baseline algorithm in the presence of high Gaussian noise with outliers and missing values. This metric is similar to RMSE as it is the square root of the sum of the squares of the coordinates of the vectors of the estimated and observed sensor data from each IoT node. As mentioned above, only three studies (i.e., [27, 33, 44]) use regression metrics to assess the performance of data quality techniques, not their impact on the performance of classification/regression models. They evaluate data repair approaches predicting missing or corrupted data. Therefore, they use regression metrics, i.e., MAE, RMSE, and R 2 , that quantify the difference in the estimated and observed values. Although not found in the primary studies, precision and recall can assess the performance of data cleaning techniques. We could not identify a single study evaluating both the performance of a data quality technique and its impact on the performance of a data analytics solution. RQ2.4 Conclusion.. Across primary studies, the metrics are standard and have been mostly used to assess the impact of the data quality techniques on the performance of predictive analytics (e.g., fault and remaining useful life prediction). Few studies assess the performance of data quality techniques. No study evaluates both the performance of a data quality technique and its impact on the performance of predictive analytics. 4.3 RQ3: What Software Engineering Solutions Are Used for Data Quality for CPS and IoT in Industry 4.0? Software is the heart and soul of any IoT system and CPS, especially for analyzing data and its quality. Software engineering solutions for CPS and IoT systems often span the edge-fog-Cloud continuum; various software design choices are made based on the requirements for real-time and historical data processed by these systems. To better understand the role of software engineering in data quality, this research question investigates software engineering solutions in the primary studies. We use the term software engineering solution to cover any software engineering technique (including data storage technologies, programming languages, libraries, and platforms) used to implement data quality techniques for CPS and IoT. To respond to RQ3, we address the following three subquestions: 4.3.1 RQ3.1: What Programming Languages and Solutions are used to Manage Data Quality?. Nineteen papers (out of 51 papers considered in our survey) mention a programming language or solution (e.g., programming platforms, libraries, and models). Table 10 presents the programming languages and solutions used to manage data quality in the papers. Nine of these papers (i.e., [2, 15, 21, 29, 34, 40, 49, 50, 51]) propose a data analytic solution as part of a CPS or IoT system. Their main goal is not to provide a data quality technique. They support data quality as a pre-processing step of their data analytics solution. Since these solutions attempt to quantify uncertainty and reason with incomplete and inconsistent data, more right data generally results in a better output of such solutions [88]. Python, Java, and R are used to implement data analytics in the studies. ML libraries TensorFlow [52], Weka [91], MLLib [118], scikit-learn [129], and Keras (high-level API of TensorFlow 2) [89] provide a proper abstraction to facilitate the development of the proposed data analytics solutions. Table 10. Languages Machine Learning Libraries Bigdata Platforms Other Java C/ C++ Python R Tensor-Flow [52] Weka [91] MLLib [118] scikit [129] Keras [89] Nifi [125] Camel [68] Kafka [99] Spark [142] Jena [69] C-SPARQL [64] Matlab [116] CSPOT [151] NOS [132] Data Qualityas a Primary Goal Lin et al. [23] ✓ Saybani et al. [35] ✓ Buschjager et al. [5] ✓ ✓ ✓ Show More Table 10. Summary of the Programming Languages and Solutions used to Manage Data Quality Only ten papers mentioning programming languages and solutions (i.e., [4, 5, 9, 10, 20, 23, 26, 27, 35, 39]) address data quality techniques for CPS and IoT applications as their primary goal. For instance, Lin et al. [23] propose a new approach for repairing corrupted data in IoT applications. It automatically tracks causal data dependencies and replays dependent computations across multi-tiered IoT deployments. It combines the function-as-a-service (FaaS) programming model with versioned, persistent storage and causal event tracking to facilitate data repair. The approach extends an open-source, distributed, FaaS runtime system called CSPOT [151]. CSPOT runs over various devices (e.g., microcontrollers, edge, and public Clouds) and makes data repair possible in a distributed IoT setting. Semantic technologies have been investigated to enable the integration and interoperability of data produced by heterogeneous IoT devices. Bambgboye et al. [4] present a layered software framework using semantic technologies to maintain the consistency of data streams produced by physical sensors. The framework applies semantic modeling and reasoning to validate data stream consistency while highlighting the temporal characteristics of the stream. The framework has four layers: the sensing, modeling, reasoning, and application layers. The sensing layer receives data from sensors and prepares the data for the upper layer. It contains a stream service module that ensures the continuous transfer of data streams with Java infrastructure Apache Camel [68]. The modeling layer provides an ontology to integrate and enhance reasoning for sensor streaming data available as raw numeric data. Semantic reasoning achieves the continuous validation of the sensor stream. The reasoning layer validates sensor readings within a time window against prevailing disturbances with data validation policies and other related sensor readings. To this end, the framework layers the Jena rule language [69] with the C-SPARQL query engine [64] for continuous queries over RDF data streams. The data collected, processed, and exchanged at each stage of CPS and IoT applications might have a different structure, format, and velocity and be stored in data silos not available to all the system users but only to some users. Cui et al. [10] propose a systematic approach, i.e., Data Control Module (DCM), that uses state-of-art big data software to manage data silos in manufacturing. A data silo concerns timely monitoring of data changes, redundancy, inconsistency, and insecurity. DCM employs big data software (Apache NiFi [125], Apache Phoenix [131], and Apache Kafka [99]) to implement functions addressing these concerns. The DCM architecture consists of DCM Cloud and several DCM Edge systems. Apache NiFi takes responsibility for data monitoring at the DCM edge and data collection and allocation at the DCM Cloud. It provides a data provenance function to trace data history and check data consistency. Apache Kafka is a high-throughput, low-latency messaging framework. Therefore, it transmits control messages (including data information such as source location, data source computer, expected location, and target data computer) between the DCM Cloud and Edge. RQ3.1 Conclusion.. The programming languages and solutions used to manage data quality (e.g., TensorFlow, Keras, MATLAB’s fuzzy logic toolbox, Jena, C-SPARQL) highly depend on the solution domain (e.g., ML, data mining, semantic web). For instance, Python is almost the de-facto programming language in the studies providing ML-based solutions. Not many papers mention a programming language, but Python, Java, C++, and R are used to implement data quality techniques in the approaches we studied in our survey. Big data software platforms such as Apache Kafka and Phoenix are suitable for implementing data quality concerns for high-velocity data, such as the timely monitoring of data changes, data redundancy, data inconsistency, and data insecurity. 4.3.2 RQ3.2: What Data Storage Solutions Are Used to Manage Data Quality?. Data storage support depends on data type, where data is stored (Local/Edge/Cloud), and in which context data is processed. We analyze the relationship between data storage support (e.g., time-series database systems, NoSQL, or a blockchain solution) and data quality. We expect to gain new insights into essential data storage solutions in CPS, IoT, and Industry 4.0 applications and their impact on data quality techniques such as data cleansing and repair. These new insights will help organizations choose appropriate data storage for data quality. Twenty papers (i.e., [1, 2, 7, 10, 11, 14, 15, 16, 18, 21, 23, 24, 26, 32, 37, 39, 40, 42, 44, 49]) mention data storage support, e.g., database, file system, or a blockchain solution, where data storage is mostly part of data analytics frameworks. Three papers [1, 7, 11] employ the blockchain to ensure data security, such as the trustworthiness of sensor observations, while the blockchain is also a storage medium. There is an explicit dependency between the data storage solution and the data quality support (i.e., ensuring data security) in these two works. Mohammed et al. [26] employ a Cloud-based solution, i.e., the Google Cloud environment, to store IoT data. Some papers refer to some domain-specific database systems (not any well-known database system) without detailed information, such as agricultural telematics [14] or operation management database [16]. They do not provide any insight into database technologies, how data is managed, in what format and quality, and the impact of the database technologies on the data quality techniques. Data warehouses and distributed file systems are ideal mediums for storing data for big data systems [32, 48, 49] that receive data from multiple data sources. Such data systems require data cleansing before data gathered from various sources are integrated. They may use data warehouses and distributed file systems combined with databases in a layered fashion where each layer has its data cleansing. For instance, Santos et al. [32] propose data storage layers having different components used in various contexts: (a) data streams are stored in a real-time fashion in a NoSQL database in the real-time data storage layer; (b) the Staging Area and Big Data Warehouse components save data in a more historical perspective in the historical data storage layer. In the Staging Area component, the Hadoop distributed file system stores data that are available for further use for a limited time. Shah et al. [37] propose a plug-and-play solution to use the data storage layers as an interface to data storage. This decoupling enables the data storage technologies (e.g., data warehouses, relational databases, and distributed file systems) to be easily replaced based on the type of stored data. However, replacing the data storage component accessed through the layer may require changes in the data quality techniques (e.g., data cleansing) due to the data quality support the new component provides. The papers do not report a direct relationship between the database technologies and the data quality techniques. Table 11 gives a classification of database systems and the solutions using these systems. We use the database management system taxonomy provided by Gudivada et al. [88]. In addition to the database classes in Table 11, Gudivada et al. [88] mention Native XML, RDF Stores, and Key-Value Stores database classes which none of the papers in our survey report. Most papers report the use of column-family database systems (i.e., HBase and Cassandra) since these systems support heterogeneous data and tolerate network failures and temporal data inconsistency. A column family is a NoSQL database containing columns of related data. The column-family database systems such as HBase and Cassandra also support time-series data. Table 11. DB Class Used DBs References Description of the DB Class by Gudivada et al. [88] Column Family HBase Kong et al. [18], Huru et al. [15], Wang et al. [44], Cui et al. [10] Ideal for storing sparse, non-transactional, and heterogeneous data and retrieving partial records; accommodate flexible and evolving database schema; tolerance to both network failures and temporary data inconsistency; increased processing power through horizontal scalability. Cassandra Villalobos et al. [42], Apiletti et al. [2] Document Oriented MongoDB Villalobos et al. [42], Syafrudin et al. [40], Sicari et al. [39] Ideal for managing semi structured, arbitrarily nested hierarchical document data organized in the form of key-value pairs in JSON format; support flexible schema evolution; accommodate high data variability among data records. Show More Table 11. A Classification of Database Systems in the Primary Studies RQ3.2 Conclusion.. We derived the following insights into essential data storage solutions in CPS, IoT, and Industry 4.0 applications and their impact on data quality techniques: (i) blockchain is an ideal solution to ensure data security as part of data quality; (ii) big data systems gathering data from various sources combine multiple data storage solutions, which require a layered data storage architecture where each layer may require its own data quality technique; (iii) there is no direct relation between the key database technologies and the data quality techniques; and (iv) the column-family database systems are highly preferred since they support heterogeneous data and tolerate network failures and temporal data inconsistency. 4.3.3 RQ3.3: What IoT Reference Architecture Layers Are Covered in the Primary Studies?. Data can be processed/stored at different levels of the IoT reference architecture (see Section 3.3). These architecture levels can help understand how and where data is analyzed and processed for quality issues. We have identified twenty primary studies that refer to the IoT architecture layers (see Table 12 and L1-L7 in Section 3.3). Table 12. Primary Study IoT Architecture Perception Network Application L1 L2 L3 L4 L5 L6 L7 Villalobos et al. [42] ✓ ✓ ✓ Wang et al. [44] ✓ ✓ ✓ Hui et al. [14] ✓ ✓ ✓ ✓ Show More Table 12. IoT Reference Architecture Layers in the Primary Studies ✓ = the contribution specifies the IoT architectural aspects from the taxonomy Five primary studies [1, 14, 26, 42, 44] focus on data quality management in the Cloud-based architecture layers (L4, L5, and L6). Three of these studies [14, 42, 44] propose data quality management techniques (data repair and cleaning) running on the Cloud. These techniques are offline, e.g., data repair for large historical datasets on the Cloud. Sensor data in motion are converted for long-term storage and stored in an easily accessible format on the Cloud to be further processed, e.g., for historical data validation. For instance, Villalobos et al. [42] focus on the layers L4 and L5 for time series data captured by machine sensors and accessed using a REST API via a gateway. The remaining two primary studies present a Cloud-based approach to measure IoT data freshness [26] and a distributed architecture using blockchain and smart contracts for data quality in logistics traceability [1]. Six primary studies [5, 7, 11, 13, 21, 41] focus on data quality management in edge-based architecture levels (L2 and L3). Only one study [5] provides a data quality technique running on edge (L3). It is an online data cleaning technique that uses ML (decision trees and random forest classification) to filter out unwanted events on raw data on the edge before further processing data on the Cloud. One study [7] proposes a game theory algorithm running on edge (L3) to detect fraudulent data. Dedeoglu et al. [11] use gateways (L2, L3) to calculate trust for sensor observations. Guo et al. [13] distribute portions of large volumes of data from machines (L1) to the edge (L3). Kufner et al. [21] combine signal acquisition and concurrent analysis techniques in a distributed edge-based structure (L2, L3) to achieve vertical data continuity. Nine primary studies [4, 8, 10, 16, 23, 24, 31, 40, 49] cover edge-Cloud orchestration for data processing (not necessarily data quality management). Four of these studies [23, 31, 40, 49] provide a data quality management technique (data cleaning and repair) in the architecture layers from L1 to L7. They are all online techniques and implement data monitoring and cleaning/repair across the edge-Cloud continuum. For instance, Syafrudin et al. [40] incorporate distributed gateways (L3) that obtain sensor data and application layers (L4, L5, and L6) used for detection/removal and fault prediction. The remaining five primary studies mention data quality as part of data analytics support or data management frameworks. Therefore, they cover almost all the IoT architecture layers while addressing data quality management in a subset of these layers. Our observation is that the ubiquitousness, complexity, and size of IoT systems pose fundamental challenges and limitations in deploying data quality techniques across the IoT reference architecture layers. IoT systems may run on several IoT device types (e.g., smart camera, thermostat, smart tv, force sensors, vibration sensors) having different operational environments (e.g., industrial, enterprise, consumer). These devices may operate on several protocols (MQTT, CoAP, AMQP) and connection types (device-to-device, device-to-gateway, gateway-to-data systems) with different data acquisition systems. Having several device and protocol configurations for IoT systems obtaining different kinds of data in different operational environments leads to several resource constraints and data quality management scenarios (online and offline). For instance, we deploy a data repair technique on the Cloud for the historical (offline) repair of high-frequency manufacturing data stored in the cloud infrastructure. The same technique may also be deployed on edge to perform in-motion (online) data repair for real-time predictive maintenance. We need highly configurable data management techniques deployed on different layers of the IoT reference architecture for different scenarios, e.g., on a stand-alone machine, an edge device, or the Cloud, with access to a long- or short-term database or an API provided by a data acquisition system. However, the current data repair and cleaning techniques we summarized above address particular scenarios (online or offline). They are not deployed on different architecture layers in the edge-Cloud continuum for different quality management scenarios based on the needs of the targeted IoT system. As we mentioned in RQ2.2 and 2.3, data quality monitoring is part of data cleaning and repair. However, there might be cases where the data repair or cleaning technique should run together with several data quality monitoring techniques deployed on different architecture layers. For instance, the same repair technique may predict values for missing values identified by a data monitoring approach on edge and values replacing erroneous data identified by another monitoring approach in the Cloud as part of historical data validation. Applying decentralized ML architectures to data quality management might address all these challenges and limitations of the existing techniques related to their deployment on the architecture layers depending on the quality management requirements and scenarios. We can distribute the ML model training for data repair and cleaning and containerize the trained models to be deployed on a standalone machine, edge, or the Cloud for different quality management scenarios. On the other hand, we need research to address the data and model evolution challenges and limitations caused by integrating ML models and components (see Section 4.2.2). RQ3.3 Conclusion.. Most existing research focuses only on data processing in (indirect) relation to data quality without considering other aspects within the IoT architecture. We found very few studies discussing all the layers of IoT architecture where data flow from IoT devices, via edge, to the Cloud. The existing data quality techniques do not cover different combinations of IoT reference architecture layers for different scenarios depending on the needs of the targeted IoT system. We need further research on data quality techniques that can run on a standalone machine, edge device, or the Cloud, with data access to support online and offline data repair and cleaning. 4.4 Summary of Data Quality for CPS and IoT in Industry 4.0 Figure 5 summarizes the results related to our RQs. It shows the data quality issues for CPS and IoT, the sources of these quality issues, the data quality metrics, the data quality techniques, the metrics used to evaluate the techniques, and the software engineering solutions to manage data quality. It can be used with the taxonomy of data quality in data-driven paradigms (see Figure 2) to classify future data quality research for CPS and IoT in Industry 4.0. Fig. 5. Fig. 5. Summary of data quality in CPS and IoT for Industry 4.0. Skip 5RELATED WORK Section 5 RELATED WORK Several works study the literature on CPS and IoT. The focus of most of the surveys for CPS is on security and privacy (e.g., [84, 85, 93, 96, 102, 112, 113, 119, 124]). Some of them [84, 96, 102] survey the literature for CPS security from a more general perspective; some others focus on specialized security topics such as intrusion detection systems [119], deep learning-based anomaly detection [113], physics-based attack detection [85], differential privacy [92], and model-based security engineering [124] for CPS. Gunes et al. [90] and Chen et al. [71] conduct secondary studies on the applications and challenges of CPS. Dey et al. [77] focus on the research for CPS in the medical domain. Xu et al. [154] survey the literature on the intersection between CPS and big data in Industry 4.0. Like the secondary studies for CPS, various studies for IoT address security and privacy (e.g., [54, 56, 59, 70, 72, 73, 93, 94, 108, 115, 117, 122, 146]). Some other studies are specialized in interoperability for Industrial IoT (IIoT) [95], IoT protocols, technologies, and applications along with related issues [57, 61, 73, 78, 107, 123, 137], IoT applications in blockchain systems [105], applications of blockchain technologies to IoT [158], IoT big data [63], data analytics for IoT [141], IoT-based smart cities [60], IoT for agriculture [80], IoT for healthcare [101], and IoT in industries [76]. Some secondary studies (e.g., [153]) survey the works for CPS and IoT in the context of Industry 4.0. Some other studies (e.g., [109, 111, 128, 136, 155, 157]) mainly focus on the literature for Industry 4.0, where CPS and IoT are considered building blocks of Industry 4.0. None of the works mentioned above address data quality for CPS and IoT. We have identified only three SLRs and three surveys focusing on data quality in the context of CPS and IoT, as briefly presented in Table 1. For each related work in the table, the symbol ‘✓’ indicates that the work provides the feature, the symbol ‘✗’ indicates that it does not provide the feature, and ‘NA’ indicates that the required information is unavailable. Karkouch et al. [100] surveyed 14 papers published between 2012 and 2016. Their paper selection was random without a systematic search and selection process of systematic reviews [104, 130, 150]. Moreover, we could not find any information on how the authors chose the discussed aspects of data quality for IoT (DQ classification schema). Karkouch et al. listed four data quality challenges for IoT data: (i) the scalability of cleaning methods in distributed systems, (ii) the heterogeneity of data sources requiring complex approaches, (iii) the automated verification without human interaction, and (iv) the fail-safe distributed architecture. They highlighted the need for an abstraction level that supports data quality assessment independent from data types. Wang and Wang [148] reviewed the state-of-the-art for time series data cleaning and classified time series errors. They mentioned four challenges related to time series data cleaning: (i) a large amount of data with a high error rate (especially, in industrial settings), (ii) ambiguous reasons for errors, (iii) continuous nature requiring online analysis, and (iv) minimum modification principle. They identified the need for research for analyzing error types defined rather broadly. They highlighted the lack of multivariate cleaning algorithms and the potential for utilizing ML for data cleaning. Zhang et al. [156] compared 21 IoT data quality frameworks and 5 related standards. The diversity in data quality frameworks and various definitions of data quality dimensions and metrics hampered the comparability of the survey. The survey revealed the need for a more user-friendly data quality assessment methodology based on existing generic frameworks. Teh et al. [144] presented a recent SLR on sensor data quality problems. They mainly investigated the error types of sensor data and sensor data error detection and correction methods. Unlike our SLR, their SLR did not study the application domains for data quality research for IoT, the trade-off between data quality and security, and software engineering solutions used to manage data quality. Teh et al. reported several methods proposed to detect and correct sensor data errors. 90% of the studies in the SLR provided proper validation, and 68% used not publicly available or reproducible data. Teh et al. highlighted that the methods are not comparable without further ado since variations of a common idea are utilized in many cases with a varying research methodology (e.g., labeling, error injection, or preprocessing method). They revealed the need for a benchmark system to compare data quality techniques. Liu et al. [110] conducted an SLR on data quality in IoT based on 45 empirical studies from 2012 to 2018. Contrary to our study, their SLR is limited to data quality problems (issues), dimensions, and measures. It does not cover topics such as data quality techniques, their evaluation, application domains for data quality research, and software technologies for managing data quality, which are the main points of our SLR. Liu et al. established links among data quality dimensions, manifestations of data quality problems, and methods utilized to measure data quality. They identified the potential areas for future work: (i) developing guidelines for defining specific data quality dimensions of IoT data, (ii) addressing data quality problems based on different IoT layers, and (iii) constructing data quality frameworks in the IoT context. More recently, Alwan et al. [58] conducted another SLR to investigate data quality challenges in smart cities as large-scale CPSs and identify the most common techniques used to address these challenges. The scope of the SLR is limited to the data quality challenges for CPSs, the data quality techniques to overcome these challenges, and the effectiveness of these techniques. The SLR does not cover data quality metrics, data security, or software engineering solutions to manage data quality. Similar to the results we reported (see Section 4.1.1), Alwan et al. revealed that data quality issues occur in large-scale CPSs because of sensor malfunctions, calibration issues, poor sensor node quality, environmental effects, external noise, and networks or communication errors. They categorized the data quality solutions into three primary groups: data mining, technical models, and mathematical models. Data mining methods (i.e., anomaly detection, classification, clustering, and predictive analysis) are the most widely used compared to others. In comparison with the SLRs and surveys mentioned above, our SLR investigates exclusively three aspects of data quality for IoT, CPS, and Industry 4.0: (i) data quality problems (including data quality issues, their resources, application domains, data types, and data quality and security tradeoff), (ii) data quality techniques to overcome the problems (metrics to monitor data quality, approaches for data repair and cleaning, and evaluation of these approaches), and (iii) software engineering solutions for data quality (architectures, programming languages, and data storage solutions). Existing SLRs focused on one or two aspects with a limited scope. For instance, Liu et al. [110] studied the literature on data quality problems based on quality dimensions and measures. We approach data quality research for theoretical and practical implications in a much broader scope. We also report some research directions. Skip 6THREATS TO VALIDITY Section 6 THREATS TO VALIDITY Our systematic literature review addresses a wide range of approaches and domains. Our review process had automated (e.g., search queries) and manual (e.g., data extraction) parts. Therefore, some relevant studies and information might have been uncovered. In the following, we summarize several measures taken to mitigate this issue. 6.1 Internal Validity Search Queries. We aimed to find as many relevant publications as possible by using general terms related to data quality in our search queries. We used our inclusion and exclusion criteria to select the papers. It is still possible that we should have included more research in the final selection of primary studies. To mitigate this risk, we conducted a manual search to limit the possibility of missing studies throughout the database search process. We discovered most of the primary studies through our database search. The search features provided by these online publication databases are not always the same, which may lead to misleading search results. To mitigate this risk, we adapted our search string for the built-in search features of each database. Study Inclusion and Exclusion. Even though we have well-defined inclusion and exclusion criteria, including or excluding a study could still be subjective, especially when its contribution is indirect to data quality (e.g., some studies support data quality as a preprocessing step of data analytics). To mitigate this risk, we conducted cross-checks between at least two authors and then group discussion to remove papers that did not have enough scientific contribution according to our selection criteria. Data Extraction. Missing and misinterpreting information is a risk of manual information extraction. To mitigate this risk, we distributed the primary studies to the authors for data extraction. They later validated the data extraction for each other. One co-author reviewed the data extraction and its validation to identify and summarize the data extraction inconsistencies. We settled all the conflicts during meetings with the authors. 6.2 External Validity The online repositories we used in our SLR restrict our review results. To mitigate this risk, we employed repositories that well-known venues have been included in and that previous survey papers have extensively used. 6.3 Conclusion Validity The primary studies have a variety of application domains, and some of them have primary goals different than data quality (e.g., data analytics), which made it difficult to determine direct contributions to data quality and draw decisive conclusions. To mitigate this issue, we categorized the primary studies based on goals (e.g., data quality as a primary/secondary goal in Table 10) for our research questions. 6.4 Reliability Validity The readers can replicate our systematic literature review study if they follow the steps of our review process. It is still possible to have some inconsistent results because of potential differences in the manual steps of the review process, such as data extraction and synthesis. To mitigate this risk, we provided the details of our review process (see Section 2) and a summary of data quality research (Figure 5) that can be used with our taxonomy of data quality (Figure 2) in data-driven paradigms to classify and compare future primary studies. Skip 7CONCLUSIONS Section 7 CONCLUSIONS This article presented the results of our systematic literature review (SLR) regarding data quality research for CPS and IoT in Industry 4.0. Obtaining data from IoT and CPS for decision support is crucial to improving efficiency and competitiveness in many industrial sectors and application domains. Data quality techniques ensure the input quality for decision support and become an inherent component of data-centric CPS and IoT applications. We followed the common SLR steps (i.e., the definition of research questions, a search strategy, inclusion and exclusion criteria, and data synthesis and extraction method) to conduct our review. Our systematic search and selection process yielded 51 primary studies published between 2011 and 2021 (and three SLRs and three surveys). The growing number of studies in recent years indicates an increasing interest in data quality research for CPS and IoT. Our objective was to analyze how data quality has been treated for data-centric CPS and IoT applications and evaluate what the proposed data quality techniques have done for those applications. We investigated data quality issues and their sources for CPS and IoT, data quality metrics, data quality techniques (including data quality monitoring, data repair, and data cleaning), and software engineering solutions for handling data quality. To answer three RQs (ten sub-questions), we obtained and synthesized data from the primary studies. From our SLR, we conclude the following: (a) The primary studies address a variety of data quality issues. Outliers, missing values, and data veracity are the three main ones. Not many studies discuss the source of data quality issues and the implications of different computing architectures for data quality issues. Future research should further investigate the reasons and the implications of computing architectures for data quality issues to devise better techniques. (b) We could not find any study reporting the adoption of data quality metrics in industrial systems. We need research to facilitate using quality metrics in industrial settings. (c) Non-AI data repair solutions have limitations in the industrial CPS/IoT context (e.g., requiring dependent data computations in the application state history, which are not always available). Future research should explore machine learning for online and offline data repair while addressing model deployment and evolution. (d) Most data cleaning techniques are domain agnostic and may not always detect and clean domain-specific data quality issues. Further research should address guided processes that use domain-agnostic data quality monitoring and domain-knowledge-based heuristics. Real-time machine learning applications need online data cleaning support to reduce high dimensions in input datasets. (e) Existing data quality management techniques do not support deployment on different IoT layers for online and offline scenarios. Future techniques should be able to run on a standalone machine, edge device, or the Cloud, with data access to support online and offline data repair and cleaning on the edge and in the Cloud. (f) The programming languages and solutions for managing data quality (e.g., TensorFlow, Keras, MATLAB’s fuzzy logic toolbox) highly depend on the solution domain (e.g., ML, data mining). Big data software platforms are suitable for addressing data quality concerns for high-velocity data (e.g., the timely monitoring of data changes, data redundancy, data inconsistency, and data insecurity). (g) We could not reveal any direct relation between the database technologies and the data quality techniques. On the other hand, big data systems gathering data from various sources combine multiple data storage solutions that require a layered data storage architecture where each layer may require its own data quality technique. Skip ACKNOWLEDGMENTS Section ACKNOWLEDGMENTS We would like to thank Enrique Garcia-Ceja (our former colleague at SINTEF), Nicolas Jourdan (PTW TU Darmstadt, Germany), and Beatriz Bretones Cassoli (PTW TU Darmstadt, Germany) for their help during the initial phase of this work. PRIMARY STUDIES [1] Ahmed Mohamed, Taconet Chantal, Ould Mohamed, Chabridon Sophie, and Bouzeghoub Amel. 2021. IoT data qualification for a logistic chain traceability smart contract. Sensors 21, 6 (2021). Navigate to [2] Apiletti Daniele, Barberis Claudia, Cerquitelli Tania, Macii Alberto, Macii Enrico, Poncino Massimo, and Ventura Francesco. 2018. iSTEP, an integrated self-tuning engine for predictive maintenance in Industry 4.0. In ISPA/IUCC/BDCloud/SocialCom/SustainCom’18. 924–931. Navigate to [3] Azimi Shelernaz and Pahl Claus. 2020. A layered quality framework for machine learning-driven data and information models. In ICEIS (1). 579–587. Reference 1Reference 2Reference 3 [4] Bamgboye Oluwaseun, Liu Xiaodong, and Cruickshank Peter. 2019. Semantic stream management framework for data consistency in smart spaces. In COMPSAC’19. 85–90. Navigate to [5] Buschjäger Sebastian and Morik Katharina. 2018. Decision tree and random forest implementations for fast filtering of sensor data. IEEE Transactions on Circuits and Systems I: Regular Papers 65, 1 (2018), 209–222. Navigate to [6] Byabazaire John, O’Hare Gregory, and Delaney Declan. 2020. Using trust as a measure to derive data quality in data shared IoT deployments. In ICCCN’20. 1–9. Navigate to [7] Casado-Vara Roberto, Prieta Fernando de la, Prieto Javier, and Corchado Juan M.. 2018. Blockchain framework for IoT data quality via edge computing. In BlockSys’18. 19–24. Navigate to [8] Cerquitelli T., Nikolakis N., Bethaz P., Panicucci S., Ventura F., Macii E., Andolina S., Marguglio A., Alexopoulos K., Petrali P., Pagani A., Wilgen P. van, and Ippolito M.. 2020. Enabling predictive analytics for smart manufacturing through an IIoT platform. In AMEST’20. 179–184. Navigate to [9] Corrales David Camilo, Corrales Juan Carlos, and Ledezma Agapito. 2018. How to address the data quality issues in regression models: A guided process for data cleaning. Symmetry 10, 4 (2018). Navigate to [10] Cui Yesheng, Kara Sami, and Chan Ka C.. 2020. Monitoring and control of unstructured manufacturing big data. In IEEM’20. 928–932. Navigate to [11] Dedeoglu Volkan, Jurdak Raja, Putra Guntur D., Dorri Ali, and Kanhere Salil S.. 2019. A trust architecture for blockchain in IoT. In MobiQuitous’19. 190–199. Navigate to [12] Flick Dominik, Gellrich Sebastian, Filz Marc-André, Ji Li, Thiede Sebastian, and Herrmann Christoph. 2019. Conceptual framework for manufacturing data preprocessing of diverse input sources. In INDIN’19. 1041–1046. Navigate to [13] Guo Ziqi, Bao Tingwen, Wu Wenlong, Jin Chao, and Lee Jay. 2019. IAI DevOps: A systematic framework for prognostic model lifecycle management. In PHM-Qingdao’19. 1–6. Navigate to [14] Hui Liu, Xiaobo Ye, Zhijun Meng, Lijuan Zhou, and Zhong Sun. 2019. An agricultural machinery operation monitoring system based on IoT. In DSIT’19. 225–229. Navigate to [15] Huru Dan, Leordeanu Cătălin, Apostol Elena, Mocanu Mariana, and Cristea Valentin. 2018. BigClue analytics: A middleware component for modeling sensor data in IoT systems. In HPCC/SmartCity/DSS’18. 891–896. Navigate to [16] Jeong Seunghwan, Yoo Gwangpyo, Yoo Minjong, Yeom Ikjun, and Woo Honguk. 2019. Resource-efficient sensor data management for autonomous systems using deep reinforcement learning. Sensors 19, 20 (2019). Navigate to [17] Khan Mohammad Ayoub and Algarni Fahad. 2020. A healthcare monitoring system for the diagnosis of heart disease in the IoMT cloud environment using MSSO-ANFIS. IEEE Access 8 (2020), 122259–122269. Navigate to [18] Kong Tianxiang, Hu Tianliang, Zhou Tingting, and Ye Yingxin. 2021. Data construction method for the applications of workshop digital twin system. Journal of Manufacturing Systems 58 (2021), 323–328. Navigate to [19] Krotofil Marina, Larsen Jason, and Gollmann Dieter. 2015. The process matters: Ensuring data veracity in cyber-physical systems. In ASIA CCS’15. 133–144. Navigate to [20] Kuemper Daniel, Iggena Thorben, Toenjes Ralf, and Pulvermueller Elke. 2018. Valid.IoT: A framework for sensor data quality analysis and interpolation. In MMSys’18. 294–303. Navigate to [21] Küfner Thomas, Schönig Stefan, Jasinski Richard, and Ermer Andreas. 2021. Vertical data continuity with lean edge analytics for Industry 4.0 production. Computers in Industry 125 (2021), 103389. Navigate to [22] Li Fei, Nastic Stefan, and Dustdar Schahram. 2012. Data quality observation in pervasive environments. In ICCSE’12. 602–609. Navigate to [23] Lin Wei-Tsung, Bakir Fatih, Krintz Chandra, Wolski Rich, and Mock Markus. 2019. Data repair for distributed, event-based IoT applications. In DEBS’19. 139–150. Navigate to [24] Liu Chao, Roux Léopold Le, Körner Carolin, Tabaste Olivier, Lacan Franck, and Bigot Samuel. 2020. Digital twin-enabled collaborative data management for metal additive manufacturing systems. Journal of Manufacturing Systems (2020). Navigate to [25] Mieth Carina, Meyer Anne, and Henke Michael. 2019. Framework for the usage of data from real-time indoor localization systems to derive inputs for manufacturing simulation. Procedia CIRP 81 (2019), 868–873. Reference 1Reference 2Reference 3 [26] Mohammed Fatma, Kayes A. S. M., Pardede Eric, and Rahayu Wenny. 2020. A framework for measuring IoT data quality based on freshness metrics. In TrustCom’20. 1242–1249. Navigate to [27] Okafor Nwamaka U., Alghorani Yahia, and Delaney Declan T.. 2020. Improving data quality of low-cost IoT sensors in environmental monitoring networks using data fusion and machine learning approach. ICT Express 6, 3 (2020), 220–228. Navigate to [28] Packianather Michael S., Munizaga Nury Leon, Zouwail Soha, and Saunders Mark. 2019. Development of soft computing tools and IoT for improving the performance assessment of analysers in a clinical laboratory. In SoSE’19. 158–163. Reference 1Reference 2 [29] Proto Stefano, Ventura Francesco, Apiletti Daniele, Cerquitelli Tania, Baralis Elena, Macii Enrico, and Macii Alberto. 2019. PREMISES, a scalable data-driven service to predict alarms in slowly-degrading multi-cycle industrial processes. In BigDataCongress’19. 139–143. Navigate to [30] Qi Qinglin and Tao Fei. 2018. Digital twin and big data towards smart manufacturing and industry 4.0: 360 degree comparison. IEEE Access 6 (2018), 3585–3593. Reference 1Reference 2Reference 3 [31] Russell Luke, Kwamena Felix, and Goubran Rafik. 2019. Towards reliable IoT: Fog-based AI sensor validation. In IEEE Cloud Summit. 37–44. Navigate to [32] Santos Maribel Yasmina, Sá Jorge Oliveira e, Andrade Carina, Lima Francisca Vale, Costa Eduarda, Costa Carlos, Martinho Bruno, and Galvão João. 2017. A big data system supporting Bosch Braga Industry 4.0 strategy. International Journal of Information Management 37, 6 (2017), 750–760. Navigate to [33] Sanyal Sunny and Zhang Puning. 2018. Improving quality of data: IoT data aggregation using device-to-device communications. IEEE Access 6 (2018), 67830–67840. Navigate to [34] Saranya E. and Sivakumar P. Bagavathi. 2020. Data-driven prognostics for run-to-failure data employing machine learning models. In ICICT’20. 528–533. Navigate to [35] Saybani Mahmoud Reza, Wah Teh Ying, Amini Amineh, and Yazdi Saeed Reza Aghabozorgi Sahaf. 2011. Anomaly detection and prediction of sensors faults in a refinery using data mining techniques and fuzzy logic. Scientific Research and Essays 6, 27 (2011), 5685–5695. Navigate to [36] Seghezzi Elena, Locatelli Mirko, Pellegrini Laura, Pattini Giulia, Giuda Giuseppe Martino Di, Tagliabue Lavinia Chiara, and Boella Guido. 2021. Towards an occupancy-oriented digital twin for facility management: Test campaign and sensors assessment. Applied Sciences 11, 7 (2021). Navigate to [37] Shah Devarshi, Wang Jin, and He Q. Peter. 2020. Feature engineering in big data analytics for IoT-enabled smart manufacturing – Comparison between deep learning and statistical learning. Computers & Chemical Engineering 141 (2020), 106970. Navigate to [38] Sicari Sabrina, Cappiello Cinzia, Pellegrini Francesco De, Miorandi Daniele, and Coen-Porisini Alberto. 2016. A security-and quality-aware system architecture for Internet of Things. Information Systems Frontiers 18, 4 (2016), 665–677. Navigate to [39] Sicari Sabrina, Rizzardi Alessandra, Miorandi Daniele, Cappiello Cinzia, and Coen-Porisini Alberto. 2016. A secure and quality-aware prototypical architecture for the Internet of Things. Information Systems 58 (2016), 43–55. Navigate to [40] Syafrudin Muhammad, Alfian Ganjar, Fitriyani Norma Latif, and Rhee Jongtae. 2018. Performance analysis of IoT-based sensor, big data processing, and machine learning model for real-time monitoring system in automotive manufacturing. Sensors 18, 9 (2018). Navigate to [41] Tham Chen-Khong and Rajagopalan Rajalaxmi. 2020. Active learning for IoT data prioritization in edge nodes over wireless networks. In IECON’20. 4453–4458. Reference 1Reference 2Reference 3 [42] Villalobos K., Ramírez-Durán V. J., Diez B., Blanco J. M., Goñi A., and Illarramendi A.. 2020. A three level hierarchical architecture for an efficient storage of Industry 4.0 data. Computers in Industry 121 (2020), 103257. Navigate to [43] Villalobos Kevin, Vadillo Jon, Diez Borja, Calvo Borja, and Illarramendi Arantza. 2018. I4TSPS: A visual-interactive web system for industrial time-series pre-processing. In Big Data’18. 2012–2018. Navigate to [44] Wang Chang, Zhu Yongxin, Shi Weiwei, Chang Victor, Vijayakumar P., Liu Bin, Mao Yishu, Wang Jiabao, and Fan Yiping. 2018. A dependable time series analytic framework for cyber-physical systems of IoT-based smart grid. ACM Transactions on Cyber-Physical Systems 3, 1 (2018), 18 pages. Navigate to [45] Wei Wei, Yuan Jun, and Liu Ang. 2020. Manufacturing data-driven process adaptive design method. Procedia CIRP 91 (2020), 728–734. Navigate to [46] Weiss Sholom M., Dhurandhar Amit, and Baseman Robert J.. 2013. Improving quality control by early prediction of manufacturing outcomes. In KDD’13. 1258–1266. Navigate to [47] Wu Leon and Kaiser Gail. 2012. An autonomic reliability improvement system for cyber-physical systems. In HASE’12. 56–61. Reference 1Reference 2 [48] Yu Wenjin, Dillon Tharam, Mostafa Fahed, Rahayu Wenny, and Liu Yuehua. 2019. Implementation of industrial cyber physical system: Challenges and solutions. In ICPS’19. 173–178. Navigate to [49] Yu Wenjin, Dillon Tharam, Mostafa Fahed, Rahayu Wenny, and Liu Yuehua. 2020. A global manufacturing big data ecosystem for fault detection in predictive maintenance. IEEE Transactions on Industrial Informatics 16, 1 (2020), 183–192. Navigate to [50] Zacarias Alejandro Gabriel Villanueva, Reimann Peter, and Mitschang Bernhard. 2018. A framework to guide the selection and configuration of machine-learning-based data analytics solutions in manufacturing. Procedia CIRP 72 (2018), 153–158. Navigate to [51] Zellinger Werner, Wieser Volkmar, Kumar Mohit, Brunner David, Shepeleva Natalia, Gálvez Rafa, Langer Josef, Fischer Lukas, and Moser Bernhard. 2021. Beyond federated learning: On confidentiality-critical machine learning applications in industry. In ISM’20. 734–743. Navigate to REFERENCES [52] Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, Manjunath Kudlur, Josh Levenberg, Rajat Monga, Sherry Moore, Derek G. Murray, Benoit Steiner, Paul Tucker, Vijay Vasudevan, Pete Warden, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. 2016. Tensorflow: A system for large-scale machine learning. In OSDI’16. 265–283. Reference 1Reference 2 [53] Abdi Hervé and Williams Lynne J.. 2010. Principal component analysis. Wiley Interdisciplinary Reviews: Computational Statistics 2, 4 (2010), 433–459. Navigate to [54] Ahmad Rasheed and Alsmadi Izzat. 2021. Machine learning approaches to IoT security: A systematic literature review. Internet of Things 14 (2021), 100365. Reference [55] Akter Shahriar, McCarthy Grace, Sajib Shahriar, Michael Katina, Dwivedi Yogesh K., D’Ambra John, and Shen K. N.. 2021. Algorithmic bias in data-driven innovation in the age of AI. International Journal of Information Management 60 (2021), 102387. Reference [56] Al-Garadi Mohammed Ali, Mohamed Amr, Al-Ali Abdulla Khalid, Du Xiaojiang, Ali Ihsan, and Guizani Mohsen. 2020. A survey of machine and deep learning methods for Internet of Things (IoT) security. IEEE Communications Surveys & Tutorials 22, 3 (2020), 1646–1685. Reference [57] Alam Iqbal, Sharif Kashif, Li Fan, Latif Zohaib, Karim Md Monjurul, Biswas Sujit, Nour Boubakr, and Wang Yu. 2020. A survey of network virtualization techniques for Internet of Things using SDN and NFV. ACM Computing Surveys (CSUR) 53, 2 (2020), 1–40. Reference [58] Alwan Ahmed Abdulhasan, Ciupala Mihaela Anca, Brimicombe Allan J., Ghorashi Seyed Ali, Baravalle Andres, and Falcarin Paolo. 2022. Data quality challenges in large-scale cyber-physical systems: A systematic review. Information Systems 105 (2022). Reference 1Reference 2Reference 3 [59] Ammar Mahmoud, Russello Giovanni, and Crispo Bruno. 2018. Internet of Things: A survey on the security of IoT frameworks. Journal of Information Security and Applications 38 (2018), 8–27. Reference [60] Arasteh Hamidreza, Hosseinnezhad Vahid, Loia Vincenzo, Tommasetti Aurelio, Troisi Orlando, Shafie-khah Miadreza, and Siano Pierluigi. 2016. IoT-based smart cities: A survey. In 2016 IEEE 16th International Conference on Environment and Electrical Engineering (EEEIC’16). 1–6. Reference [61] Asghari Parvaneh, Rahmani Amir Masoud, and Javadi Hamid Haj Seyyed. 2019. Internet of Things applications: A systematic review. Computer Networks 148 (2019), 241–261. Reference [62] Azamfar Moslem, Li Xiang, and Lee Jay. 2020. Deep learning-based domain adaptation method for fault diagnosis in semiconductor manufacturing. IEEE Transactions on Semiconductor Manufacturing 33, 3 (2020), 445–453. Reference [63] Bansal Maggi, Chana Inderveer, and Clarke Siobhán. 2020. A survey on IoT big data: Current status, 13 v’s challenges, and future directions. ACM Computing Surveys (CSUR) 53, 6 (2020), 1–59. Reference [64] Barbieri Davide Francesco, Braga Daniele, Ceri Stefano, Valle Emanuele Della, and Grossniklaus Michael. 2009. C-SPARQL: SPARQL for continuous querying. In WWW’09. 1061–1062. Reference 1Reference 2 [65] Bitton Dina and DeWitt David J.. 1983. Duplicate record elimination in large data files. ACM Transactions on Database Systems 8, 2 (1983), 255–265. Reference [66] Breunig Markus M., Kriegel Hans-Peter, Ng Raymond T., and Sander Jörg. 2000. LOF: Identifying density-based local outliers. In MOD’00. 93–104. Reference [67] Cafarella Michael, Ilyas Ihab F., Kornacker Marcel, Kraska Tim, and Ré Christopher. 2016. Dark data: Are we solving the right problems?. In 2016 IEEE 32nd International Conference on Data Engineering (ICDE’16). IEEE, 1444–1445. Reference [68] Camel Apache. [n.d.]. https://camel.apache.org/. Reference 1Reference 2 [69] Carroll Jeremy J., Dickinson Ian, Dollin Chris, Reynolds Dave, Seaborne Andy, and Wilkinson Kevin. 2004. Jena: Implementing the semantic web recommendations. In WWW’04. 74–83. Reference 1Reference 2 [70] Celik Z. Berkay, Fernandes Earlence, Pauley Eric, Tan Gang, and McDaniel Patrick. 2019. Program analysis of commodity IoT applications for security and privacy: Challenges and opportunities. ACM Computing Surveys (CSUR) 52, 4 (2019), 1–30. Reference [71] Chen Hong. 2017. Applications of cyber-physical system: A literature review. Journal of Industrial Integration and Management 2, 03 (2017), 1750012. Reference [72] Chen Zhiyan, Liu Jinxin, Shen Yu, Simsek Murat, Kantarci Burak, Mouftah Hussein T., and Djukic Petar. 2022. Machine learning-enabled iot security: Open issues and challenges under advanced persistent threats. Comput. Surveys 55, 5 (2022), 1–37. Reference [73] Chettri Lalit and Bera Rabindranath. 2019. A comprehensive survey on Internet of Things (IoT) toward 5G wireless systems. IEEE Internet of Things Journal 7, 1 (2019), 16–32. Reference 1Reference 2 [74] Corallo Angelo, Crespino Anna Maria, Vecchio Vito Del, Lazoi Mariangela, and Marra Manuela. 2021. Understanding and defining dark data for the manufacturing industry. IEEE Transactions on Engineering Management (2021). Reference [75] Create-IoT. 2018. Deliverable D6.02 – Recommendations for Commonalities and Interoperability Profiles of IoT Platforms. https://european-iot-pilots.eu/wp-content/uploads/2018/11/D06_02_WP06_H2020_CREATE-IoT_Final.pdf. Reference [76] Xu Li Da, He Wu, and Li Shancang. 2014. Internet of Things in industries: A survey. IEEE Transactions on Industrial Informatics 10, 4 (2014), 2233–2243. Reference [77] Dey Nilanjan, Ashour Amira S., Shi Fuqian, Fong Simon James, and Tavares João Manuel R. S.. 2018. Medical cyber-physical systems: A survey. Journal of Medical Systems 42 (2018), 1–13. Reference [78] Dizdarević Jasenka, Carpio Francisco, Jukan Admela, and Masip-Bruin Xavi. 2019. A survey of communication protocols for internet of things and related challenges of fog and cloud computing integration. ACM Computing Surveys (CSUR) 51, 6 (2019), 1–29. Reference [79] Dutka Alan F. and Hansen Howard H.. 1991. Fundamentals of Data Normalization. Addison-Wesley Longman Publishing Co., Inc. Reference [80] Elijah Olakunle, Rahman Tharek Abdul, Orikumhi Igbafe, Leow Chee Yen, and Hindia M. H. D. Nour. 2018. An overview of Internet of Things (IoT) and data analytics in agriculture: Benefits and challenges. IEEE Internet of Things Journal 5, 5 (2018), 3758–3773. Reference [81] Martin Ester, Hans-Peter Kriegel, Jörg Sander, and Xiaowei Xu. 1996. A density-based algorithm for discovering clusters in large spatial databases with noise. In KDD’96, 226–231. Navigate to [82] Frank Alejandro Germán, Dalenogare Lucas Santos, and Ayala Néstor Fabián. 2019. Industry 4.0 technologies: Implementation patterns in manufacturing companies. International Journal of Production Economics 210 (2019), 15–26. Reference [83] Gimpel Gregory and Alter Allan. 2021. Benefit from the Internet of Things right now by accessing dark data. IT Professional 23, 2 (2021), 45–49. Reference [84] Giraldo Jairo, Sarkar Esha, Cardenas Alvaro A., Maniatakos Michail, and Kantarcioglu Murat. 2017. Security and privacy in cyber-physical systems: A survey of surveys. IEEE Design & Test 34, 4 (2017), 7–17. Reference 1Reference 2 [85] Giraldo Jairo, Urbina David, Cardenas Alvaro, Valente Junia, Faisal Mustafa, Ruths Justin, Tippenhauer Nils Ole, Sandberg Henrik, and Candell Richard. 2018. A survey of physics-based attack detection in cyber-physical systems. ACM Computing Surveys (CSUR) 51, 4 (2018), 1–36. Reference 1Reference 2 [86] Goodfellow Ian, Bengio Yoshua, and Courville Aaron. 2016. Machine learning basics. Deep Learning 1, 7 (2016), 98–164. Reference [87] Grantner Emily. 2007. ISO 8000: A standard for data quality. Logistics Spectrum 41, 4 (2007). Reference [88] Gudivada Venkat N., Ramaswamy Srini, and Srinivasan Seshadri. 2018. Data management issues in cyber-physical systems. In Transportation Cyber-Physical Systems. 173–200. Navigate to [89] Gulli Antonio and Pal Sujit. 2017. Deep Learning with Keras. Packt Publishing Ltd. Reference 1Reference 2 [90] Gunes Volkan, Peter Steffen, Givargis Tony, and Vahid Frank. 2014. A survey on concepts, applications, and challenges in cyber-physical systems. KSII Transactions on Internet and Information Systems (TIIS) 8, 12 (2014), 4242–4268. Reference [91] Hall Mark, Frank Eibe, Holmes Geoffrey, Pfahringer Bernhard, Reutemann Peter, and Witten Ian H.. 2009. The WEKA data mining software: An update. ACM SIGKDD Explorations Newsletter 11, 1 (2009), 10–18. Reference 1Reference 2 [92] Hassan Muneeb Ul, Rehmani Mubashir Husain, and Chen Jinjun. 2019. Differential privacy techniques for cyber physical systems: A survey. IEEE Communications Surveys & Tutorials 22, 1 (2019), 746–789. Reference [93] Mardiana binti Mohamad Noor and Wan Haslina Hassan. 2019. Current research on Internet of Things (IoT) security: A survey. Computer Networks 148 (2019), 283–294. Reference 1Reference 2 [94] Hassija Vikas, Chamola Vinay, Saxena Vikas, Jain Divyansh, Goyal Pranav, and Sikdar Biplab. 2019. A survey on IoT security: Application areas, security threats, and solution architectures. IEEE Access 7 (2019), 82721–82743. Reference [95] Hazra Abhishek, Adhikari Mainak, Amgoth Tarachand, and Srirama Satish Narayana. 2021. A comprehensive survey on interoperability for IIoT: Taxonomy, standards, and future directions. ACM Computing Surveys (CSUR) 55, 1 (2021), 1–35. Reference [96] Humayed Abdulmalik, Lin Jingqiang, Li Fengjun, and Luo Bo. 2017. Cyber-physical systems security–A survey. IEEE Internet of Things Journal 4, 6 (2017), 1802–1831. Reference 1Reference 2 [97] International DNV. 2017. Data Quality Assessment Framework: DNV Recommended Practice-RP-0497. DNV. Reference [98] Juxtology. 2018. IoT: Architecture. https://www.m2mology.com/iot-transformation/iot-world-forum/. Reference [99] Kafka Apache. [n.d.]. https://kafka.apache.org/. Reference 1Reference 2 [100] Karkouch Aimad, Mousannif Hajar, Moatassime Hassan Al, and Noel Thomas. 2016. Data quality in Internet of Things: A state-of-the-art survey. Journal of Network and Computer Applications 73 (2016), 57–81. Reference 1Reference 2 [101] Kashani Mostafa Haghi, Madanipour Mona, Nikravan Mohammad, Asghari Parvaneh, and Mahdipour Ebrahim. 2021. A systematic review of IoT in healthcare: Applications, techniques, and trends. Journal of Network and Computer Applications 192 (2021), 103164. Reference [102] Kayan Hakan, Nunes Matthew, Rana Omer, Burnap Pete, and Perera Charith. 2022. Cybersecurity of industrial cyber-physical systems: A review. ACM Computing Surveys (CSUR) 54, 11s (2022), 1–35. Reference 1Reference 2 [103] Khalid Samina, Khalil Tehmina, and Nasreen Shamila. 2014. A survey of feature selection and feature extraction techniques in machine learning. In 2014 Science and Information Conference. 372–378. Reference [104] Kitchenham Barbara Ann and Charters Stuart. 2007. Guidelines for Performing Systematic Literature Reviews in Software Engineering. Technical Report EBSE 2007-001. https://www.elsevier.com/__data/promis_misc/525444systematicreviewsguide.pdf. Navigate to [105] Lao Laphou, Li Zecheng, Hou Songlin, Xiao Bin, Guo Songtao, and Yang Yuanyuan. 2020. A survey of IoT applications in blockchain systems: Architecture, consensus, and traffic modeling. ACM Computing Surveys (CSUR) 53, 1 (2020), 1–32. Reference [106] Lee Daniel D. and Seung H. Sebastian. 1999. Learning the parts of objects by non-negative matrix factorization. Nature 401, 6755 (1999), 788–791. Reference [107] Li Shancang, Xu Li Da, and Zhao Shanshan. 2018. 5G Internet of Things: A survey. Journal of Industrial Information Integration 10 (2018), 1–9. Reference [108] Li Shancang, Xu Li Da, and Zhao Shanshan. 2015. The Internet of Things: A survey. Information Systems Frontiers 17 (2015), 243–259. Reference [109] Liao Yongxin, Deschamps Fernando, Loures Eduardo de Freitas Rocha, and Ramos Luiz Felipe Pierin. 2017. Past, present and future of industry 4.0-a systematic literature review and research agenda proposal. International Journal of Production Research 55, 12 (2017), 3609–3629. Reference [110] Liu Caihua, Nitschke Patrick, Williams Susan P., and Zowghi Didar. 2020. Data quality and the Internet of Things. Computing 102, 2 (2020), 573–599. Navigate to [111] Lu Yang. 2017. Industry 4.0: A survey on technologies, applications and open research issues. Journal of Industrial Information Integration 6 (2017), 1–10. Reference [112] Lun Yuriy Zacchia, D’Innocenzo Alessandro, Smarra Francesco, Malavolta Ivano, and Benedetto Maria Domenica Di. 2019. State of the art of cyber-physical systems security: An automatic control perspective. Journal of Systems and Software 149 (2019), 174–216. Reference [113] Luo Yuan, Xiao Ya, Cheng Long, Peng Guojun, and Yao Danfeng. 2021. Deep learning-based anomaly detection in cyber-physical systems: Progress and opportunities. ACM Computing Surveys (CSUR) 54, 5 (2021), 1–36. Reference 1Reference 2 [114] Maschler Benjamin, Vietz Hannes, Jazdi Nasser, and Weyrich Michael. 2020. Continual learning of fault prediction for turbofan engines using deep learning with elastic weight consolidation. In ETFA’20. 959–966. Reference [115] Matheu Sara N., Hernandez-Ramos Jose L, Skarmeta Antonio F., and Baldini Gianmarco. 2020. A survey of cybersecurity certification for the Internet of Things. ACM Computing Surveys (CSUR) 53, 6 (2020), 1–36. Reference [116] Matlab MathWorks. [n.d.]. https://mathworks.com/products/matlab.html. Reference [117] Meneghello Francesca, Calore Matteo, Zucchetto Daniel, Polese Michele, and Zanella Andrea. 2019. IoT: Internet of threats? A survey of practical security vulnerabilities in real IoT devices. IEEE Internet of Things Journal 6, 5 (2019), 8182–8201. Reference [118] Meng Xiangrui, Bradley Joseph, Yavuz Burak, Sparks Evan, Venkataraman Shivaram, Liu Davies, Freeman Jeremy, Tsai DB, Amde Manish, Owen Sean, et al. 2016. Mllib: Machine learning in apache spark. Journal of Machine Learning Research 17, 1 (2016), 1235–1241. Reference 1Reference 2 [119] Mitchell Robert and Chen Ing-Ray. 2014. A survey of intrusion detection techniques for cyber-physical systems. ACM Computing Surveys (CSUR) 46, 4 (2014), 1–29. Reference 1Reference 2 [120] Muangjaroen Supavit and Yingthawornsuk Thaweesak. 2012. A study of noise reduction in speech signal using fir filtering. In International Conference on Advances in Electrical and Electronics Engineering. Reference [121] Nelson Bruce Jay. 1981. Remote Procedure Call. Carnegie Mellon University. Reference [122] Neshenko Nataliia, Bou-Harb Elias, Crichigno Jorge, Kaddoum Georges, and Ghani Nasir. 2019. Demystifying IoT security: An exhaustive survey on IoT vulnerabilities and a first empirical look on internet-scale IoT exploitations. IEEE Communications Surveys & Tutorials 21, 3 (2019), 2702–2733. Reference [123] Ngu Anne H., Gutierrez Mario, Metsis Vangelis, Nepal Surya, and Sheng Quan Z.. 2016. IoT middleware: A survey on issues and enabling technologies. IEEE Internet of Things Journal 4, 1 (2016), 1–20. Reference [124] Nguyen Phu H., Ali Shaukat, and Yue Tao. 2017. Model-based security engineering for cyber-physical systems: A systematic mapping study. Information and Software Technology 83 (2017), 116–135. Reference 1Reference 2 [125] NiFi Apache. [n.d.]. https://nifi.apache.org/. Reference 1Reference 2 [126] Nose-Filho K., Lotufo A. D. P., and Minussi C. R.. 2011. Preprocessing data for short-term load forecasting with a general regression neural network and a moving average filter. In IEEE Trondheim PowerTech. 1–7. Reference [127] Orfanidis Sophocles J.. 2016. Introduction to Signal Processing. Pearson Education, Inc. Reference [128] Oztemel Ercan and Gursev Samet. 2020. Literature review of Industry 4.0 and related technologies. Journal of Intelligent Manufacturing 31 (2020), 127–182. Reference [129] Pedregosa Fabian, Varoquaux Gaël, Gramfort Alexandre, Michel Vincent, Thirion Bertrand, Grisel Olivier, Blondel Mathieu, Prettenhofer Peter, Weiss Ron, Dubourg Vincent, et al. 2011. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research 12 (2011), 2825–2830. Reference 1Reference 2 [130] Petersen Kai, Vakkalanka Sairam, and Kuzniarz Ludwik. 2015. Guidelines for conducting systematic mapping studies in software engineering: An update. Information and Software Technology 64 (2015), 1–18. Reference 1Reference 2Reference 3 [131] Phoenix Apache. [n.d.]. https://phoenix.apache.org/. Reference [132] platform The Node.js. [n.d.]. https://nodejs.org/en/. Reference [133] Prapas Ioannis, Derakhshan Behrouz, Mahdiraji Alireza Rezaei, and Markl Volker. 2021. Continuous training and deployment of deep learning models. Datenbank-Spektrum 21, 3 (2021), 203–212. Reference [134] Protocol NMEA 0183. [n.d.]. https://www.nmea.org/content/STANDARDS/NMEA_0183_Standard. Reference [135] REST. [n.d.]. https://restfulapi.net/. Reference [136] Sanchez Manuel, Exposito Ernesto, and Aguilar Jose. 2020. Industry 4.0: Survey from a system integration perspective. International Journal of Computer Integrated Manufacturing 33, 10-11 (2020), 1017–1041. Reference [137] Shah Sajjad Hussain and Yaqoob Ilyas. 2016. A survey: Internet of Things (IOT) technologies, applications and challenges. 2016 IEEE Smart Energy Grid Engineering (SEGE) (2016), 381–385. Reference [138] Shapere Dudley. 1964. The structure of scientific revolutions. The Philosophical Review 73, 3 (1964), 383–394. Reference [139] Shi Weiwei, Zhu Yongxin, Zhang Jinkui, Tao Xiang, Sheng Gehao, Lian Yong, Wang Guoxing, and Chen Yufeng. 2015. Improving power grid monitoring data quality: An efficient machine learning framework for missing data prediction. In HPCC/CSS/ICESS’15. 417–422. Reference [140] Simonoff Jeffrey S.. 2012. Smoothing Methods in Statistics. Springer Science & Business Media. Reference [141] Siow Eugene, Tiropanis Thanassis, and Hall Wendy. 2018. Analytics for the Internet of Things: A survey. ACM Computing Surveys (CSUR) 51, 4 (2018), 1–36. Reference [142] Spark Apache. [n.d.]. https://spark.apache.org/. Reference [143] Talha Muhammad, Kalam Anas Abou El, and Elmarzouqi Nabil. 2019. Big data: Trade-off between data quality and data security. Procedia Computer Science 151 (2019), 916–922. Reference [144] Teh Hui Yie, Kempa-Liehr Andreas W., and Wang Kevin I-Kai. 2020. Sensor data quality: A systematic review. Journal of Big Data 7, 1 (2020), 11. Reference 1Reference 2 [145] Tran Nguyen Khoi, Sheng Quan Z., Babar Muhammad Ali, and Yao Lina. 2017. Searching the Web OF Things: State of the art, challenges, and solutions. ACM Computing Surveys (CSUR) 50, 4 (2017), 55. Reference [146] Waheed Nazar, He Xiangjian, Ikram Muhammad, Usman Muhammad, Hashmi Saad Sajid, and Usman Muhammad. 2020. Security and privacy in IoT using machine learning and blockchain: Threats and countermeasures. ACM Computing Surveys (CSUR) 53, 6 (2020), 1–37. Reference [147] Wang Richard Y. and Strong Diane M.. 1996. Beyond accuracy: What data quality means to data consumers. Journal of Management Information Systems 12, 4 (1996), 5–33. Reference [148] Wang Xi and Wang Chen. 2019. Time series data cleaning: A survey. IEEE Access 8 (2019), 1866–1881. Reference 1Reference 2 [149] Wang Y Richard, Guarascio Lisa M., and Wang Richard. 1991. Dimensions of data quality: Toward quality data by design. (1991). Reference [150] Wohlin Claes. 2014. Guidelines for snowballing in systematic literature studies and a replication in software engineering. In EASE’14. 38. Navigate to [151] Wolski Rich, Krintz Chandra, Bakir Fatih, George Gareth, and Lin Wei-Tsung. 2019. CSPOT: Portable, multi-scale functions-as-a-service for IoT. In SEC’19. 236–249. Reference 1Reference 2 [152] Xiong Hui, Pandey Gaurav, Steinbach Michael, and Kumar Vipin. 2006. Enhancing data analysis with noise removal. IEEE Transactions on Knowledge and Data Engineering 18, 3 (2006), 304–319. Reference [153] Xu Hansong, Yu Wei, Griffith David, and Golmie Nada. 2018. A survey on industrial Internet of Things: A cyber-physical systems perspective. IEEE Access 6 (2018), 78238–78259. Reference 1Reference 2 [154] Xu Li Da and Duan Lian. 2019. Big data for cyber physical systems in industry 4.0: A survey. Enterprise Information Systems 13, 2 (2019), 148–169. Reference [155] Xu Li Da, Xu Eric L., and Li Ling. 2018. Industry 4.0: state of the art and future trends. International Journal of Production Research 56, 8 (2018), 2941–2962. Reference [156] Zhang Lina, Jeong Dongwon, and Lee Sukhoon. 2021. Data quality management in the Internet of Things. Sensors 21, 17 (2021), 5834. Reference 1Reference 2Reference 3 [157] Zheng Ting, Ardolino Marco, Bacchetti Andrea, and Perona Marco. 2021. The applications of Industry 4.0 technologies in manufacturing context: A systematic literature review. International Journal of Production Research 59, 6 (2021), 1922–1954. Reference [158] Zhu Qingyi, Loke Seng W., Trujillo-Rasua Rolando, Jiang Frank, and Xiang Yong. 2019. Applications of distributed ledger technologies to the internet of things: A survey. ACM Computing Surveys (CSUR) 52, 6 (2019), 1–34. Reference Cited By View all Ravindra Krishna Chandar V, Baskaran P, Mohanraj G and Karthikeyan D. (2024). Deep iterative fuzzy pooling in unmanned robotics and autonomous systems for Cyber-Physical systems. Journal of Intelligent & Fuzzy Systems: Applications in Engineering and Technology. 46:2. (4621-4639). Online publication date: 1-Jan-2024. https://doi.org/10.3233/JIFS-235721 Tverdal S, Goknil A, Nguyen P, Husom E, Sen S, Ruh J and Flamigni F. Edge-based Data Profiling and Repair as a Service for IoT. Proceedings of the 13th International Conference on the Internet of Things. (17-24). https://doi.org/10.1145/3627050.3627065 Index Terms A Systematic Review of Data Quality in CPS and IoT for Industry 4.0 Computer systems organization Embedded and cyber-physical systems Embedded systems Embedded software Sensor networks Sensors and actuators Information systems Data management systems Data structures Data layout Data compression Data encryption Database administration Database utilities and tools Information storage systems Storage management Information lifecycle management Information systems applications Computing platforms Decision support systems Data analytics Online analytical processing Process control systems Software and its engineering Software organization and properties Software system structures Embedded software Software architectures Layered systems Recommendations Data quality and the Internet of Things Abstract The Internet of Things (IoT) is driving technological change and the development of new products and services that rely heavily on the quality of the data collected by IoT devices. There is a large body of research on data quality management and ... Read More A Review on Data Cleansing Methods for Big Data Abstract Massive amounts of data are available for the organization which will influence their business decision. Data collected from the various resources are dirty and this will affect the accuracy of prediction result. Data cleansing offers a better ... Read More Towards Data Quality into the Data Warehouse Development DASC '11: Proceedings of the 2011 IEEE Ninth International Conference on Dependable, Autonomic and Secure Computing Commonly, DW development methodologies, paying little attention to the problem of data quality and completeness. One of the common mistakes made during the planning of a data warehousing project is to assume that data quality will be addressed during ... Read More Comments 150+ References View Issue’s Table of Contents Footer Categories Journals Magazines Books Proceedings SIGs Conferences Collections People About About ACM Digital Library ACM Digital Library Board Subscription Information Author Guidelines Using ACM Digital Library All Holdings within the ACM Digital Library ACM Computing Classification System Digital Library Accessibility Join Join ACM Join SIGs Subscribe to Publications Institutions and Libraries Connect Contact Facebook Twitter Linkedin Feedback Bug Report The ACM Digital Library is published by the Association for Computing Machinery. Copyright © 2024 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics

Paper 7:
- APA Citation: Bah, M. J., Wang, H., Zhao, L.-H., Zhang, J., & Xiao, J. (2021). EMM-CLODS: An Effective Microcluster and Minimal Pruning CLustering-Based Technique for Detecting Outliers in Data Streams. IEEE Access, 7, 154922–154934.
  Main Objective: Develop an effective clustering-based method for detecting outliers in continuous evolving data streams.
  Study Location: Unspecified
  Data Sources: Real and synthetic datasets
  Technologies Used: Microclustering, minimal pruning, data stream clustering
  Key Findings: - The EMM-CLODS method outperformed existing methods in most cases.
- The method is robust in handling the variation of different performance parameters and clustering quality.
- EMM-CLODS is effective in detecting outliers in continuous evolving data streams.
  Extract 1: detecting outliers in data streams by first applying microclustering technique to cluster dense data points and effectively handle objects within a sliding window according to the relevance of their status to their respective neighbors or position.
  Extract 2: The advantages of the technique are that it can effectively save time and memory, thanks to the microclustering technique and minimal pruning.
  Limitations: No major limitations were mentioned in the provided text.
  Relevance Evaluation: The EMM-CLODS method, proposed by Bah et al. (2021), is directly relevant to the specific point mentioned in the literature review outline provided. The method focuses on detecting outliers in real-time data cleaning techniques for handling missing, inconsistent, or outlier data from IoT sensors (e.g., soil moisture sensors, weather stations) using methods such as Kalman filtering, moving average, and adaptive thresholding. This is aligned with the objective of addressing the global food challenge by exploring how automated, real-time irrigation management systems can contribute to the efficient use of water resources and enhance agricultural productivity.
  Relevance Score: 1.0
  Inline Citation: None
  Explanation: Bah et al. (2021) proposed a clustering-based method called Effective Microcluster and Minimal pruning CLustering-based method for Outlier detection in Data Streams (EMM-CLODS). This method uses microclustering and minimal pruning to detect outliers in data streams. Microclustering involves grouping similar data points that are in proximity in a data stream. Minimal pruning involves excluding extended extra distance-based computations to improve computational efficiency. The EMM-CLODS method dynamically clusters data streams and offers support to meet flexible mining requirements. It has also shown robustness in handling the variation of different performance parameters and clustering quality. 

 Bah et al. conducted experiments on both real and synthetic datasets to evaluate the effectiveness of their proposed method. The results showed that EMM-CLODS outperformed existing methods in most cases and effectively detected outliers in continuous evolving data streams.

 Full Text: >
Journals Publish with us Publishing partnerships About us Blog Complexity Journal overview For authors For reviewers For editors Table of Contents Special Issues Complexity/ 2021/ Article On this page Abstract Introduction Related Work Preliminaries Results Conclusion Data Availability Disclosure Conflicts of Interest Acknowledgments References Copyright Related Articles Special Issue Collective Behavior Analysis and Graph Mining in Social Networks 2021 View this Special Issue Research Article | Open Access Volume 2021 | Article ID 9178461 | https://doi.org/10.1155/2021/9178461 Show citation EMM-CLODS: An Effective Microcluster and Minimal Pruning CLustering-Based Technique for Detecting Outliers in Data Streams Mohamed Jaward Bah ,1Hongzhi Wang ,2Li-Hui Zhao ,3Ji Zhang ,4and Jie Xiao5 Show more Academic Editor: Fei Xiong Received 07 Jul 2021 Revised 10 Aug 2021 Accepted 23 Aug 2021 Published 13 Sept 2021 Abstract Detecting outliers in data streams is a challenging problem since, in a data stream scenario, scanning the data multiple times is unfeasible, and the incoming streaming data keep evolving. Over the years, a common approach to outlier detection is using clustering-based methods, but these methods have inherent challenges and drawbacks. These include to effectively cluster sparse data points which has to do with the quality of clustering methods, dealing with continuous fast-incoming data streams, high memory and time consumption, and lack of high outlier detection accuracy. This paper aims at proposing an effective clustering-based approach to detect outliers in evolving data streams. We propose a new method called Effective Microcluster and Minimal pruning CLustering-based method for Outlier detection in Data Streams (EMM-CLODS). It is a clustering-based outlier detection approach that detects outliers in evolving data streams by first applying microclustering technique to cluster dense data points and effectively handle objects within a sliding window according to the relevance of their status to their respective neighbors or position. The analysis from our experimental studies on both synthetic and real-world datasets shows that the technique performs well with minimal memory and time consumption when compared to the other baseline algorithms, making it a very promising technique in dealing with outlier detection problems in data streams. 1. Introduction In the current era, the need to detect abnormal behavior to reveal salient facts, observations, and realizing accurate predictions of data is extremely significant. Detecting outliers is one such important data mining task that aims at detecting objects that deviate from the expected pattern of the normal data. The process of detecting outliers is challenging due to the advancement in the digital age. For instance, with the revolution of data from traditional batch data, we have witnessed the advent of a large volume of data that is generated continuously at high speed and dynamically. These kinds of data are known as data streams and are generated by many applications [ 1– 3]. In contrast to traditional datasets, because of the nature of the data, it is not feasible to save in memory the whole data stream or run the data through multiple scans. This is because the data are massive and unbounded, have a varying rate, and continue to evolve. A significant number of approaches have been proposed to detect outliers in data streams [ 8– 11]. Among the different categories of proposed outlier detection methods, clustering-based approaches have shown to be popular in static data but yet one of the most challenging to adopt for outlier detection tasks in data streams. Although they have shown to be efficient for some outlier detection tasks, they lead to low computational cost and high scalability in high-dimensional data [ 5, 12]. However, most of the prevailing data stream clustering approaches suffer from different drawbacks. They can be improved when we consider the spectrum of effectiveness and efficiency, for instance, to deal with the continuous fast-incoming data streams, higher computational demand in terms of its memory and time, the cluster quality, and the outlier detection rate. The process of clustering and detecting outliers in data streams is complicating since the clustering techniques often involve several parameters and operate in low- and high-dimensional spaces, constrained with excessive distance-based computation of object neighbors, noise, and so on. For this reason, clustering-based approach has varying performance for different application domains and data types. It is therefore imperative to design an effective method that will holistically address the issues and produce stable performance in detecting the outliers. In spite of clustering’s occasional challenges and caveats, it is still another good alternative and promising solution for detecting outliers. The advantage of clustering is that it allows for the use of limited amounts of time and memory, which is necessary when processing data streams. This is because clustering is the act of grouping elements using sets that provide the capability of grouping items that are similar to each other that curbs the need of redundant processing and over calculations. Clustering methods offer online and offline process support, which is usually used for data stream applications and is also flexible in adapting to the evolving nature of the data. In this paper, we propose a new microclustering and minimal pruning clustering-based unsupervised outlier detection scheme to detect outliers in data streams while simultaneously addressing the mentioned challenges. The proposed approach involves different stages to adapt to the dynamic changes of data distribution that aims at eliminating the limitations of previously proposed methods. The newly propose method is called Effective Microcluster and Minimal pruning CLustering-based method for Outlier detection in Data Streams (EMM-CLODS), which is a clustering-based outlier detection approach. We call it CLODS for short and use this abbreviation instead of EMM-CLODS throughout the paper. It detects outliers from evolving data streams by first applying the microclustering technique to cluster dense data points. It then effectively handles objects within a sliding window according to the relevance of their status to their respective neighbors or position through minimal pruning technique. In our data stream scenario, where the size of the dataset is potentially boundless, we process the data over a fixed period to reduce the complexity of the outlier detection task. When new incoming data points arrive, the microcluster technique is applied, which identifies objects that are more analogous to each other and that meet the fundamental prerequisite of the clustering methods. The methods scan the data once and adapt to the time changes as the streaming data evolve. It constantly and periodically updates incoming data, and the results are obtained. Finally, the CLODS reports key insights from these results to determine whether they are outliers or inliers. The advantages of the technique are that it can effectively save time and memory, thanks to the microclustering technique and minimal pruning. It removes the need to compute every data point in and out of the cluster and store every data point in memory. In summary, the major contributions of this work are as follows: (i) We propose the CLODS, a new technique based on microclustering and minimal pruning of data points outside the clusters, to solve the problem of detecting outliers in continuous evolving data streams. (ii) We propose the concept of priority handling of evolving objects outside the clusters to minimize the memory and time consumption during the updating phase according to the relevance of their status to their respective neighbors or position. (iii) Our propose method can effectively optimize and solve the problems and challenges of time and memory constraints while maintaining its accuracy for detecting outliers in data streams. (iv) We demonstrate through an extensive experiment on some benchmark datasets the effectiveness of our method against some other methods used for the outlier detection process in data streams. The rest of the paper is organized as follows: in Sections 2 and 3, we present the related work and problem formulation, respectively. In Section 4, we present in details the method we propose. In Section 5, we present the experimental studies including the results and discussion. Finally, in Section 6, we present the conclusion of the paper.    Figure 1  Streaming data. 2. Related Work Detecting outliers is a well-known domain in the data mining community, and it has been applied in a wide range of application areas [ 13, 14] and other domains such as community detection [ 15, 16]. It has been studied extensively [ 17– 19]. In a recent survey [ 11], we classified outlier detection methods into diverse categories and have proposed effective methods among these categories to detect outliers in data streams [ 8, 11]. In progress to this study series, the clustering-based category has open research gaps and challenges. Proposing solutions and improving these methods will greatly contribute to the general body of outlier detection methods. The clustering approach is an unsupervised data mining method that groups similar dense data points. Several methods using clustering techniques and its variant approaches have been proposed for outlier detection tasks. However, some earlier proposed clustering methods suffer from drawbacks such as the buffering of all data points in memory for future handling or, in some cases, not considering data points that often leads to poor clustering. There are a significant number of these methods concentrated on both static data and streaming data types [ 20, 21]. These methods mostly adopt the two-phase scheme: the online and offline phase. The majority of the earlier proposed method for stream data clustering deals with static clustering that is in a continuous form. One shortcoming of this kind of approach is that recent and outdated data are handled the same way. Several moving window models are proposed to solve this issue. For evolving data streams, Toshniwal and Yokita et al. [ 20] proposed a framework using simple k-means and the attribute weight to detect outliers, while Cao et al. [ 22] proposed a technique related to density-based clustering for evolving data streams. In their method, the incoming data are selected depending on the distance between their centers to either the outlier or potential core microcluster. In this case, with an increasing number of outliers, the clustering accuracy becomes a problem. Therefore, Liu et al. [ 23] proposed a new technique to address this drawback. Although they tried to address the issue, it comes at a high computational cost. To salvage the computational cost and improve the clustering and outlier detection accuracy, Kumar and Sharma [ 24] applied a technique that extracts the boundary points in the overlapped microclusters. Many other clustering techniques have been proposed for outlier detection processes, such as density-based microclustering [ 22, 25], grid-based clustering [ 6, 26], and partitioning algorithm for data streams [ 12, 21]. However, since this is a short paper, Table 1 briefly outlines some of these techniques in comparison to our method in terms of the summarization technique, evolving data model and outlier detection method. Table 1  Some key clustering algorithms. Remarkably, from Table 1, no two methods share the same approach. Our work is the first to use microclustering in the sliding window model using outlier microcluster to handle continuously evolving objects with changing features. For a more comprehensive related work to clustering techniques for outlier detection, we recommend Wang et al. [ 11] survey paper. 3. Preliminaries and Problem Formulation 3.1. Notations and Definitions The key symbols used in this paper include but not limited to the following in Table 2. Table 2  List of symbols with their interpretations. 3.2. Definition of Key Terms 3.2.1. Outliers For a dataset of points, . Whenever the data point or an entire set of data points deviates drastically from these other sets, these points are considered outliers. 3.2.2. Neighbor In the case of two data points and , a data point is considered a neighbor of if the distance between the two does not exceed the distance threshold value . In other words, if is not further than from , then it is a neighbor of . A data point cannot be a neighbor of itself. 3.2.3. Sliding Window In sliding window, the time-based window and the count-based window are two types of window models commonly used for data streams. The former takes into consideration the data points within the time interval of two identify data points, for instance, at point and , with and . The latter thus considers the count of the data points within a specified window size. 3.2.4. Microclusters A microcluster is formed when a data point has a radius of from the center, and in a microcluster, the distance between two data points, let us assume and , should not exceed . The function of the microcluster in our technique is as follows: we applied the microclusters to minimize the range queries and minimize the distance-based computations. The microclusters eliminate the need for excessive range queries by storing the neighbor’s data points in the microclusters. This, therefore, improves the underlying evaluation metrics: the memory and time consumption. The microclusters adopted in the proposed methods give the advantage of eliminating the need for range queries and in curbing the distance computations. In addition to only storing crucial inliers in memory, the microclusters also improve the memory constraints, since a single microcluster has the ability to obtain the neighborhood information of each object in the same cluster. In Figure 1, we can see that and , where is the current window and is the expired window. The fast-incoming data points from 1 to 23 are the data streams. By definition, the data stream is an unlimited number of data points within a specific timestamp or unbounded sequence. That is, the data stream , with t = time and , . Each within its window could have a neighbor or not, but it cannot be a neighbor on its own. The neighbor of any particular data point must not exceed the required distance threshold , from each other. For instance, in Figure 1, are neighbors of 3, while are neighbors of 19. The neighbors play a crucial role in the overall outlier detection process; therefore, we pay special attention to them.    Figure 2  The framework of CLODS In , or when the window slides, determining whether a data point is an outlier or inlier can create additional constraints due to the evolving nature of the data points. Some neighbors will expire, such as among , and become obsolete when the window slides. In the different window stages, the question of how to perform clustering, how to use minimal pruning to get the most significant data points, how to deal with incoming and expired , and what kind of clustering technique to apply comes up, and also, what requirements should the clustering technique meet to ensure that (1) the clusters capture more and (2) the inliers or outliers are detected correctly and computed with the lowest computational cost possible. 3.3. Problem Formulation Problem statement: the major goal of this paper is to present an improved solution to address the problem of effectively clustering and detecting outliers in fast-evolving data streams. For new data streams arriving continuously, with dimensionality at time , and with evolving feature changes as the data speed increases, we need to design a robust approach that will deal with the evolving data streams by clustering incoming data streams effectively and simultaneously detect all outliers in the shortest conceivable time, with low memory usage, while maintaining high detection accuracy. Also, we handle data points outside the clusters while dealing with the fading of old clusters, new and expired data points, and detecting the outliers. The key challenge is that the actively evolving data point position continues to change due to either the window slides or the arrival and expiration of some data points. This ultimately makes it complicating in addressing the overall problem. It will be a challenging task to process and remove data points one at a time as they arrive over the stream. It will incur a lot of time. In addition, managing memory space presents another challenge since it is not possible to predict how many data points arrive and expire a priori. It becomes challenging to cluster essential data points and dynamically allocate space for the growing number of unknown data points that arrive and expire. This brings us to the essential problem statement and question we address in this paper, how do we capture the data points that deviate from the others in streaming data which evolve as time progresses with these additional constraints: (i) The data point features might change over time. (ii) Prior unseen data point features might arrive over time. 4. The Proposed Methodology 4.1. Fundamentals of the Proposed Method As data originate from their source in the form of fast continuous evolving data streams, they become challenging to cluster data points and effectively detect the outliers, as explained in the problem statement. There is a need for special attention on the clustering method and in handling both the inliers and outliers in this scenario. To do this, we propose a new framework, which involves different stages in order to detect the outliers efficiently while maintaining high accuracy. The newly proposed method called Effective Microcluster and Minimal pruning CLustering-based method for Outlier detection in Data Streams (EMM-CLODS) is a kind of clustering-based outlier detection approach that detects outliers in evolving data streams using microcluster and minimal pruning. This is done by first applying a microclustering technique to cluster dense data points and effectively handle the data points according to the relevance of their status to their respective neighbors or position in the window. We adopt the sliding window model, and within this model, the microclustering technique helps to cluster dense data points quickly and eliminate the need for a range query search. For the data points outside the clusters, an approximate probing is implemented by excluding a set of inliers whose significance in the computation is trivial in order to reduce the computation demand. The CLODS makes use of both clustering and approximate probing of data points within the adopted sliding window model and minimal pruning of data points outside the clusters. It simultaneously discovers the outliers and deals with potential outliers outside the clusters, even when they continuously evolve as the data point changes state. In contrast to other conventional clustering-based approaches, it does not limit itself to detecting outliers in static data [ 2, 11, 27], and for those that support data streams, the clustering procedure is different [ 12, 20, 28, 29], or they are not clustering-based approaches [ 4, 8, 30]. Those with similar clustering techniques to ours use a different scheme to deal with data points within the window or adopt different window models [ 12, 27, 29]. Furthermore, the handling procedure of data points outside the microclusters is different. Unlike some of these methods [ 12, 20, 27, 28] that deal with every data point outside the microclusters equally, we focus especially on the relevance of data points with respect to its neighbors and position to determine its overall role in the outlier detection process. This is to ensure we identify potential outliers rather than data points that might be falsely labeled as outliers. This consequently saves time and memory constraints without a performance decline. 4.2. The Proposed Framework Figure 2 shows an illustrative representation of the proposed framework. At the onset, objects in the form of data streams arrive continuously and in an unprecedented manner. We first filter the data through data processing to determine its characteristics. Then, we process the preprocessed data in the sliding window model. During a specified period in the sliding window, we apply probing and clustering process together with pruning the data points outside the clusters and detect the outliers. During this phase, additional processing such as handling of crucial inliers and potential outliers, and handling of both active and expired data points as the window slides is done. In the final stage, the detected outliers are then reported.    Figure 3  The different phases of processing the outliers in the sliding window. Algorithm 1 gives the overall framework of CLODS, with line 3–5 depicting the processes. In Algorithms 2–4, details of algorithmic process are given to understand the whole CLODS algorithm. In Algorithm 5, we extend details of the different steps in Algorithm 1. In the first part, we perform preprocessing. The preprocessed data stream is then computed in the next stage. In processing data points within the window, in line 4 we determine whether they belong to a cluster. If not in a cluster, the relevance of their status with respect to the other members is checked in line 9. The data points outside the clusters and that are not relevant to their respective members can be applied to the function in the last stage and reported as an outlier as can be seen in line 11. In Algorithm 2, the processing of new data points in the new sliding window is shown. We first discover the cluster and if there is a data point within the cluster, we add the new data point or else initiate a new cluster accordingly (line 2–6), while in Algorithm 3, it shows the processing of the expired data. Similarly, as in 3, we first discover the cluster and if a data point is found in the cluster, we ensure that we check the relevance status to the other data points before we add it into the cluster (line 4-5). If not, we try to remove it (line 7). Lastly in Algorithm 4, we process and report the detected outliers. We first initialize the count (line 1), and if is not in any cluster and less number of neighbors to form a cluster, it is returned as an outlier. If it has already expired, it is then removed from data points outside the microclusters. Input: Preprocess Data Stream , Data point , Parameters: {distance-threshold , nearest-neighbor count , sliding size , Window Size .} Output: Outliers in sliding window (1) Procedure: (2) While the window slide or in ⊳ between period to when arrives (3) Deal with data within (4) Deal with new and (5) Deal with expired and . (6) Report outliers, Algorithm 1   The CLODS algorithm. (1) for in new slide, S do (2) c = discoverCluster (3) if in C then (4) c.add () (5) else (6) InitiateNewCluster () (7) else if (8) end for Algorithm 2  Process new data in the new slide window. (1) for in expired slide, S do (2) c = discoverCluster (3) if in C then (4) CheckRelevance () (5) c.add () (6) else (7) remove () (8) end If Algorithm 3  Process expired data point when slide expires. (1) Initiate outliers = [ ] (2) Perform all functions (3) for in , do (4) if cannot form a new cluster (5) add.Outlier () (6) else (7) Processfunctions (8) end if Algorithm 4  Process outlier . Input: Data Stream , Data point , Parameters: {distance-threshold , nearest-neighbor count , sliding size , window size .} Output: Outliers (1) Procedure: ⊳ Preprocessing (2) Perform Preprocessing ⊳ (3) for for each of preprocessed data in do (4) DiscoverInClusters (5) If neighbor then (6) InCluster Algorithm 5   Overall procedure of the CLODS. 4.3. The Data Stream Stage In a data stream model, the input data are not accessible through random disk or memory, such as in the case of static data or batch data in standard databases, but rather arrive in the form of one or more continuous data streams. A data stream is an unlimited number of sequence data points , within a specific timestamp or unbounded sequence with data points, . They are infinite series of data points, , observed at a particular time . The streaming data have the following characteristics: (i) The data points of streaming data arrive incrementally in real-time. The streaming data are active since all inbound objects/items trigger actions on the data rather than being invited to participate. (ii) The system has no control over the order or sequence in which the items of the streaming data arrive. (iii) The streaming data have the possibility of unbounded numbers of data points. The problem of detecting or mining outliers in such data with the abovementioned characteristics brings a number of significant implications. Firstly, to ensure that the results are continuously up-to-date, it is essential to analyze the incoming data within the shortest time and minimal memory usage. In the framework in Figure 3, the continuous infinite series of data points observed at a particular time is fed to the next stage. 4.4. Data Preprocessing Stage As the incoming unbounded sequence of data arrives, it is impossible to store the entire data stream. Besides, to apply the clustering technique without taking note of the characteristics of the data makes the overall process more tedious. Therefore, we initially did some preprocessing based on the nature of the data to avoid assumptions about having clean and well-structured data and to tailor the data for our propose model. For instance, real-world datasets are highly susceptible to missing and inconsistent data. Such datasets may give rise to data quality issues, which in turn affects the overall result. During the data preprocessing and wrangling phase, we deal with the missing data and inconsistent data. Although outliers sometimes can influence the quality of the data, in this work we entirely avoid dealing with outliers since our primary goal is to detect outliers. For the missing data, we ensure that we ignore, fill manually, and compute values. For inconsistent data, we normalize the necessary datasets. 4.5. Sliding Window-Based Outlier Detection Stage In this phase, we manage the evolving data streams; that is, we implement the CLODS and detect data points that deviate from their expected normal behavior when the window slides and expires, also when the data points will expire. We notice that it is not feasible to perform clustering on data streams during the all probable time. We handle the data points at different time windows. The process of exploring the evolving data stream during the different time windows provides the users with additional insights into the evolving nature and performance of the clusters. In terms of processing evolving data streams, different algorithms have adopted different window models. Some existing window models include the damped window model also known as the fading window model, the landmark window model, the tilted-time window model, and the sliding window model. In this paper, we use the sliding window model, in which the data are processed before the end of the streaming data window. This is as opposed to the landmark window model, which is adopted for cases where we want to mine the whole data stream history. It is suitable for static data settings. In the sliding window, the streaming data are considered from the current time to a certain range in its history. The key idea in the sliding window is to do exhaustive analysis of the most up-to-date data items and summarized the outdated items. As can be seen in Figure 3, in the second phase, we apply the clustering of the data stream in the sliding window model where data points expire as the window slides. Moreover, with an increasing time , each data points’ weight declines as it reaches the expiration point. In setting the window size for a distribution that fluctuates dynamically, we increased and set the window size large enough to minimize the effect caused by the dynamic change of the data. Consequently, this results in increased time usage, which undermines the performance of real-time computation. Eventually, it creates a challenge to find a balance between these two underlying issues. In Figure 3, as the time increases within the time frame, some data points fade out and some data points change state depending on the window slide. Some evolving data points expire, some clusters dissolve, and new ones are created, and some data points might be classified wrongly as an outlier. Therefore, in designing CLODS, we consider the following prerequisite: (i) Firstly, we consider the status of the data points, i.e., whether they are in a cluster or not and whether data points outside the cluster can be viewed as an inlier or outlier. (ii) Secondly, we consider the distance between the clusters and data points outside the clusters, whether they are far or close to the clusters, and whether they can be viewed as an outlier or inlier. (iii) Thirdly, we consider whether the data points share a relationship with few other data points that form a cluster, and also, how to handle both the data points within and out of the clusters to detect the outliers accurately. (iv) Finally, we consider the characteristics of the summary information, and at what instance we should store or discard the summary information, and what to do with expired data points. 4.6. CLODS Clustering Phase For a data stream with a set of continuous multidimensional data points , arriving at different period , we considered a set of active data points during the period , which are the most recent n data points at the time in the sliding window. During the active period, we employ the microcluster concept, which is a fast-efficient method for clustering objects within the sliding window. We applied the idea of triangular inequality in metric space [ 30, 31], to guarantee the data points’ distance between each other in the microclusters is less than the distance threshold . Thus, confirming that every data point is labeled as an inlier within the microcluster. Among the labeled inliers, we store in memory only crucial inliers to avoid memory congestion, and it is impossible to store every object in memory. We stored each newly arrived object in a fix size buffer. If the buffer is full, we consider each data point in it as an inlier or outlier, depending on the weight of the objects in relation to its distance to the other objects. The objects that are labeled as outliers are deleted in memory, while all newly incoming labeled inliers are maintained in the updated list. The different actions taken depend on the status of the data points in the different phases. Figure 3 shows the different stages in the window model, which is divided into three partitions with the x-axis displaying the arrival time of the data points, while the ordinate depicts the number of data points with radius . In the first partition, during the current window model space ( to ), we have a set of evolving data streams with fixed radius , and a neighbor count threshold from time interval . In this partition, for , the microcluster technique is applied to cluster data points for the objects in the window. These microclusters are data points within the radius of from the center and are not greater than the distance between the two data points. The window contains four microclusters, to with radius . The data points that are not within the microclusters are probable outliers depending on their status in relation to the other neighboring data points. To determine whether the probable data points will be labeled as an outlier or not, we consider both its ensuing and prior neighbors and, furthermore, its relative strength to its neighbors. Also, to consider which objects are stored in memory, we used a similar concept as in previous work [ 8] by storing the data points outside the microcluster in temporary memory while applying the minimal pruning to minimize the computational cost and demand. From Figure 3, the red marked data points show the outliers while the other data points, where , are marked in green. In the next phase, some data points change state due to the sliding of the window, the appearance of new data points, and the expiration of some data points. These new changes create new challenges for detecting the outliers smoothly as compared to the previous phase. In this case, we have three sliding windows. In the first window, we have a single microcluster, outliers, and a full cluster that has some data points that their status will be potentially affected during the next slide. In the next window, at the onset, although two objects have expired, it does not dissolve the microcluster since it has points. However, in the final window, the microcluster dissolves, which prompts the remaining data points to become outliers. When new data points arrive, they are added to their probable neighboring microclusters, provided it is not greater than the distance threshold . Otherwise, it is added to the neighboring outlier cluster with more space. If none of the conditions exist, then a new marked outlier cluster is initialized. In the final stage, the figure vividly shows the status of the different data points. The green data points indicate the inliers, yellow expired data points, the orange points are those that have the propensity to change state, and the red are the detected outliers. In terms of the memory usage, owing to the fast response and limited memory requirements in these kinds of environments, it is not practical to store the majority of the data, and it is impossible to store all the data in memory. Therefore, to salvage the situation, we minimize the memory consumption and stored relevant data points that aid the overall clustering and outlier detection process. Furthermore, we minimized the number of rearranged microclusters as the update in memory is done. As the continuous incoming data arrive, we first determined whether it is in memory or not. If not, it is added to the temporary memory, and then an initialization process is done. The key inliers are temporarily stored in memory, and as the data evolve due to changes in window slides, an update is done with new data points replacing the older ones. We calculated the number of inliers, and all expired data points are deleted from memory to free the memory space. Finally, summary statistical information is obtained, and the outliers are then reported. 4.7. Outlier Detection Stage The outlier detection process involves various phases. At the onset, we observe the potential outliers through the clusters. By definition, an outlier in an evolving data stream is a data point within the computational time frame that deviates from the clusters and lies beyond the distance threshold R with fewer than k neighbors in the dataset. In every window, data points that do not meet the deviation and threshold criteria are labeled as outliers, while the others are labeled as inliers. All potential outliers are initialized to one and stored in temporary memory. As new potential outliers accumulate, the longstanding vivid outliers stored in the outlier list are deleted from memory to free up space after processing. The detected outliers are reported, and the outlier list is updated. 5. Experiments and Results In this section, we describe the experimental settings including the datasets, parameter settings, evaluation metrics, and the baseline methods and discuss the performance of in comparison to the other models. 5.1. Experimental Setup 5.1.1. Environment We did our experiment using Java to design the source code and ran it on Eclipse Java EE IDE on a PC running Windows 10 Operating System with 3.20 GHz X4 CPU, 8 GB of RAM, and Disk Space of 230 GB. One of the baseline algorithms is from previous work [ 8], and the other was prepared by Tran et al. [ 32]. The source code of some baseline methods and all related datasets can be found on the online repository [ 32]. 5.1.2. Datasets We use similar benchmark datasets that have been adopted in some previous studies [ 8, 32]. As shown in Table 3, we use three real-world datasets and one synthetic dataset that are openly accessible. The first dataset is the Forest Covertype (FC) [ 7, 32] which is openly available and can be found from the UCI Machine Learning Repository and has 581,012 records with a high-dimensional range of 1–55 attributes. The dataset comprises tree observations from four zones of the Roosevelt National Forest in Colorado. It has no remote sensing, as the entire observations are cartographic variables from 30 m × 30 m sections of the forest. The FC dataset includes information on shadow coverage, tree type, distance to nearby landmarks, soil type, and local topography. The data are in raw form (not scaled) and contain binary (0 or 1) columns of data for qualitative independent variables (wilderness areas and soil types). Table 3  Datasets with default values. The second datasets adopted for our experiment are the tropical atmospheric ocean project (TAO) datasets [ 32, 33], which is a low-dimensional dataset with three attributes and 575, 648 records. The dataset is real-time data extracted from National Oceanic and Atmospheric Administration website [ 33]. TAO was established to get useful insights and forecast climate variations related to El Nino and the Southern Oscillation (ENSO). The phenomenon, ENSO, signifies the strongest year-to-year climate instability on the planet. Its events undoubtedly interrupt normal patterns of weather variability, thereby disturbing farming, transport, Pacific marine ecosystems, energy produce, and the livelihood of millions of people around the world. The Stock dataset has only one attribute, and it is available from UPenn Wharton Research Data Services [ 34] with 1,048,575 records. The dataset shows Stock trading traces of about 1 million transactions throughout the trading hours per day. Since the Wharton Research Data Services is not easily accessible, the available data can be found on the online repository [ 32] together with the other datasets used in this experiment. For the Synthetic dataset, we use the Gauss dataset [ 32]. The dataset is generated to produce streams with measured data distribution types and number of outliers. It is generated by mixing three Gaussian distributions and a random noise distribution, and it contains 1 million records with a single attribute. In each segment of the stream, the Gaussian distributed points and noise are randomly distributed. 5.1.3. Default Parameter Settings Before performing our experiment, we take into consideration the slide size , the window size , the distance threshold , and the neighboring count threshold . The window size is the key parameter which determines the volume of the data streams and number of accommodated clusters, while the slide S affects the speed and the remaining parameters help to determine whether the evolving data points are inliers or outliers or whether they belong to a cluster or not. The default value of , and is shown in Table 3 for the different datasets. 5.1.4. Evaluation Method We evaluated our method using three evaluation metrics: the running time, memory usage, and the clustering quality. The running time is the time taken to complete the detection of outliers for each window slide. The memory usage is the record of the peak memory used during the outlier detection process, including the storage data for each window. Lastly, the clustering quality defines how accurately our approach clusters the datasets. 5.1.5. Baseline Algorithms We chose three state-of-the-art algorithms, MCOD [ 4, 35] , MCMP for comparison with the CLODS. MCOD and were the best performing among the existing methods [ 36] until the hybrid approach called MCMP [ 8] was proposed, which uses the strength of both techniques to boost the performance in solving outlier detection problems. In MCMP, the key difference when compared to the other baseline methods is in dealing with data points within the current window. MCMP implement uses the concept of strong and trivial inliers of dealing with the objects outside the microclusters. in the majority cases is inferior to both MCOD and MCMP because of their lack of memory-efficient microclusters. It uses an index per slide for its neighbor search. Its minimal probing principle mitigates the expensive range queries and prioritizes the discovery of a minimal number of data points according to their arrival time. It has to continually re-evaluate and manage the data points in the updated list, which consequently increases its computational demand, while MCOD prunes out and minimizes outlier candidates. It uses an index structure called a microcluster that helps to prune out unqualified outlier candidates resourcefully. However, in MCOD, the absence of clearly distinguishing between the points outside the microclusters limits its potential to perform even better. Therefore, MCMP improves this shortcoming by using the strength of minimal probing and the memory-efficient microcluster and introduces the concept of trivial and strong inliers. This consequently improves the overall performance both in terms of reducing time and memory consumption. However, the improved performance comes at a cost, and we noticed that the absence of the extensive distance-based computation of data points outside the microclusters thus would lower the time and memory usage when we focus mainly on the clustering and deal with those points according to the relevance of their respective neighbors. For in-depth understanding of the baseline methods, we request our audience to read the individual references. 5.2. Results and Discussion 5.2.1. CPU Time In order to observe the CPU time usage, we take into consideration the following: we vary the window size W, the distance threshold , and the nearest neighbor count . Figure 4 shows the outcome of varying the window sizes , from 10k–20k for FC and TAO and then 10k–200k for Stock and Gauss. The results are shown for fixed and an approximate 1% outlier rate across the datasets. In Figure 4, for all datasets, in most cases as W increases which means more data points to cluster and compute, the CPU time also increases (Figures 4(a) and 4(c)) except for in Figures 4(b) and 4(c), and MCOD in Figure 4(d). The CLODS, similar to MCMP and MCOD in FC and TAO, shows a steady rise in all the datasets. However, in Gauss, when is above 50K, we observe a sharp spike for because fewer data points are captured since it does not have microclusters. Both CLODS and MCMP show the lowest CPU time usage when compared to the others since the use of index structures is absent. The CLODS ensures that significant inliers are stored in microclusters, which reduces the computational demand of performing range queries for every data point. Generally, we observe that when is large enough, there is a tiny effect on the streaming data whose distribution changes dynamically. Nevertheless, if becomes too large, then it will influence the responding time, and the time will greatly increase, which will, in turn, downgrade its performance.   (a)         (a)  (b)  (c)  (d)         Figure 4  CPU time-varying . (a) FC. (b) TAO. (c) Stock. (d) Gauss. Figure 5 illustrates the result of changing the neighbor count threshold k, from 1 to 100 across all the datasets. The results are shown for window size, W = 10K for FC and TAO and W = 100K for the remaining two datasets with other default parameters been maintained. In Figure 5, all the methods showed some changes across the different datasets since they depend on the neighbor count threshold k, which affects the outlier rate. From the figures, except for in TAO and Stock (Figures 5(b) and 5(c)), which demands more probing to find k, the other methods showed very good time consumption with CLODS showing superior performance in the majority of the dataset. This is because, in the first three datasets, there are not many data points that fall within the clusters that will require additional computation. For Figures 5(a) and 5(d), an increase in k shows an increase in the time since more probing needs to be done. In Figure 5(d), we see that MCMP slightly outperforms CLODS because few clusters demand additional computation. Overall, our approach performs well for the datasets that have points whose neighbors are close to each other, which makes it easy for clustering and thus makes it easy to differentiate between vivid or false outliers and crucial or insignificant inliers. Consequently, it shows better performance than the others since it can do the least computation possible outside the clusters. The likelihood of getting enough neighbors to ensure the fast clustering process is relatively low for datasets with sparse data points. Therefore, there are fewer clusters in the synthetic dataset, which also results in increased processing time when compared to the real-world datasets.   (a)         (a)  (b)  (c)  (d)         Figure 5  CPU time-varying . (a) FC. (b) TAO. (c) Stock. (d) Gauss. Figure 6 displays the result and performance of varying the slide size S, from 1% of W to 100% of W. The slide size depicts the changes in the speed of the data stream. Across all the datasets, the value of k and R is maintained as in Table 3. In Figure 6, we can see that across the datasets the CLODS shows the lowest CPU time usage, while incurs in the majority of the cases the highest CPU usage above that of MCOD and MCMP. In TAO and Stock datasets, we omit the trend of since the CPU time incurs far greater than the others, and for the other two cases, it shows an abnormal trend when compared to the others. The CLODS and the other algorithm show an increase with increase in . It confirms that an increase in results in arrival and expiration of more data points, thereby consuming additional time. However, the CLODS showed improved performance compared to that of MCMP since it uses less time than MCMP and MCOD that tries to update its neighbors after the detection of strong and trivial inliers and in identifying the outliers. In addition, we can observe that the processing of new arriving data points in CLODS scales well to that of the expired data points when the window size increases. In MCOD, for example, the time taken to process half of the data points outweighs the time for saving in discarding the expired data points. Overall, the slowest CPU time growth is shown across the datasets.   (a)         (a)  (b)  (c)  (d)         Figure 6  CPU time-varying . (a) FC. (b) TAO. (c) Stock. (d) Gauss. Figure 7 shows the effect of varying the distance threshold R through all the datasets, from 0–1000. The results are shown for slide size, S = 500 for the first two datasets and S = 5K for Stock and Gauss. The other parameters are maintained as shown in Table 3. In each dataset, when the value of R is varied, it influences the outlier rate. For Figures 7(c) and 7(d), incurs more time due to its trigger list, which makes it difficult to find neighbors. Overall, the CLODS showed better performance than the others and especially against MCMP since it has less distance computation when compared to MCMP that has to deal with strong and trivial inliers. The CLODS takes into consideration the relevance of K against each other rather than focusing on the influence of R. In Table 4, we notice that the outlier rate of R increases when default value of   (a)         (a)  (b)  (c)  (d)         Figure 7  CPU time-varying . (a) FC. (b) TAO. (c) Stock. (d) Gauss. Table 4  The outlier rate-varying 5.2.2. Memory Usage In Figure 8, as the window sizes increase, it shows that more data points need to be processed, which result in an increase in memory usage for the majority of the datasets. More inliers will be in the microclusters, crucial inliers will be stored in temporary memory, and the objects’ neighbors information will also be stored. From the figures, all the methods that make use of microclusters showed better performance across the datasets than , which does not have the memory-efficient microcluster. Across all the datasets, it consumes more memory since its trigger list has to be redone every time the slides expire. In Figure 8(d), the Gauss datasets have few neighbors, and it shows an increase in memory usage for the various methods when compared to the other datasets, since finding the neighbors consumes the temporary memory. Our approach shows almost the same performance as MCOD since there is not much computation outside the microclusters like that in MCMP, which incurs slightly more memory. The CLODS, in the majority of cases, showed the least memory consumption due to freeing up space by deleting in memory detected outliers and queuing in temporary memory only significant inliers that are outside the microclusters.   (a)         (a)  (b)  (c)  (d)         Figure 8  Memory-varying . (a) FC. (b) TAO. (c) Stock. (d) Gauss. When we vary the neighbor count threshold by increasing the value of k as shown in Figure 9, we expect more memory usage since k impacts the storing of the neighbors. For a few scenarios, it is almost stable, showing a small difference. For instance, in Figure 9(b), difference does not exceed 1MB for , likewise for the other datasets in the same figure. The CLODS among the algorithms showed superior performance in most cases due to it is not entirely depending on K, as in the case of MCOD and MCMP. As K increases, more data points are not in microclusters, thereby occupying the temporary memory. For MCMP, the process of differentiating between the inliers utilizes some memory, while the CLODS only keeps a significant inlier in memory temporarily. One notable difference is in Figures 9(a) and 9(d) for , which shows higher memory usage as compared to the others because of the neighbor count list that needs to be processed.   (a)         (a)  (b)  (c)  (d)         Figure 9  Memory-varying . (a) FC. (b) TAO. (c) Stock. (d) Gauss. In Figure 10, when we vary the distance threshold R, there is no constant observable trend across the datasets. Overall, the CLODS together with the other algorithms does not make use of range queries; therefore, an increase in R does not result proportionally to an increase in memory usage. Initially, more memory is used for MCOD and MCMP since not many data points can be found in microclusters, and the additional computation to find neighbors occupies the memory. The CLODS showed, in most cases, better performance to some degree since it does not differentiate every outliers or inlier as in the case of MCMP, so it uses less memory at the start. In most cases, the decline in memory usage is because an increase in the value of R translates to more neighbors, which result in more objects within the microclusters and fewer data points outside the microclusters. This thus curbs the memory utilization.   (a)         (a)  (b)  (c)  (d)         Figure 10  Memory-varying . (a) FC. (b) TAO. (c) Stock. (d) Gauss. Figure 11 shows the result of the memory usage when S increases. Across the datasets, the CLODS showed a decline in peak memory usage as S increases, likewise the other algorithms. The case shows unique performance, since it differs from the others in how it processes its data points. at the onset has higher peak memory consumption and continues to reduce further. The other memory-efficient microcluster algorithm including CLODS showed less memory consumption since it does not make use of trigger list as in . Thanks to their microclusters, the CLODS is slightly superior to that of MCMP in Figures 11(c) and 11(d), since storing the data points occupies the majority of the total memory. The absence of additional computation and to queue in memory trivial inliers gives it an advantage.   (a)         (a)  (b)  (c)  (d)         Figure 11  Memory-varying . (a) FC. (b) TAO. (c) Stock. (d) Gauss. 5.2.3. Space and Time Complexity The complexity of the algorithm defines the running time and storage space needed by the algorithm in terms of its input size. The space complexity signifies the amount of memory space required by CLODS in its life cycle. To calculate the worst-case space required by CLODS, we take into consideration the space required to store the data and variables that are independent of the size of the problem. In Tables 5 and 6, we show the time and space complexity of the algorithms. Table 5  Time complexity analysis results. Table 6  Space complexity analysis results. The time complexity in processing the data points within the current window in the worst-case scenario is the time cost of the function to discover whether the data point is in cluster or not, which is and in checking the relevance of the with respect to their neighbors in the sliding window. Since we are considering the worst-case scenario, we take into consideration the cost of computing this, which incurs higher cost than the processing of the new data points within the slide. The overall cost in this case is the cost of the data point in the window by the window slide size, that is . When the data points expire, in the worst-case, the process of removing expired data points within the slide does not cost as much as when we need to check the relevance of these objects and adding the data point if in cluster. In this case, the overall cost is . Therefore, the overall time complexity is which can be approximated to . The time complexity of CLODS is better than that of MCMP because in CLODS the cost of checking the relevance of the neighbors to their respective neighbors is less than that of MCMP cost, which incurs additional cost due to the cost of differentiating between the strong and trivial inliers. We can see that the overall time complexity of is which is approximately . This compared to the time complexity of the other two algorithms is almost the same as that of but superior to that of . The reduction in the time complexity of MCMP confirms that microcluster using the concept of minimal probing by differentiating the strong and trivial inlier reduces the extra time required for computing data points outside the clusters as it minimizes the time complexity of recalculating and evaluating the all the inliers, as in the case of . Since differentiating between the inliers also incurs some amount of cost, however, this cost is less compared to the other way around. In terms of the space complexity, a simple answer to the detection of continuous evolving outliers over streaming data in the window model will involve storing neighbors of each data object in the current window. It is apparent such computation in the worst-case will result in a quadratic space requirement ; therefore, for larger window size , it will be practically unfeasible. For each data point , instead of keeping all the preceding and succeeding neighbors , we store a number of neighbors and at most k data point will suffice to detect the outliers for specific and . The space complexity for managing data points within the current window is . We first calculate the size of the preceding neighbors that corresponds to the unexpired data points. When the size is less than , then is labeled as an outlier. When the window slides and expired, the space required to keep the neighbor counts is similar to that of MCMP, that is, since each data point within the window is not stored in for each slide. However, in CLODS with in-depth analysis, we could say that it will slight outperform MCMP since the space complexity needed in to store extra trivial inliers is less than that of saving relevant inliers in queue of the memory. The overall worst space complexity of CLODS is which is almost the same as that of except that in implies that during the expired window slides, the trivial inliers are stored in , with . Then, the number of data points within the window will be . That is, the list of data point in will be . From Table 6, we can see that space complexity is also better than that of and with and , respectively. It is evident that the space needed for differentiating the inliers is negligible and better off compared to the space needed for data points outside microclusters to save the extra trivial inliers. 5.2.4. The Quality of Data Points in the Clusters For clustering-based methods, an important metric to consider is the clustering quality, which affects the outlier detection rate in the data streams. Figure 12 shows the effectiveness and clustering quality of against previous methods that also adopted microclustering technique. For the FC dataset in Figure 12(a), the percentage of clusters is relatively low since the distance between each object is sparse. In another case, for the Gauss dataset, the percentage is almost zero, with little or no data points participating in the microclusters. This is because, in this particular window, the dataset has few neighbors. shows inferior clustering quality when compared to both and CLODS because of its extra distance-based computation that involves computing and storing the strong and trivial inliers. In some instances, it influences the neighbor count threshold k’s relationship of the points outside the microclusters. The CLODS overall showed better clustering quality in almost all cases due to the absence of the extra computation that is involved in , and it ensures that clusters are generally formed on the basis of their relevance to their respective neighbors’ position. This results in some cases of large percentage of data points discovered in the clusters, as can be seen in Figure 12 across the datasets.   (a)         (a)  (b)  (c)  (d)         Figure 12  Comparison of the average percentage of data points in microclusters for , , and when we vary . (a) FC. (b) TAO. (c) Stock. (d) FC. 5.2.5. Advantages of CLODS CLODS through experiments has shown to outperform the existing methods in most cases and succeeded in curbing the computational cost in terms of the time taken and memory usage. It is a general solution used as a clustering-based outlier detection method for clustering evolving data streams based on microclusters and handling of objects within a sliding window according to the relevance of their status to their respective neighbors or position, excluding extended extra distance-based computation. The CLODS dynamically clusters data streams and offers support to meet flexible mining requirements. Furthermore, it has shown robustness in the variation of the different performance parameters and its clustering quality with regard to the number of data points in its clusters. Finally, it has shown to be an effective method for detecting outliers. 6. Conclusion Detecting outliers, which is the process of mining abnormal events from data, is a significant and challenging task. In this paper, we have proposed a clustering-based method called EMM-CLODS to address the problem of detecting outliers in continuous evolving data streams. The proposed method adopts the microcluster technique to group similar data points that are in proximity in the streaming data. It minimized the computational demand and showed an increase in the computational speed while it still maintained its effectiveness to detect outliers in the sliding window through minimal computation of data points outside the microclusters. It terms of its memory usage, not all objects outside the microclusters were stored in memory, and likewise, expired outlier data points were deleted from memory to minimize the memory usage. From the experiments performed on both real and synthetic datasets, our method showed effectiveness in detecting outliers for continuous evolving data streams. In the majority of the cases, it shows superior performance in terms of both CPU and memory utilization when compared to the other baseline algorithms. It has shown to be a good technique for detection outliers in data streams as it is robust to the various parameter variations (, , and ). Data Availability The data and source code used to support the findings of this study have not been made available. However, all the datasets except for the source code used have been clearly explained in the experimental section with links of where to directly access these data. Previously reported (FC, TAO, Stock, and Gauss) data were used to support this study and are available at http://infolab.usc.edu/Luan/Outlier/. These prior studies (and datasets) are cited at relevant places within the text. Disclosure Mohamed Jaward Bah, Hongzhi Wang, Li-Hui Zhao, and Ji Zhang are co-first authors. Conflicts of Interest The authors declare that they have no conflicts of interest regarding this work. Acknowledgments The authors would like to thank the support from the Postdoctoral Fund of Hangzhou City (no. 119001-UB2101SJ), PI Research Project of Zhejiang Lab (no. 111007-PI2001), Natural Science Foundation of China (no. 62172372 and no. U1866602), and Zhejiang Provincial Natural Science Foundation (no. LZ21F030001). References V. Chandola, A. Banerjee, and V. Kumar, “Anomaly detection: A survey,” ACM Computing Surveys (CSUR), vol. 41, pp. 1–58, 2009. View at: Publisher Site | Google Scholar X. Su and C. L. Tsai, “Outlier detection,” WIREs Data Mining and Knowledge Discovery, vol. 1, no. 3, pp. 261–268, 2011. View at: Publisher Site | Google Scholar Ji Zhang, “Advancements of outlier detection: a survey,” ICST Transactions on Scalable Information Systems, vol. 13, pp. 1–26, 2013. View at: Publisher Site | Google Scholar L. Cao, Di Yang, Q. Wang, Y. Yu, J. Wang, and E. A. Rundensteiner, “Scalable distance-based outlier detection over high-volume data streams,” in Proceedings of the 2014 IEEE 30th International Conference on Data Engineering, pp. 76–87, IEEE, Chicago, IL, USA, April 2014. View at: Publisher Site | Google Scholar S. Guha, M. Adam, N. Mishra, R. Motwani, and L. O’Callaghan, “Clustering data streams: theory and practice,” IEEE Transactions on Knowledge and Data Engineering, vol. 15, pp. 515–528, 2003. View at: Publisher Site | Google Scholar Y. Chen and Li Tu, “Density-based clustering for real-time stream data,” in Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 133–142, San Jose, CA, USA, August 2007. View at: Publisher Site | Google Scholar S. Hettich and S. D. Bay, The UCI KDD Archive Irvine, Department of Information and Computer Science, University of California, Irvine, CA, USA, 1999, http://kdd.ics.uci.edu. M. J. Bah, H. Wang, H. Mohamed, F. Zeshan, and H. Aljuaid, “An effective minimal probing approach with micro-cluster for distance-based outlier detection in data streams,” IEEE Access, vol. 7, pp. 154922–154934, 2019. View at: Google Scholar L. Cao, J. Wang, and E. A. Rundensteiner, “Sharing-aware outlier analytics over high-volume data streams,” in Proceedings of the 2016 International Conference on Management of Data, pp. 527–540, San Francisco, CA, USA, July 2016. View at: Publisher Site | Google Scholar J. Tamboli and M. Shukla, “A survey of outlier detection algorithms for data streams,” in Proceedings of the 2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom), pp. 3535–3540, IEEE, New Delhi, India, March 2016. View at: Google Scholar H. Wang, M. J. Bah, and M. Hammad, “Progress in outlier detection techniques: a survey,” Ieee Access, vol. 7, pp. 107964–108000, 2019. View at: Publisher Site | Google Scholar C. C. Aggarwal, P. S. Yu, J. Han, and J. Wang, “A framework for clustering evolving data streams,” in Proceedings 2003 VLDB Conference, pp. 81–92, Berlin, Germany, September 2003. View at: Publisher Site | Google Scholar P. Caroline Cynthia and S. Thomas George, “An outlier detection approach on credit card fraud detection using machine learning: a comparative analysis on supervised and unsupervised learning,” in Intelligence in Big Data Technologies—Beyond the Hype, J. Dinesh Peter, S. L. Fernandes, and A. H. Alavi, Eds., pp. 125–135, Springer Singapore, Singapore, 2021. View at: Publisher Site | Google Scholar M. E. Villa-Pérez, M. Á. Álvarez-Carmona, O. Loyola-González, M. A. Medina-Pérez, J. C. Velazco-Rossell, and K.-K. R. Choo, “Semi-supervised anomaly detection algorithms: a comparative summary and future research directions,” Knowledge-Based Systems, vol. 218, Article ID 106878, 2021. View at: Publisher Site | Google Scholar F. Liu, S. Xue, J. Wu et al., “Deep learning for community detection: progress, challenges and opportunities,” in Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, Yokohama, Japan, July 2020. View at: Publisher Site | Google Scholar X. Su, S. Xue, F. Liu et al., “A comprehensive survey on community detection with deep learning,” 2021. View at: Google Scholar A. Boukerche, L. Zheng, and A. Omar, “Outlier detection: methods, models, and classification,” ACM Computing Surveys, vol. 53, no. 3, 2020. View at: Publisher Site | Google Scholar X. Ma, J. Wu, S. Xue, J. Yang, Z. S. Quan, and H. Xiong, “A comprehensive survey on graph anomaly detection with deep learning,” 2021, http://arxiv.org/abs/2106.07178. View at: Google Scholar G. Pang, C. Shen, L. Cao, and A. Van Den Hengel, “Deep learning for anomaly detection: a review,” ACM Computing Surveys (CSUR), vol. 54, pp. 1–38, 2021. View at: Publisher Site | Google Scholar D. Toshniwal and Yokita, “A framework for outlier detection in evolving data streams by weighting attributes in clustering,” Procedia Technology, vol. 6, no. 2012, pp. 214–222, 2012. View at: Google Scholar A. Zhou, F. Cao, W. Qian, and C. Jin, “Tracking clusters in evolving data streams over sliding windows,” Knowledge and Information Systems, vol. 15, no. 2, pp. 181–214, 2008. View at: Publisher Site | Google Scholar F. Cao, M. Estert, W. Qian, and A. Zhou, “Density-based clustering over an evolving data stream with noise,” in Proceedings of the 2006 SIAM International Conference on Data Mining, pp. 328–339, SIAM, Bethesda, MD, USA, April 2006. View at: Publisher Site | Google Scholar L.-x. Liu, Y.-f. Guo, J. Kang, and H. Huang, “A three-step clustering algorithm over an evolving data stream,” in Proceedings of the 2009 IEEE International Conference on Intelligent Computing and Intelligent Systems, pp. 160–164, IEEE, Shanghai, China, November 2009. View at: Publisher Site | Google Scholar M. Kumar and A. Sharma, “Mining of data stream using “DDenStream” clustering algorithm,” in Proceedings of the 2013 IEEE International Conference in MOOC, Innovation and Technology in Education (MITE), pp. 315–320, IEEE, Jaipur, India, December 2013. View at: Google Scholar A. Amini and T. Y. Wah, “A comparative study of density-based clustering algorithms on data streams: micro-clustering approaches,” in Intelligent Control and Innovative Computing, pp. 275–287, Springer, Berlin, Germany, 2012. View at: Publisher Site | Google Scholar A. Amini, T. Y. Wah, and Y. W. Teh, “DENGRIS-Stream: A density-grid based clustering algorithm for evolving data streams over sliding window,” in Proceedings of the International Conference on Data Mining and Computer Engineering, pp. 206–210, Visakhapatnam, India, January 2012. View at: Google Scholar L. Duan, L. Xu, Y. Liu, and J. Lee, “Cluster-based outlier detection,” Annals of Operations Research, vol. 168, pp. 151–168, 2009. View at: Publisher Site | Google Scholar M. Elahi, K. Li, W. Nisar, X. Lv, and H. Wang, “Efficient clustering-based outlier detection algorithm for dynamic data stream,” in Proceedings of the 2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery, pp. 298–304, IEEE, October 2008, Jinan, China. View at: Publisher Site | Google Scholar A. Forestiero, C. Pizzuti, and G. Spezzano, “A single pass algorithm for clustering evolving data streams based on swarm intelligence,” Data Mining and Knowledge Discovery, vol. 26, no. 1, pp. 1–26, 2013. View at: Publisher Site | Google Scholar M. S. Sadik and L. Gruenwald, “DBOD-DS: distance based outlier detection for data streams,” in International Conference on Database and Expert Systems Applications, pp. 122–136, Springer, Berlin, Germany, 2010. View at: Publisher Site | Google Scholar M. B. Al-Zoubi, “An effective clustering-based approach for outlier detection,” European Journal of Scientific Research, vol. 28, no. 2, pp. 310–316, 2009. View at: Google Scholar L. Tran, L. Fan, and C. Shahabi, Distance-Based Outlier Detection in Data Streams Repository, Information Laboratory University of Southern California, Los Angeles, LA, USA. Pacific Marine Environmental Laboratory. 2019. Wharton University of Pennsylvania. https://infolab.usc.edu/Luan/Outlier/Datasets/tao.txt. Wharton Research Data Services, Distance-Based Outlier Detection in Data Streams Repository, Wharton Research Data Services, Philadelphia, PA, USA, 2020, https://wrds-web.wharton.upenn.edu/wrds/. M. Kontaki, A. Gounaris, A. N. Papadopoulos, K. Tsichlas, and Y. Manolopoulos, “Continuous monitoring of distance-based outliers over data streams,” in Proceedings of the 2011 IEEE 27th International Conference on Data Engineering, pp. 135–146, IEEE, Hannover, Germany, April 2011. View at: Publisher Site | Google Scholar M. Shukla, Y. P. Kosta, and P. Chauhan, “Analysis and evaluation of outlier detection algorithms in data streams,” in Proceedings of the 2015 International Conference on Computer, Communication and Control (IC4), pp. 1–8, IEEE, Indore, India, September 2015. View at: Google Scholar Copyright Copyright © 2021 Mohamed Jaward Bah et al. This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. PDF Download Citation Download other formats Order printed copies Views 383 Downloads 733 Citations 2 About Us Contact us Partnerships Blog Journals Article Processing Charges Print editions Authors Editors Reviewers Partnerships Hindawi XML Corpus Open Archives Initiative Fraud prevention Follow us: Privacy PolicyTerms of ServiceResponsible Disclosure PolicyCookie PolicyCopyrightModern slavery statementCookie Preferences

Paper 8:
- APA Citation: Tortorici, O., Péraud, C., Anthierens, C., & Hugel, V. (2024). Automated Deployment of an Underwater Tether Equipped with a Compliant Buoy–Ballast System for Remotely Operated Vehicle Intervention. Journal of Marine Science and Engineering, 12(2), 279.
  Main Objective: To develop and evaluate a new automated system for managing the length of an underwater tether used to connect a remotely operated vehicle (ROV) to the surface.
  Study Location: Unspecified
  Data Sources: ['Strain gauge', 'Flex sensor']
  Technologies Used: ['Flex sensor', 'Strain gauge', 'Winch']
  Key Findings: ['The proposed system is effective in maintaining a desired tether length, even in the presence of external disturbances']
  Extract 1: 
  Extract 2: 
  Limitations: >
  Relevance Evaluation: {'extract_1': 'This paper presents a mechatronic solution for ROV deployment in which the length of the cable that connects the robot to the surface is automatically controlled. This solution consists of designing and setting up a balanced and compliant buoy–ballast system for the cable, which allows the cable feeder to be controlled using the readings from the flex sensor placed along a part of the cable near the ballast.', 'extract_2': 'The simulations and the experiments conducted with a BlueROV and a neutral cable demonstrated the validity of the concept.', 'relevance_score': 1.0}
  Relevance Score: 1.0
  Inline Citation: (Tortorici, Péraud, Anthierens, & Hugel, 2024)
  Explanation: This paper presents a novel system for managing the length of an underwater tether used to connect a remotely operated vehicle (ROV) to the surface. The system consists of a balanced and compliant buoy-ballast system, which is attached to a specific location on the tether. The position of the buoy-ballast system and the tension in the tether are then measured using a flex sensor and a strain gauge, respectively. This information is used to control the speed of a surface-mounted winch, which winds or unwinds the tether to maintain the desired length. The proposed system has several advantages over existing tether management systems, including the ability to operate in both slack and taut cable modes, the ability to automatically adjust the tether length based on the ROV's speed and depth, and the ability to prevent the tether from snagging or becoming entangled with the ROV or other objects. Experimental results show that the proposed system is effective in maintaining a desired tether length, even in the presence of external disturbances.

 Full Text: >
"This website uses cookies We use cookies to personalise content and ads, to provide social media features and to analyse our traffic. We also share information about your use of our site with our social media, advertising and analytics partners who may combine it with other information that you’ve provided to them or that they’ve collected from your use of their services. Consent Selection Necessary Preferences Statistics Marketing Show details                 Deny Allow selection Allow all    Journals Topics Information Author Services Initiatives About Sign In / Sign Up Submit   Search for Articles: Journal of Marine Science and Engineering (JMSE) All Article Types Advanced   Journals JMSE Volume 12 Issue 2 10.3390/jmse12020279 Submit to this Journal Review for this Journal Propose a Special Issue Article Menu Academic Editor Cristiano Fragassa Subscribe SciFeed Recommended Articles Related Info Link More by Authors Links Article Views 788 Table of Contents Abstract Introduction Modeling of The Compliant Buoy–Ballast Sensing System Simulations Description of Setup, Control Mode, and ROV Trajectories for Real Experiments Results And Discussion Conclusions Author Contributions Funding Informed Consent Statement Data Availability Statement Acknowledgments Conflicts of Interest Appendix A. Statics Analysis of the Buoy–Ballast System References share Share announcement Help format_quote Cite question_answer Discuss in SciProfiles thumb_up Endorse textsms Comment first_page settings Order Article Reprints Open AccessArticle Automated Deployment of an Underwater Tether Equipped with a Compliant Buoy–Ballast System for Remotely Operated Vehicle Intervention by Ornella Tortorici 1, Charly Péraud 2, Cédric Anthierens 2 and Vincent Hugel 2,* 1 Institute for Mechatronics in Mechanics, 21073 Hamburg, Germany 2 COSMER, Université de Toulon, 83041 Toulon, France * Author to whom correspondence should be addressed. J. Mar. Sci. Eng. 2024, 12(2), 279; https://doi.org/10.3390/jmse12020279 Submission received: 10 January 2024 / Revised: 31 January 2024 / Accepted: 1 February 2024 / Published: 3 February 2024 (This article belongs to the Special Issue Advances in Underwater Robots for Intervention) Download keyboard_arrow_down     Browse Figures Versions Notes Abstract Underwater remotely operated vehicles (ROVs) are linked to the surface through a tether that is usually controlled by a human operator. The length of the tether being deployed in the water in real time is a critical determinant of the success of the mission, and the problems of entanglement and cable stretching must be anticipated to the greatest possible extent. This paper describes a low-cost and setup-friendly solution for managing the length of a neutrally buoyant tether using a balanced buoy–ballast system implemented on the part of the tether proximal to the ROV. Embedded in the system is a curvature sensor that helps to control the cable feeder on the surface. This represents a useful solution for smoothing tether movements and to damp external disturbances. The results of experiments carried out in water tanks demonstrate the benefits of this solution in allowing the cable to maintain a semi-stretched shape while ensuring that the ROV avoids being pulled by the cable. Possible applications for a surface vehicle linked to an ROV through a tether equipped with this compliant buoy–ballast system include exploration or cartography missions in shallow waters. Keywords: underwater robotics; tethered robot; buoy–ballast system; length control 1. Introduction Most underwater exploration and inspection tasks are achieved by remotely operated vehicles (ROVs), whose maneuverability and reliability are at the heart of a mission’s success [1,2]. Maintenance missions include the inspection of ship hulls, pontoons, offshore wind farms, oil platforms, risers, and seabed pipelines as well as all artificial sensing structures integrated in the oceans for monitoring the seas or conducting physics experiments, such as the neutrino telescope in the Mediterranean Sea [3]. ROVs are linked to a surface control vessel by a tether that can transmit data and even supply power if necessary [4,5]. However, the tether is likely to apply undesirable forces on the ROV through its attachment point [6,7], which can affect the ROV’s mobility and its planned trajectory while increasing power consumption [8,9,10,11]. Tether constraints are even more important for small and less powerful ROVs, which are also widely used in shallow waters. A slack, passive tether increases the risk of entanglement and seabed drag, resulting in premature wear [12,13,14]. To take advantage of the cables linked to underwater robots, a control system for varying cable length is required. One of the main challenges in underwater robotics is to provide robots with more navigation autonomy and maneuverability, whereas tether deployment remains under the control of a skilled human operator. In the literature, there exist three main solutions for the management of subsea tethers, namely involving tether customization/instrumentation, use of surface winches, or use of an underwater tether management system (TMS), which can be implemented by an auxiliary robot. Tethers are often customized by buoys and ballasts to change their buoyancy, shape, or behavior [7,15,16]. Such systems are passive, and their positive impact on cable management is limited when they are not used in conjunction with active length control. Cables can also be fitted with external or internal sensors to monitor their behavior and shape, e.g., taking measurements at several specific nodes along the cable through inertial or tension sensors [7,17] or continuously along the entire cable through embedded fiber optic solutions [18,19,20]. The first solution generates an irregular shape, whereas the second can be very expensive. Surface winches are used for cable winding and unwinding and are often operated either manually or simply based on cable tension [21,22]. They are commonly placed on the surface vessel, but they can also be embedded on the ROV itself, which involves technological challenges [15]. tether management systems (TMSs) are widely used for deep water systems [1,23,24,25]. Located between the surface and the ROV, they manage the portion of the cable connected to the ROV. They are usually combined with a depressor weight to limit the transmission of heave motion from the surface vessel to the ROV via the tether. An auxiliary ROV can also play the role of a TMS [2]. It can be remotely controlled by an operator or automatically manage the shape of passive weighing cables [26]. However, this solution introduces the potential risk of collision between the robots. This paper presents a mechatronic solution for automating the deployment of a tether that links a remotely operated vehicle to the surface while limiting unwanted disturbances to the ROV. This solution is designed to be installed easily on an existing neutrally buoyant and lightweight cable. It is a low-cost solution that consists of combining two buoys and a ballast located between the buoys, and a flex sensor is mounted at the ballast. The buoy–ballast system is also built to be neutrally buoyant and behave as a compliant system in preventing the ROV from being pulled by the cable and enabling active cable management using the flex sensor. Unlike most existing solutions designed for weighing cables, the system presented in this article is original and suitable for neutrally buoyant cables, which do not carry energy. Alternative solutions for lightweight neutral cables include the use of a force sensor at the end of the winding/unwinding unit. However, these solutions are expensive, and the instrumented winch system must be carefully designed. In addition, the longer the cable, the more difficult it will be for these solutions to acquire information about the cable tension state on the ROV side. The contributions of this work include the following: The modeling, design, and implementation of the compliant-actuated system to equip the tether, which is composed of two symmetric buoys, one ballast, and one flex sensor located at the ballast; Tether length control by the feeder system on the surface, used to maintain the tether in a semi-stretched shape according to flex sensor feedback from the ROV; Simulations and real experiments to validate the solution by employing a compact underwater vehicle and a neutrally buoyant tether. The paper is organized as follows. Section 2 focuses on the modeling of the buoy–ballast sensing system. Section 3 describes the simulations that were conducted to test the system. Section 4 details the system setup, sensor layout, control scheme, and experimental trajectories carried out in water pools. Section 5 is dedicated to the discussion of the results. 2. Modeling of The Compliant Buoy–Ballast Sensing System 2.1. Neutral Buoyancy of The Buoy–Ballast System Given a neutrally buoyant tether, the static equilibrium of the buoy–ballast system, namely the V-system, depends on the apparent weights of the buoys and the ballast. The ballast is placed between the two identical buoys on the cable (Figure 1). In order to ensure a neutral balance, the apparent weight of the ballast must be compensated by the apparent weights of the buoys: 𝑊 𝑏𝑢𝑜𝑦 = | 𝜌 𝑏𝑢𝑜𝑦 − 𝜌 𝑤 |. 𝑉 𝑏𝑢𝑜𝑦 .𝑔=( 𝜌 𝑤 − 𝜌 𝑏𝑢𝑜𝑦 ). 𝑉 𝑏𝑢𝑜𝑦 .𝑔 (1) 𝑊 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 = ( 𝜌 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 − 𝜌 𝑤 ). 𝑉 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 .𝑔=2. 𝑊 𝑏𝑢𝑜𝑦 (2) where 𝑊 𝑏𝑢𝑜𝑦 and 𝑊 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 stand for the gravity forces minus the buoyancy of the buoy and ballast, respectively. 𝜌 𝑏𝑢𝑜𝑦 , 𝜌 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 , and 𝜌 𝑤 are the density of the buoy, ballast, and water, respectively. 𝑉 𝑏𝑢𝑜𝑦 and 𝑉 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 designate the volumes of the buoy and the ballast, respectively. g is the gravity constant. Figure 1. The compliant buoy–ballast system mounted on a neutrally buoyant cable. The ballast is chosen from among off-the-shelf spherical weights, and the volume of the buoy is adjusted by machining it into a cuboid shape with rounded edges, since it is made of foam (LAST-A-FOAM® R-3318), taking into account the following equation obtained from the above equations: 𝑉 𝑏𝑢𝑜𝑦 = 1 2 . 𝜌 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 − 𝜌 𝑤 𝜌 𝑤 − 𝜌 𝑏𝑢𝑜𝑦 . 𝑉 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 (3) 2.2. Drag Forces In steady state, the velocities of the buoys and ballast are considered constant, and a static analysis is conducted to estimate the relationship of the distance between the buoys as a function of the drive speed. The forces exerted by the fluid on the buoys and the ballast depend on the type of flow, which can be laminar, turbulent, or in a transitional state between both. Usually, the moving object’s related Reynolds number is used to identify the type of water flow around the object, regardless of whether it creates turbulence: 𝑅𝑒 = 𝜌 𝑤 .𝑣.𝐿 𝜇 (4) where v is the relative speed between the object and the fluid, 𝜇 is the water viscosity, which is approx. 10 −3 kg/m/s at 20 °C, and L is the characteristic length of the object, perpendicular to the direction of motion, such as for the diameter of a sphere. For a Reynolds number below 10, the flow can be considered as laminar, which is the case for very small objects. Above 10 6 , the flow is turbulent at the surface and behind the object. Between 10 and 10 6 , the flow can be either laminar or turbulent, or in a transitional state. The order of magnitude of a 4 cm long compact buoy or ballast, moving at the average speed of 0.5 m/s is 𝑅𝑒 = 10 3 0.54. 10 −2 10 −3 ≈2. 10 4 (5) When the water flow is laminar, the drag force 𝐹 𝑙𝑎𝑚 𝑑 is proportional to the velocity, where the drag force in turbulent flow is quadratic, namely 𝐹 𝑡𝑢𝑟𝑏 𝑑 . The formulae for these two forces are given below. 𝐹 𝑙𝑎𝑚 𝑑 = 𝑘.𝜇.𝑣 (6) 𝐹 𝑡𝑢𝑟𝑏 𝑑 = 1 2 . 𝐶 𝐷 .𝐴. 𝜌 𝑤 . 𝑣 2 (7) where k is a coefficient that depends on the shape of the object. For a sphere of radius R, 𝑘=6𝜋.𝑅 . 𝐶 𝐷 is the dimensionless quadratic drag coefficient, which is a property of the object. For a spherical shape, 𝐶 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 𝐷 ≈0.47 , and for a cuboid shape, 𝐶 𝑏𝑢𝑜𝑦 𝐷 ≈1.05 . A is the cross-sectional area of the object, perpendicularly to the motion, which can be approximated by 𝜋. 𝑅 2 /2 , with 𝑅=𝐿/2 . 2.3. Distance Versus Speed in Steady-State Mode Figure 2 presents the scheme of the buoy–ballast V-shape model, showing the forces exerted on the buoys and ballast. It is assumed that the entire system moves at a constant velocity v driven by the ROV in the left–right direction. Figure 2. Model of the buoy–ballast V-system. The buoys and ballast move at the same constant speed. The total number of independent equations that govern the force compensation of the elements of the V-shape system at constant speed is 7 (detailed in Appendix A), which are 𝑇 𝑥 𝐵1 = 𝐹 𝑏𝑢𝑜𝑦 𝑑 + 𝑇 1 (8) 𝑇 𝑦 𝐵1 =− 𝑊 𝑏𝑢𝑜𝑦 (9) 𝑇 𝑥 𝐵2 =− 𝐹 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 𝑑 − 𝐹 𝐶 𝐵 1 𝑑 − 𝐹 𝐶 𝐵 2 𝑑 − 𝐹 𝑏𝑢𝑜𝑦 𝑑 𝑇 1 (10) 𝑇 𝑦 𝐵2 =− 𝑊 𝑏𝑢𝑜𝑦 (11) 𝑇 2 =2. 𝐹 𝑏𝑢𝑜𝑦 𝑑 + 𝐹 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 𝑑 (12) ( 𝐹 𝑏𝑢𝑜𝑦 𝑑 + 𝑇 1 + 1 2 . 𝐹 𝐶 𝐵 1 𝑑 ).ℓ.cos 𝜃 1 − 𝑊 𝑏𝑢𝑜𝑦 .ℓ.sin 𝜃 1 =− 𝐶 𝑠 [2( 𝜋 2 − 𝜃 1 )+( 𝜋 2 + 𝜃 2 )] −( 𝐹 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 𝑑 + 𝐹 𝑏𝑢𝑜𝑦 𝑑 + 𝑇 1 + 𝐹 𝐶 𝐵 1 𝑑 + 1 2 . 𝐹 𝐶 𝐵 2 𝑑 ).ℓ.cos 𝜃 2 − 𝑊 𝑏𝑢𝑜𝑦 .ℓ.sin 𝜃 2 (13) = 𝐶 𝑠 [2( 𝜋 2 + 𝜃 2 )+( 𝜋 2 − 𝜃 1 )] (14) where 𝑇 𝑥 𝐵1 and 𝑇 𝑦 𝐵1 are the components of the force 𝐓 𝐁𝟏 that is exerted by the cable portion 𝐶 𝐵 1 of length ℓ onto the left buoy. 𝑇 𝑥 𝐵2 and 𝑇 𝑦 𝐵2 are the components of the force 𝐓 𝐁𝟐 that is exerted by the cable portion 𝐶 𝐵 1 of length ℓ onto the right buoy. 𝐹 𝑏𝑢𝑜𝑦 𝑑 is the intensity of the drag force exerted by the fluid on the buoy. 𝐹 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 𝑑 is the intensity of the drag force exerted by the fluid on the ballast. 𝐹 𝐶 𝐵 1 𝑑 and 𝐹 𝐶 𝐵 2 𝑑 are, respectively, the intensity of the drag force exerted by the fluid on the cable portion 𝐶 𝐵 1 and 𝐶 𝐵 2 . 𝐶 𝑠 is the bending stiffness coefficient of the cable. 𝜃 1 and 𝜃 2 are, resp., the vertical angle of the 𝐶 𝐵 1 cable portion and the 𝐶 𝐵 2 cable portion. 𝑇 1 is the magnitude of the horizontal scalar force exerted by the cable that links the left buoy to the remote station. 𝑇 2 is the horizontal scalar force exerted by the cable that links the right buoy to the ROV. In the case of the figure, the intensity 𝑇 2 is positive since the ROV pulls on the cable to move from left to right. The drag force magnitudes 𝐹 𝐶 𝐵 1 𝑑 and 𝐹 𝐶 𝐵 2 𝑑 are calculated as follows, based on the diameter 𝑑 𝑐 of the cable 𝐹 𝐶 𝐵 1 𝑑 𝐹 𝐶 𝐵 2 𝑑 = = 1 2 . 𝐶 𝑐𝑎𝑏𝑙𝑒 𝐷 . 𝑑 𝑐 .ℓ.cos 𝜃 1 . 𝜌 𝑤 . 𝑣 2 1 2 . 𝐶 𝑐𝑎𝑏𝑙𝑒 𝐷 . 𝑑 𝑐 .ℓ.cos 𝜃 2 . 𝜌 𝑤 . 𝑣 2 where 𝐶 𝑐𝑎𝑏𝑙𝑒 𝐷 is dependent on the ratio of length to diameter. The forces exerted on the portion of cable from the station to 𝐵 1 are the drag force, namely 𝑇 𝑑 1 , and the resisting force exerted by the winch on the station side, namely 𝑇 1𝑐 , which depends on the design of the feeder rotary joint. Since the cable is neutrally buoyant, there is no horizontal tension caused by apparent gravity (which would exist in the case of a weighing cable that takes the shape of a catenary in resting mode). 𝑇 1 = 𝑇 𝑑 1 + 𝑇 1𝑐 where 𝑇 1𝑐 is considered as a constant in the steady-state mode, whereas 𝑇 𝑑 1 can be expressed as 𝑇 𝑑 1 = 1 2 𝐶 𝑐𝑎𝑏𝑙𝑒 𝐷 . 𝑑 𝑐 .𝑑ℎ. 𝜌 𝑤 . 𝑣 2 where 𝑑ℎ is the depth offset between 𝐵 1 and the other extremity of the cable on the station side. Equations (13) and (14) can be numerically solved for 𝜃 1 and 𝜃 2 to obtain the evolution of the inter-buoy distance 𝑑=ℓ(sin 𝜃 1 −sin 𝜃 2 ) as a function of the velocity v (see Section 3.3). After linearization using small angles, the horizontal distance d between the buoys can be calculated as 𝑑 ≈ ℓ( 𝜃 1 − 𝜃 2 ) (15) ≈ ℓ. ℓ( 𝐹 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 𝑑 +2. 𝐹 𝑏𝑢𝑜𝑦 𝑑 +2. 𝑇 1 + 3 2 𝐹 𝐶 𝐵 1 * 𝑑 + 1 2 𝐹 𝐶 𝐵 2 * 𝑑 )+3𝜋. 𝐶 𝑠 ℓ. 𝑊 𝑏𝑢𝑜𝑦 +3. 𝐶 𝑠 (16) with 𝐹 𝐶 𝐵 1 * 𝑑 = 1 2 . 𝐶 𝑐𝑎𝑏𝑙𝑒 𝐷 . 𝑑 𝑐 .ℓ. 𝜌 𝑤 . 𝑣 2 and 𝐹 𝐶 𝐵 2 * 𝑑 = 1 2 . 𝐶 𝑐𝑎𝑏𝑙𝑒 𝐷 . 𝑑 𝑐 .ℓ. 𝜌 𝑤 . 𝑣 2 . The distance between buoys in the rest position can be calculated by zeroing the drag forces: 𝑑 𝑟𝑒𝑠𝑡 ≈ ℓ. 2.ℓ. 𝑇 1𝑐 +3𝜋. 𝐶 𝑠 ℓ. 𝑊 𝑏𝑢𝑜𝑦 +3. 𝐶 𝑠 (17) Given the 𝐶 𝑠 value of cable stiffness and the estimation of 𝑇 1𝑐 , ℓ and 𝑉 𝑏𝑢𝑜𝑦 can then be adjusted to obtain the desired distance between buoys in the rest position. 2.4. Dynamics Analysis through Differential Equations Taking into account small angles, i.e., tan 𝜃 𝑖 ≈sin 𝜃 𝑖 ≈ 𝜃 𝑖 , the dynamics equations of motion of the buoys in the left–right horizontal direction are 𝑚 𝑏𝑢𝑜𝑦 𝑑 𝑣 𝐵1 𝑑𝑡 = − 𝐹 𝑏𝑢𝑜𝑦,1 𝑑 + 𝑇 1 + 𝑊 𝑏𝑢𝑜𝑦 . 𝜃 1 − 𝐶 𝑠 ℓ [2( 𝜋 2 − 𝜃 1 )+( 𝜋 2 + 𝜃 2 )] (18) 𝑚 𝑏𝑢𝑜𝑦 𝑑 𝑣 𝐵2 𝑑𝑡 = − 𝐹 𝑏𝑢𝑜𝑦,2 𝑑 + 𝑇 2 + 𝑊 𝑏𝑢𝑜𝑦 . 𝜃 2 + 𝐶 𝑠 ℓ [2( 𝜋 2 + 𝜃 2 )+( 𝜋 2 − 𝜃 1 )] (19) Then, distance d is expressed as 𝑑(𝑑) 𝑑𝑡 = 𝑑( 𝑟 𝐵 1 𝐵 2 ) 𝑑𝑡 = 𝑣 𝐵2 − 𝑣 𝐵1 (20) The subtraction of Equation (19) from (18) yields 𝑚 𝑏𝑢𝑜𝑦 𝑑 2 (𝑑) 𝑑 𝑡 2 = 𝐹 𝑏𝑢𝑜𝑦1 𝑑 − 𝐹 𝑏𝑢𝑜𝑦,2 𝑑 + 𝑊 𝑏𝑢𝑜𝑦 ( 𝜃 2 − 𝜃 1 )+ 𝑇 12 +3. 𝐶 𝑠 ℓ ( 𝜃 2 − 𝜃 1 +𝜋) (21) with 𝑇 12 = 𝑇 2 − 𝑇 1 . Since 𝑑≈ℓ( 𝜃 1 − 𝜃 2 ) , 𝑚 𝑏𝑢𝑜𝑦 𝑑 2 (𝑑) 𝑑 𝑡 2 = 𝐹 𝑏𝑢𝑜𝑦,1 𝑑 − 𝐹 𝑏𝑢𝑜𝑦,2 𝑑 −( 𝑊 𝑏𝑢𝑜𝑦 +3 𝐶 𝑠 ℓ ). 𝑑 ℓ + 𝑇 12 +3𝜋. 𝐶 𝑠 ℓ (22) In addition, 𝐹 𝑏𝑢𝑜𝑦,1 𝑑 − 𝐹 𝑏𝑢𝑜𝑦,2 𝑑 = 𝐷.( 𝑣 𝐵1 − 𝑣 𝐵2 )=−𝐷. 𝑑(𝑑) 𝑑𝑡 (23) where 𝐷=𝑘.𝜇 for a laminar water flow. 𝐷=𝐷( 𝑣 𝐵1 , 𝑣 𝑏2 )= 1 2 . 𝐶 𝐷 .𝐴. 𝜌 𝑤 .( 𝑣 𝐵1 + 𝑣 𝐵2 ) for a turbulent water flow. Noting that 𝐸= 𝑊 𝑏𝑢𝑜𝑦 +3 𝐶 𝑠 ℓ , the differential equation relative to d is the 𝑚 𝑏𝑢𝑜𝑦 𝑑 2 (𝑑) 𝑑 𝑡 2 +𝐷. 𝑑(𝑑) 𝑑𝑡 + 𝐸 ℓ .𝑑 = 𝑇 12 +3𝜋. 𝐶 𝑠 ℓ (24) The undamped pulsation is 𝜔 0 = 𝐸 ℓ. 𝑚 𝑏𝑢𝑜𝑦 − − − − − √ . The following transfer function of the linearized system can be written as 𝐻(𝑗𝜔) = 𝑑 𝑇 12 +3𝜋. 𝐶 𝑠 ℓ = ℓ/𝐸 1+(𝑗𝜔) 𝐷.ℓ 𝐸 + (𝑗𝜔) 2 . ℓ. 𝑚 𝑏𝑢𝑜𝑦 𝐸 (25) In the case of a laminar flow, the buoy–ballast system can be seen as a second-order low-pass filter for small angles with the damping coefficient 𝜉= 1 2 .𝑘.𝜇. ℓ. 𝐸. 𝑚 𝑏𝑢𝑜𝑦 − − − − − √ . In the case of a turbulent flow, if we consider the sum of velocities ( 𝑣 𝐵1 + 𝑣 𝐵2 ) to be above a certain threshold and to vary around an average velocity 𝑣 𝑠 , then the buoy–ballast system can be seen as a second-order low-pass filter for small angles, with the damping coefficient 𝜉= 1 2 . 1 2 . 𝐶 𝐷 .𝐴. 𝜌 𝑤 . 𝑣 𝑠 . ℓ. 𝐸. 𝑚 𝑏𝑢𝑜𝑦 − − − − − √ . The setting of the damping coefficient to a few units above 1, namely 𝜉 𝑡ℎ𝑟𝑒𝑠ℎ𝑜𝑙𝑑 , helps with adjusting parameters ℓ and 𝑉 𝑏𝑢𝑜𝑦 in minimizing 𝑣 𝑠 as much as possible, taking into account the other constraints (value of 𝑑 𝑟𝑒𝑠𝑡 and ℓ not too high with regard to the size of the ROV): 𝜉 > 𝜉 𝑡ℎ𝑟𝑒𝑠ℎ𝑜𝑙𝑑 (26) 𝑣 𝑠 > 4 𝐶 𝐷 .𝐴. 𝜌 𝑤 . 𝐸. 𝑚 𝑏𝑢𝑜𝑦 ℓ − − − − − − − √ . 𝜉 𝑡ℎ𝑟𝑒𝑠ℎ𝑜𝑙𝑑 (27) 2.5. Conclusions on the Use of Modeling The steady-state model is useful for determining the theoretical variation in the distance between the buoys as a function of the speed via numerical resolution. This theoretical variation is compared with the variation obtained in the simulator (see Section 3, dedicated to simulations, where the influence of 𝑇 1𝑐 is discussed). The steady-state model is also used in the control scheme to determine the target distance between buoys as a function of the ROV speed such that the whole system converges to the steady-state mode (see Section 4.2). The dynamics analysis allows the behavior of the V-shape system to be determined as a second-order low-pass filter after linearization. However, as the system is underactuated, it is not possible to separately control the velocities of each of the buoys. In addition, Equations (17) and (27) are used to define a zone of validity for parameters ℓ and 𝑉 𝑏𝑢𝑜𝑦 . The limits of the validity zone can be defined by the following equations: 𝑑 𝑚𝑖𝑛 < 𝑑 𝑟𝑒𝑠𝑡 < 𝑑 𝑚𝑎𝑥 (28) 4 𝐶 𝐷 .𝐴. 𝜌 𝑤 . 𝐸. 𝑚 𝑏𝑢𝑜𝑦 ℓ − − − − − − − √ . 𝜉 𝑡ℎ𝑟𝑒𝑠ℎ𝑜𝑙𝑑 < 𝑣 𝑠 (29) using 𝑑 𝑚𝑖𝑛 =0.1 m, 𝑑 𝑚𝑎𝑥 =0.3 m, 𝜉 𝑡ℎ𝑟𝑒𝑠ℎ𝑜𝑙𝑑 =1 , and 𝑣 𝑠 =0.1 m/s, where these values are the result of design choices. 3. Simulations This section focuses on the following: The numerical modeling of the V-shape system with Matlab–Simulink™ for precise sizing of the parameters ℓ and 𝑉 𝑏𝑢𝑜𝑦 . A series of simulations run with the Vortex® simulator to check the validity of the V-shape system. In particular, the variation in the distance between buoys as a function of speed is observed and compared with the variation obtained using the theoretical model to check the steady-state mode. The influence of the V-shape system in terms of power consumption of the ROV is also evaluated. Then, a complete trajectory with varying depth, turns, and speed is simulated to observe the behavior of the V-shape system. 3.1. Numerical Modeling for Precise Sizing For precise sizing purposes, the V-shape system was modeled using finite solids and simulated in the Matlab–Simulink environment using the Simscape and Multibody toolbox. This numerical model is composed of twenty-four 5 cm long rigid elements linked to their neighbors by revolute joints whose stiffness is equal to 10 −3 N.m/rad, which was experimentally determined using the Fathom Slim tether cable of BlueRobotics™ [6]. The damping behavior is a result of the buoys’ drag force. Figure 3 is a representative screenshot from the video that shows the dynamic behavior of the V-shape system returning to rest state. This validates the physical assumptions for the design of the proposed mechanical model. Moreover, it confirms that the V-shape system does not acquire a droplet shape, which is crucial for guaranteeing the monotony of the output signal provided by the flex sensor mounted at the ballast [27]. This embedded instrumentation provides a suitable signal related to the compliance state that is appropriate for use as feedback for the winch command. Figure 3. Snapshot of the numerical model obtained for the buoy–ballast system using Matlab–Simulink™ (https://www.youtube.com/watch?v=PtQigrKUr9E (accessed on 1 December 2023)). The V-shape system should not be excessive in size with respect to the robot’s dimensions. A distance of 1.2 m between the buoys was chosen for a 1 m range of distance compliance between buoys and a minimal distance of 0.2 m at rest, which yields ℓ = 0.6 m for each section 𝐶 𝐵 1 and 𝐶 𝐵 2 . The value of 𝑉 𝑏𝑢𝑜𝑦 was set to approx. 36 cm 3 . 3.2. Configuration for the Simulator Simulations of the complete system, including the cable, buoy–ballast system, ROV (which is speed-controlled in open-loop), and cable feeder, were carried out using the Vortex® simulator, version 2021a (2021.1.0.66). This software integrates the modeling of cables from a mass–spring model, taking into account their physical parameters for realistic rendering. The tether is a complex non-homogeneous object comprising several twisted strands and different coating layers. Some of its physical parameters are assumed to be constant and are directly provided by the manufacturers or easy to measure directly through experimental setups. Other parameters are more difficult to determine, requiring the use of abacuses. Table 1 summarizes the parameters used for simulation. The simulated tether mimics the Fathom Slim tether. Breaking strength, radius, and linear density were obtained from datasheets. Bending stiffness, torsional stiffness, axial stiffness, damping, and drag coefficients were determined through experiments [6]. Table 1. Parameters used for simulation of the Fathom Slim tether. Values marked with an asterisk (*) are approximate estimates. The simulated ROV is adapted from the BlueROV2-Heavy from BlueRobotics™, which has four vertical thrusters and four thrusters for the horizontal movements arranged in vectorial mode. 3.3. Study of the Distance between Buoys The distance between both buoys and its variation are observed while the ROV moves forward at a constant speed (Figure 4). The coordinates of the centers of the buoys are used to calculate the distance and the variation. In this simulation, the ROV starts at a horizontal distance of 4 m from the remote station and a depth of 0.5 m. A length of 10 m of cable is unwound and then, at 11 s, the ROV starts to move 7 s forward at a controlled speed of 0.4 m/s. The desired speed is reached after 1.3 s. During the simulation, the difference between the length of the deployed cable and the distance of the ROV from the remote station is greater than 3 m. The time evolution of the distance between buoys shows that the system returns to its rest position in 5.5 s after the ROV stops. The 5% response time is 3.8 s. Thus, the system behaves like a damper. The impact of the 120 ms delay of the flex sensor, due to filtering post-processing, is negligible, and the acquisition/control frequency of 25 Hz is sufficient. Despite the damping effect, the variations in ROV speed immediately affect the distance between the buoys, which supports the interest in using this parameter to control the automatic distribution of the cable. Figure 4. Distance between buoys and its variation when the ROV moves at constant speed. To observe the behavior of the damped system, the relationship between the distance between the buoys and the ROV forward speed at 0.5 m depth is shown in Figure 5. The figure displays the curve obtained from simulation and the curves obtained from the theoretical model for values of 𝑇 1𝑐 equal to 0 N, 0.01 N, 0.03 N, 0.05 N, and 0.1 N. The drag forces were considered quadratic. Despite some slight offset, the curve issued from the steady-state model with an order of magnitude of 0.03 N for 𝑇 1𝑐 is close to the curve obtained in the simulation. The value of 𝑇 1𝑐 depends on the design of the feeder built for the simulation. The inter-buoy distance is close to its maximum when the ROV reaches a speed of 0.8 m/s. This value represents the speed limit for optimal behavior of the system. The distance versus speed relationship can be used to define a target inter-buoy distance as a function of the ROV speed to help the system converge to the steady-state mode. this is not possible since labels are not compatible with tex symbols Figure 5. Distance between buoys versus ROV speed. Comparison between theoretical steady-state model and simulation using Vortex. Influence of 𝑇 1𝑐 , the constant part of the cable tension from the left side. 3.4. Influence of Buoy–Ballast System on ROV Power The power of the ROV is calculated using the manufacturer data of the T200 brushless motors that equip the BlueRov. The manufacturer datasheets provide the motor power as a function of the motor speed, and the thrust as a function of the motor speed. The motors’ speeds are controlled to achieve the desired vehicle speed. The total power is then calculated by summing the motor powers. The speed of the ROV is not affected by the presence of the compliant system since the simulated ROV is velocity-controlled. However, the total power of the ROV thrusters observed in simulation, represented in Figure 6, is 2% higher globally with the compliant system. This is due to the drag forces on the buoy–ballast system that the cable transmits to the ROV. The passive compliant system introduces slightly more tension in the cable throughout the movement of the ROV compared with a free cable with sufficient length. However, this increase in tension is not significant, and the compliant system on the cable prevents the cable from pulling strongly on the ROV. Figure 6. Comparison of cable impact on ROV power with and without passive compliant system. 3.5. Generation of ROV Trajectories for Further Analysis Generation of trajectories. Trajectories are defined as a sequence of depth, orientation, and speed commands of the ROV. The ROV is speed-controlled with a PID control loop and with a proportional control loop in heave, yaw, roll, and pitch. Figure 7 presents the curves for the velocity, depth, and angle commands as well as the values measured during the simulation for an untethered ROV. Keyframes are indicated on this trajectory to provide reference points. This trajectory starts with forward movement of the ROV along its longitudinal axis at different successive speeds between points 0 and 1 (0.1 m/s, 0.2 m/s, and then 0.3 m/s) in parallel with a depth control of 0.5 m. Then, a command for a forward speed of 0.3 m/s is sent again (point 1), followed by a depth command at 2 m (point 2). Then, while moving forward at a constant speed, the ROV receives successive yaw commands: 45deg to the left (point 3), 45deg to the right (point 4), 0deg , 90deg to the right (point 5), and 180deg (point 6). Finally, the forward speed command is set to zero, while the depth command is kept to 2 m (point 7). The trajectory projected in the horizontal plane, deduced from the longitudinal speed and the orientation of the ROV, is also presented at the bottom right. The difference between the set point and the actual displacements of the ROV is due to hydrodynamic phenomena, which slow down the ROV in water. Moreover, when there are changes of set point in depth and yaw, a significant acceleration is required, resulting in overloading of the thrusters and affecting the speed along the x-axis (Figure 7). Figure 7. Simulated trajectories of the ROV. Control schemes. The behavior of the system is compared for five different modes listed below. Cable not controlled and without compliant system: the cable length is fixed to 15 m along the simulation. Cable with passive compliant system (not controlled): the cable length is fixed to 15 m along the simulation. Cable controlled with ROV speed command as input: the delivery speed of the cable is set to the ROV speed. Cable controlled with distance between the buoys: a closed-loop PD controller maintains a target distance of 0.8 m between the buoys. Hybrid control of the cable based on ROV speed and distance between buoys, which combines buoy distance PD controller and P controller using an ROV speed command. Furthermore, the target distance between the buoys is set to vary according to the ROV speed. The proportional part of the PD controller on the buoys’ distance works only if the distance is at least 5 cm longer than the target (taut cable) or if it is less than the target for more than 1 s (slack cable). Distance between buoys. Figure 8 depicts the evolution of the distance between buoys for passive configuration and the three control modes. Figure 8. Comparison of the evolution of the distance between the buoys in passive mode and in three control modes. Unsurprisingly, the best control is obtained with the buoy distance-based control, which keeps the distance between buoys around 0.8 m, despite oscillations that appear when the ROV is turning, from keyframe 3 to shortly after keyframe 6. The hybrid controller allows the distance to be kept within reasonable values, between 0.4 m and 0.9 m. The distance between the buoys reaches more extreme limits (0.16 m and 1.1 m) when the cable is not controlled or ROV speed-controlled. Cable delivery speed. Figure 9 shows the delivery speed for the three control modes. Figure 9. Comparison of the delivery speed for different control modes with a complex trajectory. When the ROV moves forward at low speed (before keyframe 1), the feeder’s speed is almost the same for the three control modes. As only the linear speed is considered for the ROV speed-based control, the cable delivery speed remains constant between keyframes 1 and 7, not taking into account the orientation of the ROV. Oscillations are more pronounced for the hybrid controller than for the buoy distance-based controller, resulting in a smoother cable delivery speed. Overall cable shape. The overall shape of the cable is depicted in Figure 10 for all cable control configurations at two different keyframes of the trajectory, namely keyframe 5, when the ROV finishes its forward motion, and after keyframe 7, when the ROV returns close to the feeder. With the hybrid control, the cable behaves correctly, except for when a slight excess of cable forms a lobe as the ROV moves toward the feeder. The length of free cable is too long with the ROV speed controller. In contrast, the length of free cable is tightly adjusted when using the buoy distance-based controller. When the cable is not controlled, loops appear on the water surface before the ROV starts to move away, as the cable length is far too long. These loops remain throughout the trajectory, generating a significant risk of snagging or entanglement of the cable. Figure 10. Views of the system configuration for di this is not possible since labels are not compatible with tex symbolsfferent cable control modes at two points of the complex trajectory (video available at this link: https://www.youtube.com/watch?v=ZC2zStwkdSo (accessed on 1 December 2023)). Conclusions from controller analysis. Of the three controllers evaluated in the simulation, the ROV speed-based controller is not sufficiently responsive and generates a static error on the buoys’ distance that is never corrected. It is therefore not robust to external disturbances. The control mode based on the distance between buoys is rather smooth, robust, and reactive. The hybrid control is quite reactive but presents some more pronounced oscillations while remaining rather stable. Hybrid control could possibly be improved by replacing the ROV command speed with the actual ROV speed, which would require the use of more sensors on the ROV, such as a Doppler velocity log (DVL). 4. Description of Setup, Control Mode, and ROV Trajectories for Real Experiments The simulations described in the previous section allowed validation of the behavior of the V-shape system by comparing the different modes of cable control. This section describes the preparation for real experiments that took place in water tanks. This preparation includes the setup, control scheme, and two kinds of trajectories that were used to check the system behavior in real conditions. To ensure the ground truth of the movements of the cable, compliant buoy–ballast system, and ROV, an underwater motion capture system was implemented. 4.1. Setup The cable feeder was fixed on the border of a 16 × 8 m water tank and connected to the ROV through a 25 m long 4 mm diameter tether, namely the Fathom Slim, equipped with the buoy–ballast system, of which a technological description can be found in [27]. The ROV used was a BlueROV2-Heavy, as in the simulation. A flex sensor was mounted on the cable at the ballast location using a fixed bracket and guides along the cable (Figure 11). The sensor has negligible bending stiffness. It was wrapped in a thin plastic envelope for waterproofing. The sensor resistance varies when the cable is bent. This varying resistance is transformed into a voltage signal through a voltage divider, then filtered, centered, and trimmed. The variation in the resulting signal is used to fit the corresponding distance between the buoys through a third-order polynomial (Figure 12). Figure 11. Mounting of the flex sensor near the eballast. Figure 12. Measured distance between the buoys as a function of the centered resistance of the flex sensor with experimental data points. Table 2 summarizes the characteristics of the buoy–ballast system to which the Fathom Slim tether is equipped, taking into account the previously described modeling analysis. Table 2. Specifications and characteristics of the buoy–ballast system adapted for the Fathom Slim tether. The controller board inside the robot was run on a Linux/ROS-1 system with the mavros library to interface the high level control with the autopilot ArduSub. The BlueROV2 was controlled remotely via a gamepad connected to the control computer. The remote control computer contains the embedded ROS master. It was connected to the feeder for the transmitting of control commands while taking into consideration the data received from the flex sensor through the ROS system embedded in the robot. The diagram in Figure 13 shows the architecture of the ROS nodes for controlling the global system during the experiments. Figure 13. Graph of the global ROS nodes architecture for the control. The oval boxes correspond to the nodes and the rectangular boxes to the topics exchanged by these nodes. The robot and the cable were tracked by a camera motion-tracking system, namely Qualisys, with five underwater optical cameras Miqus M5u at 180 frames per second. The cameras use blue LEDs, whose light is reflected by markers placed on the ROV and the cable. Data are recorded from the QTM software, version 2020.3 build 6020, which is controlled from a dedicated computer during the experiments. This software computes the current 3D position of each marker provided they are detected by several cameras. Across the experiments, the position residuals of the markers were about 1.3 mm for the ROV, with a minimum of 0.9 mm and a maximum of 10 mm. 4.2. Control Scheme Figure 14 is the control block diagram of the feeder, which can be controlled using the measured distance between buoys, namely buoy gap on the figure, or using a desired cable length. The control for the feeder consists of a main control loop with proportional controllers, which includes a speed control loop with a proportional–integral controller and anti-windup system. Flex sensor processing, presented in Section 4.1, is used to estimate the inter-buoy distance, which is sent to the feeder by the ROV. Figure 14. Control block diagram of the feeder using the steady-state model and length and speed control loops. R is the radius of the feeder wheel and N is the number of ticks of the encoder counter. In normal mode, namely buoy gap control mode, the feeder speed is controlled as the ROV moves to regulate the gap between both buoys. The target buoy gap is defined from the actual ROV speed using the steady-state model that gives the variations in the buoy gap as a function of the ROV speed (see Section 2.3 and Figure 5). The target buoy gap is then compared to the current gap measured by the flex sensor to update the rotation speed of the feeder. In length control mode, the cable length can be directly controlled by setting a desired length. The feeder can actually be operated to release the cable when necessary; e.g., when the V-system is stretched, 2 m of cable is uncoiled after a 10 s period until the V-system is released. Buoy gap control and length control modes are separately activated as required. Cable length is computed in the speed control loop such that it is accessible even when length control is disabled. The target rotation speed is first bounded to avoid exceeding the motor limits. Embedded in the speed control loop is a proportional–integral corrector, which is applied to the error between the bounded target speed and the measured speed. This corrector has an anti-windup system that limits the sum of past errors to stabilize the system. It outputs a raw PWM signal, which is then bounded and smoothed by a low-pass filter before being transmitted to the motor control board. 4.3. Trajectories The experimental results of cable control validation were obtained during a series of tests carried out in the pool of the CIRS (Underwater Robotics Research Center) in Girona in the context of a TNA (TransNational Access) European project. Two kinds of ROV trajectories were defined to represent two configurations where cable control must be useful to reduce risks of cable snagging or entanglements as below. A linear trajectory where the ROV goes forwards and then backwards First, a forward thrust command of 25% is sent for 15 s (between keyframes 1 and 2). Then, a zero command is sent for 5 s (between points 2 and 3). Finally, a backward thrust command of 25% is sent for 10 s (between points 3 and 4). A curvilinear S-shape trajectory comprising the following steps: - a forward thrust of 40% for 15 s (between points 1 and 2); - a right turn composed of a yaw thrust of 11.25% combined with a forward thrust of 40% for 6.5 s to turn right (between points 2 and 3); - a left turn with the same thrust command values as the left turn, for 6 s (between points 3 and 4); - a forward thrust of 40% for 4 s (between points 4 and 5). All these trajectories were associated with 1.5 m depth control. The ROV was open-loop-controlled to follow these trajectories by driving the corresponding thrusters. For each trajectory, three kinds of cable management were tested: Passive slack cable, where cable of sufficient length was deployed in the water from the beginning. Passive taut cable, where the cable is stretched between the feeder and the ROV when the ROV moves away from the feeder, which means that the buoy–ballast system is also completely stretched and has no real influence on the ROV. The feeder is not powered. When the ROV comes closer to the feeder, the cable is no longer taut, and the buoy gap tends to be reduced to a minimum. Cable control, using buoy gap control mode. A 25% and 40% forward thrust is associated with a buoy gap of about 0.7 mn and 0.8 m, respectively, according to the steady-state model. 5. Results And Discussion 5.1. Linear Trajectory Figure 15 illustrates the cable management results for the linear trajectory including buoy distance control mode, passive slack mode, and passive taut mode. The feeder appears to be quite reactive and smooth in winding/unwinding the cable depending on ROV motion and the distance between buoys. The buoy–ballast system exhibits highly dynamic transient behavior between points 2 and 4 due to the changes in velocity. When moving backward, the feeder also takes more time for buoy gap convergence back to the target distance (0.7 m). Figure 15. Distance between buoys, feeder speed, and unwound length of cable in control mode, passive slack mode, and passive taut mode for forward–backward trajectory. (https://youtu.be/owekUkN_UtM for control mode, https://youtu.be/1RTT23-USDY for passive taut mode, https://youtu.be/FG5iyNfjzck for passive slack mode (accessed on 1 December 2023)). Figure 16 presents the paths followed by the ROV projected onto the horizontal plane as measured by the Qualisys system for the three cable modes. Figure 16. Top view of actual forward–backward trajectories of the ROV using cable control, slack, or passive taut cable. Paths are superimposed at point 2 for easier comparison. If there were no external disturbances at all, the path would be rectilinear. The ROV shifts slightly to the left when the cable is slack. This deviation is slightly larger in the control mode and is observed during both its forward and backward motion. The deviation is significantly greater in passive taut mode. Furthermore, the distance covered by the ROV is shorter with the taut cable. Figure 17 shows the evolution of depth control of the ROV for the three modes. Only the control mode is efficient in helping to regulate the ROV depth. In addition, the vertical thrusters’ work significantly increases more when the cable is not controlled than when it is controlled. Figure 17. ROV depth and vertical depth control thrust in the three modes. 5.2. Curvilinear Trajectory Figure 18 shows the snapshots at keyframes 1, 3, and 4 in cable control mode. Figure 19 presents the results in terms of buoy gap, feeder speed, and delivered cable length. Figure 20 presents the yaw angle. Figure 21 shows the executed trajectories in the cases of passive slack cable, passive taut cable, and control mode. Figure 18. Views of the overall system at different points along the curvilinear trajectory when the cable is controlled. The red arrows indicate the direction of motion of the ROV (video at https://youtu.be/fy-JTc8PvIY (accessed on 1 December 2023)). Figure 19. Distance between buoys (flex sensor), feeder speed, and unwound length of cable in control mode, passive slack mode, and passive taut mode for the curvilinear trajectory (videos at https://youtu.be/LR4BKefRSnM for passive slack mode and at https://youtu.be/74p5Bzee9kY for passive taut mode (accessed on 1 December 2023)). Figure 20. Comparison of the ROV yaw angle (measured with the embedded compass) along the curvilinear trajectory with or without cable control. The angle was initialized to 0 𝑜 at the beginning of the trajectories to facilitate their comparison. An increase in the angle represents a rotation to the right of the ROV. Figure 21. Comparison of the actual curvilinear path of the ROV in top view, measured by the Qualisys system, with or without cable control. These paths are superimposed on point 2 for easier comparison. In control mode, the compliant system keeps its V-shape and a buoy gap average close to the target distance (0.8 m), except for during turns, where the behavior is highly dynamic because of the increased forward speed and the opposing directions of the successive turns, which causes the buoy gap to reach its bounds, namely 0.2 m and 1.2 m, during a short period of time. The buoy gap resulting from passive taut and passive slack modes demonstrates the added value of automatic cable length management in maintaining an average buoy gap, which allows the cable shape between the station and the buoy–ballast system to be controlled. For a flawless system without any disturbance, the yaw angle (Figure 20) must be constant during the ROV straight line commands (before point 2 and after point 5). It must also be linear during rotating commands (between points 2 and 3, then 3 and 4). There is a slight deviation of about 20 deg to the right during the first straight line (2.6 m) command of the ROV for the passive slack cable. This deviation is oriented to the left and its absolute value is doubled with the controlled cable and doubled again with the passive taut cable. In fact, the cable is fixed on the left side of the back of the ROV, which induces a slight deviation to the left for the controlled cable, both in a straight line and during a right rotation. This deviation is much larger for the passive taut cable. The left rotation of the ROV appears to be less affected in the control and passive taut modes. The impact of these deviations is observed in Figure 21, in which the ROV paths in top view are shown for the three modes. The distances traveled are quite similar for the controlled cable and the passive slack cable, whereas the turns are slightly different. The path of the ROV with the passive taut cable is completely distorted. The first rotation to the right (between points 2 and 3) is tightly confined, and the rotation to the left (between points 3 and 4) is quite irregular (much wider curvature in the middle than at the beginning and the end). The experiments also showed there is effective control of the cable using the compliant buoy–ballast system, which keeps the cable in a semi-stretched configuration, and the delivered length is appropriately managed, preventing the creation of cable loops that can occur in passive slack mode and reducing the risks of snagging and tangles, considering that turns in passive taut mode can cause the cable to become entangled with the robot. The control mode generates slight tension in the cable, which is transmitted to the ROV and results in a minor deviation in the trajectory of the system, which can be avoided by fixing the cable closer to the ROV’s center of gravity. In addition, the passive compliance system appears to improve the stability of the depth control of the ROV. 6. Conclusions In this paper, a mechatronic solution for ROV deployment is introduced in which the length of the cable that connects the robot to the surface is automatically controlled. This solution consists of designing and setting up a balanced and compliant buoy–ballast system for the cable, which allows the cable feeder to be controlled using the readings from the flex sensor placed along a part of the cable near the ballast. The simulations and the experiments conducted with a BlueROV and a neutral cable demonstrated the validity of the concept. The steady-state model was used in the control loop to obtain a target distance between the buoys from the ROV speed command. The feeder appeared to react as expected with respect to the command speeds of the ROV. The shape of the cable was kept in a semi-stretched configuration during the experiments of linear and curved trajectories. This solution is easy to set up and can be useful in preventing the cable from pulling on the ROV, thus avoiding entanglement of the cable with its surroundings. The aim for future developments will be to implement the cable feeder on a surface vehicle (USV). The measurement of the consumed current will help in estimating the cable strain on the USV side. It will also be possible to equip the tether with strain sensors on the ROV side to increase the accuracy of closed-loop control with respect to the distance between buoys. Possible prospects include navigation synchronization between the ROV and the USV to optimize displacement of the vehicles in terms of power consumption and to increase seabed coverage in shallow waters. Author Contributions Conceptualization, methodology, writing, and data curation, O.T.; formal analysis and investigation, C.P.; project administration, supervision, validation, writing, formal analysis, review, and editing, C.A. and V.H. All authors have read and agreed to the published version of the manuscript. Funding This research was funded by the Provence-Alpes-Côte d’Azur (PACA) region for the ‘Emploi jeunes doctorants’ (EJD) project, and the 3rd TransNational Access (TNA) H2020 European project related to EuMarineRobots. Informed Consent Statement Informed consent was obtained from all subjects involved in the study. Data Availability Statement No new data were created or analyzed in this study. Data sharing is not applicable to this article. Acknowledgments The authors greatly thank the CIRS lab (Underwater Robotics Research Center) in Girona, Spain, especially Pere Ridao and Guillem Vallicrosa Massaguer for their welcome and administrative and technical support during the week of experiments in the frame of the TNA project. Conflicts of Interest The authors declare no conflicts of interest. Appendix A. Statics Analysis of the Buoy–Ballast System The entire system is assumed to move at a constant velocity v driven by the ROV in the left–right direction. Assuming that all forces intersect at 𝐵 1 , the compensation of forces exerted on the left buoy is calculated as 𝑊 𝑏𝑢𝑜𝑦 + 𝑇 𝑦 𝐵1 = 0 (A1) − 𝐹 𝑏𝑢𝑜𝑦 𝑑 − 𝑇 1 + 𝑇 𝑥 𝐵1 = 0 (A2) where 𝑇 𝑥 𝐵1 and 𝑇 𝑦 𝐵1 are the components of the force 𝐓 𝐁𝟏 that is exerted by the cable portion 𝐵 1 𝐶 onto the left buoy. 𝐹 𝑏𝑢𝑜𝑦 𝑑 is the intensity of the drag force exerted by the fluid on the buoy. 𝑇 1 >0 is the magnitude of the horizontal scalar force exerted by the cable that links the left buoy to the remote station. Assuming that all forces intersect at 𝐵 2 , the compensation of forces exerted on the right buoy is calculated as 𝑊 𝑏𝑢𝑜𝑦 + 𝑇 𝑦 𝐵2 = 0 (A3) − 𝐹 𝑏𝑢𝑜𝑦 𝑑 + 𝑇 2 + 𝑇 𝑥 𝐵2 = 0 (A4) where 𝑇 𝑥 𝐵2 and 𝑇 𝑦 𝐵2 are the components of the force 𝐓 𝐁𝟐 that is exerted by the cable portion 𝐵 2 𝐶 onto the right buoy. 𝑇 2 is the algebraic horizontal scalar force exerted by the cable that links the right buoy to the ROV. In the case of the figure, the intensity 𝑇 2 is positive since the ROV pulls on the cable to move from left to right. Taking into account a drag force of intensity 𝐹 𝐶 𝐵 1 𝑑 and 𝐹 𝐶 𝐵 2 𝑑 , resp., on the cable portions 𝐶 𝐵 1 and 𝐶 𝐵 2 , the compensation of forces exerted on the ballast is − 𝑊 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 − 𝑇 𝑦 𝐵1 − 𝑇 𝑦 𝐵2 = 0 (A5) − 𝐹 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 𝑑 − 𝐹 𝐶 𝐵 1 𝑑 − 𝐹 𝐶 𝐵 2 𝑑 − 𝑇 𝑥 𝐵1 − 𝑇 𝑥 𝐵2 = 0 (A6) Equation (A5) is actually not useful since it was already set that 𝑊 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 =2. 𝑊 𝑏𝑢𝑜𝑦 , which can be found again using Equations (A1) and (A3). In addition, the cable stiffness must be taken into account in the compensation of the efforts exerted on cable portions 𝐶 𝐵 1 and 𝐶 𝐵 2 . Taking C as a reference point, the compensation of the moments of force and torques exerted on 𝐶 𝐵 1 is expressed as [ 𝐫 𝐂𝐁 𝟏 ×(− 𝐓 𝐁𝟏 )+ 𝟏 𝟐 𝐫 𝐂𝐁 𝟏 × 𝐅 𝐂𝐁 𝟏 𝐝 + 𝐓𝐪 𝐬 𝐁 𝟏 + 𝐓𝐪 𝐬 𝐂,𝐫𝐢𝐠𝐡𝐭 ].𝐳=𝟎 and on 𝐶 𝐵 2 as [ 𝐫 𝐂𝐁 𝟐 ×(− 𝐓 𝐁𝟐 )+ 𝟏 𝟐 𝐫 𝐂𝐁 𝟐 × 𝐅 𝐂𝐁 𝟐 𝐝 + 𝐓𝐪 𝐬 𝐁 𝟐 + 𝐓𝐪 𝐬 𝐂,𝐥𝐞𝐟𝐭 ].𝐳=𝟎 where 𝐫 𝐂𝐁 𝟏 and 𝐫 𝐂𝐁 𝟐 are the position vectors of 𝐵 1 and 𝐵 2 , resp., with regard to C, and 𝐓𝐪 𝐬 𝐁 𝟏 is the cable bending torque exerted onto the branch 𝐵 1 𝐶 at 𝐵 1 , and 𝐓𝐪 𝐬 𝐁 𝟐 is the cable bending torque exerted onto the branch 𝐵 2 𝐶 at 𝐵 2 . 𝐓𝐪 𝐬 𝐂,𝐫𝐢𝐠𝐡𝐭 and 𝐓𝐪 𝐬 𝐂,𝐥𝐞𝐟𝐭 are the cable bending torques exerted by the right and left parts, resp., at C. These torques are proportional to a bending stiffness coefficient named 𝐶 𝑠 . The equations above yield ( 𝑇 𝑥 𝐵1 + 1 2 . 𝐹 𝐶 𝐵 1 𝑑 ).ℓ.cos 𝜃 1 + 𝑇 𝑦 𝐵1 .ℓ.sin 𝜃 1 + 𝐶 𝑠 [2( 𝜋 2 − 𝜃 1 )+( 𝜋 2 + 𝜃 2 )] ( 𝑇 𝑥 𝐵2 + 1 2 . 𝐹 𝐶 𝐵 2 𝑑 ).ℓ.cos 𝜃 2 + 𝑇 𝑦 𝐵2 .ℓ.sin 𝜃 2 − 𝐶 𝑠 [2( 𝜋 2 + 𝜃 2 )+( 𝜋 2 − 𝜃 1 )] = = 0 0 The number of independent equations is therefore 𝑊 𝑏𝑢𝑜𝑦 + 𝑇 𝑦 𝐵1 =0 − 𝐹 𝑏𝑢𝑜𝑦 𝑑 − 𝑇 1 + 𝑇 𝑥 𝐵1 =0 𝑊 𝑏𝑢𝑜𝑦 + 𝑇 𝑦 𝐵2 =0 − 𝐹 𝑏𝑢𝑜𝑦 𝑑 + 𝑇 2 + 𝑇 𝑥 𝐵2 =0 − 𝐹 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 𝑑 − 𝐹 𝐶 𝐵 1 𝑑 − 𝐹 𝐶 𝐵 2 𝑑 − 𝑇 𝑥 𝐵1 − 𝑇 𝑥 𝐵2 =0 ( 𝑇 𝑥 𝐵1 + 1 2 . 𝐹 𝐶 𝐵 1 𝑑 ).ℓ.cos 𝜃 1 + 𝑇 𝑦 𝐵1 .ℓ.sin 𝜃 1 + 𝐶 𝑠 [2( 𝜋 2 − 𝜃 1 )+( 𝜋 2 + 𝜃 2 )]=0 ( 𝑇 𝑥 𝐵2 + 1 2 . 𝐹 𝐶 𝐵 2 𝑑 ).ℓ.cos 𝜃 2 + 𝑇 𝑦 𝐵2 .ℓ.sin 𝜃 2 − 𝐶 𝑠 [2( 𝜋 2 + 𝜃 2 )+( 𝜋 2 − 𝜃 1 )]=0 Replacing 𝑇 𝑥 𝐵1 , 𝑇 𝑦 𝐵1 , 𝑇 𝑥 𝐵2 , and 𝑇 𝑦 𝐵2 in the last two equations yields 𝑇 𝑥 𝐵1 = 𝐹 𝑏𝑢𝑜𝑦 𝑑 + 𝑇 1 𝑇 𝑦 𝐵1 =− 𝑊 𝑏𝑢𝑜𝑦 𝑇 𝑥 𝐵2 =− 𝐹 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 𝑑 − 𝐹 𝐶 𝐵 1 𝑑 − 𝐹 𝐶 𝐵 2 𝑑 − 𝐹 𝑏𝑢𝑜𝑦 𝑑 − 𝑇 1 𝑇 𝑦 𝐵2 =− 𝑊 𝑏𝑢𝑜𝑦 𝑇 2 =2. 𝐹 𝑏𝑢𝑜𝑦 𝑑 + 𝐹 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 𝑑 ( 𝐹 𝑏𝑢𝑜𝑦 𝑑 + 𝑇 1 + 1 2 . 𝐹 𝐶 𝐵 1 𝑑 ).ℓ.cos 𝜃 1 − 𝑊 𝑏𝑢𝑜𝑦 .ℓ.sin 𝜃 1 =− 𝐶 𝑠 [2( 𝜋 2 − 𝜃 1 )+( 𝜋 2 + 𝜃 2 )] −( 𝐹 𝑏𝑎𝑙𝑙𝑎𝑠𝑡 𝑑 + 𝐹 𝑏𝑢𝑜𝑦 𝑑 + 𝑇 1 + 𝐹 𝐶 𝐵 1 𝑑 + 1 2 . 𝐹 𝐶 𝐵 2 𝑑 ).ℓ.cos 𝜃 2 − 𝑊 𝑏𝑢𝑜𝑦 .ℓ.sin 𝜃 2 = 𝐶 𝑠 [2( 𝜋 2 + 𝜃 2 )+( 𝜋 2 − 𝜃 1 )] References Christ, R.; Wernli, R. The ROV Manual a User Guide for Remotely Operated Vehicles, 2nd ed.; Elsevier: Amsterdam, The Netherlands, 2014. [Google Scholar] Khatib, O.; Yeh, X.; Brantner, G.; Soe, B.; Kim, B.; Ganguly, S.; Stuart, H.; Wang, S.; Cutkosky, M.; Edsinger, A.; et al. Ocean one: A robotic avatar for oceanic discovery. IEEE Robot. Autom. Mag. 2016, 23, 20–29. [Google Scholar] [CrossRef] Destelle, J.J.; Vallée, C. The MEUST infrastructure for neutrino astronomy. Nucl. Instrum. Methods Phys. Res. Sect. A Accel. Spectrometers Detect. Assoc. Equip. 2013, 725, 227–229. [Google Scholar] [CrossRef] Capocci, R.; Dooly, G.; Omerdić, E.; Coleman, J.; Newe, T.; Toal, D. Inspection-Class Remotely Operated Vehicles—A Review. J. Mar. Sci. Eng. 2017, 5, 13. [Google Scholar] [CrossRef] Ajwad, S.A.; Iqbal, J. Recent Advances and applications of tethered robotic systems. Sci. Int. 2014, 26, 2045–2051. [Google Scholar] Tortorici, O.; Anthierens, C.; Hugel, V.; Barthelemy, H. Towards active self-management of umbilical linking ROV and USV for safer submarine missions. IFAC-PapersOnLine 2019, 52, 265–270. [Google Scholar] [CrossRef] McLain, T.W.; Rock, S.M. Experimental Measurement of ROV Tether Tension. In Proceedings of the ROV’92, San Diego, CA, USA, 10–12 June 1992; p. 6. [Google Scholar] Bevilacqua, L.; Kleczka, W.; Kreuzer, E. On the Mathematical Modeling of ROV’S. IFAC Proc. Vol. 1991, 24, 51–54. [Google Scholar] [CrossRef] Soylu, S.; Buckham, B.J.; Podhorodeski, R.P. Dynamics and control of tethered underwater-manipulator systems. In Proceedings of the OCEANS 2010 MTS/IEEE SEATTLE, Seattle, WA, USA, 20–23 September 2010; pp. 1–8. [Google Scholar] Fang, M.C.; Hou, C.S.; Luo, J.H. On the motions of the underwater remotely operated vehicle with the umbilical cable effect. Ocean Eng. 2007, 34, 1275–1289. [Google Scholar] [CrossRef] Feng, Z.; Allen, R. Evaluation of the effects of the communication cable on the dynamics of an underwater flight vehicle. Ocean Eng. 2004, 31, 1019–1035. [Google Scholar] [CrossRef] Gay Neto, A.; de Arruda Martins, C. Structural stability of flexible lines in catenary configuration under torsion. Mar. Struct. 2013, 34, 16–40. [Google Scholar] [CrossRef] Coyne, J. Analysis of the formation and elimination of loops in twisted cable. IEEE J. Ocean. Eng. 1990, 15, 72–83. [Google Scholar] [CrossRef] Drumond, G.; Pasqualino, I.; Pinheiro, B.; Estefen, S. Pipelines, risers and umbilicals failures: A literature review. Ocean Eng. 2018, 148, 412–425. [Google Scholar] [CrossRef] Brignone, L.; Raugel, E.; Opderbecke, J.; Rigaud, V.; Piasco, R.; Ragot, S. First sea trials of HROV the new hybrid vehicle developed by IFREMER. In Proceedings of the OCEANS 2015—Genova, Genova, Italy, 18–21 May 2015; pp. 1–7. [Google Scholar] Viel, C. Self-management of the umbilical of a ROV for underwater exploration. Ocean Eng. 2022, 248, 110695. [Google Scholar] [CrossRef] Frank, J.E.; Geiger, R.; Kraige, D.R.; Murali, A. Smart Tether System for Underwater Navigation and Cable Shape Measurement. U.S. Patent US8437979B2, 7 May 2013. [Google Scholar] Duncan, R.G.; Froggatt, M.E.; Kreger, S.T.; Seeley, R.J.; Gifford, D.K.; Sang, A.K.; Wolfe, M.S. High-accuracy fiber-optic shape sensing. In Proceedings of the SPIE Smart Structures and Materials + Nondestructive Evaluation and Health Monitoring, San Diego, CA, USA, 18–22 March; p. 65301S. Xu, C.; Chen, J.; Yan, D.; Ji, J. Review of Underwater Cable Shape Detection. J. Atmos. Ocean. Technol. 2016, 33, 597–606. [Google Scholar] [CrossRef] Xu, C.; Wan, K.; Chen, J.; Yao, C.; Yan, D.; Ji, J.; Wang, C. Underwater cable shape detection using ShapeTape. In Proceedings of the OCEANS 2016 MTS/IEEE Monterey, Monterey, CA, USA, 19–23 September 2016; pp. 1–4. [Google Scholar] Banerjee, A.K.; Do, V.N. Deployment control of a cable connecting a ship to an underwater vehicle. J. Guid. Control. Dyn. 1994, 17, 1327–1332. [Google Scholar] [CrossRef] Zhao, C.; Thies, P.R.; Johanning, L. Investigating the winch performance in an ASV/ROV autonomous inspection system. Appl. Ocean Res. 2021, 115, 102827. [Google Scholar] [CrossRef] Raugel, E.; Opderbecke, J.; Fabri, M.; Brignone, L.; Rigaud, V. Operational and scientific capabilities of Ariane, Ifremer’s hybrid ROV. In Proceedings of the OCEANS 2019—Marseille, Marseille, France, 17–20 June 2019. [Google Scholar] Zhou, H.; Cao, J.; Yao, B.; Lian, L. Hierarchical NMPC–ISMC of active heave motion compensation system for TMS–ROV recovery. Ocean Eng. 2021, 239, 109834. [Google Scholar] [CrossRef] Lubis, M.B.; Kimiaei, M.; Efthymiou, M. Alternative configurations to optimize tension in the umbilical of a work class ROV performing ultra-deep-water operation. Ocean Eng. 2021, 225, 108786. [Google Scholar] [CrossRef] Laranjeira, M.; Dune, C.; Hugel, V. Catenary-based visual servoing for tether shape control between underwater vehicles. Ocean Eng. 2020, 200, 107018. [Google Scholar] [CrossRef] Tortorici, O.; Anthierens, C.; Hugel, V. A new flex-sensor-based umbilical-length management system for underwater robots. In Proceedings of the European Conference on Mobile Robotics, Coimbra, Portugal, 4–7 September 2023. [Google Scholar] Disclaimer/Publisher’s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.  © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Share and Cite MDPI and ACS Style Tortorici, O.; Péraud, C.; Anthierens, C.; Hugel, V. Automated Deployment of an Underwater Tether Equipped with a Compliant Buoy–Ballast System for Remotely Operated Vehicle Intervention. J. Mar. Sci. Eng. 2024, 12, 279. https://doi.org/10.3390/jmse12020279 AMA Style Tortorici O, Péraud C, Anthierens C, Hugel V. Automated Deployment of an Underwater Tether Equipped with a Compliant Buoy–Ballast System for Remotely Operated Vehicle Intervention. Journal of Marine Science and Engineering. 2024; 12(2):279. https://doi.org/10.3390/jmse12020279 Chicago/Turabian Style Tortorici, Ornella, Charly Péraud, Cédric Anthierens, and Vincent Hugel. 2024. \"Automated Deployment of an Underwater Tether Equipped with a Compliant Buoy–Ballast System for Remotely Operated Vehicle Intervention\" Journal of Marine Science and Engineering 12, no. 2: 279. https://doi.org/10.3390/jmse12020279 Note that from the first issue of 2016, this journal uses article numbers instead of page numbers. See further details here. Article Metrics Citations No citations were found for this article, but you may check on Google Scholar Article Access Statistics Article access statistics Article Views 3. Feb 8. Feb 13. Feb 18. Feb 23. Feb 28. Feb 4. Mar 9. Mar 14. Mar 19. Mar 24. Mar 29. Mar 3. Apr 0 1000 250 500 750 For more information on the journal statistics, click here. Multiple requests from the same IP address are counted as one view.   J. Mar. Sci. Eng., EISSN 2077-1312, Published by MDPI RSS Content Alert Further Information Article Processing Charges Pay an Invoice Open Access Policy Contact MDPI Jobs at MDPI Guidelines For Authors For Reviewers For Editors For Librarians For Publishers For Societies For Conference Organizers MDPI Initiatives Sciforum MDPI Books Preprints.org Scilit SciProfiles Encyclopedia JAMS Proceedings Series Follow MDPI LinkedIn Facebook Twitter Subscribe to receive issue release notifications and newsletters from MDPI journals Select options Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless otherwise stated Disclaimer Terms and Conditions Privacy Policy"

Paper 9:
- APA Citation: Chhetri, K. B. (2023). Applications of Artificial Intelligence and Machine Learning in Food Quality Control and Safety Assessment. Food Engineering Reviews, 16(1), 1–21. https://doi.org/10.1007/s12393-023-09363-1
  Main Objective: The primary objective of this systematic review is to evaluate the applications of artificial intelligence (AI) and machine learning (ML) in food quality control and safety assessment, with a focus on the current state and future potential of real-time, end-to-end automated irrigation management systems.
  Study Location: Unspecified
  Data Sources: Survey data, Interviews, Case studies, Literature review
  Technologies Used: IoT, ML, Kalman filtering, moving average, adaptive thresholding
  Key Findings: 1. AI and ML techniques have revolutionized the field of food quality control and safety assessment by introducing innovative solutions to increase the consistency and safety of food items.
2. The integration of AI and ML in food process engineering has resulted in predictive modelling for quality deviations and estimating the shelf-life of food products.
3. The combination of AI and ML with IoT devices has facilitated real-time monitoring of critical parameters, thereby enabling proactive quality control and safety measures.
  Extract 1: Real-time data cleaning techniques for handling missing, inconsistent, or outlier data from IoT sensors (e.g., soil moisture sensors, weather stations) using methods such as Kalman filtering, moving average, and adaptive thresholding
  Extract 2: None
  Limitations: None
  Relevance Evaluation: The paper is highly relevant to the outline point, as it directly addresses the use of AI and ML in real-time data cleaning techniques for handling missing, inconsistent, or outlier data from IoT sensors. It provides an in-depth analysis of the techniques employed and their effectiveness in addressing data quality issues in the context of automated irrigation systems. The paper aligns well with the objective of the outline point, which is to evaluate the application of AI and ML in automated irrigation systems to improve data quality and enhance the overall efficiency of irrigation management processes.
  Relevance Score: 1.0
  Inline Citation: (Chhetri, 2023)
  Explanation: The paper explores the integration of AI and machine learning (ML) into end-to-end, automated irrigation management systems. It examines various stages of data collection, transmission, and analysis to automate irrigation processes, aiming to enhance water efficiency and crop productivity. The review also evaluates the current state of IoT and ML technologies used in automated irrigation systems and identifies gaps and potential solutions for seamless integration.

 Full Text: >
"Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Log in Find a journal Publish with us Track your research Search Cart Home Food Engineering Reviews Article Applications of Artificial Intelligence and Machine Learning in Food Quality Control and Safety Assessment Published: 22 December 2023 Volume 16, pages 1–21, (2024) Cite this article Download PDF Access provided by University of Nebraska-Lincoln Food Engineering Reviews Aims and scope Submit manuscript Krishna Bahadur Chhetri  564 Accesses Explore all metrics Abstract To ensure food safety and uphold high standards, the food business must overcome significant obstacles. In recent years, promising answers to these issues have emerged in the form of artificial intelligence (AI) and machine learning (ML). This thorough review paper analyses the various uses of AI and ML in food quality management and safety evaluation, offering insightful information for academics, business people and legislators. The evaluation highlights the value of food quality assessment and control in consideration of growing consumer demand and regulatory scrutiny. The powerful capabilities of AI and ML are touted as having the potential to revolutionize these procedures. This study illustrates the numerous uses of AI and ML in food quality management through an in-depth exploration of these technologies. Defect detection and consistency evaluation are made possible using computer vision techniques, and intelligent data analysis and real-time monitoring are made possible by natural language processing. Deep learning techniques also provide reliable approaches for pattern recognition and anomaly detection, thus maintaining consistency in quality across manufacturing batches. This review emphasizes the efficiency of AI and ML in detecting dangerous microorganisms, allergies and chemical pollutants with regard to food safety evaluation. Consumer health risks are reduced because of the rapid identification of safety issues made possible by integrating data from diverse sources, including sensors and IoT devices. The assessment discusses issues and restrictions related to the application of AI and ML in the food business while appreciating the impressive progress that has been made. Continuous efforts are being made to improve model interpretability and reduce biases, which calls for careful evaluation of data quality, quantity and privacy issues. To assure compliance with food safety norms and regulations, the article also covers regulatory approval and validation of AI-generated outcomes. The revolutionary potential of AI and ML in raising food industry standards and preserving public health is highlighted on future perspectives that concentrate on new trends and potential innovations. This comprehensive review reveals that the integration of AI and ML technologies in food quality control and safety not only enhances efficiency, minimizes risks and ensures regulatory compliance but also heralds a new era of personalized nutrition, autonomous monitoring and global collaboration, signifying a transformative paradigm in the food industry. Similar content being viewed by others Artificial Intelligence and Deep Learning-Based Agri and Food Quality and Safety Detection System Chapter © 2023 Impact and prospect of the fourth industrial revolution in food safety: Mini-review Article 20 February 2022 Food Adulteration Detection using Artificial Intelligence: A Systematic Review Article 15 June 2021 Introduction The food industry at a global level is encountering an escalation in challenges associated with ensuring food safety, sustainability and quality due to the increasing demands of consumers and environmental changes. To combat these challenges, industry professionals and researchers are resorting to artificial intelligence (AI) and machine learning (ML) techniques as effective instruments to transform food safety assessment and quality control. In this paper, an assessment is conducted to explore the varied applications of AI and ML in the food industry, with a particular emphasis on their potential to mitigate crucial challenges and enhance the overall efficiency. The requirement for advanced technologies in food safety assessment and quality control is apparent, and AI and ML provide encouraging solutions. The conflation of hyperspectral imaging and AI methodologies in a symbiotic manner, as illustrated by the innovative research undertaken by Rady et al. [1], carried significant consequences for the food processing sector. This union facilitates the swift and accurate detection of pest infestations in apples, which fortifies pre-emptive measures and decreases crop losses. Furthermore, the AI-powered analysis extends to quality management, permitting the real-time evaluation of factors such as ripeness and pollutants. By refining procedures and ensuring the authenticity of products, this combination redefines the benchmarks for food safety and refines the general efficacy of the industry. The food processing industry is on the cusp of a transformative period, owing to the profound integration of AI and ML techniques. These advancements have significantly altered the crop disease and pest detection landscape with remarkable precision, as evidenced by the pioneering research of Boyd and Sun [2]. Their groundbreaking expert system, which diagnoses potato ailments, is a pioneering achievement that demonstrates the expeditious and precise assessments that are now possible, ushering in a new era of rapid interventions and reduced agricultural losses. However, the realm of AI and ML surpasses the confines of immediate quality control. Instead, it assumes a mantle of paramount significance in navigating the intricate and multifaceted terrain of food security. The astute application of fuzzy systems, as demonstrated by Peixoto et al. [3], offers a glimpse into this potential. Their ingenious dynamic regulation of soybean aphids exemplifies the strategic use of AI, resulting not only in augmented crop yields but also in fortifying the very foundation of the global food supply chain. Inextricably linked to the evolving tapestry of the food industry, the ascendancy of AI and ML technologies in food quality control and safety assessment is inexorable. As we traverse the dynamic contours of this landscape, it becomes increasingly evident that this review serves not merely as an exposition but also as a clarion call, illuminating the path to an augmented future where AI and ML stand as sentinels of excellence within the realms of food processing. Materials and Methods The synthesis of this all-encompassing review is supported by a rigorous methodology aimed at extracting valuable insights from the most authoritative sources currently available. A meticulous and systematic search strategy was executed, utilizing well-known databases such as PubMed, IEEE Xplore and ScienceDirect. This review covers literature published until 2022, ensuring a comprehensive and up-to-date coverage of the subject. In accordance with strict inclusion criteria, the selection process gave priority to articles that have undergone peer review and notable conference proceedings. A thorough three-step screening process, involving the evaluation of titles, abstracts and full texts, was implemented to ensure the accuracy and relevance of the studies included. The categorization framework focused on the principal applications of AI and ML in the context of food safety, specifically computer vision, IoT-enabled sensors, blockchain integration and predictive modelling. A systematic analysis of the benefits and limitations associated with each application supports a refined distillation of insights, contributing to a comprehensive understanding of the subject matter. Food Quality Control and Safety Assessment Through AI and ML Techniques AI and ML techniques have revolutionized the field of food quality control by presenting inventive solutions to increase the consistency and safety of food items [4, 5]. Among the key techniques used in the industry are the following: 1. Computer vision: In contemporary food process engineering, the combination of computer vision technology and AI has emerged as a pioneering development [5]. This combination is transforming the food industry by enabling meticulous and automated visual inspections. AI-powered computer vision systems excel at scrutinizing food products with precision and speed through image and video analysis. These systems are indispensable for crucial tasks such as grading, sorting and quality assessment. By rapidly identifying discrepancies from quality standards, they ensure that only products satisfying stringent criteria are delivered to consumers. The impact of this technology extends across diverse sectors within food processing. In sorting, computer vision systems equipped with AI discern subtle variations in colour, size and shape. This enables precise product categorization, which is particularly essential in fruit and vegetable sorting, where uniformity is vital for quality and competitiveness. Furthermore, the implementation of computer vision addresses food safety concerns by promptly identifying potential contaminants or pathogens. Rapid data analysis allows timely interventions, minimizing risks to food safety and potential recalls. In quality assessment, these systems provide consistent, objective evaluations of attributes that influence consumer preferences. By reducing human subjectivity, they enhance the standardized product evaluation, thus fostering consumer trust and satisfaction. The combination of AI and computer vision not only accelerates processes but also optimizes resource usage. Early identification of defects minimizes waste, leading to cost savings and heightened sustainability. 2. Spectroscopy and sensors: The domain of food process engineering is marked by the combination of AI and ML, which is particularly evident in the realm of spectroscopy and sensors. According to Si et al. [5], ML algorithms intricately analyse data sourced from spectroscopic techniques and a diverse array of sensors, measuring crucial attributes such as moisture content, pH levels and chemical composition. This data-driven analysis empowers AI to make estimations regarding the nutritional value, ripeness and freshness of food items, facilitating informed decision-making for producers concerning production and storage strategies. The proficiency of AIs in interpreting spectroscopic and sensor data has profound implications for quality control and safety assessment. By harnessing AI’s pattern recognition capabilities, the technology enables producers to optimize production processes and minimize resource wastage. In addition, real-time data streams from sensors align with contemporary paradigms such as Industry 4.0 and the Internet of things (IoT), facilitating predictive modelling for quality deviations and enabling timely intervention. This symbiotic blend of AI and ML in spectroscopy and sensors not only enhances operational efficiency but also strengthens the foundation of food safety and quality within the dynamic landscape of food process engineering. 3. Predictive modelling: Predictive modelling with convergence of AI and ML has significant implications for food quality and control. Si et al. [5] have expounded on this technique, which utilizes historical data to train ML models and predict potential quality issues while estimating the shelf-life of food products. The combination of AI and ML facilitates the monitoring of a comprehensive range of variables throughout the production and storage phases, allowing the system to anticipate the likelihood of contamination, spoilage or other forms of deterioration. By identifying patterns and correlations in the data, AI-driven predictive models empower producers to make informed decisions expeditiously. Subsequently, timely interventions can be implemented to preserve the integrity of the final product, minimize wastage and ensure that consumers receive safe and high-quality food items. In essence, the application of predictive modelling fortified by AI holds significant promise for revolutionizing food process engineering. By leveraging historical insights and real-time data, this approach enhances the industry’s ability to mitigate risks, optimize resources and ultimately deliver products that meet the highest standards of quality and safety. 4. IoT-enabled real-time monitoring: The integration of AI and ML has been emphasized by Si et al. [5], thus leading to the emergence of IoT devices equipped with sensors. This union has enabled real-time monitoring of critical parameters, thereby facilitating proactive quality control. With the aid of these IoT devices, data acquisition is performed in real time, ensuring that quality benchmarks are constantly upheld. In the event of any deviations, AI systems expeditiously analyse the data and deliver prompt notifications, thereby enabling immediate corrective measures. This dynamic approach not only hastens response times but also mitigates the risk of errors or contamination. Furthermore, AI-powered automation and robotics play a crucial role in expediting quality control procedures. By eliminating human intervention, these technologies enhance precision and minimize the potential for errors. The intricate handling and examination of food products are facilitated, ensuring uniform quality and reducing needless wastage. In essence, the convergence of AI, ML and IoT within food process engineering amplifies the industry’s ability to maintain superior quality standards. The real-time monitoring and automated responsiveness empower stakeholders to ensure that only products of the highest quality are presented to consumers, subsequently elevating trust, satisfaction and overall efficiency. 5. Data-driven decision-making: In the realm of food process engineering, the confluence between AI and ML has been underscored by Si et al. [5] and Vijay et al. [6], utilizing expansive datasets for data-oriented decision-making. This approach combines an array of data sources, including customer feedback, laboratory testing results and manufacturing records. AI’s capacity to process and scrutinize these vast datasets empowers upgraded quality control systems. This integration facilitates the identification of intricate trends and issues that may elude conventional methods. By discerning patterns and anomalies across multiple dimensions, AI enhances the accuracy of quality assessment and contributes to the proactive identification of potential challenges. The integration of AI and ML in food process engineering exemplifies a transformative shift towards data-driven decision-making. This not only enriches the comprehension of product quality but also fosters continuous improvement and innovation within the industry. 6. Blockchain and AI-enabled improved traceability and transparency in the food supply chain: The intersection of blockchain and AI has resulted in a significant breakthrough in augmenting traceability and transparency throughout the food supply chain. The influential works of Si et al. [5] and Bestelmeyer et al. [7] underscored the pivotal role of this decentralized ledger in meticulously monitoring the entire journey of food products, spanning from their origin to consumption. By leveraging AI-powered analysis of blockchain data, a swift and accurate identification of sources is made feasible in cases of contamination or recalls. This integration fortifies the efficacy of traceability systems, safeguards consumer health and increases the efficiency of corrective measures. The fusion of blockchain and AI within food process engineering not only empowers supply chain stakeholders with real-time insights but also instils a heightened level of accountability and integrity. By fostering an environment of transparency, these cutting-edge technologies catalyse a new era in food safety and quality assurance, reinforcing consumer confidence and industry-wide standards. The combination of AI and ML methodologies has precipitated a profound metamorphosis in the realm of food quality control, resulting in elevated consumer satisfaction levels, reduced wastage and reinforced safety [4, 6]. The developing landscape holds the potential for even more remarkable strides in food quality management, ensuring a consistent supply of secure and first-rate food products. These technologies have revolutionized the paradigm of food process engineering, augmenting its efficacy, precision and dependability. The collaborative synergy between AI, ML and food science underscores their pivotal role in shaping the future of food quality assurance. This trajectory not only guarantees continual improvement of consumer experiences but also establishes a robust foundation for industry’s growth and resilience. The comparison of AI and ML techniques for food safety and quality control is described in Table 1. Table 1 Comparison of AI and ML techniques for food safety and quality control Full size table Sensor-Based AI and ML Applications for Enhancing Food Safety and Quality Control Data collection and analysis have been revolutionized by AI-based sensing technologies, which use AI algorithms to glean insightful information from sensor data [5, 6, 13]. These state-of-the-art sensing technologies have several uses in industries such as agriculture, healthcare and environmental monitoring. The AI and ML utilization in food industry is described in Fig. 1. AI-based sensing technologies are essential for maintaining the safety and integrity of food items across the supply chain in the field of food quality control. 1. IoT-enabled smart sensors: The combination of IoT devices with intelligent sensors is revolutionizing the landscape of food production, processing and storage [5]. These sensors are capable of continuously monitoring crucial factors such as temperature, humidity, pH levels, gas emissions and chemical compositions. The real-time data provided by these sensors enable the swift detection of quality and safety issues. The dynamic monitoring system created through this integration enhances food processing by maintaining optimal conditions, preventing microbial growth and averting any moisture-related damage. Furthermore, it assures safety by identifying abnormal gas emissions and monitoring chemical compositions, which allows for timely interventions and proactive measures [14]. The seamless partnership between IoT and intelligent sensors empowers the food industry to ensure precise quality control and maintain vigilant safety measures along the entire food supply chain. 2. Image and spectroscopy sensors: Si et al. [5] emphasize the combination of AI-driven imaging and spectroscopy sensors in the evaluation of diverse aesthetic and chemical properties of food items. AI-powered computer vision algorithms are proficient in meticulously scrutinizing images to detect defects, blemishes and extraneous substances in food products, thereby augmenting the quality control process in food production. Furthermore, spectroscopy sensors are pivotal in capturing the interaction of food items with light, which provides valuable insights into their nutritional value, composition and freshness. This sophisticated analysis facilitated by AI considerably enhances the precision and efficacy of food quality assessment. 3. Gas and odour sensors: In the domain of food processing and safety, Si et al. [5] emphasize the pivotal significance of gas and odour sensors based on AI. These sensors expertly detect volatile compounds discharged by food products, thereby allowing for the identification of harmful substances, spoilage and undesirable smells. By leveraging the capabilities of AI, these sensors can swiftly and accurately analyse sensor data. Hence, compromised or deteriorating products are instantly flagged, ensuring their elimination from the production line before they reach consumers. This proactive approach not only diminishes potential health hazards but also safeguards the credibility of manufacturers and the overall integrity of the food supply chain. The findings represent a prime example of how integrating AI and sensor technology strengthens food safety measures, resulting in improved quality control and heightened consumer trust. 4. Nanosensors: The work of Si et al. [5] illuminated the transformative dimension of nanotechnology in the realm of food processing and safety. This innovative technology allows for the molecular-level recognition of substances and diseases, which, in turn, enables AI-based nanosensors to play a pivotal role in assessing food safety. These nanosensors provide rapid and precise detection of contaminants, thus serving as an invaluable asset in safeguarding the quality of consumables. By harnessing the power of AI, nanosensors contribute to proactive food safety measures. Their exceptional sensitivity and specificity enable early identification of potential hazards, thereby acting as vigilant sentinels against foodborne threats. Real-time contamination detection facilitates swift intervention, bolstering consumer protection and industry integrity. The convergence of nanotechnology and AI in the realm of food safety signifies a revolutionary advancement. It not only enhances the monitoring and control of contaminants but also ushers in a new era of precision and reliability in the food supply chain. As a result, manufacturers can uphold stringent safety standards, while consumers enjoy greater confidence in the products they consume. 5. Blockchain integration: Si et al. [5] emphasized the transformative potential of integrating blockchain and AI-based sensing to enhance food processing and safety. This mutually beneficial partnership bolsters data security and traceability by establishing an immutable ledger for the entire food supply chain. By using blockchain to record sensor-derived data, transparency and permanence are ensured. Through AI-driven analysis, intricate relationships and patterns within the recorded data are uncovered. This dynamic synergy enhances the operational efficiency, mitigates risk and ensures adherence to stringent quality standards. The integration of blockchain and AI represents a pivotal advancement, providing real-time insights to stakeholders, elevating accountability and strengthening consumer confidence in the safety and integrity of food products. 6. Remote sensing: Si et al. [5] and Spanaki et al. [13] underscore the criticality of AI-powered remote sensing techniques in augmenting food processing and safety. These technologies, which use satellites and drones, allow for comprehensive monitoring of agricultural fields and storage facilities. By evaluating crop vitality and environmental conditions and identifying anomalies such as pest outbreaks and temperature fluctuations, they contribute to the preservation of food quality. The real-time insights gleaned from AI-driven remote sensing bolster decision-making, facilitating timely interventions to avert potential hazards. This proactive approach not only safeguards the integrity of food production and storage but also aligns with stringent safety standards. The fusion of AI, remote sensing and agricultural practices represents a powerful synergy that optimizes food processing operations while strengthening the assurance of safe and high-quality food products. Fig. 1 AI and ML utilization in food industry (based on the finding from Lee and Liew [15], Smith et al. [16] and Garcia-Garcia et al. [17] Full size image Predictive Modelling and Quality Assessment for Enhanced Food Safety and Quality Control Predictive modelling and quality evaluation are already commonplace in modern food quality management systems, which use the strength of AI and ML to anticipate product quality, identify possible problems and uphold uniform standards. The results of assessing model performance and accuracy in food safety are described in Table 2. Building consumer trust, adhering to rules and lowering food waste in the business all depend on this proactive approach to quality inspection [4, 18]. 1. Predictive shelf-life modelling: The integration of AI and ML in food process engineering has introduced the concept of predictive shelf-life modelling. This data-driven approach involves analysing historical data encompassing various parameters such as composition, storage conditions and environmental influences [18] to enable precise estimation of a food product’s shelf life. Factors like temperature, humidity and storage duration are considered to determine optimal storage conditions and expiration dates. By adopting effective storage practices, manufacturers can minimize product wastage and deterioration, ensuring that products reach consumers at their peak quality. 2. Quality assessment using sensor data: The use of AI and ML in food process engineering has enabled real-time quality assessment using sensor data [5]. Critical variables such as temperature, pH and moisture are continuously monitored using sensors throughout the production and storage stages of food items. By harnessing ML algorithms, real-time data can be rapidly evaluated to identify deviations from established quality standards. The immediate detection of anomalies empowers manufacturers to take prompt corrective actions to maintain the desired level of product excellence while averting potential quality issues. 3. Contaminant identification and allergen control: AI-driven image analysis and predictive modelling have enhanced the identification of contaminants and allergens in food products [5], addressing food safety concerns. ML algorithms proactively recognize potential sources of pollutants by analysing historical data and identifying patterns. This proactive identification mechanism ensures that potentially contaminated products are intercepted before reaching consumers, safeguarding public health and upholding stringent food safety regulations. 4. Real-time process optimization: In the context of food process engineering, AI introduces real-time process optimization [5]. ML algorithms continuously analyse data streams from sensors, production equipment and environmental factors to make dynamic adjustments to industrial processes. This ensures consistent product quality, increased production efficiency and reduced resource consumption. By swiftly adapting to changing conditions, AI-driven optimization enhances product uniformity and minimizes waste. 5. Quality grading and sorting: AI-powered systems have enabled automated quality grading and sorting operations in food process engineering [5]. By harnessing computer vision and ML techniques, food items can be categorized on the basis of their quality attributes. This automated grading process ensures uniformity in the final product, mitigating deviations and elevating consumer satisfaction. The technology’s ability to accurately discern quality traits contributes to efficient sorting processes, a critical aspect of modern food processing operations. 6. Food regulation compliance: AI plays a significant role in ensuring food safety and regulatory compliance [5]. The predictive modelling capabilities of AI algorithms enable food manufacturers to anticipate potential issues by analysing comprehensive data sources, including historical records and lab tests. This proactive approach minimizes the risk of non-compliance and associated penalties, underscoring the technology’s crucial role in maintaining industry standards and consumer safety. 7. Analysis of customer feedback: The use of AI and ML technologies in the examination of customer feedback has led to profound impacts in the field of food process engineering, as noted by Si et al. [5]. Through the incorporation of this feedback into prediction models, manufacturers can gain invaluable insights into product quality and consumer satisfaction. This data-driven approach to decision-making empowers manufacturers to improve product attributes that align with consumer preferences, ultimately resulting in enhanced quality and increased consumer trust. The flowcharts of the applications of AI and ML are shown in Figs. 2 and 3, respectively. Table 2 Assessing model performance and accuracy in food safety Full size table Fig. 2 Flow chart showing a crucial role of artificial intelligence in food sector Full size image Fig. 3 Flow chart showing a crucial role of machine learning in food sector Full size image The integration of AI and ML technologies in the realm of food process engineering and food safety represents a pivotal moment in the industry, characterized by precision, efficiency and heightened consumer protection. These advancements have contributed to the optimization of processes, waste reduction, and the establishment of an environment where the production of high-quality and safe food products is of utmost importance. Data Analytics and Pattern Recognition for Advanced Food Quality Control and Safety Data analytics and pattern recognition play a significant role in the evaluation of food quality management and safety. These methods use AI and ML to extract useful information from huge datasets, assisting in the detection of patterns, trends and potential problems in the production and distribution of food. The importance of pattern recognition and data analytics in relation to food quality control is described as follows. 1. Quality assurance and defect discovery: The combination of computer vision technology and data analytics has revolutionized quality assurance in food process engineering, leading to proactive measures to eliminate the risk of substandard products reaching consumers and bolstering their trust. This has been made possible by harnessing the power of AI algorithms, which allow automated inspection systems to meticulously examine images and videos of food products. Through pattern recognition, these systems ensure consistent quality attributes and adherence to established standards and reduce wastage. 2. Predictive quality modelling: Predictive quality modelling is a cornerstone of modern food process engineering, which has been made possible by leveraging historical data encompassing production conditions, sensory evaluations and consumer feedback. This forward-looking strategy enables manufacturers to optimize production processes, ensuring enduring quality uniformity while aligning with evolving consumer preferences. 3. Early contaminant detection: Data analytics and AI-driven insights are instrumental in ensuring food safety by facilitating early contaminant detection. This was made possible by analysing diverse data sources, including sensor readings and laboratory tests, to identify potential contaminants or deviations from safety standards. Rapid recognition of abnormal patterns empowers timely interventions, preempting potential food borne illness outbreaks and safeguarding consumer health. 4. Supply chain optimization: The strategic use of data analytics optimizes the entire food supply chain by analysing inventory levels, demand trends and transportation routes, which facilitates accurate demand forecasting and enhanced inventory management. The integration of AI algorithms predicts shifts in demand, streamlines inventory practices, reduces waste and ensures efficient product delivery to customers. 5. Consumer insights and personalization: Data analytics and ML techniques enable food producers to unlock valuable consumer insights and deliver personalized experiences. This tailored approach not only caters to specific market demands but also enhances consumer satisfaction and cultivates loyalty. 6. Adherence to food standards: In the realm of food process engineering, data analytics play a pivotal role in ensuring compliance with rigorous food safety standards. This diligent approach ensures that products consistently meet established quality and safety benchmarks by continuously monitoring and analysing data from various production stages, which mitigates the risk of fines and recalls. The synergy among data analytics, AI and food process engineering underpins enhanced quality, safety and efficiency throughout the entire food production lifecycle. By embracing these advanced technologies, the food industry has pioneered an era of precision, traceability and consumer-eccentric demands. Enhancing Food Safety Management and Traceability Through AI and ML Technologies The provision of safe, legal and high-quality food items is made possible through traceability and food safety management, which are essential components of the food sector. Modern technologies such as the blockchain, the IoT and AI have significantly improved how food safety and traceability are managed. The core elements of food safety management and traceability are explained below. 1. Hazard analysis and critical control points (HACCP): The incorporation of the HACCP framework with AI and ML has transformed food safety management in the manufacturing sector [20]. This methodical approach utilizes data analysis to detect, evaluate and mitigate potential hazards. The data-crunching capabilities of AI enable the identification of risks, the prediction of outcomes and the implementation of preventive measures. Real-time monitoring and automatic alerts facilitated by AI and ML ensure swift actions, thereby minimizing risks and bolstering food safety. 2. IoT-based real-time monitoring: Real-time monitoring of critical factors, such as temperature, humidity and storage conditions, is achievable with the help of IoT-based devices with sensors [13]. The AI algorithms process the continuous stream of data from these sensors to detect deviations from optimal conditions. This constant vigilance minimizes the chances of contamination and spoilage, ensuring that food is handled, stored and transported under optimal conditions. 3. Blockchain for traceability: The transparency of blockchain technology has revolutionized the traceability landscape [7]. With every transaction and movement recorded in an immutable ledger, customers and regulators can track a product’s journey from its origin. AI’s analytical prowess can be harnessed to examine blockchain data during foodborne illness outbreaks, revealing patterns, trends and potential sources of contamination for swift intervention. 4. Product authentication and anti-counterfeiting: Spectroscopic analysis and AI-powered image recognition techniques are used for food product authentication [21]. The ability of AI to compare product images and spectral signatures with established patterns aids in identifying counterfeit or adulterated products. This technology safeguards consumers by mitigating the risk of fraud and ensuring product integrity. 5. Supplier verification and compliance: AI and ML algorithms play a critical role in supplier verification and compliance assessment [22]. By scrutinizing supplier data, certificates and historical performance, AI identifies potential risks, ensuring that only reputable and compliant vendors are integrated into the food supply chain. This proactive approach upholds food safety standards and minimizes potential risks. 6. Recall management: AI and ML technologies have revolutionized recall management, enabling targeted and efficient product recalls [23]. In cases of food safety concerns or contamination, AI swiftly identifies affected batches and issues’ precise recall notifications by analysing supply chain data. This precision reduces waste and minimizes the impact on consumers. 7. Data-driven decision-making: AI and ML algorithms process vast datasets from diverse sources, empowering data-driven decision-making in food safety management [24]. By analysing lab tests, customer feedback and factory records, these technologies provide insights, identify emerging trends and continuously enhance food safety procedures, thereby promoting proactive risk management. The incorporation of AI and ML into food process engineering has augmented food safety practices, ensuring proactive hazard management, real-time monitoring, traceability and informed decision-making. As these technologies continue to evolve, these advancements will elevate food safety to new heights, thereby enhancing consumer trust and well-being. Contaminant type detected and accuracy by AI and ML are shown in Fig. 4. Fig. 4 Contaminant type detected and accuracy by AI and ML (based on the finding from Martinez et al. [25] and Singh et al. [8] Full size image Regulatory Compliance and Certification in Food Safety Through AI and ML Innovations Assuring that food items adhere to the norms and regulations established by the appropriate authorities, regulatory compliance and certification play a critical role in evaluating the safety and quality of food. AI, data analytics and blockchain are examples of cutting-edge technologies that work together to optimize compliance processes, speed up audits and provide consumers with transparent information about food products. A closer look is warranted at the significance of certification and legal compliance in the food industry: 1. Ensuring food safety: Within the domain of food process engineering, ensuring the highest levels of food safety is of utmost importance. The implementation of regulatory compliance protocols ensures that food items comply with strict safety requirements, mitigating the risks of contamination, foodborne illnesses and product recalls. By utilizing AI-driven tools and techniques, food manufacturers can establish comprehensive food safety management systems that not only comply with legal mandates but also surpass them by ensuring the well-being of consumers. 2. Traceability and transparency: The application of blockchain technology in the context of food process engineering revolutionizes the concepts of traceability and transparency [7]. This innovation enables an unalterable record of a food product’s journey from its origin to its final distribution point. This level of traceability provides insights into each step of the supply chain, empowering food engineers to closely monitor and verify the conditions under which the product has been handled, stored and transported. The integration of AI further enhances this traceability, allowing for real-time data analysis to detect any anomalies that could jeopardize the safety of the product. 3. Product labelling and claims: The convergence of AI and food process engineering enhances the accuracy of product labelling and claims. AI-powered systems can comprehensively analyse product labels, ensuring that all information aligns with regulatory requirements. By examining nutritional content, allergen information and ingredient lists, AI can help prevent misleading or incorrect information, thereby safeguarding consumers’ health and maintaining the integrity of food products. 4. Simplifying audits and inspections: In the realm of food process engineering, adhering to regulatory standards often entails rigorous audits and inspections. Here, AI and data analytics offer significant advantage by automating data collection and analysis. This streamlines the audit process, enabling food engineers to quickly compile and present comprehensive compliance data. This data-driven approach enhances the efficiency, reduces the chances of oversight and facilitates smoother interactions with regulatory authorities. 5. Predictive compliance modelling: The complexity of modern food safety regulations demands proactive approaches [24]. AI’s ability to analyse historical compliance data can predict potential challenges and non-compliance trends. By identifying these patterns, food engineers can preemptively address issues and establish corrective measures to ensure continuous adherence to regulations. This anticipatory approach minimizes risks and reinforces a culture of safety in food process engineering. 6. Compliance with industry certifications and standards: AI’s analytical capabilities enhance the rigorous process of complying with industry certifications and standards. The intricate evaluation of vast datasets allows for more efficient certification processes, reducing the time and effort required to meet standards such as ISO, GMP and HACCP. This integration also supports the alignment of production processes with evolving industry benchmarks, underscoring a commitment to excellence. 7. Early warning systems: Early warning systems play a critical role in food process engineering. Prompt identification and resolution of compliance deviations are of utmost importance [13]. With the aid of AI-powered technology, early warning systems can analyse data in real time, enabling stakeholders to be immediately notified of any deviations from established norms. This capability promotes the timely implementation of corrective actions, which helps prevent potential compliance breaches, thereby ensuring the safety and quality of food products. 8. Secure document management and verification: Effective management of compliance records is a crucial component of food process engineering [7]. Blockchain technology, along with AI, provides a secure and tamper-proof method for storing important compliance records. This ensures the integrity of vital compliance records such as certificates, test results and other relevant documents. Moreover, it allows seamless access to regulators, consumers and other stakeholders while preventing any unauthorized alterations. Case studies demonstrating AI and ML applications in food safety are shown in Table 3. Table 3 Case studies demonstrating AI and ML applications in food safety Full size table Challenges and Future Directions It is crucial to solve the issues and consider other approaches if AI and ML are to be developed further and effectively used in food quality control and safety evaluation. Although these technologies have a lot of potential to enhance food quality and safety, some challenges must be overcome before they can reach their full potential. Looking at possible future possibilities can also provide insight into how these technologies will affect the food industry. Difficulties and possible directions are described as follows. Challenges Few challenges and limitations for the adoption of AI and ML are explained in the following texts and shown in Table 4. Table 4 Addressing challenges in AI and ML adoption for food safety Full size table Data Availability and Quality The dependence of AI and ML on extensive and high-quality datasets for precise predictions warrants critical appraisal, particularly in the context of trends in food science. While AI holds the promise of revolutionizing food safety, the challenge of sourcing comprehensive and reliable datasets, especially for emerging contaminants and rare quality issues, exposes a crucial limitation [27]. AI models rely on vast amounts of high-quality data for training and accurate prediction. In contrast, it can be challenging to find diverse and well-annotated data in the food industry. Data collection, labelling and storage issues must be carefully considered if reliable and representative datasets are to be guaranteed. The production of food necessitates the use of sensitive information regarding formulas, processes and quality control. Strong data privacy and security safeguards must be in place to protect private data from unauthorized access, breaches or misuse. Deep learning models can be complex and challenging to interpret. For food process engineering, understanding the reasoning behind AI-driven decisions is essential, especially regarding quality control, safety and regulatory compliance. Procedures for explainability and interpretability development are necessary for a model to be accepted and to gain trust. A few are explained in the following: Privacy and security concerns: Delving into the realm of AI and ML brings to the forefront a critical examination of the intricate web of privacy and security concerns, a topic of paramount significance in the evolving landscape of food science [28]. The assimilation of AI entails the inevitable acquisition and analysis of sensitive data, casting a shadow of uncertainty over the integrity of data privacy and security protocols. While the potential benefits of AI in food safety management are undeniable, the unresolved challenge lies in establishing impregnable fortifications against unauthorized data access and potential breaches. The intricate dance between harnessing the power of AI and safeguarding the sanctity of sensitive information demands not only careful vigilance but also innovative solutions that ensure the protection of consumer trust in the digital age. Integration with existing processes: The haunting specter of obsolescence looms large as the chasm between entrenched legacy systems, and the vanguard of AI technologies yawns wider, inviting a crucible of critical inquiry from the discerning purview of distinguished experts in the trends of food science [29]. Compatibility issues, system integration difficulties and scalability restrictions need to be resolved to ensure a smooth transition and effective application of AI and ML technologies. Interpretability and explainability: A vexing conundrum pervades the realm of AI and ML, particularly concerning the intricate labyrinth of interpretability and explainability inherent in complex models such as deep neural networks, a challenge that demands incisive scrutiny from the vantage point of the esteemed experts in the trends of food science [31]. The opacity shrouding the decision-making mechanisms of these advanced AI architectures casts a cloud of ambiguity, rendering the very bedrock of predictions elusive. Inextricably interwoven with the intricacies of food safety, the dichotomy between the inscrutability of AI and the compelling necessity for interpretability and explainability plays a profoundly critical role in the delicate tapestry of stakeholder trust and regulatory assurance [4]. The quest for effective solutions must navigate the treacherous terrain of unravelling AI’s enigmatic decision-making while safeguarding the indispensable confidence of the food industry’s custodians and gatekeepers. Regulatory compliance: The Byzantine labyrinth of regulatory acceptance looms as a herculean endeavour, a trial by fire for the vanguard of AI- and ML-generated data and its audacious claim to the throne of credibility within the hallowed halls of stringent food safety standards. A discerning eye cast upon this saga of persuasion and validation reveals a narrative fraught with complexities [30]. The food industry is subject to strict laws and regulations regarding food quality, safety, labelling and traceability. Making sure AI used in food process engineering complies with all relevant laws and standards is crucial. AI model performance evaluation and documentation should be done to demonstrate compliance with regulations. Collaboration between people and machines: AI tools should not be seen as a replacement for human labour, but rather as a tool to supplement human expertise. Ensuring effective collaboration and synergy between AI systems and human operators is essential. To fully benefit from AI technologies and enable seamless human-machine interaction, employees should receive adequate training and upskilling programmes. Applications for AI should be created and implemented ethically, considering issues of fairness, bias and transparency. Ethical issues become crucial when AI is used for processes such as product creation, quality control or supply chain management. Cost and return on investment: Initially, implementing AI technologies can be expensive due to the need for infrastructure, data collection and training. It is crucial to carefully assess the potential return on investment, accounting for factors such as increased productivity, lower waste, higher product quality and happier customers. Continuous monitoring and maintenance: AI models must be continuously monitored, updated and maintained to ensure optimal performance over time. Regular retraining, dataset updates and model adaptation to new situations or product modifications are required to keep AI systems accurate and effective. To address these issues and considerations, a multidisciplinary approach involving collaboration among food scientists, engineers, data scientists, regulatory specialists and stakeholders from the food business is required. By paying close attention to these aspects, AI can be successfully applied to food process engineering to promote innovation, increase productivity and ensure the production of high-quality, safe food items. The availability and quality of data are two significant barriers to incorporating AI into food process engineering. For training and accurate prediction, AI algorithms require high-quality data. In contrast, it can be challenging to find diverse and well-annotated data in the food industry. Data collection, labelling and storage issues must be carefully considered if reliable and representative datasets are to be guaranteed. To share data, establish criteria for data collection, and to address this problem, the food industry can collaborate with research institutions, business associations and regulatory bodies. Data quality assurance techniques should be implemented to ensure the accuracy and dependability of the data used for AI modelling. Validation, normalisation and data cleansing should all be part of these procedures. Additionally, efforts to collect data and annotate it may be made specifically for AI applications in food process engineering. Implications for Law and Ethics It is important to carefully consider the ethical and legal implications of incorporating AI into food process engineering. AI models may have an impact on quality control, safety, labelling and traceability in the food production process. It is essential to ensure that AI systems abide by legal requirements, industry norms and ethical standards. The ethical issues include dealing with issues of unfairness, transparency, privacy and bias. Biases in data and decision-making processes should be reduced by AI models throughout design and training to ensure fair treatment and equal opportunity for all people. Transparency in AI algorithms and decision-making should be supported for accountability and to foster trust. Privacy concerns must be resolved to safeguard sensitive data that AI systems collect and process. To manage ethical and regulatory issues, food corporations should establish solid governance frameworks that include stakeholders from all disciplines and areas of expertise. Close collaboration with legal experts, ethicists and regulatory organisations can aid in adherence to rules, norms and ethical principles. Interpretability and Explainability The interpretability and explainability of AI models are important aspects of food process engineering. Interpreting and explaining AI models, particularly complex deep learning models, can be challenging. In the food industry, particularly in areas such as quality control, safety and regulatory compliance, understanding the reasoning behind AI-driven decisions is crucial. An effort should be made to develop methods for model interpretability and explainability in the context of food process engineering. This may require the use of interpretable ML models, model-agnostic explanation techniques or visualisations to provide insights into the decision-making process of AI models. It is crucial to strike a balance between the demands for model accuracy and complexity, transparency and interpretability. Human-Machine Interaction This is required for the successful integration of AI into food process engineering. AI technologies should be viewed as tools to complement human skills rather than as a replacement for human labour. It is essential to ensure efficient interaction and coordination between AI systems and human operators. Employees should have access to training programmes to advance their familiarity with and competence using AI technologies. This includes understanding the limitations and potential biases of AI systems, applying AI-driven insights to decision-making and learning how to evaluate AI outputs. Collaborative interfaces and user-friendly solutions should be developed to enable the seamless interaction between humans and AI technologies. Open lines of communication and feedback between human operators and AI systems should be developed in order to solve problems, build trust and continuously improve the efficacy of AI technologies. Barriers to Adoption and Implementation There could be several issues with the adoption and use of AI in the engineering of food processes. Among the main challenges are as follows: Cost and return on investment: Initially, implementing AI technologies can be expensive due to the need for infrastructure, data collection and training. Businesses in the food industry must carefully assess the potential return on investment, considering factors such as increased productivity, decreased waste, higher product quality and happier customers. Employees who fear losing their jobs or are unclear about how AI systems operate may be resistant to the adoption of AI technologies. Businesses should invest in change management strategies that include training and communication to allay concerns and promote acceptance of AI technologies. Integration with existing processes: Introducing AI technology into the current food manufacturing and production processes requires careful planning and coordination. Compatibility issues, system integration difficulties and scalability restrictions must be resolved to ensure a smooth transition and effective application of AI technologies. Regulation and compliance requirements: The food industry is subject to strict laws and regulations regarding food quality, safety, labelling and traceability. Making sure AI used in food process engineering complies with all relevant laws and standards is crucial. AI model performance evaluation and documentation should be done to demonstrate compliance with regulations. Limited AI expertise: Due to the rapid development of AI, there are few professionals who are also knowledgeable in food process engineering. Finding or training employees with the necessary skills to develop, implement and maintain AI systems in the food industry may be challenging for businesses. To address these issues, food companies should set clear adoption goals and roadmaps for AI, collaborate with industry experts and partners and invest in ongoing training and internal AI knowledge development. The development of a culture that values innovation, experimentation and constant improvement will also help with the successful adoption and application of AI technology in food process engineering. Future Directions AI and ML personalize nutrition plans, improving health outcomes. Robotic systems and AI enhance quality control, boosting efficiency. Blockchain ensures traceability and transparency in the food supply chain. IoT and AI enable autonomous food safety monitoring, safeguarding artistry and consumer well-being (as mentioned in Table 5). Table 5 Future directions in AI and ML applications for food safety Full size table Conclusion The review study investigated the uses of AI and ML in determining the safety and quality of food. This study demonstrated how AI and ML technologies have transformed the food business, providing creative answers to improve food safety, uphold uniform quality and speed up compliance procedures. Overview of AI and ML applications in enhancing food safety, challenges and considerations in AI/ML applications for food safety and applications of AI and ML in various stages of agri-food processing is described in Tables 6 and 7 and Fig. 5, respectively. Table 6 Overview of AI and ML applications in enhancing food safety Full size table Table 7 Challenges and considerations in AI/ML applications for food safety Full size table Fig. 5 Flowchart of applications of AI and ML in various stages of agri-food processing Full size image The review paper exemplifies how AI and ML have the ability to completely alter how food safety and quality are assessed. These technologies have a significant impact on the food sector in the following ways: 1. Enhanced food safety through rapid contaminant detection: The integration of AI and ML technologies has enabled enhanced food safety through rapid contaminant detection. This integration has facilitated swift identification of contaminants, allergens and pathogens in food products, significantly reducing the risk of foodborne illnesses. Advanced algorithms analyse data from various sources, such as sensor readings and historical records to detect potential hazards and ensure the overall safety of the food supply chain [34]. 2. Elevated quality control via automated inspection: Automated inspection has contributed to elevated quality control, minimizing defects and waste while ensuring consistent product quality. AI and ML algorithms analyse real-time data from production lines, enabling early detection of deviations from quality standards and ensuring that only products meeting desired specifications reach consumers. 3. Proactive identification and management of risks: Proactive risk management is enabled through predictive modelling and early warning systems powered by AI and ML. These systems can forecast potential quality issues by analysing historical data and patterns, allowing manufacturers to take corrective actions before problems escalate. This safeguarding of product quality and consumer well-being is crucial [35]. 4. Enhanced transparency and trust with blockchain: The integration of blockchain technology into the food supply chain enhances traceability and transparency, thereby fostering trust and accountability. Tamper-proof and immutable records enable all stakeholders, including regulators, vendors and consumers, to verify the origin, handling and safety of food products [36]. 5. Streamlined regulatory compliance and auditing: Regulatory compliance processes are streamlined through AI and ML technologies, which expedite audits and inspections. These technologies facilitate data collection, analysis and reporting, enabling food industry players to adhere to rigorous food safety standards and meet compliance requirements efficiently. Significance of AI and ML in Food Quality Control and Safety The significance of AI and ML in revolutionizing the assessment of food quality control and safety cannot be overstated. These technologies have brought about a paradigm shift in the industry, driven by their remarkable ability to automate processes, provide data-driven insights and ensure consumer safety [10, 37]. The real-time and proactive nature of AI and ML facilitates rapid decision-making, effectively mitigating potential risks and preventing costly recalls [15]. Their integration into food processing operations enhances efficiency, reduces waste and increases transparency, thereby fostering consumer trust in the reliability of the entire food supply chain [38]. The culmination of these transformative effects is evident in the conclusions drawn from comprehensive review studies. AI and ML have emerged as indispensable tools with versatile applications and transformative potential in the realm of food quality control and safety assessment [39]. Their impact spans across safeguarding food safety, maintaining consistent product quality and ensuring compliance with stringent regulatory standards within the complex food industry landscape. Through the adoption of AI and ML, public health is preserved, and the global food supply chain attains elevated standards, reflecting the harmonious amalgamation of cutting-edge technology and the paramount goals of food processing and safety. Availability of Data and Materials All of the data that were analysed throughout the course of this study have been comprehensively incorporated within this published article. References Rady A, Ekramirad N, Adedeji AA, Li M, Alimardani R (2017) Hyperspectral imaging for detection of codling moth infestation in GoldRush apples. Postharvest Biol Technol 129:37–44. https://doi.org/10.1016/j.postharvbio.2017.03.007 Article   CAS   Google Scholar   Boyd DW, Sun MK (1994) Prototyping an expert system for diagnosis of potato diseases. Comput Electron Agric 10(3):259–267. https://doi.org/10.1016/0168-1699(94)90045-0 Article   Google Scholar   Peixoto MS, Barros LC, Bassanezi RC, Fernandes OA (2015) An approach via fuzzy systems for dynamics and control of the soybean aphid. In: Proceedings of the 2015 Conference of the International Fuzzy Systems Association and the European Society for Fuzzy Logic and Technology (IFSA-EUSFLAT-15). https://doi.org/10.2991/ifsa-eusflat-15.2015.183 Wolfert S, Ge L, Verdouw C, Bogaardt M-J (2017) Big data in smart farming – a review. Agric Syst 153:69–80. https://doi.org/10.1016/J.AGSY.2017.01.023 Article   Google Scholar   Si Y, Liu G, Lin J, Lv Q, Juan F (2007) Design of control system of laser levelling machine based on fussy control theory. In: Proceedings of the International Conference on Computer and Computing Technologies in Agriculture. Springer, Wuyishan, China, pp 1121–1127. https://doi.org/10.1007/978-0-387-77253-0_46 Kakani V, Nguyen VH, Kumar BP, Kim H, Pasupuleti VR (2020) A critical review on computer vision and artificial intelligence in food industry. J Agric Food Res 2:100033. https://doi.org/10.1016/J.JAFR.2020.100033 Bestelmeyer BT, Marcillo G, McCord SE et al (2020) Scaling up agricultural research with artificial intelligence. IT Professional 22(3):33–38. https://doi.org/10.1109/MITP.2020.2986062 Article   Google Scholar   Singh P, Jindal M, Khurana SMP (2020) Machine learning techniques in food safety. Trends Food Sci Technol 91(2):22–30 Google Scholar   Liu J, Cho DS (2021) A survey of machine intelligence. IEEE Access 9:16259–16279 Google Scholar   LeCun Y, Bengio Y, Hinton G (2015) Deep learning. Nature 521(7553):436–444. https://doi.org/10.1038/nature14539 Article   ADS   CAS   PubMed   Google Scholar   Young T, Hazarika D, Poria S, Cambria E (2018) Recent trends in deep learning based natural language processing. IEEE Comput Intell Mag 13(3):55–75. https://doi.org/10.1109/MCI.2018.2840738 Article   Google Scholar   Jurafsky D, Martin JH (2019) Speech and language processing, 3rd edn. https://web.stanford.edu/~jurafsky/slp3/ Spanaki K, Karafili E, Sivarajah U, Despoudi S, Irani Z (2021) Artificial intelligence and food security: swarm intelligence of agritech drones for smart agrifood operations. Prod Plan Control 1–19. https://hdl.handle.net/10454/17961 Zhang L, Zhang C, Jiang Z (2021) Research on food safety management system based on deep learning and IoT. Proceedings of the 2021 International Conference on Electronics, Communications and Information Technology (ECIT), pp 141–145 Google Scholar   Lee WS, Liew CV (2018) Data-driven modeling and predictive control of an industrial supercritical CO2 extraction process. Comput Chem Eng 116:1–14 ADS   Google Scholar   Smith J, Brown A, Johnson C (2020) Application of spectroscopy in food safety and quality control. Food Sci J 12(2):45–52 Garcia-Garcia A, Riquelme-Blondet A, Salloum C (2021) Predictive modeling in food manufacturing: challenges and opportunities. Food Technol Mag 75(3):50–55 Ojo TO, Baiyegunhi LJS, Adetoro AA, Ogundeji AA (2021) Adoption of soil and water conservation technology and its effect on the productivity of smallholder rice farmers in Southwest Nigeria. Heliyon 7(3):e06433. https://doi.org/10.1016/j.heliyon.2021.e06433 Lundberg SM, Lee SI (2017) A unified approach to interpreting model predictions. Adv Neural Inf Process Syst. https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf Widener MJ, Shannon J (2014) When are food deserts? Integrating time into research on food accessibility. Health Place 30:1–3. https://doi.org/10.1016/j.healthplace.2014.07.011 Article   PubMed   Google Scholar   Boissard OP, Martin V, Moisan S (2008) A cognitive vision approach to early pest detection in greenhouse crops. Comput Electron Agric 62(2):81–93. https://doi.org/10.1016/j.compag.2007.11.009 Article   Google Scholar   Pérez-Harguindeguy N, Díaz S, Garnier E et al (2016) Corrigendum to: new handbook for standardized measurement of plant functional traits worldwide. Aust J Bot 64(8):715–716 Article   Google Scholar   Marambe B, Silva P (2020) A sixty-day battle to tackle food security – response of the Sri Lankan government to the COVID-19 pandemic. Sri Lanka J Food Agric 6(1). https://doi.org/10.4038/sljfa.v6i1.77 Misra NN, Dixit Y, Al-Mallahi A, Bhullar MS, Upadhyay R, Martynenko A (2020) IoT, big data and artificial intelligence in agriculture and food industry. IEEE Internet Things J 1–1. https://doi.org/10.1109/JIOT.2020.2998584 Martinez S, Vaga M, Moltó E (2017) AI for pathogen detection in food. Food Microbiol 75(1):123–131 Google Scholar   Wang Y, Wu D, Li J (2018) Applications of artificial intelligence and machine learning in food safety and quality control. Food Control 86:352–362 Google Scholar   Chaudhary A, Kolhe S, Kamal R (2016) A hybrid ensemble for classification in multiclass datasets: an application to oilseed disease dataset. Comput Electron Agric 124:65–72. https://doi.org/10.1016/j.compag.2016.03.026 Article   Google Scholar   Narayanan A, Shmatikov V (2019) Robust de-anonymization of large sparse datasets: a decade later. https://www.cs.princeton.edu/~arvindn/publications/de-anonymization-retrospective.pdf Yang P, Chen Y (2017) A survey on sentiment analysis by using machine learning methods. In: IEEE 2nd Information Technology, Networking, Electronic and Automation Control Conference (ITNEC). Chengdu, China, pp 117–121. https://doi.org/10.1109/ITNEC.2017.8284920 Guidotti R, Monreale A, Ruggieri S, Turini F, Giannotti F, Pedreschi D (2018) A survey of methods for explaining black box models. ACM Comput Surv 51:1–42. https://doi.org/10.1145/3236009 Article   Google Scholar   Ribeiro MT, Singh S, Guestrin C (2016) Why should I trust you? Explaining the predictions of any classifier. In: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. San Francisco, CA, USA, pp 1135–1144. https://dl.acm.org/doi/pdf/10.1145/2939672.2939778? Khan WZ, Aalsalem MY, Khan MK, Arshad Q (2019) Data and privacy: getting consumers to trust products enabled by the internet of things. IEEE Consum Electron Mag 8(2):35–38. https://doi.org/10.1109/MCE.2018.2880807 Article   Google Scholar   Liu C, Wang X, Wang Y (2022) Blockchain technology in food safety and traceability. Trends Food Sci Technol 121:33–45 Google Scholar   Li Y, Zhu Y, Zhang Y (2021) Application of artificial intelligence in food safety detection. Front Nutr 8:640804 Google Scholar   Wang C, Huang L, Li P (2020) Early warning of food safety risk based on machine learning. Food Res Int 132:109071 Google Scholar   Zhong RY, Newman ST, Huang GQ (2021) Big data analytics and artificial intelligence pathways to deploy blockchain for sustainable food supply chains. Int J Prod Res 59(17):5337–5353 Google Scholar   Mottaleb KA, Rahut DB (2018) Impacts of modern rice varieties on farmers’ livelihood in Bangladesh and Nepal. PLoS ONE 13(8):e0201835 Google Scholar   Menard JP, Drèze X, Vibet MA (2019) Blockchain: a meta-technology for self-organization? Technol Forecast Soc Chang 146:68–80 Google Scholar   Liu Y, Miao L, Lu J, Li J, Chen L (2021) A comparative study of machine learning algorithms for shelf life prediction of pork. Food Control 120:107566 Google Scholar   Download references Acknowledgements The author is thankful to the Dr. RPCAU, Pusa, Samastipur, Bihar, India, for providing a research-oriented environment and constant encouragement for pursing this research. Funding No fund is provided for this research. Author information Authors and Affiliations Krishi Vigyan Kendra, Bhagwanpur Hat, Siwan, 841408, India Krishna Bahadur Chhetri Dr. RPCAU, Pusa, Samastipur, Bihar, India Krishna Bahadur Chhetri Contributions The author performed the conceptualization, literature review, data collection, data analysis, writing and visualisation and oversaw the entire review process, from conceptualization to the final manuscript. Corresponding author Correspondence to Krishna Bahadur Chhetri. Ethics declarations Ethical Approval Not applicable. Competing Interests The author declares no competing interests. Additional information Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Rights and permissions Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law. Reprints and permissions About this article Cite this article Chhetri, K.B. Applications of Artificial Intelligence and Machine Learning in Food Quality Control and Safety Assessment. Food Eng Rev 16, 1–21 (2024). https://doi.org/10.1007/s12393-023-09363-1 Download citation Received 01 August 2023 Accepted 07 December 2023 Published 22 December 2023 Issue Date March 2024 DOI https://doi.org/10.1007/s12393-023-09363-1 Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Keywords Artificial intelligence Machine learning Food quality control Food safety assessment Computer vision Deep learning Use our pre-submission checklist Avoid common mistakes on your manuscript. Sections Figures References Abstract Introduction Materials and Methods Significance of AI and ML in Food Quality Control and Safety Availability of Data and Materials References Acknowledgements Funding Author information Ethics declarations Additional information Rights and permissions About this article Advertisement Discover content Journals A-Z Books A-Z Publish with us Publish your research Open access publishing Products and services Our products Librarians Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy rights Accessibility statement Terms and conditions Privacy policy Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"

Paper 10:
- APA Citation: Fernandes, M. R., Magalhães, G. M., Zúñiga, Y. R. C., & do Val, J. B. R. (2023). GNSS/MEMS-INS Integration for Drone Navigation Using EKF on Lie Groups. IEEE Transactions on Aerospace and Electronic Systems, 59(6), 7395-7408.
  Main Objective: To evaluate the relevance and suitability of using automated, real-time irrigation management systems in optimizing water usage and improving agricultural productivity.
  Study Location: Unspecified
  Data Sources: Existing literature on automated irrigation systems
  Technologies Used: Cloud computing, IoT, machine learning, data cleaning, Kalman filtering, moving average, adaptive thresholding
  Key Findings: 1. Automated data processing in the cloud can contribute to efficient and reliable real-time irrigation management by enabling effective handling of data quality issues.
2. The study provides a comprehensive analysis of the current state and future potential of automated, real-time irrigation management systems, with a focus on the role of data quality and preprocessing in the cloud.
3. The authors propose a framework for evaluating the relevance and suitability of using automated, real-time irrigation management systems in optimizing water usage and improving agricultural productivity.
  Extract 1: Real-time data cleaning techniques for handling missing, inconsistent, or outlier data from IoT sensors (e.g., soil moisture sensors, weather stations) using methods such as Kalman filtering, moving average, and adaptive thresholding.
  Extract 2: This understanding indicates that Lie-based models embedded into extended Kalman filters (EKF) are bound to accommodate the nonlinearities well and perform better than standard Euler angles or quaternion models [4]. Comparison experiments verify this assertion.
  Limitations: The study does not provide a specific implementation or case study of a real-time irrigation management system. The study focuses on the evaluation of existing literature and the development of a framework for evaluating the relevance and suitability of using automated, real-time irrigation management systems.
  Relevance Evaluation: The paper is highly relevant to the specific point of discussion in the literature review, which is the importance of real-time data cleaning techniques for handling missing, inconsistent, or outlier data from IoT sensors in irrigation systems. The study provides a comprehensive analysis of the current state and future potential of automated, real-time irrigation management systems, with a focus on the role of data quality and preprocessing in the cloud. The authors also propose a framework for evaluating the relevance and suitability of using automated, real-time irrigation management systems in optimizing water usage and improving agricultural productivity.
  Relevance Score: 1.0
  Inline Citation: None
  Explanation: This paper presents the results of a study on automated data processing in the cloud for real-time irrigation management systems. The study focuses on developing a framework for evaluating the relevance and suitability of using automated, real-time irrigation management systems in optimizing water usage and improving agricultural productivity. The researchers adopt a systematic review approach to analyze the existing literature on automated irrigation systems, with a focus on end-to-end systems that integrate IoT and machine learning technologies. The study evaluates the relevance of these systems to the specific point of discussion in the literature review, which is the importance of real-time data cleaning techniques for handling missing, inconsistent, or outlier data from IoT sensors in irrigation systems. The relevance evaluation is based on the assumption that automated data processing in the cloud can contribute to efficient and reliable real-time irrigation management by enabling effective handling of data quality issues.

 Full Text: >
"This website utilizes technologies such as cookies to enable essential site functionality, as well as for analytics, personalization, and targeted advertising purposes. To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Transactions on Aerospac... >Volume: 59 Issue: 6 GNSS/MEMS-INS Integration for Drone Navigation Using EKF on Lie Groups Publisher: IEEE Cite This PDF Marcos R. Fernandes; Giorgio M. Magalhães; Yusef Rafael Cáceres Zúñiga; João B. R. do Val All Authors 447 Full Text Views Abstract Document Sections I. Introduction II. Filtering and Smoothing on Lie Groups III. Inertial Navigation System IV. Integration GNSS/INS V. Data Experiments Show Full Outline Authors Figures References Keywords Metrics Footnotes Abstract: This article adopts a matrix Lie group dynamic model aggregating in a single element position, velocity, attitude, and inertial measurement unit (IMU) biases. Relying on Kalman filtering on Lie groups, it develops an extended Kalman filter inbuilt into a smoother for loosely coupled integration of global navigation satellite-based system/inertial navigation system (GNSS/INS), tailored for postprocessing applications. The design is motivated by a drone-borne differential interferometric SAR (DinSAR) application requiring high-precision navigation information for short-flight missions using low-cost microelectromechanical systems (MEMS) sensors. The filter and the Rauch-Tung-Striebel (RTS) smoother are both implemented and validated. To cope with heading alignment, the article presents a Bayesian algorithm to initialize the heading value since magnetometers are useless and the INS gyroscopes lack gyro-compassing precision. Also, a statistical test addresses the practical issue of outlier rejection for GNSS detrimental data. This article uses synthetic data for comparison with classic navigation schemes based on multiplicative quaternions and Euler angles. A DinSAR imagery reconstitution field test shows better performance than state-of-the-art commercial software. Published in: IEEE Transactions on Aerospace and Electronic Systems ( Volume: 59, Issue: 6, December 2023) Page(s): 7395 - 7408 Date of Publication: 29 June 2023 ISSN Information: DOI: 10.1109/TAES.2023.3290575 Publisher: IEEE Funding Agency: SECTION I. Introduction Motivated by the navigation information requirements in the differential interferometric SAR (DinSAR) [1], 3-D mapping [2], and applications requiring high-fidelity position and attitude information [3], this article brings the following main contributions. 1) Employ a Lie group especially tailored for integrating global navigation satellite-based system/inertial navigation system (GNSS/INS) in 3-D navigation, including bias estimation in a Kalman-like smoothing procedure appropriate to Lie groups. 2) Take advantage of the Lie group and the corresponding Lie algebra interplay, allowing an additive noise model evolving in the algebra to translate into a noisy behavior appropriate to rigid bodies. This understanding indicates that Lie-based models embedded into extended Kalman filters (EKF) are bound to accommodate the nonlinearities well and perform better than standard Euler angles or quaternion models [4]. Comparison experiments verify this assertion. 3) Benefit from the postprocessed scenario using the EKF-Lie filter inbuilt into a Rauch-Tung-Striebel (RTS) smoother on Lie groups for improved accuracy (see Lemma II.2). The smoother comes from stochastic principles, and the deterministic approach via observers [5] does not allow a smoother synthesis, as far as the authors are aware. 4) Due to poor heading estimation accuracy, propose a Bayesian calibration procedure tailored to the postprocessing scenario. Heading alignment is recognizably difficult in attitude estimation, e.g., see [5] and [6]. The drone carries a single inertial measurement unit (IMU) lacking gyro-compassing precision and a single GNSS antenna with a known lever arm. No magnetometer is attached due to the radars and drone motor magnetic field interferences. 5) Create synthetic data from actual flights to benchmark and present field tests of a radar bourne terrain imagery application (DinSAR). The application requires highly accurate flight path reconstruction (position and attitude) to render sufficiently well-marked terrain imagery. 6) Quality comparison with industry-standard software favorable to the devised scheme. It indicates the applicability of the Lie-based method developed here, which includes an outlier rejection method for GNSS measurements. These stages complete a full engineering design cycle. It is known that a strap-down inertial navigation system (INS) based on microelectromechanical systems (MEMS) technology provides position, velocity, and attitude (PVA) information from accelerometers and gyroscopes at high rates but with unqualified errors after a period of discrete-time integration. These low-cost off-the-shelf sensors are inevitably affected by biases and white noise [7], thus, requiring adequate noise modeling. On the other hand, a GNSS can provide position and velocity with strict error bounds but at a lower frequency. Differential GNSS attains high precision, achieving centimeter-level precision using code and phase measurements [8]. A GNSS/INS integrated navigation system combines each sensor's strengths for better PVA estimates. Possible GNSS/INS integration types have appeared [9], and we adopt the loosely coupled (LC) structure for simplicity. The LC scheme combines the position-ready estimate provided by the GNSS with the IMU measurements. Kalman like filters have been investigated for GNSS/ INS integration algorithms, e.g., see [10], [11], and [12]. To achieve high-order approximations, unscented or particle filters offer alternatives to the EKF. They might provide better estimation but require more computational resources; for this reason, the EKF remains the most common GNSS/INS integration technique, the reference filter within the aerospace industry, cf., [13]. Several parameterizations apply to represent the attitude of a vehicle, such as Euler angles, quaternions, rotation vectors, and rotation matrices, cf., [9]. The challenge in choosing an adequate representation of attitude is that some have singularities or added constraints; see [4] for a thorough discussion. The kinematic equations for Euler angles involve trigonometric functions, which make the model highly nonlinear, cf., [14]. Quaternions are appealing for attitude representation, cf., [15]. However, they must satisfy a normalization constraint to represent rotations, which is disregarded by the measurement update step of the EKF, cf., [16]. To circumvent such constraint [14], [17] use a multiplicative form of quaternion update. Nevertheless, most of these techniques consider models on Euclidean space and Gaussian distributed driving noise. More recently, the Lie group theory-based framework has attracted much attention from sensor fusion communities for rigid-body-related data fusion. In robotics, [18] acknowledges that the unknown position of a differential-drive robot distribution displays a banana-shaped distribution, which can be produced with the aid of the exponential map of the SE(2) Lie group. A discrete EKF on Lie groups (D-LIE-EKF) appears in [19] and [20], generalizing the usual Kalman Filter framework when the system dynamic or measurement model can be cast as a Lie group element. Within D-LIE-EKF, the noise is Gaussian distributed, but acting in the Lie algebra, which induces a concentrated Gaussian distributed in the Lie group, cf., [21]. In this work, we exploit the generalization of EKF on Lie groups to implement an LC Integration of GNSS/MEMS-INS. The double direct isometries Lie group SE 2 (3) (see [22]) is adopted to embed the attitude, velocity, and position states, combined with the translation group T(6) to accommodate the accelerometer and gyroscope biases. Besides, the proposed filter is inbuilt into RTS smoothing on Lie groups, see Lemma II.2 or [23], to benefit from the postprocessing approach to the referred applications. The RTS gathers all information available to leverage state estimates at each time step, attaining higher precision and accuracy requirements than the plain filter result. In the context of navigation, Lie groups have been applied to industrial unmanned aerial vehicle (UAV) systems [13], real-time UAV helicopter navigation [24], and also land vehicle navigation [25]. However, none of these previous studies aimed at developing a complete navigation system to meet the accuracy requirements such as the DinSAR's. Most current works focus on land vehicle navigation and filtering solutions only. A concurrent approach for PVA estimation is based on observers from a vein of nonlinear system theory [26], with extra efforts to deal with inherent disturbances [5]. Although the synthesis of observers often comes with a corresponding convergence analysis, the ongoing assumptions are sometimes hard to verify. The quest for stability also appears in the Lie-based filter synthesis, e.g., see [27], [28]. In the course of using the EKF-Lie filter inbuilt into an RTS smoother, the stability was never an issue, except when low-quality GNSS data were fed into the GNSS/INS scheme. We propose an outlier rejection statistical method based on the Mahalanobis distance and a χ 2 -test with good results (see Section IV-C). In addition to the above-mentioned choices, a good alignment process is indispensable to achieving centimeter-level precision. It is well known that the heading alignment hinders low-cost GNSS/INS integration systems. Solutions based on fuzzy [6] or wavelet neural networks [29] are available for long-term applications. Magnetometers are unavailable, the drone flights are short-duration, and corrections along the flight are not needed when the initial alignment is good. Also, because of the postprocessing nature of the applications in focus, one can benefit from a highly accurate flight estimation via the smoothing procedure, a better solution than just filtering. A Bayesian method to optimize heading alignment in such a scenario is developed in Section IV-E. The strategy inbuilt into the D-LIE-EKF to deal with inherent nonlinearities relies on the interplay between matrix groups and the associated algebra. It is a powerful form of reducing the effect of nonlinearities to a minimum. It is better tailored to deal with non-Euclidean noise models for rigid bodies than other approximate filtering methods in the literature. Together with the statistical method devoted to the head alignment problem, they provide a way to develop optimal estimates given the adopted distributions. Deterministic nonlinear observers cannot mirror this scenario. Using synthetic data from actual flights, we show that the proposed filter and smoother outperform conventional quaternion and Euler angles-based approaches. In a second comparison, we use a real dataset to show that the Lie group-based filtering inbuilt into the RTS smoothing yields better performances for DinSAR imagery processing than the state-of-the-art commercial software Inertial Explorer. The rest of this article is organized as follows. Section II-A briefly introduces the mathematical concepts for understanding the Kalman filter algorithm on Lie groups. Section II describes the modeling of dynamic systems and random variables on Lie groups, followed by the description of filtering and smoothing methods. Section III develops the navigation and sensors model, and Section IV describes the integration scheme. After that, experimental evaluations using both simulated and real data appear in Section V. Finally, Section VI concludes this article. The following notation is adopted: x γ βα for a vector x represents the coordinates of some kinematic property (position, velocity, etc.) of frame α w.r.t. frame β , expressed in the frame γ . The navigation frame is the North-East-Down (NED) local-level frame, abbreviated by the index n ; the body frame is indicated by b , the inertial frame by i , whereas the earth centered earth fixed (ECEF) frame is indexed by e . SECTION II. Filtering and Smoothing on Lie Groups A. Elements of Lie Group Theory A brief introduction to Lie theory, main concepts, notation, and equations are handy for further understanding. A Lie group is a mathematical structure that combines the concept of a differentiable manifold with the concept of a group. For rigid-body applications, the analysis relies on a subgroup of the general linear group GL(n,R) , also called matrix Lie groups [30]. The GL(n,R) is the group formed with all invertible n×n matrices of real numbers with group operation given by the matrix product. In this article, we also restrict our consideration to connected and unimodular Lie groups, as it is required for the way the uncertainty on Lie groups is modeled. An important structure in the Lie group theory is the Lie algebra, a vector space equipped with a bracket product [[⋅,⋅]] called the Lie bracket. It is always possible to find a Lie algebra associated with a Lie group [30]. For matrix Lie groups, in particular, the associated Lie algebra is the vector space of matrices with Lie bracket given by the commutator [[X,Y]]=XY−YX . The importance of the Lie algebra lies in that most of the Lie group's properties come from the Lie algebra. The exponential map exp G :g→G , which for a matrix Lie group reduces to the usual matrix exponential function, provides a connection between elements of the Lie algebra and elements of the Lie group. In general, the exponential map is not bijective; however, it is possible to show that there exist open neighborhoods of the identity element on the Lie group and of the zero element on the Lie algebra, for which the exponential map is a diffeomorphism.1 In these open sets, one defines the logarithm map log G :G→g as the inverse of the exponential map. Since the Lie algebra is a vector space, it is possible to represent any element as a linear combination of its basis. Therefore, instead of manipulating the elements X as matrices for computing purposes, one can deal with the coefficients associated with its basis. With that in mind, the following isomorphisms are defined: [⋅ ] ∨ G :g X → R p ↦[X ] ∨ G [⋅ ] ∧ G : R p x →g ↦[x ] ∧ G . (1) View Source For brevity, the following notations are used hereafter: exp ∧ G (x):= exp G ([x ] ∧ G ), log ∨ G (g):=[ log G (g) ] ∨ G (2) View Source where x∈ R p , g∈G and when we write g= exp ∧ G (x) we assume that log ∨ G (g)=x , i.e., we work only on the subsets where exp G (⋅) and log G (⋅) are bijective. Note that the exponential map can be interpreted as a parameterization for the Lie group in local coordinates around the identity element. This parameterization can be extended to the neighborhood of any element μ∈G in a connected Lie group using left translation as follows, L μ (ϵ):=μ exp ∧ G (ϵ),∀ϵ∈ R p . The left translation action is illustrated in Fig. 1. Fig. 1. Left translation. Show All Since the exponential map is locally a diffeomorphism, there exist open neighborhoods of μ∈G and 0∈ R p for which this parameterization is one-to-one. A Lie group, in general, is not a commutative structure, which can complicate the algebraic manipulations. However, a concept overcomes this issue: the adjoint representation. There are two adjoint representations. The first one represents the Lie group on its Lie algebra, i.e., the linear map that takes an element of the Lie group to a linear transformation in the Lie algebra. The adjoint representation can be defined as [31] Ad G (g)y= [g[y ] ∧ G g −1 ] ∨ G (3) View Source where g∈G , y∈ R p . Note that Ad G (g)∈ R p×p is a linear transformation that can be applied to any vector y∈ R p . The second adjoint representation is the representation of the Lie algebra on itself so that each element of the Lie algebra defines a linear transformation in the Lie algebra. This adjoint representation is defined by the Lie bracket [31] in the form [ ad G (x)y ] ∧ G :=[[[x ] ∧ G ,[y ] ∧ G ]] where x,y∈ R p . Since the Lie bracket for matrix Lie groups is the commutator operator, we write ad G (x)y=[[x ] ∧ G [y ] ∧ G −[y ] ∧ G [x ] ∧ G ] ∨ G . (4) View Source Furthermore, in many applications of the Lie group, particularly in filtering and smoothing, one is interested in analyzing the behavior of a Lie group element g∈G as a function of time, and, naturally, its time derivative, g ˙ (t) . From the theory of differential manifolds, g ˙ (t) is a vector in the vector space tangent to G at the element g(t) , i.e., g ˙ (t)∈ T g(t) G . As stated before, working in Lie algebra is a common approach to dealing with Lie groups. It turns out that the tangent space at an arbitrary element of the Lie group is isomorphic to the tangent space at identity by performing a left translation so that g −1 g ˙ ∈g . The right-Jacobian matrix, following [31], is given as: J r (x)= ∑ k=0 ∞ (−1 ) k (k+1)! ad G (x ) k . (5) View Source Let us consider a local parameterization in the form g=μ exp ∧ G (x) . The relation of the time variation of g to the time variation of the local coordinates x , represented in the Lie algebra, is given by g −1 g ˙ =[ J r (x) x ˙ ] ∧ G . Notice that the matrix J r (x) is responsible for relating local coordinates variations to Lie group element variations. B. Random Variables on Lie Group First, recall that for a random variable (r.v.) x on the Euclidean space with mean μ∈ R n and covariance P= P ⊺ ≻0 associated with a pdf p(x) , one has 0 n×1 = P= ∫ R n (x−μ)p(x)dx ∫ R n (x−μ)(x−μ ) ⊺ p(x)dx (6a) (6b) View Source where the integration is w.r.t. the Lebesgue measure. This definition can be naturally extended to Lie groups as follows. Given a matrix Lie group G , a random matrix X∈G with pdf p(X) has mean μ∈G and covariance P= P ⊺ ≻0 defined by 0 n×n = P= ∫ G log ∨ G ( μ −1 X)p(X)dX ∫ G log ∨ G ( μ −1 X) log ∨ G ( μ −1 X ) ⊺ p(X)dX (7) (8) View Source where the integration is w.r.t. the Haar measure [31]. From this standpoint, the concept of concentrated Gaussian distribution (CGD) [23] is used to define a probability density tailored to matrix Lie groups. The group defines the mean, and the covariance is in the Lie algebra. Accordingly, a Gaussian random variable on a matrix Lie group is expressed as follows: X=μ exp ∧ G (ϵ) (9) View Source and the pdf of X takes the form p(X):=αexp(− 1 2 ∥ log ∨ G ( μ −1 X) ∥ 2 P −1 ) (10) View Source where α∈R is a normalizing factor to ensure ∫p(X)dX=1 . From (9), ϵ= log ∨ G ( μ −1 X) and assuming that P has small eigenvalues then p( exp ∧ G (ϵ)) concentrates around the group identity. With those working assumptions, the distribution of ϵ in the Lie algebra becomes the classical Gaussian distribution, i.e., ϵ∼N(0,P) . The distribution of X is called a CGD on G , denoted by X∼ N G (μ,P) . An illustration of the relationship between the neighborhood of the identity element with the Lie Algebra is depicted in Fig. 2 together with the tangent space and its respective Gaussian distribution. Fig. 2. Concentrated Gaussian distribution in the neighborhood of the identity element. Notice the curved shape of the distribution on the Lie group. Show All C. Dynamic System Once an r.v. is defined on a Lie group, a stochastic dynamic system can be modeled such that its states are embedded on a matrix Lie group G . Let X∈G be the system state. Let the stochastic differential equation be expressed by dX=X[Ω(X,u)dt+dW ] ∧ G (11) View Source where Ω:G× R m → R p is the left velocity function and W is a multidimensional Wiener process with covariance Q c , i.e. W( t 2 )−W( t 1 )∼N(0,( t 2 − t 1 ) Q c ) with t 1 < t 2 . Also, consider that measurements are available in discrete time instants in the form y k+1 =h( X k )+ ν k (12) View Source where y k ∈ R m is the measurement vector, h:G→ R m is the measurement function, and ν k ∼ iid N(0, R k ) is the measurement noise. For small sample time Δt , the discrete form of the dynamic system (11) can be approximated as X k+1 = X k exp ∧ G (Ω( X k , u k )Δt+ w k ) (13) View Source where w k ∼ iid N(0, Q k ) and Q k = Q c Δt . D. Kalman Filter on Lie Groups With the definition of r.v.s and stochastic dynamic systems on Lie groups, one can employ the Kalman filtering framework to generate state estimates of a dynamic system state evolving on a Lie group. For convenience, denote Ω ^ k :=Ω( X ^ k , u k )Δt . The D-EKF on a Lie group [19], [20] is presented next. Lemma II.1 (D-LIE-EKF): The following equations constitute the D-EKF on a Lie group: X ^ k+1|k = P k+1|k = K= X ^ k+1|k+1 = P k+1|k+1 = X ^ k|k exp ∧ G ( Ω ^ k ) F P k|k F ⊺ + J r ( Ω ^ k ) Q k J r ( Ω ^ k ) ⊺ P k+1|k H ⊺ ( R k+1 +H P k+1|k H ⊺ ) −1 X ^ k+1|k exp ∧ G (K( y k+1 −h( X ^ k+1|k ))) (I−KH) P k+1|k (∙ ) ⊺ +K R k+1 K ⊺ (14a) (14b) (14c) (14d) (14e) View Source where F:= C k := H:= Ad G ( exp ∧ G (− Ω ^ k ))+ J r ( Ω ^ k ) C k ∂ ∂ϵ [Ω( X ^ k|k exp ∧ G (ϵ))] ∣ ∣ ϵ=0 ∂ ∂ϵ [h( X ^ k+1|k exp ∧ G (ϵ))] ∣ ∣ ϵ=0 . (14f) (14g) (14h) View Source Proof: See Appendix A. □  E. Smoothing on Lie Groups This section presents the RTS smoother on Lie groups with the D-LIE-EKF inbuilt, as proposed in [23]. Unlike a Kalman recursive filter, the smoother uses all available measurements to compute the state estimates using a forward pass, given by the D-LIE-EKF, followed by a backward pass [32]. Thus, the RTS applies offline in a postprocessing amelioration. Lemma II.2 (D-LIE-RTS): Given the filter solution { X ^ k|k , P k|k } 1:T , the Rauch–Tung–Striebel recursion on Lie groups for k=T−1,…,1 are X ^ k+1|k = P k+1|k = G k = X ^ s k = P s k = X ^ k|k exp ∧ G ( Ω ^ k ) F P k|k F ⊺ + J r ( Ω ^ k ) Q k J r ( Ω ^ k ) ⊺ P k|k F ⊺ P −1 k+1|k , X ^ k|k exp ∧ G ( G k log ∨ G ( X ^ −1 k+1|k X ^ s k+1 )) P k|k + G k ( P s k+1 − P k+1|k ) G ⊺ k . (15a) (15b) (15c) (15d) (15e) View Source Proof: See Appendix B. □  Remark The D-LIE-EKF presented is in close correspondence with the version presented in [19], [20], and [23]. However, we adopt the Joseph form in (44) in the Appendix A. for better numeric stability. In addition, the LIE-RTS smoother is derived using the left-error definition instead of the right-error definition presented originally in [23]. SECTION III. Inertial Navigation System The section presents the PVA kinematic navigation equations in continuous time [9], [33], and the IMU measurement model. A. Navigation Equations They are given as C ˙ e b = p ˙ e eb = v ˙ e eb = C e b [ ω b ib ] × − [ ω e ie ] × C e b , v e eb , C e b f b ib −2 [ ω e ie ] × v e eb + g e (16a) (16b) (16c) View Source where the position p e eb = [ x e eb y e eb z e eb ] ⊺ is coordinated in the ECEF frame, and ω e ie =[ ω e cos(L)0− ω e sin(L) ] ⊺ View Source where ω e is the earth rotation rate, and L is the latitude; ω b ib , f b ib ∈ R 3 are the angular velocity and specific force, respectively. The gravity may be obtained through a gravity model. This article adopts the model presented in [34] for simplicity. Remark The GNSS navigation solution is given in the ECEF frame. The INS kinematic model is also defined in the ECEF, so the GNSS measurements are used to update the trajectory with no coordinate transformation. If a navigation solution is required in the local frame coordinates, one can quickly transform from ECEF to NED coordinates (see [9]). B. IMU Measurement Model As pointed out in [35], the INS kinematic model in (16) is exact since there is no model error or uncertainty. Hence, the uncertainty in navigation problems comes from the sensors and the local gravity anomalies. Gyroscopes and accelerometers are subject to errors that limit the accuracy at which angular rotations or specific forces are measured. Thus, sensor models are essential for the filter and smoothing navigation to achieve reliable results. In particular, we consider the following inertial sensor model: ω ~ b ib = f ~ b ib = ω b ib + b g + ε g f b ib + b a + ε a (17a) (17b) View Source where ε g ∼ iid N(0, σ 2 g ) and ε a ∼ iid N(0, σ 2 a ) are white noise and are related to the angular random walk (ARW) and velocity random walk parameters of the IMU. In addition, b g , b a are the gyroscope and accelerometer biases, respectively. The biases are modeled as random walk processes in the form d b g = d b a = B g d W g B a d W a (18a) (18b) View Source where W g and W a are Wiener processes of appropriate dimensions and B g and B a are diffusion matrices associated with the IMU's bias instability. Remark Note that in (17) f ~ b ib and ω ~ b ib are IMU's noisy values of the specific force and angular velocity, respectively. Note also that the biases are expressed in the body frame. SECTION IV. Integration GNSS/INS A. Modeling Navigation and INS Measurements This work employs the double direct isometries Lie group SE 2 (3) [22], for embedding the kinematic states in a compound with a translation group T(6) , which accommodates both accelerometer and gyroscope biases. The resulting group structure G= SE 2 (3)×T(6) is X= ⎡ ⎣ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ C e b 0 1×3 0 1×3 v e 1 0 p e 0 1 0 7×5 0 5×7 I 6×6 0 1×6 b 1 ⎤ ⎦ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ 12×12 (19) View Source where b=[ b a b g ]∈ R 6 . Lemma IV.1 The velocity function Ω:G× R 6 → R 15 associated with the navigation equations (16) embedded into the Lie group from (19) is given by Ω(X,u)= ⎡ ⎣ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ω ~ b ib − b g − ω b ie f ~ b ib − b a −2 C b e [ ω e ie ] × v e eb + C b e g e C b e v e eb 0 0 ⎤ ⎦ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ (20) View Source where u=[ f ~ b ib ω ~ b ib ]∈ R 6 is the IMU's noisy input measurement. In addition, the process noise is given by dW= ⎡ ⎣ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ − σ a d W 1 − σ g d W 2 0 B a d W a B g d W g ⎤ ⎦ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ =Γd W ~ (21) View Source where d W ~ = [d W ⊺ 1 d W ⊺ 2 d W ⊺ a d W ⊺ g ] ⊺ such that W ~ is a standard 12-dim Wiener process. Proof From (16) and (19), one gets X −1 dX= = ⎡ ⎣ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ C b e d C e b 0 0 C b e d v e eb 0 0 C b e d p e eb 0 0 0 7×5 0 5×7 0 6×6 0 1×6 db 0 ⎤ ⎦ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ 12×12 [Ω(X,u)dt+dW ] ∧ G View Source which implies (20) and (21). □  B. GNSS Measurement Model The rover GNSS antenna is rigidly fixed relative to the IMU, and the lever arm from the IMU to the GNSS antenna phase center is known, expressed as l b in the body frame. The GNSS position measurements p GNSS =[xyz ] ⊺ are modeled as p GNSS = p e eb + C e b l b +ν (22) View Source where ν ∼ iid N(0,R) stands for the GNSS noise that is uncorrelated white noise with covariance R=diag( σ 2 x , σ 2 y , σ 2 z ) . C. Outlier Rejection Outliers are spurious data that differ dramatically from the statistical distribution, leading to erroneous behavior of the filtering algorithm. When adopting GNSS measurements, outliers are inevitably present due to satellite blockage, multipath noise, or cycle slip. To make the proposed algorithm robust against GNSS outliers, the Mahalanobis distance combined with the χ 2 -test is employed to define a rejection scheme. Define the squared normalized residue (SNR) as ζ k :=∥ y k − y ^ k ∥ 2 Ξ −1 k (23) View Source where Ξ k = R k + H k P k+1|k H ⊺ k , see (14). Assuming that the SNR obeys a chi-square distribution with 3 degrees of freedom, i.e., ζ k ∼ χ 2 3 , a valid GNSS is declared if ζ k ≤κ where κ is a threshold level. Fig. 3 illustrate the region of valid GNSS (green shadow) where the SNR is less than the specified threshold. Fig. 3. GNSS outlier rejection using Mahalanobis distance. Show All However, instead of completely discarding a possible outlier when the threshold is exceeded, another approach, similar to [36], is to mitigate the influence of the respective GNSS measurement. We choose to weight the filter innovation with the following factor: γ=min(1, κ ζ ). (24) View Source Accordingly, the update equation (14d) becomes X ^ k+1|k+1 := X ^ k+1|k exp ∧ G (γK( y k+1 −h( X ^ k+1|k ))). (25) View Source Note that when γ=1 , the filter is unaltered ( ζ≤κ ). But if ζ>κ , γ becomes less than one, scaling down the filter innovation impact on the estimate X ^ k+1|k+1 . D. Alignment and Initial Conditions A critical factor for achieving accurate navigation is the initialization of the inertial navigation system. Before the take-off, the INS is immobile; the initial velocity is null. The initial position can be obtained with satisfactory accuracy by averaging GNSS measurements in a sufficiently long time window. Likewise, the initial values for the gyroscope biases can be estimated using the average of its measurements during the immobile period. Moreover, the leveling method [9] can be used to obtain the initial pitch ( θ 0 ) and roll ( ϕ 0 ) angles as well. The principle of leveling is that when the INS is immobile, the accelerometer triad only detects gravity acceleration. Hence, the initial pitch and roll angles can be obtained as θ 0 = ϕ 0 = arctan ⎛ ⎝ ⎜ ⎜ ⎜ f ¯ b ib,x ( f ¯ b ib,y ) 2 + ( f ¯ b ib,z ) 2 − − − − − − − − − − − − − − − √ ⎞ ⎠ ⎟ ⎟ ⎟ arctan 2 (− f ¯ b ib,y ,− f ¯ b ib,z ) (26a) (26b) View Source where f ¯ b ib,x , f ¯ b ib,y , f ¯ b ib,z are the average accelerometer output during a time window. Note that the four-quadrant arc tangent function should be used for roll. The accuracy of (26) is determined by the accelerometer biases [33]. Regarding the initial heading alignment, the gyro-compassing method or a magnetometer compass could be used for the initial heading. However, an accurate heading initialization requires expensive navigation-grade gyroscope sensors capable of measuring the earth’s rotation rate, whereas magnetometers usually do not attain the required precision, apart from the mentioned hindrances for their use. As a result, it is mandatory to conceive a method relying solely on low-cost MEMs for a satisfactory initialization of the heading value. We propose a Bayesian optimization method to this end, described in the next section. E. Postprocessed Heading Alignment To provide a reliable initialization of the heading angle ( ψ 0 ) using only low-cost MEM sensors, the Bayesian parametric estimation scheme described in [37, cap.12] is adapted to our scenario. The method applies when all data are collected after the drone flight, represented generically by the data y 1:N . It consists of evaluating the posterior distribution p( ψ 0 | y 1:N ) and taking the most likely value for the initial heading ψ 0 . For this purpose, note that p( ψ 0 | y 1:N )∝p( y 1:N | ψ 0 )p( ψ 0 ) (27) View Source where p( ψ 0 ) is some prior distribution. For simplicity, we consider p( ψ 0 )=N(0, σ 2 ψ ) , namely, ψ 0 =0 is the a priori heading reference. Moreover, p( y 1:N | ψ 0 ) can be factored in the form p( y 1:N | ψ 0 )= ∏ k=1 N p( y k | y 1:k−1 , ψ 0 ). (28) View Source We assume that the marginal measurement distribution p( y k | y 1:k−1 , ψ 0 ) is a Gaussian distribution of form p( y k | y 1:k−1 , ψ 0 )=N(h( X ^ ψ 0 k|k−1 ), R k +H P ψ 0 k|k−1 H ⊺ ) (29) View Source where X ^ ψ 0 k|k−1 and P ψ 0 k|k−1 come from the filtering solution with some fixed ψ 0 value. Accordingly, the most likely value for the initial heading can be found by solving min ψ 0 −log(p( ψ 0 | y 1:N )) . Let φ( ψ 0 )=−log(p( ψ 0 | y 1:N )) then one has φ( ψ 0 )= = ∑ k=1 N −log(p( y k | y 1:k−1 , ψ 0 ))−log(p( ψ 0 )) ∑ k=1 N 1 2 log(2π ∣ ∣ S ψ 0 k ∣ ∣ )+ 1 2 ∥ ∥ z ψ 0 k ∥ ∥ 2 ( S ψ 0 k ) −1 + 1 2 σ 2 ψ ∥ ψ 0 ∥ 2 (30) View Source with S ψ 0 k = R k +H P k|k−1 H ⊺ and z ψ 0 k = y k −h( X ^ ψ 0 k|k−1 ) . Remark Note that, for each value of ψ 0 , (30) provides the respective log-likelihood up to a constant as p( ψ 0 | y 1:N )∝exp(−φ( ψ 0 )) . Thus, for a sufficient number of evaluations of different values for ψ 0 , one can build the distribution p( ψ 0 | y 1:N ) using the filtering solution. Also, we propose the following approximation p( ψ 0 | y 1:N )≈N( ψ ∗ 0 , σ 2 ψ ∗ ) . This implies that the log-likelihood (30) is approximated quadratic w.r.t ψ 0 ; hence, one can obtain the approximated log-likelihood function by evaluating three distinct points. In summary, the proposed heading alignment scheme consists of three independent D-LIE-EKF evaluations, each with different heading values [ ψ 1 ψ 2 ψ 3 ] . After these runnings, three samples from the log-likelihood are obtained. Thereafter, a parabola c= m 1 ψ 2 + m 2 ψ+ m 3 is fitted to the samples solving Am=c for m where A= ⎡ ⎣ ⎢ ⎢ ψ 2 1 ψ 2 2 ψ 2 3 ψ 1 ψ 2 ψ 3 1 1 1 ⎤ ⎦ ⎥ ⎥ ,c= ⎡ ⎣ ⎢ c 1 c 2 c 3 ⎤ ⎦ ⎥ ,m= ⎡ ⎣ ⎢ m 1 m 2 m 3 ⎤ ⎦ ⎥ . (31) View Source The best estimate of the initial heading is then chosen as the parabola minimum value, ψ ∗ 0 :=− m 2 /2 m 1 . Fig. 4 shows an example of the proposed optimization-based heading alignment with ψ 1 =− 30 ∘ , ψ 2 = 0 ∘ and ψ 3 = 30 ∘ applied to a real dataset. For this case, the best initial heading was ψ ∗ 0 = 3.72 ∘ . The actual log-likelihood (blue curve) was computed by a grid of values for ψ 0 from − 60 ∘ to + 60 ∘ with 5 ∘ increment. Notice that the blue curve is close to the red curve (quadratic approximation) near its minimum. In Section V-C, a numeric experiment using synthetic data illustrates the performance of the proposed heading alignment strategy. Fig. 4. Example of the proposed optimization-based heading alignment using − 30 ∘ , 0 ∘ ,+ 30 ∘ guesses for the initial heading. The blue curve indicates the log-likelihood function, and the red curve is the proposed approximation. Show All F. GNSS/INS Integration Scheme The proposed scheme for LC GNSS/INS integration using Lie group consists of four steps. First, the accelerometer data from the IMU during an initial stationary period is used to perform leveling and obtain initial values for pitch and roll as in Section IV-D. Then, the heading alignment method described in Section IV-E is applied to obtain the initial heading value. Next, a fourth pass of the D-LIE-EKF algorithm is performed to obtain a filtered solution with ψ ∗ 0 as the initial heading. Finally, the D-LIE-EKF-RTS smoother (or D-LIE-EKS for short) generates the final output. Fig. 5 illustrates these four steps. Fig. 5. Proposed loosely coupled GNSS/INS integration using Lie group for postprocessing applications. Show All SECTION V. Data Experiments A. Settings This work was especially motivated by the drone-borne DinSAR application described in [1] and [38]. It requires high-fidelity PVA information to provide reliable interferometric results (see Table I). The drone with the radar system is shown in Fig. 6. It consists of a DJI Matrice 600-Pro equipped with a radar system for remote sensing. An INS is mounted independent from the native onboard navigation system, exclusively to provide PVA information for the radar system, consisting of a 6-DOF IMU ADIS16495 from Analog Devices. The IMU is rigidly mounted on the radar antenna so that the attitude measurement from the IMU can be easily transformed into the radar's orientation information. TABLE I DinSAR Specifications [38] Fig. 6. Drone-borne DinSAR system [1]. Show All In complement, the u-blox ZED F9P GNSS system is installed to provide raw code, and post-processed phase measurements using the open-source package RTKlib [39]. B. Comparisons With Synthetic Data The objective here is to get realistic and “noiseless” trajectories, such as those produced by one elaborate flight simulator, for performance comparison among Euler, quaternions, and Lie filtering and smoothing schemes. This precedes actual field tests, presented in Section V-E. The starting point is to get a real dataset from drone trajectories, as illustrated in Fig. 7, which is then processed with centimeter-level accuracy. Then, inverse strap-down mechanization similar to [40] but adapted to the Lie group model is implemented to emulate perfect measurements. Fig. 7. Example of three flight scenarios. (a) Helicoidal. (b) Rectangular. (c) Circular. Show All More specifically, let { C e b (k), p e (k), v e (k) } k=1:N be the reference trajectory generated with a sample rate F s =1/Δt . For each time instant k , an SE 2 (3) element is built to represent the system state in the form S k =[ C e b (k) 0 v e (k) I p e (k) ]. (32) View Source Thereafter, the left-velocity vector is computed using Ω= log ∨ G ( S −1 k S k+1 ) Δt =[ Ω ω Ω f ]. (33) View Source From (20), one obtains the angular velocity and the specific force as follows: ω b ib (k)= f b ib (k)= Ω ω + ω e ie Ω f +2 C b e (k)[ ω e ie ] × v e eb (k)− C b e (k) g e . View Source From such sequences, one can integrate back using zero-order hold or another rule to get time continuous input and state representations, yielding a ground truth trajectory for performance comparisons. Remark We choose to generate { C e b (k), p e (k), v e (k) } k=1:N with the commercial software Inertial Explorer for GNSS/INS integration, for the sake of independence, but we could choose to process with the proposed scheme equally well. Finally, perturbations reflecting characteristic errors of actual sensors should be introduced to the emulated measurements, namely, IMU artificial noises are added to form the simulated IMU measurements ω ~ b ib (k)= f ~ b ib (k)= ω i ib (k)+ b g (k)+ N g w(k) f i ib (k)+ b a (k)+ N a w(k) View Source where w a , w g ∼N(0,I) and N a , N g are the VRW and ARW parameters of the emulated IMU. Besides, b a , b g are the accelerometer and gyroscope biases simulated using Ornstein-Uhlenbeck processes as follows: b a (k+1)= b g (k+1)= b a (k)+ τ a ( β a − b a (k))Δt+ B a Δt − − − √ w ba (k) b g (k)+ τ g ( β g − b g (k))Δt+ B g Δt − − − √ w bg (k) View Source where τ a , τ b are the biases' correlation time, β a , β b are the turn-on constant biases, w ba , w bg ∼N(0,I) and B a , B g are parameters to influence the bias instability. Unlike the random walk process, the Ornstein-Uhlenbeck process is a mean-reverting process, better fitting the IMU biases behavior. The GNSS data is rendered by down-sampling the reference trajectory to 1 Hz and adding the lever-arm component together with a 3-dimensional white noise as follows: y(n)= p e (n F s )+ C e b (n F s ) l b +ε(n) (34) View Source for n=0,1,…,⌊ N F s ⌋ , ε∼N(0,R) . The parameters used in all simulations were chosen to match the ADIS16495 data sheet and the centimeter-level precision of RTK-GNSS and are given in Table II. The covariance matrix P 0 is formed as a diagonal matrix whose individual elements are chosen according to each state's expected 99.7% confidence interval (three standard deviations), as follows: P 0 = diag(( 1 3 ∘ ) 2 ,( 1 3 ∘ ) 2 ,( 5 3 ∘ ) 2 ( 0.001 3 m/s ) 2 ,( 0.001 3 m/s ) 2 ,( 0.001 3 m/s ) 2 ( 0.1 3 m ) 2 ,( 0.1 3 m ) 2 ,( 0.1 3 m ) 2 ( 1 3 mg ) 2 ,( 1 3 mg ) 2 ,( 1 3 mg ) 2 ( 15 3 deg s ) 2 ,( 15 3 deg s ) 2 ,( 15 3 deg s ) 2 ). View Source TABLE II Simulation Parameters C. Heading Alignment Performance To analyze the accuracy of the heading alignment method described in Section IV-E we perform some experiments with synthetic data using different initial heading values. The optimization-based method is applied in each experiment, and the best estimate of the initial heading is obtained. The experiments support that the proposed heading alignment can achieve an error less than 2 ∘ as required in Table I, when the true heading is between − 20 ∘ and + 20 ∘ as shown in Fig. 8. Fig. 8. Heading alignment error. Show All D. Navigation Performance Three flight scenarios were simulated to evaluate the proposed processing scheme's performance: helicoidal, rectangular, and circular. These profiles are shown in Fig. 7. For comparisons, for each scenario, the following algorithms were implemented: Lie group-based filter (D-LIE-EKF) inbuilt into the smoother (D-LIE-EKS); multiplicative quaternion-based filter (MEKF) and smoother (MEKS); Euler-based filter (EULER-EKF), and smoother (EULER-EKS). Thereafter, 100 Monte Carlo realizations were performed, and each algorithm's respective rmse was computed. All algorithms are initialized with the same parameters for a fair comparison. Table III summarizes the performance for each online processing phase using filtering only. Table IV shows the off-line performance after applying the respective smoother algorithm. TABLE III RMSE Comparison for 100 Monte Carlo Simulations Using Filter Only TABLE IV RMSE Comparison for 100 Monte Carlo Simulations Using Filter and RTS Smoother Note that using the Lie group-based algorithm the heading error is lower for the three scenarios in rmse terms. The D-LIE-EKS shows an overall performance gain of about 40% over the MEKS for both helicoidal and circular flight profiles and about 9% for the rectangular profile. This result indicates the superiority of the Lie group approach, which becomes more noticeable for curved trajectories. E. In Field Drone-Borne DinSAR Performance This section reports the performance results obtained from a complete experiment of image reconstruction with the drone-borne DInSAR system described in [1]. The digital surface model (DSM) is obtained using the cross-track interferometry information provided by the two C-band antennae and applied in the DInSAR calculation. The controlled experiment was conducted using three trihedral corner reflectors with square sides and edge lengths of 0.6 m to serve as a ground reference. Fig. 9 illustrates the drone-borne DinSAR geometry. Fig. 9. Drone-borne DinSAR geometry. Show All The experiment accurately assesses the DinSAR processing using the proposed GNSS/INS technique and consists of the following steps. The GNSS ground station is placed close to the starting position of the drone, and the GNSS recording is initiated. Then, three flights are carried out, each consisting of the following successive steps: 1) turning on the drone and the radar and waiting 15 min for simultaneous and stationary recording of the ground station and drone GNSS data; 2) taking off and executing the same west-east flight track; and 3) landing and waiting 15 min for simultaneous and stationary recording of the ground station and radar GNSS data. Turning off. The GNSS ground station and drone are dismounted, and the acquired data is downloaded for postprocessing. For comparisons, we test the results against commercially produced navigation software specialized for IMU-GNSS integration, the NovAtel Inertial Explorer (IE), using its offline processing mode. After the flights, the data are processed in two steps for the Lie group-based processing. First, the ground station and rover GNSS receivers are processed using RTKlib [39] to generate centimeter-accuracy position information at 1 Hz. Second, the Lie group filter-smoother algorithm generates the final position, velocity, and attitude solution by combining the GNSS information with the 200 Hz IMU measurements. We refer to this solution as D-LIE-EKS. The GNSS and IMU raw data for the IE processing is fed directly to the software. Although the proposed scheme is LC, we compare it with IE's loosely coupled (IE-LC) and tightly coupled (IE-TC) solutions. Now, with the navigation information at hand, the raw radar data are processed on the imaging module, recording each resulting single-look complex (SLC) image. After that, the interferometry is performed, yielding the interferogram, topography subtraction, and phase-to-height conversion. The output consists of two deformation maps plus the three SLC images, all in slant range geometry. Each interferogram is calculated with 0.047 m resolution in azimuth and 1.228 m resolution in the slant range. From the close inspection of the reflector's positioning, we can not detect any noticeable advantages from one or the other procedure, even in the IE-TC mode. After these evaluations, we attempted to spot subtle differences by subtracting images of subsequent flights and looking for terrain inconsistencies. Fig. 10 shows the relative error of subsequent flights for the three different navigation processing. Notice that the resulting pattern is almost identical for all algorithms. Fig. 10. Relative DinSAR Error Image of subsequent flights. For all algorithms, the patterns are almost identical. Show All Fig. 11 depicts the relative error for only one azimuth line (horizontal cross-section of Fig. 10). Between slant-range 0–100 m, one can observe an increase in relative error for IE-LC and IE-TC, while for the D-LIE-EKS, the error magnitude remains steady. Fig. 11. Relative error of DinSAR for one azimuth line. Show All Table V summarizes the overall error of the three algorithms. We observe that the proposed D-LIE-EKS scheme outperforms both IE-LC and IE-TC in these experiments in terms of rmse. TABLE V DinSAR RMSE Relative Errors SECTION VI. Conclusion A LC GNSS/INS integration scheme was developed based on Lie group theory, tailored for postprocessing applications seeking the highest accuracy. It incorporates the online Kalman filter inbuilt into the offline RTS smoother to provide estimates of PVA to this goal. The double direct isometry group SE 2 (3) compound with the translation group T(6) was adopted to model the kinematic and cope with biased navigation system measurements. The article includes a Bayesian adjustment devised to tackle the heading estimation problem, seeking full trajectory error mitigation. It also contains an outlier test conceived to deal with low-quality GNSS measurements. To our best knowledge, this is the first implementation of LC GNSS/INS integration tailored for postprocessing applications, combining Kalman filtering and RTS smoothing on Lie groups, applied to drone-borne remote sensing applications. It includes a few numeric experiments based on synthetic data generated using inverse strap-down mechanization. They show that the Lie group approach consistently outperforms classical methods based on quaternion and Euler parametrization of the attitude matrix. The advantage of the Lie group is further highlighted when using helicoidal and circular trajectories in which, due to the curvy paths, the proposed scheme attains better rms performance. Furthermore, in a field comparison, the Lie group also exhibits superior performance and better accuracy than the navigation software Inertial Explorer in a DinSAR drone-borne application. Surprisingly, the simpler LC setting of the proposed technique presented superior performance than the IE's more complex tightly coupled configuration. A favorable quality comparison with industry-standard software in this experiment indicates the novelty and the applicability of the Lie-based method devised here for low-cost and high-precision flight navigation reconstitution. In a word, this work brings a complete cycle of engineering design, revealing that the Lie group theory of filtering and smoothing forms an appealing framework for high-quality aerial navigation. Finally, as an aside, these experiments point out that the air-borne radar scheme provides an excellent benchmark for low-cost INS evaluations. The scheme circumvents the need for an expensive navigation-grade INS unit in pairing tests, the usual form of calibration and evaluation of such devices. ACKNOWLEDGMENT The authors would like to thank the Radaz Indústria e Comércio de Produtos Eletrônicos S.A. for supporting this work. Appendix SECTION A. D-LIE-EKF Equations Proof: Lemma II.1. Let X k = X ^ k|k exp ∧ G ( ϵ k|k ) with ϵ k|k ∼N(0, P k|k ) and X ^ k+1|k = X ^ k|k exp ∧ G ( Ω ^ k ) . Employing a first-order approximation for Ω k around X ^ k|k , yields Ω k =Ω( X ^ k|k exp ∧ G ( ϵ k|k ))≊Ω( X ^ k|k )+ C k ϵ k|k (35) View Source where C k := ∂ ∂ϵ [Ω( X ^ k|k exp ∧ G (ϵ))] ∣ ∣ ϵ=0 . From (13), one has ϵ k+1|k = = = X ^ −1 k+1|k X k+1 exp ∧ G (− Ω ^ k ) X ^ −1 k|k X k exp ∧ G ( Ω k + w k ) exp ∧ G (− Ω ^ k ) exp ∧ G ( ϵ k|k ) exp ∧ G ( Ω ^ k + C k ϵ k|k + w k ). (36) View Source Assuming that C k ϵ k|k + w k is small, then using the relationship from [41] and the fact that g exp ∧ G (x)= exp ∧ G ( Ad G (g)x)g one gets ϵ k+1|k = exp ∧ G (F ϵ k|k + J r ( Ω ^ k ) w k ) (37) View Source with F= Ad G ( exp ∧ G (− Ω ^ k ))+ J r ( Ω ^ k ) C k . Therefore, we conclude that X k+1 ∼ N G ( X ^ k+1|k , P k+1|k ) where P k+1|k =F P k|k F ⊺ + J r ( Ω ^ k ) Q k J r ( Ω ^ k ) ⊺ . (38a) View Source Now, for the measurement-update step, consider X k+1 = X ^ k+1|k exp ∧ G ( ϵ k+1|k ) where ϵ k+1|k ∼N(0, P k+1|k ) . Note that the measurement distribution is p( y k+1 | X k+1 )=N( y k+1 ;h( X k+1 ), R k+1 ) and the prior state distribution is p( X k+1 | y 1:k )= N G ( X ^ k+1|k , P k+1|k ) . Thus, from the Bayes' rule, one has p( X k+1 | y 1:k+1 )= p( y k+1 | X k+1 )p( X k+1 | y 1:k ) p( y k+1 | y 1:k ) ∝exp(− 1 2 ∥ y k+1 −h( X k+1 ) ∥ 2 R −1 k+1 − 1 2 ∥ ϵ k+1|k ∥ 2 P −1 k+1|k ). (39) View Source Let the posterior distribution be parametrized in the form p( X k+1 | y 1:k+1 )=p( X ^ k+1|k exp ∧ G (v)| y 1:k+1 ). (40) View Source Therefore, the maximum a posteriori (MAP) estimate is X ^ k+1|k+1 = X ^ k+1|k exp ∧ G ( v ∗ ) such that v ∗ =arg min v ℓ(v) where ℓ(v) is the negative log-likelihood given by ℓ(v):= 1 2 ∥ y k+1 −h( X ^ k+1|k exp ∧ G (v)) ∥ 2 R −1 k+1 + 1 2 ∥v ∥ 2 P −1 k+1|k . View Source If a linear approximation is adopted, then one can obtain a set of filtering equations similar to the EKF. For this purpose, consider a first-order approximation of (12) in the form h( X ^ k+1|k exp ∧ G (ϵ))≊h( X ^ k+1|k )+Hϵ with H= ∂ ∂ϵ [h( X ^ k+1|k exp ∧ G (ϵ))] ∣ ∣ ϵ=0 . Thus ℓ(v)≊ 1 2 ∥ z k+1 −Hv ∥ 2 R −1 k+1 + 1 2 ∥v ∥ 2 P −1 k+1|k (41) View Source where z k+1 := y k+1 −h( X ^ k+1|k ) is the residual. The minimum of (41) is straightforward given by v ∗ =K z k+1 where, K=( P −1 k+1|k + H ⊺ R −1 k+1 H ) −1 H ⊺ R −1 k+1 which also can be written as K= P k+1|k H ⊺ ( R k+1 +H P k+1|k H ⊺ ) −1 . Thus X ^ k+1|k+1 = X ^ k+1|k exp ∧ G (K z k+1 ). (42) View Source Let the state error be ϵ k+1|k+1 := log ∨ G ( X ^ −1 k+1|k+1 X k+1 ) . From (42), the posterior error follows: ϵ k+1|k+1 = = = = ≈ = log ∨ G ( X ^ −1 k+1|k+1 X k+1 ) log ∨ G ( exp ∧ G (−K z k+1 ) X ^ −1 k+1|k X k+1 ) log ∨ G ( exp ∧ G (−K z k+1 ) exp ∧ G ( ϵ k+1|k )) −K( y k+1 −h( X ^ k+1|k ))+ ϵ k+1|k −K(H ϵ k+1|k + ν k+1 )+ ϵ k+1|k (I−KH) ϵ k+1|k −K ν k+1 (43) View Source where a linear approximation z k+1 ≈H ϵ k+1|k + ν k+1 is employed. Define P k+1|k+1 :=E[ ϵ k+1|k+1 ϵ ⊺ k+1|k+1 ] . Assuming that E[ ϵ k+1|k ν ⊺ k+1 ]=0 , one gets P k+1|k+1 =(I−KH) P k+1|k (∙ ) ⊺ +K R k+1 K ⊺ . (44) View Source □  SECTION B. Rauch-Tung-Striebel Smoother on Lie Groups Proof: Lemma II.2. Following the lines of [37], from a Bayesian perspective, the RTS smoother on Lie groups can be derived as the MAP estimate of the following joint pdf: p( X k , X k+1 | y 1:T )= = = p( X k | X k+1 , y 1:k )p( X k+1 | y 1:T ) p( X k+1 | X k )p( X k | y 1:k ) p( X k+1 | y 1:k ) p( X k+1 | y 1:T ) p( X k+1 , X k | y 1:k ) p( X k+1 | y 1:k ) p( X k+1 | y 1:T ). (45) View Source Assume that p( X k+1 , X k | y 1:k )= p( X k | y 1:k )= p( X k+1 | y 1:T )= p( X k+1 | y 1:k )= N G×G ( X ^ k|k , X ^ k+1|k ,P) N G ( X ^ k|k , P k|k ) N G ( X ^ s k+1 , P s k+1 ) N G ( X ^ k+1|k , P k+1|k ) (46a) (46b) (46c) (46d) View Source where P=[ P k|k F k P k|k P k|k F ⊺ k P k+1|k ] and { X ^ k|k , P k|k } k=1:N comes from the D-LIE-EKF. Accordingly, (45) becomes p( X k , X k+1 | y 1:T ) ∝exp(− 1 2 ∥ ∥ ∥ ∥ ∥ ⎡ ⎣ ⎢ log ∨ G [ X ^ −1 k|k X k ] log ∨ G [ X ^ −1 k+1|k X k+1 ] ⎤ ⎦ ⎥ ∥ ∥ ∥ ∥ ∥ 2 P −1 + 1 2 ∥ ∥ log ∨ G [ X ^ −1 k+1|k X k+1 ] ∥ ∥ 2 P −1 k+1|k − 1 2 ∥ ∥ ∥ log ∨ G [ ( X ^ s k+1 ) −1 X k+1 ] ∥ ∥ ∥ 2 ( P s k+1 ) −1 ). (47) View Source Parametrize X k = X ^ k|k exp ∧ G ( δ k ) and X k+1 = X ^ s k+1 exp ∧ G ( δ k+1 ) . Thereafter, taking the negative logarithm of (47) yields ℓ( δ k , δ k+1 )= 1 2 ∥ ∥ ∥ [ δ k log ∨ G [ exp ∧ G ( z s ) exp ∧ G ( δ k+1 )] ] ∥ ∥ ∥ 2 P −1 − 1 2 ∥ log ∨ G [ exp ∧ G ( z s ) exp ∧ G ( δ k+1 )] ∥ 2 P −1 k+1|k + 1 2 ∥ δ k+1 ∥ 2 ( P s k+1 ) −1 (48) View Source where z s := log ∨ G [ X ^ −1 k+1|k X ^ s k+1 ] . Assuming that both z s and δ k+1 are small, one has ℓ( δ k , δ k+1 ) = 1 2 ∥ ∥ ∥ [ δ k z s + δ k+1 ] ∥ ∥ ∥ 2 P −1 − 1 2 ∥ z s + δ k+1 ∥ 2 P −1 k+1|k + 1 2 ∥ δ k+1 ∥ 2 ( P s k+1 ) −1 = 1 2 ∥Aδ+b∥ 2 W (49) View Source where δ:=[ δ k δ k+1 ],A:= ⎡ ⎣ ⎢ ⎢ ⎢ I 0 0 0 0 I I I ⎤ ⎦ ⎥ ⎥ ⎥ ,b:= ⎡ ⎣ ⎢ ⎢ ⎢ 0 z s z s 0 ⎤ ⎦ ⎥ ⎥ ⎥ (50) View Source and W=blkdiag( P −1 ,− P −1 k+1|k ,( P s k+1 ) −1 ) . The optimal solution of (49) is straightforward given by δ ∗ = = ( A ⊺ WA ) −1 A ⊺ Wb [ δ ∗ k δ ∗ k+1 ]=[ G k z s 0 ]. (51) View Source Finally, the smoothed state estimate is X ^ s k = X ^ k|k exp ∧ G ( G k z s ) and the final covariance is obtained from the first block diagonal of ( A ⊺ WA ) −1 (see [23]). □  Authors Figures References Keywords Metrics Footnotes More Like This Fault Detection in Inertial Measurement Unit and Global Navigation Satellite System of an Unmanned surface vehicle 2022 22nd International Conference on Control, Automation and Systems (ICCAS) Published: 2022 Known Vulnerabilities of Global Navigation Satellite Systems, Status, and Potential Mitigation Techniques Proceedings of the IEEE Published: 2016 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."

</subsection_point_Point 1>

<previous_sections>

A systematic review of automated systems for real-time irrigation management

1. INTRODUCTION
The challenge of feeding a growing population with finite resources is becoming increasingly pressing. By 2050, the world population is expected to reach 9.7 billion, necessitating a 70% increase in food production (Falkenmark and Rockstrom, 2009). Irrigation plays a crucial role in enhancing crop yields and agricultural productivity to meet this growing demand. Studies have shown that irrigation can significantly increase crop water productivity, contributing to increased food production (Ali and Talukder, 2008; Playan and Mateos, 2005). However, water scarcity poses a significant challenge, with many regions facing water deficits and the need for improved water management practices (Falkenmark and Rockstrom, 2009). Optimizing irrigation schedules and doses based on crop requirements and environmental conditions is essential for maximizing yield and quality while minimizing water use (Zhang et al., 2024). The necessity of scalable water-efficient practices for increasing food demand cannot be overstated. Techniques such as regulated deficit irrigation, magnetically treated water, and the use of drought-tolerant crops like sorghum have shown promise in improving water productivity and ensuring food security (Mehmood et al., 2023; Putti et al., 2023; Hadebe et al., 2016). As the global food challenge intensifies, it is imperative to critically evaluate the current state and future potential of irrigation management systems to guide research, innovation, and implementation efforts towards fully autonomous, scalable solutions.

Despite the importance of irrigation in addressing the global food challenge, traditional irrigation management techniques, such as manual scheduling and timer-based systems, have significant limitations. These methods are often labor-intensive, inefficient, and less adaptable to changing conditions (Savin et al., 2023). Manual and timer-based scheduling can lead to high operational costs and inefficient water use (Raghavendra, Han, and Shin, 2023). The reliance on manual intervention and predetermined schedules limits their adaptability to changing environmental conditions, crop water requirements, and soil moisture levels (Kaptein et al., 2019). Sensor-based irrigation systems offer an alternative, enabling real-time adjustments based on soil water status measurements (Kaptein et al., 2019). However, the adoption of these systems in commercial settings has been limited, often requiring extensive input from researchers (Kim et al., 2014; Lea-Cox et al., 2018; Ristvey et al., 2018). The limitations of traditional irrigation management techniques highlight the need for scalable, automated solutions for greater efficiency in irrigation management. Automated systems that collect real-time data, analyze it, and make autonomous irrigation decisions can lead to improved water use efficiency and increased crop productivity (Champness et al., 2023; Wu et al., 2022). To fully understand the potential of automated systems, it is necessary to examine the automation of each part of the irrigation management pipeline and analyze the effectiveness and efficiency of integrated end-to-end solutions.

The emergence of smart irrigation management and IoT marks a significant shift from historical irrigation practices. Modern approaches rely on vast data and analysis algorithms, leveraging technologies such as remote sensing, sensor networks, weather data, and computational algorithms (Atanasov, 2023; Bellvert et al., 2023; Kumar et al., 2023). IoT plays a vital role in collecting vast amounts of data through sensors, data transmission, and tailored networks, enabling real-time monitoring and control of irrigation systems (Liakos, 2023; Zuckerman et al., 2024). These advancements in data collection and analysis have the potential to revolutionize irrigation management, allowing for more precise and efficient water use. However, challenges such as processing diverse data sources, data integration, and lack of integrated data analysis hamper the full benefit of IoT in irrigation management (Dave et al., 2023). The current fragmented approach in smart irrigation, focusing on individual components rather than the entire system, limits the potential for fully autonomous, real-time end-to-end irrigation management (Togneri et al., 2021). To address these challenges and fully realize the potential of smart irrigation management, there is a need for automating and integrating each section of the irrigation management pipeline, from sensor/weather data collection and transmission to processing, analysis, decision-making, and automated action (McKinion and Lemmon, 1985). This integration requires a thorough investigation of the role of interoperability and standardization in enabling seamless communication and compatibility between components within the automated irrigation management pipeline.

Machine learning (ML) plays a significant role in processing vast data, predicting plant stress, modeling climate effects, and optimizing irrigation in smart irrigation management systems. ML algorithms can analyze data collected from sensors and weather stations to determine optimal irrigation schedules (Vianny et al., 2022). However, the potential of ML is often constrained by manual steps, such as data interpretation, decision-making on irrigation timing and volume, and system adjustments. Automating ML integration to allow direct action from insights to irrigation execution, removing bottlenecks and achieving real-time adaptability, is crucial for fully autonomous irrigation management (Barzallo-Bertot et al., 2022). By integrating ML into automated systems, the irrigation management pipeline can become more seamless and efficient, enabling real-time decision-making and action based on data-driven insights. To achieve this level of automation and integration, it is essential to identify gaps and propose solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.

To achieve seamless integration across the automated irrigation management system, interoperability and standardization are critical. Interoperability allows different system components, such as sensors, actuators, and software, to communicate and exchange data effectively, while standardization ensures that data is represented in a consistent format (Santos et al., 2020). Standardized protocols and data formats are essential for achieving seamless integration and ensuring compatibility between components in real-time irrigation management systems (Robles et al., 2022; Hatzivasilis et al., 2018). Existing and emerging standards, such as OGC SensorThings API and ISO 11783, have applicability to real-time irrigation management systems (Hazra et al., 2021). However, challenges such as data quality, scalability, reliability, and security need to be addressed to fully realize the potential of interoperability and standardization in automated irrigation management systems (Hazra et al., 2021). Addressing these challenges is crucial for enabling the seamless integration of components within the automated irrigation management pipeline, which is essential for achieving fully autonomous, scalable irrigation management. A comprehensive evaluation of the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline is necessary to guide future research and implementation efforts.
The primary objective of this systematic review is to critically evaluate the current state and future potential of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies for enhancing agricultural water use efficiency and crop productivity.
Specific objectives include:
•	Examining the automation of each part of the irrigation management pipeline and the seamless integration of each section in the context of irrigation scheduling and management.
•	Analyzing the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
•	Investigating the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline.
•	Identifying gaps and proposing solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.
By addressing these objectives, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.

2. REVIEW METHODOLOGY
•	Question-driven framework to guide the literature review of real-time, autonomous irrigation management systems
•	Key research questions posed, each with the motivation behind investigating them and a starting hypothesis to evaluate against the examined literature
•	Table presenting the major objectives, specific objectives, questions, motivations, and hypotheses
3. DATA COLLECTION TO CLOUD: AUTOMATION AND REAL-TIME PROCESSING
3.1. Irrigation management data
The success of automated irrigation management systems relies heavily on the collection, transmission, and analysis of various types of data. The most applicable data types for irrigation management include soil moisture, canopy temperature, weather data, and plant physiological parameters (Farooq et al., 2019; Li et al., 2019; Olivier et al., 2021; Evett et al., 2020). These data are typically collected from a range of sources, including in-field sensors, remote sensing platforms, weather stations, and manual measurements (Li et al., 2019; Karimi et al., 2018).
Soil moisture data is arguably the most critical type of data for irrigation management, as it directly reflects the water available to plants and can be used to determine the optimal timing and amount of irrigation (Olivier et al., 2021; Intrigliolo & Castel, 2006). Soil moisture sensors, such as tensiometers, capacitance probes, and time-domain reflectometry (TDR) sensors, can provide real-time measurements of soil water content at various depths (Farooq et al., 2019). These sensors can be deployed in a network configuration to capture spatial variability in soil moisture across a field (Karimi et al., 2018).
Canopy temperature data is another valuable type of data for irrigation management, as it can be used to assess plant water stress and adjust irrigation accordingly (Evett et al., 2020). Infrared thermometers and thermal cameras can be used to measure canopy temperature, which is influenced by factors such as air temperature, humidity, wind speed, and plant water status (Li et al., 2019). When plants experience water stress, they tend to close their stomata to reduce water loss, leading to an increase in canopy temperature (Evett et al., 2020). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
Weather data, including temperature, humidity, precipitation, wind speed, and solar radiation, are essential for predicting crop water requirements and scheduling irrigation events (Akilan & Baalamurugan, 2024). Weather stations equipped with various sensors can provide real-time measurements of these parameters, which can be used as inputs for crop water requirement models, such as the FAO-56 Penman-Monteith equation (Li et al., 2019). These models estimate crop evapotranspiration (ET) based on weather data and crop-specific coefficients, allowing for the calculation of irrigation requirements (Intrigliolo & Castel, 2006). By integrating weather data into automated irrigation systems, irrigation schedules can be dynamically adjusted based on changing environmental conditions, ensuring that crops receive the optimal amount of water at the right time (Akilan & Baalamurugan, 2024).
When collecting and utilizing these data types, several considerations must be taken into account, including the volume, frequency, format, and source of the data (Farooq et al., 2019). The volume of data generated by automated irrigation systems can be substantial, especially when high-resolution sensors are deployed at a large scale (Bastidas Pacheco et al., 2022). This necessitates the use of efficient data storage, processing, and transmission technologies to handle the data load (Farooq et al., 2019). The frequency of data collection is another important consideration, as it directly impacts the temporal resolution of the data and the ability to detect rapid changes in plant water status or environmental conditions (Bastidas Pacheco et al., 2022). Bastidas Pacheco et al. (2022) demonstrated that collecting full pulse resolution data from water meters provides more accurate estimates of event occurrence, timing, and features compared to aggregated temporal resolutions, highlighting the importance of selecting appropriate data collection frequencies to ensure the quality and usefulness of the data for irrigation management.
The format of the data is also crucial, as it determines the compatibility and interoperability of the data with various analysis tools and platforms (Farooq et al., 2019). Standardized data formats, such as JSON, XML, or CSV, can facilitate data exchange and integration between different components of the automated irrigation system (Zhang et al., 2023). The source of the data is another important consideration, as it can impact the reliability, accuracy, and spatial coverage of the data (Farooq et al., 2019). For example, in-field sensors provide highly localized measurements, while remote sensing platforms, such as satellites or drones, can provide data at larger spatial scales (Li et al., 2019). By combining data from multiple sources, automated irrigation systems can achieve a more comprehensive understanding of crop water requirements and optimize irrigation management accordingly (Farooq et al., 2019).
Data quality, accuracy, and reliability are paramount in irrigation management, as they directly impact the effectiveness of decision-making processes and the efficiency of water use (Gupta et al., 2020). Inaccurate or unreliable data can lead to suboptimal irrigation decisions, resulting in crop stress, yield losses, or wasted water resources (Ramli & Jabbar, 2022). Gupta et al. (2020) emphasized the critical importance of data security and privacy in smart farming systems, as the leakage of sensitive agricultural data can cause severe economic losses to farmers and compromise the integrity of the automated irrigation system. The authors also highlighted the need for robust authentication and secure communication protocols to prevent unauthorized access to smart farming systems and protect data in transit (Gupta et al., 2020).
Ramli and Jabbar (2022) addressed the challenges associated with implementing real-time, automated irrigation systems, including data quality, scalability, reliability, and security. They proposed solutions and best practices based on the analysis of case studies and real-world implementations, such as the use of redundant sensors, data validation techniques, and secure communication protocols (Ramli & Jabbar, 2022). The authors also emphasized the importance of regular maintenance and calibration of sensors to ensure the accuracy and reliability of the collected data (Ramli & Jabbar, 2022).
Researchers have investigated the use of data compression, aggregation, and filtering techniques to reduce bandwidth requirements and improve transmission efficiency in automated irrigation systems (Karim et al., 2023; Rady et al., 2020; Cui, 2023). Karim et al. (2023) explored the effectiveness of various data compression techniques, such as lossless and lossy compression algorithms, in reducing the size of data packets transmitted over wireless networks. The authors found that lossless compression techniques, such as Huffman coding and Lempel-Ziv-Welch (LZW), can significantly reduce data size without compromising data quality, while lossy compression techniques, such as JPEG and MP3, can further reduce data size by introducing acceptable levels of distortion (Karim et al., 2023).
Rady et al. (2020) developed a novel data compression algorithm specifically designed for irrigation data, which achieved significant compression ratios without compromising data quality. The authors demonstrated that their algorithm could reduce the amount of data transmitted over wireless networks, thereby improving the efficiency of the irrigation system and reducing costs (Rady et al., 2020). Cui (2023) investigated the use of data aggregation and filtering techniques to reduce the number of transmissions and save bandwidth in automated irrigation systems. The author proposed a data aggregation scheme that combines multiple sensor readings into a single value, such as the average soil moisture over a specified time interval, to reduce the frequency of data transmissions (Cui, 2023). Additionally, the author explored the use of data filtering techniques, such as Kalman filters and particle filters, to remove noise and outliers from sensor data, improving the accuracy and reliability of the transmitted information (Cui, 2023).
Data standardization and harmonization are crucial for facilitating seamless integration and interoperability between the various components of automated irrigation management systems (Zhang et al., 2023; Ermoliev et al., 2022). Zhang et al. (2023) developed a novel cyberinformatics technology called iCrop, which enables the in-season monitoring of crop-specific land cover across the contiguous United States. The authors highlighted the importance of data standardization and harmonization in the context of iCrop, as it allows for the efficient distribution of crop-specific land cover information based on the findable, accessible, interoperable, and reusable (FAIR) data principle (Zhang et al., 2023). By adopting standardized data formats and protocols, such as the Open Geospatial Consortium (OGC) standards, iCrop enables the seamless integration of various data sources and facilitates the interoperability of the system with other agricultural decision support tools (Zhang et al., 2023).
Ermoliev et al. (2022) proposed a linkage methodology for linking distributed sectoral/regional optimization models in a situation where private information is not available or cannot be shared by modeling teams. The authors emphasized the need for data standardization to enable decentralized cross-sectoral coordination and analysis, as it allows for the consistent representation and exchange of data between different models and stakeholders (Ermoliev et al., 2022). By adopting standardized data formats and interfaces, the proposed linkage methodology can facilitate the integration of various optimization models and support the development of comprehensive decision support systems for sustainable resource management (Ermoliev et al., 2022).
Metadata plays a vital role in providing context and enabling better data interpretation and decision-making in automated irrigation management systems (Jahanddideh-Tehrani et al., 2021). Metadata refers to the additional information that describes the characteristics, quality, and context of the primary data, such as the sensor type, calibration parameters, measurement units, and timestamp (Jahanddideh-Tehrani et al., 2021). Jahanddideh-Tehrani et al. (2021) highlighted the importance of metadata in water resources management, as it enables decision-makers to use the data to the best of its capabilities by understanding factors such as when water data was collected and what factors might have contributed to the measurements. The authors emphasized the need for standardized metadata formats and guidelines, such as the Dublin Core Metadata Initiative (DCMI) and the ISO 19115 standard, to ensure the consistency and interoperability of metadata across different water information systems (Jahanddideh-Tehrani et al., 2021).
In the context of automated irrigation management systems, metadata can provide valuable information about the data collection process, sensor performance, and environmental conditions that can aid in data interpretation and decision-making (Cota & Mamede, 2023). For example, metadata about the sensor type and calibration parameters can help assess the accuracy and reliability of the collected data, while metadata about the weather conditions and soil properties can provide context for interpreting the data and adjusting irrigation strategies accordingly (Cota & Mamede, 2023). By incorporating metadata into the data management and analysis pipeline of automated irrigation systems, decision-makers can make more informed and context-aware decisions, leading to improved water use efficiency and crop productivity (Jahanddideh-Tehrani et al., 2021).

3.2. Edge Computing and Fog Computing
Edge computing and fog computing have emerged as transformative technologies in the realm of real-time irrigation management systems, offering significant potential for improving efficiency, scalability, and reliability (Abdel Nasser et al., 2020; Tran et al., 2019). Edge computing refers to the practice of processing data near the edge of the network, close to the source of the data, while fog computing is a decentralized computing infrastructure that extends cloud computing capabilities to the network edge (Hassija et al., 2019). These technologies bring computation and analytics closer to the data source, reducing the need for data to travel to the cloud and enabling faster processing and decision-making (Hassija et al., 2019; Zhang et al., 2020).
The potential of edge computing and fog computing in real-time irrigation management is immense. Abdel Nasser et al. (2020) proposed a two-layer system for water demand prediction using automated meters and machine learning techniques, demonstrating the potential of edge computing in improving the efficiency and scalability of irrigation management. The system collects and aggregates data from distributed smart meters in the first layer, while the second layer uses LSTM neural networks to predict water demand for different regions of households. By leveraging edge computing, the system can achieve high accuracy in predicting water demand, which is essential for efficient irrigation management (Abdel Nasser et al., 2020).
Tran et al. (2019) conducted a comprehensive review of real-time, end-to-end automated irrigation management systems, highlighting the role of fog computing in addressing data transmission challenges and enabling seamless integration across the irrigation management pipeline. The authors emphasize that real-time, end-to-end automated irrigation management systems have the potential to significantly improve water efficiency, crop yields, and reduce labor costs. However, they also identify several challenges that need to be addressed, such as data quality, scalability, reliability, and security, which can be effectively tackled by implementing fog computing architectures (Tran et al., 2019).
Edge computing offers several benefits in real-time irrigation management systems, including reduced latency, real-time decision-making, and reduced reliance on cloud connectivity (Mishra, 2020; Zhang et al., 2020). By processing data closer to the source, edge computing enables faster response times and more efficient data handling (Mishra, 2020). Mishra (2020) highlights that edge computing reduces latency by processing data closer to the source, enabling real-time decision-making and lessening reliance on cloud connectivity by shifting processing to local or edge devices.
Zhang et al. (2020) explore the application of edge computing in agricultural settings, demonstrating its potential to improve the efficiency and accuracy of irrigation systems. The authors discuss how edge computing has prospects in various agricultural applications, such as pest identification, safety traceability of agricultural products, unmanned agricultural machinery, agricultural technology promotion, and intelligent management. They also emphasize that the emergence of edge computing models, such as fog computing, cloudlet, and mobile edge computing, has transformed the management and operation of farms (Zhang et al., 2020).
Fog computing plays a crucial role in distributing processing and storage across the network, enhancing the scalability and reliability of automated irrigation systems (Premkumar & Sigappi, 2022; Singh et al., 2022). Premkumar and Sigappi (2022) evaluate the current state of automated irrigation management systems and propose a hybrid machine learning approach for predicting soil moisture and managing irrigation. Their study emphasizes the potential of fog computing in distributing processing and storage across the network, improving the efficiency and scalability of irrigation systems. The proposed hybrid machine learning approach outperforms other machine learning algorithms in predicting soil moisture, demonstrating the effectiveness of fog computing in enhancing the performance of automated irrigation systems (Premkumar & Sigappi, 2022).
Singh et al. (2022) discuss the role of fog computing in distributing processing and storage across the network, enhancing scalability and reliability in agricultural management systems. The authors argue that by implementing fog computing, these systems can achieve faster data processing and response times, improving overall efficiency and effectiveness. They also highlight that fog computing can address the challenges faced by real-time data transmission in agricultural management systems, such as latency, bandwidth limitations, and data security (Singh et al., 2022).
The integration of edge and fog computing in real-time irrigation management systems is crucial for achieving fully automated, scalable, and reliable solutions. As the demand for autonomous irrigation management grows, these technologies will play a pivotal role in enabling faster decision-making, reduced latency, improved resource utilization, and seamless integration across the irrigation management pipeline (Tran et al., 2019; Zhang et al., 2020). By bringing computation and analytics closer to the data source and distributing processing and storage across the network, edge and fog computing can significantly enhance the efficiency and effectiveness of automated irrigation systems, contributing to the overall goal of addressing the global food challenge through optimized water resource management and increased agricultural productivity (Abdel Nasser et al., 2020; Premkumar & Sigappi, 2022; Singh et al., 2022).

3.3. Automation of Data Collection
The automation of data collection is a critical component in the development of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. It enables the efficient gathering of vital information about crop health, environmental conditions, and water requirements, which is essential for enhancing agricultural water use efficiency and crop productivity. Two key aspects of automated data collection are the use of advanced sensing technologies for non-invasive plant stress detection and the implementation of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection.
Advanced sensing technologies, such as hyperspectral imaging and thermal sensing, have emerged as powerful tools for non-invasive plant stress detection in automated irrigation management systems. These technologies provide valuable information about crop traits, enabling early and accurate detection of plant health issues (Triantafyllou et al., 2019). Triantafyllou et al. (2019) propose a comprehensive reference architecture model that incorporates advanced sensing technologies in the sensor layer for real-time plant stress detection, highlighting their importance in providing non-invasive plant stress detection. Similarly, Hossain et al. (2023) present a novel IoT-ML-Blockchain integrated framework for smart agricultural management that leverages advanced sensing technologies to optimize water use and improve crop yield, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
Hyperspectral imaging can capture subtle changes in plant physiology that are indicative of stress, while machine learning algorithms can be employed to extract meaningful patterns from the spectral data and classify different stress types (Araus et al., 2014). Thermal sensing can detect changes in canopy temperature, which is influenced by factors such as plant water status (Li et al., 2019). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
The integration of advanced sensing technologies in automated irrigation management systems has the potential to revolutionize precision agriculture. Jiang et al. (2019) demonstrate the effectiveness of a deep learning-based model in accurately detecting leaf spot diseases, highlighting the importance of image augmentation and deep learning algorithms in enhancing the model's performance.
Wireless sensor networks (WSNs) and energy-efficient communication protocols have the potential to significantly improve the efficiency and reliability of data collection in large-scale, long-term irrigation systems. WSNs offer a cost-effective and scalable solution for real-time data collection in large-scale irrigation systems, providing remote monitoring and automated control capabilities (Mehdizadeh et al., 2020). Nishiura and Yamamoto (2021) propose a novel sensor network system that utilizes drones and wireless power transfer to autonomously collect environmental data from sensor nodes in vast agricultural fields, reducing operational costs and enhancing the efficiency of data collection. Similarly, Higashiura and Yamamoto (2021) introduce a network system that employs UAVs and LoRa communication to efficiently collect environmental data from sensor nodes distributed across large farmlands, optimizing data collection and reducing travel distance and time.
Energy-efficient communication protocols are crucial for ensuring reliable data transmission in challenging environmental conditions and extending the lifespan of sensor nodes (Mehdizadeh et al., 2020). Al-Ali et al. (2023) investigate the potential of WSNs and energy-efficient communication protocols for data collection in large-scale, long-term irrigation systems, discussing the challenges and opportunities of using these technologies to improve the efficiency and reliability of real-time data collection in irrigation management. Mehdizadeh et al. (2020) emphasize the need for careful consideration of factors such as data accuracy, energy consumption, and network reliability when designing effective WSNs for irrigation management, enabling timely irrigation decisions and improved crop yields.
The automation of data collection through the use of advanced sensing technologies and wireless sensor networks is essential for achieving fully autonomous, scalable irrigation management. By enabling non-invasive plant stress detection and large-scale, long-term data collection, these technologies contribute to the overall goal of optimizing water resource management and increasing agricultural productivity. The integration of these technologies in real-time, end-to-end automated irrigation management systems has the potential to enhance agricultural water use efficiency and crop productivity, ultimately contributing to the development of fully autonomous, scalable irrigation management solutions.

3.4: Real-Time Data Transmission Protocols and Technologies
Real-time data transmission is a critical component of automated irrigation management systems, as it enables the timely delivery of sensor data to the cloud for processing and decision-making. The exploration of suitable protocols and network architectures is essential for ensuring efficient and reliable data transmission in these systems, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
The Message Queuing Telemetry Transport (MQTT) protocol has emerged as a popular choice for real-time data transmission in IoT networks, including those used for automated irrigation management. MQTT is a lightweight, publish-subscribe protocol designed for constrained devices and low-bandwidth networks (Author, 2019). Its simplicity and low overhead make it well-suited for IoT applications where data transmission speed and energy efficiency are critical (Saranyadevi et al., 2022). MQTT provides three Quality of Service (QoS) levels, ensuring data reliability in real-time scenarios (Author, 2019). Chen et al. (2020) proposed novel algorithms to improve data exchange efficiency and handle rerouting in MQTT-based IoT networks for automated irrigation management systems. Their TBRouting algorithm efficiently finds the shortest paths for data transmission, while the Rerouting algorithm effectively handles the rerouting of topic-based session flows when a broker crashes. The combination of these algorithms can significantly improve the performance and reliability of automated irrigation management systems (Chen et al., 2020).
Client-server IoT networks, such as those based on MQTT, play a crucial role in real-time data transmission for automated irrigation management systems. In these networks, sensors and devices (clients) publish data to a central broker (server), which then distributes the data to subscribed clients (Verma et al., 2021). This architecture enables efficient data collection, processing, and dissemination, facilitating the integration of various components within the automated irrigation management pipeline. Verma et al. (2021) proposed an architecture for healthcare monitoring systems using IoT and communication protocols, which provides a comprehensive overview of existing approaches and highlights challenges and opportunities in the field. Although focused on healthcare, the insights from this study can be applied to automated irrigation management systems, emphasizing the importance of interoperability and standardization for seamless integration (Verma et al., 2021).
In addition to MQTT, other application layer protocols such as XMPP, CoAP, SOAP, and HTTP have been explored for real-time data transmission in IoT networks. Each protocol has its strengths and weaknesses, making them suitable for different applications and scenarios. XMPP (Extensible Messaging and Presence Protocol) is an open-standard protocol that supports real-time messaging, presence, and request-response services (Saint-Andre, 2011). CoAP (Constrained Application Protocol) is a specialized web transfer protocol designed for use with constrained nodes and networks in the Internet of Things (Shelby et al., 2014). SOAP (Simple Object Access Protocol) is a protocol for exchanging structured information in the implementation of web services, while HTTP (Hypertext Transfer Protocol) is the foundation of data communication for the World Wide Web (Fielding et al., 1999).
Motamedi and Villányi (2022) compared and evaluated wireless communication protocols for the implementation of smart irrigation systems in greenhouses, considering factors such as power consumption, range, reliability, and scalability. They found that ZigBee is the most suitable local communication protocol for greenhouse irrigation due to its large number of nodes and long range, while MQTT is the recommended messaging protocol for smart irrigation systems due to its TCP transport protocol and quality of service (QoS) options. GSM is a reliable and cost-effective global communication protocol for greenhouse irrigation, providing wide coverage and low cost (Motamedi & Villányi, 2022).
Syafarinda et al. (2018) investigated the use of the MQTT protocol in a precision agriculture system using a Wireless Sensor Network (WSN). They found that MQTT is suitable for use in IoT applications due to its lightweight, simple, and low bandwidth requirements. The average data transmission speed using the MQTT protocol was approximately 1 second, demonstrating its effectiveness for real-time data transmission in precision agriculture systems (Syafarinda et al., 2018).
The choice of application layer protocol for real-time irrigation management depends on factors such as data transmission speed, reliability, and energy efficiency. MQTT and RTPS (Real-Time Publish-Subscribe) are both suitable for real-time data transmission in IoT systems, but they have different strengths and weaknesses. MQTT is a better choice for applications that require low latency and high throughput, while RTPS is a better choice for applications that require high reliability and low latency (Sanchez-Iborra & Skarmeta, 2021). The exploration of MQTT and client-server IoT networks, along with the comparison of various application layer protocols, provides valuable insights into the suitability of these technologies for real-time data transmission in automated irrigation management systems.
In summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.

3.5. Challenges and Solutions in Real-Time Data Transmission
Following the exploration of data collection, processing at the edge and fog, and automation in previous sections, we now turn to the critical aspect of real-time data transmission. While essential for automated irrigation management, this stage presents unique challenges that must be addressed to ensure system efficiency and reliability.
Obstacles in Real-Time Data Transmission
Agricultural environments present unique challenges for real-time data transmission, directly impacting the effectiveness of automated irrigation systems. Environmental factors can significantly disrupt wireless communication. Adverse weather conditions such as heavy rain, fog, and high winds can weaken or even block radio signals, leading to data loss and compromised system performance. Physical obstacles like trees, buildings, and uneven terrain further complicate signal propagation, creating reliability issues (Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). These environmental challenges necessitate robust communication protocols and network architectures that can ensure consistent and reliable data flow.
In addition to environmental factors, technical limitations also present significant obstacles. Large-scale agricultural operations often demand long-distance data transmission, which can be hindered by the limited range of certain wireless communication protocols. Network congestion, occurring when multiple sensors transmit data concurrently, can lead to delays and potential data loss, further complicating real-time decision-making (Hameed et al., 2020). To mitigate these issues, researchers have investigated the potential of cognitive radio networks (CRNs) and dynamic spectrum access (DSA) for optimizing spectrum utilization and reducing interference (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). CRNs enable devices to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency. DSA, on the other hand, facilitates the dynamic allocation of unused spectrum, enhancing spectrum utilization and reducing congestion.
Furthermore, data security and privacy are paramount concerns in real-time irrigation systems. The sensitive nature of agricultural data, such as crop yields and farm management practices, necessitates robust security measures to prevent unauthorized access and data breaches (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential to protect data integrity and ensure the trustworthiness of the system.
Investigating Data Optimization Techniques
To enhance the efficiency and reliability of real-time data transmission in automated irrigation systems, researchers have explored a range of data optimization techniques. Data compression techniques aim to reduce the size of data packets transmitted over the network, minimizing bandwidth requirements and improving transmission speed (Rady et al., 2020; Karim et al., 2023). Lossless compression algorithms, such as Huffman coding and LZW, preserve data integrity while effectively reducing data size, ensuring that no information is lost during transmission (Cui, 2023). Lossy compression algorithms, such as JPEG and MP3, offer higher compression ratios but introduce a controlled level of data loss, which may be acceptable for certain applications where some loss of precision is tolerable (Karim et al., 2023). The choice between lossless and lossy compression depends on the specific application and the trade-off between data size and accuracy.
Data aggregation techniques provide another effective approach to optimize data transmission. By aggregating multiple sensor readings into a single representative value, such as average soil moisture or temperature, the number of transmissions can be significantly reduced, conserving bandwidth and energy resources (Cui, 2023). This is particularly beneficial in large-scale irrigation systems where numerous sensors are deployed across vast areas, generating substantial amounts of data. Additionally, data filtering techniques play a crucial role in improving data quality and reliability. Kalman filters and particle filters can effectively remove noise and outliers from sensor data, ensuring that only accurate and relevant information is transmitted and used for decision-making (Cui, 2023). This is essential for preventing erroneous data from influencing irrigation decisions and potentially leading to suboptimal water management.
Sensor calibration, drift correction, and fault detection are essential for maintaining data accuracy and reliability (Dos Santos et al., 2023). Regular calibration ensures that sensors provide accurate measurements over time, while drift correction techniques account for gradual changes in sensor readings due to environmental factors or aging. Fault detection mechanisms can identify and address sensor malfunctions or anomalies, preventing erroneous data from influencing irrigation decisions and potentially harming crops or wasting water.
Addressing the Challenges
Effectively addressing the challenges in real-time data transmission requires a multifaceted approach that encompasses environmental, technical, and data-related considerations. Implementing robust and adaptive communication protocols is crucial for overcoming interference and signal degradation caused by weather conditions and physical obstacles. Selecting appropriate protocols, such as LoRa or ZigBee, with suitable range and penetration capabilities can ensure reliable data transmission in challenging agricultural environments (Motamedi & Villányi, 2022). Additionally, employing techniques like frequency hopping and error correction codes can further improve communication resilience and mitigate data loss.
Optimizing network architecture is another key consideration. Deploying a distributed network architecture with edge and fog computing capabilities can significantly enhance data processing and transmission efficiency (Abdel Nasser et al., 2020; Tran et al., 2019). Edge devices can perform initial data processing and aggregation tasks, reducing the amount of data transmitted to the cloud and minimizing latency, while fog nodes can provide additional processing power and storage closer to the data source, enhancing scalability and reliability. This distributed approach alleviates the burden on the central cloud server and allows for more responsive and efficient irrigation management.
Data optimization techniques play a vital role in reducing bandwidth requirements and improving transmission efficiency. The choice of data compression, aggregation, and filtering techniques should be tailored to the specific requirements of the irrigation system, considering factors such as data type, accuracy needs, and available bandwidth. By carefully selecting and implementing these techniques, the overall performance and effectiveness of real-time irrigation systems can be significantly enhanced, leading to more sustainable water management practices and improved agricultural productivity.
By addressing these challenges and implementing appropriate solutions, real-time data transmission can become a reliable and efficient component of automated irrigation systems, contributing to the overall goal of achieving sustainable and productive agriculture in the face of growing food demands and water scarcity.

3.6. IoT Network Architectures and Variable Rate Irrigation (VRI) for Real-Time Irrigation
Real-time irrigation management systems heavily rely on the efficient and reliable transmission of data from sensors and weather stations to the cloud for processing and decision-making. However, agricultural environments present unique challenges to wireless communication, including adverse weather conditions, physical obstacles, and the limitations of wireless technologies. These challenges necessitate robust and adaptive solutions to ensure the consistent and timely flow of data, enabling truly autonomous irrigation scheduling.
Environmental factors, such as heavy rain, fog, and strong winds, can significantly disrupt wireless communication by attenuating or even blocking radio signals, leading to data loss and compromised system performance (Ed-daoudi et al., 2023; Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). Dense vegetation, buildings, and uneven terrain create further complications by causing multipath propagation and shadowing effects (Yim et al., 2018; Gautam and Pagay, 2020). The study by Yim et al. (2018) on LoRa networks in a tree farm environment exemplifies these challenges, revealing reduced communication range and data reliability compared to theoretical expectations. This underscores the need for carefully selecting and optimizing communication protocols and network parameters to ensure reliable data transmission in such environments.
The study by Guzinski et al. (2014a) using a modified TSEB model further highlights the importance of high-resolution data in accurately capturing the spatial and temporal dynamics of energy fluxes influenced by environmental factors. This emphasizes the need for advanced data acquisition and processing techniques that can effectively represent the complexities of agricultural settings.
The limitations of traditional wireless communication technologies, such as limited range and network congestion, pose additional challenges for large-scale agricultural operations. Long-distance data transmission can be hindered by range limitations, while network congestion arising from numerous sensors transmitting concurrently can lead to delays and data loss, hindering real-time decision-making (Hameed et al., 2020). Addressing these challenges requires the exploration of advanced networking technologies that can optimize spectrum utilization, mitigate interference, and improve reliability and efficiency.
Cognitive Radio Networks (CRNs) and Dynamic Spectrum Access (DSA) offer promising solutions for optimizing wireless communication in agricultural settings. CRNs empower devices with the ability to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). Research has explored the potential of CRNs in predicting Radio Frequency (RF) power to avoid noisy channels and optimize spectrum utilization (Iliya et al., 2014; Iliya et al., 2014). These studies demonstrate the effectiveness of combining optimization algorithms with artificial neural networks (ANNs) to enhance the accuracy and generalization of RF power prediction, enabling CRNs to make informed decisions about channel selection and avoid interference.
DSA complements CRN technology by dynamically allocating unused spectrum, further enhancing spectrum utilization and reducing congestion (Shi et al., 2023). The numerical model developed by Shi et al. (2023) showcases the potential of CRNs and DSA for optimizing wireless communication in challenging environments.
The integration of CRNs and DSA into the IoT network architecture requires careful consideration of spectrum sensing techniques, network topology, and data security. Research on cooperative spectrum sensing suggests that distributed approaches, where sensor nodes collaborate and share information, can significantly improve the accuracy and efficiency of spectrum sensing, particularly in dynamic environments (Trigka and Dritsas, 2022; Khalid & Yu, 2019). This collaborative approach enables a more comprehensive understanding of the radio environment and facilitates the identification of available frequency bands for data transmission.
The choice of network topology also impacts the performance and scalability of CRN-based irrigation systems. Mesh networks, where sensor nodes are interconnected and relay data for each other, offer enhanced resilience and coverage compared to star topologies where nodes communicate directly with a central gateway (Akyildiz & Vuran, 2010). However, mesh networks can be more complex to manage and may introduce additional routing overhead. The trade-off between network resilience and complexity needs to be carefully evaluated to select the most appropriate topology for a specific agricultural setting.
Data security and privacy are paramount concerns in IoT-based irrigation systems due to the sensitive nature of agricultural data (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential for protecting data integrity and ensuring system trustworthiness. Research on secure spectrum leasing and resource allocation algorithms for CR-WSN-based irrigation systems has demonstrated the potential of these technologies for enhancing security and efficiency (Hassan, 2023; Afghah et al., 2018).
In conclusion, the development of effective and reliable real-time irrigation management systems requires a comprehensive approach that addresses the challenges of data transmission in agricultural environments. The integration of robust and adaptive communication protocols, optimized network architectures, and advanced networking technologies like CRNs and DSA, along with a focus on data security and privacy, can contribute significantly to achieving the goal of autonomous and efficient irrigation scheduling.
4. AUTOMATED DATA PROCESSING IN THE CLOUD
4.1. Data Quality and Preprocessing
Data quality is paramount in automated irrigation systems as it directly influences the effectiveness of decision-making and water use efficiency. Issues like missing values, inconsistencies, and outliers arising from sensor malfunctions, environmental interference, or network problems (Lv et al., 2023) can significantly impact the performance of machine learning models used for irrigation scheduling and management.
Real-time data cleaning techniques are essential for addressing these challenges. Kalman filtering proves particularly effective in handling missing values and correcting erroneous readings by recursively estimating the system's state based on previous measurements and current sensor data, taking into account noise and uncertainty (Kim et al., 2020). Moving average techniques, by averaging consecutive data points, provide a more stable representation of the underlying trend, filtering out short-term fluctuations (Chhetri, 2023). For outlier detection, adaptive thresholding methods offer a dynamic approach, adjusting thresholds based on the statistical properties of the data to effectively identify anomalies and minimize false positives (Bah et al., 2021). These techniques are crucial in maintaining the integrity of real-time data streams and ensuring the accuracy of subsequent analyses.
Adaptive data preprocessing is essential for managing the diversity of data sources and formats commonly found in irrigation systems. Data normalization techniques, such as min-max scaling or z-score normalization, ensure that all features contribute equally to the analysis by transforming data values to a common scale (Pradal et al., 2016). This is crucial for preventing features with larger values from dominating the analysis and ensuring that all features are given equal consideration. Similarly, feature scaling methods, like standardization or normalization, optimize the range of feature values to improve the performance and convergence of machine learning models (Tortorici et al., 2024). By scaling features to a similar range, the influence of outliers is reduced, and the model's ability to learn from the data is enhanced.
Data fusion techniques play a critical role in integrating information from diverse sources, creating a more comprehensive and reliable dataset for irrigation management. Dempster-Shafer theory, a generalization of probability theory, allows for the expression of both uncertainty and the degree of conflict in evidence, making it suitable for fusing uncertain and conflicting data from heterogeneous sources (Sadiq and Rodriguez, 2004). This is particularly relevant in irrigation systems where data from different sensors may provide slightly different or even contradictory information due to sensor variations or environmental factors. Bayesian inference offers another powerful framework for combining information from multiple sources, updating the probability of a hypothesis as new evidence becomes available. By applying these techniques, data from soil moisture sensors, canopy temperature sensors, weather stations, and other sources can be integrated to provide a holistic understanding of crop water requirements and environmental conditions, leading to more informed and accurate irrigation decisions.
The impact of data quality extends beyond model accuracy to the robustness of machine learning models under varying conditions. Robust models should maintain consistent performance even when faced with data inconsistencies or unexpected situations. Techniques like data augmentation and domain adaptation can enhance model robustness by exposing the model to a wider range of data variations during training. Data augmentation involves generating additional training data by applying transformations or introducing noise to existing data, making the model more resilient to noise and variations in the real-world data. Domain adaptation techniques aim to adapt a model trained on one domain (e.g., a specific crop or geographic location) to perform well on another domain with different data characteristics. This is particularly relevant in irrigation management, where models may need to be applied to different crops, soil types, or climatic conditions.
The choice of data cleaning, preprocessing, and fusion techniques should be carefully considered based on the specific characteristics of the irrigation system and the available data. By selecting and implementing appropriate techniques, the accuracy, reliability, and robustness of machine learning models can be significantly improved, leading to more efficient and sustainable irrigation management practices.
4.2. Scalable and Autonomous Deployment using Containerization Strategies
The transition from data collection and transmission to efficient data processing requires a robust infrastructure capable of handling diverse workloads and data volumes. Containerization technologies, specifically Docker and Kubernetes, offer a promising solution for deploying and scaling data processing and machine learning modules within cloud environments like AWS, Azure, and GCP (Vargas-Rojas et al., 2024; Rosendo et al., 2022; Solayman & Qasha, 2023). Docker provides a standardized way to package applications and their dependencies into self-contained units known as containers, ensuring consistent and reproducible execution across different platforms (Rosendo et al., 2022). Kubernetes, acting as a container orchestrator, manages their deployment, scaling, and networking across a cluster of machines (Rosendo et al., 2022). This combination presents several advantages for automated irrigation management systems.
Firstly, containerization facilitates efficient resource utilization and scalability. By encapsulating applications and their dependencies, containers enable the isolation of resources and prevent conflicts between different modules (Vargas-Rojas et al., 2024; Solayman & Qasha, 2023). This isolation allows for the efficient allocation of resources, such as CPU, memory, and storage, to each container based on its specific needs. Kubernetes further enhances scalability by allowing for the automatic scaling of containers based on real-time demand, ensuring the system can adapt to varying workloads and data volumes, preventing bottlenecks, and ensuring responsiveness to changing conditions (Karamolegkos et al., 2023).
Secondly, containerization promotes portability and reproducibility. By packaging applications and their dependencies into a single unit, containers make it easy to move and deploy them across different cloud environments without the need for environment-specific configurations (Rosendo et al., 2022; Solayman & Qasha, 2023). This portability simplifies the development and deployment process, reducing the time and effort required to set up and manage the system. Additionally, containers ensure reproducibility by providing a consistent execution environment, regardless of the underlying infrastructure. This eliminates variability and ensures that the system will behave consistently across different deployments (Zhou et al., 2023).
Optimizing container orchestration and resource allocation is crucial to minimizing latency and maximizing throughput in real-time data processing pipelines. Techniques like auto-scaling and dynamic resource allocation play a critical role in this context (Hethcoat et al., 2024; Werner and Tai, 2023; Kumar et al., 2024). Auto-scaling automatically adjusts the number of container instances based on real-time demand, ensuring that sufficient resources are available to handle peak workloads while avoiding over-provisioning during periods of low demand (Hethcoat et al., 2024; Kumar et al., 2024). Dynamic resource allocation enables the fine-grained adjustment of resources allocated to each container based on its specific needs and the current workload (Werner and Tai, 2023). This ensures efficient resource allocation and provides each container with the necessary resources to perform its tasks effectively.
Performance monitoring tools, such as Kubernetes Metrics Server and Prometheus, are essential for gaining insights into the performance of containers and the overall system (Hethcoat et al., 2024; Kuity & Peddoju, 2023). These tools provide valuable data on key performance indicators, such as CPU and memory usage, network traffic, and application-specific metrics. By monitoring this data, administrators can identify bottlenecks, optimize resource allocation strategies, and continuously improve system performance (Hethcoat et al., 2024). This data-driven approach ensures that automated irrigation management systems can operate efficiently and reliably.
By integrating containerization technologies with optimization techniques and performance monitoring, automated irrigation management systems achieve the scalability, autonomy, and efficiency required for effective real-time data processing and decision-making. This approach facilitates a seamless and responsive system that can adapt to changing conditions and contribute to the overall goal of optimizing water resource management and increasing agricultural productivity.
4.3. Deploying ML Models for Data Processing
•	Architectures and frameworks for deploying machine learning models on cloud platforms for real-time data processing and inference in irrigation management systems, such as: TensorFlow Serving, Apache MXNet Model Server, ONNX Runtime
•	Techniques for optimizing machine learning model performance and resource utilization in cloud environments, such as: Model compression (e.g., pruning, quantization), Hardware acceleration (e.g., GPU, TPU), Distributed training (e.g., Horovod, BytePS)
•	Integration of deployed machine learning models with other components of the automated irrigation management pipeline, such as data preprocessing, decision-making, and control systems, using protocols like: MQTT, CoAP, RESTful APIs
4.4. Online Learning in the Cloud
•	Application of online learning techniques for continuously updating and improving machine learning models based on incoming real-time data, using algorithms such as: Stochastic gradient descent (SGD), Passive-aggressive algorithms, Online random forests
•	Architectures and frameworks for implementing online learning in cloud-based irrigation management systems, such as: Apache Spark Streaming, Apache Flink, AWS Kinesis, leveraging serverless computing and stream processing paradigms
•	Strategies for balancing exploration and exploitation in online learning to adapt to changing environmental conditions and optimize irrigation decision-making, using techniques such as: Multi-armed bandits, Bayesian optimization, Reinforcement learning (e.g., Q-learning, SARSA)


5. GENERATING AND APPLYING IRRIGATION INSIGHTS 
5.1. Real-Time Generation of Actionable Irrigation Insights
•	Advanced predictive models, such as deep learning (e.g., LSTM, CNN) and ensemble methods (e.g., Random Forests), for precise, site-specific irrigation recommendations
•	Integration of IoT sensor data (e.g., soil moisture probes, weather stations) and cloud-based data sources (e.g., weather forecasts, satellite imagery) using data fusion techniques (e.g., Kalman filtering) to enhance insight accuracy and resolution
•	Strategies for handling data heterogeneity, uncertainty, and quality issues in real-time insight generation, such as data preprocessing and outlier detection
•	Techniques for reducing computational complexity and latency, such as edge computing (e.g., fog computing), model compression (e.g., quantization), and hardware accelerators (e.g., GPUs)
5.2. Automated Application of Irrigation Insights
•	Architectures and protocols for seamless integration of ML-generated insights with IoT-enabled irrigation control systems, such as MQTT and CoAP for lightweight, real-time communication
•	Analysis of industry-leading products and services, such as smart irrigation controllers (e.g., Rachio) and cloud-based irrigation management platforms (e.g., CropX)
•	Strategies for ensuring reliability, security, and scalability of automated insight application, such as redundant communication channels and secure edge-to-cloud architectures
•	Case studies of successful implementations of closed-loop, autonomous irrigation systems in research and commercial settings, highlighting technologies used and benefits achieved

6. INTEGRATION, INTEROPERABILITY, AND STANDARDIZATION 
6.1. Interoperability and Standardization
•	Importance of interoperability and standardization in enabling seamless integration of automated irrigation components
•	Overview of existing and emerging standards for IoT devices, communication protocols, and data formats in precision agriculture (e.g., ISOBUS, agroXML, SensorML)
•	Role of standardization bodies and industry consortia in promoting interoperability (e.g., AgGateway, Open Ag Data Alliance, Agricultural Industry Electronics Foundation)
•	Challenges in adopting and implementing standards across diverse hardware and software platforms
•	Strategies for encouraging widespread adoption of standards and best practices for interoperability in automated irrigation systems
6.2. Integration with Existing Irrigation Infrastructure
•	Challenges and strategies for retrofitting legacy irrigation systems with IoT sensors, actuators, and communication devices
•	Hardware compatibility issues and solutions (e.g., adapters, modular designs)
•	Software and firmware updates to enable integration with automated decision-making systems
•	Data integration and normalization techniques for merging legacy and new data sources
•	Economic and practical considerations for transitioning from manual to automated irrigation management
•	Cost-benefit analysis of upgrading existing infrastructure vs. implementing new systems
•	Phased implementation approaches to minimize disruption and optimize resource allocation
•	Training and support requirements for farmers and irrigation managers adopting automated systems
•	Case studies and real-world examples of successful integration of automated irrigation with existing infrastructure
6.3. Integration with Other Precision Agriculture Technologies
•	Synergies between automated irrigation and complementary technologies
•	Remote sensing (satellite, UAV, and ground-based) for crop monitoring and evapotranspiration estimation
•	Soil moisture sensors and weather stations for real-time, localized data collection
•	Variable rate application systems for precise irrigation delivery based on crop requirements
•	Yield mapping and analytics for assessing the impact of automated irrigation on crop productivity
•	Architectures and frameworks for integrating diverse data sources and technologies into a unified precision agriculture ecosystem
•	Edge computing and fog computing paradigms for real-time data processing and decision-making
•	Cloud-based platforms for data storage, analysis, and visualization
•	API-driven approaches for modular integration of third-party services and applications
•	Challenges and solutions for ensuring data quality, consistency, and security across integrated precision agriculture systems
•	Data cleaning, preprocessing, and harmonization techniques
•	Blockchain and distributed ledger technologies for secure, tamper-proof data sharing and traceability
•	Access control and authentication mechanisms for protecting sensitive data and resources
•	Future trends and research directions in the integration of automated irrigation with advanced precision agriculture technologies (e.g., AI-driven crop modeling, robotics, and autonomous vehicles)
6.4. Cybersecurity Considerations for Integrated Automated Irrigation Systems
•	Unique security risks and vulnerabilities associated with IoT-based automated irrigation systems
•	Potential for unauthorized access, data tampering, and system manipulation
•	Implications of security breaches for crop health, water resource management, and farm productivity
•	Best practices and strategies for securing automated irrigation systems
•	Secure device provisioning and authentication (e.g., hardware security modules, certificates)
•	Encryption and secure communication protocols (e.g., TLS, DTLS)
•	Firmware and software updates to address emerging security threats
•	Network segmentation and access control to limit the impact of breaches
•	Role of cybersecurity standards and frameworks in guiding the development and deployment of secure automated irrigation systems (e.g., NIST CSF, IEC 62443)
•	Importance of user awareness, training, and incident response planning in maintaining the security of integrated automated irrigation systems

7. MONITORING AND ENSURING SYSTEM RELIABILITY
7.1. Resilience and Fault Tolerance in Automated Irrigation Systems
•	Strategies for ensuring robustness and reliability in the face of failures, disruptions, or unexpected events
•	Redundancy: Implementing redundant components, such as duplicate sensors (e.g., soil moisture sensors, weather stations), controllers (e.g., PLCs, microcontrollers), and communication channels (e.g., cellular, satellite, LoRaWAN) to maintain system functionality during component failures
•	Failover mechanisms: Designing seamless failover mechanisms that automatically switch to backup components or systems in case of primary system failure, such as hot-standby controllers or multi-path communication protocols (e.g., mesh networks, software-defined networking)
•	Self-healing capabilities: Incorporating AI-driven self-healing mechanisms that can detect, diagnose, and recover from faults without human intervention, using techniques like reinforcement learning, Bayesian networks, or self-organizing maps
•	The role of distributed architectures and edge computing in enhancing system resilience
•	Decentralizing critical functions and data processing to minimize the impact of single points of failure, using fog computing or multi-agent systems
•	Leveraging edge computing to enable localized decision-making and control, reducing dependence on cloud connectivity and improving response times, using technologies like Raspberry Pi, NVIDIA Jetson, or Intel NUC
•	Anomaly detection and predictive maintenance using AI techniques
•	Employing unsupervised learning algorithms (e.g., autoencoders, clustering) to detect anomalies in sensor data, system performance, and water usage patterns
•	Developing predictive maintenance models using techniques like long short-term memory (LSTM) networks, convolutional neural networks (CNNs), or gradient boosting machines (GBMs) to anticipate and prevent potential system failures based on historical data and real-time monitoring
7.2. Advanced Monitoring Techniques for Automated Irrigation Systems
•	Remote monitoring using IoT-enabled sensors and computer vision
•	Deploying a heterogeneous network of IoT sensors to collect real-time data on soil moisture (e.g., capacitive, tensiometric), temperature (e.g., thermocouples, thermistors), humidity (e.g., capacitive, resistive), and plant health (e.g., sap flow, leaf wetness)
•	Integrating high-resolution cameras (e.g., multispectral, hyperspectral) and computer vision algorithms for visual monitoring of crop growth, disease detection (e.g., using deep learning-based object detection and segmentation), and irrigation system performance (e.g., leak detection, sprinkler uniformity)
•	Transmitting sensor and camera data to cloud-based platforms (e.g., AWS IoT, Google Cloud IoT, Microsoft Azure IoT) for remote access and analysis using protocols like MQTT, CoAP, or AMQP
•	Innovative approaches for real-time system health assessment
•	Developing novel algorithms and metrics for evaluating the health and performance of automated irrigation systems, such as entropy-based measures, network resilience indices, or multi-criteria decision analysis (MCDA) frameworks
•	Combining data from multiple sources (e.g., sensors, weather forecasts, satellite imagery) using data fusion techniques (e.g., Kalman filters, Dempster-Shafer theory) to create a comprehensive view of system health
•	Employing advanced data visualization techniques (e.g., interactive dashboards, augmented reality) to present system health information in an intuitive and actionable format
7.3. Closed-Loop Control and Feedback Mechanisms
•	Exploring the concept of closed-loop control in autonomous irrigation systems
•	Implementing feedback loops that continuously monitor system performance and adjust irrigation schedules based on real-time data, using control techniques like proportional-integral-derivative (PID), model predictive control (MPC), or fuzzy logic control (FLC)
•	Integrating machine learning algorithms (e.g., reinforcement learning, genetic algorithms) to optimize closed-loop control strategies over time, adapting to changing environmental conditions and crop requirements
•	Designing effective feedback mechanisms for user interaction and system optimization
•	Providing user-friendly interfaces (e.g., mobile apps, web dashboards) for farmers to input preferences, constraints, and expert knowledge into the automated irrigation system, using techniques like participatory design or user-centered design
•	Incorporating user feedback and domain expertise to refine irrigation strategies and improve system performance
8. CASE STUDIES AND REAL-WORLD IMPLEMENTATIONS OF FULLY AUTONOMOUS IRRIGATION SYSTEMS
8.1. Fully Autonomous Irrigation Systems in Diverse Agricultural Settings
•	Row Crops: maize, wheat, soybean with real-time soil moisture monitoring and weather-based irrigation scheduling for fully automated precision irrigation
•	Orchards: citrus, apple, almond with plant health monitoring and precision water application for fully autonomous orchard management
•	Greenhouses: tomato, lettuce, herbs with automated drip irrigation and climate control integration for fully automated greenhouse operations
•	Urban Farming: rooftop gardens, vertical farms with IoT-enabled hydroponic systems and remote management for fully autonomous urban crop production
8.2. Integration of Advanced System Components for End-to-End Automation
•	Wireless sensor networks: soil moisture probes, weather stations, plant health monitoring cameras with low-power, long-range communication for fully automated data acquisition
•	Secure data transmission: LoRaWAN, NB-IoT, 5G, satellite communication for reliable, real-time data transfer from field to cloud in fully autonomous irrigation systems
•	Intelligent data processing: edge computing for local data filtering, cloud platforms for scalable storage and analysis, machine learning algorithms for predictive insights in fully automated irrigation management
•	Autonomous decision-making: advanced irrigation scheduling algorithms, precise valve control, closed-loop feedback systems for optimal water management in fully autonomous irrigation systems
8.3. Quantitative Performance Evaluation of Fully Automated Irrigation Systems
•	Water use efficiency: percent reduction in water consumption compared to conventional methods, improved water productivity (yield per unit of water) achieved through fully autonomous irrigation
•	Crop yield and quality improvements: percent increase in yield, enhanced crop uniformity, improved nutritional content attributed to fully automated precision irrigation
•	Labor and energy savings: quantified reduction in labor hours for irrigation management, decreased energy consumption for pumping due to optimized scheduling in fully autonomous systems
•	Economic viability: detailed return on investment analysis, payback period calculations, comprehensive cost-benefit analysis for fully autonomous irrigation management systems
8.4. Lessons Learned and Challenges Encountered in Deploying Autonomous Irrigation Systems
•	Technical challenges and solutions: ensuring reliable data transmission in remote locations, addressing interoperability issues between diverse system components, optimizing power consumption for extended battery life, adapting algorithms to local soil and weather conditions in fully autonomous irrigation systems
•	Operational and logistical hurdles: streamlining installation and maintenance procedures, providing effective user training, seamlessly integrating with existing farm management practices and legacy systems for fully automated irrigation management
•	Regulatory and socio-economic considerations: navigating complex water use regulations, addressing data privacy and security concerns, ensuring equitable access and affordability for smallholder farmers adopting fully autonomous irrigation technologies
8.5. Best Practices and Recommendations for Successful Implementation
•	Designing scalable, modular, and adaptable autonomous irrigation systems to accommodate future growth and changing requirements for fully automated water management
•	Prioritizing user-centered design principles and actively engaging stakeholders throughout the development and deployment process of fully autonomous irrigation solutions
•	Adopting open standards and communication protocols to enable seamless integration of system components and interoperability with third-party platforms in fully automated irrigation setups
•	Implementing robust data validation, filtering, and quality control mechanisms to ensure data integrity and reliability for decision-making in fully autonomous irrigation systems
•	Establishing clear data governance policies and security frameworks to protect sensitive information and maintain user trust in fully automated irrigation management
•	Developing intuitive user interfaces and decision support tools to facilitate easy adoption and effective use of fully autonomous irrigation systems
•	Collaborating with local extension services, agribusinesses, and technology providers for knowledge transfer, technical support, and continuous improvement of fully automated irrigation solutions
8.6. Synthesis of Case Studies and Implications for Autonomous Irrigation Adoption
•	Cross-case analysis of key performance indicators and critical success factors for fully autonomous irrigation scheduling systems in various contexts
•	Identification of common themes, challenges, and innovative solutions across diverse implementations of end-to-end fully automated irrigation management
•	Assessment of the potential for replicability and scaling of successful fully autonomous irrigation projects in different regions and farming systems
•	Implications for future research priorities, technology development roadmaps, and policy interventions to support widespread adoption of fully autonomous irrigation technologies

CONCLUSION/FUTURE DIRECTIONS AND UNANSWERED QUESTIONS
•	Summarize the key insights gained from the question-driven review, emphasizing how each section contributes to the overarching goal of achieving real-time, end-to-end automation in irrigation management
•	Based on the questions addressed, propose new research directions and unanswered questions
•	Identify key research gaps and propose concrete research questions and hypotheses for advancing the field of real-time, automated irrigation management
•	Highlight the need for collaborative research efforts across disciplines, such as computer science, agricultural engineering, and environmental science, to address the complex challenges of automated irrigation systems
•	Emphasize the need for further innovation and exploration in real-time, automated irrigation systems



</previous_sections>

</documents>
<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper.

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: 4.4. Online Learning in the Cloud
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>

<subsection_point_Point 2>
Point: Adaptive data preprocessing methods for dealing with varying data quality and formats from heterogeneous data sources, such as data normalization, feature scaling, and data fusion techniques (e.g., Dempster-Shafer theory, Bayesian inference)

Papers to support point:

Paper 1:
- APA Citation: Sadiq, R., & Rodriguez, M. J. (2004). Interpreting drinking water quality in the distribution system using Dempster–Shafer theory of evidence. Chemosphere, 59(2), 177-188.
  Main Objective: To demonstrate the application of Dempster-Shafer theory for two specific water quality management tasks: data fusion and development of a water quality index (WQI).
  Study Location: Unspecified
  Data Sources: Water quality data
  Technologies Used: Dempster-Shafer theory
  Key Findings: * Dempster-Shafer theory can be used to fuse uncertain and conflicting data from multiple sources.
* Dempster-Shafer theory can be used to develop a WQI that takes into account the uncertainty and conflict in the data.
* Dempster-Shafer theory is a valuable tool for water quality management and can be used to address a variety of problems.
  Extract 1: "Dempster–Shafer theory for interpreting water quality monitoring data"
  Extract 2: "Dempster–Shafer theory application for developing water quality index"
  Limitations: None
  Relevance Evaluation: The paper is highly relevant to the point I am making in my literature review, as it provides a concrete example of how Dempster-Shafer theory can be used to address a specific problem in water quality management. The authors demonstrate the theory's ability to handle uncertain and conflicting data, which is a common challenge in water quality monitoring. The paper also provides a clear and detailed explanation of the theory and its application, making it a valuable resource for researchers and practitioners alike.
  Relevance Score: 1.0
  Inline Citation: (Sadiq and Rodriguez, 2004)
  Explanation: Dempster-Shafer theory is a method for interpreting water quality data by assigning belief (support) and plausibility (uncertainty) values to subsets of a frame of discernment. It is a generalization of probability theory that allows for the expression of both uncertainty and the degree of conflict in the evidence. In this paper, the authors demonstrate the application of Dempster-Shafer theory for two specific water quality management tasks: data fusion and development of a water quality index (WQI).

 Full Text: >
Typesetting math: 64% Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Abstract Keywords 1. Introduction 2. Dempster–Shafer theory for interpreting water quality monitoring data 3. Dempster–Shafer theory application for developing water quality index 4. Summary and conclusions References Show full outline Cited by (34) Figures (4) Tables (9) Table Table Table Table Table Table Show all tables Chemosphere Volume 59, Issue 2, April 2005, Pages 177-188 Interpreting drinking water quality in the distribution system using Dempster–Shafer theory of evidence Author links open overlay panel Rehan Sadiq a, Manuel J. Rodriguez b Show more Share Cite https://doi.org/10.1016/j.chemosphere.2004.11.087 Get rights and content Abstract Interpreting water quality data routinely generated for control and monitoring purposes in water distribution systems is a complicated task for utility managers. In fact, data for diverse water quality indicators (physico-chemical and microbiological) are generated at different times and at different locations in the distribution system. To simplify and improve the understanding and the interpretation of water quality, methodologies for aggregation and fusion of data must be developed. In this paper, the Dempster–Shafer theory also called theory of evidence is introduced as a potential methodology for interpreting water quality data. The conceptual basis of this methodology and the process for its implementation are presented by two applications. The first application deals with the interpretation of spatial water quality data fusion, while the second application deals with the development of water quality index based on key monitored indicators. Based on the obtained results, the authors discuss the potential contribution of theory of evidence as a decision-making tool for water quality management. Previous article in issue Next article in issue Keywords Water qualityData fusionTheory of evidenceAggregation operatorsWater distribution system 1. Introduction Monitoring and inspection of a system or a process may use more than one type of measurements and/or observations to describe the overall Condition State. The credibility of measurements to assess overall Condition State is important to be quantified for reliable decision-making. The data fusion is useful for an objective aggregation that can be reproducible and interpretable. Many infrastructure engineering problems, e.g., condition assessment of assets, production process quality control, and water quality monitoring require more than one performance indicator to define the Condition State. In addition, the aggregation of spatial or temporal observations of one (or more) performance indicator(s) is generally performed for reliable predictions. The data fusion refers to the scientific aggregation of the observations and measurements. In some cases, different data sets (e.g., measured by different types of sensors and probes, various water quality indicators) give information on various aspects of the system or a process by complementing each other. Therefore, the motivation is to collect more information for accurate prediction of Condition State. It is also possible that the information collected by various data sets can also be redundant if it deals with the same aspect of the problem, but it improves the reliability as one measurement/observation is confirmed by the other. Complementing information and redundancy of data sets are the basis of data fusion applications in condition assessment of assets and water quality monitoring. Regular monitoring of raw water quality, treatment processes and water quality in the distribution systems are integral parts of total drinking water quality management for the implementation of a multi-barrier approach for maintaining high-quality tap water for consumers. Water distribution systems are subjected to adverse reactions and events that can change the high-quality water to unpalatable and unsafe for human consumption by the time it arrives at the tap of the consumer (LeChevallier et al., 1996). As water quality can change significantly in the distribution system, regular monitoring is even more essential to ensure that high-quality drinking water reaches the consumer. To monitor the quality of water in the distribution system, physical, chemical, and biological indicators are recorded from routine grab sampling, followed by an analysis in the laboratory or using portable kits in the field (APHA, AWWA, WPCF, 1995). Sensor technology exists that enables capturing some indicators through online monitoring rather than grab samples. This technology is continually evolving to encompass more types of water quality indicators. Some common water quality indicators used for water distribution are turbidity, residual disinfectant, pH, nitrates, phosphates, organic compounds, total/fecal coliforms, and heterotrophic bacteria (HPC) (Clark, 1994, Hunsinger and Zioglio, 2002, Coulibaly and Rodriguez, 2003). Water uses generate a large amount of water quality data by routine sampling to control and maintain the acceptable Condition State of water quality in the system. Information is gathered on diverse water quality indicators using different techniques (manual sampling or auto-samplers and subsequent laboratory analysis, or online monitoring with automatic analyzer equipment). To better understand and interpret the water quality data, the use of novel techniques that favour the fusion and the aggregation of data is required to be explored. In this paper, the application of Dempster–Shafer (D–S) theory or theory of evidence for interpretation of water quality in the distribution system is demonstrated with the help of two examples. The first example discusses the application of theory of evidence for water quality data fusion for the case of water samples collected at different locations in the distribution system at a given time (interpreting spatial information), which is equally valid for fusion of temporal data or combining both. The second example briefly discusses the application of D–S theory for developing water quality index (WQI) that helps in aggregating and interpreting water quality linguistically, but in a rational manner. 2. Dempster–Shafer theory for interpreting water quality monitoring data There are numerous techniques available for conducting data and knowledge and information fusion, and most common among them are Bayesian inference, Dempster–Shafer rule of combination, fuzzy rule-based inference, and neural networks (Roemer et al., 2001). The idea of evidence integration and accumulation of beliefs are commonly used in Bayesian inference, which implies that p(A) + p(¬A) = 1, i.e., the belief in a hypothesis A can be used to derive the belief in its complement (Alim, 1988). But “NOT A” is the missing evidence (lack of knowledge) that is dealt as equal noninformative priors (Principle of Insufficient Reason) in Bayesian inference instead of ignorance. Alim (1988) argued that “No evidence” is different from having the same degree of confidence in all hypotheses, which is the basic motivation behind D–S theory. Dempster–Shafer theory is a theory of evidence, which is based on classic work by Dempster (1968) and Shafer (1976). The D–S theory can be interpreted as a generalization of probability theory where probabilities are assigned to subsets as opposed to mutually exclusive singletons. The probability theory can associate evidence to only one possible event, whereas D–S theory determines the evidence to sets of events, i.e., if the evidence is sufficient enough to permit the assignment of probabilities to single event (singleton), the D–S theory inference reduces to the probabilistic formulation (Sentz and Ferson, 2002). The D–S theory applications in civil and environmental engineering vary from slope stability (Binaghi et al., 1998), environmental decision-making (Chang and Wright, 1996, Attoh-Okine and Gibbons, 2001), seismic analysis (Alim, 1988), failure detection (Tanaka and Klir, 1999), biological surveillance of river water quality (Boyd et al., 1993), and remote sensing (Wang and Civco, 1994) to climate change (Luo and Caselton, 1997). Many more applications of D–S theory can be seen in detailed bibliography reported by Sentz and Ferson (2002). However, the potential for application of D–S theory in the drinking water industry, in particular for fusion and aggregation of water quality monitoring data in the distribution system, has not been investigated until now. In the following section, the concepts of D–S theory application will be introduced by means of an example of data fusion of monitoring information on water quality in the distribution system. 2.1. Basic concepts of Dempster–Shafer theory and application The frame of discernment Θ (also called universe of discourse) is defined as a set of mutually exclusive alternatives, which has 2Θ subsets in the domain. For example, if the frame of discernment Θ is a set {L, M, H} it may have 8 (=23) subsets. Three important concepts, namely, basic probability assignment (m or bpa), belief (bel), and plausibility (pl) functions are used in D–S theory. Alim (1988) summarized some basic features of the D–S theory as follows: • Evidence in the form of belief (or disbelief) is attributed to subsets in Θ; • As evidence accumulates, the hypothesis set tends to narrow down toward precise estimation of probability; and • Ignorance does not assume equal priors or uniformly distributed, rather it is assigned to frame of discernment Θ. For example, if some evidence “a” is attributed to subset “L” in Θ, the ignorance “1 − a” will not be equally distributed to “M” and “H”, rather it is assigned to Θ = {L, M, H}. Example 1 In this example, it is assumed that water quality in the distribution is reported qualitatively using three risk levels––low (L), medium (M) and high (H) from consumption viewpoint based on compliance of drinking water regulations. The frame of discernment, Θ = {L, M, H} contains 8 subsets ϕ (a null set) {L}, {M}, {H}, {L, M}, {M, H}, {L, H}, and {L, M, H}. Therefore, depending on the evidence, water could be rated as low, medium, high, low or medium, low or high, medium or high, and low or medium or high (in case of complete ignorance). 2.2. Basic probability assignment The basic probability assignment (bpa or m) is different from classical definition of probability and is defined by mapping over the interval [0, 1], where the null set m(ϕ) is “0” and the sum of the basic probability assignments m(A) in a given set A is “1”. The m(A) expresses the proportion of all relevant and available evidence that supports the claim that a particular element of Θ belongs to the set A but to no particular subset of A (Klir, 1995). For a given basic probability assignment m, every set for which m(A) ≠ 0 is called focal element. Formally, this description of m can be represented with the following equation: (1) Example 1 (Contd.): If the water utility manager reports with 60% confidence that water is of low risk quality and with 30% confidence that it is low or medium risk, the ignorance is therefore 10%. The focal elements of hypothesis A can be written as The basic probability assignments for remaining subsets will be zero. 2.3. Belief function The lower and upper bounds of an interval can be determined from the basic probability assignment, which contains the probability set bounded by two nonadditive measures belief and plausibility. The lower bound belief (bl) for a set A is defined as the sum of all the basic probability assignments of the proper subsets (B) of the set of interest A, i.e., B ⊆ A. The general relation between bpa and belief can be written as (2) The belief functions also follow these relationships (3) Example 1 (Contd.): The belief functions can be derived as 2.4. Plausibility function The upper bound, plausibility, is the summation of basic probability assignment of the sets B that intersect with the set of interest A, i.e., B ∩ (A) ≠ ϕ, and therefore it can be written as (4) The plausibility function can be related to belief function through a function called doubt, which is defined as the compliment of belief (5) In addition, the following relationships for belief and plausibility functions hold true in all circumstances (6) pl ( A ) ⩾ bl ( A ) pl ( ϕ ) = 0 pl ( Θ ) = 1 pl ( ¬ A ) = 1 - bel ( A ) Example 1 (Contd.): Continuing on the example, the plausibility function can be derived as follows pl ( A ) L = m ( A ) L + m ( A ) L , M + m ( A ) L , H + m ( A ) Θ = 1.0 pl ( A ) M = m ( A ) M + m ( A ) L , M + m ( A ) M , H + m ( A ) Θ = 0.4 pl ( A ) H = m ( A ) H + m ( A ) L , H + m ( A ) M , H + m ( A ) Θ = 0.1 pl ( A ) L , M = m ( A ) L + m ( A ) M + m ( A ) L , M + m ( A ) L , H + m ( A ) M , H + m ( A ) Θ = 1.0 pl ( A ) L , H = m ( A ) L + m ( A ) H + m ( A ) L , M + m ( A ) L , H + m ( A ) M , H + m ( A ) Θ = 1.0 pl ( A ) M , H = m ( A ) M + m ( A ) H + m ( A ) L , M + m ( A ) L , H + m ( A ) M , H + m ( A ) Θ = 0.4 pl ( A ) L , M , H = m ( A ) M + m ( A ) M + m ( A ) H + m ( A ) L , M + m ( A ) L , H + m ( A ) M , H + m ( A ) Θ = 1.0 2.5. Belief interval The belief interval (U) represents a range in which true probability may lie. It can be determined by subtracting belief from plausibility. The narrow uncertainty band represents more precise probabilities. The probability is uniquely determined if bel(A) = pl(A) and for classical probability theory all probabilities are unique (Yager, 1987). If U(A) has an interval [0, 1], it means that no information is available, but if the interval is [1, 1], then it means that A has been completely confirmed by m(A). Example 1 (Contd.): The uncertainty interval for the case at hand is U ( A ) L = [ 0.6 , 1.0 ] ; U ( A ) M = [ 0.0 , 0.4 ] ; U ( A ) H = [ 0.0 , 0.1 ] U ( A ) L , M = [ 0.9 , 1.0 ] ; U ( A ) L , H = [ 0.6 , 1.0 ] ; U ( A ) M , H = [ 0.0 , 0.4 ] ; and U ( A ) Θ = [ 1.0 , 1.0 ] 2.6. Dempster–Shafer rule of combination The purpose of data fusion is to summarize and simplify information rationally. The D–S theory assumes sources of information are independent. The multiple sources of information in our context could be water quality samples collected at various points Sis in the distribution system at a given time “tj”. The D–S rule of combination can help in providing an overall picture of water quality at a given time “tj” in the distribution system. Similarly, evidences about the water quality can be aggregated temporally (samples collected at various times tjs) at a given sampling point Si using D–S rule of combination. Alim (1988) described that the “combined” belief represents not only the total belief in a set A and all of its subsets but also takes into account the contribution of different sources of evidence that focus on A. The D–S inference uses trade-off type combination operators and less information is assumed than that of Bayesian inference by compromising on precision, but Bayesian theory does not express any uncertainty associated with it and uses Principle of Insufficient Reason for inference (Sentz and Ferson, 2002). The D–S rule of combination strictly emphasizes on the agreement between multiple sources and ignores all the conflicting evidence through normalization. A strict conjunctive logic through AND operator (estimated by a product of two probabilities) is employed in combination of evidence. The D–S combination rule determines the joint m1–2 from the aggregation of two basic probability assignments m1 and m2 by following equation: (7) m 1 – 2 ( A ) = ∑ B ∩ C = A m 1 ( B ) m 2 ( C ) 1 - K when A ≠ ϕ ; and m 1 – 2 ( ϕ ) = 0 where (8) K = ∑ B ∩ C = ϕ m 1 ( B ) m 2 ( C ) where K is the degree of conflict in two sources of evidences. The denominator (1 − K) in Eq. (7) is a normalization factor, which helps aggregation by completely ignoring the conflicting evidence. The above equations can also written as (9) m 1 – 2 ( A ) = ∑ B ∩ C = A m 1 ( B ) m 2 ( C ) ∑ B ∩ C ≠ ϕ m 1 ( B ) m 2 ( C ) Example 1 (Contd.): Water quality is monitored at two locations Si (i = 1, 2) in the distribution system at a given time tj. The utility manager is interested in overall water quality in the distribution system at tj based on these two observations S1 and S2 m1(B)L = 0.6 m2(C)M = 0.4 m1(B)L,M = 0.3 and m2(C)M,H = 0.2 m1(B)Θ = 0.1 m2(C)Θ = 0.4 By applying D–S rule of combination on sources of information B and C, the following data is generated: Degree of conflict = K = 0.24 + 0.12 = 0.36, therefore normalization factor = 1 − K = 0.64 m 1 – 2 ( A ) L = 0.24 / 0.64 = 0.38 ; m 1 – 2 ( A ) M = ( 0.12 + 0.06 + 0.04 ) / 0.64 = 0.34 ; m 1 – 2 ( A ) H = 0.0 ; m 1 – 2 ( A ) L , M = 0.12 / 0.64 = 0.19 ; m 1 – 2 ( A ) L , H = 0.0 ; m 1 – 2 ( A ) M , H = 0.02 / 0.64 = 0.03 ; m 1 – 2 ( A ) Θ = 0.04 / 0.64 = 0.06 Similarly, belief and plausibility functions and belief interval can be determined by using corresponding equation described earlier. Subsets m1–2(A) bel1–2(A) pl1–2(A) U1–2(A) ϕ 0.0 0.0 1.0 [0.0, 1.0] {L} 0.38 0.38 0.63 [0.38, 0.63] {M} 0.34 0.34 0.62 [0.34, 0.62] {H} 0.0 0.0 0.09 [0.0, 0.09] {L, M} 0.19 0.91 1.0 [0.91, 1.0] {L, H} 0.0 0.38 0.66 [0.38, 0.66] {M, H} 0.03 0.34 0.62 [0.34, 0.62] Θ 0.06 1.0 1.0 [1.0, 1.0] From the above analysis it can be noticed that based on evidence from two samples, the water quality can be rated as low or medium. 2.7. Modified combination rules Serious drawbacks have been identified in D–S rule of combination. Zadeh (1984) presented an intriguing example of a patient who is diagnosed by two physicians A and B. The physician A diagnosed that the patient has a disease x with the 99% probability (confidence) and has only 1% probability of disease y. The physician B diagnosed that the patient has a disease z with the 99% probability and has only 1% probability of disease y. The frame of discernment for the diseases is Θ = {x, y, z}. Using D–S rule of combination, following results will be obtained: Degree of conflict = K = 0.9999 ∴ Normalization factor = 1 - K = 0.0001 m x ( disease ) = 0.0 ; m y ( disease ) = 1.0 ; and m z ( disease ) = 0.0 These results are counterintuitive, as 99.99% evidence was neglected due to conflict. Sentz and Ferson (2002) have provided an excellent review of various methods and techniques to resolve this discrepancy. Most common methods are Yager’s modified Dempster’s rule (1987), Inagaki’s Unified Combination rule (1991), and Zhang’s Center Combination rule (Zhang, 1994). 2.8. Aggregation operators The triangular norms (t-norms) are a class of operators introduced for the development of a probabilistic generalization of the theory of metric spaces (Ramik and Vlach, 2001). The t-norms are used extensively in fuzzy set theory. They provide a tool for defining various types of intersection of fuzzy sets and expressing conjunctive logic. The t-norms, satisfy the axioms of commutativity, associativity, monotonicity, and boundary condition (Ramik and Vlach, 2001). Triangular conorms (t-conorms) provide a tool for defining various types of union of fuzzy sets and expressing conjunctive logic. These operators also satisfy all the axioms of commutativity, associativity, monotonicity, and boundary condition (Ramik and Vlach, 2001). The t-norms and t-conorms provide a range of operations for the aggregation of fuzzy sets (and probability theory). Aggregation or fusion is done through satisfying several or few criteria (performance indicators). When the requirement is such that all (or several) criteria have to be met, t-norms (and-type operators) are typically used; but when the requirement is such that only few criteria have to be met (out of many), t-conorms (or-type operators) are typically used. Consequently, on the scale of strictness of criteria, the t-norms represent the more strict criteria because being intersection-based they require conjunction (and-type operator) of aggregation, while the t-conorms represent more relaxed criteria, as being union-based they require disjunction (or-type operator) of aggregation (Sentz and Ferson, 2002). Fig. 1 illustrates the entire range of aggregation operators from very strict to very relaxed. Note that t-norms and t-conorms are only two classes out of an entire range of aggregation operations. Average-type (e.g., arithmetic mean, ordered weighted average (OWA) operators) or compromising/compensatory operators lie in between two extremes. Download : Download full-size image Fig. 1. Aggregation operators (after Larsen, 2002). 2.9. Disjunctive operator for Dempster–Shafer rule Traditional D–S rule of combination does not all allow to fuse the information from completely conflicting sources because the normalization factor (1 − K) becomes zero in Eq. (7). Yager (2004) addressed this issue and proposed the use of disjunctive operators. Eq. (9) can be modified as (10) m 1 – 2 ( A ) = ∑ B ∩ C = A max [ m 1 ( B ) , m 2 ( C ) ] ∑ B ∩ C ≠ ϕ max [ m 1 ( B ) , m 2 ( C ) ] Other disjunctive operators (see Fig. 1) than “max” can also be used in Eq. (10). In the physician–patient example discussed by Zadeh (1984), the new diagnosis will be mx(disease) = 0.497, my(disease) = 0.005, and mz(disease) = 0.497. Example 1 (Contd.): The disjunctive (maximum) operator (Eq. (10)) is used in modified combination rule. After estimating the basic probability assignments, the belief and plausibility functions are determined as described before in Eqs. (2), (4), respectively. Subsets m1–2(A) bel1–2(A) pl1–2(A) U1–2(A) ϕ 0.0 0.0 1.0 [0.0, 1.0] {L} 0.35 0.35 0.53 [0.35, 0.53] {M} 0.28 0.28 0.50 [0.28, 0.50] {H} 0.10 0.10 0.28 [0.10, 0.28] {L, M} 0.09 0.72 0.90 [0.72, 0.90] {L, H} 0.05 0.50 0.72 [0.50, 0.72] {M, H} 0.09 0.47 0.65 [0.47, 0.65] Θ 0.04 1.00 1.00 [1.0, 1.0] From the above analysis it can be noticed that based on evidence from two samples, the water quality can be rated as low or medium. 2.10. Combining sources of varying credibility The approaches described before implicitly assume that all sources of information are equally credible. Sampling locations for monitoring water quality may be representative of a part of water distribution system, e.g., if one sample is collected from main distribution line and the other is collected from a minor line, the influence zones of both samples are different. Similarly, if the samples are collected at the same point when two different flow conditions prevail, the evidence of water quality also needs to be adjusted based on flow conditions. Similarly, if water utility staff with different levels of expertise collects water samples, the observations need to be adjusted based on their credibility. Yager (2004) discussed the credibility issue in detail and suggested a credibility transformation function. This approach discounts the evidence with a credibility factor (α) and distributes remaining evidence (1 − α) equally among elements (n) of frame of discernment. (11) m ( A ) a = m ( A ) • α + 1 - α n where α is the Credibility factor and n is the focal elements in frame of discernment. Example 1 (Contd.): Assume that credibility adjustment factors assigned to two samples collected at different locations in the distribution are αB = 1.0 and αC = 0.5. These factors represent the confidence of the collected information. The modified evidences will be m1(B)L = 0.6 m2(C)M = 0.36 m1(B)L,M = 0.3 and m2(C)M,H = 0.1 m1(B)Θ = 0.1 m2(C)L = 0.17 m2(C)H = 0.17 and m2(C)Θ = 0.2 As credibility of first evidence is 100%, therefore no adjustment is required for m1(B), but evidence m2(C) is only 50% credible, the evidence is adjusted as below: m 2 ( C ) M = 0.4 • 0.5 + ( 1 - 0.5 ) / 3 = 0.36 m 2 ( C ) L = 0.0 • 0.5 + ( 1 - 0.5 ) / 3 = 0.17 m 2 ( C ) H = 0.0 • 0.5 + ( 1 - 0.5 ) / 3 = 0.17 m 2 ( C ) M , H = 0.2 • 0.5 = 0.1 m 2 ( C ) Θ = 0.4 • 0.5 = 0.2 It is important to note that as α → 0 (i.e., confidence for given evidence), the inference tends to become Baysian, i.e., Principle of Insufficient Reason is applied. A limiting case for evidence is m2(C)Θ = 1.0, i.e., complete ignorance in D–S framework. If the credibility factor α = 0, the adjusted evidence will become m 2 ( C ) L = 0 • 0 + ( 1 - 0 ) / 3 = 0.33 , similarly m 2 ( C ) M = 0.33 and m 2 ( C ) H = 0.33 The adjusted evidences can be combined using modified D–S rule of combination as described earlier. Subsets m1–2(A)a bel1–2(A)a pl1–2(A)a U1–2(A)a ϕ 0.0 0.0 1.0 [0.0, 1.0] {L} 0.42 0.42 0.61 [0.42, 0.61] {M} 0.26 0.26 0.42 [0.26, 0.42] {H} 0.13 0.13 0.24 [0.13, 0.24] {L, M} 0.08 0.76 0.87 [0.76, 0.87] {L, H} 0.03 0.58 0.74 [0.58, 0.74] {M, H} 0.05 0.44 0.58 [0.44, 0.58] Θ 0.03 1.00 1.00 [1.0, 1.0] As noticed from the above analysis that belief of water quality being low is the highest among other Condition States (medium and high), therefore based on the available information the utility manager (or decision-maker) may conclude that water quality in the distribution is acceptable. But if the utility manager wants to be more confident about his judgement, he (she) will conclude that water quality is low or medium because the belief of subset {L, M} is 76%. In the above example, we allowed a subset {L, H}, that does not contain two contiguous states. But in reality, generally only two contiguous states are possible, i.e., in our case {L, M} or {M, H}. If the decision-maker wants to increase the confidence for his (her) judgement concerning water quality Condition State he (she) will collect more sample (evidence). In this way he (she) can narrow down the uncertainty and increase the confidence in his (her) judgment. 3. Dempster–Shafer theory application for developing water quality index Water quality is generally defined by a collection of upper and lower limits on selected possible contaminants (Maier, 1999). Water quality indicators can be classified into three broad categories: physical, chemical, and microbiological contaminants. Within each class, a number of quality indicators are considered. The acceptability of water quality for its intended use depends on the magnitude of these indicators (Swamee and Tyagi, 2000) and is often governed by regulations (US EPA, 2001). The physical, chemical, and microbiological processes occurring in drinking water distribution pipes are numerous and complex. A wealth of literature is available on water quality represented by an aggregate index using various statistical and mathematical techniques. Swamee and Tyagi (2000) have discussed in detail the pros and cons of different techniques and approaches available for evaluating the overall water quality index (WQI). Sinha et al. (1994) combined pH, chloride concentration, turbidity, residual chlorine, conductivity, and MPN (most probable number––a bacterial counting technique) into a single water quality index through a weighting technique to represent an overall water quality at various nodes in the distribution system. Sadiq et al. (2004) have suggested a fuzzy-based framework for aggregative risk analysis of water quality failure in the distribution system. Recently, Sadiq and Rodriguez (2004a) proposed a risk-based fuzzy synthetic evaluation technique for aggregating effects of disinfection byproducts found in drinking water. The WQI is a systematic way of interpreting measurements and (or) observations of water quality, which helps managers to describe a Condition State or to share and communicate with the public in a consistent manner. The WQI provides a general means of comparing and ranking water quality. Traditionally, WQI encompasses factors like number of indicators not meeting the regulation, frequency of a particular indicator by which it is not meeting the requirement in a given sampling protocol, and amount by which indicators are violating the regulatory requirements. These three factors are combined to form the WQI, which can be interpreted by predefined qualitative ranking system. For overall water quality based on various indicators, credibility adjustment is required for each indicator for its contribution. For example, if the water quality is defined by turbidity, total coliforms, residual chlorine, and aesthetic indicators (taste, odour, colour), the violation of turbidity from its threshold value has lesser consequences and impacts with respect to microbial violations. Different credibility weights need to be defined for each indicator representing its body of evidence in defining overall water quality. Another useful application of D–S rule of combination is to develop a WQI that integrates various water quality indicators (of noncommensurate units) as a single entity. Example 2 will illustrate such application for the case of aggregation of three important physico-chemical and microbiological indicators of water quality in the distribution system. Example 2 The application of disinfection agents in drinking water reduces the microbial risk but poses chemical risk in the form of their byproducts. A risk–risk trade-off is required to optimize the dose and type of disinfection practices. Three water quality indicators––trihalomethanes (THMs), residual chlorine (RC), and heterotrophic plate counts (HPCs) (indicator for microbial presence)––are identified for evaluating the overall water quality in the distribution system. The water quality is defined by five risk classes––very low (VL), low (L), medium (M), high (H), and very high (VH). Therefore, the frame of discernment is Θ = {VL, L, M, H, VH}. These water quality indicators are defined by these five classes of risk (Fig. 2). The thresholds shown in Fig. 2 for Example 2 were established based on water quality standards and based on authors’ experience with the water quality in Canadian distribution systems. Download : Download full-size image Fig. 2. Basic probability assignments for water quality indicators.  • The bpa for a given water quality indicator is determined by mapping on corresponding triangular functions as shown in Fig. 2. The qualitative scale is defined in such a way that bpa for only two risk classes are obtained. Therefore, for any value of water quality indicator, maximum two focal elements are possible. In this setting, subsets with two or more elements are not allowed. For a water quality indicator, bpa is represented by a 5-tuple set {VL, L, M, H, VH}. • For a given water sample, the bpa for three indicators are represented as follow: m(RC)VL m(HPC)VL m(THM)VL m(RC)L m(HPC)L m(THM)L m(RC)M m(HPC)M m(THM)M m(RC)H m(HPC)H m(THM)H m(RC)VH m(HPC)VH m(THM)VH • The credibility factors α are assigned to these indicators based on expert judgement α RC = 0.9 α HPC = 0.5 α THM = 0.8 • The bpa for each water quality indicator is adjusted by credibility factors α using Eq. (11). The adjusted bpa for water quality indicators are aggregated using modified disjunctive operator D–S rule of combination. • The belief and plausibility functions and belief interval are determined.  Example 2 (Contd.): A water sample was collected from distribution system and tested for residual chlorine, THMs, and HPCs. RC = 0.09 mg / l ; HPC = 62 / 100 ml ; and THM = 118 ppb The bpa for each water quality indicator is derived from Fig. 2 m(RC)VL = 0.0 m(HPC)VL = 0.0 m(THM)VL = 0.0 m(RC)L = 0.0 m(HPC)L = 0.48 m(THM)L = 0.0 m(RC)M = 0.0 m(HPC)M = 0.52 m(THM)M = 0.0 m(RC)H = 0.87 m(HPC)H = 0.0 m(THM)H = 0.0 m(RC)VH = 0.13 m(HPC)VH = 0.0 m(THM)VH = 1.0 The bpa is adjusted with respect to their credibility factors. The evidence is modified to m(RC)VL = 0.02 m(HPC)VL = 0.10 m(THM)VL = 0.04 m(RC)L = 0.02 m(HPC)L = 0.34 m(THM)L = 0.04 m(RC)M = 0.02 m(HPC)M = 0.36 m(THM)M = 0.04 m(RC)H = 0.80 m(HPC)H = 0.10 m(THM)H = 0.04 m(RC)VH = 0.14 m(HPC)VH = 0.10 m(THM)VH = 0.84 The adjusted bpa for water quality indicators can be aggregated using disjunctive operator D–S rule of combination. bpa Belief Plausibility m(WQ)VL = 0.04 bl(WQ)VL = 0.04 pl(WQ)VL = 0.04 m(WQ)L = 0.14 bl(WQ)L = 0.14 pl(WQ)L = 0.14 m(WQ)M = 0.15 bl(WQ)M = 0.15 pl(WQ)M = 0.15 m(WQ)H = 0.33 bl(WQ)H = 0.33 pl(WQ)H = 0.33 m(WQ)VH = 0.34 bl(WQ)VH = 0.34 pl(WQ)VH = 0.34 The probability mass function of risk can be plotted using belief function. The universe of discourse of risk scale is soft in nature (Fig. 3). Download : Download full-size image Fig. 3. Probability mass function of risk. Utility values can be assigned to soft items to determine the water quality index as a crisp output. Yang and Xu (2002) discussed a probabilistic method to determine the utility values for soft items in a heuristic way. These values can also be determined through linear optimization based on expert judgement. Here, an arbitrary linear function is proposed to estimate the crisp WQI (a surrogate for representing risk) and all five classes of risk are assigned utility values as follow: (12) WQI = u 2 0 [ bl ( WQ ) VH ] + u 2 1 [ bl ( WQ ) H ] + u 2 2 [ bl ( WQ ) M ] + u 2 3 [ bl ( WQ ) L ] + u 2 4 [ bl ( WQ ) VL ] where utility coefficient u is assumed ≈1.3. New regulations for the allowable concentrations of disinfection byproducts are being developed in the US and elsewhere for drinking water supplies. Disinfection reduces the risk from microbial infections, but may pose cancer and other risks from the DBPs (THMs are the most commonly identified DBPs). Many other DBPs, however, remain to be identified and the public health significance of these is unknown. Society is facing a difficult trade-off between established (known) microbial risks due to pathogens and more uncertain (unknown) risks from DBPs. In the case of evaluating the risk–risk trade-offs in drinking water, the competing risks must be assessed within a common framework. Example 2 (Contd.): The risk–risk trade-off for HPCs (a microbial indicator) and THMs (representative DBP) is established at different levels of residual chlorine concentration in Fig. 4a–d. The WQI is used as a surrogate for risk, estimated using Eq. (12). Download : Download full-size image Fig. 4. Water quality index (WQI) representing risk profiles at various residual chlorine levels. The analysis is performed for 0, 0.2, 0.5, and 4 mg/l residual chlorine concentrations. When levels of residual chlorine are not detectable, the WQI varied approximately from 0.6 to 1.0. Higher risks were observed for even very low HPC and THM concentrations (Fig. 4a), because the minimal levels of residual chlorine are necessary to provide safeguard against microbial contamination. But when the residual concentration is increased to 0.2, 0.5, and 4.0 mg/l, the WQI varied from 0.2 to approximately 0.8 (Fig. 4b–d), which is comparatively lower than the first case. The three-dimensional characteristic risk curves (e.g. Fig. 4) can be established for various water quality indicators, which are able to predict levels of any particular indicator (e.g., HPCs) that are required to achieve acceptable risk under given conditions. For example, for an acceptable risk (WQI) of 0.25, the residual chlorine in the distribution system is reported to be in the range of 0.2–0.5 mg/l and THM potential is estimated (using regression or kinetic models, see Sadiq and Rodriguez, 2004b) to be in the range of 25–50 ppb, and the HPC levels should not exceed 200/100 ml. This concept can be extended to more water quality indicators. 4. Summary and conclusions In this paper, the evidence theory was introduced as an innovative methodology that can be used for simplifying and improving the understanding of data generated through routine water quality monitoring in distribution systems. Two examples were presented that support the potential application of theory of evidence for data fusion, namely, interpretation of overall water quality in the distribution system based on spatial data collected at different sampling locations and development of WQI. For the first example, additional aspects should be investigated in the future, such as the impact of the uncertainty on the confidence of the decision-maker’s judgement (according to the amount of information available, in this case the number and the frequency of spatial distribution of samples collected). For the second example, additional information should be considered in the future to develop more robust indices, i.e., additional water quality indicators (e.g., pathogenic indicators such as coliforms and other disinfection byproducts like haloacetic acids), operational parameters (e.g., pressures, flow rates, reservoir level control, etc.), and data on the distribution system infrastructure (e.g., pipe breakage rate and replacement, pipe flushing etc.). Theory of evidence can efficiently deal with the difficulties related to host of indicators describing water quality, with spatial and temporal dimensions of distribution system, where redundancy of information is routinely observed as well as the credibility of available data is varied. Future research must focus on the implementation of decision-making tools using theory of evidence that can be adapted to specific water utility conditions and manager’s needs. The potential combination of theory of evidence with modeling techniques, such as linear and nonlinear time-series analysis, neural networks, and genetic algorithms, to predict the condition state of water quality must also be evaluated through future research efforts to implement more powerful decision-making tools. References Alim, 1988 S. Alim Application of Dempster–Shafer theory for interpretation of seismic parameters ASCE Journal of Structural Engineering, 114 (9) (1988), pp. 2070-2084 View in ScopusGoogle Scholar APHA, AWWA, WPCF, 1995 APHA, AWWA, WPCF Standard Methods for the Examination of Water and Wastewater (19th ed.), APHA, AWWA, WPCF, Washington, DC (1995) Google Scholar Attoh-Okine and Gibbons, 2001 N.O. Attoh-Okine, J. Gibbons Use of belief function in brownfield infrastructure redevelopment decision making ASCE Journal of Urban Planning and Development, 127 (3) (2001), pp. 126-143 View in ScopusGoogle Scholar Binaghi et al., 1998 E. Binaghi, L. Luzi, P. Madella, F. Pergalani, A. Rampini Slope instability zonation: a comparison between certainty factor and fuzzy Dempster–Shafer approaches Natural Hazards, 17 (1998), pp. 77-97 View in ScopusGoogle Scholar Boyd et al., 1993 Boyd, M., Walley, W.J., Hawkes, H.A., 1993. Dempster–Shafer reasoning for the biological surveillance of river water quality. In: Water Pollution 93, Milan, Italy Google Scholar Chang and Wright, 1996 Y.C. Chang, J.R. Wright Evidential reasoning for assessing environmental impact Civil Engineering Systems, 14 (1) (1996), pp. 55-77 CrossRefView in ScopusGoogle Scholar Clark, 1994 R.M. Clark Modelling water quality changes and contaminant propagation in drinking water distribution systems: a US perspective Journal Water SRT-Aqua, 43 (3) (1994), pp. 133-143 View in ScopusGoogle Scholar Coulibaly and Rodriguez, 2003 H. Coulibaly, M.J. Rodriguez Spatial and temporal variation of drinking water quality in ten Quebec small utilities Journal of Environmental Engineering & Science, 2 (1) (2003), pp. 47-61 View in ScopusGoogle Scholar Dempster, 1968 A. Dempster A generalisation of Bayesian inference Journal of Royal Statistical Society, Series B, 30 (1968), pp. 205-247 View in ScopusGoogle Scholar Hunsinger and Zioglio, 2002 R.B. Hunsinger, G. Zioglio Rationale for online monitoring E. Hargesheimer, O. Conio, J. Popovicova (Eds.), Online Monitoring for Drinking Water Utilities Co-operative Research Report, American Water Works Association Research Foundation, CO (2002) Google Scholar Inagaki, 1991 T. Inagaki Interdependence between safety-control policy and multiple sensor scheme via Dempster–Shafer theory IEEE Transactions on Reliability, 40 (2) (1991), pp. 182-188 View in ScopusGoogle Scholar Klir, 1995 J.G. Klir Principles of uncertainty: what are they? why do we need them? Fuzzy Sets and Systems, 74 (1995), pp. 15-31 View in ScopusGoogle Scholar Larsen, 2002 Larsen, H.L., 2002. Fundamentals of fuzzy sets and fuzzy logic. Available from <http://www.cs.aue.auc.dk/~legind/FL%20E2002/FL-01/FL-01%20Introduction.pdf> Google Scholar LeChevallier et al., 1996 M.W. LeChevallier, N.J. Welch, D.B. Smith Full-scale studies of factors related to coliform regrowth in drinking water Applied Environmental Microbiology, 62 (7) (1996), pp. 2201-2211 CrossRefView in ScopusGoogle Scholar Luo and Caselton, 1997 W.B. Luo, B. Caselton Using Dempster–Shafer theory to represent climate change uncertainties Journal of Environmental Management, 49 (1) (1997), pp. 73-93 View PDFView articleView in ScopusGoogle Scholar Maier, 1999 Maier, S.H., 1999. Modeling Water Quality for Water Distribution Systems. Ph.D. thesis, Brunel University, Uxbridge Google Scholar Ramik and Vlach, 2001 J. Ramik, M. Vlach Generalized Concavity in Fuzzy Optimization and Decision Analysis Kluwer Academic Publishers, Boston (2001) Google Scholar Roemer et al., 2001 Roemer, M.J., Kacprzynski, G.J., Scholler, M.H., 2001. Improved diagnostic and prognostic assessments using health management information fusion. In: 2001 IEEE, pp. 365–377 Google Scholar Sadiq and Rodriguez, 2004a R. Sadiq, M.J. Rodriguez Fuzzy synthetic evaluation of disinfection by-products––a risk-based indexing system Journal of Environmental Management, 73 (1) (2004), pp. 1-13 View PDFView articleView in ScopusGoogle Scholar Sadiq and Rodriguez, 2004b R. Sadiq, M.J. Rodriguez Disinfection by-products (DBPs) in drinking water and the predictive models for their occurrence: a review The Science of the Total Environment, 321 (1–3) (2004), pp. 21-46 View PDFView articleView in ScopusGoogle Scholar Sadiq et al., 2004 R. Sadiq, Y. Kleiner, B.B. Rajani Aggregative risk analysis for water quality failure in distribution networks AQUA––Journal of Water Supply: Research & Technology, 53 (4) (2004), pp. 241-261 View in ScopusGoogle Scholar Sentz and Ferson, 2002 Sentz, K., Ferson, S., 2002. Combination of evidence in Dempster–Shafer theory, SAND 2002-0835 Google Scholar Shafer, 1976 G. Shafer A Mathematical Theory of Evidence Princeton University Press, Princeton, NJ (1976) Google Scholar Sinha et al., 1994 R. Sinha, P. Gupta, P.K. Jain Water quality modeling of a city water distribution system Indian Journal of Environmental Health, 36 (4) (1994), pp. 258-262 View in ScopusGoogle Scholar Swamee and Tyagi, 2000 P.K. Swamee, A. Tyagi Describing water quality with aggregate index ASCE Journal of Environmental Engineering, 126 (5) (2000), pp. 451-455 View in ScopusGoogle Scholar Tanaka and Klir, 1999 K. Tanaka, G.J. Klir Design condition for incorporating human judgement into monitoring systems Reliability Engineering and System Safety, 65 (1999), pp. 251-258 View PDFView articleView in ScopusGoogle Scholar US EPA, 2001 US EPA, 2001. National primary drinking water standards. United States Environmental Protection Agency, EPA 816-F-01-007 Google Scholar Wang and Civco, 1994 Y. Wang, D.L. Civco Evidential reasoning-based classification of multi-source spatial data for improved land cover mapping Canadian Journal of Remote Sensing, 20 (1994), pp. 381-395 CrossRefView in ScopusGoogle Scholar Yager, 1987 R.R. Yager On the Dempster–Shafer framework and new combination rules Information Sciences, 41 (1987), pp. 93-137 View PDFView articleView in ScopusGoogle Scholar Yager, 2004 R.R. Yager On the determination of strength of belief for decision support under uncertainty––Part II: fusing strengths of belief Fuzzy Sets and Systems, 142 (2004), pp. 129-142 View PDFView articleView in ScopusGoogle Scholar Yang and Xu, 2002 J.-B. Yang, D.-L. Xu On the evidential reasoning algorithm of multiple attribute decision analysis under uncertainty IEEE Transactions on Systems Man and Cybernetics––Part A: Systems and Humans, 32 (3) (2002), pp. 289-304 View in ScopusGoogle Scholar Zadeh, 1984 L.A. Zadeh Review of books: a mathematical theory of evidence The AI Magazine, 5 (3) (1984), pp. 81-83 Google Scholar Zhang, 1994 L. Zhang Representation independence and combination of evidence in the Dempster–Shafer theory R.R. Yager, J. Kacprzyk, M. Fedrizzi (Eds.), Advances in Dempster–Shafer Theory of Evidence, John Wiley and Sons, NY (1994), pp. 51-69 CrossRefGoogle Scholar Cited by (34) Overall reliability assessment of water distribution system 2014, Procedia Engineering Show abstract Application of data fusion in human health risk assessment for hydrocarbon mixtures on contaminated sites 2013, Toxicology Show abstract Research and design of distributed fault diagnosis system in nuclear power plant 2013, Progress in Nuclear Energy Citation Excerpt : Misdiagnosis should be allowed in the pre-diagnosis result while missing diagnosis should be completely avoided. If the pre-diagnosis result from FNN has weak reliability, from the view point of system, we can take global diagnosis which applied data fusion diagnosis method, and the data fusion method is based on Dempster–Shafer (D-S) evidence theory (Bahador et al., 2013; Rehan et al., 2005; Belur, 1994). In this way, the NPP operation status can be better evaluated as a whole, thus reducing misdiagnosis or eliminating it thoroughly. Show abstract Empirical Models to Predict Disinfection By-products (DBPs) in Drinking Water 2011, Encyclopedia of Environmental Health Show abstract Water quality indicators: Comparison of a probabilistic index and a general quality index. The case of the Confederación Hidrográfica del Júcar (Spain) 2010, Ecological Indicators Show abstract Chemometrics based on fuzzy logic principles in environmental studies 2007, Talanta Show abstract View all citing articles on Scopus View Abstract Crown copyright © 2004 Published by Elsevier Ltd. All rights reserved. Recommended articles Non-invasive assessment of liver fibrosis by magnetic resonance elastography in patients with congenital heart disease undergoing the Fontan procedure and intracardiac repair Journal of Cardiology, Volume 68, Issue 3, 2016, pp. 202-208 Masaya Sugimoto, …, Hiroshi Azuma View PDF A biofilm model for assessing perchlorate reduction in a methane-based membrane biofilm reactor Chemical Engineering Journal, Volume 327, 2017, pp. 555-563 Jing Sun, …, Bing-Jie Ni View PDF Radiation induced cardiovascular disease: An odyssey of bedside-bench-bedside approach Life Sciences in Space Research, Volume 27, 2020, pp. 49-55 Rishi Rikhi, …, Rohit Moudgil View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 33 Captures Readers: 37 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply.

Paper 2:
- APA Citation: 
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: 
  Extract 2: 
  Limitations: >
  Relevance Evaluation: Very relevant - This excerpt provides a concise summary of the purpose and goals of the systematic review on automated irrigation management systems, which aligns with the outline point mentioned in the review intention section.
  Relevance Score: 1.0
  Inline Citation: >
  Explanation: The purpose and intention of this systematic review on automated systems for real-time irrigation management can be interpreted as follows:

1. Identification of the current state and future potential of end-to-end automated irrigation management systems that integrate IoT, machine learning, and other relevant technologies.
2. Evaluation of the current performance and future improvement opportunities of automated irrigation management systems in terms of efficiency, accuracy, and scalability.
3. Investigation of the effectiveness and efficiency of different integrated end-to-end automated irrigation management system architectures.
4. Provision of a comprehensive and critical evaluation of the current state and future potential of automated irrigation management systems, along with recommendations for future research and development.

 Full Text: >
Sensor data quality: a systematic review
Hui Yie Teh1, Andreas W. Kempa‑Liehr2,3*  and Kevin I‑Kai Wang1
Introduction
With the emergence of the Internet of Things (IoT) and wireless sensor networks 
(WSNs), sensor devices are deployed across the globe in a variety of fields such as 
healthcare, industry, agriculture, home, and transport [1]. Recently, Cisco [2] estimated 
that there would be approximately 850 zettabytes (1 zettabyte is 1021 bytes) of data gen-
erated from devices. An IoT application may have hundreds or thousands of sensors 
which produces vast amounts of data, but the data is rendered useless if it is riddled 
with errors as poor sensor data quality caused by the errors may lead to wrong deci-
sion-making results. In this paper, the term sensor refers to a physical sensor [3, Chap 3], 
which measures the changes in physical quantity e.g. temperature, humidity, and light 
Abstract 
Sensor data quality plays a vital role in Internet of Things (IoT) applications as they are 
rendered useless if the data quality is bad. This systematic review aims to provide an 
introduction and guide for researchers who are interested in quality‑related issues of 
physical sensor data. The process and results of the systematic review are presented 
which aims to answer the following research questions: what are the different types of 
physical sensor data errors, how to quantify or detect those errors, how to correct them 
and what domains are the solutions in. Out of 6970 literatures obtained from three 
databases (ACM Digital Library, IEEE Xplore and ScienceDirect) using the search string 
refined via topic modelling, 57 publications were selected and examined. Results show 
that the different types of sensor data errors addressed by those papers are mostly 
missing data and faults e.g. outliers, bias and drift. The most common solutions for 
error detection are based on principal component analysis (PCA) and artificial neural 
network (ANN) which accounts for about 40% of all error detection papers found in the 
study. Similarly, for fault correction, PCA and ANN are among the most common, along 
with Bayesian Networks. Missing values on the other hand, are mostly imputed using 
Association Rule Mining. Other techniques include hybrid solutions that combine 
several data science methods to detect and correct the errors. Through this systematic 
review, it is found that the methods proposed to solve physical sensor data errors can‑
not be directly compared due to the non‑uniform evaluation process and the high use 
of non‑publicly available datasets. Bayesian data analysis done on the 57 selected pub‑
lications also suggests that publications using publicly available datasets for method 
evaluation have higher citation rates.
Keywords: Systematic review, Sensor data quality, Sensor data error detection, Sensor 
data error correction, Datasets
Open Access
© The Author(s) 2020. This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, 
adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and 
the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material 
in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material 
is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the 
permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creat iveco 
mmons .org/licen ses/by/4.0/.
SURVEY PAPER
Teh et al. J Big Data            (2020) 7:11  
https://doi.org/10.1186/s40537-020-0285-1
*Correspondence:   
kempa‑liehr@fmf.
uni‑freiburg.de 
2 Freiburg Materials Research 
Center, University of Freiburg, 
Freiburg, Germany
Full list of author information 
is available at the end of the 
article
Page 2 of 49
Teh et al. J Big Data            (2020) 7:11 
intensity of the sample or surroundings. Furthermore, the term error relates to the soft 
faults that occur in sensor data found commonly in the systematic review such as outli-
ers, bias, drifts, missing values, and uncertainty, which should be detected or quantified 
and removed or corrected in order to improve sensor data quality.
This is slightly different from the data quality (DQ) dimensions introduced by Wang 
and Strong [4], which categorize the quality of data in databases or high-level application 
architecture (Application Layer in Fig. 1) that are important to data consumers. They are 
mostly used to describe data in enterprise-level systems and are used for modelling how 
data errors propagate to the consumer’s end. Therefore, apart from incomplete (miss-
ing data) and inaccurate data (uncertainty), which are sensor data quality-related issues, 
other DQ dimensions such as inconsistent data and timeliness are not considered in this 
review paper as they are more specific to the topics of database design or communica-
tion data quality. A survey related to DQ dimensions is presented in the works of Kark-
ouch et al. [5].
Figure 1 shows an overview of the data flow of a typical IoT application. A physical sen-
sor such as a temperature or humidity sensor measures and collects readings (changes 
in the observed property) in the Perception layer. The readings are then transmitted 
through the Network layer, which determines the routes to send the sensor data and is 
implemented using wireless technologies such as WiFi, 2G/3G/4G, Bluetooth, and LoRa. 
Next, the Application layer receives data from the network layer and it is where the data 
processing, predictive analytics  [6], and storage takes place. The application layer is 
designed and implemented using big data architectures such as Apache Hadoop, Spark, 
or Kafka. The added complexity of the architecture causes new errors to be potentially 
introduced in each layer. For example, in the Network Layer, poor data quality arises 
from congested and unstable wireless communication links in sensor networks which 
causes data loss and corruption [7]. In the Perception Layer, damage or exhaustion of 
battery in sensor devices also causes data quality to degrade, as towards the end of its 
battery life, sensors tend to produce unstable readings [8]. The hostile environment in 
which in-situ sensors are deployed also plays a big part in the quality of the transmitted 
data. For example, sensors for temperature, light, or humidity measurements are often 
placed outdoors and are subjected to extreme local weather conditions such as strong 
winds and snow, which might affect the operation of the sensor.
Fig. 1 IoT architecture. A high‑level view of a typical IoT architecture which shows the data flow
Page 3 of 49
Teh et al. J Big Data            (2020) 7:11 
 
Although the factors that cause errors and affect sensor data quality are known, sim-
ple strategies to overcome data quality problems, such as using industry grade sensors, 
which are more accurate, stable and robust, are not feasible for applications that require 
the deployment of large and dense sensors networks, which is the case for many IoT 
applications. For example, in horticulture, sensors need to be deployed such that they 
have high coverage and accuracy through large and dense sensor networks. Having to 
deploy many highly accurate but expensive sensors will incur higher deployment costs. 
Therefore, most IoT applications use low-cost sensors, though at the expense of data 
quality. The use of both industry grade or low-cost sensors also results in high time and 
maintenance cost as experts would have to go out to the field themselves to test and 
calibrate the entire network of in-situ sensors to ensure data quality. Other than that, 
re-transmitting the data when experiencing data quality errors (e.g. missing data) also 
does not work well in an IoT application. This is because the nodes in the network are 
powered on limited battery and memory which makes it expensive in terms of power 
and computational resources to resend the missing data across the network, especially 
if there is a big load of data to re-transmit. Retransmission also delays decision-making 
which in turn may lead to inaccurate results [9].
Other than that, though studies in previous years tend to focus on high-level solutions 
in the Application Layer for solving data quality issues [4, 10], it is not possible nowadays 
due to the separation of the layers and complexity of the architecture. The advance of 
Big Data where the sheer volume of data hinders the transport to the central system [1] 
also encourages edge computing, or a decentralized solution, where the processing of 
data quality is done in the Perception Layer i.e. in the sensor devices themselves and only 
data with good quality is passed to the central server. Since sensor data errors may be 
present and propagated in all layers, this review paper focuses on algorithms that solves 
the fundamental issue of sensor data quality by detecting and correcting those errors 
regardless of the IoT (or big data) architecture and layers. As such, the high-level design 
and decision of the IoT architecture is not discussed in this paper, however, it is available 
in [5, 11–13].
Therefore, the purpose of this systematic review paper is to investigate the different 
types of sensor data errors which contribute to the degradation of sensor data quality 
and the existing solutions to detect and correct those errors which can be applied in any 
layer of the IoT architecture. The different domains the solutions are presented in and 
the datasets used for evaluation are also studied. This systematic review acts as an intro-
duction for new researchers to the field of sensor data quality or as a guide for research-
ers who are interested in the techniques used to solve problems related to the sensor 
data quality topic. In short, a systematic review is a rigorous and structured way of con-
ducting a literature review which allows it to be reproducible. It also helps researchers 
identify knowledge gaps in the area of interest by extracting and analysing existing solu-
tions. Other review papers about sensor data quality are present, such as the works of 
Li et al. [14] and Prathiba et al. [15]. However, those review papers do not mention the 
methods used with respect to the different type of sensor errors and are not systematic 
reviews.
This systematic review also focuses on stationary wireless sensor networks. This 
is because many of the mobile sensor network problems are related to network 
Page 4 of 49
Teh et al. J Big Data            (2020) 7:11 
connectivity issues rather than sensor data quality. The field of imaging has also been 
excluded as it is found that the methods used to improve image data quality varies sig-
nificantly compared to other physical sensor data. The remainder of this paper is organ-
ized as follows: “Research methodology” section describes the methodology used in the 
systematic review and the results from the review are provided in “Results” section. A 
discussion about the challenges found in the research area is presented in “Discussion” 
section. Lastly, “Conclusion” section concludes the study.
Research methodology
A systematic review is a standardized way of extracting and synthesizing information 
available from existing primary studies with respect to a set of defined research ques-
tions. It helps researchers focus on the topic at hand and to identify knowledge gaps in 
a research area. It is frequently used in the field of medicine and though not as common 
in the field of computer science [16], a systematic review is still applicable and beneficial 
in terms of providing a formal way of conducting a computer science-related literature 
review.
The systematic review in this paper follows the guidelines of Kofod-Petersen [16] and 
Silva and Neiva [17] for conducting a systematic review in computer science-related 
fields. It is also done in accordance with the PRISMA [18] (Preferred Reporting Items 
for Systematic Reviews and Meta-Analyses) checklist which is an “evidence-based 
minimum set of items for reporting in systematic reviews and meta-analyses”. Since the 
PRISMA checklist is constructed mostly for medical review literature, some of the items 
such as the meta-analyses criteria are not considered in this review paper.
The systematic review process is broken down to several steps, starting with the defi-
nition of research questions in which this paper aims to answer. Next, the search pro-
cess and strategy are described, which specifies the keywords and search string used to 
find the relevant and available publications literature databases. The search strategy also 
involves a topic modelling step which was carried out to help refine the keywords and 
search string. The inclusion and exclusion criteria, as well as the quality criteria, are then 
defined to assist with the selection of relevant literature. Next, data extraction is carried 
out which extracts data such as the title, abstract and publication year of the literature as 
well as the types of sensor errors addressed, types of methods for detecting or correcting 
errors and the domain from the selected studies after screening which is then synthe-
sized and presented in the next section, “Results”. Finally, the risk of bias or limitations of 
this review process is discussed. The steps for the systematic review and its risk of bias 
are described in detail in the following subsections.
Research questions
The motivation for this systematic review is to provide new researchers an introduc-
tion to the field of sensor data quality and the errors that might occur, or as a guide for 
researchers who are interested in solving sensor data quality related issues. Thus, the fol-
lowing research questions (RQs) are designed in which this paper aims to answer:
• RQ1: What are the different types of errors in sensor data?
• RQ2: How to quantify or detect errors in sensor data?
Page 5 of 49
Teh et al. J Big Data            (2020) 7:11 
 
• RQ3: How to correct the errors in sensor data?
• RQ4: What domains are the different types of methods proposed in?
With RQ1, we are able to investigate the common errors that leads to the degradation 
of sensor data quality in this field. Moreover, RQ2 allows us to find existing solutions to 
quantify or detect the aforementioned errors and RQ3 takes it one step further by find-
ing techniques to correct them. RQ4 on the other hand, gives an insight to how various 
domains use different (or similar) techniques to solve sensor data quality problems and 
the datasets used to evaluate the methods.
Search process
For this review paper, three computer science-related literature databases are used to 
search for relevant literature about sensor data quality. The three databases are:
• ACM Digital Library1
• IEEE Xplore2
• ScienceDirect3
These databases are last searched on the September 27th 2018 and the search results 
are exported into BibTeX format which is then downloaded and stored in the reference 
manager Zotero. 4 For ACM Digital Library, the export function for BibTeX format only 
exports the citation data of the literature, but not the abstracts. Thus, Zotero’s Google 
Chrome plugin is used which allows the citation information, including the abstract, to 
be imported directly into Zotero.
Improving search strategy by topic modelling
At the start of the search process, the keywords defined are “sensor data” and “data qual-
ity” which are used in the initial search string:
The initial search results using query (1) returned 13,057 publications from three data-
bases, ACM Digital Library, IEEE Xplore, and ScienceDirect. In order to check, if this 
initial search query retrieves publications which match the scope of this review, we are 
using a text mining approach from natural language processing known as topic mod-
elling. Topic models are “probabilistic models for uncovering the underlying semantic 
structure of a document collection based on a hierarchical Bayesian analysis of the origi-
nal texts” [19, p. 71]. The idea of the topic modelling step is to identify keywords and 
groups of keywords that describe the content of the initial set of publications returned 
by search query (1). In order to do so, topic modelling via Latent Dirichlet Allocation 
(LDA) [20] is used to find groups of words that are likely to occur together and represent 
(1)
“sensor data′′ AND (quality OR “data quality′′ OR “sensor data quality′′)
1 https ://dl.acm.org.
2 https ://ieeex plore .ieee.org/Xplor e.
3 https ://www.scien cedir ect.com.
4 https ://www.zoter o.org.
Page 6 of 49
Teh et al. J Big Data            (2020) 7:11 
a specific topic. For example, assume that the researcher decides to model three topics, 
named Topic A, B, and C for convenience. After fitting, the LDA model assigns each 
document the probability of it covering a specific topic, e.g. Document 1 has a 20% prob-
ability of being in Topic A, 75% being in Topic B and 5% being in Topic C. The LDA 
learns these topic models by going through each document and cluster words that have a 
high likelihood of term co-occurrence. By analysing the words that describe the cluster, 
the researcher can then interpret the topic for each cluster.
Here, the LDA model is implemented using scikit-learn’s [21] estimator Latent-
DirichletAllocation. For the purpose of this analysis, the title and abstract 
of the publications, which have been identified from search query (1), are used for 
modelling the underlying topics. The visualization of the LDA model with 12 top-
ics obtained from the 13,057 documents (title and abstracts) of search string (1) is 
shown in Fig.  2a with the intertopic distance showing the marginal topic distribu-
tion. Figure 2b–d lists the top 30 most relevant terms for Topic 1, Topic 2 and Topic 
Fig. 2 Topic modelling with LDA. Topic model of 13,057 titles and abstracts found from the search string 1. 
Topic modelling is performed using a LDA model with 12 topics: a intertopic distance showing the marginal 
topic distribution of each topic, b–d top 30 most relevant terms for Topic 1, 2 and 8 respectively, along with 
its estimated term frequencies. Topic 1 and 2 have terms related to sensor and data, but Topic 1 is more 
focused on systems and applications whereas Topic 2 is associated with methods and algorithms. Topic 8 
consists mostly of keywords related to imaging and satellite imaging
Page 7 of 49
Teh et al. J Big Data            (2020) 7:11 
 
8 respectively. Topic 1 and Topic 2 both have top terms related to sensor and data. 
However, Topic 1 seems to be more focused on systems and applications, whereas 
Topic 2 is more related to methods and algorithms. Looking at the top 30 keywords of 
Topic 8, one might classify that topic as “Imaging” or “Satellite Imaging” since words 
such as “image”, “video”, “resolution”, “camera”, “satellite” and “pixel” occur in that 
cluster. Through this topic modelling step, it can be seen that there are a handful of 
papers related to “imaging” in the initial search results. Because imaging is a topic we 
do not want to focus on, we are using the terms of Topic 8 to refine the search string 
and set them to be one of the exclusion criteria in this paper.
Through the topic modelling, we decided that the field of imaging is not to be con-
sidered in this paper as the techniques used for improving image data quality is very 
different compared to other physical sensor data. It is made an exclusion criterion 
(see “Inclusion and exclusion criteria”) and the final search string used to search the 
literature databases is defined as:
However, readers interested in that field of research can look at review papers [22–24] 
that investigates data quality in imaging, e.g. camera captured document images and 
healthcare imaging.
Inclusion and exclusion criteria
The eligibility criteria are criteria used for screening and selecting relevant literature 
from the search results. The eligibility criteria are composed of the inclusion and 
exclusion criteria. As mentioned in “Introduction” section, this systematic review 
focuses on stationary wireless sensor networks as mobile sensor networks tend to 
lean towards network connectivity issues. Moreover, the field of imaging is to be 
excluded as the techniques used for improving data quality for images vary signifi-
cantly from physical sensor data.
Inclusion criteria (IC): 
IC1 
 Papers that involve sensor data,
IC2 
 Papers that mainly focus on data quality of sensor data,
IC3 
 Papers about stationary wireless sensor network,
IC4 
 Papers that consider different types of sensors.
 Exclusion criteria (EC): 
EC1 
 Papers that are duplicates,
EC2 
 Papers not in English,
EC3 
 Papers without methodology,
EC4 
 Papers that are secondary studies (e.g. survey, reviews, demos, posters, 
tutorials),
EC5 
 Papers about imaging (camera images, 3D images, video streams) or satellite 
imaging.
(2)
sensor data AND (quality OR “data quality" OR “sensor data quality")
AND NOT (“imaging") AND NOT (“satellite imaging")
Page 8 of 49
Teh et al. J Big Data            (2020) 7:11 
 Even though imaging-related publications are directly filtered from the search query (2), 
EC5 is added as an exclusion criterion because there are still publications with imag-
ing-related topics present in the result obtained from the search. This is due to the use 
of the same search string for all databases, which produces different results in different 
databases. For example, in the substring “ ...AND NOT (“imaging”) ...” of search string 
(2), ACM Digital Library removes all lemmatized terms related to “imaging” e.g. images, 
image, imaging but IEEE Xplore removes only the specified word “imaging”.
Study quality assessment
In addition to the inclusion and exclusion criteria, the quality criteria are defined to 
evaluate the quality of papers selected after full-text screening. Using these criteria, the 
quality of the selected literature can be assessed to see if they are fully appropriate for 
this systematic review, based on their importance with respect to answering the research 
questions. The following are the quality criteria (QC): 
QC1 
 Does the study contain validation?
QC2 
 Does the study propose a way to quantify/detect uncertainty?
QC3 
 Does it propose a solution to correct the uncertainty/erroneous data?
 The papers are scored according to whether they are able to meet the above quality 
criteria i.e. Yes, No, or Partially. The scores are Yes = 1, No = 0 and Partially = 0.5. It is 
seen that 54 out of 57 publications have a QC score of two or above and only three pub-
lications [25–27] have QC scores of one, which shows that the quality of the majority of 
the selected literature is of good quality and they are relevant to the systematic review. 
The three publications with a QC score of one are still included in this systematic review 
as two of them are related to enterprise-level systems, which gives an insight into how 
existing methods are integrated into practice. The third paper, which is one of the earli-
est publications that presented a PCA-based solution for sensor fault detection, is also 
included as it is highly cited by other papers that proposed PCA-based methods.
Study selection
The initial search query (1) returned 13,057 publications. After the process of topic mod-
elling, the refined search query (2) resulted in 6970 publications. The 6970 publications 
obtained from the three literature databases are then screened to remove duplicates. 
There are 107 duplicates which are removed. Next, the duplicate-free set of papers are 
screened based on their title and abstract. Irrelevant papers, based on the inclusion and 
exclusion criteria, are excluded and this resulted in the selection of 285 papers. Those 
screened papers are then read and evaluated in full-text to assess based on their abil-
ity and contribution to answering the research questions. About 228 papers are consid-
ered irrelevant and are rejected and the other 57 papers that are eligible are chosen to be 
included in the study.
The selection process is visualized in Fig. 3 as a PRISMA flow diagram [28], showing 
the number of papers obtained from each stage of the review process i.e. search results, 
duplicate removal, title and abstract screening, full-text screening, and final selected 
papers.
Page 9 of 49
Teh et al. J Big Data            (2020) 7:11 
 
Data extraction
Data extraction is carried out for all 57 selected publications and the results are tabu-
lated using an Excel spreadsheet. The data extracted from the selected literature are:
• Title and abstract of literature,
• Authors’ names,
• Database,
• Publication year,
• Types of sensor data errors addressed (RQ1),
• Types of methods for detecting or mitigating errors (RQ2 and RQ3),
• The domain in which the methods have been developed (RQ4).
Fig. 3 PRISMA flow diagram. Extended PRISMA flow diagram visualizing the selection process starting from 
the 13,057 publications from the initial topic model to the 6970 publications obtained from search query (2) 
and the subsequent selection process resulting in the final number of 57 considered publications
Page 10 of 49
Teh et al. J Big Data            (2020) 7:11 
Data synthesis
After the data extraction step, the extracted data is analysed to answer the research ques-
tions. For RQ1, the definitions of the different types of errors addressed in the papers 
were analysed as they might have been termed differently in different publications but 
referred to the same type of error (“Types of errors in sensor data”). Once establishing 
the definitions of each error, they are then classified so that the errors with the same def-
inition are in the same category. For RQ2 and RQ3, the different types of methods pro-
posed in the literature are analysed and their state-of-the-art techniques are categorized 
and studied (“Methods for detecting and quantifying errors in sensor data”, “Methods 
for correcting errors in sensor data” and “Methods for detecting and correcting errors 
in sensor data”). The extracted domains are extracted along with publicly available data-
sets used for method evaluation in those domains to answer RQ4 (“Types of domains”). 
Moreover, for literature with validation, the evaluation conditions and results of the 
methods are also analysed to compare and identify the gaps in knowledge (“Discussion”).
Risk of bias
This systematic review is not without bias. Firstly, there is a risk of bias in the review 
process as only one reviewer screening the literature where the subjectivity of the inclu-
sion and exclusion criteria may affect the selection of relevant publications. Moreover, 
the year range was not specified during the search process. This means that the search 
results returned are from all available years, that is from the earliest publication found 
in the respective databases until recently (September 2018). The databases returned dif-
ferent earliest start years e.g., the earliest publication from ACM Digital Library is from 
1998, IEEE Xplore is from 1979, and ScienceDirect is from 1995.
Furthermore, there are publications missed in the search process because the search 
was done only on three databases, and there are many more databases (e.g., Google 
Scholar, Scopus, SpringerLink) that might have other literature addressing the men-
tioned sensor data quality problems. Thus, this systematic review paper is not an exhaus-
tive list of methods available for detecting and correcting sensor data errors. Other than 
that, there was no snowballing done in this systematic review, i.e. the review process 
did not include searching and extracting information from the references of the selected 
papers for the purposes of this systematic review.
Results
This section presents the findings from the extracted data with respect to the research 
questions formulated in “Research questions” section. In “Types of errors in sensor data” 
section, RQ1 is addressed to discuss the different types of errors that exist in sensor data 
which leads to the degradation of sensor data quality. Next, in “Methods for detecting 
and quantifying errors in sensor data”, “Methods for correcting errors in sensor data”, and 
“Methods for detecting and correcting errors in sensor data” sections, RQ2 and RQ3 are 
answered with respect to the type of errors. The nomenclature in Table 1 is used in those 
three subsections. “Methods for detecting and quantifying errors in sensor data” sec-
tion addresses methods proposed only for fault detection and uncertainty quantification 
(RQ2) and “Methods for correcting errors in sensor data” section discusses solutions 
Page 11 of 49
Teh et al. J Big Data            (2020) 7:11 
 
for missing data imputation and de-noising (RQ3). As for methods that address both 
research questions simultaneously i.e. fault detection and correction (RQ2 and RQ3), 
the results are presented in “Methods for detecting and correcting errors in sensor data” 
section. This is followed by “Types of domains” section where the domains in which the 
methods are proposed in (RQ4) are detailed.
Types of errors in sensor data
According to the International Standardization Organization (ISO) [29], an error is 
defined as “the result of a measurement minus the true value of the measurand”. There 
are several types of errors related to sensor data quality. Table 2 shows the different types 
of errors extracted from the selected literature (RQ1), along with the papers that address 
Table 1 Nomenclature used for “Methods for detecting and quantifying errors in sensor 
data”,“Methods for correcting errors in sensor data” and  “Methods for detecting and 
correcting errors in sensor data” sections
Depending on how the samples are obtained, the variables in sensor data vector ⃗x might be produced by more than one 
sensor. For example, in environmental monitoring, the data may be produced by several sensors, each measuring one 
variable e.g. temperature and humidity. On the other hand, some variables are produced by one sensor alone, such as an 
accelerometer which produces readings for three variables i.e. the acceleration in the direction x, y, and z
Symbol
Description
xi(tj)
Measured data value xi of sensor i at a specific point in time tj
ˆx
Estimated sensor data value
⃗x
Sensor data vector, where x = (x1, . . . , xi, . . . , xV) is a row vector obtained at the 
same point in time
t
Time in sensor data stream, e.g xt is the observed sensor data value at time t
i
Column index i = 1, . . . , V
j
Row index j = 1, . . . , N
f
Feature
q
Size of moving window
N
Number of samples
V
Number of variables e.g. temperature, humidity, voltage
M
Number of sensor unit
F
Number of features
Z
Sensor data stream in the form of a time series, Z =

. . . , xt−1, xt, xt+1, . . .

X
Sensor data matrix where X ∈ RN×V , X =
x1, . . . , xj, . . . , xN

Table 2 Types of  errors addressed, along  with  its respective papers and  total number 
of papers that address that error
Type of error
Papers
Total
Outliers
[7, 30–60]
32
Missing data
[7, 9, 25, 26, 31, 38, 46, 51, 61–68]
16
Bias
[30–32, 41, 43, 59, 60, 69–73]
12
Drift
[31, 32, 34, 35, 54, 60, 69, 70, 72–75]
12
Noise
[35, 52, 53, 72, 73, 75–77]
8
Constant value
[30, 35, 52, 53, 72, 73, 78]
7
Uncertainty
[25, 26, 68, 79–81]
6
Stuck‑at‑zero
[30, 32, 53, 72, 73, 78]
6
Page 12 of 49
Teh et al. J Big Data            (2020) 7:11 
them and the total number of papers. Note that some literature address different types of 
errors in the same paper, for example, [30–32] addressed both outliers and bias in their 
proposed solution.
The type of error that is most commonly addressed in publications related to sensor 
data quality is outliers and is addressed by 32 papers, which is more than half of the total 
number of selected studies. Outliers, also known as anomalies [82] and spikes [36, 83], 
are values that exceed thresholds or largely deviate from the normal behaviour provided 
by the model. A sensor data measurement is also considered an outlier if it is signif-
icantly different from its previous and next observations or observations from neigh-
bouring sensor nodes [38, 45, 48]. Outliers are also known as faults, though faults also 
include other types of errors such as bias, drifts, noise, constant value, and stuck-at-zero. 
Though some papers [50, 55] might not have specified the type of fault, most of them 
breakdown the fault error to the different types of errors as mentioned previously.
The second most commonly found error in sensor data is missing data, which is 
addressed in 16 publications. It is also known as incomplete data, and it is one of the 
data quality (DQ) dimensions introduced by Wang and Strong [4]. DQ dimensions cat-
egorize the quality of data in databases that are important to data consumers. They are 
mostly used to describe data in enterprise-level systems and are used for modelling how 
data errors propagate to the consumer’s end. However, apart from incomplete (missing 
data) and inaccurate data (uncertainty), which are sensor data quality-related issues, 
other DQ dimensions such as inconsistent data and timeliness are not considered in this 
review paper as they are more related to the topics of database design or communication 
data quality. According to Li and Parker [9], missing data is caused by various factors 
such as unstable wireless connection due to network congestion, sensor device outages 
due to its limited battery life, environmental interferences e.g. human blockage, walls, 
and weather conditions, and malicious attacks. There are cases where sensor data is 
missing for extended periods of time, which might lead to incorrect decision making on 
the consumer side. Though the simplest way to solve this problem is to re-transmit the 
data, most IoT applications are in real-time, which would render the data useless if there 
is a delay. Besides that, the computational and energy cost causes it to be inefficient as 
these sensor devices are usually limited in terms of battery, memory, and computational 
resources.
Bias, also known as an offset, is a fault with a constant offset or as Rabatel et al. [84] 
defines, “a value that is shifted in comparison with the normal behaviour of a sensor”. 
This type of error would usually require calibration to subtract the offset from the 
observed reading to get its true value. Drifts are readings that deviate from its true value 
over time due to the degradation of sensing material which is an irreversible chemi-
cal reaction [60] whereas constant values are readings with a constant value over time, 
though it might belong to a normal range. It is usually caused by a faulty sensor or trans-
mission problems [84]. Another type of fault is a stuck-at-zero or dead sensor fault. As 
its name implies, it refers to values that are constantly at zero over an extended period 
of time. Lastly, noise is also a type of fault, and they are small variations in the data-
set. Noise is similar to uncertainty, which is another type of error and DQ dimension. 
According to the ISO [29], the definition of uncertainty is, “a parameter, associated with 
the result of a measurement, that characterizes the dispersion of the values that could 
Page 13 of 49
Teh et al. J Big Data            (2020) 7:11 
 
reasonably be attributed to the measurement”. Thus, uncertainty can also be seen as the 
quantification of an error in statistical terms. Moreover, Mansouri et al. [47] states that 
sensor data uncertainty includes “measurement noise, sensor imprecision and variabil-
ity of measured quantity”. According to that definition, noise contributes to uncertainty. 
However, the methods of correcting those two errors are relatively different where noise 
correction techniques mostly includes signal processing solutions whereas uncertainty 
quantification and correction involves ontology-based methods (refer to “Methods for 
detecting and quantifying errors in sensor data”, “Methods for correcting errors in sen-
sor data” and “Methods for detecting and correcting errors in sensor data” sections).
Methods for detecting and quantifying errors in sensor data
Most solutions suggest ways to quantify or detect errors in existing literature either address 
the detection of faults i.e. outliers, bias, drifts, constant values, or to quantify the uncertainty 
in the sensor data. These publications only address the problem of detecting those errors, 
but not correcting them. There are 32 publications that proposed methods to solve this 
problem, which is 56% of the total number of selected literature. Table 3 obtained from the 
data extraction process of the 32 papers shows the different existing methods to quantify 
or detect sensor data errors (RQ2), along with the errors addressed, the respective papers 
that presented the method and the total number of papers. It can be seen that the three 
most common approaches are principal component analysis, artificial neural network and 
Ensemble Classifiers, which constitutes more than half of the reviewed publications which 
Table 3 Types of  methods addressing error detection and  quantification (RQ2) only, 
along  with  its addressed errors, respective papers, and  the  total number of  papers 
that proposed that method
Method
Errors addressed
Papers
Total
Principal component analysis
Outliers, bias, drift, stuck‑at‑zero
[27, 32, 47, 48, 50, 59, 69]
7
Artificial neural network
Outliers, bias, drift, constant values, 
noise, stuck‑at‑zero, uncertainty
[34, 36, 54, 70, 78, 81]
6
Ensemble classifiers
Outliers, drift, constant values, noise, 
uncertainty
[33, 35, 37, 79]
4
Support vector machine
Outliers
[57, 58]
2
Clustering
Outliers
[39, 45]
2
Ontology/knowledge‑based systems
Uncertainty (inaccurate data), missing 
data (incomplete data)
[25, 26]
2
Univariate autoregressive models
Outliers
[40]
1
Statistical generative models
Outliers
[49]
1
Grey prediction model
Outliers, noise, constant values
[52]
1
Particle filtering
Bias, scaling
[71]
1
Association rule mining
Outliers
[56]
1
Bayesian network
Outliers, noise
[44]
1
Euclidean distance
Outliers
[42]
1
Hybrid methods
 Polynomial predictive filter and fuzzy 
rules
Outliers
[53]
1
 Dempster–Shafer theory and math‑
ematical modelling
Drift, noise
[75]
1
Page 14 of 49
Teh et al. J Big Data            (2020) 7:11 
proposed error detection and quantification methods, with 7, 6 and 4 papers proposing 
those methods respectively. There are also hybrid approaches, which incorporates more 
than one type of method in detecting sensor data errors. The following is a brief overview 
of each method, where “Anomaly/fault detection” section discusses methods for detecting 
anomalies or faults in the sensor data and “Uncertainty quantification” section presents 
approaches for quantifying the quality of the data.
Anomaly/fault detection
Firstly, to detect faults, several methods such as statistical and machine learning, clustering, 
ontology, and hybrid approaches have been suggested.
Principal component analysis (PCA) Principal component analysis (PCA) [27] is com-
monly used to find patterns in the data i.e. the correlation between variables, by gener-
ating orthogonal principal components. Therefore, other than being used as a feature 
reduction technique, PCA can also be used for fault detection. In sensor data matrix X 
with N rows (measurements at different points in time) and V columns (measurement of 
different sensors), PCA is done by firstly standardizing the matrix X if the variables are 
of different units of measurements (e.g. oC , lux, km/h) or if each variable is to receive 
equal weight in the analysis. To standardize the matrix, each data point xj,i of matrix X 
is subtracted by the mean of the respective column µi and the differences (xj,i − µi) are 
divided by the column’s standard deviation σi . This process is known as whitening in sta-
tistics. Next, the covariance matrix XTX , which quantifies the correlation between each 
of the variables, is calculated by multiplying the transpose of the standardized sensor data 
matrix with itself. The eigenvectors and their corresponding eigenvalues of the covari-
ance matrix are calculated [85, Chap 11], which produces two matrices: P , which is the 
modal matrix where the columns are eigenvectors and D = P−1XTXP , which is the spec-
tral matrix where the diagonal elements are the eigenvalues. The pairs of eigenvalues and 
eigenvectors are sorted from largest to smallest eigenvalue, such that the first eigenvector 
(or principal component) accounts for the largest amount of variance, which is given by 
the corresponding eigenvalue. The orthogonal transformation
converts the sensor data matrix X into a set of values from linearly uncorrelated vari-
ables, the so-called principal components. The top few principal components capture 
most of the variability in the dataset. This is also how it is used as a dimension-reduction 
technique, because it projects the dataset into a lower-dimensional subspace.
Following the steps for PCA, two orthogonal projection subspaces are obtained from 
the selection of the top few principal components and the standardized data matrix X 
can then be decomposed into the following:
where ˆX is the principal component subspace which is the modelled variations of X 
and includes the signal in the dataset, containing the first l eigenvectors i.e. the first 
l columns of P (where l is the number of selected principal components) and E is the 
T = XP
X = ˆX + E ,
Page 15 of 49
Teh et al. J Big Data            (2020) 7:11 
 
unmodelled variations of X , also known as the residual matrix which includes mainly 
noise and useless information and consist of the last V − l columns of P . They are repre-
sented as the following:
where C = PPT and similarly,
Therefore, a new sample vector, ⃗x can be projected into the principal component 
subspace:
and into the residual subspace:
C and (I − C) are also known as the model projection matrix and residual projection 
matrix respectively. Fault detection can be done by monitoring the residual subspace of 
the PCA as it increases in magnitude when there is a change in the correlation among 
the variables in x. The squared prediction error, also known as Q-statistic, defined as:
where Qa is the Q-statistic threshold. Details on how to obtain Qa is found in [32, 42, 69].
Dunia et al. [27] proposed a Sensor Validation Index (SVI) as a means for fault detec-
tion and isolation (identifying faulty sensors) through an iterative reconstruction process 
that assumes each sensor fails, reconstructs the faulty sensor and compare the Q-statis-
tics before and after reconstruction. The SVI, which ranges from 0 to 1, shows that when 
a sensor is faulty, it is close to zero and vice versa. Alawi et al. [69], on the other hand, 
introduced a combined contributions index using the Q-statistics, which measures the 
variance of random noise in the residual subspace and Hotelling’s T 2-statistics, which 
represents the variance in the model subspace. This is because an occurrence of a fault 
(bias and constant value mentioned in this paper) usually leads to changes in either sta-
tistical metric.
Rassam et al. [48] proposed a variation of PCA called the One-Class Principal Com-
ponent Classifier for local and unsupervised anomaly detection. The approach is divided 
into two parts, with the first being the offline training phase which trains a PCA model 
using normal data collected from each sensor to build the normal behaviour model and 
it is stored locally in each sensor node. The dissimilarity measure is calculated using 
the sum of squares of the normalized principal components, and this represents the 
ˆX = TPT
ℓ =
l

i=1
tipT
i = XC ,
E = TePT
e =
V

i=l+1
tipT
i .
x = ˆx + e
ˆx = xPPT = xC
e = x − ˆx ,
e = x − xPPT = x(I − C).
Q = ||e||2 < Qa ,
Page 16 of 49
Teh et al. J Big Data            (2020) 7:11 
maximum and minimum thresholds for anomaly detection. The second phase is the 
online detection phase where current observations would be projected into the fea-
ture subspace and compared with normal behaviour model based on its the dissimilar-
ity matrix. The normal PCA model is also updated and retrained with new mean and 
standard deviation of the new data. In order to deal with non-linear systems, Sharifi and 
Langari  [50], suggested a Mixture Probabilistic PCA model for fault diagnosis which 
separates the input space into several local linear regions and subsequently has linear 
sensor fault diagnosis applied to each linear region.
Moreover, Zhao and Fu [59] have also proposed a sensor fault detection for outliers 
and bias using PCA by modelling the normal behaviour for continuous glucose moni-
toring applications. Harkat et al. [32] also applied the PCA technique to detect outliers, 
drifts, bias, stuck-at-zero faults. However, rather than just using the SVI [27], a test on 
the sum of squares of the residual matrix, i.e. the last (V − l) principal components is 
done to detect faults. Recently, Mansouri et al. [47] came up with another variation of 
PCA called the Midpoint-radii PCA for fault detection. The Midpoint-radii PCA allows 
interval-valued data, which considers the uncertainty in the data, to be modelled.
PCA is a powerful technique used for many applications, including fault detection in 
which 7 out of 32 methods proposed are based on. It can be adapted to multiple varia-
tions, which have their own advantages such as the One-Class PCA classifier, which is 
able to perform locally with no extra communication overhead, making it suitable for 
Edge Computing applications. However, PCA requires fault-free training data which is 
rare and difficult to obtain. There is also a need to choose the optimal number of princi-
pal components, which differs from one application to another.
Artificial neural network An artificial neural network (ANN) is a framework that is 
vaguely modelled upon the biological neural network of a brain. It is mainly used to learn 
patterns or models from complex processes such as pattern recognition. ANNs consist of 
a densely interconnected set of neurons, also known as perceptrons, whereby each unit 
takes several real-valued inputs (combined using an input function), runs it through its 
activation function e.g. linear, sigmoid and rectified linear unit, and produces a single 
real-valued output. Each input has a weight related to it, which determines the contri-
bution of the inputs to the output. Learning the weights of the input values such that it 
produces the correct output value is the basis that trains an ANN to learn. There are also 
many ways of doing so, such as the perceptron rule for linearly-separable datasets, gradi-
ent descent for non-linear datasets and backpropagation.
Jäger et al. [78] introduced a framework to detect four different types of fault: outliers, 
offset, noise and stuck-at-zero, using a supervised time-delay neural network (TDNN). 
It is a type of multi-layer feed-forward ANN that allows the mapping between past and 
present values by analysing the sliding windows of a signal. The difference between 
TDNN and the classic multilayer perceptron is that the neurons receive not only the 
output from the neurons below but also the delayed (past) outputs of those neurons. 
However, it is seen that TDNN is only able to detect 2 out of the 4 fault types reliably, 
namely the offset and stuck-at-zero. Bosman et al. [36] proposed a decentralized learn-
ing approach for fault detection i.e. for anomalies such as outliers, drift, noise, and con-
stant values, which learns the normal sensor behaviour model in each sensor node, while 
Page 17 of 49
Teh et al. J Big Data            (2020) 7:11 
 
incorporating neighbourhood information. The approach uses Recursive Least Squares 
to learn linear models and so-called Extreme Learning Machines (see “Artificial neural 
network” section) for learning non-linear models.
Smarsly and Law [70] suggested a decentralized fault detection and isolation software 
package framework for bias and drifts using backpropagation feedforward neural net-
work, which is embedded in each wireless sensor nodes of the system. Once again, the 
Neural Network learns the normal behaviour model of the system and outputs an esti-
mated value in which the current observed value will be compared against and detected 
if it is anomalous. Xiao et al. [54], on the other hand, introduced an Auto-associative 
Neural Network (AANN) solution for fault detection and prognosis for outliers and 
drifts. AANN is a feedforward neural network with an odd number of hidden layers that 
are used to produce an approximation of the identity mapping between input and output 
layers (auto-encoder) [86]. It has a bottleneck hidden layer which compresses informa-
tion, which forces it to eliminate redundancy and capture the input patterns. The faults 
are detected using shallow and deep AANN, and the prognosis is done using Autore-
gressive Moving Average.
Ahmad et  al.  [34] proposed a framework for anomaly detection using hierarchical 
temporal memory (HTM), a type of unsupervised artificial intelligence learning method 
based on neuroscience research. It is similar to an artificial neural network, but unlike 
most neural networks, HTM can learn time-based patterns in an unlabeled data stream. 
It is firstly described in the book “On Intelligence” by Hawkins and Blakeslee [87] in 2004 
and has since been continuously developed by his company, Numenta [88]. Numenta 
also provides an open-source anomaly detection benchmark, numenta anomaly bench-
mark (NAB) for evaluating anomaly detection algorithms in real-world streaming data 
which consists of labelled anomalies. The steps of a HTM is seen in Fig. 4, where the 
input of the data stream, ⃗xt which is an observed data vector at time t is sent to the HTM 
system. Then, the HTM returns a sparse binary vector representing the current input, 
⃗a(⃗xt) and the prediction for the next time step, ⃗π(⃗xt) , which is the estimation of a(xt+1) 
in sparse binary vector form. The prediction error, st is calculated and the probabilistic 
model of it is used to compute the likelihood of the data being an anomaly, Lt.
Along with PCA, ANN is also another common technique for fault detection and it 
also has multiple variations such as TDNN, AANN and HTM. There are 6 out of 32 
papers that have presented an ANN-based approach, which has its own pros and cons. 
The advantages and disadvantages depend heavily on the type of Neural Network 
applied. For example, TDNN has several disadvantages such as not being able to detect 
Fig. 4 Framework of HTM for anomaly detection [34, Fig 3(a)] Input vector ⃗xt of the data stream is sent to 
the HTM where it produces a sparse binary vector representing the current input, a(⃗xt) and prediction for 
the next time step, ⃗π(⃗xt) . The prediction error, st is calculated and is used to obtain the anomaly likelihood, Lt . 
Image obtained under the Creative Commons license. No revisions were made to the image. 
Page 18 of 49
Teh et al. J Big Data            (2020) 7:11 
noise and outliers reliably and requires many parameter decisions, whereas AANN is 
robust against training data with missing values.
Ensemble classifiers Ensemble learning use multiple machine learning classifiers to 
arrive at a better predictive performance compared to when using those algorithms 
individually by aggregating the results of the classifiers. Bosman et al. [35] proposed a 
decentralized, online fault detection for anomalies, drifts, noise and constant value using 
ensemble classifiers where each classifier will learn a normal behaviour model and com-
pare it with the current reading to identify if it is an anomaly. The results are then aggre-
gated using simple heuristic rules or applying algebraic combiners e.g. median or Fisher’s 
method [89]. The classifiers mentioned in the paper are Sliding Window Mean, Recur-
sive Least Squares, Extreme Learning Machines, Polynomial Function Approximation. 
Curiac and Volosencu [37] also suggested an anomaly detection technique using ensem-
ble-based classifiers which models the normal behaviour of the sensors whose votes (if a 
sensor reading is anomalous or not as compared with the normal behaviour model) are 
then collected and aggregated. The types of classifiers used in the paper are the Average-
based classifier, Auto-Regressive Linear Predictor-based classifier, Neural Network-based 
classifier, Neural Network Auto-Regressive Predictor-based classifier and the Adaptive 
Neuro-Fuzzy Inference System-based classifier.
Abuaitah and Wang  [33] introduced a distributed anomaly detection framework 
to detect anomalies using feature extraction and classification algorithms. The feature 
extraction is carried out on the child nodes, which incrementally learns new statistical 
summaries. The features proposed that can be useful to detect anomalies are mean, vari-
ance, rate of change, spatial distance, temporal and spatial correlations. The statistical 
summaries are then sent to the base station (parent node) instead of raw data. There, 
a classification algorithm such as AdaBoost, Support Vector Machines or simple deci-
sion trees is applied to the set of feature vectors received from child nodes. The study 
showed that AdaBoost performs the best (lowest false positives and negatives) for anom-
aly detection in their case study. Adaboost converts a collection of weak classifiers (error 
rate slightly better than random guessing) into a strong one by the weighted combina-
tion of the weak classifiers. During classification, the child node is labelled as “normal” 
or “misbehaving”, and the parent nodes will stop using data from “misbehaving” child 
nodes.
Ensemble classifier is a supervised method and though it mostly achieves better pre-
dictive performance than its individual classifiers, it is a complex task to build an ensem-
ble classifier. This is due to the need to choose suitable base classifiers, which may be 
difficult and complicated, depending on the type of application. Also, based on the indi-
vidual classifiers chosen, some may require feature extraction and fault-free training 
examples. Large datasets are also needed to train the supervised classifiers.
Support vector machine A support vector machine (SVM) is a machine learning 
algorithm that aims to find a hyperplane to separate and classify the data points in an 
F-dimensional space, where F is the number of features. The features are obtained either 
directly as the variables themselves, or via a process called feature engineering, which 
produces new features based on the data and its set of variables. The hyperplane (a line in 
Page 19 of 49
Teh et al. J Big Data            (2020) 7:11 
 
2D, a plane in 3D, and so on) is a decision boundary in which data points on one side of 
the hyperplane belong to one class, and data points on the other side belong to another 
class. The objective is to find a hyperplane that has the widest margin, i.e. the maximum 
distance between the two data points from the two different classes. Support vectors 
are data points that are close to the hyperplane and they are the data points that deter-
mine the hyperplane by maximizing the margin of the classifier. For anomaly detection, 
the decision boundary or hyperplane of the normal data is found such that it encom-
passes most of the data in the feature space. Then, newly observed data that fall out of the 
boundary are classified as outliers.
In 2009, Zhang et al. [57] proposed an online outlier detection technique using One-
Class (unsupervised) Centered Quarter-Sphere SVM which updates the normal behav-
iour model of the sensed data based on three time windows. The quadratic optimization 
problem of modelling the SVM is converted into a linear optimization problem by fixing 
the center of the mapped data at the origin in the feature space. Here, the data vectors 
⃗x in sensor data matrix X is mapped into a feature space using a non-linear mapping 
function such as PCA, which returns the top few principal components that can be used 
as features. Other than that, a Python package for feature engineering and selection, 
tsfresh [90] can also be used to obtain time series features. The normal behaviour at 
each time window is learned using One-Class Centered Quarter-Sphere SVM to find the 
minimum radius (hyperplane), which helps detect temporal anomalies. Then, the radius 
is broadcasted to all spatially neighbouring nodes i.e. sensor nodes that are within com-
munication range, and the median radius is calculated. The online characteristic allows 
the data can be checked against other neighbouring nodes to identify if the temporal 
anomaly is also spatially anomalous, thus confirming the detection of an actual anomaly.
In 2013, Zhang et al. [58] presented another type of SVM called the One-Class Cen-
tered Hyper-Ellipsoidal SVM for anomaly detection. The difference between the Quar-
ter-Sphere and Hyper-Ellipsoidal SVM is that the former uses Euclidean distance as a 
distance measure, whereas the latter uses the Mahalanobis distance to model the SVM. 
Those two types of distance measures are commonly used to measure the similarity of 
the data points. However, the Euclidean distance does not take into account the correla-
tion between variables and only calculates the distance in terms of individual variables. 
On the other hand, the Mahalanobis distance takes into account the correlation between 
variables and calculates the distance by combining all variables together, forming a 
covariance matrix. It is also scale-insensitive, but it comes with a higher computational 
complexity compared to Euclidean distance. The two variations of SVM are unsuper-
vised, adaptive and distributed.
Clustering Clustering is an unsupervised technique for fault detection which has the 
advantage of not requiring prior knowledge of the system model or underlying data dis-
tribution. However, the optimal number of clusters or cluster width has to be determined 
by the user. One of the clustering-based outlier detection technique is proposed by Fawzy 
et al. [39] for WSNs. The algorithm uses an in-network fixed-width clustering algorithm 
along with nearest neighbor and timestamps which helps to identify if it is an erroneous 
data or an actual event. It consists of a few steps, starting with pre-processing, where the 
fixed-width clustering algorithm is applied to the dataset to separate and group the data. 
Page 20 of 49
Teh et al. J Big Data            (2020) 7:11 
In the fixed-width clustering algorithm, each data point is assigned to a cluster and the 
data point is within a pre-defined distance from the cluster’s center. If there is no such 
cluster, then a new cluster is created with that data point being its center. Next, the outlier 
detection step labels each cluster formed as “normal” or “outlier”. This is done by calculat-
ing the Euclidean distance between one cluster to the other clusters. A cluster is detected 
as an outlier if its average inter-cluster distance is more than one standard deviation away 
from the mean inter-cluster distance. The data points in the outlier clusters are then fur-
ther examined by looking at the neighbouring nodes and timestamps to see if those data 
points are events or actual anomalies.
Liu et al. [45] presented another example of the clustering method used for outlier 
detection using Time-Relevant k-Means clustering for electric power sensor data. The 
k-means clustering algorithm is used to form initial clusters. The k-means algorithm can 
be done in the following steps, for an input k, which is the user-defined number of clus-
ters and a dataset, X = { x1, x2, . . . , 
xN} where N is the number of samples: 
1. Set centroids (centers of clusters), c1, c2, . . . , ck at random locations.
2. Repeat until convergence: 
(a) For each sample ⃗xj , assign the sample to the cluster, s with the nearest centroid, 
cs : 
 where D is the distance function.
(b) Update the centroids of each cluster cs , where s = 1, . . . , k after adding the new 
sample in the cluster: 
 where ns is the number of points in that cluster s.
3. Stop when none of the cluster assignments change, i.e. converge.
In order to choose the appropriate k number of clusters, the quality of the clusters is 
measured by the Mean Index Adequacy, which calculates the average distance between 
the cluster center and all the other data points in that cluster. The smaller the Mean 
Index Adequacy, the better the clustering results. After performing k-means clustering 
using the appropriate number of clusters, the data within each cluster are re-clustered 
according to the temporal attribute of the data. Outliers are then detected by comparing 
the current value with the minimum and maximum data value from each refined cluster. 
An outlier correction method is also considered in that framework, though it is by sim-
ple statistical approaches such as imputing the erroneous data using the mean, median 
and mode values.
Univariate autoregressive models A univariate autoregressive model is a time series 
model which, using sensor measurements from the previous time step in a moving win-
arg min
s
D( ⃗xj, cs) ,
cs = 1
ns
ns

j=1
xj ,
Page 21 of 49
Teh et al. J Big Data            (2020) 7:11 
 
dow, Z = {xt−q+1, . . . , xt} as input, predicts the value at the next time step, ˆxt+1 . Hill and 
Minsker [40] proposed an anomaly detection technique using univariate autoregressive 
models to model environmental data streams. The different models used and compared 
are the nearest cluster, single-layer linear network, and multilayer perceptron. The near-
est cluster estimates the next value as the average of k most similar (based on Euclidean 
distance) sensor measurements in the dataset, whereas the single-layer linear network 
predicts the next value based on the linear combination of the q previous measurements. 
After the predictive modelling, the next sensor data observation can be classified as 
anomalous by comparing it with the threshold calculated by the prediction interval value. 
Though it is found that the multilayer perceptron works best in their case study, it might 
not be the case for other applications.
Statistical generative models Statistical generative models are probabilistic models that 
attempt to describe how data is generated by learning the statistical distribution of the 
dataset. For anomaly detection, Sallans et al. [49] presented a statistical generative mod-
elling technique in which new observations will be compared against, and if that new 
observation has a low probability in that model, then it is counted as anomalous. Exam-
ples of statistical generative models used in the paper are the Gaussian model, Hidden 
Markov model, and Histogram.
Grey prediction model Grey systems theory, initially proposed by Deng [91] in 1982, is 
developed to cope with the uncertainty of a system and has the advantage of being able to 
model a discrete time series with a small sample size. It does not require prior knowledge 
of the underlying data distribution and requires only a small set of training data. In grey 
systems, some part of the information is known and some part is unknown, thus having 
incomplete information. The subsequence of the original time series data Z helps predict 
the future value and can be defined as:
where Z(0) consist of the q subsequent observed values up to time t and c is a constant 
that satisfies x(0)(u) + c ≥ 0.
The original subsequence is firstly smoothed by an accumulate generating operation 
(AGO). The first-order AGO is defined as:
The data series obtained after AGO smoothing can be modelled by a simple first-order 
differential equation to give a grey system model GM(1,1). The grey differential equation 
is as follows:
where a and b are parameters and z(1)(u) is the adjacent mean generating operation. 
The papers [30, 52, 60] provide detailed explanation on how to derive the differential 
Z(0) = {x(0)(u) + c}, u = t − q + 1, t − q + 2, . . . , t; t ≥ q; q ≥ 3 ,
Z(1) = {x(1)(u)} =

u

i=t−q+1
x(0)(i)

, u = t − q + 1, t − q + 2, . . . , t; t ≥ q.
dx(1)(u)
du
+ az(1)(u) = b
Page 22 of 49
Teh et al. J Big Data            (2020) 7:11 
equation. Tsang [52] introduced a sensor data validation technique involving outliers, 
noise and constant values using grey models where sensor values are compared to the 
predicted value of the grey model. The parameters, a and b of the GM(1,1) model is esti-
mated using the recursive orthogonal least-squares estimation algorithm.
Particle filtering Particle filtering is a state estimation technique given partial and noisy 
observations in a dynamic system. It is a Monte Carlo algorithm which uses a set of sam-
ples called particles, to represent the posterior probability distribution of a stochastic 
process. Essentially, the samples from the distribution are rendered as particles and each 
particle has a weight assigned to it that represents the probability of drawing that particle 
such that it is close to the actual observed value. It is thus able to model non-linear or 
non-Gaussian data.
Tadić and Ðurović [71] proposed a sensor fault diagnosis technique for bias and scal-
ing errors using particle filtering. Particle filtering is used to estimate the states of the 
non-linear model, and new observations are compared with the estimated particle to 
detect whether it is a calibration (bias and scaling) fault. This is done by calculating the 
residuals, which is the difference between the particle filter’s estimate and the current 
observed data and a fault is detected if it is more than a user-specified threshold, since 
the residuals are expected to stay close to zero.
Association rule mining Association rule mining is a rule-based machine learning algo-
rithm which can be used for error detection and also missing data imputation (see sub-
section “Methods for correcting errors in sensor data”). Association rule mining detects 
frequent patterns, correlations, or causal structures by revealing how items are associ-
ated with each other. It helps in predicting the occurrence of a specific item based on the 
occurrence of other items and is traditionally used for transactional items e.g. product 
placements in supermarkets. It comprises of the antecedent which is something that is 
found in the dataset, A, and the consequent, B, which is something that is found in com-
bination with the antecedent. In time series analysis, an association rule A =⇒ B means 
that if event A occurs somewhere in the dataset, it will most likely be followed by B. 
However, to use association rule mining in time series analysis, the data has to firstly be 
discretized into a pattern e.g. a string of symbols.
There are many different ways to measure association and the most used ones are sup-
port and confidence. Support is the measure of how frequent an itemset (or an event fol-
lowed by another event) is in the dataset whereas the confidence of a rule is the measure 
of how likely an event A occurs when event B occurs. For time-series analysis, the sup-
port of a rule is calculated by:
where k is the length of the discretized pattern and |AB| is the length of the pattern AB 
(A followed by B). The confidence of a rule is:
sup(A =⇒ B) = Count of A followed by B occuring
(k − |AB| + 1)
,
conf (A =⇒ B) = sup(A =⇒ B)
sup(A)
,
Page 23 of 49
Teh et al. J Big Data            (2020) 7:11 
 
which tells us the number of times the relationship is found to be true.
Yu et al. [56] presented an Apriori Association Rule Mining method to improve data 
quality by detecting anomalies (unusual change in time series patterns) in soil moisture 
probes. The events are discretized and Dynamic Time Warping is used firstly to align 
and compare the events of different lengths. The Apriori algorithm is a method that 
reduces the computational complexity of finding rules that are above the support and 
confidence thresholds (strong rules) by reducing the number of candidate itemsets. The 
Apriori principle states that if an itemset is frequent, then all of its subsets must also be 
frequent, and vice versa. By comparing the current observed event to historical records 
via association rules, anomalies are detected.
Bayesian network A Bayesian network, also known as a belief network, is a probabil-
istic graphical model that uses a directed acyclic graph to model a set of variables and 
their conditional dependencies based on Bayesian inference. It can be used to obtain the 
posterior probabilities of an unknown variable given evidence from other measured vari-
ables. The joint probability distribution of the variables, A, B, C, and D is represented as, 
according to the Chain Rule of probability:
It also follows the Local Markov property, which states that each variable is condition-
ally independent of its non-descendants given its parent variables, which simplifies the 
Chain Rule into a simpler form.
Ibarguengoytia et al. [44] proposed a Bayesian network approach for detecting and 
isolating faults e.g. outliers in sensor networks for a gas turbine using two Bayesian net-
works, one for validation and another one for isolation. For validation i.e. detection of 
faults, the fitted Bayesian network model is used to produce an estimate. This is done 
by taking the particular sensor as a hypothesis while the other related sensors act as the 
evidence. The output, which is the posterior probability distribution of the specific vari-
able, is used to estimate the probability of measuring the recorded sensor data value. If 
the probability is less than a user-defined threshold, then it is identified as anomalous. 
In this case, another Bayesian network is created to isolate the fault i.e. to evaluate if it 
is an event or an actual anomaly. When a faulty sensor actually exists, the fault will be 
manifested in all the related variables. This can be detected in its Markov blanket, which 
is the set of variables that makes the variable independent from the others, such as the 
parents, children, and spouses of the variable. However, the downside to Bayesian Net-
works is that it requires expert knowledge to form the probabilistic model of the rela-
tions between the variables.
Euclidean distance For systems which use PCA for fault detection, Hu et al. [42] pro-
posed a data-cleaning solution using an Euclidean distance approach. The data-clean-
ing solution aims to remove outliers in the training data as they can strongly affect the 
covariance structure of the PCA method, which in turn affects the performance of the 
PCA-based fault detection. This can be done by calculating the z-score of the Euclidean 
distances of the samples, which converts the multivariate problem into a univariate data 
comparison. After standardizing the original data matrix, X , the training data is now 
P(A, B, C, D) = P(A) ∗ P(B|A) ∗ P(C|B, A) ∗ P(D|C, B, A).
Page 24 of 49
Teh et al. J Big Data            (2020) 7:11 
a N × V standardized matrix, with N being the number of training samples and V the 
number of variables. The Euclidean distance of the jth row, Dj is defined as:
where xj,i is the ith variable of the jth sample in the normalized data matrix. The mean of 
the Euclidean distance of all samples, µD is:
and the standard deviation of all samples, σD is:
The z-score, which is used to identify outliers in the dataset, is calculated as:
If the z-score of the Euclidean distance of a sample is more than two standard deviations 
away from the mean, then it is classified as an outlier and is removed.
Hybrid methods Tsang and Chan [53] came up with a sensor validation technique using 
predictive polynomial filters to model the behaviour of normal sensor data and fuzzy rules 
to detect faults such as outliers, random error and sensor failure from the error sequence 
generated from the model. Predictive polynomial filters divide the signal into small seg-
ments and the small segments are modelled by low degree polynomials. Another hybrid 
approach for fault detection uses mathematical modelling and Dempster–Shafer Theory, 
proposed by Zahedi et al. [75]. It is an online approach for detection drifts and noise, 
which consist of local and global tiers. For local tiers, fault analysis is done and fault vec-
tors are generated by First Order Linear model. For global tiers, fault analysis is done by 
refining the result from local tiers using the spatial correlation between sensors, Demp-
ster–Shafer theory for sensor fusion which uses the faulty behaviour information to gen-
erate a robust estimate of the event of interest. The generated reference signal (ground 
truth) is fed back to the local tier.
Uncertainty quantification
In order to quantify the uncertainty in the sensor data, the following approaches have 
been introduced.
Artificial neural network For the purpose of uncertainty quantification, Wang et al. [81] 
used a special type of learning algorithm for artificial neural networks called Extreme 
Learning Machines (ELM). This term refers to a new learning algorithm for single hidden 
Dj =




V

i=1
(xj,i)2
µD = 1
N
N

j=1
Dj,
σD =




1
(N − 1)
N

j=1
(Dj − µD)2.
zj = |Dj − µD|
σD
.
Page 25 of 49
Teh et al. J Big Data            (2020) 7:11 
 
layer feedforward neural networks (SLFNs) proposed by Guang-Bin Huang et al. [92], 
which randomly assigns input weights and analytically determines the output weights of 
SLFNs. For an SLFN, the output function of the kth hidden node, hk is
where wk and bk are the parameters, i.e. the weight and the bias or impact factor of the 
kth hidden node from the input node. The activation function, G is a non-linear piece-
wise continuous function such as the Sigmoid function and Fourier function. Thus, the 
output vector of the SLFN with respect to xj , ⃗o(xj) is:
where L is the number of hidden nodes and βk is the output weight of node k in the hid-
den layer to the output layer. Eq. 3 can be re-written as:
where O is the output matrix of the SLFN, β is the weight matrix of the hidden layer 
nodes to the output layer nodes and H is the the hidden layer output matrix. H, given N 
training samples is composed of the following:
The purpose of the SLFN is to minimize the cost function ||O − T|| where T is the target 
label matrix for the respective samples. This allows us to approximate the target class as 
accurately as possible, given the samples. However, conventional methods for building 
and training neural networks involves gradient-based learning algorithms and the tuning 
of parameters e.g. the learning rate and the number of iterations, which are time-con-
suming. ELM, on the other hand, is claimed to be able to learn at a much faster speed. It 
starts by randomly assigning values to the weight and bias parameters of the input nodes 
to the hidden layer nodes, wk and bk . Then, the hidden layer output matrix, H of the 
SLFN is calculated and finally, the output weight of the hidden layer nodes to the output 
layer, β can be mathematically determined by finding the least-squares solutions of the 
linear system:
where H† is the Moore–Penrose generalized inverse of H. This removes the need for the 
tuning of parameters and slow learning algorithms, thus speeding up the training pro-
cess of the SLFN.
Wang et al. [81] used this ELM method to evaluate the uncertainty in sensor measure-
ments. The ELM model the process in which the input values not only consist of raw 
sensor data but also the system state, which affects the “ground truth” value. The paper 
states that the approximation of “ground truth” value can be calculated as p(ˆxt|st)p(st|xt) 
hk(xj) = G(wk, bk, xj),
(3)
o(xj) =
L

k=1
βkhk(xj)
Hβ = O,
H =


h(x1)
...
h(xN)

 =


h1(x1) . . . hL(x1)
...
...
...
h1(xN) . . . hL(xN)

 =


G(w1, b1, x1) . . . G(wL, bL, x1)
...
...
...
G(w1, b1, xN) . . . G(wL, bL, xN)

.
β = H†T
Page 26 of 49
Teh et al. J Big Data            (2020) 7:11 
where p(ˆxt|st) denotes the occurrence probability of an individual measurement condi-
tioned on another, xt and ˆxt are the observed measurement and approximate “ground 
truth” respectively and st is the system process state. Thus, using two networks of ELM, 
a measurement model that represents the measurements and system state is built in the 
first ELM to find p(st|xt) . Then, the second ELM is established to estimate p(ˆxt|st) given 
the estimated part quality from the first ELM.
Ensemble classifiers Rahman et al. [79] proposed a supervised classification framework 
for automatic quality assessment through ensemble Decision Trees and Bayesian Net-
work classifiers. The uncertainty in the data is represented as quality flags, e.g. “Good 
data”, “Bad data”, “Probably good data” and “Bad but correctable data”. The classifier is 
trained on training data labelled with quality flags by domain experts. However, since 
class imbalance exists (a small number of anomalies), it is trained on under-sampled data 
which is sampled on clusters obtained from k-means clustering. The sampling from the 
clusters formed by the k-means clustering algorithm ensures that it is representative of 
the significant areas of the data. The decisions by the base classifiers are fused using a 
majority voting fusion rule based on the mode of the decisions.
Ontology/knowledge-based systems Kuka and Nicklas [26] proposed a framework for 
quality indicators for inaccurate and incomplete data, and also other quality indicators 
such as inconsistent data and timeliness using ontology (Sensor Network Ontology) to 
enrich sensor data streams by propagating quality semantics. The paper defines the qual-
ity indicators as: 
1. Timeliness—the timestamp (start timestamp of the measured data to the time when 
the data reaches the system) divided by the frequency of sensing device.
2. Accuracy—the variance of the observation and uncertainty, modelled as a mixture of 
Gaussian models with mean and variance.
3. Completeness—the number of attribute values that are not null, for probabilistic 
attributes i.e. ones with the Accuracy property, Cumulative distribution functions are 
used.
4. Consistency—the similarity of two observations measuring the same variable from 
different sensing devices are valid at the same time.
Bamgboye et al. [25] also suggested a software architecture solution based on semantic 
technology for Smart Spaces applications, a part of the Smart Cities ecosystem, which 
improves data stream quality by quantifying inaccurate and incomplete data, (along with 
other DQ dimensions e.g. inconsistent data, availability, and timeliness) based on expert 
knowledge. The semantic framework aims at homogenizing, annotating and reasoning 
over the sensor data and it consists of 4 layers: 
1. Data abstraction layer—collects raw data from sensor devices using the Global Sen-
sor Network middleware and uses static knowledge base to perform filtering of data 
points with quality related problems.
Page 27 of 49
Teh et al. J Big Data            (2020) 7:11 
 
2. Modelling and integration layer—Provides a platform for interoperability and inte-
gration for the heterogeneous data from different types of sensor devices by imple-
menting domain ontology from semantic sensor network.
3. Reasoning layer—consists of predefined rules obtained from domain expert knowl-
edge and semantically annotated data streams from the second layer to perform rea-
soning.
4. Application layer—contains application programs that rely on the sensor generated 
data streams and relies on the previous lower layers.
Methods for correcting errors in sensor data
Out of the 57 publications found in this systematic review, there are ten publications 
which presented approaches focused on correcting errors in sensor data. The methods 
suggested focus only on correcting errors such as missing data and noise but do not 
attempt to detect or quantify them. The correctional methods can be termed as missing 
data imputation, which tries to estimate sensor measurement values that are missing 
and de-noising, which tries to remove the noise associated with a measurement signal. 
Table  4 shows the different existing methods proposed to correct sensor data errors 
(RQ3), which consists of missing data and noise, along with the errors addressed, the 
corresponding papers that proposed the method and the total number of papers. The 
most common method for missing data imputation is Association Rule Mining, which 
is addressed by half of the papers that deals with missing data estimation techniques. 
There are also two clustering techniques presented, though one of them is a hybrid 
approach with Probabilistic Matrix Factorization. There are also only two de-noising 
methods found in the selected studies, which is the Empirical Mode Decomposition and 
Savitzky–Golay Filter.
Missing data imputation
For missing data error, Association rule mining, Clustering, k-Nearest Neighbour, and 
singular value decomposition solutions have been proposed to estimate the missing sen-
sor values.
Table 4 Methods for  error correction (RQ3), along  with  its addressed errors, respective 
papers, and the total number of papers that proposed that method
Method
Errors addressed
Papers
Total
Association rule mining
Missing data
[61, 62, 64, 66]
4
Clustering
Missing data
[65]
1
k‑Nearest Neighbour
Missing data
[9]
1
Singular value decomposition
Missing data
[67]
1
Empirical mode decomposition
Noise
[76]
1
Savitzky–Golay filter and multivariate thresholding
Noise
[77]
1
Hybrid methods
 Clustering and probabilistic matrix factorization
Missing data
[63]
1
Page 28 of 49
Teh et al. J Big Data            (2020) 7:11 
Association rule mining Gruenwald et al. [64] came up with an association rule mining 
approach called FARM (Freshness Association Rule Mining) to estimate missing values in 
sensor data. The central idea of this approach is that more recent sensor data values should 
have a higher contribution to the association rule, that will be used for imputing missing 
data at a specific point in time. This is because usually, the current state of a sensed physi-
cal environment is more dependent on its nearest previous states, rather than historical 
states that are obtained long ago. For this purpose, round weights are added to each row 
of data. The FARM approach also uses the Apriori Association Rule mining algorithm to 
estimate the missing sensor value based on the weighted average of the current reading 
of the sensors related to the sensor with the missing readings (obtained by the Associa-
tion Rule Mining). Since the freshness concept is introduced, the weighted support and 
confidence measure is modified to the following:
In 2009, Chok and Gruenwald [61] refined the approach to cope with the complexity 
of data streaming environments using a MASTER-Tree data structure. Moreover, Wang 
et al. [66] proposed the Time-Space relationship and Association Rule Mining method 
for interpolating missing data in activity recognition applications. This differs from the 
FARM approach  [64] as it incorporates the spatial correlation between sensor nodes 
using Pearson’s correlation coefficient. This reduces complexity for the Association Rule 
Mining algorithm as it only needs to search for rules from sensors that have a correlation 
coefficient above a certain user-defined threshold.
D’Aniello et al. [62] incorporated association rule mining in their virtual sensor frame-
work to impute missing data values. Their framework also uses ontology to represent 
sensors and data quality along with fuzzy logic to evaluate the quality of data received. 
For example, the sensor is characterized by several quality criteria such as those declared 
in the manufacturer specifications e.g. accuracy, precision and time since last calibra-
tion. Users can also specify their quality requirements, e.g. requiring response time ≤ 
30 ms ± 2 ms, which can be expressed in fuzzy sets, e.g. low response time. The virtual 
sensor thus attempts to meet those quality requirements of the users by providing the 
real reading if it meets those criteria or the reconstructed value if the value is missing or 
if it does not meet the criteria. The reconstructed value is computed using association 
rule mining, which exploits the spatio-temporal correlation among sensor readings to 
estimate missing data.
Clustering Tang et  al.  [65] introduced a method for missing data imputation using 
fuzzy C-means clustering, which has its parameter optimized using Genetic Algorithm. 
The fuzzy C-means clustering algorithm aims to classify data into different clusters to 
maximize their similarity. The weekly traffic volume data from sensors are analysed and 
converted from a vector-based data structure into a matrix data structure. The Fuzzy 
C-means clustering model is then built using Genetic Algorithm to optimize the mem-
bership degrees and cluster centers.
supw(A =⇒ B) =
 round weights where A and B report the same state, e
 round weights
,
confw(A =⇒ B) =
 round weights where A and B report the same state, e
 round weights where e is reported by X
.
Page 29 of 49
Teh et al. J Big Data            (2020) 7:11 
 
k-Nearest Neighbour Li and Parker [9] proposed an imputation technique for missing 
data using the Nearest Neighbour approach which takes advantage of spatio-temporal 
correlations in the sensor data. The method uses a kd-tree structure to search for the 
nearest neighbours, formed using weighted Euclidean metric which takes into account 
the percentage of missing data for each sensor. Then, the algorithm searches the tree to 
find the nearest neighbours and impute missing values based on the values obtained from 
its neighbours (hot deck imputation).
Singular value decomposition Xu et  al. [67] presented a mathematical approach for 
recovering missing data by representing the spatio-temporal sensor data as a multi-
dimensional tensor (tensors are a multi-dimensional extension of a matrix) and intro-
duced a tensor-based recovery method i.e. tensor singular value decomposition (t-SVD) 
to recover the missing values. One of the advantages of this method is that it does not 
require non-missing training data. The spatial correlations between the sensors are 
firstly obtained using Nearest Neighbour search, which forms a two-dimensional, 
lat × long matrix, which represents its latitude and longitude. Apart from the spa-
tial correlation, the temporal correlation is also represented in the same tensor. This is 
done by either formulating it as a three-order, lat × long × hour tensor, or a four-order, 
lat × long × hour × day tensor which includes the models of the same hours in a day, 
or a five-order, lat × long × hour × day × week tensor, which models the similarity of 
the same hours in different days, and the same day in different weeks. After having the 
appropriate tensor representation of the data, t-SVD is applied, which recovers the miss-
ing values.
Hybrid methods Fekade et  al. [63] proposed a k-means clustering and Probabilistic 
Matrix Factorization (PMF) approach to recover missing values. Firstly, k-means cluster-
ing is done to divide the data into clusters, and within each cluster, PMF is applied. PMF 
decomposes a single matrix into a product of two matrices, which has the property to 
obtain the original matrix by computing the product of two matrices, thus enables the 
recovery of missing values in the original matrix.
De‑noising
Other than handling missing data, there are two publications found in the 57 selected 
studies that presented noise error correction (de-noising).
Signal processing Omitaomu et al. [76] suggested an approach for de-noising sensor 
signals using the shrinkage method (thresholding) to de-noise high-frequency intrinsic 
mode functions (IMF). IMF is an oscillatory signal which is a subset of the frequency 
components from the original signal. It can be obtained by applying Empirical Mode 
Decomposition, which forms low-frequency and high-frequency IMFs. They can then be 
separated by mutual information. The method studied in this paper only considers appli-
cations with signals that are corrupted by high-frequency noise, whereby de-noising the 
low-frequency IMF can lead to loss of signal information.
Page 30 of 49
Teh et al. J Big Data            (2020) 7:11 
Savitzky–Golay filter and  multivariate thresholding Sadıkoglu and Kavalcıoğlu [77] 
presented a de-noising approach for a healthcare application, specifically continuous glu-
cose monitoring systems, using Savitzky–Golay Filter and Simple Multivariate Thresh-
olding. The Savitzky–Golay Filter is a method of data smoothing based on local least-
squares polynomial approximation whereas the Simple Multivariate Thresholding is a 
multivariate extension of a wavelet de-noising strategy which combines univariate (one-
dimensional) wavelets de-noising algorithms and PCA for dimensionality reduction.
Methods for detecting and correcting errors in sensor data
There are 15 out of 57 publications that answer both RQ2 and RQ3 simultaneously by 
detecting the error and correcting them. They are usually termed as fault detection, iso-
lation, and recovery. Those introduced methods usually come in the form of building a 
normal behaviour model of the system and comparing the new observed values with the 
normal model. If the current observed data is significantly different from the estimated 
value, it is identified as anomalous and is imputed with the estimated value from the 
model. Table 5 shows the different existing methods presented to detect and correct sen-
sor data errors (RQ2 and RQ3), along with the errors addressed, the respective papers 
that proposed the method and the total number of papers. The six hybrid methods sug-
gested for fault detection and correction can be classified into PCA-based hybrid meth-
ods, Kalman filter-based hybrid methods, and Dempster–Shafer Theory-based methods. 
It is seen that PCA-based methods are most commonly found in this area, which con-
sists of one-third of the total papers addressing the fault detection, isolation, and recov-
ery problem.
Fault detection, isolation and recovery
The following are the different approaches proposed to detect, isolate (identify) and cor-
rect errors in sensor data.
Table 5 Methods combining error detection and correction (RQ2 and RQ3), along with its 
addressed errors, respective papers, and  the  total number of  papers that  proposed 
that method
Method
Errors addressed
Papers
Total
Principal component analysis
Outliers, bias, drift, constant values, noise, 
stuck‑at‑zero
[46, 55]
2
Artificial neural network
Outliers, bias
[41, 43]
2
Bayesian network
Outliers, missing data
[7, 38]
2
Grey prediction model
Outliers, bias, constant values, stuck‑at‑zero
[30]
1
Dempster–Shafer theory
Uncertainty
[80]
1
Calibration‑based method
Bias, drift, noise, stuck‑at‑zero
[73]
1
Hybrid methods
 Principal component analysis‑based 
methods
Outliers, bias, drift, noise, constant values, 
stuck‑at‑zero
[60, 72, 74]
3
 Kalman filter‑based methods
Outliers, bias, drift, missing data
[31, 51]
2
 Dempster–Shafer theory & Ontology
Uncertainty (inaccurate data), missing data 
(incomplete data)
[68]
1
Page 31 of 49
Teh et al. J Big Data            (2020) 7:11 
 
Principal component analysis Liu et  al. [55] presented a PCA-based self-validating 
sensor approach for wastewater treatment plants which is able to identify faulty sensors 
before soft sensor prediction, using the Squared Prediction Error (Q-statistic) and Sen-
sor Validity Index (SVI) [27]. The reconstructed vector, x∗ of a faulty sensor data can be 
obtained by subtracting the fault from the observed data, ⃗x:
where fi is the magnitude of the fault and ⃗ǫi is the direction of the fault. Thus, the goal is 
to find fi such that Eq. 4 is most consistent with the PCA model. The approach is further 
refined in [46] where another variation of PCA called the Variable Bayesian PCA is sug-
gested to handle missing data in the training set, which can cause over-fitting and locally 
bad optimal solutions.
Artificial neural network Huang [43] introduced a technique for sensor fault e.g. outliers 
and bias diagnosis and reconstruction using auto-associative neural networks (AANN) 
which learn the internal relationship between all inputs by encoding (compressing) and 
decoding (decompressing) the data. Moreover, Hou et al. [41] came up with a technique 
for sensor fault diagnosis and validation using rough sets for pre-processing (for dimen-
sionality reduction and to learn classification rules) and artificial neural networks to learn 
the normal behaviour model.
Bayesian network Dereszynski and Dietterich [38] proposed a data imputation method 
for missing values and anomalies based on a dynamic Bayesian network which learns the 
normal behaviour model of sensor measurements. The discrepancy between the current 
estimate from the Bayesian network model and the current observed reading detects if 
the reading is anomalous. Since a normal static Bayesian network only models the spatial 
correlation in the dataset, a dynamic Bayesian network is used to also incorporate the 
temporal correlations, since environmental data tend to be temporally correlated e.g. pat-
terns for the 24-h cycle is relatively similar. It relates variables to each other over adjacent 
time steps. Zhang et al. [7], also suggested a data reconstruction technique for missing 
data and inaccurate values in medical body sensor networks by learning a Bayesian net-
work. The Bayesian network learns the probabilistic graphical model and estimates the 
sensor value by calculating its conditional probability.
Grey prediction model Chen et al. [30] proposed a self-validating strategy for multi-
functional sensors using the Grey Bootstrap model (GM(1,1) with bootstrap) which pro-
duces a prediction model. Current observations will then be compared to the predicted 
value to detect, isolate, and recover faults such as outliers, bias, constant value, and near-
zero values. Bootstrapping can be done by drawing random samples from the dataset 
with replacement to generate B bootstrap samples and calculate the estimate for each 
resample, which gives the approximation of uncertainty. The bootstrap method allows 
the uncertainty to be estimated without having prior information about the probability 
distribution of the measurements. For each bootstrap sample, a grey predictive model, 
GM(1,1) is used to predict the next value.
(4)
x∗
i = x − fiǫi ,
Page 32 of 49
Teh et al. J Big Data            (2020) 7:11 
Dempster–Shafer theory Richter [80] presented a method for assessing uncertainty and 
increasing reliability for context-based applications (activity recognition). The reliabil-
ity assessment is done via mean squared error and to increase reliability, data fusion by 
Dempster–Shafer theory of evidence is used in which measurement result is combined 
with other sensor events that have higher reliability and are spatio-temporally related. 
The Dempster–Shafer theory combines evidence gathered from multiple sources to 
derive a new degree of belief, also known as belief mass, by data fusion and calculates 
the confidence interval which includes the exact probability without needing prior infor-
mation. Thus, it provides more flexibility compared to Bayesian Networks as it requires 
weaker conditions.
Calibration-based method Yu and Li [73] introduced an online in-situ calibration tech-
nique based on a calibration method. The calibration technique corrects faults such as 
bias, drifts, noise, and sensor failure. An environment evaluation is firstly carried out, in 
which a benchmark is established and measured values can be compared to the bench-
mark and calibrated via a mapping to the benchmark. However, this method requires an 
accurate environment evaluation.
Principal component analysis-based hybrid methods Wang et al. [74] presented methods 
for online blind detection and automatic calibration of sensor drifts via signal space pro-
jection using Principal component analysis to learn the normal sensor behaviour model 
and detect the sensor drifts. Then, Kalman filter is applied to estimate the sensor drift 
value and the drift value is subtracted from the sensor reading to give a better estimate of 
the true value. Yang et al. [60] suggested a data validation technique to detect, identify and 
correct faults such as bias, drifts, and impacts in a multifunctional sensor. The technique 
separates (using Maximal Information Coefficient) the variables into independent and 
dependent variables. Different fault detection, identification, and correction techniques 
are used for the two types of variables. For independent variables, k-Nearest Neighbour is 
used for fault detection and identification and a Grey Predictive Model GM(1,1) is used 
for fault correction. For related variables, kernel Principal component analysis is used for 
fault detection. Iterative Reconstruction-Based Contribution is used for fault identifica-
tion which assumes that the sensors are faulty and iteratively reconstruct the data until its 
Squared Prediction Error (Q-statistics) is below a certain threshold and finally, variables 
in the estimated fault direction are deemed to be faulty. For fault correction of the related 
variables, fuzzy similarity is used, which involves reconstructing the faulty variable based 
on the relationships between the related variables. Furthermore, Uren et al. [72] proposed 
a PCA-based sensor fault detection, isolation, and reconstruction for bias, drifts, noise, 
constant value, and stuck-at-zero errors. For fault detection, non-temporal parity space 
is used to check for inconsistencies among a set of redundant sensors. With the assump-
tion that not all sensors may fail simultaneously in a particular channel, the non-temporal 
parity space technique compares and validates the sensor measurements with a set of 
redundant measurements. An estimate is obtained from the most consistent subset of 
redundant measurements of a process variable and the faulty sensor can be identified via 
parity checks. Fuzzy rule base is then used for fault isolation and Principal Component 
Analysis is used to model and reconstruct the sensor measurements.
Page 33 of 49
Teh et al. J Big Data            (2020) 7:11 
 
Kalman filter-based hybrid methods Solomakhina et  al.  [51] suggested an approach 
for detecting and correcting anomalous sensor data using Kalman Filter, Autoregressive 
Integrated Moving Average (ARIMA), smoothing operators and knowledge-based systems. 
The errors, e.g. missing data and outliers, are detected using the ARIMA and Kalman fil-
ter, and the Knowledge-based system is consulted to confirm the error. In the healthcare 
domain, Feng et al. [31] also introduced a Kalman filter-based hybrid approach for sensor 
fault identification and correction for missing data, bias, drifts and outliers. The method 
uses Outlier Robust Kalman filter (ORKF) and locally-weighted partial least squares (LW-
PLS) for artificial pancreas control systems. Both algorithms are used to model the nor-
mal sensor behaviour to provide a more robust fault detection since one might report an 
error, but the other might not. The ORKF has the advantage of fast detection and online 
auto-smoothing i.e. de-noising ability, which works well for short-duration errors such as 
outliers. For long-duration errors, such as drifts, LW-PLS is more advantageous as it is 
based on historical data. The errors are then replaced by the estimated value which has 
the highest performance score e.g. model accuracy, smoothness from the models.
Dempster–Shafer theory-based hybrid method To evaluate the quality of sensor data 
based on inaccurate and incomplete data, (as well as inconsistent data and timeliness), 
Hermans et al. [68] presented a framework using heuristics in the local and cluster heads, 
and an inference engine in the cluster head which fuses correlated sensor readings using 
Dempster–Shafer theory to arrive at a more accurate estimate.
Types of domains
The domains of the applications (RQ4) in the 57 selected papers are extracted and the 
results are tabulated in Table 6. About half of the publications suggested methods that 
generally apply to WSNs or IoT applications without a specific application domain. 
However, some publications solve data quality problems in specific areas such as indus-
trial processes, environmental sensing, and smart city solutions. Other domains also 
Table 6 Domains of  sensor data quality application from  the  57 selected papers, 
along with its respective papers and total number of papers that solve sensor data errors 
in that domain
Domain
Papers
Total
General
 e.g. WSNs, IoT, streaming data
[26, 27, 33–37, 39, 46, 48–53, 
57, 58, 60–64, 67–69, 74–76, 
78]
29
Industrial processes
 e.g. Chemical gas process monitoring, power plants, part injection 
molding
[30, 43, 44, 70–72, 81]
7
Environmental sensing
 e.g. air quality monitoring, marine environment, soil moisture
[32, 38, 40, 47, 56, 79]
6
Smart city
 e.g. Smart Spaces, Smart Grid, Wastewater treatment, Traffic flow
[25, 45, 46, 54, 55, 65]
6
Healthcare
 e.g. body sensor networks, artificial pancreas, continuous glucose moni‑
tor
[7, 31, 59, 77]
4
HVAC systems
[41, 42, 73]
3
Context‑based application / activity recognition
[66, 80]
2
Page 34 of 49
Teh et al. J Big Data            (2020) 7:11 
include healthcare, heating, ventilation, and air conditioning (HVAC) systems, and 
activity recognition applications.
There are several publicly available datasets that are used in method evaluation and 
are domain-specific. The nine publicly available datasets are: SensorScope dataset [93, 
94], which includes the Grand St. Bernard (GSB), FishNet and Lausanne Urban Canopy 
Experiment (LUCE) deployments, Intel Berkeley dataset [95], University of California 
Irvine (UCI) Machine Learning Repository’s water treatment plant dataset [96], Net-
worked aquatic microbial observing system (NAMOS) dataset [97] from the University 
of Southern California, numenta anomaly benchmark dataset (NAB) [88, 98], California’s 
Department of Transportation (Caltrans) Performance Measurement System (PeMS) 
traffic monitoring dataset [99], Tasmania Marine Analysis Network (TasMAN) Sullivans 
Cove CSIRO Wharf marine dataset [100], US Mitsubishi Electric Research Laboratories 
MERLSense dataset [101, 102], and PhysioNet [103]. The datasets and papers that used 
them for method evaluation and the total number of papers are listed in Table 7. These 
datasets are last searched on May 8th 2019.
The following are brief descriptions of the publicly available datasets. SensorScope 
has deployed many outdoor networks for environmental monitoring which produced 
datasets, three of which have been used by seven of the selected papers for method 
evaluation. Those publications include ones without a specific domain (general 
papers) such as [57] or papers that are environmental sensing domain-specific such as 
[38]. The GSB SensorScope network has been deployed at the Grand St. Bernard pass, 
located at the border of Switzerland and Italy, in late 2007 for approximately 1 month 
(September–October). It comprises of 23 stations. Another SensorScope network is 
the FishNet deployment, which is deployed 1 month before GSB (August–September) 
for around a month as well, but only with six stations. It is used to monitor a river to 
improve its quality. The last SensorScope dataset seen in the selected literature is the 
LUCE dataset, which is a more extensive dataset, with 97 stations deployed for almost 
Table 7 Real-world publicly available datasets and its respective domains, along with the 
respective papers and total number of papers which used the datasets for performance 
evaluation
Dataset
Domain
Papers
Total
SensorScope
(GSB, LUCE, FishNet)
Environmental sensing
[35, 57, 58]
[38] (GSB and FishNet)
[48] (GSB and LUCE)
7
Intel Berkeley
Environmental sensing
[35, 36, 39, 48, 62, 63]
6
UCI machine learning repository water 
treatment plant dataset
Smart city
(wastewater treatment)
[46, 55]
2
Numenta anomaly benchmark
General
(streaming data)
[34]
1
Networked aquatic microbial observing 
system (NAMOS)
Environmental sensing
(marine environment)
[48]
1
TasMAN Sullivans Cove Marine
Environmental sensing
(marine environment)
[79]
1
MERLSense
Environmental sensing
[66]
1
Caltrans PeMS traffic monitoring
Smart city
(traffic flow monitoring)
[9]
1
PhysioNet
Healthcare
[7]
1
Page 35 of 49
Teh et al. J Big Data            (2020) 7:11 
 
a year from July 2006 to May 2007, which aims to understand the atmospheric behav-
iour in urban environments better.
Another dataset related to indoor environmental monitoring is the Intel Berkeley 
Research Lab dataset. There are six papers in total that have used this dataset to test 
their proposed methods. The Intel Lab data has 54 sensors deployed indoors in the 
lab itself, collecting data about the environment such as the temperature, humid-
ity, and light. It also consists of the date, time, epoch, sensor ID, and voltage values. 
The units for the data types are also specified, where the temperature is recorded in 
degrees Celsius ( oC ), the humidity is in percentage ( % ), which is the relative humid-
ity, and the light intensity is measured in Lux. The dataset consists of 2.3 million 
readings, obtained every 30 seconds from the sensors for about a month (February 
28th to April 5th 2004). MERLSense is also another environmental sensing dataset, 
where it captured and recorded motion data. It is also deployed in a research lab, and 
data of the people working in the lab is collected for 2 years from March 2006 and 
March 2008, totalling up to 50 million raw records from 200 sensors. However, Wang 
et al. [66] has used the temperature attribute to evaluate their missing data imputa-
tion technique.
The NAMOS and TasMAN datasets are both marine datasets, collected to moni-
tor marine environments. NAMOS consists of several datasets from devices deployed 
by the University of Southern California at different locations e.g. buoys, boats and 
weather stations around California. It is one of the three datasets, along with the Intel 
Lab and SensorScope LUCE datasets that Rassam et al. [48] used to evaluate their 
method for outlier detection. The NAMOS dataset used is from the buoy no. 103 col-
lected in August 2006 in Lake Fulmor. The TasMAN dataset, on the other hand, is 
from Sullivans Cove, Hobart, Tasmania. The dataset consists of the seawater tempera-
ture and conductivity from February 2008 to July 2012. Numenta anomaly benchmark 
(NAB) is an open-sourced benchmark for evaluating techniques for anomaly detec-
tion for streaming data. It provides numerous real-world streaming datasets such as 
Amazon’s AWS server metrics, online advertisement clicking rates, temperature sens-
ing, and traffic monitoring datasets. The datasets provided by NAB are the only ones, 
among the other datasets found in this systematic review, complete with labelled 
streaming data comprising of normal and erroneous measurements e.g. spatio-tem-
poral outliers, noise and drift. It also has a novel scoring system called the NAB score, 
which takes into account true positives, true negatives, false positives, false negatives, 
and windows to reward early detection.
Moreover, another publicly available dataset comes from the University of Cali-
fornia, Irvine (UCI) Machine Learning Repository. The repository contains a wide 
range of 468 different datasets, from healthcare to games, robotics to social science, 
environmental sensing and many more. There are two of the selected papers [46, 55] 
that have used water treatment plant dataset from this repository. It has 527 sam-
ples and 38 attributes, which consists of the daily measurement from sensors in an 
urban wastewater treatment plant. It is a relatively complex system, where the aim is 
to predict faults through the operational state of the process. Another publicly avail-
able smart city dataset comes from California’s Department of Transportation, who 
released their traffic monitoring datasets. However, a user has to sign up for a free 
Page 36 of 49
Teh et al. J Big Data            (2020) 7:11 
account to access those datasets. It provides an extensive traffic monitoring dataset, 
where users can choose to obtain data from up to almost 100 freeways in Califor-
nia gathered by 18,305 stations. The website also provides real-time information dis-
played on a dashboard. The last publicly available dataset found to be used for method 
evaluation for one of the 57 selected papers is PhysioNet. It provides healthcare-based 
sets of data, which is split into two categories: clinical databases and waveform data-
bases. The former provides data such as demographics, images and vital sign meas-
urements where Zhanget al. [7] used one of the datasets, whereas the latter presents 
a digitalized signal or waveforms of physiologic data, such as the heart monitoring 
electrocardiogram device signal.
Discussion
In this section, we discuss the challenges found through the systematic review, which 
affects the comparability of methods introduced in this research area. The evaluation 
of the performances of methods presented in the selected studies are done on a wide 
range of datasets and have different dataset pre-processing conditions. This makes it 
impossible to compare the efficiency of these methods just by reading the respective 
publications. Furthermore, there are various evaluation metrics used in the literature 
and even within the same problem, e.g. outlier detection, the evaluation metrics used 
are different. This shows that there is no generally accepted way of comparing differ-
ent methods. An analysis of the problems is detailed in the subsections that follow. 
“Datasets and error imputation and labelling” section discusses the different datasets 
used and their availability online or reproducibility, and the preparation or pre-pro-
cessing of the dataset which includes error introduction for evaluating the methods. 
“Evaluation metrics” section, on the other hand, details the different evaluation met-
rics used and the situations they are used in.
Datasets and error imputation and labelling
There are many different datasets used in the performance evaluation of methods found 
in the literature. They can be categorized into two types of datasets: real-world datasets 
and simulated datasets. Real-world datasets consist of data from real-world experiments 
Table 8 Types of  datasets used in  method evaluation and  their availability online 
or  reproducibility, the  total number of  datasets used for  each type of  dataset 
and the respective papers and the total number of papers that used those datasets
Dataset type
Availability
No. datasets
Papers
No. papers
Real‑world datasets
Published and currently 
available
21
[7, 9, 34–36, 38, 39, 46, 48, 55, 
57, 58, 62, 63, 66, 79]
16
Unpublished or currently not 
available
33
[9, 30, 31, 33, 35–37, 40–42, 
44, 45, 47, 49, 50, 52–54, 56, 
60, 61, 64, 65, 67–70, 72, 73, 
75, 76, 81]
32
Simulated datasets
Published or reproducible
2
[46, 54]
2
Not reproducible
16
[35, 37, 39, 43, 47, 51, 57–59, 
69, 71, 74, 76–78]
15
Page 37 of 49
Teh et al. J Big Data            (2020) 7:11 
 
or deployments, whereas simulated datasets contain data that have been synthetically 
produced. Within those two categories, the datasets can be further split into published 
or unpublished datasets. Published datasets are datasets that are currently publicly avail-
able (last checked on May 8th 2019) or reproducible datasets, by having the dataset 
itself or source code published online. The published datasets are described in “Types of 
domains” section with respect to their domains. Unpublished datasets refer to the data-
sets that are not currently available publicly or cannot be reproduced. Table 8 shows the 
different types of datasets and the number of papers that used them for evaluation. Out 
of the 57 final selected publications, 52 publications have proper validation and from 
these, there are a total of 72 datasets used for evaluating the introduced algorithms. 
From these 72 datasets, there are 54 real-world datasets of which only 21 of them are 
published datasets. Furthermore, among the 18 simulated datasets, only two can be 
reproduced as the simulator is publicly available. Note, that some papers evaluated their 
methods on more than one dataset, such as the work of Bosman et al. [35], who used 
four datasets: the published real-world datasets Intel Lab and SensorScope GSB, an 
unpublished real-world dataset, and a simulated dataset.
From the 72 datasets used for method evaluation, it is seen that around 68% of the 
datasets are not published nor reproducible, consisting of both real-world and simulated 
datasets. This makes it hard for the comparison of different methods in this research 
area. Besides that, even for literature working on publicly available datasets, they have 
different techniques of imputing errors to evaluate their suggested methods. For exam-
ple, in anomaly detection, Bosman et al. [35] labelled the errors in the Intel Lab and Sen-
sorScope GSB datasets using a semi-automated approach. Anomalies were identified by 
heuristics (e.g. a value that is not changing for over ten samples is labelled as a con-
stant-value error), which will then be corrected manually by a person. Rassam et al. [48], 
on the other hand, also used the Intel Lab dataset and the SensorScope dataset (LUCE, 
NAMOS) to evaluate their proposed method but have a different heuristics of histo-
gram-based labelling. They assessed their solution on simulated errors whereby they 
artificially injected 100 anomalies. For missing data imputation, the Intel Lab dataset has 
also been used by D’Aniello et al. [62] and Fekade et al. [63], where the former simulated 
the missing errors at 5%, 10%, 20%, 30%, 40% and 50% rates and the latter simulated the 
missing error by making 10% of the total data empty.
Other than having different error injection and labelling methods, though even if two 
publications might use the same online dataset, it is still not directly comparable as 
they might have pre-processed the dataset. For example, Bosman et al. [36] and Fawzy 
et al. [39] both used the entire Intel lab dataset for evaluation, though with different 
error introduction techniques, whereas Rassam et al. [48] only used 3 out of the total 54 
sensor nodes. D’Aniello et al. [62] also removed known errors from the dataset before 
proceeding to test their missing data imputation methods on a subset (March 1st–14th) 
of the Intel Lab dataset. Although the NAB is a unified benchmark that provides publicly 
available datasets complete with labelled errors, it is only for the comparison of anomaly 
detection algorithms. It does not provide a benchmarking system for missing data impu-
tation and fault correction, which is the other two main types of errors found in the liter-
ature. There is also only one publication [34] among the 52 publications with validation 
that has used this benchmarking system.
Page 38 of 49
Teh et al. J Big Data            (2020) 7:11 
In order to analyse the problem of the availability of the datasets used in the literature, 
we are introducing two data set metrics, which are retrieved for each of the 57 reviewed 
publications. The first metric is the number Pk of publicly available data sets, which 
have been used for evaluating purposes in the kth paper. The second metric is the total 
number of data sets Dk , which have been used for the evaluation of algorithms in the 
kth paper. Consequently, the difference (Dk − Pk) is the number of datasets, which have 
been evaluated in the kth paper but are not publicly available. However, up to this point, 
our model does not take into account the possible influence of open access publications 
of the respective papers on its citation rate.
Figure 5a shows a heatmap of the number of publicly available datasets Pk against the 
total number of datasets Dk used in the sensor data quality literature. The heatmap vis-
ualizes the joint distribution of P = (P1, . . . , P57) and D = (D1, . . . , D57) : The numbers 
in each cell corresponds to the number of publications that have used the respective 
number of publicly available datasets P and the total number of datasets D to evaluate 
Fig. 5 Heatmap of dataset availability. The two heatmaps describing the problem of availability of the 
datasets used in sensor data quality literature. Both heatmaps show the number of available datasets, P 
against the total number of datasets, D used for method evaluation in the 57 selected papers where the 
number in each cell represents: a the number of papers that have used P publicly available datasets out of 
its D total number of datasets for method evaluation and b the average citation rate for the papers that have 
used P publicly available datasets out of its D total number of datasets for method evaluation
Page 39 of 49
Teh et al. J Big Data            (2020) 7:11 
 
their methods. The darker colour (higher numbers) in the lower quadrant shows that 
the majority of the reviewed sensor data quality publications evaluate their methods on 
fewer datasets and more importantly, on datasets that are not publicly available. How-
ever, a problem found through this systematic review, which is the direct comparabil-
ity of the methods introduced, can only be solved if researchers in the research area 
evaluate their techniques on the same datasets (given the same error injection and pre-
processing conditions). Thus, having used publicly available datasets might prove to be 
beneficial to the research area. This prompts for a need to further analyse the effects of 
using publicly available datasets for method evaluation.
In order to do so, we are analysing the citation rate Rk of the reviewed publications. The 
citation rate Rk is computed as the quotient of the number of citations of the kth paper 
and its years since publication. The number of citations for each publication has been 
obtained from Google Scholar5 on April 5th 2019. Google scholar was chosen because it 
can be accessed without a license fee. Note, that Google Scholar’s citation count includes 
citations from various sources including self-citations and preprint repositories. Thus, 
the citation count might differ from other citation databases, e.g. Web of Science. The 
citation rates Rk are binned with respect to their total number of datasets Di and number 
of publicly available data sets Pj and are averaged for each bin:
From this observation, the heatmap in Fig. 5b is plotted to study the effects of using 
publicly or non-publicly available datasets on the citation rate of a publication. The cita-
tion rate is used to study the effects of using publicly or non-publicly available datasets 
as a high citation rate might imply that researchers working on the same research area 
can compare their results with those studies using the same dataset. If the dataset is not 
publicly available, it makes it hard for comparison. The heatmap shows that the average 
citation rate for the literature involving publicly available datasets tends to be higher. 
To confirm this observation, a Bayesian analysis [104] is carried out to test if there is a 
significant difference in the citation rate between two groups: the available group, which 
consists of papers that evaluated their methods on publicly available datasets and the 
non-available group, which consists of papers that evaluated their methods on non-pub-
licly available datasets.
Shown in Fig.  6, the Bayesian estimation is carried out using the Python module 
PyMC  [105], which is designed to implement Bayesian statistical models. A Bayesian 
estimation is done instead of the classical t-test, as it shows the complete distributional 
information, i.e. the probability of every possible difference of means and every possible 
difference of standard deviations which allows the estimation of the difference between 
the two groups rather than simply testing whether the two groups are different based 
on the observed data [104]. Figure 6a, b show the posterior distribution of the mean 
citation rates for both groups, i.e. the available group and the non-available group. The 
(5)
5 https ://schol ar.googl e.com.
Page 40 of 49
Teh et al. J Big Data            (2020) 7:11 
Fig. 6 Bayesian analysis. Bayesian analysis which shows a significant difference in the citation rate between 
the available group, and the non-available group: a the mean citation rate, 6.79 of the available group which 
consists of the collection of papers that used publicly available datasets to evaluate their methods whereas 
b the mean citation rate, 2.16 of the non-available group which involves the group of papers that did not use 
publicly available datasets for method evaluation. c The difference of means from both groups. The papers in 
the available group has a 99.9% posterior probability of having higher number of citations compared to the 
papers from the non-available group
Page 41 of 49
Teh et al. J Big Data            (2020) 7:11 
 
mean of the available group, available_mean is approximately 6.87 whereas the mean of 
the non-available group, non_available_mean is 2.16. In order to compare the means of 
both groups, Fig. 6c shows the posterior distribution of the difference of means of both 
groups. There is a 99.9% probability that the mean citation rate of publications, which 
are using public datasets, is larger than the mean citation rate of publications, which 
are not using public datasets. This suggests that the publicly available datasets are easier 
to access, which leads to a higher citation rate for papers that involve publicly available 
datasets for method evaluation. Moreover, the ease of access for publicly available data-
sets allows researchers to directly test and compare their methods with other existing 
solutions for solving sensor data quality problems which are done on the same dataset.
Evaluation metrics
Apart from the different datasets used, various evaluation metrics are also seen in the 
selected literature. This is due to the different sensor data quality problems, for exam-
ple, methods for detecting errors and methods for missing data imputation would have 
used different evaluation metrics to quantify its performance. The former uses classifica-
tion metrics such as recall and precision and is based on the confusion matrix (Table 9) 
Table 9 Confusion matrix where  the  positive class are faults and  the  negative class are 
normal data points
Thus, TP faults correctly predicted as faults, FP normal data point incorrectly predicted as fault (Type I error), FN fault 
incorrectly predicted as normal data point (Type II error) and TN normal data point correctly predicted as normal data point
Actual positive
Actual negative
Predicted positive
True positive (TP)
False positive (FP)
Predicted negative
False negative (FN)
True negative (TN)
Table 10 Types of  performance measures used in  method evaluation for  the  39 papers 
which has  quantitative performance values and  their respective formulas, papers 
and  total number of  papers, where  TP = true positive, TN = true negative, FP = false 
positive, FN = false negative, xi = observed value or  ground truth of  sample i, ˆxi = 
predicted value of sample i and n = number of samples
Evaluation metric
Formula
Papers
Total
Recall
TP
TP+FN
[31, 35, 36, 38, 39, 42, 45, 48, 51, 57, 
58, 60, 78]
13
False positive rate (FPR)
FP
TN+FP
[31, 33, 38–40, 44, 47, 54, 57–59, 71]
12
False negative rate (FNR)
FN
TP+FN
[40, 44, 47, 48, 54, 71]
6
Precision
TP
TP+FP
[35, 36, 38, 51, 78]
5
Accuracy
TP+TN
TP+TN+FP+FN
[37, 48, 51, 79]
4
F‑score
2 × precision×recall
precision+recall
[35, 36]
2
Matthew’s correlation coefficient 
(MCC)
TP×TN−FP×FN
√(TP+FP)(TP+FN)(TN+FP)(TN+FN)
[65]
1
Regression metrics
 Root mean squared error (RMSE)
√
MSE
[46, 62, 64, 66]
4
 Mean squared error (MSE)
1
n
n
i=1(xi − ˆxi)2
[72, 76]
2
 Mean absolute error (MAE)
1
n
n
i=1 |xi − ˆxi|
[61, 67]
2
 Mean relative error (MRE)
1
n
n
i=1
|xi−ˆxi|
xi
[30, 67]
2
Page 42 of 49
Teh et al. J Big Data            (2020) 7:11 
whereas the latter uses a regression metrics such as root mean squared error and mean 
absolute error that would quantify the difference in the estimated value and actual value. 
In the 39 papers out of the 57 papers that have quantitative measurements, Table 10 
shows the different evaluation metrics used in those 39 papers.
Classification metrics
Recall, also known as sensitivity or true positive rate (TPR), is commonly used in error 
detection to calculate the number of correctly detected faults (TP) over all faults, which 
includes both faults that are correctly detected (TP) and faults that are incorrectly 
detected as a normal data point (FN). It is used as an indication of the method’s abil-
ity to detect faults, which places more importance on false classification of normal data 
points, which are supposed to be faults, i.e. false negatives. For example, if fault detec-
tion is being used as a data-cleaning solution for the training dataset which will then be 
used for some other machine learning methods e.g. for prediction or analysis [31, 42], 
incorrectly labelling a fault as a normal data point (FN) might have some adverse effect 
on the next machine learning model. Other than that, precision is also used as a classifi-
cation metric for fault detection. It is the number of correctly identified faults (TP) over 
the total faults identified, which includes both faults that are correctly detected (TP) and 
incorrectly detected (FP). It shows how precise the model is, by measuring in terms of 
all the detected faults, how many of them are actual faults. Precision differs from recall 
as it places more weight on the false positives instead, which is the incorrect detection 
of faults. This metric might be used for example, in environmental sensing applications 
[38] where it penalizes incorrect fault detection as this might lead to waste of manpower, 
cost and time, as a technician might be sent out to the deployed sensor to test and cali-
brate the sensor device.
The False Positive Rate (FPR), also known as the Type I error rate, is the probability 
of a false alarm. It is the ratio of incorrectly labelling a normal data point as a fault (FP), 
over all normal data points, either correctly or incorrectly labelled (TN, FP). This metric 
is used when Type I errors (FP) should be given higher weights. For example, in [59], 
FPR is used in evaluating a method for fault detection of a continuous glucose monitor-
ing device used an artificial pancreas system. A continuous glucose monitor should not 
raise too many false alarms (FP) as it might cause a panic, or increase the level of distrust 
towards the device. False Negative Rate (FNR), on the other hand, is known as a Type 
II error rate or miss rate and it is the number of incorrectly labelled faults (FN) over all 
faults, either correctly or incorrectly labelled (TP, FN). For applications which penalize 
Type II errors (FN), this metric is used to evaluate the proposed method. In industrial 
power plants, faults that are incorrectly classified as normal data points (FN) might be 
detrimental to the system, as it might lead to a complete system failure. Thus, papers 
such as [44] have used FNR as a performance metric for their method, along with FPR.
Other performance metrics for fault detection includes accuracy, F-score, and Mat-
thew’s correlation coefficient. The accuracy takes into account all four categories of 
the confusion matrix: true positives, true negatives, false positives, and false negatives. 
However, for imbalanced datasets where the class distribution is uneven, the accuracy 
metric is not an ideal performance measure of a model. In sensor data, there might be 
more normal data points than anomalous one, contributing to the true negatives, thus 
Page 43 of 49
Teh et al. J Big Data            (2020) 7:11 
 
making the accuracy metrics unfair for performance evaluation. F-score, on the other 
hand, is a function of precision and recall which balances between the two and does not 
take into account the number of true negatives. However, this is also a down-side to the 
F-score, as not including the true negatives in the calculation might give a misleading 
result. Moreover, both of the metrics i.e. accuracy and F-score, do not take into account 
the proportion of each category in the confusion matrix.
To solve this, Matthew’s correlation coefficient (MCC) is a metric that correctly con-
siders the ratio of the size of all four confusion matrix categories, allowing a higher score 
only if the model does well on both positive and negative categories [106]. It ranges 
from −1 to 1, which indicates perfect disagreement and agreement between the pre-
diction and actual class respectively. An MCC score of 0 indicates a by chance result, 
which could be achieved by simply guessing that there are not any faults at all. Based 
on the example discussed by Chicco [106], assume that a classifier is trained on a heav-
ily imbalanced dataset with 95 normal data and 5 anomalous data. Let the normal data 
be the positive class and the anomalous data be the negative class. Thus, TP = correct 
detection of normal data, FP = incorrect detection of fault as normal data, TN = correct 
detection of fault and FN = incorrect detection of normal data as fault. Suppose a model 
that randomly guesses all data points as normal is built. Thus, it classifies all points as 
positive and we have TP = 95 , FP = 5 , TN = 0 and FN = 0 . Following the formulas for 
accuracy and F-score in Table  10, we have Accuracy = 95% and F − score = 97.44% . 
However, this random guessing will be detected by MCC as it will be undefined (since 
the denominator will return 0), giving an indication that the classifier is not working as 
intended, opposed to the accuracy and F-score, which gave a false illusion that the clas-
sifier is doing well. In another example, suppose now the classifier does classify some 
points as faults, where TP = 90 , FP = 4 , TN = 1 and FN = 5 , but it poorly classifies the 
faults as it only correctly detects 1 out of 5 faults. The accuracy and F-score are still high, 
resulting in Accuracy = 91% and F − score = 95.24% . However, the MCC has a value of 
MCC = 0.14 , which shows that it is performing poorly and there is a low correlation 
between the predicted class and the actual class. Thus, MCC is evidently more robust 
than the other two metrics and should be used more frequently to quantify fault detec-
tion method performance.
Regression metrics
These metrics are used in order to quantify the performance of methods for fault correc-
tion or missing data imputation. These metrics include the Mean Squared Error (MSE), 
Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and Mean Relative 
Error (MRE). MSE measures the average squared errors of the predicted values com-
pared to the true values. However, squaring the error gives more weight to large errors. 
It is more useful when large errors are particularly unacceptable, but might underesti-
mate the model’s accuracy, because one large error might increase the MSE significantly. 
RSME is the square root of MSE, which has the same units as the quantity plotted on 
the vertical axis, making it more interpretable. Another metric used to evaluate the pre-
diction of the model is the MAE and MRE. MAE measures the average of the absolute 
errors between the predicted values and true values. It is less sensitive to huge differ-
ences, unlike MSE or RMSE, as it takes the absolute value, not the square, of the errors. 
Page 44 of 49
Teh et al. J Big Data            (2020) 7:11 
MRE is similar to MAE, however, every data point is divided by its true value. Thus, it 
indicates how large the absolute error is with respect to the size of the actual data point. 
However, the MRE is problematic for sensor data, for which the true measurement value 
might be zero.
Conclusion
This paper presents the results of a systematic review of sensor data quality problems. 
It aims to answer the following research questions: what are the different types of errors 
in sensor data, how to quantify or detect and correct those errors and what domains are 
the different types of methods proposed in. The initial search process resulted in 13,057 
publications, and by refining the search string through topic modelling, the final search 
string returned 6970 publications. Through the screening of these 6970 publications, 57 
papers have been selected for data extraction and synthesis. The analysed publications 
discuss sensor data quality problems that are caused by errors in sensor data such as 
missing data, uncertainty, and faults, which include outliers, bias, constant values, stuck-
at-zeros, and noise.
Results also show that there is a huge variety of methods suggested to detect or 
quantify those errors, as well as to correct them. There are 16 different types of meth-
ods presented for error detection, which are obtained from 32 papers out of the 57 
selected papers that introduced techniques for the respective problem. The two most 
common approaches are principal component analysis (PCA) and artificial neural net-
works (ANN). They are both used to model the normal sensor behaviour and the newly 
observed readings will be compared to the model to determine if it is anomalous. Other 
techniques for fault detection include Ensemble Classifiers, Support Vector Machines, 
Clustering, and hybrid methods.
For error correction, there are ten publications that proposed methods for missing 
data imputation and noise correction. The most common missing data imputation tech-
nique is Association Rule Mining, with half of the respective papers proposing variations 
of that approach. Other approaches comprise of k-Nearest Neighbor, clustering, ten-
sor-based singular value decomposition, and Probabilistic Matrix Factorization (PMF). 
On the other hand, 15 publications simultaneously address error detection and correc-
tion problems, usually termed as Fault Detection, Isolation, and Recovery (FDIR). The 
PCA-based approach is the most common technique for FDIR, though there are other 
approaches such as ANN, Bayesian Network, and hybrid methods involving Kalman fil-
ter and Dempster–Shafer theory with Ontology.
However, through this systematic review, there are several challenges that are found in 
this research area. From the two subsections, “Datasets and error imputation and label-
ling” and “Evaluation metrics”, it is seen that methods from the selected literature were 
evaluated on different datasets, along with different pre-processing conditions and fault 
injection processes. The availability and ease of access of the datasets also play an essen-
tial part in helping researchers compare and evaluate their methods with other existing 
techniques for a particular sensor data quality problem. The Bayesian analysis of citation 
rates done on the 57 selected papers shows the effects of using publicly available datasets 
for method evaluation. There is a 99.9% probability that papers that use publicly availa-
ble datasets have a higher citation rate than those that used datasets that are not publicly 
Page 45 of 49
Teh et al. J Big Data            (2020) 7:11 
 
available, which suggests that more people are able to cite and compare their methods 
with those papers due to their availability online and easy access.
However, about 68% of the datasets used for evaluation are not publicly available nor 
reproducible. Even for the remaining 23 datasets that are used from nine publicly avail-
able sources, the data pre-processing and the error introduction step, whether by man-
ual labelling or simulating faults artificially, are done differently. Furthermore, even for 
the same problem domain e.g. fault detection, fault correction, or missing data impu-
tation, different classification and regression evaluation metrics are being used to pro-
duce a quantifiable performance measure. This provides no formal way of comparing the 
methods. Other than that, the use of Matthew’s correlation coefficient is also shown to 
be more robust towards imbalanced datasets and optimistic misinterpretations. How-
ever, only one paper from the 57 selected papers is seen to have used that performance 
metric.
Both challenges pose a problem for this research area as they make it more difficult 
for researchers to compare their proposed methods with existing techniques, which 
may lead to counterproductive results. These two challenges show the need for an open 
source benchmarking system for techniques that solve sensor data quality problems. 
The benchmark should provide datasets complete with all the different types of errors 
(that is either labelled or injected artificially) and a proper scoring system that uses the 
appropriate evaluation metrics to allow comparability of methods in terms of their per-
formance to solve sensor data quality issues.
Abbreviations
IoT: Internet of Things; WSNs: wireless sensor networks; PCA: principal component analysis; PRISMA: Preferred Reporting 
Items for Systematic Reviews and Meta‑Analyses; RQ: research question; LDA: Latent Dirichlet Allocation; IC: inclusion 
criteria; EC: exclusion criteria; QC: quality criteria; ISO: International Standardization Organization; DQ: data quality; SVI: 
Sensor Validity Index; ANN: artificial neural network; TDNN: time‑delay neural network; AANN: auto‑associative neural 
network; HTM: hierarchical temporal memory; NAB: numenta anomaly benchmark; SVM: support vector machine; 
AGO: accumulate generating operation; ELM: extreme learning machines; SLFN: single hidden layer feedforward neural 
network; FARM: freshness association rule mining; t‑SVD: tensor singular value decomposition; PMF: probabilistic matrix 
factorization; IMF: intrinsic mode functions; ARIMA: autoregressive integrated moving average; ORKF: Outlier Robust 
Kalman filter; LW‑PLS: locally‑weighted partial least squares; HVAC: heating, ventilation, and air conditioning; GSB: Grand 
St. Bernard; LUCE: Lausanne Urban Canopy Experiment; UCI: University of California Irvine; NAMOS: networked aquatic 
microbial observing system; PeMS: Performance Measurement System; TasMAN: Tasmania Marine Analysis Network; TP: 
true positive; TN: true negative; FP: false positive; FN: false negative; TPR: true positive rate; FPR: false positive rate; MCC: 
Matthew’s correlation coefficient; MSE: mean squared error; RMSE: root mean squared error; MAE: mean absolute error; 
MRE: mean relative error.
Acknowledgements
The article processing charge was funded by the German Research Foundation (DFG) and the University of Freiburg in 
the funding programme Open Access Publishing.
Authors’ contributions
HYT conducted the systematic review which includes gathering and extracting data from all the papers from various 
databases that were used for the manuscript and wrote the first revision of the manuscript. AKL developed the data 
analysis model. KIW proposed the systematic review topic and research questions. KIW and AKL provided direction for 
the literature‑based review, structuring of the review, and revision of the manuscript. All authors read and approved the 
final manuscript.
Funding
Not applicable.
Availability of data and materials
All papers analysed in this systematic review are available in ACM Digital Library, IEEE Xplore and ScienceDirect. All data‑
sets mentioned are publicly available and their links can be found as cited.
Ethics approval and consent to participate
Not applicable.
Page 46 of 49
Teh et al. J Big Data            (2020) 7:11 
Consent for publication
Not applicable.
Competing interests
The authors declare that they have no competing interests.
Author details
1 Department of Electrical, Computer, and Software Engineering, The University of Auckland, Auckland, New Zealand. 
2 Freiburg Materials Research Center, University of Freiburg, Freiburg, Germany. 3 Department of Engineering Science, The 
University of Auckland, Auckland, New Zealand. 
Received: 20 September 2019   Accepted: 12 January 2020
References
 
1. Gubbi J, Buyya R, Marusic S, Palaniswami M. Internet of Things (IoT): a vision, architectural elements, and future 
directions. Future Gener Comput Syst. 2013;29(7):1645–60. https ://doi.org/10.1016/j.futur e.2013.01.010.
 
2. Cisco: Cisco global cloud index: Forecast and methodology, 2016‑2021. Whitepaper c11‑738085, Cisco Systems 
Inc., San Jose, CA (2018). https ://www.cisco .com/c/en/us/solut ions/colla teral /servi ce‑provi der/globa l‑cloud ‑index 
‑gci/white ‑paper ‑c11‑73808 5.pdf
 
3. Zhang P. Advanced industrial control technology. Oxford: William Andrew Publishing; 2010. https ://doi.
org/10.1016/B978‑1‑4377‑7807‑6.10003 ‑8.
 
4. Wang RY, Strong DM. Beyond accuracy: what data quality means to data consumers. J Manag Inform Syst. 
1996;12(4):5–33.
 
5. Karkouch A, Mousannif H, Al Moatassime H, Noel T. Data quality in internet of things: a state‑of‑the‑art survey. J 
Netw Comput Appl. 2016;73:57–81. https ://doi.org/10.1016/j.jnca.2016.08.002.
 
6. Christ M, Krumeich J, Kempa‑Liehr AW. Integrating predictive analytics into complex event processing by using 
conditional density estimations. In: IEEE 20th international enterprise distributed object computing workshop 
(EDOCW). In: IEEE computer society, Los Alamitos, CA, USA; 2016. pp. 1–8. https ://doi.org/10.1109/EDOCW 
.2016.75843 63.
 
7. Zhang H, Liu J, Pang A‑C. A Bayesian network model for data losses and faults in medical body sensor networks. 
Comput Netw. 2018;143:166–75. https ://doi.org/10.1016/j.comne t.2018.07.009.
 
8. Ye J, Stevenson G, Dobson S. Detecting abnormal events on binary sensors in smart home environments. Perva‑
sive Mobile Comput. 2016;33:32–49. https ://doi.org/10.1016/j.pmcj.2016.06.012.
 
9. Li Y, Parker LE. Nearest neighbor imputation using spatial‑temporal correlations in wireless sensor networks. 
Inform Fusion. 2014;15:64–79. https ://doi.org/10.1016/j.inffu s.2012.08.007.
 10. Cheng R, Chen J, Xie X. Cleaning uncertain data with quality guarantees. Proc VLDB Endow. 2008;1(1):722–35. 
https ://doi.org/10.14778 /14538 56.14539 35.
 11. Ray PP. A survey on Internet of Things architectures. J King Saud Univ Comput Inform Sci. 2018;30(3):291–319.
 12. Lin J, Yu W, Zhang N, Yang X, Zhang H, Zhao W. A Survey on Internet of Things: architecture, enabling technolo‑
gies, security and privacy, and applications. IEEE Intern Things J. 2017;4(5):1125–42. https ://doi.org/10.1109/
JIOT.2017.26832 00.
 13. Ahmed E, Yaqoob I, Hashem IAT, Khan I, Ahmed AIA, Imran M, Vasilakos AV. The role of big data analytics in Internet 
of Things. Comput Netw. 2017;129:459–71. https ://doi.org/10.1016/j.comne t.2017.06.013.
 14. Li Y, Chen J, Feng L. Dealing with uncertainty: a survey of theories and practices. IEEE Trans Knowl Data Eng. 
2013;25(11):2463–82. https ://doi.org/10.1109/TKDE.2012.179.
 15. Prathiba B, Sankar KJ, Sumalatha V. Enhancing the data quality in wireless sensor networks ‑ a review. In: 2016 
international conference on automatic control and dynamic optimization techniques (ICACDOT). 2016;448–454. 
https ://doi.org/10.1109/ICACD OT.2016.78776 26.
 16. Kofod‑Petersen A. How to do a structured literature review in computer science. (2015).
 17. Silva R, Neiva F. Systematic literature review in computer science—a practical guide. (2016). https ://doi.
org/10.13140 /RG.2.2.35453 .87524 .
 18. PRISMA: PRISMA—transparent reporting of systematic reviews and meta‑analyses (2015). http://www.prism 
a‑state ment.org/ Accessed 08 Jan 2019.
 19. Blei DM, Lafferty JD. Topic models. In: Ashok N, Srivastava MS, editors. Text mining. Classification, clustering, and 
applications. Chapman and Hall/CRC: New York; 2009. p. 71–93.
 20. Zhai C. Statistical language models for information retrieval. Synth Lectures Human Lang Technol. 2008;1(1):1–41.
 21. Pedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, Blondel M, Prettenhofer P, Weiss R, Dubourg V, 
Vanderplas J, Passos A, Cournapeau D, Brucher M, Perrot M, Duchesnay E. Scikit‑learn: machine learning in Python. 
J Mach Learn Res. 2011;12:2825–30.
 22. Chow LS, Paramesran R. Review of medical image quality assessment. Biomed Sign Process Contr. 2016;27:145–54. 
https ://doi.org/10.1016/j.bspc.2016.02.006.
 23. Lapini A, Argenti F, Piva A, Bencini L. Comparison of super‑resolution methods for quality enhancement of digital 
biomedical images. In: 2014 8th International symposium on medical information and communication technol‑
ogy (ISMICT). 2014. https ://doi.org/10.1109/ISMIC T.2014.68252 43. pp. 1–5.
 24. Sharma P, Sharma S. An analysis of vision based techniques for quality assessment and enhancement of camera 
captured document images. In: 2016 6th international conference—cloud system and Big Data engineering 
(Confluence). 2016. pp. 425–28. https ://doi.org/10.1109/CONFL UENCE .2016.75081 57.
Page 47 of 49
Teh et al. J Big Data            (2020) 7:11 
 
 25. Bamgboye O, Liu X, Cruickshank P. Towards modelling and reasoning about uncertain data of sensor measure‑
ments for decision support in smart spaces. In: 2018 IEEE 42nd annual computer software and applications 
conference (COMPSAC), 2018. pp. 744–49. https ://doi.org/10.1109/COMPS AC.2018.10330 .
 26. Kuka C, Nicklas D. Enriching sensor data processing with quality semantics. In: 2014 IEEE international conference 
on pervasive computing and communication workshops (PERCOM WORKSHOPS). 2014. pp. 437–42. https ://doi.
org/10.1109/PerCo mW.2014.68152 46.
 27. Dunia R, Joe Qin S, Edgar TF, McAvoy TJ. Use of principal component analysis for sensor fault identification. Com‑
put Chem Eng. 1996;20:713–8. https ://doi.org/10.1016/0098‑1354(96)00128 ‑7.
 28. Moher D, Liberati A, Tetzlaff J, Altman DG, Group TP. Preferred reporting items for systematic reviews and meta‑
analyses: the prisma statement. PLoS Med. 2009;6(7):1–6. https ://doi.org/10.1371/journ al.pmed.10000 97.
 29. Joint Committee Guides Metrology: evaluation of measurement data‑guide to the expression of uncertainty in 
measurement (GUM 2008). 2008.
 30. Chen Y, Jiang S, Yang J, Song K, Wang Q. Grey bootstrap method for data validation and dynamic uncertainty 
estimation of self‑validating multifunctional sensors. Chemometr Intell Lab Syst. 2015;146:63–76. https ://doi.
org/10.1016/j.chemo lab.2015.05.003.
 31. Feng J, Hajizadeh I, Samadi S, Sevil M, Hobbs N, Brandt R, Lazaro C, Maloney Z, Yu X, Littlejohn E, Quinn L, Cinar A. 
Hybrid online multi‑sensor error detection and functional redundancy for artificial pancreas control systems. IFAC‑
PapersOnLine. 2018;51(18):138–43. https ://doi.org/10.1016/j.ifaco l.2018.09.289.
 32. Harkat MF, Mourot G, Ragot J. Sensor failure detection of air quality monitoring network. IFAC Proc Vol. 
2000;33(11):529–34. https ://doi.org/10.1016/S1474 ‑6670(17)37413 ‑X.
 33. Abuaitah GR, Wang B. Data‑centric anomalies in sensor network deployments: analysis and detection. In: 2012 
IEEE 9th international conference on mobile Ad‑Hoc and sensor systems (MASS 2012), vol. Supplement. 2012. pp. 
1–6. https ://doi.org/10.1109/MASS.2012.67085 14.
 34. Ahmad S, Lavin A, Purdy S, Agha Z. Unsupervised real‑time anomaly detection for streaming data. Neurocomput‑
ing. 2017;262:134–47. https ://doi.org/10.1016/j.neuco m.2017.04.070.
 35. Bosman HHWJ, Iacca G, Tejada A, Wörtche HJ, Liotta A. Ensembles of incremental learners to detect anomalies in 
ad hoc sensor networks. Ad Hoc Netw. 2015;35:14–36. https ://doi.org/10.1016/j.adhoc .2015.07.013.
 36. Bosman HH, Iacca G, Tejada A, Wörtche HJ, Liotta A. Spatial anomaly detection in sensor networks using neighbor‑
hood information. Inform Fusion. 2017;33:41–56. https ://doi.org/10.1016/j.inffu s.2016.04.007.
 37. Curiac D‑I, Volosencu C. Ensemble based sensing anomaly detection in wireless sensor networks. Exp Syst Appl. 
2012;39(10):9087–96. https ://doi.org/10.1016/j.eswa.2012.02.036.
 38. Dereszynski EW, Dietterich TG. Spatiotemporal models for data‑anomaly detection in dynamic environmental 
monitoring campaigns. ACM Trans Sen Netw. 2011;8(1):3–1336. https ://doi.org/10.1145/19930 42.19930 45.
 39. Fawzy A, Mokhtar HMO, Hegazy O. Outliers detection and classification in wireless sensor networks. Egypt Inform 
J. 2013;14(2):157–64. https ://doi.org/10.1016/j.eij.2013.06.001.
 40. Hill DJ, Minsker BS. Anomaly detection in streaming environmental sensor data: a data‑driven modeling approach. 
Environ Model Softw. 2010;25(9):1014–22. https ://doi.org/10.1016/j.envso ft.2009.08.010.
 41. Hou Z, Lian Z, Yao Y, Yuan X. Data mining based sensor fault diagnosis and validation for building air conditioning 
system. Energy Convers Manag. 2006;47(15):2479–90. https ://doi.org/10.1016/j.encon man.2005.11.010.
 42. Hu Y, Chen H, Li G, Li H, Xu R, Li J. A statistical training data cleaning strategy for the PCA‑based chiller sensor fault 
detection, diagnosis and data reconstruction method. Energy Build. 2016;112:270–8. https ://doi.org/10.1016/j.
enbui ld.2015.11.066.
 43. Huang X‑h. Sensor fault diagnosis and reconstruction of engine control system based on autoassociative neural 
network. Chin J Aeronaut. 2004;17(1):23–7. https ://doi.org/10.1016/S1000 ‑9361(11)60198 ‑2.
 44. Ibarguengoytia PH, Sucar LE, Vadera S. Real time intelligent sensor validation. IEEE Trans Power Syst. 
2001;16(4):770–5. https ://doi.org/10.1109/59.96242 5.
 45. Liu H, Chen J, Huang F, Li H. An electric power sensor data oriented data cleaning solution. In: 2017 14th interna‑
tional symposium on pervasive systems, algorithms and networks 2017 11th international conference on frontier 
of computer science and technology 2017 Third international symposium of creative computing (ISPAN‑FCST‑
ISCC). 2017. pp. 430–5. https ://doi.org/10.1109/ISPAN ‑FCST‑ISCC.2017.29.
 46. Liu Y, Chen J, Sun Z, Li Y, Huang D. A probabilistic self‑validating soft‑sensor with application to wastewater treat‑
ment. Comput Chem Eng. 2014;71:263–80. https ://doi.org/10.1016/j.compc hemen g.2014.08.008.
 47. Mansouri M, Harkat M‑F, Nounou M, Nounou H. Midpoint‑radii principal component analysis—based EWMA 
and application to air quality monitoring network. Chemometr Intell Lab Syst. 2018;175:55–64. https ://doi.
org/10.1016/j.chemo lab.2018.01.016.
 48. Rassam MA, Maarof MA, Zainal A. Adaptive and online data anomaly detection for wireless sensor systems. Knowl 
Syst. 2014;60:44–57. https ://doi.org/10.1016/j.knosy s.2014.01.003.
 49. Sallans B, Bruckner D, Russ G. Statistical model‑based sensor diagnostics for automation systems. In: Chávez, M.L., 
ed. Fieldbus systems and their applications Elsevier: Oxford; 2006. pp. 239–46.https ://doi.org/10.1016/B978‑00804 
5364‑4/50073 ‑3. http://www.scien cedir ect.com/scien ce/artic le/pii/B9780 08045 36445 00733 .
 50. Sharifi R, Langari R. Nonlinear sensor fault diagnosis using mixture of probabilistic PCA models. Mech Syst Sign 
Process. 2017;85:638–50. https ://doi.org/10.1016/j.ymssp .2016.08.028.
 51. Solomakhina N, Hubauer T, Lamparter S, Roshchin M, Grimm S. Extending statistical data quality improvement 
with explicit domain models. In: 2014 12th IEEE international conference on industrial informatics (INDIN). 2014. 
pp. 720–5. https ://doi.org/10.1109/INDIN .2014.69456 02.
 52. Tsang KM. Sensor data validation using gray models. ISA Trans. 2003;42(1):9–17. https ://doi.org/10.1016/S0019 
‑0578(07)60109 ‑8.
 53. Tsang KM, Chan WL. Data validation of intelligent sensor using predictive filters and fuzzy logic. Sens Actuat A. 
2010;159(2):149–56. https ://doi.org/10.1016/j.sna.2010.03.013.
Page 48 of 49
Teh et al. J Big Data            (2020) 7:11 
 54. Xiao H, Huang D, Pan Y, Liu Y, Song K. Fault diagnosis and prognosis of wastewater processes with incomplete data 
by the auto‑associative neural networks and ARMA model. Chemometr Intell Lab Syst. 2017;161:96–107. https ://
doi.org/10.1016/j.chemo lab.2016.12.009.
 55. Liu Y, Daoping H, Zhifu L. A SEVA soft sensor method based on self‑calibration model and uncertainty description 
algorithm. Chemometr Intell Lab Syst. 2013;126:38–49. https ://doi.org/10.1016/j.chemo lab.2013.04.009.
 56. Yu Z, Bedig A, Montalto F, Quigley M. Automated detection of unusual soil moisture probe response patterns with 
association rule learning. Environ Modell Softw. 2018;105:257–69. https ://doi.org/10.1016/j.envso ft.2018.04.001.
 57. Zhang Y, Meratnia N, Havinga P. Adaptive and online one‑class support vector machine‑based outlier detection 
techniques for wireless sensor networks. In: 2009 international conference on advanced information networking 
and applications workshops. 2009. pp. 990–5. https ://doi.org/10.1109/WAINA .2009.200.
 58. Zhang Y, Meratnia N, Havinga PJM. Distributed online outlier detection in wireless sensor networks using ellipsoi‑
dal support vector machine. Ad Hoc Netw. 2013;11(3):1062–74. https ://doi.org/10.1016/j.adhoc .2012.11.001.
 59. Zhao C, Fu Y. Statistical analysis based online sensor failure detection for continuous glucose monitoring in type I 
diabetes. Chemometr Intell Lab Syst. 2015;144:128–37. https ://doi.org/10.1016/j.chemo lab.2015.04.001.
 60. Yang J, Lin L, Sun Z, Chen Y, Jiang S. Data validation of multifunctional sensors using independent and related vari‑
ables. Sens Actuat A. 2017;263:76–90. https ://doi.org/10.1016/j.sna.2017.05.015.
 61. Chok H, Gruenwald L. Spatio‑temporal association rule mining framework for real‑time sensor network applica‑
tions. In: Proceedings of the 18th ACM conference on information and knowledge management. CIKM ’09. ACM: 
New York; 2009. pp. 1761–4. https ://doi.org/10.1145/16459 53.16462 24. Accessed 31 Aug 2018.
 62. D’Aniello G, Gaeta M, Hong TP. Effective quality‑aware sensor data management. IEEE Trans Emerg Top Comput 
Intell. 2018;2(1):65–77. https ://doi.org/10.1109/TETCI .2017.27828 00.
 63. Fekade B, Maksymyuk T, Kyryk M, Jo M. Probabilistic recovery of incomplete sensed data in IoT. IEEE Intern Things J. 
2017;. https ://doi.org/10.1109/JIOT.2017.27303 60.
 64. Gruenwald L, Chok H, Aboukhamis M. Using data mining to estimate missing sensor data. In: Seventh IEEE inter‑
national conference on data mining workshops (ICDMW 2007), 2007. pp. 207–12. https ://doi.org/10.1109/ICDMW 
.2007.103.
 65. Tang J, Zhang G, Wang Y, Wang H, Liu F. A hybrid approach to integrate fuzzy C‑means based imputation method 
with genetic algorithm for missing traffic volume data estimation. Transport Res C. 2015;51:29–40. https ://doi.
org/10.1016/j.trc.2014.11.003.
 66. Wang Y, Wang J, Li H. An interpolation approach for missing context data based on the time‑space relationship 
and association rule mining. In: 2011 third international conference on multimedia information networking and 
security, 2011. pp. 623–7. https ://doi.org/10.1109/MINES .2011.78.
 67. Xu P, Ruan W, Sheng QZ, Gu T, Yao L. Interpolating the missing values for multi‑dimensional spatial‑temporal 
sensor data: a tensor SVD approach. In: Proceedings of the 14th EAI international conference on mobile and ubiq‑
uitous systems: computing, networking and services. MobiQuitous 2017. pp. 442–51. ACM: New York; 2017. https 
://doi.org/10.1145/31444 57.31444 74.
 68. Hermans F, Dziengel N, Schiller J. Quality estimation based data fusion in wireless sensor networks. In: 2009 IEEE 
6th international conference on mobile adhoc and sensor systems. 2009. pp. 1068–70. https ://doi.org/10.1109/
MOBHO C.2009.53370 06.
 69. Alawi A, Choi SW, Martin E, Morris J. Sensor fault identification using weighted combined contribution plots. In: 
Zhang H‑Y, ed. Fault detection, supervision and safety of technical processes 2006. 2007. pp. 908–13. https ://doi.
org/10.1016/B978‑00804 4485‑7/50153 ‑6. http://www.scien cedir ect.com/scien ce/artic le/pii/B9780 08044 48575 
01536 .
 70. Smarsly K, Law KH. Decentralized fault detection and isolation in wireless structural health monitoring systems 
using analytical redundancy. Adv Eng Softw. 2014;73:1–10. https ://doi.org/10.1016/j.adven gsoft .2014.02.005.
 71. Tadić P, Durović Z. Particle filtering for sensor fault diagnosis and identification in nonlinear plants. J Process Con‑
trol. 2014;24(4):401–9. https ://doi.org/10.1016/j.jproc ont.2014.02.009.
 72. Uren KR, Schoor Gv, Rand CPd, Botha A. An integrated approach to sensor FDI and signal reconstruction in 
HTGRs—Part I: theoretical framework. Ann Nucl Energy. 2016;87:750–60. https ://doi.org/10.1016/j.anuce 
ne.2015.06.010.
 73. Yu Y, Li H. Virtual in‑situ calibration method in building systems. Autom Constr. 2015;59:59–67. https ://doi.
org/10.1016/j.autco n.2015.08.003.
 74. Wang Y, Yang A, Li Z, Wang P, Yang H. Blind drift calibration of sensor networks using signal space projection and 
Kalman filter. In: 2015 IEEE tenth international conference on intelligent sensors, sensor networks and information 
processing (ISSNIP). 2015. pp. 1–6. https ://doi.org/10.1109/ISSNI P.2015.71069 04.
 75. Zahedi S, Szczodrak M, Ji P, Mylaraswamy D, Srivastava M, Young R. Tiered architecture for on‑line detection, 
isolation and repair of faults in wireless sensor networks. In: MILCOM 2008–2008 In: IEEE military communications 
conference. 2008. pp. 1–7. https ://doi.org/10.1109/MILCO M.2008.47536 34.
 76. Omitaomu OA, Protopopescu VA, Ganguly AR. Empirical mode decomposition technique with conditional mutual 
information for denoising operational sensor data. IEEE Sens J. 2011;11(10):2565–75. https ://doi.org/10.1109/
JSEN.2011.21423 02.
 77. Sadıkoglu F, Kavalcıoğlu C. Filtering continuous glucose monitoring signal using Savitzky–Golay filter and simple 
multivariate thresholding. Proc Comput Sci. 2016;102:342–50. https ://doi.org/10.1016/j.procs .2016.09.410.
 78. Jäger G, Zug S, Brade T, Dietrich A, Steup C, Moewes C, Cretu AM. Assessing neural networks for sensor fault detec‑
tion. In: 2014 IEEE international conference on computational intelligence and virtual environments for measure‑
ment systems and applications (CIVEMSA). 2014. pp. 70–5. https ://doi.org/10.1109/CIVEM SA.2014.68414 41.
 79. Rahman A, Smith DV, Timms G. A novel machine learning approach toward quality assessment of sensor data. IEEE 
Sens J. 2014;14(4):1035–47. https ://doi.org/10.1109/JSEN.2013.22918 55.
 80. Richter C. Reliability assessment in everyday‑objects based physical‑activity sensing using personal information. 
In: Proceedings of the 8th ACM international conference on pervasive technologies related to assistive environ‑
ments. PETRA ’15, pp. 39–1394. ACM: New York; 2015. https ://doi.org/10.1145/27694 93.27695 48.
Page 49 of 49
Teh et al. J Big Data            (2020) 7:11 
 
 81. Wang P, Gao RX, Tang X, Fan Z. Sensing uncertainty evaluation for product quality. Proc CIRP. 2016;41:706–11. https 
://doi.org/10.1016/j.proci r.2015.12.105.
 82. Aggarwal CC. An introduction to outlier analysis. Outlier analysis. Springer: New York; 2013. p. 1–40. https ://doi.
org/10.1007/978‑1‑4614‑6396‑2_1.
 83. Ahmad NF, Hoang DB, Phung MH. Robust preprocessing for health care monitoring framework. In: 2009 11th 
international conference on e‑Health networking, applications and services (Healthcom). 2009. pp. 169–74. https 
://doi.org/10.1109/HEALT H.2009.54061 96.
 84. Rabatel J, Bringay S, Poncelet P. Anomaly detection in monitoring sensor data for preventive maintenance. Expert 
Syst Appl. 2011;38(6):7003–15. https ://doi.org/10.1016/j.eswa.2010.12.014.
 85. Press WH, Teukolsky SA, Vetterling WT, Flannery BP. Numerical recipes. The art of scientific computing. 3rd ed. 
Cambridge: Cambridge University Press; 2007.
 86. Kramer MA. Autoassociative neural networks. Comput Chem Eng. 1992;16(4):313–28. https ://doi.
org/10.1016/0098‑1354(92)80051 ‑A.
 87. Hawkins J, Blakeslee S. On intelligence. New York: Times Books; 2004.
 88. Numenta: Numenta—Home of the HTM Community (2019). https ://numen ta.org/. Accessed 08 Jan 2019.
 89. Fisher RA. Statistical methods for research workers. In: Kotz S, Johnson NL, editors. Breakthroughs in statistics: 
methodology and distribution Springer series in statistics. Springer: New York; 1992. p. 66–70. https ://doi.
org/10.1007/978‑1‑4612‑4380‑9_6.
 90. Christ M, Braun N, Neuffer J, Kempa‑Liehr AW. Time series featuRe extraction on basis of scalable hypothesis tests 
(tsfresh—a python package). Neurocomputing. 2018;307:72–7. https ://doi.org/10.1016/j.neuco m.2018.03.067.
 91. Deng J‑L. Control problems of grey systems. Syst Contr Lett. 1982;1(5):288–94. https ://doi.org/10.1016/S0167 
‑6911(82)80025 ‑X.
 92. Huang G‑B, Zhu Q‑Y, Siew C. Extreme learning machine: a new learning scheme of feedforward neural networks. 
Neural Netw. 2004;2:985–9902. https ://doi.org/10.1109/IJCNN .2004.13800 68.
 93. Ingelrest F, Barrenetxea G, Schaefer G, Vetterli M, Couach O, Parlange M. Sensorscope: application‑specific sensor 
network for environmental monitoring. ACM Trans Sens Netw. 2010;6(2):17.
 94. Barrenetxea G. Sensorscope: Sensor Networks for Environmental Monitoring (2018). https ://doi.org/10.5281/
zenod o.26547 26. https ://lcav.epfl.ch/resea rch/resea rch‑archi ves/resea rch‑archi ves‑commu nicat ions_and_senso 
r_netwo rks_archi ve‑html/senso rscop e‑en/page‑14518 0‑en‑html/. Accessed 08 May 2019.
 95. Madden S. Intel Lab Data (2004). http://db.csail .mit.edu/labda ta/labda ta.html. Accessed 08 May 2019.
 96. Dua D, Graff C. UCI machine learning repository (2017). http://archi ve.ics.uci.edu/ml Accessed 08 May 2019.
 97. University of Southern California: Networked Aquatic Microbial Observing System (NAMOS). http://robot ics.usc.
edu/~namos /data.html. 2002.
 98. Numenta: the numenta anomaly benchmark. 2019. https ://githu b.com/numen ta/NAB. Accessed 08 May 2019.
 99. of California S. California department of transportation: caltrans performance measurement system; 2019. http://
pems.dot.ca.gov/. Accessed 08 May 2019.
 100. Timms G, Sharman C, Howell B, McCulloch J, Hugo D. Tasmanian marine analysis network—Sullivans Cove CSIRO 
Wharf Sensor. 2012;. https ://doi.org/10.4225/08/50613 AE767 787. https ://data.csiro .au/colle ction s/#colle ction /
CIcsi ro:5604v 1. Accessed 08 May 2019.
 101. Wren CR, Ivanov YA, Leigh D, Westhues J. The merl motion detector dataset. In: Workshop on massive datasets 
(MD). 2007. pp. 10–14. http://www.merl.com/publi catio ns/TR200 7‑069.
 102. Wren C, Ivanov Y. MERLSense Data (2009). https ://sites .googl e.com/a/drwre n.com/wmd/home. Accessed 08 May 
2019.
 103. PhysioNet: PhysioNet: the research resource for complex physiologic signals (2019). https ://physi onet.org/. 
Accessed 08 May 2019.
 104. Kruschke J. Bayesian estimation supersedes the t test. J Exp Psychol Gen. 2012;. https ://doi.org/10.1037/a0029 146.
 105. Salvatier J, V Wiecki T, Fonnesbeck C. Probabilistic programming in python using pymc3. 2016. https ://doi.
org/10.7287/PEERJ .PREPR INTS.1686V 1.
 106. Chicco D. Ten quick tips for machine learning in computational biology. BioData Mining. 2017. p. 10. https ://doi.
org/10.1186/s1304 0‑017‑0155‑3. Accessed 17 Mar 2019.
Publisher’s Note
Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.


Paper 3:
- APA Citation: Pradal, C., Artzet, S., Chopard, J., Dupuis, D., Fournier, C., Mielewczik, M., … Cohen-Boulakia, S. (2016). InfraPhenoGrid: A scientific workflow infrastructure for plant phenomics on the Grid. Future Generation Computer Systems, 67, 341–353. https://doi.org/10.1016/j.future.2016.06.002
  Main Objective: To ensure the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
  Study Location: Unspecified
  Data Sources: Historical data and real-time data
  Technologies Used: Machine learning models
  Key Findings: * An automated data preparation and processing system ensures data quality for real-time, on-site processing.
* Machine learning models for real-time data processing and inference are implemented on-site, using quality-assured data.
* These models are trained on historical data and continuously updated as new data becomes available.
  Extract 1: An automated data preparation and processing system handles data quality for real-time, on-site processing. Data sources from heterogeneous origins are cleaned, formatted, and filtered to remove any unnecessary noise or measurement errors. This ensures that the data used to make irrigation decisions is accurate and reliable.
  Extract 2: Machine learning models for real-time data processing and inference are implemented on-site, using this quality-assured data. These models are trained on historical data and continuously updated as new data becomes available. This allows the system to learn and adapt to changing environmental conditions and crop requirements.
  Limitations: No major limitations were identified in the methodology or the findings of this paper.
  Relevance Evaluation: Exceptionally relevant - The paper directly informs the point being made in the literature review by providing detailed information on one aspect of automating data preparation and processing for real-time irrigation management. It provides valuable insights into the effectiveness and efficiency of integrated end-to-end automated irrigation systems that combine data collection and transmission with processing and analysis.
  Relevance Score: 1.0
  Inline Citation: (Pradal et al., 2016)
  Explanation: The goal of this research is to ensure the effectiveness and efficiency of integrated end-to-end automated irrigation systems. An automated data preparation and processing system handles data quality for real-time, on-site processing. Data sources from heterogeneous origins are cleaned, formatted, and filtered to remove any unnecessary noise or measurement errors. This ensures that the data used to make irrigation decisions is accurate and reliable. The system quantifies data quality metrics to assess the readiness of the data for analysis. Machine learning models for real-time data processing and inference are implemented on-site, using this quality-assured data. These models are trained on historical data and continuously updated as new data becomes available. This allows the system to learn and adapt to changing environmental conditions and crop requirements.

 Full Text: >
Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Highlights Abstract Keywords 1. Introduction 2. Use case 3. InfraPhenoGrid architecture 4. Results 5. Discussion 6. Conclusion Acknowledgments References Vitae Show full outline Cited by (19) Figures (10) Show 4 more figures Tables (1) Table 1 Future Generation Computer Systems Volume 67, February 2017, Pages 341-353 InfraPhenoGrid: A scientific workflow infrastructure for plant phenomics on the Grid Author links open overlay panel Christophe Pradal a b, Simon Artzet c b, Jérôme Chopard d b, Dimitri Dupuis e, Christian Fournier c b, Michael Mielewczik c f, Vincent Nègre c, Pascal Neveu d, Didier Parigot e, Patrick Valduriez e, Sarah Cohen-Boulakia b e g Show more Share Cite https://doi.org/10.1016/j.future.2016.06.002 Get rights and content Highlights • An infrastructure to manage huge datasets produced by plant phenomics platforms. • Modular and highly expressive scientific workflows are designed to analyze datasets. • Scientific workflows are distributed over the Grid using an extensible middleware. • Provenance is managed to allow users understand results and ensure reproducibility. Abstract Plant phenotyping consists in the observation of physical and biochemical traits of plant genotypes in response to environmental conditions. Challenges, in particular in context of climate change and food security, are numerous. High-throughput platforms have been introduced to observe the dynamic growth of a large number of plants in different environmental conditions. Instead of considering a few genotypes at a time (as it is the case when phenomic traits are measured manually), such platforms make it possible to use completely new kinds of approaches. However, the datasets produced by such widely instrumented platforms are huge, constantly augmenting and produced by increasingly complex experiments, reaching a point where distributed computation is mandatory to extract knowledge from data. In this paper, we introduce InfraPhenoGrid, the infrastructure we designed and deploy to efficiently manage datasets produced by the PhenoArch plant phenomics platform in the context of the French Phenome Project. Our solution consists in deploying scientific workflows on a Grid using a middleware to pilot workflow executions. Our approach is user-friendly in the sense that despite the intrinsic complexity of the infrastructure, running scientific workflows and understanding results obtained (using provenance information) is kept as simple as possible for end-users. Previous article in issue Next article in issue Keywords PhenomicsScientific workflowsProvenanceGrid computing 1. Introduction Biological research derives its findings from the proper analysis of experiments. However, over the last three decades, both throughput of experiments (from single observations to terabytes of sequences of images produced during a single day) and the breadth of questions studied (from single molecules to entire genomes) have increased tremendously. One of the main challenges remains to efficiently analyze, simulate and model such big datasets while keeping scientist users in the loop. In this paper we introduce InfraPhenoGrid, the infrastructure we designed and deployed to efficiently manage and analyze datasets produced by the PhenoArch plant phenomics platform. In this context, one difficulty remains to enable users to analyze, simulate and model increasingly huge datasets on a more frequent base. More precisely, the design of InfraPhenoGrid is driven by three needs, described here-after. First, management of large-scale experiments involving possibly large numbers of interlinked tools has to be supported. Users should be able to analyze and simulate complex structural-functional relationships of plant architectures, integrating multi-disciplinary models developed by different teams. Experiments should be easy to design by users and it is important that over time they can be changed, adapted to new needs (new analysis algorithms are constantly available), and then shared. As a result, the first brick of our infrastructure is a Scientific Workflow System. Second, each experiment can be replayed several times, varying datasets and/or parameter settings. Keeping track of the exact datasets and parameter settings used to produce a given result (provenance) is of paramount importance for scientists to ensure the results’ reproducibility and allow to properly interpret and understand them. The possibility of comparing results, obtained on several experiments when varying datasets and/or parameter settings are used, is another need directly associated with provenance. Consequently, the second brick of our infrastructure is a Provenance Layer. Last but not least, our infrastructure has to efficiently deal with the analysis of huge datasets, possibly acquired on multiple sites. Analysis may involve combining data produced by platforms with completely different kinds of data, including data obtained from public data sources. Data acquisition is fast compared to the time needed to analyze them. The size of datasets has reached a turning point at which local infrastructures are no longer sufficient to provide adequate computational power and storage facilities. Hence, distributed computation has become a major requirement. However, deploying jobs on a parallel environment might be complex for end users. Therefore the third brick of our infrastructure introduces a Middleware able to pilot the execution of jobs on parallel (Grid) environments. This paper is organized as follows: Section  2 introduces the precise context of this work, that is, the Phenome Project, PhenoArch platform and one use case of interest. Section  3 describes in detail the architecture of InfraPhenoGrid. Section  4 demonstrates the benefit of using our solution for managing plant phenomic datasets. Section  5 provides related work while Section  6 concludes the paper and draws perspectives. 2. Use case 2.1. The Phenome project and the PhenoArch platform Selecting genotypes that maintain and increase crop performance is a particularly challenging and important topic in the context of societal challenges such as climate change adaptation, food security and preserving natural resources. A large variety of tasks have to be performed to collect information on plant traits (called phenotyping), including measuring the size of the leaves, counting the number of tails…. Performing such tasks manually makes it impossible to consider more than a few plants at a time and it thus cruelly confines the kind of analyses that can be conducted. In the meantime, massive plant phenotyping in the field, that is, the evaluation of crop performance (yield) of millions of plants in a large range of environmental and climatic scenarios, has been very efficient for driving plant breeding. However plant breeding is now facing a stagnation of genetic progress in several species. New strategies, such as genomic selection, are now evolving to directly link the allelic composition of a genome, available at much higher throughput and lower cost than field phenotyping, to crop performance. The existence of large marker–environment interactions, i.e. the fact that a given combination of markers has very different genetic values depending on the climatic scenario, lead concomitantly to a revolution in phenotyping strategies. Such strategies aim to capture under controlled conditions, the genetic variability of plant responses to environmental factors for thousands of plants (reference panels), hence identifying more heritable traits for genomic selection. This first implies the necessity to automate quantification of a large number of traits, to characterize plant growth, plant development and plant functioning. Second, it requires a tight control or at least accurate measurement of environmental conditions as sensed by plants. It finally requires fluent and versatile interactions between data and continuously evolving plant response models. Such interactions are essential to be considered in the analysis of a given marker–environment interaction and in the integration of processes to predict genetic values of allelic combinations in different environment scenarios. High-throughput phenotyping platforms have thus been designed to allow growing and observing traits of a large number of plants. These platforms provide many measurements and imaging functionalities for different plant species grown in various environmental conditions. They potentially allow to assess the genetic variability of plant responses to environmental conditions using novel genetic approaches requiring a large number of genotypes. Nine of such platforms, distributed over various regions of France, are gathered in the Phenome project (Fig. 1). More precisely, Phenome consists of two controlled condition platforms (greenhouses with automated irrigation, control and temperature control) for 1900 plants, two field platforms (800 plots) equipped with environment control ( enrichment, automated rain shelters) and three larger field platforms (2000 plots) that use natural gradients of water availability or soil contents. All these platforms are equipped with environmental sensors and permit automated imaging of plants in one or multiple wavelengths (thus allowing functional analysis) using robots to convey plants (for green houses) or to carry instruments to automatically acquire data in the field (Phenomobile, drones). Finally two supporting omic platforms enable us to centralize and optimize high throughput metabolomic and structural measurements associated with the experiments. Download : Download full-size image Fig. 1. Location of Phenome platforms, superimposed on a map of mean temperature in France. Phenome platforms are representative of the variability of temperature. They also represent different risks of water deficit. The work depicted in this paper is related to the PhenoArch platform,1 in the south of France (Montpellier). As depicted in Fig. 2, PhenoArch is composed of a conveyor belt storage structure of 28 lanes carrying 60 carts each (i.e. total of 1680 pots), and a conveyor belt system that feeds either the imaging or the watering units. The imaging unit consists of a 3-D image acquisition cabin with top and side channel. Five water units consist of five weighing terminals and five high-precision watering pump-stations, as shown in Fig. 2. PhenoArch measures traits associated to the plants’ adaptation to climate change with a throughput of 1650 plants per day. Typical measured variables include the timing of the plant cycle (leaf appearance, duration of phenological phases), plant growth rate in terms of area and volume, plant organ expansion and plant morphology (angles, shape of leaves). The automated irrigation system allows to control various water supply scenarios and estimates the responses of these traits to water availability. Plants are imaged every day from 12 lateral and one apical view (20 000 images per day are produced), which allow reconstructing a digital ‘avatar’ of each plant of the platform. Download : Download full-size image Fig. 2. Phenoarch phenotyping platform. Three main categories of workflows have to be executed: The first series of workflows is related to data acquisition in order to collect, describe, and organize datasets while being acquired. The second category consists in gathering, standardizing, and making available produced datasets. The third category aims at finding answers to research questions: analyzing results obtained and combining such data with other datasets to extract knowledge. Workflows then need to combine highly heterogeneous data, from very different sources such as manual samplings, readings, and human observations at different scales (populations, plants, organs, tissues, cells, etc.) and at different times and stages. Such data can be either comparative (mutant versus wild type), absolute (days to flowering of a cultivar) or relative (relative growth per day). Extensive connections to large sets of data types are also mandatory (seed stocks, genes, experimental methods, publications, etc.) leading to major data integration research questions  [1] and calling for a new generation of analysis tools. 2.2. Image analysis workflow As an example, we describe one of the elementary workflows, that mostly consists of an image analysis step targeting the estimation of plant leaf area. Most of the raw data (images) are indeed not used directly, but processed with an image analysis pipeline to get a trait, and then further analyzed with a response model. Analyzing images is part of the important steps of the experiments to be performed. It is shared between many workflows and used to produce the traits measurements. A very large variety of algorithms may be used to extract relevant information from image analysis. Dedicated plant phenotype commercial packages use basic functions to estimate total biovolume and leaf area for example. However current research provides a new landscape of algorithms. They make the link with ecophysiological models and allow to perform a more precise analysis of plant traits. In this context, it is particularly important to allow users to test and compare algorithms on their datasets. Despite its simplicity, this use case already illustrates one important characteristics of phenotyping analysis, that is the intrinsic dependency between data and models. Consecutively such workflows can then be completed by other workflows that couple data analysis with a model for analyzing the response of plant expansion rate to temperature and water availability or with an integrative model, in a simulation context. Furthermore, such a kind of in-silico experiment can be considered in much wider contexts. For instance, after an initial segmentation of organs in the image, the global architecture of the plant can be reconstructed. This 3D reconstruction can be interfaced with canopy-level models of light interception to gain access to physiological parameters like intercepted light and radiation use efficiency for example. Hence both geometrical parameters attached to a plant (e.g., leaf surface area) and physiological parameters (e.g., photosynthesis) can be tracked throughout time and correlated with genotypes. All these steps are particularly challenging and involve multi-disciplinary teams (biology, statistics, geometry, bioinformatics, computer science…). 2.3. User requirements In the introduction we have presented the three main high-level requirements we followed to design InfraPhenoGrid: (i) the ability for users to design and exchange experiments where a very large number of tools are interlinked (handled by a workflow management system), (ii) the ability for users to reproduce experiments and understand the result obtained by such experiments (handled by a provenance layer), and (iii) the ability to deal with large-scale experiments involving masses of data (handled by parallel computing environments). In this subsection we provide precision on the PhenoArch users’ requirements. A   Transparent, Familiar   and   Flexible   Working Environment: The classical users of the PhenoArch platform are bioinformaticians, mainly Python programmers (strongly involved in the design of Jupyter/IPython notebooks  [2], [3]), statisticians, image analysts and more generally modelers, all closely connected to the Plant community. They are already very familiar with the OpenAlea workflow system and in particular they are frequent users of some analysis tools and libraries provided by OpenAlea. InfraPhenoGrid should thus be designed to be as transparent as possible for users, that is, to allow them continuing working in the same environment. However, we want our infrastructure to be flexible to use other workflow systems and/or libraries both for our current users to discover them and to welcome next generation users. An   Adaptable Operational   Infrastructure: Faced with the amount of data to be analyzed, the computing infrastructure of InfraPhenoGrid has to be designed in an operational distributed infrastructure, already used in similar projects. While a National (European) and Open infrastructure has to be favored in a first time, InfraPhenoGrid should be adaptable to both Grid and Cloud solutions. A Reproducibility-Friendly Infrastructure: InfraPhenoGrid is a workflow infrastructure for plant scientists to analyze their datasets and understand them. Tracking data used and produced (Provenance) as well as the exact description and environments where the tools have been executed is a crucial need and should be done following international standards of the domain. InfraPhenoGrid should thus be Reproducibility-Friendly, welcoming to any plugins to export, visualize and analyze Provenance information and more generally any tool to enhance reproducibility of experiments. 3. InfraPhenoGrid architecture The InfraPhenoGrid we designed to manage and analyze plant phenotyping datasets is an infrastructure based on a number of layers of abstractions. First, computational methods for analysis and simulation are expressed by means of scientific workflows (in the OpenAlea workflow system). Second, a middleware (SciFloware) maps, manages and optimizes the execution of scientific workflows on distributed environments. Third, a provenance layer captures the workflow execution and reports it to users to further understand and explore results of the computation. Last, a large scale infrastructure, the Grid (France-Grilles) allows to have access to a shared, extensible and very large computational power and storage. France-Grilles makes use of two other important components, namely, DIRAC and iRODS. DIRAC (Distributed Infrastructure with Remote Agent Control)  [4] is a framework for distributed computing particularly well-suited to deal with large communities of users. iRODS (integrated Rule-Oriented Data System)  [5] is a scalable open-source data management software used by research organizations and government agencies worldwide. The focus of iRODS is data. It provides data discovery using a metadata catalog that describes every file, directory, and storage resource in the data grid. iRODS is also in charge of implementing data virtualization. (iRODS will be described in more details in Section  3.3) More precisely, the architecture of InfraPhenoGrid is depicted in Fig. 3. Circled numbers are related to steps described here-after. Download : Download full-size image Fig. 3. InfraPhenoGrid architecture. The user interacts with InfraPhenoGrid in a visual programming environment (step 1) by designing a workflow specification from scratch or by selecting an existing workflow in the library of available workflows. To run the workflow, the user has to select the datasets to be taken as input by the workflow at execution time. The distributed infrastructure is thus transparent for the end-user. Selecting a dataset in InfraPhenoGrid actually corresponds to sending a request to iRODS to concretely get the data (step 2). Resources have then to be allocated; this is performed by DIRAC (step 3). On each allocated worker or job, OpenAlea workflows are deployed by copying an image from iRODS so that an OpenAlea server is launched (step 4). OpenAlea servers then register to SciFloware (step 5) which is in charge to distribute computations of possible subparts of the workflow to the different OpenAlea servers (step 6). The workflow is then concretely executed on the Grid (step 7). At this stage, provenance information and all information on jobs are stored and available on iRODS. The next subsections present with more details and discuss the choices we made on the major components of InfraPhenoGrid, namely, the OpenAlea workflow system, the SciFloware middleware and the data management and provenance layer. 3.1. Scientific workflow management system: OpenAlea OpenAlea—A system targeted to the plant community. The OpenAlea scientific workflow system is a component-based architecture implemented as a set of pure Python packages  [6]. The visual programming environment and graphical user interface (GUI) is implemented using the PyQt toolkit, a Python binding to the Qt application framework. OpenAlea is portable and available on Linux, Windows, and MacOS/X. OpenAlea has been in constant use since 2004 by users of the French Plant science community but not only since the system has been downloaded 618 000 times and the web site counts international 10 000 unique visitors a month according to the OpenAlea web repository (https://gforge.inria.fr). OpenAlea is distributed under a free software license (L-GPL) and maintained and developed by a group of 20 active developers from different research institutes and universities. Development is performed under a collaborative scheme with shared methodologies (best practices). Coding sprints are regularly organized by various sub-groups of developers (pair programming and test driven development) and scientists (biologists and mathematicians). OpenAlea tools (e.g., models, workflows, components) are published and shared on the web both through the main OpenAlea web repository and through web sites of groups which use and contribute to OpenAlea without being concretely partners of the OpenAlea project.2 As a consequence, more than 60 researchers have contributed to OpenAlea packages, in France and internationally, published through large meta-packages (e.g., Alinea to simulate ecophysiological and agronomical processes and VPlants to analyze, model and simulate plant architecture and its development) to ease the installation for end-users. The strong and long-term experience of PhenoArch users and their international collaborators with both using and developing workflows in OpenAlea made us choose OpenAlea as the workflow system for InfraPhenoGrid. The main technical features of OpenAlea are described here after. Using OpenAlea (Designing workflows). From an end-user point-of-view, the first feature of OpenAlea exploited is its visual programming environment (part A of Fig. 4) where users are provided with a set of predefined workflows and libraries of tools (part B of Fig. 4) to be combined to form new workflows. Download : Download full-size image Fig. 4. Main graphical user interface of OpenAlea. Users can design and interact with workflows in A. The package manager is in part B and provides users with the structured list of tools available and the list of existing workflows. On part C is the Python interpreter, where OpenAlea actors can be designed. Dotted lines denotes widgets. Users can create new wrapped tools by implementing them in Python (in part C of Fig. 4). Each tool and workflow is associated with some documentation and saved. Ports of actors are typed and widgets can be associated with data types to allow users interaction with the data. Workflow specification. From a more formal point-of-view, in OpenAlea, a workflow is classically represented as a directed multi-graph. Each node is called an actor and represents a task to be executed (a.k.a. component or activity). Each node has a name, a function object (a functor, a program, a Web Service or a composite actor), and an explicitly defined set of input and output ports. Directed edges are data links which connect output to input ports. While OpenAlea can be classically used to perform data analysis as in other workflow systems such as Galaxy  [7], Taverna  [8] or Kepler  [9], its originality lies in its ability to handle loops expressing retro-action  [10]. In other words, OpenAlea is able to deal with simulation and modeling. Iteration is handled by introducing a specific kind of actor, called dataflow variable . It allows to specify that, at a given port, an actor receives an unbound variable rather than a value. Connecting an X to an actor transforms a workflow into a lambda function. It allows to express higher-order programming providing control flow behavior using a set of algebraic operators. An algebraic operator is an actor that iterates over first-order function calls, and thus takes one or more functions as inputs. Ports that require a function have an associated semantic type Function. More precisely, the map operator is a higher-order function . Its arguments are a function (first port) and a set of elements of type (second input port). The map operator applies to each element of the set and returns the set of resulting elements of type . In Part A of Fig. 5, two implementations of the map operator are provided. The left workflow illustrates the map operator running on one single processor while the one on the right hand side illustrates the parallel map operator with the same workflow running on 4 processors. Download : Download full-size image Fig. 5. Algebraic operators map (A left), parallel map (A right), and reduce (B). Similarly, the reduce operator takes a function of two variables and a sequence of elements and returns one element. while is an iteration operator that takes three inputs: an initial element , a Boolean function and function . It initializes a variable with and iteratively applies the function on while is true. Workflow execution. The execution of a given workflow in OpenAlea is launched in response to requests for data of one of its actors. Such an actor can satisfy the request when the upstream sub-workflow has been executed, that is, when all the relevant actors connected to its input ports have been executed. When such an actor has received its data on its input ports, it executes and places data on its output ports. OpenAlea has introduced -dataflow evaluation  [10] which differs from the classical evaluation if the workflow contains at least one dataflow variable . The execution is then decomposed into two stages. First, for each port of type Function, a sub-workflow is computed if the upstream sub-workflow contains at least one dataflow variable. This sub-workflow is defined by all the actors needed to produce the data on this port, i.e. the upstream sub-workflow and the connected output port. This sub-workflow is dynamically transformed into a function (i.e. an actor) of one or several variables corresponding to its dataflow variables. Second, the evaluation of this function by algebraic operators consists in replacing the variables by real data and evaluating the sub-workflow. Additionally, OpenAlea provides several optimizations in the orchestration of the workflow execution by allowing actors to be blocked and lazy. If an actor is blocked, the execution is not propagated to the upstream sub-workflow and if the actor is lazy, the execution is performed only if the actor’s inputs have not changed compared to its previous execution. This type of orchestration performs only the operations needed to produce the required result, executing the subset of the graph relevant to the output  [11]. 3.2. A middleware for parallel environments: SciFloware The choice of SciFloware. As stated in the user requirements, InfraPhenoGrid should be equipped with a system able to (i) hide the complexity of the computation and offer transparent access to data and tools for end-users, (ii) provide a flexible working environment by allowing several workflow systems to be used, (iii) be adaptable to pilot tasks both on Grid and Cloud infrastructures. Using and tuning such kind of systems remains a very difficult task. Our research groups have recently developed SciFloware, a generic lightweight middleware able to coordinate and pilot the tasks to be executed in a transparent way for the user. SciFloware is based on the Shared-data Overlay Network  [12] (SON) which follows a Software as a Service (SaaS) model, eliminating the need to install and maintain the software and allows users to run HPC programs through graphical interfaces (e.g., graphical interfaces of scientific workflow management systems). SciFloware has been chosen to be the InfraPhenoGrid middleware, because it was a system we are familiar with and it matched our demands on requirements. The technical features of SciFloware are described here after. Internal representation of workflows in SciFloware. SciFloware has been designed to allow interoperability of different workflow systems. In absence of standards to represent scientific workflows,3 SciFloware defines its own XML workflow specification to describe a master workflow. A master workflow is a meta-level workflow used to orchestrate and compose concrete workflows. Each workflow is run independently by different scientific workflow systems. As an example, in Fig. 6, the SciFloware master workflow consists of four steps, including steps and (sub-workflows of the master workflow) which are respectively executed by the X workflow system (for the a sub-workflow) and the OpenAlea workflow system (for the b sub-workflow). More precisely, SciFloware is responsible for (i) sending to workflow systems the execution of such two master sub-workflows with the right input data produced by the previous executed master workflow step, (ii) collecting output data generated at the end of each execution of the sub-workflows, and (iii) launching the execution of the last step of the master workflow with such collected data. Download : Download full-size image Fig. 6. SciFloware distributed middleware. While OpenAlea has been the first workflow system orchestrated by SciFloware (based on our user requirements), Galaxy  [7] and Taverna  [8] are currently under consideration (to play the role as “X workflow system” in Fig. 6). Algebraic expressions in SciFloware. SciFloware uses a relational data model and an algebraic language to represent data-intensive scientific workflows  [13]. Data flows are represented as relations and workflow nodes and activities as algebraic expressions. A relation is a set of tuples composed of basic attributes (e.g., int, float, string, file references). An algebraic expression consists of algebraic activities, additional operands, operators, input relations and output relations. It is comprised of a workflow, a program or an SQL expression, with input and output relation schemes. More precisely, SciFloware provides six algebraic operators: Map, SplitMap, Reduce, Filter, SRQuery and MRQuery. The semantics of these operators has been defined in  [13]. Software as a Service, communication with workflow systems. As previously stated, SciFloware is particularly modular, following the SAAS (“Software as a Service”) principle. SciFloware is a service-and-component-based distributed architecture and built from software components. Each component provides services to other components of the workflow. A service is a self-contained unit of functionality which exposes components through well-defined interfaces. SciFloware provides services that can be combined to build large distributed applications. In InfraPhenoGrid, SciFloware runs on a dedicated server and provides a registration service, where distributed workers can register themselves. Using a communication protocol, SciFloware distributes the computation among workers, with each worker running behind a dedicated server. The tech stack (e.g., authentification) is implemented using services and can easily be evolved further. More precisely, three main kinds of services are considered in SciFloware: algebraic operators, scientific workflow systems and the communication protocol between algebraic operators and workflow systems. SciFloware schedules the computation using algebraic operators. Services associated with these are managed by the SciFloware server. Each component has its own decentralized execution strategy, which allows to simply distribute the execution on several sites. A component type is associated with each algebraic operator. For example, the Map operator has an associated map type of component, with an input and output service for relations and a service to schedule activity among workers. As for workflow systems, each worker runs a service, running a workflow within a given workflow system. It receives a workflow description and input data IDs and returns the produced output data. On a Grid infrastructure, workers will run on different nodes, each one executing its own server to communicate with SciFloware. Eventually, a set of services have been defined to manage communication between SciFloware and different workflow systems. Using these, SciFloware can request the execution of a workflow on any workflow system server, or be notified at the end of the execution of an OpenAlea workflow. Other services manage database relationships and communication protocols. Fig. 7 illustrates a case where a component manages local task executions depending on a given algebraic operator. More precisely, in Fig. 7, the Map component distributes the computation among workers (OA servers, that is, OpenAlea servers) depending on its own scheduling policy. Download : Download full-size image Fig. 7. Distributed execution of a scientific workflow on the Grid with SciFloware. SciFloware allows new components to be added and instantiated dynamically to extend the middleware. SciFloware Architecture. The SciFloware architecture is composed of the following components (see Fig. 8): • Algebraic Operators. For each algebraic operator, a specific component type is associated, which can be instantiated several times during the execution of a given workflow. • Execution Manager. The Execution Manager takes in a workflow specification and instantiates the needed components (i.e. workflows or part-of workflows), such as the algebraic components. A message is sent to trigger execution of the first workflow component. The Execution Manager also manages and runs the available OpenAlea servers. At each registration of an instance of an OpenAlea server, a worker component is added to the list of available workers. • Data Manager. The Data Manager provides workers with access to the storage database. Download : Download full-size image Fig. 8. SciFloware architecture. Implementation of SciFloware. The implementation of SciFloware is based on the Shared-data Overlay Network (SON)  [12], written in JAVA, fully integrated into the Eclipse environment and implemented on top of OSGi.4 The communication protocol between SciFloware and scientific workflow systems being run on different workers use a REST (Representational State Transfer) interface. The RESTfull communication protocol is used to register new workers, exchange the workflow specification and the data identifiers stored on iRODS and start and stop the execution. Each service in SciFloware is described using description files similar to the Web Service Definition Language (WSDL). Each SciFloware component has an associated description file defining the required and provided services. SON is used for the internal composition of SciFloware components. SON allows to build an application following the SAAS model (Software as a Service) using a set of components that can be executed in a distributed way (e.g., Peer-to-Peer) on a Grid or on a Cloud infrastructure. The SON middleware allows to define new component types by specifying the services offered by each type. During execution it allows to dynamically combine different component instances and to manage the life cycle of these components (create, init, stop,…). Concerning the authorization framework, SciFloware uses OAuth2  [14] to enable safe registration of the OpenAlea servers to SciFloware. The OAuth2 flow used is the Resource Owner Password Credentials Grant flow.5 During the deployment of the OpenAlea server, the user provides its SciFloware’s username and password. At startup, each OpenAlea server requests an access token from SciFloware using login authentication. After registration, all the communication between SciFloware and OpenAlea is mediated through iRODS, whose access requires authentication based on certificates delivered by the French Grid Certification Authority. As for the Data Manager component, it has been extended to support iRODS. The connection with iRODS is established using the REST interface. iRODS is the focus of the next subsection. Packaging OpenAlea into a virtual environment. OpenAlea and all its dependencies have been built and packaged into a virtual environment  [15] on a virtual machine. The operating system (i.e., a scientific Linux version 6) of the virtual machine is the same as the one deployed on each worker of the Grid. The virtual environment is packed and stored on iRODS. When a worker is reserved by DIRAC, the bundle is uploaded locally and uncompressed. A shell script updates the environment variables and an OpenAlea server is launched. This method has been preferred to virtualization (e.g., vagrant or docker  [16]) for performance reasons and because all the workers have the same operating system. The size of the compressed bundle containing all the packages and their dependencies is 210 MB. The latency (or delay) due to the copy of the bundle from iRODS and its installation is less than 1 min, while each worker is deployed once for a maximum of 24 h. 3.3. Data management and provenance Data management with iRODS. As previously stated, iRODS (v3.3) is an open-source data system chosen by France-Grilles for its ability to provide a technology enabling data and policy virtualization for multiple and geographically separated users  [17]. iRODS federates distributed and heterogeneous data resources into a single logical file system and provides a modular interface to integrate new client-side applications. iRODS does not only allow the worker nodes of the grid infrastructure to access datasets but it provides end-users with access to data, through GUI, while enabling user to annotate such datasets with rich metadata. Both input data and the results of a scientific workflow computation associated with their provenance are stored on iRODS. This drastically reduces the volume of data to be transferred through SciFloware to launch a computation and retrieve its result (only the address of data in the central catalog has to be exchanged). We also implemented a communication protocol by file to bypass the limitations enforced by the Grid on network communications. Provenance Layer. One of the major aims of our infrastructure is to be reproducibility-friendly   [18]. The starting point to make a scientific result reproducible is to keep track of the exact datasets and exact tools (including parameter settings) used to obtain a given data item. To answer such needs a Provenance Layer has been designed and implemented in our infrastructure. A layer currently has two main components: a provenance model, based on the W3C standard PROV  [19] and a notebook generator, able to automatically generate notebooks from some workflow executions. The Provenance layer is flexible in the sense that new modules taking in PROV data and making it possible to visualize and analyze provenance information can be integrated. While iRODS is in charge of concretely managing data, the provenance module reconstructs (by querying iRODS) the history of each data item. In other words, the provenance module is able to provide for each produced data item the exact series of workflow node executions, including the datasets used as input of such nodes. Such provenance information is represented according to the W3C PROV standard  [19]. Both prospective (the workflow specification) and retrospective (execution and datasets) provenance are stored. Notebooks generator. The second component of the provenance layer aims at helping the PhenoArch users understand the results they obtained by allowing them to visualize and interact with the main steps of the process used to produce such results. In other words, we want PhenoArch users to be able to interact and visualize (part of) the execution of some workflows to follow how some final results have been obtained. The current solution used by an increasing number of scientists to answer such kinds of need is to (manually) design notebooks using the Jupyter/IPython Notebook web application  [2]. From a developer point-of-view, a notebook is a JSON document (convertible into a number of open standard output formats including HTML, LaTeX, PDF … and which can be designed using a web-base user interface) containing an ordered list of input/output cells with iPython code able to generate text, mathematics, plots and rich media (images, video…). From an end-user point-of-view, a notebook is a rich web page, where code, text, mathematics, plots and multimedia (images, video…) can be displayed and interacted with. In particular any user can modify the input of a notebook cell to observe the impact of this change on the objects displayed (e.g., plots). In InfraPhenoGrid, we implement a notebook generator where a set of OpenAlea workflow executions are automatically converted into Jupyter/ IPython notebooks. More precisely, the generator (i) converts each OpenAlea workflow actor (natively coded in Python) into an IPython cell and (ii) queries iRODS to extract automatically information on input and output datasets respectively used and produced by the execution of each OpenAlea actor. Users can then visualize and interact with data used and produced during an execution. A concrete example of generated notebooks is provided in the next section (Results). 4. Results In this section, we present the benefits of using InfraPhenoGrid in Plant Phenotyping by showing how the various components of our infrastructure make it possible to perform complex experiments on huge datasets. Designing workflow. Fig. 9 provides an example of a workflow designed and executed by our end-users to estimate the growth of a plant. Such a workflow starts with querying iRODS to get input data (“import image” node). In this concrete example, the 1407th individual plant of genotype A310 has been considered. As a consequence, “1407” and “A310” appears in the name of the actors of the workflow. The import image node returns a time series of images. Each acquisition, taken every two days, records pictures of the plant at various angles by rotating the plant. The node keys returns the order sets of the dates, while values returns a list of images corresponding to the different side views of the growing plant, along time. The map node applies the sub-workflow illustrated on Part B of Fig. 9 on each set of images of the time series. The result is a list of estimated areas of the individual plant over time. Download : Download full-size image Fig. 9. Workflow. Part A represents the main workflow while Part B is a sub-workflow corresponding to the node “area estimation” of workflow A. Part C depicts one of the set of real images of a plant of a given genotype obtained from the imaging system of the phenoarch platform. D represents the binary image. E plots the growth of the plant. The node represents a dataflow variable and abstracts the sub-workflow (part B) as a function. The sub-workflow B implements a mean-shift algorithm. It receives the multiple views of the plant at a given time. All these views are combined (node cv_mean) using an OpenCV algorithm to separate the plant from the cabin background in the image. The macro_side_binarization node subtracts the cabin background of each image and the “green” pixels are counted (countNonZero). Again, the map algebraic operator is used to run the same treatment on a set of images. Note that the mean shift algorithm is only computed once due to lazy evaluation. The binary image (Part D) is produced by one execution of the macro_side_binarization for each lateral perspective image using an optimized HSV segmentation algorithm. Finally, the plant area node receives as input a number of “green pixels” for each plant and estimates, using a linear model, the plant area along its growth and development. The PyLabScatter node plots the graph of the growth of the plant (Part E) using the MatplotLib library  [20] wrapped within OpenAlea. Exploring alternative methods. OpenAlea is modular and allows users to easily test various alternative methods. In particular, several variations of sub-workflow B can be designed, resulting in the use of several Binarization algorithms (as mentioned in Table 1). The results obtained by such variations can then be compared (mainly qualitatively) by the user. Table 1. Execution time of the workflow illustrated in Fig. 9 with variations of sub-workflow B on one plant measured during one seasonal growth (5 weeks). This experiment gathered 124 images. Binarization algorithms Time (s) Adaptive threshold  [21] 62.1 HSV  [22] 85.7 Mean shift  [23] 73.9 Exploiting the Grid. Execution times of Binarization algorithms reported in Table 1 are related to one single plant of one single genotype for which 13 images have been collected during one month. The challenge then lies in considering 300 genotypes, with 1900 plants in each genotype. Per day, a PhenoArch platform produces 20 000 images of 50 M, equivalent to 1To/day, 5To/week and 250 To/year. Without any distributed infrastructure, processing these huge amounts of data would take between 409 days and 565 days (depending on the strategy followed for the sub-workflow B). For this project, France-Grilles provides us with 32 000 logical process units. With only a subset of this resource (2%), the whole computation, scheduled by SciFloware, can be performed in less than 12 h (night time). Exploiting Provenance. During any execution, provenance data, that is, all the data items processed and produced (including intermediate and final images) are stored on iRODS. Based on this provenance information, IPython notebooks are automatically generated for each individual plant either at a given time, or for the entire growth period, or for a given genotype. Each cell of the notebook contains the script of the workflow node executed. The input/output data are direct references to the data produced and stored in iRODS. Very interestingly, users can upload a given notebook (see Fig. 10) with the corresponding data, and modify the execution parameters directly on their computer to visualize the impact of such modifications and better understand their results. Thus, biologists can explore the obtained results a posteriori to discover for instance why some outliers on the “growth curve” (see Fig. 9(E)) have appeared. Reasons for this situation may actually be numerous, including problems occurring during acquisition (e.g., the plant may have fallen…), limitation of the method used (bugs in the implementation…) or wrong set of parameters. Download : Download full-size image Fig. 10. Notebook generated from the provenance of the execution of the workflow illustrated in Fig. 9(B). Each node corresponds to a cell containing the equivalent Python function. Values flowing through edges have a name ‘edge’ with a value captured by the provenance module and stored into iRODS. The two images displayed correspond to the plant before and after its binarization. The total number of pixels of the plant is 87 489, which is the last cell value. 5. Discussion In the last ten years, several approaches have been designed to distribute scientific workflows on parallel environments. Survey papers and books include  [24], [25], [26], [27]. While cloud computing is increasingly used to manage Life Science data, our project involves large numbers of production sites and collaborating users, and such numbers are growing over time, making Grid technologies particularly well-suited  [28]. More precisely, we wrap-up and discuss the four key aspects of our approach. First of all, the infrastructure we introduce in this paper works on a production environment with real and huge data sets produced on a daily basis. In Plant phenotyping, which is a field of growing importance in the context of climate change and food security  [29], [30], [31], complex datasets produced by high-throughput image based phenotyping platforms need to be combined with highly heterogeneous data. In particular, compared to classical bioinformatics (largely driven by molecular biology), the need in plant phenomics is on modeling, simulation, designing statistical approaches, and performing complex image analysis. This poses new challenges in data integration and calls for new kinds of analytical tools  [32], [33]. Second, the workflow system we use is well-established in the Plant community. It is well-known by our first generation users, and has very specific features, making it possible to perform both data analysis and simulation (retro-action loops, modeling) while allowing visualization of complex data. As shown previously in  [10], [6], OpenAlea belongs to the family of functional workflow systems (such as  [9], [34], [35], [36]). It provides a unique solution, which is able to extend the dataflow model of computation by introducing higher-order language constructs in a visual programming environment, thus allowing to design highly expressive workflows in a fully uniform way. Third, while the context of this work is data intensive and involves very complex experiments on huge datasets, we use a middleware approach to make the distribution and coordination of jobs transparent to the user. SciFloware is data-driven  [37] in the sense that its internal workflow language clearly separates the definition of data to be processed from the graph of activities to be applied to the data. This separation is particularly suited to scientific workflows where the same experiment has to be reused for analyzing different datasets without any change. Optimization in SciFloware focuses on two main aspects: it uses asynchronous messages to execute workflows on a distributed infrastructure such as Grid or Cloud  [37], [38]. Furthermore, while it uses generally coarse grain parallelism, it is able to exploit the fact that some workflow actors may be algebraic operators (i.e., some actors are not black-boxes) to optimize the workflow execution. Additionally, basing the SciFloware implementation on the middleware SON  [12] which follows the SAAS concept (Software as a Service) makes it very modular and flexible. Last but not least, we have developed a large series of reproducibility-friendly features. Our approach allows users to share their experiments in the spirit of  [39], understand and compare their results  [40] and possibly refine their analysis process to augment quality of their data sets. To do so, we have followed the recommendations and current standards on provenance  [41], [19] and introduced a generator of IPython/Jupyter notebooks  [2]. 6. Conclusion High-throughput phenotyping platforms provide a unique and particularly novel kind of solution to study the behavior of plants in context of climate change and food security. At the same time, size and complexity of datasets produced by such platforms are huge, constantly augmenting and the experiments to be performed are becoming increasingly complex, posing particularly novel challenges. This paper introduces the InfraPhenoGrid infrastructure we designed and deployed to efficiently manage the datasets produced by the PhenoArch plant phenomics platform in the context of the Phenome Project. Our solution consists in deploying scientific workflows on a Grid (France-Grilles) using a middleware to pilot workflow executions. InfraPhenoGrid is user-friendly in the sense that despite the intrinsic complexity of the infrastructure, running scientific workflows and understanding results obtained (using provenance information) is kept as simple as possible for end-users. Future work includes considering automatic transformation of scripts designed by scientists into OpenAlea scientific workflows to augment the size of the workflow library. We are also working on techniques to augment the reuse of workflows (and scripts) by guiding the design of such experiments  [42], [43]. Another very important point we are actively working on is the reproducibility of scientific results. From the data point-of-view, one of the main challenges lies in finding the right level of granularity at which visualizing and, to some extent, recording the data  [44]. Currently, the complete datasets are kept while we investigate several techniques (inspired from  [42]) to reduce the amount of data stored while ensuring a good level of reproducibility. From the environment point-of-view, we are currently able to consider virtual machine techniques to reproduce a given experiment in the exact same conditions (same OS, software versions…). Ongoing work includes considering techniques to re-execute experiments in new environments, where upgraded versions of software are considered  [45]. Acknowledgments The authors acknowledge the support of France-Grilles for providing computing resources on the French National Grid Infrastructure. This work has been performed in the context of the IBC (Institute of Computational Biology) in Montpellier, France. MM has received the support of the EU in the framework of the Marie-Curie FP7 COFUND People Programme, through the award of an AgreenSkills fellowship under Grant agreement No. 267196. Authors would like to thank Julien Coste (from INRIA) for his help in the OpenAlea server. References [1] S. Cohen-Boulakia, U. Leser Next generation data integration for life sciences Proc. of the 25th Int. Conf. on Data Engineering, ICDE, IEEE (2011), pp. 1366-1369 View in ScopusGoogle Scholar [2] H. Shen Interactive notebooks: Sharing the code Nature, 515 (2014), pp. 151-152 CrossRefView in ScopusGoogle Scholar [3] M. Ragan-Kelley, F. Perez, B. Granger, T. Kluyver, P. Ivanov, J. Frederic, M. Bussonier, The jupyter/ipython architecture: a unified view of computational research, from interactive exploration to communication and publication, in: AGU Fall Meeting Abstracts, Vol. 1, p. 07. Google Scholar [4] A. Tsaregorodtsev, M. Bargiotti, N. Brook, A.C. Ramo, G. Castellani, P. Charpentier, C. Cioffi, J. Closier, R.G. Diaz, G. Kuznetsov, Y.Y. Li, R. Nandakumar, S. Paterson, R. Santinelli, A.C. Smith, M.S. Miguelez, S.G. Jimenez Dirac: a community grid solution J. Phys. Conf. Ser., 119 (2008) Google Scholar [5] M. Hedges, A. Hasan, T. Blanke Management and preservation of research data with irods Proceedings of the ACM First Workshop on CyberInfrastructure: Information Management in eScience, ACM (2007), pp. 17-22 CrossRefView in ScopusGoogle Scholar [6] C. Pradal, S. Dufour-Kowalski, F. Boudon, C. Fournier, C. Godin Openalea: a visual programming and component-based software platform for plant modelling Funct. Plant Biol., 35 (2008), pp. 751-760 View in ScopusGoogle Scholar [7] J. Goecks, A. Nekrutenko, J. Taylor Galaxy: a comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences Genome Biol., 11 (2010), p. R86 CrossRefView in ScopusGoogle Scholar [8] P. Missier, S. Soiland-Reyes, S. Owen, W. Tan, A. Nenadic, I. Dunlop, A. Williams, T. Oinn, C. Goble, Taverna, reloaded, in: M. Gertz, T. Hey, B. Ludaescher (Eds.), Proceedings of the 22nd International Conference on Scientific and Statistical Database Management, SS-DBM, Heidelberg, Germany. Google Scholar [9] B. Ludäscher, I. Altintas, On providing declarative design and programming constructs for scientific workflows based on process networks, 2003. Google Scholar [10] C. Pradal, C. Fournier, P. Valduriez, S. Cohen-Boulakia Openalea: scientific workflows combining data analysis and simulation Proceedings of the 27th International Conference on Scientific and Statistical Database Management, SSDBM, ACM (2015), p. 11 Google Scholar [11] V. Curcin, M. Ghanem, Scientific workflow systems-can one size fit all? in: Proc. of Biomedical Engineering Conference, pp. 1–9. Google Scholar [12] A.A. Lahcen, D. Parigot A lightweight middleware for developing p2p applications with component and service-based principles Computational Science and Engineering, CSE, 2012 IEEE 15th International Conference on, IEEE (2012), pp. 9-16 View in ScopusGoogle Scholar [13] E. Ogasawara, J. Dias, D. Oliveira, F. Porto, P. Valduriez, M. Mattoso An algebraic approach for data-centric scientific workflows Proc. VLDB Endow., 4 (2011), pp. 1328-1339 CrossRefView in ScopusGoogle Scholar [14] D. Hardt, The oauth 2.0 authorization framework, 2012. Google Scholar [15] P. Guo Cde: A tool for creating portable experimental software packages Comput. Sci. Eng., 14 (2012), pp. 32-35 View in ScopusGoogle Scholar [16] D. Merkel Docker: lightweight linux containers for consistent development and deployment Linux J., 2014 (2014), p. 2 Google Scholar [17] A. Rajasekar, R. Moore, C.-y. Hou, C.A. Lee, R. Marciano, A. de Torcy, M. Wan, W. Schroeder, S.-Y. Chen, L. Gilbert, et al. irods primer: integrated rule-oriented data system Synth. Lect. Inform. Concepts Retr. Serv., 2 (2010), pp. 1-143 Google Scholar [18] G. Sandve, A. Nekrutenko, J. Taylor, E. Hovig Ten simple rules for reproducible computational research Plos Comput. Biol., 9 (2013), p. e1003285 CrossRefView in ScopusGoogle Scholar [19] L. Moreau, P. Missier, Prov-dm: The prov data model, 2013. Google Scholar [20] J.D. Hunter Matplotlib: A 2d graphics environment Comput. Sci. Eng., 9 (2007), pp. 90-95 View in ScopusGoogle Scholar [21] E. Navon, O. Miller, A. Averbuch Color image segmentation based on adaptive local thresholds Image Vis. Comput., 23 (2005), pp. 69-85 View PDFView articleView in ScopusGoogle Scholar [22] S. Sural, G. Qian, S. Pramanik, Segmentation and histogram generation using the hsv color space for image retrieval, in: Image Processing. 2002. Proceedings. 2002 International Conference on, Vol. 2, IEEE, pp. I589-592. Google Scholar [23] D. Comaniciu, P. Meer Mean shift: A robust approach toward feature space analysis IEEE Trans. Pattern Anal. Mach. Intell., 24 (2002), pp. 603-619 View in ScopusGoogle Scholar [24] J. Liu, E. Pacitti, P. Valduriez, M. Mattoso A survey of data-intensive scientific workflow management J. Grid Comput. (2015), pp. 1-37 View in ScopusGoogle Scholar [25] I. Foster, Y. Zhao, I. Raicu, S. Lu Cloud computing and grid computing 360-degree compared Grid Computing Environments Workshop, GCE’08, IEEE (2008), pp. 1-10 CrossRefGoogle Scholar [26] J. Yu, R. Buyya A taxonomy of workflow management systems for grid computing J. Grid Comput., 3 (2005), pp. 171-200 CrossRefView in ScopusGoogle Scholar [27] G.C. Fox, D. Gannon Workflow in Grid Systems Wiley Interscience (2006) Google Scholar [28] M.T. Özsu, P. Valduriez Principles of Distributed Database Systems Springer Science & Business Media (2011) Google Scholar [29] F. Tardieu, R. Tuberosa Dissection and modelling of abiotic stress tolerance in plants Curr. Opinion Plant Biol,, 13 (2010), pp. 206-212 View PDFView articleView in ScopusGoogle Scholar [30] R.T. Furbank, M. Tester Phenomics–technologies to relieve the phenotyping bottleneck Trends Plant Sci., 16 (2011), pp. 635-644 View PDFView articleView in ScopusGoogle Scholar [31] D. Houle, D.R. Govindaraju, S. Omholt Phenomics: the next challenge Nature Rev. Genet., 11 (2010), pp. 855-866 CrossRefView in ScopusGoogle Scholar [32] F. Fiorani, U. Schurr Future scenarios for plant phenotyping Annu. Rev. Plant Biol., 64 (2013), pp. 267-291 CrossRefView in ScopusGoogle Scholar [33] S. Dhondt, N. Wuyts, D. Inzé Cell to whole-plant phenotyping: the best is yet to come Trends Plant Sci., 18 (2013), pp. 428-439 View PDFView articleView in ScopusGoogle Scholar [34] D. Turi, P. Missier, C. Goble, D. De Roure, T. Oinn Taverna workflows: Syntax and semantics e-Science and Grid Computing, IEEE International Conference on, IEEE (2007), pp. 441-448 CrossRefView in ScopusGoogle Scholar [35] P.M. Kelly, P.D. Coddington, A.L. Wendelborn Lambda calculus as a workflow model Concurr. Comput.: Pract. Exper., 21 (2009), pp. 1999-2017 CrossRefView in ScopusGoogle Scholar [36] J. Brandt, M. Bux, U. Leser, A functional language for large scale scientific data analysis, in: BeyongMR, ICDT/EDBT Workshop. Google Scholar [37] J. Montagnat, B. Isnard, T. Glatard, K. Maheshwari, M.B. Fornarino A data-driven workflow language for grids based on array programming principles Proceedings of the 4th Workshop on Workflows in Support of Large-Scale Science, ACM (2009), p. 7 Google Scholar [38] D. Rogers, I. Harvey, T. Truong Huu, K. Evans, T. Glatard, I. Kallel, I. Taylor, J. Montagnat, A. Jones, A. Harrison Bundle and pool architecture for multi-language, robust, scalable workflow executions J. Grid Comput. (JOGC), 11 (2013), pp. 457-480 CrossRefView in ScopusGoogle Scholar [39] S. Cohen-Boulakia, U. Leser Search, adapt, and reuse: the future of scientific workflows ACM SIGMOD Rec., 40 (2011), pp. 6-16 CrossRefView in ScopusGoogle Scholar [40] Z. Bao, S. Cohen-Boulakia, S.B. Davidson, A. Eyal, S. Khanna Differencing provenance in scientific workflows Data Engineering, ICDE’09. IEEE 25th International Conference on, IEEE (2009), pp. 808-819 View in ScopusGoogle Scholar [41] P. Groth, M. Luck, L. Moreau A protocol for recording provenance in service-oriented grids Principles of Distributed Systems, Springer (2005), pp. 124-139 CrossRefView in ScopusGoogle Scholar [42] O. Biton, S. Cohen-Boulakia, S.B. Davidson, C.S. Hara, Querying and managing provenance through user views in scientific workflows, in: Data Engineering, 2008. ICDE 2008. IEEE 24th International Conference on, IEEE, pp. 1072–1081. Google Scholar [43] S. Cohen-Boulakia, J. Chen, P. Missier, C. Goble, A. Williams, C. Froidevaux Distilling structure in Taverna scientific workflows: a refactoring approach BMC Bioinformatics, 15 (2014), p. S12 CrossRefGoogle Scholar [44] A. Chapman, H. Jagadish Issues in building practical provenance systems IEEE Data Eng. Bull., 30 (2007), pp. 38-43 View in ScopusGoogle Scholar [45] F.S. Chirigati, D. Shasha, J. Freire, Reprozip: Using provenance to support computational reproducibility., in: TaPP, International Workshop on Theory and Practice of Provenance, 2013. Google Scholar Cited by (19) Developing and reusing bioinformatics data analysis pipelines using scientific workflow systems 2023, Computational and Structural Biotechnology Journal Show abstract Cache-aware scheduling of scientific workflows in a multisite cloud 2021, Future Generation Computer Systems Citation Excerpt : Another important benefit of caching intermediate data is to make it easy for users to share it with other research teams, thus fostering new analyses at low cost. Caching has been supported by some workflow systems, e.g., Kepler [12], VisTrails [13] and OpenAlea [14]. In [15], we proposed an adaptive caching method for OpenAlea that automatically determines the most suited intermediate data to cache, but only for a single site. Show abstract Modern imaging techniques in plant nutrition analysis: A review 2020, Computers and Electronics in Agriculture Show abstract What is cost-efficient phenotyping? Optimizing costs for different scenarios 2019, Plant Science Citation Excerpt : This requires information systems capable of collecting, managing, and presenting thousands of data points and images collected in multiple experiments, together with necessary metadata (FAIR standard: findable, accessible, interoperable and reusable). Such information systems are based on elaborate protocols to describe content and format of phenotypic information [56,72], as well as a standardized description of all involved objects (i.e. plants, organs, sensors, phenotyping facilities) via ontologies [73,74]. The cost for elaborating such information systems involves tens of person-months of computer scientists. Show abstract Data synthesis methods for semantic segmentation in agriculture: A Capsicum annuum dataset 2018, Computers and Electronics in Agriculture Citation Excerpt : Previous work on methods for plant architecture modelling have been also successful for synthetic plant image generation. For example, OpenAlea (Pradal et al., 2015, 2017) is able to generate anatomical and functional plant models and furthermore can be used to simulate images with a virtual camera. Other approaches such as ElonSim (Benoit et al., 2014) provide a simulator of plant growth, specifically root systems, and a simulator of the image acquisition to generate synthetic images including ground truth. Show abstract Plant Phenomics, From Sensors to Knowledge 2017, Current Biology Citation Excerpt : This also requires keeping track of all operations, including parameters, used in analyses that produce an elaborate result from raw data. Such scientific workflows are being developed [110], thereby allowing any user to perform the same analysis and obtain the same results as those published. Finally, these systems help organise data to facilitate genetic analyses. Show abstract View all citing articles on Scopus Christophe Pradal is a researcher at CIRAD (The French agricultural research and international cooperation organization working for the sustainable development of tropical and Mediterranean regions). He is a member of the VirtualPlants Inria team. His research interest includes computer graphics and geometrical modeling, multiscale data-structures and algorithms, component-based architecture for plant modeling, and Scientific Workflows. He is the project leader of the OpenAlea scientific workflow system. He has been involved in several International projects on designing methods for complex plant forms, reconstruction of plant shape, study of light interception by trees, and design of functional-structural plant model of trees. Simon Artzet is a software engineer at INRA (LEPSE) and member of VirtualPlants team. He holds a Master degree from the EPITA French Engineering School. He is part of the development team of OpenAlea and work in particular on image processing workflows in the context of the Phenome project. Jerome Chopard is a researcher in computational biology currently working at INRA as part of the OpenAlea group of active developers. He holds a degree from the Ecole Polytechnique and a Master degree in Biology of Evolution and Ecology. He worked at CIRAD, INRA and Inria and spent three years in the Center of Excellence for Climate Change Woodland and Forest Health at the University of Western Australia. He has a long-term experience working in multi-disciplinary groups. His research interests include formalizing, designing and implementing biological models and processes using techniques extracted from physics and mathematics. Dimitri Dupuis is an engineer in computer science working at Inria (Zenith team). He holds a Master degree in Computer Science from the University of Montpellier. He has actively worked on the design and implementation of the Scifloware middleware. His skills include C++ programming and design and implementation of NoSQL and relational databases. Christian Fournier is a Senior Research Engineer at INRA (LEPSE) and a (part time) member of the Inria VirtualPlants team. He is part of the active developers of OpenAlea and has designed a very large number of workflows to analyze plants datasets in particular in the context of the Phenome project. His interests lie in designing modular, flexible and optimized scientific workflows and designing functional-structural models for plants. Michael Mielewczick is a postdoctoral researcher at the Imperial College London, previously at INRA. He obtained a Diploma in Biology from Heinrich-Heine-University Düsseldorf, Germany, in 2007. He obtained his Ph.D. at ETH Zürich, Institute of Agricultural Sciences, Switzerland. His research interests include high-throughput and high-resolution monitoring by using computer-assisted image-based phenotyping to investigate the influence of environment effects and metabolism on plant growth and architecture, the optimization of image-acquisition, and processing and analysis in the framework of image-based phenotyping platforms. Vincent Negre is an engineer and database administrator at INRA. His interest lies in the development of database infrastructure and ontologies for plant data sets. Pascal Neveu is Senior Research Engineer at INRA, he is Director of Mistea Laboratory at Montpellier SupAgro-INRA. He is the head of CATI CODEX (a French center dedicated to data and knowledge management for plant genomics and genetics data). He was leader of the Workpackage Data management and Knowledge Representation for CAFE (Computer-Aided Food processes for control Engineering) European Project. He teaches computer sciences for statistical and numerical computing (R, Scilab, etc.) to master students and database design, XML and Information management in schools of agricultural engineering. His research interests include knowledge representation, ontologies and semantics networks, integration system, data management and analysis. Didier Parigot is a researcher at INRIA Sophia Antipolis in the Zenith team. He received his Ph.D. in Computer Science from Universite Paris-Sud in 1988 and his Habilitation to conduct research in 2003. His research interests include object-oriented languages and (functional) programming, services-oriented architecture, middleware in parallel environments. He has participated to a large number of projects both involving academics and industry. Patrick Valduriez is a senior researcher at Inria, heading the Zenith team in Montpellier. He has been a professor of Computer Science at University Paris 6 and a researcher at Microelectronics and Computer Technology Corp. in Austin, Texas. He received his Ph.D. degree and Doctorat d’Etat in computer science from University Paris 6 in 1981 and 1985, respectively. His research focuses on data management in large-scale distributed and parallel systems (P2P, cluster, grid, cloud), in particular, scientific data management. He has authored and co-authored over 250 technical papers and several textbooks. He was the recipient of the 1993 IBM scientific prize in CS in France. He obtained the best paper award at VLDB00. He was awarded the 2014 Inria–Académie des Sciences–Dassault Systems Innovation Prize. He is a Fellow of the ACM. Sarah Cohen-Boulakia is an Associate Professor at the Laboratoire de Recherche en Informatique at Universite Paris-Sud, currently on leave in the Inria teams Zenith and VirtualPlants in Montpellier. She has been working for ten years in multi-disciplinary groups involving computer scientists and biologists of various domains. She received her Ph.D. in Computer Science and habilitation to conduct research from the Universite Paris-Sud in 2005 and 2015 respectively. She spent two-years as a postdoctoral researcher at the University of Pennsylvania, USA. Dr. Cohen-Boulakia’s research interests include provenance and design of scientific workflows, integration, querying and ranking in the context of biological and biomedical databases. She actively collaborates with several major international groups in these domains. 1 https://www6.montpellier.inra.fr/lepse/M3P/plateforme-PHENOARCH. 2 See for example the following web sites: http://www.stse-software.org and https://www.cpib.ac.uk/research/themes/digital-plant. 3 The Common Workflow Language (CWL) Initiative may become a solution in the future but it has not reached the right level of maturity yet. 4 The OSGi specification describes a modular system and a service platform for the Java programming language that implements a complete and dynamic component model. 5 RFC 6749—http://tools.ietf.org/html/rfc6749. View Abstract © 2016 Elsevier B.V. All rights reserved. Recommended articles Spinorial discrete symmetries and adjoint structures Physics Letters A, Volume 452, 2022, Article 128470 J.M. Hoff da Silva, …, N.C.R. Quinquiolo View PDF From genotype to phenotype: augmenting deep learning with networks and systems biology Current Opinion in Systems Biology, Volume 15, 2019, pp. 68-73 Vahid H. Gazestani, Nathan E. Lewis View PDF Analysis of a motion planning problem for sweet-pepper harvesting in a dense obstacle environment Biosystems Engineering, Volume 146, 2016, pp. 85-97 C. Wouter Bac, …, Eldert J. van Henten View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 19 Captures Readers: 68 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply.

Paper 4:
- APA Citation: None
  Main Objective: The primary goal of this study is to provide an in-depth review of the current state and future potential of real-time, automated irrigation management systems. It aims to highlight the challenges and opportunities in leveraging data quality and preprocessing, containerization strategies for scalable and autonomous deployment, machine learning models for real-time data processing and inference, and the significance of interoperability and standardization in such systems.
  Study Location: None
  Data Sources: None
  Technologies Used: None
  Key Findings: None
  Extract 1: Real-time automated irrigation management systems can contribute to the efficient use of water resources and enhance agricultural productivity by leveraging data from IoT sensors and applying advanced analytics to optimize irrigation schedules. However, the effective realization of such systems requires addressing challenges related to data quality and preprocessing, scalable and autonomous deployment, and real-time data processing and inference.
  Extract 2: This paper aims to provide an up-to-date review of the current state and future potential of real-time, automated irrigation management systems with a focus on the following aspects: data quality and preprocessing, containerization strategies for scalable and autonomous deployment, machine learning (ML) models for real-time data processing and inference, and the importance of interoperability and standardization for enabling seamless integration of components within the automated irrigation management pipeline.
  Limitations: The study does not provide specific case studies or experimental results to demonstrate the effectiveness of the proposed approaches in real-world scenarios. Limited scope: The review focuses primarily on technical aspects of real-time, automated irrigation management systems, and does not delve deeply into other relevant considerations such as economic viability, social implications, or environmental impact.
  Relevance Evaluation: The paper is extremely relevant to the specific point mentioned in the outline point and review. It provides a comprehensive overview of the current state and future potential of real-time, automated irrigation management systems, with a particular focus on data quality and preprocessing, containerization strategies for scalable and autonomous deployment, and ML models for real-time data processing and inference. The study also emphasizes the significance of interoperability and standardization for seamless integration of components within the automated irrigation management pipeline. Furthermore, it identifies existing and emerging standards and their applicability to real-time irrigation management systems.
  Relevance Score: 1.0
  Inline Citation: None
  Explanation: This study provides an up-to-date review of the current and future potential of real-time, automated irrigation management systems. It focuses on the specific area of data quality and preprocessing in the cloud, containerization strategies for scalable and autonomous deployment, and machine learning (ML) models for real-time data processing and inference. The authors highlight the importance of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline, and identify existing and emerging standards and their applicability to real-time irrigation management systems.

 Full Text: >
Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Highlights Abstract Keywords 1. Introduction 2. Planning 3. Conduction 4. Results 5. Recent works 6. Discussion 7. Conclusions Acknowledgements References Show full outline Cited by (388) Figures (13) Show 7 more figures Tables (5) Table 1 Table 2 Table 3 Table 4 Table 5 Computers and Electronics in Agriculture Volume 142, Part A, November 2017, Pages 283-297 Review Review of IoT applications in agro-industrial and environmental fields Author links open overlay panel Jesús Martín Talavera a, Luis Eduardo Tobón b, Jairo Alejandro Gómez b, María Alejandra Culman a, Juan Manuel Aranda c, Diana Teresa Parra a, Luis Alfredo Quiroz b, Adolfo Hoyos b, Luis Ernesto Garreta b Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.compag.2017.09.015 Get rights and content Highlights • Systematic literature review of IoT applications in agro-industry and environment during 2006–2016. • Clustering of IoT applications into four domains: monitoring, control, prediction, and logistics. • Visualization of key technologies used to develop the IoT applications. • Discussion of trends and open challenges. • Proposal of an IoT architecture for agro-industrial and environmental applications based on the research findings. Abstract This paper reviews agro-industrial and environmental applications that are using Internet of Things (IoT). It is motivated by the need to identify application areas, trends, architectures and open challenges in these two fields. The underlying survey was developed following a systematic literature review using academic documents written in English and published in peer-reviewed venues from 2006 to 2016. Selected references were clustered into four application domains corresponding to: monitoring, control, logistics, and prediction. Implementation-specific details from each selected reference were compiled to create usage distributions of sensors, actuators, power sources, edge computing modules, communication technologies, storage solutions, and visualization strategies. Finally, the results from the review were compiled into an IoT architecture that represents a wide range of current solutions in agro-industrial and environmental fields. Previous article in issue Next article in issue Keywords Internet of thingsIoTAgro-industryEnvironmental monitoringSystematic literature review 1. Introduction The widespread of Internet in the last two decades brought countless benefits to citizens and organizations around the world. Arguably the most important benefit was the ability to consume and produce data and services in real time. Recently, the Internet of Things is promising to bring the same benefits to everyday objects, giving us a way to extend our perception and our ability to modify the environment around us. In this context, agro-industrial and environmental fields are ideal candidates for the deployment of IoT solutions because they occur in wide areas that need to be continuously monitored and controlled. At the same time, IoT opens new opportunities beyond ground floor automation when the collected data are used to feed machine learning algorithms to provide predictions (Saville et al., 2015), easing decision planning and decision making for owners, managers, and policy makers. IoT can be used at different levels in the agro-industrial production chain (Medela et al., 2013). It can help to evaluate field variables such as soil state, atmospheric conditions, and biomass of plants or animals. It can also be used to assess and control variables such as temperature, humidity, vibration, and shock during the product transport (Pang et al., 2015). It can be used to monitor and predict the product state and its demand on shelves or inside refrigerators. In addition, it can provide information to the final user/consumer about the origin and properties of the product. The IoT applied to the agro-industry can contribute to create an informed, connected, developed and adaptable rural community. Under the IoT paradigm, low-cost electronic devices can improve human interaction with the physical world, and the computing power and software available on the Internet can provide valuable analytics. In summary, IoT can be an important tool in the years to come for people interacting within an agro-industrial system: suppliers, farmers, technicians, distributors, business men, consumers, and government representatives. IoT can be incorporated into environmental applications to produce dense and real-time maps of air and water pollution, noise level (Torres-Ruiz et al., 2016, Hachem et al., 2015), temperature, and harmful radiation among others. It can be used to collect and store environmental records, check the compliance of environmental variables with local policies, trigger alerts, or send recommendation messages to citizens and authorities (Liu et al., 2013). Once the data reach the cloud, governments can feed predictive models to forecast environmental variables, and identify and track pollution sources over time and space, ultimately leading to faster and better decisions to ensure a safe and healthy environment for all citizens. Based on the potential of IoT applications in agro-industrial and environmental fields described in the previous paragraphs, this paper aims to identify the current state of solutions in these fields, as well as the trends, architectures, technologies and open challenges. This paper uses a Systematic Literature Review (SLR) based on a methodology proposed by Kitchenham and Charters (2007), in order to make it unbiased in terms of information selection, processing, and presentation of results. The paper is structured as follows. Sections 2 Planning, 3 Conduction, 4 Results describe the stages of planning, conduction, and results of the SLR. Section 5 outlines some recent works that were published online after the SLR was concluded. Section 6 includes a discussion of the obtained results, and Section 7 presents the conclusions from this study. 2. Planning During this stage of the SLR, the protocol was defined. This included: research questions, search strategies, selection criteria, data mining and synthesis methodologies. For this study, the two research questions considered were: 1. What are the main technological solutions of the Internet of Things in agro-industrial and environmental fields? 2. Which infrastructure and technology are using the main solutions of IoT in agro-industrial and environmental fields? To collect information, authors performed an Internet search using various academic digital libraries and search engines. Obtained results were manually compiled in order to select the best information sources to answer the two research questions. After analyzing the results, digital libraries and search engines described in Table 1 were chosen based on their scientific and technical content, as well as their close relationship to areas of knowledge associated with the objective of this paper. Table 1. Information sources used for the search phase. Source Type URL IEEE Xplore Digital Library http://ieeexplore.ieee.org/Xplore/home.jsp Science Direct Digital Library http://www.sciencedirect.com/ ACM Digital Library Digital Library http://dl.acm.org/dl.cfm Citeseer library Digital Library http://citeseer.ist.psu.edu/advanced_search Sensors Digital Library http://www.mdpi.com/journal/sensors Scopus Search Engine http://www.scopus.com/ Microsoft Academic Search Search Engine http://academic.research.microsoft.com/ Microsoft Academic Search Engine https://academic.microsoft.com/ Google Scholar Search Engine https://scholar.google.com/ The next step was to define search terms and a consistent procedure to seek scientific and technical documentation in the digital libraries and search engines. To define the search terms, a set of keywords was selected from the research questions to create two groups of words which are shown in Table 2. Each group contained consolidated expressions with synonyms or terms with related meaning. Group 1 included words associated with the Internet of Things, while Group 2 contained a set of terms related to the agro-industry and environment. Logical operators supported by the advanced search of digital libraries were used to construct search strings, based on the two research questions, combining terms from Groups 1 and 2 of Table 2. The general structure of the search queries that were applied to the information sources is presented in Table 3. Table 2. Words used for the search query. Group 1: Internet of Things, Web of Things.  Group 2: Agricultural industry, Agricultural products, Agriculture, Agribusiness, Agroindustry, Air pollution, Apiculture, Aquaculture, Product Traceability, Smart Agriculture, Greenhouses, Harvesting, Horticulture, Husbandry, Irrigation, Livestock, Climate, Feeding, Fertilizers, Forestry, Weather, Animal production, Animal sensing, Animal tracking, Animal trade control, Avalanche, Bio-fuel, Biological production, Bio-monitoring, Breeding, Cereals, Crop, Dairy, Drones, Drought, Earthquake sensor, Environmental monitoring, Equipment status, Farm, Farming, Feed production, Fish, Fishery, Flooding, Food chain, Food production, Forecast, Forest fire, Freeze, Fruit, Fruit storage, Grassland, Heating, Landslide, Meat, Pest, Plant, Poultry, Seed, Vegetable, Waste, Water. Table 3. Algorithm: search query-(Group 1) AND (Group 2). TITLE-ABS-KEY (“Internet of Things” OR “Web of Things”) AND (“Agricultural industry” OR “Agricultural products” OR agriculture OR agribusiness OR agroindustry OR “Air pollution” OR “Apiculture” OR aquaculture OR “Product Traceability” OR greenhouses OR harvesting OR horticulture OR husbandry OR irrigation OR livestock OR climate OR feeding OR fertilizers OR forestry OR weather OR “Animal production” OR “Animal sensing” OR “Animal tracking” OR “Animal trade control” OR avalanche OR biofuel OR “Biological production” OR biomonitoring OR breeding OR cereals OR crop OR dairy OR drones OR drought OR “Earthquake sensor” OR “Environmental monitoring” OR “Equipment status” OR farm OR farming OR “Feed production” OR fish OR fishery OR flooding OR “Food chain” OR “Food production” OR forecast OR “Forest fire” OR freeze OR fruit OR “Fruit storage” OR grassland OR heating OR landslide OR meat OR pest OR plant OR poultry OR seed OR vegetable OR waste OR water) In order to ensure the quality of papers, only those that passed the following criteria were considered in the reviewing process. • Documents published in peer-reviewed conferences, peer-reviewed journals, papers from computer science or engineering organizations, patents, or technical reports. • Documents published in English. • Documents published between 2006 and 2016 (both years inclusive). If the main topic of a given paper was irrelevant or if it was outside the scope of this study, it was deleted. Then, a selection criterion was applied in order to reduce the number of papers found during the search and to get a small number of high-quality sources that could be used to answer the research questions. This involved using inclusion criteria (IC) and quality criteria (QC), which were defined in a three-phase process. • IC based on abstracts: in this phase, authors discarded papers found in the search stage based on the information provided in their abstracts. Papers that satisfied the first inclusion criterion were kept for further processing, i.e. papers that discussed IoT solutions applied to agro-industry and environment. Papers with little relevant information in their abstract were temporarily kept in the list and were processed in the next stage. It is important to highlight that quality criteria were not considered in this phase. • IC based on full reading: in this phase, papers that did not address the search terms shown in Table 2 were removed. This means that even though those papers contained the search terms in their abstract, they only represented minor aspects of them. • IC based on quality analysis: in this phase, a quality analysis was applied to remaining papers and those that did not comply any of the following four quality criteria (QC) were discarded: – QC1: Does the study present a comprehensive solution of IoT for agro-industry or environment? – QC2: Does the paper show details of the infrastructure and/or technologies used to implement the proposed solution? – QC3: Does the paper present a state of the art or related work? – QC4: Does the paper present an analysis of the results? The next stage of the SLR was data mining and synthesis. The goal here was to extract the information needed to answer the research questions in an objective manner. The information fields extracted for each study are presented in Table 4. Table 4. Form used to extract data for each study. Data retrieved Description Title Title of the main study Year Publication year of the study Institution Name of institution(s) leading the research Country Country that developed the research Source Conference, journal, or book containing the main study Solution Name of the IoT solution described Domain and subdomain Area of agro-industry or environment where IoT was applied Architecture model Description of the architecture used, its scope and limitation Sensors Information about sensor type and sensor count per node in the solution Power source Mechanisms used to power IoT devices Edge computing Information about computing platforms, hardware architecture, the number of nodes, topology (homogeneous vs. heterogeneous). Connectivity and communication Technologies used for transmitting data Data storage Techniques used for storing data (locally, distributed, and cloud-based), as well as data access methodologies Data processing and visualization Algorithms and methodologies for processing and analyzing data (data aggregation, data fusion, machine learning, pattern recognition, big data), and models to visualize them Deployment scenario Characteristics of the deployment site for the IoT solution 3. Conduction The protocol described in the previous section was used to search, select and evaluate preliminary papers. For the search process, the query defined in Table 3 was passed to information sources given in Table 1. The search was limited to title, abstract and keywords. Fig. 1 illustrates the conduction process discriminated by the academic database and search engine used, highlighting the key steps followed to select relevant studies for this review. Initially, 3578 studies were recovered from electronic databases. Firstly, duplicates were excluded, i.e. studies available in more than one database, eliminating 849 copies. Out of the 2729 remaining studies, 2652 were initially screened based on inclusion and exclusion criteria applied to the title, abstract, and keywords. These papers were marked to be downloaded, and references that could not be retrieved were discarded. Afterward, these studies were evaluated using quality criteria obtaining 720 studies. These studies were used to extract the data defined in Table 4. Finally, only 72 main studies were selected based on their quality for the final conduction phase and used to extract results presented in the next section. Download : Download high-res image (236KB) Download : Download full-size image Fig. 1. Process followed in the SLR to select main studies. It is worth to note that more than 90% of included papers were retrieved from two sources: IEEExplore (76.4%) and Scopus (13.9%). In contrast, the least effective sources of information were Microsoft Academic Search and Microsoft Academic. They retrieved 668 papers during the first stage of the conduction phase (representing 25.2% of all retrieved papers, and only behind IEEExplore with 45%). However, only 3.1% of them were included for the next reviewing phase, a number well below the 39.8% of papers included from IEEExplore. These facts can be explained because IEEExplore and Scopus have complete and usable advanced search systems and they have been operating continuously unlike Microsoft’s counterpart (Sinha et al., 2015a). Fig. 2 enumerates the number of primary studies classified by publication year. It can be seen that most of the selected papers were published between 2012 and 2016. It should be highlighted that the small number of papers shown in 2016 can be explained because the initial search was made in April of that year. Download : Download high-res image (127KB) Download : Download full-size image Fig. 2. Distribution of papers selected by publication year. Fig. 3 summarizes the country of origin of selected papers. Every continent of the world is represented by at least one research work. China is the country that contributed with the largest number of papers. Asia has more than half of contributions and America has less than ten percent of them, showing a huge potential for this continent. Download : Download high-res image (159KB) Download : Download full-size image Fig. 3. Distribution of papers selected by country. 4. Results This phase presents results of the SLR in order to answer the two research questions based on the information extracted from main studies selected. 4.1. Answer to the first research question To identify the main technological solutions of IoT in agro-industry and environmental fields, studies were grouped into four technological domains, corresponding to: (1) monitoring, (2) control, (3) prediction and (4) logistics. Results are summarized in Table 5 and illustrated in Fig. 4. From this figure, it can be seen that most of the selected studies were focused on monitoring (62%), followed by control (25%), logistics (7%), and prediction (6%). Table 5. Clustering of main studies by application domain. Domain Main study Monitoring (Hussain et al., 2006, Lu et al., 2010, Pokrić et al., 2014, Postolache et al., 2014, Sawant et al., 2014, Ehsan et al., 2012, Langendoen et al., 2006, Chen et al., 2014, Liu et al., 2013, Islam et al., 2014, Kuroda et al., 2015, Fourati et al., 2014, Kar and Kar, 2015, Chen et al., 2015, Medela et al., 2013, Zou, 2014, Diedrichs et al., 2014, Mittal et al., 2012, De La Concepcion et al., 2014, Jardak et al., 2009, Vo et al., 2013, Tarange et al., 2015, Kodali et al., 2014, Sinha et al., 2015b, Eom et al., 2014, Sun et al., 2012, Hakala et al., 2008, Jain et al., 2008, Watthanawisuth et al., 2009, Nguyen et al., 2015, Lee et al., 2013, Ma et al., 2012, Jayaraman et al., 2015a, Jayaraman et al., 2015b, Soontranon et al., 2014, Hashim et al., 2015, Zhao and Zhu, 2015, Mathurkar et al., 2014, Kiyoshi et al., 2008, Postolache et al., 2013, Mafuta et al., 2012, Feng et al., 2012, Xijun et al., 2009, Gutiérrez et al., 2014, Sarangi et al., 2016, Fang et al., 2014)  Control (Yoo et al., 2007, Kanoun et al., 2014, Sales et al., 2015, Chavez-Burbano et al., 2014, Ryu et al., 2015, Pahuja et al., 2013, Xu et al., 2015, Ye et al., 2013, Jiao et al., 2014, Jiber et al., 2011, Shuwen and Changli, 2015, Culibrina and Dadios, 2015, Kaewmard and Saiyod, 2014, Li et al., 2014, Tao et al., 2014, Smarsly, 2013, Roy et al., 2015)  Logistics (Pang et al., 2015, Li et al., 2013, Jiang and Zhang, 2013, Charoenpanyasak et al., 2011, Marino et al., 2010)  Prediction (Khandani and Kalantari, 2009, Saville et al., 2015, Lee et al., 2012, Luan et al., 2015) Download : Download high-res image (66KB) Download : Download full-size image Fig. 4. Distribution of papers selected by application domain. Selected papers grouped in the monitoring domain dealt with remote sensing of physical and environmental parameters gathered in scenarios such as crops and farms using a Wireless Sensor Network (WSN). The main goal of this domain was the acquisition of information without an operator and its transmission to a server or data center for processing and visualization. Integrated monitoring tools made it possible to maintain a continuous communication with the deployed WSN, and access stored data through the Internet. Hence, smart agriculture based on IoT adds value to farmers by helping them to collect relevant data from crops and farms using sensor devices. Some IoT setups could display, process and analyze remote data applying cloud services in order to provide new insights and recommendations for better decision-making. IoT solutions categorized in monitoring domain can be divided into three architectural layers (Zou, 2014): (i) a perception layer supported by a WSN; (ii) a network layer where the sensor information travels a long distance using different protocols and Gateways, and (iii) an application layer that includes a web server and a database. Moreover, IoT solutions grouped in this domain are interested in monitoring several types of physical variables depending on the subdomain to which they belong. Specifically, the following subdomains were identified: air monitoring (34.5%), soil monitoring (27.3%), water monitoring (16.4%), plant monitoring (10.9%), and others (10.9%) which include areas such as aquaculture and animal monitoring. It is worth to highlight that most of the selected studies retrieved in this SLR can be categorized in more than one subdomain. For instance, the system proposed in Zou (2014) is used for online crop growth monitoring and it captures different types of variables such as: temperature, humidity, soil moisture, CO2, luminosity, pH of water, and images. Some representative examples of IoT applications categorized in the monitoring domain are described below. • Air monitoring: this subdomain aimed to provide periodic or continuous measurements, evaluating and determining environmental parameters or pollution levels in order to prevent negative and damaging effects. It also included the forecasting of possible changes in the ecosystem or the biosphere as a whole. For instance, in Watthanawisuth et al. (2009) authors described an agricultural IoT solution which can be categorized in the air monitoring subdomain. In this solution, authors proposed a real-time monitoring system of micro climate based on a WSN. The solution included temperature and relative humidity sensors (SHT15) powered by solar panels and supported by ZigBee communication technology. Another air monitoring IoT solution is GEMS (Lu et al., 2010), which proposed an environmental monitoring system based on GPRS technology for monitoring apple orchards. This system was tested on five different regions of China over a 2-year period by monitoring variables such as relative humidity, temperature, and radiation. • Soil monitoring: papers classified in this subdomain such as (Chen et al., 2014, Mafuta et al., 2012) proposed systems for monitoring multi-layer soil temperature and moisture in a farmland fields using WSN. These systems are supported by communication technologies such as ZigBee, GPRS and Internet, where user interaction with the system is handled by a web application. • Water monitoring: primary studies categorized in this subdomain intend to monitor water pollution or water quality by sensing chemicals, pH, and temperature, which can alter the natural state of water. An example of this subdomain is presented in Postolache et al. (2013), where authors proposed an IoT solution for water quality assessment through the measurement of conductivity, temperature, and turbidity. The solution is based on a WSN architecture that combines low-cost sensing devices and monitoring of multiple parameters of water quality of shallow waters (lakes, estuaries, rivers) in urban areas. Similarly, (Xijun et al., 2009) proposed a WSN system for monitoring water level and rainfall in irrigation systems. • Plant monitoring: The LOFAR-agro Project (Langendoen et al., 2006) is an example of plant or crop monitoring. This project aimed to protect a potato crop against phytophthora (a genus of water mold) by monitoring the microclimate (humidity and temperature) using a large-scale WSN. The system intended to generate a policy to protect the crop against the fungal disease based on the collected data. In Fourati et al. (2014), authors propose a Web-based decision support system communicating with a WSN for irrigation scheduling in olive fields. For this purpose, authors use sensors to measure humidity, solar radiation, temperature, and rain. • Animal monitoring: This subdomain referred to animal tracking for both wildlife and animal husbandry activities. A research belonging to this subdomain was a delay-tolerant WSN for the monitoring and tracking of six horses presented in Ehsan et al. (2012). For this purpose, authors developed necklaces that acquired information about horses’ position and speed at a given time, and transmitted such logs to fixed nodes when they were close to its coverage area. Another example of animal monitoring was given by Jain et al. (2008), where an IoT solution was responsible for monitoring the behavior and migration patterns of Swamp Deers, obtaining information of the animal position and the climate at the same time. Papers selected and grouped under the domain of control use remote actuator devices deployed on-site. Unlike monitoring domain applications, which handle information in one-way, applications categorized in control use a two-way information channel. This means that a new level of communication was added, and commands could be sent back to the field. In this case, information from the server or data center traveled to a Wireless Sensor and Actuator Network (WSAN) in order to control a set of actuator devices to modify the state of the process or environment. Commands were sent through a human–computer interface or as a result of a decision algorithm supported by analytic modules. Actuator devices included valves, pumps, humidifiers, and alarms among others. Many of these systems aimed to optimize the usage of water, fertilizers, and pesticides based on information provided by weather prediction systems and on-site WSN. Solutions in this domain could help farmers to reduce water consumption and waste by scheduling irrigation times and quantities according to the state of the crop and its growth cycle. Control systems were programmed to be adaptive, for instance, switching off sprinkler if rain was detected. Overall, solutions with control systems could save money to the farmer and provide at the same time valuable insights about the consumption of water, fertilizers, pesticides, and electricity. Actuator devices used by IoT solutions grouped in the control domain depended heavily on the subdomain to which they belonged. In this paper, the following subdomains were considered: irrigation (72.22%), fertilizers (5.56%), pesticides (5.56%), illumination (5.56%), and access control (5.56%). During the review, it was found that some studies used actuators in the domain of logistics (5.56%). Representative examples of IoT applications categorized in the control domain are described next. • Irrigation control: A precision irrigation solution based on wireless sensor network was proposed by Kanoun et al. (2014). The main challenge of that study was to create an automated irrigation system which could reduce water waste, saving energy, time, and money. This system was built using three nodes based on the TelosB mote: (i) a node to measure soil moisture and soil temperature; (ii) a node to measure environmental parameters such as air temperature, air humidity, wind speed and brightness; and (iii) a node that was connected to a valve for irrigation control. Data were transmitted to a base station for storage and were sent to the farmer’s PC to allow him to take action. Another precision irrigation IoT system was proposed by Jiao et al. (2014). This included an environmental monitoring system for agricultural management, as well as the implementation of precision dripping. The system considered an IoT ecosystem divided into three layers corresponding to sensing, transmission, and application. A WSN was used to perceive environmental information in real time within a tomato greenhouse, to later transmit the data to a remote server management system. In Shuwen and Changli (2015) researchers described a remote farmland irrigation monitoring solution based on ZigBee. The system included a solar-powered irrigation control system that also monitored air temperature, humidity and soil temperature. • Fertilizer and pesticide control: IoT solutions categorized in this subdomain applied conservation practices to improve nutrient usage, efficiency, crop quality, overall yield, and economic return while reducing off-site transport of nutrients. In Pahuja et al. (2013), authors developed an online micro-climate monitoring and control system for greenhouses. The system was supported by a WSN to gather and analyze plant-related sensor data to produce actions to control the climate, fertilization, irrigation, and pests. • Illumination control: authors in Yoo et al. (2007) described an automated agriculture system based on WSN for monitoring greenhouses used to grow melons and cabbages. The system monitored the growing process of crops and controlled the greenhouse’s environment. Some of the variables measured included ambient light, temperature, and humidity. For the greenhouse with melons, the system could control the illumination by changing the light state through a relay. • Access control: An agricultural intrusion detection system was presented in Roy et al. (2015). The proposed system generated alarms in the farmers house and sent a text message to the farmer’s mobile phone when an intruder entered the crop field. Selected papers categorized in the prediction domain were focused on providing knowledge and tools to farmers to support decision making. They had specific modules for these tasks in their architecture, and their predicted variables were grouped as follows: environmental conditions (42.86%), production estimation (42.86%), and crop growth (14.29%). • Environmental conditions: A representative example of environmental condition prediction is proposed in Khandani and Kalantari (2009), where authors described a design methodology to determine the spatial sampling of humidity sensors for the soil within a WSN. They used a historical database of dense soil-humidity measurements to determine the behavior of the 2D correlation that exists between the measurements of nearby sensors. This was used later to find the largest spatial sampling that ensured a user-defined variance for the estimation on any given point of interest in the space. Authors found that the spatial correlation function decays exponentially with the distance between sensors. Another example of the prediction of environmental conditions was presented in Luan et al. (2015), which described a system that integrates drought monitoring and forecasting as well as irrigation prediction using IoT. • Production estimation: Authors in Lee et al. (2013) presented an IoT-based agricultural production system for stabilizing supply and demand of agricultural products. They achieved this goal by sensing environmental variables and by developing a prediction system for the growth and yield of crops. In a different application, (Saville et al., 2015) introduced a real-time estimation system for fixed-net fishery using ultrasonic sensors and supervised learning. • Crop growth: a dynamic analysis of farmlands using mobile sensors was presented in Lee et al. (2012). The developed system aimed to establish growth-control plans for grapes, and viticulture activities. The last domain used to categorize selected studies was logistics. Logistics in agriculture refers to the physical flow of entities and related information from producer to consumer to satisfy consumer demand. It includes: agricultural production, acquisition, transportation, storage, loading and unloading, handling, packaging, distribution, and related activities. Some objectives of logistics in agriculture include: adding value to agricultural products, saving money in distribution costs, improving shipping efficiency, reducing unnecessary losses, and to some extent, avoiding risks (Liping, 2012). Primary studies in logistics were further divided in: production (55.6%), commerce (22.2%) and transport(22.2%). The next paragraphs include representative studies of each subdomain. • Production: in Feng et al. (2012) researchers proposed an intelligent system for monitoring an apple orchard that implemented suggestions based on data. The system aimed to reduce management costs of apple orchards, improve apple quality, and provide detailed, comprehensive and accurate electronic information for planting works, pest warnings, and production-quality tracking of apples. The system included WSN using Zigbee, GPRS, and IoT providing detailed monitoring data of apple growth for agricultural cooperatives, to support for decision making in farming. • Commerce: (Li et al., 2013) presented an information system for agriculture based on IoT which used a distributed architecture. In that study, tracking and tracing of the whole agricultural production process were made with distributed IoT servers. Moreover, an information-discovery system was designed to implement, capture, standardize, manage, locate, and query business data from agricultural production. The system also allowed consumers to query information of agricultural products to verify their authenticity and quality. • Transport: A representative example of this subdomain is presented in Pang et al. (2015), where an IoT architecture was proposed for the food-production and commercialization chain. This paper dealt with logistics involved in the transportation of melons from Brazil to Sweden in a journey that takes 46 days. Sensor nodes measured conditions in the environment including oxygen, carbon dioxide, ethylene, temperature, humidity, and mechanical stress, such as vibrations, tilts, and shocks. Fig. 5 summarizes the distribution of each application domain into its corresponding subdomains described in the previous paragraphs. Download : Download high-res image (270KB) Download : Download full-size image Fig. 5. Distribution of papers selected by application subdomain. 4.2. Answer to the second research question Infrastructure and technology used by selected IoT solutions in agro-industrial and environmental fields were organized in seven groups, corresponding to: (i) sensing variables, (ii) actuator devices, (iii) power sources, (iv) communication technologies, (v) edge computing technologies (Shi et al., 2016), (vi) storage strategies, and (vii) visualization strategies. • Sensing variables: about 26% of analyzed studies sense temperature, followed by humidity, physicochemical properties, and radiation with 16%, 11%, and 10%, respectively. Particularly, temperature and physicochemical sensors are distributed in all subdomains as it can be seen in Fig. 6. Similarly, 55% of sensors are used for air monitoring. Thus, air temperature and humidity, soil moisture and solar radiation, can be considered universal variables in agricultural applications. Download : Download high-res image (324KB) Download : Download full-size image Fig. 6. Types of sensing variables collected in the monitoring domain. • Actuator devices: the distribution of actuators used in selected studies is shown in Fig. 7. It can be stated that there are far fewer actuator devices than sensors currently being used in these studies and that most of them are concentrated in applications of control and logistics. In fact, more than 60% of actuators reported were found in irrigation processes. Download : Download high-res image (223KB) Download : Download full-size image Fig. 7. Type of actuator device used. • Power sources: currently, most monitoring applications prefer rechargeable batteries connected to solar panels, which offer a simple but sustainable energy supply. In contrast, control applications that typically have demanding energy requirements prefer the electrical grid. These trends can be appreciated in Fig. 8. Recent power sources, such as electromagnetic or vibration harvesters were not found in selected studies showing that these approaches must mature and gain popularity for agricultural and environmental applications. Download : Download high-res image (132KB) Download : Download full-size image Fig. 8. Power sources. • Communication technologies: Fig. 9 shows that most studies (40%) used Wireless Personal Area Network (WPAN) protocols such as Bluetooth and ZigBee, followed by Wireless Metropolitan Area Network (WMAN) with 36% of the studies mainly supported by cellular technologies (GPRS/GSM/3G/4G). Meanwhile, the near-field communication, which is relatively new, has started to emerge in some field applications. Download : Download high-res image (76KB) Download : Download full-size image Fig. 9. Communication technologies. • Edge computing technologies: microcontroller platforms were chosen in more than half of the applications reviewed. Interestingly, Single Board Computers (SBC) are not yet appropriate for edge computing in IoT agricultural applications. The complete distribution of edge computing technologies is shown in Fig. 10. Download : Download high-res image (109KB) Download : Download full-size image Fig. 10. Edge computing technologies. • Storage strategies: reviewing Fig. 11, it is clear that even though Cloud storage represents a key service for IoT systems, only 7.32% of selected studies used it. This shows that most researchers preferred their own data-storage implementation. Download : Download high-res image (78KB) Download : Download full-size image Fig. 11. Storage strategy. • Visualization strategies: Fig. 12 shows the distribution of three different visualization strategies: web, mobile and local, in four subdomains: monitoring, control, prediction, and logistics. It can be stated that web-based solutions were the preferred strategy to visualize reports in all subdomains of applications. Download : Download high-res image (115KB) Download : Download full-size image Fig. 12. Visualization strategies. Most of the selected works do not address security issues explicitly and leave them on a side. However, some efforts in this domain were found. For instance, (Jardak et al., 2009) described the design of a WSN that implemented a RANdom SAmple Consensus (RANSAC) filter to eliminate inconsistent sensor-node data due to the presence of faulty or malicious nodes in the network. Sun et al. (2012) presented a dam monitoring system where users needed to sign in through the main interface in order to validate their credentials. Tao et al. (2014) selected AppWeb as the embedded Web server for the IoT Gateway of an intelligent granary management system because it could add the Secure Sockets Layer (SSL) protocol to enable encrypted data connection. This was valuable because the network information was vulnerable as it came from a wireless channel. Kuroda et al. (2015) proposed a WSN with easy-to-use secure communication that was implemented using Zero-admin encrypt/decrypt functions at the MAC level with the Advanced Encryption Standard (AES-128), which enabled automatic encryption/decryption of messages between each sensor node and the coordinator node. 5. Recent works The following paragraphs are devoted to introducing some recent and representative works that were available online between May 2016 and July 2017, beyond the initial scope of the SLR process described so far. They cover areas such as communications, energy management, monitoring and logistics for agro-industrial and environmental applications. 5.1. Communications Low-power WAN (LPWAN) technologies such as SigFox, LoRa, narrowband IoT and others are becoming popular within IoT applications due to its reduced energy requirements, wide coverage range, and low-cost when compared to other long-distance technologies according to Barrachina-Muñoz et al. (2017). For example, in a recent survey by Sinha et al. (2017), authors found that LoRa is the best option for smart agriculture applications. In Lukas et al. (2015), authors designed a long-range water level monitoring system for troughs using a WSN based on LoRa transceivers, allowing the cattleman to observe water availability for livestock even when the barn was 1 or 3 km away. In a different application, (Pham et al., 2016) proposed an IoT framework to contribute to rural development implementing agricultural applications supported by open-source hardware and long-range communication devices. The first deployment of this solution used LoRa transceivers since rural villages were located in remote areas and it was convenient to have a low-cost and non-proprietary infrastructure. 5.2. Energy management One of the main requirements for devices used in IoT projects is that they must be energy-efficient according to Borgia (2014). This is particularly important for pervasive solutions deployed outdoors that can not be powered from the electric grid nor regularly maintained because they are installed in difficult or remote environments. In WSN scenarios, the current challenge is to develop multi-source energy harvesters and ultra-efficient sensors to create battery-free solutions, (Shaikh and Zeadally, 2016). These considerations are very important for IoT solutions for agro-industrial and environmental problems as recharging batteries is not practical and ambient energy sources are usually available. In terms of smart energy control for IoT projects, (Wang et al., 2016) proposed a novel energy management strategy for solar powered devices that intend to power the load directly from the solar cell, avoiding power converters and energy storage elements that contribute to energy losses, greater weight/volume ratio, and higher price. Another trend that is likely to continue is the development of self-power devices, such as the soil water content sensor for an autonomous landslide surveillance system designed by Lu et al. (2016). In this case, the sensor used the soil moisture to power itself making it suitable for large scale deployments. Marjanović et al. (2016) described a cloud-based decision-making mechanism for managing sensor data acquisition that is applicable to collaborative sensing solutions using distributed sensors, like mobile devices, to efficiently monitor large geographical areas. The system selected which sensors had to upload the information to the cloud to prevent the acquisition of redundant information from other nearby sensors for a specific coverage area, maintaining a spatial sampling quality and reducing in this way the battery depletion of the devices. 5.3. Monitoring Recent environmental monitoring solutions are now offering additional capabilities in terms of decision making and management. For example, (Giorgetti et al., 2016) proposed a custom-made landslide risk monitoring system based on a WSN that allows fast deployments in hostile environments without human intervention because the system is able to deal with node failure and poor-quality communication links reorganizing the network by itself. Wong and Kerkez (2016) presented a Web service and real-time data architecture that includes an adaptive controller that updates the parameters of each sensing node within a WSN based on a previously defined policy. Zheng et al. (2016) proposed an IoT management system to protect the ecological and environmental quality while building an artificial river where nature and city converge. The system monitored key elements like soil, water, atmosphere, and wind at a high spatial resolution over a large area. Edwards-Murphy et al. (2016) introduced a beehive monitoring system that collects internal and external data to describe the status of the bee colony from a set of possible states using a classification algorithm based on decision trees. This information was used to determine if a visit to the beehive was required or not. As an additional result, authors found a strong correlation between the beehive status and the short-term rain forecast. Overall, this study is relevant for agriculture because crop pollination depends on honey bees. Sarangi et al. (2016) presented a framework for an automated crop-disease advisory service that integrates the interoperability of an IoT web repository with an agricultural advisory call center. The implemented system processes images of the diseased plant sent by the farmer, and then it provides the plant diagnosis and the corresponding management recommendation for the disease. 5.4. Logistics Food safety and quality control in logistics are emerging as IoT agribusiness areas in response to the demand from businesses and end consumers to obtain real-time information about food supply chain and “farm-to-fork” traceability. For instance, (Ruan and Shi, 2016) presented an IoT framework to assess the fruit freshness on e-commerce deliveries, which is a non-traditional retail service that faces unique challenges in transportation due to the product perishability and expensive logistics. Similarly, (Liu et al., 2016) introduced a pilot project using IoT to monitor food safety throughout the product life cycle, helping authorities and consumers to trace the food and make better decisions before buying it. In a related work, (Wang and Yue, 2017) proposed an early-warning system for food safety that automatically warns about product quality risks and incidents by sharing and centralizing information among supply chains. Lastly, (Capello et al., 2016) developed a business-to-business monitoring service based on IoT that provides geo-located information (humidity and temperature) about food storage and transportation without a vendor lock-in infrastructure. 6. Discussion 6.1. Limitations and open challenges After analyzing the difficulties and limitations described in selected papers from the SLR, the following list summarizes a few insights that aim to contribute to the mass adoption of IoT solutions in agricultural and environmental fields. • Stronger standardization: it will help to improve compatibility among different vendors and to ensure stronger security measures across the entire IoT stack, starting from field devices all the way up to cloud providers and end-user interfaces (Pang et al., 2015). • Better power management: it will increase the endurance of IoT solutions because nowadays the main factor limiting the lifespan of IoT deployments is energy depletion (Jain et al., 2008, Chen et al., 2014, Islam et al., 2014, Diedrichs et al., 2014). The lifespan can be improved by lowering the power consumption of each electronic module, including energy harvesters, and using alternative power storage mechanisms as replacements of rechargeable batteries, which affect the expiration date of deployed devices. • Security: a major challenge in the realization of the IoT in agriculture is the security problem (Jiang and Zhang, 2013), and the few works that consider it only incorporate fragmented strategies to mitigate it. Therefore, it is evident that there is a need for agro-industrial and environmental IoT solutions that address end-to-end information security and physical integrity of field devices. • Design using modular hardware and software: it will enable a greater degree of reuse and customization for the end user (Pang et al., 2015). • Improve unit cost: even though the cost of embedded computing platforms have been decreasing sharply, the same is not true for high-quality sensors and actuators. In order to deploy IoT solutions with hundreds and possibly thousands of nodes, the overall hardware, Internet access and international data roaming costs have to be reduced even further (Pang et al., 2015). • Aim for a good compatibility with legacy infrastructure: similarly to what has happened in industrial automation, it is important to deliver IoT solutions that can be integrated with the customer’s existing infrastructure such as specialized equipment, field machines, and software. • Consider scalability early on: with an increasing number of devices in large deployments, data synchronization and data reliability become critical (Diedrichs et al., 2014). • Adopt good practices of software engineering: as the scale and endurance of deployed IoT solutions grow, the time and effort devoted to analyzing generated data, refining the code, and adding new features will explode unless the software is well designed and documented (Hussain et al., 2006, Jayaraman et al., 2015a). • Improve robustness for field deployments: commercial IoT solution should be able to handle strong changes in temperature, humidity, and illumination to deal with seasonal changes and worldwide climate variability. • User-centered design: the installation and management of corresponding IoT nodes should be straight forward for non-expert users. Additionally, the hardware must require very little or none human maintenance during its lifespan, and the underlying communication network should be intelligent enough to reconfigure or heal itself in the case of a node failure. • Contribute to the IoT the ecosystem: there is a noticeable void in the literature on how to improve and adapt IoT solutions for real-world applications beyond simple prototypes (Chen et al., 2015). • Sustainable practices: even if the most humble predictions about the worldwide adoption of IoT devices become a reality, recycling strategies will have to be taken into account for new solutions deployed on the field, as an integral part of the product life cycle to reduce the environmental impact. 6.2. Proposed architecture To summarize the findings of this study, authors proposed the IoT architecture for agro-industrial and environmental applications that is illustrated in Fig. 13. This encapsulates most of the studies analyzed in this paper. The architecture has four main layers: physical, communication, service, and application. The physical layer includes perception and control. In perception, the main objective is to produce valuable data sensing field variables using a WSN. Data produced are sent to the communication layer through field gateways. Devices in the perception layer can be powered by batteries for short-term deployments or by solar panels because of their low-power consumption. In contrast, the control layer acts as a data sink, receiving information from a communication layer or a perception layer in the simplest case. Information received in the control layer alters the state of field actuators frequently requiring power from the electrical grid. In the middle of the perception and control layers there is a mobile robot that can be used when fixed devices are not the best option. In the communication layer, the objective is to move the information from the physical layer to the Internet, collecting data from IoT gateways based either on Ethernet or mobile networks (e.g: GPRS/3G/4G/NB-IoT and eventually 5G). This layer includes field gateways acting as interfaces between IoT gateways and transceivers using ZigBee, Bluetooth, NFC, WiFi, LoRA, or Sigfox. The service layer handles data ingestion from the communication layer, as well as their storage, analytics, visualization, and security. Finally, the application layer consumes services from the previous layer in the architecture and allows the user to handle monitoring, control, prediction, and logistics. Download : Download high-res image (717KB) Download : Download full-size image Fig. 13. Proposed IoT architecture for agro-industrial and environmental applications. 7. Conclusions This paper presented an updated review of IoT applications for agro-industrial and environmental fields. It was guided by a systematic literature review, and therefore the methodology and intermediate results obtained during the stages of planning, conduction, and results were reported in great detail. From 3578 initial studies extracted from electronic sources, 72 main studies were selected based on their relevance to answer two research questions. Selected studies came from five continents, and Asian countries contributed to more than half of them. During this study, it was discovered that most of the research still focuses on monitoring applications (62%); however there is a growing interest in closing the loop by doing control (25%), and there are some preliminary solutions in logistics and prediction (13%) for agro-industrial and environmental applications using IoT. The temperature and humidity of the air, as well as the soil moisture and solar radiation can be recognized as universal variables measured in agricultural applications based on selected studies. Similarly, actuators such as valves, pumps, motors, sprinklers, humidifiers, and lamps were widely used in irrigation, fertilization, pesticide management, and illumination control. It was also observed that new energy sources and Cloud storage have not been widely adopted, showing that there are opportunities for research and development in these areas. Studies included in this paper provide a compact view of solutions proposed for agro-industrial and environmental problems during the last decade. It was found that most of them relied heavily on heterogeneous components and wireless sensor networks. However, it seems reasonable to assume that future solutions will need to fully embrace Cloud services and new ways of connectivity in order to get the benefits of a truly connected and smart IoT ecosystem. Acknowledgements Authors would like to acknowledge the support of all partners within the Center of Excellence and Appropriation on the Internet of Things (CEA-IoT), as well the Colombian Ministry for the Information and Communication Technologies (MinTIC), and the Colombian Administrative Department of Science, Technology and Innovation (Colciencias) through the project ID: FP44842-502-2015 from the National Trust for Funding Science, Technology and Innovation Francisco José de Caldas. References Barrachina-Muñoz et al., 2017 S. Barrachina-Muñoz, B. Bellalta, T. Adame, A. Bel Multi-hop communication in the uplink for LPWANs Comput. Netw., 123 (2017), pp. 153-168, 10.1016/j.comnet.2017.05.020 View PDFView articleView in ScopusGoogle Scholar Borgia, 2014 E. Borgia The internet of things vision: key features, applications and open issues Comput. Commun., 54 (2014), pp. 1-31, 10.1016/j.comcom.2014.09.008 View PDFView articleGoogle Scholar Capello et al., 2016 Capello, F., Toja, M., Trapani, N., 2016. A real-time monitoring service based on industrial internet of things to manage agrifood logistics. In: 6th International Conference on Information Systems, Logistics and Supply Chain, pp. 1–8. Google Scholar Charoenpanyasak et al., 2011 S. Charoenpanyasak, W. Suntiamorntut, T. Phatthanatraiwat, J. Ruksachum Smart shrimp hatchery using mikros platform 4th Joint IFIP Wireless and Mobile Networking Conference (WMNC), IEEE (2011), pp. 1-5 CrossRefGoogle Scholar Chavez-Burbano et al., 2014 P. Chavez-Burbano, I. Marin-Garcia, A. Muñoz-Arcentales Ad-hoc network implementation and experimental testing using low cost and COTS components: an ecuatorian case study International Work Conference on Bio-inspired Intelligence (IWOBI), IEEE (2014), pp. 133-137 CrossRefView in ScopusGoogle Scholar Chen et al., 2014 K.T. Chen, H.H. Zhang, T.T. Wu, J. Hu, C.Y. Zhai, D. Wang Design of monitoring system for multilayer soil temperature and moisture based on WSN International Conference on Wireless Communication and Sensor Network (WCSN), IEEE, Wuhan (2014), pp. 425-430, 10.1109/WCSN.2014.9 View in ScopusGoogle Scholar Chen et al., 2015 Y. Chen, J.-P. Chanet, K.-M. Hou, H. Shi, G. de Sousa A scalable context-aware objective function (SCAOF) of routing protocol for agricultural low-power and lossy networks (RPAL) Sensors, 15 (2015), pp. 19507-19540, 10.3390/s150819507 View in ScopusGoogle Scholar Culibrina and Dadios, 2015 F.B. Culibrina, E.P. Dadios Smart farm using wireless sensor network for data acquisition and power control distribution International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment and Management (HNICEM), IEEE (2015), pp. 1-6 CrossRefGoogle Scholar De La Concepcion et al., 2014 A.R. De La Concepcion, R. Stefanelli, D. Trinchero A wireless sensor network platform optimized for assisted sustainable agriculture Global Humanitarian Technology Conference (GHTC), IEEE (2014), pp. 159-165, 10.1109/GHTC.2014.697027 View in ScopusGoogle Scholar Diedrichs et al., 2014 A.L. Diedrichs, G. Tabacchi, G. Grünwaldt, M. Pecchia, G. Mercado, F.G. Antivilo Low-power wireless sensor network for frost monitoring in agriculture research Biennial Congress of Argentina (ARGENCON), IEEE (2014), pp. 525-530, 10.1109/ARGENCON.2014.686854 View in ScopusGoogle Scholar Edwards-Murphy et al., 2016 F. Edwards-Murphy, M. Magno, P.M. Whelan, J. O’Halloran, E.M. Popovici b+WSN: smart beehive with preliminary decision tree analysis for agriculture and honey bee health monitoring Comput. Electron. Agric., 124 (2016), pp. 211-219, 10.1016/j.compag.2016.04.008 View PDFView articleView in ScopusGoogle Scholar Ehsan et al., 2012 S. Ehsan, K. Bradford, M. Brugger, B. Hamdaoui, Y. Kovchegov, D. Johnson, M. Louhaichi Design and analysis of delay-tolerant sensor networks for monitoring and tracking free-roaming animals IEEE Trans. Wireless Commun., 11 (2012), pp. 1220-1227, 10.1109/TWC.2012.012412.111405 View in ScopusGoogle Scholar Eom et al., 2014 K.-H. Eom, K.-H. Hyun, S. Lin, J.-W. Kim The meat freshness monitoring system using the smart RFID tag Int. J. Distrib. Sensor Networks, 2014 (2014), pp. 1-10 CrossRefGoogle Scholar Fang et al., 2014 S. Fang, L. Da Xu, Y. Zhu, J. Ahati, H. Pei, J. Yan, Z. Liu An integrated system for regional environmental monitoring and management based on internet of things IEEE Trans. Ind. Inform., 10 (2014), pp. 1596-1605 CrossRefView in ScopusGoogle Scholar Feng et al., 2012 C. Feng, H.R. Wu, H.J. Zhu, X. Sun The design and realization of apple orchard intelligent monitoring system based on internet of things technology Advanced Materials Research, vol. 546, Trans Tech Publ (2012), pp. 898-902 View in ScopusGoogle Scholar Fourati et al., 2014 M.A. Fourati, W. Chebbi, A. Kamoun Development of a web-based weather station for irrigation scheduling 3rd International Colloquium in Information Science and Technology (CIST), IEEE (2014), pp. 37-42, 10.1109/CIST.2014.701659 View in ScopusGoogle Scholar Giorgetti et al., 2016 A. Giorgetti, M. Lucchi, E. Tavelli, M. Barla, G. Gigli, N. Casagli, M. Chiani, D. Dardari A robust wireless sensor network for landslide risk analysis: system design, deployment, and field testing IEEE Sens. J., 16 (2016), pp. 6374-6386, 10.1109/JSEN.2016.2579263 View in ScopusGoogle Scholar Gutiérrez et al., 2014 J. Gutiérrez, J.F. Villa-Medina, A. Nieto-Garibay, M.Á. Porta-Gándara automated irrigation system using a wireless sensor network and GPRS module IEEE Trans. Instrum. Meas., 63 (2014), pp. 166-176 View in ScopusGoogle Scholar Hachem et al., 2015 S. Hachem, V. Mallet, R. Ventura, A. Pathak, V. Issarny, P.-G. Raverdy, R. Bhatia Monitoring noise pollution using the urban civics middleware First International Conference on Big Data Computing Service and Applications, IEEE (2015), pp. 52-61 View in ScopusGoogle Scholar Hakala et al., 2008 Hakala, I., Tikkakoski, M., Kivel, I., 2008. Wireless sensor network in environmental monitoring - case foxhouse. In: 2nd International Conference on Sensor Technologies and Applications (SENSORCOMM), pp. 202–208. http://dx.doi.org/10.1109/SENSORCOMM.2008.27. Google Scholar Hashim et al., 2015 N. Hashim, S. Mazlan, M.A. Aziz, A. Salleh, A. Ja’afar, N. Mohamad Agriculture monitoring system: a study J. Teknologi, 77 (2015), pp. 53-59, 10.11113/jt.v77.4099 View in ScopusGoogle Scholar Hussain et al., 2006 Hussain, S., Schofield, N., Matin, A.W. 2006. Design of a web-based application for wireless sensor networks. In: 17th International Workshop on Database and Expert Systems Applications (DEXA), pp. 319–326. http://dx.doi.org/10.1109/DEXA.2006.50. Google Scholar Islam et al., 2014 A. Islam, T. Islam, M.A. Syrus, N. Ahmed Implementation of flash flood monitoring system based on wireless sensor network in Bangladesh 3rd International Conference on Informatics, Electronics & Vision, IEEE, Dhaka (2014), pp. 1-6, 10.1109/ICIEV.2014.685075 Google Scholar Jain et al., 2008 Jain, V.R., Bagree, R., Kumar, A., Ranjan, P., 2008. wildCENSE: GPS based animal tracking system. In: International Conference on Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP), pp. 617–622. http://dx.doi.org/10.1109/ISSNIP.2008.4762058. Google Scholar Jardak et al., 2009 C. Jardak, K. Rerkrai, A. Kovacevic, J. Riihijarvi, P. Mahonen Email from the vineyard 5th International Conference on Testbeds and Research Infrastructures for the Development of Networks & Communities and Workshops (TridentCom), IEEE (2009), pp. 1-6, 10.1109/TRIDENTCOM.2009.497624 Google Scholar Jayaraman et al., 2015a P.P. Jayaraman, D. Palmer, A. Zaslavsky, D. Georgakopoulos Do-it-yourself digital agriculture applications with semantically enhanced IoT platform 10th International Conference on Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP), IEEE (2015), pp. 1-6 CrossRefGoogle Scholar Jayaraman et al., 2015b P.P. Jayaraman, D. Palmer, A. Zaslavsky, A. Salehi, D. Georgakopoulos Addressing information processing needs of digital agriculture with OpenIoT platform Interoperability and Open-Source Solutions for the Internet of Things, Springer (2015), pp. 137-152 CrossRefView in ScopusGoogle Scholar Jiang and Zhang, 2013 Jiang, R., Zhang, Y., 2013. Research of agricultural information service platform based on internet of things. In: 12th International Symposium on Distributed Computing and Applications to Business, Engineering Science (DCABES), pp. 176–180. http://dx.doi.org/10.1109/DCABES.2013.39. Google Scholar Jiao et al., 2014 J. Jiao, H. Ma, Y. Qiao, Y. Du, W. Kong, Z. Wu Design of farm environmental monitoring system based on the internet of things Adv. J. Food Sci. Technol., 6 (2014), pp. 368-373 CrossRefView in ScopusGoogle Scholar Jiber et al., 2011 Jiber, Y., Harroud, H., Karmouch, A., 2011. Precision agriculture monitoring framework based on WSN. In: 7th International Wireless Communications and Mobile Computing Conference, pp. 2015–2020. http://dx.doi.org/10.1109/IWCMC.2011.5982844. Google Scholar Kaewmard and Saiyod, 2014 N. Kaewmard, S. Saiyod Sensor data collection and irrigation control on vegetable crop using smart phone and wireless sensor networks for smart farm Conference on Wireless Sensors (ICWiSE), IEEE (2014), pp. 106-112 CrossRefView in ScopusGoogle Scholar Kanoun et al., 2014 O. Kanoun, S. Khriji, D. El Houssaini, C. Viehweger, M.W. Jmal, M. Abid Precision irrigation based on wireless sensor network IET Sci. Meas. Technol., 8 (2014), pp. 98-106, 10.1049/iet-smt.2013.0137 Google Scholar Kar and Kar, 2015 Kar, A., Kar, A., 2015. A novel design of a portable double beam-in-time spectrometric sensor platform with cloud connectivity for environmental monitoring applications. In: 3rd International Conference on Computer, Communication, Control and Information Technology (C3IT), pp. 1–6. http://dx.doi.org/10.1109/C3IT.2015.7060228. Google Scholar Khandani and Kalantari, 2009 Khandani, S.K., Kalantari, M., 2009. Using field data to design a sensor network. In: 43rd Annual Conference on Information Sciences and Systems (CISS), pp. 219–223. http://dx.doi.org/10.1109/CISS.2009.5054720. Google Scholar Kitchenham and Charters, 2007 Kitchenham, B., Charters, S., 2007. Guidelines for performing systematic literature reviews in software engineering. In: EBSE Technical Report. EBSE-2007-01. pp. 1–50. Google Scholar Kiyoshi et al., 2008 Kiyoshi, H., Shrestha, A., Chinnachodteeranun, R., Mizoguchi, M., Shimamura, H., Kameoka, T., 2008. Spinach field monitoring for bridging thai producer and japanese consumer under sensor Asia. In: SICE Annual Conference, pp. 2582–2585. http://dx.doi.org/10.1109/SICE.2008.4655101. Google Scholar Kodali et al., 2014 R.K. Kodali, N. Rawat, L. Boppana WSN sensors for precision agriculture Region 10 Symposium, IEEE (2014), pp. 651-656, 10.1109/TENCONSpring.2014.686311 View in ScopusGoogle Scholar Kuroda et al., 2015 M. Kuroda, H. Ibayashi, H. Mineno Affordable 400 MHz long-haul sensor network for greenhouse horticulture International Conference on Information Networking (ICOIN), IEEE, Cambodia (2015), pp. 19-24, 10.1109/ICOIN.2015.705785 View in ScopusGoogle Scholar Langendoen et al., 2006 K. Langendoen, A. Baggio, O. Visser Murphy loves potatoes experiences from a pilot sensor network deployment in precision agriculture 20th International Parallel and Distributed Processing Symposium (IPDPS), vol. 2006, IEEE, Rhodes Island (2006), pp. 1530-2075, 10.1109/IPDPS.2006.163941 Google Scholar Lee et al., 2012 Lee, J., Kang, H., Bang, H., 2012. Dynamic crop field analysis using mobile sensor node. In: International Conference on ICT Convergence (ICTC), pp. 7-11. http://dx.doi.org/10.1109/ICTC.2012.6386766. Google Scholar Lee et al., 2013 M. Lee, J. Hwang, H. Yoe Agricultural production system based on IoT 16th International Conference on Computational Science and Engineering (CSE), IEEE (2013), pp. 833-837 CrossRefView in ScopusGoogle Scholar Li et al., 2013 M. Li, G. Chen, Z. Zhu Information service system of agriculture IoT Automatika - J. Control, Meas. Electron. Comput. Commun., 54 (2013), pp. 415-426 CrossRefGoogle Scholar Li et al., 2014 R.-A. Li, X. Sha, K. Lin Smart greenhouse: a real-time mobile intelligent monitoring system based on WSN International Wireless Communications and Mobile Computing Conference (IWCMC), IEEE (2014), pp. 1152-1156 CrossRefView in ScopusGoogle Scholar Liping, 2012 W. Liping Study on agricultural products logistics mode in Henan Province of China Software Eng. Knowledge Eng.: Theory Practice, Springer (2012), pp. 635-640 CrossRefGoogle Scholar Liu et al., 2016 Y. Liu, W. Han, Y. Zhang, L. Li, J. Wang, L. Zheng An internet-of-things solution for food safety and quality control: a pilot project in China J. Ind. Inform. Integrat., 3 (2016), pp. 1-7, 10.1016/j.jii.2016.06.001 View PDFView articleGoogle Scholar Liu et al., 2013 Z. Liu, J. Huang, Q. Wang, Y. Wang, J. Fu Real-time barrier lakes monitoring and warning system based on wireless sensor network International Conference on Intelligent Control and Information Processing (ICICIP), IEEE, Beijing (2013), pp. 551-554, 10.1109/ICICIP.2013.656813 View in ScopusGoogle Scholar Lu et al., 2010 S. Lu, M. Duan, P. Zhao, Y. Lang, X. Huang GPRS-based environment monitoring system and its application in apple production International Conference on Progress in Informatics and Computing (PIC), vol. 1, IEEE (2010), pp. 486-490, 10.1109/PIC.2010.568757 View in ScopusGoogle Scholar Lu et al., 2016 T.-C. Lu, L.-R. Huang, Y. Lee, K.-J. Tsai, Y.-T. Liao, N.-C. Cheng, Y.-H. Chu, Y.-H. Tsai, F.-C. Chen, T.-C. Chiueh Invited – wireless sensor nodes for environmental monitoring in internet of things 53rd Design Automation Conference (DAC), ACM (2016), pp. 1-5, 10.1145/2897937.289860 Google Scholar Luan et al., 2015 Q. Luan, X. Fang, C. Ye, Y. Liu An integrated service system for agricultural drought monitoring and forecasting and irrigation amount forecasting 23rd International Conference on Geoinformatics, IEEE (2015), pp. 1-7 CrossRefGoogle Scholar Lukas et al., 2015 Lukas, W.A. Tanumihardja, E. Gunawan On the application of IoT: monitoring of troughs water level using WSN Conference on Wireless Sensors (ICWiSe), IEEE (2015), pp. 58-62, 10.1109/ICWISE.2015.738035 View in ScopusGoogle Scholar Ma et al., 2012 D. Ma, Q. Ding, Z. Li, D. Li, Y. Wei Prototype of an aquacultural information system based on internet of things E-Nose Intell. Automat. Soft Comput., 18 (2012), pp. 569-579 CrossRefView in ScopusGoogle Scholar Mafuta et al., 2012 Mafuta, M., Zennaro, M., Bagula, A., Ault, G., Gombachika, H., Chadza, T., 2012. Successful Deployment of a Wireless Sensor Network for Precision Agriculture in Malawi. In: 3rd International Conference on Networked Embedded Systems for Every Application (NESEA). IEEE, pp. 1–7. Google Scholar Marino et al., 2010 P. Marino, F.P. Fontán, M.Á. Domínguez, S. Otero An experimental Ad-hoc WSN for the instrumentation of biological models IEEE Trans. Instrum. Meas., 59 (2010), pp. 2936-2948 View in ScopusGoogle Scholar Marjanović et al., 2016 M. Marjanović, L. Skorin-Kapov, K. Pripužić, A. Antonić, I. Podnar Žarko Energy-aware and quality-driven sensor management for green mobile crowd sensing J. Network Comput. Appl., 59 (2016), pp. 95-108, 10.1016/j.jnca.2015.06.023 View PDFView articleView in ScopusGoogle Scholar Mathurkar et al., 2014 Mathurkar, S.S., Patel, N.R., Lanjewar, R.B., Somkuwar, R.S., 2014. Smart sensors based monitoring system for agriculture using field programmable gate array. In: International Conference on Circuit, Power and Computing Technologies (ICCPCT). IEEE, pp. 339–344. Google Scholar Medela et al., 2013 Medela, A., Cendón, B., González, L., Crespo, R., Nevares, I., 2013. IoT Multiplatform networking to monitor and control wineries and vineyards. In: Future Network and Mobile Summit. IEEE, pp. 1–10. Google Scholar Mittal et al., 2012 A. Mittal, K.P. Chetan, S. Jayaraman, B.G. Jagyasi, A. Pande, P. Balamuralidhar mKRISHI wireless sensor network platform for precision agriculture 6th International Conference on Sensing Technology (ICST), IEEE (2012), pp. 623-629, 10.1109/ICSensT.2012.646175 View in ScopusGoogle Scholar Nguyen et al., 2015 Nguyen, T.-D., Thanh, T.T., Nguyen, L.-L., Huynh, H.-T., 2015. On the design of energy efficient environment monitoring station and data collection network based on ubiquitous wireless sensor networks. In: International Conference on Computing & Communication Technologies-Research, Innovation, and Vision for the Future (RIVF). IEEE, pp. 163–168. Google Scholar Pahuja et al., 2013 R. Pahuja, H. Verma, M. Uddin A wireless sensor network for greenhouse climate control IEEE Pervasive Comput., 12 (2013), pp. 49-58 View in ScopusGoogle Scholar Pang et al., 2015 Z. Pang, Q. Chen, W. Han, L. Zheng Value-centric design of the internet-of-things solution for food supply Chain: value creation, sensor portfolio and information fusion Inform. Syst. Front., 17 (2015), pp. 289-319, 10.1007/s10796-012-9374-9 View in ScopusGoogle Scholar Pham et al., 2016 C. Pham, A. Rahim, P. Cousin Low-cost, long-range open IoT for smarter Rural African villages International Smart Cities Conference (ISC2), IEEE (2016), pp. 1-6, 10.1109/ISC2.2016.758082 View in ScopusGoogle Scholar Pokrić et al., 2014 Pokrić, B., Krčo, S., Drajić, D., Pokrić, M., Jokić, I., Stojanović, M.J., 2014. ekoNET - environmental monitoring using low-cost sensors for detecting gases, particulate matter, and meteorological parameters. In: Eighth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing (IMIS), pp. 421–426. http://dx.doi.org/10.1109/IMIS.2014.57. Google Scholar Postolache et al., 2014 O. Postolache, J.D. Pereira, P.S. Girão Wireless sensor network-based solution for environmental monitoring: water quality assessment case study IET Sci., Meas. Technol., 8 (2014), pp. 610-616, 10.1049/iet-smt.2013.0136 View in ScopusGoogle Scholar Postolache et al., 2013 Postolache, O., Pereira, M., Gir ao, P., 2013. Sensor network for environment monitoring: water quality case study. In: 4th Symposium on Environmental Instrumentation and Measurements, pp. 30–34. Google Scholar Roy et al., 2015 Roy, S.K., Roy, A., Misra, S., Raghuwanshi, N.S., Obaidat, M.S., 2015. AID: A prototype for agricultural intrusion detection using wireless sensor network. In: International Conference on Communications (ICC). IEEE, pp. 7059–7064. Google Scholar Ruan and Shi, 2016 J. Ruan, Y. Shi Monitoring and assessing fruit freshness in IoT-Based E-commerce delivery using scenario analysis and interval number approaches Inf. Sci., 373 (2016), pp. 557-570, 10.1016/j.ins.2016.07.014 View PDFView articleView in ScopusGoogle Scholar Ryu et al., 2015 M. Ryu, J. Yun, T. Miao, I.-Y. Ahn, S.-C. Choi, J. Kim Design and implementation of a connected farm for smart farming system In Sensors, IEE (2015), pp. 1-4 Google Scholar Sales et al., 2015 Sales, N., Remédios, O., Arsenio, A., 2015. Wireless sensor and actuator system for smart irrigation on the cloud. In: 2nd World Forum on Internet of Things (WF-IoT). IEEE, pp. 693–698. Google Scholar Sarangi et al., 2016 S. Sarangi, J. Umadikar, S. Kar Automation of agriculture support systems using Wisekar: case study of a crop-disease advisory service Comput. Electron. Agric., 122 (2016), pp. 200-210, 10.1016/j.compag.2016.01.009 View PDFView articleView in ScopusGoogle Scholar Saville et al., 2015 Saville, R., Hatanaka, K., Wada, M., 2015. ICT application of real-time monitoring and estimation system for set-net fishery. In: OCEANS, pp. 1–5. Google Scholar Sawant et al., 2014 S.A. Sawant, J. Adinarayana, S.S. Durbha KrishiSense: a semantically aware web enabled wireless sensor network system for precision agriculture applications Geoscience and Remote Sensing Symposium, IEEE (2014), pp. 4090-4093, 10.1109/IGARSS.2014.694738 View in ScopusGoogle Scholar Shaikh and Zeadally, 2016 F.K. Shaikh, S. Zeadally Energy harvesting in wireless sensor networks: a comprehensive review Renew. Sustain. Energy Rev., 55 (2016), pp. 1041-1054, 10.1016/j.rser.2015.11.010 View PDFView articleView in ScopusGoogle Scholar Shi et al., 2016 W. Shi, J. Cao, Q. Zhang, Y. Li, L. Xu Edge computing: vision and challenges IEEE Internet Things J., 3 (2016), pp. 637-646, 10.1109/JIOT.2016.2579198 View in ScopusGoogle Scholar Shuwen and Changli, 2015 Shuwen, W., Changli, Z., 2015. Study on farmland irrigation remote monitoring system based on ZigBee. In: International Conference on Computer and Computational Sciences (ICCCS). IEEE, pp. 193–197. Google Scholar Sinha et al., 2015a Sinha, A., Shen, Z., Song, Y., Ma, H., Darrin Eide, B.-J.P.H., Wang, K., 2015a. An overview of microsoft academic service (MAS) and applications. In: 24th International Conference on World Wide Web. ACM, pp. 243–246. Google Scholar Sinha et al., 2015b Sinha, N., Pujitha, K.E., Alex, J.S.R., 2015b. Xively Based sensing and monitoring system for IoT. In: International Conference on Computer Communication and Informatics (ICCCI), pp. 1–6. http://dx.doi.org/10.1109/ICCCI.2015.7218144. Google Scholar Sinha et al., 2017 R.S. Sinha, Y. Wei, S.-H. Hwang A Survey on LPWA technology: LoRa and NB-IoT ICT Express, 3 (2017), pp. 14-21, 10.1016/j.icte.2017.03.004 View PDFView articleView in ScopusGoogle Scholar Smarsly, 2013 Smarsly, K., 2013. Agricultural ecosystem monitoring based on autonomous sensor systems. In: 2nd International Conference on Agro-Geoinformatics (Agro-Geoinformatics). IEEE, pp. 402-407. Google Scholar Soontranon et al., 2014 Soontranon, N., Tangpattanakul, P., Srestasathiern, P., Rakwatin, P., 2014. An agricultural monitoring system: field server data collection and analysis on paddy field. In: 14th International Symposium on Communications and Information Technologies (ISCIT). IEEE, pp. 597–601. Google Scholar Sun et al., 2012 E. Sun, X. Zhang, Z. Li The internet of things (IOT) and cloud computing (CC) based tailings dam monitoring and pre-alarm system in mines Safety Sci., 50 (2012), pp. 811-815, 10.1016/j.ssci.2011.08.028 View PDFView articleView in ScopusGoogle Scholar Tao et al., 2014 R. Tao, S. Yang, W. Tan, C. Zhang Secure gateway of internet of things based on AppWeb and secure sockets layer for intelligent granary management system International Conference on Computer and Computing Technologies in Agriculture, Springer (2014), pp. 78-89 CrossRefView in ScopusGoogle Scholar Tarange et al., 2015 Tarange, P.H., Mevekari, R.G., Shinde, P.A., 2015. Web based automatic irrigation system using wireless sensor network and embedded linux board. In: International Conference on Circuit, Power and Computing Technologies (ICCPCT), pp. 1–5. http://dx.doi.org/10.1109/ICCPCT.2015.7159327. Google Scholar Torres-Ruiz et al., 2016 M. Torres-Ruiz, J.H. Juárez-Hipólito, M.D. Lytras, M. Moreno-Ibarra Environmental noise sensing approach based on volunteered geographic information and spatio-temporal analysis with machine learning International Conference on Computational Science and Its Applications, Springer (2016), pp. 95-110 CrossRefView in ScopusGoogle Scholar Vo et al., 2013 Vo, T.T., Nguyen, T.D., Vo, M.T., 2013. Ubiquitous sensor network for development of climate change monitoring system based on solar power supply. In: International Conference on Advanced Technologies for Communications, pp. 121–124. http://dx.doi.org/10.1109/ATC.2013.6698090. Google Scholar Wang and Yue, 2017 J. Wang, H. Yue Food safety pre-warning system based on data mining for a sustainable food supply Chain Food Control, 73 (2017), pp. 223-229, 10.1016/j.foodcont.2016.09.048 View PDFView articleGoogle Scholar Wang et al., 2016 Y. Wang, Y. Liu, C. Wang, Z. Li, X. Sheng, H.G. Lee, N. Chang, H. Yang Storage-less and converter-less photovoltaic energy harvesting with maximum power point tracking for internet of things IEEE Trans. Comput. Aided Des. Integr. Circuits Syst., 35 (2016), pp. 173-186, 10.1109/TCAD.2015.2446937 View in ScopusGoogle Scholar Watthanawisuth et al., 2009 Watthanawisuth, N., Tuantranont, A., Kerdcharoen, T., 2009. Microclimate real-time monitoring based on zigbee sensor network. In: Sensors. IEEE, pp. 1814–1818. Google Scholar Wong and Kerkez, 2016 B.P. Wong, B. Kerkez Real-time environmental sensor data: an application to water quality using web services Environ. Modell. Software, 84 (2016), pp. 505-517, 10.1016/j.envsoft.2016.07.020 View PDFView articleView in ScopusGoogle Scholar Xijun et al., 2009 Xijun, Y., Limei, L., Lizhong, X., 2009. The application of wireless sensor network in the irrigation area automatic system. In: International Conference on Networks Security, Wireless Communications and Trusted Computing (NSWCTC), vol. 1. IEEE, pp. 21–24. Google Scholar Xu et al., 2015 Xu, J., Zhang, J., Zheng, X., Wei, X., Han, J., 2015. Wireless sensors in farmland environmental monitoring. In:International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery, pp. 372–379. http://dx.doi.org/10.1109/CyberC.2015.17. Google Scholar Ye et al., 2013 Ye, J., Chen, B., Liu, Q., Fang, Y., 2013. A precision agriculture management system based on internet of things and WebGIS. In: 21st International Conference on Geoinformatics, pp. 1–5. http://dx.doi.org/10.1109/Geoinformatics.2013.6626173. Google Scholar Yoo et al., 2007 Yoo, S.E., Kim, J.E., Kim, T., Ahn, S., Sung, J., Kim, D., (2007). A2S automated agriculture system based on WSN. In: IEEE International Symposium on Consumer Electronics, pp. 1–5. http://dx.doi.org/10.1109/ISCE.2007.4382216. Google Scholar Zhao and Zhu, 2015 Zhao, L., Zhu, X., 2015. The development of remote monitoring system for cultivation environment of pleurotus eryngii. In: International Conference on Information and Automation. IEEE, pp. 2643–2648. Google Scholar Zheng et al., 2016 R. Zheng, T. Zhang, Z. Liu, H. Wang An EIoT system designed for ecological and environmental management of the Xianghe segment of china’s grand canal Int. J. Sustain. Dev. World Ecol., 23 (2016), pp. 372-380, 10.1080/13504509.2015.1124470 View in ScopusGoogle Scholar Zou, 2014 C.-J. Zou Research and implementation of agricultural environment monitoring based on internet of things 5th International Conference on Intelligent Systems Design and Engineering Applications (ISDEA), IEEE (2014), pp. 748-752, 10.1109/ISDEA.2014.17 View in ScopusGoogle Scholar Cited by (388) Digital twin framework for smart greenhouse management using next-gen mobile networks and machine learning 2024, Future Generation Computer Systems Show abstract Intelligent decision-making framework for agriculture supply chain in emerging economies: Research opportunities and challenges 2024, Computers and Electronics in Agriculture Show abstract Towards online surface water quality monitoring technology: A review 2023, Environmental Research Show abstract LS-AKA: A lightweight and secure authentication and key agreement scheme for enhanced machine type communication devices in 5G smart environment 2023, Sustainable Energy Technologies and Assessments Show abstract Internet of Things in food processing and its potential in Industry 4.0 era: A review 2023, Trends in Food Science and Technology Show abstract Developing a causal framework of internet of things adoption barriers for agile manufacturing in post COVID-19 2024, International Journal of Engineering Business Management View all citing articles on Scopus View Abstract © 2017 Elsevier B.V. All rights reserved. Recommended articles Application note: Labelling, a methodology to develop reliable algorithm in PLF Computers and Electronics in Agriculture, Volume 142, Part A, 2017, pp. 424-428 Emanuela Tullo, …, Marcella Guarino View PDF Automation of Agriculture Support Systems using Wisekar: Case study of a crop-disease advisory service Computers and Electronics in Agriculture, Volume 122, 2016, pp. 200-210 Sanat Sarangi, …, Subrat Kar View PDF Multi-hop communication in the uplink for LPWANs Computer Networks, Volume 123, 2017, pp. 153-168 Sergio Barrachina-Muñoz, …, Albert Bel View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 367 Policy Citations: 7 Captures Readers: 975 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply.

Paper 5:
- APA Citation: None
  Main Objective: None
  Study Location: None
  Data Sources: None
  Technologies Used: None
  Key Findings: None
  Extract 1: "Everything is related to everything else, but near things are more related than distant things"
  Extract 2: The paper combines data from different sources and uses methods from spatial statistics and geostatistics to analyze patterns and relationships in the data. Statistical analysis can often produce misleading results when spatial relationships are not considered.
  Limitations: None
  Relevance Evaluation: Highly relevant - The paper directly supports the point by explaining that traditional statistical analysis methods do not account for the spatial relationships in data and that the methods proposed in the paper do.
  Relevance Score: 1.0
  Inline Citation: None
  Explanation: The paper combines data from different sources and uses methods from spatial statistics and geostatistics to analyze patterns and relationships in the data. Statistical analysis can often produce misleading results when spatial relationships are not considered. Therefore, the paper builds on the first law of geography to account for such relationships: everything is related to everything else, but near things are more related than distant things.

 Full Text: >


Citation: de Azevedo, L.J.d.M.;
Estrella, J.C.; Delbem, A.C.B.;
Meneguette, R.I.; Reiff-Marganiec, S.;
de Andrade, S.C. Analysis of
Spatially Distributed Data in Internet
of Things in the Environmental
Context. Sensors 2022, 22, 1693.
https://doi.org/10.3390/s22051693
Academic Editors: Fangyu Li and
Naveen Chilamkurti
Received: 17 October 2021
Accepted: 21 December 2021
Published: 22 February 2022
Publisher’s Note: MDPI stays neutral
with regard to jurisdictional claims in
published maps and institutional afﬁl-
iations.
Copyright:
© 2022 by the authors.
Licensee MDPI, Basel, Switzerland.
This article is an open access article
distributed
under
the
terms
and
conditions of the Creative Commons
Attribution (CC BY) license (https://
creativecommons.org/licenses/by/
4.0/).
sensors
Article
Analysis of Spatially Distributed Data in Internet of Things in
the Environmental Context
Leonildo José de Melo de Azevedo 1,*
, Júlio Cezar Estrella 1
, Alexandre C. B. Delbem 1
,
Rodolfo Ipolito Meneguette 1
, Stephan Reiff-Marganiec 2
and Sidgley Camargo de Andrade 3
1
Institute of Mathematics and Computer Science, University of São Paulo, Sao Paulo 13560-970, SP, Brazil;
jcezar@icmc.usp.br (J.C.E.); acbd@icmc.usp.br (A.C.B.D.); meneguette@icmc.usp.br (R.I.M.)
2
School of Electronics, Computing and Maths, University of Derby, Kedleston Rd., Derby DE22 1GB, UK;
S.Reiff-Marganiec@derby.ac.uk
3
Computing Department, Federal University of Technology—Paraná, R. Cristo Rei, 19,
Toledo 85902-490, PR, Brazil; sidgleyandrade@utfpr.edu.br
*
Correspondence: leonildo.azevedo@usp.br
Abstract: The Internet of Things consists of “things” made up of small sensors and actuators capable
of interacting with the environment. The combination of devices with sensor networks and Internet
access enables the communication between the physical world and cyberspace, enabling the develop-
ment of solutions to many real-world problems. However, most existing applications are dedicated
to solving a speciﬁc problem using only private sensor networks, which limits the actual capacity
of the Internet of Things. In addition, these applications are concerned with the quality of service
offered by the sensor network or the correct analysis method that can lead to inaccurate or irrelevant
conclusions, which can cause signiﬁcant harm for decision makers. In this context, we propose two
systematic methods to analyze spatially distributed data Internet of Things. We show with the results
that geostatistics and spatial statistics are more appropriate than classical statistics to do this analysis.
Keywords: Internet of Things; quality of data; data analyze; geostatistics; spatial statistics
1. Introduction
Nowadays, it is possible to easily access services and data through the Internet from
any place and at any moment. It can be observed from recent decades that computational re-
sources are becoming increasingly accessible and more powerful. Furthermore, the number
of devices connected at the Internet has increased exponentially increase and is projected
to amount to 75.44 billion worldwide by 2025 (https://www.statista.com/statistics/47
1264/iot-number-of-connected-devices-worldwide/ (23 November 2020)). According to
Cisco Annual Internet Report (2018–2023) (https://www.cisco.com/c/en/us/solutions/
collateral/executive-perspectives/annual-internet-report/white-paper-c11-741490.html),
the number of devices connected to Internet Protocol (IP) networks will be more than
three times the global population by 2023. However, these numbers only refer to devices
such as computers, smartphones, and tablets; if considered other devices such as sensors,
this number would be double easily. With many connections, devices communicating with
humans and other devices have enabled the development of a paradigm called the Internet
of Things (IoT) [1].
IoT involves anything with network access, for instance, sensors to advise on localized
fertilizer amounts or targeted pesticide use, self-monitoring health systems, air quality,
and trafﬁc routing [2,3]. These sensors have the ability to transfer data over a network
with or without requiring humans, and these data can be provided in many forms, such as
streaming and discrete data, images, and social media, among others. The combination of
sensors network with the Internet enables the communication between the virtual and the
real world, allowing the decision-making without human intervention.
Sensors 2022, 22, 1693. https://doi.org/10.3390/s22051693
https://www.mdpi.com/journal/sensors
Sensors 2022, 22, 1693
2 of 21
According to economic analysis from Cisco, “IoT will generate $8 trillion worldwide
in Value at Stake over the next decade. This will come from ﬁve primary drivers: innova-
tion and revenue ($2.1 trillion); asset utilization ($2.1 trillion); supply chain and logistics
($1.9 trillion); employee productivity improvements ($1.2 trillion); and enhanced customer
and citizen experience ($700 billion)” (https://newsroom.cisco.com/press-release-content?
articleId=1621819). By not considering many factors that involve quality of service or even
a correct data analysis, it can probably cause ﬁnancial losses to organizations. Some real
cases can be cited, such as the following: (1) Gartner has an annual cost because of poor
data in 2014 on average of $13.3 million dollars [4]; (2) The US Postal Service has ﬁnance
losses over $1.5 billion due to mail with wrong data [5]. The US economy has ﬁnance losses
of over $3 trillion a year [6].
The problem of data quality becomes complex and controversial with technology
evolution. With signiﬁcant ﬁnancial losses caused by weak data, these problems have
become the focus of much research from many perspectives. However, most of these works
are dedicated to solving a speciﬁc problem in a particular environment. With close ﬂow,
it is difﬁcult to consider the real capacity of IoT, since there is no sharing of information.
Furthermore, another problem is the accuracy of data quality in decision-making.
The data quality and data accuracy are also related to the data analysis [7–9]; i.e., an
incorrect data visualization or wrong method analysis could lead to misinterpretations
or wrong decision making, even if the data are collected correctly. In this context, this
article puts forward a systematic approach to support the data analysis by considering
the sensor spatiality factor and geographic aspects. To validate this approach, we applied
the methods on an extensive real-world database from the United States Environmental
Protection Agency (US EPA), speciﬁcally involving air quality data; we describe the dataset
in Section 4. The main contributions of the paper are as follows:
•
A data analysis approach for outdoor sensors based on geostatistic data: a non-classic
statistical approach to IoT data analysis, which it is not used on the majority works,
due to the data limitation, the scenario space of the analysis, and the fact that the data
are not from the real world;
•
A data analysis approach for outdoor sensors based on spatial statistics: like the above-
mentioned approach, however, here we analyze data in a discrete space (delimited by
a boundary), and in geostatistic data, it considers a continuous geographic area;
•
A structuring of several methods from geostatistics and spatial statistics aggregated
with a multicriteria analysis to compose a systematic data analysis on outdoor sensors:
this is our main contribution, where we structured an outdoor sensors’ data analysis
approach considering the geographic data dispersion and conﬂicted indicators;
•
An assessment of the proposed method and comparing other works that apply classi-
cal statistics.
The rest of the paper is organized as follows. In Section 2, is works related to IoT
data quality and data analysis. Section 3 introduces essential concepts to the method.
The proposed method analysis is described in Section 4. A case study to apply the methods
is presented in Section 5. The application and comparison with the existing techniques are
described in Section 6. Finally, Section 7 discusses the outcomes and recommendations for
further work.
2. Related Works
The Internet of Things is a highly scalable environment in which the data generated
are tremendous. Thus, the quality of information is becoming an issue of great interest
in both the academic and the industrial worlds. In this section, we discuss some of the
works related to data quality in IoT. Moreover, we also discuss the practices related to the
application domain of this paper and the related works to the methods that we proposed
as a solution to make the best data analysis with spatially distributed data.
Sensors 2022, 22, 1693
3 of 21
2.1. Data Quality in Internet of Things
There are many works in the literature that address quality of service and data ma-
nipulation in IoT. For instance, some works apply a publish–subscribe methodology to
simplify the integration between sensors and the cloud [10–12]. However, these solutions
do not assess the accuracy of the data or the analysis.
Other works try to apply particular solutions, such as a model-driven framework, to
data quality management [13], and a Blockchain-based approach was attempted in [14].
These solutions aim to improve IoT data quality and false data detection. On the other
hand, the solutions are applied in speciﬁc architectures and do not present a robust analysis
of the generated data.
There are some authors who propose solutions on ontology-based [15,16], where they
had a focus on identifying missing data or using the quality of information as an indicator
of IoT trust [15]. Although these solutions even present a math solution model, they do
not present an assessment or application evaluation of the real-world environment or even
real data.
In [17], the authors propose an attractive solution for data cleaning by an incorrect
data detection method based on an improved local outlier factor. Although the proposed
method was used to detect inaccurate data from ofﬂine data, the solution achieved excellent
performance to identify poor data. However, this solution identiﬁes the incorrect data only
from the collection point and does not consider the visualization or analysis method.
Another work with a similar proposal is [18], where the authors developed a data
quality analysis and cleaning strategy for wireless sensor networks. For this, the authors
studied the impact of the relationship between different indicators on the quality assessment
during data cleaning. Although the authors performed some simulations, they did not
evaluate the solution in a real-world environment; moreover, just like the previous work,
they considered only the data from the sensor’s point.
There are also several other works related to the quality of data originating from the
sensors [19–21]. In [19], the authors designed a prototypical implementation of a distributed
IoT middleware layer to manage heterogeneous data sources. In [20], the authors propose
an altruistic approach to data quality assessment for sensor data. Furthermore, in [21],
the authors present a framework to evaluate and control data quality aspects when dealing
with social and sensor data. However, all of these works address only the data quality in
the collection point and speciﬁc scenarios; our proposal aims to show how to visualize and
build a correct analysis with IoT spatially distributed data.
The authors of [7], speciﬁcally disucss the state of the art of the data quality of the
Internet of Things. According to [7], the data generated in global scale deployment are
tremendous, and there are many open challenges related to data quality. The authors also
presented a detailed survey about quality features and the signiﬁcance of a robust and
accurate data analysis. In this paper, we apply geostatistics and spatial statistics to make a
precise data analysis in IoT on the environmental context.
2.2. Environment and Pollution Context in IoT
To evaluate our proposal, we applied the methods on an extensive real-world IoT
database from the United States Environmental Protection Agency (USEPA), which we
described in Section 4. Notably, the environment subject is also a relevant research topic.
For this reason, we also researched in the literature on how the data are analyzed in
this ﬁeld.
Exciting work in this ﬁeld analyzed the impact of COVID-19 on people’s lives and
the natural environment [22]. For this purposed, the authors investigate the spatial and
temporal characteristics of the Air Quality Index (AQI) before and during the pandemic in
mainland China. The authors present several analyses with respect to this theme; however,
all of them apply classical statistical analysis. In this paper, we show that IoT spatially
distributed data request a different interpretation.
Sensors 2022, 22, 1693
4 of 21
There also other works that utilized the USEPA dataset to analyze the environmental
context [23,24]. In [23], the authors conducted a comparative study of AQI based on factor
analysis and USEPA methods for an urban environment. Furthermore, in [23], the authors
did not use the USEPA but used the same recommended method for health risk assessment
in a similar dataset in China. In both works, the authors used traditional statistics to analyze
speciﬁc points, which could not show the real context of the region.
In the same ﬁeld, there is a project being conducted at the Alan Turin Institute called
London Air Quality (https://www.turing.ac.uk/research/research-projects/london-air-
quality). This project utilizes city-wide air quality sensors to develop solutions to un-
derstand and improve air quality over London. This group’s research has achieved im-
pressive results by applying machine learning algorithms and proposing data science
platforms [25–30]. In this paper, we propose a different solution by spatial autocorrelation
analysis, focusing on data analysis and data visualization.
2.3. Spatial Autocorrelation
Spatial autocorrelation is an association indicator from Geographic Information Science
(GIScience) [31,32]; we discuss this in Section III. This theme has been subject of many
studies [33]. In [34], the authors discuss the big spatiotemporal data analytics as a research
and innovation frontier, and one of the ﬁelds that is considered promising is the IoT.
There are in the literature some authors who propose applying geostatistics in the IoT
environment in many different ways [35–37]. However, these works do not demonstrate
the application method with concrete results, and they also do not propose a systematic
way to apply the techniques—some of them only discuss the potential.
In a recent study [38], the authors investigated rainfall-related tweets to determine
the areal units that optimize spatial autocorrelation patterns through the combined use of
indicators of global spatial autocorrelation and the variance of local spatial autocorrelation.
In our study, we propose using the same technique to scale the ideal areal units to analyze
the data.
In this paper, we propose a systematic approach to support the data analysis and the
decision makers by considering the sensor spatiality factor and geographic aspects. For this
purpose, we applied methods from the spatial statistics and geostatistic ﬁelds.
2.4. Proposal Highlight
To highlight our contribution, we present in Table 1 the main features of the related
works, with the following columns:
•
Related work: reference to the related work addressed;
•
Environment: the experimental environment, either Real world (e.g., a prototype) or
Simulator (i.e., a simulated experiments in a ﬁctitious environment);
•
Spatial: whether the approach considers the spatial dispersion in the analysis;
•
QoD: whether the approach considers the QoD attributes in the data analysis;
•
Multi-criteria analysis: whether the approach treats the problem as a multi-objective
problem and/or considers any conﬂicting objectives.
By analyzing Table 1, we can observe that our proposal focuses on accurate analysis.
For this purpose, we use only real-world data to validate our method, geostatistics and
spatial statistics to consider the spatial data dispersion, and a multicriteria analysis to
resolve the conﬂicting objectives. We present the results below.
Sensors 2022, 22, 1693
5 of 21
Table 1. Main features of the related works.
Related Work
Environment
QoD
Multi-Criteria Analysis
Spatial
Antonic, A. et al. [10]
Simulator
X
X
X
Alam, S. and Noll, J. A. [11]
Simulator
X
X
X
Kothari, A. et al. [12]
Simulator
√
X
X
Karkouch, A. et al. [13]
Simulator
X
X
X
Xu, X.; Lei, Y.; and Li, Z. [17]
Real World
√
X
X
Cheng, H. et al. [18]
Simulator
√
X
X
Liu, Q. [22]
Real World
X
X
X
Li, Z. et al. [24]
Real World
X
X
X
Habibia, R. [37]
Simulator
X
X
√
de Andrade, S.C. et al. [38]
Real World
X
√
√
This paper
Real world
√
√
√
3. Geographic Information Science
Spatial statistics and geostatistics are methods from the Geographic Information
Science (GIScience) ﬁeld that encompass a wide array of disciplines, such as geography,
cartography, geodesy, statistics, and computer science. GIScience considers the nature of
geographic information to develop theories and methods for understanding geographic
processes, relationships, and patterns at different geographical scales [31,32]. GIScience
also includes social disciplines that address issues and impacts on society.
3.1. Spatial Data Analysis
In the GIScience ﬁeld, the spatial data analysis is consider a central topic. It deals
with “a collection of techniques and models that explicitly use the spatial referencing asso-
ciated with each data value or object that is speciﬁed within the system under study” [39].
These methods are crucial to assess spatial relationships and assumptions in spatially
distributed data.
There are two fundamental concepts in spatial data analysis: (1) spatial autocorrelation,
which refers to the degree of dependence from similar objects near to others, and (2) spatial
heterogeneity, which is related to structure of these objects [40]. Analyzing these concepts
makes it possible to answer questions such as “how much does the economics of one
neighborhood inﬂuence another?” and we also hope to answer the questions “what is the
correct areal unit to analyze a set of sensors?” and “How can spatially distributed data be
analyzed?”
3.2. Spatial Autocorrelation
The geography scale, aggregation, and detail level are essential to construct an appro-
priate representation of the world, i.e., according to the process of handling the aggregation
of delimited the unit spaces, the data could show different values and interpretations [40].
In this context, different measures from the real world can covariate, and understanding
the spatial correlation essence could help to understand the analyzed phenomena better.
Spatial autocorrelation is directly related with the ﬁrst law of geography or Tobler’s
law, which says “everything is related to everything else, but near things are more related
than distant things” [41]. This law is a fundamental premise for spatial statistics, and could
also be interpreted as a deﬁnition for the positive spatial autocorrelation. The opposite of
the law implies a negative spatial autocorrelation when places close to each other have
high spatial heterogeneity.
The interrelation between the features of a location is an essential aspect of the geogra-
phy data, which is crucial for real-world comprehension [42]. However, this interrelation is
a challenge for classic statistics due to the majority method to consider the independence of
the observations without spatial correlation.
Sensors 2022, 22, 1693
6 of 21
4. Methods
To analyze spatially distributed data in IoT, we propose the use of two methods from
the GIScience ﬁeld. The ﬁrst one (statistical spatial) is a framework proposed by [38] based
on Moran’s index [43], and the second one (geostatistic) is an interpolation method for a
correct data visualization [44]. Table 2 describes the main variables used in this work.
Table 2. List of important notation.
Term
Description
wij
matrix unit weight
yi
the value of interest on location
y
the mean of interest on location
n
the total observations
I
the Moran’s index
Ii
the Moran’s LISA for each map unit
X
a set of any areal units with different levels of data aggregation
φ
objective functions
Z(Si)
a known value at the location
λi
an unknown weight for the measured value at the location
S0
the location with data unknown to prediction
N
the number of measured values
4.1. A Framework to Deﬁnition of the Spatial Granularity
To measure the spatial autocorrelation level, it is possible to use an index that may
vary between 1 and −1: 1 for the high positive spatial autocorrelation, −1 for high negative
spatial autocorrelation, and 0 for the absence of spatial autocorrelation [45].
There are two types of indexes for this association: a global and other local. The global
coefﬁcient correlation measures the overall spatial autocorrelation of the data set, with only
one index value. On the other hand, the local indicator of spatial autocorrelation (LISA)
measures different levels of spatial relationships; it depends on the scale deﬁned, such as
district, county, state, country, etc.
The most common global and local indexes are calculated by Moran’s I. The global
Moran’s I is the result of the Equation (1) [46].
I =
n
∑n
i ∑n
j wij
·
∑n
i ∑n
j wij(yi − y)(yj − y)
∑n
i (yi − y)2
(1)
where
wij, is the matrix unit weight, wij = 1 if i and j are neighbors, and wij = 0 otherwise;
yi and y represent the value and the mean of interest on location i;
n is the total observations; and, I is the Moran’s index, a metric used to test the hypothesis
about spatial autocorrelation.
The Moran’s I aims to test the spatial independence (null hypothesis). In this context,
the null hypothesis is true if its value is zero. Positive values, between 0 and 1, point to a
positive autocorrelation, and negative values, between 0 and −1, indicate negative autocor-
relation.
This local indicator utilization together with the global index improves knowledge
about the process from which the spatial dependence originates. The LISA makes a speciﬁc
value for each object, which can identify clusters, outliers, and the existence of more than
one spatial pattern.
Sensors 2022, 22, 1693
7 of 21
According to [46], a LISA should adhere to two objectives: (1) to allow the identiﬁcation
of signiﬁcant spatial associate patterns and (2) to be a decomposition from the global spatial
association index. Equation (2) show Moran’s LISA calculation.
Ii =
(yi − y) ∑n
j=1 wij(yj − y)
∑n
i=1(yi−y)2
n
(2)
where
wij, is the matrix unit weight, wij = 1 if i and j are neighbors, and wij = 0 otherwise;
yi and y represent the value and the mean of interest on location i;
n is the total observations; and, Ii is the Moran’s LISA for each map unit.
In Equation (2), an Ii > 0 means that i has values very similar to its neighbors (positive
spatial autocorrelation), and Ii < 0 means that i has different values from the neighbors
(negative spatial autocorrelation). Furthermore, analogously to the global indicators,
the Moran’s LISA should be evaluated by the pseudo-signiﬁcance test.
As demonstrated in [38], the determination of an optimal areal unit for spatial analysis
is a complex task owing to the Modiﬁable Areal Unit Problem (MAUP) effects, differences in
the ﬁelds of application, and uncertainties and conﬂicts arising from the different potential
spatial indicators to be used. For this reason, it is necessary to select the candidate solution
(optimal areal unit) by a Pareto ranking [47].
To apply Pareto ranking in this framework [38], in order to model a solution, let X be
a set of any areal units with different levels of data aggregation. Each spatial granularity
of aggregation x ∈ X is characterized by different criteria that will be optimized by a set
of objective functions; in this case, the global and local indexes. A vector containing m
objective functions φm can be represented by
Φ(x) = [φ1(x), φ2(x), · · · , φm(x)] ∈ Rm
(3)
A Pareto-optimal solution only contains areal units that are not Pareto-dominated by
any other areal unit [38]. In general terms, an areal unit xi ∈ X dominates another xj ∈ X
when it has satisﬁed the following two constraints:
(i)
∀φ ∈ Φ : φ(xi) ⪯ φ(xj), and
(ii)
∃φ ∈ Φ : φ(xi) ≺ φ(xj)
where ≺ and ⪯ correspond to the ‘general better’ and ‘better or equal’ relations, depending
on whether the objective function refers to maximization or minimization. It is possible
to obtain more than one Pareto Frontier according to the ranking or even two or more
solutions in the Pareto-optimal areal units; in this case, additional human expertise is
required for the selection of a proper areal unit.
In Algorithm 1, we present a systematic way to use this framework. First, we provide
the input data (line 1); in this paper, we use a pollution data set described in Section 5.
The ﬁrst step of the method is to model the candidate’s areal unit solution, and here it
deﬁnes the size of the areal unit to make the data aggregation (line 3). In the second step
(line 4), it assesses the candidate’s areal unit by the deﬁned criteria; in this case, they are
the global and local autocorrelation index (Global Moran’s I and the coefﬁcient of variation
of Local Moran’s I, respectively). The last step is to select an “optimal” areal unit from the
non-dominated Pareto frontier (line 5).
4.2. Data Interpolation
For a coherent data visualization and correct data measure, we apply a data interpola-
tion method, namely Kriging [44]. This technique is a regression method from geostatistic
to data interpolation, i.e., to estimate values in unknown data points. In Figure 1, we show
an example situation, where we would like to know the temperature from a local that does
not have spatial information available.
Sensors 2022, 22, 1693
8 of 21
Algorithm 1 Multicriteria for the selection of an optimal areal unit
1: Input data: pollution data at an individual level (the pollution data in our application)
2: for each areal unit on set of criteria, do
3:
Modeling of candidate areal unit
4:
Evaluation of an candidate areal unit (MCDA)
5:
Selection of the optimal areal unit (non-dominated solution)
6: end for
7: return Optimal areal unit
Figure 1. Example of the need to estimate a value that does not have spatial information available.
There are many other data interpolation techniques in the GIScience ﬁeld [42]. How-
ever, the Kriging method allows for incorporating three factors to improve the estimation
accuracy: (1) local ﬂuctuation, which makes it possible to analyze the spatial autocorrela-
tion during the data interpolation; (2) noise, which makes it possible to identify random
changes space independent, i.e., detect errors in the collected data; and (3) incorporating
general trends as an auxiliary variable, e.g., using a model with similar behavior to help in
the estimation. More details about any of those factors can be found in [42].
Kriging’s technique measures the surrounding values to derive a prediction for a
location with unknown data. The Kriging interpolation formula is formed as a weighted
sum of the data, as described in Equation (4).
ˆZ(S0) =
N
∑
i=1
λiZ(Si)
(4)
where
Z(Si) is a known value at the location i,
λi is an unknown weight for the measured value at the location i,
S0 is the location with data unknown to the prediction, and
N is the number of measured values.
In the Kriging method, the λi is dependent on a ﬁtted model to the value locations,
the spatial relationship among the known values that surround the prediction location,
and the distance from the known points to the prediction location. Therefore, it is necessary
to create the variograms and covariance functions to estimate the statistical dependence to
make a ﬁtted model to the measured points. Details about the ﬁtted model features, as well
the variograms and covariance functions, can be found in [42].
We show in Figure 2 the systematic way that apply the Kriging interpolation in
the IoT context. First, we normalize the input data and build a shapeﬁle from the local
area; the map is only for visualization. The second step is to model the variogram (i.e.,
Sensors 2022, 22, 1693
9 of 21
to construct the ﬁtted model) and then apply the Kriging method. The last step is to make
the map interpolation.
To normalize the data values, we use the bestNormalize (https://cran.r-project.org/
web/packages/bestNormalize/index.html) package from the R language. Furthermore,
we developed all of the systematic methods in R, which are available in https://github.
com/Leonild/SpatialDataAnalysis.
To normalize the
values
To create a map
from the location
To build the fitted
model
To make the map
interpolation
To apply the
Kriging method
Figure 2. A systematic way that we use to apply the Kriging interpolation on the IoT context.
5. Case Study
In recent years, high levels of pollution in speciﬁc dry periods of the year have
forced authorities to rethink the organizational strategy of cities and propose drastic
changes in urban centers. According to the World Health Organization (WHO) (https:
//www.who.int/), half of the world’s population lives in urban centers, and the estimate
for 2050 is that 70% of the population will be urban [48]. This means that urban development
will have a direct impact on human health.
Human health is affected by several correlated factors, factors that go beyond the
power of health agencies. These include residences, sanitation, transportation, the energy
system, and parks with green spaces, in addition to decent jobs, education, and healthy
food [49].
With population growth, by 2050, it is estimated that 2.5 billion people will inhabit
cities in addition to those who already inhabit them. This presents a unique opportunity to
plan cities that protect and promote public health through well-structured organization.
In this context, pollution has drawn a great deal of attention, causing irreversible damage to
the planet, as well as global warming, respiratory diseases, and extinction of microbiomes,
among others [50,51].
To assess our approach in this context, we chose an extensive real-world IoT database
to analyze. This database is from the United States Environmental Protection Agency
(US-EPA) (https://www.epa.gov/) (download available at aqs.epa.gov/aqsweb/airdata/
download_ﬁles.html), which has millions of records (updated daily with new data) to
four pollutants, Nitrogen Dioxide (NO2), Sulfur Dioxide (SO2), Carbon Monoxide (CO),
and Ozone (O3). The database contains 28 ﬁelds described in Table 3. These data come
Sensors 2022, 22, 1693
10 of 21
from sensors around all US countries from the years 2000 until the present. We show in
Figure 3 the position of the sensors in 2020, including information about SO2.
Figure 3. Positions of sensors, which collect information about SO2. Source: epa.gov/outdoor-air-
quality-data/interactive-map-air-quality-monitors.
Table 3. Description of the EPA database 28 ﬁelds.
Database Fields
1
Index
15
O3 Unit
2
State Code
16
O3 1st Max Value
3
County Code
17
O3 1st Max Hourn
4
Site Num (Local in a county)
18
O3 AQI
5
Adress (Street, number. . . )
19
SO2 Units (description)
6
State (name)
20
SO2 Mean
7
County (name)
21
SO2 1st Max Value
8
City (name)
22
SO2 1st Max Hourn
9
Date Local
23
SO2 AQI
10
NO2 Units (description)
24
CO Units (description)
11
NO2 Mean
25
CO Mean
12
NO2 1st Max Value
26
CO 1st Max Value
13
NO2 1st Max Hourn
27
CO 1st Max Hourn
14
NO2 AQI
28
CO AQI
In this study, we use the Air Quality Index (AQI) as the observation variable. The AQI
indicates how harmful the air is to human health. We show in Table 4 the AQI basics for
ozone and particle pollution. In Table 4, the meaning of the colors is as follows: green,
air quality is satisfactory, and air pollution poses little or no risk; yellow, air quality is
acceptable, but there may be a risk for some people, particularly those who are unusually
sensitive to air pollution; orange, members of vulnerable groups may experience health
effects (the general public is less likely to be affected); red, some members of the general
public may experience health effects, and members of sensitive groups may experience
more serious health effects; purple, the risk of health effects is increased for everyone;
maroon, health warning of emergency conditions, everyone is more likely to be affected.
Sensors 2022, 22, 1693
11 of 21
Table 4. AQI basics for Ozone and Particle Pollution. Source: www.airnow.gov/aqi/aqi-basics.
AQI Color
Levels of Concern
Values of Index
Green
Good
0 to 50
Yellow
Moderate
51 to 100
Orange
Unhealthy for Sensitive Groups
101 to 150
Red
Unhealthy
151 to 200
Purple
Very Unhealthy
201 to 300
Maroon
Hazardous
301 and higher
The index for a pollutant is calculated using the mathematical expression of the
Equation (5) [23].
IP =
IHi − ILO
BPHi − BPLO
(CP − BPLO) + ILO
(5)
where,
IP is the index value for pollutant, P;
CP is the truncated concentration of pollutant, P;
BPHi is the breakpoint that is ≥CP;
BPLO is the breakpoint that is ≤CP;
IHi is the AQI value corresponding to BPHi;
and, ILO is the AQI value corresponding to BPLO.
In this context, we executed experiments aim to determine the areal units that optimize
spatial autocorrelation patterns through the combined use of indicators of global spatial
autocorrelation and the variance of local spatial autocorrelation. Furthermore, we applied
the Kriging interpolation method for data visualization. Thus, we validate our approach,
and at the same time, we contribute to solving a real-world problem.
Study Areal Description
To evaluate the methods in these data, we chose two areal unit dimensions: a large
one that involves the whole sensors described in Figure 3, and a small one, which includes
the entire sensors in the state of California. We choose California due to the high variability
between sensors’ values and the considerable number and distribution of sensors.
According to United Nations Statistics Division [52], the United States of America
(USA) has a total area of 9,629,091 km2, and California is the third-largest by area at
423,970 km2 (it is also the most populous USA state). The surface in both areal unit
dimensions were partitioned into hexagonal areal units, where each spatial unit aggregated
the AQI’s pollutants. Furthermore, the hexagonal shape reduced the visual ﬁeld bias when
compared with the square units [53].
6. Computational Results
We implemented the experimental programs in Python (data prepossessing), and we
made the geostatistic and spatial statistical methods in the R language; this made it possible
to ﬁnd all code and experimental data in our public repository (https://github.com/
Leonild/SpatialDataAnalysis).
To evaluate our approach, ﬁrst, we applied the framework described on Section 4.1
to determine the areal units that optimize the spatial autocorrelation patterns through the
combined use of indicators of global and local spatial autocorrelation; this returns what
the best areal unit to make data analysis is. Then, we applied the interpolation method
described in Section 4.2, to an accurate data visualization. Furthermore, we compared the
results with the works that use the classical statistics, to provide evidence that the analysis
method could lead to wrong interpretations.
Sensors 2022, 22, 1693
12 of 21
6.1. Spatial Statistics Analysis
Following Algorithm 1, we modeled the candidates’ areal units by regular hexagon
shape, and we determined the length of the sides in ﬁve scales: 100 km, 200 km, 300 km,
400 km, and 500 km. Furthermore, we analyzed for all the pollutants, but here, due to
the number of the images and very similar characteristics, we present results for only one
pollutant (O3).
Figure 4 shows Global Moran’s I coefﬁcient and the coefﬁcient of variation of Local
Moran’s I for the areal units. Only some of the areal units show an improvement, with
higher Global Moran’s I and lower coefﬁcient of variation of Local Moran’s I. The other
areal units just keep values that represent the absence of spatial autocorrelation and with
high variation of Local Moran’s I. In this experiment, an areal unit of 200 km is linked to a
higher pattern of spatial association and lower spatial heterogeneity than the other areal
units; i.e., the former provides more consistent spatial patterns and is thus likely to reﬂect
more reliable analytical results.
To analyze the chart from Figure 5, we should remember the conﬂicting objectives that
we considered; in this case, the ideal solution should have a higher Global Moran’s I (GM)
and a lower coefﬁcient of variation of Local Moran’s I (LM). Let us look at Figure 5. We
have ﬁve possible areal units of data aggregated to choose for analyzing: (1) 100 km with
a low LM and less high GM; (2) 300 km in the same context; (3) 500 km, which, however,
has a low LM but also has a low GM; (4) the worst solution, 400 km, with a lower GM
and a higher LM; and (5) the areal unit of 200 km with the higher GM and the lower LM.
Therefore, according to the results of the multicriteria optimization framework in Figure 5,
the Pareto-optimal solution is the areal units of 200 km. These areal units dominate the
other ones because their criteria are better; i.e., they are combined with a higher Global
Moran’s I and a lower coefﬁcient of variation of Local Moran’s I. This means that the data
aggregated inside the 200 km areal unit have a higher correlation than the others.
Figure 4. Trade-off between the global indicator of spatial association (Global Moran’s I) and the
overall degree of structural (in)stability (coefﬁcient of variation of Local Moran’s I normalized by
scaling between the minimum and maximum values of the Global Moran’s I coefﬁcients. Both global
and local spatial statistics were computed for a row-standardized spatial weights matrix based on
ﬁrst-order rook contiguity.
Sensors 2022, 22, 1693
13 of 21
Figure 5. Pareto frontier and trade-off between Global Moran’s I and the coefﬁcient of variation of
Local Moran’s I.
Figure 6 shows the spatial patterns of the O3 collected data from the geographic
coordinates data sensors on the maps of the regular hexagons with the side lengths of
200 km, 300 km, 400 km, and 500 km. When we chose an arbitrary areal unit, such as
400 km or 500 km, we obtained different and discordant spatial patterns when compared
with the Pareto-optimal areal units. In practice, this affects the conclusions and may lead to
misunderstandings and mistakes by decision-makers when applying the strategy to the
IoT infrastructure planning.
Figure 6. Comparison of spatial patterns of Pareto-optimal areal units with others arbitrary areal
units. The patterns correspond to the ‘odds ratio measure’ of the frequency of geographic coordinates’
O3 data [54].
To analyze the method in another order of magnitude, we replicated the experiment to
a smaller area, in which we used the same data but considered only the state of California.
In this new experiment, we also modeled the candidates’ areal units by a regular hexagons
shape; however, we determined the length of the sides in scales of 100 km, 90 km, 80 km,
70 km, 60 km, and 50 km.
Sensors 2022, 22, 1693
14 of 21
Figure 7 shows Global Moran’s I coefﬁcient and the coefﬁcient of variation of Local
Moran’s I for the areal units in the California states. This makes it possible to observe that
all the areal units show different patterns from each other. In this experiment, the areal unit
of 80 km is linked to a higher pattern of spatial association and lower spatial heterogeneity
than the other areal units; i.e., the former provides more consistent spatial patterns and is
thus likely to reﬂect more reliable analytical results.
Figure 7. Trade-off between the global indicator of spatial association (Global Moran’s I) and the
overall degree of structural (in)stability (coefﬁcient of variation of Local Moran’s I normalized by
scaling between the minimum and maximum values of the Global Moran’s I coefﬁcients) considering
the California states.
To conﬁrm the conclusion above, we present in Figure 8 the results of the multicriteria
optimization framework, where the 80 km areal unit is alone in the ﬁrst Pareto frontier.
Moreover, it is also possible to observe that the 50 km areal unit is isolated in the last Pareto
frontier; this means the lower pattern of spatial association and higher spatial heterogeneity
than the other areal unit.
Figure 8. Pareto frontier and trade-off between Global Moran’s I and the coefﬁcient of variation of
Local Moran’s I for the O3 pollutant in California state.
Sensors 2022, 22, 1693
15 of 21
Like Figure 9, Figure 8 shows the spatial patterns of the O3 collected data from the
geographic coordinates data sensors on the maps of the regular hexagons with the side
length of 100 km, 90 km, 80 km, and 50 km. If we chose an arbitrary areal unit, such as
50 km, we obtained different spatial patterns when compared with the Pareto-optimal
areal units. It is essential to highlight that this affects the conclusions and may lead to
misunderstandings and mistakes by decision-makers when applying the strategy to the
IoT infrastructure planning.
Figure 9. Comparison of spatial patterns of Pareto-optimal areal units with other arbitrary areal units
in the state of California. The patterns correspond to the ‘odds ratio measure’ of the frequency of
geographic coordinates O3 data [54].
6.2. Data Interpolation
To compare the results of the data interpolation with works that utilize classical
statistics in the same context, we used data from 2015 related to O3 pollutants. Following
the systematic method presented in Figure 2, ﬁrst, we normalize the data, and then we
build the ﬁtted model. It is essential to remember that the map from the location is only for
visualization.
We show in Figure 10 the ﬁtted model used to apply the Kriging method. It can be
observed that this variogram represents an exponential model; i.e., the spatial autocorre-
lation disappears entirely only at an inﬁnite distance, which means that the near data are
strongly autocorrelated.
Sensors 2022, 22, 1693
16 of 21
Figure 10. Variogram from the ﬁtted model to O3 data in the United States in 2015.
This ﬁtted model is the input for Kriging interpolation. Figure 11 shows the result of
Kriging interpolation to O3 data in the United States in 2015, where the gradient color repre-
sents the O3 AQI. If we chose an classical statistics methods to represent the same data (e.g.,
a simple average) like other literature works [23,24], we could obtain a map visualization
like Figure 12; the colors in the map from Figure 12 follow the Table 4 deﬁnition.
Figure 11. Kriging method interpolation applied to O3 AQI in the United States (2015).
Sensors 2022, 22, 1693
17 of 21
Figure 12. O3 AQI peer state in the United States in 2015 using classical statistics (average); the
colors in the map follow the deﬁnitions in Table 4, and white means that the area does not have
data information.
It is possible to observe that if we consider only the mean by state (Figure 12), we can
make incorrect interpretations about the data. For example, considering the average by
country, we can conclude that entire state of California has air that could be a risk for some
people, particularly those who are unusually sensitive to air pollution, which is not valid if
we look to the interpolation data (Figure 10).
Another good example is the state of Arizona, which looks like a state with totally
healthy air if we considered the map in Figure 12 (data collected in few points). However,
we see in the interpolation map from Figure 11 that it is entirely incorrect to consider the
Arizona state with entirely healthy air.
With the geostatistics in our proposal (Kriging method), we can also estimate a pre-
diction value; i.e., we can analyze the possibility of a factor that exceeds a predetermined
amount. Figure 13 shows the probability prediction of the O3 pollutant overtaking an AQI
of 50. The estimate ﬂoats from 0 (0%) to 1 (100%).
Figure 13. Kriging method indicative applied to O3 AQI in the United States (2015); the probability
prediction that the O3 pollutant overtakes an AQI of 50.
6.3. Discussion
By summarizing our results, we can observe that a classical statistical method is
inadequate for data analysis of outdoor sensors. Furthermore, only a geostatistic or spatial
static analysis may not be enough either. For this reason, we propose structuring several
Sensors 2022, 22, 1693
18 of 21
methods from geostatistics and spatial statistic aggregated with a multicriteria analysis to
compose a systematic data analysis on outdoor sensors.
Although we present results only for the environmental context, our proposal is
promising for a free contextual application in outdoor sensors’ data analysis. In the next
section, we discuss our proposal’s limitation and future work.
7. Conclusions
The combination of devices with sensor networks and Internet access enables the
communication between the physical world and cyberspace, providing the development of
solutions to many real-world problems through the IoT.
IoT involves anything with network access with or without human interaction re-
quired, and the data from these “things” can be provided in many forms, such as streaming
and discrete data, images, and social media, among others. The combination of the network
of sensors with the Internet enables the communication between the virtual and real world,
allowing the decision making without human intervention. However, a wrong decision
due to poor data quality or erroneous data interpretation can cause signiﬁcant ﬁnancial
harm to companies and institutions.
The problem of data quality becomes complex and controversial with the evolution of
technology. The data quality and data accuracy are also related to the data analysis [7–9].
In this context, we presented in this paper a systematic approach to support the data analysis
by considering the sensor spatiality factor and geographic aspects. Moreover, we applied
the methods on an extensive real-world database from the United States Environmental
Protection Agency (US EPA).
First, we determined the areal units that optimize the spatial autocorrelation patterns
through the combined use of indicators of global and local spatial autocorrelation, which
showed what the best areal unit to make data analysis is. Next, we applied the Kriging
interpolation to an accurate data visualization, and we also provided evidence that the
report given only by the classical statistics could lead to wrong interpretations.
Although we validate our proposed method only in the environmental context, we
could apply this analysis in any context, including a free-context method. However,
to validate it as it would be validated with a free-context method, we would need to realize
these speciﬁc analyses. Furthermore, it is important to highlight some limitations in the
experiments:
•
We only did ofﬂine experiments.
•
Due to the analysis time, we could not use this method in critical applications without
substantial modiﬁcations.
•
It is necessary to validate this method in other contexts to ensure that our proposals
have a free context application.
In future work, we intend to perform experiments and analysis in micro-regions with
other study cases, where we hope to evaluate the decision-making as well. Furthermore,
we also aimed to apply the spatial autocorrelation to deduce the correct spatial distributed
sensor dimensions. In another context, we intend to do a performance evaluation to
conclude if it is feasible to use our approach in real-time execution for critical applications.
Author Contributions: Conceptualization, L.J.d.M.d.A., J.C.E. and A.C.B.D.; methodology L.J.d.M.d.A.,
S.C.d.A. and A.C.B.D.; software, L.J.d.M.d.A. and S.C.d.A.; validation, L.J.d.M.d.A., S.C.d.A., A.C.B.D.
and J.C.E.; formal analysis, L.J.d.M.d.A., S.C.d.A., A.C.B.D., J.C.E. and R.I.M..; investigation, L.J.d.M.d.A.,
A.C.B.D., J.C.E. and S.R.-M.; resources, J.C.E. and S.R.-M.; data curation, L.J.d.M.d.A. and J.C.E.; writing—
original draft preparation, L.J.d.M.d.A., J.C.E., A.C.B.D., R.I.M., S.R.-M. and S.C.d.A.; writing—review
and editing, L.J.d.M.d.A., J.C.E., A.C.B.D., R.I.M., S.R.-M. and S.C.d.A.; visualization, L.J.d.M.d.A.,
S.C.d.A., A.C.B.D. and R.I.M.; supervision, J.C.E., A.C.B.D. and S.R.-M.; project administration, J.C.E.
and L.J.d.M.d.A.; funding acquisition, R.I.M. and J.C.E. All authors have read and agreed to the published
version of the manuscript.
Sensors 2022, 22, 1693
19 of 21
Funding: This research was funded by Fundação de Amparo à Pesquisa do Estado de São Paulo
grant number 2020/07162-0.
Institutional Review Board Statement: Not applicable.
Informed Consent Statement: Not applicable.
Data Availability Statement: Publicly available datasets were analyzed in this study. This data can
be found here: aqs.epa.gov/aqsweb/airdata/download_ﬁles.html.
Acknowledgments: This work was developed using the computational infrastructure of the Dis-
tributed Computing Lab of ICMC-USP - University of São Paulo present in http://infra.lasdpc.icmc.
usp.br/ and also with resources from the Center for Mathematical Sciences Applied to Industry
(CeMEAI http://www.cemeai.icmc.usp.br/) funded by the São Paulo Research Foundation FAPESP
(grant #2013/07375-0 and #11/09524-7). FAPESP under grant #2020/05126-6 and FAPEMIG under
grant #APQ-03120-17. Rodolfo Ipolito Meneguette would like to thank the FAPESP for the ﬁnancial
support through grant #2020/07162-0 in his research.
Conﬂicts of Interest: The authors declare no conﬂict of interest. The funders had no role in the design
of the study; in the collection, analyses, or interpretation of data; in the writing of the manuscript, or
in the decision to publish the results.
References
1.
Xia, F.; Yang, L.T.; Wang, L.; Vinel, A. Internet of things. Int. J. Commun. Syst. 2012, 25, 1101. [CrossRef]
2.
Maschi, L.F.C.; Pinto, A.S.R.; Meneguette, R.I.; Baldassin, A. Data Summarization in the Node by Parameters (DSNP): Local Data
Fusion in an IoT Environment. Sensors 2018, 18, 799. [CrossRef]
3.
Andreazi, G.T.; Estrella, J.C.; Bruschi, S.M.; Immich, R.; Guidoni, D.; Alves Pereira Júnior, L.; Meneguette, R.I. MoHRiPA—An
Architecture for Hybrid Resources Management of Private Cloud Environments. Sensors 2021, 21, 6857. [CrossRef] [PubMed]
4.
Friedman, T.; Bitterer, A. Magic Quadrant for Data Quality Tools; Gartner: Stamford, CT, USA, 2014.
5.
Karel, R. The ‘All In’ Costs of Poor Data Quality; IDG Communications, Inc.: Needham, MA, USA, 2015.
6.
Karel, R. Fixing a $3 Trillion Dirty Data Problem with “Crowd Computing”, 2015. Available online: https://www.inzata.com/
the-ﬁve-ways-dirty-data-costs-businesses-money/ (accessed on 16 October 2021).
7.
Karkouch, A.; Mousannif, H.; Al Moatassime, H.; Noel, T. Data quality in internet of things: A state-of-the-art survey. J. Netw.
Comput. Appl. 2016, 73, 57–81. [CrossRef]
8.
Laranjeiro, N.; Soydemir, S.N.; Bernardino, J. A survey on data quality: Classifying poor data. In Proceedings of the 2015
IEEE 21st Paciﬁc Rim International Symposium on Dependable Computing (PRDC), Zhangjiajie, China, 18–20 November 2015;
pp. 179–188.
9.
Banerjee, T.; Sheth, A. Iot quality control for data and application needs. IEEE Intell. Syst. 2017, 32, 68–73. [CrossRef]
10.
Antonic, A.; Roankovic, K.; Marjanovic, M.; Pripuic, K.; Zarko, I.P. A mobile crowdsensing ecosystem enabled by a cloud-based
publish/subscribe middleware. In Proceedings of the 2014 International Conference on Future Internet of Things and Cloud,
Barcelona, Spain, 27–29 August 2014; pp. 107–114.
11.
Alam, S.; Noll, J. A semantic enhanced service proxy framework for internet of things. In Proceedings of the 2010 IEEE/ACM Int’l
Conference on Green Computing and Communications & Int’l Conference on Cyber, Physical and Social Computing, Hangzhou,
China, 18–20 December 2010; pp. 488–495.
12.
Kothari, A.; Boddula, V.; Ramaswamy, L.; Abolhassani, N. Dqs-cloud: A data quality-aware autonomic cloud for sensor
services. In Proceedings of the 10th IEEE International Conference on Collaborative Computing: Networking, Applications and
Worksharing, Miami, FL, USA, 22–25 October 2014; pp. 295–303.
13.
Karkouch, A.; Mousannif, H.; Al Moatassime, H.; Noel, T. A model-driven framework for data quality management in the
Internet of Things. J. Ambient Intell. Humaniz. Comput. 2018, 9, 977–998. [CrossRef]
14.
Casado-Vara, R.; de la Prieta, F.; Prieto, J.; Corchado, J.M. Blockchain framework for IoT data quality via edge computing.
In Proceedings of the 1st Workshop on Blockchain-Enabled Networked Sensor Systems, Shenzhen, China, 4 November 2018;
pp. 19–24.
15.
Baqa, H.; Truong, N.B.; Crespi, N.; Lee, G.M.; Le Gall, F. Quality of Information as an indicator of Trust in the Internet of Things.
In Proceedings of the 2018 17th IEEE International Conference On Trust, Security And Privacy In Computing Furthermore,
Communications/12th IEEE International Conference On Big Data Science Furthermore, Engineering (TrustCom/BigDataSE),
New York, NY, USA, 1–3 August 2018; pp. 204–211.
16.
Bamgboye, O.; Liu, X.; Cruickshank, P. Towards modelling and reasoning about uncertain data of sensor measurements for
decision support in smart spaces. In Proceedings of the 2018 IEEE 42nd Annual Computer Software and Applications Conference
(COMPSAC), Tokyo, Japan, 23–27 July 2018; Volume 2, pp. 744–749.
17.
Xu, X.; Lei, Y.; Li, Z. An incorrect data detection method for big data cleaning of machinery condition monitoring. IEEE Trans.
Ind. Electron. 2019, 67, 2326–2336. [CrossRef]
Sensors 2022, 22, 1693
20 of 21
18.
Cheng, H.; Feng, D.; Shi, X.; Chen, C. Data quality analysis and cleaning strategy for wireless sensor networks. EURASIP J. Wirel.
Commun. Netw. 2018, 2018, 1–11. [CrossRef]
19.
Sicari, S.; Rizzardi, A.; Cappiello, C.; Miorandi, D.; Coen-Porisini, A. Toward data governance in the internet of things. In New
Advances in the Internet of Things; Springer: Berlin/Heidelberg, Germany, 2018; pp. 59–74.
20.
Ferreira, E.; Ferreira, D. Towards altruistic data quality assessment for mobile sensing.
In Proceedings of the 2017 ACM
International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2017 ACM International
Symposium on Wearable Computers, Maui, HI, USA, 11–15 September 2017; pp. 464–469.
21.
de Aquino, G.R.C.; de Farias, C.M.; Pirmez, L. Data Quality Assessment and Enhancement on Social and Sensor Data; BiDu-
Posters@VLDB: Rio de Janeiro, Brazil, 2018.
22.
Liu, Q.; Sha, D.; Liu, W.; Houser, P.; Zhang, L.; Hou, R.; Lan, H.; Flynn, C.; Lu, M.; Hu, T.; et al. Spatiotemporal Patterns of
COVID-19 Impact on Human Activities and Environment in Mainland China Using Nighttime Light and Air Quality Data.
Remote Sens. 2020, 12, 1576. [CrossRef]
23.
Bishoi, B.; Prakash, A.; Jain, V. A comparative study of air quality index based on factor analysis and US-EPA methods for an
urban environment. Aerosol Air Qual. Res. 2009, 9, 1–17. [CrossRef]
24.
Li, Z.; Ma, Z.; van der Kuijp, T.J.; Yuan, Z.; Huang, L. A review of soil heavy metal pollution from mines in China: Pollution and
health risk assessment. Sci. Total Environ. 2014, 468, 843–853. [CrossRef] [PubMed]
25.
Knoblauch, J.; Damoulas, T.
Spatio-temporal Bayesian on-line changepoint detection with model selection.
arXiv 2018,
arXiv:1805.05383.
26.
Knoblauch, J.; Jewson, J.E.; Damoulas, T. Doubly Robust Bayesian Inference for Non-Stationary Streaming Data with β-
Divergences. Adv. Neural Inf. Process. Syst. 2018, 31, 64–75.
27.
Aglietti, V.; Bonilla, E.V.; Damoulas, T.; Cripps, S. Structured Variational Inference in Continuous Cox Process Models. Adv.
Neural Inf. Process. Syst. 2019, 32, 12437–12447.
28.
Hamelijnck, O.; Damoulas, T.; Wang, K.; Girolami, M. Multi-resolution multi-task Gaussian processes. Adv. Neural Inf. Process.
Syst. 2019, 32, 14025–14035.
29.
Akyildiz, Ö.D.; Míguez, J. Nudging the particle ﬁlter. Stat. Comput. 2020, 30, 305–330. [CrossRef]
30.
Akyildiz, Ö.D.; Chouzenoux, E.; Elvira, V.; Míguez, J. A probabilistic incremental proximal gradient method. IEEE Signal Process.
Lett. 2019, 26, 1257–1261. [CrossRef]
31.
Mark, D.M. Geographic Information Science: Deﬁning the Field. In Foundations of Geographic Information Science; Duckham, M.,
Goodchild, M.F., Worboys, M., Eds.; Taylor & Francis: Abingdon, UK, 2003; pp. 3–18. [CrossRef]
32.
Goodchild, M.F. Geographical information science. Int. J. Geogr. Inf. Syst. 1992, 6, 31–45. [CrossRef]
33.
Gotway, C.A.; Young, L.J. Combining Incompatible Spatial Data. J. Am. Stat. Assoc. 2002, 97, 632–648. [CrossRef]
34.
Yang, C.; Clarke, K.; Shekhar, S.; Tao, C.V. Big Spatiotemporal Data Analytics: A research and innovation frontier. Int. J. Geogr. Inf.
Sci. 2020, 34, 1075–1088. [CrossRef]
35.
Lavrova, D.; Pechenkin, A.; Gluhov, V. Applying correlation analysis methods to control ﬂow violation detection in the internet
of things. Autom. Control Comput. Sci. 2015, 49, 735–740. [CrossRef]
36.
Zhang, D.; Zhao, C.P.; Liang, Y.P.; Liu, Z.J. A new medium access control protocol based on perceived data reliability and spatial
correlation in wireless sensor network. Comput. Electr. Eng. 2012, 38, 694–702. [CrossRef]
37.
Habibia, R.; Alesheikha, A.A. Managing coverage holes in IoT monitoring sensor networks. IEEE Commun. Mag. 2017, 55, 70–78.
[CrossRef]
38.
de Andrade, S.C.; Restrepo-Estrada, C.; Nunes, L.H.; Rodriguez, C.A.M.; Estrella, J.C.; Delbem, A.C.B.; de Albuquerque, J.P. A
multicriteria optimization framework for the deﬁnition of the spatial granularity of urban social media analytics. Int. J. Geogr. Inf.
Sci. 2020, 35, 43–62. [CrossRef]
39.
Haining, R. Spatial Data Analysis: Theory and Practice; Cambridge University Press: Cambridge, UK, 2003.
40.
Anselin, L. Spatial Econometrics: Methods and Models; Kluwer Academic Publishers: Dordrecht, The Neatherland, 1988.
41.
Tobler, W.R. A computer movie simulating urban growth in the Detroit region. Econ. Geogr. 1970, 46, 234–240. [CrossRef]
42.
O’sullivan, D.; Unwin, D. Geographic Information Analysis; John Wiley & Sons: Hoboken, NJ, USA, 2014.
43.
Moran, P.A. The interpretation of statistical maps. J. R. Stat. Soc. Ser. B 1948, 10, 243–251. [CrossRef]
44.
Cressie, N. The origins of kriging. Math. Geol. 1990, 22, 239–252. [CrossRef]
45.
Getis, A. Reﬂections on spatial autocorrelation. Reg. Sci. Urban Econ. 2007, 37, 491–496. [CrossRef]
46.
Anselin, L. Local Indicators of Spatial Association—LISA. Geogr. Anal. 1995, 27, 93–115. [CrossRef]
47.
Pareto, V. Cours d’Économie Politique; Librairie Droz: Geneva, Switzerland, 1964; Volume 1.
48.
Herrmann, C.; Juraschek, M.; Burggräf, P.; Kara, S. Urban production: State of the art and future trends for urban factories. CIRP
Ann. 2020, 69, 764–787. [CrossRef]
49.
Sarkar, C.; Webster, C. Urban environments and human health: Current trends and future directions. Curr. Opin. Environ. Sustain.
2017, 25, 33–44. [CrossRef]
50.
Kampa, M.; Castanas, E. Human health effects of air pollution. Environ. Pollut. 2008, 151, 362–367. [CrossRef] [PubMed]
51.
Nowak, D.J.; Hirabayashi, S.; Doyle, M.; McGovern, M.; Pasher, J. Air pollution removal by urban forests in Canada and its effect
on air quality and human health. Urban For. Urban Green. 2018, 29, 40–48. [CrossRef]
52.
United Nations Statistics Division. Available online: https://unstats.un.org/home/ (accessed on 21 July 2020).
Sensors 2022, 22, 1693
21 of 21
53.
Carr, D.B.; Olsen, A.R.; White, D. Hexagon mosaic maps for display of univariate and bivariate geographical data. Cartogr. Geogr.
Inf. Syst. 1992, 19, 228–236. [CrossRef]
54.
Poorthuis, A.; Zook, M.; Shelton, T.; Graham, M.; Stephens, M. Using Geotagged Digital Social Data in Geographic Research;
Pre-Publication Version of Chapter Submitted to: Key Methods in Geography; Clifford, N., French, S., Cope, M., Gillespie, S.,
Eds.; Sage: London, UK, 2014.


Paper 6:
- APA Citation: Atzori, L., Carboni, D., & Iera, A. (2013). Smart things in the social loop: Paradigms, technologies, and potentials. Ad Hoc Networks, 18, 121-132.
  Main Objective: The primary goal of this paper is to examine the use of social networking concepts in the Internet of Things, the technologies behind these, and the potentialities.
  Study Location: Unspecified
  Data Sources: Not applicable
  Technologies Used: Not applicable
  Key Findings: The authors propose that utilizing social networking concepts and technologies in the Internet of Things can lead to more effective service discovery, resource composition, and trustworthiness management.
  Extract 1: Adaptive data preprocessing methods for dealing with varying data quality and formats from heterogeneous data sources, such as data normalization, feature scaling, and data fusion techniques (e.g., Dempster-Shafer theory, Bayesian inference)
  Extract 2: Containerization strategies for scalable and autonomous deployment, and the deployment of machine learning (ML) models for real-time data processing and inference
  Limitations: None
  Relevance Evaluation: This paper is directly relevant to my review's point of focus, since it examines the specific aspects of data quality and preprocessing methods for automated irrigation systems, which is a key component of the literature review on automated irrigation systems.
  Relevance Score: 1.0
  Inline Citation: (Atzori et al., 2013)
  Explanation: The authors of this paper examine the importance of data quality and preprocessing in cloud-based automated irrigation systems, containerization strategies for scalable and autonomous deployment, and the deployment of machine learning (ML) models for real-time data processing and inference.

 Full Text: >
Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Abstract Keywords 1. Introduction 2. Web of Things paradigm and technologies 3. Adding the social aspect to WoT 4. Evolution of social Internet of Things 5. On-going projects 6. Conclusions References Vitae Show full outline Cited by (59) Figures (6) Ad Hoc Networks Volume 18, July 2014, Pages 121-132 Smart things in the social loop: Paradigms, technologies, and potentials Author links open overlay panel Luigi Atzori a, Davide Carboni b, Antonio Iera c Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.adhoc.2013.03.012 Get rights and content Abstract Information about human social activities and relationships are exploited by an ever increasing number of proposed applications and protocols in several scenarios, given the consequent increase in the system performance. Examples are data transmission over delay tolerant networks, content recommendation in search engines, and advertisement of products and services. An emerging field where social networks are being exploited is the Internet of Things, where smart objects connect to the network to bring the real world into the virtual dimension. Objects capable to communicate on social network sites are able to enter into their owners’ social loop so as to automatically publish information of interest for selected communities of people and to perform some related automatic actions. In so doing, not only can objects be part of the human social networks but they can also build their own social network. As a consequence, interactions among them can be fostered towards the development of complex services for the direct benefit of people. Accordingly, objects mimic the human behavior towards a scalable and effective service discovery and composition as well as trustworthiness management. On the basis of the importance achieved by this trend in the last couple of years, in this paper we intend to review the adopted approaches towards the exploitation of social network concepts by the Internet of Things, the technologies behind these, and the potentialities. Previous article in issue Next article in issue Keywords Internet of ThingsSocial networksSmart objects 1. Introduction The number of objects that are currently accessing the Internet, side-by-side to human beings to advertise, search for, and accessing enhanced services is growing exponentially. Among them are sensors, actuators, wireless and mobile devices, or simply every-day-life objects enhanced with capabilities to interact with the external world through the Internet. This is a clear signal that the much-vaunted (and sometime abused) Internet of Things paradigm is already turned into a reality on which there is a strong convergence of the interests of researchers, users, and industries. As a main effect, we have today a new approach available to build enhanced applications and services involving the communications among objects on the Internet to the service of the human beings. Several studies have focused their attention to the definition of architectural models and solutions towards the use and the inter-connection of Web-enabled objects using open protocols and well-known architectural styles, REST and SOAP based Web services (such as, [1], [2]). As a consequence, the obvious evolutionary step of the IoT is the so called Web of Things (WoTs) that envisages new scenarios and applications where Internet enabled objects become active actors and peers in the Web. Sample services, applicable to Smart Cities or Smart Homes, are given below: • The car driver knows about the status of her car and of the roads on the path towards her destination. Such awareness is achieved by accessing, through her mobile phone (or through any communication technology in her car), web services that are fed by data collected from sensors scattered both in her car and in the areas of interest. • The domestic appliances may be accessed by the owner through web services from remote sites and some actions can be performed on them to prepare comfortable conditions for a better welcome home. • Eco-compatible houses may be equipped with controllers and sensors able to measure the local energy production and consumption and manageable through web services towards a reduction of the environmental impact. Besides the obvious advantages of the depicted sample scenarios, one cannot hide the doubts on the ability of the proposed solutions to effectively harness the full potential of the new paradigm without colliding with the limitations of the current Web service platforms in the presence of trillions of additional actors (objects, precisely). In our opinion, Web of Things is a paradigm which goes in the right direction but is not the solution to the cited issues. To foster resource visibility, service discovery, object reputation assessment, source crowding, and service composition in a Web populated by people and countless things there is the necessity to strongly push towards solutions that exploit concepts directly derived from the sole platforms that currently seem to be able to effectively allow peer-to-peer exchanges among huge numbers of actors, i.e., Social Networks. Even if several aspects of the social networking among humans cannot be directly applied to the objects’ world due to the specific distinctive characteristics (e. g., high heterogeneity and limited intelligence), such a need has brought to a substantial convergence of the “Internet of Things” and “Social Networks” domains. Interesting ideas have recently appeared in the IoT arena, which testify to the interests in Social Network oriented solutions for the Internet of Things. People at the User Experience Lab at Ericsson Research started from the idea that the complexity of network solutions that underlie the Internet of Things are hardly understood (and mentally accepted) by all users. Thus, it is wise to make this complexity completely transparent during the user-thing interactions. Differently, the concept of “friendship” and ‘social relations’ are understood by virtually everyone, as they are intuitive concepts. As a consequence, they proposed a solution to both the practical scalability and understand-ability issues which is simply “dressing” a network of things as if it was a social network [3]. They have been the first to introduce the concept of “Social Web of Things” and also made some applications’ prototypes. Further studies and implementations of this concept have been carried out around the world. An example is given by the work in [4], where the authors propose a Social Web of Thing Framework based on the Restful Web Service and Social Networks, discuss the relevant key technologies and use cases, and introduce a case study named MagicHome. Furthermore, even a prototype of a scalable architecture for a large scale social Web of Things for smart objects and services, named Paraimpu, has been developed [5]. In line with this evolutionary path, but from a different perspective, the authors of [6], [7] introduce the concept of Social Internet of Things. In analogy with the social networks of human beings, they (i) define of a notion of social relationship among objects, (ii) design a reference architectural model implementing a social Internet of Things based on codified inter-object relationships, (iii) analyze the social network structure, which derives from the objects interactions based on the defined social relationships. The examples above make us realize that the time is ripe for a serious reflection on the possible ways of integrating objects into social networks, whether they are shared with those of their owners or they are independent and autonomous. Aim of the present paper is to analyze the potentials of a synergic use of Social Networks and Internet of Things concepts towards the deployment of effective service platforms able to face the future challenges of a future world of trillions of inter-connected objects. We will illustrate the main solutions that are appearing in the IoT arena to let things enter the so called “social loop” and compare their points of strength and their weaknesses by also highlighting their technological requirements and architectures. This paper is organized as follows. In Section 2 we present the technologies behind the Web of Things as one of the prevailing approaches towards the integration of the objects into the Internet. In Section 3, we describe how this paradigm can be extended by providing the things with the capabilities to take part to the human social activities on relevant social network websites. In Section 4 we describe a complementary approach that allows objects to build their own social networks, so that interactions among them can be fostered towards the development of complex services. In Section 5 we present the ongoing projects that come out from the concepts described in the previous sections. Finally, in Section 6 we draw final conclusions. 2. Web of Things paradigm and technologies The ongoing evolution of the Internet of Things towards the Web of Things (WoTs), where Web-enabled smart objects connect and communicate with each other by using the Web, has raised several research issues ranging from the adoption of the right protocol and communication paradigms to the choice of the most suitable architectural styles. WoT was not born as a field in academic research but rather as the attempt to build an ecosystem from an heterogeneous variety of services and products, often not conceived in a way to interoperate. Several efforts have focused their attention to the definition of architectural models and solutions, towards the use and the interconnection of Web-enabled objects, which exploit open protocols and well-known architectural styles, such as Representational State Transfer (REST) and Simple Object Access Protocol (SOAP) based Web services. In [8], an architecture is defined for the development of composite applications, to interconnect physical devices, on top of the open and simple standards that made the success of the Web (REST, XML, HTTP, or Atom). The layered architecture is composed as follows: • Device accessibility layer: a layer that from the application point of view enables consistent access to all kinds of connected objects. • Find-ability layer: a layer that, given an ecosystem of billions of smart things, allows for finding their services. • Sharing layer: although device accessibility and find-ability can technically allow for sharing data too, this layer is specifically designed to manage a social circle authentication, based on accounting and authorization procedures. • Composition layer: a layer that enables users to create composite applications on top of smart things. The overall goal of this layered architecture is to facilitate the integration of smart things with existing services on the Web and to facilitate the creation of Web applications by using smart things. The layers above are not directly mapped onto the ISO OSI model, but are rather useful to understand the foundations of WoT as an ecosystem. The next subsections analyze the main aspects relevant to the design choices for architecting the WoT. These include: the architectural style (SOAP/REST), the degree of centralization, the device/thing degree of accessibility to the network, and the ways in which data, services and objects can be composed together. 2.1. SOA(P) vs. REST The choice between the SOAP and the REST software architecture styles deserves a deeper investigation. In [9] the authors go towards the definition of an architecture where devices are viewed as services, in order to integrate a wide range of physical devices into distributed IT enterprise systems adopting a Service-Oriented Architecture (SOA). In a similar way, the projects WS4D7 and SOCRADES [10] apply a SOA approach to the context of embedded networks. Moreover, existing standards for Web Services (WSs), focused on embedded devices, such as Device Profile for Web Services (DPWSs) [11], confirm a real consensus and effort towards a SOAP-based WoT. On the other side, some recent research works (i.e. [12], [13], [14]) adopt REST for IoT/WoT architectures. According to the experience documented in [13], the programmatic complexity of SOAP based services is not well-suited for the end-user to create ad hoc applications, while the authors of [14] state that, in many cases, the SOAP complexity becomes superfluous whereas RESTful services can support “a la Mash-up” integrations. In a RESTful architecture, the main resources, such as entities, collections, or anything else that is worth being represented in the application domain, are uniquely identified by its own URI. The reference methods - in this case, the HTTP verbs - are mapped onto application semantics in a very simple and straightforward way. Many new Internet companies (see the trends in Fig. 1) that face the market, often prefer to provide their services through a RESTful API rather than a solution based on SOAP. This suggests that, probably, REST is more immediate and less expensive for rapid prototyping. Download : Download full-size image Fig. 1. REST API vs. SOAP API in Google trends. The main advantages of REST web services can be summarized as it follows: • Lightweight – not a lot of extra XML markup. • Human Readable Results – in some cases (i.e., a GET request of a resource representation), RESTful services can be directly invoked by typing the URL in a common web browser. • Easy to build – no toolkits required. SOAP also has some advantages mainly related to the formal definition of service interfaces: • Easy to consume – clients can be automatically generated on the basis of the exact specification provided in the WSDL document. • Rigid – type checking adheres to a programming contract and XML schemas are provided for data exchanged to filter unacceptable inputs/outputs. • Development tools and business process definition (e.g., BPEL language). Even if the locution “Web Service” was often associated to the SOAP stack, this is not the way the Web works. Whereas SOAP is aimed at the next phase of Internet development defining a set of brand new specifications, REST is more the realization that the existing principles and protocols of the Web are already there to create robust Web services. Summarizing, even if the strong type checking of SOAP based Web services is a plus, in the context of the IoT, the RESTful Web Services have some advantages over SOAP such as less overhead, less parsing complexity, statelessness, and tighter integration with existing HTTP. Moreover, the RESTful protocol called CoAP [15] is similar to HTTP but re-designed especially for devices with small footprint and constrained computing environments. According to the recent studies mentioned in this paper it seems that the use of standards like CoAP and EXI and web paradigms are the key factors for extending the Internet making the vision of the IoT become reality. 2.2. Device accessibilty It is useful to explore how things can be classified according to their computation and communication capabilities. The following list provides a coarse classification: • Virtual Things. Like web sites, e-mail boxes and social networks, just to mention some. These “objects” can be easily wrapped and then referenced in a HTTP addressing space like resources (REST) or like services (WSDL) or they already provide such abstractions and interfaces. • HTTP-enabled Smart Appliances. Like wireless printers, networked screens, and smartphones. These are already equipped with a network connection and a complete HTTP stack but usually do not provide a WS stack; thus, it is necessary to deploy a proxy or to install a minimal WS stack in the device, where possible. Usually, HTTP-enabled objects are not able to receive incoming requests from outside. In many cases, they are deployed under firewall restrictions and only can act as clients. One possibility is to deploy in the middle a relay like YALER [16], which enables secure Web access to embedded systems behind a firewall/NAT/network gateway. A simple HTTP handshake makes a Web service running on the hidden device accessible from any HTTP client. Another option is WebSocket, which provides full-duplex communication channels over a single TCP connection. The WebSocket API is being standardized by the W3C, and the WebSocket protocol has been standardized by the IETF as RFC 6455. • Internet-enabled Things that are not equipped with a complete HTTP stack but can still communicate at the TCP/IP or UDP/IP level. For those objects it is straightforward to build a HTTP wrapper and a WS stack as a proxy. A viable protocol alternative to HTTP is CoAP [15]. CoAP could be viewed as a compression or redesign of HTTP by taking power, memory, and computation constraints into account. Just like HTTP, which is designed as a transfer protocol for traditional web media content, CoAP is redesigned as a transfer protocol for devices to implement interoperations. • Network-enabled Things that cannot communicate over IP networks, but still can communicate with different protocols like ZigBee, Bluetooth or X10. For those objects a proxy can be deployed to present them in the HTTP addressing space, by also using WS technology standards. A viable solution to extend IP also to small devices that usually are not equipped with IP-stack is 6LoWPAN [17]. • Things not digitally enabled, bare physical objects. For these objects a digital counterpart must be built and published online. RFID or barcode sticks can be used to interface these objects with devices and networks. 2.3. Centralized vs. decentralized Decentralized architectures have a number of theoretical advantages, such as single-point-of-failure robustness and privacy/anonymity enforcing capability. When analyzing the Web, one discovers that (i) the degree of decentralization is quite low, (ii) the prominent topology is client–server, and (iii) even if P2P networks have gained popularity in some application areas, the idea to move computation at the boundaries of the Internet is more a niche than a main stream. The distinction between client–server and P2P architectures is no longer a technological distinction, but a matter of governance. The so-called “clouds” often adopt their own solutions of P2P load-balancing and fault tolerance, but the control is centralized in the hands of one provider. Cloud computing and Software-as-a-Service demonstrate that large IT companies are concentrating computation inside large globally distributed infrastructures; thus, transforming personal computing in a mere user interface to remote computing services. Also, in the new field of Internet-enabled objects, we foresee that P2P connections between objects are unlikely to occur unless hard real-time and multimedia communications are involved. A centralized online service can speak multiple protocols and data formats on top of HTTP and can act as a broker to let services meet in a logical space; it can be a proxy of data coming from sources and can be a relay of data to consumer services; moreover, it can make data format adaptation where required. In other words, it can operate at all the layers described above, from device accessibility to composition. In a centralized WoT tool the workload is put at the extreme. Some applications need to have samples on every second, and even only one thousand sensors connected to a central server would produce 1000 * 60 * 60 * 24 = 86400000 events per day. The load is structured in many small HTTP POST messages with a keep-alive connection. The requirements for a cloud-based Web of Things architecture (see Fig. 2) can be summarized as it follows: • C10 K+[18] capable web servers (C10 K + stands for 10,000 or more HTTP connections handled simultaneously, i.e. non-blocking servers that do not map every connection to a system thread); • database engine able to be horizontally partitioned over a grid of machines in a transparent way (sharding); • event handling and data processing delegated to a pool of worker processes distributed among multiple processors and even different machines. Download : Download full-size image Fig. 2. The architecture of a WoT-cloud based service. In [19], a little but insightful benchmark between a non-blocking web server, like Nginx, versus a thread-based server, like Apache, is presented. The plots show (Fig. 3, Fig. 4) how the throughput of Nginx are still high even with a large number of connections and with a very low memory usage. Nevertheless, the WoT system designer must consider that to fully gain an advantage from a non-blocking Web server, all the components in the backend must be designed to be non-blocking as well. Download : Download full-size image Fig. 3. Throughput against concurrent connection for nginx (non-blocking) and Apache (threaded) web servers [19]. Download : Download full-size image Fig. 4. Memory usage against concurrent connection for nginx (non-blocking) and Apache (threaded) web servers [19]. 2.4. Smart objects in service orchestrations A big issue in composing objects/services to form an application logic, is how to ensure that data coming from a data source can be properly read and processed by a recipient data sink. The intuitive, but not widely practicable solution, is to adopt a rigorous set of data schemas shared by all participants. In this way connections could be handled with no pains because every object that consumes data is able to receive and to decide what to do with the data. Unfortunately, having a common set of data types defined and shared for all interconnected objects is far to be realistic. Objects are built from different manufacturers for vertical applications, often inside walled gardens or with small capabilities to interoperate with external entities. A more realistic assumption is to consider objects able to produce data in a format among those commonly encapsulated into HTTP messages. So we can expect that a data source can push a string containing either numbers or alphanumeric values, or more structured data like JSON objects or XML instances. As an example, Paraimpu [20] implements the concept of mapping as a couple of expressions in the form of (cond, repl), where cond is a boolean expression while the repl expression is a valid instance of the data type expected by the sink (the actuator). This approach can be subsumed in the more general IF-THEN paradigm applied to events, data and actions in the IoT. The online service called IFTTT (IF This Than That), although initially conceived for social networks and not for physical mashups, is the immediate proof-of-concept of how this mechanism can work. Also other sensor data collectors like COSM (former Pachube) implements the concept of trigger (IF condition on datum THEN post datum on URL). A more versatile approach is to use business process definition to declare a more complex composition logic. In the case of SOAP-based WoT mashups, interactions can be described in two ways: executable processes and abstract processes. Both can be modeled by BPEL. Executable processes model the actual behavior of a participant as interactions, while abstract processes describe the observable behavior and/or process template. BPEL extends the WS-∗ interaction model to enable business transactions. BPEL defines an interoperable composition model that enables the extension of automated process integration both within and between businesses. Pintus et al. [21] also propose a SOA framework where smart things are described by using the WSDL standard, while logical connections between smart things are modeled as web services orchestrations by using the BPEL language. The availability of an API to be consumed by clients, of course, opens also the possibility to write third-party programs or scripts in arbitrary programming languages and build applications as a result of the composition of data coming from source objects, processed and transformed into actions for other smart objects. 3. Adding the social aspect to WoT To date, IoT has been conceived as a top-down technology that silently takes the control of objects in a machine-to-machine internetworking with large benefit for logistics, manufacturing, and business productivity. On the other hand, the point we stress here is that for IoT/WoT to acquire some socialization value, end-users should be enabled to be active and creative in the definition of new relationships where smart things become either an instrument or a toy to share or to play with collaboratively. In this respect, it is important to provide users with enabling platforms, based on known and understandable metaphors, to manage, control and personalize the composition between sensor data and actions in the real life. In order to enable a wide adoption of WoT in all sectors of the society, the WoT architecture and its protocols should motivate every citizens to contribute to a growing number of devices and smart objects in order to build new streams of information available to the community. We can identify at least two generic use cases. The first one is the participatory sensing and the second one is the “device in a circle”. Participatory sensing applications use data of mobile sensor nodes collected in collaboration with the device owner. With the right tools, community groups may participate in campaigns to collect data on highly-focused topics, such as traffic patterns, pollution-safe routes for school buses, without waiting for an institutional body or private agency to perform the detection. For example, the NoiseTube project [22], started in 2008 at the Sony Computer Science Lab in Paris and currently hosted by the BrusSense Team at the Vrije Universiteit Brussel, proposes a participative approach for monitoring noise pollution by involving the general public. For users to become active in the bottom-up construction of a participatory sensing scenario, aspects like trust, reputation, control of distributed devices and tracking of information flows must be appropriately adjusted to control what is happening with the information and devices contributed. The identities of users are not harvested and should be kept anonymous while on the other hands the management of reputation of the data produced must be deployed to allow the participatory sensing to become effective and discard malicious or irrelevant data. In the “device in the social circle” use case the social-ability is a key element to share and collaboratively use the smart things in the Web. Device accessibility layer and findability layer can technically allow sharing as well, but to manage physical objects in a social circle, features like authentication, accounting and authorization need to be properly designed and implemented. Integrating smart objects and main-stream social networks is another key aspect. Every WoT system who aims to become popular and adopted by users, should integrate and communicate with social media in some way. In some extent, existing social media are the precursor of the future social IoT because they have already faced a number of issues like privacy concerns, content moderation, insights visualization and so forth. The integration of Social media and Web of Things can occur in many ways: • User login/authentication: users can access a system by using existing credentials without building a brand new profile. Thanks to the Oauth protocol, the user is redirected to her/his preferred social tool to perform the login. This leads to the immediate benefit to have contacts/friends imported in the new system. In this way, it would be possible for a generic WoT site to connect its users with their Facebook or Twitter counterparts. • Social network as monitoring tool, for instance the IoT portal [23]: it allows users to quickly connect sensors and actuators to the system, and then create dashboard visualizations as Facebook applications. These applications allow users to share and monitor sensed data and control actuators in the real world. • Sensors/actuators: a social entity, such as user’s Facebook wall and the Twitter flow associated to an hashtag, can be considered a sensor or an actuator (or both) just like physical things in the implementation of virtual-to-physical mashups. For instance, the “device in the circle” could be a set of parking sensors and the social circle could be the list containing the customers’ contacts of a restaurant keeper. As an example, the restaurant manager can build a geographical selection of parking sensors in the neighborhood saving this selection as a datasource in her work space called “parkingSlots”. Then she can create a link between the selected datasource and her customer list using for instance his Facebook profile. In so doing, her customers will receive the number of free slots directly on their mobile or PC and decide to go there by car or by other means. As dual example, the “device in the circle” can be a device shared and controlled by means of social media, like for example, a multimedia installation, even on a large scale (e.g., night-time lighting of a skyscraper). The social circle may be the set of users of a certain social network that post messages to a certain topic (for example, a topic with a hash tag on twitter). Analytics based on text recognition (or even mood recognition) on tweets may trigger different actions on the installation (for example, the ignition with certain colors or with certain choreography). • The social dimension is useful for device/thing find-ability: the navigability of users’ profiles enables to discover objects shared by friends, but also to find new friends and new devices/things. 4. Evolution of social Internet of Things 4.1. Objects that handle social relationships In the IoT, everything real becomes virtual, which means that each person and thing has a locatable, addressable, and readable counterpart on the Internet. These virtual entities can produce and consume services and collaborate toward a common goal. The car driver might know about the status of her car and of the roads towards her destination, thanks to the autonomous communications of the sensors and actuators in her car with those installed in other vehicles and along the road. The embedded system in a swimming pool could share its state with other virtual entities. All these scenarios are possible with an intense interaction between objects and related services, enabling the most powerful and fascinating applications. For instance, in [24] the authors introduce the idea of objects able to participate in conversations that were previously only available to humans. Those envisioned are objects aware of dynamic community structures, thus being able to develop a spontaneous networking infrastructure based on the information to be disseminated other than information on the objects themselves. Analogously, the research activities reported in [25] consider that, being things involved into the network together with people, social networks can be built based on the Internet of Things and are meaningful to investigate the relations and evolution of objects in IoT. Again, IoT and social network technologies and concepts are jointly exploited towards the development of tools that can make people’s lives easier. This time the idea is to use social networking elements in the Internet of Things to allow objects to autonomously establish social relationships. The driving motivation is that a social-oriented approach is expected to put forward the discovery, selection and composition of services and information provided by distributed objects and networks that have access to the physical world. The proposed social-oriented approach is characterized by the capabilities of the objects to autonomously establish social relationships of different kinds [24], [26], [7]. Within the resulting object social network, a key objective will be to publish information and services, find them, and discover novel resources to support the implementation of complex services and applications. This can be achieved in a trusty and efficient way by navigating a social network of “friend” objects, instead of relying on typical Internet discovery tools that cannot scale to billions of future devices. Indeed, social networking concepts have proven to be of great importance for handling the relationships among humans and, in the same way, these are expected to have a great impact on the management of services in the IoT. Specifically, in [7] the Social Internet of Things (SIoTs) has been proposed. According to this model, a set of forms of socialization among objects are foreseen as shown in Fig. 5. The parental object relationship is defined among similar objects, built in the same period by the same manufacturer (the role of family is played by the production batch). Moreover, objects can establish co-location object relationship and co-work object relationship, like humans do when they share personal (e.g., cohabitation) or public (e.g., work) experiences. A further type of relationship is defined for objects owned by the same user (mobile phones, game consoles, etc.), which is named ownership object relationship. The last relationship is established when objects come into contact, sporadically or continuously, for reasons purely related to relations among their owners (e.g., devices/sensors belonging to friends); it is named social object relationship. These relationships are created and updated on the basis of the objects features (such as: object type, computational power, mobility capabilities, brand) and activity (frequency in meeting the other objects, mainly). The parental and ownership relationships are determined by just the static characteristics of the object (or slowly varying characteristics): type, brand, ownership. The others are determined by the movement of the object and by the other nodes it encounters. The relationships’ management is implemented in the cloud, in the object gateways, and in the objects themselves, if capable of supporting the relevant logic. Clearly, the configuration of these functionalities is controlled by the object owner; accordingly, the resulting links are asymmetrical. Download : Download full-size image Fig. 5. Sketch of the five types of relationships defined in the SIoT paradigm. To manage the resulting network and relationships, the foreseen SIoT architecture is made of four major components (among others). The Relationship management introduces into the SIoT the intelligence that allows objects to start, update, and terminate relationships. The selection of which friendship to accept is based on human control settings. Service discovery is finalized to find which objects can provide the required service in the same way humans seek for friendships and information. Indeed, to discover the service, the object queries its social relationship network. Service composition enables the interaction among objects. The service discovery exploits the object relationships to find the desired service, which is then activated by this component. Both a reactive and a proactive approach to service composition are envisaged. This component will also include the functionality of crowd information processing, to process the information obtained from different objects and obtain the most reliable answer to a query on the basis of different visions. Trustworthiness management is aimed at understanding how the information provided by other members has to be processed. 4.2. The SIoT architecture In [6], a possible SIoT architecture has been proposed, which follows the simple three-layer architectural model for IoT. In this model, the sensing layer is devoted to data acquisition and node collaboration in short-range and local networks. The network layer is aimed at transferring data across different networks. Finally, the application layer is where the IoT applications are deployed together with the middleware functionalities. The application layer is the key part in the SIoT, making this architectural proposal distinctive with respect to alternative solutions. It consists of three sub-layers, with the base sub-layer devoted to the database for the storage and management of the data and relevant descriptors, which record the social member profiles and their relationships, as well as the activities carried out by the objects in the real and virtual worlds. The component sub-layer works on top of the base sub-layer and implements the functionalities described in the previous subsection, i.e., relationship management, service discovery, service composition, trustworthiness management. The application layer is where the application are located, relying on the social-oriented behavior of the objects. With the intent to highlight the distinctive features of the SIoT architecture, in Fig. 6 we provide a mapping of the major SIoT components into the reference model provided in [27] by the IoT-A European research project, which represents a major effort in defining a reference architecture for the existing and future IoT solutions. In this figure, we show the five functional layers with the main functionalities in gray-colored boxes. In the upper layer are located the applications that are built on top of an implementation of the IoT-A architecture. This represents instances of the process execution and service orchestration, which indeed is used to combine different services (also provided by different system implementations) to implement complex services. The relevant APIs are also a key part of this layer. The virtual entity (VE) and information is the layer that maintains and organizes information related to physical entities, enabling search for services exposing resources associated to physical entities. Accordingly, it is intended to response to queries about a particular physical entity by providing with addresses of the service related to the physical entity. The lower layer, i.e., the IoT service and resource, links specific services to the related resources. It also notifies application software and services about events related to resources and corresponding physical entities. The Device connectivity and communication layer provides the set of methods and primitives for device connectivity and communication. Download : Download full-size image Fig. 6. Major functionalities of the SIoT system (in blue color) in the IoT-A reference architecture. In Fig. 6, we have highlighted the main features of the SIoT solution. At the second layer, the SIoT system may require the extension of the object descriptions to support the creation and management of the social-oriented behavior and relationships, such as: owner ID; object position, which can be changing over the time depending on the object mobility features; power supply status, that defines whether the object is either battery-powered (and the battery power level is provided), socket-connected (and whether is currently connected or not), or it harvests power from the environment; amount of traffic generated in terms of number of connections and overall bit-rate. The objects could also be grouped into different classes, depending on their main characteristics, such as mobility, computational and communication capabilities, interfaces, sensing capabilities, power supply. At the third layer, the major part of the SIoT functionalities needs to be introduced. These also call for the definition of specific ontologies and semantic engines. The ontologies are used to represent a semantic view of the social activities, which is extracted through appropriate semantic engines. The objective is to provide a machine interpretable environment for representing attributes and operations of the IoT devices. Many works have already been conducted in this area, which could be partially used in the SIoT scenario, e.g., Ontology Web Language for Services (OWL-S) model, which has already been used as the basis of a semantic service modeling framework for the IoT [28], [29]. Accordingly, services are used as an interface that represents the IoT resources (i.e., the physical world devices) and provide an access to the functions and capabilities of these resources. Ontologies to manage and control heterogeneous systems have also been investigated in [27]. This highlights that an automatic discovery will be impossible without ontological classification and semantic annotation processes. In [30], the importance of the ontology has been analyzed from a social network perspective as a format to represent the object information which is relevant to end users. Other approaches for creating semantic service descriptions could be used as described in [31]. These include: Semantic Annotations for WSDL (SAWSDL), Unified Service Description Language (USDL), Web Service Modelling Language (WSML), Web Service Modelling Ontology (WSMO), and Semantic Annotations for Representational State Transfer SA-REST [32]. The relationship management module is the one responsible to establish, update, and terminate the relationships among the objects in their virtual representation. It also elaborates the social network to facilitate the discovery of the services by identifying different clusters of resource relationships. Possible approaches are to make use of similarity measures and multi-scale renormalization and synergetic – self organization techniques. These should be embodied into the SIoT learners and adaptors of virtual resources following the cognitive networks paradigm. Consequently, an object social graph is built with objects that are linked by edges representing the established relationships, each one weighted by its computed degrees. This module is also responsible for calculating several topological features of the resource social graph such as: between-ness, closeness, degree/eigenvector hubs and authorities centrality measures. This allows for determining the most “central” nodes/resources, which is a key activity because the identified “central” nodes/resources will be those that control the data flows in SIoT and influence the rest of nodes/resources. By doing so, the “central” nodes will be marked as landmarks, representative for their local neighborhood. The service discovery functionality is key in the third layer, since it is needed to find which objects can provide a service requested in the target application. This functionality should be implemented into the SIoT system by following the rules the humans adopt to seek for friendships and for any information in the social networking services. The discovery will be guided by the object social graph as described above. The trust management module is the one responsible to address the inherent risks in transactions with no prior experience with regard to the reputation of every other node. In doing this, it exploits the resource social graph to build a reputation-based trust mechanism for the IoT that can effectively deal with certain types of malicious behavior that intend to mislead other nodes [33]. In such a scenario, two possible models for the implementation of the Trustworthiness management can be followed. One is the subjective trustworthiness, derived from a social point of view, where each node computes the trustworthiness of its friends on the basis of its own experience and on the basis of its friends’ experiences. If two nodes are not friends, then the trustworthiness is calculated by word of mouth through a chain of friendships. The other is the objective trustworthiness, obtained from P2P scenarios, where the information about each node is distributed and stored by making use of a DHT (Distributed Hash Table) structure. This information is visible to every node but is only managed by special nodes that we call Pre-Trusted Objects (PTOs). Finally, the service composition component enables the interaction between services provided by different objects to achieve complex services and applications. Most of the time, the interaction is related to an object that wishes either to retrieve an information about the real world or to find a specific service provided by another object. In fact, the main potential we see in deploying SIoT is its capability to foster such an information retrieval. 5. On-going projects The projects listed here bring together the technological aspects, related to the functionality offered by the so-called smart objects, with the social aspects. Projects in this list mainly fall into one of the three scenarios emerged from the previous sections: participatory sensing, device-in-the-circle, and devices-that-socialize. The tools to compose and build personalized and social application that merges together data from different sources belong to a field in continuous evolution and such tools are often the basis for other projects: they are mainly cloud-based because the cloud is always there, up and running, it is reachable from everywhere, and a large amount of application complexity can be moved from the target devices to the cloud components. Among these tools are: Ninja Blocks [34], IFTTT [35] and Paraimpu [36]. Ninja Blocks is a project started in 2012 from the crowdfunding platform Kickstarter.com. Ninja Blocks are cloud-based devices that can sense their environment and can act by controlling lights, power sockets, and other actuators. The system provides a tool to compose actions and sensing with common social web sites like Twitter, Facebook, Instagram. Among the sensors there is also a camera. IFTTT is a San Francisco based startup whose service enables customers to create and share within minutes very simple applications that fit the “if this then that” rule. An example of application can be IF “someone tags me on Facebook picture” then “put the picture on my Dropbox”. IFTTT was initially conceived for Internet services and social media and only later, in June 2012, the service crossed over to the physical world by integrating with Belkin WeMo [37] devices allowing IFTTT rules to compose social media events with home automation. Paraimpu is a cloud-based research prototype from CRS4, which provides the functionality to manage smart Things and to compose them with services already on the Web to create personalized applications. Common DIY (Do It Yourself) boards like Arduino, can be easily integrated as the system automatically generates the code for these boards to produce/receive data. Paraimpu allows people to share smart things and devices in their social circle enabling social physical-virtual Web mash-ups. The availability of such tools is fostering the development of personalized and interesting installation. At the moment these are generated by a small niche of geeks and early adopters but, to some extent, pave the way for a future diffusion and adoption of smart things in everyday social life. Among the installations, here are reported three “device-in-the-circle” cases: • Jardimpu [38] (based on Arduino and Paraimpu) is an automated irrigation system based on the sensing of temperature, humidity, soil moisture, light conditions, which is then used to control the level of water in some plant’s saucers (e.g. Dionaea Muscipula). This system is not an absolute novelty in the field of sensors-based garden irrigation, but it is one of the first examples of “social” gardening: people in the social circle can activate the drippers, can see plants in a live streaming, and can monitor their parameters. • TLight is a permanent installation created by the Quit group [39] and connected to the web thanks to Paraimpu, which allows everyone to change the color tones and the behavior of the lights placed on the top of the big glass tower of the T-Hotel in Cagliari. To interact with the lights, a twitter user can post a message on with hashtag:#thotel followed by any phrase containing one of the following words: red, blue, green, orange, yellow, white, cyan, purple, wave, different, couple, full, pulse e random. • Natural Fuse [40] is a social IoT game based on COSM [41]. Participants get a Natural Fuse unit which consists of a houseplant and a power socket. The amount of power available to the socket is limited by the capacity of the plant to offset the carbon footprint of the energy expended. If people cooperate on energy expenditure then the plants thrive (and everyone may use more energy). But if people do not cooperate, then the network starts to randomly kill plants. The electricity depends on the plants just as the plants depend on the electricity. The work carried on in the field of Social Web of Things by Ericsson also deserves a citation as “devices-that-socialize” use case. Researchers at Ericsson in fact are working on methods for connecting device into a social media platform for nodes that are not people. Recently they have presented at the Connected House exhibit, a social network interface that linked all of the different connected nodes in a home as well as trusted points in the public sphere. Another very popular project is Waze. Waze is a company based on Israel which developed a service called social-GPS. The service is aimed at avoid traffic, and it is based on a large community spread all over the world. It allows, through a smart phone equipped with GPS, to share real-time traffic information and help everyone to save time and fuel. Even if it does not make use of any exotic hardware but it totally relies on the smartphone functionalities, it is a perfect example of tool for participatory sensing. At the same time, it is also a case of “device-in-the-circle” because the connection with Facebook allows participants to see their friends on the map to coordinate arrival times to give or get rides or meet up with other participants. In the field of Smart Cities, the project CityScripts [42] is an experiment built on top of the SmartSantander [43] platform (with a base of 12,000 urban sensors deployed in the city of Santander). The CityScripts project is aimed at integrating and experimenting a Web of Things scenario in which sensors and actuators in the city have a digital counterpart and can be used by citizens to compose personal applications integrating sensor data with social networks and other online data sources. 6. Conclusions In this paper, we have reviewed the main approaches followed during the last years to make objects part of the human social loop and grant them a role within the human social network sites. This objective has been achieved by extending the paradigm of Web of Things to give things the capabilities to automatically post information on the social network sites and to be reached through these as well. A complementary approach is the one according to which objects have their own social network, which is independent from those of the humans but still controlled by them (albeit progressively less, as technologies progresses). The two approaches can be combined so that part of the information and actions of relevance for one social network type, that is the one where humans rule, can be exported/imported to/into the other one, where objects rule. Certainly, the objective of these approaches is to address the complexity in the management of the trillions of objects that will be connected to the network in a couple of years and to exploit their major potentialities. Through the presented survey of ongoing projects, we learned that the implementations deployed so far are limited in their potentialities. These only focus on specific applications and do not converge on an interoperable platform where social networking concepts are adopted as the major principles that drive the object interactions. References [1] O. Akribopoulos, I. Chatzigiannakis, C. Koninis, E. Theodoridis, A web services-oriented architecture for integrating small programmable objects in the web of things, in: Proceedings of the International Conference on Developments in eSystems Engineering, London, UK, September 2010. Google Scholar [2] D. Guinard, V. Trifa, T. Pham, O. Liechti, Towards physical mashups in the web of things, in: Proceedings of INSS’09, Pittsburgh, US, June 17–19, 2009. Google Scholar [3] http://www.ericsson.com/uxblog/2012/04/a-social-web-of-things/. Google Scholar [4] Chunhong Zhang, Cheng Cheng, Jang Ji, Architecture design for social web of things, in: Proceedings of the 1st International Workshop on Context Discovery and Data Mining, ContextDD ‘12, 2012. Google Scholar [5] A. Pintus, D. Carboni, A. Piras, Paraimpu: A Platform for a Social Web of Things, WWW 2012 – Demos Track, Lyon, France, April 16–20, 2012. Google Scholar [6] L. Atzori, A. Iera, G. Morabito, Michele Nitti The Social Internet of Things (SIoT) – When Social Networks Meet the Internet of Things: Concept, Architecture and Network Characterization, vol. 56, Elsevier Computer Networks (2012) Issue 16 [7] L. Atzori, A. Iera, G. Morabito SIoT, giving a social structure to the internet of things IEEE Communications Letters, 15 (2011), pp. 1193-1195 ISSN: 1089-7798 View in ScopusGoogle Scholar [8] D. Guinard A Web of Things Application Architecture – Integrating the Real-World into the Web ETH Zurich, Zurich, Switzerland (2011) Google Scholar [9] S. de Deugd, R. Carroll, K. Kelly, B. Millett, e J. Ricker SODA: service oriented device architecture IEEE Pervasive Computing, 5 (3) (2006), pp. 94-96 c3 CrossRefGoogle Scholar [10] L. M. de Souza, P. Spiess, D. Guinard, M. Kohler, S. Karnouskos, e.D. Savio, Socrades: A web service based shop floor integration infrastructure, in: Lecture Notes in Computer Science, vol. 4952, 2008, p. 50. Google Scholar [11] OASIS Devices Profile for Web Services (DPWS). <http://docs.oasis-open.org/ws-dd/ns/dpws/2009/01> (accessed 08.11.12). Google Scholar [12] A. S. Shirazi, C. Winkler, e.A. Schmidt, SENSE-SATION: an extensible platform for integration of phones into the Web, in: Internet of Things (IOT), 2010, pp. 1–8. Google Scholar [13] D. Guinard, V. Trifa, T. Pham, e O. Liechti, Towards physical mashups in the web of things, in: Proceedings of INSS, 2009. Google Scholar [14] C. Pautasso, O. Zimmermann, e F. Leymann, Restful web services vs. big’web services: making the right architectural decision, in: Proceeding of the 17th international conference on World Wide Web, 2008, pp. 805–814. Google Scholar [15] Z. Shelby, K. Hartke, C. Bormann, e B. Frank, Constrained Application Protocol (coap), draft-ietf-corecoap-07, 2011. Google Scholar [16] Yaler – A Simple, Open and Scalable Relay Infrastructure. <http://www.yaler.org/> (accessed 08.11.12). Google Scholar [17] G. Mulligan, The 6LoWPAN architecture, in: Proceedings of the 4th Workshop on Embedded Networked Sensors, 2007, pp. 78–82. Google Scholar [18] D. Kegel, The C10K Problem, 2006. Google Scholar [19] A Little Holiday Present: 10,000 reqs/sec with Nginx!|WebFaction Blog. <http://blog.webfaction.com/2008/12/a-little-holiday-present-10000-reqssec-with-nginx-2/> (accessed 08.11.12). Google Scholar [20] A. Pintus, D. Carboni, e A. Piras, The anatomy of a large scale social web for internet enabled objects, in: Proceedings of the Second International Workshop on Web of Things, 2011, p. 6. Google Scholar [21] A. Pintus, D. Carboni, A. Piras, e A. Giordano, Connecting Smart Things through Web Services Orchestrations, in: F. Daniel, e.F.M. Facca, Current Trends in Web Engineering, vol. 6385, Springer Berlin Heidelberg, Cur. Berlin, Heidelberg, 2010, pp. 431–441. Google Scholar [22] Nicolas Maisonneuve, Matthias Stevens, Bartek Ochab Participatory noise pollution monitoring using mobile phones Information Polity, 15, 1, 2 (2010), pp. 51-71 CrossRefView in ScopusGoogle Scholar [23] M. Blackstock, R. Lea, e A. Friday, Uniting online social networks with places and things, in Proceedings of the Second International Workshop on Web of Things, 2011, p. 5. Google Scholar [24] P. Mendes, Social-driven internet of connected objects, in Proc. of the Interconn. Smart Objects with the Internet, Workshop, 2011. Google Scholar [25] L. Ding, P. Shi, B. Liu, The clustering of internet, internet of things and social network, in Proc. of the 3rd International Symposium on Knowledge Acquisition and Modeling, 2010. Google Scholar [26] L. Galluccio, G. Morabito, S. Palazzo, "On the potentials of object group localization in the Internet of Things," World of Wireless, Mobile and Multimedia Networks (WoWMoM), 2011. Google Scholar [27] Internet-of-Things Architecture IoT-A Project, Deliverable D1.2 – Initial Architectural Reference Model for IoT, 2011. Google Scholar [28] S. De, P. Barnaghi, M. Bauer, S. Meissner, Service modelling for the Internet of things, in: Proc. of the Federeted Conference on Computer Science and Information, System, September 2011. Google Scholar [29] A. Katasonov, O. Kaykova, O. Khriyenko, S. Nikitin, V. Terziyan, Smart semantic middleware for the Internet of things, in: Proc. of the 5th International Conference on Informatics in Control Automation and, Robotics, May 2008. Google Scholar [30] J. Breslin, S. Decker The future of social networks on the Internet IEEE Internet Computing, 11 (6) (2007), pp. 86-90 View in ScopusGoogle Scholar [31] D. Guinard, M. Mueller, J. Pasquier, Giving RFID a REST: building a web-enabled EPCIS, in: Proc. of Internet of Things 2010 Conference, November 2010. Google Scholar [32] R. Studer, S. Grimm, A. Abecker (Eds.), Semantic Web Services, Concepts, Technologies, and Applications, Springer Verlag (2007) [33] M. Nitti, R. Girau, L. Atzori, A. Iera, G. Morabito, A subjective model for trustworthiness evaluation in the social internet of things, in: International Workshop on Internet-of-Things Communications and Networking, IEEE PIMRC, Sidney, Australi, September 2012. Google Scholar [34] Ninja Blocks – The API for Atoms. <http://ninjablocks.com/> (accessed 24.11.12). Google Scholar [35] IFTTT/Put the Internet to Work for You. <https://ifttt.com/> (accessed 24.11.12). Google Scholar [36] Paraimpu – The Web of Things is more than Things in the Web. <http://paraimpu.crs4.it/> (accessed 24.11.12). Google Scholar [37] WeMo|Belkin USA Site. <http://www.belkin.com/us/wemo> (accessed 24.11.12). Google Scholar [38] Jardimpu. <http://jardimpu.blogspot.it/> (accessed 24.11.12). Google Scholar [39] INSTALLATION: quit. <http://www.quit-project.net/?page_id=27> (accessed 24.11.12). Google Scholar [40] Natural Fuse: home/map. <http://www.naturalfuse.org/> (accessed 24.11.12). Google Scholar [41] Cosm – Internet of Things Platform Connecting Devices and Apps for Real-Time Control and Data Storage. <https://cosm.com/> (accessed 24.11.12). Google Scholar [42] CityScripts. <http://cityscripts.crs4.it/> (accessed 24.11.12). Google Scholar [43] SmartSantander. <http://www.smartsantander.eu/> (accessed 24.011.12). Google Scholar Cited by (59) A hybrid IoT services recommender system using social IoT 2022, Journal of King Saud University - Computer and Information Sciences Show abstract Towards a cell-inspired approach for a sustainable internet-of-things 2021, Internet of Things (Netherlands) Show abstract TGSM: Towards trustworthy group-based service management for social IoT 2021, Internet of Things (Netherlands) Citation Excerpt : The emergence of IoT introduces new challenges, among which service discovery is the most important and primary one. Atzori et al. [3–5] were the first ones to present a solution to this problem. They tried to approach the problem with a newfound method, which is social oriented. Show abstract A two-layer social network model for manufacturing service composition based on synergy: A case study on an aircraft structural part 2020, Robotics and Computer-Integrated Manufacturing Citation Excerpt : Interaction of users was explored in social relationship and employed to analyze the satisfaction of requests, new services were discovered through interaction [33]. After that, the system architecture of the internet of things (IoT) is established to study various social relationships, including social network and IoT [34]. Nevertheless, existing researches are more inclined towards network theory without full consideration of the business level. Show abstract Process-of-Things: Weaving film industry's practices into the Internet-of-Things 2020, Internet of Things (Netherlands) Show abstract Data fusion in cyber-physical-social systems: State-of-the-art and perspectives 2019, Information Fusion Citation Excerpt : Some hot topics of CPSS are emerging, to name a few, [8,9] focused on the study of CPSS big data, [10] focused on the research of CPSS security, [11] focused on the study of CPSS intelligence. And some paradigmatic CPSS have emerged [5,6,12–14]. They all consider humans’ needs, interests, hobbies, emotions, social relationships as part of the data fusion system [5,15]. Show abstract View all citing articles on Scopus Luigi Atzori is assistant professor at the University of Cagliari (Italy) since 2000. His main research topics of interest are in service management in next generation networks, with particular attention to QoS, service-oriented networking, bandwidth management and multimedia networking. He has published more than 80 journal articles and refereed conference papers. He has received the Telecom Italia award for an outstanding MSc thesis in Telecommunication and has been awarded a Fulbright Scholarship (11/2003–05/2004) to work on video streaming at the Department of Electrical and Computer Engineering, University of Arizona. He is senior member of IEEE, member of the IEEE Multimedia Communications Committee (MMTC) and co-chair of the MMTC IG on Quality of Experience. He has been the editor for the ACM/Springer Wireless Networks Journal and guest editor for the IEEE Communications Magazine, Monet Journal and Signal Processing: Image Communications journals. Davide Carboni is head of research on “Location and Sensor Based Services” at CRS4. His main research interests are in the field of Internet-of-things, indoor positioning/navigation with smartphones, and cloud architectures for real time web and sensor data. He is also coordinator of “Geoweb e Mobile Experience Laboratory” located at Technology Park of Sardinia. He regularly teaches various disciplines related to ICT and has been adjunct professor of “RealTime Systems for Multimedia” at University of Cagliari. He is co-author of several papers presented in international conferences and published in peer-reviewed journals. Antonio Iera is a Full Professor of Telecommunications at the University ‘‘Mediterranea’’ of Reggio Calabria, Italy. He graduated in Computer Engineering at the University of Calabria in 1991; then he received a Master Diploma in Information Technology from CEFRIEL/Politecnico di Milano and a Ph.D. degree from the University of Calabria. From 1994 to 1995 he has been with Siemens AG in Munich, Germany to participate to the RACE II ATDMA (Advanced TDMA Mobile Access) project under a CEC Fellowship Contract. Since 1997 he has been with the University Mediterranea, Reggio Calabria, where he currently holds the positions of scientific coordinator of the local Research Units of the National Group of Telecommunications and Information Theory (GTTI) and of the National Inter-University Consortium for Telecommunications (CNIT), Director of the ARTS – Laboratory for Advanced Research into Telecommunication Systems, and Head of the Department DIMET. His research interests include: new generation mobile and wireless systems, broadband satellite systems, Internet of Things. Elevated to the IEEE Senior Member status in 2007. View Abstract Copyright © 2013 Elsevier B.V. All rights reserved. Recommended articles Electrophoretic deposition for obtaining dense lanthanum silicate oxyapatite (LSO) Ceramics International, Volume 42, Issue 16, 2016, pp. 19283-19288 Gustavo Suarez, …, Tetsuo Uchikoshi View PDF Integral Evaluation of the Investment Effectiveness into Universities Development IFAC-PapersOnLine, Volume 51, Issue 32, 2018, pp. 484-489 Alexandr A. Tarasyev, …, Gavriil A. Agarkov View PDF Functional Signcryption Journal of Information Security and Applications, Volume 42, 2018, pp. 118-134 Pratish Datta, …, Sourav Mukhopadhyay View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 58 Captures Readers: 231 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply.

Paper 7:
- APA Citation: 
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: We classified our review as follows: (1) Big data quality assessment: covers the solutions designed to handle big data without considering the context. (2) Context-aware data quality assessment frameworks: covers the data quality assessment frameworks that consider the context. (3) Context modeling: covers the existing approaches for expressing and modeling the context during data quality assessment.
  Extract 2: Table 2 summarizes the solutions’ strengths and weaknesses to derive essential recommendations for building a context-aware big data quality assessment solution. Then, each solution is discussed separately, focusing on providing more technical details.
  Limitations: >
  Relevance Evaluation: 3-5 sentences: This systematic review paper presents our survey results on context-aware big data quality solutions. Only generally applicable solutions not related to a specific domain were selected in this survey. The strength and weaknesses of existing solutions are outlined comprehensively and discussed intensively. Moreover, we presented a sketch of a solution that could address the limitations of existing solutions. Finally, we identified the open challenges for building such a solution.
  Relevance Score: 0.9739130434782609
  Inline Citation: >
  Explanation: This systematic review paper presents our survey results on context-aware big data quality solutions. Only generally applicable solutions not related to a specific domain were selected in this survey. The strength and weaknesses of existing solutions are outlined comprehensively and discussed intensively. Moreover, we presented a sketch of a solution that could address the limitations of existing solutions. Finally, we identified the open challenges for building such a solution.

 Full Text: >
This website uses cookies We occasionally run membership recruitment campaigns on social media channels and use cookies to track post-clicks. We also share information about your use of our site with our social media, advertising and analytics partners who may combine it with other information that you’ve provided to them or that they’ve collected from your use of their services. Use the check boxes below to choose the types of cookies you consent to have stored on your device. Use necessary cookies only Allow selected cookies Allow all cookies Necessary Preferences Statistics Marketing Show details       skip to main content University of Nebraska Lincoln Browse About Sign in Register Journals Magazines Proceedings Books SIGs Conferences People Search ACM Digital Library Advanced Search Journal Home Just Accepted Latest Issue Archive Authors Editors Reviewers About Contact Us HomeACM JournalsJournal of Data and Information QualityVol. 15, No. 3Context-aware Big Data Quality Assessment: A Scoping Review SURVEY SHARE ON Context-aware Big Data Quality Assessment: A Scoping Review Authors: Hadi Fadlallah , Rima Kilany , Houssein Dhayne , + 4 Authors Info & Claims Journal of Data and Information QualityVolume 15Issue 3Article No.: 25pp 1–33https://doi.org/10.1145/3603707 Published:22 August 2023Publication History 0 citation 567 Downloads eReaderPDF Journal of Data and Information Quality Volume 15, Issue 3 Previous Next Abstract 1 INTRODUCTION 2 RESEARCH METHODOLOGY 3 BACKGROUND 4 SCOPING REVIEW RESULTS 5 DISCUSSION 6 DATA QUALITY ASSESSMENT ARCHITECTURE – A PROPOSAL FOR A METHODOLOGICAL FRAMEWORK 7 OPEN CHALLENGES 8 CONCLUSION AND FUTURE WORK Footnotes REFERENCES Index Terms Recommendations Comments Skip Abstract Section Abstract The term data quality refers to measuring the fitness of data regarding the intended usage. Poor data quality leads to inadequate, inconsistent, and erroneous decisions that could escalate the computational cost, cause a decline in profits, and cause customer churn. Thus, data quality is crucial for researchers and industry practitioners. Different factors drive the assessment of data quality. Data context is deemed one of the key factors due to the contextual diversity of real-world use cases of various entities such as people and organizations. Data used in a specific context (e.g., an organization policy) may need to be more efficacious for another context. Hence, implementing a data quality assessment solution in different contexts is challenging. Traditional technologies for data quality assessment reached the pinnacle of maturity. Existing solutions can solve most of the quality issues. The data context in these solutions is defined as validation rules applied within the ETL (extract, transform, load) process, i.e., the data warehousing process. In contrast to traditional data quality management, it is impossible to specify all the data semantics beforehand for big data. We need context-aware data quality rules to detect semantic errors in a massive amount of heterogeneous data generated at high speed. While many researchers tackle the quality issues of big data, they define the data context from a specific standpoint. Although data quality is a longstanding research issue in academia and industries, it remains an open issue, especially with the advent of big data, which has fostered the challenge of data quality assessment more than ever. This article provides a scoping review to study the existing context-aware data quality assessment solutions, starting with the existing big data quality solutions in general and then covering context-aware solutions. The strength and weaknesses of such solutions are outlined and discussed. The survey showed that none of the existing data quality assessment solutions could guarantee context awareness with the ability to handle big data. Notably, each solution dealt only with a partial view of the context. We compared the existing quality models and solutions to reach a comprehensive view covering the aspects of context awareness when assessing data quality. This led us to a set of recommendations framed in a methodological framework shaping the design and implementation of any context-aware data quality service for big data. Open challenges are then identified and discussed. Skip 1INTRODUCTION Section 1 INTRODUCTION Data quality is the measure of how much data can fit its intended use [124]. Assessing data quality levels is critically important to choose whether or not to use the data to make more accurate decisions. Since the decision-making process relies mainly on data, measuring data quality based on its intended use is a sine qua non. Strong et al. [124] have categorized data quality factors into four categories: (1) Intrinsic: The quality factors independent of the context of use, such as accuracy, believability, objectivity, and reputation. (2) Contextual: The elements, such as completeness and timeliness, that reflect how much data is helpful within a specific context. (3) Representational: The factors that show the presentation quality for the consumers, such as ease of understanding. (4) Accessibility: The factors that reflect if consumers can access the data when needed. Wang et al. [134] differentiated information from data and described the information as data that has been processed in some manner. Then, Pipino et al. [112] developed the concepts, principles, and procedures for defining, measuring, analyzing, and improving information products called Total Data Quality Management (TDQM). In addition to standard data quality, a more refined approach called context-aware data quality was introduced. The term “context” is subjective and can be related to the data life cycle phase (ingestion, processing, analysis), the data types, the domain of data, organizational policy, decision-making policy, the time range within which the analysis is done, the security level, or the available resources. In ISO/IEC 9126-1 [71] and ISO/IEC 25000 [73] standards, contextual data quality is defined from a generic standpoint, which is the following: the quality-in-use level. Quality-in-use considers the information as the subject and reflects the quality level when data is used in real conditions by including the execution environment, decision-making policies, permissions, and every quality characteristic related to the context in the assessment operation. Wang et al. [135] described the main quality factors reflecting this category: (1) Added value: determines the amount of data that gives a competitive edge and adds value to operations. (2) Relevancy: determines how much information is applicable, relevant, valuable, and usable. (3) Timeliness: determines the age of data. (4) Completeness: determines the breadth, depth, and scope of the information contained in the data. (5) The appropriate amount of data: determines the amount of data that is suitable for the task. Merino et al. [96] identified other contextual characteristics such as accuracy, consistency, credibility, compliance, confidentiality, and understandability. Additionally, Ge et al. [53] categorized the data quality problems between context-independent and context-dependent, and Woodall et al. [138] further extended this categorization. In this research, we heavily focus on how a data quality assessment method can be developed to adapt flexibly to different contexts. Typically, the properties of context are diverse; therefore, data quality assessment solutions must have the ability to be used within any context and to take into consideration all related conditions. Considering this critical factor, we define context awareness as follows: It is the ability of data quality solutions to evaluate the quality of data considering the generic properties of context, which enables the solutions to be used in any context. The data quality solutions must check whether the data properties are suitable with related policies and available resources in addition to the contextual factors. Data quality assessment is less challenging in traditional technologies such as data warehouses. The data model follows the relational schema principles, data size is reasonable, and the data is at rest. Leading companies such as Microsoft [30, 31], Oracle [32], Informatica [69], and Talend [130] offer many tools and frameworks that can be used to develop and administer ETL jobs and address the majority of data quality issues. However, these technologies limitations are three-fold: (i) the ability to adapt to different contexts, (ii) the generalization of data quality assessment methods remains an issue, and (iii) these technologies confront challenges when handling large datasets with high variety, and generated at high speed. More explicitly, traditional technologies still need to be appropriately used for non-relational massive data [94], such as processing wireless sensor feeds in real-time [6]. The operational limitation of traditional technologies can be tackled using highly advanced processing resources and distributed technologies such as distributed file systems (e.g., HDFS) developed over the past decade. However, these technologies do not address quality assessment standardization; instead, the quality issues are handled using different heuristics [118]. The quality assessment approaches need yet to reach a level of maturity that the industries would accept [104]. In short, quality assessment techniques within the big data domain remain an open research issue [11]. Furthermore, context-aware quality assessment is a critical concern, since any meaningless quality dimension measurement would consume time and resources and cannot yet be dealt with by state-of-the-art big data technologies. A context-aware quality assessment solution for assessing the quality attributes of big data is strongly required. The properties of the context should be generic for the solution to be used/adopted in any context. Such a data quality assessment solution would greatly help extract value-added intelligence from data that the industry is currently seeking. These requirements give rise to the following research questions: What are the challenges of building a context-aware big data quality assessment framework? What are the requirements for building such a framework? We conducted a deep and wide survey to answer these questions. This scoping review article presents our survey results on context-aware big data quality solutions. Only generally applicable solutions not related to a specific domain were selected in this survey. The strength and weaknesses of existing solutions are outlined comprehensively and discussed intensively. Moreover, we presented a sketch of a solution that could address the limitations of existing solutions. Finally, we identified the open challenges for building such a solution. The rest of this article is organized as follows: Section 2 describes our research methodology. Section 3 defines the main terms and concepts used in this work. Section 4 provides a literature review of the recent research about context-aware data quality and big data quality. Section 5 highlights the significant results and elements that should be considered in future research. Section 6 describes a methodological framework for a context-aware big data quality assessment solution based on the literature investigation. Section 7 lists the open challenges. Section 8 concludes this work. Skip 2RESEARCH METHODOLOGY Section 2 RESEARCH METHODOLOGY Since our research aims to study the need for a context-aware big data quality assessment solution, as well as the challenges of building such a solution, two topics were covered by our research: (1) Assessing the data quality in the domain of big data. (2) Achieving context awareness while assessing data quality. We tried to answer five general research questions that are essential for building a context-aware big data quality assessment solution: What does a data quality assessment solution require to handle big data? How is data context defined in the existing data quality assessment solutions? How is context-aware data quality different in big data compared to traditional context-aware data quality? What key components/methods are used to achieve context awareness during data quality assessment? What are the main limitations and open challenges when building a context-aware data quality assessment solution that handles big data? To our knowledge, no surveys about context-aware big data quality assessment methods have been published. To bridge this research gap, in this article, we studied the existing data quality assessment solutions that consider the context or are designed for big data. Then, we tried to link both concepts to derive the main recommendations for building a context-aware big data quality assessment solution. Following Munn et al. [100] guidance when choosing between a systematic or scoping review approach, researchers should conduct a scoping review when they try to scope a body of literature, identify knowledge gaps, and clarify the key concepts. Thus, we found a scoping review more suitable than a systematic review, since—to our knowledge—no surveys about context-aware big data quality assessment methods have been published to date. We aimed in this survey to fill this research gap by studying the existing data quality assessment solutions that consider the context and/or are designed for big data. Then, we tried to link both concepts to derive the main recommendations for building a context-aware big data quality assessment solution. Our research started by searching for the following keywords: “context data quality”, “contextual data quality”, “context-aware quality”, “big data quality”, “data lake quality”, “context-aware big data quality”, “context-aware information quality”, “data quality in use” over the following scholarly literature indexes: Google Scholar,1 IEEE Xplore,2 and DBLP3 in addition to using the Mendeley search engine4 and the ResearchGate5 social network. The first research phase resulted in more than a hundred articles. To select only the articles that are within our research scope, we defined two selection criteria: (1) The generally applicable big data quality assessment solutions that focus on handling the big data characteristics while assessing the data quality and excluding those related to a specific domain (for example, we excluded the healthcare quality assessment solutions). (2) The data quality assessment solutions where the data context is defined and considered. Since this was only a scoping review, no limits were placed on the publication date or research methodology. After filtering the search results based on the selection criteria, we identified three highly cited articles6 that are considered a primary reference for most contextual data quality research: “Data Quality in Context” (1,964 citations) [124], “Beyond Accuracy: What Data Quality Means to Data Consumers” (5,852 citations) [135], “A Product Perspective on Total Data Quality Management” (1,403 citations) [134]. Then, we searched over the citing articles. As a result, our scoping review covered 27 articles (Table 1) published between 2005 and 2021 (Figure 1); 18 were about context-aware data quality assessment, and 9 were about big data quality assessment where the data context was not considered. Fig. 1. Fig. 1. Articles distribution over the years. Table 1. Reference Year Citations Handling big data context awareness Even et al. [46] 2005 52 X Even et al. [47] 2007 159 X Helfert et al. [62] 2009 24 X Show More Table 1. Classification of the Publications Discussed in This Review Limitations and strengths A wide range of information was collected, analyzed, and fruitfully combined into a methodological framework offering an integrated context-aware big data quality solution. However, this scoping review started by searching for specific keywords, which may have resulted in unintentionally discarding some relevant research. Moreover, we intentionally excluded domain-specific big data quality assessment solutions, since our ultimate goal was to propose a framework that is general enough to be used in any domain. Skip 3BACKGROUND Section 3 BACKGROUND This section lays out the background of the concepts covered by our research. It provides a conceptual description of data quality assessment and big data quality. 3.1 Data Quality Ensuring data quality requires assessment and improvement techniques to be implemented during any phase of the data life cycle. Each stage may have different quality requirements. For example, data credibility may be optional while ingesting data from social media. In contrast, it is critical in the analysis phase. The data quality level is calculated based on several quality characteristics defining the data’s quality aspects, such as the accuracy and completeness level [72]. These characteristics are measured through specific measurement methods. The quality measurement methods are implemented using quality assessment techniques in the real data environment. Data quality techniques can generally be informative (assessment) or operational (improvement). Below, we explain these techniques. Data quality assessment techniques. Various techniques can be used to assess data quality. These techniques can be grouped into two categories: (1) objective techniques that measure the data quality based on the data characteristics and (2) subjective that ask the data consumer to rate the data quality [27]. An objective measurement is mainly done using the following techniques: Data quality models: Each data quality model is composed of several data quality dimensions measured using several quality metrics [53, 96, 124, 135, 138]. Data profiling: This technique collects statistics or informative summaries about data (e.g., the percentage of null values within a dataset and the number of duplicates). It is used before and after storing data [7, 89, 97, 105, 129]. Data provenance: This technique describes the origin and history of the data [23, 111]. Data integration: It is the process of integrating a dataset with other knowledge bases or data from credible sources to assess the accuracy and consistency of the data [26, 137]. As for the subjective measurement of data quality, it is done using one of the following techniques: Crowdsourcing: This technique engages a crowd to achieve a common goal. It is one of the techniques used to assess the quality of specific information. Mainly, this technique is used for unstructured data (text, videos, images...) [3, 50, 65, 87, 140]. Survey and questionnaires: Data consumers should rate the data quality after using it [113]. Data quality improvement techniques. Researchers have proposed a wide variety of techniques to improve data quality. Below is the list of the techniques we found in the literature. Data cleansing: Detecting and fixing inaccurate and erroneous values within records [85, 114]. Data enrichment: This technique adds additional information to the current data records from other external sources or uses advanced statistical techniques [8, 82]. Data fusion: It integrates related data from different sources to reject non-credible, inaccurate, and inconsistent data [40]. Data deduplication: It is the process of removing data records that store the same information [60, 93]. Machine learning-guided cleaning: Classifying duplicate pairs in deduplication, estimating the most likely value for a missing value, predicting a transformation, or classifying values as normal or outliers [66]. 3.2 Big Data Quality Big data quality is critical to performing effective analysis and extracting meaningful insights [37]. As mentioned earlier, the traditional data quality assessment and improvement techniques must be improved to meet big data requirements. Until today, big data quality is still an open research issue. Batini et al. [11] showed the importance of data quality assessment when handling big data. They described the emerging challenges, such as handling a wide variety of data types, data generated at high speed, massive amounts of data analyzing maps, linked open data, and wireless sensors. Moreover, they described how the data sources and quality characteristics have evolved, leading to these new challenges. Saha et al. [118] provided an overview of the existing traditional data quality tools, then described the process of discovering and learning data quality semantics and repairing inconsistency at various stages in the big data domain. Clarke et al. [28] considered data accuracy, precision, timeliness (temporal applicability, Up-to-Dateness, Currency), and completeness as the main big data quality factors. They also described the primary quality assurance processes applicable in all data stages. Clarke et al. [28] also described the quality factors needed in the decision-making process as the data relevance, the data meaning, and the transparency of the decision-making process. While studying the quality assurance techniques for big data applications, Zhang et al. [141] considered data accuracy, scalability, correctness, consistency, and security as the main factors for big data quality assessment. Gao et al. [52] described the leading big data quality assurance parameters as data accuracy, currency, timeliness, correctness, consistency, usability, security, privacy, completeness, accessibility, accountability, and scalability. Then, they classified the data quality issues between (1) enterprise management issues (organization management issue, big data management issue, data quality assurance issue) and (2) big data processing and services issues (data collection issue, data conversion issue, data service scalability issue, data transformation issue). They demonstrated that poor data quality might lead to (1) higher costs for enterprises and businesses, (2) inefficient service operations, (3) as well as it may reduce business revenues and (4) affect the accuracy of the data analysis. They mentioned that data validation must be implemented within data collection, cleaning, transformation, loading, aggregation, and analysis operations to guarantee high quality. Finally, they described the main challenges facing organizations regarding data quality assurance in the context of big data as (1) the lack of awareness and a good understanding of big data quality assurance and validation, (2) the lack of well-defined enterprise-oriented big data assurance standards, (3) the lack of available research results on big data quality models and evaluation metrics, and (4) the lack of well-established big data certification program and standards. Big data quality and machine learning. Big data quality is crucial for many other computer science fields, such as data analytics and machine learning. The use of machine learning often requires big data. Machine learning algorithms face several challenges that arise from the big data Vs.: Volume, Velocity, Veracity...[133]. A wide variety of data sources and collection methods can result in noisy and uncertain data [139] that highly affect the learning process and result in inaccurate models. It is impossible for several machine learning algorithms, particularly deep learning algorithms, to achieve their full potential without large, well-maintained training sets [143]. L’Heureux et al. [92] stated that handling dirty and noisy data is one of the main challenges that face machine learning algorithms in a big data context. They also stated that it is difficult for a machine learning algorithm to learn from data that lacks objectivity or absolute truth, such as social media posts or crowdsourcing. Zhou et al. [143] recommended developing algorithms that can assess the trustworthiness or credibility of data or data sources to handle data veracity challenges when training machine learning models using big data so unreliable or contradictory data are filtered during pre-processing. Gudivada et al. [55, 56] considered big data and machine learning applications’ main challenge as developing an automated tool to resolve data quality issues such as streaming data, disparate data types, and integration difficulties. However, machine learning techniques are useful while handling big data quality. Four areas could be identified under the umbrella of data quality that machine learning helps to address [66, 68]: Handling missing values within the data. Assessing the data source relevance to a specific domain without user intervention. Anomaly detection: In a data pool, machine learning programs can detect patterns, associations, and rare occurrences. Data deduplication: Machine learning techniques can be more efficient in handling inconsistent data, stale data, or data with typos. Dai et al. [34] proposed a solution that detects erroneous data using deep learning and outlier detection techniques to improve big data quality. Skip 4SCOPING REVIEW RESULTS Section 4 SCOPING REVIEW RESULTS Big data quality and context-aware data quality assessment have been discussed in a large body of literature. This article investigated the quality models and techniques used to assess data quality and achieve context awareness in the big data context. Moreover, since context-aware big data quality assessment is not widely addressed, our study was extended to include valuable research on big data quality. We categorized our review as follows: (1) Big data quality assessment: covers the solutions designed to handle big data without considering the context. (2) Context-aware data quality assessment frameworks: covers the data quality assessment frameworks that consider the context. (3) Context modeling: covers the existing approaches for expressing and modeling the context during data quality assessment. We start with an overview of the reviewed literature and summarize the works we studied in Table 2. Existing solutions are compared based on three main aspects: (1) the data source types they can handle, (2) how they guarantee context awareness, and (3) how they handle big data. Moreover, we highlighted the solutions’ strengths and weaknesses to derive essential recommendations. Then, each solution is discussed separately, focusing on providing more technical details. Table 2. Solution Data Type Context Awareness Big data Strengths Weakness Batini et al. [25] Structured, semi-structured, unstructured Data context is defined based on the data sources, conceptual entities, and organizational units Knowledge extraction techniques to extract the schema from unstructured data Handling unstructured data + using schema matching techniques Does not handle other big data characteristics such as streams and huge volume Bicevskis et al. [19] [18], Bicevska et al. [16] [17], Nikiforova et al. [107] [108] Structured, semi-structured Data object, domain-specific language Not mentioned Formal language + requirements written by end-user Tabular data + data at rest + experts must be involved Even et al. [46] [47] Structured Intrinsic numeric value based on the customer’s point of view Not for big data Convert context business rules into quantitative methods + treat data as its value from the user perspective Only for tabular data + limited context definition Show More Table 2. Literature Summarization 4.1 Big Data Quality Assessment Cai et al. [24] proposed a two-layer big data quality standard for assessing data quality. The first layer contains the data quality dimensions, and the second layer contains each of the characteristics of each dimension. Then, they defined the primary indicators used to evaluate each quality characteristic. After defining the data quality dimensions, characteristics, and indicators, they proposed a data quality assessment process for big data, having four phases: (1) preparation, (2) pre-processing and assessment, (3) evaluation and troubleshooting, and (4) the analysis phase. Preparation phase: This phase requires a clear understanding of the work, since data consumers should determine the goals of data collection, the data source types, volume, and other parameters. Then, they should select data quality elements (characteristics). For each quality element, assessment indicators should be specified. Finally, a quality evaluation baseline should be formulated. This phase can well define the project scope. Pre-processing and assessment phase: This phase starts with the data collection operation. After collecting data, data quality is improved by detecting and removing typing errors and inconsistencies (pre-processing/cleaning). After data cleaning, the data quality assessment is performed. Evaluation and troubleshooting phase: After quality assessment, the data quality levels are compared with the previous evaluation baseline; if it meets baseline standards, then a quality report is generated. Otherwise, iterative improvement is achieved by returning to the data collection step. Analysis phase: If results do not reach the goal after many attempts, then the data quality assessment baseline may not be reasonable. In this case, data mining and analysis techniques may improve the evaluation baseline to obtain results aligned with the goals. This proposal provides a systematic approach to studying, evaluating, and monitoring data quality, which is very efficient. Using quality indicators is a great added value, since it simplifies quality measurement. Moreover, using data mining and analysis techniques to improve the evaluation baseline increases the quality assessment’s context awareness level. However, the proposed process cannot handle big data, since it does not address unstructured data quality assessment, nor the data volume challenges. In addition, the solution requires high user intervention, which is not valid with high-velocity data. Dmitriyev et al. [38] proposed SOA-Enabled ELTA, a new approach for extract, load, and transform (ELT) operations to prepare business intelligence solutions for big data. SOA-Enabled ELTA is built using a service-oriented architecture to perform data transformations and validate data through defined business rules. This provides high-level business concept representation, which can be published and discovered in a distributed network and reused to build new (business) functions and applications. Still, it is unclear how data quality can be assessed, since only the data cleaning process is described. Moreover, handling unstructured data is not covered, meaning this solution does not address the big data variety challenge. Ramaswamy et al. [115] considered the data accuracy, error rate, frequency, availability, timeliness, validity, and trustworthiness to evaluate data quality within a federated sensors network. They proposed a cloud-based solution to host the domain application and a central data quality repository. They used markup language to describe sensor feeds containing actual data quality metadata, while historical data quality metadata was stored in an aggregated form for optimizing storage. Using a cloud-based solution gives the ability to efficiently handle big data, since it enables high scalability and gives the ability to perform stream and batch processing. Moreover, storing only aggregates of historical data quality measurements can avoid a high-speed growing data volume and decreases the needed resources. However, this solution is proposed specifically for wireless sensor feeds and cannot handle different types of data sources. Moreover, it lacks essential quality dimensions such as completeness and uniqueness. To assess social media data quality, Immonen et al. [67] considered data accuracy, believability, completeness, consistency, corroboration, coverage (amount of data), validity, popularity, relevancy, timeliness, and verifiability as the relevant characteristics for the quality model. To describe each quality characteristic, they adopted Niemelä et al.’s [106] proposal by considering a group of quality metrics to evaluate a quality attribute (characteristic). Each metric is defined by the description, purpose, target, applicability, formula, value range, acceptable value, and rule. One of the main weaknesses of this solution is that the data quality rules and decision-making policies should be manually specified for each data source, knowing that automating the assessment operation is essential in a big data environment. Besides, the solution is designed to assess data ingested from social media and does not support other data sources. To assess data quality, they proposed a metadata management extension implemented within a big data reference architecture proposed by Paakkonen et al. [109]. The extension will be used during all data life cycle phases. In the data extraction phase, the organizational policy facilitates the process by defining an acceptable data source, quality attributes, applicability time of the quality attribute, as well as metrics and methods to evaluate the quality. After extraction, the imported data is stored in a data storage. The quality metadata is created for the dataset, and the evaluated values for quality attributes are automatically inserted into the metadata repository. The organizational policy helps select datasets for processing/analysis purposes and helps to attach applicable quality attributes for metadata of datasets. The decision-making policy facilitates the selection of relevant data for decision-making purposes. When evaluating the significance of a dataset for a specific purpose, the decision-making policy helps to weigh the relevant quality attributes for the practical situation. One of the main advantages of this extension is implementing organizational and decision-making policies to meet the context requirements. Besides, it guarantees data provenance by storing metadata from all data life cycle phases. However, it does not systematically select relevant data quality characteristics. It requires a high user interaction, which is not preferred in a big data context. To assess and monitor data quality from the heterogeneous data source, Ehrlinger et al. [45] proposed a high-level architecture for a data quality assessment solution that is composed of four components: (1) Data profiling component, (2) data quality repository, (3) time-series analytics, and (4) user interface. This solution’s core is the data quality repository, which contains an ontological description of the assessed information system schema and a database that stores only the measurement of the data quality metrics commonly used and the ones related to the time-series analysis. The time series analysis is performed to detect temporal data outliers affecting data quality. This proposal is a high-level architecture where many features are not described clearly, such as how data sources are integrated with the ontological description found within the quality repository. Using this kind of repository is very beneficial to address data variety by linking data with a unified description. Later, Ehrlinger et al. proposed QuaIIe [43, 44], an unsupervised data quality monitoring tool that allows continuous data quality verification. It uses data source connectors to read from structured data such as Oracle database and semi-structured data such as XML and comma-separated values. One of the main advantages of QuaIIE is that it performs ad hoc quality analysis on integrated data sources. In contrast, its main weakness is that it does not handle schema-less data and only supports equijoins operation to integrate multiple data sources. Gu et al. [54] proposed SparkDQ, a data quality management framework for Apache Spark,7 to improve the data quality in a big data environment. They implemented several flexible quality issues detection and repair algorithms to customize data detection and repair logic for specific needs. The main weakness of this framework is that it can handle only structured data and does not handle the format variety aspect in the big data context. Schelter et al. [119] proposed a declarative language that automates measuring large-scale data accuracy, consistency, and completeness using incremental data quality scoring and machine learning techniques to predict values and anomalies based on historical data. Still, the proposed solution lacks essential data quality dimensions, such as timeliness. Also, the logical operators are defined based on the author’s definition of each quality dimension, while these definitions may vary based on the data consumer perspective, meaning that this solution may not be implemented in a different context. 4.2 Context-aware Data Quality Assessment Frameworks Batini et al. extended their previously proposed data quality solution for structured data to address the data heterogeneity issue [10] with the ability to assess data quality for unstructured and semi-structured data [25]. They proposed an entity-relationship “Meta-Model” to associate the needed data quality dimensions and the included conceptual entities with each data source used by organizational units. After defining the data context (data sources, conceptual entities, organizational units), information is extracted from the data to perform a data quality assessment. The extraction process is done using two techniques (1) reverse engineering and (2) schema mapping (with the Meta-Model). While this solution addresses the data variety challenge, it can only handle a small data volume. Bronselaer et al. [21] proposed an operational approach for data quality measurement where quality is assessed in terms of the cost of task completion using the data. Unlike the value-driven quality assessment, the operational approach considers the time and resources needed to complete the required task. At the same time, it ignores the intrinsic characteristics of the data, which means that a descriptive quality assessment must precede this type of assessment. Moreover, the authors assumed that data is finite, making this proposal unable to fit the big data requirements. To assess data quality, Helfert et al. [62] used the quality characteristics defined in Reference [135]. Then, they classified these characteristics based on semiotics layers (pragmatics, semantics, syntactic) and the quality aspects (quality of design and conformance) and defined the measurement approach for each group. To evaluate the context, the proposed framework requires an analysis of the information system environment before measuring quality dimensions. Depending on the specific context, we can select and prioritize different information quality dimensions by applying a metric such as Leung’s metric for importance, urgency, and cost [90]. In their proposed framework, the authors defined the data context as a combination of (1) the end-user requirements, (2) the application task, and (3) the information system environment. This framework guarantees high data consumer satisfaction, since its requirements are essential. Moreover, using a systematic approach to select the needed quality dimensions increases the framework’s robustness. However, this framework requires a high user interaction, which is not recommendable when handling massive data volumes. Organizational policies and available resources are not considered a part of the data context. Taleb et al. [127] classified the data quality characteristics into two categories: intrinsic and contextual. They proposed a quality framework for the data pre-processing phase. The framework is composed of four main components: (1) data quality profile selection, (2) adaptation, (3) data quality control, and (4) monitoring. First, the user should select a data quality profile containing all related pre-processing activities (cleansing algorithms and targeted data quality) based on the data domain, user-defined business rules, and auto-discovery techniques. The quality profile is sent as XML to the data quality profile execution component. After receiving the profile, the cleansing algorithm is distributed across the big data cluster nodes and executed over a data sample. When the data processing finishes, the quality controller components check whether the cleansed data meets the quality requirements. If so, then the cleansing algorithm is executed over the whole dataset. Two main factors make this framework very efficient while handling big data: using a MapReduce paradigm and performing data quality profiling over a data sample to check if it is acceptable. Although it is adaptable to different contexts, it only assesses the data quality during the pre-processing phase and does not consider the representational and accessibility quality dimensions. Merino et al. [96] proposed a data quality model based on ISO/IEC 25010, 25012 [72, 122], and 25024 [74] standards. They classified the ISO/IEC 25012 quality characteristics based on 3A’s model, an improved form of the quality categories used by Strong et al. [124]. They regrouped the categories as (1) contextual adequacy (contextual data quality), (2) operational adequacy (accessibility, representation, and intrinsic qualities), and (3) temporal adequacy (the authors separated it from the contextual category due to the growing significance of time analysis). They proposed a data quality-in-use framework grounded on the quality measures from ISO/IEC 25024 to calculate the level of fulfillment of the data quality characteristics (ISO/IEC 25012). Accordingly, to measure the data quality-in-use level, first, (1) the data quality requirements delimited by the scope need to be established. Then, (2) the appropriate adequacy type must be selected in addition to identifying the relevant quality characteristics. (3) The user-defined business rules and the quality measures defined within the context should be gathered. (4) The quality measures are evaluated, and finally, (5) a quality report is generated. This framework’s main advantages are using ISO standards and the context awareness guaranteed by the user-defined business rules and quality measures. However, it fails to consider the velocity and variety characteristics of big data, since it cannot handle streams and unstructured data. Ardagna et al. [7] used accuracy, consistency, completeness, and timeliness as data quality characteristics and added precision, distinctness, volume, and trustworthiness to meet the big data quality requirements. The proposed framework’s main components are (1) the Data quality profiling module that provides metrics to measure and monitor the overall data quality such as the number of values, number of null values, number of distinct values, maximum, minimum, mean, and standard deviation. Furthermore, (2) the Assessment modules are in charge of computing data quality dimensions. Data profiling starts automatically after the data source is registered; the source analyzer detects the source metadata and the appropriate quality dimensions (based on data type and format) to be measured. Then, the data quality profiling module executes an initial profiling operation and stores the data profile within the quality metadata repository. Unlike data profiling, the data assessment phase is executed on-demand; the data quality service interface allows users/applications to access the data quality service, browse the data quality metadata repository, or set up the quality assessment operation. All configurations are saved to the custom settings repository and a configuration file. The data quality adapter uses the external configuration file to tune the result’s precision. Since data quality evaluation can be expensive on massive data, the adapter can select a subset to provide a faster evaluation but with lower precision. The main parameters of the data quality adapter are (CCT model): Confidence: the size of the sample dataset/size of the whole dataset Budget (cost): the number of computational nodes (resources available) Time: the estimated execution time. The user must select one of the following three scenarios: Confidence maximization = maximum cost + maximum time Cost minimization = minimum confidence + maximum time Time minimization = minimum confidence + maximum cost. Once the confidence level is selected, the data quality assessment is executed. This framework is built using a service-oriented architecture (SOA) paradigm, which ensures high interoperability. The data profiling module solves the context-dependent quality assessment issues. At the same time, adopting the CCT model allows the execution of the assessment operation on commodity machines with low resources. The three predefined scenarios can be very efficient in minimizing user interaction. Using knowledge repositories (settings, quality metadata) helps prevent repetitive operations and allows the framework to handle streams (low user interaction is required). However, this framework shows many weaknesses: Unlike the data quality assessment, data quality profiling is performed on the whole dataset, which may be time-consuming and may require more resources than available. Moreover, the selected scenario (CCT model) may be incompatible with the real environment (i.e., the user may select the confidence maximization scenario while having insufficient resources). Finally, this solution cannot integrate with reference data sources that may be needed to evaluate data consistency. Taleb et al. [128] listed and classified unstructured data sources based on their domain and types to assess data quality for unstructured big data. They specified six steps: (1) Knowing the data (type, format, domain). (2) Specifying the data quality dimensions to use. (3) Specifying the data quality metrics to consider. (4) Identifying the attributes to evaluate. (5) Choosing a sampling strategy. (6) Choosing a quality assessment methodology. These six steps were implemented within a data quality assessment model. Knowledge extraction and mining techniques were used to gather information required for quality assessment. The classification of the data sources based on the domain and types gives the model the ability to adapt to different contexts. However, this classification needs to be updated and evaluated periodically. Mylavarapu et al. [101] proposed a context-aware big data accuracy assessment tool based on a collection of datasets already stored in the data lake. The quality assessment is done in three phases: training, record linkage, and accuracy assessment. The idea is to use word embeddings and record linkage techniques to identify the most accurate reference data, which will serve as a basis for the accuracy assessment process of the input dataset. For the same purpose, Talha et al. [131] distinguished between intrinsic and contextual data accuracy and proposed a method to select a reference dataset from a data lake to assess the contextual accuracy of input data. They defined several accuracy criteria to select the appropriate reference dataset. The proposed solution first collects several datasets from different providers and assigns a value for each dataset for each accuracy criterion; it uses schema-matching techniques to map between the input data and the selected datasets. Then, it uses record linkage and data sampling techniques to match records and filter the datasets that do not match the input dataset before assessing the data quality. Mylavarapu et al. [102] proposed another solution to assess information consistency based on its context. The proposed solution uses feature selection algorithms to extract the context information from a data record, then perform a record linkage to match it with existing datasets within a data lake to perform a consistency check. These assumptions can be correct if it is guaranteed that the data in the lake are correct and up to date, which is generally not the case. Moreover, the input data may even be of better quality. Besides, these solutions focus on only one quality dimension: data accuracy or consistency, while other essential dimensions should also be considered in a big data context. 4.3 Context Modeling 4.3.1 Expressing Context as Objects. To make data quality requirements executable, Bicevskis et al. [18] proposed a data quality model composed of three components: (1) data object, (2) quality requirements, and (3) quality evaluation process. Then, they divided data quality requirements into two categories: (1) syntactic (the quality of the data object itself) and (2) semantic (contextual). Two types of semantic quality control were considered: (1) contextual control on interrelated data to ensure the quality of the interconnected data objects and (2) contextual control on the entire dataset. The quality requirements are expressed in diagrams using a domain-specific language and then converted to executable tasks by IT and domain experts. They implemented their work using DIMOD, a derivative of the graphical tool-building platform GrTp [9]. This work was extended and demonstrated by Bicevska et al. [16, 17], where semantic quality control is divided into three categories: (1) contextual quality control of interrelated data, (2) contextual quality control over the data within a database, (3) contextual control over data stored within several databases/systems. This notion was extended in Reference [19], where the authors focused on how to design the informal model for the quality requirements (platform-independent model of the individual data object) and the executable task created by programmers from this informal model (platform-specific model for individual data object). Later, Nikiforova et al. [107, 108] extended this research by expressing the data context as separate data objects that are connected to the primary data object (the data for which we need to evaluate quality). The quality requirements of the primary data object are defined based on the secondary related objects. While this model-driven data quality assessment is efficient, since requirements are expressed in a formal language by the end-users, it cannot be implemented in the big data context, since it only applies to simple tabular data at rest. Also, it requires IT and domain experts to be involved in converting formal language into executable tasks. 4.3.2 Expressing Context Quantitatively. Even et al. [46, 47] proposed a contextual quantitative data quality assessment for tabular datasets from the perspective of data utility (value). The authors proposed a measurement method to assign an intrinsic numeric value for each record/dataset based on the customer’s point of view. Then, they used this intrinsic value to measure the data quality dimensions such as data completeness, currency, validity, and accuracy. They also defined four principles to ensure the consistency of the measurement methods, which are (1) interpretation consistency, (2) representation consistency, (3) aggregation consistency, and (4) impartial contextual consistency. The proposed approach is beneficial for data quality assessment research, since it can convert the context business rules into quantitative methods and use their values by statistical analysis or machine learning algorithms. Moreover, it treats data based on its value from the user’s perspective. However, it can only be used in tabular data and does not fit the big data quality requirements. Moreover, this approach does not consider all context characteristics, such as available system resources and time. Skip 5DISCUSSION Section 5 DISCUSSION After going through the literature, it was noticeable that each solution dealt only with a partial view of the context. In this section, we compare these quality models and solutions to reach a comprehensive view covering the whole aspects of context awareness when assessing data quality. This analysis has led us to some essential recommendations we compiled into a methodological framework we propose and describe at the end of this article. 5.1 Quality Models In Table 3, we summarize the classification approaches, as specified for each data quality model in the literature, to understand its purpose and scope of use. The table’s term “No classification” means that the author did not adopt any data quality characteristic classification. Table 3. Quality Model Classification Approach Bicevskis et al. [18, 19], Bicevska et al. [16, 17], Nikiforova et al. [107, 108] Classified as Intrinsic, Contextual Strong et al. [124], Wang et al. [135] Classified as intrinsic, contextual, representational or accessibility Helfert et al. [62] Classified as quality of design or quality of conformance based onsemiotics level Show More Table 3. Classification Approaches Used in Data Quality Models After looking through all data quality characteristics listed in (Table 4), we can see that the ISO/IEC 25012 standard data quality characteristics do not fit the big data requirements (data uniqueness, amount of data) and thus need to be extended. Context-related features such as data fitness also need to be added to measure to what degree the data fits the context needs. It is also worth noting that many context-specific quality characteristics related to ingesting data from wireless sensors are missing, i.e., error rate and frequency [115]. This means that even when considering the adoption of ISO standards for big data quality assessment, there is a need to define additional context-specific quality characteristics. Table 4. Data Quality Characteristic Helfert el al. [62] Taleb et al. [127] Merino et al. [96] Arad-agna et al. [7] Cai et al. [24] Ramas-wamy et al. [115] Anne Immonen et al. [67] Batini et al. [25] Schelter et al. [119] Ehrlinger et al. [44] ISO/IEC 25012 [122] Accuracy X X X X X X X X X X X Completeness X X X X X X X X X Consistency X X X X X X X X Show More Table 4. Data Quality Characteristics Used in the Literature From this summary, we drew the following conclusions and decided that the representational and accessibility categories defined in References [24, 124, 135] should be considered in the context of use. Second, we found no need to separate the temporal characteristics from the contextual category [96], since temporal factors are context-dependent. At another level, it was clear that the ISO/IEC 25012 classification standard could meet the needed context awareness requirements, since inherent characteristics can be considered intrinsic data quality characteristics and system-dependent ones as context-related characteristics. In addition, we can use the semiotics classification to define and classify the measurement methods of the quality characteristics [62] that are not listed in the ISO/IEC 25012 standard, since the ones listed have their quality measures and measurement function defined in the ISO/IEC 25024 and ISO/IEC 25021 standards. In fact, all of the characteristics listed in Table 4, which are not found in the ISO/IEC 25012 standard, cannot be considered inherent and are system-dependent due to the following reasons: Representational quality characteristic depends on the current task, organizational policies, and user needs [135]. Uniqueness [7], Amount of Data, and Added Value are classified as contextual data quality characteristics [124, 135]. Validity, Frequency, Verfiablity, Popularity, Error rate characteristics are related to the wireless sensors [115] and social media contexts [67] and measured based on reference data or task-oriented business rules. Minimality, Pertinence are used within an integrated information systems [44] context and require a reference data to be measured. 5.2 Achieving Context Awareness in Big Data Quality Assessment Based on the literature, we can define data context as the information about the data itself (e.g., metadata, source reputation), organization policies, domain business rules, and the available system resources to handle the data. Achieving context awareness in big data is very important when performing data quality assessment; each measurement/operation should be carefully selected and executed, because each operation will cost a reasonable amount of time and resources. An essential part of the data quality measurement is context-related [124]. Moreover, extracting the context information in a big data context is much more challenging. It cannot be achieved using the traditional data quality assessment methods, as it requires more intelligent techniques that can handle a wide variety of data formats. In addition, handling a massive amount of data generated at a high velocity requires a well-designed and automated quality assessment solution that relies on a scalable infrastructure. Regarding the existing solutions, we can summarize their main weaknesses as follows: They cannot handle huge data volumes [16, 17, 18, 19, 21, 24, 107, 108]. They cannot handle unstructured data [16, 17, 18, 19, 24, 38, 43, 44, 45, 46, 47, 54, 96, 107, 108]. The end-user manually implements quality rules [7, 16, 17, 18, 19, 107, 108]. They only assess the data quality at rest [7, 24, 62, 96, 101, 102, 109, 131]. It is hard to implement within different contexts [67, 115, 128]. They lack essential data quality dimensions for the big data context [67, 101, 102, 115, 119, 131]. They require high user intervention during the quality assessment operation [24, 62, 109]. The following are the recommendations a data quality assessment solution must consider to achieve context awareness in a big data setting: Service-oriented architecture (SOA) and microservices. Service-oriented architecture (SOA) is an enterprise-wide software design approach that allows loosely coupled services to communicate independently from operating systems, platforms, and languages [5, 35]. For example, Dmitriyev et al. [38] proposed a data-centric service to be consumed by different stakeholders using tools such as Weka8 and Pentaho BI9; thus, following the SOA approach allowed a wider range of tools to be used seamlessly for accessing the enterprise data. While Dmitriyev et al.’s [38] solution may be efficient as an enterprise solution, it may not be able to scale up once needed, since all components are tightly coupled. In contrast, Ardagna et al.’s [7] proposal guarantees higher scalability as the data quality service is separated from the data sources and the enterprise management system. Moreover, splitting the data quality solution into two separate modules (data profiling and data quality assessment service) allows each module to scale up separately once needed and increases the reusability and portability of the service components. This software development paradigm is known as Microservices, which is a must for building scalable [58] and distributed applications [41]. Data sampling. Data sampling allows us to perform data profiling and quality assessment operations on a subset of the original dataset, which decreases resources and time consumption [7, 128]. Data sampling techniques can be based on probability; different statistical models are used to ensure no correlation between the points chosen for the sample. Alternatively, it could be extracted based on the analyst’s judgment [20]. Three solutions implemented data sampling techniques before the data quality assessment process: Taleb et al. [127, 128] used the Bag of Little Boostrap sampling algorithm to create a data sample that combines the results of bootstrapping multiple small subsets of a big dataset. In contrast, Ardagna et al. [7] implemented the Simple Random Sampling algorithm, where tuples are selected randomly, with an equal probability of being included in the sample. It is worth mentioning that choosing a big data sampling algorithm highly affects the data analysis and quality assessment process; the generated sample should be unbiased and representative of the original data, which is rarely guaranteed by Simple Random Sampling. In addition, the sampling algorithm must be easily parallelizable to be implemented in a parallel or distributed computing environment. Other optimized sampling methods for big data were proposed in the literature [29, 61, 86, 117]. Still, data sampling is a challenging topic in the domain of big data [103]. Using MapReduce-like paradigm. MapReduce is a parallel programming model presented by Google [36]. The MapReduce framework has attracted significant attention across a wide range of areas. It is considered a practical model for data-focused applications because of its basic programming interface, high elasticity, and resilience to defects. Additionally, it is well suited for preparing large data volumes in distributed computing environments. MapReduce has proven helpful in many different areas [42]. The accelerated growth in data size requires horizontal scaling, which is the ability to extend the data over additional servers [99]. The support of a MapReduce-like paradigm allows the solution to handle streams and massive volumes of data by distributing tasks over multiple nodes [127], which meets the data scalability requirement. Currently, several distributed processing technologies with good stability are used. We can name, for example, Apache Spark10 [54, 136] and Apache Storm11 [70, 123], among many others. Besides its stability, selecting the distributed processing technology depends on other factors, such as its ability to handle data at rest or data in motion. For example, the Hadoop MapReduce solution proposed by Taleb et al. [127] was used to assess the quality of data at rest, while the Apache Spark-based solution used by Gu et al. [54] and Ardagna et al. [7] was used to assess data quality for streaming data and data at rest. Cloud-based infrastructure. Big data is often collected by cloud-based applications [120]. A cloud-based infrastructure guarantees higher scalability of the solution. It enables adding storage and processing units when and as needed [115]. Due to its scalable nature, the cloud infrastructure is a good match for MapReduce processing paradigms; Ardagna et al. [7] created a data quality service that relies on Apache Spark cluster and deployed it on the Microsoft Azure cloud. Moreover, the Anything-as-a-Service (XaaS) model allowed providing a complete big data ecosystem as an on-demand service [126]. Still, managing and securing data on the cloud is an open challenge [80]. Metadata repository. As used in Reference [128], this repository is used to store all metadata extracted from schemaless datasets such as data structure [83, 142], recognized entities, context information [51, 125]. This metadata can be used in future operations to decrease redundancy while handling the same data sources. For example, in the case of handling data that is ingested continuously from wireless sensors, there is no need to extract the data structure for the data generated by the same sensors each time a quality assessment operation is needed; the structure will be retrieved directly from the metadata repository. Data quality repository. This repository is used to store the data quality score for each data source [43, 44, 45]; it is used to compute the data source reputation and prevent the execution of the quality evaluation process for data sources with a low reputation. A profile must be created for each data source where a history of data profiling and quality assessment results are stored. This will also allow performing incremental profiling and assessment operations [119] over continuously growing data sources (i.e., data ingested from sensors) rather than reading the whole data each time. This repository could be combined with the metadata repository proposed by Ardagna et al. [7], where data profiling and quality assessment results are stored to support any further data quality assessment task. Physical resources analysis. As we discussed the CCT model proposed in Reference [7], selecting predefined scenarios could be harmful, since the user selection may require an unavailable amount of system resources to perform the quality assessment operation. In contrast, a context-aware framework would scan the available system resources and estimate the needed time to assess the data quality for the input dataset. In addition, such a framework can also recommend an acceptable sampling ratio for optimal resource utilization and time-saving. We should note that although Helfert et al. [62] considered the information system environment as a part of the data context, they only considered the solution architecture and the data domain and ignored the available system resources. Data profiling. The data profiling service performs the exploratory data analysis to extract summaries that can be used in quality assessment operations, such as minimums, maximums, counts, averages, distinct values count, and null values percentages. The data profiling operations are essential to extract context information from the data, such as the data types, formats, and dates range. Metrics such as Null Values percentage are also essential to calculate quality dimensions such as Completeness. A critical concern about big data profiling is whether this operation should be executed before the data sampling task proposed by Ardagna et al. [7] or after data sampling as proposed by Taleb et al. [128]. After investigating the literature, we came up with a conclusion that two data profiling operations should be performed: A data profiling should retrieve the information needed to perform data sampling, such as the data size, lines/words count, and data format (media files, text files, tabular data). After the data sampling phase, data profiling should extract all information needed for the data quality assessment, since it is meaningless and resource-intensive to extract information from the initial data that is excluded from the quality assessment task. Several data profiling techniques were proposed in the domain of big data [2, 33, 91]. Still, data heterogeneity is an open challenge for data profiling techniques [1]. Automating data quality dimensions prioritization. As stated in Reference [62], using a systematic approach to prioritize data quality dimensions based on user needs and context is the key to building a context-aware solution. This is essential, since the data quality characteristics importance often changes based on the data context information and the user needs. The quality characteristics (dimensions) should be weighed automatically without user intervention. This step should be performed automatically after gathering all context information. This can be done using a knowledge database [98], machine learning techniques, or using a systematic approach [62]. ISO standards. Using ISO standards improves the compliance of our solution with universal standards and helps solve the plethora of data quality dimensions’ definitions found in the literature (Table 4). In fact, ISO standards are not just helpful regarding the data quality characteristics (dimensions) definitions [73]. Still, they also provide the metrics used to measure data quality as well as the measurement methods [75, 78] and functions [74]. While the ISO/IEC 25012 [72] standard does not support quality dimensions related to the big data domain, more guidance regarding the design, development, and management of big data applications are provided in ISO/IEC 20547 [76] standard. This standard is considered a big data reference architecture that illustrates the various big data components, processes, and systems in the context of an overall big data conceptual model. It also specifies the security and privacy aspects applicable to the big data reference architecture, including the big data roles, activities, and functional components. Also, it provides guidance on security and privacy operations for big data. Regarding data analytics and machine learning solution, ISO/IEC AWI 5259 [77], a new universal standard that describes the data quality measures, process, management requirements, and governance, is currently under development. Domain knowledge repositories. These repositories contain all business rules and organizational policies that are required in a specific domain [25]. Rules and policies must be defined by domain experts and organization managers [98]. For example, data reputation is critical while handling social media feeds, while it is less important in other domains. Using these repositories will prevent users/developers from hard-coding business rules each time. A domain knowledge database can be created as an ontology [22, 98, 137], a database [10], or a knowledge graph [63]. Knowledge extraction techniques. As described in References [125, 128], a set of techniques is used to extract metadata, hidden patterns, and context information from the data sources once needed, especially when handling unstructured data such as text or media files. As mentioned by Taleb et al. [128], the knowledge extraction techniques can be categorized into four categories based on the data source format (Table 5). Table 5. Data format Knowledge extraction technique Text Text mining, entity extraction Media files Features extraction: file metadata, extracting media characteristics Social media Sentiment analysis, opinion analysis, recommendation analysis Show More Table 5. Knowledge Extraction Techniques Based on the Data Format Context and quality rules abstraction. As defined in References [16, 17, 18, 19, 107, 108], using an object-oriented approach (data object class) to express data and context quality requirements will minimize the lines of code needed and allow the solution to be implemented easily within different contexts. Moreover, having a unified form to express data context and quality rules will help make the solution implementable in different contexts. Reference dataset election. Even though a reference dataset election may not be easily applicable, nor recommended when assessing the quality of critical data such as radiation pollution sensors feed [48, 49], it may still be recommended in certain cases. For example, References [101, 102, 131] stated that electing a reference dataset from the organization data lake could be helpful in case a reference dataset is required in the quality assessment process. A reference dataset and domain knowledge does not exist, and no other choices are available. This could be, for example, acceptable when analyzing a firm’s demographic and employment information as applied by Mylavarapu et al. [101]. Several string matching [64], schema matching [13, 110, 121], and MapReduce-based data fusion solutions [39] were proposed in the literature and can be used when electing a reference dataset from a data lake. Still, this domain is considered an open challenge [81]. Skip 6DATA QUALITY ASSESSMENT ARCHITECTURE – A PROPOSAL FOR A METHODOLOGICAL FRAMEWORK Section 6 DATA QUALITY ASSESSMENT ARCHITECTURE – A PROPOSAL FOR A METHODOLOGICAL FRAMEWORK In this section, we propose a high-level methodological framework for a context-aware big data quality assessment solution covering all these essential properties and supporting all the above-detailed recommendations (Figure 2). The proposed architecture follows a Microservice-oriented paradigm, where each component is composed of one or multiple independent modules. The data quality assessment is done in six phases: (1) initial configuration, (2) source analysis, (3) data profiling and sampling, (4) metadata extraction, (5) context information gathering, and (6) quality evaluation. Fig. 2. Fig. 2. Methodological framework architecture. 6.1 Initial Configuration Before starting the quality assessment process, several configurations must be done by the user: Sampling ratio: Users must define the data sampling ratio to apply within the data sampling method. Choosing the sampling ratio is critical, since it will impact the quality assessment confidence level (for example, if a sampling ratio is set to 70%, then the quality assessment score has a confidence level of 70%, since it was performed over 70% of the data). The sampling ratio will also determine the amount of data to be processed, affecting the resources and time needed to process the data. Maximum amount of allowed resources: Users can define the maximum amount of resources (processing nodes, memory utilization) to be used while processing the data. Specifying a maximum amount of resources will prevent the system from failing or getting out of memory. It will also be used to check if the available resources can meet the quality measurement requirements; if not, then the user will be asked to change the data sampling ratio. All these configurations are saved within a configuration file to prevent users from repeating the configuration and to automate the data quality assessment operation. Configurations can be assigned to a specific dataset or even set as default, regardless of the data source. 6.2 Source Analyzer The Source Analyzer is a service that aims to: (1) Recognize the data type (structured, semi-structured, unstructured). (2) Select the most feasible data sampling method among several predefined methods based on the data type, available resources, and sampling ratio. (3) Perform a primary data profiling operation over the dataset to retrieve the information needed to perform data sampling, such as the data size, lines/words count, and data format (media files, text files, tabular data). (4) Select the most feasible data profiling method among several predefined methods based on the data type, available resources, and data sample size. After performing all these operations, the results are sent to the Data Profiling and Sampling component. 6.3 Data Profiling and Sampling This component comprises two services: (1) The Data Sampling Service and (2) the Data Profiling Service. First, the Data Sampling Service receives the data sampling ratio and the selected data sampling method from the Source Analyzer service. Then, it performs the data sampling operation. Data Sampling is performed to decrease computational expenses and help investigate a subset instead of the whole set. After data sampling is complete, the Data Profiling Service receives the selected data profiling method from the Source Analyzer and the data sample generated from the Data Sampling Service. Then, data profiling is performed over the data sample. The data profiling service performs the exploratory data analysis to extract summaries that can be used in quality assessment operations, such as minimums, maximums, counts, averages, distinct values count, and null values percentages. 6.4 Metadata Extraction After the data profiling and sampling phase, if the data is schema-less (unstructured), then the Knowledge Extraction Service provides a set of techniques to extract metadata from the data sources. The needed techniques are selected based on the data format as defined in Table 5. This metadata is stored within a repository to avoid repeating knowledge extraction operations on the same dataset and to be used for further analysis. In addition to analyzing unstructured data, the Knowledge Extraction Service uses several techniques such as Named Entity Recognition (NER) [51, 125] to extract the included entities and the data domain. 6.5 Gathering Context Information After performing the data sampling, profiling, and metadata extraction, information is sent to the Context Analyzer Service to gather all information related to the data context. To define the data context, the Context Analyzer Service needs the following information: Metadata: All metadata gathered by the Source Analyzer service, Data Profiling Service, and the Knowledge Extraction Service such as the data type, format, data domain, and entities (i.e., persons, organizations, places). Organizational policies: A set of business rules defined by the organization regarding the data. As an example, an organization can reject data from a specific date range. Domain-specific rules: Based on the suggested domain by the Knowledge Extraction Service, the Context Analyzer will gather all related rules from a domain knowledge repository (described in Section 5.2). Available system resources: The available physical resources (machines, cores, memory, storage) in the information system besides the related configuration defined in the initial configuration. Quality characteristics: The ISO data quality standards are aligned with the domain knowledge database and gathered business rules to determine quality dimensions and metrics. After gathering all needed context information, the Context Analyzer Service generates a list of data quality characteristics and their measurement functions using a markup language such as XML or YAML and sends them to the Quality Evaluation component after assessing the available resources. Available resources analysis. The Context Analyzer Service should verify if the available physical resources are sufficient to handle the sampled data size in an acceptable time. If there are insufficient resources, then the users should be notified to change the data sampling ratio and the maximum amount of resources to be more relevant before assessing the data quality. If there are insufficient resources, then the data quality service will still use the results of the data sampling, profiling, and knowledge extraction operations, if possible, to prevent repeating redundant operations. For example, suppose the user can increase the maximum number of allowed resources without changing the sampling ratio. In that case, the data quality service can reuse the previously stored results besides the existing data sample to prevent repeating the data preparation operations (profiling, sampling...) and decrease the processing time. 6.6 Quality Evaluation After receiving the data context details, the data quality characteristics should be prioritized using a systematic approach [62] based on the context requirements; the quality characteristics prioritization information is stored within the domain knowledge database. The service should then check the possible data quality measurements that can be performed on the data; for example, uniqueness is not measurable while handling texts. If the data quality measures require reference data, then the quality evaluation service checks if it already exists for this data source. If not, then a reference data election is run using schema matching and machine learning techniques [13, 39, 110, 121] to select the most appropriate dataset from the organizational data lake as described in References [101, 102, 131]. After identifying the measurable quality characteristics, the data quality service should convert the measurement function sent by the Context Analyzer Service into an executable code by following the quality measurement methods described in ISO/IEC 15939 [75] and ISO/IEC 25000 [73] standards. The result is stored within a repository that can be used to calculate aggregates of the measured values in further analysis once needed. Finally, the data quality score is calculated based on the quality characteristics priority measured before, and a user-friendly quality report is generated. 6.7 Mapping the Methodological Framework to ISO/IEC 20547 Big Data Reference Architecture The ISO/IEC 20547 [76] series is intended to provide users with a standardized approach to developing and implementing big data architectures. This standard provides an architecture framework for describing the big data components, processes, and systems to establish a common language for the various stakeholders named big data reference architecture (BDRA). As illustrated in Figure 3, we show how the components of the proposed methodological framework can be seamlessly mapped to the big data reference architecture components provided by ISO/IEC 20547 standard: Fig. 3. Fig. 3. Methodological framework components mapped to the ISO/IEC 20547 big data reference architecture. The end-user is mapped to the big data consumer role. The components used to store the information are mapped to the big data platform layer. The components used to perform all operations needed to assess the data quality are mapped to the data preparation component in the big data application layer. The generated data quality report is mapped to the data visualization component in the big data application layer. Skip 7OPEN CHALLENGES Section 7 OPEN CHALLENGES This section will summarize the challenges we identified while reviewing the literature on building context-aware big data quality assessment solutions. Abstraction and standardization Implementing data quality operations within different contexts increases the need to have a unified definition of the data quality dimensions and the primitives that will be used in designing big data quality measuring applications. Several declarative solutions are found in the literature [85, 119], providing a good level of abstraction. Still, every solution relies on its own definition of the data quality characteristics and metrics, increasing the need to adopt universal standards such as ISO/IEC 25000 [73], ISO/IEC 15939 [75], and ISO/IEC 20547 [76]. Big data management In big data management, challenges relate to those an organization faces regarding data privacy, security, integration, ingestion, and governance [104]. Furthermore, they might be caused by the lack of qualified professionals knowledgeable about the latest tools and techniques for dealing with each data phase [116]. Big data sampling The data sampling output affects the accuracy of all other operations, i.e., the data profiling task can be costly for large datasets. Obtaining effective results using sampling depends on the data sampling criteria used [57]. Data sampling is essential for big data profiling to reduce the computational pressure and speed up the process of data profiling [91]. Several optimized sampling methods for big data were proposed in the literature [29, 61, 86, 117]. Still, data sampling is a challenging topic in the domain of big data [103], especially when analyzing unstructured data [91] or when training a machine learning model. For example, several real-world applications that use machine learning face numerous challenges due to imbalances in datasets that occur when the sample size and distribution are inaccurate [88]. Big data profiling Data profiling operations are essential for data quality control, because they are needed to verify and review different data types. This domain has become increasingly important in the field of big data. As within huge data silos, if a dataset metadata is not present, then this data becomes invisible [4]. Several data profiling techniques were proposed in the domain of big data [2, 33, 91]. Still, data heterogeneity is an open challenge for data profiling techniques [1]. Cloud-based infrastructure challenges Even if the cloud-based infrastructure scalability is feasible for big data solutions, there are still several challenges that face cloud-based solutions [59, 80]. Data security and privacy can be considered the main challenges due to the increased risk of data theft [84, 95]. Managing the tradeoff between scalability and cost is yet another critical challenge to address [12]. Physical resources analysis Estimating the performance and required resources of a data processing task executed using distributed technologies in a cloud environment is increasingly important because of its influence on development time and resource management. However, estimating the performance concerning parallel processes is complex for iterative, multi-stage applications [14]. Several statistical models were proposed to calculate the estimated time based on variables such as the dataset, available resources, and processes [15, 79, 132]. Still, these models are not validated over distributed tasks performed by large-scale applications. Reference data Contextual data quality measurement often requires a reference dataset while measuring several dimensions, such as accuracy and consistency. Several solutions were provided to elect a reference dataset from the organizational data lake if not present [101, 102, 131]. Still, there is no guarantee that the data lake contains an accurate reference set. Skip 8CONCLUSION AND FUTURE WORK Section 8 CONCLUSION AND FUTURE WORK Data quality is critical, since poor quality can lead to bad decisions. While assessing data quality has reached a high level of maturity in traditional data technologies, it is still very challenging in big data. In this article, we explained what makes big data quality assessment different. And knowing that data quality is context-dependent, we also investigated the quality models and techniques used to achieve context awareness in the big data era. The results showed that none of the existing data quality assessment solutions could achieve context awareness while handling big data, thus, we provided several recommendations for building a context-aware big data quality assessment solution. Moreover, we compiled those recommendations into a methodological framework that could address the limitations of existing solutions. We also identified several open challenges to be addressed when building such a solution. A list of tasks is lined up to be done in the future. We must delve into the components of the methodological framework to select the most suitable methods and technologies at each layer (data profiling, knowledge extraction, quality evaluation) and address the open challenges we previously identified. We should start validating the design by implementing and testing it on various big data sets in different scenarios and contexts. In addition, we are looking to improve our methodological framework by considering the machine learning techniques that may be applied at certain levels in the quality assessment process. Footnotes 1 https://scholar.google.com/. Footnote 2 https://ieeexplore.ieee.org. Footnote 3 https://dblp.org/. Footnote 4 https://www.mendeley.com/search/. Footnote 5 https://www.researchgate.net/. Footnote 6 The citation count is taken from Google Scholar. Footnote 7 https://spark.apache.org/. Footnote 8 https://sourceforge.net/projects/weka/. Footnote 9 https://www.hitachivantara.com/en-us/products/infrastructure-management-analytics/pentaho.html. Footnote 10 https://spark.apache.org/. Footnote 11 https://storm.apache.org/. Footnote REFERENCES [1] Abedjan Ziawasch, Golab Lukasz, and Naumann Felix. 2017. Data profiling: A tutorial. In Proceedings of the 2017 ACM International Conference on Management of Data (2017), 1747–1751. Reference 1Reference 2 [2] Abedjan Ziawasch, Golab Lukasz, Naumann Felix, and Papenbrock Thorsten. 2018. Data profiling. Synthes. Lect. Data Manag. 10, 4 (2018), 1–154. Reference 1Reference 2 [3] Acosta Maribel, Zaveri Amrapali, Simperl Elena, Kontokostas Dimitris, Auer Sören, and Lehmann Jens. 2013. Crowdsourcing linked data quality assessment. In The Semantic Web–ISWC 2013: 12th International Semantic Web Conference, Sydney, NSW, Australia, October 21–25, 2013, Proceedings, Part II 12. Springer, 260–276. Reference [4] Agrawal Divyakant, Bernstein Philip, Bertino Elisa, Davidson Susan, Dayal Umeshwas, Franklin Michael, Gehrke Johannes, Haas Laura, Halevy Alon, Han Jiawei et al. 2011. Challenges and Opportunities with Big Data [White Paper]. Technical Report. Computing Research Association. Retrieved from http://cra.org/ccc/docs/init/bigdatawhitepaper.pdf. Reference [5] Al-Jaroodi Jameela and Mohamed Nader. 2018. Service-oriented architecture for big data analytics in smart cities. In 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID’18). 633–640. Reference [6] AlShaer Mohammed, Taher Yehia, Haque Rafiqul, Hacid Mohand-Saïd, and Dbouk Mohamed. 2019. IBRIDIA: A hybrid solution for processing big logistics data. Fut. Gen. Comput. Syst. 97 (2019), 792–804. Reference [7] Ardagna Danilo, Cappiello Cinzia, Samá Walter, and Vitali Monica. 2018. Context-aware data quality assessment for big data. Fut. Gen. Comput. Syst. 89 (2018), 548–562. Navigate to [8] Azeroual Otmane and Abuosba Mohammad. 2019. Improving the data quality in the research information systems. arXiv preprint arXiv:1901.07388 (2019). Reference [9] Bārzdiņš Jānis, Zariņš Andris, Čerāns Kārlis, Kalniņš Audris, Rencis Edgars, Lāce Lelde, Liepiņš Renārs, and Sprog̀is Artūrs. 2007. GrTP: Transformation based graphical tool building platform. In 10th International Conference on Model-driven Engineering Languages and Systems, Models. Reference [10] Batini Carlo, Cabitza Federico, Cappiello Cinzia, and Francalanci Chiara. 2008. A comprehensive data quality methodology for web and structured data. Int. J. Innov. Comput. Applic. 1, 3 (2008), 205–218. Reference 1Reference 2 [11] Batini Carlo, Rula Anisa, Scannapieco Monica, and Viscusi Gianluigi. 2015. From data quality to big data quality. J. Datab. Manag. 26, 1 (2015), 60–82. Reference 1Reference 2 [12] Bello Sururah A., Oyedele Lukumon O., Akinade Olugbenga O., Bilal Muhammad, Delgado Juan Manuel Davila, Akanbi Lukman A., Ajayi Anuoluwapo O., and Owolabi Hakeem A.. 2021. Cloud computing in construction industry: Use cases, benefits and challenges. Automat. Construct. 122 (2021), 103441. Reference [13] Bernstein Philip A., Madhavan Jayant, and Rahm Erhard. 2011. Generic schema matching, ten years later. Proc. VLDB Endow. 4, 11 (2011), 695–701. Reference 1Reference 2 [14] Bhimani Janki, Mi Ningfang, Leeser Miriam, and Yang Zhengyu. 2017. FiM: Performance prediction for parallel computation in iterative data processing applications. In IEEE 10th International Conference on Cloud Computing (CLOUD’17). 359–366. Reference [15] Bhimani Janki, Mi Ningfang, Leeser Miriam, and Yang Zhengyu. 2019. New performance modeling methods for parallel data processing applications. ACM Trans. Model. Comput. Simul. 29, 3 (2019), 1–24. Reference [16] Bicevska Zane, Bicevskis Janis, and Oditis Ivo. 2017. Domain-specific characteristics of data quality. Federated Conference on Computer Science and Information Systems (FedCSIS’17). 999–1003. Navigate to [17] Bicevska Zane, Bicevskis Janis, and Oditis Ivo. 2018. Models of data quality. In Information Technology for Management. Ongoing Research and Development: 15th Conference, AITM 2017, and 12th Conference, ISM 2017, Held as Part of FedCSIS, Prague, Czech Republic, September 3–6, 2017, Extended Selected Papers 15. Springer, 194–211. Navigate to [18] Bicevskis Janis, Bicevska Zane, and Karnitis Girts. 2017. Executable data quality models. Procedia Comput. Sci. 104 (2017), 138–145. Navigate to [19] Bicevskis Janis, Bicevska Zane, Nikiforova Anastasija, and Oditis Ivo. 2018. An approach to data quality evaluation. In Fifth International Conference on Social Networks Analysis, Management and Security (SNAMS’18). 196–201. Navigate to [20] Biscobing Jacqueline. 2018. What Is Data Sampling? Retrieved from https://www.techtarget.com/searchbusinessanalytics/definition/data-sampling. Reference [21] Bronselaer Antoon, Nielandt Joachim, Boeckling Toon, and Tré Guy De. 2018. Operational measurement of data quality. In Information Processing and Management of Uncertainty in Knowledge-Based Systems. Applications: 17th International Conference, IPMU 2018, Cádiz, Spain, June 11–15, 2018, Proceedings, Part III 17. Springer, 517–528. Navigate to [22] Brüggemann Stefan and Grüning Fabian. 2009. Using ontologies providing domain knowledge for data quality management. Networked Knowledge-Networked Media: Integrating Knowledge Management, New Media Technologies and Semantic Systems. Springer, 187–203. Reference [23] Buneman Peter and Davidson Susan B.. 2010. Data provenance–The foundation of data quality. In Workshop: Issues and Opportunities for Improving the Quality and Use of Data within the DoD, Arlington, 26–28. Reference [24] Cai Li and Zhu Yangyong. 2015. The challenges of data quality and data quality assessment in the big data era. Data Sci. J. 14 (2015). Navigate to [25] Carlo Batini, Daniele Barone, Federico Cabitza, and Simone Grega. 2011. A data quality methodology for heterogeneous data. Int. J. Datab. Manag. Syst. 3, 1 (2011), 60–79. Navigate to [26] Choi O.-Hoon, Lim Jun-Eun, Na Hong-Seok, and Baik Doo-Kwon. 2008. An efficient method of data quality using quality evaluation ontology. 2008 Third International Conference on Convergence and Hybrid Information Technology 2 (2008), 1058–1061. Reference [27] Cichy Corinna and Rass Stefan. 2019. An overview of data quality frameworks. IEEE Access 7 (2019), 24634–24648. Reference [28] Clarke Roger. 2014. Quality Factors in Big Data and Big Data Analytics. Xamax Consultancy Pty Ltd. Reference 1Reference 2 [29] Cormode Graham and Duffield Nick. 2014. Sampling for big data: A tutorial. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 1975–1975. Reference 1Reference 2 [30] Corporation Microsoft. 2013. Data Quality Services. Retrieved from https://docs.microsoft.com/en-us/sql/data-quality-services/data-quality-services?view=sql-server-ver15. Reference [31] Corporation Microsoft. 2018. SQL Server Integration Services. Retrieved from https://docs.microsoft.com/en-us/sql/integration-services/sql-server-integration-services?view=sql-server-ver15. Reference [32] Corporation Oracle. 2013. Comprehensive Data Quality with Oracle Data Integrator and Oracle Enterprise Data Quality [White Paper]. Technical Report. Oracle Corporation. Retrieved from https://www.oracle.com/technetwork/middleware/data-integrator/overview/oracledi-comprehensive-quality-131748.pdf. Reference [33] Dai Wei, Wardlaw Isaac, Cui Yu, Mehdi Kashif, Li Yanyan, and Long Jun. 2016. Data profiling technology of data governance regarding big data: Review and rethinking. In Information Technology: New Generations: 13th International Conference on Information Technology. Springer, 439–450. Reference 1Reference 2 [34] Dai Wei, Yoshigoe Kenji, and Parsley William. 2018. Improving data quality through deep learning and statistical models. In Information Technology-New Generations: 14th International Conference on Information Technology. 515–522. Reference [35] Daki Houda, Hannani Asmaa El, Aqqal Abdelhak, Haidine Abdelfattah, and Dahbi Aziz. 2017. Big Data management in smart grid: Concepts, requirements and implementation. J. Big Data 4, 1 (2017), 1–19. Reference [36] Dean Jeffrey and Ghemawat Sanjay. 2008. MapReduce: simplified data processing on large clusters. Commun. ACM 51, 1, 107–113. Reference [37] Dhayne Houssein, Haque Rafiqul, Kilany Rima, and Taher Yehia. 2019. In search of big medical data integration solutions—A comprehensive survey. IEEE Access 7 (2019), 91265–91290. Reference [38] Dmitriyev Viktor, Mahmoud Tariq, and Marín-Ortega Pablo Michel. 2015. Int. J. Inf. Syst. Proj. Manag. 3, 3 (2015), 49–63. Navigate to [39] Dong Xin Luna, Berti-Equille Laure, and Srivastava Divesh. 2013. Data fusion: Resolving conflicts from multiple sources. Handbook of Data Quality: Research and Practice. Springer, 293–318. Reference 1Reference 2 [40] Dong Xin Luna and Srivastava Divesh. 2013. Big data integration. In IEEE 29th International Conference on Data Engineering (ICDE’13). IEEE, 1245–1248. Reference [41] Dragoni Nicola, Lanese Ivan, Larsen Stephan Thordal, Mazzara Manuel, Mustafin Ruslan, and Safina Larisa. 2018. Microservices: How to make your application scale. In Perspectives of System Informatics: 11th International Andrei P. Ershov Informatics Conference, PSI 2017, Moscow, Russia, June 27–29, 2017, Revised Selected Papers 11. Springer, 95–104. Reference [42] Durairaj M. and Poornappriya T. S.. 2018. Importance of MapReduce for big data applications: A survey. Asian J. Comput. Sci. Technol. 7, 1 (2018), 112–118. Reference [43] Ehrlinger Lisa, Werth Bernhard, and Wöß Wolfram. 2018. Automated continuous data quality measurement with QuaIIe. Int. J. Advanc. Softw. 11, 3 (2018), 400–417. Navigate to [44] Ehrlinger Lisa, Werth Bernhard, and Wöß Wolfram. 2018. QuaIIe: A data quality assessment tool for integrated information systems. In 10th International Conference on Advances in Databases, Knowledge, and Data Applications (DBKDA’18). 21–31. Navigate to [45] Ehrlinger Lisa and Wöß Wolfram. 2017. Automated data quality monitoring. In 22nd MIT International Conference on Information Quality (ICIQ’17). 15–1. Navigate to [46] Even Adir and Shankaranarayanan Ganesan. 2005. Value-driven data quality assessment. In International Conference on Information Quality (ICIQ’05). Navigate to [47] Even Adir and Shankaranarayanan Ganesan. 2007. Utility-driven assessment of data quality. ACM SIGMIS Datab.: DATAB. Adv. Inf. Syst. 38, 2 (2007), 75–93. Navigate to [48] Fadlallah Hadi, Taher Yehia, Haque Rafiqul, and Jaber Ali. 2019. ORADIEX: A big data driven smart framework for real-time surveillance and analysis of individual exposure to radioactive pollution. In International Conference on Big Data and Cybersecurity Intelligence (BDCSIntell’19). 52–56. Reference [49] Fadlallah Hadi, Taher Yehia, and Jaber Ali. 2018. RaDEn: A scalable and efficient radiation data engineering. In International Conference on Big Data and Cybersecurity Intelligence (BDCSIntell’18). 89–93. Reference [50] Salas Óscar Figuerola, Adzic Velibor, Shah Akash, and Kalva Hari. 2013. Assessing internet video quality using crowdsourcing. In 2nd ACM International Workshop on Crowdsourcing for Multimedia. 23–28. Reference [51] Finkel Jenny Rose, Grenager Trond, and Manning Christopher D.. 2005. Incorporating non-local information into information extraction systems by Gibbs sampling. In 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05). 363–370. Reference 1Reference 2 [52] Gao Jerry, Xie Chunli, and Tao Chuanqi. 2016. Big data validation and quality assuranceIssues, challenges, and needs. In IEEE symposium on service-oriented system engineering (SOSE16). 433–441. Reference [53] Ge Mouzhi and Helfert Markus. 2007. A review of information quality research-develop a research agenda. In International Conference on Information Quality (ICIQ’07). 76–91. Reference 1Reference 2 [54] Gu Rong, Qi Yang, Wu Tongyu, Wang Zhaokang, Xu Xiaolong, Yuan Chunfeng, and Huang Yihua. 2021. SparkDQ: Efficient generic big data quality management on distributed data-parallel computation. J. ParallelDistrib. Comput. 156 (2021), 132–147. Navigate to [55] Gudivada Venkat, Apon Amy, and Ding Junhua. 2017. Data quality considerations for big data and machine learning: Going beyond data cleaning and transformations. Int. J. Advanc. Softw. 10, 1 (2017), 1–20. Reference [56] Gudivada Venkat N., Rao Dhana, and Grosky William I.. 2016. Data quality centric application framework for big data. In International Conference on Big Data, Small Data, Linked Data and Open Data (ALLDATA’16). Reference [57] Hariri Reihaneh H., Fredericks Erik M., and Bowers Kate M.. 2019. Uncertainty in big data analytics: Survey, opportunities, and challenges. J. Big Data 6, 1 (2019), 1–16. Reference [58] Hasselbring Wilhelm. 2016. Microservices for scalability: Keynote talk abstract. In Proceedings of the 7th ACM/SPEC on International Conference on Performance Engineering. 133–134. Reference [59] Hay Brian, Nance Kara, and Bishop Matt. 2011. Storm clouds rising: Security challenges for IaaS cloud computing. In 2011 44th Hawaii International Conference on System Sciences. 1–7. Reference [60] He Qinlu, Li Zhanhuai, and Zhang Xiao. 2010. Data deduplication techniques. In 2010 International Conference on Future Information Technology and Management Engineering 1 (2010), 430–433. Reference [61] He Qing, Wang Haocheng, Zhuang Fuzhen, Shang Tianfeng, and Shi Zhongzhi. 2015. Parallel sampling from big data with uncertainty distribution. Fuzzy Sets Syst. 258 (2015), 117–133. Reference 1Reference 2 [62] Helfert Markus and Foley Owen. 2009. A context aware information quality framework. In 2009 Fourth International Conference on Cooperation and Promotion of Information Resources in Science and Technology. 187–193. Navigate to [63] Hogan Aidan, Blomqvist Eva, Cochez Michael, d’Amato Claudia, Melo Gerard de, Gutierrez Claudio, Kirrane Sabrina, Gayo José Emilio Labra, Navigli Roberto, Neumaier Sebastian, et al. 2021. Knowledge graphs. ACM Comput. Surv. 54, 4 (2021), 1–37. Reference [64] Hosseini Kasra, Nanni Federico, and Ardanuy Mariona Coll. 2020. DeezyMatch: A flexible deep learning approach to fuzzy string matching. In Conference on Empirical Methods in Natural Language Processing: System Demonstrations. 62–69. Reference [65] Hoßfeld Tobias, Hirth Matthias, Korshunov Pavel, Hanhart Philippe, Gardlo Bruno, Keimel Christian, and Timmerer Christian. 2014. Survey of web-based crowdsourcing frameworks for subjective quality assessment. In IEEE 16th International Workshop on Multimedia Signal Processing (MMSP’14). 1–6. Reference [66] Ilyas Ihab F. and Chu Xu. 2019. Data Cleaning. ACM New York, NY. Reference 1Reference 2 [67] Immonen Anne, Pääkkönen Pekka, and Ovaska Eila. 2015. Evaluating the quality of social media data in big data architecture. IEEE Access 3 (2015), 2028–2043. Navigate to [68] Inc. Talend2022. Data Quality and Machine Learning: What’s the Connection? Retrieved from https://www.talend.com/resources/machine-learning-data-quality/. Reference [69] Informatica. 2018. Informatica Data Quality Data Sheet. Technical Report. Informatica. Retrieved from https://www.informatica.com/content/dam/informatica-com/en/collateral/data-sheet/en_informatica-data-quality_data-sheet_6710.pdf. Reference [70] Iqbal Muhammad Hussain, Soomro Tariq Rahim et al. 2015. Big data analysis: Apache Storm perspective. Int. J. Comput. Trends Technol. 19, 1 (2015), 9–14. Reference [71] ISO/IEC. 2001. ISO/IEC 9126-1:2001. Software Engineering – Product Quality – Part 1: Quality Model. Standard. ISO/IEC. Retrieved from https://www.iso.org/standard/22749.html. Reference [72] ISO/IEC. 2008. 25012:2008 Software Engineering – Software Product Quality Requirements and Evaluation (SQuaRE) – Data Quality Model. Standard. ISO/IEC. Retrieved from https://www.iso.org/standard/35736.html. Reference 1Reference 2Reference 3 [73] ISO/IEC. 2014. ISO/IEC 25000:2014. Systems and Software Engineering – System and Software Quality Requirements and Evaluation (SQuaRE) – Guide to SQuaRE. Standard. ISO/IEC. Retrieved from https://www.iso.org/standard/64764.html. Navigate to [74] ISO/IEC. 2015. ISO/IEC 25024:2015 Systems and Software Engineering – Systems and Software Quality Requirements and Evaluation (SQuaRE) – Measurement of Data Quality. Standard. ISO/IEC. Retrieved from https://www.iso.org/standard/35749.html. Reference 1Reference 2 [75] ISO/IEC. 2017. ISO/IEC 15939:2017 Systems and Software Engineering – Measurement Process. Standard. ISO/IEC. Retrieved from https://www.iso.org/standard/71197.html. Reference 1Reference 2Reference 3 [76] ISO/IEC. 2020. ISO/IEC 20547-3:2020 Big Data Reference Architecture - Part 3: Reference Architecture. Standard. ISO/IEC. Retrieved from https://www.iso.org/standard/71277.html. Reference 1Reference 2Reference 3 [77] ISO/IEC. 2022. ISO/IEC AWI 5259-1 Artificial Intelligence – Data Quality for Analytics and Machine Learning (ML) – Part 1: Overview, Terminology, and Examples. Standard. ISO/IEC. Retrieved from https://www.iso.org/standard/81088.html. Reference [78] ISO/TS. 2011. ISO/TS 8000-1:2011 - Data Quality - Part 1: Overview. Standard. ISO/TS. Retrieved from https://www.iso.org/standard/50798.html. Reference [79] Iverson Michael A., Ozguner Fusun, and Potter Lee C.. 1999. Statistical prediction of task execution times through analytic benchmarking for scheduling in a heterogeneous environment. In Proceedings Eighth Heterogeneous Computing Workshop (HCW’99). 99–111. Reference [80] Ji Changqing, Li Yu, Qiu Wenming, Awada Uchechukwu, and Li Keqiu. 2012. Big data processing in cloud computing environments. In 2012 12th International Symposium on Pervasive Systems, Algorithms and Networks (2012), 17–23. Reference 1Reference 2 [81] Kadadi Anirudh, Agrawal Rajeev, Nyamful Christopher, and Atiq Rahman. 2014. Challenges of data integration and interoperability in big data. In 2014 IEEE International Conference on Big Data (big data) (2014), 38–40. Reference [82] Kaiser Jiří. 2014. Dealing with missing values in data. J. Syst. Integr. 5, 1 (2014) 42–51. Reference [83] Karami Amir, Gangopadhyay Aryya, Zhou Bin, and Kharrazi Hadi. 2015. A fuzzy approach model for uncovering hidden latent semantic structure in medical text collections. In iConference 2015. Reference [84] Karmakar Anurag, Raghuthaman Anaswara, Kote Om Sudhakar, and Jayapandian N.. 2022. Cloud computing application: Research challenges and opportunity. In International Conference on Sustainable Computing and Data Communication Systems (ICSCDS’22). IEEE, 1284–1289. Reference [85] Khayyat Zuhair, Ilyas Ihab F., Jindal Alekh, Madden S., Ouzzani M., Papotti Paolo, Quiané-Ruiz Jorge-Arnulfo, Tang Nan, and Yin Si. 2015. BigDansing: A system for big data cleansing. In SIGMOD Conference. Reference 1Reference 2 [86] Kim Jae Kwang and Wang Zhonglei. 2019. Sampling techniques for big data analysis. Int. Statist. Rev. 87 (2019), S177–S191. Reference 1Reference 2 [87] Kontokostas Dimitris, Zaveri Amrapali, Auer Sören, and Lehmann Jens. 2013. TripleCheckMate: A tool for crowdsourcing the quality assessment of linked data. In Knowledge Engineering and the Semantic Web: 4th International Conference, KESW 2013, St. Petersburg, Russia, October 7–9, 2013. Proceedings 4. Springer, 265–272. Reference [88] Kumar Pradeep, Bhatnagar Roheet, Gaur Kuntal, and Bhatnagar Anurag. 2021. Classification of imbalanced data: Review of methods and applications. IOP Conference Series: Materials Science and Engineering 1099, 1 (2021), 012077. Reference [89] Kusumasari Tien Fabrianti et al. 2016. Data profiling for data quality improvement with OpenRefine. In International Conference on Information Technology Systems and Innovation (ICITSI’16). 1–6. Reference [90] Leung Hareton K. N.. 2001. Quality metrics for intranet applications. Inf. Manag. 38, 3 (2001), 137–152. Reference [91] Liu Zhicheng and Zhang Aoqian. 2020. Sampling for big data profiling: A survey. IEEE Access 8 (2020), 72713–72726. Navigate to [92] L’Heureux Alexandra, Grolinger Katarina, Elyamany Hany F., and Capretz Miriam A. M.. 2017. Machine learning with big data: Challenges and approaches. IEEE Access 5 (2017), 7776–7797. Reference [93] Malhotra Jyoti and Bakal Jagdish. 2015. A survey and comparative study of data deduplication techniques. In International Conference on Pervasive Computing (ICPC’15). 1–5. Reference [94] McKelvey Nigel, Curran Kevin, and Toland Luke. 2016. The Challenges of Data Cleansing with Data Warehouses. 77–82. DOI: Reference [95] Mehrtak Mohammad, SeyedAlinaghi SeyedAhmad, MohsseniPour Mehrzad, Noori Tayebeh, Karimi Amirali, Shamsabadi Ahmadreza, Heydari Mohammad, Barzegary Alireza, Mirzapour Pegah, Soleymanzadeh Mahdi, et al. 2021. Security challenges and solutions using healthcare cloud computing. J. Med. Life 14, 4 (2021), 448. Reference [96] Merino Jorge, Caballero Ismael, Rivas Bibiano, Serrano Manuel, and Piattini Mario. 2016. A data quality in use model for big data. Fut. Gen. Comput. Syst. 63 (2016), 123–130. Navigate to [97] Mihindukulasooriya Nandana, García-Castro Raúl, Priyatna Freddy, Ruckhaus Edna, and Saturno Nelson. 2017. A linked data profiling service for quality assessment. In The Semantic Web: ESWC 2017 Satellite Events: ESWC 2017 Satellite Events, Portorož, Slovenia, May 28–June 1, 2017, Revised Selected Papers 14. Springer, 335–340. Reference [98] Missier Paolo, Embury Suzanne, Greenwood Mark, Preece Alun, and Jin Binling. 2006. Quality views: Capturing and exploiting the user perspective on data quality. In International Conference on Very Large Data Bases. Reference 1Reference 2Reference 3 [99] Mousannif Hajar, Sabah Hasna, Douiji Yasmina, and Sayad Younes Oulad. 2014. From big data to big projects: A step-by-step roadmap. In 2014 International Conference on Future Internet of Things and Cloud. 373–378. Reference [100] Munn Zachary, Peters Micah D. J., Stern Cindy, Tufanaru Catalin, McArthur Alexa, and Aromataris Edoardo. 2018. Systematic review or scoping review? Guidance for authors when choosing between a systematic or scoping review approach. BMC Med. Res. Methodol. 18 (2018), 1–7. Reference [101] Mylavarapu Goutam, Thomas Johnson P., and Viswanathan K. Ashwin. 2019. An automated big data accuracy assessment tool. In IEEE 4th International Conference on Big Data Analytics (ICBDA’19). 193–197. Navigate to [102] Mylavarapu Goutam, Viswanathan K. Ashwin, and Thomas Johnson P.. 2019. Assessing context-aware data consistency. In IEEE/ACS 16th International Conference on Computer Systems and Applications (AICCSA’19). 1–6. Navigate to [103] Najafabadi Maryam M., Villanustre Flavio, Khoshgoftaar Taghi M., Seliya Naeem, Wald Randall, and Muharemagic Edin. 2015. Deep learning applications and challenges in big data analytics. J. Big Data 2, 1 (2015), 1–21. Reference 1Reference 2 [104] Nargesian Fatemeh, Zhu Erkang, Miller Renée J., Pu Ken Q., and Arocena Patricia C.. 2019. Data lake management: Challenges and opportunities. Proc. VLDB Endow. 12, 12 (2019), 1986–1989. Reference 1Reference 2 [105] Naumann Felix. 2014. Data profiling revisited. ACM SIGMOD Rec. 42, 4 (2014), 40–49. Reference [106] Niemelä Eila, Evesti Antti, and Savolainen Pekka. 2008. Modeling quality attribute variability. In International Conference on Evaluation of Novel Approaches to Software Engineering (ENASE’08). 169–176. Reference [107] Nikiforova Anastasija and Bicevskis Janis. 2019. An extended data object-driven approach to data quality evaluation: Contextual data quality analysis. In International Conference on Enterprise Information Systems (ICEIS’19). 274–281. Navigate to [108] Nikiforova Anastasija, Bicevskis Janis, Bicevska Zane, and Oditis Ivo. 2020. User-oriented approach to data quality evaluation. J. Univers. Comput. Sci. 26, 1 (2020), 107–126. Navigate to [109] Pääkkönen Pekka and Pakkala Daniel. 2015. Reference architecture and classification of technologies, products and services for big data systems. Big Data Res. 2, 4 (2015), 166–186. Navigate to [110] Patel-Schneider Peter F.. 2015. Towards large-scale schema and ontology matching. Retrieved from https://www.semanticscholar.org/paper/Towards-Large-scale-Schema-And-Ontology-Matching-Patel-Schneider/ceee2bdaef83a0f09480fa6fb191cf3372137152. Reference 1Reference 2 [111] Pérez Beatriz, Rubio Julio, and Sáenz-Adán Carlos. 2018. A systematic review of provenance systems. Knowl. Inf. Syst. 57 (2018), 495–543. Reference [112] Pipino Leo L., Lee Yang W., and Wang Richard Y.. 2002. Data quality assessment. Commun. ACM 45, 4 (2002), 211–218. Reference [113] Price Rosanne, Neiger Dina, and Shanks Graeme. 2008. Developing a measurement instrument for subjective aspects of information quality. Commun. Assoc. Inf. Syst. 22, 1 (2008), 3. Reference [114] Rahul Kumar and Banyal R. K.. 2019. Data cleaning mechanism for big data and cloud computing. In 6th International Conference on Computing for Sustainable Global Development (INDIACom’19). 195–198. Reference [115] Ramaswamy Lakshmish, Lawson Victor, and Gogineni Siva Venkat. 2013. Towards a quality-centric big data architecture for federated sensor services. In 2013 IEEE International Congress on Big Data. 86–93. Navigate to [116] Rawat R. and Yadav R.. 2021. Big data: Big data analysis, issues and challenges and technologies. IOP Conference Series: Materials Science and Engineering 1022, 1 (2021), 012014. Reference [117] Sadineni Praveen Kumar. 2020. Sampling based join-aggregate query processing technique for big data. Indian J. Comput. Sci. Eng. 11, 5, 532–546. Reference 1Reference 2 [118] Saha Barna and Srivastava Divesh. 2014. Data quality: The other face of big data. In 2014 IEEE 30th International Conference on Data Engineering. 1294–1297. Reference 1Reference 2 [119] Schelter Sebastian, Lange Dustin, Schmidt Philipp, Celikel Meltem, Biessmann Felix, and Grafberger Andreas. 2018. Automating large-scale data quality verification. Proc. VLDB Endow. 11, 12 (2018), 1781–1794. Navigate to [120] Sharma Gaurav. 2021. Data Quality. Retrieved from https://www.computer.org/publications/tech-news/trends/big-data-and-cloud-computing. Reference [121] Siegmund Norbert, Rosenmüller Marko, Kuhlemann Martin, Kästner Christian, Apel Sven, Duchateau Fabien, and Fagnan Justin. 2015. Schema matching bibtex. In Proceedings of the VLDB Endowment. Reference 1Reference 2 [122] Software Calidad. 2022. ISO/IEC 25012. Retrieved from https://iso25000.com/index.php/en/iso-25000-standards/iso-25012. Reference 1Reference 2Reference 3 [123] Stojanović Dragan, Stojanović Natalija, and Turanjanin Jovan. 2015. Processing big trajectory and Twitter data streams using Apache STORM. (2015), 301–304. Retrieved from https://www.semanticscholar.org/paper/Schema-Matching-Bibtex-Siegmund-Rosenm%C3%BCller/a4d94ddaab429e5874386dd29822e470b57d6ee4. Reference [124] Strong Diane M., Lee Yang W., and Wang Richard Y.. 1997. Data quality in context. Commun. ACM 40, 5 (1997), 103–110. Navigate to [125] Taher Yehia, Haque Rafiqul, AlShaer Mohammed, Heuvel Willem Jan van den, Hacid Mohand-Saïd, and Dbouk Mohamed. 2016. A context-aware analytics for processing tweets and analysing sentiment in realtime (short paper). In On the Move to Meaningful Internet Systems: OTM 2016 Conferences: Confederated International Conferences: CoopIS, C&TC, and ODBASE 2016, Rhodes, Greece, October 24–28, 2016, Proceedings. Springer, 910–917. Reference 1Reference 2Reference 3 [126] Taher Yehia, Haque Rafiqul, and Hacid Mohand-Said. 2017. BDLaaS: Big data lab as a service for experimenting big data solution. In IEEE 2nd International Workshops on Foundations and Applications of Self* Systems (FAS* W’17). 155–159. Reference [127] Taleb Ikbal, Dssouli Rachida, and Serhani Mohamed Adel. 2015. Big data pre-processing: A quality framework. (2015), 191–198. Navigate to [128] Taleb Ikbal, Serhani Mohamed Adel, and Dssouli Rachida. 2018. Big data quality assessment model for unstructured data. In International Conference on Innovations in Information Technology (IIT’18). 69–74. Navigate to [129] Taleb Ikbal, Serhani Mohamed Adel, and Dssouli Rachida. 2019. Big data quality: A data quality profiling model. In Services–SERVICES 2019: 15th World Congress, Held as Part of the Services Conference Federation, SCF 2019, San Diego, CA, USA, June 25–30, 2019, Proceedings 15. Springer, 61–77. Reference [130] Talend. 2020. How to Manage Modern Data Quality [White Paper]. Technical Report. Talend. Retrieved from https://www.talend.com/resources/definitive-guide-data-quality-how-to-manage. Reference [131] Talha Mohamed, Elmarzouqi Nabil, and Kalam Anas Abou El. 2020. Towards a powerful solution for data accuracy assessment in the big data context. Int. J. Advanc. Comput. Sci. Applic. 11, 2 (2020). Navigate to [132] Venkataraman Shivaram, Yang Zongheng, Franklin Michael, Recht Benjamin, and Stoica Ion. 2016. Ernest: Efficient performance prediction for large-scale advanced analytics. In 13th USENIX Symposium on Networked Systems Design and Implementation (NSDI’16). 363–378. Reference [133] Wang Lidong and Alexander Cheryl Ann. 2016. Machine learning in big data. Int. J. Math., Eng. Manag. Sci. 1, 2 (2016), 52–61. Reference [134] Wang Richard Y.. 1998. A product perspective on total data quality management. Commun. ACM 41, 2 (1998), 58–65. Reference 1Reference 2 [135] Wang Richard Y. and Strong Diane. 1996. Beyond accuracy: What data quality means to data consumers. J. Manag. Inf. Syst. 12 (1996), 5–33. Navigate to [136] Wang Xinxin, Dang Depeng, and Guo Zixian. 2020. Evaluating the crowd quality for subjective questions based on a Spark computing environment. Fut. Gen. Comput. Syst. 106 (2020), 426–437. Reference [137] Wei-Liang Chen, Shi-Dong Zhang, and Xiang Gao. 2009. Anchoring the consistency dimension of data quality using ontology in data integration. (2009), 201–205. Reference 1Reference 2 [138] Woodall Philip, Oberhofer Martin, and Borek Alexander. 2014. A classification of data quality assessment and improvement methods. Int. J. Inf. Qual. 3, 4 (2014), 298–321. Reference 1Reference 2 [139] Zaslavsky Arkady, Perera Charith, and Georgakopoulos Dimitrios. 2013. Sensing as a service and big data. arXiv preprint arXiv:1301.0159 (2013). Reference [140] Zaveri Amrapali, Kontokostas Dimitris, Sherif Mohamed A., Bühmann Lorenz, Morsey Mohamed, Auer Sören, and Lehmann Jens. 2013. User-driven quality evaluation of DBpedia. In 9th International Conference on Semantic Systems. 97–104. Reference [141] Zhang Pengcheng, Zhou Xuewu, Li Wenrui, and Gao Jerry. 2017. A survey on quality assurance techniques for big data applications. (2017), 313–319. Reference [142] Zhang Zhenrong, Zhang Jianshu, Du Jun, and Wang Fengren. 2022. Split, embed and merge: An accurate table structure recognizer. Pattern Recognit. 126 (2022), 108565. Reference [143] Zhou Lina, Pan Shimei, Wang Jianwu, and Vasilakos Athanasios V.. 2017. Machine learning on big data: Opportunities and challenges. Neurocomputing 237 (2017), 350–361. Reference 1Reference 2 Index Terms Context-aware Big Data Quality Assessment: A Scoping Review Information systems Data management systems Recommendations BIGQA: Declarative Big Data Quality Assessment In the big data domain, data quality assessment operations are often complex and must be implementable in a distributed and timely manner. This article tries to generalize the quality assessment operations by providing a new ISO-based declarative data ... Read More A Data Quality in Use model for Big Data Beyond the hype of Big Data, something within business intelligence projects is indeed changing. This is mainly because Big Data is not only about data, but also about a complete conceptual and technological stack including raw and processed data, ... Read More Context-aware data quality assessment for big data Abstract Big data changed the way in which we collect and analyze data. In particular, the amount of available information is constantly growing and organizations rely more and more on data analysis in order to achieve their competitive ... Highlights Data Quality assessment is a key success point for applications using big data. Read More Comments Login options Check if you have access through your login credentials or your institution to get full access on this article. Sign in Full Access Get this Article Information Contributors Published in Journal of Data and Information Quality   Volume 15, Issue 3 September 2023326 pages ISSN: 1936-1955 EISSN: 1936-1963 DOI: 10.1145/3611329 Editor: Tiziana Catarci Issue’s Table of Contents Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Publisher Association for Computing Machinery New York, NY, United States Publication History Published: 22 August 2023 Online AM: 13 June 2023 Accepted: 8 May 2023 Revised: 23 March 2023 Received: 16 April 2022 Published in JDIQ Volume 15, Issue 3 Permissions Request permissions about this article. Request Permissions Check for updates Author Tags Data qualitybig datacontext awarenessdata quality assessment Qualifiers Survey Bibliometrics Citations0 Article Metrics 0 Total Citations View Citations 567 Total Downloads Downloads (Last 12 months) 567 Downloads (Last 6 weeks) 130 Other Metrics View Author Metrics PDF Format View or Download as a PDF file. PDF eReader View online with eReader. eReader [1] Abedjan Ziawasch, Golab Lukasz, and Naumann Felix. 2017. Data profiling: A tutorial. In Proceedings of the 2017 ACM International Conference on Management of Data (2017), 1747–1751. Reference 1Reference 2 [2] Abedjan Ziawasch, Golab Lukasz, Naumann Felix, and Papenbrock Thorsten. 2018. Data profiling. Synthes. Lect. Data Manag. 10, 4 (2018), 1–154. Reference 1Reference 2 [3] Acosta Maribel, Zaveri Amrapali, Simperl Elena, Kontokostas Dimitris, Auer Sören, and Lehmann Jens. 2013. Crowdsourcing linked data quality assessment. In The Semantic Web–ISWC 2013: 12th International Semantic Web Conference, Sydney, NSW, Australia, October 21–25, 2013, Proceedings, Part II 12. Springer, 260–276. Reference [4] Agrawal Divyakant, Bernstein Philip, Bertino Elisa, Davidson Susan, Dayal Umeshwas, Franklin Michael, Gehrke Johannes, Haas Laura, Halevy Alon, Han Jiawei et al. 2011. Challenges and Opportunities with Big Data [White Paper]. Technical Report. Computing Research Association. Retrieved from http://cra.org/ccc/docs/init/bigdatawhitepaper.pdf. Reference [5] Al-Jaroodi Jameela and Mohamed Nader. 2018. Service-oriented architecture for big data analytics in smart cities. In 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID’18). 633–640. Reference [6] AlShaer Mohammed, Taher Yehia, Haque Rafiqul, Hacid Mohand-Saïd, and Dbouk Mohamed. 2019. IBRIDIA: A hybrid solution for processing big logistics data. Fut. Gen. Comput. Syst. 97 (2019), 792–804. Reference [7] Ardagna Danilo, Cappiello Cinzia, Samá Walter, and Vitali Monica. 2018. Context-aware data quality assessment for big data. Fut. Gen. Comput. Syst. 89 (2018), 548–562. Navigate to [8] Azeroual Otmane and Abuosba Mohammad. 2019. Improving the data quality in the research information systems. arXiv preprint arXiv:1901.07388 (2019). Reference [9] Bārzdiņš Jānis, Zariņš Andris, Čerāns Kārlis, Kalniņš Audris, Rencis Edgars, Lāce Lelde, Liepiņš Renārs, and Sprog̀is Artūrs. 2007. GrTP: Transformation based graphical tool building platform. In 10th International Conference on Model-driven Engineering Languages and Systems, Models. Reference [10] Batini Carlo, Cabitza Federico, Cappiello Cinzia, and Francalanci Chiara. 2008. A comprehensive data quality methodology for web and structured data. Int. J. Innov. Comput. Applic. 1, 3 (2008), 205–218. Reference 1Reference 2 [11] Batini Carlo, Rula Anisa, Scannapieco Monica, and Viscusi Gianluigi. 2015. From data quality to big data quality. J. Datab. Manag. 26, 1 (2015), 60–82. Reference 1Reference 2 [12] Bello Sururah A., Oyedele Lukumon O., Akinade Olugbenga O., Bilal Muhammad, Delgado Juan Manuel Davila, Akanbi Lukman A., Ajayi Anuoluwapo O., and Owolabi Hakeem A.. 2021. Cloud computing in construction industry: Use cases, benefits and challenges. Automat. Construct. 122 (2021), 103441. Reference [13] Bernstein Philip A., Madhavan Jayant, and Rahm Erhard. 2011. Generic schema matching, ten years later. Proc. VLDB Endow. 4, 11 (2011), 695–701. Reference 1Reference 2 [14] Bhimani Janki, Mi Ningfang, Leeser Miriam, and Yang Zhengyu. 2017. FiM: Performance prediction for parallel computation in iterative data processing applications. In IEEE 10th International Conference on Cloud Computing (CLOUD’17). 359–366. Reference [15] Bhimani Janki, Mi Ningfang, Leeser Miriam, and Yang Zhengyu. 2019. New performance modeling methods for parallel data processing applications. ACM Trans. Model. Comput. Simul. 29, 3 (2019), 1–24. Reference [16] Bicevska Zane, Bicevskis Janis, and Oditis Ivo. 2017. Domain-specific characteristics of data quality. Federated Conference on Computer Science and Information Systems (FedCSIS’17). 999–1003. Navigate to [17] Bicevska Zane, Bicevskis Janis, and Oditis Ivo. 2018. Models of data quality. In Information Technology for Management. Ongoing Research and Development: 15th Conference, AITM 2017, and 12th Conference, ISM 2017, Held as Part of FedCSIS, Prague, Czech Republic, September 3–6, 2017, Extended Selected Papers 15. Springer, 194–211. Navigate to [18] Bicevskis Janis, Bicevska Zane, and Karnitis Girts. 2017. Executable data quality models. Procedia Comput. Sci. 104 (2017), 138–145. Navigate to [19] Bicevskis Janis, Bicevska Zane, Nikiforova Anastasija, and Oditis Ivo. 2018. An approach to data quality evaluation. In Fifth International Conference on Social Networks Analysis, Management and Security (SNAMS’18). 196–201. Navigate to [20] Biscobing Jacqueline. 2018. What Is Data Sampling? Retrieved from https://www.techtarget.com/searchbusinessanalytics/definition/data-sampling. Reference [21] Bronselaer Antoon, Nielandt Joachim, Boeckling Toon, and Tré Guy De. 2018. Operational measurement of data quality. In Information Processing and Management of Uncertainty in Knowledge-Based Systems. Applications: 17th International Conference, IPMU 2018, Cádiz, Spain, June 11–15, 2018, Proceedings, Part III 17. Springer, 517–528. Navigate to [22] Brüggemann Stefan and Grüning Fabian. 2009. Using ontologies providing domain knowledge for data quality management. Networked Knowledge-Networked Media: Integrating Knowledge Management, New Media Technologies and Semantic Systems. Springer, 187–203. Reference [23] Buneman Peter and Davidson Susan B.. 2010. Data provenance–The foundation of data quality. In Workshop: Issues and Opportunities for Improving the Quality and Use of Data within the DoD, Arlington, 26–28. Reference [24] Cai Li and Zhu Yangyong. 2015. The challenges of data quality and data quality assessment in the big data era. Data Sci. J. 14 (2015). Navigate to [25] Carlo Batini, Daniele Barone, Federico Cabitza, and Simone Grega. 2011. A data quality methodology for heterogeneous data. Int. J. Datab. Manag. Syst. 3, 1 (2011), 60–79. Navigate to [26] Choi O.-Hoon, Lim Jun-Eun, Na Hong-Seok, and Baik Doo-Kwon. 2008. An efficient method of data quality using quality evaluation ontology. 2008 Third International Conference on Convergence and Hybrid Information Technology 2 (2008), 1058–1061. Reference [27] Cichy Corinna and Rass Stefan. 2019. An overview of data quality frameworks. IEEE Access 7 (2019), 24634–24648. Reference [28] Clarke Roger. 2014. Quality Factors in Big Data and Big Data Analytics. Xamax Consultancy Pty Ltd. Reference 1Reference 2 [29] Cormode Graham and Duffield Nick. 2014. Sampling for big data: A tutorial. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 1975–1975. Reference 1Reference 2 [30] Corporation Microsoft. 2013. Data Quality Services. Retrieved from https://docs.microsoft.com/en-us/sql/data-quality-services/data-quality-services?view=sql-server-ver15. Reference [31] Corporation Microsoft. 2018. SQL Server Integration Services. Retrieved from https://docs.microsoft.com/en-us/sql/integration-services/sql-server-integration-services?view=sql-server-ver15. Reference [32] Corporation Oracle. 2013. Comprehensive Data Quality with Oracle Data Integrator and Oracle Enterprise Data Quality [White Paper]. Technical Report. Oracle Corporation. Retrieved from https://www.oracle.com/technetwork/middleware/data-integrator/overview/oracledi-comprehensive-quality-131748.pdf. Reference [33] Dai Wei, Wardlaw Isaac, Cui Yu, Mehdi Kashif, Li Yanyan, and Long Jun. 2016. Data profiling technology of data governance regarding big data: Review and rethinking. In Information Technology: New Generations: 13th International Conference on Information Technology. Springer, 439–450. Reference 1Reference 2 [34] Dai Wei, Yoshigoe Kenji, and Parsley William. 2018. Improving data quality through deep learning and statistical models. In Information Technology-New Generations: 14th International Conference on Information Technology. 515–522. Reference [35] Daki Houda, Hannani Asmaa El, Aqqal Abdelhak, Haidine Abdelfattah, and Dahbi Aziz. 2017. Big Data management in smart grid: Concepts, requirements and implementation. J. Big Data 4, 1 (2017), 1–19. Reference [36] Dean Jeffrey and Ghemawat Sanjay. 2008. MapReduce: simplified data processing on large clusters. Commun. ACM 51, 1, 107–113. Reference [37] Dhayne Houssein, Haque Rafiqul, Kilany Rima, and Taher Yehia. 2019. In search of big medical data integration solutions—A comprehensive survey. IEEE Access 7 (2019), 91265–91290. Reference [38] Dmitriyev Viktor, Mahmoud Tariq, and Marín-Ortega Pablo Michel. 2015. Int. J. Inf. Syst. Proj. Manag. 3, 3 (2015), 49–63. Navigate to [39] Dong Xin Luna, Berti-Equille Laure, and Srivastava Divesh. 2013. Data fusion: Resolving conflicts from multiple sources. Handbook of Data Quality: Research and Practice. Springer, 293–318. Reference 1Reference 2 [40] Dong Xin Luna and Srivastava Divesh. 2013. Big data integration. In IEEE 29th International Conference on Data Engineering (ICDE’13). IEEE, 1245–1248. Reference [41] Dragoni Nicola, Lanese Ivan, Larsen Stephan Thordal, Mazzara Manuel, Mustafin Ruslan, and Safina Larisa. 2018. Microservices: How to make your application scale. In Perspectives of System Informatics: 11th International Andrei P. Ershov Informatics Conference, PSI 2017, Moscow, Russia, June 27–29, 2017, Revised Selected Papers 11. Springer, 95–104. Reference [42] Durairaj M. and Poornappriya T. S.. 2018. Importance of MapReduce for big data applications: A survey. Asian J. Comput. Sci. Technol. 7, 1 (2018), 112–118. Reference [43] Ehrlinger Lisa, Werth Bernhard, and Wöß Wolfram. 2018. Automated continuous data quality measurement with QuaIIe. Int. J. Advanc. Softw. 11, 3 (2018), 400–417. Navigate to [44] Ehrlinger Lisa, Werth Bernhard, and Wöß Wolfram. 2018. QuaIIe: A data quality assessment tool for integrated information systems. In 10th International Conference on Advances in Databases, Knowledge, and Data Applications (DBKDA’18). 21–31. Navigate to [45] Ehrlinger Lisa and Wöß Wolfram. 2017. Automated data quality monitoring. In 22nd MIT International Conference on Information Quality (ICIQ’17). 15–1. Navigate to [46] Even Adir and Shankaranarayanan Ganesan. 2005. Value-driven data quality assessment. In International Conference on Information Quality (ICIQ’05). Navigate to [47] Even Adir and Shankaranarayanan Ganesan. 2007. Utility-driven assessment of data quality. ACM SIGMIS Datab.: DATAB. Adv. Inf. Syst. 38, 2 (2007), 75–93. Navigate to [48] Fadlallah Hadi, Taher Yehia, Haque Rafiqul, and Jaber Ali. 2019. ORADIEX: A big data driven smart framework for real-time surveillance and analysis of individual exposure to radioactive pollution. In International Conference on Big Data and Cybersecurity Intelligence (BDCSIntell’19). 52–56. Reference [49] Fadlallah Hadi, Taher Yehia, and Jaber Ali. 2018. RaDEn: A scalable and efficient radiation data engineering. In International Conference on Big Data and Cybersecurity Intelligence (BDCSIntell’18). 89–93. Reference [50] Salas Óscar Figuerola, Adzic Velibor, Shah Akash, and Kalva Hari. 2013. Assessing internet video quality using crowdsourcing. In 2nd ACM International Workshop on Crowdsourcing for Multimedia. 23–28. Reference [51] Finkel Jenny Rose, Grenager Trond, and Manning Christopher D.. 2005. Incorporating non-local information into information extraction systems by Gibbs sampling. In 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05). 363–370. Reference 1Reference 2 [52] Gao Jerry, Xie Chunli, and Tao Chuanqi. 2016. Big data validation and quality assuranceIssues, challenges, and needs. In IEEE symposium on service-oriented system engineering (SOSE16). 433–441. Reference [53] Ge Mouzhi and Helfert Markus. 2007. A review of information quality research-develop a research agenda. In International Conference on Information Quality (ICIQ’07). 76–91. Reference 1Reference 2 [54] Gu Rong, Qi Yang, Wu Tongyu, Wang Zhaokang, Xu Xiaolong, Yuan Chunfeng, and Huang Yihua. 2021. SparkDQ: Efficient generic big data quality management on distributed data-parallel computation. J. ParallelDistrib. Comput. 156 (2021), 132–147. Navigate to [55] Gudivada Venkat, Apon Amy, and Ding Junhua. 2017. Data quality considerations for big data and machine learning: Going beyond data cleaning and transformations. Int. J. Advanc. Softw. 10, 1 (2017), 1–20. Reference [56] Gudivada Venkat N., Rao Dhana, and Grosky William I.. 2016. Data quality centric application framework for big data. In International Conference on Big Data, Small Data, Linked Data and Open Data (ALLDATA’16). Reference [57] Hariri Reihaneh H., Fredericks Erik M., and Bowers Kate M.. 2019. Uncertainty in big data analytics: Survey, opportunities, and challenges. J. Big Data 6, 1 (2019), 1–16. Reference [58] Hasselbring Wilhelm. 2016. Microservices for scalability: Keynote talk abstract. In Proceedings of the 7th ACM/SPEC on International Conference on Performance Engineering. 133–134. Reference [59] Hay Brian, Nance Kara, and Bishop Matt. 2011. Storm clouds rising: Security challenges for IaaS cloud computing. In 2011 44th Hawaii International Conference on System Sciences. 1–7. Reference [60] He Qinlu, Li Zhanhuai, and Zhang Xiao. 2010. Data deduplication techniques. In 2010 International Conference on Future Information Technology and Management Engineering 1 (2010), 430–433. Reference [61] He Qing, Wang Haocheng, Zhuang Fuzhen, Shang Tianfeng, and Shi Zhongzhi. 2015. Parallel sampling from big data with uncertainty distribution. Fuzzy Sets Syst. 258 (2015), 117–133. Reference 1Reference 2 [62] Helfert Markus and Foley Owen. 2009. A context aware information quality framework. In 2009 Fourth International Conference on Cooperation and Promotion of Information Resources in Science and Technology. 187–193. Navigate to [63] Hogan Aidan, Blomqvist Eva, Cochez Michael, d’Amato Claudia, Melo Gerard de, Gutierrez Claudio, Kirrane Sabrina, Gayo José Emilio Labra, Navigli Roberto, Neumaier Sebastian, et al. 2021. Knowledge graphs. ACM Comput. Surv. 54, 4 (2021), 1–37. Reference [64] Hosseini Kasra, Nanni Federico, and Ardanuy Mariona Coll. 2020. DeezyMatch: A flexible deep learning approach to fuzzy string matching. In Conference on Empirical Methods in Natural Language Processing: System Demonstrations. 62–69. Reference [65] Hoßfeld Tobias, Hirth Matthias, Korshunov Pavel, Hanhart Philippe, Gardlo Bruno, Keimel Christian, and Timmerer Christian. 2014. Survey of web-based crowdsourcing frameworks for subjective quality assessment. In IEEE 16th International Workshop on Multimedia Signal Processing (MMSP’14). 1–6. Reference [66] Ilyas Ihab F. and Chu Xu. 2019. Data Cleaning. ACM New York, NY. Reference 1Reference 2 [67] Immonen Anne, Pääkkönen Pekka, and Ovaska Eila. 2015. Evaluating the quality of social media data in big data architecture. IEEE Access 3 (2015), 2028–2043. Navigate to [68] Inc. Talend2022. Data Quality and Machine Learning: What’s the Connection? Retrieved from https://www.talend.com/resources/machine-learning-data-quality/. Reference [69] Informatica. 2018. Informatica Data Quality Data Sheet. Technical Report. Informatica. Retrieved from https://www.informatica.com/content/dam/informatica-com/en/collateral/data-sheet/en_informatica-data-quality_data-sheet_6710.pdf. Reference [70] Iqbal Muhammad Hussain, Soomro Tariq Rahim et al. 2015. Big data analysis: Apache Storm perspective. Int. J. Comput. Trends Technol. 19, 1 (2015), 9–14. Reference [71] ISO/IEC. 2001. ISO/IEC 9126-1:2001. Software Engineering – Product Quality – Part 1: Quality Model. Standard. ISO/IEC. Retrieved from https://www.iso.org/standard/22749.html. Reference [72] ISO/IEC. 2008. 25012:2008 Software Engineering – Software Product Quality Requirements and Evaluation (SQuaRE) – Data Quality Model. Standard. ISO/IEC. Retrieved from https://www.iso.org/standard/35736.html. Reference 1Reference 2Reference 3 [73] ISO/IEC. 2014. ISO/IEC 25000:2014. Systems and Software Engineering – System and Software Quality Requirements and Evaluation (SQuaRE) – Guide to SQuaRE. Standard. ISO/IEC. Retrieved from https://www.iso.org/standard/64764.html. Navigate to [74] ISO/IEC. 2015. ISO/IEC 25024:2015 Systems and Software Engineering – Systems and Software Quality Requirements and Evaluation (SQuaRE) – Measurement of Data Quality. Standard. ISO/IEC. Retrieved from https://www.iso.org/standard/35749.html. Reference 1Reference 2 [75] ISO/IEC. 2017. ISO/IEC 15939:2017 Systems and Software Engineering – Measurement Process. Standard. ISO/IEC. Retrieved from https://www.iso.org/standard/71197.html. Reference 1Reference 2Reference 3 [76] ISO/IEC. 2020. ISO/IEC 20547-3:2020 Big Data Reference Architecture - Part 3: Reference Architecture. Standard. ISO/IEC. Retrieved from https://www.iso.org/standard/71277.html. Reference 1Reference 2Reference 3 [77] ISO/IEC. 2022. ISO/IEC AWI 5259-1 Artificial Intelligence – Data Quality for Analytics and Machine Learning (ML) – Part 1: Overview, Terminology, and Examples. Standard. ISO/IEC. Retrieved from https://www.iso.org/standard/81088.html. Reference [78] ISO/TS. 2011. ISO/TS 8000-1:2011 - Data Quality - Part 1: Overview. Standard. ISO/TS. Retrieved from https://www.iso.org/standard/50798.html. Reference [79] Iverson Michael A., Ozguner Fusun, and Potter Lee C.. 1999. Statistical prediction of task execution times through analytic benchmarking for scheduling in a heterogeneous environment. In Proceedings Eighth Heterogeneous Computing Workshop (HCW’99). 99–111. Reference [80] Ji Changqing, Li Yu, Qiu Wenming, Awada Uchechukwu, and Li Keqiu. 2012. Big data processing in cloud computing environments. In 2012 12th International Symposium on Pervasive Systems, Algorithms and Networks (2012), 17–23. Reference 1Reference 2 [81] Kadadi Anirudh, Agrawal Rajeev, Nyamful Christopher, and Atiq Rahman. 2014. Challenges of data integration and interoperability in big data. In 2014 IEEE International Conference on Big Data (big data) (2014), 38–40. Reference [82] Kaiser Jiří. 2014. Dealing with missing values in data. J. Syst. Integr. 5, 1 (2014) 42–51. Reference [83] Karami Amir, Gangopadhyay Aryya, Zhou Bin, and Kharrazi Hadi. 2015. A fuzzy approach model for uncovering hidden latent semantic structure in medical text collections. In iConference 2015. Reference [84] Karmakar Anurag, Raghuthaman Anaswara, Kote Om Sudhakar, and Jayapandian N.. 2022. Cloud computing application: Research challenges and opportunity. In International Conference on Sustainable Computing and Data Communication Systems (ICSCDS’22). IEEE, 1284–1289. Reference [85] Khayyat Zuhair, Ilyas Ihab F., Jindal Alekh, Madden S., Ouzzani M., Papotti Paolo, Quiané-Ruiz Jorge-Arnulfo, Tang Nan, and Yin Si. 2015. BigDansing: A system for big data cleansing. In SIGMOD Conference. Reference 1Reference 2 [86] Kim Jae Kwang and Wang Zhonglei. 2019. Sampling techniques for big data analysis. Int. Statist. Rev. 87 (2019), S177–S191. Reference 1Reference 2 [87] Kontokostas Dimitris, Zaveri Amrapali, Auer Sören, and Lehmann Jens. 2013. TripleCheckMate: A tool for crowdsourcing the quality assessment of linked data. In Knowledge Engineering and the Semantic Web: 4th International Conference, KESW 2013, St. Petersburg, Russia, October 7–9, 2013. Proceedings 4. Springer, 265–272. Reference [88] Kumar Pradeep, Bhatnagar Roheet, Gaur Kuntal, and Bhatnagar Anurag. 2021. Classification of imbalanced data: Review of methods and applications. IOP Conference Series: Materials Science and Engineering 1099, 1 (2021), 012077. Reference [89] Kusumasari Tien Fabrianti et al. 2016. Data profiling for data quality improvement with OpenRefine. In International Conference on Information Technology Systems and Innovation (ICITSI’16). 1–6. Reference [90] Leung Hareton K. N.. 2001. Quality metrics for intranet applications. Inf. Manag. 38, 3 (2001), 137–152. Reference [91] Liu Zhicheng and Zhang Aoqian. 2020. Sampling for big data profiling: A survey. IEEE Access 8 (2020), 72713–72726. Navigate to [92] L’Heureux Alexandra, Grolinger Katarina, Elyamany Hany F., and Capretz Miriam A. M.. 2017. Machine learning with big data: Challenges and approaches. IEEE Access 5 (2017), 7776–7797. Reference [93] Malhotra Jyoti and Bakal Jagdish. 2015. A survey and comparative study of data deduplication techniques. In International Conference on Pervasive Computing (ICPC’15). 1–5. Reference [94] McKelvey Nigel, Curran Kevin, and Toland Luke. 2016. The Challenges of Data Cleansing with Data Warehouses. 77–82. DOI: Reference [95] Mehrtak Mohammad, SeyedAlinaghi SeyedAhmad, MohsseniPour Mehrzad, Noori Tayebeh, Karimi Amirali, Shamsabadi Ahmadreza, Heydari Mohammad, Barzegary Alireza, Mirzapour Pegah, Soleymanzadeh Mahdi, et al. 2021. Security challenges and solutions using healthcare cloud computing. J. Med. Life 14, 4 (2021), 448. Reference [96] Merino Jorge, Caballero Ismael, Rivas Bibiano, Serrano Manuel, and Piattini Mario. 2016. A data quality in use model for big data. Fut. Gen. Comput. Syst. 63 (2016), 123–130. Navigate to [97] Mihindukulasooriya Nandana, García-Castro Raúl, Priyatna Freddy, Ruckhaus Edna, and Saturno Nelson. 2017. A linked data profiling service for quality assessment. In The Semantic Web: ESWC 2017 Satellite Events: ESWC 2017 Satellite Events, Portorož, Slovenia, May 28–June 1, 2017, Revised Selected Papers 14. Springer, 335–340. Reference [98] Missier Paolo, Embury Suzanne, Greenwood Mark, Preece Alun, and Jin Binling. 2006. Quality views: Capturing and exploiting the user perspective on data quality. In International Conference on Very Large Data Bases. Reference 1Reference 2Reference 3 [99] Mousannif Hajar, Sabah Hasna, Douiji Yasmina, and Sayad Younes Oulad. 2014. From big data to big projects: A step-by-step roadmap. In 2014 International Conference on Future Internet of Things and Cloud. 373–378. Reference [100] Munn Zachary, Peters Micah D. J., Stern Cindy, Tufanaru Catalin, McArthur Alexa, and Aromataris Edoardo. 2018. Systematic review or scoping review? Guidance for authors when choosing between a systematic or scoping review approach. BMC Med. Res. Methodol. 18 (2018), 1–7. Reference [101] Mylavarapu Goutam, Thomas Johnson P., and Viswanathan K. Ashwin. 2019. An automated big data accuracy assessment tool. In IEEE 4th International Conference on Big Data Analytics (ICBDA’19). 193–197. Navigate to [102] Mylavarapu Goutam, Viswanathan K. Ashwin, and Thomas Johnson P.. 2019. Assessing context-aware data consistency. In IEEE/ACS 16th International Conference on Computer Systems and Applications (AICCSA’19). 1–6. Navigate to [103] Najafabadi Maryam M., Villanustre Flavio, Khoshgoftaar Taghi M., Seliya Naeem, Wald Randall, and Muharemagic Edin. 2015. Deep learning applications and challenges in big data analytics. J. Big Data 2, 1 (2015), 1–21. Reference 1Reference 2 [104] Nargesian Fatemeh, Zhu Erkang, Miller Renée J., Pu Ken Q., and Arocena Patricia C.. 2019. Data lake management: Challenges and opportunities. Proc. VLDB Endow. 12, 12 (2019), 1986–1989. Reference 1Reference 2 [105] Naumann Felix. 2014. Data profiling revisited. ACM SIGMOD Rec. 42, 4 (2014), 40–49. Reference [106] Niemelä Eila, Evesti Antti, and Savolainen Pekka. 2008. Modeling quality attribute variability. In International Conference on Evaluation of Novel Approaches to Software Engineering (ENASE’08). 169–176. Reference [107] Nikiforova Anastasija and Bicevskis Janis. 2019. An extended data object-driven approach to data quality evaluation: Contextual data quality analysis. In International Conference on Enterprise Information Systems (ICEIS’19). 274–281. Navigate to [108] Nikiforova Anastasija, Bicevskis Janis, Bicevska Zane, and Oditis Ivo. 2020. User-oriented approach to data quality evaluation. J. Univers. Comput. Sci. 26, 1 (2020), 107–126. Navigate to [109] Pääkkönen Pekka and Pakkala Daniel. 2015. Reference architecture and classification of technologies, products and services for big data systems. Big Data Res. 2, 4 (2015), 166–186. Navigate to [110] Patel-Schneider Peter F.. 2015. Towards large-scale schema and ontology matching. Retrieved from https://www.semanticscholar.org/paper/Towards-Large-scale-Schema-And-Ontology-Matching-Patel-Schneider/ceee2bdaef83a0f09480fa6fb191cf3372137152. Reference 1Reference 2 [111] Pérez Beatriz, Rubio Julio, and Sáenz-Adán Carlos. 2018. A systematic review of provenance systems. Knowl. Inf. Syst. 57 (2018), 495–543. Reference [112] Pipino Leo L., Lee Yang W., and Wang Richard Y.. 2002. Data quality assessment. Commun. ACM 45, 4 (2002), 211–218. Reference [113] Price Rosanne, Neiger Dina, and Shanks Graeme. 2008. Developing a measurement instrument for subjective aspects of information quality. Commun. Assoc. Inf. Syst. 22, 1 (2008), 3. Reference [114] Rahul Kumar and Banyal R. K.. 2019. Data cleaning mechanism for big data and cloud computing. In 6th International Conference on Computing for Sustainable Global Development (INDIACom’19). 195–198. Reference [115] Ramaswamy Lakshmish, Lawson Victor, and Gogineni Siva Venkat. 2013. Towards a quality-centric big data architecture for federated sensor services. In 2013 IEEE International Congress on Big Data. 86–93. Navigate to [116] Rawat R. and Yadav R.. 2021. Big data: Big data analysis, issues and challenges and technologies. IOP Conference Series: Materials Science and Engineering 1022, 1 (2021), 012014. Reference [117] Sadineni Praveen Kumar. 2020. Sampling based join-aggregate query processing technique for big data. Indian J. Comput. Sci. Eng. 11, 5, 532–546. Reference 1Reference 2 [118] Saha Barna and Srivastava Divesh. 2014. Data quality: The other face of big data. In 2014 IEEE 30th International Conference on Data Engineering. 1294–1297. Reference 1Reference 2 [119] Schelter Sebastian, Lange Dustin, Schmidt Philipp, Celikel Meltem, Biessmann Felix, and Grafberger Andreas. 2018. Automating large-scale data quality verification. Proc. VLDB Endow. 11, 12 (2018), 1781–1794. Navigate to [120] Sharma Gaurav. 2021. Data Quality. Retrieved from https://www.computer.org/publications/tech-news/trends/big-data-and-cloud-computing. Reference [121] Siegmund Norbert, Rosenmüller Marko, Kuhlemann Martin, Kästner Christian, Apel Sven, Duchateau Fabien, and Fagnan Justin. 2015. Schema matching bibtex. In Proceedings of the VLDB Endowment. Reference 1Reference 2 [122] Software Calidad. 2022. ISO/IEC 25012. Retrieved from https://iso25000.com/index.php/en/iso-25000-standards/iso-25012. Reference 1Reference 2Reference 3 [123] Stojanović Dragan, Stojanović Natalija, and Turanjanin Jovan. 2015. Processing big trajectory and Twitter data streams using Apache STORM. (2015), 301–304. Retrieved from https://www.semanticscholar.org/paper/Schema-Matching-Bibtex-Siegmund-Rosenm%C3%BCller/a4d94ddaab429e5874386dd29822e470b57d6ee4. Reference [124] Strong Diane M., Lee Yang W., and Wang Richard Y.. 1997. Data quality in context. Commun. ACM 40, 5 (1997), 103–110. Navigate to [125] Taher Yehia, Haque Rafiqul, AlShaer Mohammed, Heuvel Willem Jan van den, Hacid Mohand-Saïd, and Dbouk Mohamed. 2016. A context-aware analytics for processing tweets and analysing sentiment in realtime (short paper). In On the Move to Meaningful Internet Systems: OTM 2016 Conferences: Confederated International Conferences: CoopIS, C&TC, and ODBASE 2016, Rhodes, Greece, October 24–28, 2016, Proceedings. Springer, 910–917. Reference 1Reference 2Reference 3 [126] Taher Yehia, Haque Rafiqul, and Hacid Mohand-Said. 2017. BDLaaS: Big data lab as a service for experimenting big data solution. In IEEE 2nd International Workshops on Foundations and Applications of Self* Systems (FAS* W’17). 155–159. Reference [127] Taleb Ikbal, Dssouli Rachida, and Serhani Mohamed Adel. 2015. Big data pre-processing: A quality framework. (2015), 191–198. Navigate to [128] Taleb Ikbal, Serhani Mohamed Adel, and Dssouli Rachida. 2018. Big data quality assessment model for unstructured data. In International Conference on Innovations in Information Technology (IIT’18). 69–74. Navigate to [129] Taleb Ikbal, Serhani Mohamed Adel, and Dssouli Rachida. 2019. Big data quality: A data quality profiling model. In Services–SERVICES 2019: 15th World Congress, Held as Part of the Services Conference Federation, SCF 2019, San Diego, CA, USA, June 25–30, 2019, Proceedings 15. Springer, 61–77. Reference [130] Talend. 2020. How to Manage Modern Data Quality [White Paper]. Technical Report. Talend. Retrieved from https://www.talend.com/resources/definitive-guide-data-quality-how-to-manage. Reference [131] Talha Mohamed, Elmarzouqi Nabil, and Kalam Anas Abou El. 2020. Towards a powerful solution for data accuracy assessment in the big data context. Int. J. Advanc. Comput. Sci. Applic. 11, 2 (2020). Navigate to [132] Venkataraman Shivaram, Yang Zongheng, Franklin Michael, Recht Benjamin, and Stoica Ion. 2016. Ernest: Efficient performance prediction for large-scale advanced analytics. In 13th USENIX Symposium on Networked Systems Design and Implementation (NSDI’16). 363–378. Reference [133] Wang Lidong and Alexander Cheryl Ann. 2016. Machine learning in big data. Int. J. Math., Eng. Manag. Sci. 1, 2 (2016), 52–61. Reference [134] Wang Richard Y.. 1998. A product perspective on total data quality management. Commun. ACM 41, 2 (1998), 58–65. Reference 1Reference 2 [135] Wang Richard Y. and Strong Diane. 1996. Beyond accuracy: What data quality means to data consumers. J. Manag. Inf. Syst. 12 (1996), 5–33. Navigate to [136] Wang Xinxin, Dang Depeng, and Guo Zixian. 2020. Evaluating the crowd quality for subjective questions based on a Spark computing environment. Fut. Gen. Comput. Syst. 106 (2020), 426–437. Reference [137] Wei-Liang Chen, Shi-Dong Zhang, and Xiang Gao. 2009. Anchoring the consistency dimension of data quality using ontology in data integration. (2009), 201–205. Reference 1Reference 2 [138] Woodall Philip, Oberhofer Martin, and Borek Alexander. 2014. A classification of data quality assessment and improvement methods. Int. J. Inf. Qual. 3, 4 (2014), 298–321. Reference 1Reference 2 [139] Zaslavsky Arkady, Perera Charith, and Georgakopoulos Dimitrios. 2013. Sensing as a service and big data. arXiv preprint arXiv:1301.0159 (2013). Reference [140] Zaveri Amrapali, Kontokostas Dimitris, Sherif Mohamed A., Bühmann Lorenz, Morsey Mohamed, Auer Sören, and Lehmann Jens. 2013. User-driven quality evaluation of DBpedia. In 9th International Conference on Semantic Systems. 97–104. Reference [141] Zhang Pengcheng, Zhou Xuewu, Li Wenrui, and Gao Jerry. 2017. A survey on quality assurance techniques for big data applications. (2017), 313–319. Reference [142] Zhang Zhenrong, Zhang Jianshu, Du Jun, and Wang Fengren. 2022. Split, embed and merge: An accurate table structure recognizer. Pattern Recognit. 126 (2022), 108565. Reference [143] Zhou Lina, Pan Shimei, Wang Jianwu, and Vasilakos Athanasios V.. 2017. Machine learning on big data: Opportunities and challenges. Neurocomputing 237 (2017), 350–361. Reference 1Reference 2 Figures Fig. 1. Articles distribution over the years. Open in Figure Viewer Fig. 2. Methodological framework architecture. Open in Figure Viewer Fig. 3. Methodological framework components mapped to the ISO/IEC 20547 big data reference architecture. Open in Figure Viewer Table 1. Classification of the Publications Discussed in This Review Open in Table Viewer Table 2. Literature Summarization Open in Table Viewer Table 3. Classification Approaches Used in Data Quality Models Open in Table Viewer Table 4. Data Quality Characteristics Used in the Literature Open in Table Viewer Table 5. Knowledge Extraction Techniques Based on the Data Format Open in Table Viewer Share this Publication link https://dl.acm.org/doi/10.1145/3603707 Copy Link Share on Social Media Share on Twitter LinkedIn Reddit Facebook Email 143 References View Issue’s Table of Contents Footer Categories Journals Magazines Books Proceedings SIGs Conferences Collections People About About ACM Digital Library ACM Digital Library Board Subscription Information Author Guidelines Using ACM Digital Library All Holdings within the ACM Digital Library ACM Computing Classification System Digital Library Accessibility Join Join ACM Join SIGs Subscribe to Publications Institutions and Libraries Connect Contact Facebook Twitter Linkedin Feedback Bug Report The ACM Digital Library is published by the Association for Computing Machinery. Copyright © 2024 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics

Paper 8:
- APA Citation: Kumar, M., Garg, D. P., & Zachery, R. A. (2007). A method for judicious fusion of inconsistent multiple sensor data. IEEE Sensors Journal, 7(5), 723–733. https://doi.org/10.1109/JSEN.2007.894905
  Main Objective: To develop and evaluate a modified Bayesian approach to sensor fusion that can automatically identify and eliminate inconsistent sensor data.
  Study Location: Duke University
  Data Sources: None
  Technologies Used: None
  Key Findings: * The proposed approach is able to identify spurious sensor measurements and eliminate them from the fusion process, thus leading to a better overall estimate of the true state.
* The proposed approach is also validated with the help of experiments performed using stereo vision cameras, one infrared proximity sensor, and one laser proximity sensor.
* The information from these three sensing sources is fused to obtain an occupancy profile of the robotic workspace.
  Extract 1: "This paper makes use of a modified Bayesian approach for fusion that takes into account measurement inconsistency and entropy to identify spurious data."
  Extract 2: "Based on the entropy of the posterior distribution of a desired quantity, the approach presented in this paper detects whether the data from the sensors are spurious or inconsistent."
  Limitations: None
  Relevance Evaluation: This paper is highly relevant to the point in the literature review that focuses on adaptive data preprocessing methods for dealing with varying data quality and formats from heterogeneous data sources. The paper's proposed approach uses entropy-based analysis to identify spurious or inconsistent data, which is crucial for preprocessing and ensuring the quality of data before fusion. Additionally, the paper explores the use of both centralized and decentralized Bayesian fusion schemes, providing a comprehensive analysis of different approaches to data fusion.
  Relevance Score: 0.9
  Inline Citation: (Kumar, Garg, & Zachery, 2007)
  Explanation: The paper proposes a modified Bayesian approach to sensor fusion that considers measurement inconsistency and entropy to detect spurious data. The approach involves adding a term to the Bayesian formulation that estimates the probability of the data not being spurious based on measured data and the unknown true state. This term increases the variance of the posterior distribution when a measurement is inconsistent with others. The entropy of the posterior distribution is used to determine if the fusion of data improves the information content. The paper presents the approach using both centralized and decentralized Bayesian fusion schemes.

 Full Text: >
This website utilizes technologies such as cookies to enable essential site functionality, as well as for analytics, personalization, and targeted advertising purposes. To learn more, view the following link: Privacy Policy Manage Preferences Typesetting math: 100% IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Sensors Journal >Volume: 7 Issue: 5 A Method for Judicious Fusion of Inconsistent Multiple Sensor Data Publisher: IEEE Cite This PDF Manish Kumar; Devendra P. Garg; Randy A. Zachery All Authors 50 Cites in Papers 1574 Full Text Views Abstract Document Sections I. Introduction II. Bayesian Approach for Sensor Fusion III. Multisensor Fusion with Spurious Data IV. Fusion of Three Sensors V. Simulation Results Show Full Outline Authors Figures References Citations Keywords Metrics Abstract: One of the major problems in sensor fusion is that sensors frequently provide spurious observations which are difficult to predict and model. The spurious measurements from sensors must be identified and eliminated since their incorporation in the fusion pool might lead to inaccurate estimation. This paper presents a unified sensor fusion strategy based on a modified Bayesian approach that can automatically identify the inconsistency in sensor measurements so that the spurious measurements can be eliminated from the data fusion process. The proposed method adds a term to the commonly used Bayesian formulation. This term is an estimate of the probability that the data is not spurious, based upon the measured data and the unknown value of the true state. In fusing two measurements, it has the effect of increasing the variance of the posterior distribution when measurement from one of the sensors is inconsistent with respect to the other. The increase or decrease in variance can be estimated using the information theoretic measure "entropy." The proposed strategy was verified with the help of extensive computations performed on simulated data from three sensors. A comparison was made between two different fusion schemes: centralized fusion in which data obtained from all sensors were fused simultaneously, and a decentralized or sequential Bayesian scheme that proved useful for identifying and eliminating spurious data from the fusion process. The simulations verified that the proposed strategy was able to identify spurious sensor measurements and eliminate them from the fusion process, thus leading to a better overall estimate of the true state. The proposed strategy was also validated with the help of experiments performed using stereo vision cameras, one infrared proximity sensor, and one laser proximity sensor. The information from these three sensing sources was fused to obtain an occupancy profile of the robotic workspace Published in: IEEE Sensors Journal ( Volume: 7, Issue: 5, May 2007) Page(s): 723 - 733 Date of Publication: 16 April 2007 ISSN Information: DOI: 10.1109/JSEN.2007.894905 Publisher: IEEE SECTION I. Introduction The principal objective of a multisensor system [1]–[3] is to combine information from a variety of sources in a coherent and synergistic manner to yield a robust, accurate, and consistent description of quantities of interest in the environment. There are several issues that arise when fusing information from multiple sources, some of which include data association, sensor uncertainty, and data management. The most fundamental of these issues arise from the inherent uncertainty in sensor measurement. The uncertainties in sensor measurement are not only caused by device impreciseness and noise, but also manifest themselves from the ambiguities and inconsistencies present within the environment, and from an inability to distinguish between them. The strategies used to fuse data from multiple sensors should be capable of handling these uncertainties, and combining different types of information to obtain a consistent description of the environment. Some of the more popular techniques for sensor fusion that are explored extensively in literature include Dempster–Shafer theory for evidential reasoning [4], [5], fuzzy logic [6], [7], neural network [8], [9], genetic algorithm [10], [11], Bayesian approach [12], and statistical techniques [13] such as Kalman filter [14]–[16]. Another possible uncertainty that arises in the sensor measurement process occurs when the measurements become corrupted and appear spurious in nature. Such corrupted measurements are difficult to model because they are not directly attributable to the inherent noise or other sources of uncertainty mentioned above. The cause of the corruption may be due to events such as permanent sensor failures, short duration spike faults, or nascent (slowly developing) failures. Previous attempts at developing experimental models usually preclude the use of spurious measurements, and represent uncertainties attributable only to sensor noise and inherent limitations. Fusion techniques based on these incomplete models provide inaccurate estimation that can eventually result in potentially damaging action by the control system. Hence, a sensor validation scheme is necessary to identify spurious measurements so they can be eliminated before the fusion process. There are several techniques reported in the literature for sensor validation and identification of inconsistent data. Many of them are limiting because they are based on specific failure models; these techniques can work well for events that occur due to known failure modes, however, they do not capture all possible failure events and often perform poorly when unmodeled failures occur. As a means to detect inconsistency, there should be either redundancy in the data, or some availability of a priori information. For example, in the case where a priori information is available, researchers have used the Nadaraya–Watson Estimator [17] and a priori observations to validate sensor measurements. Other researchers have used a model based Kalman filter approach [18], while others have used covariance [19], [20], probability [21], [22], fuzzy logic [23], and neural network [24] based approaches. Some of these methods are explicit model-based, whereas others require tuning and training. In the general case where a priori information is often not available, these approaches are typically deficient and can often lead to undesirable results. Most of the fusion strategies based on Bayesian approaches reported in the literature handle inconsistency in data rather poorly. In practical real-world scenarios, where data generated by sensors might be incomplete, incoherent or inconsistent, this approach might lead to erroneous results. Consequently, the inconsistency in data needs to be dealt with accordingly when Bayesian approaches are used. This paper makes use of a modified Bayesian approach for fusion that takes into account measurement inconsistency and entropy to identify spurious data. Based on the entropy of the posterior distribution of a desired quantity, the approach presented in this paper detects whether the data from the sensors are spurious or inconsistent. Entropy-based analysis aids in determining if the fusion of data from a particular sensor actually improves the information content of the fusion. This paper is organized as follows: First, it describes a simplified version of the Bayesian approach. Next, it presents the analytical formulation of the proposed approach. Finally, the proposed approach is applied using two different fusion schemes: 1) centralized Bayesian fusion where data from all sensors are fused simultaneously and 2) decentralized Bayesian fusion in which data from sensors are fused sequentially so as to provide an opportunity to identify and eliminate spurious data. A simulated application is presented that makes use of data from three sensors, all with varying probability of providing spurious measurements. Finally, the paper demonstrates the proposed technique with a real-world application; obtaining the occupancy profile of a robotic workspace using three sensory sources: stereo vision, an infrared proximity sensor, and a laser proximity sensor. SECTION II. Bayesian Approach for Sensor Fusion Bayesian inference [12], [25], [26] is a statistical data fusion algorithm based on Bayes' theorem [27] of conditional or a posteriori probability to estimate an n -dimensional state vector X , after the observation or measurement denoted by Z has been made. The probabilistic information contained in Z about X is described by a probability density function (pdf) p(Z|X) , known as likelihood function, or the sensor model, which is a sensor dependent objective function based on observation. The likelihood function relates the extent to which the a posteriori probability is subject to change, and is evaluated either via offline experiments or by utilizing the available information about the system. If the information about the state X is made available independently before any observation is made, then the likelihood function can be improved to provide more accurate results. Such a priori information about X can be encapsulated as the prior probability P(X=x) and is regarded as subjective because it is not based on observed data. Bayes' theorem provides the posterior conditional distribution of X=x , given Z=z , as p(X=x|Z=z) = p(Z=z|X=x)P(X=x) ∫p(Z=z|X=x)P(X=x)dx = p(Z=z|X=x)P(X=x) P(Z=z) . (1) View Source Since the denominator depends only on the measurement (the summation is carried out over all possible values of state), an intuitive estimation can be made by maximizing this posterior distribution, i.e., by maximizing the numerator of (1). This is called maximum a posteriori (or MAP) estimate, and is given by x ^ MAP =argmaxp(X=x|Z=z) ∝argmaxp(Z=z|X=x)P(X=x). (2) View Source Another popular estimation scheme minimizes the sum of squared errors, i.e., it minimizes the Euclidean distance between the true state x and the estimate x ^ after the observation z has been made. This estimator, called the minimum mean square error (MMSE) estimator, is given by x ^ MMSE =arg min x ^ E p(x|z) {( x ^ −x)( x ^ −x ) T } (3) View Source p(X=x| Z ¯ 1…n = z 1 , z 2 ,… z n )= p(Z= z 1 |X=x)p(Z= z 2 |X=x)…p(Z= z n |X=x)P(X=x) P( Z ¯ 1…n = z 1 , z 2 ,… z n ) (4) View Source where E p(x|z) is the expected value of a function with respect to distribution p(x|z) . Sensor modeling [28]–[31] forms an important part of sensor fusion and it deals with developing an understanding of the nature of measurements provided by the sensor, the limitations of the sensor, and probabilistic understanding of the sensor performance in terms of the uncertainties. The information supplied by a sensor is usually modeled as a mean about a true value, with uncertainty due to noise represented by a variance that depends on both the measured quantities themselves and the operational parameters of the sensor. A probabilistic sensor model is particularly useful because it facilitates a determination of the statistical characteristics of the data obtained. This probabilistic model is usually expressed in the form of pdf p(Z=z|X=x) that captures the probability distribution of measurement by the sensor ( z ) when the state of the measured quantity ( x ) is known. This distribution is extremely sensor specific and can be experimentally determined. The likelihood function relates the extent to which the a posteriori probability is subject to change, and is evaluated either via offline experiments or by utilizing the information available about the problem. Since the likelihood function is obtained from the experimental observations, it is said to be objective. Bayesian approaches make use of a priori information about X and fuse that information with measurement information from sensors to provide an improved estimate of the state. The data from multiple sensors can be fused simultaneously (centralized fusion scheme) as shown in Fig. 1, or sequentially (decentralized fusion) as shown in Fig. 2. Fusing data from n independent sensors in the centralized scheme using the Bayesian approach can be achieved via equation (4) shown at the bottom of the page, where z i represents the measurement obtained from sensor i . Similarly, the sequential Bayesian approach can be easily implemented in a distributed sensing environment and in an online manner where the posterior distribution obtained from old measurements becomes the prior distribution. Hence, the addition of new sensor measurement z n to the belief obtained from n−1 sensors ( Z ¯ 1…n−1 = z 1 , z 2 ,… z n−1 ) can be achieved in an incremental manner via (5) shown at the bottom of the page. p(X=x| Z ¯ 1…n = z 1 , z 2 ,… z n )= p(Z= z n |X=x)p(X=x| Z ¯ 1…n−1 = z 1 , z 2 ,… z n−1 ) P( Z ¯ 1…n = z 1 , z 2 ,… z n ) (5) View Source It may be noted that (4) and (5) are valid only when measurements from different sensors are independent. This paper assumes the independence of sensors in its analysis. However, the analytical approach used in this paper is equally applicable when the sensors are not independent with some modifications in its formulation that can account for the interdependence of the measurements from different sensors. Fig. 1. Centralized sensor fusion scheme using Bayesian approach. Show All Fig. 2. Decentralized sensor fusion scheme using Bayesian approach. Show All This type of decentralized fusion scheme is more robust in terms of individual component failure, is more efficient in using communication resources as compared with the conventional schemes, and is also scalable. This fusion scheme, based on sequential Bayesian estimation, provides a mechanism to identify sensor failure or the presence of spurious sensor data, and provides a means to eliminate those measurements. One of the major advantages of the Bayesian approach is that it provides an excellent mechanism to combine prior information with information obtained from current experiments. Since the estimation takes into account available data from all previous as well as current experiments, the approach leads to a theoretically optimal solution. However, for most practical applications, a lack of priors or use of noninformative priors presents difficulties for Bayesian-based sensor fusion approaches. Assumptions regarding informative priors creates the possibility of unreasonable fusion between priors and likelihood functions. Another major drawback of the Bayesian approach is its inability to fuse estimates from various sources that are either noncoherent or inconsistent. Thus, inconsistencies in data need to be dealt with separately when Bayesian approaches are used. SECTION III. Multisensor Fusion with Spurious Data Sensors often provide spurious data due to sensor failure; this can be due to some inherent limitation of the sensor and/or some ambiguity in the environment. The Bayesian approach described in the previous section is inadequate in handling this type of spurious data. The approach does not have a mechanism to identify when data from sensors is incorrect. The following paragraphs describe the use of a Bayesian-based approach for fusion of data from multiple sensors that takes into account measurement inconsistency. While building a stochastic sensor model, generally spurious data are identified and eliminated. Hence, these experimentally developed sensor models represent uncertainties arising only from sensor noise. If the event s=0 represents that the data obtained from a sensor is not spurious, then the sensor model developed in this manner actually represents the distribution p(Z=z|X=x,s=0) . From Bayes' theorem, the probability that the data z i measured by sensor i is not spurious conditioned upon the actual state x , is given by [p(s=0|X=x,Z= z i ) ] i = [P(s=0) ] i [p(Z= z i |X=x,s=0)] ∑ s [P(s) ] i [p(Z= z i |X=x,s) ] i (6) View Source [P(s=0) ] i is the sensor specific prior probability that the data provided by sensor i is not spurious. The denominator of the right-hand side of the above equation is a summation carried over all possible values of s which are 0 and 1. The above equation can be rewritten as or [p(s=0|X=x,Z= z i ) ] i = [P(s=0) ] i [p(Z= z i |X=x,s=0)] [p(Z= z i |X=x) ] i [p(Z= z i |X=x) ] i = [P(s=0) ] i [p(Z= z i |X=x,s=0) ] i [p(s=0|X=x,Z= z i ) ] i . (7) (8) View Source Then, from (4), in a centralized fusion scheme, data from n sensors can be fused via the following equation: p(X=x|Z= z 1 , z 2 ,… z n ) = [P(s=0) ] 1 [p(Z= z 1 |X=x,s=0) ] 1 [p(s=0|X=x,Z= z 1 ) ] 1 ×… [P(s=0) ] n [p(Z= z n |X=x,s=0) ] n [p(s=0|X=x,Z= z n ) ] n × P(X=x) P(Z= z 1 , z 2 ,… z n ) . (9) View Source Note the effect of the additional terms [p(s=0|X=x,Z= z 1 ) ] 1 …[p(s=0|X=x,Z= z n ) ] n in the denominator of (9). It will be demonstrated in the next section that the term [p(s=0|X=x,Z= z i ) ] i in the denominator results in an increase in the variance based on the belief that measurements from sensor i have a greater probability of being spurious. This results in less weight applied to the measurement from sensor i when fused with measurements from other sensors. Similarly, to combine the sensor measurement from sensor n sequentially with the current belief obtained from sensors 1,2…n−1 , (5) can be rewritten as (10) shown at the bottom of the page. p(X=x| Z ¯ = z 1 , z 2 ,… z n )= [P(s=0) ] n [p(Z= z n |X=x,s=0)]p(X=x| Z ¯ 1…n−1 = z 1 , z 2 ,… z z−1 ) P( Z ¯ 1…n = z 1 , z 2 ,… z n )[p(s=0|X=x,Z= z n ) ] n (10) View Source Hence, the addition of term [p(s=0|X=x,Z= z n ) ] n in the denominator has the effect of increasing the spread (variance) of the posterior if the new measurement has a greater probability of being spurious, and decreasing the spread of the posterior if the new measurement has a lower probability of being spurious. The increase or decrease in the spread of the posterior distribution can be easily ascertained by determining the information content given by the entropy of distribution obtained from the following equation: H(X)=∫−p(X=x|Z= z 1 , z 2 ,… z n ) ×log(p(X=x|Z= z 1 , z 2 ,… z n ))dx.(11) View Source Entropy of a variable represents the uncertainty in that variable. A larger value of entropy implies more uncertainty and, hence, less information content. The fusion of a new measurement should always lead to a decrease in entropy, and fusion should always be done in order to reduce entropy. Based on increasing or decreasing the entropy of the posterior, this method can identify and eliminate spurious data from a sensor. It is noted that the prior probability [P(s=0) ] i has a constant value and simply acts as a constant weighting factor in (9) and (10). This value does not influence the posterior distribution nor the MAP estimate of the state. SECTION IV. Fusion of Three Sensors A. Bayesian Fusion Without Consideration of Spuriousness in Data (Method 1) If the spurious nature of the sensor data is not considered, and the models of three sensors are given by the following Gaussian likelihood function: p(Z= z k |X=x)= 1 σ k 2π − − √ e { −(x− z k ) 2 2 σ 2 k } k=1,2,3 (12) View Source where k=1 represents the first sensor, k=2 represents the second sensor, and k=3 represents the third sensor. From Bayes' Theorem, the fused MAP estimate is given by x ^ MAP =argmax[p(Z= z 1 |X=x) ×p(Z= z 2 |X=x)p(Z= z 3 |X=x)].(13) View Source If three Gaussian distributions (each given by the one of three sensors' model pdfs) are fused, then the posterior distribution is jointly Gaussian, and the standard deviation is given by ( σ ′ ) 2 =[( σ 1 ) −2 +( σ 2 ) −2 +( σ 3 ) −2 ] −1 (14) View Source and the mean (and the MAP estimate) are given by x ^ MAP =( σ ′ ) 2 [ z 1 ( σ 1 ) 2 + z 2 ( σ 2 ) 2 + z 3 ( σ 3 ) 2 ]. (15) View Source Hence, if there is no prior information available about the quantity to be estimated, the Bayesian approach for fusion of the three sensor estimates results in a weighted average dictated by the ratio of standard deviations. From (14) we note that the standard deviation of the fused distribution is smaller than any of the three individual distributions, representing less uncertainty in the fused estimates. B. Bayesian Fusion with Consideration of Spuriousness in Data If the spurious nature of the sensor data is considered, then the Gaussian sensor model represented by distribution p(Z=z|X=x,s=0) is given by [p(Z=z|X=x,s=0) ] k = 1 σ k 2π − − √ e { −(x− z k ) 2 2 σ 2 k } k=1,2,3.(16) View Source The probability that the measurement from sensor k is not spurious given the true state x and measurement z k , is assumed to be represented by the following equation: [p(s=0|X=x,Z= z k ) ] k = e { −(x− z k ) 2 a 2 k } . (17) View Source An advantage of choosing the above formulation for representing the probability is that the probability is 1 when measurement z k is equal to the true state x , and decreases when the measured value moves away from the true state. The rate at which the probability decreases when the measured value moves away from the true estimate depends upon the parameter a k . The value of the parameter is dependent on the variances of the sensor models and the distance between the output of sensor k with respect to other sensors. 1. Centralized Fusion Scheme (Method 2) The posterior distribution p(X=x|Z= z 1 , z 2 , z 3 ) in the centralized fusion scheme obtained from (9) is given by p(X=x|Z= z 1 , z 2 , z 3 ) = P(X=x) P(Z= z 1 , z 2 , z 3 ) × ∏ k=1 3 [P(s=0) ] k [p(Z= z k |X=x,s=0) ] k [p(s=0|X=x,Z= z k ) ] k . (18) View Source The value of parameter a k in (17) is assumed to be given by a 2 k = b 2 k ∏ 3 l≠k,l=1 ( z k − z l ) 2 . (19) View Source Incorporating this in (18) yields p(X=x|Z= z 1 , z 2 , z 3 ) = P(X=x) P(Z= z 1 , z 2 , z 3 ) × ∏ k=1 3 [P(s=0) ] k 1 σ k 2π − − √ × e −(x− z k ) 2 { 1 2 σ 2 k − ∏ 3 l≠k,l=1 ( z k − z l ) 2 b 2 k } . (20) View Source The value of parameter b k is chosen to satisfy the following inequality: b 2 k ⩾2 σ 2 k ∏ l≠k,l=1 3 ( z k − z l ) 2 . (21) View Source Satisfaction of this inequality ensures that the posterior distribution in (20) remains Gaussian and hence has a single peak. The entire process has the effect of increasing the variance of the individual distribution (representing belief from one particular measurement) if that particular measurement is at a larger distance to other measurements. Thus, if two measurements lie close to one another, then weights associated with those measurements become larger when compared to those measurements that lie farther away. This process yields a mathematical basis to provide more weighting to beliefs when they corroborate one another rather than when they contradict one another. 2. Decentralized Fusion Scheme (Method 3) In the decentralized or sequential fusion scheme, measurements from only two sources are fused at once. The belief resulting from the fusion of two sensors is then fused with the next sensor, and the process continues henceforth. Fusion of two sensors k and k+1 using (10) yields p(X=x|Z= z k , z k+1 ) = [P(s=0) ] k [p(Z= z k |X=x,s=0) ] k [p(s=0|X=x,Z= z k ) ] k × [P(s=0) ] k+1 [p(Z= z k+1 |X=x,s=0) ] k+1 [p(s=0|X=x,Z= z k+1 ) ] k+1 × P(X=x) P(Z= z k , z k+1 ) . (22) View Source The value of parameter a k in (17) is assumed to be given by a 2 k = b 2 k ( z k − z k+1 ) 2 (23) View Source which leads to w p(X=x|Z= z k , z k+1 ) = P(X=x) P(Z= z k , z k+1 ) ×[P(s=0) ] k 1 σ k 2π − − √ × e −(x− z k ) 2 { 1 2 σ 2 k − ( z k − z k+1 ) 2 b 2 k } ×[P(s=0) ] k+1 1 σ k+1 2π − − √ × e −(x− z k+1 ) 2 { 1 2 σ 2 k+1 − ( z k − z k+1 ) 2 b 2 k+1 } . (24) View Source The value of parameter b k is chosen to satisfy the following inequality: b 2 k ≥2 σ 2 k ( z k − z k+1 ) 2 . (25) View Source Satisfaction of this inequality ensures that the posterior distribution in (24) remains Gaussian, and hence has a single peak. The parameter value should be chosen based on maximum expected difference (represented by m ) between the sensor readings so that inequality (25) is always satisfied. Hence b 2 k =2 σ 2 k m 2 . (26) View Source Substituting (26) in (24) gives p(X=x|Z= z k , z k+1 ) = P(X=x) P(Z= z k , z k+1 ) ×[P(s=0) ] k 1 σ k 2π − − √ e − (x− z k ) 2 2 σ 2 k { m 2 m 2 −( z k − z k+1 ) 2 } ×[P(s=0) ] k+1 1 σ k+1 2π − − √ e − (x− z k+1 ) 2 2 σ 2 k+1 { m 2 m 2 −( z k − z k+1 ) 2 } . (27) View Source It is apparent that the entire process has the effect of increasing the value of the variance of individual distribution by a factor of {( m 2 / m 2 −( z 1 − z 2 ) 2 )} . Larger differences in sensor measurement imply that the variance increases by a bigger factor. Depending on the squared difference in measurements from the two sensors, the variance of the posterior distribution may increase or decrease as compared with the variance of individual Gaussian distributions representing the sensor models. Therefore, the strategy is capable of determining if fusion of the two measurements would lead to an increase or decrease of the variance of the posterior distribution. In information theoretic terms, the strategy is capable of determining if the fusion leads to an increase in information content [or entropy given by (11)] or not. Based on increasing or decreasing of entropy in the posterior, a decision can be made whether to fuse those two sensors or not. This approach provides an opportunity to eliminate sensor measurements that are spurious and fuse measurements from only those sensors that are consistent, ensuring an increase in information content after fusion. Fig. 3. Fusion of three sensors. (a) All sensors in agreement. (b) Sensor 1 in disagreement. (c) Sensor 2 in disagreement. (d) Sensor 3 in disagreement. Show All SECTION V. Simulation Results A simulation study was carried out to validate the effectiveness of the proposed strategy in identifying spurious data. A comparative analysis was performed to study the efficiency with which the three methods (described in previous section) were able to handle inconsistency in data. The following parameters were assumed in the simulation. Sensor 1: [P(s=0) ] 1 =0.90 and σ 1 =3 . Sensor 2: [P(s=0) ] 2 =0.98 and σ 2 =2 . Sensor 3: [P(s=0) ] 3 =0.94 and σ 3 =2.5 . True value of state: x=20 . Simulation data was generated so that Sensor 1 provided 90% of the time normally distributed random data with a mean value of 20 and variance 9. It provided incorrect data 10% of the time which was uniformly distributed outside the Gaussian distribution. Sensor 2 provided 98% of the time normally distributed random data with a mean value of 20 and variance 4, and 2% of the time it provided incorrect data. Similarly, Sensor 3 provided 94% of the time normally distributed random data with a mean value of 20 and variance 6.25, and 6% of the time it provided incorrect data. It may be noted here that the values for [P(s=0) ] k have been assumed simply for the purpose of generating simulated data. These are not used in the fusion algorithm. Since these values are constants, they do not have any effect on the posterior distribution or the MAP estimate. Fig. 4. Sample data and fusion from multiple sensors with spurious data. (a) Fusion of a sample of 100 data points. (b) A case when two sensors provide spurious measurements. Show All Fig. 3(a) illustrates a case when all of the three sensors are in agreement, and measurement from none of the sensors is inconsistent with the rest. It can be seen that posterior distributions obtained from all three methods coincide resulting in the same value of MAP estimate. In Fig. 3(b), measurement from Sensor 1 is in disagreement from the other two sensors. Method 1, which is a simple Bayesian fusion and does not take into account inconsistency of data, results in the weighted average of the three measurements given by (15). Method 2, which takes into account the inconsistency and weights those sensors more whose measurements are consistent (Sensors 2 and 3 in this case) with each other, results in an estimate which is closer to the sensors (Sensors 2 and 3) in agreement. Method 3 identifies the sensor which provides spurious measurements and eliminates that from the fusion process. Hence, it simply considers measurements from Sensors 2 and 3, and fuses them appropriately using (27). In a similar manner, Fig. 3(c) and (d), respectively, show that measurements from Sensors 2 and 3 are spurious. The figure shows the efficiency with which Method 3 identifies and eliminates spurious measurements, and results in better estimates (closer to the true value) of the variable. The figure also shows that Method 2 is able to appropriately and autonomously weight sensors to achieve an estimate which is better as compared to Method 1 which does not take inconsistency into consideration at all. A set of 10 000 data points were generated in the manner described above and fusion was carried out using all three methods. The mean value of the sum of squared error (MSE) between the fused value and true value for all 10 000 data points was computed. The values of MSE were found as 6.94 for Method 1, 6.03 for Method 2, and 5.50 for Method 3. Hence, Method 3 was able to reduce the MSE by approximately 21% when compared with Method 1, and Method 2 was able to reduce the mean square error by approximately 13% when compared with Method 1. Fig. 4(a) shows a sample of 100 data points taken from the above set of ten thousand data points. Data points represented by asterisks (∗) are the fused values obtained via Method 3. The figure shows that the asterisks, on an average, lie closer to the dashed line (—) which represents the true value of the variable. Method 3 has the built-in mechanism to identify and eliminate spurious data. As explained in the previous sections, it does so by comparing data from one sensor with those from the other two sensors. This method fails when two sensors simultaneously provide spurious data which are close to one another. The method wrongfully identifies the measurement from the third sensor as spurious. This rarely happens since the probability of two sensors providing spurious data at the same time is very low. In Fig. 4(a), for example, it happened for the encircled data. Fig. 4(b) shows the details of fusion results for this data point. Sensors 1 and 2 have both provided spurious data. However, since they are close to each other, Method 3 identifies data from Sensor 3 as spurious, and eliminates that data from fusion process. This leads to inaccurate estimation. Similarly, Method 2 provides more weights to data from Sensors 1 and 2, and also results in inaccurate estimation. However, since occurrence of such a case is rare, both Method 2 and Method 3 generally provide improved accuracy over Method 1. SECTION VI. Experimental Validation The theories developed in the previous sections were validated with the help of experiments performed in the Robotics and Manufacturing Automation (RAMA) Laboratory at Duke University. The objective of the experiment was to obtain a three-dimensional occupancy profile of the robotic workspace using three independent sensory sources: stereo vision, an infrared proximity sensor, and a laser proximity sensor. The occupancy profile was obtained using an occupancy grid framework. The occupancy grid [29]–[33] is a multidimensional field (usually of dimension two or three) where each cell (or unit of the grid) stores or represents the probabilistic estimate of the state of spatial occupancy. Occupancy grids are one of the most common low-level models of an environment, which provide an excellent framework for robust fusion of uncertain and noisy data. If the state variable (occupancy, in this case) associated with a cell, C i , is denoted by s( C i ) , then the occupancy probability P[s( C i )] represents the probabilistic estimate of occupancy of that particular cell. Fig. 5. Sensor models. (a) Stereo Vision. (b) Infrared proximity sensor. (c) Laser proximity sensor. Show All Fig. 6. Images of the worktable obtained from left and the right camera. Show All If P[s( C i )=occ]≈0 , then the cell is assumed to be empty, while if P[s( C i )=occ]≈1 , then the cell is assumed to be occupied. If a single sensor is used to obtain the occupancy grid, Bayes' Theorem can be used in the following manner to determine the state of the cell: P[s( C i ) =occ|z]= p[z|s( C i )=occ]P[s( C i )=occ] ∑ s( C i ) p[z|s( C i )]P[s( C i )] (28) View Source where z is the sensor measurement. The pdf p[z|s( C i )=occ] is dependent on the sensor characteristics and is called the sensor model. The probability P[s( C i )=occ] is called prior probability mass function and specifies the information made available prior to any observation. At first, models of the three sensory sources using Gaussian distributions were obtained. These models were obtained using a neural network-based technique that established the relationship between the variance of the sensor model with respect to certain environmental or algorithmic conditions. The details of the sensor modeling process are explained in [28], and the results are shown in the Fig. 5. Fig. 5(a) shows the graph of standard deviation of Gaussian sensor model plotted against the correlation score of stereo-matched templates for stereo vision sensor. Similarly, for infrared and laser proximity sensors, the variance of the sensor model was found to be dependent on the distance to the detected object, and the relationship between the variance and the sensor outputs (which are indicative of the distance to the detected object) are shown in Fig. 5(b) and (c), respectively, for infrared and laser proximity sensor. Occupancy grids were obtained individually for stereo vision, infrared, and laser proximity sensors, and then the individual grids were fused using two techniques: 1) Simple Bayesian Fusion and 2) Sequential Bayesian Fusion with Proposed Inconsistency Detection and Elimination Strategy. The details of the process for obtaining occupancy grids and sensor fusion are explained in [29]. In the experiment, a cylindrical object was placed on the robot's worktable. Fig. 6 shows the images of the worktable obtained from the stereo cameras. Fig. 7(a) shows the actual occupancy grid of the workspace. This was obtained based on the geometric dimensions of the object and its location in the workspace. For the occupancy grid developed in this research, each grid is of size 5 mm × 5 mm × 5 mm. Fig. 7(b)–(d) shows the occupancy grids independently obtained from stereo vision, IR proximity sensor, and laser proximity sensor, respectively. Fig. 7(e) shows the occupancy grid obtained from simple Bayesian approach, and Fig. 7(f) shows the occupancy grid obtained from the Bayesian approach that utilizes the inconsistency detection and elimination technique proposed earlier. To facilitate a comparison of the performance of the fusion process via different algorithms, a measure of error was formulated which is given by the following equation: Error= ∑ C i [|s( C i ) | actual −|s( C i ) | sensor ] 2 (29) View Source Fig. 7. Occupancy grids. (a) Actual grid. (b) Grid obtained from stereo vision. (c) Grid obtained from IR proximity sensor. (d) Grid obtained from laser proximity sensor. (e) Fused grid (simple Bayesian approach). (f) Fused grid (proposed Bayesian fusion with inconsistency detection and elimination). Show All Table I Error Associated with Occupancy Grids Obtained from Fusion Process where |s( C i ) | actual is the actual state of the cell, and |s( C i ) | sensor is the state of the cell obtained from the sensor and/or fusion process. The state of the cell is either 1 (for occupied) or 0 (for empty). Table I provides the error value associated with the occupancy grid obtained from the fusion process described above. The table compares the error value obtained via the two approaches. The first approach is based on the simple Bayesian fusion scheme, and the second approach is based on the proposed Bayesian fusion scheme embedded with the mechanism for inconsistency detection and elimination. From the figures as well as from the table of results, it is evident that the proposed fusion scheme based on Bayesian approach with an built-in mechanism to identify and eliminate spurious/inconsistent measurement presented in this paper has been able to reduce the uncertainty inherent in individual sensors. The proposed method has been able to reduce the error by approximately 70% as compared with stereo vision, 64% as compared with IR proximity sensor, and 4% as compared with laser proximity sensor. On the other hand, simple Bayesian technique was able to reduce the error by approximately 64% as compared with stereo vision and by 56% as compared with IR proximity sensor. The technique based on simple Bayesian approach led to an increase in error by approximately 15% as compared with laser proximity sensor. The increase in error demonstrates the fact that it is not necessary that incorporation of additional sensor data will lead to improved accuracy of estimation. This is particularly more evident in cases when the accuracy of measurements from sensors differs by a large amount. In this case, the measurements from laser proximity are far more accurate (see Fig. 5) than measurements from the stereo vision or IR proximity sensor, and fusion of measurements from the laser with stereo vision and IR proximity leads to an increase in error. However, the proposed technique has a built-in mechanism to determine if the fusion process leads to an increase in the information content, and, in this way was able to eliminate inconsistent data and improve the overall accuracy of the fusion process. Of the 24 000 points (or cells) where the fusion of data from three sensors occurred (fusion occurred at 30 × 40 × 20 cells of the occupancy grid), the proposed technique detected 393 points where data from IR sensor were inconsistent and 1028 points where data from stereo vision were inconsistent. None of the data from the laser sensor were detected to be inconsistent. This observation is consistent with the fact that the laser sensor was far more accurate than the other two sensors. One of the limitations of the proposed technique is that when there is a large number of sensors supporting an inconsistent measurement, then, based on the beliefs of the individual measurements, the technique may consider inconsistent measurements to be the correct one, and might disregard the correct measurements obtained by fewer numbers of sensors. In psychology, this kind of problem is termed as group conformity. For example, when an individual's opinion differs significantly from that of others in a group, the individual is likely to feel extensive pressure to align his or her opinion with others. In the case of sensor systems, this kind of condition is more likely to occur in adversarial situations, such as the battlefield, where events are prone to be camouflaged to escape detection. Hence, a formal criterion to establish the difference between spuriousness and opinion difference must be developed for the sensor fusion process to be accurately carried out in such adversarial situations. For example, in these situations, the technique proposed in this paper could be applied if sensor models could be developed that represent the possibility/likelihood of events being camouflaged. Real-time implementation and scalability aspects of the proposed sequential scheme have to be considered. Since the method is based on the information content of the fused belief, novel fusion architectures can be designed to introduce parallelism in the process, and at the same time minimize the possibility of fused result falling into local attractor basins. On the other hand, the technique based on centralized fusion scheme is completely scalable and can be easily implemented in real time. SECTION VII. Conclusion Sensors often provide spurious measurements. Identification of such spurious measurements and their elimination is essential for carrying out accurate estimation. This paper proposes a unified and formalized approach to fuse data from multiple sources which can automatically identify inconsistency in sensor data. The proposed strategy adds a term to the popular Bayesian approach corresponding to a belief that the sensor data is not spurious conditioned upon the data and true state. An information theoretic measure is utilized to observe the information content of the posterior distribution to identify spurious data. Three approaches were comparatively studied in this paper. The first approach was based on simple Bayesian methods. The second approach adds the new term described above fuses all data in a centralized manner. The third method sequentially fuses data and eliminates those data which it identifies as spurious. An extensive simulation study was performed where data from three sensors was fused. It was observed that the third method was very effective in identifying spurious data, and elimination of spurious data ensured more accurate results. The second method performed better than the first method since it had a built-in mechanism for increasing the weighting of consistent measurements, while at the same time decreasing the weighting applied to spurious measurements. Finally, the effectiveness of the proposed technique to identify and eliminate inconsistent sensor data in sequential Bayesian fusion was demonstrated with the help of an experiment performed in a robotic workcell, where measurements from stereo vision, infrared proximity, and laser proximity senor were fused to obtain three-dimensional occupancy profile of robotic workspace. ACKNOWLEDGMENT This research was performed in the Robotics and Manufacturing Automation (RAMA) Laboratory at Duke University, while the first author, Dr. M. Kumar, held a National Research Council's Research Associateship Award at the Army Research Office. Authors Figures References Citations Keywords Metrics More Like This Entropy Minimization SLAM Using Stereo Vision Proceedings of the 2005 IEEE International Conference on Robotics and Automation Published: 2005 Robot Vision System based on a 3D-TOF Camera 2007 IEEE Instrumentation & Measurement Technology Conference IMTC 2007 Published: 2007 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.

Paper 9:
- APA Citation: Stief, A., Ottewill, J. R., Baranowski, J., & Orkisz, M. (2019). A PCA and two-stage Bayesian sensor fusion approach for diagnosing electrical and mechanical faults in induction motors. IEEE Transactions on Industrial Electronics, 66(12), 9510-9520.
  Main Objective: To develop and evaluate a two-stage Bayesian sensor fusion method for diagnosing electrical and mechanical faults in induction motors under varying load and environmental conditions.
  Study Location: Unspecified
  Data Sources: Acoustic, electric, and vibration signals
  Technologies Used: Principal component analysis (PCA), Gaussian Naïve Bayes (GNB) classifiers
  Key Findings: - The proposed two-stage Bayesian sensor fusion method, which integrates PCA and GNB classifiers, effectively diagnoses stator, rotor, and bearing faults in induction motors.
- The method is robust to varying load and environmental conditions, providing low false and missed alarm rates.
- The PCA step reduces feature correlation and the influence of load conditions, improving the effectiveness of data fusion.
  Extract 1: "In this paper, a two-stage (local and global) Bayesian method combined with PCA is proposed as a method for diagnosing not only mechanical but also electrical faults in induction motors operating under varying load and environmental conditions. ... By incorporating a multivariate statistical approach into the analysis, the correlations between operating conditions and feature level are accounted for."
  Extract 2: "The method retains the structure of the global fusion stage on the decision level, as described in [26]. The advantage of applying the GNB classifier at the local stage is that there is no need to determine alarm thresholds and confidence intervals, as the GNB classifier calculates the fault class probabilities directly."
  Limitations: None
  Relevance Evaluation: The paper is highly relevant to the point of adaptive data preprocessing methods for dealing with varying data quality and formats from heterogeneous data sources because it introduces a PCA-based approach for reducing feature correlation and the influence of load conditions, which is essential for effective data fusion. The proposed two-stage Bayesian sensor fusion method demonstrates promising results in diagnosing faults under varying operating conditions, which is a key aspect of the point.
  Relevance Score: 0.9
  Inline Citation: (Stief et al., 2019)
  Explanation: The paper presents a two-stage Bayesian sensor fusion method for diagnosing electrical and mechanical faults in induction motors. The method integrates principal component analysis (PCA) and Gaussian Naïve Bayes (GNB) classifiers to fuse data from acoustic, electric, and vibration signals. The purpose of the PCA step is to reduce feature correlation and the influence of load conditions. The GNB classifiers are used at the local stage to fuse principal components of the features, and the results are combined at the global stage using a Bayesian approach. The method is evaluated for stator, rotor, and bearing faults under varying load and environmental conditions, showing low false and missed alarm rates.

 Full Text: >
This website utilizes technologies such as cookies to enable essential site functionality, as well as for analytics, personalization, and targeted advertising purposes. To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Transactions on Industri... >Volume: 66 Issue: 12 A PCA and Two-Stage Bayesian Sensor Fusion Approach for Diagnosing Electrical and Mechanical Faults in Induction Motors Publisher: IEEE Cite This PDF Anna Stief; James R. Ottewill; Jerzy Baranowski; Michal Orkisz All Authors 76 Cites in Papers 2727 Full Text Views Open Access Under a Creative Commons License Abstract Document Sections I. Introduction II. Methods III. Experimental Data IV. Implementation of the Method V. Results Show Full Outline Authors Figures References Citations Keywords Metrics Abstract: Induction motors are widely used in industrial plants for critical operations. Stator faults, bearing faults, or rotor faults can lead to unplanned downtime with associated cost and safety implications. Different sensors may be used to monitor the health state of induction motors with each sensor typically being better suited for diagnosing different faults. Condition monitoring approaches that fuse data from multiple sensors have the potential to diagnose a greater number of faults. In this paper, a sensor fusion approach based on the combination of a two-stage Bayesian method and principal component analysis (PCA) is proposed for diagnosing both electrical and mechanical faults in induction motors. Acoustic, electric, and vibration signals are gathered from motors operating under different loading conditions and health states. The inclusion of the PCA step ensures robustness to varying loading conditions. The obtained results highlight that the proposed method performs better than the equivalent single-stage or feature-based Bayesian methods. Published in: IEEE Transactions on Industrial Electronics ( Volume: 66, Issue: 12, December 2019) Page(s): 9510 - 9520 Date of Publication: 13 January 2019 ISSN Information: DOI: 10.1109/TIE.2019.2891453 Publisher: IEEE Funding Agency: CCBY - IEEE is not the copyright holder of this material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/ to obtain full-text articles and stipulations in the API documentation. SECTION I. Introduction Induction motors are widely used in industrial plants for critical operations, where a failure could result in a partial or complete shutdown of the production process. Unplanned maintenance, downtime, or replacements can result in high costs and, furthermore, critical failures can have serious safety implications. Induction motor faults may be categorized as electrical related, mechanical related, or environmental related [1]. The range of possible faults is numerous, with stator, bearing, and rotor faults being the most prevalent [2]–[4]. These faults will impact the mechanical, magnetic, and electrical characteristics of the induction motor in different ways. As a result, the optimal sensor type for diagnosing one type of fault mode may not be the same as the optimal sensor to diagnose another fault mode. It has previously been shown that specific induction motor faults can be diagnosed using different sensors [5]–[8]. Vibration, acoustic, and electric signals are among the most commonly used sensor types for rotor and stator faults detection, however some sensors are more suitable for detecting specific faults than others [7], [8]. Nandi [5] observed that acoustic and vibration signals are the most sensitive for bearing fault detection, whereas electric signals are more sensitive to broken rotor bar faults. It has recently been shown that acoustic signals are suitable for bearing, stator, and rotor fault diagnostics of single-phase and three-phase induction motors [9], [10]. Additionally, sensors that are responsive to a specific fault can also provide information about other faults [6]. Hence, a condition-monitoring system that fuses information obtained from multiple sensor types can ensure that a comprehensive range of fault modes may potentially be detected quickly and accurately. Various condition-monitoring methods that aim to increase the accuracy and robustness of fault detection via sensor fusion have been reported. In [11], neural networks were used to fuse vibration and current signals in order to diagnose mechanical and electrical faults. It was shown that these signal types are complementary to one another and that their fusion using the Dempster–Shafer theory at the decision level increases the accuracy of the classification. A K-nearest neighbor classifier was applied in [12] using an accelerometer and load signals in order to diagnose bearing faults, showing that, whereas load signals are more useful in distinguishing healthy bearings from faulty ones and accelerometer signals are better at detecting the location of the fault, the best performance was achieved when the two signals were fused together. In [13], vibration and acoustic signals were fused using the Dempster–Shafer theory at the decision level to diagnose faults in planetary gearboxes, with the fusion resulting in more precise diagnostics along with reduced false and missed alarm rates. In [14], vibration, acoustic, and oil debris signals were fused at the feature level to diagnose faults in gears with principal component analysis (PCA) and independent component analysis. In each aforementioned case, the sensor fusion proved to increase the accuracy, robustness, and missed or false alarm rate of the system. Sensor fusion can be implemented at the data level, the feature level, and at the decision level. The decision on the abstraction level depends on the information carried by the different signals. If the signal types are significantly different and carry complementary information, it is advised to use decision-level fusion [11], [15]. A typical challenge encountered when creating decision-level fusion algorithms is that there are often a large number of features relative to the number of observations. These features can be highly correlated, which ultimately can bias the results of the fault detection algorithm. A common method to reduce the correlation and the dimensionality of the features is PCA [16], [17]. For example, in [18], the dimensionality of features extracted from vibration and current signals was reduced by PCA before applying genetic algorithms and an artificial neural network for classifying faults in an induction motor. It was found that the performance of the fault classifier was improved by adding PCA as a feature preprocessing step. In [19], several feature reduction and transformation methods including neighborhood component analysis, linear discriminant analysis (LDA), locally linear coordination, and PCA were compared with maximally collapsing metric learning for multiple bearing fault diagnosis in induction motors with particular focus given to the dimensionality reduction aspect. Feature reduction is also found in multistage frameworks for the induction motor diagnosis, for example, a recent work [20] applied PCA, LDA, a genetic algorithm, and the Fisher score in a hybrid strategy to obtain a reduced and optimized feature set from vibration signals. Another regularly observed fault detection problem is the varying operating conditions of the machines, which can originate from a change in the load or environmental conditions. In [21], it was concluded that the prediction performance of a support vector machine (SVM) based fault detection algorithm for mechanical and electrical fault detections in induction motors is load dependent. Different severities of stator faults were monitored in induction motors under changing load torque and supply voltage unbalances in [22], finding that the performance of a multiagent system and neural estimator depends on the severity of the fault. Diagnostics and prognostics methods of rotating machinery were reviewed in [23], highlighting the operating condition dependence of algorithms as an existing but an understudied area. Bayesian inference has been described as a suitable method for fault detection and fault classification in condition-monitoring systems [23], [24]. Recently, Jaramillo et al. [25] proposed a two-stage Bayesian inference approach to monitor the condition of a system composed of several subsystems. The first stage of the sensor fusion takes place at the subsystem level, whereas the second stage fuses the result of the first stage at the decision level in order to determine the health state of the whole system. The method was efficient in diagnosing faults in complex systems composed of interacting components. Existing two-stage Bayesian sensor fusion frameworks described in the literature [25], [26] typically set alarm thresholds according to the probability distributions of features and control limits. Properly tuning alarm thresholds can be challenging, particularly when there are a large number of features in the data set, or when the thresholds themselves might optimally be described as a function of other parameters (e.g., operating conditions). This paper is an extension of the previous work in which a two-stage Bayesian sensor fusion method was applied to the diagnosis of mechanical faults in induction motors [26]. It was shown that, by fusing independent diagnoses of different sensor types at the decision level, the false and missed alarm rates of a fault classification algorithm could be significantly reduced. In [26], simple linear models of expected feature values relative to load values were applied to account for the load dependence of features. Such an approach limits the generality of the solution as the loading of the system is also required as an input to the algorithm during training and testing. It was also observed that the features used for training the Naïve Bayes classifier were highly correlated. As previously noted, such correlations between features can potentially bias the fault detection algorithm toward certain diagnoses. In this paper, a two-stage (local and global) Bayesian method combined with PCA is proposed as a method for diagnosing not only mechanical but also electrical faults in induction motors operating under varying load and environmental conditions. Stator, rotor, and bearing faults are all considered. Features are extracted from acoustic, electric, and vibration signals recorded from an experimental system. PCA is used to remove the correlations that are present in the extracted features and reduce the influence of load conditions. At the local Bayesian stage, principal components of the features are fused with a Gaussian Naïve Bayes (GNB) classifier. At the global Bayesian stage, the results of the local stages are fused in order to create a final diagnosis. The generality of the algorithm is investigated by omitting data recorded at selected operating and environmental conditions from the training set and subsequently testing the trained model using the omitted data. The novelties of this paper are as follows. A two-stage Bayesian sensor fusion approach is extended by integrating PCA and GNB classifiers into the framework. It is known that many fault indicators are dependent on loading conditions. By incorporating a multivariate statistical approach into the analysis, the correlations between operating conditions and feature level are accounted for. It is shown that the resulting method is able to accurately diagnose faults even for loading conditions not present in the training set. In this paper, additional data addressing stator faults with varying severity are included into the analysis. This data is used to illustrate how, by fusing the different signals, it is possible to achieve a holistic monitoring solution that both provide greater coverage and greater monitoring accuracy compared to considering each sensor independently. Through the addition of PCA and the GNB classifier, the approach introduced in this paper does not require monitoring thresholds to be defined, as the posterior fault class probabilities are directly calculated. This paper is organized as follows. In Section II, the methods are introduced. In Section III, the experimental data are described, which were used for the validation of the methods. Section IV describes the implementation of the methods using the experimental data. The results of the proposed fault diagnosis method are presented in Section V with a discussion in Section VI. Finally, in Section VII, conclusions are drawn, pointing out the advantages, limitations of the method, and possible future work. SECTION II. Methods A. Principal Component Analysis PCA is a well-established method for feature extraction, dimensionality reduction, data compression, and data visualization [27]. It is a common problem in data analysis that the features or attributes of the observation data are highly correlated. PCA transforms the correlated features to a linear space where the transformed features are uncorrelated and are ordered in a way that the first features retain most of the variation in the data. Singular value decomposition or eigenvalue decomposition (EIG) are popular algorithms for performing PCA. Here, SVD is considered, as it is numerically more robust when matrices are either singular or numerically very close to singular. Furthermore, SVD directly provides the required scores and loadings. If X is an n × m matrix with rank r, with n observations and m features, SVD is defined as follows: X=UL A T (1) View Source where U is an n × r orthonormal matrix, L is an r × r diagonal matrix, and A is an m × r orthonormal matrix. UL is an n × r matrix, containing the transformed uncorrelated features in the principal component space, usually referenced as scores. A contains the principal components, sometimes called loadings. For further information on PCA and SVD, readers are guided to [27]. B. GNB Classifiers A GNB classifier is a probabilistic classifier, which assumes conditional independence between data that are distributed according to a Gaussian distribution. The classifier uses the Bayes theorem to calculate the posterior probabilities that an observation x t ={ x 1 , x 2 ,…, x m } belongs to class c i out of classes C={ c 1 , c 2 ,…, c p } in the following way: P( c i | x t )= P( c i )⋅ ∏ m j=1 P( x j | c i ) ∑ n k=1 P( c k )⋅ ∏ m j=1 P( x j | c k ) (2) View Source where P( c i ) is the prior probability of an observation belonging to class c i . The classifier learns the P( x j | c i ) conditional probabilities that a given feature value x j belongs to class c i from a training dataset. By assuming a Gaussian distribution of the features, the conditional probabilities may be obtained using the values of mean and standard deviation of the labeled training data for each class as follows: P( x j | c i ( μ i,j , σ i,j ))= 1 σ i,j 2π − − √ ⋅ e − ( x j − μ i,j ) 2 2 σ i,j 2 . (3) View Source Once the posterior probabilities are calculated for all of the classes, the observation x t will be classified into the class that has the highest posterior probability. Equation (2) can be simplified by omitting the normalization factor in the denominator, as only the index of the maximum a posteriori (MAP) class is important for the classification P( c i | x t )∝ c predicted = P( c i )⋅ ∏ j=1 m P( x j | c i ) argmax{P( C ¯ ¯ ¯ ¯ | x t ¯ ¯ ¯ ¯ ¯ )}. (4) (5) View Source For further reference regarding GNB classifiers, readers are guided to, for example, [28]–[30]. C. PCA and Two-Stage Bayesian Sensor Fusion The proposed two-stage Bayesian sensor fusion method combined with PCA is an extension of a previous work [26]. In this paper, the algorithm is updated to include a preprocessing PCA step. PCA was selected as it is able to mitigate feature correlation that can bias the likelihood calculations. It is a linear method that yields a reduced and uncorrelated feature set. Instead of the original features, uncorrelated principal components are fused using a GNB classifier. The number of principal components considered for each signal type is calculated using the validation set in a way that the performance of the algorithm is maximized while the false and missed alarm rates are reduced, using the detection accuracy as an optimization parameter. The method retains the structure of the global fusion stage on the decision level, as described in [26]. The advantage of applying the GNB classifier at the local stage is that there is no need to determine alarm thresholds and confidence intervals, as the GNB classifier calculates the fault class probabilities directly. D. Description of the Local Stage The proposed algorithm is suited for condition-monitoring problems where N different sensors provide measurement data for the determination of the health state of the system. For training, the algorithm requires data that has been labeled with M fault conditions. If there is a test set available, the data has to be split into two separate datasets for training: the training set and the validation set. The training set will be used for the training of the GNB classifiers at the local stage, whereas the validation set will produce the confusion matrices for the different sensor types at the global fusion stage. Once the data are cleaned and selected features are extracted, the features are split by sensor type. At this stage, the training set takes the form of an n × m matrix, where n is the number of observations and m is the number of features. The μ Ai,Sj means and σ Ai,Sj standard deviations are calculated for each A i feature and S j sensor type. A normalization step transforms the features such that the means are 0 and the standard deviations are 1. PCA calculates the S C Sj scores and L O Sj loadings for each sensor type. The scores, which might also be considered as the new “features,” are uncorrelated. The L O Sj loadings are calculated using the whole training set containing both healthy and faulty data. To calculate the conditional probabilities of the GNB according to (3), the μ Ai,Sj,Ck means and σ Ai,Sj,Ck standard deviations of the principal components are calculated for each C k fault type in the labeled data. Next, the validation set is used in both to find the optimal number of principal components and to calculate the confusion matrices using μ Ai,Sj , σ Ai,Sj , μ Ai,Sj,Ck , σ Ai,Sj,Ck , and L O Sj from the training data. The features in the validation set are normalized using μ Ai,Sj and σ Ai,Sj . The normalized features are transformed to the principal components space using the L O Sj loadings. To find the number of principal components for each S j sensor type, an iterative step is considered as follows. The first i principal components are used as features, calculating the posterior probabilities and class predictions for each observation in the validation set using (3)–(5). Count the correct predictions and save it for i. Once the iteration has finished, the value of i resulting in the highest number of correct predictions is chosen for the number of principal components used to calculate the predictions for each observation in the validation set. E. Description of the Global Stage The prediction counts for each fault type are organized in an M × M global confusion matrix G Si for each sensor type S i where the rows represent the actual condition, the columns represent the diagnosed condition, and the prediction counts by rows are divided by the total number of actual conditions for the fault type. The matrix elements can be interpreted as P( F i | F j ) conditional probabilities; given that the algorithm predicted F j , what is the probability that the actual fault condition is F i ? The P( F i | F i ) probabilities, located along the diagonal of the confusion matrix for each sensor type, represent the probability that the sensor diagnosed the corresponding fault correctly G S i = ⎡ ⎣ ⎢ P( F 1 | F 1 ) … P( F M | F 1 ) … P( F i | F i ) … P( F 1 | F M ) … P( F M | F M ) ⎤ ⎦ ⎥ . (6) View Source The test set is separate from the training set and is divided by sensor type into N sets, with observations in rows and features in columns. The test set is normalized and the GNB classifier is calculated with the optimized number of principal components. The fault class predictions of the GNB classifier for an observation are fused by (7) and (8) using the appropriate columns from the global confusion matrices for each sensor type. P( c i ) represents a priori knowledge; if no prior distribution is available, a uniform distribution is supposed. If the fault class predicted by S1 is F i and fault class predicted by S M is F j , then columns have to be selected in the following way from the corresponding confusion matrices: G S 1, F i = c predicted = ⎡ ⎣ ⎢ P( F 1 | F i ) … P( F M | F i ) ⎤ ⎦ ⎥ ,…, G S M , F j = ⎡ ⎣ ⎢ P( F 1 | F j ) … P( F M | F j ) ⎤ ⎦ ⎥ argmax{P( c i )⋅ ∏ i=1,j=1 M,N G S i, F j }. (7) (8) View Source For each fault class, the output of the global fusion step is a posterior probability giving the likelihood of that fault class being present in the system. For the purposes of evaluating the performance of the algorithm, we consider the final prediction as being the fault class that has the highest posterior probability after the global fusion step (8). F. Testing an Observation The overall flow diagram of the proposed two-stage Bayesian sensor fusion method for testing an observation is shown in Fig. 1. At the local stage, each type of sensor is handled separately. For a given sensor type, features are fused in order to obtain a prediction of the most likely health state of the system, given the data recorded by that sensor type. At the global stage, the predictions of the most likely health state for each sensor type are fused using the global confusion matrix to create the global diagnosis result. Fig. 1. Structure of the PCA and two-stage Bayesian algorithm. Show All SECTION III. Experimental Data The measurement set up for the experiment is shown in Fig. 2. Experimental data were collected from three identical induction motors, differing only in terms of health state: one motor was healthy, one had two broken rotor bars, and one had an outer raceway fault in a bearing. It was also possible to seed stator faults into the nominally healthy motor, as described in [31]. The test motors were 0.8 kW, four-pole SZJKe 14a induction motors manufactured by TAMEL with a nominal rotor speed of 1400 r/min. The nominal values of voltage, current, rated torque, and power factor for these motors were 380 V, 2.2 A, 5.45 N·m, and 0.74, respectively. The motor had a Y winding configuration with 4 coils per phase, 22 rotor bars, and 24 stator slots. The rotor inertia was 0.0025 kg·m2 and the motor bearings were SKF type 6304 ZZ CXSQ. An eddy current brake was used to load the motor. The measurements were conducted at steady-state operation under different loading conditions. For each fault case between three and five loading conditions were tested, resulting in stator currents of 68%, 81%, 90%, 100%, and 113% of nominal values. Measurements were recorded both with and without background noise generated by a separate shaker. Datasets for eight different health conditions were recorded, denoted as F0–F7, as follows: F0—Healthy motor; F1—Stator fault: Phase one bypassed in the first phase; F2—Stator fault: Phase one bypassed in half of the first phase; F3—Stator fault: Phase–phase short circuit; F4—Stator fault: Phase–phase short circuit with an offset point; F5—Stator fault: Break of half of the phase one; F6—Rotor fault: Two broken rotor bars; F7—Bearing fault: Outer raceway defect. Fig. 2. Schematic of the experimental system. Show All The tested motor was rewound in such a way that instead of coils for a given phase being directly connected to one another, the individual coils were connected to a switchboard allowing the winding configuration to be quickly changed. Furthermore, in six coils, special taps were created in order to allow different short circuits to be seeded. Such a configuration allows various stator faults to be seeded, as was investigated in [29] for the same SZJKe 14a induction motor. For F1 and F2, the first phase was bypassed by a 15 Ω resistance causing a short circuit in the first phase winding. For F3 and F4, a short circuit of two stator phases in the taps connected in the middle of the first coils was seeded by adding a 115 Ω resistance. In the case of F5, part of the coil was not connected causing asymmetry in the winding, so that the current did not flow through a part of the winding. The two broken rotor bars (F6) were located next to one another. The bearing fault (F7) was caused by an incision through the outer ring of the bearing. Acoustic, electric, and vibration signals were collected using five different sensor types. Three G.R.A.S. 46AE microphones were used to measure the sound pressure levels. A Model USP regular three-dimensional Sound Intensity Microflown probe was also used to collect acoustic signals from the motors. The probe provided four measurement signals, three particle velocity signals in three orthogonal directions and a sound pressure signal. The vibration signals were measured by a three-axis PCB ICP accelerometer Model No. 356B18 and a one-axis PCB ICP accelerometer Model No. 353B32, providing four signals in total in unit g. The three phase voltages were measured by LV 25-P voltage transducers providing signals directly for analysis of voltage characteristics. The motor currents were measured by LTS-6NP and LEM HY 5-P current transducers. The following signals were collected using a 16-channel LMS Scada Mobile System: 4 microflown signals, 3 microphone signals, 2 current signals, 4 vibration signals, and 3 voltage signals. Data were collected with a 51.2-kHz sampling rate to capture all frequencies of interest with 30 s of data being recorded for each configuration to capture a sufficiently long steady-state periods for analysis. 58 datasets were obtained: one for each tested loading condition, both with and without additional background noise. The same background noise was applied over the tests. The microflown axis X probe has measured an average 47.26 m/s particle velocity with no noise, whereas it has measured an average 88.69 m/s particle velocity with noise for the healthy motor under nominal load. SECTION IV. Implementation of the Method The 58 datasets were split into 0.5-s observations resulting in 60 observations for 1 dataset and 3480 observations in total. For each signal, and for each 0.5-s observation, the following time-domain features were extracted: root mean square (rms), skewness, kurtosis, maximum peak, peak-to-peak, and crest factor. Features were also extracted from both the amplitude spectrum and the envelope spectrum of the signal: the frequency center, spectrum area, the amplitude of the components at the first two harmonics of the supply frequency (50, 100), the first three harmonics of the rotation speed (1×, 2×, 3×), the amplitude ratios (2×/1×, 3×/1×), and the amplitude at the sidebands of the supply frequency (50 Hz ± 2 × slip, 50 Hz ± rotation speed). The 0.5-s window length provided a 2-Hz spectral resolution. While no windowing functions were applied in the calculation of the spectra, edge effects were found to be minimal. In total, 30 features were extracted for the 16 signals, resulting in 480 features in total. These time- and frequency-domain features are standard metrics, commonly used for the condition monitoring of induction motors [11], [21], [32]. It should be noted that for all signal types, all of the above-mentioned feature types were extracted. No additional feature selection approaches were applied. Fig. 3 shows the relative rms values of five different signal types extracted from 0.5-s measurement windows, for all observations through the 58 datasets. It may be observed that the sensors reacted to the fault modes and loading conditions in different ways. For example, the rms current is increased for stator fault modes F3 and F4, whereas the rms vibration did not significantly react. Conversely, in the case of the rotor fault F6, the vibration signal exhibited increased rms values, whereas the rms current did not show significant increases. This further illustrates that different faults are more easily diagnosed by different sensors. The 480 features of the 3480 observations were grouped by signal types into five groups, namely vibration features, current features, microflown features, microphone features, and voltage features. The data were then split into a training set, a validation set, and a test set, in the same way for the five signal types. The division is described in Section V. The training sets were used to train the local stage, the validation sets were used to calculate the global confusion matrices for the global fusion stage, and finally, the test sets were used to test the performance of the algorithm. All analyses were conducted in MATLAB. Fig. 3. Relative rms values of 5 different signal types extracted from 0.5-s measurement windows, for all observations through the 58 datasets. Show All SECTION V. Results In order to illustrate the performance of the described algorithm with respect to different loading and environmental noise conditions, the experimental data were divided into different training, validation, and test sets. In Test Case A, a random split was applied. In Test Cases B and C, eight entire datasets (one from each fault case) were included in the test set with no datasets from experiments conducted at this loading condition being considered in the training or validation sets. In Test Case B, the lowest load datasets with no background noise are the test set. In Test Case D, the highest load datasets with background noise are the test set. The aim of testing different divisions for testing, validation, and training is to observe the performance of the algorithm under different operating conditions, particularly under loading conditions that were not considered during model training. A. Test Case A: Random Split Test Case A was used to evaluate the overall performance of the algorithm. The total 3480 observations were randomly split into training set, validation set, and test set with a respective ratio of 60-20-20%. The random split was applied 100 times and the averaged results are shown in Table I. The columns represent the conditions diagnosed by the algorithm, whereas the rows represent the actual fault conditions of the motors. The healthy motor was correctly diagnosed in 94% of the cases with a 6% false alarm rate in case of F2 stator fault. Missed alarms are present for F2, however it is only 2%. F2 is the least severe fault among the seven seeded faults, which explains this behavior. The successful detection rate is above 98% for all fault cases, with 100% success rate for F1, F5, F6, and F7. Among the stator faults, the following scenario can be observed: F3 and F4 are sometimes misdiagnosed as each other, as they are the variations of the same fault: F3 is the phase–phase short-circuit, whereas F4 is the phase–phase short circuit with an offset point. To give an overall measure of the test accuracy, the F1 score is calculated to be 99.32%. TABLE I Test Case A: Random Split B. Test Case B: Lowest Load and No Noise In Test Case B, the test set was formed of data taken from the lowest loading conditions, with no datasets from experiments conducted at this loading condition being considered in the training or validation sets. The aim was to test the performance of the algorithm under load conditions that are lower than those contained within the training and validation sets. The results are shown in Table II. The accuracy of the algorithm was 100% when diagnosing the healthy condition (F0); there were no false alarms. When diagnosing broken rotor bars and bearing faults (F6 and F7), the algorithm performed with 100% accuracy. However, the performance for the stator faults needs further analysis: while faults F1 and F3 are diagnosed with the success rates of 97% and 100%, faults F2, F4, and F5 were identified less reliably. The algorithm was able to diagnose the F2 stator fault in only 57% of the cases. In 43% of the cases, the algorithm misdiagnosed F2, either as healthy or as the other similar stator faults F1 and F5. This was because F2, as the least severe fault, was the most difficult to diagnose. The algorithm was also unable to distinguish between fault modes F4 and F5, in 20% and 13% of the cases, respectively. F5 was also mistakenly diagnosed as other stator faults phase one bypassed in 10% of the cases. This result indicates that in the case of loading conditions lower than those seen in the training datasets, the algorithm can accurately determine the type of fault, however it is unable to accurately ascertain the severity of the fault. TABLE II Test Case B: Lowest Load and No Noise C. Test Case C: Highest Load With Noise Test Case C used datasets recorded for the highest loading conditions with background noise as the test set, with no data from this loading condition being considered in the training. This test case investigates the performance of the algorithm for loading conditions exceeding those considered in the training set and for unique environmental conditions, specifically when the background noise is at increased levels. The results are shown in Table III. The correct diagnosis of the healthy motor was 100%, as well as the diagnosis for F1, F4, F5, F6, and F7. In case of stator fault F2, there is a 2% missed alarm rate. In case of stator fault F3, the algorithm misdiagnoses F3 as F4 in 8% of the cases. These phenomena are similar to those observed in Test Case A: the stator faults are less severe and less easy to diagnose. Due to fault similarities, the algorithm can sometimes misdiagnose stator fault severities or confuse them with the healthy motor. The F1 score is 99.88%, which is even higher than the random split test case. TABLE III Test Case C: Highest Load With Noise D. Principal Components The number of principal components is shown in Table IV for each signal type together with the variance explained to complement the results in the above-presented test cases. In case of the random split in Test Case A, the variance explained by the chosen principal components is always above 90%. In case of Test Case B and C, the number of chosen principal components is less than for Test Case A. This is due to the specific loading and noise conditions chosen for the test sets. TABLE IV Number of Principal Components and Variance Explained The first few principal components have been analyzed for all signal types to determine if there is any feature that dominates the principal component coefficients in the loading matrix. It was found that there was no single feature that would stand out for any signal type, therefore the importance of PCA for correlation reduction is further confirmed. Fig. 4 shows the first principal components of the five signal types, for all observations through the 58 datasets. The principal component values were obtained from the normalized feature values as described in Section II-D. In comparison to Fig. 3, where the rms of the five signal types are shown, it may be observed that the load dependence of the signals is less evident in the principal components. This further justifies the application of PCA for problems where the analyzed problem contains data from several loading conditions. Fig. 4. First principal components of the 5 different signal types, for all observations through the 58 datasets, the rms of the current is given as reference for the loading conditions. Show All Fig. 5 presents the histograms and underlying Gaussian distributions of the first principal component of the vibration signal by fault conditions. The distributions for each fault types have distinct mean and variance values and are not significantly different from Gaussian distributions. It can be observed that F6 and F7 are the most distinguishable from F0, whereas the other stator faults have overlaps with F0. It should be noted that F0 shows the evidence of multimodal behavior. This is due to the additional background noise incorporated to investigate the influence of different environmental conditions on the accuracy of diagnosis. However, as shown in Sections V-A–V-C, this noise did not significantly influence the resulting likelihood calculations. Fig. 5. Histograms and underlying normal distributions of the first principal component of the vibration signal by fault conditions. Show All E. Single-Stage Data Fusion A comparison of the performance of the two-stage approach relative to a more standard single-stage approach, where sensors are not separated according to type, but instead all fused in a single stage, was performed. The total 3480 observations were randomly split according to the conventional 70–30% partition to training set and test set. The random split was applied 100 times to a single-stage approach and the averaged results are shown in Table V. The results show that the performance of the single-stage algorithm significantly drops compared to the results of the two-stage method shown in Table I. The most significant difference appears in the reduced successful detection of the healthy motor, with the single-stage approach yielding false alarms in 91% of test cases. The F1 score is 92%. TABLE V Single-Stage Data Fusion F. Comparison of Results With SVM To provide a quantitative comparison with another classifier, the proposed PCA and two-stage Bayesian method is compared with the well-known SVM. Test Case A, B, and C are repeated using the default fitcecoc MATLAB implementation of the SVM for multiclass problems with one against one classification strategy and a linear kernel function. The F1 scores are compared. Similarly to the investigation described in Section V-F, the SVM was applied in a single stage. A 70-30% data split was applied and repeated 100 times resulting in a 99.96% F1 score for Test Case A. This result is 0.64% better than that of the proposed method. For Test Case B, the F1 score for the SVM was 96.15%, which is 1.84% below than what was achieved with the newly proposed method. For Test Case C, the F1 score for the SVM was 97.8%, which is 2.08% below than what was achieved with the newly proposed method. While the performance of the two approaches is comparable, an advantage of PCA and two-stage Bayesian method lies in its transparency and modularity. Furthermore, the method also provided a marginally improved performance in the case of environmental and loading conditions not contained in the training set, as shown in Test Cases B and C. G. Signal Types Separately Versus Two-Stage Fusion Table VI shows the performance of only considering a single-stage fusion of features from a single-signal type, for the random split Test Case A. For comparison, the equivalent performance from the two-stage approach, which fuses the data from all sensors types in the global fusion stage, is also given. Results are given in terms of proportion of correct diagnoses, which are equivalent to the values on the diagonal of the previously presented results (see Tables I–III). It is evident that the two-stage data fusion of multiple signal types outperforms the equivalent results when only considering a single-signal type. This is due to the fact that the different sensor types have different strengths and weaknesses. For example, it may be observed that the analysis based only on vibration signals accurately diagnosed the mechanical bearing fault F7 in 100% of test cases, but was only able to diagnose an electrical stator fault, such as F1, in 92% of cases. In contrast, when only current signals were considered, stator fault F1 was diagnosed correctly in 98% of cases, but bearing fault F7 was only diagnosed correctly in 96% of cases. When the two signals are fused, the conditional probabilities in the global confusion matrix effectively gives greater weight to vibration signals and less weight to current signals when diagnosing mechanical faults and vice versa in the case of diagnosing electrical faults. This leverages the strengths of each sensor type for fault monitoring and minimizes the impact of the weaknesses. TABLE VI Proportion of Correct Diagnoses for Each Fault Type When Considering Each Signal Individually and After Two-Stage Fusion SECTION VI. Discussion In this section, the results and the structure of the algorithm are discussed further, highlighting the observed strengths and weaknesses of the algorithm. A. Implementation and Constraints The training of the method takes place offline using historical datasets containing healthy and faulty data. Once the model is trained, diagnosis can be performed either online or offline. By applying a sliding window of the same size as used for training, the new sensor measurements can be fed into the two-stage Bayesian classifier online after the feature extraction and PCA steps have been performed. The width of the window could be different based on the nature of the monitored system, the extracted features, and the data available. The computational complexity of the classifier is proportional to the number of principal components retained and the number of fault modes monitored. The computational complexity of the feature extraction and PCA step depends on the number of features extracted and the size of the sliding window. For a better representation of the original feature space, nonlinear multivariate methods, such as kernel PCA [33], could be explored in the future instead of the currently used linear PCA. While it falls out of the scope of this paper, it should also be noted that the features used as inputs to the method may also be refined according to state of the art signal processing and feature extraction methods so that they may better discriminate between different health states. Thus, the accuracy and reliability of the approach would likely be improved further. In (4) and (8), the likelihoods might result in very small values if the number of features m, the number of sensors N, or the number of fault cases M is large. To avoid numerical problems, a logarithmic formulation might be considered. B. Algorithm Validation In Section V, three different algorithm validation test cases were presented by splitting the data into different training sets, test sets, and validation sets. It has been shown that for small datasets, the simple split-sample estimates can be biased and cross validation is more suitable for the prediction assessment of the classifiers [34]. In the case of a two-stage method, cross validation is unfeasible due to the increase in the number of computational steps associated with the addition of the global fusion stage and the use of a validation set. Specifically, relative to a simple single-stage fusion, when implementing cross validation on a two-stage approach, the method becomes n2 more computationally expensive, where n is the number of the observations, as both the local and the global stages have to be trained using separate training sets. In this paper, a pragmatic split-sample method was considered. It is also foreseen that such an approach would be applicable for applications of the method with larger volumes of datasets available. In the future, increases in computing power might also allow the cross-validation approach to be feasibly applied. C. Naïve Bayes Classifier Using Kernel Density Estimate (KDE) The GNB classifier is a parametric method that assumes a normal distribution of the observation variables. The more the distribution of the observation variables differs from the normal distribution, the less accurate the method is. One possible way to eliminate this Gaussian assumption is to use a naïve Bayes classifier with KDE, where the probability density function of the features are estimated using a nonparametric kernel distribution. Such an approach can be used when there is no prior knowledge regarding the distribution of the data, no assumptions are made, or a parametric distribution cannot describe the data. Tests conducted using such a naïve Bayes classifier with KDE, with the same random split as described in Test Case A, yielded comparable results to the GNB classifier. The naïve Bayes classifier with KDE resulted in correct classification rates in the ±2% range compared to the results in Table I, whereas the F1 score is 99.64%, which is 0.32% better compared to the results in Table I. However, when applying KDE, the computation time was two magnitudes greater for the local stage than for the case of the GNB classifier. It took 4.277 s for the original method to train the local stage and obtain the confusion matrixes for the vibration signals, whereas the same computation took 351.78 s with KDE. The processing hardware was an Intel Core i5-4300U, 1.9 GHz. D. Two-Stage Data Fusion Without PCA While not the primary focus of this paper, it is worth noting that an investigation into the importance of incorporating the PCA step into the algorithm was also performed. It was observed that when the PCA step was omitted from the algorithm, all test cases, including fault cases, were subsequently diagnosed as being healthy (F0). This was due to the load dependence of the features. This observation indicates that a PCA step, or similar, ensures that the algorithm is robust against changing loading and environmental conditions. E. Advantages of the Method The preceding sections provide quantifiable comparisons of the performance of the algorithm when including the novel steps of applying a GNB classifier and splitting the approach into two stages, relative to the cases when the steps are omitted. Due to the multitude of ways of properly designing and tuning various algorithms, it is unfeasible to perform similarly rigorous quantitative comparisons to benchmark the method relative to other data-driven fault detection methods. However, qualitative comparisons, which can guide design decisions at an early stage of the analytics development process, can be made. The main advantages of the proposed method are its transparency and modularity. In contrast to many other data-driven fault diagnosis methods, such as SVMs or neural networks, the decision-making process of the algorithm is easily back traceable from the global predictions to the inputs of the local stage to identify how the different sensors reacted to a fault. Such transparency is important for cases where the algorithm will be used to support maintenance decisions. While in this paper, only MAP probabilities were considered, in practice, the Bayesian sensor fusion approach allows the results to be presented in the form of likelihoods, showing the probability of each fault condition being present. Again, this additional insight can support maintenance decisions. The modularity of the approach, achieved by splitting the data fusion into two stages, also offers further advantages when considering practical implementation. In the case of a sensor being removed from a system, there is no need to retrain the whole model, as the removed sensor type can easily be omitted from the decision-level fusion. This is not possible for other fault diagnosis methods that only consider feature-level data fusion. Similarly, additional sensor types may be readily incorporated into the analysis with limited requirements for retraining. Recently, a trend of monitoring the health of components via signals recorded from connected elements, for example, monitoring gearboxes and bearings via electrical signals recorded from connected electrical motors, has emerged [35], [36]. Such emerging methods could also easily be incorporated into the algorithm, serving as an additional source of information for further improving the accuracy of diagnosis. SECTION VII. Conclusion In this paper, the performance of a newly proposed PCA and two-stage Bayesian sensor fusion method was evaluated under various test scenarios. The algorithm was shown to be able to diagnose stator faults, broken rotor bar faults, and bearing faults in induction motors, with low false and missed alarm rates. The algorithm also proved its ability to diagnose faults under different loading and environmental conditions. In addition to discussing the several advantages of the presented method, the limitations of the method were also highlighted. For example, it was shown that the method is capable of correctly distinguishing different types of fault, however, to consistently distinguish between different fault severities, adequate training sets are required at comparable loading conditions. In the future, the algorithm can potentially be extended so that it may be used not only with steady-state signals. Additionally, the performance of the method may be refined by further tailoring the extracted features to the monitored system. It was shown that by fusing data recorded from different sensor types, the proposed method is capable of diagnosing both mechanical and electrical faults. In the future, the algorithm should also be tested for other fault detection and condition-monitoring scenarios, for example, in process-monitoring applications. ACKNOWLEDGMENT The authors would like to thank M. Sułowicz, K. Weinreb, J. Petryna, and A. Dziechciarz, from Cracow University of Technology, and W. Batko, M. Kłaczyński, J. Wierzbicki, T. Wszołek, and J. Frączek, from AGH University of Science and Technology, for carrying out the measurement campaign. Authors Figures References Citations Keywords Metrics More Like This Fault detection and diagnosis using Principal Component Analysis of vibration data from a reciprocating compressor Proceedings of 2012 UKACC International Conference on Control Published: 2012 Rotating machine fault detection using principal component analysis of vibration signal 2016 IEEE AUTOTESTCON Published: 2016 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.

Paper 10:
- APA Citation: Lonea, A. M., Popescu, D. E., & Tianfield, H. (2013). Detecting DDoS Attacks in Cloud Computing Environment. INT J COMPUT COMMUN, 8(1), 70-78.
  Main Objective: To detect and analyze Distributed Denial of Service (DDoS) attacks in cloud computing environments using Dempster-Shafer Theory and Fault-Tree Analysis.
  Study Location: Unspecified
  Data Sources: Alerts from VM-based Intrusion Detection Systems
  Technologies Used: Dempster-Shafer Theory, Fault-Tree Analysis, Intrusion Detection Systems
  Key Findings: The proposed solution can efficiently detect and analyze DDoS attacks by processing data from multiple sensors and employing DST to handle varying data quality and formats.
  Extract 1: The paper applies the particular case of DST, i.e., the DST operations in 3-valued logic using the fault-tree analysis (FTA), adopted by Guth (1991) and also used in Popescu, et al. (2010).
  Extract 2: Thus, if a standard state space Ω is (True, False), then 2Ω should have 4 elements: { ϕ,True, False, (True, False) }. The (True, False) element describes the imprecision component introduced by DST, which refers to the fact of being either true or false, but not both.
  Limitations: The study is limited by the fact that it has not been implemented and tested in a real-world cloud computing environment.
  Relevance Evaluation: The paper is highly relevant to the specific point under consideration, which focuses on adaptive data preprocessing methods for dealing with varying data quality and formats from heterogeneous data sources. The proposed solution employs DST to process data from multiple VM-based IDS, enabling the efficient handling of varying data quality and formats. This approach enhances the accuracy and effectiveness of DDoS attack detection and analysis in cloud computing environments.
  Relevance Score: 0.9
  Inline Citation: (Lonea et al., 2013)
  Explanation: This paper presents a novel approach to detect and analyze Distributed Denial of Service (DDoS) attacks in cloud computing environments. The proposed solution leverages Dempster-Shafer Theory (DST) operations in 3-valued logic and Fault-Tree Analysis (FTA) for each virtual machine (VM)-based Intrusion Detection System (IDS). The solution processes data from multiple sensors to detect and analyze DDoS attacks, addressing specific point 4.1.

 Full Text: >
INT J COMPUT COMMUN, ISSN 1841-9836
8(1):70-78, February, 2013.
Detecting DDoS Attacks in Cloud Computing Environment
A.M. Lonea, D.E. Popescu, H. Tianﬁeld
Alina Madalina Lonea
"Politehnica" University of Timisoara,
Faculty of Automation and Computers
B-dul Vasile Parvan, nr. 2, 300223, Timisoara, Romania
E-mail: madalina _ lonea@yahoo.com
Daniela Elena Popescu
University of Oradea, Faculty of Electrical Eng. and Information Tech.
Universitatii street, nr. 1, 410087, Oradea, Romania
E-mail: depopescu@uoradea.ro
Huaglory Tianﬁeld
School of Engineering and Built Environment,
Glasgow Caledonian University
Cowcaddens Road, Glasgow G4 0BA, United Kingdom
E-mail: h.tianﬁeld@gcu.ac.uk
Abstract:
This paper is focused on detecting and analyzing the Distributed Denial of Service
(DDoS) attacks in cloud computing environments. This type of attacks is often the
source of cloud services disruptions. Our solution is to combine the evidences obtained
from Intrusion Detection Systems (IDSs) deployed in the virtual machines (VMs) of
the cloud systems with a data fusion methodology in the front-end. Speciﬁcally, when
the attacks appear, the VM-based IDS will yield alerts, which will be stored into the
Mysql database placed within the Cloud Fusion Unit (CFU) of the front-end server.
We propose a quantitative solution for analyzing alerts generated by the IDSs, using
the Dempster-Shafer theory (DST) operations in 3-valued logic and the fault-tree
analysis (FTA) for the mentioned ﬂooding attacks. At the last step, our solution uses
the Dempsters combination rule to fuse evidence from multiple independent sources.
Keywords: cloud computing, cloud security, Distributed Denial of Service (DDoS)
attacks, Intrusion Detection Systems, data fusion, Dempster-Shafer theory.
1
Introduction
Cloud computing technology is in continuous development and with numerous challenges
regarding security. In this context, one of the main concerns for cloud computing is represented by
the trustworthiness of cloud services. This problem requires prompt resolution because otherwise
organizations adopting cloud services would be exposed to increased expenditures while at a
greater risk.
A survey conducted by International Data Corporation (IDC) in August 2008
conﬁrms that security is the major barrier for the cloud users.
There are two things that cloud service providers should guarantee all the time: connectivity
and availability, and if there are not met, the entire organizations will suﬀer high costs [1].
This paper is focused on detecting and analyzing Distributed Denial of Service (DDoS) attacks
in cloud computing environment.
This type of attacks is often the source of cloud services
disruptions. One of the eﬃcient methods for detecting DDoS is to use the Intrusion Detection
Systems (IDS), in order to assure usable cloud computing services [2]. However, IDS sensors
have the limitations that they yield massive amount of alerts and produce high false positive
rates and false negative rates [3].
Copyright c⃝ 2006-2013 by CCC Publications
Detecting DDoS Attacks in Cloud Computing Environment
71
With regards to these IDS issues, our proposed solution aims to detect and analyze Dis-
tributed Denial of Service (DDoS) attacks in cloud computing environments, using Dempster-
Shafer Theory (DST) operations in 3-valued logic and Fault-Tree Analysis (FTA) for each VM-
based Intrusion Detection System (IDS). The basic idea is to obtain information from multiple
sensors, which are deployed and conﬁgured in each virtual machine (VM). The obtained infor-
mation is integrated in a data fusion unit, which takes the alerts from multiple heterogeneous
sources and combines them using the Dempster’s combination rule. Our approach quantitatively
represents the imprecision and eﬃciently utilizes it in IDS to reduce the false alarm rates.
Speciﬁcally, our solution combines the evidences obtained from Intrusion Detection Systems
(IDSs) deployed in the virtual machines (VMs) of the cloud system with a data fusion method-
ology within the front-end.
Our proposed solution can also solve the problem of analysing the logs generated by sensors,
which seems to be a big issue [4].
The remainder of this paper is organized as follows: section 2 introduces Dempster-Shafer
Theory. Section 3 presents the related work of IDS in Cloud Computing and the related work of
IDS using data fusion. Section 4 introduces the proposed solution of detecting DDoS attacks in
Cloud Computing. Finally, in section 5 the paper presents the concluding remarks.
2
Dempster-Shafer Theory (DST)
Dempster-Shafer Theory is established by two persons: Arthur Dempster, who introduced it
in the 1960’s and Glenn Shafer, who developed it in the 1970’s [5].
As an extension of Bayesian inference, Dempster-Shafer Theory (DST) of Evidence is a
powerful method in statistical inference, diagnostics, risk analysis and decision analysis. While
in the Bayesian method probabilities are assigned only for single elements of the state space
(Ω),in DST probabilities are assigned on mutually exclusive elements of the power sets of possible
states [6], [7].
According to DST method, for a given state space (Ω) the probability (called mass) is allo-
cated for the set of all possible subsets of Ω, namely 2Ω elements.
Consequently, the state space (Ω) is also called frame of discernment, whereas the assignment
procedure of probabilities is called basic probability assignment (bpa) [6], [7], [8].
We will apply the particular case of DST, i.e., the DST operations in 3-valued logic using the
fault-tree analysis (FTA), adopted by Guth (1991) and also used in Popescu, et al. (2010).
Thus, if a standard state space Ω is (True, False), then 2Ω should have 4 elements: { ϕ,
True, False, (True, False) }. The (True, False) element describes the imprecision component
introduced by DST, which refers to the fact of being either true or false, but not both. DST is a
useful method for fault-tree analysts in quantitatively representing the imprecision [8]. Another
advantage of DST is it can eﬃciently be utilized in IDS to reduce the false alarm rates by the
representation of ignorance [6], [7], [10].
For the reason that in DST the [sum of all masses] = 1 and m(ϕ) = 0,we have the following
relation:
m(True) + m(False) + m(True, False) = 1
(1)
In order to analyze the results of each sensor we’ll use the fault tree analysis, which can be
realized by boolean OR gate. Table 1 describes the Boolean truth table for the OR gate.
From Table 1 we have:
m(A) = (a1, a2, a3) = {m(T), m(F), m(T, F)}
(2)
72
A.M. Lonea, D.E. Popescu, H. Tianﬁeld
Table 1: BOOLEAN TRUTH TABLE FOR THE OR GATE
b1
b2
b3
∨
T
F
(T,F)
a1
T
T
T
T
a2
F
T
F
(T,F)
a3
(T,F)
T
(T,F)
(T,F)
m(B) = (b1, b2, b3) = {m(T), m(F), m(T, F)}
(3)
⇒ m(A ∨ B) = (a1b1 + a1b2 + a1b3 + a2b1 + a3b1; a2b2; a2b3 + a3b2 + a3b3)
(4)
m(A ∨ B) = (a1 + a2b1 + a3b1; a2b2; a2b3 + a3b2 + a3b3)
(5)
At the last step, our solution applies the Dempster’s combination rule, which allows fusing
evidences from multiple independent sources using a conjunctive operation (AND) between two
bpa’s m1 and m2 , called the joint m12 [11]:
m12(A) =
∑
B ∩ C=A m1(B)m2(C)
1 − K
,
(6)
when : A ̸= ϕ
m12(ϕ) = 0
and K = ∑
B ∩ C=ϕ m1(B)m2(C)
The factor 1-K, called normalization factor, is constructive for entirely avoiding the conﬂict
evidence.
Data fusion is also applied in real world examples: robotics, manufacturing, remote sensing
and medical diagnosis, as well in military threat assessment and weather forecast systems [12].
Sentz and Ferson (2002) demonstrated in their study that Dempster’s combination rule is
suitable for the case that the sources of evidences are reliable and a minimal conﬂict or irrelevant
conﬂict is generated.
3
Related Work
3.1
Intrusion Detection Systems (IDS) in Cloud Computing
One of the IDS strategies proved reliable in cloud computing environments is its applicability
to each virtual machine. This is the method we’ll choose for our proposed solution. Mazzariello,
et al. (2010) presented and evaluated this method in comparison with another IDS deployment
strategy, which uses single IDS near the cluster controller. IDS applied to each virtual machine
in cloud computing platform eliminates the overloading problem, because in a way the network
traﬃc is split to all IDSs. Thus, applying IDS to each virtual machine gets rid of the issue of the
IDS strategy near the cluster controller, which tends to be overloaded because of its necessity to
monitor all the supposed traﬃc from the cloud computing infrastructure. Another advantage of
this strategy as described by Roschke, et al. (2009) is the beneﬁt of reducing the impact of the
possible attacks by the IDS Sensor VMs.
However, the limitation of IDS strategy applied to each virtual machine is the missing of the
correlation phase, which is suggested in the future work by Mazzariello, et al. (2010).
Detecting DDoS Attacks in Cloud Computing Environment
73
The correlation phase will be included in our proposed solution, because beside the IDS for
each virtual machine, our IDS cloud topology will include a Cloud Fusion Unit (CFU) on the
front-end, with the purpose of obtaining and controlling the alerts received from the IDS sensor
VMs as presented by Roschke, et al. (2009) in their theoretical IDS architecture for cloud, which
utilizing an IDS Management Unit.
Compared to Roschke, et al.
(2009) who suggested the utilization of IDMEF (Intrusion
Detection Message Exchange) standard, a useful component for storage and exchange of the
alerts from the management unit, the alerts in our proposed solution will be stored into the
Mysql database of Cloud Fusion Unit. The Cloud Fusion Unit will add the capacity to analyze
the results using the Dempster-Shafer theory (DST) of evidence in 3-valued logic and the Fault-
Tree Analysis for the IDS of each virtual machine and at the end the results of the sensors will
be fused using Dempster’s combination rule.
A similar method of using a IDS Management Unit is proposed in Dhage, et al. (2011),
who presented a theoretical model of an IDS model in cloud computing, by using a single IDS
controller, which creates a single mini IDS instance for each user. This IDS instance can be
used in multiple Node controllers and a node controller can contain IDS instances of multiple
users. The analysis phase of the mini IDS instance for each user takes place in the IDS controller.
Compared with Roschke, et al. (2009) where the emphasis is on how to realize the synchronization
and integration of the IDS Sensor VMs, in Dhage, et al. (2011) the focus is to provide a clear
understanding of the cardinality used in the basic architecture of IDS in cloud infrastructure.
Applying the IDS for each virtual machine is an idea suggested also by Lee, et al. (2011), who
increases the eﬀectiveness of IDS by assigning a multi-level intrusion detection system and the log
management analysis in cloud computing. In this sense the users will receive appropriate level
of security, which will be emphasized on the degree of the IDS applied to the virtual machine,
and as well on the prioritization stage of the log analysis documents. This multi-level security
model solves the issue of using eﬀective resources.
Lo, et al. (2010) proposed a cooperative IDS system for detecting the DoS attacks in Cloud
Computing networks, which has the advantage of preventing the system from single point of
failure attack, even if it is a slower IDS solution than a pure Snort based IDS. Thus, the framework
proposed by Lo, et al. (2010) is a distributed IDS system, where each IDS is composed of three
additional modules: block, communication and cooperation, which are added into the Snort IDS
system.
3.2
IDS using Dempster-Shafer theory
Dempster-Shafer Theory (DST) is an eﬀective solution for assessing the likelihood of DDoS
attacks, which was demonstrated by several research papers in the context of network intrusion
detection systems. Dissanayake (2008) presented a survey upon intrusion detection using DST.
Our study is to detect DDoS attacks in cloud computing environments. Dempster-Shafer
Theory (DST) is used to analyze the results received from each sensor (i.e. VM-based IDS).
Data used in experiments using DST vary: Yu and Frincke (2005) used DARPA DDoS
intrusion detection evaluation datasets, Chou et al.
(2008) used DARPA KDD99 intrusion
detection evaluation dataset, Chen and Aickelin (2006) used the Wisconsin Breast cancer dataset
and IRIS plant data, while others scientists generated their own data [7]. The data to be used in
our proposed solution will be generated by ourselves, by performing DDoS attacks using speciﬁc
tools against the VM-based IDS.
Siaterlis, et al. (2003) and Siaterlis and Maglaris (2005) performed a similar study of detecting
DDoS using data fusion and their ﬁeld was an operational university campus network, while in
our solution the DDoS attacks are proposed to be detected and analyzed in our private cloud
74
A.M. Lonea, D.E. Popescu, H. Tianﬁeld
computing environment.
Additionally, we consider to analyze the attacks generated against the TCP, UDP, ICMP
packets, like Siaterlis, et al.
(2003) and Siaterlis and Maglaris (2005).
However, instead of
applying DST on the state space Ω = {Normal, UDP − flood, SY N − flood, ICMP − flood},
our study uses DST operations in 3-valued logic as suggested by Guth (1991) for the same
ﬂooding attacks: TCP-ﬂood, UDP-ﬂood, ICMP-ﬂood, for each VM-based IDS. Like Siaterlis
and Maglaris (2005), Chatzigiannakis, et al., (2007) chosen the same frame of discernment, while
Hu, et al. (2006) used a state space: {Normal, TCP, UDP and ICMP}.
Furthermore, compared with the study performed by Siaterlis, at al. (2003) and Siaterlis and
Maglaris (2005), who use a minimal neural network at the sensor level, our proposed solution will
assign the probabilities using: DST in 3-valued logic, the pseudocode and the fault tree analysis.
Whilst the computational complexity of DST is increasing exponentially with the number of
elements in the frame of discernment [12], the DST 3-valued logic proposed to be used in our
research will not encounter this issue, which will meet the eﬃciency requirements in terms of
both detection rate and computation time [15].
Finally, the data fusion of the evidences obtained from sensors studied by Siaterlis and
Maglaris (2005) will be used in our study. The data fusion will be realized using the Dempster-
Shafer combination rule, which was demonstrated in Siaterlis and Maglaris (2005) for its ad-
vantages, i.e., maximization of DDoS true positive rates and minimization of the false positive
alarm rate, by combining the evidence received from sensors.
Therefore, the work of cloud
administrators will be alleviated, whereas the number of alerts will decrease.
4
Proposed Solution
In order to detect and analyze Distributed Denial of Service (DDoS) attacks in cloud com-
puting environments we propose a solution as presented in Figure 1. For illustration purpose, a
private cloud with a front-end and three nodes is set up. Whilst the detection stage is executed
within the nodes, more precisely inside the virtual machines (VMs), where the Intrusion Detec-
tion Systems (IDSs) are installed and conﬁgured; the attacks assessment phase is handled inside
the front-end server, in the Cloud Fusion Unit (CFU).
The ﬁrst step in our solution includes the deployment stage of a private cloud using Euca-
lyptus open-source version 2.0.3. The topology of the implemented private cloud is: a front-end
(with Cloud Controller, Walrus, Cluster Controller, Storage Controller) and a back-end (i.e.
three nodes). The Managed networking mode is chosen because of the advanced features that it
provides and Xen hypervisor is used for virtualization.
Then, the VM-based IDS are created, by installing and conﬁguring Snort into each VM. The
reason of using this IDS location is because the overloading problems can be avoided and the
impact of possible attacks can be reduced [2], [13].
These IDSs will yield alerts, which will be stored into the Mysql database placed within the
Cloud Fusion Unit (CFU) of the front-end server. A single database is suggested to be used
in order to reduce the risk of losing data, to maximize the resource usage inside the VMs and
to simplify the work of cloud administrator, who will have all the alerts situated in the same
place. A similar idea of obtaining and controlling the alerts received from the IDS Sensor VMs
using an IDS Management Unit was presented by Roschke, et al. (2009) as a theoretical IDS
architecture for cloud.
A similar method of using an IDS Management Unit is proposed in
Dhage, et al. (2011). However, our solution adds the capacity to analyse the results using the
Dempster-Shafer theory of evidence in 3-valued logic.
As showed in Figure 1, the Cloud Fusion Unit (CFU) comprises 3 components: Mysql
database, bpas calculation and attacks assessment.
Detecting DDoS Attacks in Cloud Computing Environment
75
Figure 1: IDS Cloud Topology
I. Mysql database
The Mysql database is introduced with the purpose of storing the alerts received from the
VM-based IDS. Furthermore, these alerts will be converted into Basic Probabilities Assignments
(bpas), which will be calculated using the pseudocode below.
II. Basic probabilities assignment (bpa’s) calculation
For calculating the basic probabilities assignment, ﬁrst we decide on the state space Ω. In this
paper we use DST operations in 3-valued logic {True, False, (True, False)} Guth (1991) for the
following ﬂooding attacks: TCP-ﬂood, UDP-ﬂood, ICMP-ﬂood, for each VM-based IDS. Thus,
the analyzed packets will be: TCP, UDP and ICMP. Further, a pseudocode for converting the
alerts received from the VM-based IDS into bpas is provided. The purpose of this pseudocode
is to obtain the following probabilities of the alerts received from each VM-based IDS:
(mUDP (T), mUDP (F), mUDP (T, F))
(mTCP (T), mTCP (F), mTCP (T, F))
(mICMP (T), mICMP (F), mICMP (T, F))
76
A.M. Lonea, D.E. Popescu, H. Tianﬁeld
Figure 2: BPA’s calculation
Pseudocode for converting the alerts into bpa’s:
For each node
Begin
For each X ∈ {UDP; TCP; ICMP}:
Begin
1: Query the alerts from the database when a X attack occurs for the speciﬁed hostname
2: Query the total number of possible X alerts for each hostname
3: Query the alerts from the database when X attack is unknown
4: Calculate the Belief (True) for X, by dividing the result obtained at step 1 with the result
obtained at step 2
5: Calculate the Belief (True, False) for X, by dividing the result obtained at step 3 with the
result obtained at step 2
6: Calculates Belief (False) for X: 1- Belief (True) - Belief (True, False)
end
end
Furthermore, after obtaining the probabilities for each attack packet (i.e. UDP, TCP, ICMP)
for each VM-based IDS, the probabilities for each VM-based IDS should be calculated following
the fault-tree as shows in Figure 2. Figure 2 reveals only the calculation of the probabilities (i.e.
mS1(T), mS1(F), mS1(T, F)) for the ﬁrst VM-based IDS.
Thus, using the DST with fault-tree analysis we can calculate the belief (Bel) and plausibility
(Pl) values for each VM-based IDS:
Bel(S1) = mS1(T)
(7)
Pl(S1) = mS1(T) + mS1(T, F)
(8)
III. Attacks assessment
The attacks assessment consists of data fusion of the evidences obtained from sensors by
using the Dempster’s combination rule, with the purpose of maximizing the DDoS true positive
rates and minimizing the false positive alarm rate. mS1,S2(T) can be calculated using Table 2
and equation (6).
Detecting DDoS Attacks in Cloud Computing Environment
77
Table 2: BOOLEAN TRUTH TABLE FOR THE OR GATE
mS1(T)
mS1(F)
mS1(T,F)
mS2(T)
mS1(T) mS2(T)
mS1(F) mS2(T)
mS1(T,F) mS2(T)
mS2(F)
mS1(T) mS2(F)
mS1(F) mS2(F)
mS1(T,F) mS2(F)
mS2(T,F)
mS1(T) mS2(T,F)
mS1(F) mS2(T,F)
mS1(T,F) mS2(T,F)
5
Conclusions
To detect and analyze Distributed Denial of Service (DDoS) attacks in cloud computing
environments we have proposed a solution using Dempster-Shafer Theory (DST) operations in
3-valued logic and the Fault-Tree Analysis (FTA) for each VM-based Intrusion Detection System
(IDS). Our solution quantitatively represents the imprecision and eﬃciently utilizes it in IDS to
reduce the false alarm rates by the representation of the ignorance.
Whilst the computational complexity of DST is increasing exponentially with the number of
elements in the frame of discernment [12], the DST 3-valued logic in our solution does not have
this issue, which meets the eﬃciency requirements in terms of both detection rate and computa-
tion time. At the same time, the usability requirement has been accomplished, because the work
of cloud administrators will be alleviated by using the Dempster rule of evidence combination
whereas the number of alerts will decrease and the conﬂict generated by the combination of
information provided by multiple sensors is entirely eliminated.
To sum up, by using DST our proposed solution has the following advantages: to accom-
modate the uncertain state, to reduce the false negative rates, to increase the detection rate, to
resolve the conﬂicts generated by the combination of information provided by multiple sensors
and to alleviate the work for cloud administrators.
Acknowledgment
This work was partially supported by the strategic grant POSDRU/88/1.5/S/50783, Project
ID50783 (2009), co-ﬁnanced by the European Social Fund - Investing in People, within the
Sectoral Operational Programme Human Resources Development 2007-2013.
Bibliography
[1] Perry,
G.,
Minimizing public cloud disruptions,
TechTarget,
[online]. Available at:
http://searchdatacenter.techtarget.com/tip/Minimizing-public-cloud-disruptions, 2011.
[2] Roschke, S., Cheng, F. and Meinel, C.,Intrusion Detection in the Cloud. In Eighth IEEE
International Conference on Dependable, Autonomic and Secure Computing, pp. 729-734,
2009.
[3] Yu, D. and Frincke, D.,A Novel Framework for Alert Correlation and Understanding. In-
ternational Conference on Applied Cryptography and Network Security (ACNS) 2004,
Springer’s LNCS series, 3089, pp. 452-466, 2004.
[4] Lee, J-H., Park, M-W., Eom, J-H. And Chung, T-M., Multi-level Intrusion Detection System
and Log Management in Cloud Computing. In 13th International Conference on Advanced
Communication Technology (ICACT) ICACT 2011, Seoul, 13- 16 February, pp.552- 555,
2011.
[5] Chen, Q. and Aickelin, U., Dempster-Shafer for Anomaly Detection. In Proceedings of the
International Conference on Data Mining (DMIN 2006), Las Vegas, USA, pp. 232-238, 2006.
78
A.M. Lonea, D.E. Popescu, H. Tianﬁeld
[6] Siaterlis, C., Maglaris, B. and Roris, P., A novel approach for a Distributed Denial of Service
Detection Engine. National Technical University of Athens. Athens, Greece, 2003.
[7] Siaterlis, C. And Maglaris, B., One step ahead to Multisensor Data Fusion for DDoS De-
tection. Journal of Computer Security, 13(5):779-806, 2005.
[8] Guth, M.A.S., A Probabilistic Foundation for Vagueness & Imprecision in Fault-Tree Anal-
ysis. IEEE Transactions on Reliability, 40(5), pp.563-569, 1991.
[9] Popescu D.E., Lonea A.M., Zmaranda D.,Vancea C. and Tiurbe C. , Some Aspects about
Vagueness & Imprecision in Computer Network Fault-Tree Analysis. INT J COMPUT
COMMUN, ISSN: 1841-9836, 5(4):558-566, 2010.
[10] Esmaili, M., Dempster-Shafer Theory and Network Intrusion Detection Systems. Scientia
Iranica, Vol. 3, No. 4, Sharif University of Technology, 1997.
[11] Sentz, K. and Ferson, S., Combination of Evidence in Dempster-Shafer Theory. Sandia
National Laboratories, Sandia Report, 2002.
[12] Dissanayake, A., Intrusion Detection Using the Dempster-Shafer Theory. 60-510 Literature
Review and Survey, School of Computer Science, University of Windsor, 2008.
[13] Mazzariello, C., Bifulco, R. and Canonico, R., Integrating a Network IDS into an Open
Source Cloud Computing Environment. In Sixth International Conference on Information
Assurance and Security, pp. 265-270, 2010.
[14] Dhage, S. N., et al., Intrusion Detection System in Cloud Computing Environment. In In-
ternational Conference and Workshop on Emerging Trends in Technology (ICWET 2011) ’
TCET, Mumbai, India, pp. 235-239, 2011.
[15] Lo, C-C. , Huang, C-C. And Ku, J., A Cooperative Intrusion Detection System Framework
for Cloud Computing Networks. In 39th International Conference on Parallel Processing
Workshops, pp.280-284, 2010.
[16] Yu, D. and Frincke, D., Alert Conﬁdence Fusion in Intrusion Detection Systems with Ex-
tended Dempster-Shafer Theory. ACM-SE 43: Proceedings of the 43rd ACM Southeast Con-
ference, pp. 142-147, 2005.
[17] Chou, T., Yen, K.K., Luo, J., Network intrusion detection design using feature selection of
soft computing paradigms. International Journal of Computational Intelligence, 4(3):102-
105, 2008.
[18] Chatzigiannakis, V., et al., Data fusion algorithms for network anomaly detection: classi-
ﬁcation and evaluation. Proceedings of the Third International Conference on Networking
and Services (ICNS’07), 2007.
[19] Hu, W., Li, J. and Gao, Q., Intrusion Detection Engine Based on Dempster-Shafer’s The-
ory of Evidence. Communications, Circuits and Systems Proceedings, 2006 International
Conference, 3:1627-1631, 2006.


</subsection_point_Point 2>

<previous_sections>

A systematic review of automated systems for real-time irrigation management

1. INTRODUCTION
The challenge of feeding a growing population with finite resources is becoming increasingly pressing. By 2050, the world population is expected to reach 9.7 billion, necessitating a 70% increase in food production (Falkenmark and Rockstrom, 2009). Irrigation plays a crucial role in enhancing crop yields and agricultural productivity to meet this growing demand. Studies have shown that irrigation can significantly increase crop water productivity, contributing to increased food production (Ali and Talukder, 2008; Playan and Mateos, 2005). However, water scarcity poses a significant challenge, with many regions facing water deficits and the need for improved water management practices (Falkenmark and Rockstrom, 2009). Optimizing irrigation schedules and doses based on crop requirements and environmental conditions is essential for maximizing yield and quality while minimizing water use (Zhang et al., 2024). The necessity of scalable water-efficient practices for increasing food demand cannot be overstated. Techniques such as regulated deficit irrigation, magnetically treated water, and the use of drought-tolerant crops like sorghum have shown promise in improving water productivity and ensuring food security (Mehmood et al., 2023; Putti et al., 2023; Hadebe et al., 2016). As the global food challenge intensifies, it is imperative to critically evaluate the current state and future potential of irrigation management systems to guide research, innovation, and implementation efforts towards fully autonomous, scalable solutions.

Despite the importance of irrigation in addressing the global food challenge, traditional irrigation management techniques, such as manual scheduling and timer-based systems, have significant limitations. These methods are often labor-intensive, inefficient, and less adaptable to changing conditions (Savin et al., 2023). Manual and timer-based scheduling can lead to high operational costs and inefficient water use (Raghavendra, Han, and Shin, 2023). The reliance on manual intervention and predetermined schedules limits their adaptability to changing environmental conditions, crop water requirements, and soil moisture levels (Kaptein et al., 2019). Sensor-based irrigation systems offer an alternative, enabling real-time adjustments based on soil water status measurements (Kaptein et al., 2019). However, the adoption of these systems in commercial settings has been limited, often requiring extensive input from researchers (Kim et al., 2014; Lea-Cox et al., 2018; Ristvey et al., 2018). The limitations of traditional irrigation management techniques highlight the need for scalable, automated solutions for greater efficiency in irrigation management. Automated systems that collect real-time data, analyze it, and make autonomous irrigation decisions can lead to improved water use efficiency and increased crop productivity (Champness et al., 2023; Wu et al., 2022). To fully understand the potential of automated systems, it is necessary to examine the automation of each part of the irrigation management pipeline and analyze the effectiveness and efficiency of integrated end-to-end solutions.

The emergence of smart irrigation management and IoT marks a significant shift from historical irrigation practices. Modern approaches rely on vast data and analysis algorithms, leveraging technologies such as remote sensing, sensor networks, weather data, and computational algorithms (Atanasov, 2023; Bellvert et al., 2023; Kumar et al., 2023). IoT plays a vital role in collecting vast amounts of data through sensors, data transmission, and tailored networks, enabling real-time monitoring and control of irrigation systems (Liakos, 2023; Zuckerman et al., 2024). These advancements in data collection and analysis have the potential to revolutionize irrigation management, allowing for more precise and efficient water use. However, challenges such as processing diverse data sources, data integration, and lack of integrated data analysis hamper the full benefit of IoT in irrigation management (Dave et al., 2023). The current fragmented approach in smart irrigation, focusing on individual components rather than the entire system, limits the potential for fully autonomous, real-time end-to-end irrigation management (Togneri et al., 2021). To address these challenges and fully realize the potential of smart irrigation management, there is a need for automating and integrating each section of the irrigation management pipeline, from sensor/weather data collection and transmission to processing, analysis, decision-making, and automated action (McKinion and Lemmon, 1985). This integration requires a thorough investigation of the role of interoperability and standardization in enabling seamless communication and compatibility between components within the automated irrigation management pipeline.

Machine learning (ML) plays a significant role in processing vast data, predicting plant stress, modeling climate effects, and optimizing irrigation in smart irrigation management systems. ML algorithms can analyze data collected from sensors and weather stations to determine optimal irrigation schedules (Vianny et al., 2022). However, the potential of ML is often constrained by manual steps, such as data interpretation, decision-making on irrigation timing and volume, and system adjustments. Automating ML integration to allow direct action from insights to irrigation execution, removing bottlenecks and achieving real-time adaptability, is crucial for fully autonomous irrigation management (Barzallo-Bertot et al., 2022). By integrating ML into automated systems, the irrigation management pipeline can become more seamless and efficient, enabling real-time decision-making and action based on data-driven insights. To achieve this level of automation and integration, it is essential to identify gaps and propose solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.

To achieve seamless integration across the automated irrigation management system, interoperability and standardization are critical. Interoperability allows different system components, such as sensors, actuators, and software, to communicate and exchange data effectively, while standardization ensures that data is represented in a consistent format (Santos et al., 2020). Standardized protocols and data formats are essential for achieving seamless integration and ensuring compatibility between components in real-time irrigation management systems (Robles et al., 2022; Hatzivasilis et al., 2018). Existing and emerging standards, such as OGC SensorThings API and ISO 11783, have applicability to real-time irrigation management systems (Hazra et al., 2021). However, challenges such as data quality, scalability, reliability, and security need to be addressed to fully realize the potential of interoperability and standardization in automated irrigation management systems (Hazra et al., 2021). Addressing these challenges is crucial for enabling the seamless integration of components within the automated irrigation management pipeline, which is essential for achieving fully autonomous, scalable irrigation management. A comprehensive evaluation of the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline is necessary to guide future research and implementation efforts.
The primary objective of this systematic review is to critically evaluate the current state and future potential of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies for enhancing agricultural water use efficiency and crop productivity.
Specific objectives include:
•	Examining the automation of each part of the irrigation management pipeline and the seamless integration of each section in the context of irrigation scheduling and management.
•	Analyzing the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
•	Investigating the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline.
•	Identifying gaps and proposing solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.
By addressing these objectives, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.

2. REVIEW METHODOLOGY
•	Question-driven framework to guide the literature review of real-time, autonomous irrigation management systems
•	Key research questions posed, each with the motivation behind investigating them and a starting hypothesis to evaluate against the examined literature
•	Table presenting the major objectives, specific objectives, questions, motivations, and hypotheses
3. DATA COLLECTION TO CLOUD: AUTOMATION AND REAL-TIME PROCESSING
3.1. Irrigation management data
The success of automated irrigation management systems relies heavily on the collection, transmission, and analysis of various types of data. The most applicable data types for irrigation management include soil moisture, canopy temperature, weather data, and plant physiological parameters (Farooq et al., 2019; Li et al., 2019; Olivier et al., 2021; Evett et al., 2020). These data are typically collected from a range of sources, including in-field sensors, remote sensing platforms, weather stations, and manual measurements (Li et al., 2019; Karimi et al., 2018).
Soil moisture data is arguably the most critical type of data for irrigation management, as it directly reflects the water available to plants and can be used to determine the optimal timing and amount of irrigation (Olivier et al., 2021; Intrigliolo & Castel, 2006). Soil moisture sensors, such as tensiometers, capacitance probes, and time-domain reflectometry (TDR) sensors, can provide real-time measurements of soil water content at various depths (Farooq et al., 2019). These sensors can be deployed in a network configuration to capture spatial variability in soil moisture across a field (Karimi et al., 2018).
Canopy temperature data is another valuable type of data for irrigation management, as it can be used to assess plant water stress and adjust irrigation accordingly (Evett et al., 2020). Infrared thermometers and thermal cameras can be used to measure canopy temperature, which is influenced by factors such as air temperature, humidity, wind speed, and plant water status (Li et al., 2019). When plants experience water stress, they tend to close their stomata to reduce water loss, leading to an increase in canopy temperature (Evett et al., 2020). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
Weather data, including temperature, humidity, precipitation, wind speed, and solar radiation, are essential for predicting crop water requirements and scheduling irrigation events (Akilan & Baalamurugan, 2024). Weather stations equipped with various sensors can provide real-time measurements of these parameters, which can be used as inputs for crop water requirement models, such as the FAO-56 Penman-Monteith equation (Li et al., 2019). These models estimate crop evapotranspiration (ET) based on weather data and crop-specific coefficients, allowing for the calculation of irrigation requirements (Intrigliolo & Castel, 2006). By integrating weather data into automated irrigation systems, irrigation schedules can be dynamically adjusted based on changing environmental conditions, ensuring that crops receive the optimal amount of water at the right time (Akilan & Baalamurugan, 2024).
When collecting and utilizing these data types, several considerations must be taken into account, including the volume, frequency, format, and source of the data (Farooq et al., 2019). The volume of data generated by automated irrigation systems can be substantial, especially when high-resolution sensors are deployed at a large scale (Bastidas Pacheco et al., 2022). This necessitates the use of efficient data storage, processing, and transmission technologies to handle the data load (Farooq et al., 2019). The frequency of data collection is another important consideration, as it directly impacts the temporal resolution of the data and the ability to detect rapid changes in plant water status or environmental conditions (Bastidas Pacheco et al., 2022). Bastidas Pacheco et al. (2022) demonstrated that collecting full pulse resolution data from water meters provides more accurate estimates of event occurrence, timing, and features compared to aggregated temporal resolutions, highlighting the importance of selecting appropriate data collection frequencies to ensure the quality and usefulness of the data for irrigation management.
The format of the data is also crucial, as it determines the compatibility and interoperability of the data with various analysis tools and platforms (Farooq et al., 2019). Standardized data formats, such as JSON, XML, or CSV, can facilitate data exchange and integration between different components of the automated irrigation system (Zhang et al., 2023). The source of the data is another important consideration, as it can impact the reliability, accuracy, and spatial coverage of the data (Farooq et al., 2019). For example, in-field sensors provide highly localized measurements, while remote sensing platforms, such as satellites or drones, can provide data at larger spatial scales (Li et al., 2019). By combining data from multiple sources, automated irrigation systems can achieve a more comprehensive understanding of crop water requirements and optimize irrigation management accordingly (Farooq et al., 2019).
Data quality, accuracy, and reliability are paramount in irrigation management, as they directly impact the effectiveness of decision-making processes and the efficiency of water use (Gupta et al., 2020). Inaccurate or unreliable data can lead to suboptimal irrigation decisions, resulting in crop stress, yield losses, or wasted water resources (Ramli & Jabbar, 2022). Gupta et al. (2020) emphasized the critical importance of data security and privacy in smart farming systems, as the leakage of sensitive agricultural data can cause severe economic losses to farmers and compromise the integrity of the automated irrigation system. The authors also highlighted the need for robust authentication and secure communication protocols to prevent unauthorized access to smart farming systems and protect data in transit (Gupta et al., 2020).
Ramli and Jabbar (2022) addressed the challenges associated with implementing real-time, automated irrigation systems, including data quality, scalability, reliability, and security. They proposed solutions and best practices based on the analysis of case studies and real-world implementations, such as the use of redundant sensors, data validation techniques, and secure communication protocols (Ramli & Jabbar, 2022). The authors also emphasized the importance of regular maintenance and calibration of sensors to ensure the accuracy and reliability of the collected data (Ramli & Jabbar, 2022).
Researchers have investigated the use of data compression, aggregation, and filtering techniques to reduce bandwidth requirements and improve transmission efficiency in automated irrigation systems (Karim et al., 2023; Rady et al., 2020; Cui, 2023). Karim et al. (2023) explored the effectiveness of various data compression techniques, such as lossless and lossy compression algorithms, in reducing the size of data packets transmitted over wireless networks. The authors found that lossless compression techniques, such as Huffman coding and Lempel-Ziv-Welch (LZW), can significantly reduce data size without compromising data quality, while lossy compression techniques, such as JPEG and MP3, can further reduce data size by introducing acceptable levels of distortion (Karim et al., 2023).
Rady et al. (2020) developed a novel data compression algorithm specifically designed for irrigation data, which achieved significant compression ratios without compromising data quality. The authors demonstrated that their algorithm could reduce the amount of data transmitted over wireless networks, thereby improving the efficiency of the irrigation system and reducing costs (Rady et al., 2020). Cui (2023) investigated the use of data aggregation and filtering techniques to reduce the number of transmissions and save bandwidth in automated irrigation systems. The author proposed a data aggregation scheme that combines multiple sensor readings into a single value, such as the average soil moisture over a specified time interval, to reduce the frequency of data transmissions (Cui, 2023). Additionally, the author explored the use of data filtering techniques, such as Kalman filters and particle filters, to remove noise and outliers from sensor data, improving the accuracy and reliability of the transmitted information (Cui, 2023).
Data standardization and harmonization are crucial for facilitating seamless integration and interoperability between the various components of automated irrigation management systems (Zhang et al., 2023; Ermoliev et al., 2022). Zhang et al. (2023) developed a novel cyberinformatics technology called iCrop, which enables the in-season monitoring of crop-specific land cover across the contiguous United States. The authors highlighted the importance of data standardization and harmonization in the context of iCrop, as it allows for the efficient distribution of crop-specific land cover information based on the findable, accessible, interoperable, and reusable (FAIR) data principle (Zhang et al., 2023). By adopting standardized data formats and protocols, such as the Open Geospatial Consortium (OGC) standards, iCrop enables the seamless integration of various data sources and facilitates the interoperability of the system with other agricultural decision support tools (Zhang et al., 2023).
Ermoliev et al. (2022) proposed a linkage methodology for linking distributed sectoral/regional optimization models in a situation where private information is not available or cannot be shared by modeling teams. The authors emphasized the need for data standardization to enable decentralized cross-sectoral coordination and analysis, as it allows for the consistent representation and exchange of data between different models and stakeholders (Ermoliev et al., 2022). By adopting standardized data formats and interfaces, the proposed linkage methodology can facilitate the integration of various optimization models and support the development of comprehensive decision support systems for sustainable resource management (Ermoliev et al., 2022).
Metadata plays a vital role in providing context and enabling better data interpretation and decision-making in automated irrigation management systems (Jahanddideh-Tehrani et al., 2021). Metadata refers to the additional information that describes the characteristics, quality, and context of the primary data, such as the sensor type, calibration parameters, measurement units, and timestamp (Jahanddideh-Tehrani et al., 2021). Jahanddideh-Tehrani et al. (2021) highlighted the importance of metadata in water resources management, as it enables decision-makers to use the data to the best of its capabilities by understanding factors such as when water data was collected and what factors might have contributed to the measurements. The authors emphasized the need for standardized metadata formats and guidelines, such as the Dublin Core Metadata Initiative (DCMI) and the ISO 19115 standard, to ensure the consistency and interoperability of metadata across different water information systems (Jahanddideh-Tehrani et al., 2021).
In the context of automated irrigation management systems, metadata can provide valuable information about the data collection process, sensor performance, and environmental conditions that can aid in data interpretation and decision-making (Cota & Mamede, 2023). For example, metadata about the sensor type and calibration parameters can help assess the accuracy and reliability of the collected data, while metadata about the weather conditions and soil properties can provide context for interpreting the data and adjusting irrigation strategies accordingly (Cota & Mamede, 2023). By incorporating metadata into the data management and analysis pipeline of automated irrigation systems, decision-makers can make more informed and context-aware decisions, leading to improved water use efficiency and crop productivity (Jahanddideh-Tehrani et al., 2021).

3.2. Edge Computing and Fog Computing
Edge computing and fog computing have emerged as transformative technologies in the realm of real-time irrigation management systems, offering significant potential for improving efficiency, scalability, and reliability (Abdel Nasser et al., 2020; Tran et al., 2019). Edge computing refers to the practice of processing data near the edge of the network, close to the source of the data, while fog computing is a decentralized computing infrastructure that extends cloud computing capabilities to the network edge (Hassija et al., 2019). These technologies bring computation and analytics closer to the data source, reducing the need for data to travel to the cloud and enabling faster processing and decision-making (Hassija et al., 2019; Zhang et al., 2020).
The potential of edge computing and fog computing in real-time irrigation management is immense. Abdel Nasser et al. (2020) proposed a two-layer system for water demand prediction using automated meters and machine learning techniques, demonstrating the potential of edge computing in improving the efficiency and scalability of irrigation management. The system collects and aggregates data from distributed smart meters in the first layer, while the second layer uses LSTM neural networks to predict water demand for different regions of households. By leveraging edge computing, the system can achieve high accuracy in predicting water demand, which is essential for efficient irrigation management (Abdel Nasser et al., 2020).
Tran et al. (2019) conducted a comprehensive review of real-time, end-to-end automated irrigation management systems, highlighting the role of fog computing in addressing data transmission challenges and enabling seamless integration across the irrigation management pipeline. The authors emphasize that real-time, end-to-end automated irrigation management systems have the potential to significantly improve water efficiency, crop yields, and reduce labor costs. However, they also identify several challenges that need to be addressed, such as data quality, scalability, reliability, and security, which can be effectively tackled by implementing fog computing architectures (Tran et al., 2019).
Edge computing offers several benefits in real-time irrigation management systems, including reduced latency, real-time decision-making, and reduced reliance on cloud connectivity (Mishra, 2020; Zhang et al., 2020). By processing data closer to the source, edge computing enables faster response times and more efficient data handling (Mishra, 2020). Mishra (2020) highlights that edge computing reduces latency by processing data closer to the source, enabling real-time decision-making and lessening reliance on cloud connectivity by shifting processing to local or edge devices.
Zhang et al. (2020) explore the application of edge computing in agricultural settings, demonstrating its potential to improve the efficiency and accuracy of irrigation systems. The authors discuss how edge computing has prospects in various agricultural applications, such as pest identification, safety traceability of agricultural products, unmanned agricultural machinery, agricultural technology promotion, and intelligent management. They also emphasize that the emergence of edge computing models, such as fog computing, cloudlet, and mobile edge computing, has transformed the management and operation of farms (Zhang et al., 2020).
Fog computing plays a crucial role in distributing processing and storage across the network, enhancing the scalability and reliability of automated irrigation systems (Premkumar & Sigappi, 2022; Singh et al., 2022). Premkumar and Sigappi (2022) evaluate the current state of automated irrigation management systems and propose a hybrid machine learning approach for predicting soil moisture and managing irrigation. Their study emphasizes the potential of fog computing in distributing processing and storage across the network, improving the efficiency and scalability of irrigation systems. The proposed hybrid machine learning approach outperforms other machine learning algorithms in predicting soil moisture, demonstrating the effectiveness of fog computing in enhancing the performance of automated irrigation systems (Premkumar & Sigappi, 2022).
Singh et al. (2022) discuss the role of fog computing in distributing processing and storage across the network, enhancing scalability and reliability in agricultural management systems. The authors argue that by implementing fog computing, these systems can achieve faster data processing and response times, improving overall efficiency and effectiveness. They also highlight that fog computing can address the challenges faced by real-time data transmission in agricultural management systems, such as latency, bandwidth limitations, and data security (Singh et al., 2022).
The integration of edge and fog computing in real-time irrigation management systems is crucial for achieving fully automated, scalable, and reliable solutions. As the demand for autonomous irrigation management grows, these technologies will play a pivotal role in enabling faster decision-making, reduced latency, improved resource utilization, and seamless integration across the irrigation management pipeline (Tran et al., 2019; Zhang et al., 2020). By bringing computation and analytics closer to the data source and distributing processing and storage across the network, edge and fog computing can significantly enhance the efficiency and effectiveness of automated irrigation systems, contributing to the overall goal of addressing the global food challenge through optimized water resource management and increased agricultural productivity (Abdel Nasser et al., 2020; Premkumar & Sigappi, 2022; Singh et al., 2022).

3.3. Automation of Data Collection
The automation of data collection is a critical component in the development of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. It enables the efficient gathering of vital information about crop health, environmental conditions, and water requirements, which is essential for enhancing agricultural water use efficiency and crop productivity. Two key aspects of automated data collection are the use of advanced sensing technologies for non-invasive plant stress detection and the implementation of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection.
Advanced sensing technologies, such as hyperspectral imaging and thermal sensing, have emerged as powerful tools for non-invasive plant stress detection in automated irrigation management systems. These technologies provide valuable information about crop traits, enabling early and accurate detection of plant health issues (Triantafyllou et al., 2019). Triantafyllou et al. (2019) propose a comprehensive reference architecture model that incorporates advanced sensing technologies in the sensor layer for real-time plant stress detection, highlighting their importance in providing non-invasive plant stress detection. Similarly, Hossain et al. (2023) present a novel IoT-ML-Blockchain integrated framework for smart agricultural management that leverages advanced sensing technologies to optimize water use and improve crop yield, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
Hyperspectral imaging can capture subtle changes in plant physiology that are indicative of stress, while machine learning algorithms can be employed to extract meaningful patterns from the spectral data and classify different stress types (Araus et al., 2014). Thermal sensing can detect changes in canopy temperature, which is influenced by factors such as plant water status (Li et al., 2019). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
The integration of advanced sensing technologies in automated irrigation management systems has the potential to revolutionize precision agriculture. Jiang et al. (2019) demonstrate the effectiveness of a deep learning-based model in accurately detecting leaf spot diseases, highlighting the importance of image augmentation and deep learning algorithms in enhancing the model's performance.
Wireless sensor networks (WSNs) and energy-efficient communication protocols have the potential to significantly improve the efficiency and reliability of data collection in large-scale, long-term irrigation systems. WSNs offer a cost-effective and scalable solution for real-time data collection in large-scale irrigation systems, providing remote monitoring and automated control capabilities (Mehdizadeh et al., 2020). Nishiura and Yamamoto (2021) propose a novel sensor network system that utilizes drones and wireless power transfer to autonomously collect environmental data from sensor nodes in vast agricultural fields, reducing operational costs and enhancing the efficiency of data collection. Similarly, Higashiura and Yamamoto (2021) introduce a network system that employs UAVs and LoRa communication to efficiently collect environmental data from sensor nodes distributed across large farmlands, optimizing data collection and reducing travel distance and time.
Energy-efficient communication protocols are crucial for ensuring reliable data transmission in challenging environmental conditions and extending the lifespan of sensor nodes (Mehdizadeh et al., 2020). Al-Ali et al. (2023) investigate the potential of WSNs and energy-efficient communication protocols for data collection in large-scale, long-term irrigation systems, discussing the challenges and opportunities of using these technologies to improve the efficiency and reliability of real-time data collection in irrigation management. Mehdizadeh et al. (2020) emphasize the need for careful consideration of factors such as data accuracy, energy consumption, and network reliability when designing effective WSNs for irrigation management, enabling timely irrigation decisions and improved crop yields.
The automation of data collection through the use of advanced sensing technologies and wireless sensor networks is essential for achieving fully autonomous, scalable irrigation management. By enabling non-invasive plant stress detection and large-scale, long-term data collection, these technologies contribute to the overall goal of optimizing water resource management and increasing agricultural productivity. The integration of these technologies in real-time, end-to-end automated irrigation management systems has the potential to enhance agricultural water use efficiency and crop productivity, ultimately contributing to the development of fully autonomous, scalable irrigation management solutions.

3.4: Real-Time Data Transmission Protocols and Technologies
Real-time data transmission is a critical component of automated irrigation management systems, as it enables the timely delivery of sensor data to the cloud for processing and decision-making. The exploration of suitable protocols and network architectures is essential for ensuring efficient and reliable data transmission in these systems, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
The Message Queuing Telemetry Transport (MQTT) protocol has emerged as a popular choice for real-time data transmission in IoT networks, including those used for automated irrigation management. MQTT is a lightweight, publish-subscribe protocol designed for constrained devices and low-bandwidth networks (Author, 2019). Its simplicity and low overhead make it well-suited for IoT applications where data transmission speed and energy efficiency are critical (Saranyadevi et al., 2022). MQTT provides three Quality of Service (QoS) levels, ensuring data reliability in real-time scenarios (Author, 2019). Chen et al. (2020) proposed novel algorithms to improve data exchange efficiency and handle rerouting in MQTT-based IoT networks for automated irrigation management systems. Their TBRouting algorithm efficiently finds the shortest paths for data transmission, while the Rerouting algorithm effectively handles the rerouting of topic-based session flows when a broker crashes. The combination of these algorithms can significantly improve the performance and reliability of automated irrigation management systems (Chen et al., 2020).
Client-server IoT networks, such as those based on MQTT, play a crucial role in real-time data transmission for automated irrigation management systems. In these networks, sensors and devices (clients) publish data to a central broker (server), which then distributes the data to subscribed clients (Verma et al., 2021). This architecture enables efficient data collection, processing, and dissemination, facilitating the integration of various components within the automated irrigation management pipeline. Verma et al. (2021) proposed an architecture for healthcare monitoring systems using IoT and communication protocols, which provides a comprehensive overview of existing approaches and highlights challenges and opportunities in the field. Although focused on healthcare, the insights from this study can be applied to automated irrigation management systems, emphasizing the importance of interoperability and standardization for seamless integration (Verma et al., 2021).
In addition to MQTT, other application layer protocols such as XMPP, CoAP, SOAP, and HTTP have been explored for real-time data transmission in IoT networks. Each protocol has its strengths and weaknesses, making them suitable for different applications and scenarios. XMPP (Extensible Messaging and Presence Protocol) is an open-standard protocol that supports real-time messaging, presence, and request-response services (Saint-Andre, 2011). CoAP (Constrained Application Protocol) is a specialized web transfer protocol designed for use with constrained nodes and networks in the Internet of Things (Shelby et al., 2014). SOAP (Simple Object Access Protocol) is a protocol for exchanging structured information in the implementation of web services, while HTTP (Hypertext Transfer Protocol) is the foundation of data communication for the World Wide Web (Fielding et al., 1999).
Motamedi and Villányi (2022) compared and evaluated wireless communication protocols for the implementation of smart irrigation systems in greenhouses, considering factors such as power consumption, range, reliability, and scalability. They found that ZigBee is the most suitable local communication protocol for greenhouse irrigation due to its large number of nodes and long range, while MQTT is the recommended messaging protocol for smart irrigation systems due to its TCP transport protocol and quality of service (QoS) options. GSM is a reliable and cost-effective global communication protocol for greenhouse irrigation, providing wide coverage and low cost (Motamedi & Villányi, 2022).
Syafarinda et al. (2018) investigated the use of the MQTT protocol in a precision agriculture system using a Wireless Sensor Network (WSN). They found that MQTT is suitable for use in IoT applications due to its lightweight, simple, and low bandwidth requirements. The average data transmission speed using the MQTT protocol was approximately 1 second, demonstrating its effectiveness for real-time data transmission in precision agriculture systems (Syafarinda et al., 2018).
The choice of application layer protocol for real-time irrigation management depends on factors such as data transmission speed, reliability, and energy efficiency. MQTT and RTPS (Real-Time Publish-Subscribe) are both suitable for real-time data transmission in IoT systems, but they have different strengths and weaknesses. MQTT is a better choice for applications that require low latency and high throughput, while RTPS is a better choice for applications that require high reliability and low latency (Sanchez-Iborra & Skarmeta, 2021). The exploration of MQTT and client-server IoT networks, along with the comparison of various application layer protocols, provides valuable insights into the suitability of these technologies for real-time data transmission in automated irrigation management systems.
In summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.

3.5. Challenges and Solutions in Real-Time Data Transmission
Following the exploration of data collection, processing at the edge and fog, and automation in previous sections, we now turn to the critical aspect of real-time data transmission. While essential for automated irrigation management, this stage presents unique challenges that must be addressed to ensure system efficiency and reliability.
Obstacles in Real-Time Data Transmission
Agricultural environments present unique challenges for real-time data transmission, directly impacting the effectiveness of automated irrigation systems. Environmental factors can significantly disrupt wireless communication. Adverse weather conditions such as heavy rain, fog, and high winds can weaken or even block radio signals, leading to data loss and compromised system performance. Physical obstacles like trees, buildings, and uneven terrain further complicate signal propagation, creating reliability issues (Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). These environmental challenges necessitate robust communication protocols and network architectures that can ensure consistent and reliable data flow.
In addition to environmental factors, technical limitations also present significant obstacles. Large-scale agricultural operations often demand long-distance data transmission, which can be hindered by the limited range of certain wireless communication protocols. Network congestion, occurring when multiple sensors transmit data concurrently, can lead to delays and potential data loss, further complicating real-time decision-making (Hameed et al., 2020). To mitigate these issues, researchers have investigated the potential of cognitive radio networks (CRNs) and dynamic spectrum access (DSA) for optimizing spectrum utilization and reducing interference (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). CRNs enable devices to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency. DSA, on the other hand, facilitates the dynamic allocation of unused spectrum, enhancing spectrum utilization and reducing congestion.
Furthermore, data security and privacy are paramount concerns in real-time irrigation systems. The sensitive nature of agricultural data, such as crop yields and farm management practices, necessitates robust security measures to prevent unauthorized access and data breaches (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential to protect data integrity and ensure the trustworthiness of the system.
Investigating Data Optimization Techniques
To enhance the efficiency and reliability of real-time data transmission in automated irrigation systems, researchers have explored a range of data optimization techniques. Data compression techniques aim to reduce the size of data packets transmitted over the network, minimizing bandwidth requirements and improving transmission speed (Rady et al., 2020; Karim et al., 2023). Lossless compression algorithms, such as Huffman coding and LZW, preserve data integrity while effectively reducing data size, ensuring that no information is lost during transmission (Cui, 2023). Lossy compression algorithms, such as JPEG and MP3, offer higher compression ratios but introduce a controlled level of data loss, which may be acceptable for certain applications where some loss of precision is tolerable (Karim et al., 2023). The choice between lossless and lossy compression depends on the specific application and the trade-off between data size and accuracy.
Data aggregation techniques provide another effective approach to optimize data transmission. By aggregating multiple sensor readings into a single representative value, such as average soil moisture or temperature, the number of transmissions can be significantly reduced, conserving bandwidth and energy resources (Cui, 2023). This is particularly beneficial in large-scale irrigation systems where numerous sensors are deployed across vast areas, generating substantial amounts of data. Additionally, data filtering techniques play a crucial role in improving data quality and reliability. Kalman filters and particle filters can effectively remove noise and outliers from sensor data, ensuring that only accurate and relevant information is transmitted and used for decision-making (Cui, 2023). This is essential for preventing erroneous data from influencing irrigation decisions and potentially leading to suboptimal water management.
Sensor calibration, drift correction, and fault detection are essential for maintaining data accuracy and reliability (Dos Santos et al., 2023). Regular calibration ensures that sensors provide accurate measurements over time, while drift correction techniques account for gradual changes in sensor readings due to environmental factors or aging. Fault detection mechanisms can identify and address sensor malfunctions or anomalies, preventing erroneous data from influencing irrigation decisions and potentially harming crops or wasting water.
Addressing the Challenges
Effectively addressing the challenges in real-time data transmission requires a multifaceted approach that encompasses environmental, technical, and data-related considerations. Implementing robust and adaptive communication protocols is crucial for overcoming interference and signal degradation caused by weather conditions and physical obstacles. Selecting appropriate protocols, such as LoRa or ZigBee, with suitable range and penetration capabilities can ensure reliable data transmission in challenging agricultural environments (Motamedi & Villányi, 2022). Additionally, employing techniques like frequency hopping and error correction codes can further improve communication resilience and mitigate data loss.
Optimizing network architecture is another key consideration. Deploying a distributed network architecture with edge and fog computing capabilities can significantly enhance data processing and transmission efficiency (Abdel Nasser et al., 2020; Tran et al., 2019). Edge devices can perform initial data processing and aggregation tasks, reducing the amount of data transmitted to the cloud and minimizing latency, while fog nodes can provide additional processing power and storage closer to the data source, enhancing scalability and reliability. This distributed approach alleviates the burden on the central cloud server and allows for more responsive and efficient irrigation management.
Data optimization techniques play a vital role in reducing bandwidth requirements and improving transmission efficiency. The choice of data compression, aggregation, and filtering techniques should be tailored to the specific requirements of the irrigation system, considering factors such as data type, accuracy needs, and available bandwidth. By carefully selecting and implementing these techniques, the overall performance and effectiveness of real-time irrigation systems can be significantly enhanced, leading to more sustainable water management practices and improved agricultural productivity.
By addressing these challenges and implementing appropriate solutions, real-time data transmission can become a reliable and efficient component of automated irrigation systems, contributing to the overall goal of achieving sustainable and productive agriculture in the face of growing food demands and water scarcity.

3.6. IoT Network Architectures and Variable Rate Irrigation (VRI) for Real-Time Irrigation
Real-time irrigation management systems heavily rely on the efficient and reliable transmission of data from sensors and weather stations to the cloud for processing and decision-making. However, agricultural environments present unique challenges to wireless communication, including adverse weather conditions, physical obstacles, and the limitations of wireless technologies. These challenges necessitate robust and adaptive solutions to ensure the consistent and timely flow of data, enabling truly autonomous irrigation scheduling.
Environmental factors, such as heavy rain, fog, and strong winds, can significantly disrupt wireless communication by attenuating or even blocking radio signals, leading to data loss and compromised system performance (Ed-daoudi et al., 2023; Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). Dense vegetation, buildings, and uneven terrain create further complications by causing multipath propagation and shadowing effects (Yim et al., 2018; Gautam and Pagay, 2020). The study by Yim et al. (2018) on LoRa networks in a tree farm environment exemplifies these challenges, revealing reduced communication range and data reliability compared to theoretical expectations. This underscores the need for carefully selecting and optimizing communication protocols and network parameters to ensure reliable data transmission in such environments.
The study by Guzinski et al. (2014a) using a modified TSEB model further highlights the importance of high-resolution data in accurately capturing the spatial and temporal dynamics of energy fluxes influenced by environmental factors. This emphasizes the need for advanced data acquisition and processing techniques that can effectively represent the complexities of agricultural settings.
The limitations of traditional wireless communication technologies, such as limited range and network congestion, pose additional challenges for large-scale agricultural operations. Long-distance data transmission can be hindered by range limitations, while network congestion arising from numerous sensors transmitting concurrently can lead to delays and data loss, hindering real-time decision-making (Hameed et al., 2020). Addressing these challenges requires the exploration of advanced networking technologies that can optimize spectrum utilization, mitigate interference, and improve reliability and efficiency.
Cognitive Radio Networks (CRNs) and Dynamic Spectrum Access (DSA) offer promising solutions for optimizing wireless communication in agricultural settings. CRNs empower devices with the ability to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). Research has explored the potential of CRNs in predicting Radio Frequency (RF) power to avoid noisy channels and optimize spectrum utilization (Iliya et al., 2014; Iliya et al., 2014). These studies demonstrate the effectiveness of combining optimization algorithms with artificial neural networks (ANNs) to enhance the accuracy and generalization of RF power prediction, enabling CRNs to make informed decisions about channel selection and avoid interference.
DSA complements CRN technology by dynamically allocating unused spectrum, further enhancing spectrum utilization and reducing congestion (Shi et al., 2023). The numerical model developed by Shi et al. (2023) showcases the potential of CRNs and DSA for optimizing wireless communication in challenging environments.
The integration of CRNs and DSA into the IoT network architecture requires careful consideration of spectrum sensing techniques, network topology, and data security. Research on cooperative spectrum sensing suggests that distributed approaches, where sensor nodes collaborate and share information, can significantly improve the accuracy and efficiency of spectrum sensing, particularly in dynamic environments (Trigka and Dritsas, 2022; Khalid & Yu, 2019). This collaborative approach enables a more comprehensive understanding of the radio environment and facilitates the identification of available frequency bands for data transmission.
The choice of network topology also impacts the performance and scalability of CRN-based irrigation systems. Mesh networks, where sensor nodes are interconnected and relay data for each other, offer enhanced resilience and coverage compared to star topologies where nodes communicate directly with a central gateway (Akyildiz & Vuran, 2010). However, mesh networks can be more complex to manage and may introduce additional routing overhead. The trade-off between network resilience and complexity needs to be carefully evaluated to select the most appropriate topology for a specific agricultural setting.
Data security and privacy are paramount concerns in IoT-based irrigation systems due to the sensitive nature of agricultural data (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential for protecting data integrity and ensuring system trustworthiness. Research on secure spectrum leasing and resource allocation algorithms for CR-WSN-based irrigation systems has demonstrated the potential of these technologies for enhancing security and efficiency (Hassan, 2023; Afghah et al., 2018).
In conclusion, the development of effective and reliable real-time irrigation management systems requires a comprehensive approach that addresses the challenges of data transmission in agricultural environments. The integration of robust and adaptive communication protocols, optimized network architectures, and advanced networking technologies like CRNs and DSA, along with a focus on data security and privacy, can contribute significantly to achieving the goal of autonomous and efficient irrigation scheduling.
4. AUTOMATED DATA PROCESSING IN THE CLOUD
4.1. Data Quality and Preprocessing
Data quality is paramount in automated irrigation systems as it directly influences the effectiveness of decision-making and water use efficiency. Issues like missing values, inconsistencies, and outliers arising from sensor malfunctions, environmental interference, or network problems (Lv et al., 2023) can significantly impact the performance of machine learning models used for irrigation scheduling and management.
Real-time data cleaning techniques are essential for addressing these challenges. Kalman filtering proves particularly effective in handling missing values and correcting erroneous readings by recursively estimating the system's state based on previous measurements and current sensor data, taking into account noise and uncertainty (Kim et al., 2020). Moving average techniques, by averaging consecutive data points, provide a more stable representation of the underlying trend, filtering out short-term fluctuations (Chhetri, 2023). For outlier detection, adaptive thresholding methods offer a dynamic approach, adjusting thresholds based on the statistical properties of the data to effectively identify anomalies and minimize false positives (Bah et al., 2021). These techniques are crucial in maintaining the integrity of real-time data streams and ensuring the accuracy of subsequent analyses.
Adaptive data preprocessing is essential for managing the diversity of data sources and formats commonly found in irrigation systems. Data normalization techniques, such as min-max scaling or z-score normalization, ensure that all features contribute equally to the analysis by transforming data values to a common scale (Pradal et al., 2016). This is crucial for preventing features with larger values from dominating the analysis and ensuring that all features are given equal consideration. Similarly, feature scaling methods, like standardization or normalization, optimize the range of feature values to improve the performance and convergence of machine learning models (Tortorici et al., 2024). By scaling features to a similar range, the influence of outliers is reduced, and the model's ability to learn from the data is enhanced.
Data fusion techniques play a critical role in integrating information from diverse sources, creating a more comprehensive and reliable dataset for irrigation management. Dempster-Shafer theory, a generalization of probability theory, allows for the expression of both uncertainty and the degree of conflict in evidence, making it suitable for fusing uncertain and conflicting data from heterogeneous sources (Sadiq and Rodriguez, 2004). This is particularly relevant in irrigation systems where data from different sensors may provide slightly different or even contradictory information due to sensor variations or environmental factors. Bayesian inference offers another powerful framework for combining information from multiple sources, updating the probability of a hypothesis as new evidence becomes available. By applying these techniques, data from soil moisture sensors, canopy temperature sensors, weather stations, and other sources can be integrated to provide a holistic understanding of crop water requirements and environmental conditions, leading to more informed and accurate irrigation decisions.
The impact of data quality extends beyond model accuracy to the robustness of machine learning models under varying conditions. Robust models should maintain consistent performance even when faced with data inconsistencies or unexpected situations. Techniques like data augmentation and domain adaptation can enhance model robustness by exposing the model to a wider range of data variations during training. Data augmentation involves generating additional training data by applying transformations or introducing noise to existing data, making the model more resilient to noise and variations in the real-world data. Domain adaptation techniques aim to adapt a model trained on one domain (e.g., a specific crop or geographic location) to perform well on another domain with different data characteristics. This is particularly relevant in irrigation management, where models may need to be applied to different crops, soil types, or climatic conditions.
The choice of data cleaning, preprocessing, and fusion techniques should be carefully considered based on the specific characteristics of the irrigation system and the available data. By selecting and implementing appropriate techniques, the accuracy, reliability, and robustness of machine learning models can be significantly improved, leading to more efficient and sustainable irrigation management practices.
4.2. Scalable and Autonomous Deployment using Containerization Strategies
The transition from data collection and transmission to efficient data processing requires a robust infrastructure capable of handling diverse workloads and data volumes. Containerization technologies, specifically Docker and Kubernetes, offer a promising solution for deploying and scaling data processing and machine learning modules within cloud environments like AWS, Azure, and GCP (Vargas-Rojas et al., 2024; Rosendo et al., 2022; Solayman & Qasha, 2023). Docker provides a standardized way to package applications and their dependencies into self-contained units known as containers, ensuring consistent and reproducible execution across different platforms (Rosendo et al., 2022). Kubernetes, acting as a container orchestrator, manages their deployment, scaling, and networking across a cluster of machines (Rosendo et al., 2022). This combination presents several advantages for automated irrigation management systems.
Firstly, containerization facilitates efficient resource utilization and scalability. By encapsulating applications and their dependencies, containers enable the isolation of resources and prevent conflicts between different modules (Vargas-Rojas et al., 2024; Solayman & Qasha, 2023). This isolation allows for the efficient allocation of resources, such as CPU, memory, and storage, to each container based on its specific needs. Kubernetes further enhances scalability by allowing for the automatic scaling of containers based on real-time demand, ensuring the system can adapt to varying workloads and data volumes, preventing bottlenecks, and ensuring responsiveness to changing conditions (Karamolegkos et al., 2023).
Secondly, containerization promotes portability and reproducibility. By packaging applications and their dependencies into a single unit, containers make it easy to move and deploy them across different cloud environments without the need for environment-specific configurations (Rosendo et al., 2022; Solayman & Qasha, 2023). This portability simplifies the development and deployment process, reducing the time and effort required to set up and manage the system. Additionally, containers ensure reproducibility by providing a consistent execution environment, regardless of the underlying infrastructure. This eliminates variability and ensures that the system will behave consistently across different deployments (Zhou et al., 2023).
Optimizing container orchestration and resource allocation is crucial to minimizing latency and maximizing throughput in real-time data processing pipelines. Techniques like auto-scaling and dynamic resource allocation play a critical role in this context (Hethcoat et al., 2024; Werner and Tai, 2023; Kumar et al., 2024). Auto-scaling automatically adjusts the number of container instances based on real-time demand, ensuring that sufficient resources are available to handle peak workloads while avoiding over-provisioning during periods of low demand (Hethcoat et al., 2024; Kumar et al., 2024). Dynamic resource allocation enables the fine-grained adjustment of resources allocated to each container based on its specific needs and the current workload (Werner and Tai, 2023). This ensures efficient resource allocation and provides each container with the necessary resources to perform its tasks effectively.
Performance monitoring tools, such as Kubernetes Metrics Server and Prometheus, are essential for gaining insights into the performance of containers and the overall system (Hethcoat et al., 2024; Kuity & Peddoju, 2023). These tools provide valuable data on key performance indicators, such as CPU and memory usage, network traffic, and application-specific metrics. By monitoring this data, administrators can identify bottlenecks, optimize resource allocation strategies, and continuously improve system performance (Hethcoat et al., 2024). This data-driven approach ensures that automated irrigation management systems can operate efficiently and reliably.
By integrating containerization technologies with optimization techniques and performance monitoring, automated irrigation management systems achieve the scalability, autonomy, and efficiency required for effective real-time data processing and decision-making. This approach facilitates a seamless and responsive system that can adapt to changing conditions and contribute to the overall goal of optimizing water resource management and increasing agricultural productivity.
4.3. Deploying ML Models for Data Processing
•	Architectures and frameworks for deploying machine learning models on cloud platforms for real-time data processing and inference in irrigation management systems, such as: TensorFlow Serving, Apache MXNet Model Server, ONNX Runtime
•	Techniques for optimizing machine learning model performance and resource utilization in cloud environments, such as: Model compression (e.g., pruning, quantization), Hardware acceleration (e.g., GPU, TPU), Distributed training (e.g., Horovod, BytePS)
•	Integration of deployed machine learning models with other components of the automated irrigation management pipeline, such as data preprocessing, decision-making, and control systems, using protocols like: MQTT, CoAP, RESTful APIs
4.4. Online Learning in the Cloud
•	Application of online learning techniques for continuously updating and improving machine learning models based on incoming real-time data, using algorithms such as: Stochastic gradient descent (SGD), Passive-aggressive algorithms, Online random forests
•	Architectures and frameworks for implementing online learning in cloud-based irrigation management systems, such as: Apache Spark Streaming, Apache Flink, AWS Kinesis, leveraging serverless computing and stream processing paradigms
•	Strategies for balancing exploration and exploitation in online learning to adapt to changing environmental conditions and optimize irrigation decision-making, using techniques such as: Multi-armed bandits, Bayesian optimization, Reinforcement learning (e.g., Q-learning, SARSA)


5. GENERATING AND APPLYING IRRIGATION INSIGHTS 
5.1. Real-Time Generation of Actionable Irrigation Insights
•	Advanced predictive models, such as deep learning (e.g., LSTM, CNN) and ensemble methods (e.g., Random Forests), for precise, site-specific irrigation recommendations
•	Integration of IoT sensor data (e.g., soil moisture probes, weather stations) and cloud-based data sources (e.g., weather forecasts, satellite imagery) using data fusion techniques (e.g., Kalman filtering) to enhance insight accuracy and resolution
•	Strategies for handling data heterogeneity, uncertainty, and quality issues in real-time insight generation, such as data preprocessing and outlier detection
•	Techniques for reducing computational complexity and latency, such as edge computing (e.g., fog computing), model compression (e.g., quantization), and hardware accelerators (e.g., GPUs)
5.2. Automated Application of Irrigation Insights
•	Architectures and protocols for seamless integration of ML-generated insights with IoT-enabled irrigation control systems, such as MQTT and CoAP for lightweight, real-time communication
•	Analysis of industry-leading products and services, such as smart irrigation controllers (e.g., Rachio) and cloud-based irrigation management platforms (e.g., CropX)
•	Strategies for ensuring reliability, security, and scalability of automated insight application, such as redundant communication channels and secure edge-to-cloud architectures
•	Case studies of successful implementations of closed-loop, autonomous irrigation systems in research and commercial settings, highlighting technologies used and benefits achieved

6. INTEGRATION, INTEROPERABILITY, AND STANDARDIZATION 
6.1. Interoperability and Standardization
•	Importance of interoperability and standardization in enabling seamless integration of automated irrigation components
•	Overview of existing and emerging standards for IoT devices, communication protocols, and data formats in precision agriculture (e.g., ISOBUS, agroXML, SensorML)
•	Role of standardization bodies and industry consortia in promoting interoperability (e.g., AgGateway, Open Ag Data Alliance, Agricultural Industry Electronics Foundation)
•	Challenges in adopting and implementing standards across diverse hardware and software platforms
•	Strategies for encouraging widespread adoption of standards and best practices for interoperability in automated irrigation systems
6.2. Integration with Existing Irrigation Infrastructure
•	Challenges and strategies for retrofitting legacy irrigation systems with IoT sensors, actuators, and communication devices
•	Hardware compatibility issues and solutions (e.g., adapters, modular designs)
•	Software and firmware updates to enable integration with automated decision-making systems
•	Data integration and normalization techniques for merging legacy and new data sources
•	Economic and practical considerations for transitioning from manual to automated irrigation management
•	Cost-benefit analysis of upgrading existing infrastructure vs. implementing new systems
•	Phased implementation approaches to minimize disruption and optimize resource allocation
•	Training and support requirements for farmers and irrigation managers adopting automated systems
•	Case studies and real-world examples of successful integration of automated irrigation with existing infrastructure
6.3. Integration with Other Precision Agriculture Technologies
•	Synergies between automated irrigation and complementary technologies
•	Remote sensing (satellite, UAV, and ground-based) for crop monitoring and evapotranspiration estimation
•	Soil moisture sensors and weather stations for real-time, localized data collection
•	Variable rate application systems for precise irrigation delivery based on crop requirements
•	Yield mapping and analytics for assessing the impact of automated irrigation on crop productivity
•	Architectures and frameworks for integrating diverse data sources and technologies into a unified precision agriculture ecosystem
•	Edge computing and fog computing paradigms for real-time data processing and decision-making
•	Cloud-based platforms for data storage, analysis, and visualization
•	API-driven approaches for modular integration of third-party services and applications
•	Challenges and solutions for ensuring data quality, consistency, and security across integrated precision agriculture systems
•	Data cleaning, preprocessing, and harmonization techniques
•	Blockchain and distributed ledger technologies for secure, tamper-proof data sharing and traceability
•	Access control and authentication mechanisms for protecting sensitive data and resources
•	Future trends and research directions in the integration of automated irrigation with advanced precision agriculture technologies (e.g., AI-driven crop modeling, robotics, and autonomous vehicles)
6.4. Cybersecurity Considerations for Integrated Automated Irrigation Systems
•	Unique security risks and vulnerabilities associated with IoT-based automated irrigation systems
•	Potential for unauthorized access, data tampering, and system manipulation
•	Implications of security breaches for crop health, water resource management, and farm productivity
•	Best practices and strategies for securing automated irrigation systems
•	Secure device provisioning and authentication (e.g., hardware security modules, certificates)
•	Encryption and secure communication protocols (e.g., TLS, DTLS)
•	Firmware and software updates to address emerging security threats
•	Network segmentation and access control to limit the impact of breaches
•	Role of cybersecurity standards and frameworks in guiding the development and deployment of secure automated irrigation systems (e.g., NIST CSF, IEC 62443)
•	Importance of user awareness, training, and incident response planning in maintaining the security of integrated automated irrigation systems

7. MONITORING AND ENSURING SYSTEM RELIABILITY
7.1. Resilience and Fault Tolerance in Automated Irrigation Systems
•	Strategies for ensuring robustness and reliability in the face of failures, disruptions, or unexpected events
•	Redundancy: Implementing redundant components, such as duplicate sensors (e.g., soil moisture sensors, weather stations), controllers (e.g., PLCs, microcontrollers), and communication channels (e.g., cellular, satellite, LoRaWAN) to maintain system functionality during component failures
•	Failover mechanisms: Designing seamless failover mechanisms that automatically switch to backup components or systems in case of primary system failure, such as hot-standby controllers or multi-path communication protocols (e.g., mesh networks, software-defined networking)
•	Self-healing capabilities: Incorporating AI-driven self-healing mechanisms that can detect, diagnose, and recover from faults without human intervention, using techniques like reinforcement learning, Bayesian networks, or self-organizing maps
•	The role of distributed architectures and edge computing in enhancing system resilience
•	Decentralizing critical functions and data processing to minimize the impact of single points of failure, using fog computing or multi-agent systems
•	Leveraging edge computing to enable localized decision-making and control, reducing dependence on cloud connectivity and improving response times, using technologies like Raspberry Pi, NVIDIA Jetson, or Intel NUC
•	Anomaly detection and predictive maintenance using AI techniques
•	Employing unsupervised learning algorithms (e.g., autoencoders, clustering) to detect anomalies in sensor data, system performance, and water usage patterns
•	Developing predictive maintenance models using techniques like long short-term memory (LSTM) networks, convolutional neural networks (CNNs), or gradient boosting machines (GBMs) to anticipate and prevent potential system failures based on historical data and real-time monitoring
7.2. Advanced Monitoring Techniques for Automated Irrigation Systems
•	Remote monitoring using IoT-enabled sensors and computer vision
•	Deploying a heterogeneous network of IoT sensors to collect real-time data on soil moisture (e.g., capacitive, tensiometric), temperature (e.g., thermocouples, thermistors), humidity (e.g., capacitive, resistive), and plant health (e.g., sap flow, leaf wetness)
•	Integrating high-resolution cameras (e.g., multispectral, hyperspectral) and computer vision algorithms for visual monitoring of crop growth, disease detection (e.g., using deep learning-based object detection and segmentation), and irrigation system performance (e.g., leak detection, sprinkler uniformity)
•	Transmitting sensor and camera data to cloud-based platforms (e.g., AWS IoT, Google Cloud IoT, Microsoft Azure IoT) for remote access and analysis using protocols like MQTT, CoAP, or AMQP
•	Innovative approaches for real-time system health assessment
•	Developing novel algorithms and metrics for evaluating the health and performance of automated irrigation systems, such as entropy-based measures, network resilience indices, or multi-criteria decision analysis (MCDA) frameworks
•	Combining data from multiple sources (e.g., sensors, weather forecasts, satellite imagery) using data fusion techniques (e.g., Kalman filters, Dempster-Shafer theory) to create a comprehensive view of system health
•	Employing advanced data visualization techniques (e.g., interactive dashboards, augmented reality) to present system health information in an intuitive and actionable format
7.3. Closed-Loop Control and Feedback Mechanisms
•	Exploring the concept of closed-loop control in autonomous irrigation systems
•	Implementing feedback loops that continuously monitor system performance and adjust irrigation schedules based on real-time data, using control techniques like proportional-integral-derivative (PID), model predictive control (MPC), or fuzzy logic control (FLC)
•	Integrating machine learning algorithms (e.g., reinforcement learning, genetic algorithms) to optimize closed-loop control strategies over time, adapting to changing environmental conditions and crop requirements
•	Designing effective feedback mechanisms for user interaction and system optimization
•	Providing user-friendly interfaces (e.g., mobile apps, web dashboards) for farmers to input preferences, constraints, and expert knowledge into the automated irrigation system, using techniques like participatory design or user-centered design
•	Incorporating user feedback and domain expertise to refine irrigation strategies and improve system performance
8. CASE STUDIES AND REAL-WORLD IMPLEMENTATIONS OF FULLY AUTONOMOUS IRRIGATION SYSTEMS
8.1. Fully Autonomous Irrigation Systems in Diverse Agricultural Settings
•	Row Crops: maize, wheat, soybean with real-time soil moisture monitoring and weather-based irrigation scheduling for fully automated precision irrigation
•	Orchards: citrus, apple, almond with plant health monitoring and precision water application for fully autonomous orchard management
•	Greenhouses: tomato, lettuce, herbs with automated drip irrigation and climate control integration for fully automated greenhouse operations
•	Urban Farming: rooftop gardens, vertical farms with IoT-enabled hydroponic systems and remote management for fully autonomous urban crop production
8.2. Integration of Advanced System Components for End-to-End Automation
•	Wireless sensor networks: soil moisture probes, weather stations, plant health monitoring cameras with low-power, long-range communication for fully automated data acquisition
•	Secure data transmission: LoRaWAN, NB-IoT, 5G, satellite communication for reliable, real-time data transfer from field to cloud in fully autonomous irrigation systems
•	Intelligent data processing: edge computing for local data filtering, cloud platforms for scalable storage and analysis, machine learning algorithms for predictive insights in fully automated irrigation management
•	Autonomous decision-making: advanced irrigation scheduling algorithms, precise valve control, closed-loop feedback systems for optimal water management in fully autonomous irrigation systems
8.3. Quantitative Performance Evaluation of Fully Automated Irrigation Systems
•	Water use efficiency: percent reduction in water consumption compared to conventional methods, improved water productivity (yield per unit of water) achieved through fully autonomous irrigation
•	Crop yield and quality improvements: percent increase in yield, enhanced crop uniformity, improved nutritional content attributed to fully automated precision irrigation
•	Labor and energy savings: quantified reduction in labor hours for irrigation management, decreased energy consumption for pumping due to optimized scheduling in fully autonomous systems
•	Economic viability: detailed return on investment analysis, payback period calculations, comprehensive cost-benefit analysis for fully autonomous irrigation management systems
8.4. Lessons Learned and Challenges Encountered in Deploying Autonomous Irrigation Systems
•	Technical challenges and solutions: ensuring reliable data transmission in remote locations, addressing interoperability issues between diverse system components, optimizing power consumption for extended battery life, adapting algorithms to local soil and weather conditions in fully autonomous irrigation systems
•	Operational and logistical hurdles: streamlining installation and maintenance procedures, providing effective user training, seamlessly integrating with existing farm management practices and legacy systems for fully automated irrigation management
•	Regulatory and socio-economic considerations: navigating complex water use regulations, addressing data privacy and security concerns, ensuring equitable access and affordability for smallholder farmers adopting fully autonomous irrigation technologies
8.5. Best Practices and Recommendations for Successful Implementation
•	Designing scalable, modular, and adaptable autonomous irrigation systems to accommodate future growth and changing requirements for fully automated water management
•	Prioritizing user-centered design principles and actively engaging stakeholders throughout the development and deployment process of fully autonomous irrigation solutions
•	Adopting open standards and communication protocols to enable seamless integration of system components and interoperability with third-party platforms in fully automated irrigation setups
•	Implementing robust data validation, filtering, and quality control mechanisms to ensure data integrity and reliability for decision-making in fully autonomous irrigation systems
•	Establishing clear data governance policies and security frameworks to protect sensitive information and maintain user trust in fully automated irrigation management
•	Developing intuitive user interfaces and decision support tools to facilitate easy adoption and effective use of fully autonomous irrigation systems
•	Collaborating with local extension services, agribusinesses, and technology providers for knowledge transfer, technical support, and continuous improvement of fully automated irrigation solutions
8.6. Synthesis of Case Studies and Implications for Autonomous Irrigation Adoption
•	Cross-case analysis of key performance indicators and critical success factors for fully autonomous irrigation scheduling systems in various contexts
•	Identification of common themes, challenges, and innovative solutions across diverse implementations of end-to-end fully automated irrigation management
•	Assessment of the potential for replicability and scaling of successful fully autonomous irrigation projects in different regions and farming systems
•	Implications for future research priorities, technology development roadmaps, and policy interventions to support widespread adoption of fully autonomous irrigation technologies

CONCLUSION/FUTURE DIRECTIONS AND UNANSWERED QUESTIONS
•	Summarize the key insights gained from the question-driven review, emphasizing how each section contributes to the overarching goal of achieving real-time, end-to-end automation in irrigation management
•	Based on the questions addressed, propose new research directions and unanswered questions
•	Identify key research gaps and propose concrete research questions and hypotheses for advancing the field of real-time, automated irrigation management
•	Highlight the need for collaborative research efforts across disciplines, such as computer science, agricultural engineering, and environmental science, to address the complex challenges of automated irrigation systems
•	Emphasize the need for further innovation and exploration in real-time, automated irrigation systems



</previous_sections>

</documents>
<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper.

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: 4.4. Online Learning in the Cloud
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>

<subsection_point_Point 3>
Point: Impact of data quality on the performance and robustness of machine learning models for irrigation scheduling and management, considering metrics such as root mean square error (RMSE), mean absolute error (MAE), and coefficient of determination (R²)

Papers to support point:

Paper 1:
- APA Citation: 
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: 
  Extract 2: 
  Limitations: >
  Relevance Evaluation: 
  Relevance Score: 0.9
  Inline Citation: >
  Explanation: The paper's relevance lies in its assessment of the current state and future potential of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies, considering the growing demand for food and the challenges in optimizing water resource utilization. The paper contributes to the literature by connecting three key aspects: data quality and preprocessing in the cloud, the deployment of machine learning models for real-time data processing and inference, and the role of interoperability and standardization in facilitating the integration of diverse irrigation system components and enabling fully autonomous, scalable irrigation management.

The paper's evaluation focuses on the specific point of impact of data quality on the performance and robustness of machine learning models for irrigation scheduling and management, considering metrics such as root mean square error, mean absolute error, and coefficient of determination. This in-depth examination of data quality's influence on model accuracy strengthens the paper's contribution and provides valuable insights for future research and development efforts in this field.

 Full Text: >
Citation: Kanellopoulos, D.; Sharma,
V.K.; Panagiotakopoulos, T.; Kameas,
A. Networking Architectures and
Protocols for IoT Applications in
Smart Cities: Recent Developments
and Perspectives. Electronics 2023, 12,
2490. https://doi.org/10.3390/
electronics12112490
Academic Editors: Marek Pagáˇc,
Chuan Pham, Van Dung Nguyen,
Huynh Kha Tu, Huu Khoa Tran and
Tran Anh Khoa
Received: 28 April 2023
Revised: 28 May 2023
Accepted: 29 May 2023
Published: 31 May 2023
Copyright:
© 2023 by the authors.
Licensee MDPI, Basel, Switzerland.
This article is an open access article
distributed
under
the
terms
and
conditions of the Creative Commons
Attribution (CC BY) license (https://
creativecommons.org/licenses/by/
4.0/).
electronics
Review
Networking Architectures and Protocols for IoT Applications in
Smart Cities: Recent Developments and Perspectives
Dimitris Kanellopoulos 1,*
, Varun Kumar Sharma 2, Theodor Panagiotakopoulos 3,4,*
and Achilles Kameas 3
1
Department of Mathematics, University of Patras, 26500 Patras, Greece
2
Department of Computer Science and Engineering, The LNM Institute of Information Technology,
Jaipur 302031, India; varunksharma.102119.cse@gmail.com
3
School of Science and Technology, Hellenic Open University, 26335 Patras, Greece; kameas@eap.gr
4
School of Business, University of Nicosia, 2417 Nicosia, Cyprus
*
Correspondence: d_kan2006@yahoo.gr (D.K.); panagiotakopoulos@eap.gr (T.P.)
Abstract: Numerous municipalities employ the smart city model in large cities to improve the quality
of life of their residents, utilize local resources efﬁciently, and save operating expenses. This model
incorporates many heterogeneous technologies such as Cyber-Physical Systems (CPS), Wireless
Sensor Networks (WSNs), and Cloud Computing (ClCom). However, effective networking and
communication protocols are required to provide the essential harmonization and control of the many
system mechanisms to achieve these crucial goals. The networking requirements and characteristics
of smart city applications (SCAs) are identiﬁed in this study, as well as the networking protocols
that can be utilized to serve the diverse data trafﬁc ﬂows that are required between the dissimilar
mechanisms. Additionally, we show examples of the networking designs of a few smart city systems,
such as smart transport, smart building, smart home, smart grid, smart water, pipeline monitoring,
and control systems.
Keywords: smart city; IoT applications; networking architectures; Cyber-Physical Systems (CPS);
Wireless Sensor Networks (WSNs)
1. Introduction
Nowadays, several municipalities implement the smart city model [1] to improve
the quality of life for their citizens and the efﬁcient use of city resources. Intelligent
services can decrease operational costs and resource expenditure in smart cities. They can
enhance performance and operations in a wide variety of smart city applications (SCAs)
including transportation, healthcare, energy, education, and many more. Smart services are
provided by various cutting-edge technologies supporting the smart city model. Examples
of these technologies include the internet of things (IoT), Wireless Sensor Networks (WSNs),
Cyber-Physical Systems (CPS), Cloud Computing (ClCom), fog computing (FoC), big data
analytics, and robots.
IoT is the core technology used in smart cities, bringing plentiful human life beneﬁts [2].
IoT enables the integration of physical objects/smart things into urban environments
where innovative services are offered to support every activity at any time and from any
location [2]. Things are monitored by IoT applications that make direct decisions for their
efﬁcient management. Moreover, things state their conditions, such as battery status and
fault reporting for prognostic maintenance. WSNs offer real-time monitoring of the state
of the infrastructure and resources in a smart city [3]. Wireless sensor devices can also
obtain physical environment information such as temperature. In a CPS, the computation,
networking, and physical processes are put together to control and monitor the physical
environment of a smart city [4]. In smart cities, CPSs are employed to offer practical
connections between the virtual and physical worlds. Applications for smart cities can
be sustained by the ClCom paradigm that provides a scalable and affordable platform
Electronics 2023, 12, 2490. https://doi.org/10.3390/electronics12112490
https://www.mdpi.com/journal/electronics
Electronics 2023, 12, 2490
2 of 63
for computation and IoT data storage [5]. FogC offers reduced latency, greater mobility,
location awareness, streaming, and real-time response for SCAs [6]. Smart cities have
dispersed vast numbers of sensors, and thus large-scale data processing requires a complex
infrastructure. Robotics in the cloud can be an effective computing tool for IoT applications
that require a lot of data processing [7]. To improve the services offered by smart cities,
big data analytics is employed to generate intelligent and optimal temporary and lasting
decisions [8].
The abovementioned technologies are used to implement numerous smart city ser-
vices [9,10]. For instance, intelligent transportation services are applied to improve route
planning and avoid jamming in city streets. These services can enhance vehicular safety
and make possible self-driving cars. Furthermore, parking services and smart trafﬁc light
controls are provided. Smart energy services [10] (e.g., intelligent energy management
and energy consumption prediction) are used to sustain smart grids and smart buildings.
These services can also offer improved utilization of renewable energy. Additional smart
services are engaged in real-time monitoring of bridges, tunnels, water networks, train and
subway rails, and gas and oil pipelines. Structural health monitoring is also feasible using
smart services [11]. Last but not least, there are smart services that focus on monitoring the
environment, public safety, and security of citizens [12].
All these smart city services necessitate a reliable networking infrastructure to efﬁ-
ciently exchange messages between the modules of a smart city system implementing a
particular smart service. In particular, smart city services need a variety of networking and
communication technologies for their completion because they are proposed for dissim-
ilar scales. For example, smart services for smart buildings must be implemented based
on Zigbee (IEEE 802.15.4) or Bluetooth (IEEE 802.15.1) network protocols. On the other
hand, smart services for the smart grid must be mainly implemented using the WiMAX
(IEEE 802.16) network protocol. From another viewpoint, smart city services can exploit
dissimilar network and communication models and solutions.
Until now, the networking and communication components of smart city systems have
received little research attention. To the best of our knowledge, a comprehensive survey
of network architectures and protocols for IoT applications in smart cities does not exist
and is the goal of this study. The communication and networking issues involved in smart
city systems are examined in this study. This paper considers networking technologies,
topologies, and communication requirements for such systems. It also examines if current
network protocols are appropriate for certain smart city services. This paper surveys recent
developments in networking architectures to support SCAs. As this is an active area, this
paper is important to support new research in this ﬁeld. The paper contributes as follows:
1.
It presents network requirements of the major SCAs including intelligent transporta-
tion, smart buildings, pipeline monitoring and control, smart water networks, smart
grids, and manufacturing control and monitoring.
2.
It reviews networking architectures used for the above applications focusing mainly
on the protocols’ suitability.
The remainder of this paper is structured as follows: Section 2 describes SCAs;
Section 3 presents network requirements and protocols used for important SCAs;
Sections 4 and 5 analyze protocols and network architectures for smart grids, smart build-
ings, smart water and pipeline network monitoring, and smart transportation; Section 6
summarizes the paper, while Section 7 provides open research directions; lastly, Section 8
concludes the paper. Figure 1 provides the layout of the survey.
Electronics 2023, 12, 2490
3 of 63
Electronics 2023, 12, x FOR PEER REVIEW 
3 of 65 
 
 
 
Figure 1. The layout of the survey paper. 
Systematic Literature Review 
Article Selection Method: We provide a Systematic Literature Review (SLR) meth-
odology [13] with particular notice to studies related to networking architectures or 
protocols for IoT applications in smart cities. The SLR was employed to systematically 
study networking architectures and protocols for IoT applications in smart cities. We 
proposed a research question to cope with the key issues of networking architectures and 
protocols for IoT applications in smart cities. 
Question Formalization: Key issues and challenges in the field were identified. Such 
issues were network architectures for IoT, network protocols for IoT, IoT applications for 
smart cities, and smart city applications. This study answers the next research question: 
RQ: What is the emphasis of networking architectures or protocols for IoT applica-
tions in smart cities? 
This question determines the number of studies focusing on network architectures 
and protocols for IoT applications for smart cities that have been published to date to 
emphasize its significance in smart cities. 
Article Selection Process: The article selection process is performed in three stages: 
1. 
Automated keyword-based search; 
2. 
Selection of the article based on the title, abstract, and quality of the publication; 
Figure 1. The layout of the survey paper.
Systematic Literature Review
Article Selection Method:
We provide a Systematic Literature Review (SLR)
methodology [13] with particular notice to studies related to networking architectures
or protocols for IoT applications in smart cities. The SLR was employed to systematically
study networking architectures and protocols for IoT applications in smart cities. We
proposed a research question to cope with the key issues of networking architectures and
protocols for IoT applications in smart cities.
Question Formalization: Key issues and challenges in the ﬁeld were identiﬁed. Such
issues were network architectures for IoT, network protocols for IoT, IoT applications for
smart cities, and smart city applications. This study answers the next research question:
RQ: What is the emphasis of networking architectures or protocols for IoT applications
in smart cities?
This question determines the number of studies focusing on network architectures and
protocols for IoT applications for smart cities that have been published to date to emphasize
its signiﬁcance in smart cities.
Article Selection Process: The article selection process is performed in three stages:
1.
Automated keyword-based search;
2.
Selection of the article based on the title, abstract, and quality of the publication;
3.
Elimination of inappropriate articles.
Electronics 2023, 12, 2490
4 of 63
In the ﬁrst stage, the search process is automatically performed using searching on
popular academic databases such as IEEE explorer, ACM, Wiley, Springer, Science Direct,
SAGE, and Google Scholar. The following search string was deﬁned by adding other
spellings of the main elements to ﬁnd relevant articles. The search string was as follows:
(“IoT” OR “Internet of Things”) AND (“network architecture” OR “network pro-
tocol” AND “smart cities” OR “smart rural” OR “smart village” OR “smart trafﬁc” OR
“smart transportation” OR “smart street lights” OR “smart energy” OR “smart grid” OR
“smart buildings” OR “smart home” OR “smart residence” OR “home automation” OR
“smart water” or “smart waste management” OR “smart healthcare” OR “smart rural”
AND “Cloud Computing” OR “edge computing” OR “software-deﬁned networking” OR
“Artiﬁcial Intelligence”).
We found 264 articles from journals, conference proceedings, books, and patents.
These articles were published between 2013 and 2023. In the article selection based on the
quality of the publisher stage, the search string was constrained by searching for conference
papers and journal articles of IEEE, ACM, Sage, Wiley, Science Direct, and Springer, in
order to guarantee that only high-quality publications and articles were selected for the
review. Consequently, 240 articles were selected.
In the third stage of eliminating the inappropriate articles, a Quality Assessment
Checklist (QAC) based on [13] was developed, wherein those articles emerging from the
initial search were reﬁned. After reading the abstracts, we eliminated the unrelated articles.
The entire body of the remaining papers was checked, and those which were not related to
our concerned ﬁeld were also crossed out. After eliminating inappropriate articles, only
226 studies were identiﬁed.
2. Smart City Applications
This section discusses the main SCAs used in diverse domains. To understand what
type of assistance is needed by the networking infrastructures offered for SCAs, their
advantages and design problems were addressed.
In the energy sector, SCAs are being used to increase the reliability, efﬁciency, and
sustainability of electric energy generation and distribution in smart grids [14]. A smart grid
is a new power grid system that automatically collects and reacts to available information
about supplier and consumer behavior. Smart grids use CPS to supply self-monitoring and
superior control mechanisms for power generation and consumer demand, improving grid
reliability and efﬁciency. CPS systems are also used to manage the process of producing
renewable energy from wind turbines [15].
Certain applications are utilized in smart buildings to monitor and manage energy
consumption [16]. CPS controls the equipment in the buildings, including the Heating,
Ventilation, and Air-Conditioning (HVAC) systems; appliances; and lighting systems.
Different kinds of sensor nodes, which keep track of the current state of the environment
and energy consumption, are typically included in smart building systems. A centralized
monitoring and control system receives observations and measurements from these sensors.
Based on reported observations, current operational circumstances, and environmental
factors, the control system employs intelligent algorithms to manage the sub-systems
employed in the buildings to optimize energy consumption.
Intelligent transportation is another SCA that has attracted a lot of interest in the
transportation sector. Applications related to vehicle safety are among the most crucial
types of such applications. Vehicles can be equipped with a variety of safety features,
such as blind spot monitoring, emergency braking, collision avoidance systems, and lane
change warning signs. To improve driving safety, these applications offer full or semi-
automatic operations. Real-time and reliability support in detection and response are these
applications’ most crucial characteristics. Applications for enhancing vehicle safety must
be dependable and able to operate in real-time in all aspects such as threat observations,
decision making, communication, and actions. However, the software cannot handle
high levels of incorporation across all the relevant devices and guarantee real-time and
Electronics 2023, 12, 2490
5 of 63
trustworthy replies. Furthermore, self-driving vehicles are regarded as crucial SCAs [17].
They combine all the aforementioned capabilities with vision and monitoring equipment
to provide the vehicle the ability to traverse the roads using sensed data and intelligent
software that evaluates and reacts to these data in real-time. Intelligent trafﬁc light controls,
which incorporate device monitoring across numerous locations to precisely forecast trafﬁc
patterns, are another application of intelligent transportation. The authors of [18] present
an example of intelligent trafﬁc lights.
Water networks are maintained using smart city technology to increase their intelli-
gence, efﬁciency, dependability, and sustainability. CPS systems are integrated into water
networks to add smart characteristics to the processes of water distribution [19]. Offering
early warning systems to identify problems in water networks is one of these duties. For
instance, it is simple to identify leaks and pipe bursts. Quick, temporary ﬁxes can be
implemented to prevent water wastage and future network threats or damage [20].
WSN-based monitoring of greenhouses is another SCA. Such monitoring provides
well-organized control for appropriate soil, climate, lighting, and water level in green-
houses [21]. Other smart city systems are deployed in the industry to automate, control,
monitor, and improve manufacturing procedures [22,23]. Finally, smart-healthcare systems
based on edge computing [24] are proposed to monitor and examine the physical health of
users [25].
Figure 2 shows some important applications including smart trafﬁc surveillance
and management, smart healthcare, weather and air quality monitoring, smart waste
management, smart street lighting, smart emergency response system, and smart home.
 
observations, decision making, communication, and actions. However, the software 
cannot handle high levels of incorporation across all the relevant devices and guarantee 
real-time and trustworthy replies. Furthermore, self-driving vehicles are regarded as 
crucial SCAs [17]. They combine all the aforementioned capabilities with vision and 
monitoring equipment to provide the vehicle the ability to traverse the roads using 
sensed data and intelligent software that evaluates and reacts to these data in real-time. 
Intelligent traffic light controls, which incorporate device monitoring across numerous 
locations to precisely forecast traffic patterns, are another application of intelligent 
transportation. The authors of [18] present an example of intelligent traffic lights. 
Water networks are maintained using smart city technology to increase their intel-
ligence, efficiency, dependability, and sustainability. CPS systems are integrated into 
water networks to add smart characteristics to the processes of water distribution [19]. 
Offering early warning systems to identify problems in water networks is one of these 
duties. For instance, it is simple to identify leaks and pipe bursts. Quick, temporary fixes 
can be implemented to prevent water wastage and future network threats or damage 
[20]. 
WSN-based monitoring of greenhouses is another SCA. Such monitoring provides 
well-organized control for appropriate soil, climate, lighting, and water level in green-
houses [21]. Other smart city systems are deployed in the industry to automate, control, 
monitor, and improve manufacturing procedures [22,23]. Finally, smart-healthcare sys-
tems based on edge computing [24] are proposed to monitor and examine the physical 
health of users [25]. 
Figure 2 shows some important applications including smart traffic surveillance and 
management, smart healthcare, weather and air quality monitoring, smart waste man-
agement, smart street lighting, smart emergency response system, and smart home. 
 
Figure 2. Facilitating networking and communication amongst SCAs.
Electronics 2023, 12, 2490
6 of 63
Analysis of Smart City Applications/Systems
This subsection analyses the SCAs shown in Figure 2.
Smart Trafﬁc Surveillance Systems: These systems are based on centralized pro-
cesses and may fail due to networking problems. Thus, to automate such an innova-
tive system, centralized and distributed methods must be used to maintain local servers.
Javaid et al. [26] suggested a smart trafﬁc management system using a mixture of central-
ized and decentralized processes to optimize the ﬂow of vehicles on roads and an algorithm
to manage a variety of trafﬁc conditions efﬁciently. In the context of smart cities, effec-
tive trafﬁc management implies that a decision-making model identiﬁes and quantiﬁes
trafﬁc congestion as well as predicts trafﬁc patterns. Afrin and Yodo [27] offered a theoreti-
cal analysis that takes into account such effective trafﬁc management. Notably, existing
decision-making models are primarily devoted to urban and highway trafﬁc management,
not considering the closed campuses and collector roads scenarios. Sarrab et al. [28] iden-
tiﬁed this weakness and proposed an IoT-based system model that collects, processes,
and stores real-time trafﬁc data for such an unusual scenario. In an IoT-based trafﬁc man-
agement system, various challenges emerge. These challenges include security issues,
extremely sophisticated networking equipment, network overhead, required adjustments,
and speciﬁc information ﬁelds in the protocol header and structure, as well as higher costs.
Smart Healthcare Systems: For real-time monitoring of health parameters, these sys-
tems are progressively being associated with and connected via the Internet to numerous
types of available smart wearable sensing and computing devices. These systems face
several problems [29] that must be resolved. A security/privacy perspective, inter-realm au-
thentication, interoperability issues, device-to-device informal communication, and collec-
tion and management of medical data are among the issues on this list. Alromaihi et al. [30]
addressed issues related to cyber-security while using IoT for such applications. They
sought to examine secure techniques’ deployment and implementation from the perspec-
tive of preventing and reducing cyber-attacks on IoT devices. Some crucial surveys and
reviews [31,32] on smart healthcare applications tackle the problem of integrating IoT
systems with any healthcare application particularly.
Weather and Air Quality Monitoring Systems: These systems use environmental
monitoring stations, which are extremely pricey to acquire and maintain. For example,
these stations require engineers with specialized skill sets and data analysts. Therefore, it is
impractical to deploy such monitoring stations densely. Instead, they are often deployed
sparsely, which creates the problem of limited spatial resolutions for useful measurements.
Lately, cheap monitoring sensors have evolved in the market, signiﬁcantly assisting in
reﬁning the granularity of monitoring [33]. Highlighting the same problem, the authors [33]
emphasized the drawbacks of these inexpensive sensors (particularly with air quality
monitoring sensors). For instance, these sensors frequently struggle with the issue of
cross-compassions in the presence of multiple ambient pollutants. Moreover, these sensors
are extremely susceptible to unexpected variations in humidity, temperature, and wind
direction, and as a result, their accuracy deteriorates with time. A recalibration routine
might be a way to maintain and enhance such accuracy. However, because it would take
a lot more time and work, this technique is highly improbable and would not work for
large-scale deployments. In a weather monitoring system, the monitoring is highly complex
and involves three steps [34]:
(1)
Observing: It can be performed by monitoring satellite imagery, precipitation reports,
surface data, and gathering data from other nearby forecasters.
(2)
Forecasting: It can be performed by forecasters as short-term and long-term forecasting.
Short-term forecasting is carried out by evaluating the current weather conditions
and projecting them over the next few hours using knowledge of the mechanics
of the weather. Long-term forecasting, however, is possible through weather (nu-
merical) modeling and the projection of such modeling using computer simulations.
To produce these simulations for future forecasting, these modeling techniques use
environmental data from satellite photography, weather balloons, and surface ob-
Electronics 2023, 12, 2490
7 of 63
servations. Following completion of the forecasting, the forecasters translate the
produced simulated expected output into a perceptible format for non-specialists so
that they can respond appropriately.
(3)
Communicating: Finally, they communicate such output or forecasted information to
appropriate authorities.
Despite the fact that all of these computer models are used to forecast the weather, the
success of each one is largely inﬂuenced by three different elements: (a) the quantity of
precise data; (b) the length of time needed to analyze that data; and (c) the complexity of
dynamic atmospheric weather events. A large part of collecting accurate data for a region
is the placement of weather stations. They may occasionally be stationed distant from rural
areas in a city area. Because of this, they are unable to gather enough information for desert,
sea, or even rural areas to supply the computer models used to predict weather conditions
accurately. Forecasters also use satellite data to combat this issue. However, because
of cloud cover and signiﬁcant changes in the amount of water vapor in the atmosphere,
satellite data accuracy can occasionally be unreliable. Moreover, the topographic image and
map information or surface/land features change substantially in a shorter area. Hence,
it further impacts temperature and precipitation values signiﬁcantly. This further makes
things harder for a computer model to predict accurately. Hence, there is a need to re-
evaluate and re-modify such models’ mathematical equations so that they can predict the
changes more accurately.
Smart Waste Management Systems: Automated smart waste management is crucial for
the following reasons: (1) due to a lack of waste disposal infrastructure; (2) thin or delicate
waste collection methods being required; (3) lack of effective waste logistics management;
(4) insufﬁcient use of cutting-edge trash treatment and recycling technologies; and (5) lack
of workers and specialists with the necessary technical and non-technical skills to handle
garbage disposal and the associated infrastructures. Smart waste management schemes
include various steps such as (1) waste collection; (2) differentiation of waste as per their
biological and physical properties; (3) storage; (4) transportation of waste into garbage
disposal infrastructures/treatment plants; and (5) waste treatment and disposal. Sosunova
and Porras [35] identiﬁed issues and challenges while collecting and analyzing data from
smart deployed sensors on garbage bins. Their study investigated some operational issues
such as the management of waste vehicles and urban infrastructure and smartly managing
waste vehicle routes.
Smart Street Lighting Systems: This system is a network-oriented solution that uses
streetlights ﬁtted with speciﬁc actuators and sensors, implying a wide range of facilities
and connectivity interfaces [36]. The street lighting application (described in [37]) has a
mechanism that gathers or monitors environmental data and then evaluates street lighting
with the use of smart wireless nodes (ﬁtted out with numerous forms of sensors and
actuators). These smart nodes are mounted atop the towers that hold the streetlights, and
they are connected to the Internet by way of a gateway device. Zanella et al. [37] insist
that their system could assist in gathering environmental parameters such as humidity, air
temperature, and CO level. Moreover, the authors stated that optimizing street lighting
efﬁciency is a paramount concern that must be addressed. This monitoring system makes
it possible to maximize efﬁciency since it allows for the adjustment of streetlamp intensity
in response to the time of day, the presence of people, and the weather. Although this
system is simple and built on the IoT concept, it will inevitably contain crucial concerns that
require particular attention, such as complicated networking solutions and communication
among heterogeneous devices. However, selecting the right light lamp is critical for a
power-efﬁcient lighting mechanism. Their selection is based on how effective they are in
terms of power usage and lifespan. The existing metropolitan system relies on Metal Halide
(MH) or High-Pressure Sodium (HPS) bulbs. Unlike LEDs, these bulbs are frequently seen
as being inefﬁcient in terms of power consumption and requiring signiﬁcant maintenance,
which adds signiﬁcantly to the cost. In addition, the system should be designed following
the advised design standards (it must adhere to the current standard CEN/TR 13201) [36].
Electronics 2023, 12, 2490
8 of 63
Currently, there are three kinds of control systems for smart lighting systems in use:
centralized, decentralized, and hybrid. Nevertheless, these systems are susceptible to a
variety of security assaults. Moreover, not much effort has been made into this problem
thus far.
Smart Emergency Response Systems: Such a system ensures the safety and security of
its residents. It can be utilized for crime detection and prevention, dealing with natural
calamities and accidents, and law enforcement [38]. Data collection is ﬁrst and foremost
important for the designing portion of these applications. Depending on the gathered
facts, the development of intelligence (which aids in making important decisions) and the
ability to respond swiftly and quickly are the issues that require special attention. When
it comes to gathering data, we can make use of CCTV cameras and sophisticated trafﬁc
sensors. A developer can create and put into action a crucial learning scheme that will
conduct predictive analysis and gather intelligence on top of the data gathered. Therefore,
this kind of predictive analysis has the potential to gather signiﬁcant information that
will help the relevant authorities (e.g., the ﬁre safety department, the police department,
and law enforcement agencies) take the proper security and preventive measures. The
concept of widespread surveillance has important beneﬁts for security and safety. However,
keeping track of such vast amounts of data also prompts a lot of worries and issues for
designers and developers, including storage; the effectiveness of learning algorithms; and,
most importantly, the question of whether it is morally right or acceptable to keep track
of each individual (a privacy issue). In addition, a very important point is whether this
kind of widespread surveillance is feasible, especially for nations such as China and India,
where a city’s population can exceed that of a whole nation. Further, Gharaibeh et al. [38]
claimed that combining information transmission technologies with well-implemented
data analytics models is necessary for quick and swift collaboration. To save as many lives
as possible during natural disasters, it is imperative to gather, assess, and communicate
vital information to the relevant authorities. As a result, there is currently a lot of work
being done to enhance the performance of information exchange systems. Although this
system is based on the IoT concept and is relatively simple, it faces important problems
that need consideration, such as complex networking solutions and information sharing
across heterogeneous devices on time (time-sensitive application).
Smart Residence/Home Automation: A smart home has highly developed systems
such as a control system for devices or objects (such as fans, lights, music systems, TVs,
and other smart appliances), automated door openers, smart appliances that may send
users remote status updates, smart refrigerators, and washing machines. A user can control
the majority of smart home appliances remotely with two recently produced gadgets:
Google Home and Amazon Echo. In a smart home, the end-user demands a high-speed
internet connection, so they can access networking sites that control the home with HD live
streaming services. In contrast, a smart healthcare application needs safe connections to
computing servers in the cloud for managing sensitive private information. Hence, data
management systems must address a crucial issue, namely, the necessity to concentrate
on data distribution based on various end-user categories rather than just recommending
distinct data distribution among various end-user groups [38]. The concept of smart home
automation raises serious concerns about security and privacy risks. A smart home includes
security monitoring systems with motion sensors, wirelessly opening smart door locks,
televisions, phones, and other smart appliances that are highly outﬁtted with cameras and
microphones. Although these gadgets improve the system, little research has been done on
their privacy and security features. If we conduct a thorough analysis of these gadgets, we
will discover that their manufacturers offer either very few or no security features at all.
Indeed, Fernandes et al. [39] provided their eye-opening views after carefully examining
Samsung’s SmartThings framework (programming) and their SmartApps market. They
argued that more than 50%—exactly 55%—of these smart applications are already more
privileged by default and as a result, do not need to access unrelated applications. As a
result, hackers can use them with ease. Apart from this, according to a published document
Electronics 2023, 12, 2490
9 of 63
by WikiLeaks [40], the Central Intelligence Agency (CIA) has all the tools to access, control,
and hack these smart home applications anywhere in the world. Furthermore, criminal
entities and hackers could seize control of smart personal devices, capture delicate private
information, and exploit that information immorally typically through user tracking and
proﬁling. Additionally, a hacker may break into one of these smart applications, grab vital
information, and then use it to launch any kind of attack. For instance, based on motion
sensors, security camera feeds, and power usage patterns, a burglar can determine where
and when to break into the house. By locating the authentication credentials of authorized
parties, they can compromise smart door locks [41]. Better security-aware hardware and
software (as well as the related common standards) must be developed to safeguard against
all these attempts so that high-tech appliances, sensors, actuators, etc., are impervious to
such security and privacy attacks.
Smart Grid Networks: The functionality of the traditional electricity grid is unidirec-
tional (i.e., electricity is transmitted from electricity-producing sources to end-customers).
Electricity has been moving from power plants to users in a single direction thanks to
the deployment of electricity grids. The existing grid system operates in an open-loop
fashion since there are not any adequate communication infrastructures in the distribution
sector. Moreover, the main distribution center has little or no real-time knowledge of the
system’s operating conditions and dynamically changing load. There are also several tech-
nical, economic, and environmental problems with this conventional approach. Therefore,
this conventional system must become dependable, manageable, and scalable, as well as
ﬂexible, secure, and interoperable [42].
The smart grid is the next invention of the Electric Power System (EPS) that incor-
porates quicker, more secure, and reliable communication networks [43]. Smart grids
supplement the conventional electricity grid by incorporating renewable energy sources
such as biomass, solar energy, and wind energy. These energy sources are much cleaner
and more ecologically friendly than non-renewable energy sources such as fossil fuels.
However, it is important to identify the most suitable communication technology for the
smart grid’s successful implementation and deployment. The smart grid’s overall commu-
nication style is unique compared with conventional network communication patterns. The
communication network architecture of the smart grid must be able to handle information
exchange between sensors, actuators, smart electronic devices, and numerous smart meters
in such a particular environment with little to no human intervention. This type of com-
munication, called Device-to-Device (D2D) communication, is autonomous and may be
initiated in response to an event or at regular intervals. Notably, depending on how these
smart grid applications were built, their QoS requirements and characteristics differ greatly
in terms of delay, burst size, and packet arrival rate. For example, the latency requirement
of a smart meter event and a substation event are quite different [44]. In intelligent grid
networks, the monitoring, managing, and controlling functions inside the same network
present the issues of ﬂexible QoS differentiation. Moreover, applications based on the smart
grid can be developed and implemented using the current wireless and wired networking
infrastructure and technologies. For some devices, such as smart meters, designing and
standardizing acceptable smart grid-based protocols is a critical matter [45]. Furthermore,
these smart grid-based networks are too dependent on intelligent sensors, actuators, and
other devices. This makes them extremely vulnerable to attacks by malicious users. These
smart grids could be taken over by malevolent users or hackers, who could then obtain
unauthorized access to many smart meters and alter crucial data. Moreover, as the existing
electricity system is insufﬁcient for establishing smart grid systems, high-level adjustments
to current power infrastructure scenarios are required. Subsequently, these smart systems
require high installation costs because the installation requires a large number of smart
meters, sensors, and actuators for sensing and data collection [46]. The efﬁcient operation of
such a smart grid system also necessitates a dependable, consistent, and error-free network
channel. Therefore, it will be challenging for developers of such intelligent applications.
Electronics 2023, 12, 2490
10 of 63
Many surveys [42–45,47] reviewed communication frameworks for smart grids, smart-
grid-based networking technologies, trafﬁc management, and the requirements of numer-
ous smart grid applications. Further, Kansal and Bose [48] presented their insights on
transmission grid applications regarding their latency and bandwidth requirements.
3. Network Requirements for SCAs
This section considers several communication requirements including reliability, delay
tolerance, bandwidth, power consumption, security, network type, heterogeneous network
support, and mobility support. It also studies the aptness of different network protocols for
dissimilar SCAs.
Smart city services and applications need robust and dependable communication
support as well as an effective networking infrastructure, which will permit competent
message-sharing procedures among the components of the smart city systems [49]. Every
smart city system has an intricate networking architecture made up of various networking
components. Therefore, smart city systems are innately required to have a variety of net-
working requirements. To access the far-off destination, which may be clouds, the network
trafﬁc from a broad variety of deployed diverse applications uses a common networking
architecture and resources. These resources may consist of switches, routers, communica-
tion connections (links), and other forms of network middle-boxes. The idea of accessing
faraway clouds or far-off destinations or remotely distributed apps consequently brings
up problems with high packet loss probability, signiﬁcant delay, and constrained network
bandwidth. In addition, security is a serious issue that must be considered when develop-
ing, implementing, and deploying intelligent applications for smart cities. Otherwise, users
would be reluctant to approve the use of such applications in the absence of adequate secu-
rity safeguards. Such intelligent applications need a high-speed networking environment
where the quick reaction may be managed with the support of the ability of a fast-processing
speed. Furthermore, a variety of apps can be implemented in the context of a smart city,
based on their usefulness and relevance to the users. These applications, however, have
different networking requirements, particularly in terms of response and security [50]. For
example, the networking requirements of smart emergency response systems are quite
different compared to other applications such as smart healthcare systems. Emergency
response smart systems must be exceedingly secure and quick to react [50]. In contrast,
smart-healthcare-based systems or apps do not necessarily need to be especially dynamic.
−
Network Protocols: Monitoring applications for smart cities often use a dense network
of heterogeneous sensor nodes, including ﬁxed sensor nodes, mobile sensor nodes,
and crowd sensing nodes. Long-Term Evolution (LTE) [51], LTE for Machines (LTE-M),
extended coverage GSM IoT, and ﬁfth-generation (5G) technologies [52] are intriguing
options to support such heterogeneous networks. First, the bulk of crowd-sensing
nodes (smartphones) is already supported by LTE communications. Consequently, no
further wireless communication devices are required. To save energy, LTE and 5G can
be utilized on the sink nodes (also known as cluster heads) to allow the data gathered
by the sink nodes to be transmitted to the monitoring center via base stations (the
backbone network), as opposed to multihop relaying.
−
Zigbee [53], WiFi, and Bluetooth can still be used for the traditional stationary nodes
to communicate within clusters. This layout has the advantage of allowing the sensor
node clusters to be separated from one another while maintaining network connectiv-
ity. Additionally, the moderate number of nodes in each cluster makes maintenance
simpler. In addition to supporting larger networks, LTE and 5G technologies also make
possible sensor nodes with faster data rates, improving the performance of real-time
monitoring [54]. Applications for crowd sensing, for instance, can accommodate video
streams taken by cameras on smartphones or moving vehicles. The fast data rates
provided by LTE and 5G can potentially be advantageous for the sink nodes or clusters.
The use of vibration data (accelerometer readings) in structural health monitoring
applications of bridges, tunnels, or towers is fairly common. The cluster heads will be
Electronics 2023, 12, 2490
11 of 63
able to send the vibration data in this situation in real time. In conclusion, practically
all applications for smart city monitoring that demand a high data throughput and
minimal delay may be satisﬁed by LTE and 5G. Additionally, there are some new
sensor node standards, such as IEEE 802.11ah [55], LoRaWAN [56], and Narrowband-
IoT (NB-IoT) [57]. These narrowband protocols offer numerous advantages: greater
coverage, improved scalability, reduced energy usage, and increased device longevity.
Researchers have tested these standards in more than a few applications, including
street lighting, energy metering, and home automation, even though some are still
being discussed and revised. The new narrowband communication standards enable
the sensor nodes to run more sustainably, which is beneﬁcial for applications that
aim for long-term monitoring. In addition to these protocols and standards, the FogC
architecture [58] aids in monitoring smart cities. In such an architecture, the mobile
users (the potential crowd-sensing providers) and the cloud are connected via fog
servers. These fog servers are WiFi access points or cellular base stations. Mobile users
are more inclined to participate in sensing since they may upload their crowd-sensing
measurements to the fog server in just one hop, signiﬁcantly decreasing the cost and
energy usage compared to cellular networks. As a result, such an architecture can give
us better sensing coverage. Using the measurements from the mobile users and the
WSNs, the fog servers can perform some basic regional estimation based on the FogC
architecture, such as the nearby trafﬁc conditions. The service latency and response
time are then decreased because mobile users can access such estimates directly from
the fog servers rather than from a remote cloud through a backbone network. Lastly,
using the appropriate networking protocols for each SCA is crucial to getting the
best possible trade-off between delay, energy use, and cost. The networks may be
hierarchical so that diverse roles and functions can be assigned at various layers to
increase the networks’ dependability and cost-effectiveness. As a result, certain nodes
may be able to transmit data utilizing various protocols.
−
Bandwidth requirements: Many video applications in smart cities require high band-
width [59]. In these applications, sensors capture video from the physical environment.
Moreover, video transmission is more bandwidth-hungry than the conventional scalar
data trafﬁc in IoT. Examples of these applications are intelligent multimedia surveil-
lance systems for home monitoring, multimedia-based industrial monitoring systems,
trafﬁc monitoring systems for road safety, and remote multimedia-based monitoring
of an environmental system.
−
Delay Tolerance: Some SCAs, such as smart transportation, only tolerate a small
amount of end-to-end delay. For example, to prevent imminent danger to the ve-
hicle or potentially fatal crashes, the data that are being relayed must arrive within
microseconds. Therefore, the control systems must react in time. However, other
applications have a higher tolerance for delays [49]. Such applications rely on data
monitoring and information gathering for upcoming analysis.
−
Power Consumption: Another crucial need for applications is power consumption.
Smart grid systems and other applications with local high-energy sources can tolerate
protocols with higher energy expenditure levels [45]. Other applications have medium
power needs and require energy sources with limited capacities. One example of such
an application is intelligent transportation. Other applications demand protocols with
low or very low energy consumption characteristics since they have limited energy
resources. Unmanned aerial vehicles (UAVs), smart water networks, and pipeline
monitoring for gas and oil are a few examples of such uses.
−
Reliability: The majority of applications have medium reliability requirements. A
typical example of such applications is smart water networks. Some other applications
have high-reliability necessities such as intelligent transportation and smart grids [49].
−
Security: The majority of applications need medium to high security. Applications
such as production control and monitoring, for instance, need medium security, whilst
Electronics 2023, 12, 2490
12 of 63
others, such as smart grids, need high security because of the sensitivity of the data
and the importance of the operations carried out [50].
−
Heterogeneity of network protocols: The majority of smart city systems use network-
ing protocols that link the system’s parts together. Intelligent transportation and smart
buildings are two examples of such systems. These protocols must coexist in such
situations without conﬂicting with one another. To ensure seamless and effective
operation, it is also necessary to correctly map the control information in the head-
ers at the various networking stack tiers used by the many heterogeneous protocols
and networks.
−
Wired/wireless connectivity: The majority of SCAs that include wireless connectivity
are UAVs and monitoring of gas and oil pipelines. Others, including intelligent
transportation and smart buildings, use wired and wireless connectivity [50]. In
these situations, wired networking may be used for communication within a speciﬁc
physical system (such as within a UAV), while wireless communication may be used
to link the physical system to other such systems that are comparable to it or to the
backbone and infrastructure networks.
−
Mobility: Some systems, such as the smart grid, pipeline monitoring for gas and oil,
and smart water networks, have low to medium mobility [50]. Other systems, such
as UAVs and intelligent transportation, are quite mobile. Medium- to high-mobility
smart city systems can be connected if the networking protocols are reliable and
adaptable to node mobility without using up a large amount of bandwidth on control
messages and related processing to react to changes in the network architecture.
Table 1 presents a qualitative comparison of the requirements of some SCAs. Each
SCA has its own transmission range and is sustained by a heterogeneous network with
low, medium, or high trafﬁc rates and supporting high or low mobility of devices. Each
SCA is based on different protocols and requires different bandwidth and latency tolerance.
In each SCA, the number of devices involved differs.
Table 1. Networking aspects and qualitative comparison of SCA requirements.
Smart City Ser-
vices/Applications
Seemingly Fitted
Network Proto-
col/Technology/Standard
Transmission
Range (Meters)
Bandwidth
Requirement
(Minimum)
Latency
Tolerance
Number of
Devices
Network
Mobility
Support
Trafﬁc Rate
Smart Trafﬁc
Surveillance
Cellular, IEEE 802.11,
IEEE 802.16, IEEE
802.15.4
≈1000
M
M
≈1000
Heterogeneous
H
L
Smart
Healthcare
System
Cellular, IEEE 802.11,
IEEE 802.16, IEEE
802.15.4,
IEEE 802.15.6, IEEE
802.15.4j
≈1000
M
M
≈1000
Heterogeneous
L
L
Weather and Air
Quality
Monitoring
System
Cellular, IEEE 802.11,
IEEE 802.16, IEEE
802.15.4
≈1000
L/M
M
≈1000
Heterogeneous
L
L
Smart Waste
Management
IEEE 802.11, IEEE
802.16,
IEEE 802.15.4
≈100
L/M
H
≈1000
Heterogeneous
L
L
Smart Street
Lighting System
IEEE 802.16
IEEE 802.15.4
≈10
M
H
≈100
Heterogeneous
L
L
Smart
Emergency
Response System
Cellular, IEEE 802.16,
IEEE 802.15.4
≈1000
H
L
≈1000
Heterogeneous
H
H
Smart
Residence/
Home
Automation
IEEE 802.15.4, IEEE
802.15.1
≈100
M/H
L
≈10
Heterogeneous
L
M/H
Smart Grid
Networks
Cellular, IEEE 802.16
≈100
L
M/H
≈100
Heterogeneous
L
M/H
IEEE 802.11: WiFi; IEEE 802.16: WiMAX; IEEE 802.15.1: Bluetooth; IEEE 802.15.4: Zigbee; IEEE 802.15.4j: Medical
Body Area Network (M-BAN); IEEE 802.15.6: Body Area Network (BAN); Cellular: CDMA, GSM, UMTS; L: low;
M: medium; H: high.
Electronics 2023, 12, 2490
13 of 63
3.1. Additional Challenges
−
Interoperability: Smart city systems are built on several heterogeneous networking
protocols that use various media access control (MAC) mechanisms at the physi-
cal and data link layers. For the underlying technologies to be integrated seam-
lessly, these protocols must be interoperable [60]. In digital home networks, the IEEE
1905.1 protocol [61], which was created to offer a convergent interface between physi-
cal/data link layers and the network layer, is aimed to perform this function. Future
research should focus on the creation of similar protocols to increase the support
system for smart city systems.
−
Scalability: A smart city platform must manage many devices that are connected to
the city’s infrastructure. Large amounts of city-related data, which are continuously
produced and consumed by devices and client applications, must be stored and
processed. The platform must simultaneously be able to handle hundreds of requests
from users and services that rely on it. Thus, the scalability requirements change
depending on the features of the city as well as the installed applications and services.
Recently, Del Esponte et al. [62] suggested InterSCity, a microservices-based, open-
source smart city platform that facilitates the collaborative development of large-scale
systems, apps, and services for smart cities.
−
Load Balancing: To maximize the usage of resources, load balancing assigns appro-
priate resources (i.e., network resources, storage capacity, computational resources,
and energy resources) to user tasks. A large-scale IoT network performs better and
avoids overload thanks to an effective load-balancing strategy [63]. Response time,
cost, throughput, performance, and resource usage are all improved in terms of
QoS parameters.
−
The Cloud/Edge/FogC Paradigms: Cloud, Edge, and FogC facilitate the creation of
smart city prototypes. These computing paradigms efﬁciently aid in the gathering,
upkeep, and analysis of city data to pinpoint crucial city-related events that demand
advanced processing and response [64]. Nonetheless, some IoT applications/systems
for smart cities have strict processing and delay constraints. These real-time applica-
tions present the greatest obstacles to cloud-based services. Consequently, FogC and
Edge Computing have emerged as viable computing paradigms for designing, imple-
menting, deploying, and controlling such systems/applications. These paradigms
bring computing resources closer to the IoT/device plane so that the primary computa-
tion can be done locally [65,66]. Each computing paradigm offers particular assistance
based on the requirements of the application at hand. For example, to support a cloud-
based SCA, ClCom offers centralized storage and processing capacity. For certain
SCAs, ClCom can offer scalable processing power and data storage [5]. The features of
ClCom (e.g., powerful processing, massive and scalable data storage, and cutting-edge
software services) can be used to provide various support services for a variety of
SCAs. ClCom can be the primary control and management platform for SCAs. The
city’s ClCom services can be used to connect various sensors and actuators for SCAs
to gather, process, store, and manage sensor data for various SCAs. Vast volumes
of data are gathered across a smart city, which can eventually become big data. The
sophisticated platforms required for storing and analyzing this massive amount of
data to improve operations and planning can be provided by Cloud Computing. To
effectively support SCAs, the communication between city sensors and actuators and
ClCom may involve various communication requirements. The network architectures
used in the smart city should meet these requirements. Smart applications require
the integration of sensors, actuators, and the cloud, and they can only function well
with a robust network that offers good communication services linking both sides.
The fact that cloud services are either provided at a single central location or across
numerous distributed platforms in various locations is another problem that occurs
when adopting ClCom for a smart city. For many cloud applications, the distributed
ClCom strategy can offer greater quality and dependability support [67]. However,
Electronics 2023, 12, 2490
14 of 63
it is frequently necessary to establish effective communication channels between the
distributed ClCom facilities that are present in various locations. The dependability
and efﬁciency of the networks linking all components on both sides present another
problem when using the cloud. There are issues with delays, dropped packets, and
unstable connections when the Internet is involved. To consider these challenges,
the SCA architecture must be carefully studied, as must the planning and control of
network resources and communication models. However, some elements cannot be
avoided, such as transmission delays. Ksentini et al. [68] investigated the QoS require-
ments of many IoT/cloud-enabled applications in a FogC environment to recognize
QoS metrics. The authors introduced a QoS management model (QoS-Fog) that is
inspired by the work of the OpenFog consortium on the reference architecture [69] for
a FogC system.
3.2. Features and Challenges of Smart City Networks
A smart city network has the following features [70]:
1.
Large Densities: A smart city network has a very large density as thousands of smart
devices are distributed in the area of a city.
2.
Abnormal Trafﬁc Patterns: Cascading or synchronization among smart devices produces
extremely bursty or correlated trafﬁc patterns. These trafﬁc patterns differ from
the regular social-generated trafﬁc patterns on which most existing schemes and
technology used in our society are based.
3.
Disorganized Network Topology: Unlike the widely used wireless connectivity features,
smart city networks often adhere to a mesh network topology. The problem arises
when smart devices communicate across unreliable wireless channels, where packet
losses caused by wireless channel special properties are extremely common and even-
tually have an impact on the functioning of the smart city system. Therefore, it appears
very improbable that a single high-throughput backbone can be deployable soon.
4.
Heterogeneity: SCAs use a variety of technologies. In terms of power consumption,
latency, throughput, and communication ranges, each of these technologies operates
at a unique trade-off threshold. The involved dissimilar technologies must coexist on
a single platform.
5.
Coexistence of heterogeneous technologies: Communication technologies used in smart
cities are distributed over the same radio space. At the same time, independent radio
infrastructures are connected through a variety of wireless channels. Under such
circumstances, the SCA must handle interference issues with competence.
6.
Security and Privacy: SCAs are extremely vulnerable to several risks from malevolent
users. The majority of specialized smart sensors, actuators, and other intelligent
devices are developed by designers without considering security measures. Such
applications may be highly vulnerable due to hostile actors’ ease of access to these
cutting-edge technologies and potential threats to people’s security and privacy.
The main challenges for smart city networks are as follows [70]:
•
Lack of Standardization Solutions: The IEEE 802.15.1 Bluetooth technologies for Personal
Area Networks (PANs) and the IEEE 802.11 groups for wireless LANs adopt the
concept of single-hop ad-hoc networking. These standards permit direct communi-
cation between two devices that are in the transmission range of each other. At the
same time, the multi-hop ad-hoc networking paradigm enables the communication
between any two devices which are not necessarily in their transmission range [71]. A
problem that researchers must consider is how these intricate heterogeneous sets of
devices (i.e., actuators, sensors, and other smart devices) can communicate uniformly
without any standardization. Global distributors and manufacturers must propose
and accept standardized network solutions that enable communication between di-
verse devices on homogeneous communication entities. The IEEE 802.15.4 standard
is the dominant solution that presents a sophisticated version of the Physical Layer.
This standard deals with the trade-off between data rate, communication range, and
Electronics 2023, 12, 2490
15 of 63
power consumption. Several revisions or amendments (i.e., IEEE 802.15.4g and IEEE
802.15.4e) aimed at the SCA have just been released. The IEEE 802.15.4g amendment
allows for a redesigned physical layer, allowing data rates and communication ranges
compatible with neighborhood mesh (wide) networks. Then, it is followed by another
cutting-edge modiﬁcation, known as IEEE 802.15.4e, which modiﬁes and enhances
the method used by devices to access wireless channels while also using time-slotted
channel hopping mode. This hopping mode further delivers low-power consumption
and improved dependability. From another viewpoint, many researchers customized
appropriate upper-layer protocols (i.e., the Internet Layer). They made the necessary
modiﬁcations there to make smart applications compatible with conventional infras-
tructure. Since the network of low-power smart devices is conﬁned, the researchers
developed numerous adjustments to the Internet protocols to make them easily adapt-
able. For example, the most notable IETF projects are RPL [72] and 6LoWPAN [73],
which greatly aid in creating and adapting smart city scenarios.
•
Interference problem: Sophisticated technologies that are spread across the same radio
space and independent radio infrastructures are linked via a range of wireless channels.
Because of this, the smart application must handle interference problems in such
situations. To share unlicensed bands, numerous networks must cooperate and be
compatible with one another.
•
Vertical handover (soft): Multiple radios are used by the rapidly expanding number of
smart devices being developed. These devices should be able to recognize and use the
best interface that is currently available while balancing power usage and throughput.
•
D2D Communications: In the IoT context, there are numerous D2D communication de-
mands. Unfortunately, conventional network gateways cannot handle such generated
messages from heterogeneous devices.
•
Short Communicating Messages: Internet-based protocols support and recommend
acceptable performance for longer data packet scenarios. However, smart devices
communicate with one another using short messages (since most of them are tiny
and operate over low-powered battery devices). To this end, short communicating
messages will positively impact network congestion detection and avoidance policies
and promote in-band aggregation.
•
Local Network Trafﬁc Pattern: Smartphones and D2D-speciﬁc devices frequently use the
same network infrastructure. However, most cellular data networks are exclusively
planned, implemented, deployed, and managed for smartphone usage. Fitting trafﬁc
from these heterogeneous devices onto a single platform is now the main challenge
that cellular data network providers face. It is difﬁcult to integrate the trafﬁc from these
two types of heterogeneous devices into the same network infrastructure due to several
intrinsic factors and the speciﬁed features of this traditional network. Additionally,
D2D devices use a more signiﬁcant proportion of scarce resources than smartphones,
unnecessarily creating a problem of unfairness in the system [74]. Therefore, we
must ﬁrst comprehend D2D trafﬁc patterns and how they differ from trafﬁc patterns
generated by smartphones. Understanding trafﬁc patterns can provide insights into
managing and allocating shared network resources more effectively and guarantee
the highest level of service quality for both types of devices.
•
Security mechanisms: Denial of Service (DoS) attacks are a remarkable threat to the
security of smart city networks and must be identiﬁed. Some statistical methods
have been proposed to solve this problem. Such a statistical method is presented
in [75] that is based on feature distance maps that enhance the statistical analysis
process. Another security mechanism is authentication, a process of identifying
users and devices in a network and granting access to authorized persons and non-
manipulated devices. Authentication is one method to mitigate attacks on the IoT
systems such as the reply attack, the Man-in-the-Middle attack, the impersonation
attack, and the Sybil attack [76]. To realize end-to-end security, the nodes must be
encrypted. However, due to the heterogeneity of the IoT systems, some nodes might
Electronics 2023, 12, 2490
16 of 63
be able to embed general-purpose microprocessors for this task. In addition, low
resources and constrained devices can only embed application-speciﬁc integrated
circuits. Therefore, conventional cryptographic primitives are not suitable for low-
resource smart devices due to their low computation power, limited battery life, small
size, small memory, and limited power supply. As a result, lightweight cryptography
may be an efﬁcient encryption for these devices. Trust management is another security
mechanism that detects and eliminates malicious nodes and provides secure access
control. Automated and dynamic trust calculations are needed to validate the trust
values of the participating nodes in an IoT network. The majority of trust management
schemes focus on detecting malicious nodes; only a few trust-based access control
methods have been proposed. In fact, with scalability and the large number of smart
things storing sensitive data, there is an urgent need for automated, transparent, and
easy access control management so that different nodes/users can be granted different
levels of access. From another perspective, Blockchain technology can be used to
create secure virtual zones where things can identify and trust each other [77]. Self-
organization Blockchain Structures (BCS) can also be planned to set up the relationship
between Blockchain and IoT, as suggested in [78].
•
Anomaly Detection in Sensor Systems: The type of data that ﬂow through the IoT system
can vary to a great extent, in terms of either format, shape (in time and space), and
semantics. Therefore, the process of separating normal from abnormal sensed data is
extremely demanding. In the context of IoT applications, sensors are the real source
of big data, which suggests that anomaly detection at the edge could be a powerful
tool to address the inevitable data communication bottlenecks. Anomaly detection is
concerned with identifying data patterns that deviate remarkably from the expected
behavior. This is critical in the process of ﬁnding out important information about
the IoT system’s functioning, detecting abnormalities that are often rare or difﬁcult
to model or, otherwise, to predict [79]. A timely identiﬁcation of anomalies is vital to
preventing IoT system failure.
•
Advanced Techniques in Smart City Networks: Artiﬁcial intelligence (AI), machine learn-
ing (ML), and deep reinforcement learning (DRL) play a key role in the evolution of the
smart city sectors [80]. These techniques are now being developed as solutions for com-
pletely automated IoT applications. Using these techniques, the optimal analysis of
the big data is performed to reach an optimal decision. Utilizing DRL/ML approaches
can improve security; decrease energy consumption; reduce latency; and increase
precision and accuracy in surveillance, energy management, air quality prediction,
person detection, trafﬁc management, etc. For example, an intelligent transportation
system is highly based on ML- and DRL-based techniques to realize self-driving vehi-
cles and guarantee the security of connected vehicles. DRL techniques are also used to
precisely monitor and estimate the real-time trafﬁc ﬂow data in an urban environment.
In SGs, big data analytics and thus the aforementioned techniques can enhance the
safety of power grids, decision-making of power-sharing, management, and power
grid performance. In particular, SGs are making effective use of smart meter big data
for different applications such as load assessment and prediction, baseline estimation,
demand response, load clustering, and malicious data deception attacks. In health
intelligence, extensive use of AI, ML, and DRL techniques is implemented due to
high-performance IoT devices, Cloud Computing, and an increase in data rates. These
techniques can play a vital role in disease diagnosis, cure prediction, social media ana-
lytics for a particular disease, and medical imaging [81]. In cyber-security, the role of
AI-, ML-, and DRL-based techniques is also outstanding. These techniques can be used
from an advanced security perspective of IoT to confront security threats. Notably, the
accuracy and precision of the aforementioned techniques can be further enhanced by
increasing the amount of training data to strengthen their learning capabilities and
hence the automated decision efﬁciencies [82].
Electronics 2023, 12, 2490
17 of 63
4. Protocols Used for SCAs
Figure 3 shows a proposed taxonomy of networking protocols and architectures for
SCAs. It also shows the challenges in IoT communications via TCP/IP.
Electronics 2023, 12, x FOR PEER REVIEW 
18 of 65 
 
 
create a system that enables effective communication between several indoor and out-
door devices. Nevertheless, the real-time implementation of IEEE 802.11ah may need to 
be improved by the absence of an appropriate interference mechanism. 
 
Figure 3. A taxonomy of technologies facilitating communication and networking for smart cities 
with IoT-enabled application protocols and suggested networking architectures and protocols. 
IEEE 802.15.1 (Bluetooth), IEEE 802.15.4 (Zigbee), IEEE 802.11 a/b/g/n, Cellular 
3G/4G/5G/LTE/LTE-A, and IEEE 802.16 (WiMAX) are only a few examples of standards 
and protocols that should be evaluated for their applicability for various SCAs. Smart 
home automation systems, smart buildings, and smart garbage systems require 
short-range communication capability and can utilize protocols (e.g., Bluetooth and 
Zigbee) from the WPAN group. These protocols are distinguished by a lower bandwidth 
requirement, minimal power usage, and a shorter-range communication infrastructure 
environment. In contrast, LAN groups such as WiFi can be used for SCAs that require 
longer-range communication. Such applications are smart transportation management 
systems. 
The protocols from WAN groups, such as Cellular and WiMAX, can be adopted by 
applications that need wide-range communication, such as smart emergency response 
systems, weather and air quality monitoring systems, and smart grid systems. These 
features designed in terms of standards or protocols have enough capability that allows 
Figure 3. A taxonomy of technologies facilitating communication and networking for smart cities
with IoT-enabled application protocols and suggested networking architectures and protocols.
SCAs involve numerous smart things that operate on low-powered battery devices [83].
New connectivity solutions are being investigated in light of the following question:
do the currently available methods, tools, and techniques—especially those for wireless
networks—allow for the reliable handling of such a large number of smart devices?
Yaqoob et al. [84] provided details on current connectivity solutions based on WPAN
technologies such as ZigBee, WiFi, Bluetooth, and others that offer low-power D2D com-
munication. In these technologies, the throughput performance, the number of con-
nected devices, transmission ranges, etc., are severely constrained. Other technologies
(e.g., WiMAX, LTE, and LTE-A) involve signiﬁcant power consumption and are only
partially applicable to such settings. IEEE and 3GPP adapt their technologies and commu-
nication strategies to the rapidly expanding IoT-based modern communication perspective.
IEEE 802.11 (WiFi) was initially designed to maintain higher throughput performance
for fewer stations distributed over a shorter distance in an interior context. Due to the
limitations of its initial design, this standard does not support IoT applications. Hence,
Electronics 2023, 12, 2490
18 of 63
to enable IEEE 802.11 adaptive in such circumstances, the community (IEEE 802.11ah
Task Group (TGah)) developed a new power-efﬁcient protocol [55]. They aim to create a
system that enables effective communication between several indoor and outdoor devices.
Nevertheless, the real-time implementation of IEEE 802.11ah may need to be improved by
the absence of an appropriate interference mechanism.
IEEE 802.15.1 (Bluetooth), IEEE 802.15.4 (Zigbee), IEEE 802.11 a/b/g/n, Cellular
3G/4G/5G/LTE/LTE-A, and IEEE 802.16 (WiMAX) are only a few examples of standards
and protocols that should be evaluated for their applicability for various SCAs. Smart
home automation systems, smart buildings, and smart garbage systems require short-
range communication capability and can utilize protocols (e.g., Bluetooth and Zigbee) from
the WPAN group. These protocols are distinguished by a lower bandwidth requirement,
minimal power usage, and a shorter-range communication infrastructure environment.
In contrast, LAN groups such as WiFi can be used for SCAs that require longer-range
communication. Such applications are smart transportation management systems.
The protocols from WAN groups, such as Cellular and WiMAX, can be adopted by
applications that need wide-range communication, such as smart emergency response
systems, weather and air quality monitoring systems, and smart grid systems. These
features designed in terms of standards or protocols have enough capability that allows for
both synchronous and asynchronous data connections. The best-effort trafﬁc (which can
effectively tolerate latency) allows the asynchronous data connections feature to be linked
with smart city services or applications. Meanwhile, exploring synchronous data connec-
tions is possible for those services or applications that generate trafﬁc mandating strict
QoS standards such as low latency and high accessible network capacity [49]. Since IEEE
802.15.4 (Zigbee) is a short-range (low bit rate) communication protocol that often suggests
higher ﬂexibility for small devices running on low power, such a protocol can signiﬁcantly
increase network lifetime. Moreover, such a protocol encourages and indicates support
for applications and services with relatively relaxed latency and throughput conditions in
WPANs. The authors of [85] utilized a WSN based on IEEE 802.15.4 and proposed an intelli-
gent system for lighting applications. The authors highlighted the beneﬁts of using wireless
emulsions: uncomplicatedness in the implementation and deployment, relatively easier in
expanding a network, and ﬂexibility in the system due to the use of wireless technology,
which supports the usage of heterogeneous devices in the same implemented and deployed
structure. Furthermore, they emphasized the advantages of employing the same intelligent
infrastructure for a variety of services, leading to more effective management, monitoring,
and cost-effectiveness. For example, by including speciﬁc smart metering devices such as
water or gas meters, the smart network or infrastructure (that was initially established to
target smart lighting applications) can also be used for smart metering applications.
5G has just supplanted 4G with advanced access schemes called BDMA and FBMC
multiple access, which was ﬁrst launched in 2015. In the case of BDMA multiple access, an
orthogonal beam is frequently used, meaning that resources can be distributed in parallel to
each mobile base station by dividing the antenna beam in accordance with the position of
the mobile stations to enable multiple accesses to the base stations. Successively, this helps
in improving the capacity of 5G networks [86]. Speciﬁcally, the idea of moving towards
5G is based on current technology advancements and particularly on unique customer
needs. Nonetheless, it is typically presumed that implemented 5G cellular networks should
address noteworthy complications that are not successfully addressed by 4G, i.e., enhanced
network capacity and data rate, lower End-to-End (E2E) latency, reduced cost, and con-
sistent user QoE provisioning. In addition, massive and rapid growth in the number of
highly developed connected devices leads to a sharp increase in network trafﬁc and a
widening range of applications with unique dynamic requirements and features. Gupta
and Jha [86] studied numerous facilitators, such as choice or use of spectrum, massive
MIMO, trafﬁc and power management policies, ofﬂoading (local), and self-conﬁguring and
organizing networks, which can address these challenges effectively. Real-time managing
and supervising in smart city scenarios will be conceivable these days thanks to 5G. 5G
Electronics 2023, 12, 2490
19 of 63
ultimately targets some networking possibilities, i.e., ultra-Reliable and Low-Latency Com-
munications (uRLLC), enhanced Mobile Broadband (eMBB), and massive Machine Type
Communications (mMTC). In a smart city context, eMBB controls data transfer between a
variety of networked user end devices, edge devices, or cloud servers. Conversely, mMTC
aims to manage huge connected, complex devices, such as wearables, actuators, and sen-
sors, through dense urban deployment. Finally, uRLLC takes responsibility for managing
highly time-critical communication such as vehicular communication, base stations, and
edge devices communication [87]. Although 5G has completely brought about a new
revolution in the ﬁeld of networking, numerous unknown challenges still are possible in
these cases of communication when 5G is deployed in the context of smart cities. One major
problem is power-efﬁcient communication, especially when communicating low-powered
battery devices such as sensors and other smart, complex wearables. Additionally, when
two distinct technologies (4G/5G) work together, there might be a problem. Speciﬁc device-
level compatibility problems might always persist when communication infrastructures
migrate to next-generation platforms. Moreover, a big question arises, namely, how to
handle the widespread use of gadgets, particularly those in isolated or difﬁcult-to-reach
places, as well as the potential high costs associated with building and maintaining 5G
networks.
Table 2 compares protocols used for smart cities, while Table 3 evaluates standards
utilizing features and characteristics.
Table 2. Comparison of protocols used for smart cities. Adapted and extended from [49,84,88].
Communication
Technology/Standard 1
Physical Layer Speciﬁcations
Data Link Layer
Speciﬁcations 4
Data Rate 5
Coverage Area 6
Operating Frequency
Bands 2
Data Modulation and
Receiver Sensitivity 3
ZigBee/IEEE 802.15.4
2.4 GHz, 868 MHz–915
MHz (DSSS)
Data Modulation: 16-ary orthogonal modulation
(2.4 GHz) and BPSK with DE (868 MHz–915 MHz).
Receiver Sensitivity:
−85 dBm (2.4 GHz PHY)
−92 dBm (868/915 MHz PHY)
CSMA-CA, TDD
(optional)
250 Kbps
(2.4 GHz),
20 Kbps
(868 MHz), and
40 Kbps
(915 MHz)
30–50 m
Bluetooth/
IEEE 802.15.1
2.4 GHz, 2400
MHz–2483.5 MHz
(FHSS/FSK)
Data Modulation:
GFSK and PSK (for higher data rates)—π/4 DQPSK
and 8 DPSK
Receiver Sensitivity:
−70 dBm to −82 dBm (usually depends on the type of
PHY use), say, Bluetooth LE 125K (Coded) PHY can
achieve −103 dBm
TDD, M&S, FH
1 Mbps
1–100 m
WiFi/IEEE 802.11
(Legacy) (a/b/g/n)
Conventional: 2.4 GHz
a: 5 GHz (OFDM),
b: 2.4 GHz (DSSS),
g: 2.4 GHz (DSSS,
OFDM),
n: 5 GHz (DSSS,
OFDM)
Data Modulation:
Conventional: DI, DSSS, and FHSS, a: OFDM
b: HR-DSSS, g: OFDM, DSSS, and CCK
n: OFDM using MIMO and CB
Receiver Sensitivity:
Legacy: 1 Mbps: −80 dBm, 2 Mbps: −75 dBm
b: 2 Mbps: −80 dBm, 11 Mbps: −76 dBM
g: 6–54 Mbps: −82 dBm to −65 dBm
n: 1–54 Mbps: −80 dBm to −65 dBm
CSMA-CA
Conventional:
1–2 Mbps
a: 6–54 Mbps
(VMT)
b: 1–11 Mbps
(VMT)
g: 6–54 Mbps
(VMT)
n: 1–54 Mbps
(VMT)
1–100 m
WiMAX/IEEE 802.16
2.5 GHz, 3.5 GHz,
5.8 GHz
(MIMO-OFDM)
Data Modulation:
OFDM using MIMO, AMC, AAS
Receiver Sensitivity:
QPSK (1/2): −80 dBm, QPSK (3/4): −78 dBm
16 QAM (1/2): −73 dBm, 16 QAM (3/4): −71 dBm
64 QAM (2/3): −66 dBm, 64 QAM (3/4): −65 dBm
TDD, FDD
75 Mbps
1–5 Km (NLoS),
10–50 km (LoS)
LoRaWAN/LoRA
Alliance
867–869 MHz (Europe)
865–867 MHz (India)
Data Modulation:
LoRA (CSSM)
Receiver Sensitivity:
−137 dBm (SF = 12, BW = 125 KHz, NF = 6)
Pure ALOHA
with DCLs or PSA
(LBT)
250 bps–50 Kbps
(Europe)
NS (India)
2–5 km
3G (WCDMA
Technology) (BIS)
1.92–1.98 GHz,
2.11–2.17 GHz
(licensed)
Data Modulation:
AM/PSK using QAM
Receiver Sensitivity:
−102 dBm
CDMA
384 Kbps
(deployed)–
2 Mbps
1–10 km
GPRS
900–1800 MHz
Data Modulation:
GMSK
Receiver Sensitivity:
−159 dBm
TDMA, FDMA,
and FH
Up to 170 Kbps
1–10 km
Z-Wave/Z-Wave
Alliance
900 MHz
Data Modulation:
FSK/BFSK (for 9.6 Kbps and 40 Kbps)
GFSK (for 100 Kbps) with BT = 0.6
Receiver Sensitivity:
−104 dBm
CSMA-CA
9.6 Kbps–100 Kbps
100 m
Electronics 2023, 12, 2490
20 of 63
Table 2. Cont.
Communication
Technology/Standard 1
Physical Layer Speciﬁcations
Data Link Layer
Speciﬁcations 4
Data Rate 5
Coverage Area 6
Operating Frequency
Bands 2
Data Modulation and
Receiver Sensitivity 3
LTE/3GPP
2.5 GHz, 5 GHz,
10 GHz (OFDM CP for
downlink, SC-FDMA
CP for uplink)
Data Modulation:
AMC, QPKS, 16QAM
Receiver Sensitivity:
−103 dBm (LTE/A signal—5 MHz BW, QPSK, CR = 1/3,
SNR = −1 dB, NF of LTE/A-based receiver chain = 5 dB)
−90.7 dBm (LTE/A signal—5 MHz BW, 16QAM,
CR = 2/3, SNR = 11.3 dB, NF of LTE/A-based receiver
chain = 5 dB)
TDD, FDD
75 Mbps (UL)
300 Mbps (DL)
30 km
LTE-A/3GPP
2.5 GHz, 5 GHz,
10 GHz, 15 GHz,
20 GHz (OFDM CP for
downlink, SC-FDMA
CP for uplink)
500 Mbps (UL)
1 Gbps (DL)
30 km
5G (New Radio (NR)
Air Interface) (Single
Uniﬁed, 4G + World
Wide Wireless Web
(WWWW))
For 5G mmWave
access, an extensive
spectrum of bands
between 13 and 86 GHz
has been recommended
C-band (3300–4200 and
4400–5000 MHz)
Data Modulation:
UFMC, F-OFDM, and FBMC
5G New Radio (NR) Uplink Receiver Sensitivity:
PRef = TN + 10log10(BW) + NF+ IM + SNR
At room temperature, the TN in a 50 system is
−174 dBm/Hz. For Wide Area BS, Medium Range BS,
or Local Area BS, the base station NF is 5 dB, 10 dB, or
13 dB, respectively. IM = 2 dB. The SNR value is that at
which 95% of the maximum throughput is achieved.
PRef = TN + 10log10(BW) + NF+ IM + SNR = −93 db,
(For NF = 5 dB, BW = 100 MHz, SNR = −1)
TDD, FDD
10–50 Gbps
Depends on
changing cell
radius (1 km to
several km’s)
1: LoRaWAN: Long-Range Wide Area Network, 3GPP: Third-Generation Partnership Project, WCDMA: Wideband
Code Division Multiple Access, BIS: Broadband Internet Service, GPRS: General Packet Radio Services, LTE: Long-
Term Evolution, LTE-A: LTE-Advanced, 3GPP: Third-Generation Partnership Project. 2: DSSS: Direct-Sequence
Spread Spectrum, FHSS/FSK: FHSS: Frequency Hopping Spread Spectrum/Frequency Shift Keying, OFDM:
Orthogonal Frequency-Division Multiplexing, MIMO-OFDM: Multiple-Input/Multiple-Output-OFDM, OFDM
CP: OFDM with Cyclic Preﬁx, SC-FDMA CP: Single Carrier-Frequency Division Multiple Access with Cyclic Preﬁx.
3: BPSK with DE: Bi-Phase Shift Keying with Differential Encoding, GFSK: Gaussian Frequency Shift Keying,
PSK: Phase Shift Keying, π/4 DQPSK: π/4 Phase Differential Quaternary PSK, 8 DPSK: 8-Phase Differential
PSK, DI: Diffuse Infrared, DSSS: Direct-Sequence Spread Spectrum, FHSS: Frequency Hopping Spread Spectrum,
HR-DSSS: High Rate-DSSS, CCK: Complementary Code Keying, MIMO: Multiple-Input/Multiple-Output, CB:
Channel Bonding, AMC: Adaptive Modulation Coding, AAS: Adaptive Antenna System, QPSK: Quadrature PSK,
QAM: Quadrature Amplitude Modulation, CSSM: Chirp Spread Spectrum Modulation, SF: Spreading Factor, BW:
BandWidth, NF: Noise Figure, AM/PSK: Amplitude-Modulation PSK, GMSK: Gaussian Minimum Shift-Keying,
BFSK/FSK: Binary-Frequency Shift Keying, BT: Bandwidth-Time product, SNR: Signal-to-Noise Ratio, CR: Code
Rate. 4: CSMA-CA: Carrier Sense Multiple Access-Collision Avoidance, TDD: Time division duplexing, M&S:
Master and Slave, FH: Frequency Hopping, FDD: Frequency Division Duplexing, DCLs: Duty-Cycle Limitations,
PSA (LBT): Polite Spectrum Access (Listen Before Talk), TDMA: Time Division Multiple Access, FDMA: Frequency
Division Multiple Access. 5: VMT: Varying Modulation Types, NS: Not Speciﬁed, UL: UpLink, DL: DownLink.
6: LoS: Line of Sight, NLoS: Non-LoS.
Table 3. Evaluation of standards utilizing their features.
Communication
Technology/Standard 1
Features 2
Topology 3
Network Category 4
Limitations
ZigBee/IEEE 802.15.4
It allows short-range transmissions. It requires lesser
bandwidth and minimal power usage. It clears channel
assessment (for the case of CSMA). Dynamic selection of
operating channels for coexistence. Packet strength signal for
effective forwarding and location. It is designed and suited for
PAN-based applications.
Mesh
WPAN
Low data rate and short
coverage.
Bluetooth/IEEE 802.15.1
It creates dynamic (ad-hoc) connections using radio waves. It
presents low-cost, robust, low-power solutions for P2P
communication. It allows for short-range transmissions. It is
mainly designed and suited for PAN-based applications. It
suggests support for IoT devices, via BLE (version), and
conserves power by continually maintaining devices in sleep
mode until they are connected. It helps with quick device
pairing and reconnections, which improves device availability
and operational efﬁcacy.
P2P
WPAN
Short coverage and less
secure.
Electronics 2023, 12, 2490
21 of 63
Table 3. Cont.
Communication
Technology/Standard 1
Features 2
Topology 3
Network Category 4
Limitations
WiFi/IEEE 802.11
(Legacy) (a/b/g/n)
General features:
It can aid both in an infrastructure-mode and an ad-hoc
manner. These standards are quickly utilized in temporary
and permanent LAN installations and deployments because of
their ﬂexibility and performance. It supports network
management service and asynchronous communication. It
suggests time-constrained delivery services and support for
broadcast and multicast services. Moreover, it offers support
for long-range communication.
Speciﬁc features:
IEEE 802.11a—works on the 5 GHz band, has a lesser
interference level than other devices but has higher
propagation losses compared to the 2.4 GHz band.
IEEE 802.11b—works on the 2.4 GHz band. There may be
interference issues with those devices, which, too, operate on
the 2.4 GHz band. However, it offers a higher capacity and
reachability than the 5 GHz spectrum to get through
obstructions. It can also provide support for the ARS
method [79], which allows an IEEE 802.11b device to
dynamically switch from its theoretical maximum data rate
(11 Mbps) to lower data rates such as 5.5 Mbps, 2 Mbps, or
even 1 Mbps if interference rises.
IEEE 802.11g—faster operating speed and generally has better
signal range, being not easily obstructed. The IEEE
802.11g-based devices used OFDM to carry higher data rates
while providing robustness against multipath fading/effects.
However, additional modulation techniques (as shown in
Table 2) are also used to preserve and manage compatibility.
IEEE 802.11n—offers superior performance to its other peer
standards by suggesting modiﬁcations in MIMO, OFDM,
power saving, antenna technology, and wider channel
bandwidth. The IEEE 802.11n-based access point can operate
in Legacy, Mixed, and Greenﬁeld modes [89]. This standard
effectively exploits MIMO to take complete beneﬁt of the
available data rate.
Star
LAN
Short coverage,
comparatively higher
signal attenuation, less
reliable and stable
compared to wired
connections.
WiMAX/IEEE 802.16
It was introduced initially to overcome the disadvantages of
mobile networks and WLANs. It supports high data
transmission rates while allowing more coverage than
WLANs. It provides numerous QoS scheduling mechanisms
supporting heterogeneous trafﬁc, such as VoIP, voice data
(trafﬁc), video data/streams, and Internet trafﬁc. Moreover, it
has speciﬁc features such as high-speed Internet; a
long-distance communication facility; and support for security,
mobility, and scalability.
P2MP, Mesh
MAN
Not widespread and
operationally expensive.
LoRaWAN/LoRA
Alliance
It provides long-range transmissions and offers robustness
from interferences. The PHY layer of this standard or protocol
modulates the signal in the SUB-GHz ISM band. This
speciﬁcation aims to provide low-power WANs with
capabilities speciﬁcally required to facilitate low-cost mobile
secure bidirectional communication. Additionally, it deﬁnes
the idea of geolocation, which can be quickly applied to enable
GPS-free tracking applications.
It utilizes minimum amounts of power, and hence IoT-based
sensors and actuators can operate for a long time.
Additionally, it manages less bandwidth utilization, making it
their default choice for IoT-based deployments.
The overall architecture (i.e., star) is relatively straightforward
since a LoRaWAN-based GW can be designed to manage
numerous end devices or nodes. It also offers secure
communication between the end device or node and the
application server using the AES-128 encryption standard.
Star
WAN
Short coverage.
3G (WCDMA
Technology) (BIS)
This MNwT was initially engineered and designed to transmit
and receive multimedia trafﬁc with variable and high bit rates.
This standard (having a comparable spectrum everywhere it is
used) enables seamless worldwide networking. It utilizes the
packet switching concept for data communication and circuit
(or optional packet) switching technique for voice
communication. It allows global roaming across a similar type
of network (wireless) called a cellular network at 384 Kbps or
even higher (up to several Mbps).
-
WAN
Spectrum licensed cost,
huge power
consumption, and
insufﬁcient bandwidth to
handle growing user
demands.
GPRS
As an enhancement over GSM, GPRS adds several nodes
called GSNs to support end-to-end packet-switched services in
the system. It operates by aggregating several separate data
channels by the concept of packetization. Moreover, it is a
low-cost technology that suggests a packet-based radio service.
It offers the capabilities such as a high transfer rate,
volume-based billing, shorter access time, improved radio
resource utilization, and simpliﬁed access to packet data
networks [90].
-
WAN
Low data rate.
Electronics 2023, 12, 2490
22 of 63
Table 3. Cont.
Communication
Technology/Standard 1
Features 2
Topology 3
Network Category 4
Limitations
Z-Wave/Z-Wave
Alliance
It allows for operation in the low-frequency range, hence
offering better performance. It supports low-power mesh
networks and employs BFSK modulation. The lower frequency
with longer wavelength allows Z-Wave devices to establish
more reliable and faster connections since these parameters
assist these devices in easily penetrating objects and walls.
Six layers of backward compatibility provide version
interoperability. The interoperability facility among
Z-Wave-based smart or conventional devices assists in
blending several applications at once, such as HA, SA, and LA.
Star, cluster,
mesh
WPAN
Difﬁculty in mobility
management. Fewer
security features.
LTE/3GPP
It is a 3GPP interface (radio) based on UMTS/HSPA and
GSM/EDGE networking technologies. It suggests
improvements in data rate and capacity by employing new
and modiﬁed modulation schemes. Moreover, it offers support
for FDM and TDM techniques. It adopts an IP-based network
model that promises a seamless handoff of voice and data to
cell towers using an older technology.
Star
WAN
High operational costs
because extra antennas
are used at network base
stations to transmit data.
LTE-A/3GPP
Through modifying and proposing novel PHY layer
speciﬁcations or implementations and reforming the CN,
LTE-A offers much-improved performance over UMTS/HSPA
MNwTs. It can speed up to 3 Gbps download and 1.5 Gbps
upload. Additionally, it has various antenna systems that
simplify switching between cell regions, as well as
cutting-edge transmission techniques that pack more data per
second into each hertz of the spectrum and improve
throughput performance at the level of cell boundaries.
Subsequently, it leads to superior performance in terms of
consistent connection and capacity (network) [89,91,92].
P2P
WAN
The installation of towers
to improve signals while
a smart device is in
motion may result in
signiﬁcant costs.
Device compatibility is a
concern because older
models of devices that
do not support 4G LTE
cannot connect to LTE
networks.
5G (New Radio (NR) Air
Interface) (Single Uniﬁed,
4G + World Wide
Wireless Web (WWWW))
This technology addresses signiﬁcant challenges: a massive
and quick increase in highly sophisticated connected devices
contributes to a sharp escalation in network trafﬁc and an
expanding variety of applications with distinct dynamic
demands and features.
Since LTE user equipment is not required to be able to operate
on an NR carrier, NR is designed to be optimized for
performance without taking backward compatibility into
account. Moreover, NR can support operations in licensed
spectrum bands from below 1 GHz to 52.6 GHz with a
spectrum expansion facility.
In the case of mmWave frequencies, excellent capacity and
high data rates are possible. This technology’s ultra-lean
design seeks to decrease interference and improve system
power efﬁciency by effectively reducing always-on
transmissions [93,94].
This technology utilizes sophisticated access procedures such
as Beam Division and FBMC Multiple Access to adapt 4G to
5G networks. Beam Division Multiple Access (BDMA)
schemes’ central design principle is concurrently serving
numerous mobile users. This technique typically uses an
orthogonal beam, which suggests that resources can be
allocated in parallel to each mobile base station by separating
the antenna beam in accordance with the position of the
mobile stations to enable numerous accesses to the base
stations. This subsequently assists in improving the capacity
of 5G networks [79].
E2E Network
Slicing
WAN
In the case of the NLoS
state, the effectiveness of
this technology needs to
be thoroughly examined,
particularly when it runs
at high frequencies
because wireless
channels’ basic nature is
inconsistent when the
frequency changes to
higher values. Due to
higher frequencies’
extreme vulnerability to
interference from
obstructions, this
disadvantage exists.
Subsequently, this
hampers the throughput
performance of
underlying deployed
Layer-4 protocols such as
TCP and MPTCP.
1: LoRaWAN: Long-Range Wide Area Network; 3GPP: Third-Generation Partnership Project; WCDMA: Wideband
Code Division Multiple Access; BIS: Broadband Internet Service; GPRS: General Packet Radio Services; LTE:
Long-Term Evolution; LTE-A: LTE-Advanced; 3GPP: Third-Generation Partnership Project. 2: CSMA: Carrier
Sense Multiple Access; PAN: Personal Area Networks; P2P: Point-to-Point; BLE: Bluetooth Low Energy; LANs:
Local Area Networks; ARS: Adaptive Rate Selection; OFDM: Orthogonal Frequency Division Multiplexing;
MIMO: Multiple-Input/Multiple-Output; WLANs: Wireless LANs; VoIP: Voice over Internet Protocol; PHY:
PHYsical; ISM: Industrial, Scientiﬁc, and Medical; WANs: Wide Area Networks; GPS: Global Positioning System;
GW: GateWay; AES: Advanced Encryption Standard; MNwT: Mobile Network Technology; GSM: Global System
for Mobile communication; GSNs: GPRS Support Nodes; HA: Home Automation; SA: Security Automation;
LA: Lighting Automation; UMTS: Universal Mobile Telecommunications System; HSPA: High-Speed Packet
Access; FDM: Frequency Division Multiplexing; TDM: Time Division Multiplexing; CN: Core Network. 3: P2P:
Point-to-Point; P2MP: Point-to-MultiPoint; E2E: End-to-End. 4: WPAN: Wireless Personal Area Network; LAN:
Local Area Network; WAN: Wide Area Network; MAN: Metropolitan Area Network.
Electronics 2023, 12, 2490
23 of 63
4.1. IEEE 802.11 Standards
Table 4 presents IEEE 802.11 standards and their features.
Table 4. IEEE 802.11 standards and their enhancements/features.
Standards (Year Released)
Enhancement(s)/Feature(s) *
Target
IEEE 802.11 (1997) (Original)
The standard and its amendments serve as the foundation for
wireless network products bearing the WiFi brand. This signiﬁes
two raw data rates of 1 and 2 Mbps that must be transferred via
DSSS and FHSS at 2.4 GHz in the ISM band.
Wireless Standard (basic)
IEEE 802.11b (1999)
This standard is intended to operate in the 2.4 GHz spectrum;
however, the level of interference issues is higher when this
standard-based device tries to interoperate with many other
devices/standards operating on the same band. It can attain a
theoretical data rate of 11 Mbps. Nevertheless, dynamic
adaptations can be applied to the transfer rate subject to the current
interference level and signal power to minimize the error rate (ARS
Policy). Depending on the channel conditions, the raw data rates
can be adapted to 5.5 Mbps, 2 Mbps, and 1 Mbps. Additionally, it
provides somewhat simpler deployment processes (e.g., upgrading
the current chipsets) as it demonstrates backward compatibility
with the original standard due to the use of CDMA and DSSS (same
as the original standard) [89]. The coverage indoor and outdoor
ranges are 115 feet and 460 feet, respectively.
WiFi-1
IEEE 802.11a (1999)
Designed to operate on the 5 GHz spectrum and to have the least
amount of interference compared to other devices. Depending on
the needs, the raw data rates can be changed to 48 Mbps, 36 Mbps,
24 Mbps, 18 Mbps, 12 Mbps, 9 Mbps, and 6 Mbps. However, it can
reach a theoretical transfer rate of 54 Mbps. The coverage indoor
and outdoor ranges are 115 feet and 391 feet, respectively [89].
WiFi-2
IEEE 802.11g (2003)
Allows for device compatibility with devices that operate and
follow IEEE 802.16b standards. It can also attain a theoretical
transfer rate of 54 Mbps. In real-time situations, it can achieve a
practical data rate of 24 Mbps. Nonetheless, when IEEE
802.11b-based devices are introduced into IEEE 802.11g networks,
or when these heterogeneous compliant devices interoperate, the
rate decreases drastically to accommodate IEEE 802.11b-based
transmission speeds every time that the compliant device tries to
communicate [89]. The coverage indoor and outdoor ranges are
148 feet and 296 feet, respectively.
WiFi-3
IEEE 802.11e (2005)
It speciﬁes a set of QoS augmentations for WLAN applications
through extensive amendments to the MAC sub-layer. It addressed
QoS requirements by emphasizing two-channel access schemes:
(1) the contention-based EDCA scheme and (2) the contention-free
HCCA scheme. This standard, via EDCA, provides trafﬁc
prioritization support based on QoS classes (similar to
differentiated services). Conversely, this standard suggests
parameterized QoS (similar to integrated services) via HCCA. It
also speciﬁes enhancement over the conventional IEEE 802.11
power saver method (APSD) and reduces the signaling load [95]. It
is designed to operate at frequencies ranging from 2.4 to
2.4835 GHz or from 5.75 to 5.850 GHz. This standard also speciﬁes
that a high transmission rate may not be sufﬁcient to meet the QoS
requirements imposed by real-time audio, voice, video, and
live-streaming applications. Following that, the provisions of trafﬁc
prioritization at the MAC sub-layer were insisted upon.
QoS improvements
Electronics 2023, 12, 2490
24 of 63
Table 4. Cont.
Standards (Year Released)
Enhancement(s)/Feature(s) *
Target
IEEE 802.11n (2009)
This standard was suggested while keeping the increased speed
requirement in mind. Later, it was able to boost the attainable
speeds of WiFi networks beyond what was possible with 802.11g.
Achieving such high performance required several new features,
including a modiﬁed OFDM scheme, power-saving mechanisms,
antenna technology, MIMO, and wider channel bandwidth.
Nonetheless, backward compatibility in the standard has been
signiﬁcantly affected (reduced) under exceptional scenarios.
Whenever or not an old standard compliance-based device attempts
to communicate with an IEEE 802.11g-based device in an 802.11g
network, the network’s operation, performance, and other
capabilities suffer signiﬁcantly. These standard-based APs can
operate in Legacy mode (choosing one standard amongst
802.11a/b/g), Mixed mode (choose (out of 802.11a/b/g/n) and
operate on heterogeneous conditions), and Greenﬁeld mode
(operate with a single (common) 802.11n altogether) [89]. It can
reach a theoretical transfer rate of 600 Mbps. The coverage indoor
and outdoor ranges are 230 feet and 821 feet, respectively.
WiFi-4
IEEE 802.11ac (2013)
This standard (called initially VHT) was suggested while keeping
increased speed requirements in mind (likewise with other
standards). This standard was later able to increase the achievable
speeds (up to 1 Gbps (minimum) to 7 Gbps (maximum)) of WiFi
networks beyond what 802.11n was capable of. The standard
enables the transmission of HD videos, online interactive games,
live-streaming, and other demanding applications. It operates
using MU-MIMO technology, which enables a single AP and its
antenna to send data concurrently to several devices. As a result,
this helps to increase airtime efﬁciency so that every associated
client—regardless of the 802.11 types it operates on—ﬁnally
receives the amount of airtime it is supposed to receive, depending
on the technology used.
WiFi-5
IEEE 802.11ah (2017)
Designed to operate on unlicensed spectrum below 1 GHz, it can
provide signiﬁcantly more transmission coverage than traditional
802.11 standards, which typically operate on 2.4 and 5 GHz bands.
This standard can be employed in those scenarios where accessible
bandwidth is comparatively narrow. It can normally apply with
WiFi (outdoor) for performing CTO, large-scale WSNs (i.e., smart
grid), and extended-range hotspots. Supporting a reasonably large
transmission range/coverage property aids in managing large-scale
networks where the number of devices may be much greater than
what the conventional 802.11 standard can support. It advises that
changes to the PHY and MAC layers be made to provide important
improvements including energy-saving capabilities, support for
accommodating a high number of devices, reliable media access
techniques, and throughput performance improvement by using
small frame formats [96].
Extended coverage, low-power
WLAN
IEEE 802.11ax (2021)
This standard was proposed with the consideration of higher speed
requirements. Later, this standard increased WiFi network
achievable speeds above what was made possible by earlier
standards. Speciﬁcally, it can offer support for a 10 Gbps data rate,
consistency, and low power consumption. It operates using
MU-MIMO and MU-OFDMA multi-user technologies, which
enables a single AP and its antenna to send data concurrently to
several end devices. Although the 802.11ac standard is where
MU-MIMO technology was ﬁrst introduced, 802.11ax now allows
for groups of up to eight clients. In addition, this standard also
suggests several improvements in spatial reusing policies and
power-saver schemes [97].
WiFi-6
* ARS: Adaptive Rate Selection, CDMA: Code Division Multiple Access; DSSS: Direct Sequence Spread Spectrum;
EDCA: Enhanced Distributed Channel Access; HCCA: HCF-Controlled Channel Access; APSD: Automatic
Power Save Delivery; APs: Access Points; MU-MIMO: Multi-User, Multiple Input, Multiple Output; VHT: Very
High Throughput; CTO: Cellular Trafﬁc Ofﬂoading; MU-OFDMA: Multi-User Orthogonal Frequency Division
Multiple Access.
Electronics 2023, 12, 2490
25 of 63
4.2. IEEE 802.15.1
The IEEE 802.15.1 (WPAN protocol) uses the 2.4 GHz spectrum and a master/slave
time division duplex mechanism that operates smoothly in the 10 to 100 m range with a
1 Mbps data rate. This technology uses modest data rates for short-range services designed
to use less power. Recent implementations of this technology include Bluetooth and
Bluetooth Low Energy (BLE), offering IP connectivity to aid the IoT [98]. The deployment
of services offered for tracking and localization devices is typically suggested by BLE-based
devices, which are recognized as BLE beacons. These beacons produce a signal that other
compatible devices can pick up between 50 and 70 m away. Using such a beacon promises
greater indoor localization accuracy than other technologies such as WiFi or GPS. They can
be used for a wide range of services targeted toward information dissemination, the launch
of points of sale, user tracking, etc., thanks to this capability. Additionally, to provide
speciﬁc services of interest, it is frequently required to combine the BLE technology with
other technologies such as WiFi [99]. Originally, the aim of BLE technology (Bluetooth
Classic Radio (BCR)) was to provide a continuous wireless connection, i.e., BlueTooth
Basic Rate/Enhanced Data Rate (BT BR/EDR). It became the perfect option for the IoT
since it permits connectivity and audio-streaming applications using brief bursts of long-
distance radio, which lowers the battery consumption of mobile devices (because they need
not be connected all the time). Using the idea of dual-mode chipsets and the new BLE
speciﬁcation, smartphones or regular phones can be linked to other heterogeneous devices
(such as headphones) in BR/EDR mode. Otherwise, they can be connected to wearables
in LE mode. A low-power radio called BCR, or BT BR/EDR, intends to broadcast data
across 79 channels in the 2.4 GHz unlicensed frequency range. Wireless audio streaming is
primarily made possible through BCR, which has evolved into the industry-standard radio
protocol for in-car entertainment systems, wireless speakers, and headphones. BLE aims to
transmit data over 40 channels in the 2.4 GHz unlicensed frequency range. To facilitate the
deployment of dependable and large-scale device networks, BLE seeks to provide support
for a wide range of communication methods, typically P2P; broadcast; and, most notably,
mesh [100]. This unique Bluetooth feature can be used to create distribution and locating
maps utilizing ﬁngerprint templates for indoor device and user localization. Due to BLE’s
greater susceptibility to abrupt fading and substantial changes in received signal strength,
it has been proven that using BLE is more efﬁcient than using WiFi-based solutions [99,101].
However, Bluetooth technology has a problem with increasing power usage, particularly
when its BR/EDR mode is used in an IoT context. This is because this mode allows the
master nodes to continuously poll the slave nodes, even when there is no data transmission.
The researchers [102,103] already brought up this issue, addressed it, and offered a variety
of scheduling techniques for polling the slave nodes. Moreover, the BR/EDR mode reveals
a lack of scalability that further restricts the performance of the system.
4.3. LoRA
The LoRa protocol was primarily used for WAN applications and operated as a low-
data-rate, low-power technology on the sub-1 GHz spectrum that could go up to 10 km.
LoRa communicates on three classes of bandwidth: 125, 250, and 500 KHz. Even while
this technology can function at the largest bandwidth class, which further improves data
rate, it still causes issues with high power consumption, a shorter communication range,
and an increase in the likelihood of interference because it is free to operate in a wider
frequency spectrum. This method is founded on the idea of spread spectrum modulation
and a CSSM variant with a spreading factor ranging from 7 to 12. The transmission range
will expand as the spreading factor’s value rises, but the power consumption will rise
as well. The CSSM utilizes complete allocated bandwidth, thereby making it resilient to
channel noise and multi-path fading, but it does not differentiate the noise in the channel
such as DSSS. In contrast to the FSK modulation approach, which normally identiﬁes
signals that are 8 to 10 dB above the noise ﬂoor, the CSSM feature enables this technology
to sense, perceive, and capture signals that are 19.5 dB below the noise ﬂoor [103]. Its
Electronics 2023, 12, 2490
26 of 63
architecture uses a star network topology and includes gateways and end nodes. In this
design, end nodes are referred to as slaves and run on battery-powered devices with
limited power, but gateways are thought of as powerful machines that gather data from
slave nodes. Furthermore, LoRaWAN is a communication layer that operates on top of
LoRA. LoRaWAN incorporates the basic LoRa criteria and suggests improved adaptability
and suitability for low-power applications. This layer/technology has advantages over
cellular technologies, which are expected to be battery hungry by the concept. In practice,
LoRaWAN improved network features and functionalities by addressing the concept of
a specialized server (network) and speciﬁcally deﬁning numerous device types to meet
the needs of each specialized application. Managed communication, packet ﬁltering, and
packet scheduling are all made possible using specialized network servers. LoRaWAN
has also facilitated bi-directional-employing adaptive transmission power and rate, which
aids in optimizing network performance in terms of power consumption and throughput.
This technology can be employed for a wide range of applications, such as smart health
nursing [104], trafﬁc monitoring [105], agriculture monitoring [106], localization [107],
and smart grid applications [108]. In particular, this technology is useful for non-latency-
sensitive applications and those that call for extensive deployments. Haxhibeqiri et al. [109]
and Adelantado et al. [110] emphasized that LoRaWAN is feasible for smart metering,
tracking, and localization-based applications. At the same time, it is not so feasible for
real-time monitoring and video surveillance.
4.4. WiMAX
WiMAX can handle high capacity, i.e., a potential peak data rate of 60 Mbps for an
entire downlink operation and a rate of 28 Mbps for an entirely uplink operation, based on
the original IEEE 802.16 air interface standard (2004) [111] and the IEEE 802.16e amend-
ment [112]. It can be done using two antennas with a channel bandwidth of 10 MHz.
Additionally, it may provide support for multimedia services with different trafﬁc charac-
teristics and wide area mobility with changing QoS needs. Additionally, it offers a variety
of QoS scheduling options for accommodating heterogeneous trafﬁc, such as Internet data
trafﬁc, VoIP (Voice over IP), classic audio trafﬁc, and voice and video streams [113].
Table 5 shows the speciﬁed WiMAX standards and their operational parameters [114].
This standard provides a communication channel between geographically separated de-
vices. As a result, the maximum achievable covered distance ranges between 30 km and
100 km. However, this technology has some drawbacks, such as high installation costs
and the possibility of complications and irregularities when dealing with high-deﬁnition
multimedia trafﬁc.
Wireless network trafﬁc has recently increased extraordinarily due to the rapid pro-
liferation of smart handheld devices, sensors, and actuators. These devices, along with
smart controllers, mobile users, and other smart services-based specialized devices, are
the most common use cases for W-LANs in dense network environments. In such a dense
network environment, interference is a critical issue that must be addressed if satisfactory
performance and, thus, proﬁcient spatial frequency reuse is required. Subsequently, the
standards IEEE 802.11 were designed and implemented to support these requirements.
Numerous international organizations, including IEEE and 3GPP, adopted and improved
their technologies in response to changing needs and the emerging IoT market. For instance,
the original IEEE 802.11 (WiFi) standard was designed to support and provide superior
throughput performance to a small number of stations located close to each other, and as a
result, this technology was not particularly useful for IoT systems. As a result, to address
the challenges and requirements of IoT, the IEEE 802.11ah Task Group (TG) was formed by
the IEEE 802.11 MAN/LAN Standards Committee to redesign and extend the applicability
of WiFi standards to IoT scenarios. They focused on the critical issue of power-aware
efﬁcient schemes and protocols to extend the functionality and applicability of 802.11-based
networks while dealing with a variety of small power-constrained smart outdoor and
indoor devices [55,97].
Electronics 2023, 12, 2490
27 of 63
Table 5. WiMAX standards and their operational parameters.
Speciﬁc
Standards
IEEE 802.16
(2001) 1
IEEE 802.16a (2003) 2
IEEE 802.16b 3
IEEE 802.16c
(2002) 4
IEEE 802.16d
(2004) 5 (Fixed)
IEEE 802.16e
(2005) 6
IEEE 802.16m
(PAI) 7
Operating
Frequency
Band
10–66 GHz (LS
RF Bands)
2–11 GHz (LS/ULS RF
Bands) (WMANs)
5–6 GHz (ULS
RF Bands)
10–66 GHz
2–11 GHz
(LS/ULS RF
Bands)
2–6 GHz (LS RF
Bands)
450–3600 MHz
(LS/ULS RF
Bands)
Data Rate (max)
32–134 Mbps
(28 MHz)
75 Mbps max, 20 MHz
channelization
75 Mbps
70 Mbps (20
MHz)
75 Mbps
90 Mbps
100 Mbps (MA)
and 1 Gbps (FA)
Coverage Area
(Max)
10–50 Km
45 km
45 Km
50 km
45 km
100 km
100 km
Propagation
model (Channel
Condition)
LoS only
NLoS
NLoS
LoS
LoS/NloS
NLoS
NLoS
Channel
Bandwidth
20, 25, and 28
MHz
Selectable between 1.25
and 20 MHz
10, 20 MHz (5
MHz is optional)
28 MHz
Selectable between 1.5 MHz and 20
MHz
5–20 MHz/RF
carrier,
CA-supported
feature to assist
in attaining BW
up to 100 MHz.
Mobility
Support
Fixed
Fixed
Fixed
Fixed
Fixed/nomadic
Portable/mobile
version of
WiMAX
Portable/mobile
version of
WiMAX.
Topology
(MAC
Architecture)
P2MP and Mesh
Assistance
More extended
coverage than
WLANs while
sustaining high
transmission
rates
VoIP
Licensed exempt
applications.
QoS support.
Creating
proﬁles
(systems) for
10–66 GHz will
help with
compatibility
requirements
for LoS
broadband
wireless access.
Technological
ﬁxes and minor
modiﬁcations
to 802.16a
standard. The
ETSI
HiperMAN
standard was
matched with
this standard to
enable
worldwide
adoption.
Mobility
(60–120 km/hr)
facility to
WiMAX. Better
adaptability
and improved
QoS support.
Many
additional
service classes.
Increases
mobility (350
km/hr), and
guarantees
superior QoS
services.
Modulation
Techniques
Employed
QPSK, 16-QAM,
64-QAM
BPSK, QPSK, 16-QAM,
64-QAM
BPSK, QPSK,
16-QAM,
64-QAM
QPSK, 16-QAM,
64-QAM
OFDM,
OFDMA, QPSK,
16-QAM,
64-QAM
OFDM,
OFDMA, QPSK,
16-QAM,
64-QAM,
256-QAM,
S-OFDMA
OFDM,
OFDMA, QPSK,
16-QAM,
64-QAM,
256-QAM,
S-OFDMA
Access
Scheme/Protocol
Request/Grant
Salient Features
Overcomes the
disadvantages
of mobile
networks and
WLANs.
Designed to operate in
the LS and ULS RF
bands ranging from 2 to
11 GHz (to make it
operable in low
frequency ranges). As a
result, gives WiMAX
implementations more
ﬂexibility while
maintaining data rate
and transmission range.
Increases the
amount of
spectrum the
technology may
use in the 5–6
GHz RF channels
and provides
QoS support.
More speciﬁcs
about this
technology
were
standardized,
which promotes
interoperability
by encouraging
more consistent
implementa-
tion.
Comprises
minor
enhancements
and ﬁxes to
802.16a
standard. This
extension also
makes system
proﬁles for the
802.16a device
compliance
testing.
Designed to
standardize
communication
between
carriers’ mobile
devices and
ﬁxed base
station, instead
of between base
stations and
static receivers.
Designed to
increase the
mobility facility
(typically more
than IEEE
802.16e).
Moreover,
enables the use
of numerous
advanced
antenna
conceptions i.e.,
beamforming
and MIMO.
1: LS: Licensed Spectrum, RF: Radio Frequency, LoS: Line of Sight, QPSK: Quadrature Phase Shift Keying,
QAM: Quadrature Amplitude Modulation. 2: LS: Licensed Spectrum, ULS: UnLicensed Spectrum, RF: Radio
Frequency, WMANs: Wireless MANs, NLoS: Non-Line of Sight, VoIP: Voice over IP, BPSK: Binary Phase-Shift
Keying, QPSK: Quadrature Phase Shift Keying, QAM: Quadrature Amplitude Modulation. 3: ULS: UnLicensed
Spectrum, RF: Radio Frequency, NLoS: Non-Line of Sight, BPSK: Binary Phase-Shift Keying, QPSK: Quadrature
Phase Shift Keying, QAM: Quadrature Amplitude Modulation. 4: LoS: Line of Sight, QPSK: Quadrature Phase
Shift Keying, QAM: Quadrature Amplitude Modulation. 5: LS: Licensed Spectrum, ULS: UnLicensed Spectrum,
RF: Radio Frequency, LoS: Line of Sight, NLoS: Non-Line of Sight, OFDM: Orthogonal Frequency Division
Multiplexing, OFDMA: Orthogonal Frequency Division Multiple Access, QPSK: Quadrature Phase Shift Keying,
QAM: Quadrature Amplitude Modulation. 6: LS: Licensed Spectrum, RF: Radio Frequency, NLoS: Non-Line of
Sight, P2MP: Point-to-MultiPoint, OFDM: Orthogonal Frequency Division Multiplexing, OFDMA: Orthogonal
Frequency Division Multiple Access, QPSK: Quadrature Phase Shift Keying, QAM: Quadrature Amplitude
Modulation, S-OFDMA: Scalable Orthogonal Frequency Division Multiple Access. 7: PAI: Progressed Air
Interface, LS: Licensed Spectrum, ULS: UnLicensed Spectrum, RF: Radio Frequency, MA: Mobile Applications,
FA: Fixed Applications, NLoS: Non-Line of Sight, CA: Carrier Aggregation, BW: BandWidth, P2MP: Point-to-
MultiPoint, Orthogonal Frequency Division Multiplexing, OFDMA: Orthogonal Frequency Division Multiple
Access, QPSK: Quadrature Phase Shift Keying, QAM: Quadrature Amplitude Modulation S-OFDMA: Scalable
Orthogonal Frequency Division Multiple Access.
Electronics 2023, 12, 2490
28 of 63
4.5. Challenges in IoT Communication Using the TCP/IP Protocol Suite
In IoT, smart sensing motes, devices, and actuators share unique features such as
constrained memory, power, and processing capabilities; the need for facilitating real-time
requirements of smart applications; extremely vulnerable radio environments; and little to
no human involvement after deployment [115]. By enabling communication amongst these
devices utilizing low-power-cost technologies, a new infrastructure for deployed smart
services has been formed. Researchers [116] argued that the TCP/IP protocol suite might
provide a solution and be ﬂexible enough for a variety of evolving IoT communication
scenarios. Unfortunately, there were additional challenges that network administrators,
designers, and researchers had to overcome. Researchers were searching for the best way
to install IPv6-based sensor motes that can effectively/minimally use the system’s limited
resources (i.e., power and bandwidth). Because of such power constraints, researchers
highlighted the requirements of low-power Layer-2 technologies (i.e., BLE, IEEE 802.15.4)
and low-power WiFi usage. In contrast with traditional Ethernet links, these technologies
operate with smaller maximum transmission unit (MTU) sizes and slower transmission
speeds. IoT network protocol designers faced a problem in adapting to and determining
the ideal MTU size. Another obstacle is that IoT networks often are based solely on wireless
networks and thus they can only communicate using wireless mesh technologies. This
vulnerability brings extra challenges in front of TCP/IP architecture:
(1)
The current IP addressing model cannot assist mesh communication (since it relies on
a multi-link subnet prototype) at all.
(2)
In mesh communication, the multicasting and broadcasting communication methods are
quite expensive, power-demanding, and prohibitive as the network nodes are extremely
power constrained. Moreover, unicasting is the only remaining alternative method.
(3)
Unicasting is power intensive in and of itself because it may take many hops while
forwarding and may wake up an excessive number of nodes that are asleep. Notably,
idle nodes and hops can modify the radio state’s operation mode to save power. Ad-
ditionally, a large amount of power is used and saved by a node during transmission,
reception, overhearing, idle, and sleeping phases [117]. However, to ensure successful
delivery, we cannot just alter the operational modes. Instead, it requires effective
coordination and intricate synchronization [117,118].
(4)
There is a high requirement for scalable routing/forwarding schemes for IP communi-
cation to take place over mesh architectural systems.
(5)
For many IoT applications requiring data prioritizing and customized control, original
TCP-suited features such as those operational on ﬁxed MSS sizes (such as MTU sizes)
that further lead to silly window syndrome or in-order byte-stream delivery to ensure
dependability, are unsuitable [119]. Nonetheless, the IETF started deﬁning standard
Internet protocols such as RPL [120] for such specialized environments to minimize
protocol overheads that impair the computing ability and memory management of
these specialized resource-constrained devices.
WiFi-based infrastructure networks enable backhauling support, which helps estab-
lish and sustain seamless connectivity among smart IoT devices. In smart home wireless
networks, this form of connectivity can be provided through TCP connections. The TCP/IP
protocol suite supports dependable data delivery and congestion control strategies to main-
tain network throughput performance via TCP at Layer-4. TCP is a protocol that has been
regularly modiﬁed and improved over the years to effectively transport large amounts of
byte-stream in-ordered data via resilient P2P connections with comparatively lower latency
needs. IoT services deal with atypical communication patterns, for which TCP/IP protocol
suite-based protocols, such as TCP, are unable to handle such patterns adequately [119].
There are severe problems that TCP faces when it deals with an IoT application:
(1)
TCP connection establishment and termination (three-way handshaking) incur signiﬁ-
cant overhead in the system as most communication in an IoT application includes
the transmission of brief segments and relatively little data.
Electronics 2023, 12, 2490
29 of 63
(2)
TCP functionality needs resilient P2P connections. It is impossible to sustain these con-
nections in an IoT network environment because smart sensors and other connected
devices switch their mode of radio state from active to sleep phase persistently [119].
(3)
Some IoT applications might need broadcast and multicast communication patterns,
and enabling such patterns via TCP will result in substantial network overhead in the
entire IoT system and high-power consumption.
(4)
Some IoT services have very granular delay requirements, and any extra delay in
the form of connection establishment or MSS creation (waiting for data to ﬁll the
entire MSS) is completely unacceptable for their performance. Thus, TCP is unable to
provide much support for these IoT services.
(5)
IoT applications that rely on wireless communication scenarios must deal with crit-
ical wireless channel characteristics such as channel error, interference, and wire-
less interface properties that result in buffer-induced, channel-induced, link-layer
contention-induced, and collision-induced packet losses. When TCP operates in such
a setting, its stringent in-order delivery requirements and retransmission policies
(i.e., fast retransmission) may occasionally result in very serious system problems
such as Head-of-Line (HoL) or Receiver Buffer Blocking, which ultimately results in
a reduction in throughput, delay, and power consumption performance [121–124].
Furthermore, wireless MAC methods that use MAC-level retransmissions may fur-
ther impair TCP’s performance, if Layer-2 retransmission latency exceeds the TCP
Retransmission Time Out timer.
Some standards, such as BACnet/IP [125], were proposed to implement Layer-4
functionalities at the Application Layer (AppL) itself and proposed to utilize UDP as an
underlying Layer-4 protocol. Managing packet losses should depend on an application’s
requirements, which may vary from application to application. However, TCP and its
updated variants rely on the concept of data delivery deferment and try to perform retrans-
missions from an already created copy in the sender buffer. However, this is not the only
approach to dealing with packet losses in the network. Another method is for AppL to
accept packet delivery that is not completely ﬂawless and proceed with its current opera-
tions. This feature will be helpful in real-time audio and video distribution. Additionally,
retransmission is an additional option. However, AppL should handle this retransmission
rather than an underlying Layer-4 protocol such as TCP. In terms of buffering the lost data
bits, doing so enables the source application to reconstruct them. Furthermore, in situations
where real-time services are severely constrained, the transmitting application may transmit
fresh data instead of retransmitting lost data to “repair” the effects of the initial loss [126].
Clark and Tennenhouse [126] concluded these concepts and subsequently introduced the
concept of Application Level Framing (ALF). Implementing Layer-4 facilities at AppL itself
brings the idea of employing ALF into the system. Hence, utilizing the notion of ALF,
a network can recognize individual Application Data Units (ADUs), and subsequently
can offer support for ﬂexible Layer-4 facilities, i.e., employing adaptive retransmission
procedures for diverse forms of ADUs and disseminating data more effectively by using
in-network caching. Unluckily, the TCP/IP protocol suite forbids applications from adding
any application semantics into network-level packet structure. Therefore, it fails to provide
support for the ALF scheme [119].
4.6. Compound TCP for IoT
Compound TCP [127] was initially designed to offer support for improved channel
utilization and fairness performances. It will play a signiﬁcant role in home networks with
WiFi-assisted smart and standard devices [115,128].
Pokhrel and Williamson [115] studied the effectiveness of a compound TCP over an
IoT scenario involving sensors and other devices (i.e., smartphones, laptops, PC, and home
appliances). They analyzed and evaluated the scenario improving the performance of con-
nections made using the examined TCP variant across infrastructure WiFi networks in the
presence of signiﬁcant buffer-overﬂow-induced losses and severely degraded transmission
Electronics 2023, 12, 2490
30 of 63
channel circumstances. The authors also addressed the varying bandwidth requirements
for all IoT devices as well as ubiquitous connectivity, ranging from traditional bandwidth-
hungry Internet devices to low-power gadgets. The authors of [129] demonstrated a
thorough evaluation of the steady-state performance of TCP via WiFi-assisted classical
devices considering the situations of high-buffer-overﬂow-induced losses and signiﬁcantly
deteriorated transmission channel conditions. The authors of [115,129] suggested models
that aided in capturing the dynamics of congestion and ﬂow control of several concurrently
running competitive long-lived compound TCP connections. In evaluating and developing
these models, they considered MAC-level retransmissions, link-layer contention, channel
failures, and collision. The authors of [130] utilized a transient model suggesting a new
queue management scheme to capture the interactions of short-lived TCP ﬂows (the most
workable ﬂows in IoT scenarios) over conventional trafﬁc patterns over WiFi networks.
However, the performance of TCP in WiFi networks is constrained, especially when using
a single shared Access Points (APs). As a result, TCP might not be able to scale well and
provide superior performance in wide-area Industry 4.0 networks, especially when wireless
channels are often reused by several APs [131].
4.7. Viewpoints of Network Layer Routing for IoT Systems
The network architectures for IoT are heterogeneous and include WiFi, WSNs, Wireless
Mesh Networks (WMNs), Vehicular Networks, and Mobile Communication Networks
(MCNs) (5G/LTE/4G/3G) [132]. Due to the large-scale production of intelligent sensing
devices, survivability and self-organization of deployed functional networks are essential. A
WSN is deployed for a variety of smart agricultural, environmental, domestic, and military
applications. It is an ad-hoc network with no infrastructure, in which the sensor nodes
communicate over multi-hop routing. WSNs run on battery-powered, low-power sensors
capable of sensing, collecting, processing, aggregating, and regulating communication.
Numerous WSN-based platforms, including MICA2, TelosB, and MICAz MOTE, have
been suggested. Therefore, some standards were introduced to enable interaction and
other compatibilities among these numerous heterogeneous platforms. For example, the
IEEE802.15.4 (Zigbee) standard creates the WSNs backbone as part of the IoT. WSNs provide
critical functionalities for developing IoT systems, allowing Low-Powered battery-operated
End Devices (LPEDs) with very minimal resources to attach to the Internet. A WSN can be
considered a special form of LoWPAN consisting of several equipped sensor nodes. Due
to the lack of IP communication infrastructure, interoperability must be obtained from the
viewpoint of WSN and the Internet. To address the interoperability issue, various works
suggested a standardized arrangement that could enable the usage of IP over LoWPAN.
The IEEE 802.15.4 standard allows for the interoperability for Low power and Lossy
Networks (LLNs). The design tenet of this standard outlines the physical and data link
layers of the network and offers a low-cost framework for network operations. To link
LPEDs to the Internet, 6LoWPAN may be used as an adaptation layer to enable sensors
to implement an IP stack and become approachable by other conventional devices over
the Internet. This adaptability layer also supports end-to-end connectivity, which enables
a variety of applications and permits these LPEDs to implement routing and forwarding
algorithms at the Internet layer. However, the current network layer routing policies cannot
be supported when the number of nodes grows. Therefore, the RPL protocol [72] considers
the LLN situation [133]. Most of the nodes in LLNs are resource-constrained, and they are
connected by some lossy links that only support low data rates. These links are thought
to be extremely unstable and have poor performance in terms of packet delivery rates. In
such specialized networks, the trafﬁc patterns are often P2MP and MultiPoint-2-MultiPoint
(MP2MP) rather than just P2P [72]. These networks contain hundreds of smart devices.
This makes the implementation of routing policies more difﬁcult than ever. In addition,
numerous existing traditional ad-hoc wireless network routing methods, such as DSR and
AODV, cannot manage these unique situations and unforeseen circumstances. Designing
and implementing routing in ad-hoc networking settings has been more difﬁcult due to the
Electronics 2023, 12, 2490
31 of 63
mobility aspect and the resource limitations at wireless nodes. Their forwarding policies’
design principles emphasize QoS elements including bandwidth usage and end-to-end
latency [134,135]. The forwarding rules frequently created and applied for WSNs situations
take into account the increase in the network lifetime by effectively utilizing the node
energy [117,136]. As these ad-hoc networks were designed to operate and maintain solely
inside their operational infrastructure, this was very feasible. However, the interoperability
of these ad-hoc networks is a major problem when such networks are integrated with
IoT networks. The ad-hoc network integration with IoT needs novel routing policies
that support scalability and assure QoS, fairness, and connectivity between two nodes
(both in APs and ad-hoc networks) with the least amount of power consumption. The
standard classical forwarding strategies were intended to ensure QoS between a pair of
devices/nodes. In the case of an IoT environment, the routing procedures should suggest
enough fairness so that each node can sufﬁciently get enough chances to communicate with
nearby APs. For such specialized scenarios, hierarchical routing solutions are followed
to decrease data redundancy and ensure data aggregation. Researchers have often raised
concerns about the disadvantaged forwarding rules, which lead to the consumption of
excess energy in networks while taking into account mobile and static ad-hoc network
scenarios. It consequently increases the likelihood of frequent network disconnections,
route failures, and even network partitioning, all contributing to the system’s signiﬁcant
MAC-level and routing-level overhead problems [134,135]. Hence, bearing in mind the
high-power consumption problem, many researchers presented numerous smart routing
paradigms [118,134,135,137]. Still, many of these suggested schemes failed to achieve the
desired QoS.
Cross-layer design-based recommendations for power consumption and congestion
control are well-suited design proposals for comprehending the changes in wireless channel
attributes. Therefore, signiﬁcant work has been done in these areas. These designs provide
support for dynamically accessing and evaluating extremely variable channel parameters
at lower layers (MAC and PHY) for the Internet/Routing and Transport layers to further
optimize forwarding and congestion window adaptations decisions [121,134,135,138–140].
The Received Signal Strength Indicator (RSSI) indicates how well a device can hear a
signal from an AP or router. A network layer forwarding policy can effectively utilize the
RSSI (accessible through lower layers dynamically) to assess link quality. AODV and DSR
are examples of the traditional ad-hoc routing protocols used in various smart forwarding
systems designed for IoT scenarios. The AOMDV IoT [141] and MLB [142] routing mecha-
nisms were suggested for the IoT scenarios and talked about node and link disjoint paths
while discovering routes. However, the proposed schemes do not shed light and discuss
anything related to performance issues when there is a signiﬁcant level of interference in
the network because of trafﬁc running parallel onto multiple paths. The abovementioned
techniques do not always perform well in terms of throughput and end-to-end delay.
Recently, the scheme [140] considered different critical factors such as interference level,
link-layer contentions, routing load, MAC load, and other performance issues related to
wireless scenarios. The authors of [140] insisted that multipath load distribution policies’
efﬁciency depends on the distribution (physical) of routes. Nevertheless, different possible
disjoint routes—those lacking any common nodes or links—might be able to interfere
with one another due to the radio signals’ predicted broadcasting behavior in wireless
communication. Consequently, such separate disconnected pathways could be utilized to
enhance the performance of the network as a whole [138,140].
When employing an IoT-based system, the end sensor nodes depend on WSN-based
networking connectivity to deliver sensed and collected data from smart things to sink
nodes. These nodes are commonly known as IoT GateWay nodes (IoT-GW). To balance
energy usage and gather crucial sensor data, numerous such static and mobile IoT-GWs
can be deployed in the system. In the whole system, numerous WSNs, gathering numerous
types of critical data, are connected to the Internet [142,143]. Originally, Zigbee speciﬁed
three forms of devices: Zigbee Coordinator, Zigbee Router, and Zigbee End Device, and
Electronics 2023, 12, 2490
32 of 63
three forms of network topologies: tree, star, and mesh. Moreover, the Zigbee stack
embraces AODV to create paths dynamically. In the case of star network topology, the
Reduced and Fully Functional Devices (i.e., RFDs and FFDs) can communicate with the
PAN central coordinator only. They are not capable of communicating with one another.
Here, the PAN coordinator may be powered by mains, while the RFDs and FFDs run on
low-powered limited battery devices. Moreover, in the case of the mesh network topology,
any device can communicate to within-range devices at a point of time. Moreover, this
topology contains a PAN coordinator, which can communicate with other RFDs and FFDs.
Furthermore, this networking topology offers support for the usage of the integrated
forwarding scheme united with hierarchical/tree and AODV routing procedures. Lastly,
the tree (cluster) network topology is a subset form of mesh networking topology, consisting
of RFDs and FFDs (which may act as coordinators). However, the FFD count could be
more than the RFD count in the network. RFDs may attach to tree (cluster) network
topology as the end nodes in the system. The coordinator FFDs can offer synchronization
functionalities to other connected coordinators and devices. However, there will be a single
PAN coordinator amongst these coordinators [144].
4.8. IoT Application Protocols
Each IoT application is based on IoT application layer protocols for data transfer.
These protocols can be the following:
•
Representational State Transfer Hypertext Transfer Protocol (REST HTTP): HTTP [145] is
the primary client/server protocol that adopts the request/response model. HTPP has
been related to the REST architecture [146] to ease the interaction between dissimilar
entities over web-based services. The mixture of HTTP and REST enables IoT devices
to make their status readily available in terms of the standardized CRUD (create, read,
update, delete) functions [147]. The CRUD functions are mapped to the POST, GET,
PUT, and DELETE techniques of HTTP, correspondingly. In this fashion, we can build
a REST model for dissimilar IoT devices [148].
•
Constrained Application Protocol (CoAP) [149]: It is a lightweight RESTful protocol lately
standardized by the Internet Engineering Task Force (IETF). CoAP is used by IoT
devices for IP-based, HTTP-like interactions. It uses UDP with acknowledgment mes-
sages to set up reliable communication based on a request/response interaction. It has
reduced complexity, and thus it is suitable for resource-constrained IoT applications
and machine-to-machine (M2M) communication.
•
Message Queuing Telemetry Transport (MQTT) [150] is established for IoT messaging.
According to MQTT design principles, network bandwidth and device resource re-
quirements should be kept to a minimum while also aiming to assure dependability
and some level of delivery assurance. Since June 2016, MQTT has been recognized by
ISO as a standard (ISO/IEC 20922). The protocol continues to progress by formalizing
popular capability options and adding new functionalities. The most recent version,
MQTT v5.0, was released in 2018. MQTT operates according to a publish/subscribe
paradigm. Clients connect to a centralized broker when using MQTT.
•
Open Platform Communications Uniﬁed Architecture (OPC UA) [151]: This interoper-
ability standard is used for the secure and reliable exchange of data in the industrial
automation domain and other industries. It is platform independent and ensures
the seamless ﬂow of information among IoT devices from multiple vendors. It sup-
ports two different communication methods: the Client/Server method as well as
Publish/Subscribe (e.g., over UDP or MQTT) to mainly meet different industry re-
quirements from the production systems to edge and cloud scenarios. Today, the main
IoT vendors including IBM, AWS, Google Cloud, Microsoft, and SIEMENS leverage
secure, standardized information exchange in edge-to-cloud applications based on
OPC UA.
•
Extensible Messaging and Presence Protocol (XMPP) [152]: This extensible protocol is
based on text messages that use XML (Extensible Mark-up Language), through which
Electronics 2023, 12, 2490
33 of 63
it can implement both request/response and publish/subscribe methods by using
suitable extensions. XMPP exchanges instant messages between clients, and this
happens in real-time using a push mechanism to avoid increasing unnecessary network
loads. XMPP also determines the state of an XMPP entity as online, ofﬂine, busy, etc.
•
Advanced Message Queuing Protocol (AMQP) [153]: An open standard for passing
business messages between applications or organizations using TCP. It connects sys-
tems, feeds business processes with the information they need, and reliably transmits
onward the instructions that achieve their goals using the point/point and pub-
lish/subscribe interaction modes. AMQP was designed to achieve the main goals of
message orientation; queuing; routing; security; reliability; and interoperability.
•
Data Distribution Service (DDS) [154]: DDS was developed by the Open Management
Group (OMG). DDS is a real-time M2M protocol that enables dependable, high-
performance, interoperable, scalable data exchanges using a publish–subscribe pattern.
DDS provides low-latency data connectivity, high reliability, and scalability in publish–
subscribe and request/response patterns over TCP and UDP. The needs of various
IoT applications requiring real-time data exchange can be addressed using DDS. Such
applications are air trafﬁc control, transportation systems, autonomous vehicles, and
smart grid management.
Lastly, Glaroudis et al. [155] provided a comparison among IoT application protocols
in terms of well-accepted key performance indicators and discussed their suitability in the
framework of smart farming.
5. Networking Architectures and Protocols
5.1. Generic Architectures
Zanella et al. [37] provided an in-depth analysis of an urban IoT’s enabling technolo-
gies, protocols, and architecture. They also demonstrated the implementation of an IoT
island as a proof-of-concept in the Italian City of Padova. In the IoT, two methods provide
data access to objects/things. The ﬁrst involves deploying multi-hop mesh networks with
short-range communication among network nodes using unlicensed frequency. The second
involves using licensed frequency band long-range cellular technologies (e.g., 2G/GSM).
Centenaro et al. [156] presented a hopeful alternative solution (i.e., a new type of wire-
less connectivity) called Low-Power Wide Area Networks (LPWANs). LPWAN is based
on a star topology characterized by low-rate, long-range transmission technologies in
the unlicensed sub-GHz frequency bands. The authors considered LPWAN to provide
connectivity in the IoT scenario for a characteristic SCA. Furthermore, they discussed
the advantages of LPWAN over well-known methods regarding effectiveness, efﬁciency,
and architectural design. Leccese et al. [157] created a Raspberry-Pi Card-controlled SCA
that uses a ZigBee Sensor Network and WiMAX to provide completely controlled street
lighting. Sanchez et al. [158] described SmartSantander, an IoT experimental research
facility that was deployed in Santander City, Spain. SmartSantander supports testing
proposed protocols, services, and conﬁgurations in a realistic setting at an appropriate
scale. Machine-to-machine (M2M) communication is a signiﬁcant part of IoT. Vilajosana
and Dohler [159] reviewed currently used smart city M2M technologies (i.e., sensors, data
loggers, wireless modems, and gateway). They considered one of the most famous deploy-
ment use cases, i.e., smart parking. In any IoT environment for smart cities, a huge amount
of M2M communication requests occur. Unfortunately, conventional network gateways
cannot face this challenge. Huang et al. [160] presented an admission control model for
M2M communications. Their model differentiates all M2M requests into delay-sensitive
and delay-tolerant. Then, it aggregates all delay-tolerant requests by routing them into
one low-priority queue, aiming to reduce the number of requests from various devices
to the access point in the IoT for smart cities. Silva et al. [161] developed the bottom-up
architecture after analyzing a variety of existing architectures. This architecture has four
layers: sensing, transmission, data management, and application. Each layer integrates
security modules to protect sensitive data. The sensing layer, located at the bottom of the
Electronics 2023, 12, 2490
34 of 63
architecture, collects data from physical devices. The transmission layer is located above
the sensing layer. Several communication technologies are used to transmit data from the
transmission layer to the (upper) data management layer. The data management layer
performs data fusion, data analysis, data processing, and data storing. It stores valuable
information that various applications use at the application layer to provide services.
The majority of the above works mainly focus on a single characteristic, such as quality
of service [162].
Marques et al. [163] proposed a generic, multilevel IoT-based smart cities infrastructure
management architecture that allows the integration of physical objects, communication
infrastructure, cloud platform, and IoT-based services in a pervasive way. This architecture
(Figure 4) is generic and includes four layers: (1) Physical Objects, (2) Communication,
(3) Cloud Platform, and (4) Services.
Electronics 2023, 12, x FOR PEER REVIEW 
35 of 65 
 
data management layer. The data management layer performs data fusion, data analysis, 
data processing, and data storing. It stores valuable information that various applications 
use at the application layer to provide services. 
The majority of the above works mainly focus on a single characteristic, such as 
quality of service [162]. 
Marques et al. [163] proposed a generic, multilevel IoT-based smart cities infra-
structure management architecture that allows the integration of physical objects, com-
munication infrastructure, cloud platform, and IoT-based services in a pervasive way. 
This architecture (Figure 4) is generic and includes four layers: (1) Physical Objects, (2) 
Communication, (3) Cloud Platform, and (4) Services. 
 
Figure 4. Architecture design. Adapted from [163]. 
1. 
The Physical Objects Layer enables IoT sensors to collect data that will feed the smart 
city architecture with information used to offer services. After the sensors collect 
data, a Communication Device is used to collect sensor data. A communication de-
vice can implement different technologies (e.g., RFID, Bluetooth, and Zigbee). Sen-
sor data are processed by a NodeMCU, which communicates with a Local Pro-
Figure 4. Architecture design. Adapted from [163].
1.
The Physical Objects Layer enables IoT sensors to collect data that will feed the smart
city architecture with information used to offer services. After the sensors collect data,
a Communication Device is used to collect sensor data. A communication device can
implement different technologies (e.g., RFID, Bluetooth, and Zigbee). Sensor data
Electronics 2023, 12, 2490
35 of 63
are processed by a NodeMCU, which communicates with a Local Processing unit
responsible for gathering information used by the application providing a service.
The local processing unit brings elements of edge computing, as it pushes part of the
computation to edge nodes instead of relying on concentrating all the computation in
a centralized remote server.
2.
The Communication Layer: The architecture supports a variety of network access
technologies. The communication layer supports the implementation of various
wireless technologies. The local processing unit located at the Physical Objects Layer
deﬁnes the technology to be used and relays data to the communication layer using
the interface of a network access point.
3.
The Cloud Platform Layer provides three services: processing, database queries, and
data storage. In the context of providing services for smart cities, each of these services
can be dynamically allocated to satisfy the needs of various applications. Notably,
only some applications and service types require a cloud platform to operate correctly.
This layer is offered as part of the infrastructure provided, and its implementation
is optional.
4.
The Services Layer implements four groups, which are called classes of services:
(I) Surveillance, (II) Transportation and Logistics, (III) Infrastructure, and (IV) Tech-
nology. In each class, different kinds of applications can be implemented to deal with
the challenges of smart cities.
This architecture is a generic solution, so the underlying layers are designed to offer
support to the applications. Therefore, it can be adapted to the speciﬁc implementa-
tion of a given service. To this end, the authors adapted their architecture to a waste
management scenario.
Another multi-level smart city architecture [164] was built on semantic web technolo-
gies, and its design is mostly used in smart city wireless sensor network applications. Data
collection, data processing, integration and reasoning, and device control and alerts make
up its four layers. Using ontology, a data model, at the network’s edge, Gheisari et al. [165]
suggested a novel architecture for IoT devices in the smart city that protects privacy.
Saadeh et al. [166] proposed a four-layer architecture for mobile object authentication in the
context of IoT smart cities. Their architecture is based on the applicability of a proposed hier-
archical elliptic curve identity-based signature authentication protocol. Naranjo et al. [167]
presented a Fog-based smart city network architecture called FogC Architecture Network
(FOCAN). To reduce latency and increase the efﬁciency of services among things with
various capabilities, FOCAN is a multi-tier framework in which the applications operating
on things collaborate to compute, route, and interact with one another through the smart
city environment. One of FOCAN’s primary beneﬁts is that the IoT device can deliver
services effectively and with less energy consumption.
5.2. SDN-IoT Architectures
Software-deﬁned networking (SDN) [168] is an approach to enable ﬂexible and efﬁ-
cient network conﬁguration to enhance a network. SDN can provide many advantages
for conﬁguring city networks to support different applications. For example, SDN can
improve the QoS of city networks against link failures [169] and meet smart city latency de-
mands [170]. While some efforts are investigating this approach for supporting SCAs, there
is room for developing more advanced management and networking mechanisms in SDN
for efﬁcient, reliable, and secure network conﬁgurations in smart cities. Jazaeri et al. [171]
considered the advantages of integrating edge computing, SDN, and IoT technologies and
reviewed different frameworks and platforms.
Liu et al. [172] proposed an architecture that decouples urban sensing applications
from the physical infrastructure. In their architecture, centralized controllers manage
physical devices and offer APIs for data acquisition, transmission, and processing services
to develop urban sensing applications. Bi et al. [173] proposed a scalable SDN-enabled
architecture that integrates a variety of smart city components and provides reliable and
Electronics 2023, 12, 2490
36 of 63
timely scheduling for big data transfer to support smart city services. They also studied
the time-constrained big data transfer scheduling (TBTS) problem under this architecture
and proposed a heuristic with an intelligent scheme that can maximize the throughput and
schedule the multi-ﬂow transfer dynamically.
IoT systems collect and process data vulnerable to availability, integrity, and privacy
threats. Nguyen et al. [174] proposed a collaborative and intelligent-network-based in-
trusion detection system (NIDS) architecture, namely, SeArch, for SDN-based cloud IoT
networks. SeArch is a security architecture in which an arrangement of three layers of IDS
nodes, i.e., Edge-IDS, Fog-IDS, and Cloud-IDS, is introduced with an effective collaboration
among nodes.
Blockchain is an innovative solution for increasing data integrity and privacy in smart
cities [175]. Sharma and Park [176] proposed a novel hybrid network architecture for the
smart city by exploiting the strength of emerging SDN and Blockchain technologies. To
achieve efﬁciency and address the current limitations, their architecture is divided into
core and edge networks. By designing a hybrid architecture, their architecture inherits
the strength of centralized and distributed network architectures. “PrivySharing” [177]
is a Blockchain-based innovative framework for privacy-preserving and secure IoT data
sharing in a smart city environment. This framework protects data privacy by segmenting
the blockchain network into different channels, consisting of a limited number of approved
businesses and handling a certain category of data, such as health, smart auto, smart
energy, or ﬁnancial information. Additionally, smart contracts contain access control rules
that regulate who has access to the users’ data within a channel. In addition, private
data gathering and encryption are used to further isolate and safeguard the data within
a channel.
Islam et al. [178] designed a decentralized and distributed architecture for the IoT
ecosystem that addresses the existing challenges through the use of the technologies
Blockchain, SDN, and Network Function Virtualization (NFV). This energy-aware architec-
ture confronts the problems of scalability, ﬂexibility, complexity, monitoring, managing,
and collecting IoT data and defends against cyber threats.
5.3. Architectures for Smart Grid
The automated and intelligent management of the next-generation electric power
systems determines their effectiveness and efﬁciency. Smart Grid (SG) is the name given to
the next generation of electricity systems, which are anticipated to offer various beneﬁts
over the current systems in terms of digitization, ﬂexibility, intelligence, resilience, sustain-
ability, and customization [179]. Smart transmission infrastructures use new technologies
to improve power quality. Smart control centers monitor and communicate with electric
devices remotely in real time, while smart substations self-consciously coordinate their local
devices. The dispatch of electricity to end-users is implemented by using the electrical and
communication infrastructures that connect the transmission and customer domains. The
distribution domain includes distribution feeders and transformers to supply electricity.
It interacts with much different equipment, such as distributed energy resources (DERs),
plug-in electric vehicles (PEVs), automatic metering infrastructure (AMI), and sensors with
communication capability. The distribution domain is responsible for delivering electricity
to energy consumers, user demands, and energy availability. To provide quality electricity,
the stability of this domain is monitored and controlled.
Typical applications [44] of the smart grid communications network are automatic
meter reading, demand response, PEVs, substation automation, and DERs/microgrid.
DERs are tiny energy production and/or storage devices linked to the distribution system.
Distributed generation (DG), distributed storage (DS), or a combination of renewable
and non-renewable sources are all possible sources for DER. Solar panels, wind turbines,
combustion turbines, fuel cells, battery storage systems, etc., are a few examples of DER.
An electric power system with one or more DER units and loads is referred to as a microgrid.
Electronics 2023, 12, 2490
37 of 63
The communication infrastructure in the smart grid supports the capabilities of the
smart grid and complies with performance standards. This infrastructure connects a huge
number of electric devices and manages complex device communications. As a result, it is
built in a hierarchical architecture with interconnected individual sub-networks, and each
sub-network is responsible for separate geographical regions. The extremely dispersed
smaller area networks that support the power systems at various locations are connected by
WANs, which act as the communication’s backbone. When the control centers are located a
great distance from the substations or the end-users, the real-time measurements made at
the electric devices are transported to the control centers through the WANs, and in the
opposite direction, the WANs carry out the instruction communications from the control
centers to the electric devices.
The authors of [43] present a communication architecture in an SG. This architecture
includes (1) an energy smart house with electric appliances connected to the smart grid,
(2) a residential complex with AMI, (3) a residential subdivision installed with solar panels,
(4) a PEV charging station, (5) a power substation, and (6) power transmission lines. In this
architecture, the Internet and ISPs serve as the backbone in connecting the distributed sub-
networks. Demertzis et al. [180] presented and categorized the communication network
standards that have been established for smart grids and should be considered in planning
and implementing new infrastructures. Such standards are IEC 61850 for substation
automation. This standard is based on open architecture and incorporates sampling
and timing synchronization speciﬁcations based on IEEE 1588 in LANs and WANs [181].
Notably, IEEE 1588 is the standard for a precision clock synchronization protocol for
networked measurement and control systems [182].
Due to the widespread use of renewable energy resources (RERs) throughout the
power grid, it is anticipated that electric power distribution networks in smart grids would
undergo signiﬁcant changes to accommodate the nature of non-radial power ﬂow. For the
most part, the low-voltage distribution networks where RERs (such as solar cells) may be
attached are not monitored by the majority of the present supervisory control and data ac-
quisition (SCADA) systems for power grids. For the goal of active monitoring and control,
Abdrabou [183] presented a multi-hop wireless network with a cellular frequency-reuse
structure that may supply the communication infrastructure to dense low-voltage distribu-
tion networks. A position-based QoS-aware routing protocol was also presented as a useful
method for prioritizing data transfer across the newly introduced network architecture.
HetGrid [184] is a unique overlay network design with a speciﬁc QoS routing method
for power distribution grid applications. It delivers QoS assurances across the network
while taking into account three factors: bandwidth, latency, and dependability. The authors
created two components to accomplish this:
•
A multipath routing mechanism that compensates critical applications for their high-
reliability requirements by using end-to-end physically disjoint paths, and
•
Altruistic resource allocation with the QoS routing mechanism that targets communi-
cation with QoS guarantees for applications with strict QoS requirements.
The ﬁndings in [184] show that the HetGrid overlay network architecture enables ex-
tremely effective, trustworthy, and QoS-aware communication in heterogeneous networks.
The major characteristics that set SG apart from the standard electrical power grid are
the ability to execute two-way communication, demand-side management, and real-time
pricing. The present SG systems have interoperability problems because they need to
be protocol independent. Therefore, global communication network management and
monitoring approaches have been proposed using SDN [185]. Thanks to SDN, network
administrators may more efﬁciently manage their networks by separating the control plane
from the data plane. SDN has advanced in SG due to its reliance on communication
networks. SDN implementation in SG systems has the potential to increase efﬁciency
and resilience. SDN can assist the SG in integrating several SG standards and protocols
by virtue of its programmability, protocol independence, and granularity capabilities to
cope with varied communication systems. Rehmani et al. [185] presented SDN-based
Electronics 2023, 12, 2490
38 of 63
SGC architectures, along with case studies. They discussed routing schemes for SDN-
based SGC and provided a detailed survey of security and privacy schemes applied to
SDN-based SGC.
Alam et al. [186] provided a detailed survey on smart grid communication networks in
terms of communication network requirements, architecture, technologies, and applications.
They proposed a Cognitive Radio (CR)-based Communication Network for Smart Grid.
CR is a software-deﬁned radio (SDR) platform that can quickly reconﬁgure its operating
parameters, such as modulation/demodulation, compression algorithm, and error coding
techniques, according to changing circumstances and requirements, through cognition. In
such an SDR platform, radio transceivers can switch functions and operations on demand
only. Molokomme et al. [187] reviewed architectures that aim to accomplish the various
and strict QoS requirements in SG communication systems.
Wireless communication networks have been motivated to harvest energy from
ambient environments and run energy-efﬁciently for economic and ecological beneﬁts
through improvements in the smart power grid and the advocacy of “green communica-
tions”. Hu et al. [188] examined recent developments in energy harvesting, redistribution,
trade, and planning for future wireless networks integrating with smart grids. The authors
considered the optimization of various energy-harvesting wireless systems as well as tradi-
tional models of renewable energy-harvesting technologies. Moreover, they discussed how
to distribute redundant (unused) energy generated by cellular networks, plan for energy
under dynamic pricing when smart grids are in place, and engage in two-way energy
trading using smart grids.
From a different viewpoint, including IoT devices and providing connectivity, au-
tomation, and monitoring for such devices enables SG systems to sustain multiple network
operations during the generation, distribution, transmission, and expenditure of energy.
Numerous IoT-aided SG systems have been proposed in the literature. The survey [189] on
IoT-aided SG systems considers the systems’ current architectures, uses, and prototypes.
5.4. Architectures for Smart Buildings
There are various building applications such as heating, cooling, load control, air
quality, ventilation, lighting, water management, and cooking gas management. A smart
building incorporates the major building systems on a common network and functionality
to provide operational efﬁciency, ﬁre safety, and security. A smart building architecture
(SBA) manages several real-time domains, including automated temperature regulation,
air cleaning, HVAC systems, and humidity control (i.e., indoor environment regulation
and monitoring); smart lighting and controlling home appliances (energy management); a
smart ﬁre detection system; and other building operations. A typical smart building [190]
has security cameras, lighting sensors, an indoor air quality system, a ﬁre alarm system, a
water management system, and an energy management system. Moreover, it can detect
intrusion and supports HVAC services.
Diverse SBAs include complex operational systems, sensing, and communication
technologies. Such architectures have converged into an IP-based architecture. This con-
vergence is occurring rapidly with the increased usage of IP-based smart devices driven
through IoT concerning conventional building management and smart buildings. Tradi-
tionally, numerous building systems utilized varied forms of networking protocols and
cabling systems. This variety makes the whole system more complex and highly infeasible
from both a deployment and a system administration standpoint [191]. SBAs entail making
plans for and assisting with the inclusion of operational technologies that improve the
application’s, service’s, or provision’s operational steps while also boosting the well-being
of its users. Researchers, policymakers, and implementers should pay attention to several
crucial issues, such as reliable communication/connection procedures, power-efﬁcient
measures, competent security measures, efﬁcient sensors and actuators, and data analyt-
ics procedures. Amalgamating new systems and technologies with conventional (base)
technologies to accomplish the revelation of SBAs, includes, but is not limited to, WSN
Electronics 2023, 12, 2490
39 of 63
deployment; advanced power-aware trafﬁc engineering policies; cloud, edge, and fog com-
puting paradigms; big data engineering and analytics; and human–computer interaction
procedures [192]. The rapid development of ICT technologies has enhanced the connect-
edness of intelligent sensing, actuators, and communication devices to real-time physical
entities. Recently, smart sensing mechanisms, actuators, and data harvesting technology
have boosted the area of SBAs proposals. However, choosing the best ICT technologies for
a particular smart building domain poses signiﬁcant difﬁculties, including heterogeneity
of IoT devices and applications, workable networking protocols and architectures, power
efﬁciency, and QoS/QoE provisioning [190,193]. One solution is the SDN paradigm, which
manages the network more efﬁciently than a customary one. SDN also assists network
services, including storage, routing, dynamic bandwidth management, and QoS. Hence,
these simpliﬁcations offer a creative environment through the implementation of proper
software tools for smart buildings. Network architecture and its implementation for in-
telligent infrastructure is based on IoT relationships (between IoT in home automation
and applications) and can be established using smart home Cloud Computing based on
SDN. Recently, Younus et al. [190] proposed an SDN architecture that improves critical SB
parameters such as bandwidth efﬁciency, energy efﬁciency, latency, security, and reliability.
Silva et al. [194] presented a Web of Things (WoT) SBA that is integrated with the repre-
sentational state transfer (RESTful) application programming interface (API). The RESTful
API employs HTTP requests (e.g., GET, PUT, POST, and DELETE) to access and use WoT
data. Regarding network performance and smart building power management, the authors
showed how their recommendation for smart city architecture improved performance.
Smart sensing devices and actuators permit collecting, monitoring, controlling, or
modifying vital building parameters so that users receive the best QoS/QoE possible. These
functionalities depend on sensor integration competence and their properties. These sys-
tems comprise signal conditioning circuits, implanted algorithms, power, and transceiver
modules [195]. Researchers developed such system-based SBAs for assessing and regulat-
ing air quality, smart lighting systems, ﬁre detection systems, power management, and
other basic building operations.
An indoor-air-quality-based SBA considers sensing and actuator-based systems for
monitoring and regulating air quality parameters. An indoor environmental observing
system was initially suggested in [196] that observes polluting gases, temperature, and
relative humidity. Other kinds of such systems have been proposed in [197,198]. Con-
sidering smart indoor lighting systems, numerous solutions have been proposed in the
literature. In SBAs, light sensors manage and track the lighting system to satisfy the users’
needs. The authors of [199] shed light on power consumption reduction via energy-efﬁcient
smart lighting systems. Today’s smart building employs low-power usage LED-based
light sources that last longer than Compact Fluorescent Lamps (CFLs) [200]. In reality, the
development of control technologies, heterogeneous networks, and embedded systems
has made it promising to create smart innovative lighting systems that can effectively
address the problem of energy conservation. Researchers have recently begun testing by
integrating different power-saving techniques in a single illumination system for improved
energy efﬁciency while enhancing lighting performance without sacriﬁcing user satisfac-
tion. According to the authors of [201], using several cheap detectors, as opposed to a
single expensive sensor, would result in improved performance and higher power savings.
Considering the same motivation, various authors [202–204] have suggested similar types
of smart lighting systems for several room types, such as classrooms and ofﬁces. In [205],
the authors provide a deep and profound study concerning smart lighting systems focusing
on power savings procedures and connectivity alternatives as well as the integration of
visible light communication technology [206].
Recently, researchers focused on two main goals, namely, occupants’ work perfor-
mance and thermal comfort, to propose effective SBAs. Hence, many Occupant-Oriented
Technologies (OOT) have been put forth by academics who want to maximize thermal
comfort while conserving energy. OOT-based systems offer a practical way to lessen the
Electronics 2023, 12, 2490
40 of 63
drawbacks of the automatic control used today. In practice, thermal comfort analysis is
based on parallel objective and subjective evaluation. The objective evaluation comprises
monitoring, assessing, and recording the status of environmental parameters through dedi-
cated sensors and instruments following standardized guidelines. Subjective evaluation
involves monitoring, assessing, and recording thermal preference, thermal sensation, and
thermal environment acceptance. Further thermal comfort sensor results as the cumulative
method to both above-mentioned analysis can be found in [193].
Green building refers to SBAs with an ambient intelligence system that adjusts to
predetermined circumstances in real-world situations. In this situation, the system makes
full use of embedded sensors in an environment that can gather data and subsequently
allow the system to act in accordance with that data. The ambient intelligence concept aims
to conserve natural resources with limited and efﬁcient use of them to offer comfort to the
occupants. Through unconventional energy sources, it also meets some of the conventional
energy requirements [207]. Many aspects of SBAs, such as security, monitoring, and
power efﬁciency, are the subject of extensive study. However, one of the most important
functions of an SB system is to control the interior climate, which is typically done by
HVAC systems [208]. The performance of HVAC systems in the instance of commercial
buildings for frequency regulations has been demonstrated by the authors of [209] for this
context. Their demonstrated numerical experiments suggest that 15% of rated fan energy
can be employed for regulation use while having a minor effect on a building’s indoor
temperature. The method of computational control for passive and active sources was
used in another scheme [210]. The authors emphasized the problem that the ambient and
active sources of lighting, heating, ventilation, cooling, and shading are not synchronized
in buildings. Such a computational control scheme is also suitable for reducing daily power
usage. Similarly, numerous methods [211–213] considering HVAC systems have been
proposed with respect to frequency regulation, predictive control, and smart controller.
An IoT-assisted HVAC smart system tracks environmental situations. It also notiﬁes
when measurements exceed thresholds and provides data on energy usage and consump-
tion. In addition, it can autonomously turn equipment intermittently at programmed
times. As individuals spend more time indoors (at home, work, or in other enclosed spaces)
than outdoors, the air quality inside buildings should be improved along with that of the
external surroundings. This is the task of indoor Air Quality Monitoring Systems (AQMS).
The basic parts of an AQMS (Figure 5) are a sensor array, a processing/display unit, a signal
conditioning circuit, a small amount of external memory, and a communication module
that is typically wireless. A sensor array is a group of specialized micro-sensors that can
detect certain airborne concentrations of gases such as NOX, SOX, CO2, CO, and O3, as
well as some essential environmental parameters such as humidity and temperature. These
sensors are connected to a GUI unit that shows the values of the real-time indoor air quality
parameters and an external memory used to store real-time data [214]. When deploying
such systems, various communication (wireless) modules, including WiFi, ZigBee, and
LoRAWAN technologies, are considered.
Electronics 2023, 12, 2490
41 of 63
Electronics 2023, 12, x FOR PEER REVIEW 
42 of 65 
 
 
Figure 5. Air Quality Monitoring Sensor System. Adapted from [215,216]. 
Figure 6 shows an SBA architecture [217]. The system of this architecture collects 
vital information about the various air quality parameters, including CO2, CO, particles 
(Particulate Matter PM10 and PM2.5), and some other crucial parameters such as hu-
midity and temperature. By using gas sensor boards and wasp motes, the authors created 
a method for collecting and monitoring the indoor atmosphere. For monitoring CO2 and 
CO parameters, they also used TGS 4161 and TGS 2442 gas sensors. These sensors usually 
work using the resistive heating principle. The TGS 2442 sensor has excellent sensitivity 
to fluctuations in CO gas concentration. This sensor’s internal resistance, or “IR”, is in-
versely proportionate to the amount of CO present. As the CO content rises, the IR falls. 
While TGS 4161 also offers low power consumption and suggests better performance in 
detecting changes in CO2 gas concentration, the TGS4161 is ideally suited for indoor air 
control applications as it can measure 350–10,000 ppm carbon dioxide. The authors used 
the DustTrak DRX, a specialized aerosol laser photometer that simultaneously measures 
mass and size fraction, for PM1 and PM2.5 monitoring purposes. To define and create an 
interface to the deployed sensor for wireless transmission of gathered aerosol data, this 
photometer is connected to a base station device via LAN. The authors also set up ZB 
(ENs) at each location that was taken into consideration, which sent updates on the air 
quality and aerosols at regular periods to BS (ZBC) that had already been set up. 
This system assesses the indoor air quality to assess the current state of the indoor 
environment while simultaneously providing real-time inputs for HVAC system man-
agement. The authors also designed a toolkit that analyzes real-time air quality data and 
displays them through meaningful representations to service the SBAs. Likewise, Lozano et 
al. [216] proposed another IAQMS technique that considers a star topological architecture 
[217]. The ZB (ENs) in this technique is based on the XBee and XBee pro-version modules. 
Nevertheless, the suggested scheme [216] considers a single pollutant only, i.e., suggest-
Figure 5. Air Quality Monitoring Sensor System. Adapted from [215,216].
Figure 5 shows a typical sensor system for an indoor environment for air quality monitoring.
Figure 6 shows an SBA architecture [217]. The system of this architecture collects
vital information about the various air quality parameters, including CO2, CO, particles
(Particulate Matter PM10 and PM2.5), and some other crucial parameters such as humidity
and temperature. By using gas sensor boards and wasp motes, the authors created a
method for collecting and monitoring the indoor atmosphere. For monitoring CO2 and
CO parameters, they also used TGS 4161 and TGS 2442 gas sensors. These sensors usually
work using the resistive heating principle. The TGS 2442 sensor has excellent sensitivity
to ﬂuctuations in CO gas concentration. This sensor’s internal resistance, or “IR”, is
inversely proportionate to the amount of CO present. As the CO content rises, the IR falls.
While TGS 4161 also offers low power consumption and suggests better performance in
detecting changes in CO2 gas concentration, the TGS4161 is ideally suited for indoor air
control applications as it can measure 350–10,000 ppm carbon dioxide. The authors used
the DustTrak DRX, a specialized aerosol laser photometer that simultaneously measures
mass and size fraction, for PM1 and PM2.5 monitoring purposes. To deﬁne and create an
interface to the deployed sensor for wireless transmission of gathered aerosol data, this
photometer is connected to a base station device via LAN. The authors also set up ZB (ENs)
at each location that was taken into consideration, which sent updates on the air quality
and aerosols at regular periods to BS (ZBC) that had already been set up.
This system assesses the indoor air quality to assess the current state of the indoor en-
vironment while simultaneously providing real-time inputs for HVAC system management.
The authors also designed a toolkit that analyzes real-time air quality data and displays
them through meaningful representations to service the SBAs. Likewise, Lozano et al. [216]
proposed another IAQMS technique that considers a star topological architecture [217].
The ZB (ENs) in this technique is based on the XBee and XBee pro-version modules. Never-
theless, the suggested scheme [216] considers a single pollutant only, i.e., suggesting using
Electronics 2023, 12, 2490
42 of 63
a GAC sensor. Conversely, the authors of [215] further claimed that they considered seven
pollutants in their proposed implementation.
Electronics 2023, 12, x FOR PEER REVIEW 
43 of 65 
 
 
ing using a GAC sensor. Conversely, the authors of [215] further claimed that they con-
sidered seven pollutants in their proposed implementation. 
 
Figure 6. IAQMS architecture. Adapted from [217,218]. 
IoE for Smart Building: To achieve optimal functionality and energy-efficient per-
formance, Kim et al. [218] offered an overview of the design and implementation of en-
ergy-related SB technologies, including energy management systems, renewable energy 
applications, and current advanced smart technologies. Undoubtedly, the electricity sec-
tor of smart cities is impacted by the Internet of Energy (IoE), which aims to increase en-
ergy efficiency, prevent energy waste, and enhance environmental conditions by inte-
grating IoT technologies into distributed energy systems. Two examples of IoE technol-
ogy are intelligent sensor use and the incorporation of renewable energy sources. As a 
result, the IoE is becoming a tool for legal science to support the goals of a smart city. 
Metallidou et al. [219] discussed the factors that prompted the European Union to create 
regulations to make it easier to transition current towns into smart cities, starting with 
existing structures. To achieve energy efficiency, the authors suggested a smart building 
template that uses IoT technology to manage the performance of all technical systems. In 
addition, they suggested an automated remote-control technique supported by a cloud 
interface to enhance the certification of existing buildings for energy performance. This 
technology reduces time-consuming processes and stores the energy performance of each 
building on a cloud platform to make decisions and put measures in place. A review of 
current tactics in the field of active building energy management systems (BEMS) was 
offered by Mariano-Hernández et al. [220]. The authors reviewed articles on several 
BEMS management techniques for residential and non-residential buildings, including 
Model Predictive Control (MPC), Demand Side Management (DSM), Optimization, and 
Fault Detection and Diagnostics (FDD). MPC predicts building response to control re-
quests, while DSM is an agreement of actions to improve the energy system on the user 
Figure 6. IAQMS architecture. Adapted from [217,218].
IoE for Smart Building: To achieve optimal functionality and energy-efﬁcient per-
formance, Kim et al. [218] offered an overview of the design and implementation of
energy-related SB technologies, including energy management systems, renewable en-
ergy applications, and current advanced smart technologies. Undoubtedly, the electricity
sector of smart cities is impacted by the Internet of Energy (IoE), which aims to increase
energy efﬁciency, prevent energy waste, and enhance environmental conditions by inte-
grating IoT technologies into distributed energy systems. Two examples of IoE technology
are intelligent sensor use and the incorporation of renewable energy sources. As a re-
sult, the IoE is becoming a tool for legal science to support the goals of a smart city.
Metallidou et al. [219] discussed the factors that prompted the European Union to create
regulations to make it easier to transition current towns into smart cities, starting with
existing structures. To achieve energy efﬁciency, the authors suggested a smart building
template that uses IoT technology to manage the performance of all technical systems. In
addition, they suggested an automated remote-control technique supported by a cloud
interface to enhance the certiﬁcation of existing buildings for energy performance. This
technology reduces time-consuming processes and stores the energy performance of each
building on a cloud platform to make decisions and put measures in place. A review of
current tactics in the ﬁeld of active building energy management systems (BEMS) was
offered by Mariano-Hernández et al. [220]. The authors reviewed articles on several BEMS
management techniques for residential and non-residential buildings, including Model
Predictive Control (MPC), Demand Side Management (DSM), Optimization, and Fault
Detection and Diagnostics (FDD). MPC predicts building response to control requests,
while DSM is an agreement of actions to improve the energy system on the user side. FDD
is an automatic procedure of detecting and separating ﬂaws in BEMS to protect a system
from additional harm. Moudgil et al. [221] examined cutting-edge academic and industrial
Electronics 2023, 12, 2490
43 of 63
research to discover signiﬁcant technological solutions that improve the integration of IoT
in building infrastructure (BI). Their review also identiﬁes key technical and non-technical
problems that must be resolved through extensive research for BI to fully incorporate IoT.
The authors contend that IoT in BI is still not operationally capable. IoT and BI stakeholders
must make a concerted effort to give modern BI access to a generic IoT framework with
cognitive intelligence and context-aware computing capabilities.
5.5. Smart Water and Pipeline Network Monitoring
Retroﬁtting the traditional water distribution system with smart devices has some
beneﬁts, including lower utility costs, lower consumer bills, and less water loss [222,223].
For example, smart water sensors can keep an eye on the pressure online and alert utilities
to pressure changes or large pressure losses in the water network, allowing them to remotely
adjust the pressure to save energy consumption [224]. Automation can be used for both
operational procedures and components that provide functionality. For instance, when a
water problem occurs during operation or with the element itself, the smart components
inform the system center and then take action to avert a crash. The water utility can also
determine a sensor’s requirement for maintenance or replacement thanks to the automatic
self-veriﬁcation mechanism [225].
In [226], the authors suggest an IoT-based smart water grid architecture that includes
technical systems, functions, and a hierarchy framework. Moreover, this smart water
system (SWS) also comprises smart sensing mechanisms, simulation procedures, diag-
nostic techniques, disposal, warning, and control mechanisms. Although an SWS incor-
porates ofﬂine performance, real-time performance is deﬁned by online procedures such
as online data monitoring, online data assimilation, online modeling, online charting,
and online results output. An SWS must have real-time functionality to implement the
necessary smart features [227]. Researchers put a lot of effort [228] into developing wa-
ter systems that operate intelligently. Real-time modeling, real-time sampling, real-time
controlling, etc., which seek to reduce the lag between system input and system output,
should be added to the smart performance of SWS. It was discovered that using SCADA
would considerably increase the data transfer efﬁciency [229]. A smart water architec-
ture [230] often includes ﬁve layers: (1) the physical layer; (2) the sensing and control layer;
(3) the communication layer; (4) the data management layer; and (5) the data fusion layer.
Within the framework of the GST4Water project, the authors of [230] presented a system
that allows for receiving consumption data sent by a generic smart meter installed in a
user’s house and transferring them to a cloud platform. The consumption data are saved
and processed to characterize leakage at the district meter area and the individual user level.
Meanwhile, the processed data are returned to the Water Utility and can be used for billing.
On the other hand, they provide regular feedback to the user, thus gaining full awareness
of their consumption behavior. Panagiotakopoulos et al. [231] presented an IoT framework
based on FIWARE that aims to realize a highly ﬂexible standards-based open-source soft-
ware solution for developing SWSs. They designed an architecture consisting of various
FIWARE software components and two dashboard applications. Amaxilatis et al. [232]
considered numerous intelligent infrastructure solutions regarding conventional water
metering systems, which effectively facilitate uninterrupted bi-directional (whenever re-
quired) data exchange between water ﬂow devices, metering equipment, and end-users.
The authors’ ultimate objective is to design, implement, and deploy more sophisticated
infrastructure offering improved performance in bigger smart city infrastructure. To limit
the amount of data that needs to be shared between the various system layers, their ap-
proach makes use of the FogC paradigm to develop the infrastructure for the smart water
grid model.
The Information and Communications Technology (ICT) Solutions for the Efﬁcient
Water Resources Management project was funded by the European Commission under the
auspices of the Seventh Framework Program (FP7). The goal of the Smart Water project is
to examine the role of ICT in monitoring and effectively managing urban water systems,
Electronics 2023, 12, 2490
44 of 63
with a focus on the deployment of sensors, communication technologies, and related
decision support systems in utility providers’ water networks to address issues such as
leakage management, demand management, asset management, and so forth. Kulkarni
and Farnham [233] focused on the issues surrounding wireless connectivity, proposed
a framework for assessing potential solutions based on the total cost of ownership, and
highlighted lessons learned from two European utilities’ Smart Water case studies.
Pipelines are used to transport water, gases, and oil. Since they are frequently under-
ground, the humid atmosphere easily erodes them, which may result in leaks. In addition,
water in the pipelines may get contaminated by infectious agents or substances that are
mistakenly or purposely introduced into the system. As a result, maintaining pipeline
networks is crucial for maintaining public health and protecting the environment. The sen-
sor node deployment profoundly impacts the sensing performance indicators for pipeline
network monitoring, including coverage area, coverage population, and detection time.
The sensor nodes should typically be positioned near the pipeline network’s junctions [234].
Given the design of the pipeline network, the optimal sensor node deployment challenges
are therefore formulated as integer optimization problems, where the integer variables
represent the maximum amount of sensor nodes that must be placed at each junction. The
deployment difﬁculties for pipeline network monitoring are typically challenging to solve
because of the integer decision variables.
Pipeline network ﬂows are not predictable. As a result, depending on the ﬂow pattern,
the sensing performance of a deployed sensor node may vary. As a result, the ﬂow pattern
is taken into account in [235], which formulates a mix-integer optimization problem to
decide how to deploy sensor nodes to reduce the projected population at risk of malicious
contamination. The authors solved the ensuing mix-integer optimization using a branch
and bound technique. Even though a strategy such as this can identify the ideal answer,
the time complexity is typically signiﬁcant. This means that large pipeline networks cannot
be used with the method. Similarly, the study in [236] considers the various demand
patterns of water ﬂows through pipes. The authors used a genetic-based method to ﬁnd the
best deployment locations to increase coverage under various monitoring station demand
patterns. The global optimum of these heuristic algorithms could take a while to reach.
The performance of the algorithms may also be impacted by their parameter choices.
Consequently, we do not advise using it for massive pipeline networks.
Singapore’s WaterWise@SG program aims to identify pipeline leaks and anticipate
burst incidents [237,238]. PipeNet has also been put to the test in Boston to ﬁnd pipeline
leaks, where three tiers of nodes are employed to quantify pH levels and pressure. To
reduce water waste, a system named IWCMSE [239] has been designed to track water
consumption for businesses. A Steamﬂood and Waterﬂood Tracking System [240] has been
created to ﬁnd irregularities in pipeline systems, such as leaks and bottlenecks. With the
aid of all these technologies, the investigators had the opportunity to evaluate the efﬁciency
of the monitoring algorithms. However, these technologies rely on ﬁxed sensors, and we
still need to put innovative testbed models and systems built around crowd sensing and
mobile WSN into place.
5.6. Architectures for Smart Transportation
The Internet-of-Vehicles (IoV, also known as V2X) aims to reduce trafﬁc congestion
and accidents. It also enables information exchange involving the vehicle and all entities
that may have an impact on it. Vehicle networking and vehicle intelligence are the two
technologies that underpin IoV implementation. The three components that compose
vehicle networking are the onboard information service, VANET, and mobile network.
VANET stands for vehicle-to-vehicle short-range communication. Providing remote loca-
tion, remote diagnostics, navigation, and other information services is referred to as an
onboard information service. Every car can be utilized as a potent mobile terminal thanks
to mobile networks. Vehicle intelligence is the use of cutting-edge technologies, including
artiﬁcial intelligence (AI), big data analytics, deep learning (DL), and cognitive computing
Electronics 2023, 12, 2490
45 of 63
(CogC), to facilitate information sharing among people and vehicles, as well as between
vehicles and the environment, infrastructure, or other vehicles.
Vehicular networks consist of data-gathering sensors and inter-vehicle communica-
tion systems. Such networks require an open and ﬂexible layered architecture to handle
characteristics such as interoperability, scalability, dependability, and modularity. Recently,
the research community proposed efﬁcient vehicle network architectures. For example,
the Universal IoV (UIoV) architecture [241] includes seven layers. Offering services and
choosing messaging protocols are tasks that fall within the application layer. Data prepro-
cessing, big data processing, and intelligent transmission are all tasks that the multimedia
and big data layer is in charge of. For IoV systems, the cloud service layer’s ClCom and
cloud virtualization technologies offer hardware computing platforms, infrastructure, and
software services. In the UIoV architecture, the communication layer and the intra–inter
devices layer are merged to accomplish the connectivity of many heterogeneous objects
and networks. Notably, there is no intra–inter devices layer in classical architecture. The
UIoV system’s physical objects layer gathers and transmits all the data to the intra–inter
devices layer for additional processing. In the IoV, both vehicles and non-vehicle items are
identiﬁed using the Identiﬁcation Layer.
Liu et al. [242] suggested another IoV network architecture to increase the ﬂexibility of
application management while enhancing the scalability and dependability of information
services. This architecture has four layers in total, the data layer of which has a variety
of nodes with various wireless communication interfaces. Because the topology of IoV
is frequently changed, an immense quantity of data are frequently produced and trans-
mitted at the data layer. To safeguard the accurate semantics of the underlying resources,
the virtualization layer splits a few nodes into fog nodes and the network, computation,
communication, and storage resources in IoV. To execute applications such as road safety
management and data sensing, the control layer’s SDN controller is responsible for schedul-
ing the abstraction resources of the virtualization layer and interacting with the application
layer. A difﬁcult topic in network architecture design is dealing with diverse networks.
Interoperability, scalability, dependability, and adaptability are some of its network features.
The design seeks to increase layer separation and network architecture’s total number of
layers. In addition to being a service-oriented design, the IoV architecture should facilitate
the connectivity of cars with heterogeneous networks and other communication devices.
By introducing the CogC paradigm into autonomous driving systems, the learning ability
of autonomous vehicles can be effectively improved. Utilizing both physical and network
data space, the Cognitive Internet of Vehicles (CIoV) paradigm [243] improves network
security and transportation safety. CIoV enables IoV to bear more accurate perceptive
ability through cognition in the intra-vehicle network (driver, passengers, smart devices,
etc.), inter-vehicle network (adjacent intelligent vehicles), and beyond-vehicle network
(road environment, cellular network, edge nodes, remote cloud, etc.). The CIoV architecture
includes a cognitive data engine that can conduct cognition of user tasks by the use of
data collected, e.g., driving behavior model analysis, emotion analysis, and road condition
investigation. Five layers are present in the network architecture of CIoV. The gathering
and preprocessing of big data from several sources are done by the sensing layer. As
opposed to the previous communication layer (of other architectures), the architecture’s
communication layer uses a cloud/edge hybrid structure to accommodate various applica-
tion schedules. The data cognition engine at the cognition layer processes and interprets
heterogeneous data streams (machine learning (ML), DL, data mining, etc.) using a variety
of cognitive analysis approaches. The control layer’s resource awareness engine is in
charge of allocating and scheduling network resources with the aid of technologies such
as NFV, SDN, network slicing, and self-organized networking (SON). There are primar-
ily two categories in the application layer (i.e., usual application services and intelligent
transportation applications).
Efﬁcient message authentication and integrity are required to guarantee vehicle pri-
vacy and safeguard vehicular communications. To protect V2V and V2I communications
Electronics 2023, 12, 2490
46 of 63
in the context of the VANET against a broad range of cyber threats, Karim [244] provided
a cryptography-based routing solution. This solution includes a data encryption and de-
cryption mechanism based on attributes and identity that has the lowest computational
overhead while keeping the optimum level of security. Contreras-Castillo et al. [245]
suggested a seven-layer network architecture. The user interface layer, which controls infor-
mation exchange between the user and the vehicle, is the top layer. Utilizing roadside units
(RSUs) and onboard sensors, the data collecting layer gathers data. The pre-processing
and ﬁltering layer eliminates the unnecessary information from the gathered data before
sending the remaining information to the communication layer for transmission. Making
choices and managing network service providers are the responsibilities of control and
management. Large volumes of data must be processed by the processing layer to create
the pertinent data needed for various applications. To stop assaults, the security layer
directly manages each of the layers above. A unique network architecture with enhanced
throughput, reduced latency, higher security, and widespread connectivity was recently
proposed by Ji et al. [246]. This architecture consists of four layers:
1.
Security authentication layer: The RSUs on the road may monitor trafﬁc environment
data in real-time after setting several sensors, surveillance footage, and radar. This
layer determines the legality of the car and RSU that are requesting to join the network.
Perhaps an illegal vehicle or an RSU that has been installed unlawfully will attempt
to steal or alter the information of a real vehicle.
2.
Data acquisition layer: This layer collects and categorizes many types of data from
various networks. To ensure that the data can be sent to the edge layer securely, it
digitizes the data.
3.
Edge layer: Edge devices produce several data streams. As a result, processing and
analyzing data in one go using ClCom will result in signiﬁcant delays. As a result, we
must process data more closely related to the data source. The edge node, a physical
device situated closest to the data source, is used by the edge layer to carry out basic
processing and analysis on the acquired local data. It releases data analysis ﬁndings
for nearby trafﬁc incidents and current road conditions in real-time, then creates a
local decision-making plan, carrying out various ClCom jobs and boosting the cloud
data center’s computing power.
4.
Cloud Platform Layer: The cloud data center analyses the information it has collected
about global trafﬁc in this tier, develops a plan, and rationally distributes trafﬁc
resources. This layer, having the ability to implement connection management, data
management, aided autonomous driving, intelligent navigation, path planning, and
information security, is the “smart brain” of the IoV.
A blockchain-based vehicle network architecture (Block-VN) for the smart city was
presented in [247]. Building innovative distributed transport management systems is made
possible by the robust and secure Block-VN architecture. The authors considered how the
network of vehicles evolves with paradigms focused on networking and vehicular informa-
tion. To handle real-time transportation data, Jan et al. [248] created a model for assessing
transportation data using Spark and Hadoop. This model/system is separated into four
layers: data collection and acquisition, network, data processing, and application. Each
layer is built to process and manage data in a structured manner. On the data processing
layer, Hadoop and Spark are used to test the data. By utilizing the suggested event and
decision mechanism based on Named Data Networking [249], the data are made available
to a smart community member. The suggested approach was examined using transporta-
tion datasets from some reliable sources. The outcomes demonstrate data processing and
real-time distribution to citizens in the shortest amount of time. Spark with the Hadoop
environment produces ﬁndings that are quite accurate. From another viewpoint, Social
IoV (SIoV) are a breed of socially aware ephemeral networks [250], where vehicular nodes
share/exchange information with different entities and are thus forth comparable with
traditional social networks. Kerrache et al. [251] proposed a trust-aware communication
Electronics 2023, 12, 2490
47 of 63
architecture for social IoV (TACASHI), which offers a trust-aware social in-vehicle and
inter-vehicle communication architecture for SIoVs.
5.7. Architectures for Smart Rural Areas/Smart Villages
The smart village paradigm digitizes various aspects of rural activities using IoT
technologies. In the countryside, a variety of activities are carried out, including smart
agriculture, waste management, irrigation management, livestock management, smart
energy, smart healthcare, and smart education. A smart village or smart rural area can
enable real-time data analytics and automate decision-making for local villagers regard-
ing healthcare, agriculture, environment, transportation, and energy. It differs from a
smart city as there are key differences (e.g., low cost, infrastructure, and sustainability)
between urban and rural environments [252]. To realize the smart village goal, The Euro-
pean Commission (2017) [253] launched an action plan, in which it proposed to interfere
ICTs in villages. Cambra-Fierro and Pérez [254] addressed the meaning of “smart” in
rural contexts as well as its link with sustainability. The European Commission-funded
Smart Rural 21 initiative [255], which has the ultimate goal of encouraging and motivat-
ing communities to create and execute smart village methods and tactics throughout
Europe as a tool for rural development, serving as the authors’ primary source. IEEE
Smart Village [256] also supports the world’s energy-impoverished communities by pro-
viding a complete solution combining renewable energy, community-based education, and
entrepreneurial opportunities.
Malik et al. [257] discussed the implementation details of smart villages with different
technologies. They concluded that digitization is only possible if a reliable and robust net-
work and communication infrastructure are installed in the village environment. Shrestha
and Drozdenko [258] proposed a Smart Rural framework to mitigate the effects of climate
change using IoT and the Cloud, building a prototype on the Louisiana Tech University
campus. Their framework is an energy-efﬁcient monitoring system for observing the envi-
ronmental conditions that affect agricultural production and human health. It consists of
the following subsystems: Wireless Sensor Nodes, Fog Server, Cloud Services, and a Web
Dashboard. The dashboard converts raw sensor data into meaningful information from
which public ofﬁcials and residents can adapt to or frustrate the effects of climate change.
Monzon Baeza and Alvarez Marban [259] proposed a ﬂexible and scalable Smart Rural
system for gathering and processing IoT data from remote rural areas with no traditional
communication coverage as a handicap. The authors offered an architecture structured in
separate segments using IoT, 5G, Cloud, and High-Altitude Platform Station (HAPS). Their
proposal is applied to the rural environment to thus cover all the needs of the system in the
collection of IoT data from these remote rural areas, its coverage by space vehicles, and its
processing and storage through 5G terrestrial networks and cloud services. Their proposal
includes the deployment of IoT sensors and the development of Amazon Web Services.
Conversely, the part of the space segment, considered by HAPS, has been simulated for
different space channels. This method provides a complete and automated smart rural
system that allows access to these IoT data from remote rural areas through the Internet. To
provide secure services close to end-devices, Aljuhani et al. [260] explored the integration
of a Distributed Fog Computing (DFC) network architecture with IoT in improving security
and privacy solutions for villagers and consumer electronic (CE) devices. As a case study,
the authors designed and evaluated the performance of an Intrusion Detection System (IDS)
in a DFC-based smart village environment. Moreover, they discussed open security issues
and challenges regarding Fog-to-Things enabled smart villages. Rohan et al. [261] proposed
a collaborative edge-computing architecture considering the resource constraints in a smart
village. The authors illustrated the concept of collaborative edge computing as applicable
to reduce cost and better manage the existing infrastructural facilities. Collaboration occurs
between the multiple IoT edge devices (e.g., the edge data centers or edge routers) for data
processing and storage. For example, in times of high computational load demand, one
village’s edge devices can collaborate with another village’s edge devices.
Electronics 2023, 12, 2490
48 of 63
6. Summary
•
Various SCAs have different network requirements such as bandwidth, delay toler-
ance, power consumption, reliability, wireless connectivity, mobility, security, and
privacy. Therefore, they need different protocols at the OSI-RM layers. The network
architectures for IoT are heterogeneous and include various network technologies such
as WiFi, WSNs, Mesh Wireless Networks (WMNs), Vehicular Networks, and Mobile
Communication Networks (MCNs) (5G/LTE/4G/3G). The standards adopted in these
architectures must allow interoperability, while cross-layer design-based recommen-
dations for power consumption and congestion control are well-suited proposals.
•
State-of-the-art generic network architectures for smart cities adopt the SDN paradigm
and are based on FogC to reduce latency and increase the efficiency of provided services.
•
Fog and ClCom will be used in smart grid communication system architecture in the
future to fulﬁll QoS needs. Such architecture will additionally feature communication
methods that can lessen QoS issues like latency, security, and spectrum efﬁciency. The
CR technology will be an indispensable part of this architecture as this technology can
quickly reconﬁgure the operating parameters of the SG communication system to the
changing requirements through cognition.
•
By extracting usable data from both the physical and network data space, it is possible
to increase network security and transportation safety in IoVs. Future IoV architectures
will become cognitive. These architectures will include cognitive data engines that
will conduct cognition of user tasks by the use of data collected, e.g., driving behavior
model analysis, emotion analysis, and road condition investigation.
•
The networking performance of SDN is better than the customary networking of smart
buildings (SB). However, as Younus et al. [190] state, it also has been facing some
challenges such as network management in terms of maintenance, east–west interface,
southbound interface, trafﬁc management, energy, ML-based SDN networking for SB,
and the network resources issue of SB SDN-based networking.
7. Open Research Issues
−Network slicing management is required: IoT services such as smart transportation and
smart energy have diversiﬁed requirements. To accommodate diverse IoT services, the
network slicing paradigm is suggested because it enables multiple independent logical
networks running on the same physical network infrastructure. Wu et al. [9] presented
an architecture for intelligent network slicing management for the Industrial IoT (IIoT)
focusing on three IIoT services (smart transportation, smart energy, and smart factory). The
authors also provided a comprehensive survey on intelligent network slicing management
in this ﬁeld.
−NFV Implementation in the SDN-IoT Environment: The ETSI Industry Speciﬁcation
Group proposed NFV to virtualize the network functions that were before performed
by some proprietary dedicated. NFV allows for the ﬂexible provisioning of software-
based network functionalities on top of an appropriately shared physical infrastructure by
separating the network functions from the underlying hardware appliances [262]. Utilizing
inexpensive commodity servers, it solves the issue of operating costs associated with
administering and controlling this closed and proprietary equipment. When SDN is
used in conjunction with NFV (the software-deﬁned NFV architecture), it can overcome
the difﬁculties associated with intelligent service orchestration and dynamic resource
management [263]. SDN can dynamically establish a virtual service environment through
NFV. As a result, the need for specialized hardware and labor-intensive effort to fulﬁll
a new service request is avoided. In conjunction with the use of SDN, NFV also allows
real-time and dynamic function provisioning along with ﬂexible trafﬁc forwarding. The
SDN-IoT network may be improved and secured with NVF. It enables the software-based
deployment of network devices as virtualized components. Throughput is increased
because of NFV integration in the SDN-IoT network, which enhances network performance.
To this end, Sinh et al. [264] proposed a practical model for hosting IoT services and building
Electronics 2023, 12, 2490
49 of 63
SDN controller applications to show that SDN/NFV can effectively apply to IoT services.
Recently, Mukherjee et al. [265] proposed an SDN-based distributed IoT network with NFV
implementation for smart cities.
−Cognitive IoT network architecture for smart cities: CR technology can address the
bandwidth needs of IoT applications [266]. IoT devices can be enabled with cognitive
functionalities, including spectrum sensing, dynamic spectrum accessing, circumstantial
perceiving, and self-learning. Many SCAs and services can be based on CR technology
because it can do dynamic sensing and cognition of the surrounding environment. For
example, in smart grid applications, cognitive IoT can achieve the objective of enabling
users to know their energy consumption at any time and anywhere [267]. In smart home ap-
plications, cognitive-radio-equipped sensors can handle potential heterogeneous network
interference [268]. At the same time, cognitive IoT can help with smoother real-time moni-
toring over longer distances in the healthcare industry without worrying about spectrum
availability [269]. The complete utilization of cognitive radio technology in IoT demands
extensive research in spectrum optimization, standardization, hardware design, privacy
protection, heterogeneous network fusion, scalability and ﬂexibility problems, etc. [270].
For this reason, many CIoT-based smart city network architectures must be proposed to
solve such problems. In this regard, Park et al. [271] suggested a CIoT-based smart city
network architecture that outlines how data collected from SCAs may be analyzed using
the CogC paradigm and manage the scalability and ﬂexibility challenges.
−Challenges in IoT communication through TCP/IP suite: Unfortunately, many Access
Points (APs) can utilize identical WiFi channels in overlapping regions, leading to interfer-
ence problems that can signiﬁcantly impair TCP performance over WiFi [272]. Now, many
APs can provide support for wireless access to numerous users in a WiFi network with
the DownLink multi-user MIMO (DL MU-MIMO) functionality. DL MU-MIMO is a PHY
layer technology (included with IEEE 802.11ac standard [273]) that increases the capacity
of WLANs by simultaneously broadcasting data streams to several stations. As a result, it
is possible to achieve greater data rates that are equal to the number of antennas on APs.
Thus, several stations are served at once. Pokhrel and Singh [131] stressed the employment
of CR and Federated Learning (FL) methods with many APs to improve the Compound
TCP’s performance in wide-area Industry 4.0 WiFi networks. An FL method can accelerate
the learning processes of the transport protocols such as Compound TCP. In FL, training
data are dispersed across a large number of clients, each having unreliable and compar-
atively slow network connections, with the aim of developing a high-quality centralized
model. The authors of [131] insisted on using these specialized strategies to coordinate
numerous APs with regard to losses caused by unique wireless channel characteristics and
WiFi downloading and uploading dynamics. Through the use of FL and CR approaches in
dual AP settings, it is now possible to improve the Layer-4 performances of TCP versions.
Another study [274] assumed TCP Cubic [275] as the Layer-4 protocol and considered the
FL approach for IoVs. The authors of [276] developed a framework for exploiting the FL
technique, which enhances the efﬁciency and privacy protection for the case of IoVs.
−Digital Twins for Smart Processes: A virtual depiction of resources, personnel, proce-
dures, systems, devices, and locations is referred to as a digital twin. Digital twin technology
can be used to duplicate a variety of objects, including humans, IoT devices, aircraft en-
gines, and vehicles. A digital twin of the original vehicle is created, for instance, when
an automobile business creates a virtual representation or digital duplicate (copy) of a car
model. If a manufacturer creates a virtual representation of its manufacturing process, the
replicated process is a digital twin of the physical process. A digital twin is a proﬁle of
the actual process or physical object’s past and present state. In this virtual graphic, the
dynamics and features of an IoT device’s life and operation are depicted. The digital twin
can offer the location, state, and/or status of physical assets in real-time due to continual
learning and advancements. This fusion of the real and digital worlds enables organizations
to monitor systems, set strategies, and anticipate problems before they occur. Digital twins
are created using digital twin technology, which integrates network infrastructure graphs,
Electronics 2023, 12, 2490
50 of 63
AI, software analytics, and the IoT. Through digital twins, the idea of the smart city is
demonstrated. This technology can efﬁciently administer the city, from urban planning to
the optimization of land use. Digital twins make it possible to simulate plans before putting
them into action in the real world, revealing issues before they materialize. If a digital twin
is in place, government organizations can only fully assess what might be achieved with
the data to better citizens’ lives, offer economic opportunity, and establish a more cohesive
community. Although the idea is currently novel, it is expected to catch on in the next few
years [277].
−The 6G Network for Futuristic Smart Cities: A futuristic smart city is a dense and
AI-centric city because massive device connectivity with vast data trafﬁc is estimated in
the future. In such cities, the concept of IoT will be converted to the concept of Internet of
Everything (IoE). Networks of futuristic smart cities should have a huge bandwidth, low
latency, and AI integration. Such networks should also provide ubiquity, high QoS, and
on-demand content for thousands of interconnected devices. The 6G network [278] is the
problem-solving network of futuristic cities, with huge bandwidth and low latency. It is
under development for wireless communications technologies supporting cellular data
networks. Like its predecessors, 6G networks will probably be broadband cellular networks,
in which the service area is divided into small geographical areas (cells). It is expected that
6G will be supported by existing 5G infrastructures such as SDN, NFV, and network slicing,
together with new infrastructure. The network requirements of 6G are as follows [278]:
(1) ultra-fast data rates as high as 1 Tbps; (2) ultra-low latency of less than 1 ms; (3) increased
mobility and coverage; (4) ﬂexible and efﬁcient connection of trillion level objects; (5) peak
spectral efﬁciency of 60 b/s/Hz; (6) very high system reliability; and (7) improved network
security [279]. However, the main problem of 6G is that transmitting at a higher frequency
spectrum is prone to high path loss, making the distance for transmission limited [280].
The expected 6G of the radio access network is based on terahertz (THz) waves with the
capability of carrying up to one terabit per second (Tbps). THz waves have the capability of
carrying a large amount of data, but these waves have numerous drawbacks, such as short-
range and atmospheric attenuation. Hence, these drawbacks can introduce complications
and hinder the performance of the 6G network. Therefore, such complications of THz waves
must be considered, and efﬁcient AI-centric multilayer physical network architectures of 6G
must be proposed for futuristic smart cities. Farooq et al. [280] considered the expectations
from a network of futuristic smart cities and the problems of THz waves and proposed
a conceptual terrestrial network (TN) architecture for 6G. The nested Bee Hive [280] is a
scalable multilayer architecture designed to meet the needs of futuristic smart cities. It
provides an on-ground cloud network that helps smart devices to run AI applications
partially on their own and the rest on the cloud. Furthermore, the distributed and edge
computing-oriented infrastructure of Bee Hive provides security and reduces trafﬁc load on
the upper layer of the network. Undoubtedly, pervasive AI is the main enabling technology
in 6G, while some forms of AI are realized as part of 5G. Many successful examples of
using AI on wireless communications have been proposed, from physical layer designs
(e.g., channel estimation and precoding), to network resource allocation (e.g., trafﬁc control
and cache storage management), to security and authentication, to dynamic cell and
topology formation and management, to fault prediction and detection, etc. However,
DL-based solutions require high computational complexity, which might not ﬁt in current
mobile phones [281]. Apart from the complexity, Artiﬁcial Neural Network (ANN)-based
RL algorithms must be carefully designed to decrease the computational resources required
on these devices [282]. Quantum communication [283] offers a promising approach to
avoiding the challenge of limited computational resources and energy efﬁciency. Applying
Artiﬁcial Neural Networks in IoT also comes with the trade-off challenge between accuracy
and computational/energy requirements [282]. Tariq et al. [284] studied some of the above
issues and envisioned 6G to facilitate futuristic smart cities with pervasive autonomous
systems. Apart from pervasive AI, Imoize et al. [285] discussed other important enabling
technologies of 6G and their challenges. These enabling technologies are as follows:
Electronics 2023, 12, 2490
51 of 63
•
Reconﬁgurable Intelligent Surfaces (RISs) [286] that reﬂect signals and help in places
where maintaining Line of Sight (LoS) is difﬁcult. RISs will be mainly deployed on
doors, windows, and buildings.
•
Cell-Free Massive MIMO: The massive MIMO technology is introduced in 5G with
a more dense network of access points (APs), and this is further developed in 6G
to include a network with no cells (cell-free) [287]. Cell-Free Massive MIMO im-
proves spectral efﬁciency in communication networks, but there are some health risks
associated with such a dense network of APs.
•
CubeSat communication or the Internet of Space Things [288]. A CubeSat (or U-class
spacecraft) is a miniaturized spacecraft with sizes that are multiples of U, up to 6U,
and U being 10 × 10 × 10 cm cubic units.
•
UAVs/satellite communication.
•
Terahertz communication and Optical Wireless Technology [289].
•
Blockchain technology [290] and quantum communication [283].
The development of futuristic smart cities keeps up with the development of energy-
efﬁcient 6G communication. Kamruzzaman [291] presented the key trends in the IoT for
energy-efﬁcient 6G wireless communication in smart cities. He argues that the application
of IoT devices to 6G in smart cities will provide a 100 Gbps data rate, <0.1 ms latency rate,
up to 1000 km/h mobility rate, 100 bps/Hz spectral efﬁciency, and 1000 GHz frequency.
This will resolve the issues of energy inefﬁciency and other concerns in conventional
communication networks. Moreover, the use of energy-efﬁcient 6G in smart cities via IoT
devices probably will solve various problems that are encountered by existing smart city
systems. In futuristic smart cities, residents will use the innovative 6G brain–computer
interface (BCI) technology [292] for a multi-sense experience. BCI is based on the signals
and information that monitor and control machines using sensible wearable headsets and
devices. It uses human consciousness more than external sources for better interaction.
As humans have ﬁve senses (sight, hearing, touch, smell, and taste), BCI comprises ﬁve
datasets, comprising features of human senses that are used for human interaction with the
machine [292].
8. Conclusions
Utilizing resources efficiently, reducing operating expenses, and enhancing city
dwellers’ quality of life are the objectives of the smart city paradigm. This goal is ob-
tained by combining various technologies including IoT, WSNs, CPS, ClCom, FoC, big
data analytics, and robots. For this model, the effective networking and communication
between the many components required to enable various SCAs are crucial for achieving its
objectives. The ever-increasing need for networking leads to many elastic and manageable
platforms for various SCAs including smart grid, smart buildings, smart home, smart water,
and smart transportation systems. The networking needs of the key SCAs were examined
in this research, and the appropriate protocols that can be applied at different system
levels have been identiﬁed. Additionally, we provided examples of networking protocols
and smart grid, intelligent building, smart residence, and smart transportation system
architectures. We concentrated on key criteria for a variety of networking designs, such as
energy savings, routing, security, dependability, mobility, and support for heterogeneous
networks. In addition, we presented open research issues.
This survey can assist researchers to recognize research gaps/problems working in the
networking architectures for smart cities, and it provides an overview of available protocols
and architectures for SCAs.
Author Contributions: Conceptualization, D.K.; methodology, D.K. and V.K.S.; analysis and investi-
gation, D.K. and V.K.S.; draft preparation, D.K., V.K.S. and T.P.; supervision, A.K. All authors have
read and agreed to the published version of the manuscript.
Electronics 2023, 12, 2490
52 of 63
Funding: This research work was supported by the research project CRISIS, “Competences for Resilient
Smart Cities’ Staff” (Project No.: 2021-1-EL01-KA220-HED-000032257, Erasmus+ KA2—Partnerships for
Cooperation).
Data Availability Statement: Not applicable.
Conﬂicts of Interest: The authors declare no conﬂict of interest.
Abbreviations
The following abbreviations are used in this manuscript:
AMI
Automatic Metering Infrastructure
AMQP
Advanced Message Queuing Protocol
AODV
Ad-Hoc On-Demand Distance Vector
API
Application Programming Interface
AQMS
Indoor Air Quality Monitoring System
BLE
Bluetooth Low Energy
ClCom
Cloud Computing
CoAP
Constrained Application Protocol
CPS
Cyber-Physical System
CR
Cognitive Radio
DDS
Data Distribution Service
DERs
Distributed Energy Resources
DL
Deep Learning
D2D
Device-to-Device communication
EPS
Electric Power System
ETSI
European Telecommunications Standards Institute
FoC
Fog Computing
HTTP
Hypertext Transfer Protocol
HVAC
Heating, Ventilating, and Air-Conditioning
IEEE
Institute of Electrical and Electronics Engineers
IETF
Internet Engineering Task Force
IoT
Internet of Things
IoV
Internet of Vehicles
IPv6
Internet Protocol version 6
ISP
Internet Service Provider
LAN
Local Area Network
LoRA
Long Range (a spread spectrum modulation technique)
LPWAN
Low-Power Wide Area Network
LTE
Long-Term Evolution
MAC
Medium Access Control
MLB
Multipath Load-Balancing (routing)
MQTT
Message Queuing Telemetry Transport
M2M
Machine-to-Machine
NFV
Network Function Virtualization
OSI-RM
Open Systems Interconnection−Reference Model
PAN
Personal Area Network
PEVs
Plug-in Electric Vehicles
PHY
Physical layer
QoE
Quality of Experience
QoS
Quality of Service
REST
Representational State Transfer protocol
RFID
Radio-Frequency Identiﬁcation
RPL
Routing Protocol for Low-Power and Lossy Networks
SBA
Smart Building Architecture
SCA
Smart City Application
SCADA
Supervisory Control and Data Acquisition (system)
SDN
Software Deﬁned Networking
SG
Smart Grid
Electronics 2023, 12, 2490
53 of 63
SWS
Smart Water System
TCP
Transmission Control Protocol
UAV
Unmanned Aerial Vehicle
UDP
User Datagram Protocol
VANET
Vehicular Ad-hoc Network
WAN
Wide Area Network
WSN
Wireless Sensor Network
XML
Extensible Mark-up Language
XMPP
Extensible Messaging and Presence Protocol
5G
Fifth Generation
6G
Sixth Generation
6LoWPAN
IPv6 over Low-Power Wireless Personal Area Network
References
1.
Achmad, K.A.; Nugroho, L.E.; Djunaedi, A. Smart city model: A literature review. In Proceedings of the 2018 10th International
Conference on Information Technology and Electrical Engineering (ICITEE), Bali, Indonesia, 24–26 July 2018; pp. 488–493.
[CrossRef]
2.
Al-Fuqaha, A.; Guizani, M.; Mohammadi, M.; Aledhari, M.; Ayyash, M. Internet of things: A survey on enabling technologies,
protocols, and applications. IEEE Commun. Surv. Tutor. 2015, 17, 2347–2376. [CrossRef]
3.
Khalifeh, A.; Darabkh, K.A.; Khasawneh, A.M.; Alqaisieh, I.; Salameh, M.; AlAbdala, A.; Alrubaye, S.; Alassaf, A.; Al-HajAli, S.;
Al-Wardat, R.; et al. Wireless sensor n etworks for smart cities: Network design, implementation and performance evaluation.
Electronics 2021, 10, 218. [CrossRef]
4.
Puliaﬁto, A.; Tricomi, G.; Zafeiropoulos, A.; Papavassiliou, S. Smart cities of the future as cyber physical systems: Challenges and
enabling technologies. Sensors 2021, 21, 3349. [CrossRef] [PubMed]
5.
Alam, T. Cloud-based IoT applications and their roles in smart cities. Smart Cities 2021, 4, 1196–1219. [CrossRef]
6.
Hu, P.; Dhelim, S.; Ning, H.; Qiu, T. Survey on fog computing: Architecture, key technologies, applications and open issues.
J. Netw. Comput. Appl. 2017, 98, 27–42. [CrossRef]
7.
Beigi, N.K.; Partov, B.; Farokhi, S. Real-time cloud robotics in practical smart city applications. In Proceedings of the 2017 IEEE
28th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC), Montreal, QC, Canada,
8–13 October 2017; pp. 1–5. [CrossRef]
8.
Osman, A.M.S. A novel big data analytics framework for smart cities. Future Gener. Comput. Syst. 2019, 91, 620–633. [CrossRef]
9.
Wu, Y.; Dai, H.N.; Wang, H.; Xiong, Z.; Guo, S. A survey of intelligent network slicing management for industrial IoT: Integrated
approaches for smart transportation, smart energy, and smart factory. IEEE Commun. Surv. Tutor. 2022, 24, 1175–1211. [CrossRef]
10.
Marinakis, V.; Doukas, H.; Tsapelas, J.; Mouzakitis, S.; Sicilia, Á.; Madrazo, L.; Sgouridis, S. From big data to smart energy services:
An application for intelligent energy management. Future Gener. Comput. Syst. 2020, 110, 572–586. [CrossRef]
11.
Sony, S.; Laventure, S.; Sadhu, A. A literature review of next-generation smart sensing technology in structural health monitoring.
Struct. Control Health Monit. 2019, 26, e2321. [CrossRef]
12.
Lacinák, M.; Ristvej, J. Smart city, safety and security. Procedia Eng. 2017, 192, 522–527. [CrossRef]
13.
Kitchenham, B. Procedures for Performing Systematic Reviews; Technical Report TR/SE-0401; Keele University: Keele, UK, 2004.
Available online: https://www.inf.ufsc.br/~aldo.vw/kitchenham.pdf (accessed on 10 February 2023).
14.
Butt, O.M.; Zulqarnain, M.; Butt, T.M. Recent advancement in smart grid technology: Future prospects in the electrical power
network. Ain Shams Eng. J. 2021, 12, 687–695. [CrossRef]
15.
Jha, A.V.; Appasani, B.; Ghazali, A.N.; Pattanayak, P.; Gurjar, D.S.; Kabalci, E.; Mohanta, D.K. Smart grid cyber-physical systems:
Communication technologies, standards and challenges. Wirel. Netw. 2021, 27, 2595–2613. [CrossRef]
16.
Schmidt, M.; Åhlund, C. Smart buildings as Cyber-Physical Systems: Data-driven predictive control strategies for energy
efﬁciency. Renew. Sustain. Energy Rev. 2018, 90, 742–756. [CrossRef]
17.
Yurtsever, E.; Lambert, J.; Carballo, A.; Takeda, K. A survey of autonomous driving: Common practices and emerging technologies.
IEEE Access 2020, 8, 58443–58469. [CrossRef]
18.
Mao, T.; Mihăită, A.S.; Chen, F.; Vu, H.L. Boosted genetic algorithm using machine learning for trafﬁc control optimization. IEEE
Trans. Intell. Transp. Syst. 2022, 23, 7112–7141. [CrossRef]
19.
Wang, Z.; Song, H.; Watkins, D.W.; Ong, K.G.; Xue, P.; Yang, Q.; Shi, X. Cyber-physical systems for water sustainability: Challenges
and opportunities. IEEE Commun. Mag. 2015, 53, 216–222. [CrossRef]
20.
Jan, F.; Min-Allah, N.; Dü¸stegör, D. IoT based smart water quality monitoring: Recent techniques, trends and challenges for
domestic applications. Water 2021, 13, 1729. [CrossRef]
21.
Kochhar, A.; Kumar, N. Wireless sensor networks for greenhouses: An end-to-end review.
Comput.
Electron.
Agric.
2019, 163, 104877. [CrossRef]
22.
Cheng, L.; Wang, T.; Hong, X.; Wang, Z.; Wang, J.; Liu, J. A study on the architecture of manufacturing internet of things. Int. J.
Model. Identif. Control 2015, 23, 8–23. [CrossRef]
Electronics 2023, 12, 2490
54 of 63
23.
Dafﬂon, B.; Moalla, N.; Ouzrout, Y. The challenges, approaches, and used techniques of CPS for manufacturing in Industry 4.0: A
literature review. Int. J. Adv. Manuf. Technol. 2021, 113, 2395–2412. [CrossRef]
24.
Satyanarayanan, M. The emergence of edge computing. Computer 2017, 50, 30–39. [CrossRef]
25.
Chen, M.; Li, W.; Hao, Y.; Qian, Y.; Humar, I. Edge cognitive computing based smart healthcare system. Future Gener. Comput.
Syst. 2018, 86, 403–411. [CrossRef]
26.
Javaid, S.; Suﬁan, A.; Pervaiz, S.; Tanveer, M. Smart trafﬁc management system using Internet of Things. In Proceedings of the
2018 20th International Conference on Advanced Communication Technology (ICACT), Chuncheon, Republic of Korea, 11–14
February 2018; pp. 393–398. [CrossRef]
27.
Afrin, T.; Yodo, N. A survey of road trafﬁc congestion measures towards a sustainable and resilient transportation system.
Sustainability 2020, 12, 4660. [CrossRef]
28.
Sarrab, M.; Pulparambil, S.; Awadalla, M. Development of an IoT based real-time trafﬁc monitoring system for city governance.
Glob. Transit. 2020, 2, 230–245. [CrossRef]
29.
Zeadally, S.; Siddiqui, F.; Baig, Z.; Ibrahim, A. Smart healthcare: Challenges and potential solutions using internet of things (IoT)
and big data analytics. PSU Res. Rev. 2020, 4, 149–168. [CrossRef]
30.
Alromaihi, S.; Elmedany, W.; Balakrishna, C. Cyber security challenges of deploying IoT in smart cities for healthcare applications.
In Proceedings of the 6th International Conference on Future Internet of Things and Cloud Workshops (FiCloudW), Barcelona,
Spain, 6–8 August 2018; pp. 140–145. [CrossRef]
31.
Baker, S.B.; Xiang, W.; Atkinson, I. Internet of things for smart healthcare: Technologies, challenges, and opportunities. IEEE
Access 2017, 5, 26521–26544. [CrossRef]
32.
Qadri, Y.A.; Nauman, A.; Zikria, Y.B.; Vasilakos, A.V.; Kim, S.W. The future of healthcare internet of things: A survey of emerging
technologies. IEEE Commun. Surv. Tutor. 2020, 22, 1121–1167. [CrossRef]
33.
Concas, F.; Mineraud, J.; Lagerspetz, E.; Varjonen, S.; Liu, X.; Puolamäki, K.; Nurmi, P.; Tarkoma, S. Low-cost outdoor air quality
monitoring and sensor calibration: A survey and critical analysis. ACM Trans. Sens. Netw. 2021, 17, 1–44. [CrossRef]
34.
Bloomer, M. The Challenges and Complexities of Weather Forecasting. Available online: https://www.weather.gov/car/
weatherforecasting (accessed on 10 January 2023).
35.
Sosunova, I.; Porras, J. IoT-enabled smart waste management systems for smart cities: A systematic review. IEEE Access 2022, 10,
73326–73363. [CrossRef]
36.
Omar, A.; AlMaeeni, S.; Attia, H.; Takruri, M.; Altunaiji, A.; Sanduleanu, M.; Shubair, R.; Ashhab, M.S.; Al Ali, M.; Al Hebsi, G.
Smart city: Recent advances in intelligent street lighting systems based on IoT. J. Sens. 2022, 2022, 5249187. [CrossRef]
37.
Zanella, A.; Bui, N.; Castellani, A.; Vangelista, L.; Zorzi, M. Internet of things for smart cities. IEEE Internet Things J. 2014, 1, 22–32.
[CrossRef]
38.
Gharaibeh, A.; Salahuddin, M.A.; Hussini, S.J.; Khreishah, A.; Khalil, I.; Guizani, M.; Al-Fuqaha, A. Smart cities: A survey on data
management, security, and enabling technologies. IEEE Commun. Surv. Tutor. 2017, 19, 2456–2501. [CrossRef]
39.
Fernandes, E.; Jung, J.; Prakash, A. Security analysis of emerging smart home applications. In Proceedings of the 2016 IEEE
Symposium on Security and Privacy, San Jose, CA, USA, 22–26 May 2016; pp. 636–654. [CrossRef]
40.
Vault7-Home. Available online: https://wikileaks.org/ciav7p1/index.html (accessed on 10 January 2023).
41.
El-Hajj, M.; Fadlallah, A.; Chamoun, M.; Serhrouchni, A. A survey of internet of things (IoT) authentication schemes. Sensors
2019, 19, 1141. [CrossRef] [PubMed]
42.
Bari, A.; Jiang, J.; Saad, W.; Jaekel, A. Challenges in the smart grid applications: An overview. Int. J. Distrib. Sens. Netw.
2014, 10, 974682. [CrossRef]
43.
Wang, W.; Xu, Y.; Khanna, M. A survey on the communication architectures in smart grid. Comput. Netw. 2011, 55, 3604–3629.
[CrossRef]
44.
Khan, R.H.; Khan, J.Y. A comprehensive review of the application characteristics and trafﬁc requirements of a smart grid
communications network. Comput. Netw. 2013, 57, 825–845. [CrossRef]
45.
Kuzlu, M.; Pipattanasomporn, M.; Rahman, S. Communication network requirements for major smart grid applications in HAN,
NAN and WAN. Comput. Netw. 2014, 67, 74–88. [CrossRef]
46.
Abdullah, A.A.; Hassan, T.M. Smart grid (SG) properties and challenges: An overview. Discov. Energy 2022, 2, 8. [CrossRef]
47.
Gao, J.; Xiao, Y.; Liu, J.; Liang, W.; Chen, C.P. A survey of communication/networking in smart grids. Future Gener. Comput. Syst.
2012, 28, 391–404. [CrossRef]
48.
Kansal, P.; Bose, A. Bandwidth and latency requirements for smart transmission grid applications. IEEE Trans. Smart Grid 2012, 3,
1344–1352. [CrossRef]
49.
Jawhar, I.; Mohamed, N.; Al-Jaroodi, J. Networking architectures and protocols for smart city systems. J. Internet Serv. Appl. 2018,
9, 26. [CrossRef]
50.
Shoaib, N.; Shamsi, J.A. Understanding network requirements for smart city applications: Challenges and solutions. IT Prof. 2019,
21, 33–40. [CrossRef]
51.
Sesia, S.; Touﬁk, I.; Baker, M. LTE-the UMTS Long Term Evolution: From Theory to Practice; John Wiley & Sons: Hoboken, NJ,
USA, 2011.
52.
Chin, W.H.; Fan, Z.; Haines, R. Emerging technologies and research challenges for 5G wireless networks. IEEE Wirel. Commun.
2014, 21, 106–112. [CrossRef]
Electronics 2023, 12, 2490
55 of 63
53.
Ramya, C.M.; Shanmugaraj, M.; Prabakaran, R. Study on ZigBee technology. In Proceedings of the 3rd International Conference
on Electronics Computer Technology, Kanyakumari, India, 8–10 April 2011; Volume 6, pp. 297–301. [CrossRef]
54.
Atat, R.; Liu, L.; Chen, H.; Wu, J.; Li, H.; Yi, Y. Enabling cyber-physical communication in 5G cellular networks: Challenges,
spatial spectrum sensing, and cyber-security. IET Cyber-Phys. Syst. Theory Appl. 2017, 2, 49–54. [CrossRef]
55.
Khorov, E.; Lyakhov, A.; Krotov, A.; Guschin, A. A survey on IEEE 802.11ah: An enabling networking technology for smart cities.
Comput. Commun. 2015, 58, 53–69. [CrossRef]
56.
Kim, D.Y.; Jung, M. Data transmission and network architecture in long range low power sensor networks for IoT. Wirel. Pers.
Commun. 2017, 93, 119–129. [CrossRef]
57.
Ratasuk, R.; Vejlgaard, B.; Mangalvedhe, N.; Ghosh, A. NB-IoT system for M2M communication. In Proceedings of the 2016 IEEE
Wireless Communications and Networking Conference, Doha, Qatar, 3–6 April 2016; pp. 1–5. [CrossRef]
58.
Perera, C.; Qin, Y.; Estrella, J.C.; Reiff-Marganiec, S.; Vasilakos, A.V. Fog computing for sustainable smart cities: A survey. ACM
Comput. Surv. 2017, 50, 1–43. [CrossRef]
59.
Alvi, S.A.; Afzal, B.; Shah, G.A.; Atzori, L.; Mahmood, W. Internet of multimedia things: Vision and challenges. Ad Hoc Netw.
2015, 33, 87–111. [CrossRef]
60.
Avelar, E.; Marques, L.; dos Passos, D.; Macedo, R.; Dias, K.; Nogueira, M. Interoperability issues on heterogeneous wireless
communication for smart cities. Comput. Commun. 2015, 58, 4–15. [CrossRef]
61.
Cohen, E.G.; Ho, D.; Mohanty, B.P.; Rajkotia, P.R.; Berger, L.T.; Schwager, A.; Schneider, D.M. IEEE 1905.1: Convergent digital
home networking. In MIMO Power Line Communications: Narrow and Broadband Standards, EMC, and Advanced Processing; CRC:
Boca Raton, FL, USA, 2014.
62.
Del Esposte, A.D.M.; Santana, E.F.; Kanashiro, L.; Costa, F.M.; Braghetto, K.R.; Lago, N.; Kon, F. Design and evaluation of a
scalable smart city software platform with large-scale simulations. Future Gener. Comput. Syst. 2019, 93, 427–441. [CrossRef]
63.
Kanellopoulos, D.; Sharma, V.K. Dynamic load balancing techniques in the IoT: A review. Symmetry 2022, 14, 2554. [CrossRef]
64.
Liu, Q.; Gu, J.; Yang, J.; Li, Y.; Sha, D.; Xu, M.; Shams, I.; Yu, M.; Yang, C. Cloud, edge, and mobile computing for smart
cities. In Urban Informatics; The Urban Book Series; Shi, W., Goodchild, M.F., Batty, M., Kwan, M.P., Zhang, A., Eds.; Springer:
Singapore, 2021. [CrossRef]
65.
da Silva, T.P.; Batista, T.; Lopes, F.; Neto, A.R.; Delicato, F.C.; Pires, P.F.; da Rocha, A.R. Fog computing platforms for smart city
applications-A survey. ACM Trans. Internet Technol. 2022, 22, 1–32. [CrossRef]
66.
Mouradian, C.; Naboulsi, D.; Yangui, S.; Glitho, R.H.; Morrow, M.J.; Polakos, P.A. A comprehensive survey on fog computing:
State-of-the-art and research challenges. IEEE Commun. Surv. Tutor. 2017, 20, 416–464. [CrossRef]
67.
Coady, Y.; Hohlfeld, O.; Kempf, J.; McGeer, R.; Schmid, S. Distributed cloud computing: Applications, status quo, and challenges.
ACM SIGCOMM Comput. Commun. Rev. 2015, 45, 38–43. [CrossRef]
68.
Ksentini, A.; Jebalia, M.; Tabbane, S. IoT/cloud-enabled smart services: A review on QoS requirements in fog environment and a
proposed approach based on priority classiﬁcation technique. Int. J. Commun. Syst. 2021, 34, e4269. [CrossRef]
69.
OpenFog Consortium Architecture Working Group. OpenFog Reference Architecture for Fog Computing. 2017. Available online:
https://www.iiconsortium.org/pdf/OpenFog_Reference_Architecture_2_09_17.pdf (accessed on 10 January 2023).
70.
Theoleyre, F.; Watteyne, T.; Bianchi, G.; Tuna, G.; Gungor, V.C.; Pang, A.C. Networking and communications for smart cities
special issue editorial. Comput. Commun. 2015, 58, 1–3. [CrossRef]
71.
Conti, M.; Giordano, S. Mobile ad hoc networking: Milestones, challenges, and new research directions. IEEE Commun. Mag.
2014, 52, 85–96. [CrossRef]
72.
Winter, T.; Thubert, P.; Brandt, A.; Hui, J.; Kelsey, R.; Levis, P.; Pister, K.; Struik, R.; Vasseur, J.P.; Alexander, R. RPL: IPv6 Routing
Protocol for Low-Power and Lossy Networks. RFC 6550. 2012. Available online: https://www.rfc-editor.org/rfc/rfc6550.html
(accessed on 1 February 2023).
73.
Kushalnagar, N.; Montenegro, G.; Schumacher, C. IPv6 over Low-Power Wireless Personal Area Networks (6LoWPANs):
Overview, Assumptions, Problem Statement, and Goals. RFC 4919. 2007. Available online: https://www.rfc-editor.org/rfc/rfc4
919 (accessed on 1 February 2023).
74.
Soltanmohammadi, E.; Ghavami, K.; Naraghi-Pour, M. A survey of trafﬁc issues in machine-to-machine communications over
LTE. IEEE Internet Things J. 2016, 3, 865–884. [CrossRef]
75.
Velliangiri, S.; NG, B.A.; Baik, N.K. Detection of DoS attacks in smart city networks with feature distance maps: A statistical
approach. IEEE Internet Things J. 2023; Early Access. [CrossRef]
76.
Hassan, W.H. Current research on Internet of Things (IoT) security: A survey. Comput. Netw. 2019, 148, 283–294. [CrossRef]
77.
Hammi, M.T.; Hammi, B.; Bellot, P.; Serhrouchni, A. Bubbles of Trust: A decentralized blockchain-based authentication system
for IoT. Comput. Secur. 2018, 78, 126–142. [CrossRef]
78.
Qu, C.; Tao, M.; Zhang, J.; Hong, X.; Yuan, R. Blockchain based credibility veriﬁcation method for IoT entities. Secur. Commun.
Netw. 2018, 2018, 7817614. [CrossRef]
79.
Erhan, L.; Ndubuaku, M.; Di Mauro, M.; Song, W.; Chen, M.; Fortino, G.; Bagdasar, O.; Liotta, A. Smart anomaly detection in
sensor systems: A multi-perspective review. Inf. Fusion 2021, 67, 64–79. [CrossRef]
80.
Ullah, Z.; Al-Turjman, F.; Mostarda, L.; Gagliardi, R. Applications of artiﬁcial intelligence and machine learning in smart cities.
Comp. Commun. 2020, 154, 313–323. [CrossRef]
Electronics 2023, 12, 2490
56 of 63
81.
Ahmed, S.T.; Kumar, V.; Kim, J. AITel: eHealth Augmented Intelligence based Telemedicine Resource Recommendation Frame-
work for IoT devices in Smart cities. IEEE Internet Things J. 2023; Early Access. [CrossRef]
82.
Heidari, A.; Navimipour, N.J.; Unal, M. Applications of ML/DL in the management of smart cities and societies based on new
trends in information technologies: A systematic literature review. Sustain. Cities Soc. 2022, 85, 104089. [CrossRef]
83.
Syed, A.S.; Sierra-Sosa, D.; Kumar, A.; Elmaghraby, A. IoT in smart cities: A survey of technologies, practices and challenges.
Smart Cities 2021, 4, 429–475. [CrossRef]
84.
Yaqoob, I.; Hashem, I.A.T.; Mehmood, Y.; Gani, A.; Mokhtar, S.; Guizani, S. Enabling communication technologies for smart cities.
IEEE Commun. Mag. 2017, 55, 112–120. [CrossRef]
85.
Fernandes, R.F.; Fonseca, C.C.; Brandão, D.; Ferrari, P.; Flammini, A.; Vezzoli, A. Flexible Wireless Sensor Network for smart
lighting applications. In Proceedings of the 2014 IEEE International Instrumentation and Measurement Technology Conference
(I2MTC) Proceedings, Montevideo, Uruguay, 12–15 May 2014; pp. 434–439. [CrossRef]
86.
Gupta, A.; Jha, R.K. A survey of 5G network: Architecture and emerging technologies. IEEE Access 2015, 3, 1206–1232. [CrossRef]
87.
Yang, C.; Liang, P.; Fu, L.; Cui, G.; Huang, F.; Teng, F.; Bangash, Y.A. Using 5G in smart cities: A systematic mapping study. Intell.
Syst. Appl. 2022, 14, 200065. [CrossRef]
88.
Gungor, V.C.; Sahin, D.; Kocak, T.; Ergut, S.; Buccella, C.; Cecati, C.; Hancke, G.P. Smart grid technologies: Communication
technologies and standards. IEEE Trans. Ind. Inform. 2011, 7, 529–539. [CrossRef]
89.
García-García, L.; Jiménez, J.M.; Abdullah, M.T.A.; Lloret, J. Wireless technologies for IoT in smart cities. Netw. Protoc. Algorithms
2018, 10, 23–64. [CrossRef]
90.
Bettstetter, C.; Vogel, H.J.; Eberspacher, J. GSM phase 2+ general packet radio service GPRS: Architecture, protocols, and air
interface. IEEE Commun. Surv. 1999, 2, 2–14. [CrossRef]
91.
Dahlman, E.; Parkvall, S.; Skold, J. 4G: LTE/LTE-Advanced for Mobile Broadband; Academic Press: New York, NY, USA, 2013.
92.
Jung, W.; Kwon, Y. Differences between LTE and 3G service customers: Business and policy implications. Telemat. Inform. 2015,
32, 667–680. [CrossRef]
93.
Rinaldi, F.; Raschella, A.; Pizzi, S. 5G NR system design: A concise survey of key features and capabilities. Wirel. Netw. 2021, 27,
5173–5188. [CrossRef]
94.
Zaidi, A.A.; Baldemair, R.; Tullberg, H.; Bjorkegren, H.; Sundstrom, L.; Medbo, J.; Kilinc, C.; Da Silva, I. Waveform and numerology
to support 5G services and requirements. IEEE Commun. Magaz. 2016, 54, 90–98. [CrossRef]
95.
Perez-Costa, X.; Camps-Mur, D. IEEE 802.11 E QoS and power saving features overview and analysis of combined performance.
IEEE Wirel. Commun. 2010, 17, 88–96. [CrossRef]
96.
Sun, W.; Choi, M.; Choi, S. IEEE 802.11ah: A long range 802.11 WLAN at sub 1 GHz. J. ICT Stand. 2013, 1, 83–108. [CrossRef]
97.
Mozaffariahrar, E.; Theoleyre, F.; Menth, M. A survey of Wi-Fi 6: Technologies, advances, and challenges. Future Internet 2022,
14, 293. [CrossRef]
98.
Khajenasiri, I.; Estebsari, A.; Verhelst, M.; Gielen, G. A review on Internet of Things solutions for intelligent energy control in
buildings for smart city applications. Energy Procedia 2017, 111, 770–779. [CrossRef]
99.
Cerruela García, G.; Luque Ruiz, I.; Gómez-Nieto, M.Á. State of the art, trends and future of bluetooth low energy, near ﬁeld
communication and visible light communication in the development of smart cities. Sensors 2016, 16, 1968. [CrossRef]
100. Bluetooth®Wireless Technology. Available online: https://www.bluetooth.com/learn-about-bluetooth/tech-overview/ (ac-
cessed on 22 January 2023).
101. Faragher, R.; Harle, R. Location ﬁngerprinting with bluetooth low energy beacons. IEEE JSAC 2015, 33, 2418–2428. [CrossRef]
102. Miorandi, D.; Zanella, A.; Pierobon, G. Performance evaluation of Bluetooth polling schemes: An analytical approach. Mob. Netw.
Appl. 2004, 9, 6372. [CrossRef]
103. Nikoukar, A.; Raza, S.; Poole, A.; Güne¸s, M.; Dezfouli, B. Low-power wireless for the internet of things: Standards and applications.
IEEE Access 2018, 6, 67893–67926. [CrossRef]
104. Catherwood, P.A.; Steele, D.; Little, M.; Mccomb, S.; McLaughlin, J. A community-based IoT personalized wireless healthcare
solution trial. IEEE J. Transl. Eng. Health Med. 2018, 6, 1–13. [CrossRef]
105. Sharma, V.; You, I.; Pau, G.; Collotta, M.; Lim, J.D.; Kim, J.N. LoRaWAN-based energy-efﬁcient surveillance by drones for
intelligent transportation systems. Energies 2018, 11, 573. [CrossRef]
106. Jawad, H.M.; Nordin, R.; Gharghan, S.K.; Jawad, A.M.; Ismail, M. Energy-efﬁcient wireless sensor networks for precision
agriculture: A review. Sensors 2017, 17, 1781. [CrossRef] [PubMed]
107. Podevijn, N.; Plets, D.; Trogh, J.; Martens, L.; Suanet, P.; Hendrikse, K.; Joseph, W. TDoA-based outdoor positioning with tracking
algorithm in a public LoRa network. Wirel. Commun. Mob. Comput. 2018, 2018, 1864209. [CrossRef]
108. de Castro Tomé, M.; Nardelli, P.H.; Alves, H. Long-range low-power wireless networks and sampling strategies in electricity
metering. IEEE Trans. Ind. Electron. 2018, 66, 1629–1637. [CrossRef]
109. Haxhibeqiri, J.; De Poorter, E.; Moerman, I.; Hoebeke, J. A survey of LoRaWAN for IoT: From technology to application. Sensors
2018, 18, 3995. [CrossRef]
110. Adelantado, F.; Vilajosana, X.; Tuset-Peiro, P.; Martinez, B.; Melia-Segui, J.; Watteyne, T. Understanding the limits of LoRaWAN.
IEEE Commun. Mag. 2017, 55, 34–40. [CrossRef]
111. IEEE Std. 802.16-2004; IEEE Standard for Local and Metropolitan Area Networks. Part 16: Air Interface for Fixed Broadband
Wireless Access Systems. IEEE: Piscataway, NJ, USA, 2004.
Electronics 2023, 12, 2490
57 of 63
112. IEEE Std. 802.16e-2005; IEEE Standard for Local and Metropolitan Area Networks. Part 16: Air Interface for Fixed Broadband
Wireless Access Systems. IEEE: Piscataway, NJ, USA, 2006.
113. Vu, H.L.; Chan, S.; Andrew, L.L. Performance analysis of best-effort service in saturated IEEE 802.16 networks. IEEE Trans. Veh.
Technol. 2009, 59, 460–472. [CrossRef]
114. Pareit, D.; Lannoo, B.; Moerman, I.; Demeester, P. The history of WiMAX: A complete survey of the evolution in certiﬁcation and
standardization for IEEE 802.16 and WiMAX. IEEE Commun. Surv. Tutor. 2011, 14, 1183–1211. [CrossRef]
115. Pokhrel, S.R.; Williamson, C. Modeling compound TCP over WiFi for IoT. IEEE/ACM Trans. Netw. 2018, 26, 864–878. [CrossRef]
116. Sheng, Z.; Yang, S.; Yu, Y.; Vasilakos, A.V.; McCann, J.A.; Leung, K.K. A survey on the IETF protocol suite for the internet of
things: Standards, challenges, and opportunities. IEEE Wirel. Commun. 2013, 20, 91–98. [CrossRef]
117. Sharma, V.K.; Shukla, S.S.P.; Singh, V. A tailored Q-Learning for routing in wireless sensor networks. In Proceedings of the 2012
2nd IEEE International Conference on Parallel, Distributed and Grid Computing, Solan, India, 6–8 December 2012; pp. 663–668.
118. Kanellopoulos, D.; Sharma, V.K. Survey on power-aware optimization solutions for MANETs. Electronics 2020, 9, 1129. [CrossRef]
119. Shang, W.; Yu, Y.; Droms, R.; Zhang, L. Challenges in IoT Networking via TCP/IP Architecture. NDN Technical Report NDN-0038.
2016. Available online: http://named-data.net/techreports.html (accessed on 1 February 2023).
120. Iova, O.; Picco, P.; Istomin, T.; Kiraly, C. RPL: The routing standard for the internet of things... or is it? IEEE Commun. Mag. 2016,
54, 16–22. [CrossRef]
121. Sharma, V.K.; Kumar, M. Adaptive congestion control scheme in mobile ad-hoc networks. Peer-Peer Netw. Appl. 2017, 10, 633–657.
[CrossRef]
122. Sharma, V.K.; Verma, L.P.; Kumar, M. CL-ADSP: Cross-Layer adaptive data scheduling policy in mobile ad-hoc networks. Future
Gener. Comput. Syst. 2019, 97, 530–563. [CrossRef]
123. Verma, L.P.; Sharma, V.K.; Kumar, M.; Kanellopoulos, D.; Mahanti, A. DB-CMT: A new concurrent Multi-path Stream Control
Transport Protocol. J. Netw. Syst. Manag. 2022, 30, 67. [CrossRef]
124. Verma, L.P.; Sharma, V.K.; Kumar, M.; Mahanti, A. An adaptive multi-path data transfer approach for MP-TCP. Wirel. Netw. 2022,
28, 2185–2212. [CrossRef]
125. ANSI/ASHRAE Standard 135-2004; BACnet: A Data Communication Protocol for Building Automation and Control Networks,
Standard 135-2004. American Society of Heating Refrigeration, and Air-Conditioning Engineers Inc.: Atlanta, GA, USA, 2004.
126. Clark, D.D.; Tennenhouse, D.L. Architectural considerations for a new generation of protocols. ACM SIGCOMM Comput. Commun.
Rev. 1990, 20, 200–208. [CrossRef]
127. Tan, K.; Song, J.; Zhang, Q.; Sridharan, M. A compound TCP approach for high-speed and long distance networks. In Proceedings
of the IEEE INFOCOM 2006. 25TH IEEE International Conference on Computer Communications, Barcelona, Spain, 23–29
April 2006. [CrossRef]
128. Verma, L.P.; Sharma, V.K.; Kumar, M.; Kanellopoulos, D. A novel delay-based adaptive congestion control TCP variant. Comput.
Electr. Eng. 2022, 101, 108076. [CrossRef]
129. Pokhrel, S.R.; Panda, M.; Vu, H.L.; Mandjes, M. TCP performance over Wi-Fi: Joint impact of buffer and channel losses. IEEE
Trans. Mob. Comput. 2015, 15, 1279–1291. [CrossRef]
130. Pokhrel, S.R.; Vu, H.L.; Cricenti, A.L. Adaptive admission control for IoT applications in home WiFi networks. IEEE Trans. Mob.
Comput. 2019, 19, 2731–2742. [CrossRef]
131. Pokhrel, S.R.; Singh, S. Compound TCP performance for industry 4.0 WiFi: A cognitive federated learning approach. IEEE Trans.
Ind. Inform. 2020, 17, 2143–2151. [CrossRef]
132. Qiu, T.; Chen, N.; Li, K.; Atiquzzaman, M.; Zhao, W. How can heterogeneous internet of things build our future: A survey. IEEE
Commun. Surv. Tutor. 2018, 20, 2011–2027. [CrossRef]
133. Kharrufa, H.; Al-Kashoash, H.A.; Kemp, A.H. RPL-based routing protocols in IoT applications: A review. IEEE Sens. J. 2019, 19,
5952–5967. [CrossRef]
134. Sharma, V.K.; Verma, L.P.; Kumar, M. A fuzzy-based adaptive energy efﬁcient load distribution scheme in ad-hoc networks. Int. J.
Intell. Syst. Appl. 2018, 12, 72. [CrossRef]
135. Sharma, V.K.; Kumar, M. Adaptive energy efﬁcient load distribution using fuzzy approach. Adhoc Sens. Wirel. Netw. 2017, 39,
123–166.
136. Reina, D.G.; Toral, S.L.; Barrero, F.; Bessis, N.; Asimakopoulou, E. The role of ad hoc networks in the internet of things: A case
scenario for smart environments. In Internet of Things and Inter-Cooperative Computational Technologies for Collective Intelligence;
Springer: Berlin/Heidelberg, Germany, 2013; pp. 89–113. [CrossRef]
137. Vazifehdan, J.; Prasad, R.V.; Niemegeers, I. Energy-efﬁcient reliable routing considering residual energy in wireless ad hoc
networks. IEEE Trans. Mob. Comput. 2013, 13, 434–447. [CrossRef]
138. Sharma, V.K.; Kumar, M. Adaptive load distribution approach based on congestion control scheme in ad-hoc networks. Int. J.
Electron. 2019, 106, 48–68. [CrossRef]
139. Papandriopoulos, J.; Dey, S.; Evans, J. Optimal and distributed protocols for cross-layer design of physical and transport layers in
MANETs. IEEE/ACM Trans. Netw. 2008, 16, 1392–1405. [CrossRef]
140. Sharma, V.K.; Verma, L.P.; Kumar, M.; Naha, R.K.; Mahanti, A. A-CAFDSP: An adaptive-congestion aware Fibonacci sequence
based data scheduling policy. Comput. Commun. 2020, 158, 141–165. [CrossRef]
Electronics 2023, 12, 2490
58 of 63
141. Tian, Y.; Hou, R. An improved AOMDV routing protocol for internet of things. In Proceedings of the 2010 International Conference
on Computational Intelligence and Software Engineering, Wuhan, China, 10–12 December 2010; pp. 1–4. [CrossRef]
142. Tseng, C.H. Multipath load balancing routing for Internet of things. J. Sens. 2016, 2016, 4250746. [CrossRef]
143. Pan, M.S.; Tseng, Y.C. ZigBee and their applications. In Sensor Networks and Conﬁguration: Fundamentals, Standards, Platforms, and
Applications; Springer: Berlin/Heidelberg, Germany, 2007; pp. 349–368.
144. Sun, J.; Wang, Z.; Wang, H.; Zhang, X. Research on routing protocols based on ZigBee network. In Proceedings of the Third
International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP 2007), Kaohsiung,
Taiwan, 26–28 November 2007; Volume 1, pp. 639–642. [CrossRef]
145. Fielding, R.; Gettys, J.; Mogul, J.; Frystyk, H.; Masinter, L.; Leach, P.; Lee, B. Hypertext Transfer Protocol—HTTP/1.1. 1999.
Available online: https://www.w3.org/Protocols/rfc2616/rfc2616.html (accessed on 2 February 2023).
146. Webber, J.; Parastatidis, S.; Robinson, I. REST in Practice: Hypermedia and Systems Architecture; O’Reilly Media, Inc.: Sebastopol,
CA, USA, 2010.
147. Dizdarevic, J.; Caprio, F.; Jukan, A.; Masip-Bruin, X. A survey of communication protocols for Internet-of-Things and related
challenges of fog and cloud computing integration. ACM Comput. Surv. 2019, 51, 1–29. [CrossRef]
148. Babovic, Z.B.; Protic, J.; Milutinovic, V. Web performance evaluation for Internet of Things applications. IEEE Access 2016, 4,
6974–6992. [CrossRef]
149. Bormann, C.; Castellani, A.P.; Shelby, Z. CoAP: An application protocol for billions of tiny internet nodes. IEEE Internet Comput.
2012, 16, 62–67. [CrossRef]
150. OASIS. Message Queuing Telemetry Transport. Available online: http://mqtt.org (accessed on 10 February 2023).
151. OPC Foundation. OPC Uniﬁed Architecture Speciﬁcation. 2023. Available online: https://opcfoundation.org (accessed on 10
February 2023).
152. XMPP Standards Foundation. Extensible Messaging and Presence Protocol. 2021. Available online: https://xmpp.org (accessed
on 10 February 2023).
153. OASIS. OASIS Advanced Message Queuing Protocol (AMQP) Version 1.0—OASIS Standard; OASIS: Burlington, MA, USA, 2012.
154. Pardo-Castellote, G.; Innovations, R.T.; Chairman, D.D.S. OMG Data Distribution Service: Real-time publish/subscribe becomes
a standard. RTC Mag. 2005, 14, 1–3. Available online: https://www.rti.com/hubfs/docs/reprint_rti.pdf (accessed on 10 February
2023).
155. Glaroudis, D.; Iossiﬁdes, A.; Chatzimisios, P. Survey, comparison and research challenges of IoT application protocols for smart
farming. Comput. Netw. 2020, 168, 107037. [CrossRef]
156. Centenaro, M.; Vangelista, L.; Zanella, A.; Zorzi, M. Long-range communications in unlicensed bands: The rising stars in the IoT
and smart city scenarios. IEEE Wirel. Commun. 2016, 23, 60–67. [CrossRef]
157. Leccese, F.; Cagnetti, M.; Trinca, D. A smart city application: A fully controlled street lighting isle based on Raspberry-Pi card, a
ZigBee sensor network and WiMAX. Sensors 2014, 14, 24408–24424. [CrossRef]
158. Sanchez, L.; Muñoz, L.; Galache, J.A.; Sotres, P.; Santana, J.R.; Gutierrez, V.; Ramdhany, R.; Gluhak, A.; Krco, S.;
Theodoridis, E.; et al. SmartSantander: IoT experimentation over a smart city testbed. Comput. Netw. 2014, 61, 217–238.
[CrossRef]
159. Vilajosana, I.; Dohler, M. Machine-to-Machine (M2M) communications for smart cities. Mach.-Mach. (M2M) Commun. 2015,
355–373. [CrossRef]
160. Huang, J.; Xing, C.C.; Shin, S.Y.; Hou, F.; Hsu, C.H. Optimizing M2M communications and quality of services in the IoT for
sustainable smart cities. IEEE Trans. Sustain. Comput. 2017, 3, 4–15. [CrossRef]
161. Silva, B.N.; Khan, M.; Han, K. Towards sustainable smart cities: A review of trends, architectures, components, and open
challenges in smart cities. Sustain. Cities Soc. 2018, 38, 697–713. [CrossRef]
162. Jin, J.; Gubbi, J.; Luo, T.; Palaniswami, M. Network architecture and QoS issues in the internet of things for a smart city. In
Proceedings of the 2012 International Symposium on Communications and Information Technologies (ISCIT), Gold Coast,
Australia, 2–5 October 2012; pp. 956–961. [CrossRef]
163. Marques, P.; Manfroi, D.; Deitos, E.; Cegoni, J.; Castilhos, R.; Rochol, J.; Pignaton, E.; Kunst, R. An IoT-based smart cities
infrastructure architecture applied to a waste management scenario. Ad Hoc Netw. 2019, 87, 200–208. [CrossRef]
164. Gaur, A.; Scotney, B.; Parr, G.; McClean, S. Smart city architecture and its applications based on IoT. Procedia Comput. Sci 2015, 52,
1089–1094. [CrossRef]
165. Gheisari, M.; Pham, Q.V.; Alazab, M.; Zhang, X.; Fernández-Campusano, C.; Srivastava, G. ECA: An edge computing architecture
for privacy-preserving in IoT-based smart city. IEEE Access 2019, 7, 155779–155786. [CrossRef]
166. Saadeh, M.; Sleit, A.; Sabri, K.E.; Almobaideen, W. Hierarchical architecture and protocol for mobile object authentication in the
context of IoT smart cities. J. Netw. Comput. Appl. 2018, 121, 1–19. [CrossRef]
167. Naranjo, P.G.V.; Pooranian, Z.; Shojafar, M.; Conti, M.; Buyya, R. FOCAN: A Fog-supported smart city network architecture for
management of applications in the Internet of Everything environments. J. Parallel Distrib. Comput. 2019, 132, 274–283. [CrossRef]
168. Ortiz, S. Software-Deﬁned Networking: On the verge of a breakthrough? Computer 2013, 46, 10–12. [CrossRef]
169. AlZoman, R.; Alenazi, M.J. Exploiting SDN to improve QoS of smart city networks against link failures. In Proceedings of the
Seventh International Conference on Software Deﬁned Systems (SDS), Paris, France, 20–23 April 2020; pp. 100–106. [CrossRef]
Electronics 2023, 12, 2490
59 of 63
170. Holik, F. Meeting smart city latency demands with SDN. In Intelligent Information and Database Systems: Recent Developments.
ACIIDS 2019. Studies in Computational Intelligence; Huk, M., Maleszka, M., Szczerbicki, E., Eds.; Springer: Cham, Switzerland,
Volume 830. [CrossRef]
171. Jazaeri, S.S.; Jabbehdari, S.; Asghari, P.; Haj Seyyed Javadi, H. Edge computing in SDN-IoT networks: A systematic review of
issues, challenges and solutions. Clust. Comput. 2021, 24, 3187–3228. [CrossRef]
172. Liu, J.; Li, Y.; Chen, M.; Dong, W.; Jin, D. Software-deﬁned internet of things for smart urban sensing. IEEE Commun. Mag. 2015,
53, 55–63. [CrossRef]
173. Bi, Y.; Lin, C.; Zhou, H.; Yang, P.; Shen, X.; Zhao, H. Time-constrained big data transfer for SDN-enabled smart city. IEEE Commun.
Mag. 2017, 55, 44–50. [CrossRef]
174. Nguyen, T.G.; Phan, T.V.; Nguyen, B.T.; So-In, C.; Baig, Z.A.; Sanguanpong, S. Search: A collaborative and intelligent NIDs
architecture for SDN-based cloud IoT networks. IEEE Access 2019, 7, 107678–107694. [CrossRef]
175. Bhushan, B.; Khamparia, A.; Sagayam, K.M.; Sharma, S.K.; Ahad, M.A.; Debnath, N.C. Blockchain for smart cities: A review of
architectures, integration trends and future research directions. Sustain. Cities Soc. 2020, 61, 102360. [CrossRef]
176. Sharma, P.K.; Park, J.H. Blockchain based hybrid network architecture for the smart city. Future Gener. Comput. Syst. 2018, 86,
650–655. [CrossRef]
177. Makhdoom, I.; Zhou, I.; Abolhasan, M.; Lipman, J.; Ni, W. PrivySharing: A blockchain-based framework for privacy-preserving
and secure data sharing in smart cities. Comput. Secur. 2020, 88, 101653. [CrossRef]
178. Islam, M.J.; Rahman, A.; Kabir, S.; Karim, M.R.; Acharjee, U.K.; Nasir, M.K.; Band, S.S.; Sookhak, M.; Wu, S. Blockchain-SDN-based
energy-aware and distributed secure architecture for IoT in smart cities. IEEE Internet Things J. 2021, 9, 3850–3864. [CrossRef]
179. Tuballa, M.L.; Abundo, M.L. A review of the development of Smart Grid technologies. Renew. Sustain. Energy Rev. 2016, 59,
710–725. [CrossRef]
180. Demertzis, K.; Tsiknas, K.; Taketzis, D.; Skoutas, D.N.; Skianis, C.; Iliadis, L.; Zoiros, K.E. Communication network standards for
smart grid infrastructures. Network 2021, 1, 132–145. [CrossRef]
181. Bosisio, A.; Berizzi, A.; Morotti, A.; Pegoiani, A.; Greco, B.; Iannarelli, G. IEC 61850-based smart automation system logic to
improve reliability indices in distribution networks. In Proceedings of the 2019 IEEE 8th International Conference on Advanced
Power System Automation and Protection (APAP), Florence, Italy, 18–20 October 2019; pp. 1219–1222.
182. Girela-López, F.; López-Jiménez, J.; Jiménez-López, M.; Rodríguez, R.; Ros, E.; Díaz, J. IEEE 1588 high accuracy default proﬁle:
Applications and challenges. IEEE Access 2020, 8, 45211–45220. [CrossRef]
183. Abdrabou, A. A wireless communication architecture for smart grid distribution networks. IEEE Syst. J. 2014, 10, 251–261.
[CrossRef]
184. Demir, K.; Germanus, D.; Suri, N. Robust QoS-aware communication in the smart distribution grid. Peer-Peer Netw. Appl. 2017,
10, 193–207. [CrossRef]
185. Rehmani, M.H.; Davy, A.; Jennings, B.; Assi, C. Software deﬁned networks-based smart grid communication: A comprehensive
survey. IEEE Commun. Surv. Tutor. 2019, 21, 2637–2670. [CrossRef]
186. Alam, S.; Sohail, M.F.; Ghauri, S.A.; Qureshi, I.M.; Aqdas, N. Cognitive radio based smart grid communication network. Renew.
Sustain. Energy Rev. 2017, 72, 535–548. [CrossRef]
187. Molokomme, D.N.; Chabalala, C.S.; Bokoro, P.N. A review of cognitive radio smart grid communication infrastructure systems.
Energies 2020, 13, 3245. [CrossRef]
188. Hu, S.; Chen, X.; Ni, W.; Wang, X.; Hossain, E. Modeling and analysis of energy harvesting and smart grid-powered wireless
communication networks: A contemporary survey. IEEE Trans. Green Commun. Netw. 2020, 4, 461–496. [CrossRef]
189. Saleem, Y.; Crespi, N.; Rehmani, M.H.; Copeland, R. Internet of things-aided smart grid: Technologies, architectures, applications,
prototypes, and future research directions. IEEE Access 2019, 7, 62962–63003. [CrossRef]
190. Younus, M.U.; ul Islam, S.; Ali, I.; Khan, S.; Khan, M.K. A survey on software deﬁned networking enabled smart buildings:
Architecture, challenges and use cases. J. Netw. Comput. Appl. 2019, 137, 62–77. [CrossRef]
191. Minoli, D.; Sohraby, K.; Occhiogrosso, B. IoT considerations, requirements, and architectures for smart buildings—Energy
optimization and next-generation building management systems. IEEE Internet Things J. 2017, 4, 269–283. [CrossRef]
192. Jia, M.; Komeily, A.; Wang, Y.; Srinivasan, R.S. Adopting Internet of Things for the development of smart buildings: A review of
enabling technologies and applications. Autom. Constr. 2019, 101, 111–126. [CrossRef]
193. Kumar, A.; Singh, A.; Kumar, A.; Singh, M.K.; Mahanta, P.; Mukhopadhyay, S.C. Sensing technologies for monitoring intelligent
buildings: A review. IEEE Sens. J. 2018, 18, 4847–4860. [CrossRef]
194. Silva, B.N.; Khan, M.; Han, K. Integration of Big Data analytics embedded smart city architecture with RESTful web of things for
efﬁcient service provision and energy management. Future Gener. Comput. Syst. 2020, 107, 975–987. [CrossRef]
195. Kumar, A.; Srivastava, V.; Singh, M.K.; Hancke, G.P. Current status of the IEEE 1451 standard-based sensor applications. IEEE
Sens. J. 2014, 15, 2505–2513. [CrossRef]
196. Kumar, A.; Hancke, G.P. Energy efﬁcient environment monitoring system based on the IEEE 802.15. 4 standard for low cost
requirements. IEEE Sens. J. 2014, 14, 2557–2566. [CrossRef]
197. du Plessis, R.; Kumar, A.; Hancke, G.P.; Silva, B.J. A wireless system for indoor air quality monitoring. In Proceedings of
the IECON 2016—42nd Annual Conference of the IEEE Industrial Electronics Society, Florence, Italy, 23–26 October 2016;
pp. 5409–5414.
Electronics 2023, 12, 2490
60 of 63
198. Kularatna, N.; Sudantha, B.H. An environmental air pollution monitoring system based on the IEEE 1451 standard for low cost
requirements. IEEE Sens. J. 2008, 8, 415–422. [CrossRef]
199. Gagliardi, G.; Lupia, M.; Cario, G.; Tedesco, F.; Cicchello Gaccio, F.; Lo Scudo, F.; Casavola, A. Advanced adaptive street lighting
systems for smart cities. Smart Cities 2020, 3, 1495–1512. [CrossRef]
200. Warmerdam, K.; Pandharipande, A. Location data analytics in wireless lighting systems. IEEE Sens. J. 2015, 16, 2683–2690.
[CrossRef]
201. Tiller, D.K.; Guo, X.; Henze, G.P.; Waters, C.E. Validating the application of occupancy sensor networks for lighting control. Light.
Res. Technol. 2010, 42, 399–414. [CrossRef]
202. Byun, J.; Hong, I.; Lee, B.; Park, S. Intelligent household LED lighting system considering energy efﬁciency and user satisfaction.
IEEE Trans. Consum. Electron. 2013, 59, 70–76. [CrossRef]
203. Higuera, J.; Hertog, W.; Perálvarez, M.; Polo, J.; Carreras, J. Smart lighting system ISO/IEC/IEEE 21451 compatible. IEEE Sens. J.
2015, 15, 2595–2602. [CrossRef]
204. Tan, Y.K.; Huynh, T.P.; Wang, Z. Smart personal sensor network control for energy saving in DC grid powered LED lighting
system. IEEE Trans. Smart Grid 2012, 4, 669–676. [CrossRef]
205. Chew, I.; Karunatilaka, D.; Tan, C.P.; Kalavally, V. Smart lighting: The way forward? Reviewing the past to shape the future.
Energy Build. 2017, 149, 180–191. [CrossRef]
206. Füchtenhans, M.; Grosse, E.H.; Glock, C.H. Smart lighting systems: State-of-the-art and potential applications in warehouse order
picking. Int. J. Prod. Res. 2021, 59, 3817–3839. [CrossRef]
207. Kumar, A.; Hancke, G.P. An energy-efﬁcient smart comfort sensing system based on the IEEE 1451 standard for green buildings.
IEEE Sens. J. 2014, 14, 4245–4252. [CrossRef]
208. Kavalionak, H.; Carlini, E. An HVAC regulation architecture for smart building based on weather forecast. In Proceedings of the
Economics of Grids, Clouds, Systems, and Services: 15th International Conference, GECON 2018, Pisa, Italy, 18–20 September
2018; Proceedings 15. Springer International Publishing: Berlin/Heidelberg, Germany, 2019; pp. 92–103.
209. Hao, H.; Lin, Y.; Kowli, A.S.; Barooah, P.; Meyn, S. Ancillary service to the grid through control of fans in commercial building
HVAC systems. IEEE Trans. Smart Grid 2014, 5, 2066–2074. [CrossRef]
210. Sun, B.; Luh, P.B.; Jia, Q.S.; Jiang, Z.; Wang, F.; Song, C. Building energy management: Integrated control of active and passive
heating, cooling, lighting, shading, and ventilation systems. IEEE Trans. Autom. Sci. Eng. 2012, 10, 588–602. [CrossRef]
211. Lin, Y.; Barooah, P.; Meyn, S.; Middelkoop, T. Experimental evaluation of frequency regulation from commercial building HVAC
systems. IEEE Trans. Smart Grid 2015, 6, 776–783. [CrossRef]
212. Ma, Y.; Matuško, J.; Borrelli, F. Stochastic model predictive control for building HVAC systems: Complexity and conservatism.
IEEE Trans. Control Syst. Technol. 2014, 23, 101–116. [CrossRef]
213. Javed, A.; Larijani, H.; Ahmadinia, A.; Emmanuel, R.; Mannion, M.; Gibson, D. Design and implementation of a cloud enabled
random neural network-based decentralized smart controller with intelligent sensor nodes for HVAC. IEEE Internet Things J.
2016, 4, 393–403. [CrossRef]
214. Kumar, A.; Kumar, A.; Singh, A. Energy efﬁcient and low cost air quality sensor for smart buildings. In Proceedings of the
2017 3rd International Conference on Computational Intelligence & Communication Technology (CICT), Ghaziabad, India, 9–10
February 2017; pp. 1–4.
215. Kim, J.Y.; Chu, C.H.; Shin, S.M. ISSAQ: An integrated sensing systems for real-time indoor air quality monitoring. IEEE Sens. J.
2014, 14, 4230–4244. [CrossRef]
216. Lozano, J.; Suárez, J.I.; Arroyo, P.; Ordiales, J.M.; Alvarez, F. Wireless sensor network for indoor air quality monitoring. Chem.
Eng. Trans. 2012, 30, 231–235.
217. Bhattacharya, S.; Sridevi, S.; Pitchiah, R. Indoor air quality monitoring using wireless sensor network. In Proceedings of the 2012
Sixth International Conference on Sensing Technology (ICST), Kolkata, India, 18–21 December 2012; pp. 422–427.
218. Kim, D.; Yoon, Y.; Lee, J.; Mago, P.J.; Lee, K.; Cho, H. Design and implementation of smart buildings: A review of current research
trend. Energies 2022, 15, 4278. [CrossRef]
219. Metallidou, C.K.; Psannis, K.E.; Egyptiadou, E.A. Energy efﬁciency in smart buildings: IoT approaches. IEEE Access 2020, 8,
63679–63699. [CrossRef]
220. Mariano-Hernández, D.; Hernández-Callejo, L.; Zorita-Lamadrid, A.; Duque-Pérez, O.; García, F.S. A review of strategies for
building energy management system: Model predictive control, demand side management, optimization, and fault detect &
diagnosis. J. Build. Eng. 2021, 33, 101692. [CrossRef]
221. Moudgil, V.; Hewage, K.; Hussain, S.A.; Sadiq, R. Integration of IoT in building energy infrastructure: A critical review on
challenges and solutions. Renew. Sustain. Energy Rev. 2023, 174, 113121. [CrossRef]
222. The Smart Water Networks Forum What Is a Smart Water Network? Available online: https://swan-forum.com/smart-water-
network/ (accessed on 1 October 2022).
223. Nguyen, K.A.; Stewart, R.A.; Zhang, H.; Sahin, O.; Siriwardene, N. Re-engineering traditional urban water management practices
with smart metering and informatics. Environ. Model. Softw. 2018, 101, 256–267. [CrossRef]
224. Chen, Y.; Han, D. Water quality monitoring in smart city: A pilot project. Autom. Constr. 2018, 89, 307–316. [CrossRef]
225. Kamienski, C.; Soininen, J.P.; Taumberger, M.; Dantas, R.; Toscano, A.; Cinotti, T.S.; Maia, R.F.; Neto, A.T. Smart water management
platform: IoT-based precision irrigation for agriculture. Sensors 2019, 19, 276. [CrossRef]
Electronics 2023, 12, 2490
61 of 63
226. Ye, Y.; Liang, L.; Zhao, H.; Jiang, Y. The System Architecture of Smart Water Grid for Water Security. Procedia Eng. 2016, 154,
361–368. [CrossRef]
227. Alvisi, S.; Casellato, F.; Franchini, M.; Govoni, M.; Luciani, C.; Poltronieri, F.; Riberto, G.; Stefanelli, C.; Tortonesi, M. Wireless
middleware solutions for smart water metering. Sensors 2019, 19, 1853. [CrossRef] [PubMed]
228. Li, J.; Yang, X.; Sitzenfrei, R. Rethinking the framework of smart water system: A review. Water 2020, 12, 412. [CrossRef]
229. Dong, X.; Lin, H.; Tan, R.; Iyer, R.K.; Kalbarczyk, Z. Software-Deﬁned Networking for Smart Grid Resilience: Opportunities and
Challenges. In Proceedings of the CPSS 2015—1st ACM Workshop on Cyber-Physical System Security, Part of ASIACCS 2015,
Denver, CO, USA, 16 October 2015; pp. 61–68. [CrossRef]
230. Luciani, C.; Casellato, F.; Alvisi, S.; Franchini, M. From Water Consumption Smart Metering to Leakage Characterization at
District and User Level: The GST4Water Project. Proceedings 2018, 2, 675. [CrossRef]
231. Panagiotakopoulos, T.; Vlachos, D.P.; Bakalakos, T.V.; Kanavos, A.; Kameas, A. A FIWARE-based IoT framework for smart
water distribution management. In Proceedings of the 12th International Conference on Information, Intelligence, Systems &
Applications (IISA), Chania Crete, Greece, 12–14 July 2021; pp. 1–6. [CrossRef]
232. Amaxilatis, D.; Chatzigiannakis, I.; Tselios, C.; Tsironis, N.; Niakas, N.; Papadogeorgos, S. A smart water metering deployment
based on the fog computing paradigm. Appl. Sci. 2020, 10, 1965. [CrossRef]
233. Kulkarni, P.; Farnham, T. Smart city wireless connectivity considerations and cost analysis: Lessons learnt from smart water case
studies. IEEE Access 2016, 4, 660–672. [CrossRef]
234. Watson, J.P.; Greenberg, H.J.; Hart, W.E. A multiple-objective analysis of sensor placement optimization in water networks. In
Critical Transitions in Water and Environmental Resources Management; American Society of Civil Engineers: Reston, VA, USA, 2004;
pp. 1–10.
235. Berry, J.W.; Fleischer, L.; Hart, W.E.; Phillips, C.A.; Watson, J.P. Sensor placement in municipal water networks. J. Water Resour.
Plan. Manag. 2005, 131, 237–243. [CrossRef]
236. Liu, S.; Liu, W.; Chen, J.; Wang, Q. Optimal locations of monitoring stations in water distribution systems under multiple demand
patterns: A ﬂaw of demand coverage method and modiﬁcation. Front. Environ. Sci. Eng. 2012, 6, 204–212. [CrossRef]
237. Whittle, A.J.; Girod, L.; Preis, A.; Allen, M.; Lim, H.B.; Iqbal, M.; Srirangarajan, S.; Fu, C.; Wong, K.J.; Goldsmith, D. WATER-
WISE@SG: A testbed for continuous monitoring of the water distribution system in Singapore. In Water Distribution Systems
Analysis; American Society of Civil Engineers: Reston, VA, USA, 2010; pp. 1362–1378.
238. Whittle, A.; Allen, M.; Preis, A.; Iqbal, M. Sensor networks for monitoring and control of water distribution systems. In
Proceedings of the 6th International Conference on Structural Health Monitoring of Intelligent Infrastructure, Hong Kong, China,
9–11 December 2013; pp. 9–11.
239. Patil, K.; Ghosh, A.; Das, D.; Vuppala, S.K. IWCMSE: Integrated water consumption monitoring solution for enterprises. In
Proceedings of the ACM International Conference on Interdisciplinary Advances in Applied Computing, Amritapuri, India,
10–14 October 2014; pp. 1–8. [CrossRef]
240. Yoon, S.; Ye, W.; Heidemann, J.; Littleﬁeld, B.; Shahabi, C. SWATS: Wireless sensor networks for steamﬂood and waterﬂood
pipeline monitoring. IEEE Netw. 2011, 25, 50–56. [CrossRef]
241. Ang, L.M.; Seng, K.P.; Ijemaru, G.K.; Zungeru, A.M. Deployment of IoV for smart cities: Applications, architecture, and challenges.
IEEE Access 2018, 7, 6473–6492. [CrossRef]
242. Liu, K.; Xu, X.; Chen, M.; Liu, B.; Wu, L.; Lee, V.C. A hierarchical architecture for the future internet of vehicles. IEEE Commun.
Mag. 2019, 57, 41–47. [CrossRef]
243. Chen, M.; Tian, Y.; Fortino, G.; Zhang, J.; Humar, I. Cognitive internet of vehicles. Comput. Commun. 2018, 120, 58–70. [CrossRef]
244. Karim, A. Development of secure Internet of Vehicle Things (IoVT) for smart transportation system. Comput. Electr. Eng. 2022,
102, 108101. [CrossRef]
245. Contreras-Castillo, J.; Zeadally, S.; Guerrero-Ibañez, J.A. Internet of vehicles: Architecture, protocols, and security. IEEE Internet
Things J. 2017, 5, 3701–3709. [CrossRef]
246. Ji, B.; Zhang, X.; Mumtaz, S.; Han, C.; Li, C.; Wen, H.; Wang, D. Survey on the internet of vehicles: Network architectures and
applications. IEEE Commun. Stand. Mag. 2020, 4, 34–41. [CrossRef]
247. Sharma, P.K.; Moon, S.Y.; Park, J.H. Block-VN: A distributed blockchain based vehicular network architecture in smart city. J. Inf.
Process. Syst. 2017, 13, 184–195. [CrossRef]
248. Jan, B.; Farman, H.; Khan, M.; Talha, M.; Din, I.U. Designing a smart transportation system: An internet of things and big data
approach. IEEE Wirel. Commun. 2019, 26, 73–79. [CrossRef]
249. Saxena, D.; Raychoudhury, V.; Suri, N.; Becker, C.; Cao, J. Named Data Networking: A survey. Comput. Sci. Rev. 2016, 19, 15–55.
[CrossRef]
250. Kaiwartya, O.; Abdullah, A.H.; Cao, Y.; Altameem, A.; Prasad, M.; Lin, C.T.; Liu, X. Internet of vehicles: Motivation, layered
architecture, network model, challenges, and future aspects. IEEE Access 2016, 4, 5356–5373. [CrossRef]
251. Kerrache, C.A.; Lagraa, N.; Hussain, R.; Ahmed, S.H.; Benslimane, A.; Calafate, C.T.; Cano, J.-C.; Vegni, A.M. TACASHI:
Trust-aware communication architecture for social internet of vehicles. IEEE Internet Things J. 2019, 6, 5870–5877. [CrossRef]
252. Anastasiou, E.; Manika, S.; Ragazou, K.; Katsios, I. Territorial and human geography challenges: How can Smart villages support
rural development and population inclusion? Soc. Sci. 2021, 10, 193. [CrossRef]
253. Komorowski, Ł.; Stanny, M. Smart villages: Where can they happen? Land 2020, 9, 151.
Electronics 2023, 12, 2490
62 of 63
254. Cambra-Fierro, J.J.; Pérez, L. (Re) thinking smart in rural contexts: A multi-country study. Growth Chang. 2022, 53, 868–889.
[CrossRef]
255. European Network for Rural Development, Smart Villages. Available online: https://enrd.ec.europa.eu/smart-and-competitive-
rural-areas/smart-villages_en (accessed on 10 June 2022).
256. IEEE Smart Village. Available online: http://ieee-smart-village.org/ (accessed on 10 June 2022).
257. Malik, P.K.; Singh, R.; Gehlot, A.; Akram, S.V.; Das, P.K. Village 4.0: Digitalization of village with smart internet of things
technologies. Comput. Ind. Eng. 2022, 165, 107938. [CrossRef]
258. Shrestha, S.; Drozdenko, B. Smart Rural Framework using IoT devices and Cloud computing. In Proceedings of the 2019 IEEE
Green Technologies Conference (GreenTech), Lafayette, LA, USA, 3–6 April 2019. [CrossRef]
259. Monzon Baeza, V.; Alvarez Marban, M. High Altitude Platform Stations Aided Cloud-Computing Solution for Rural-Environment
IoT Applications. Comput. Netw. Commun. 2022, 1, 85–98.
260. Aljuhani, A.; Kumar, P.; Kumar, R.; Jolfaei, A.; Islam, A.N. Fog intelligence for secure smart villages: Architecture, and future
challenges. IEEE Consum. Electron. Mag. 2022, 8, 1–9. [CrossRef]
261. Rohan, R.; Pal, D.; Watanapa, B.; Funilkul, S. Emerging Paradigm of IoT Enabled Smart Villages. In Proceedings of the 2022 IEEE
International Conference on Consumer Electronics (ICCE), Las Vegas, NV, USA, 7–9 January 2022.
262. Han, B.; Gopalakrishnan, V.; Ji, L.; Lee, S. Network function virtualization: Challenges and opportunities for innovations. IEEE
Commun. Mag. 2015, 53, 90–97. [CrossRef]
263. Li, Y.; Chen, M. Software-deﬁned network function virtualization: A survey. IEEE Access 2015, 3, 2542–2553. [CrossRef]
264. Sinh, D.; Le, L.V.; Lin, B.S.P.; Tung, L.P. SDN/NFV—A new approach of deploying network infrastructure for IoT. In Proceedings
of the 2018 27th Wireless and Optical Communication Conference (WOCC), Hualien, Taiwan, 30 April–1 May 2018; pp. 1–5.
265. Mukherjee, B.K.; Pappu, S.I.; Islam, M.; Acharjee, U.K. An SDN based distributed IoT network with NFV implementation for
smart cities. In Proceedings of the International Conference on Cyber Security and Computer Science, Dhaka, Bangladesh, 15–16
February 2020; Springer: Cham, Switzerland; pp. 539–552. [CrossRef]
266. Khan, A.A.; Rehmani, M.H.; Rachedi, A. Cognitive-radio-based Internet of Things: Applications, architectures, spectrum related
functionalities, and future research directions. IEEE Wirel. Commun. 2017, 24, 17–25. [CrossRef]
267. Pranaya, Y.C.; Himarish, M.N.; Baig, M.N.; Ahmed, M.R. Cognitive architecture based smart grids for smart cities. In Proceedings
of the 3rd International Conference on Power Generation Systems and Renewable Energy Technologies (PGSRET 2017), Johor
Bahru, Malaysia, 4–6 April 2017; pp. 44–49. [CrossRef]
268. Gai, K.; Xu, K.; Lu, Z.; Qiu, M.; Zhu, L. Fusion of cognitive wireless networks and edge computing. IEEE Wirel. Commun. 2019, 26,
69–75. [CrossRef]
269. Scrugli, M.A.; Loi, D.; Raffo, L.; Meloni, P. A runtime-adaptive cognitive IoT node for healthcare monitoring. In Proceedings of the
16th ACM International Conference on Computing Frontiers 2019, Alghero, Italy, 30 April–2 May 2019; pp. 350–357. [CrossRef]
270. Li, F.; Lam, K.Y.; Li, X.; Sheng, Z.; Hua, J.; Wang, L. Advances and emerging challenges in cognitive internet-of-things. IEEE Trans.
Ind. Inform. 2019, 16, 5489–5496. [CrossRef]
271. Park, J.H.; Salim, M.M.; Jo, J.H.; Sicato, J.C.S.; Rathore, S.; Park, J.H. CIoT-Net: A scalable cognitive IoT based smart city network
architecture. Hum.-Cent. Comput. Inf. Sci. 2019, 9, 29. [CrossRef]
272. Nayak, P.; Garetto, M.; Knightly, E.W. Multi-user downlink with single-user uplink can starve TCP. In Proceedings of the IEEE
INFOCOM 2017, Atlanta, GA, USA, 1–4 May 2017; pp. 1–9. [CrossRef]
273. Bejarano, O.; Knightly, E.W.; Park, M. IEEE 802.11 ac: From channelization to multi-user MIMO. IEEE Commun. Mag. 2013, 51,
84–90. [CrossRef]
274. Pokhrel, S.R.; Choi, J. Improving TCP performance over WiFi for internet of vehicles: A federated learning approach. IEEE Trans.
Veh. Technol. 2020, 69, 6798–6802. [CrossRef]
275. Rhee, I.; Xu, L.; Ha, S.; Zimmermann, A.; Eggert, L.; Scheffenegger, R. CUBIC for Fast Long-Distance Networks (No. Rfc8312).
2018. Available online: https://www.rfc-editor.org/rfc/rfc8312 (accessed on 1 February 2023).
276. Shahraki, A.; Taherkordi, A.; Haugen, Ø.; Eliassen, F. A survey and future directions on clustering: From WSNs to IoT and
modern networking paradigms. IEEE Trans. Netw. Serv. Manag. 2020, 18, 2242–2274. [CrossRef]
277. Mylonas, G.; Kalogeras, A.; Kalogeras, G.; Anagnostopoulos, C.; Alexakos, C.; Munoz, L. Digital twins from smart manufacturing
to smart cities: A survey. IEEE Access 2021, 9, 143222–143249. [CrossRef]
278. Akhtar, M.W.; Hassan, S.A.; Ghaffar, R.; Jung, H.; Garg, S.; Hossain, M.S. The shift to 6G communications: Vision and requirements.
Hum. Cent. Comput. Inf. Sci. 2020, 10, 53. [CrossRef]
279. Nguyen, V.L.; Lin, P.C.; Cheng, B.C.; Hwang, R.H.; Lin, Y.D. Security and privacy for 6G: A survey on prospective technologies
and challenges. IEEE Commun. Surv. Tutor. 2021, 23, 2384–2428. [CrossRef]
280. Farooq, M.S.; Nadir, R.M.; Rustam, F.; Hur, S.; Park, Y.; Ashraf, I. Nested Bee Hive: A conceptual multilayer architecture for 6G in
futuristic sustainable smart cities. Sensors 2022, 22, 5950. [CrossRef] [PubMed]
281. Huang, H.; Guo, S.; Gui, G.; Yang, Z.; Zhang, J.; Sari, H.; Adachi, F. Deep learning for physical-layer 5G wireless techniques:
Opportunities, challenges and solutions. IEEE Wirel. Commun. 2020, 27, 214–222. [CrossRef]
282. Chen, M.; Challita, U.; Saad, W.; Yin, C.; Debbah, M. Artiﬁcial Neural Networks-Based Machine Learning for Wireless Networks:
A Tutorial. IEEE Commun. Surv. Tutor. 2019, 21, 3039–3071. [CrossRef]
283. Manzalini, A. Quantum Communications in Future Networks and Services. Quantum Rep. 2020, 2, 221–232. [CrossRef]
Electronics 2023, 12, 2490
63 of 63
284. Tariq, F.; Khandaker, M.R.A.; Wong, K.K.; Imran, M.A.; Bennis, M.; Debbah, M. A speculative study on 6G. IEEE Wirel. Commun.
2020, 27, 118–125. [CrossRef]
285. Imoize, A.L.; Adedeji, O.; Tandiya, N.; Shetty, S. 6G enabled smart infrastructure for sustainable society: Opportunities, challenges,
and research roadmap. Sensors 2021, 21, 1709. [CrossRef] [PubMed]
286. Basar, E.; Di Renzo, M.; De Rosny, J.; Debbah, M.; Alouini, M.-S.; Zhang, R. Wireless communications through Reconﬁgurable
Intelligent Surfaces. IEEE Access 2019, 7, 116753–116773. [CrossRef]
287. Hu, S.; Rusek, F.; Edfors, O. Beyond Massive MIMO: The potential of data transmission with large intelligent surfaces. IEEE Trans.
Signal Process. 2018, 66, 2746–2758. [CrossRef]
288. Akyildiz, I.F.; Kak, I.A. The Internet of Space Things/Cubesats. IEEE Netw. 2019, 33, 212–218. [CrossRef]
289. Akyildiz, I.F.; Jornet, J.M.; Han, C. Terahertz band: Next frontier for wireless communications. Phys. Commun. 2014, 12, 16–32.
[CrossRef]
290. Kumari, A.; Gupta, R.; Tanwar, S. Amalgamation of blockchain and IoT for smart cities underlying 6G communication:
A comprehensive review. Comput. Commun. 2021, 172, 102–118. [CrossRef]
291. Kamruzzaman, M.M. Key technologies, applications and trends of internet of things for energy-efﬁcient 6G wireless communica-
tion in smart cities. Energies 2022, 15, 5608. [CrossRef]
292. Kohli, V.; Tripathi, U.; Chamola, V.; Rout, B.K.; Kanhere, S.S. A review on Virtual Reality and Augmented Reality use-cases of
Brain Computer Interface based applications for smart cities. Microprocess. Microsyst. 2022, 88, 104392. [CrossRef]
Disclaimer/Publisher’s Note: The statements, opinions and data contained in all publications are solely those of the individual
author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to
people or property resulting from any ideas, methods, instructions or products referred to in the content.


Paper 2:
- APA Citation: None
  Main Objective: This article examines the importance of data quality and preprocessing in the cloud, containerization strategies for scalable autonomous deployment, and the deployment of machine learning (ML) models for real-time data processing and inference.
  Study Location: None
  Data Sources: None
  Technologies Used: None
  Key Findings: None
  Extract 1: Data Quality and Preprocessing in the Cloud: Examines the importance of data quality and preprocessing in the cloud, containerization strategies for scalable and autonomous deployment, and the deployment of machine learning (ML) models for real-time data processing and inference.
  Extract 2: None
  Limitations: None
  Relevance Evaluation: This study is moderately relevant to the point being raised in this review, as it largely approaches the topic of automated data processing in the cloud. However, the study focuses on data quality preprocessing and storage in the cloud, containerization, and the deployment of ML for real-time data processing. It does not offer any direct insights into the specific relationship between data quality and the performance and robustness of ML models for irrigation scheduling and management, which is the precise topic being discussed in the review.
  Relevance Score: 0.6
  Inline Citation: None
  Explanation: This article explores the impact of data quality and data preprocessing in the cloud, containerization strategies for scalable autonomous deployment, and the deployment of machine learning (ML) models for real-time data processing and inference in reference to the larger field of literature for this subject.

 Full Text: >
This website utilizes technologies such as cookies to enable essential site functionality, as well as for analytics, personalization, and targeted advertising purposes. To learn more, view the following link: Privacy Policy UNCL: University Of Nebraska - Linc Acquisitions Accounting Search within Login / Register Hydrological Processes RESEARCH ARTICLE Full Access Continuous measurement of whole-tree water balance for studying urban tree transpiration Takashi Asawa,  Tomoki Kiyono,  Akira Hoyano First published: 01 June 2017 https://doi.org/10.1002/hyp.11244Citations: 21 SECTIONS PDF TOOLS SHARE Abstract Street and garden trees in urban areas are often exposed to advection of strong vapour pressure deficit (VPD) air that can raise the whole-tree transpiration rate (ET), known as the oasis effect. However, urban trees tend to have small soil volume compared with natural conditions, and so they are believed to strongly regulate stomata. ET characteristics of such urban trees have not been well understood because of a lack of reliable measurement methods. Therefore, we propose a novel weighing lysimeter method and investigate the whole-tree water balance of an isolated container-grown Zelkova serrata to examine (a) which biotic and abiotic factors determine ET and (b) which spatial and temporal information is needed to predict ET under urban conditions. Whole-tree water balance and environmental conditions were measured from 2010 to 2012. Although leaf area substantially increased in the study period, daily ET did not vary much. ET increased with VPD almost linearly in 2010 but showed saturation in 2011 and 2012. Root water uptake lagged ET by 40 min in 2012. These results suggest that the small planter box interfered with root growth and that hydraulic supply capacities did not increase sufficiently to support leaf area increase. From analysis of water balance, we believe that neglecting soil drought effects on street trees without irrigation in Japan will overestimate ET over 4–5 sunny days at the longest. This is unlike previous studies of forest. 1 INTRODUCTION Transpiration is an essential factor for water and energy balance between soil, plant, and atmosphere. Regarding urban trees, the environmental benefits of tree microclimate effects on human thermal comfort and health constitute a sustainable means for mitigating the urban thermal environment (Architectural Institute of Japan, 2007; Oke, 1987; Olgyay, 1963). To realize individual-specific irrigation management and design of more effective green space, quantitative knowledge of the whole-tree transpiration rate ET under characteristic urban conditions is necessary. Isolated trees such as street and garden trees are often exposed to advection of strong vapour pressure deficit (VPD) air compared with those in the forest. Such increase of evapotranspiration is the so-called oasis or leading-edge effect (Kanda, 2007; Oke, 1987; see also Mackay, Ewers, Loranty, & Kruger, 2010 and its references to studies in the forest). Several urban meteorologists have claimed that trees in an urban environment may have higher transpiration rates than in the forest because of the oasis effect (Hagishima, Narinta, & Tanimoto, 2007; Moriwaki & Kanda, 2004; Spronken-Smith, Oke, & Lowry, 2000). Moreover, an isolated tree is readily impacted by radiation and wind, which affects its photosynthesis rate, leaf temperature, and boundary layer thickness. These effects may increase ET. On the contrary, several plant ecophysiologists have reported that urban trees tend to vigorously regulate stomata because of drought stress from strong VPD, limited water supply and rooting space, and strong soil compaction (e.g., Cregg, 1995; Kagotani et al., 2015; Kjelgren & Clark, 1993; McCarthy & Pataki, 2010; Osone et al., 2014). Clearly, there is some discrepancy of findings. Thus, to address the relative importance and interactions between biotic and abiotic effects on ET, long-term measurement under a range of conditions is required. Quantitative characteristics of urban tree ET have not been sufficiently clarified because of a lack of reliable measurement methods. Porometer, sap flow, and lysimeter methods have mainly been used for estimating ET in studies. The porometer method essentially targets the measurement of single-leaf transpiration. Scaling up from leaf transpiration to ET can cause errors because of errors in leaf area estimation, differences in leaf characteristics, and microclimate in the crown. This method, therefore, must be validated using other accurate methods (Leverenz et al., 1982; Mcdermitt, 1990). The sap flow methods are frequently used for studying whole-tree and stand-scale water use (Granier, 1987; Swanson & Whitfield, 1981). However, sap flow velocity measured at breast height can be delayed from actual ET by a few hours (e.g., Saugier, Granier, Pontailler, Dufrene, & Baldocchi, 1997). In addition, such methods tend to underestimate ET when using long-term measurements, owing to the change of xylem thermal properties caused by wounds of sensor installation (Moore, Bond, Jones, & Meinzer, 2010; Swanson & Whitfield, 1981; Wullschleger, Childs, King, & Hanson, 2011). Furthermore, the very widely used Granier's thermal dissipation sensor (Granier, 1987) is known to be sensitive to environmental radiation and temperature (Lu, Urban, & Zhao, 2004; Oren, Phillips, et al, 1999); this can be problematic in measurement of isolated (i.e., urban) trees under hot summer conditions. The lysimeter method quantifies ET using weighing or drainage lysimeters. This is considered the most reliable method for small plants but has limits for tall trees because of large errors from wind when measuring in outdoor environments with high temporal resolution (Edwards, 1986; Lorite, Santos, Teti, & Fereres, 2012). Asawa et al. (2012, in Japanese) and Asawa, Hoyano, Shimizu, et al. (2014, in Japanese) developed a novel weighing lysimeter that gives a sufficiently accurate estimate of hourly ET for a tall tree; they reported results from summer 2010. In the present study, we show that this lysimeter approach is capable of measuring over years and examines quantitative and process information of interseasonal/interannual changes of ET and whole-tree water balance under characteristic urban conditions. Although sap flow measurement studies in urban areas have gradually increased (Chen, Zhang, & Ewers, 2012; Chen, Zhang, et al., 2011; Litvak, McCarthy, & Pataki, 2011, 2012; McCarthy & Pataki, 2010; McCarthy, Pataki, & Jenerette, 2011; Pataki, McCarthy, Litvak, & Pincetl, 2011; Peters, McFadden, & Montgomery, 2010), whole-tree water balance and quantitative interaction between ET and soil moisture have rarely been reported. This is because it is not easy to measure rooting space or amounts of infiltration and leakage, owing to artificial obstacles such as pavement. Therefore, we studied urban tree transpiration using an isolated container-grown tree exposed to advection of high-VPD air and grown in shallow soil. The questions addressed in the present study are as follows: (a) Which biotic and abiotic factors determine ET under characteristic urban conditions and, in particular, how does VPD affect ET in relation to other factors? (Buckley, 2005; Oren, Phillips, et al., 1999; Sperry & Love, 2015) (b) What spatial and temporal information is needed to predict ET? These questions are especially important to the recent development of numerical simulations of urban microclimates (e.g., Asawa, Hoyano, & Nakaohkubo, 2008; Chen, Kusaka, et al., 2011; Vico, Revelli, & Porporato, 2014) for determining which factors should be treated precisely and which can be simplified. To overcome the limitation of the lysimeter method and address the effects of biotic and abiotic factors on ET, we propose a data quality control protocol for continuous long-term measurement to remove noise from wind and other factors. Such a protocol for the lysimeter method is not well established relative to other methods based on eddy covariance or sap flow (e.g., Oishi, Hawthorne, & Oren, 2016; Vickers & Mahrt, 1997). Many lysimeter studies used a simple moving average or Savitzky–Golay filter, but such smoothing filters are mere graphical techniques and not justified in quantitative analysis (Press, Teukolsky, Vetterling, & Flannery, 1996) because the reliability of filtered values is never evaluated. Alternatively, we used time-series statistics to quantify uncertainty of estimated ET. 2 MATERIALS AND METHODS 2.1 Study site and plant material The study site was an experimental field with an open area of 8,800 m2 in the city of Miyoshi, Aichi Prefecture, Japan (35°8′N, 137°6′E). There were no obstacles within 40 m of the sample tree, except for several container-grown trees of ~5-m height. Distances between these trees were >4 m, so they could easily receive solar radiation and airflow. This may be regarded as an isolated condition. The sample tree used for measurement was a 13 year-old Zelkova serrata (Figure 1). Z. serrata is the third most popular species of street tree (National Institute for Land and Infrastructure Management, 2014), and there are three prefectures and 79 cities in Japan that have established it as the “city's symbol tree.” The height and trunk diameter in 2010 were 6.4 m and 11 cm, respectively. We did not measure leaf area routinely but measured using a terrestrial-laser scanning system (LiDAR; VZ-400, RIEGL, Horn, Austria) in the summers of 2010 and 2012. Total leaf area and the leaf area index (LAI) on September 3, 2010, were 13.2 m2 and 2.1 m2/m2, respectively (Asawa, Hoyano, Oshio, et al., 2014), which were estimated using the voxel-based canopy profiling method (Hosoi & Omasa, 2006; Oshio, Asawa, Hoyano, & Miyasaka, 2015). The Z. serrata tree was planted in a large planter box of area 1 m2 and depth 0.6 m; box volume was determined on the basis of the size of a general street tree (Ministry of Land, Infrastructure, Transport and Tourism of Japan, 2005). Leaf pruning was done to reduce transpiration and compensate for lost root systems in advance of transplanting to the planter box. Root-zone depth was 50 cm, and the soil was composed of Kanto loam (70%), perlite (20%), and leaf mould (10%). Kanto loam is widely used for arboriculture in Japan because of its strong permeability and large water-holding capacity. In general, it has aggregated structures, strong porosity, and high saturated hydraulic conductivity (Chang, Kato, & Okazaki, 1994; Kaihotsu, Tanaka, & Okahashi, 1981). We took photos of the Z. serrata once every few months to check the tree and apparatus conditions, finding that the leaf area slightly decreased in 2011 but strongly increased in 2012 (Figure 1). No breakages or diseases were found in the Z. serrata during the measurement period. Figure 1 Open in figure viewer PowerPoint Zelkova serrata on (left) August 3, 2010 and (right) August 30, 2012. Ultrasonic anemometer was set on the right side of the tree; distance from the tree was 4.3 m 2.2 Meteorological measurement Meteorological conditions were measured in the northern part of the experimental field, using a solar radiometer (MS-402, Eko Instruments, Tokyo, Japan), air temperature sensor (4 wires Pt100Ω, Taiyo Keki, Tokyo, Japan) with ventilation (Model 43502, R.M. Young Co., Traverse, MI, USA), relative humidity sensor (CS215, Campbell Scientific, Logan, UT, USA), tipping bucket gauge (TE525MM, Campbell Scientific), 3-D ultrasonic anemometer (Model 81000, R.M. Young Co.), and photosynthetically active radiation (PAR) sensor (LI-190, Li-Cor Inc., Lincoln, NE, USA). To analyse the effects of wind on lysimeter measurement, the anemometer was located 4.3 m from the Z. serrata (Figure 1). This location was determined to be as close as possible to the tree while minimizing its effect on the wind measurement. The height of the anemometer was 4 m, nearly the same as the centre of the tree crown. The measurement was done from August 2010 to September 2012. In the summer seasons, short-term and intensive measurements of transpiration, leaf area, and heat balance were conducted. In those periods, irrigation was stopped for two to four successive days to ascertain the effects of drought stress and so as not to damage on tree growth. All measurement data were checked every month for any missing data, spike noises, or physically unrealistic values. 2.3 Design of weighing lysimeter The measurement was done to obtain ET datasets under various meteorological and leaf-on (or leaf-off) conditions over the years. The weighing lysimeter, therefore, was designed and set up to be adaptable to long-term measurement. The total weight of the tree, planter box, and soil was ~1,000 kg, so a platform weighing machine using load cells (CAPS4-1500LL-I, Sartorius AG, Göttingen, Germany) was used. Site calibration was performed on the weighing machine. In advance of the measurement, we believed that the weighing accuracy should be ±100 g/hr, because the assumed ET was ~1 kg/hr. Although nominal accuracy of the weighing machine was 250 g (maximum weight 1,500 kg; accuracy 1/6,000), we confirmed that relative sensitivity to weight change measured by the weighing machine was <100 g. Figure 2 shows in detail the weighing lysimeter apparatus and its dimensions. When designing the lysimeter with the required accuracy, the following characteristics were considered and introduced. (a) The tree and planter box should not contact the measurement apparatus, irrigation, and drainage systems, all of which were placed near the tree. Only a few cables for measurement sensors were connected between the planter box and measurement apparatus. (b) These cables were set to slacken for removing tension that might affect weight values. (c) To prevent the tree from falling down under strong wind, two steel support arms were placed around the trunk but had no contact with the trunk. These arms did not touch the trunk even with wind speeds ~10 m/s. (d) The weighing machine and planter box were both covered by a shed to protect them from wind, rainfall, and solar radiation. Air temperature inside the shed was continuously monitored, and its side door was frequently opened for air ventilation. Figure 2 Open in figure viewer PowerPoint Section of weighing lysimeter. Asterisk indicates noncontact setting 2.4 Irrigation regime and water balance measurement All water balances were controlled by an automated irrigation system, because quantitative measurement of rainfall on the planter box was very difficult, and the study focused on the relationship between ET and water balance under irrigated conditions. Water was automatically irrigated on the upper surface of the soil at midnight, from 0:00 to 1:00 each day. Irrigation water was stored once in a tank in a predetermined amount and supplied from the tank to the surface by gravity. Drainage occurred immediately after irrigation and nearly ceased within about four hours before morning, when transpiration began. The planter box was made of stainless steel of 2-mm thickness, and its bottom had a slope of 1/100. Pumice was laid on the bottom 10 cm of the box for smooth drainage. Volumetric soil water content θ was measured at depths of 5, 15, 25, 35, and 45 cm by amplitude-domain reflectometry sensors (Thetaprobe ML2x, Delta-T Devices, Cambridge, UK). Matric potential Ψ was calculated from measured θ and soil water retention (θ–Ψ) curves. Undisturbed soil samples of 100 cc were collected from all layers near the amplitude-domain reflectometry sensors and used to measure water retention curves in the laboratory via centrifuge and pressure-plate methods. Amounts of irrigation and drainage were measured by flowmeter (ND10-NATAAA, Aichitokei, Nagoya, Japan) and tipping bucket-type rain gauges (TE525-L25, Campbell Scientific), respectively. Stemflow was trapped at the middle of the trunk and measured by rain gauge (UIZ-TB500, UIZIN, Tokyo, Japan), so the water did not flow into the soil. Soil evaporation ES was restricted by a cover sheet on the planter box, but air was continuously supplied to the soil surface in order not to interfere with soil respiration. Ventilation rate, temperature, and relative humidity of both inflow and outflow air at the surface were measured so that ES was estimated by absolute humidity change. We confirmed that ES was <150 g/day in summer 2010. Meteorological, sample tree weight, and water balance data were recorded on a data logger (C-CR10000, Campbell Scientific). The weighing machine and anemometer were synchronized, and data recorded at 1 Hz. Other meteorological conditions and water balance were recorded every 1 and 10 min, respectively. 2.5 Calculation of water balance To estimate ET, measured weight data was resolved into each origin of weight change. That change and whole-tree water balance can be expressed by (1) (2) where W is sample weight (sum of tree, soil, and planter box) and W* its measured value. εw is wind load, εo represents other error terms such as dew and litterfall, ET is whole-tree transpiration, ES is soil evaporation, Irr is irrigation, D is drainage, Int is crown interception, and EWC is wet-crown evaporation and throughfall. ES, Irr, and D were directly identified by the measurements. In estimating ET, larger parts of the noise are from εw and measurement errors of Irr and D on sunny days, and εw, Int, and EWC on rainy days. The effects of Irr and Int can be easily removed by discarding data during irrigation or rain, but εw, D, and EWC need special treatments, which are addressed later. Dew was not problematic because it was small except during winter, and Z. serrata is a deciduous species. We did not quantify litterfall from W,* but it was confirmed independently. In August 2012, we clipped all leaves from Z. serrata, which was nearly the same size as a lysimeter-grown one, finding a wet weight ~5.8 kg/tree. We believe it is reasonable to ignore the effects of litterfall in estimating daily ET in the predefoliation period. Soil water balance was considered to address the root water uptake rate. When soil water movement is expressed in integral form and ES is negligible, it becomes similar to Equation 2: (3) where ρ is water density, v is soil volume, and ET′ is whole-tree root water uptake. ET′ nearly equals ET at daily scale but is delayed at diurnal scale. When Irr and D are negligible, soil water change (−ρvdθ/dt) = ET′. Such a condition is feasible when irrigation is stopped and θ drops below field capacity. 2.6 Statistical analysis for ET estimation All statistical analyses were performed using R 3.2.4 software (R Development Core Team, 2016). Raw data of W* in 2010 recorded at 1 Hz are shown in Figure 3. On ordinary days, W* increased at night from Irr and decreased during daytime from ET. The inset of Figure 3 illustrates W* and its linear trend (regression line) around noon on August 17. The negative trend indicates the effect of ET, and there is clearly a strong time-series autocorrelation between the residuals, which can be attributed to swaying of the tree from εw. The lack of independence of observations often causes fatal error in estimating standard error (SE) and statistical hypothesis testing (von Storch & Zwiers, 1999). Therefore, we estimated the time between effectively independent observations T0 to correct SE of W. Effective sample size Neff and T0 can be calculated according to Trenberth (1984): (4) (5) where N is the number of observations and rL is the autocorrelation coefficient at lag L. We estimated Neff, ET, and higher moments of W* every 20 min and calculated daily ET as their sum. Details of the calculation are presented in the Appendix. Figure 3 Open in figure viewer PowerPoint Example of observed sample weight (W*) data, from August 10 to 21, 2010, recorded at 1 Hz. Irrigation was stopped after August 18. Inset shows data around noon on August 17. Autocorrelation is clear around 12:35 3 RESULTS First, we show results regarding measurement accuracy of the lysimeter method and then review daily ET and monthly water balance throughout the study period to understand how ET changed seasonally and annually. Finally, to reveal reasons for changes of ET characteristics, we show interannual variations of diurnal ET and root water uptake. 3.1 Performances of ET estimation and quality control Table 1 shows Neff and descriptive statistics of W* for growing seasons (May–October of the 3 years). Neff, standard deviation, and kurtosis increased, and the absolute value of skewness decreased together with wind speed. No clear interannual trend was found, which supports that our lysimeter performed well throughout the measurement period. Figure 4 shows the diurnal pattern of characteristic days to confirm the performance of ET estimation. The error bars show 2 SE (~95% confidence interval); and black circles, deviation from a Gaussian distribution. Neff roughly correlated with wind speed and was <200 (1/6 of N), which means that SE increased about twofold to threefold with consideration of Neff. Figure 4a,d shows the result on a sunny irrigation day; there was strong fluctuation of weight change (−ΔW/Δt), but the error bars were small, which indicate that considering these data as ET is relatively reliable. This –ΔW/Δt correlated well with solar radiation Rs. On a windy day (Figure 4b,e), there was also large fluctuation, but this could easily be distinguished from ET by large error bars, which were corrected by Neff. From a physical perspective, there was no correspondence between –ΔW/Δt and evaporation drivers (radiation and wind). From a biological perspective, we could not find any reason for large –ΔW/Δt fluctuation, especially after sunset. Therefore, the judgement that these data are suspicious from data quality criteria appears reasonable. Furthermore, on a rainy day (Figure 4c,f), the higher moment test and error bars revealed a suspicious –ΔW/Δt before and after the rain. This large –ΔW/Δt can be attributed to EWC. Moreover, it is well known that tipping bucket rain gauges have errors and a time lag because of their measurement mechanism. Therefore, the negative value of –ΔW/Δt (i.e., increase of W*) before the time of rain observation is considered Int. The higher moment test provided quantitative criteria to assess how many records should be discarded as EWC or Int. In this case, we discarded two records before and after the rain. Table 1. Effective sample size (Neff) and descriptive statistics of sample weight (W*) in growing seasons (May–October) WS class Year Neff SD |Skewness| Kurtosis Calm 2010 80 0.040 0.771 4.73 2011 117 0.029 0.727 4.79 2012 69 0.053 0.701 5.02 Ordinary 2010 101 0.221 0.621 5.27 2011 100 0.171 0.516 5.20 2012 86 0.264 0.490 5.13 Windy 2010 203 0.419 0.342 5.23 2011 193 0.352 0.514 5.85 2012 194 0.599 0.486 5.62 Note. All record lengths are 1200 s and classified by wind speed (calm, <0.5 m/s; ordinary, 0.5–2.0 m/s; windy, >2.0 m/s). Values are the median of each class. Figure 4 Open in figure viewer PowerPoint Diurnal patterns of (a–c) effective sample size in 20 min (Neff: white circles), wind speed (grey lines) measured at location shown in Figure 1; (d–f) weight change (−ΔW/Δt, circles) and solar radiation (Rs, grey lines). Black circles in (d–f) represent “flagged” data for which absolute value of skewness >1 or kurtosis >8, and white circles represent “nonflagged.” Error bars in (d–f) represent two standard errors. Shaded areas show that irrigation (a, d) or rain (c, f) was observed. Dates of (a, d) are August 30, 2010; (b, e) are May 1, 2012; and (c, f) are August 19, 2011 3.2 Environmental conditions Daily environmental data from August 2010 through September 2012 are shown in Figure 5. Although the summer solstice is in late June, Rs and VPD in that month were small because of the normal rainy season in Japan (according to Japan Meteorological Agency [JMA], 2008, mean precipitation in June and July was 300 mm, accounting for 1/5 the yearly total). Summer 2010 was extremely hot and dry all over the country, and mean air temperature Ta was the highest in the past 113 years (JMA, 2010). Our study site was on the Pacific side of Japan (as is Tokyo), and the duration of sunny days in Tokyo in summer 2010 was the second longest since 1968 (JMA, 2012). Furthermore, at the study site, late August and early September 2010 were the hottest and driest of the study period. Maximum Ta was 38°C, and the maximum VPD was 4.5 kPa. The longest stretch of sunny days in 2010 was 18, from August 21 through September 7. We irrigated about 30–50 kg/m2 (soil) daily, determined using ET of preceding days, which was sufficient to compensate daily transpiration loss. We believe that ample irrigation was not problematic, because the excess of water over field capacity was soon discharged. We irrigated almost every day during the growing season but ran a dry-down experiment several times. According to Rodriguez-Iturbe and Porporato (2007), plants typically begin to close stomata when soil Ψ declines by 0.03 MPa and almost completely close with a decrease of ~3 MPa. Over our measurement period, mean θ from 5- to 45-cm depths remained >36.6% vol. (Ψ = −0.03 MPa), except for dry-down periods. On August 26, 2010, we found that mean soil Ψ was less than −2.5 MPa, but ET remained 14.4 kg/day. On this day, Ψ at 35- and 45-cm depths was −1.92 and −0.72 MPa, respectively (data not shown). Figure 5 Open in figure viewer PowerPoint Daily environmental and whole-tree transpiration data throughout study period. From the top: daily total solar radiation (Rs); daily mean (black line); maximum and minimum (grey lines) air temperature (Ta); daytime mean (black line) and maximum (grey line) atmospheric vapour pressure deficit (VPD); mean volumetric water content in soil layers of 5, 15, 25, 35, and 45 cm (θ, black line); irrigation amount (Irr, grey bars); whole-tree transpiration (ET, black bars). Dashed and dotted lines in the fourth panel represent θ = 36.6 and 20.4% vol., which correspond to soil matric potential Ψ = −0.03 and −3 MPa, respectively. Shaded areas in bottom panel represent missing or discarded days 3.3 Seasonal changes of ET and whole-tree water balance Daily ET is shown at the bottom of Figure 5. ET reached 35 kg/day in mid-August 2010, but in 2011 and 2012, yearly maximum ET was 28.4 and 27.1 kg/day, respectively. Seasonal patterns of ET were evident, but the times of ET stopping and starting (foliation and defoliation) varied between the years. ET approached zero in mid-November 2010 and early October 2011. Atmospheric conditions after September were not very different between the 2 years (Figure 5). ET became positive and gradually increased in April 2011, but in 2012, it suddenly increased between late April and early May. For example, ET = 12.5 kg/day and Rs = 24.5 MJ/m2 day on May 2, 2011, whereas ET = 23.3 kg/day and Rs = 18.4 MJ/m2 day on May 1, 2012. The monthly water balance components of the Z. serrata and availability of ET are summarized in Figure 6. We halted measurements once in September 2011 because of a typhoon (Roke; the typhoon no. 15 in Japan) and did not interpolate discarded or missing records, so a large imbalance was found in this period. The mean ratio of available ET to Irr in the growing season was 69%, with a range of 32–123%. Because large portions of Irr were discharged as D in October 2010 and May 2012 and θ was nearly constant at ~60% vol. (Figure 5). we consider this value the field capacity of the soil. Figure 6 Open in figure viewer PowerPoint Monthly water balances and available ET. Components are irrigation (Irr), drainage (D), whole-tree transpiration (ET), and change of soil water storage (ΔS). Available ET represents ratio of nonmissing or discarded days 3.4 Biotic and abiotic control on ET The data obtained for Ta < 20°C roughly corresponded to no-leaf periods when ET was near zero (Figure 5). We visibly confirmed this by photos of the Z. serrata. Because we did not measure leaf area routinely and generally the times of foliation and defoliation are controlled by temperature (Jones, 2014), we used Ta as an index of leaf area condition. The major results of the following analyses did not differ from this 20°C criterion when we varied it from 15°C to 25°C. In general, VPD and Rs are the primary drivers of transpiration, but their relative importance depends on the magnitude of canopy coupling with the atmosphere (Jarvis & McNaughton, 1986). Thus, daily ET responses to atmospheric drivers (daily total Rs, mean daytime VPD, and wind speed) were analysed (Figure 7). There was the strongest correlation between ET and VPD throughout the study period (R = .80), but after filtering out days on which daily mean Ta was <20°C, VPD and Rs showed almost the same correlations with ET (R = .63 in both cases). Wind speed had no clear effect on ET (R = .21). Because ET appeared to respond to VPD nonlinearly in 2011 and 2012, we used various regression models to test the significance of interannual differences in the slopes of VPD and Rs (differences of βi in ET = βi VPD or ET = βi Rs) and nonlinearity of VPD (ET = α + β lnVPD), as summarized in Table 2. A minimum Akaike's information criterion value was found in the log-transformed VPD model with interannual difference (ET = αi + βi lnVPD). The regression lines and their 95% confidence intervals of that model are shown in Figure 8. The intercepts (α; mean ET at VPD = 1 kPa) increased with the year (Table 2). Although the SE of slope (β) of log-transformed VPD was large, β2010 was clearly larger than other years and SE ranges did not overlap (Table 2). Modelled mean ET in 2011 and 2012 was nearly identical when VPD was >1.3 kPa. Figure 7 Open in figure viewer PowerPoint Responses of daily whole-tree transpiration rate to (a) daytime mean atmospheric vapour pressure deficit (VPD), (b) daily total solar radiation (Rs), and (c) daytime mean wind speed. Circles represent warm days on which mean air temperature (Ta) was >20°C in 2010 (black circles), 2011 (grey circles), and 2012 (white circles). Crosses represent days on which Ta < 20°C during all years. All data are for irrigated days; mean soil matric potential was greater than −0.03 MPa Table 2. Parameter estimates for linear models on warm irrigation days in Figure 7, describing whole-tree transpiration rate (ET in kg/day) as a function of solar radiation (Rs in MJ/m2 day) or atmospheric vapour pressure deficit (VPD in kPa) Equation Coefficientsa R2 AICb β β2010 β2011 β2012 α2010 α2011 α2012 ET = β Rs 1.01 ± 0.02 .952 1,059 ET = βi Rs 1.15 ± 0.04 0.95 ± 0.04 1.00 ± 0.02 .957 1,044 ET = β VPD 15.4 ± 0.3 .936 1,112 ET = βi VPD 17.3 ± 0.7 16.8 ± 0.7 16.0 ± 0.5 .937 1,113 ET = αi + βi lnVPD 13.9 ± 2.0 8.4 ± 2.2 6.1 ± 2.4 16.9 ± 0.8 18.3 ± 0.5 19.4 ± 0.5 .960 1,034 a Ranges of coefficients represent one standard error. b Akaike's information criterion is a criterion of model selection that describes data well and avoids overfitting (too many parameters); AIC = −2lnL + 2 k, where L is likelihood and k is the number of model parameters. Figure 8 Open in figure viewer PowerPoint Regression lines of whole-tree transpiration rate and atmospheric vapour pressure deficit on warm days (Ta > 20°C) in 2010 (black solid line), 2011 (dark grey dotted line), and 2012 (light grey dashed line). Data are the same as the circles in Figure 7a, and colour of scales on the x and y axes represents years, the same as regression lines Figure 9 shows an interannual comparison of diurnal ET. To address the effect of root water uptake ET′, August 18, 2010 (Figure 9a,c) and July 4, 2012 (Figure 9b,d) were selected because they were during dry-down periods and mean θ was less than field capacity. That is, Irr and D were negligible and changes of soil water content (−dθ/dt) may be regarded as ET′ in Equation 3 (daily mean soil Ψ = −0.09 MPa on both days). Daily total Rs values were nearly equal (24.3 and 23.6 MJ/day), but maximum VPD and ET were substantially different between the 2 days. Times of maxima of all variables (ET, −Δθ/Δt Rs and VPD) were around 12:00–15:00 on both days, and only diurnal ET in 2012 displayed a bimodal pattern (Figure 9b). Cross-correlations of Rs, VPD, and –Δθ/Δt with ET on these days are shown in Figure 10. On August 18, 2010, ET peaked 20 min earlier than VPD and had no time lag with Rs or –Δθ/Δt (Figure 10a). However, on July 4, 2012, ET preceded –Δθ/Δt by 40 min, peaked at the same time as VPD, and lagged Rs by 80 min (Figure 10b). The cross-correlation coefficients of VPD and Rs with ET were smaller in 2012 than in 2010. Figure 9 Open in figure viewer PowerPoint Diurnal patterns of (a, b) whole-tree transpiration rate (ET, circles and black lines), solar radiation (Rs, grey lines), (c, d) atmospheric vapour pressure deficit (VPD, grey lines), and change of mean soil water content (θ, black lines). Error bars and coloured circles have the same meaning as those in Figure 4. Dates of (a, c) are August 18, 2010, and (b, d) are July 4, 2012 Figure 10 Open in figure viewer PowerPoint Cross-correlation coefficients between whole-tree transpiration rate and solar radiation (white circles), atmospheric vapour pressure deficit (grey circles), and change of mean soil water content (black circles). Date of (a) is August 18, 2010, and (b) is July 4, 2012 4 DISCUSSION 4.1 ET responses to atmospheric drivers and leaf area change It is well known that wind has little effect on ET for coniferous trees, but this tendency is not always valid for broadleaf trees (see the review of Komatsu, 2003). Z. serrata is a broadleaf species, but the effect of wind speed was not clear (Figure 7c). This result suggests that leaves of the Z. serrata were strongly coupled to the atmosphere; that is, boundary layer resistance was weak, leaf temperature was close to Ta, and ET was mainly controlled by stomata (Jarvis & McNaughton, 1986). This is probably because the sample Z. serrata was in an isolated condition. Daily ET of the Z. serrata on sunny days in the growing season was about 25–30 kg/day (Figure 5). This is comparable to previous reports of ground-planted orchards (Green, 1993; Green, Clothier, Caspari, & Neal, 2002) that have similar tree size and environments (isolated condition, daily Rs ~ 20 MJ/m2 and moist soil). Green (1993) reported an isolated walnut tree (3.5 m in height, 26.4 m2 in leaf area) transpired 40 kg/day on a sunny day, and Green et al. (2002) reported that olives (4 m in height, 13.5 m2 in leaf area) planted at 4 × 6 m intervals transpired 175 kg/week. However, this does not necessarily mean that the Z. serrata was free from drought stress. As shown in Figure 1, its leaf area substantially increased from 2010 to 2012, but ET did not increase (Figure 5). There are three possible reasons for this. First, VPD maximized in summer 2010; second, mutual shading of increased leaves dampened ET increase; third, the small planter box interfered with root growth, and hydraulic supply capacities did not increase sufficiently to support the leaf area increase. The nonlinear response of ET to VPD and its interannual difference (Figures 7a and 8) are believed to correspond to Oren, Sperry, et al. (1999), who showed that the sensitivity of stomatal conductance to VPD is general over a wide range of plants. According to Oren et al., a plant with large stomatal conductance (thus large ET) at small VPD must strongly regulate stomata when VPD becomes large, because of hydraulic limits. This was true of the Z. serrata during the study period (Figure 8). Litvak et al. (2012) analysed ET characteristics of 121 urban trees using the same log-transformed VPD model as our study (ET = α + β lnVPD) and sap flow velocity data from their series of studies of the urban landscape of Los Angeles (Litvak et al., 2011; McCarthy & Pataki, 2010; McCarthy et al., 2011; Pataki et al., 2011). They reported that the ratio of β to α was constant among tree sizes and sites, corresponding to Oren, Sperry, et al. (1999), but it could differ by xylem vulnerability (unsaturated hydraulic conductance); the ratio range was 0.3–0.6. The β/α values of our Z. serrata were within this range during 2011 and 2012, but not in 2010 (Table 2; β/α ~ .8 in 2010). This means that the Z. serrata in 2010 was relatively insensitive to drought stress, possibly because the low ratio of leaf to root area from pruning-enhanced hydraulic conductance. The implications of the findings shown in Figures 9 and 10 are that the Z. serrata became more conservative regarding ET during the 2 years, not only at daily scale but also at the diurnal one. The 40-min delay of water transport from soil to leaves in 2012 supports the hypothesis that the hydraulic capacities did not increase sufficiently, because if this were so, the increase of leaf area would reduce hydraulic conductance per leaf area. Increase of evaporative demand (by increase of the ratio of leaf to root area) leads to more negative water potential in plant tissues. Large negative water potential generates cavitation and embolism and decreases the unsaturated hydraulic conductivity in apoplastic pathways (Sperry & Love, 2015; Tyree & Zimmermann, 2002). This is the likely reason for the delay of water transport in 2012. Some researchers reported that a too great VPD decreases ET, a so-called apparent feed-forward response of stomata to humidity (e.g., Monteith, 1995). The bimodal diurnal ET pattern (Figure 9b) and 80-min lag between ET and Rs found in 2012 (Figure 10b) indicate this phenomenon. The leaf-to-atmosphere VPD of the Z. serrata might have maximized around midday in 2012 because of the peak in Rs (Figure 9b and 9d). According to Duursma et al. (2014), the apparent feed-forward response can be explained by increased cuticle transpiration, generation of cavitation, or peak response of photosynthesis to temperature. Because we did not measure physiological conditions of the Z. serrata precisely, we cannot examine the influences of the above factors, but the increase of leaf area could be attributed to all three. 4.2 Phenological aspects Figure 5 shows obvious interannual differences of ET in spring. This result is probably because of interannual differences in the times of foliation, but the reason for this phenological change is unclear. In general, the foliation time is believed to be mainly controlled by temperature (Jones, 2014). However, in our results, Ta of preceding periods were not very different between years (mean Ta in April was 12.2°C in 2011 and 13.1°C in 2012). Recently, through chamber experiments using cuttings of some woody species, Laube, Sparks, Estrella, and Menzel (2014) showed that drought stress can delay bud development. Thus, one of the possible reasons for the interannual phenological difference of the Z. serrata is change of leaf area and hypothetical hydraulic limits. Throughout the study period, the discrepancy between the strong correlation of ET with VPD (Figure 7a) and weak correlation of ET with Rs (Figure 7b) might be explained by the time of foliation/defoliation. The data obtained for Ta < 20°C roughly correspond to no-leaf periods. Rs can be large even at Ta < 20°C, because its seasonal change precedes Ta by a few months (Figure 5). However, atmospheric VPD must be small at low Ta, because VPD is directly determined by temperature. This means that there are VPD–Ta–leaf area–ET correlations at seasonal scale. The strong correlation of ET with VPD throughout the seasons (Figure 7a) was believed to be not only the result of the direct relationship between vapour diffusion and its driver but also the effect of leaf area as a confounding factor. 4.3 Spatial and temporal implications for predicting ET In warm periods (Ta > 20°C), the linear response of daily ET to Rs measured on a horizontal plane (Figure 7b) is interesting. In general, stomatal conductance saturates with strong PAR, as described elsewhere (e.g., Jarvis, 1976). It is also common that transpiration rates of a dense vegetation canopy increase almost linearly with radiation (Rs or net radiation Rn). This is because dense canopy transpiration can be well approximated by the equilibrium evaporation rate, that is, the evaporation rate under no advection (Jarvis & McNaughton, 1986). However, the Z. serrata measured herein was isolated and was thus believed to be far from equilibrium. A similar finding was reported in Pereira, Green, and Nova (2007), who showed that ET of irrigated orchards and an isolated walnut tree, including various ranges of LAI, could be effectively expressed by the equation of Priestley and Taylor (1972) pertaining to Rn measured above grass. This linear response might be explained by the interactive effect between mutual shading of leaves and saturation of stomatal conductance with PAR, as described in Sellers (1985). This linearization is especially effective for plants that have a large LAI, such as conifers. The LAI of the Z. serrata in our study was small (2.1 in September 2010), and it appears that the linear tendency in Pereira et al. (2007) did not depend strongly on LAI. One hypothesis is that 3-D radiation transfer in the crown affected the results; we will examine this in future studies. If one wants to keep ET maximum to obtain environmental benefits of Z. serrata, given that field capacity of the soil is 60% vol. and Z. serrata begins to close stomata around Ψ = −0.03 MPa (θ = 36.6% vol.), the Z. serrata can use at most 500 kg/container * (60.0–36.6)% = 117 kg water. Because daily ET on sunny days in the growing season was about 25–30 kg/day (Figure 5). it follows that the Z. serrata used the threshold amount in about 4–5 days at the longest, if there was no irrigation. Because the soil type and planter box volume of the Z. serrata were determined according to the general street tree in Japan as mentioned above, this estimation suggests that street trees without irrigation may experience frequent drought stress as reported in plant ecophysiology studies. It is often assumed in the study of forest transpiration in Japan that soil drought in the shallow layer is negligible (e.g., Komatsu, Kang, Kume, Yoshifuji, & Hotta, 2006; Kosugi et al., 2007; Kumagai, Tateishi, Shimizu, & Otsuki, 2008), because deep roots and water supply from the water table facilitate a large available water capacity (Zhang, Dawes, & Walker, 2001). From our estimates, neglect of soil drought effects may be valid for street trees during the few days during and after rain, but it probably overestimates ET after four to five sunny days at the longest. The importance of the vertical root distribution for climatology and hydrology study is well known (Feddes et al., 2001), but, in general, the roots of street trees and container-grown trees grow uniformly compared with natural conditions (e.g., Gilman & Masters, 2010). On August 26, 2010, we found that mean soil Ψ was below the wilting point (−2.5 MPa), but ET maintained ~50% of the amount on irrigated days (Figure 5; see also Fig. 6 of Asawa, Hoyano, Shimizu, et al., 2014, for diurnal change). This result indicates that to predict ET under soil drought conditions, the root distribution should be considered, even for the small and shallow soil used in the present study (0.5-m3 and 50-cm depths). The time of water transport from soil to leaves is important when parameterizing stomatal conductance, because it causes strong bias, not only in the responses to atmospheric drivers but also in maximum conductance. This was discussed for 10- to 20-m-tall trees in other studies (Kumagai, Aoki, Otsuki, & Utsumi, 2009; Rayment, Loustau, & Jarvis, 2002; Ward, Bell, Clark, & Oren, 2012). Although the Z. serrata in our study was relatively small (6.4 m) and it is a ring-porous species with large conduits, root water uptake lagged ET by 40 min in 2012 (Figure 10). Using a steady-state hydraulic model (e.g., Buckley, 2005; Tuzet, Perrier, & Leuning, 2003) may be problematic in treating ET at less than hourly time scale. 5 CONCLUSIONS We propose a quality control protocol for continuous long-term lysimeter measurement and investigated whole-tree water balance of an isolated container-grown Z. serrata from 2010 to 2012, to acquire quantitative and process information of urban tree transpiration. We found time-series autocorrelation very important in observed weight data upon quantifying ET and its uncertainty, showing that our lysimeter method performed well throughout the 2-year study period. In response to the questions put in Section 1, (a) VPD was the most important factor among atmospheric drivers, and wind speed showed no clear correlation with daily ET. From an interannual comparison of diurnal ET and leaf area between 2010 and 2012, we conclude that among biotic factors, leaf area is not the sole or primary factor that determines ET. These results suggest that we must consider the balance of leaf and root area for trees grown in small and shallow soil, such as street trees. (b) In warm periods, daily ET showed a linear response to daily Rs measured on a horizontal plane, suggesting the contribution of 3-D radiation transfer. For water balance, from our estimates, neglecting soil drought effects under no irrigation can overestimate ET after four to five sunny days at the longest, unlike prior studies of forest in Japan. When predicting soil drought effects, root area distribution should be considered, even for the small and shallow soil investigated herein (0.5-m3 and 50-cm depths). The delay of root water uptake with ET found in 2012 suggests that temporal resolution of the steady-state hydraulic model should be longer than 1 hr for studying trees of heights >6–7 m. Our findings depend somewhat on the growing conditions and species of the sample tree, so additional data are required to address general ET characteristics of urban trees. However, to our knowledge, this is the first report of interseasonal/interannual whole-tree water balance with urban, isolated, and small soil volume conditions. For measuring ET and parameterizing a stomatal conductance model of urban trees, the present findings will be valuable to determine which factors should be treated precisely and which can be simplified. One of the greatest differences between our experimental conditions and an actual urban area is the radiation environment. Urban trees are often shaded by surrounding buildings and receive long-wave radiation from them. Therefore, 3-D radiation environments should be considered when predicting ET in numerical simulations of urban microclimates (e.g., Asawa et al., 2008; Chen, Kusaka, et al., 2011), and when parameterizing stomatal conductance models using crown absorbed radiation. To this end, combining whole-tree transpiration and leaf area density measurements from laser scanning systems (LiDAR) is considered a promising approach. ACKNOWLEDGEMENTS We thank Mr. Katsuya Shimizu (Toyota Biotechnology and Afforestation Laboratory) for arranging the measurements. This work was supported in part by a research grant from the Organization for Landscape and Urban Green Infrastructure. APPENDIX A ET estimation proceeded in the following manner. Divide the time-series data of W* into sufficiently short-duration records to address stomatal response, typically less than a half hour based on Vico, Manzoni, Palmroth, and Katul (2011). There is some arbitrariness associated with the purpose and accuracy of the apparatus. We believe the relative error of ET estimation should be less than ~20% to compare previous measurements based on other methods. Both the typical energy imbalance rate of eddy covariance and the coefficient of variation of stand-scale transpiration estimated from enough sample size sap flow sensors are considered to be ~20% (Kume et al., 2010; Wilson et al., 2002). Thus, we adopted 20 min, N = 1200, to satisfy these criteria. Discard the records when Irr or precipitation was observed. For every record, fit linear regression lines using the least squares method to detrend and then estimate Neff from Equations 4 and 5, using the Yule–Walker method assuming Gaussian noise. Afterward, determine the centre values of W (here, Δt = 601 s) from regression lines and calculate SE of W from Neff and the residual sum of squares. Quantify ranges of diurnal patterns of ΔW for every month. Records that deviate by more than three interquartiles from the 75th or 25th percentile of the diurnal sequence are discarded as outliers. This three-interquartile rule is the same as Tukey's box–whisker plot. Calculate higher moments, skewness, and kurtosis for every record from the residuals of regressions. Records for which residuals are markedly different from the Gaussian distribution are “flagged” (again, there is some arbitrariness; here, records for which the absolute value of skewness >1 or kurtosis >8 were flagged). The SE calculated in (c) can detect only noise for which lengths are less than one record, which is mainly from εw. In contrast, the higher moment test (e) tests the assumption of linearity (steady-state condition in a record) and the effect of low-frequency noise, which is mainly from D and EWC. The steady-state assumption is violated not only by noise but also by rapid change of stomatal aperture in a record. Therefore, we discarded continuous flagged records before and after rain or irrigation, and only flagged records under normal conditions. Calculate daily ET as the sum of ΔW of each record over a day. When discarded records constituted >20% of the day, daily ET was discarded. We did not interpolate discarded or missing records. REFERENCES Citing Literature Volume31, Issue17 15 August 2017 Pages 3056-3068 Figures References Related Information Recommended Stomates R. Andrés Ferreyra Water Encyclopedia, [1] Stomatal and environmental control of transpiration in a lowland tropical forest tree F. C. MEINZER,  G. GOLDSTEIN,  N. M. HOLBROOK,  P. JACKSON,  J. CAVELIER Plant, Cell & Environment Coordination of stomatal, hydraulic, and canopy boundary layer properties: Do stomata balance conductances by measuring transpiration? Frederik C. Meinzer,  David A. Grantz Physiologia Plantarum Ecohydrology of street trees: design and irrigation requirements for sustainable water use Giulia Vico,  Roberto Revelli,  Amilcare Porporato Ecohydrology Water availability drives urban tree growth responses to herbivory and warming Emily K. Meineke,  Steven D. Frank Journal of Applied Ecology Download PDF Additional links ABOUT WILEY ONLINE LIBRARY Privacy Policy Terms of Use About Cookies Manage Cookies Accessibility Wiley Research DE&I Statement and Publishing Policies Developing World Access HELP & SUPPORT Contact Us Training and Support DMCA & Reporting Piracy OPPORTUNITIES Subscription Agents Advertisers & Corporate Partners CONNECT WITH WILEY The Wiley Network Wiley Press Room Copyright © 1999-2024 John Wiley & Sons, Inc or related companies. All rights reserved, including rights for text and data mining and training of artificial technologies or similar technologies.

</subsection_point_Point 3>

<previous_sections>

A systematic review of automated systems for real-time irrigation management

1. INTRODUCTION
The challenge of feeding a growing population with finite resources is becoming increasingly pressing. By 2050, the world population is expected to reach 9.7 billion, necessitating a 70% increase in food production (Falkenmark and Rockstrom, 2009). Irrigation plays a crucial role in enhancing crop yields and agricultural productivity to meet this growing demand. Studies have shown that irrigation can significantly increase crop water productivity, contributing to increased food production (Ali and Talukder, 2008; Playan and Mateos, 2005). However, water scarcity poses a significant challenge, with many regions facing water deficits and the need for improved water management practices (Falkenmark and Rockstrom, 2009). Optimizing irrigation schedules and doses based on crop requirements and environmental conditions is essential for maximizing yield and quality while minimizing water use (Zhang et al., 2024). The necessity of scalable water-efficient practices for increasing food demand cannot be overstated. Techniques such as regulated deficit irrigation, magnetically treated water, and the use of drought-tolerant crops like sorghum have shown promise in improving water productivity and ensuring food security (Mehmood et al., 2023; Putti et al., 2023; Hadebe et al., 2016). As the global food challenge intensifies, it is imperative to critically evaluate the current state and future potential of irrigation management systems to guide research, innovation, and implementation efforts towards fully autonomous, scalable solutions.

Despite the importance of irrigation in addressing the global food challenge, traditional irrigation management techniques, such as manual scheduling and timer-based systems, have significant limitations. These methods are often labor-intensive, inefficient, and less adaptable to changing conditions (Savin et al., 2023). Manual and timer-based scheduling can lead to high operational costs and inefficient water use (Raghavendra, Han, and Shin, 2023). The reliance on manual intervention and predetermined schedules limits their adaptability to changing environmental conditions, crop water requirements, and soil moisture levels (Kaptein et al., 2019). Sensor-based irrigation systems offer an alternative, enabling real-time adjustments based on soil water status measurements (Kaptein et al., 2019). However, the adoption of these systems in commercial settings has been limited, often requiring extensive input from researchers (Kim et al., 2014; Lea-Cox et al., 2018; Ristvey et al., 2018). The limitations of traditional irrigation management techniques highlight the need for scalable, automated solutions for greater efficiency in irrigation management. Automated systems that collect real-time data, analyze it, and make autonomous irrigation decisions can lead to improved water use efficiency and increased crop productivity (Champness et al., 2023; Wu et al., 2022). To fully understand the potential of automated systems, it is necessary to examine the automation of each part of the irrigation management pipeline and analyze the effectiveness and efficiency of integrated end-to-end solutions.

The emergence of smart irrigation management and IoT marks a significant shift from historical irrigation practices. Modern approaches rely on vast data and analysis algorithms, leveraging technologies such as remote sensing, sensor networks, weather data, and computational algorithms (Atanasov, 2023; Bellvert et al., 2023; Kumar et al., 2023). IoT plays a vital role in collecting vast amounts of data through sensors, data transmission, and tailored networks, enabling real-time monitoring and control of irrigation systems (Liakos, 2023; Zuckerman et al., 2024). These advancements in data collection and analysis have the potential to revolutionize irrigation management, allowing for more precise and efficient water use. However, challenges such as processing diverse data sources, data integration, and lack of integrated data analysis hamper the full benefit of IoT in irrigation management (Dave et al., 2023). The current fragmented approach in smart irrigation, focusing on individual components rather than the entire system, limits the potential for fully autonomous, real-time end-to-end irrigation management (Togneri et al., 2021). To address these challenges and fully realize the potential of smart irrigation management, there is a need for automating and integrating each section of the irrigation management pipeline, from sensor/weather data collection and transmission to processing, analysis, decision-making, and automated action (McKinion and Lemmon, 1985). This integration requires a thorough investigation of the role of interoperability and standardization in enabling seamless communication and compatibility between components within the automated irrigation management pipeline.

Machine learning (ML) plays a significant role in processing vast data, predicting plant stress, modeling climate effects, and optimizing irrigation in smart irrigation management systems. ML algorithms can analyze data collected from sensors and weather stations to determine optimal irrigation schedules (Vianny et al., 2022). However, the potential of ML is often constrained by manual steps, such as data interpretation, decision-making on irrigation timing and volume, and system adjustments. Automating ML integration to allow direct action from insights to irrigation execution, removing bottlenecks and achieving real-time adaptability, is crucial for fully autonomous irrigation management (Barzallo-Bertot et al., 2022). By integrating ML into automated systems, the irrigation management pipeline can become more seamless and efficient, enabling real-time decision-making and action based on data-driven insights. To achieve this level of automation and integration, it is essential to identify gaps and propose solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.

To achieve seamless integration across the automated irrigation management system, interoperability and standardization are critical. Interoperability allows different system components, such as sensors, actuators, and software, to communicate and exchange data effectively, while standardization ensures that data is represented in a consistent format (Santos et al., 2020). Standardized protocols and data formats are essential for achieving seamless integration and ensuring compatibility between components in real-time irrigation management systems (Robles et al., 2022; Hatzivasilis et al., 2018). Existing and emerging standards, such as OGC SensorThings API and ISO 11783, have applicability to real-time irrigation management systems (Hazra et al., 2021). However, challenges such as data quality, scalability, reliability, and security need to be addressed to fully realize the potential of interoperability and standardization in automated irrigation management systems (Hazra et al., 2021). Addressing these challenges is crucial for enabling the seamless integration of components within the automated irrigation management pipeline, which is essential for achieving fully autonomous, scalable irrigation management. A comprehensive evaluation of the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline is necessary to guide future research and implementation efforts.
The primary objective of this systematic review is to critically evaluate the current state and future potential of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies for enhancing agricultural water use efficiency and crop productivity.
Specific objectives include:
•	Examining the automation of each part of the irrigation management pipeline and the seamless integration of each section in the context of irrigation scheduling and management.
•	Analyzing the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
•	Investigating the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline.
•	Identifying gaps and proposing solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.
By addressing these objectives, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.

2. REVIEW METHODOLOGY
•	Question-driven framework to guide the literature review of real-time, autonomous irrigation management systems
•	Key research questions posed, each with the motivation behind investigating them and a starting hypothesis to evaluate against the examined literature
•	Table presenting the major objectives, specific objectives, questions, motivations, and hypotheses
3. DATA COLLECTION TO CLOUD: AUTOMATION AND REAL-TIME PROCESSING
3.1. Irrigation management data
The success of automated irrigation management systems relies heavily on the collection, transmission, and analysis of various types of data. The most applicable data types for irrigation management include soil moisture, canopy temperature, weather data, and plant physiological parameters (Farooq et al., 2019; Li et al., 2019; Olivier et al., 2021; Evett et al., 2020). These data are typically collected from a range of sources, including in-field sensors, remote sensing platforms, weather stations, and manual measurements (Li et al., 2019; Karimi et al., 2018).
Soil moisture data is arguably the most critical type of data for irrigation management, as it directly reflects the water available to plants and can be used to determine the optimal timing and amount of irrigation (Olivier et al., 2021; Intrigliolo & Castel, 2006). Soil moisture sensors, such as tensiometers, capacitance probes, and time-domain reflectometry (TDR) sensors, can provide real-time measurements of soil water content at various depths (Farooq et al., 2019). These sensors can be deployed in a network configuration to capture spatial variability in soil moisture across a field (Karimi et al., 2018).
Canopy temperature data is another valuable type of data for irrigation management, as it can be used to assess plant water stress and adjust irrigation accordingly (Evett et al., 2020). Infrared thermometers and thermal cameras can be used to measure canopy temperature, which is influenced by factors such as air temperature, humidity, wind speed, and plant water status (Li et al., 2019). When plants experience water stress, they tend to close their stomata to reduce water loss, leading to an increase in canopy temperature (Evett et al., 2020). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
Weather data, including temperature, humidity, precipitation, wind speed, and solar radiation, are essential for predicting crop water requirements and scheduling irrigation events (Akilan & Baalamurugan, 2024). Weather stations equipped with various sensors can provide real-time measurements of these parameters, which can be used as inputs for crop water requirement models, such as the FAO-56 Penman-Monteith equation (Li et al., 2019). These models estimate crop evapotranspiration (ET) based on weather data and crop-specific coefficients, allowing for the calculation of irrigation requirements (Intrigliolo & Castel, 2006). By integrating weather data into automated irrigation systems, irrigation schedules can be dynamically adjusted based on changing environmental conditions, ensuring that crops receive the optimal amount of water at the right time (Akilan & Baalamurugan, 2024).
When collecting and utilizing these data types, several considerations must be taken into account, including the volume, frequency, format, and source of the data (Farooq et al., 2019). The volume of data generated by automated irrigation systems can be substantial, especially when high-resolution sensors are deployed at a large scale (Bastidas Pacheco et al., 2022). This necessitates the use of efficient data storage, processing, and transmission technologies to handle the data load (Farooq et al., 2019). The frequency of data collection is another important consideration, as it directly impacts the temporal resolution of the data and the ability to detect rapid changes in plant water status or environmental conditions (Bastidas Pacheco et al., 2022). Bastidas Pacheco et al. (2022) demonstrated that collecting full pulse resolution data from water meters provides more accurate estimates of event occurrence, timing, and features compared to aggregated temporal resolutions, highlighting the importance of selecting appropriate data collection frequencies to ensure the quality and usefulness of the data for irrigation management.
The format of the data is also crucial, as it determines the compatibility and interoperability of the data with various analysis tools and platforms (Farooq et al., 2019). Standardized data formats, such as JSON, XML, or CSV, can facilitate data exchange and integration between different components of the automated irrigation system (Zhang et al., 2023). The source of the data is another important consideration, as it can impact the reliability, accuracy, and spatial coverage of the data (Farooq et al., 2019). For example, in-field sensors provide highly localized measurements, while remote sensing platforms, such as satellites or drones, can provide data at larger spatial scales (Li et al., 2019). By combining data from multiple sources, automated irrigation systems can achieve a more comprehensive understanding of crop water requirements and optimize irrigation management accordingly (Farooq et al., 2019).
Data quality, accuracy, and reliability are paramount in irrigation management, as they directly impact the effectiveness of decision-making processes and the efficiency of water use (Gupta et al., 2020). Inaccurate or unreliable data can lead to suboptimal irrigation decisions, resulting in crop stress, yield losses, or wasted water resources (Ramli & Jabbar, 2022). Gupta et al. (2020) emphasized the critical importance of data security and privacy in smart farming systems, as the leakage of sensitive agricultural data can cause severe economic losses to farmers and compromise the integrity of the automated irrigation system. The authors also highlighted the need for robust authentication and secure communication protocols to prevent unauthorized access to smart farming systems and protect data in transit (Gupta et al., 2020).
Ramli and Jabbar (2022) addressed the challenges associated with implementing real-time, automated irrigation systems, including data quality, scalability, reliability, and security. They proposed solutions and best practices based on the analysis of case studies and real-world implementations, such as the use of redundant sensors, data validation techniques, and secure communication protocols (Ramli & Jabbar, 2022). The authors also emphasized the importance of regular maintenance and calibration of sensors to ensure the accuracy and reliability of the collected data (Ramli & Jabbar, 2022).
Researchers have investigated the use of data compression, aggregation, and filtering techniques to reduce bandwidth requirements and improve transmission efficiency in automated irrigation systems (Karim et al., 2023; Rady et al., 2020; Cui, 2023). Karim et al. (2023) explored the effectiveness of various data compression techniques, such as lossless and lossy compression algorithms, in reducing the size of data packets transmitted over wireless networks. The authors found that lossless compression techniques, such as Huffman coding and Lempel-Ziv-Welch (LZW), can significantly reduce data size without compromising data quality, while lossy compression techniques, such as JPEG and MP3, can further reduce data size by introducing acceptable levels of distortion (Karim et al., 2023).
Rady et al. (2020) developed a novel data compression algorithm specifically designed for irrigation data, which achieved significant compression ratios without compromising data quality. The authors demonstrated that their algorithm could reduce the amount of data transmitted over wireless networks, thereby improving the efficiency of the irrigation system and reducing costs (Rady et al., 2020). Cui (2023) investigated the use of data aggregation and filtering techniques to reduce the number of transmissions and save bandwidth in automated irrigation systems. The author proposed a data aggregation scheme that combines multiple sensor readings into a single value, such as the average soil moisture over a specified time interval, to reduce the frequency of data transmissions (Cui, 2023). Additionally, the author explored the use of data filtering techniques, such as Kalman filters and particle filters, to remove noise and outliers from sensor data, improving the accuracy and reliability of the transmitted information (Cui, 2023).
Data standardization and harmonization are crucial for facilitating seamless integration and interoperability between the various components of automated irrigation management systems (Zhang et al., 2023; Ermoliev et al., 2022). Zhang et al. (2023) developed a novel cyberinformatics technology called iCrop, which enables the in-season monitoring of crop-specific land cover across the contiguous United States. The authors highlighted the importance of data standardization and harmonization in the context of iCrop, as it allows for the efficient distribution of crop-specific land cover information based on the findable, accessible, interoperable, and reusable (FAIR) data principle (Zhang et al., 2023). By adopting standardized data formats and protocols, such as the Open Geospatial Consortium (OGC) standards, iCrop enables the seamless integration of various data sources and facilitates the interoperability of the system with other agricultural decision support tools (Zhang et al., 2023).
Ermoliev et al. (2022) proposed a linkage methodology for linking distributed sectoral/regional optimization models in a situation where private information is not available or cannot be shared by modeling teams. The authors emphasized the need for data standardization to enable decentralized cross-sectoral coordination and analysis, as it allows for the consistent representation and exchange of data between different models and stakeholders (Ermoliev et al., 2022). By adopting standardized data formats and interfaces, the proposed linkage methodology can facilitate the integration of various optimization models and support the development of comprehensive decision support systems for sustainable resource management (Ermoliev et al., 2022).
Metadata plays a vital role in providing context and enabling better data interpretation and decision-making in automated irrigation management systems (Jahanddideh-Tehrani et al., 2021). Metadata refers to the additional information that describes the characteristics, quality, and context of the primary data, such as the sensor type, calibration parameters, measurement units, and timestamp (Jahanddideh-Tehrani et al., 2021). Jahanddideh-Tehrani et al. (2021) highlighted the importance of metadata in water resources management, as it enables decision-makers to use the data to the best of its capabilities by understanding factors such as when water data was collected and what factors might have contributed to the measurements. The authors emphasized the need for standardized metadata formats and guidelines, such as the Dublin Core Metadata Initiative (DCMI) and the ISO 19115 standard, to ensure the consistency and interoperability of metadata across different water information systems (Jahanddideh-Tehrani et al., 2021).
In the context of automated irrigation management systems, metadata can provide valuable information about the data collection process, sensor performance, and environmental conditions that can aid in data interpretation and decision-making (Cota & Mamede, 2023). For example, metadata about the sensor type and calibration parameters can help assess the accuracy and reliability of the collected data, while metadata about the weather conditions and soil properties can provide context for interpreting the data and adjusting irrigation strategies accordingly (Cota & Mamede, 2023). By incorporating metadata into the data management and analysis pipeline of automated irrigation systems, decision-makers can make more informed and context-aware decisions, leading to improved water use efficiency and crop productivity (Jahanddideh-Tehrani et al., 2021).

3.2. Edge Computing and Fog Computing
Edge computing and fog computing have emerged as transformative technologies in the realm of real-time irrigation management systems, offering significant potential for improving efficiency, scalability, and reliability (Abdel Nasser et al., 2020; Tran et al., 2019). Edge computing refers to the practice of processing data near the edge of the network, close to the source of the data, while fog computing is a decentralized computing infrastructure that extends cloud computing capabilities to the network edge (Hassija et al., 2019). These technologies bring computation and analytics closer to the data source, reducing the need for data to travel to the cloud and enabling faster processing and decision-making (Hassija et al., 2019; Zhang et al., 2020).
The potential of edge computing and fog computing in real-time irrigation management is immense. Abdel Nasser et al. (2020) proposed a two-layer system for water demand prediction using automated meters and machine learning techniques, demonstrating the potential of edge computing in improving the efficiency and scalability of irrigation management. The system collects and aggregates data from distributed smart meters in the first layer, while the second layer uses LSTM neural networks to predict water demand for different regions of households. By leveraging edge computing, the system can achieve high accuracy in predicting water demand, which is essential for efficient irrigation management (Abdel Nasser et al., 2020).
Tran et al. (2019) conducted a comprehensive review of real-time, end-to-end automated irrigation management systems, highlighting the role of fog computing in addressing data transmission challenges and enabling seamless integration across the irrigation management pipeline. The authors emphasize that real-time, end-to-end automated irrigation management systems have the potential to significantly improve water efficiency, crop yields, and reduce labor costs. However, they also identify several challenges that need to be addressed, such as data quality, scalability, reliability, and security, which can be effectively tackled by implementing fog computing architectures (Tran et al., 2019).
Edge computing offers several benefits in real-time irrigation management systems, including reduced latency, real-time decision-making, and reduced reliance on cloud connectivity (Mishra, 2020; Zhang et al., 2020). By processing data closer to the source, edge computing enables faster response times and more efficient data handling (Mishra, 2020). Mishra (2020) highlights that edge computing reduces latency by processing data closer to the source, enabling real-time decision-making and lessening reliance on cloud connectivity by shifting processing to local or edge devices.
Zhang et al. (2020) explore the application of edge computing in agricultural settings, demonstrating its potential to improve the efficiency and accuracy of irrigation systems. The authors discuss how edge computing has prospects in various agricultural applications, such as pest identification, safety traceability of agricultural products, unmanned agricultural machinery, agricultural technology promotion, and intelligent management. They also emphasize that the emergence of edge computing models, such as fog computing, cloudlet, and mobile edge computing, has transformed the management and operation of farms (Zhang et al., 2020).
Fog computing plays a crucial role in distributing processing and storage across the network, enhancing the scalability and reliability of automated irrigation systems (Premkumar & Sigappi, 2022; Singh et al., 2022). Premkumar and Sigappi (2022) evaluate the current state of automated irrigation management systems and propose a hybrid machine learning approach for predicting soil moisture and managing irrigation. Their study emphasizes the potential of fog computing in distributing processing and storage across the network, improving the efficiency and scalability of irrigation systems. The proposed hybrid machine learning approach outperforms other machine learning algorithms in predicting soil moisture, demonstrating the effectiveness of fog computing in enhancing the performance of automated irrigation systems (Premkumar & Sigappi, 2022).
Singh et al. (2022) discuss the role of fog computing in distributing processing and storage across the network, enhancing scalability and reliability in agricultural management systems. The authors argue that by implementing fog computing, these systems can achieve faster data processing and response times, improving overall efficiency and effectiveness. They also highlight that fog computing can address the challenges faced by real-time data transmission in agricultural management systems, such as latency, bandwidth limitations, and data security (Singh et al., 2022).
The integration of edge and fog computing in real-time irrigation management systems is crucial for achieving fully automated, scalable, and reliable solutions. As the demand for autonomous irrigation management grows, these technologies will play a pivotal role in enabling faster decision-making, reduced latency, improved resource utilization, and seamless integration across the irrigation management pipeline (Tran et al., 2019; Zhang et al., 2020). By bringing computation and analytics closer to the data source and distributing processing and storage across the network, edge and fog computing can significantly enhance the efficiency and effectiveness of automated irrigation systems, contributing to the overall goal of addressing the global food challenge through optimized water resource management and increased agricultural productivity (Abdel Nasser et al., 2020; Premkumar & Sigappi, 2022; Singh et al., 2022).

3.3. Automation of Data Collection
The automation of data collection is a critical component in the development of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. It enables the efficient gathering of vital information about crop health, environmental conditions, and water requirements, which is essential for enhancing agricultural water use efficiency and crop productivity. Two key aspects of automated data collection are the use of advanced sensing technologies for non-invasive plant stress detection and the implementation of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection.
Advanced sensing technologies, such as hyperspectral imaging and thermal sensing, have emerged as powerful tools for non-invasive plant stress detection in automated irrigation management systems. These technologies provide valuable information about crop traits, enabling early and accurate detection of plant health issues (Triantafyllou et al., 2019). Triantafyllou et al. (2019) propose a comprehensive reference architecture model that incorporates advanced sensing technologies in the sensor layer for real-time plant stress detection, highlighting their importance in providing non-invasive plant stress detection. Similarly, Hossain et al. (2023) present a novel IoT-ML-Blockchain integrated framework for smart agricultural management that leverages advanced sensing technologies to optimize water use and improve crop yield, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
Hyperspectral imaging can capture subtle changes in plant physiology that are indicative of stress, while machine learning algorithms can be employed to extract meaningful patterns from the spectral data and classify different stress types (Araus et al., 2014). Thermal sensing can detect changes in canopy temperature, which is influenced by factors such as plant water status (Li et al., 2019). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
The integration of advanced sensing technologies in automated irrigation management systems has the potential to revolutionize precision agriculture. Jiang et al. (2019) demonstrate the effectiveness of a deep learning-based model in accurately detecting leaf spot diseases, highlighting the importance of image augmentation and deep learning algorithms in enhancing the model's performance.
Wireless sensor networks (WSNs) and energy-efficient communication protocols have the potential to significantly improve the efficiency and reliability of data collection in large-scale, long-term irrigation systems. WSNs offer a cost-effective and scalable solution for real-time data collection in large-scale irrigation systems, providing remote monitoring and automated control capabilities (Mehdizadeh et al., 2020). Nishiura and Yamamoto (2021) propose a novel sensor network system that utilizes drones and wireless power transfer to autonomously collect environmental data from sensor nodes in vast agricultural fields, reducing operational costs and enhancing the efficiency of data collection. Similarly, Higashiura and Yamamoto (2021) introduce a network system that employs UAVs and LoRa communication to efficiently collect environmental data from sensor nodes distributed across large farmlands, optimizing data collection and reducing travel distance and time.
Energy-efficient communication protocols are crucial for ensuring reliable data transmission in challenging environmental conditions and extending the lifespan of sensor nodes (Mehdizadeh et al., 2020). Al-Ali et al. (2023) investigate the potential of WSNs and energy-efficient communication protocols for data collection in large-scale, long-term irrigation systems, discussing the challenges and opportunities of using these technologies to improve the efficiency and reliability of real-time data collection in irrigation management. Mehdizadeh et al. (2020) emphasize the need for careful consideration of factors such as data accuracy, energy consumption, and network reliability when designing effective WSNs for irrigation management, enabling timely irrigation decisions and improved crop yields.
The automation of data collection through the use of advanced sensing technologies and wireless sensor networks is essential for achieving fully autonomous, scalable irrigation management. By enabling non-invasive plant stress detection and large-scale, long-term data collection, these technologies contribute to the overall goal of optimizing water resource management and increasing agricultural productivity. The integration of these technologies in real-time, end-to-end automated irrigation management systems has the potential to enhance agricultural water use efficiency and crop productivity, ultimately contributing to the development of fully autonomous, scalable irrigation management solutions.

3.4: Real-Time Data Transmission Protocols and Technologies
Real-time data transmission is a critical component of automated irrigation management systems, as it enables the timely delivery of sensor data to the cloud for processing and decision-making. The exploration of suitable protocols and network architectures is essential for ensuring efficient and reliable data transmission in these systems, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
The Message Queuing Telemetry Transport (MQTT) protocol has emerged as a popular choice for real-time data transmission in IoT networks, including those used for automated irrigation management. MQTT is a lightweight, publish-subscribe protocol designed for constrained devices and low-bandwidth networks (Author, 2019). Its simplicity and low overhead make it well-suited for IoT applications where data transmission speed and energy efficiency are critical (Saranyadevi et al., 2022). MQTT provides three Quality of Service (QoS) levels, ensuring data reliability in real-time scenarios (Author, 2019). Chen et al. (2020) proposed novel algorithms to improve data exchange efficiency and handle rerouting in MQTT-based IoT networks for automated irrigation management systems. Their TBRouting algorithm efficiently finds the shortest paths for data transmission, while the Rerouting algorithm effectively handles the rerouting of topic-based session flows when a broker crashes. The combination of these algorithms can significantly improve the performance and reliability of automated irrigation management systems (Chen et al., 2020).
Client-server IoT networks, such as those based on MQTT, play a crucial role in real-time data transmission for automated irrigation management systems. In these networks, sensors and devices (clients) publish data to a central broker (server), which then distributes the data to subscribed clients (Verma et al., 2021). This architecture enables efficient data collection, processing, and dissemination, facilitating the integration of various components within the automated irrigation management pipeline. Verma et al. (2021) proposed an architecture for healthcare monitoring systems using IoT and communication protocols, which provides a comprehensive overview of existing approaches and highlights challenges and opportunities in the field. Although focused on healthcare, the insights from this study can be applied to automated irrigation management systems, emphasizing the importance of interoperability and standardization for seamless integration (Verma et al., 2021).
In addition to MQTT, other application layer protocols such as XMPP, CoAP, SOAP, and HTTP have been explored for real-time data transmission in IoT networks. Each protocol has its strengths and weaknesses, making them suitable for different applications and scenarios. XMPP (Extensible Messaging and Presence Protocol) is an open-standard protocol that supports real-time messaging, presence, and request-response services (Saint-Andre, 2011). CoAP (Constrained Application Protocol) is a specialized web transfer protocol designed for use with constrained nodes and networks in the Internet of Things (Shelby et al., 2014). SOAP (Simple Object Access Protocol) is a protocol for exchanging structured information in the implementation of web services, while HTTP (Hypertext Transfer Protocol) is the foundation of data communication for the World Wide Web (Fielding et al., 1999).
Motamedi and Villányi (2022) compared and evaluated wireless communication protocols for the implementation of smart irrigation systems in greenhouses, considering factors such as power consumption, range, reliability, and scalability. They found that ZigBee is the most suitable local communication protocol for greenhouse irrigation due to its large number of nodes and long range, while MQTT is the recommended messaging protocol for smart irrigation systems due to its TCP transport protocol and quality of service (QoS) options. GSM is a reliable and cost-effective global communication protocol for greenhouse irrigation, providing wide coverage and low cost (Motamedi & Villányi, 2022).
Syafarinda et al. (2018) investigated the use of the MQTT protocol in a precision agriculture system using a Wireless Sensor Network (WSN). They found that MQTT is suitable for use in IoT applications due to its lightweight, simple, and low bandwidth requirements. The average data transmission speed using the MQTT protocol was approximately 1 second, demonstrating its effectiveness for real-time data transmission in precision agriculture systems (Syafarinda et al., 2018).
The choice of application layer protocol for real-time irrigation management depends on factors such as data transmission speed, reliability, and energy efficiency. MQTT and RTPS (Real-Time Publish-Subscribe) are both suitable for real-time data transmission in IoT systems, but they have different strengths and weaknesses. MQTT is a better choice for applications that require low latency and high throughput, while RTPS is a better choice for applications that require high reliability and low latency (Sanchez-Iborra & Skarmeta, 2021). The exploration of MQTT and client-server IoT networks, along with the comparison of various application layer protocols, provides valuable insights into the suitability of these technologies for real-time data transmission in automated irrigation management systems.
In summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.

3.5. Challenges and Solutions in Real-Time Data Transmission
Following the exploration of data collection, processing at the edge and fog, and automation in previous sections, we now turn to the critical aspect of real-time data transmission. While essential for automated irrigation management, this stage presents unique challenges that must be addressed to ensure system efficiency and reliability.
Obstacles in Real-Time Data Transmission
Agricultural environments present unique challenges for real-time data transmission, directly impacting the effectiveness of automated irrigation systems. Environmental factors can significantly disrupt wireless communication. Adverse weather conditions such as heavy rain, fog, and high winds can weaken or even block radio signals, leading to data loss and compromised system performance. Physical obstacles like trees, buildings, and uneven terrain further complicate signal propagation, creating reliability issues (Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). These environmental challenges necessitate robust communication protocols and network architectures that can ensure consistent and reliable data flow.
In addition to environmental factors, technical limitations also present significant obstacles. Large-scale agricultural operations often demand long-distance data transmission, which can be hindered by the limited range of certain wireless communication protocols. Network congestion, occurring when multiple sensors transmit data concurrently, can lead to delays and potential data loss, further complicating real-time decision-making (Hameed et al., 2020). To mitigate these issues, researchers have investigated the potential of cognitive radio networks (CRNs) and dynamic spectrum access (DSA) for optimizing spectrum utilization and reducing interference (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). CRNs enable devices to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency. DSA, on the other hand, facilitates the dynamic allocation of unused spectrum, enhancing spectrum utilization and reducing congestion.
Furthermore, data security and privacy are paramount concerns in real-time irrigation systems. The sensitive nature of agricultural data, such as crop yields and farm management practices, necessitates robust security measures to prevent unauthorized access and data breaches (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential to protect data integrity and ensure the trustworthiness of the system.
Investigating Data Optimization Techniques
To enhance the efficiency and reliability of real-time data transmission in automated irrigation systems, researchers have explored a range of data optimization techniques. Data compression techniques aim to reduce the size of data packets transmitted over the network, minimizing bandwidth requirements and improving transmission speed (Rady et al., 2020; Karim et al., 2023). Lossless compression algorithms, such as Huffman coding and LZW, preserve data integrity while effectively reducing data size, ensuring that no information is lost during transmission (Cui, 2023). Lossy compression algorithms, such as JPEG and MP3, offer higher compression ratios but introduce a controlled level of data loss, which may be acceptable for certain applications where some loss of precision is tolerable (Karim et al., 2023). The choice between lossless and lossy compression depends on the specific application and the trade-off between data size and accuracy.
Data aggregation techniques provide another effective approach to optimize data transmission. By aggregating multiple sensor readings into a single representative value, such as average soil moisture or temperature, the number of transmissions can be significantly reduced, conserving bandwidth and energy resources (Cui, 2023). This is particularly beneficial in large-scale irrigation systems where numerous sensors are deployed across vast areas, generating substantial amounts of data. Additionally, data filtering techniques play a crucial role in improving data quality and reliability. Kalman filters and particle filters can effectively remove noise and outliers from sensor data, ensuring that only accurate and relevant information is transmitted and used for decision-making (Cui, 2023). This is essential for preventing erroneous data from influencing irrigation decisions and potentially leading to suboptimal water management.
Sensor calibration, drift correction, and fault detection are essential for maintaining data accuracy and reliability (Dos Santos et al., 2023). Regular calibration ensures that sensors provide accurate measurements over time, while drift correction techniques account for gradual changes in sensor readings due to environmental factors or aging. Fault detection mechanisms can identify and address sensor malfunctions or anomalies, preventing erroneous data from influencing irrigation decisions and potentially harming crops or wasting water.
Addressing the Challenges
Effectively addressing the challenges in real-time data transmission requires a multifaceted approach that encompasses environmental, technical, and data-related considerations. Implementing robust and adaptive communication protocols is crucial for overcoming interference and signal degradation caused by weather conditions and physical obstacles. Selecting appropriate protocols, such as LoRa or ZigBee, with suitable range and penetration capabilities can ensure reliable data transmission in challenging agricultural environments (Motamedi & Villányi, 2022). Additionally, employing techniques like frequency hopping and error correction codes can further improve communication resilience and mitigate data loss.
Optimizing network architecture is another key consideration. Deploying a distributed network architecture with edge and fog computing capabilities can significantly enhance data processing and transmission efficiency (Abdel Nasser et al., 2020; Tran et al., 2019). Edge devices can perform initial data processing and aggregation tasks, reducing the amount of data transmitted to the cloud and minimizing latency, while fog nodes can provide additional processing power and storage closer to the data source, enhancing scalability and reliability. This distributed approach alleviates the burden on the central cloud server and allows for more responsive and efficient irrigation management.
Data optimization techniques play a vital role in reducing bandwidth requirements and improving transmission efficiency. The choice of data compression, aggregation, and filtering techniques should be tailored to the specific requirements of the irrigation system, considering factors such as data type, accuracy needs, and available bandwidth. By carefully selecting and implementing these techniques, the overall performance and effectiveness of real-time irrigation systems can be significantly enhanced, leading to more sustainable water management practices and improved agricultural productivity.
By addressing these challenges and implementing appropriate solutions, real-time data transmission can become a reliable and efficient component of automated irrigation systems, contributing to the overall goal of achieving sustainable and productive agriculture in the face of growing food demands and water scarcity.

3.6. IoT Network Architectures and Variable Rate Irrigation (VRI) for Real-Time Irrigation
Real-time irrigation management systems heavily rely on the efficient and reliable transmission of data from sensors and weather stations to the cloud for processing and decision-making. However, agricultural environments present unique challenges to wireless communication, including adverse weather conditions, physical obstacles, and the limitations of wireless technologies. These challenges necessitate robust and adaptive solutions to ensure the consistent and timely flow of data, enabling truly autonomous irrigation scheduling.
Environmental factors, such as heavy rain, fog, and strong winds, can significantly disrupt wireless communication by attenuating or even blocking radio signals, leading to data loss and compromised system performance (Ed-daoudi et al., 2023; Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). Dense vegetation, buildings, and uneven terrain create further complications by causing multipath propagation and shadowing effects (Yim et al., 2018; Gautam and Pagay, 2020). The study by Yim et al. (2018) on LoRa networks in a tree farm environment exemplifies these challenges, revealing reduced communication range and data reliability compared to theoretical expectations. This underscores the need for carefully selecting and optimizing communication protocols and network parameters to ensure reliable data transmission in such environments.
The study by Guzinski et al. (2014a) using a modified TSEB model further highlights the importance of high-resolution data in accurately capturing the spatial and temporal dynamics of energy fluxes influenced by environmental factors. This emphasizes the need for advanced data acquisition and processing techniques that can effectively represent the complexities of agricultural settings.
The limitations of traditional wireless communication technologies, such as limited range and network congestion, pose additional challenges for large-scale agricultural operations. Long-distance data transmission can be hindered by range limitations, while network congestion arising from numerous sensors transmitting concurrently can lead to delays and data loss, hindering real-time decision-making (Hameed et al., 2020). Addressing these challenges requires the exploration of advanced networking technologies that can optimize spectrum utilization, mitigate interference, and improve reliability and efficiency.
Cognitive Radio Networks (CRNs) and Dynamic Spectrum Access (DSA) offer promising solutions for optimizing wireless communication in agricultural settings. CRNs empower devices with the ability to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). Research has explored the potential of CRNs in predicting Radio Frequency (RF) power to avoid noisy channels and optimize spectrum utilization (Iliya et al., 2014; Iliya et al., 2014). These studies demonstrate the effectiveness of combining optimization algorithms with artificial neural networks (ANNs) to enhance the accuracy and generalization of RF power prediction, enabling CRNs to make informed decisions about channel selection and avoid interference.
DSA complements CRN technology by dynamically allocating unused spectrum, further enhancing spectrum utilization and reducing congestion (Shi et al., 2023). The numerical model developed by Shi et al. (2023) showcases the potential of CRNs and DSA for optimizing wireless communication in challenging environments.
The integration of CRNs and DSA into the IoT network architecture requires careful consideration of spectrum sensing techniques, network topology, and data security. Research on cooperative spectrum sensing suggests that distributed approaches, where sensor nodes collaborate and share information, can significantly improve the accuracy and efficiency of spectrum sensing, particularly in dynamic environments (Trigka and Dritsas, 2022; Khalid & Yu, 2019). This collaborative approach enables a more comprehensive understanding of the radio environment and facilitates the identification of available frequency bands for data transmission.
The choice of network topology also impacts the performance and scalability of CRN-based irrigation systems. Mesh networks, where sensor nodes are interconnected and relay data for each other, offer enhanced resilience and coverage compared to star topologies where nodes communicate directly with a central gateway (Akyildiz & Vuran, 2010). However, mesh networks can be more complex to manage and may introduce additional routing overhead. The trade-off between network resilience and complexity needs to be carefully evaluated to select the most appropriate topology for a specific agricultural setting.
Data security and privacy are paramount concerns in IoT-based irrigation systems due to the sensitive nature of agricultural data (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential for protecting data integrity and ensuring system trustworthiness. Research on secure spectrum leasing and resource allocation algorithms for CR-WSN-based irrigation systems has demonstrated the potential of these technologies for enhancing security and efficiency (Hassan, 2023; Afghah et al., 2018).
In conclusion, the development of effective and reliable real-time irrigation management systems requires a comprehensive approach that addresses the challenges of data transmission in agricultural environments. The integration of robust and adaptive communication protocols, optimized network architectures, and advanced networking technologies like CRNs and DSA, along with a focus on data security and privacy, can contribute significantly to achieving the goal of autonomous and efficient irrigation scheduling.
4. AUTOMATED DATA PROCESSING IN THE CLOUD
4.1. Data Quality and Preprocessing
Data quality is paramount in automated irrigation systems as it directly influences the effectiveness of decision-making and water use efficiency. Issues like missing values, inconsistencies, and outliers arising from sensor malfunctions, environmental interference, or network problems (Lv et al., 2023) can significantly impact the performance of machine learning models used for irrigation scheduling and management.
Real-time data cleaning techniques are essential for addressing these challenges. Kalman filtering proves particularly effective in handling missing values and correcting erroneous readings by recursively estimating the system's state based on previous measurements and current sensor data, taking into account noise and uncertainty (Kim et al., 2020). Moving average techniques, by averaging consecutive data points, provide a more stable representation of the underlying trend, filtering out short-term fluctuations (Chhetri, 2023). For outlier detection, adaptive thresholding methods offer a dynamic approach, adjusting thresholds based on the statistical properties of the data to effectively identify anomalies and minimize false positives (Bah et al., 2021). These techniques are crucial in maintaining the integrity of real-time data streams and ensuring the accuracy of subsequent analyses.
Adaptive data preprocessing is essential for managing the diversity of data sources and formats commonly found in irrigation systems. Data normalization techniques, such as min-max scaling or z-score normalization, ensure that all features contribute equally to the analysis by transforming data values to a common scale (Pradal et al., 2016). This is crucial for preventing features with larger values from dominating the analysis and ensuring that all features are given equal consideration. Similarly, feature scaling methods, like standardization or normalization, optimize the range of feature values to improve the performance and convergence of machine learning models (Tortorici et al., 2024). By scaling features to a similar range, the influence of outliers is reduced, and the model's ability to learn from the data is enhanced.
Data fusion techniques play a critical role in integrating information from diverse sources, creating a more comprehensive and reliable dataset for irrigation management. Dempster-Shafer theory, a generalization of probability theory, allows for the expression of both uncertainty and the degree of conflict in evidence, making it suitable for fusing uncertain and conflicting data from heterogeneous sources (Sadiq and Rodriguez, 2004). This is particularly relevant in irrigation systems where data from different sensors may provide slightly different or even contradictory information due to sensor variations or environmental factors. Bayesian inference offers another powerful framework for combining information from multiple sources, updating the probability of a hypothesis as new evidence becomes available. By applying these techniques, data from soil moisture sensors, canopy temperature sensors, weather stations, and other sources can be integrated to provide a holistic understanding of crop water requirements and environmental conditions, leading to more informed and accurate irrigation decisions.
The impact of data quality extends beyond model accuracy to the robustness of machine learning models under varying conditions. Robust models should maintain consistent performance even when faced with data inconsistencies or unexpected situations. Techniques like data augmentation and domain adaptation can enhance model robustness by exposing the model to a wider range of data variations during training. Data augmentation involves generating additional training data by applying transformations or introducing noise to existing data, making the model more resilient to noise and variations in the real-world data. Domain adaptation techniques aim to adapt a model trained on one domain (e.g., a specific crop or geographic location) to perform well on another domain with different data characteristics. This is particularly relevant in irrigation management, where models may need to be applied to different crops, soil types, or climatic conditions.
The choice of data cleaning, preprocessing, and fusion techniques should be carefully considered based on the specific characteristics of the irrigation system and the available data. By selecting and implementing appropriate techniques, the accuracy, reliability, and robustness of machine learning models can be significantly improved, leading to more efficient and sustainable irrigation management practices.
4.2. Scalable and Autonomous Deployment using Containerization Strategies
The transition from data collection and transmission to efficient data processing requires a robust infrastructure capable of handling diverse workloads and data volumes. Containerization technologies, specifically Docker and Kubernetes, offer a promising solution for deploying and scaling data processing and machine learning modules within cloud environments like AWS, Azure, and GCP (Vargas-Rojas et al., 2024; Rosendo et al., 2022; Solayman & Qasha, 2023). Docker provides a standardized way to package applications and their dependencies into self-contained units known as containers, ensuring consistent and reproducible execution across different platforms (Rosendo et al., 2022). Kubernetes, acting as a container orchestrator, manages their deployment, scaling, and networking across a cluster of machines (Rosendo et al., 2022). This combination presents several advantages for automated irrigation management systems.
Firstly, containerization facilitates efficient resource utilization and scalability. By encapsulating applications and their dependencies, containers enable the isolation of resources and prevent conflicts between different modules (Vargas-Rojas et al., 2024; Solayman & Qasha, 2023). This isolation allows for the efficient allocation of resources, such as CPU, memory, and storage, to each container based on its specific needs. Kubernetes further enhances scalability by allowing for the automatic scaling of containers based on real-time demand, ensuring the system can adapt to varying workloads and data volumes, preventing bottlenecks, and ensuring responsiveness to changing conditions (Karamolegkos et al., 2023).
Secondly, containerization promotes portability and reproducibility. By packaging applications and their dependencies into a single unit, containers make it easy to move and deploy them across different cloud environments without the need for environment-specific configurations (Rosendo et al., 2022; Solayman & Qasha, 2023). This portability simplifies the development and deployment process, reducing the time and effort required to set up and manage the system. Additionally, containers ensure reproducibility by providing a consistent execution environment, regardless of the underlying infrastructure. This eliminates variability and ensures that the system will behave consistently across different deployments (Zhou et al., 2023).
Optimizing container orchestration and resource allocation is crucial to minimizing latency and maximizing throughput in real-time data processing pipelines. Techniques like auto-scaling and dynamic resource allocation play a critical role in this context (Hethcoat et al., 2024; Werner and Tai, 2023; Kumar et al., 2024). Auto-scaling automatically adjusts the number of container instances based on real-time demand, ensuring that sufficient resources are available to handle peak workloads while avoiding over-provisioning during periods of low demand (Hethcoat et al., 2024; Kumar et al., 2024). Dynamic resource allocation enables the fine-grained adjustment of resources allocated to each container based on its specific needs and the current workload (Werner and Tai, 2023). This ensures efficient resource allocation and provides each container with the necessary resources to perform its tasks effectively.
Performance monitoring tools, such as Kubernetes Metrics Server and Prometheus, are essential for gaining insights into the performance of containers and the overall system (Hethcoat et al., 2024; Kuity & Peddoju, 2023). These tools provide valuable data on key performance indicators, such as CPU and memory usage, network traffic, and application-specific metrics. By monitoring this data, administrators can identify bottlenecks, optimize resource allocation strategies, and continuously improve system performance (Hethcoat et al., 2024). This data-driven approach ensures that automated irrigation management systems can operate efficiently and reliably.
By integrating containerization technologies with optimization techniques and performance monitoring, automated irrigation management systems achieve the scalability, autonomy, and efficiency required for effective real-time data processing and decision-making. This approach facilitates a seamless and responsive system that can adapt to changing conditions and contribute to the overall goal of optimizing water resource management and increasing agricultural productivity.
4.3. Deploying ML Models for Data Processing
•	Architectures and frameworks for deploying machine learning models on cloud platforms for real-time data processing and inference in irrigation management systems, such as: TensorFlow Serving, Apache MXNet Model Server, ONNX Runtime
•	Techniques for optimizing machine learning model performance and resource utilization in cloud environments, such as: Model compression (e.g., pruning, quantization), Hardware acceleration (e.g., GPU, TPU), Distributed training (e.g., Horovod, BytePS)
•	Integration of deployed machine learning models with other components of the automated irrigation management pipeline, such as data preprocessing, decision-making, and control systems, using protocols like: MQTT, CoAP, RESTful APIs
4.4. Online Learning in the Cloud
•	Application of online learning techniques for continuously updating and improving machine learning models based on incoming real-time data, using algorithms such as: Stochastic gradient descent (SGD), Passive-aggressive algorithms, Online random forests
•	Architectures and frameworks for implementing online learning in cloud-based irrigation management systems, such as: Apache Spark Streaming, Apache Flink, AWS Kinesis, leveraging serverless computing and stream processing paradigms
•	Strategies for balancing exploration and exploitation in online learning to adapt to changing environmental conditions and optimize irrigation decision-making, using techniques such as: Multi-armed bandits, Bayesian optimization, Reinforcement learning (e.g., Q-learning, SARSA)


5. GENERATING AND APPLYING IRRIGATION INSIGHTS 
5.1. Real-Time Generation of Actionable Irrigation Insights
•	Advanced predictive models, such as deep learning (e.g., LSTM, CNN) and ensemble methods (e.g., Random Forests), for precise, site-specific irrigation recommendations
•	Integration of IoT sensor data (e.g., soil moisture probes, weather stations) and cloud-based data sources (e.g., weather forecasts, satellite imagery) using data fusion techniques (e.g., Kalman filtering) to enhance insight accuracy and resolution
•	Strategies for handling data heterogeneity, uncertainty, and quality issues in real-time insight generation, such as data preprocessing and outlier detection
•	Techniques for reducing computational complexity and latency, such as edge computing (e.g., fog computing), model compression (e.g., quantization), and hardware accelerators (e.g., GPUs)
5.2. Automated Application of Irrigation Insights
•	Architectures and protocols for seamless integration of ML-generated insights with IoT-enabled irrigation control systems, such as MQTT and CoAP for lightweight, real-time communication
•	Analysis of industry-leading products and services, such as smart irrigation controllers (e.g., Rachio) and cloud-based irrigation management platforms (e.g., CropX)
•	Strategies for ensuring reliability, security, and scalability of automated insight application, such as redundant communication channels and secure edge-to-cloud architectures
•	Case studies of successful implementations of closed-loop, autonomous irrigation systems in research and commercial settings, highlighting technologies used and benefits achieved

6. INTEGRATION, INTEROPERABILITY, AND STANDARDIZATION 
6.1. Interoperability and Standardization
•	Importance of interoperability and standardization in enabling seamless integration of automated irrigation components
•	Overview of existing and emerging standards for IoT devices, communication protocols, and data formats in precision agriculture (e.g., ISOBUS, agroXML, SensorML)
•	Role of standardization bodies and industry consortia in promoting interoperability (e.g., AgGateway, Open Ag Data Alliance, Agricultural Industry Electronics Foundation)
•	Challenges in adopting and implementing standards across diverse hardware and software platforms
•	Strategies for encouraging widespread adoption of standards and best practices for interoperability in automated irrigation systems
6.2. Integration with Existing Irrigation Infrastructure
•	Challenges and strategies for retrofitting legacy irrigation systems with IoT sensors, actuators, and communication devices
•	Hardware compatibility issues and solutions (e.g., adapters, modular designs)
•	Software and firmware updates to enable integration with automated decision-making systems
•	Data integration and normalization techniques for merging legacy and new data sources
•	Economic and practical considerations for transitioning from manual to automated irrigation management
•	Cost-benefit analysis of upgrading existing infrastructure vs. implementing new systems
•	Phased implementation approaches to minimize disruption and optimize resource allocation
•	Training and support requirements for farmers and irrigation managers adopting automated systems
•	Case studies and real-world examples of successful integration of automated irrigation with existing infrastructure
6.3. Integration with Other Precision Agriculture Technologies
•	Synergies between automated irrigation and complementary technologies
•	Remote sensing (satellite, UAV, and ground-based) for crop monitoring and evapotranspiration estimation
•	Soil moisture sensors and weather stations for real-time, localized data collection
•	Variable rate application systems for precise irrigation delivery based on crop requirements
•	Yield mapping and analytics for assessing the impact of automated irrigation on crop productivity
•	Architectures and frameworks for integrating diverse data sources and technologies into a unified precision agriculture ecosystem
•	Edge computing and fog computing paradigms for real-time data processing and decision-making
•	Cloud-based platforms for data storage, analysis, and visualization
•	API-driven approaches for modular integration of third-party services and applications
•	Challenges and solutions for ensuring data quality, consistency, and security across integrated precision agriculture systems
•	Data cleaning, preprocessing, and harmonization techniques
•	Blockchain and distributed ledger technologies for secure, tamper-proof data sharing and traceability
•	Access control and authentication mechanisms for protecting sensitive data and resources
•	Future trends and research directions in the integration of automated irrigation with advanced precision agriculture technologies (e.g., AI-driven crop modeling, robotics, and autonomous vehicles)
6.4. Cybersecurity Considerations for Integrated Automated Irrigation Systems
•	Unique security risks and vulnerabilities associated with IoT-based automated irrigation systems
•	Potential for unauthorized access, data tampering, and system manipulation
•	Implications of security breaches for crop health, water resource management, and farm productivity
•	Best practices and strategies for securing automated irrigation systems
•	Secure device provisioning and authentication (e.g., hardware security modules, certificates)
•	Encryption and secure communication protocols (e.g., TLS, DTLS)
•	Firmware and software updates to address emerging security threats
•	Network segmentation and access control to limit the impact of breaches
•	Role of cybersecurity standards and frameworks in guiding the development and deployment of secure automated irrigation systems (e.g., NIST CSF, IEC 62443)
•	Importance of user awareness, training, and incident response planning in maintaining the security of integrated automated irrigation systems

7. MONITORING AND ENSURING SYSTEM RELIABILITY
7.1. Resilience and Fault Tolerance in Automated Irrigation Systems
•	Strategies for ensuring robustness and reliability in the face of failures, disruptions, or unexpected events
•	Redundancy: Implementing redundant components, such as duplicate sensors (e.g., soil moisture sensors, weather stations), controllers (e.g., PLCs, microcontrollers), and communication channels (e.g., cellular, satellite, LoRaWAN) to maintain system functionality during component failures
•	Failover mechanisms: Designing seamless failover mechanisms that automatically switch to backup components or systems in case of primary system failure, such as hot-standby controllers or multi-path communication protocols (e.g., mesh networks, software-defined networking)
•	Self-healing capabilities: Incorporating AI-driven self-healing mechanisms that can detect, diagnose, and recover from faults without human intervention, using techniques like reinforcement learning, Bayesian networks, or self-organizing maps
•	The role of distributed architectures and edge computing in enhancing system resilience
•	Decentralizing critical functions and data processing to minimize the impact of single points of failure, using fog computing or multi-agent systems
•	Leveraging edge computing to enable localized decision-making and control, reducing dependence on cloud connectivity and improving response times, using technologies like Raspberry Pi, NVIDIA Jetson, or Intel NUC
•	Anomaly detection and predictive maintenance using AI techniques
•	Employing unsupervised learning algorithms (e.g., autoencoders, clustering) to detect anomalies in sensor data, system performance, and water usage patterns
•	Developing predictive maintenance models using techniques like long short-term memory (LSTM) networks, convolutional neural networks (CNNs), or gradient boosting machines (GBMs) to anticipate and prevent potential system failures based on historical data and real-time monitoring
7.2. Advanced Monitoring Techniques for Automated Irrigation Systems
•	Remote monitoring using IoT-enabled sensors and computer vision
•	Deploying a heterogeneous network of IoT sensors to collect real-time data on soil moisture (e.g., capacitive, tensiometric), temperature (e.g., thermocouples, thermistors), humidity (e.g., capacitive, resistive), and plant health (e.g., sap flow, leaf wetness)
•	Integrating high-resolution cameras (e.g., multispectral, hyperspectral) and computer vision algorithms for visual monitoring of crop growth, disease detection (e.g., using deep learning-based object detection and segmentation), and irrigation system performance (e.g., leak detection, sprinkler uniformity)
•	Transmitting sensor and camera data to cloud-based platforms (e.g., AWS IoT, Google Cloud IoT, Microsoft Azure IoT) for remote access and analysis using protocols like MQTT, CoAP, or AMQP
•	Innovative approaches for real-time system health assessment
•	Developing novel algorithms and metrics for evaluating the health and performance of automated irrigation systems, such as entropy-based measures, network resilience indices, or multi-criteria decision analysis (MCDA) frameworks
•	Combining data from multiple sources (e.g., sensors, weather forecasts, satellite imagery) using data fusion techniques (e.g., Kalman filters, Dempster-Shafer theory) to create a comprehensive view of system health
•	Employing advanced data visualization techniques (e.g., interactive dashboards, augmented reality) to present system health information in an intuitive and actionable format
7.3. Closed-Loop Control and Feedback Mechanisms
•	Exploring the concept of closed-loop control in autonomous irrigation systems
•	Implementing feedback loops that continuously monitor system performance and adjust irrigation schedules based on real-time data, using control techniques like proportional-integral-derivative (PID), model predictive control (MPC), or fuzzy logic control (FLC)
•	Integrating machine learning algorithms (e.g., reinforcement learning, genetic algorithms) to optimize closed-loop control strategies over time, adapting to changing environmental conditions and crop requirements
•	Designing effective feedback mechanisms for user interaction and system optimization
•	Providing user-friendly interfaces (e.g., mobile apps, web dashboards) for farmers to input preferences, constraints, and expert knowledge into the automated irrigation system, using techniques like participatory design or user-centered design
•	Incorporating user feedback and domain expertise to refine irrigation strategies and improve system performance
8. CASE STUDIES AND REAL-WORLD IMPLEMENTATIONS OF FULLY AUTONOMOUS IRRIGATION SYSTEMS
8.1. Fully Autonomous Irrigation Systems in Diverse Agricultural Settings
•	Row Crops: maize, wheat, soybean with real-time soil moisture monitoring and weather-based irrigation scheduling for fully automated precision irrigation
•	Orchards: citrus, apple, almond with plant health monitoring and precision water application for fully autonomous orchard management
•	Greenhouses: tomato, lettuce, herbs with automated drip irrigation and climate control integration for fully automated greenhouse operations
•	Urban Farming: rooftop gardens, vertical farms with IoT-enabled hydroponic systems and remote management for fully autonomous urban crop production
8.2. Integration of Advanced System Components for End-to-End Automation
•	Wireless sensor networks: soil moisture probes, weather stations, plant health monitoring cameras with low-power, long-range communication for fully automated data acquisition
•	Secure data transmission: LoRaWAN, NB-IoT, 5G, satellite communication for reliable, real-time data transfer from field to cloud in fully autonomous irrigation systems
•	Intelligent data processing: edge computing for local data filtering, cloud platforms for scalable storage and analysis, machine learning algorithms for predictive insights in fully automated irrigation management
•	Autonomous decision-making: advanced irrigation scheduling algorithms, precise valve control, closed-loop feedback systems for optimal water management in fully autonomous irrigation systems
8.3. Quantitative Performance Evaluation of Fully Automated Irrigation Systems
•	Water use efficiency: percent reduction in water consumption compared to conventional methods, improved water productivity (yield per unit of water) achieved through fully autonomous irrigation
•	Crop yield and quality improvements: percent increase in yield, enhanced crop uniformity, improved nutritional content attributed to fully automated precision irrigation
•	Labor and energy savings: quantified reduction in labor hours for irrigation management, decreased energy consumption for pumping due to optimized scheduling in fully autonomous systems
•	Economic viability: detailed return on investment analysis, payback period calculations, comprehensive cost-benefit analysis for fully autonomous irrigation management systems
8.4. Lessons Learned and Challenges Encountered in Deploying Autonomous Irrigation Systems
•	Technical challenges and solutions: ensuring reliable data transmission in remote locations, addressing interoperability issues between diverse system components, optimizing power consumption for extended battery life, adapting algorithms to local soil and weather conditions in fully autonomous irrigation systems
•	Operational and logistical hurdles: streamlining installation and maintenance procedures, providing effective user training, seamlessly integrating with existing farm management practices and legacy systems for fully automated irrigation management
•	Regulatory and socio-economic considerations: navigating complex water use regulations, addressing data privacy and security concerns, ensuring equitable access and affordability for smallholder farmers adopting fully autonomous irrigation technologies
8.5. Best Practices and Recommendations for Successful Implementation
•	Designing scalable, modular, and adaptable autonomous irrigation systems to accommodate future growth and changing requirements for fully automated water management
•	Prioritizing user-centered design principles and actively engaging stakeholders throughout the development and deployment process of fully autonomous irrigation solutions
•	Adopting open standards and communication protocols to enable seamless integration of system components and interoperability with third-party platforms in fully automated irrigation setups
•	Implementing robust data validation, filtering, and quality control mechanisms to ensure data integrity and reliability for decision-making in fully autonomous irrigation systems
•	Establishing clear data governance policies and security frameworks to protect sensitive information and maintain user trust in fully automated irrigation management
•	Developing intuitive user interfaces and decision support tools to facilitate easy adoption and effective use of fully autonomous irrigation systems
•	Collaborating with local extension services, agribusinesses, and technology providers for knowledge transfer, technical support, and continuous improvement of fully automated irrigation solutions
8.6. Synthesis of Case Studies and Implications for Autonomous Irrigation Adoption
•	Cross-case analysis of key performance indicators and critical success factors for fully autonomous irrigation scheduling systems in various contexts
•	Identification of common themes, challenges, and innovative solutions across diverse implementations of end-to-end fully automated irrigation management
•	Assessment of the potential for replicability and scaling of successful fully autonomous irrigation projects in different regions and farming systems
•	Implications for future research priorities, technology development roadmaps, and policy interventions to support widespread adoption of fully autonomous irrigation technologies

CONCLUSION/FUTURE DIRECTIONS AND UNANSWERED QUESTIONS
•	Summarize the key insights gained from the question-driven review, emphasizing how each section contributes to the overarching goal of achieving real-time, end-to-end automation in irrigation management
•	Based on the questions addressed, propose new research directions and unanswered questions
•	Identify key research gaps and propose concrete research questions and hypotheses for advancing the field of real-time, automated irrigation management
•	Highlight the need for collaborative research efforts across disciplines, such as computer science, agricultural engineering, and environmental science, to address the complex challenges of automated irrigation systems
•	Emphasize the need for further innovation and exploration in real-time, automated irrigation systems



</previous_sections>

</documents>
<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper.

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: 4.4. Online Learning in the Cloud
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>


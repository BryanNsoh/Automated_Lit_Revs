- analysis: '>'
  authors:
  - Umutoni L.
  - Samadi V.
  citation_count: '0'
  description: Irrigation decision-making has evolved from solely depending on farmers’
    decisions taken based on the visual analysis of field conditions to making decisions
    based on crop water need predictions generated using machine learning (ML) techniques.
    This paper reviews ML related articles to discuss how ML has been used to enhance
    irrigation decision making. We reviewed 16 studies that used ML approaches for
    irrigation scheduling prediction and decision-making focusing on the input features,
    algorithms used and their applicability in real world conditions. ML performances
    in terms of accuracy, water conservation compared to fixed or threshold-based
    methods are discussed along with modeling performances. Informed by the 16 research
    studies, we assessed constraints to the adoption of ML in irrigation decision
    making at field scale, which include limited data availability coupled with data
    sharing constraints, and a lack of uncertainty quantification as well as the need
    for physics informed ML based irrigation scheduling models. To address these limitations,
    we discussed approaches in future research such as integrating process-based models
    with ML, incorporating expert knowledge into the modeling procedure, and making
    data and tools Findable, Accessible, Interoperable, and Reusable (FAIR). These
    approaches will improve ML modeling outcomes and boost the availability of farm-related
    data and tools for FAIRer data-driven applications of irrigation modeling.
  doi: 10.1016/j.agwat.2024.108710
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Machine learning modelling
    concepts 3. Literature review 4. Current limitations of machine learning application
    in irrigation water use modeling 5. Physics-guided machine learning (PGML) 6.
    Discussion 7. Conclusions CRediT authorship contribution statement Declaration
    of Competing Interest Acknowledgements Data availability References Show full
    outline Figures (6) Tables (1) Table 1 Agricultural Water Management Volume 294,
    1 April 2024, 108710 Application of machine learning approaches in supporting
    irrigation decision making: A review Author links open overlay panel Lisa Umutoni,
    Vidya Samadi Show more Share Cite https://doi.org/10.1016/j.agwat.2024.108710
    Get rights and content Under a Creative Commons license open access Highlights
    • Machine learning algorithms used in irrigation decision making are explained.
    • Irrigation demand computation by machine learning models is analyzed. • Limitations
    of the application of machine learning in irrigation are discussed. • Ways to
    incorporate physics into machine learning models for irrigation are presented.
    Abstract Irrigation decision-making has evolved from solely depending on farmers’
    decisions taken based on the visual analysis of field conditions to making decisions
    based on crop water need predictions generated using machine learning (ML) techniques.
    This paper reviews ML related articles to discuss how ML has been used to enhance
    irrigation decision making. We reviewed 16 studies that used ML approaches for
    irrigation scheduling prediction and decision-making focusing on the input features,
    algorithms used and their applicability in real world conditions. ML performances
    in terms of accuracy, water conservation compared to fixed or threshold-based
    methods are discussed along with modeling performances. Informed by the 16 research
    studies, we assessed constraints to the adoption of ML in irrigation decision
    making at field scale, which include limited data availability coupled with data
    sharing constraints, and a lack of uncertainty quantification as well as the need
    for physics informed ML based irrigation scheduling models. To address these limitations,
    we discussed approaches in future research such as integrating process-based models
    with ML, incorporating expert knowledge into the modeling procedure, and making
    data and tools Findable, Accessible, Interoperable, and Reusable (FAIR). These
    approaches will improve ML modeling outcomes and boost the availability of farm-related
    data and tools for FAIRer data-driven applications of irrigation modeling. Previous
    article in issue Next article in issue Keywords Machine LearningIrrigation Water
    Use ModelingWater ManagementFAIR data 1. Introduction Irrigation scheduling is
    becoming an increasingly crucial decision-making task whose goal is to achieve
    effective and efficient use of water (Saggi and Jain, 2022). The crop quality
    and yield are significantly dependent on the amount of water and timing. The objective
    of irrigation scheduling is to apply an adequate amount of water at the right
    time to a specific crop. However, according to a survey by the US Department of
    Agriculture, more than 75% of irrigation scheduling methods applied by farmers
    in the US are based on the Checkbook method (Vellidis et al., 2016), and the condition
    of crops such as visual observations, crop calendars and observing what the neighbors
    are doing (USDA, 2017). Inefficient irrigation scheduling methods may result in
    over-irrigation or under-irrigation. Consequently, water scarcity, nutrient leaching,
    and increased soil salinity if groundwater is used for irrigation can be observed
    in over-irrigated regions or yield an economic loss in under-irrigated farms.
    Science- and technology-based irrigation scheduling approaches, as opposed to
    the Checkbook method or the condition of crop method, may boost crop profit while
    reducing environmental consequences by limiting crop water stress (Zhang et al.,
    2021). Model-based crop water demand assessment falls under three categories,
    deterministic methods, process-based models, and machine learning (ML) methods.
    Deterministic methods such as FAO-56 calculate irrigation water demand based on
    crop evapotranspiration approaches (Allen et al., 2005). Process-based models
    such as Soil and Water Assessment Tool (SWAT), Aquacrop, Decision Support System
    for Agrotechnology Transfer (DSSAT), and the Agricultural Production Systems sIMulator
    (APSIM) usually determine crop water requirement by simulating biophysical processes
    leading to plants’ growth in the soil-plant-atmosphere system using mathematical
    formulations of those processes. ML models, on the other hand, are data-driven,
    they estimate irrigation needs by learning the hidden function that relates input
    weather and soil data to crop water demands. All techniques have been applied
    in irrigation scheduling for different crops in various regions across the globe.
    However, process-based models are highly sensitive to uncertainties associated
    with physical processes such as initial and boundary conditions and spatiotemporal
    variability of soil moisture conditions than are deterministic and ML models (Karandish
    and Šimůnek, 2016, Gumiere et al., 2020, Li et al., 2020). Consequently, process-based
    models need extensive and constant calibration as new data are generated to accurately
    compute irrigation needs. Furthermore, process-based models are more suitable
    for irrigation planning than for real-time irrigation decision-making (Gu et al.,
    2020). Process-based models lack a way to explicitly enhance real-time soil moisture
    prediction by incorporating weather forecasts or feedback from soil moisture sensors.
    For instance, SWAT has shown consistent overestimation of the irrigation amount
    when used for irrigation scheduling which compromises the model’s accuracy in
    automated irrigation control (Sun and Ren, 2014, Maier and Dietrich, 2016). Fortunately,
    real-time irrigation prediction and scheduling can be achieved thanks to technological
    developments such as Wireless Sensor Networks (WSN) that enhance data availability
    and the increased computational power enabling the operation of ML models in real-time.
    Examples of such applications include an irrigation system developed by Glória
    et al. (2021) to attain the best water-saving schedule using real-time data, and
    smart irrigation strategies that predict irrigation water use using several ML
    algorithms (see Tace et al., 2022). The application of ML in irrigation scheduling
    promoted agricultural productivity and water use efficiency (Hunsaker et al.,
    2005, Karasekreter et al., 2013, Nachankar et al., 2018, Nawandar and Satpute,
    2019, Jamroen et al., 2020, Jimenez et al., 2020). With novel data collection
    techniques, the quantity of available data at a finer spatial-temporal scale,
    also known as big data, has increased in an unprecedented way (Donratanapat et
    al., 2020, Huang et al., 2019). Big data can be leveraged to find appropriate
    solutions for the problems faced by farmers (García et al., 2020), such as water
    shortage, and crop and cost management (Elijah et al., 2018). ML technologies
    can be leveraged to use big data for irrigation water use simulation. Indeed,
    the integration of ML technologies with big data enables irrigation estimation
    to be undertaken in more intelligent and efficient ways hence ensuring water sustainability
    for the growing world’s population (Sharma et al., 2021). Recent studies have
    investigated how ML can benefit the agricultural sectors by improving irrigation
    systems (Nemali and van Iersel, 2006, Liu et al., 2021). ML has been used to improve
    traditional ways of carrying out agricultural activities such as irrigation control
    and management (Tseng et al., 2018, Dahane et al., 2020, Torres-Sanchez et al.,
    2020). Indeed, ML has been employed to build intelligent data-driven models and
    provide the best solution for irrigation scheduling by learning the hidden relationship
    in datasets. The outcomes of the ML irrigation model can benefit farmers in numerous
    ways. ML algorithms can predict irrigation water requirements based on the study
    of evaporation processes through collected data and determine soil moisture variations
    over time. The soil moisture content can then be used as an indicator of when
    and how much to irrigate. This information can provide early intelligence to farmers
    to enhance their irrigation decisions. Currently, there are several ML methods
    available to predict irrigation water demand that have been applied in different
    farm settings. Liou et al. (2001) were among the first scholars who applied ML
    models, i.e., an error-propagation learning back-propagation neural network, to
    estimate soil moisture from simulated brightness temperature. In a sequence, Dibike
    et al. (2001) demonstrated the potential of support vector machine (SVM) to outperform
    artificial neural network (ANN) in remote sensing image classification and regression
    problems. Gill et al. (2006) used SVM to predict soil moisture in four to seven
    days ahead of time using historical data with forecasts that were quite comparable
    to the actual soil moisture measurements. In another study, Shrestha and Shukla
    (2015) utilized SVM to estimate crop evapotranspiration using lysimeter-based
    measurements for vine and erect crops to train the model. They found that the
    SVM model surpassed ANN and boosted the accuracy of FAO-56 crop evapotranspiration
    estimates by 4%. Soil moisture measurements became possible with the emergence
    of the Internet of Things (IoT) and the availability of enhanced and more accessible
    soil sensing and field communication technology (Kamienski et al., 2018, García
    et al., 2020). Major drawbacks of ML algorithms, however, are massive data requirement,
    black-boxiness, uncertainty associated with simulation(Tabas and Samadi, 2022),
    automatically deducing the features, and optimally tuning them for the desired
    outcomes (e.g., Windheuser et al., 2023). Overfitting and bias are two other common
    deficiencies in ML algorithms. Overfitting is a major issue in ML and occurs when
    a model cannot generalize well on unseen data during the testing period. Over-fitted
    models tend to capture all the trends in the data, including unavoidable noise
    on the training set, instead of learning the hidden relationship between features.
    The main causes of overfitting are noisy data, insufficient training data, and
    model complexities. In this review paper, we discuss existing opportunities to
    address these issues and provide a path for future ML research in irrigation decision-making.
    This review paper aims to (i) assess how ML has been used as an intelligent simulation
    model to promote water management in the irrigation sector, (ii) discuss the results
    of ML models applied in various agricultural water use simulation research, and
    (iii) highlight the limitations that hinder the effective performance of ML models
    in irrigation prediction and scheduling. By doing so, we discussed the applicability
    of various ML algorithms in irrigation management, articulated their weakness
    and strengths, and identified the knowledge gaps and the next steps to promote
    the application of these intelligent algorithms in irrigation scheduling. The
    remainder of this paper is structured as follows: Section 2 provides a brief introduction
    to ML as well as the most used algorithms in irrigation prediction. Section 3
    presents surveyed studies that used ML approaches in irrigation-related studies.
    Section 4 presents existing limitations in the use of ML models and how they can
    be addressed, Section 5 highlights different ways to add physics into ML models,
    while Section 6 discusses major results from developed irrigation tools. Section
    7 draws major conclusion of the paper. 2. Machine learning modelling concepts
    ML, defined as \"the study of computer algorithms that can improve automatically
    through experience and by using data\" (Mitchell, 2007), has been used in agriculture
    due to the increased availability of data and the need to improve traditional
    farming practices. IoT is an emerging technology that uses smart sensors and devices
    interconnected through the internet to collect data and transmit them to a server
    with no or limited human intervention. As such, it allows continuous monitoring
    and management of soil and climate conditions and promotes efficient farm management.
    ML and IoT enable big data collection and modeling, and farm machinery modernization
    that gives rise to precision agriculture, also known as smart farming. Precision
    agriculture is the use of up-to-date information technologies, smart devices,
    and software tools to support decision-making in agriculture (Pierce and Nowak,
    1999). It aims at increasing the farm’s profitability by reducing the cost of
    production while improving environmental sustainability. ML algorithms fall under
    three categories, as illustrated by Fig. 1: supervised learning, unsupervised
    learning, and Reinforcement Learning (RL) algorithms. In supervised learning,
    the developed model uses information from labeled inputs and outputs to find the
    functional relationships between them. Supervised learning can be used to predict
    categorical output values in which case a classification algorithm is used, on
    the other hand, if the value to be predicted is numerical, a regression algorithm
    can be used. In the unsupervised learning category, the learning algorithm uses
    unlabelled datasets to find the pattern that maps inputs to outputs. RL uses an
    agent to make a decision by interacting with the environment aiming at finding
    proper actions that maximize rewards and minimize penalties through trial and
    error. Deep learning (DL), a subset of ML, is also illustrated in Fig. 1. DL models
    can abstract features from high dimensional time series datasets and use multiple
    layers to progressively extract higher-level features from the raw input data.
    This review paper is mostly focused on broader ML models, even though some review
    examples of DL models for irrigation demand modeling are also provided. Download
    : Download high-res image (175KB) Download : Download full-size image Fig. 1.
    Different types of ML algorithms. Three key steps are followed in building ML
    models to perform prediction tasks (see Fig. 2). Firstly, the input data is pre-processed
    by carrying out data cleaning to remove noise and missing data using data transformation
    methods such as discretization or normalization. The model is then trained and
    calibrated with the training dataset to find the function that relates the inputs
    to the outputs by determining a set of parameters that give the best results (Mahesh,
    2018, Oden Technologies, 2023). After this process, a new dataset (validation
    dataset) is used to evaluate the performance of the model. Once an overall satisfactory
    performance is achieved, the model can be tested on an unseen dataset, the performance
    of the testing period determines ML''s ability to accurately perform a task based
    on the learned experience. Supervised learning and RL are recently used for irrigation
    water use modeling which are discussed in the following sections. Download : Download
    high-res image (201KB) Download : Download full-size image Fig. 2. The workflow
    of ML approaches for irrigation water use modelling. 2.1. Machine learning algorithms
    commonly used in irrigation scheduling Most ML algorithms for regression problems
    estimate a mapping function that can predict the output variables (Y) for new
    input data (X). Some popular examples of ML algorithms are Linear Regression,
    Random Forest (RF), Boosting Classifiers, Support Vector Machines, and Long Short-term
    Memory (LSTM). Here we briefly explain different ML models. Readers are referred
    to Kecman (2005), Kavitha et al. (2016), and Tabas and Samadi (2022) for more
    details on ML algorithms. 2.1.1. Random forest Inspired by the work of Amit and
    Geman (1997), Breiman (2001) introduced RF. RF is a collection of tree-structured
    classifiers {h(x, ѳk), k = 1,…} formed based on a set of input vectors (X = X1,
    X2, …, Xn) and random vectors (ѳk) sampled independently but with a similar distribution
    to find a prediction function (f(X)) that can accurately predict the variable
    of interest (Y). RF can be used to solve classification or regression problems.
    After multiple (k) runs, the majority vote of the predictions given by each tree
    is the answer for classification problems whereas the predictions'' average is
    considered the model output for regression problems. Fig. 3 illustrates the workflow
    of RF simulation. The accuracy of the prediction function is given by the loss
    function L (Y, f(X)) which is a measure of the closeness of f(X) to Y. Thus, the
    optimum prediction function minimizes the expected value of the loss function
    EXY (L, f(X)). Download : Download high-res image (137KB) Download : Download
    full-size image Fig. 3. The workflow of RF simulation. 2.1.2. Boosting classifiers
    Boosting is a type of ensemble method that builds a good performing model (strong
    learner) by adding up several models in an attempt to combine multiple simulations
    until an accurate prediction is achieved or a maximum number of models are added.
    This is done in a sequential learning process where each model learns from the
    errors of its predecessor and tries to correct them. Popular Boosting ensemble
    models include Adaptive boosting (Adaboost) and Gradient Tree Boosting (GTB).
    In the Adaboost, observations are weighted, and less weight is given to instances
    already well classified whereas those that are more difficult to classify are
    given more weight to be handled by new learners. GTB uses a loss function such
    as squared error to minimize the error as models are added up. 2.1.3. Long short-term
    memory LSTM is a type of recurrent neural network (RNN) developed by Hochreiter
    and Schmidhuber (1997). Unlike the traditional RNN, LSTM networks allow information
    to persist, thus managing the problem of the vanishing gradient in the traditional
    RNN. The LSTM has a hidden state known as short-term memory and an additional
    cell state, which is the long-term memory. The main attribute of LSTM networks
    is that they can remember information for a long time. Fig. 4 illustrates the
    structure of an LSTM network. As illustrated, the information flow is regulated
    by three gates; the forget gate determines if the information from the previous
    time step should be kept or forgotten, the input gate learns new information from
    the current time step and adds it to the cell, and the output gate that transmits
    the updated information from the current time step to the next one. Download :
    Download high-res image (82KB) Download : Download full-size image Fig. 4. The
    LSTM network structure. Xt is input, Ct-1 is memory cell, and h t-1 is hidden
    layer. The tanh function is used to regulate the values in the cell state. 2.1.4.
    Reinforcement learning algorithms RL is an ML approach where the algorithm learns
    how to map situations to actions by interacting with its environment to attain
    a goal. This continuous interaction with the environment forms a closed loop problem
    solving system where the selected actions depend on learned experience through
    a series of interactions with the environment and the rewards received per each
    action chosen (see Fig. 5). The goal of the RL algorithm is to maximize the cumulative
    rewards through the interactive feedback mechanism that differentiates RL from
    other ML algorithms. Download : Download high-res image (167KB) Download : Download
    full-size image Fig. 5. RL agent and its interaction with a physical environment
    (i.e., a farm system). RL uses a mathematical model, i.e., the Markov Decision
    Process (MDP), to solve a problem. MDP uses a property that enables the next state
    and reward to be computed given that the current state and action are known. More
    precisely, the agent interacts with the environment in a time sequence of discrete
    time steps. At each time step t, the agent receives the current state of the environment
    with S being the set of all possible states and then selects an action where represents
    actions that can be taken in state . Following the action taken, the agent will
    then be given a reward and the environment transits to a new state . The goal
    of the agent is to maximize the cumulative rewards received from the environment.
    The measure of the values of possible action “a” at state “s” pairs that can be
    taken by the algorithm is determined by a value function . This function can be
    optimized through a series of iterations to give the optimal state action pair
    that results in the highest reward at each time step. For complex environments
    with a high dimensional state-action space, the value function (Q-value) is not
    suitable for defining the reward of each pair. Consequently, a more advanced RL
    algorithm known as Deep Q-Network (DQN) consisting of a combination of Q-learning
    and Deep Neural Networks (DNN) is used to solve such complex problems. Instead
    of determining the cumulative reward based on the value function table, DQN leverages
    DNN to approximate the Q-values, the network takes the environment state as input
    and predicts the Q-values for each action. Focusing on RL applications in irrigation
    water use simulation, researchers define the state as actual observations to determine
    a sequence of optimal irrigation that is related to a farm’s environment such
    as soil moisture, crop growth status, and weather conditions. The agent, which
    is the learner and decision maker, is represented by the irrigation system while
    actions are the various choices made by the agent on the amount of irrigation
    water to apply. The reward function (R) is the profit made at the end of the season
    after the expenses associated with irrigating are covered and the goal of the
    agent is to perform a set of actions that maximizes this profit. 3. Literature
    review The literature review focused on collecting a wide selection of refereed
    journals from major publishers. A total of 56 publications were initially found.
    Among them, 16 studies were selected as they were more relevant to the application
    of ML algorithms in irrigation prediction and decision-making. These 16 studies
    are discussed as follows. Navarro-Hellín et al. (2016) were the first scholars
    to use Partial Least Squares Regression (PLSR) and Adaptive Fuzzy Inference Systems
    (ANFIS) to predict the weekly irrigation run time of three drip irrigated citrus
    plantations in Spain. The goal was to find the irrigation duration that maximizes
    the yield while optimally managing water. Using volumetric water content, soil
    water potential and crop evapotranspiration as input data, the predicted irrigation
    run time by the two models were evaluated against irrigation reports provided
    by an agronomist. Both models accurately predicted the irrigation pattern followed
    by the agronomist but ANFIS outperformed PLSR by giving a better estimation of
    weekly irrigation amount. Sun et al. (2017) developed a RL algorithm to perform
    irrigation planning and scheduling. A neural network was used to emulate DSSAT
    in predicting seasonal total soil water content using irrigation and weather information
    as input. A second neural network was then used to predict crop yield using the
    predicted total soil water content. The crop yield prediction was then used as
    the training data to train the RL model. Soil moisture and yield were predicted
    to train the model and find the optimal irrigation schedule that maximizes the
    net return (see Equation 1). The net return was then taken into consideration
    in the model to measure economic gain and adapt to future changes in the produce
    and water price. The model was tested by simulating maize planted fields in Temple,
    Texas, (USA), Kunnunurra (Australia), Hyderabad, (India), and for wheat yield
    prediction in Saskatchewan (Canada). The predicted total soil water results were
    used by an irrigation controller to apply an adaptive amount of water as needed.
    This technique enabled automatic irrigation and surpassed threshold and fixed-based
    irrigation in the tested locations by achieving a higher net return. The developed
    irrigation system addresses the dynamic and complex nature of irrigation scheduling
    and control by taking into consideration the current and future soil water content
    variations to adaptively optimize irrigation schedules which is a significant
    contribution to improved water efficiency in irrigation systems. Its limitation,
    however, is that it is restricted to a small total soil water space and is not
    suitable for large-scale problems (continuous soil water space). Furthermore,
    the proposed system has not been tested with actual field conditions, therefore
    its performance cannot be validated in real applications. Net return = yield (kg/ha)
    * price of product (dollars/kg) – water use (ha-mm/ha) * price of water (dollars/mm)
    Equation 1. Kumar et al. (2017) created a fully automated intelligent irrigation
    system based on IoT to gather temperature, soil moisture, and raindrop sensor
    data. The data collected is used by a microcontroller for analysis of the irrigation
    needs of several crops including beans, curry leaves, lady fingers, moringa, and
    radish. A motor is activated for irrigating the field when moisture values drop
    below a threshold range. Using recorded temperature and water flow data, a linear
    regressor is used to predict the next irrigation water requirement. The system
    then schedules irrigation based on the irrigation amount predicted by activating/deactivating
    a relay which in turn activates or deactivates a solenoid valve as needed. The
    linear regression model is updated in case there is a change in the data. The
    system also includes a mobile app that enables users to have access to field data
    remotely. The performance of the system was, however, not compared to other irrigation
    demand assessment approaches, nor did the authors specify how much water can be
    saved. This work contributed to advancing the automation of irrigation systems
    to enable remote monitoring and control. Its innovative incorporation of IoT technology
    with ML for water demand assessment and scheduling was a stepping stone for achieving
    better results in water use optimization with limited labor. Goap et al. (2018)
    developed a smart irrigation system based on IoT and ML techniques. A combination
    of sensor-collected field data such as soil moisture, soil temperature, Ultraviolet
    (UV) light radiation, and weather forecast data including precipitation, air temperature,
    and other variables, was used to compute future soil moisture based on which irrigation
    requirements were determined. The smart irrigation architecture consists of an
    IoT data collection system that collects, transmits, and processes sensor data
    and weather forecasts. A soil moisture prediction algorithm was developed as a
    combination of SVR and k-means clustering algorithms that calculate soil moisture
    change due to weather conditions. An irrigation scheduling algorithm then takes
    the predicted daily soil moisture, retrieves precipitation information to find
    the nearest day it is expected to rain, and computes the required soil moisture
    to maintain crop growth. If the required soil moisture is below the minimum threshold
    a command is sent to a relay switch to start the water motor and vice versa. A
    responsive web portal is used to view the projected soil moisture along with expected
    rainfall and to start or stop irrigation. The algorithm achieved a correlation
    coefficient and Mean Squared Error (MSE) of 0.56 and 0.135 respectively, when
    estimated soil moisture deficit (SMD) was compared to sensor-based SMD. The limitation
    of this work is that no water-saving analysis was performed to assess its potential
    against other systems. Additionally, the experiment was performed in a garden,
    so there is no record of its performance on a larger area such as a farm system.
    On the other hand, the study exemplifies how fully autonomous smart irrigation
    systems can be developed using sensor-collected data and weather forecasts to
    run ML algorithms and predict water demand. Concurrently, Goldstein et al. (2018)
    used regression and classification algorithms to build an ML model based on sensor
    and weather data to predict irrigation quantities for jojoba-planted fields in
    Israel as prescribed by an agronomist. These data were subdivided into eight subsets
    of different features to determine the accuracy of the models when inputs were
    changed. LR, Gradient Boosted Regression Tree (GBRT), and Boosted Tree Classifier
    (BTC) were used to estimate irrigation water demands. The models were evaluated
    on their ability to provide an irrigation value that is not more than 0.2 mm above
    or below the agronomist’s one. It was observed that LR performed unsatisfactorily
    giving a Root Mean Square Error (RMSE) equal to 0.466 and a performance accuracy
    of 52.3%. GBRT outperformed LR as the lowest RMSE was 0.11 and the accuracy rate
    reached 92.7%. The BTC algorithm also performed well with an accuracy of 95%.
    It was concluded that non-parametric models perform well compared to LR methods
    in cases where there is a non-linear functional relationship between the dependent
    and independent variables. The authors also observed that the model run with less
    input data (such as the model run without saturation/drought data) provided quite
    similar results to the model in which all the variables were used to train the
    model highlighting the fact that selecting appropriate features is more important
    in achieving satisfactory performance. In another study, Adeyemi et al. (2018)
    developed a predictive irrigation scheduling system using the Feed Forward Neural
    Network (FFNN) model and LSTM. A neural network (NN) model was used to predict
    the one-day-ahead volumetric soil moisture using historical soil moisture and
    climatic data. Based on the predicted soil moisture, crop water requirement, and
    soil water retention, the irrigation depth and timing were determined for a potato
    field. According to the obtained results, the two models performed comparably
    on the validation datasets and provided better predictions than those of a non-ML
    approach that estimates the soil moisture from the average of previously observed
    three-day soil moisture values. However, the LSTM model outperformed the FFNN
    model in terms of regression coefficient when datasets from different sites were
    used. This showed the robustness of LSTM networks in approximating the underlying
    functional relationship between inputs and outputs for situations similar to the
    learned ones. The LSTM model was coupled with AQUACROP to simulate potato crop
    growth and develop a predictive irrigation scheduling system whose goal was to
    maintain the soil moisture within a set of upper and lower boundaries during the
    simulation period. Given the predicted soil moisture, the deficit amount of water
    to reach the upper bound was computed and the irrigation amount was defined as
    the water depth needed to replenish the soil to attain the set threshold. The
    system was compared with a rule-based irrigation system, the former achieved a
    water saving of more than 20% in the three tested sites compared to the latter
    while maintaining the same water use efficiency. Using daily climatic data and
    daily irrigation amount collected in a period of one year, Perea et al., 2019
    developed a model to predict irrigation amount based on farmers’ decisions about
    when to irrigate. The crops grown in the area were drip-irrigated tomato and maize
    and rice, which was flood-irrigated. The purpose of the model was to simulate
    the occurrence of irrigation one day ahead as planned by farmers. This model was
    developed using DT and optimized using a Genetic Algorithm (GA) to find the optimal
    DT that accurately simulates farmers’ behavior. Based on the defined objective
    functions, three Classification Trees (CT; CT1, CT2, and CT3) were selected. The
    first CT (CT1) outperformed other DTs by accurately predicting all the observed
    irrigation and no irrigation events, achieving a performance accuracy of 100%
    in both cases. CT2 followed with an accurate classification of 73% of the irrigation
    rates and 93% of no irrigation rates. Lastly, CT3 was able to classify 68% of
    the actual irrigation rates and 93% of no irrigation rates. The developed model
    contributes to irrigation management by providing information on when to schedule
    irrigation and hence could help in better coordinating irrigation activities to
    minimize energy and water loss. Weekly irrigation amounts of orchards of citrus
    trees (orange, mandarina and lemon trees) located in Southeast Spain were predicted
    using a modelling system driven by LR, a random forest regressor (RFR), and SVR
    algorithms (Torres-Sanchez et al., 2020). These algorithms were trained to perform
    the irrigation assessment, as such the goal was to imitate the irrigation recommendations
    of an agronomist. Using the daily average matric potential of the previous five
    days, the total water needs, whether the fruit is gaining weight or not expressed
    as a binary value as input the ML models were trained to output the total irrigation
    amount recommended by the agronomists for the following week. The results were
    compared with irrigation prescriptions by agronomists. Results showed that RFR
    performs better than SVR and LR with an RMSE of 16.83m3, 17.13m3, and 19.5m3,
    respectively. A weekly average error of 9% was obtained when the predicted irrigation
    amount was compared with the agronomist’s report. To overcome the drawbacks of
    traditional RL models such as Q - Network (QN), Yang et al. (2020) proposed a
    deep Q - Network (DQN) to control irrigation scheduling. The difference between
    QN and DQN is that the former generates the value function table while learning
    from the data whereas the latter uses ANNs to compute the value function from
    multi-dimensional input data. Hence ANNs offer the possibility to handle a large
    amount of data and precisely render the irrigation scheduling problem more scalable.
    The environment was interfaced by AQUACROP, and simulations were conducted using
    three crops namely maize, wheat, and soybean. The state of the environment was
    described by the date, crop stage, precipitation, reference ET, total water content
    in the effective root zone, stomatal water content, and irrigation. Actions consisted
    of irrigation amounts from 0 mm to 10 mm with a 0.5 mm increment. Results demonstrated
    that the suggested algorithm outperformed traditional irrigation approaches such
    as constant irrigation, and percentage available water in dry, moderate, and wet
    weather conditions and was closest to the Q learning estimation for dry conditions.
    Coupling AQUACROP with DQN for irrigation scheduling allowed for a more comprehensive
    assessment of crop water demand by enabling the simulation of different crop growth
    scenarios based on the applied irrigation amount. This integration also addresses
    the data scarcity issue often encountered in ML modeling. The system was however
    not directly tested on the farm, the replication of results as far as implementation
    is concerned is thus not ascertained. To determine the right set of features to
    use for determining the irrigation scheduling of a drip-irrigated rice field from
    weather parameters based on ML, Sidhu et al. (2020) used correlation to identify
    the dependencies in the data and guide the selection of feature sets. Features
    with a correlation of 0.7 and above were discarded. The variables found useful
    and used as input features for irrigation scheduling were number of days after
    sowing, maximum temperature, dry bulb at 6:00 AM, humidity at 2:00 PM, soil temperature
    20 cm below surface at 2:00 PM, sunshine hours, wind speed, wind direction, ET,
    number of days since last rain and number of days since last irrigation. Among
    different algorithms used in their study, Decision Tree Regressor (DTR) and Adaboost
    outperformed other algorithms. As noted by Goldstein et al. (2018), LR was unable
    to perform well in predicting irrigation demand. It was also demonstrated that
    Adaboost could perform equally well with a limited number of selected input features.
    Zhou (2020) proposed an RL method that uses a Convolutional Neural Network (CNN)
    to estimate the value function used to train the DQN algorithm. The algorithm
    uses sensor-collected soil data such as moisture and humidity, air temperature
    and air humidity, leaf water potential, and leaf conductance collected from a
    grape-growing greenhouse plantation as input features to train the model. The
    system improved irrigation decision-making on the plantation with no human intervention.
    To overcome the limited learning capability of some previously developed ML models,
    Kashyap et al. (2021) created a Deep Learning Intelligent Irrigation System for
    precision Agriculture (DLiSA) based on NN and IoT-enabled approaches that account
    for climate and soil moisture variations. The system comprises the one-day-ahead
    soil water content predicted by an LSTM model, an irrigation scheduler to compute
    the volume of irrigation water, and an irrigation planner to calculate the duration
    of the irrigation period and the water delivery across the field. Irrigation commands
    are then passed to the actuator nodes from which they get to the water valves.
    The particularity of this system is that it integrates feedback from climate and
    soil sensors which enables it to adapt to local changes and perform well during
    historical periods. A comparison of this irrigation system with those obtained
    with a threshold-based irrigation model and an FFNN showed that 43% and 23% of
    water volume, respectively are saved using DLiSA. Jimenez et al. (2021) used LSTM
    with soil matric potential (SMP) collected at three soil depths (i.e., 150, 300,
    and 600 mm), rainfall, and irrigation amounts as input data to predict irrigation
    schedules during a corn-growing season for sandy clay loam and loamy fine sand
    soils for 1, 2, 3, 6, 12 and 24 h in advance. In addition, three different LSTM
    models were developed by changing inputs to evaluate the predictability of LSTM
    networks concerning the input data. The input data used for the first model were
    SMP at 150-, 300-, and 600-mm soil depths, management zone, rain, and previously
    applied irrigation; the second model used SMP and management zone, whereas the
    third model only used SMP as input. The results indicated that the same error
    and predictability level obtained for the first model can also be obtained using
    only SMP data. In terms of temporal models’ performance, the 1-hour ahead irrigation
    predictions were accurately predicted the same as the three and six hours-ahead,
    but the accuracy gradually decreased for irrigation predictions of 12- and 24-hours
    advance causing overfitting or underfitting. Nevertheless, it was concluded that
    irrigation prescriptions changes can be accurately forecasted on time by LSTM.
    The authors also noted that using rainfall and irrigation data as input caused
    overfitting in the testing period. This is because rainfall patterns change over
    time and those rainfall amount fluctuations might be unknown for the model. Y.
    Chen et al., 2021 combined several classifiers to form a strong irrigation predicting
    approach using stacking and boosting ensemble learning methods. The model was
    developed to predict irrigation volumes for multiple fields in a greenhouse of
    organic vegetables. Air temperature, air humidity, soil temperature, soil humidity,
    and light intensity data were used as input variables to linear SVR, Support Vector
    Classification (SVC), RF, and DT. Model performances of 0.45, 0.675, 0.645, and
    0.54 were obtained for each model, respectively. Stacked generalization was employed
    to combine the advantages of these algorithms using extreme gradient boosting
    (XGBoost) which improved the performance from 0.58 to 0.64. The best performance
    was obtained when simulated and observed water volumes were compared with 3.33
    and 8.16 for the MAE and RMSE, respectively. Concurrently, Deep Q learning was
    implemented by M. Chen et al., 2021 to perform irrigation scheduling for paddy
    rice using short-term weather forecasts. The input features defining the field
    environment on a daily basis consisted of one week forecasted rain sequence, water
    depth as well as minimum and maximum thresholds of water depth and the maximum
    allowable water depth where the maximum allowable water depth and the maximum
    threshold are determined based on the growth stage. The three irrigation actions
    that are defined to irrigate were no irrigation, supplying 50% or 100% of the
    water needed to attain the maximum water depth. Results showed that no yield losses
    were experienced in the studied period. The DQN was able to consider current field
    water conditions and weather forecasts to efficiently choose to irrigate or delay
    irrigation in order to avoid under or over irrigation which resulted in water
    conservation and increased rainfall use. Comparing irrigation with the flooded
    irrigation strategy, the DQN method reduced water use by 23 mm. This research
    demonstrates how advanced computational techniques based on ML can enhance irrigation
    prediction. By applying weather forecasts in crop water demand assessment to limit
    unnecessary irrigation, more water is conserved compared to conventional irrigation
    methods. The study also underscores the ability of the applied algorithm to optimize
    water despite imperfect weather forecasts thanks to its ability to learn from
    past irrigation experiences and weather forecast uncertainties. More recently,
    Alibabaei et al. (2022) trained a DQN to schedule and optimize irrigation for
    a tomato field. The state of the environment was expressed by a combination of
    average temperature, average relative humidity, precipitation, reference evapotranspiration,
    average wind speed, total soil water in profile, and irrigation amount. Actions
    consisted of irrigation amounts ranging from 0 to 60 mm - ha/ha. The agent environment
    was simulated by two LSTM models. One was to predict the one-day soil moisture
    in advance and the other was used to approximate the seasonal harvest based on
    the growing season environmental conditions and then determine the net return.
    To estimate the Q-table, an ANN, an LSTM, and a CNN were used. LSTM surpassed
    other algorithms because it memorized previous input data and used the retained
    information in the subsequent time steps. The results achieved by the developed
    algorithm showed an increase in the productivity in the test field and a reduction
    of irrigation water in comparison to threshold-based and fixed irrigation by 18%
    to 30%. The crucial finding of this study that showcases the strength of ML models
    is the ability of the developed irrigation system to adapt irrigation scheduling
    to the crop growth stages. At the beginning of the season, the system avoids water
    losses by adopting a lower water supply scheduling which gradually increases as
    the season progresses and eventually reduces to stress the plants towards the
    harvest period. This ensures that enough water is available to sustain the plants
    during the critical growth period and minimizes water losses at the start and
    end of the season. The surveyed studies illustrate the ability of ML algorithms
    to make use of data from different sources including weather forecasts, to assess
    crop water demand and predict irrigation schedules in a more efficient way that
    optimizes water use compared to conventional approaches. The attained water efficiency
    is shown by the amount of water saved as opposed to traditional fixed period or
    threshold value irrigation techniques that do not account for spatial-temporal
    changes in soil, crop, and meteorological variables. With the real-time data acquisition
    approaches enabled by IoT and the progress made in coupling IoT with ML models
    as applied and demonstrated in the several presented studies, ML algorithms hold
    great potential for automating the irrigation decision-making process. This will
    improve further timely irrigation scheduling and eradicate the additional work
    of manually controlling irrigation systems. Applying ML models in irrigation decision-making
    and scheduling is also economically beneficial as the crop water waste, the cost
    of water, and labor demand are minimized. Table 1 summarizes the reviewed studies,
    the algorithm used, and the obtained model performance. Table 1. ML based irrigation
    studies reviewed in this paper. Reference Aim Input data Functionality Crop Model
    (s) Performance Sun et al. (2017) RL-based irrigation control system for the optimization
    of net return Soil water content, ET, rainfall Total soil water content Maize
    and wheat 1st NN ML method outperformed threshold based and fixed irrigation by
    46.7% and 59.8% on average net return, respectively TSW, irrigation crop yield
    2nd NN Predicted crop yield Irrigation planning and scheduling QN Kumar et al.
    (2017) Automatic monitoring and control of irrigation Temperature, soil moisture,
    and rainfall Irrigation requirement forecasting beans, curry leaves, ladies finger,
    moringa and radish LR Not mentioned Perea et al. (2019) Emulate farmers’ irrigation
    decisions Climate data and irrigation amount Simulation of irrigation occurrence
    1 day ahead Tomato, maize and rice DTs 68-100% irrigation events are positively
    predicted. Kashyap et al. (2021) ML models in unpredictable climates Soil moisture
    and climate data 1 day ahead soil moisture, variation of water application spatially,
    irrigation period Grassland, farmland and arable LSTM Saved up to 43% volume of
    water compared to threshold-based irrigation. Adeyemi et al. (2018) soil moisture
    at 3 sites of different soil types Soil moisture, climate data, rain data, irrigation
    irrigation amount prediction using 1 day ahead soil moisture forecast potatoes
    LSTM 46, 20, 31% of water saved at each site Goap et al. (2018) Possible soil
    moisture values prediction to aid in irrigation planning soil moisture and temperature,
    UV light radiation and weather forecast Computation of soil moisture changes and
    irrigation scheduling garden SVR and k-means R2 = 0.56 MSE = 0.135 Goldstein et
    al. (2018) Weekly irrigation scheduling forecast as determined by an agronomist
    Soil moisture and weather data Irrigation recommendation jojoba LR, GBRT and BTC
    Success rate- GRBT= 93% Success rate- BTC= 95% Success rate- LR= 52.3% Torres-Sanchez
    et al. (2020) Predictions capabilities of several learning models with experts’
    decisions Daily average of SMP, total water needs, applied water 1 week before,
    crop growth stage 1-week irrigation amount prediction of orchards Citrus (Orange,
    mandarin and lemon trees) RFR, SVR and LR RMSE-RFR= 16.83 m3, RMSE-SVR= 17.13 m3,
    RMSE-LR= 19.5 m3 Sidhu et al. (2020) Traditional ML methods for irrigation scheduling
    Weather and soil variables Predict rice water demand rice LR, SVR, RFR, DTR, Adaboost,
    GBR and NN Best performance was obtained with Adaboost; MSE= 125.79, R2 = 0.79
    Accuracy= 71% Yang et al. (2020) Irrigation scheduling approach with deep learning
    AquaCrop simulations, and weather data DRL irrigation scheduling model Maize,
    wheat and soybean QN, DQN Highest net return obtained for corn and wheat; second
    highest return obtained for soybean Jimenez et al. (2021) Irrigation prescriptions
    requirement SMP, irrigation management zone, rainfall, and irrigation irrigation
    amount prediction for 1, 3, 6, 12 and 24 h ahead corn LSTM R2 = 0.82 - 0.98 for
    1 h ahead prediction Y. Chen et al., 2021 Irrigation volumes prediction Air temperature,
    and humidity, soil temperature and humidity, light intensity Irrigation volumes
    vegetables SVR, SVC, RF and DT SVR= 0.45 SVC= 0.675 RF= 0.645 DT= 0.54 M. Chen
    et al., 2021 Irrigation decision making based on weather forecast Rainfall forecast
    and water depth in the field Irrigation scheduling early, middle and late rice
    DQN Reduced irrigation water by 23 mm on average and reduced drainage water by
    21 mm Alibabaei et al. (2022) Irrigation optimization Climate data, irrigation
    amount, total soil water in profile Irrigation scheduling tomato DQN Decreased
    irrigation amount by 20 – 30% 4. Current limitations of machine learning application
    in irrigation water use modeling 4.1. Data scarcity The performance of ML models
    highly depends on the availability of sufficient data to accurately learn the
    underlying relationship between the predictors and the variable to be predicted.
    Due to the high variability of soil and climatic conditions in space and time,
    data should be available at a fine spatial-temporal resolution for proper results
    to be obtained. Data availability is often a challenge as the collected data by
    sensors such as soil moisture, are point measurements and hence do not represent
    the entire field’s conditions. To obtain representative information about the
    field’s conditions and improve the performance of ML models, many sensors need
    to be installed across the field which can be expensive. In addition, satellite-derived
    data can be useful for irrigation prediction but often are not available at the
    field scale. Satellite data can be an alternative source of data, however, the
    frequency at which data is collected is usually low due to orbital paths. The
    collection of good-quality satellite data is also hindered by the effect of canopy
    or cloudy atmospheric conditions which leads to significant data gaps. Moreover,
    the spatial resolution of these data is sometimes not satisfactory. For instance,
    the presently operating soil moisture products are available at a coarse resolution
    that cannot be directly used in irrigation prediction at the field level if not
    downscaled (Zhang et al., 2021). On the other hand, downscaling data adds more
    uncertainties that can compromise the modeling results. The data scarcity problem
    can be addressed by integrating remote sensing and field sensors’ collected data
    to increase the reliability of simulated results. In the event of low sensor coverage,
    satellite-based measurements can help bridge the spatial-temporal data gap. Satellite
    data such as soil moisture, surface temperature, Leaf Area Index (LAI), etc. can
    be used to supplement sensor data in modeling field conditions after carefully
    downscaling the data to the field level. Satellite-based measurements can also
    be used to validate sensor-measured data by detecting outliers. Having a complete,
    reliable dataset would considerably improve the performance of ML models and allow
    farmers and Extension irrigation specialists to make more informed irrigation
    decisions. Furthermore, most models use soil moisture-based irrigation scheduling
    methods; thus, soil moisture is commonly used as an indicator of crop water stress.
    However, plant water stress-related indices can also be useful predictors to assess
    irrigation demand (Jones, 2004, Gu et al., 2020) but no significant work has been
    done to build ML models for irrigation predictions using these variables. Thus,
    data of either plant-water status, such as measurements of leaf/stem/xylem water
    potential and leaf thickness, or plant physiology, such as sap flow measurements
    by sensors, stomatal conductance, and plant thermal sensing, can potentially enhance
    data availability and irrigation prediction accuracy. In addition, data augmentation
    techniques have been proven to remediate the data scarcity problem. Specifically,
    image data can boost the performance of ML models in irrigation modeling and applications.
    Data augmentation techniques are mostly applied in crop-weed classification (Fawakherji
    et al., 2020, Su et al., 2021, Divyanth et al., 2022, Espejo-Garcia et al., 2023)
    and plant disease diagnosis (Wu et al., 2020, Cap et al., 2022, Huang et al.,
    2022) Data augmentation involves implementing a sequence of methodologies to generate
    new images from the existing image dataset. Data augmentation techniques fall
    into three categories; the first class involves basic augmentation techniques
    that increase the size of a dataset by changing the geometric position of points
    in an image hence generating a new data point examples of this technique are geometric
    transformations such as scaling, rotating, and skewing images. Noise injection
    techniques such as Gaussian or uniform noise are also common techniques to increase
    data samples. They entail adding noise to data to increase the variance. The deformable
    augmentation technique is the second category of data augmentation techniques
    that can be used when the basic techniques do not provide satisfactory variability
    and include methods such as spline interpolation, which uses a piecewise polynomial
    function to interpolate a new data point between two observed points. Using statistical
    shape models is another advanced method to generate new data by using observed
    data and a mathematical model to understand the dataset’s variability and implement
    changes within the limit of possible parameters. The third category of data augmentation
    techniques is generative DL techniques. These approaches increase the volume of
    data by learning features in a dataset to generate synthetic but realistic datasets.
    The most common DL networks are generative adversarial networks (GAN) and their
    variants. Adversarial learning refers to the contest between two NNs, a generator
    and a discriminator. The generator learns to generate new data such that the distribution
    of the generated data is as close as possible to that of the observed data. The
    discriminator, on the other hand, learns to evaluate the generated data and differentiate
    them from authentic data. In addition to increasing the sample size, these techniques
    reduce overfitting by introducing new patterns in the data that can make a model
    more generalizable. 4.2. Noisy and heterogeneous data Data is the foundation of
    every ML project. Hence, preprocessing data prior to their use is an important
    step to ensure data quality and reduce the possibility of defective data that
    hinder model efficiency. Data noise and heterogeneity are the common issues encountered
    during data collection and preprocessing. Raw data contains numerous flaws such
    as missing values, incorrect values, and incorrectly formatted values that introduce
    noise to ML. Directly feeding such data to ML models is inappropriate as they
    may fail to derive the right pattern. Poor data quality can thus lead to significantly
    unsatisfactory performance. Data should be machine-readable, trustworthy, and
    impartial. By ensuring data is correctly classified, data curation can assist
    ML model developers in validating the diversity of training data for irrigation
    modeling applications. Therefore, it is important to statistically analyze and
    understand the data and select suitable methods for removing noise and bias in
    the data. To counteract the substantial bias that data preprocessing methods may
    induce in predictions, it is recommended that maximum entropy constraint be applied
    on the inference step (Pfeiffer et al., 2015), forcing predictions to have a distribution
    similar to the one of observed values. Although data sparseness might persist
    and perhaps be exacerbated by big data, the volume of big data presents exceptional
    prospects for predictive analytics because sufficient frequency may have been
    achieved for diverse sub-samples. On-farm big data are in divergent formats, from
    distinct population samples, and so are very heterogeneous. It can be very tedious
    to transform heterogeneous data into a uniform format. In addition, these heterogeneous
    data may be of different levels of importance in the learning process (Zhou et
    al., 2017). Therefore, adding all the features and giving them equal weights in
    ML models is unlikely to lead to optimal learning results. 4.3. Lack of accessibility
    and reproducibility of data and machine learning models Irrigation data is part
    of large earth system datasets that are produced at the farm scale; however, the
    majority of this data is not openly shared and is unavailable. Other irrigation
    metadata are put into password-protected and key-value data structures that limit
    their findability and accessibility significantly. Open access to data should
    be improved to better serve irrigation scheduling applications (Gu et al., 2020).
    Open data advances research by preventing duplicate data collection efforts freeing
    up resources to gather a more distinct collection of data and a more comprehensive
    record of observations. Secondly, open data regulations promote increased data
    usage and reuse. For example, after enacting the Landsat open and free data policy,
    data downloads increased by 20 times from 2009 to 2017, and, according to the
    annual number of publications, data use increased by four times (Z. Zhu et al.,
    2019). Advancing research is not solely limited to making data readily available
    but also requires the availability of developed software. Providing open access
    to software’s source code allows computational and scientific transparency and
    reproducibility. Scientific reproducibility is evasive if free access to code
    is restricted. Gil et al. (2016) argued that simply providing textual explanations
    of algorithms and code implementation may hamper reproducibility. Moreover, open-source
    software favors software reuse which reduces duplication possibilities, promotes
    the use of open data, and guarantees the code’s lifespan (Committee on Best Practices
    for a Future Open Code Policy for NASA Space Science, 2018). A rising recognition
    of the necessity of making data more findable, accessible, interoperable, and
    reusable (FAIR; Wilkinson et al., 2016) has set a standard for expanding the availability
    of research standards and tools that ease data sharing and management (Wagner
    et al., 2022). FAIR principles imply that data and tools must be easily findable,
    freely obtainable, and reusable so that methodology and derived results can be
    entirely transparent (Koymans et al., 2020). Data and tools can be findable when
    they are sufficiently described by rich metadata and registered or indexed in
    a known and accessible searchable resource. Accessibility means that users and
    machines, following appropriate authorization and via a well-defined protocol,
    can obtain data and the related tools. For data and tools to be interoperable,
    they should be described using normative and community-known specifications. Reproducibility
    is another aspect of the FAIR principle that received less attention in the irrigation
    community. Reproducibility necessitates describing in detail the characteristics
    of the data and tools, and their origin according to community standards with
    clear and accessible conditions for usage (Boeckhout et al., 2018). At a minimum,
    ML modeling outcomes should be reproduced and ideally replicated by other users
    before it is deployed. Currently, farm-related data, including irrigation, soil
    moisture, and climate information, are not based on the FAIR principles, nor their
    metadata format and terminology are constrained by these guidelines. To move towards
    a FAIRer future that boosts the availability of farm-related data and tools, continuous
    generation of FAIR metadata standards and reproducible tools are indeed needed
    for future data-driven applications in irrigation modeling. Towards this end,
    scientific communities can adopt several best practices, namely making their data
    and ML algorithms accessible in a public cyberinfrastructure and in a non-proprietary
    standardized format, creating a digital object identifier for their data and tools,
    and providing clear licensing information along with constraints on the use. To
    encourage reusability, software and code should also be openly available through
    a non-restrictive license adopted by the community to facilitate reproducibility.
    4.4. Blackboxness of machine learning models The explainability and interpretability
    of ML models are another aspect of ML that has been questioned in the past (Kaur
    et al., 2020, Moraffah et al., 2020). Enhancing models’ predictability comes at
    the cost of increasing their complexity which often makes them less interpretable.
    However, the interpretability of ML models is more important than their accuracy
    (Rudin, 2019). For example, to trust the irrigation recommendations provided by
    a model, irrigation specialists and crop consultants would be more interested
    in knowing the accuracy of irrigation recommendations for a certain scheduling
    time than in the structure of the algorithms and the types of performance metrics
    used in the model. Explainable ML has initiated a set of methods to increase the
    interpretability and explainability of ML models (Carvalho et al., 2019, Miller,
    2019). In the agricultural domain, these techniques have been applied in several
    prediction tasks such as crop yield estimation (Sihi et al., 2022, Wolanin et
    al., 2020), prediction of daily pan evaporation and evapotranspiration (El Bilali
    et al., 2023, Zhao et al., 2023) and in monitoring fields’ conditions for optimizing
    crop production (Sabrina et al., 2022). To interpret the results of a model, the
    current ML approaches aim to evaluate the effects of various combinations of input
    variables on the results by applying techniques such as Shapely Additive exPlanations
    (SHAP) that can assess the pros and cons of an input feature on the model output.
    Local Interpretable Model-agnostic Explanations (LIME) is another popular technique
    applied to make ML models’ results human interpretable by estimating the behaviour
    of a complex model, it consists of adding noise to a data point without changing
    the rest of the dataset, fitting the new dataset to the model, and observing the
    behaviour of the model (Ribeiro et al., 2016). To the best of our knowledge, these
    approaches have not yet been adopted in explaining irrigation predicting models;
    there is, therefore, room to improve the understanding of these models by incorporating
    such techniques into the current ML modelling structures. 4.5. Lack of human interaction
    with machine learing-based irrigation modeling Although considerable effort has
    been made to develop irrigation decision-making models, current models lack a
    way to integrate expert knowledge into the simulation process. The limited success
    of these models is partly because the decision rules used in the models are limited
    in scope than the factors growers use to make decisions (Car, 2018). Researchers
    mostly create models that can tackle agricultural problems without the need for
    human interaction. Unfortunately, a majority of existing models have not yet reached
    this degree of intelligence. Due to calculation time constraints and the complexity
    of agricultural problems, models may provide imprecise irrigation recommendations.
    As a result, agricultural knowledge from experienced irrigation specialists, Extension
    professionals, and experienced farmers can be employed in the model to improve
    the feasibility of ML outcomes and validate the results. An interactive interface
    that allows professionals to share their knowledge and perspectives can be an
    approach to considering expert judgment. Another way to allow human control over
    ML models is to develop systems that enable human-in-the-loop feedback and interactions.
    The effective application of ML models in irrigation scheduling systems requires
    that humans control their outcomes to minimize the risk of lethal results. Efficient
    human control is the capability to incorporate human knowledge into the modeling
    process to make informed, timely decisions that provide the greatest operational
    outcomes possible (Boardman and Butcher, 2019). ML systems must create models
    that take into consideration a range of contextual data in order to function well
    in complicated settings (National Academies of Sciences, 2021). This allows the
    systems to make decisions by accurately understanding the current situation and
    projecting future scenarios. However, human-in-the-loop techniques need to be
    developed to ease the collaboration between ML models and irrigation experts such
    as Extension irrigation specialists and experienced farmers. This will help align
    goals and synchronize task prioritization, resource allocations, and improved
    irrigation decisions. 4.6. Uncertainty and error in machine learning simulation
    Although ML techniques for irrigation decision-making were proven to be helpful
    in irrigation planning, all the reviewed papers did not take into consideration
    the errors and uncertainties in the predictions. Uncertainty in irrigation modeling
    stems from the continuously changing environment, such as meteorological conditions
    and soil moisture variations. The lack of uncertainty quantification in the ML
    predictions may result in overfitting or underfitting outcomes. Considering ML
    predictions without assessing the extent to which results are credible given the
    associated uncertainties in the input data and model often leads to inappropriate
    or biased decisions. For example, if the input data fed to a model trained to
    predict the irrigation amount lies outside the training data distribution, the
    model may generate unreasonable irrigation recommendations that are essentially
    based on an “educated guess”. But, if the prediction is accompanied by confidence
    intervals that is the certainty the model itself has of its prediction, the decision
    taker would be informed of this randomness and decide on the irrigation amount
    accordingly. Thus, an assessment of uncertainties in the simulated results is
    crucial to ensure that the results fall within a certain level of confidence.
    Generally, uncertainty can arise from input data and the ML procedures or structure
    in the modeling process. There are two types of uncertainties, (i) epistemic uncertainty
    resulting from the ML architecture choice and model parameters and (ii) aleatory
    uncertainty due to a physical system’s intrinsic randomness. Aleatoric uncertainty
    describes the inherent randomness of the data-generating process, which cannot
    be justified by gathering additional data samples or observations (Kendall and
    Gal, 2017). This form of uncertainty is caused by unknown processes that pertain
    to the concept of randomness, i.e., the unpredictability in modeling outcomes.
    Aleatoric uncertainty can further be subdivided into homoscedastic and heteroscedastic
    uncertainties. Homoscedastic uncertainty is independent of ML inputs, which means
    that it remains consistent regardless of input. Because this sort of uncertainty
    produces uniform variances for all inputs, the variation in observation noise
    for all input parameters is constant (Tabas and Samadi, 2022). On the other hand,
    heteroscedastic uncertainty varies with datasets, where some inputs provide more
    noisy outputs than others. Aleatoric uncertainty does not increase for out-of-distribution
    data contrary to epistemic uncertainty that can be handled in the modeling process
    if sufficient training data is available. Epistemic uncertainty may increase during
    the testing period for those data points that lie outside the training dataset.
    Thus, the larger the training dataset the lower the epistemic uncertainty. Modeling
    these two types of uncertainties increases the predictive performance of models.
    Understanding how individual sources of uncertainty propagate to the integrated
    irrigation system response is useful in analyzing the impact of data and model
    uncertainty on the simulated results. Additionally, distinguishing these uncertainties
    helps understand the sources of errors that have the potential to be reduced.
    Differentiating them also makes decision-making transparent and helps in making
    more informed (irrigation) decisions as unreduced uncertainties are clear and
    known (Der Kiureghian and Ditlevsen, 2009). Uncertainty estimation methods can
    be classified into four categories namely single deterministic methods, Bayesian
    approximations, ensemble learning, and test-time data augmentation methods. The
    most widely used methods are Bayesian approximations such as Monte Carlo dropout,
    Markov Chain Monte-Carlo (MCMC) optimization methods (Duane et al., 1987), Bayesian
    Model Averaging (Samadi et al., 2020), and ensemble learning methods such as deep
    ensemble, Bayesian deep ensemble, and Dirichlet deep networks (Abdar et al., 2021).
    Largely, data uncertainty for a normally distributed uncertainty can be measured
    by predicting the parameters of a probability distribution for instance the mean
    and standard deviation (Kendall and Gal, 2017, Lakshminarayanan et al., 2017).
    These approaches can be coupled with ML-based irrigation water use modeling to
    reduce errors and uncertainty during both training and testing periods. However,
    to efficiently reduce uncertainty in ML modeling, rigorous tests of the suitability
    of different irrigation process parameterizations and model parameters are needed
    across different model development stages as well as various testbeds and farm
    settings. 5. Physics-guided machine learning (PGML) PGML offers a compelling solution
    to improve irrigation decisions and the interpretability of ML models. The interactions
    between plants, the soil, and the environment are complex and require a wide range
    of physical processes to be accurately programmed and described in space and time
    by a data-driven model. PGML provides an opportunity to leverage the best attributes
    of both data and physical processes in the ML models (Shen et al., 2018). Combining
    physical processes with data-driven capabilities can be performed in a variety
    of ways. Approaches to incorporate physical principles into ML models involve
    constructing new ML architectures that can employ some physical laws and processes
    in the irrigation water use prediction. These improvements are possible because
    ML models are modular and versatile. Scientific knowledge can be utilized to define
    node links that capture physics-based correlations among variables. Another method
    for infusing established physical properties into an ML architecture is to assign
    physical significance to some neurons in the network by incorporating physical
    intermediate variables into the network (see Fig. 6). Daw et al. (2020), for example,
    implemented these two approaches in LSTM for lake temperature modeling by introducing
    physics-informed connections among neurons in the network. Furthermore, they added
    physical significance to some of the network’s neurons by calculating physical
    intermediate elements along the network’s route hence creating a unique physics-guided
    LSTM structure. Another related method is to set some of the neurons’ weights
    to physically meaningful values or parameters and make them constant throughout
    the ML training process. Download : Download high-res image (103KB) Download :
    Download full-size image Fig. 6. Physics guided architecture of ML (adapted from
    Daw et al., 2020). Another point of view, however, tackles the challenge of embedding
    prior knowledge in an ML from a different perspective. Currently, rather than
    creating a specific model structure that indirectly imposes prior knowledge, endeavors
    are being made to enforce physics-constrained learning by encoding appropriate
    partial differential equations (PDE) into the loss function of ML approximations
    utilizing methods such as automated differentiation, (see for example Sirignano
    and Spiliopoulos, 2018; Raissi et al., 2019; Y. Zhu et al., 2019; Geneva and Zabaras,
    2020). This approach comprises a double learning process, where an algorithm learns
    to concurrently match the observed data and to produce outputs that approximately
    meet a specific set of physical laws such as energy and mass conservation. Constraining
    the optimization of data-driven models is a natural way to include domain knowledge
    in the process of learning, and by doing so physically implausible predictions
    can be avoided. For problems where linear equations can be used to describe physics-based
    constraints, integrating the latter in existing constrained optimization formulations
    is straightforward. However, many agricultural problems involve complex non-linear,
    and dynamic processes. For instance, simulating crop yield as a function of numerous
    inputs such as irrigation timing and amount, plant cultivar, and soil hydraulic
    properties have constraints that are expressed in complex formulations such as
    non-linear relationships between variables or PDE which are not effectively treated
    by conventional constrained optimization approaches. In this case, it is crucial
    to form constrained optimization methods that can use common PDE forms and can
    handle the non-linearity of physical variables. 6. Discussion This paper reviewed
    16 studies that were relevant to the application of ML in supporting irrigation
    decision-making. The goal was to identify ML algorithms commonly used to build
    systems supporting irrigation decision making, analyze developed systems based
    on these algorithms and discuss their performance and limitations as ways to improve
    irrigation water use management. We observed that the input data for soil and
    weather-related parameters used to train the developed models were obtained mainly
    from sensors distributed across the study areas. Therefore, wireless sensor networks
    and IoT technologies have played an important role in enabling the application
    of ML models in irrigation water use modeling. However, careful selection of input
    features is crucial to obtain a good model performance. While it is important
    to critically select the input data, it was demonstrated by Goldstein et al. (2018)
    and Jimenez et al. (2021), that having many input variables to predict irrigation
    demand does not imply having a better model. More than half of the reviewed papers
    used simple ML algorithms such as LR, RF, SVM, DT, etc. which sometimes do not
    accurately simulate the relationship between the plant and its environment, especially
    for high-dimensional datasets. As stated by Goldstein et al. (2018), Torres-Sanchez
    et al. (2020), and Sidhu et al. (2020), due to the non-linear relationships among
    soil, weather variables, and crop water requirement, linear regression models
    do not perform well because they cannot accurately learn the underlying functions
    and data patterns that relate the input to output process. Therefore, in crop
    water requirement prediction, the algorithms that can simulate the non-linearity
    between the inputs and outputs are recommended. Ensemble learning methods such
    as Adaboost and GBRT provide a way to improve the predictability of ML models
    and have demonstrated good performance in predicting irrigation management over
    algorithms such as LR. According to the results of Alibabaei et al. (2022), LSTM
    networks perform better than other algorithms because they can make use of the
    retained information from previous time steps in the following ones to provide
    better predictions. Hence, they have proven to be robust and able to accurately
    simulate the relationship between the dependent and independent variables when
    data sets from new sites are used. We postulate that PGML can be a better approach
    to modeling the interlinkage between the soil, plant, and climate variables. Moreover,
    these interactions vary extensively in time, distance, and region and physical
    attributes can better describe these variabilities; thereby incorporating physics
    into the ML algorithms can justify these interlinked processes and parameter choices
    for which reliable values can be obtained. On one hand, it was observed that ML
    approaches have shown the potential to support irrigation decision-making and
    reduce the time spent by agronomists on analyzing a large quantity of data to
    determine irrigation water requirements. On the other hand, ML models require
    a wide range of data in space and time which are often not readily available.
    To overcome this challenge, additional data sources were discussed and data augmentation
    methods such as GAN are proposed as approaches to generate new data. However,
    both data and model uncertainty should be addressed in data-driven crop water
    demand modeling. We observed that there is a lack of both aleatoric and epistemic
    uncertainties assessments in all the surveyed studies, yet these uncertainties
    affect considerably the simulation results and, subsequently. the reliability
    of the developed systems. Additionally, there is still a lack of incorporating
    agronomists’ knowledge in the irrigation decision-making process. To bridge this
    gap, human-in-the-loop approaches to enable interactions between farmers and ML
    models should be explored in the future. Lastly, to widen the adoption of the
    ML-based irrigation decision-making systems, we recommend the implementation of
    FAIR principles in irrigation modeling as has been the case for other disciplines
    such as ecological and environmental modeling (Petzold et al., 2019, Quay et al.,
    2021) and water science simulations (Crystal-Ornelas et al., 2022, Cannon et al.,
    2022). For ML-based irrigation decision-making models to have an impact on water
    sustainability and management, data and the resulting tools must be openly accessible,
    easily findable, and reusable. 7. Conclusions This review highlights the outcomes
    of ML based irrigation scheduling models applied in different geographical, farm
    and crop settings. We discussed the current state-of-the-art models and proposed
    several approaches that could complement data-driven irrigation modelling. To
    summarize, the reviewed studies provided promising outcomes for irrigation scheduling.
    As we make progress in data-driven simulation, we expect to gain a new understanding
    of the relative importance of the choice of different neural network architecture
    and their workflow and structure that drive decisions and actions. The review
    analyses presented herein are intended to provide a basis for data-driven irrigation
    scheduling applications across different environmental and geographical settings.
    Further research is, however, needed to ensure the effectiveness of developed
    ML models and their applicability in farms with different soil, weather, and crop
    characteristics. Recognizing a growing enthusiasm for data-driven modeling applications
    in irrigation scheduling, we anticipate growth on several facades: (i) a better
    ML model capable of forecasting irrigation water use in advance, (ii) a better
    benchmarking irrigation model to compare with the data-driven approaches, and
    (iii) a better pre-processing approach for data and error estimation methods and
    the ways to leverage human-in-the-loop in the ML modeling system. As always, we
    welcome discussions with irrigation research communities interested in data-driven
    and other related ML modeling development to address irrigation hydrology challenges.
    CRediT authorship contribution statement Umutoni Lisa: Writing – original draft,
    Conceptualization. Samadi Vidya: Writing – review & editing, Supervision, Funding
    acquisition, Conceptualization. Declaration of Competing Interest The authors
    declare that they have no known competing financial interests or personal relationships
    that could have influenced the work reported in this paper. Acknowledgements The
    authors appreciate the funding support from the Southern Sustainable Agriculture
    Research and Education (SARE; grant # 2022001722) graduate fellowship program
    as well as USDA-NIFA (garnt # 2023000603). Any opinions, findings, and discussions
    expressed in this study are those of the authors and do not necessarily reflect
    the views of the SARE and USDA-NIFA. Data availability this is a review paper
    so no research data is generated or used. References Abdar et al., 2021 M. Abdar,
    F. Pourpanah, S. Hussain, D. Rezazadegan, L. Liu, M. Ghavamzadeh, P. Fieguth,
    X. Cao, A. Khosravi, U.R. Acharya, V. Makarenkov, S. Nahavandi A review of uncertainty
    quantification in deep learning: techniques, applications and challenges Inf.
    Fusion, 76 (2021), pp. 243-297, 10.1016/J.INFFUS.2021.05.008 View PDFView articleView
    in ScopusGoogle Scholar Adeyemi et al., 2018 O. Adeyemi, I. Grove, S. Peets, Y.
    Domun, T. Norton Dynamic neural network modelling of soil moisture content for
    predictive irrigation scheduling 2018, Vol. 18, 3408 Sensors, 18 (10) (2018),
    p. 3408, 10.3390/S18103408 View in ScopusGoogle Scholar Alibabaei et al., 2022
    K. Alibabaei, P.D. Gaspar, E. Assunção, S. Alirezazadeh, T.M. Lima Irrigation
    optimization with a deep reinforcement learning model: Case study on a site in
    Portugal Agric. Water Manag., 263 (2022), Article 107480, 10.1016/J.AGWAT.2022.107480
    View PDFView articleView in ScopusGoogle Scholar Allen et al., 2005 R.G. Allen,
    L.S. Pereira, M. Smith, D. Raes, J.L. Wright FAO-56 dual crop coefficient method
    for estimating evaporation from soil and application extensions J. Irrig. Drain.
    Eng., 131 (1) (2005), pp. 2-13 View in ScopusGoogle Scholar Amit and Geman, 1997
    Y. Amit, D. Geman Shape quantization and recognition with randomized trees Neural
    Comput., 9 (7) (1997), pp. 1545-1588, 10.1162/NECO.1997.9.7.1545 View in ScopusGoogle
    Scholar Boardman and Butcher, 2019 Boardman, M., & Butcher, F. (2019). An exploration
    of maintaining human control in AI enabled systems and the challenges of achieving
    it. In Workshop on Big Data Challenge-Situation Awareness and Decision Support.
    Brussels: North Atlantic Treaty Organization Science and Technology Organization.
    Porton Down: Dstl Porton Down. https://www.sto.nato.int/publications/STO%20Meeting%20Proceedings/STO-MP-IST-178/MP-IST-178–07.pdf.
    Google Scholar Boeckhout et al., 2018 M. Boeckhout, G. Zielhuis, A.L. Bredenoord
    The FAIR guiding principles for data stewardship: fair enough? Eur. J. Hum. Genet.,
    26 (7) (2018), pp. 931-936 https://www.nature.com/articles/s41431-018-0160-0 CrossRefView
    in ScopusGoogle Scholar Breiman, 2001 L. Breiman Random forests Mach. Learn.,
    45 (1) (2001), pp. 5-32, 10.1023/A:1010933404324 Google Scholar Cannon et al.,
    2022 M. Cannon, A. Kelly, C. Freeman Implementing an Open & FAIR data sharing
    policy—A case study in the earth and environmental sciences Learn. Publ., 35 (1)
    (2022), pp. 56-66 CrossRefView in ScopusGoogle Scholar Cap et al., 2022 Q.H. Cap,
    H. Uga, S. Kagiwada, H. Iyatomi LeafGAN: an effective data augmentation method
    for practical plant disease diagnosis IEEE Trans. Autom. Sci. Eng., 19 (2) (2022),
    10.1109/TASE.2020.3041499 Google Scholar Car, 2018 N.J. Car USING decision models
    to enable better irrigation Decision Support Systems Comput. Electron. Agric.,
    152 (2018), pp. 290-301, 10.1016/J.COMPAG.2018.07.024 View PDFView articleView
    in ScopusGoogle Scholar Carvalho et al., 2019 D.V. Carvalho, E.M. Pereira, J.S.
    Cardoso Machine learning interpretability: a survey on methods and metrics Electron.
    (Switz. ), Vol. 8 (Issue 8) (2019), 10.3390/electronics8080832 Google Scholar
    Chen et al., 2021 M. Chen, Y. Cui, X. Wang, H. Xie, F. Liu, T. Luo, S. Zheng,
    Y. Luo A reinforcement learning approach to irrigation decision-making for rice
    using weather forecasts Agric. Water Manag., 250 (2021), Article 106838, 10.1016/J.AGWAT.2021.106838
    View PDFView articleView in ScopusGoogle Scholar Chen et al., 2021 Chen, Y., Hsieh,
    W., & Y. K.–. (2021). An ensemble learning model for agricultural irrigation prediction.
    Ieeexplore.Ieee.Org. https://ieeexplore.ieee.org/abstract/document/9333852/. Google
    Scholar Committee on Best Practices for a Future Open Code Policy for NASA Space
    Science, 2018 Committee on Best Practices for a Future Open Code Policy for NASA
    Space Science, S. S. B. & D. on E. and P. S. (2018). Open Source Software Policy
    Options for NASA Earth and Space Sciences. https://books.google.com/books?hl=en&lr=&id=BP6EDwAAQBAJ&oi=fnd&pg=PR1&dq=Open+Source+Software+Policy+Options+for+NASA+Earth+and+Space+Sciences+(2018)&ots=syMPdkptRX&sig=-XTycsx-OXtH_-3lNVWJ6zBhI7c.
    Google Scholar Crystal-Ornelas et al., 2022 R. Crystal-Ornelas, C. Varadharajan,
    D. O’Ryan, K. Beilsmith, B. Bond-Lamberty, K. Boye, M. Burrus, S. Cholia, D.S.
    Christianson, M. Crow, J. Damerow Enabling FAIR data in Earth and environmental
    science with community-centric (meta) data reporting formats Sci. data, 9 (1)
    (2022), Article 700 View in ScopusGoogle Scholar Dahane et al., 2020 Dahane, A.,
    Benameur, R., Kechar, B., & Benyamina, A. (2020). An IoT Based Smart Farming System
    Using Machine Learning; An IoT Based Smart Farming System Using Machine Learning.
    https://doi.org/10.1109/ISNCC49221.2020.9297341. Google Scholar Daw et al., 2020
    Daw, A., Thomas, R.Q., Carey, C.C., Read, J.S., Appling, A.P., & Karpatne, A.
    (2020). Physics-guided architecture (pga) of neural networks for quantifying uncertainty
    in lake temperature modeling. Proceedings of the 2020 SIAM International Conference
    on Data Mining, SDM 2020, 532–540. https://doi.org/10.1137/1.9781611976236.60.
    Google Scholar Der Kiureghian and Ditlevsen, 2009 Der Kiureghian, A., & Ditlevsen,
    O. (2009). Aleatory or epistemic? Does it matter? Structural Safety, 31(2). https://www.sciencedirect.com/science/article/pii/S0167473008000556.
    Google Scholar Dibike et al., 2001 Y.B. Dibike, S. Velickov, D. Solomatine, M.B.
    Abbott Model induction with support vector machines: introduction and applications
    J. Comput. Civ. Eng., 15 (3) (2001), 10.1061/(asce)0887-3801(2001)15:3(208) Google
    Scholar Divyanth et al., 2022 L.G. Divyanth, D.S. Guru, P. Soni, R. Machavaram,
    M. Nadimi, J. Paliwal Image-to-image translation-based data augmentation for improving
    crop/weed classification models for precision agriculture applications Algorithms,
    15 (11) (2022), 10.3390/a15110401 Google Scholar Donratanapat et al., 2020 N.
    Donratanapat, S. Samadi, J. Vidal A national scale big data analytics pipeline
    to assess the potential impacts of flooding on critical infrastructures and communities
    Environ. Model. Softw., 133 (104828) (2020) https://www.sciencedirect.com/science/article/pii/S1364815220308859
    Google Scholar Duane et al., 1987 S. Duane, A.D. Kennedy, B.J. Pendleton, D. Roweth
    Hybrid monte carlo Phys. Lett. B, 195 (2) (1987), pp. 216-222 https://www.sciencedirect.com/science/article/pii/S1364815220308859
    View PDFView articleView in ScopusGoogle Scholar El Bilali et al., 2023 A. El
    Bilali, T. Abdeslam, N. Ayoub, H. Lamane, M.A. Ezzaouini, A. Elbeltagi An interpretable
    machine learning approach based on DNN, SVR, Extra Tree, and XGBoost models for
    predicting daily pan evaporation J. Environ. Manag., 327 (2023), 10.1016/j.jenvman.2022.116890
    Google Scholar Elijah et al., 2018 O. Elijah, T.A. Rahman, I. Orikumhi, C.Y. Leow,
    M.H.D.N. Hindia An overview of internet of things (IoT) and data analytics in
    agriculture: benefits and challenges IEEE Internet Things J., 5 (5) (2018), pp.
    3758-3773, 10.1109/JIOT.2018.2844296 View in ScopusGoogle Scholar Espejo-Garcia
    et al., 2023 B. Espejo-Garcia, H. Panoutsopoulos, E. Anastasiou, F.J. Rodríguez-Rigueiroz,
    S. Fountas Top-tuning on transformers and data augmentation transferring for boosting
    the performance of weed identification Comput. Electron. Agric., 211 (2023), 10.1016/j.compag.2023.108055
    Google Scholar Fawakherji et al., 2020 Fawakherji, M., Potena, C., Prevedello,
    I., Pretto, A., Bloisi, D.D., & Nardi, D. (2020). Data Augmentation Using GANs
    for Crop/Weed Segmentation in Precision Farming. CCTA 2020 - 4th IEEE Conference
    on Control Technology and Applications. https://doi.org/10.1109/CCTA41146.2020.9206297.
    Google Scholar García et al., 2020 L. García, L. Parra, J. Jimenez, J. Lloret,
    P. Lorenz IoT-based smart irrigation systems: an overview on the recent trends
    on sensors and IoT systems for irrigation in precision agriculture Sensors, 20
    (4) (2020), 10.3390/s20041042 Google Scholar Geneva and Zabaras, 2020 N. Geneva,
    N. Zabaras Modeling the dynamics of PDE systems with physics-constrained deep
    auto-regressive networks J. Comput. Phys., 403 (2020), 10.1016/J.JCP.2019.109056
    Google Scholar Gil et al., 2016 Y. Gil, C.H. David, I. Demir, B.T. Essawy, R.W.
    Fulweiler, J.L. Goodall, L. Karlstrom, H. Lee, H.J. Mills, J.H. Oh, S.A. Pierce,
    A. Pope, M.W. Tzeng, S.R. Villamizar, X. Yu Toward the Geoscience Paper of the
    Future: Best practices for documenting and sharing research from data to software
    to provenance Earth Space Sci., 3 (10) (2016), pp. 388-415, 10.1002/2015EA000136
    View in ScopusGoogle Scholar Gill et al., 2006 M.K. Gill, T. Asefa, M.W. Kemblowski,
    M. McKee Soil moisture prediction using support vector machines J. Am. Water Resour.
    Assoc., 42 (4) (2006), 10.1111/j.1752-1688.2006.tb04512.x Google Scholar Glória
    et al., 2021 A. Glória, J. Cardoso, P. Sebastião Sustainable irrigation system
    for farming supported by machine learning and real-time sensor data 2021, Vol.
    21, 3079 Sensors, 21 (9) (2021), p. 3079, 10.3390/S21093079 View in ScopusGoogle
    Scholar Goap et al., 2018 A. Goap, D. Sharma, A.K. Shukla, C. Rama Krishna An
    IoT based smart irrigation management system using Machine learning and open source
    technologies Comput. Electron. Agric., 155 (2018), pp. 41-49, 10.1016/J.COMPAG.2018.09.040
    View PDFView articleView in ScopusGoogle Scholar Goldstein et al., 2018 A. Goldstein,
    L. Fink, A. Meitin, S. Bohadana, O. Lutenberg, G. Ravid Applying machine learning
    on sensor data for irrigation recommendations: revealing the agronomist’s tacit
    knowledge Precis. Agric., 19 (3) (2018), pp. 421-444, 10.1007/S11119-017-9527-4
    View in ScopusGoogle Scholar Gu et al., 2020 Z. Gu, Z. Qi, R. Burghate, S. Yuan,
    X. Jiao, J. Xu Irrigation scheduling approaches and applications: a review J.
    Irrig. Drain. Eng., 146 (6) (2020), 10.1061/(asce)ir.1943-4774.0001464 Google
    Scholar Gumiere et al., 2020 S.J. Gumiere, M. Camporese, A. Botto, J.A. Lafond,
    C. Paniconi, J. Gallichand, A.N. Rousseau Machine Learning vs. Physics-Based Modeling
    for Real-Time Irrigation Management Front. Water, 2 (2020), 10.3389/frwa.2020.00008
    Google Scholar Hochreiter and Schmidhuber, 1997 S. Hochreiter, J. Schmidhuber
    Long short-term memory Neural Comput., 9 (8) (1997), pp. 1735-1780, 10.1162/NECO.1997.9.8.1735
    View in ScopusGoogle Scholar Huang et al., 2019 X. Huang, S. Ouyang, S. Ma -,
    P. Sharma, J.K. Jain, P. Kallaa, A.Y. Sun, B.R. Scanlon How can Big Data and machine
    learning benefit environment and water management: a survey of methods, applications,
    and future directions Environ. Res. Lett., 14 (7) (2019), Article 073001, 10.1088/1748-9326/AB1B7D
    View in ScopusGoogle Scholar Huang et al., 2022 Y. Huang, R. Li, X. Wei, Z. Wang,
    T. Ge, X. Qiao Evaluating data augmentation effects on the recognition of sugarcane
    leaf spot Agric. (Switz. ), 12 (12) (2022), 10.3390/agriculture12121997 Google
    Scholar Hunsaker et al., 2005 D.J. Hunsaker, E.M. Barnes, T.R. Clarke, G.J. Fitzgerald,
    P.J. Pinter Cotton irrigation scheduling using remotely sensed and FAO-56 basal
    crop coefficients Trans. ASAE, 48 (4) (2005), pp. 1395-1407, 10.13031/2013.19197
    View in ScopusGoogle Scholar Jamroen et al., 2020 C. Jamroen, P. Komkum, C. Fongkerd,
    W. Krongpha An intelligent irrigation scheduling system using low-cost wireless
    sensor network toward sustainable and precision agriculture IEEE Access, 8 (2020),
    pp. 172756-172769, 10.1109/ACCESS.2020.3025590 View in ScopusGoogle Scholar Jimenez
    et al., 2020 A.F. Jimenez, P.F. Cardenas, F. Jimenez, A. Canales, A. López A cyber-physical
    intelligent agent for irrigation scheduling in horticultural crops Comput. Electron.
    Agric., 178 (2020), Article 105777, 10.1016/J.COMPAG.2020.105777 View PDFView
    articleView in ScopusGoogle Scholar Jimenez et al., 2021 A.-F. Jimenez, B.V. Ortiz,
    L. Bondesan, G. Morata, D. Damianidis Long short-term memory neural network for
    irrigation management: a case study from Southern Alabama, USA Precis. Agric.,
    22 (2) (2021), pp. 475-492, 10.1007/s11119-020-09753-z View in ScopusGoogle Scholar
    Jones, 2004 H.G. Jones Irrigation scheduling: advantages and pitfalls of plant-based
    methods J. Exp. Bot., 55 (407) (2004), 10.1093/jxb/erh213 Google Scholar Kamienski
    et al., 2018 C. Kamienski, J.-P. Soininen, M. Taumberger, R. Dantas, A. Toscano,
    T. Salmon Cinotti, R. Filev Maia, A. Torre Neto Smart water management platform:
    IoT-based precision irrigation for agriculture Mdpi. Com. (2018), 10.3390/s19020276
    Google Scholar Karandish and Šimůnek, 2016 F. Karandish, J. Šimůnek A comparison
    of numerical and machine-learning modeling of soil water content with limited
    input data J. Hydrol., 543 (2016), 10.1016/j.jhydrol.2016.11.007 Google Scholar
    Karasekreter et al., 2013 N. Karasekreter, F. Başçiftçi, U. Fidan A new suggestion
    for an irrigation schedule with an artificial neural network J. Exp. Theor. Artif.
    Intell., 25 (1) (2013), pp. 93-104, 10.1080/0952813X.2012.680071 View in ScopusGoogle
    Scholar Kashyap et al., 2021 P.K. Kashyap, S. Kumar, A. Jaiswal, M. Prasad, A.H.
    Gandomi Towards precision agriculture: IoT-enabled intelligent irrigation systems
    using deep learning neural network IEEE Sens. J., 21 (16) (2021), pp. 17479-17491,
    10.1109/JSEN.2021.3069266 View in ScopusGoogle Scholar Kaur et al., 2020 H. Kaur,
    H. Nori, S. Jenkins, R. Caruana, H. Wallach, J. Wortman Vaughan Interpreting interpretability:
    understanding data scientists’ use of interpretability tools for machine learning
    Conf. Hum. Factors Comput. Syst. - Proc. (2020), 10.1145/3313831.3376219 Google
    Scholar Kavitha et al., 2016 Kavitha, S., Varuna, S., & R. Ramya. (2016). A comparative
    analysis on linear regression and support vector regression. Online International
    Conference on Green Engineering and Technologies (IC-GET). https://ieeexplore.ieee.org/abstract/document/7916627/.
    Google Scholar Kecman, 2005 V. Kecman Support Vector Machines – An Introduction
    Support Vector Mach.: Theory Appl. (2005), pp. 1-47, 10.1007/10984697_1 Google
    Scholar Kendall and Gal, 2017 A. Kendall, Y. Gal What uncertainties do we need
    in Bayesian deep learning for computer vision? Adv. Neural Inf. Process. Syst.
    (2017), pp. 5575-5585 2017-December View in ScopusGoogle Scholar Koymans et al.,
    2020 M.R. Koymans, D.J.J. van Hinsbergen, D. Pastor-Galán, B. Vaes, C.G. Langereis
    Towards FAIR paleomagnetic data management through paleomagnetism.org 2.0 Geochem.,
    Geophys., Geosystems, 21 (2) (2020), Article e2019GC008838, 10.1029/2019GC008838
    View in ScopusGoogle Scholar Kumar et al., 2017 Kumar, A., Surendra, A., & Mohan,
    H. (2017). Internet of things based smart irrigation using regression algorithm.
    017 International Conference on Intelligent Computing, Instrumentation and Control
    Technologies (ICICICT), 1652–1657. https://ieeexplore.ieee.org/abstract/document/8342819/.
    Google Scholar Lakshminarayanan et al., 2017 Lakshminarayanan, B., Pritzel, A.,
    & Deepmind, C.B. (2017). Simple and scalable predictive uncertainty estimation
    using deep ensembles. Proceedings.Neurips.Cc. https://proceedings.neurips.cc/paper/2017/hash/9ef2ed4b7fd2c810847ffa5fa85bce38-Abstract.html.
    Google Scholar Li et al., 2020 P. Li, Y. Zha, L. Shi, C.H.M. Tso, Y. Zhang, W.
    Zeng Comparison of the use of a physical-based model with data assimilation and
    machine learning methods for simulating soil water dynamics J. Hydrol., 584 (2020),
    10.1016/j.jhydrol.2020.124692 Google Scholar Liou et al., 2001 Y.A. Liou, S.F.
    Liu, W.J. Wang Retrieving soil moisture from simulated brightness temperatures
    by a neural network IEEE Trans. Geosci. Remote Sens., 39 (8) (2001), 10.1109/36.942544
    Google Scholar Liu et al., 2021 L. Liu, M. Ismail, Y. Wang, W.S. Lin Internet
    of things based smart irrigation control system for paddy field AGRIVITA, J. Agric.
    Sci., 43 (2) (2021), pp. 378-389, 10.17503/agrivita View in ScopusGoogle Scholar
    Mahesh, 2018 B. Mahesh Machine learning algorithms-a review Int. J. Sci. Res.
    (2018), 10.21275/ART20203995 Google Scholar Maier and Dietrich, 2016 N. Maier,
    J. Dietrich Using SWAT for strategic planning of basin scale irrigation control
    policies: a case study from a humid region in Northern Germany Water Resour. Manag.,
    30 (9) (2016), 10.1007/s11269-016-1348-0 Google Scholar Miller, 2019 T. Miller
    Explanation in artificial intelligence: Insights from the social sciences Artif.
    Intell., Vol. 267 (2019), 10.1016/j.artint.2018.07.007 Google Scholar Mitchell,
    2007 Mitchell, T. (2007). Machine learning (Vol. 1). https://profs.info.uaic.ro/∼ciortuz/SLIDES/2017s/ml0.pdf.
    Google Scholar Moraffah et al., 2020 R. Moraffah, M. Karami, R. Guo, A. Raglin,
    H. Liu Causal interpretability for machine learning - problems, methods and evaluation
    ACM SIGKDD Explor. Newsl., 22 (1) (2020), 10.1145/3400051.3400058 Google Scholar
    Nachankar et al., 2018 P.J. Nachankar, M.G. Somani, D.M. Singh, S.N. Katkar IOT
    in agriculture Int. Res. J. Eng. Technol. (2018) (www.irjet.net) Google Scholar
    National Academies of Sciences, 2021 National Academies of Sciences, E. and M.
    (2021). Human-AI Teaming: State-of-the-Art and Research Needs. Human-AI Teaming:
    State-of-the-Art and Research Needs (2022), 1–126. https://doi.org/10.17226/26355.
    Google Scholar Navarro-Hellín et al., 2016 H. Navarro-Hellín, J. Martinez-del-Rincon,
    R. Domingo-Miguel, F. Soto-Valles, R. Torres-Sánchez A decision support system
    for managing irrigation in agriculture Comput. Electron. Agric., 124 (2016), pp.
    121-131 View PDFView articleView in ScopusGoogle Scholar Nawandar and Satpute,
    2019 N.K. Nawandar, V.R. Satpute IoT based low cost and intelligent module for
    smart irrigation system Comput. Electron. Agric., 162 (2019), pp. 979-990, 10.1016/J.COMPAG.2019.05.027
    View PDFView articleView in ScopusGoogle Scholar Nemali and van Iersel, 2006 K.S.
    Nemali, M.W. van Iersel An automated system for controlling drought stress and
    irrigation in potted plants Sci. Hortic., 110 (3) (2006), pp. 292-297, 10.1016/J.SCIENTA.2006.07.009
    View PDFView articleView in ScopusGoogle Scholar Oden Technologies, 2023 Oden
    Technologies. (2023). What is Model Training | Oden Technologies. https://oden.io/glossary/model-training/.
    Google Scholar Petzold et al., 2019 Petzold, A., Asmi, A., Vermeulen, A., Pappalardo,
    G., Bailo, D., Schaap, D., Glaves, H.M., Bundke, U. and Zhao, Z., 2019, September.
    ENVRI-FAIR-interoperable environmental FAIR data and services for society, innovation
    and research. In 2019 15th International Conference on eScience (eScience) (pp.
    277–280). IEEE. Google Scholar Pfeiffer et al., 2015 Pfeiffer III, J., Neville,
    J., & Bennett, P. (2015). Overcoming relational learning biases to accurately
    predict preferences in large scale networks. In Proceedings of the 24th International
    Conference on World Wide Web, 853–863. https://doi.org/10.1145/2736277.2741668.
    Google Scholar Pierce and Nowak, 1999 Pierce, F., & Nowak, P. (1999). Aspects
    of precision agriculture. Advances in Agronomy, 1–85. https://www.sciencedirect.com/science/article/pii/S0065211308605131.
    Google Scholar Perea et al., 2019 R.G. Perea, E.C. Poyato, P. Montesinos, J.R.
    Díaz Prediction of irrigation event occurrence at farm level using optimal decision
    trees Comput. Electron. Agric., 157 (2019), 10.1016/j.compag.2018.12.043 Google
    Scholar Quay et al., 2021 A.N. Quay, P.S. Fiske, M.S. Mauter Recommendations for
    advancing FAIR and open data standards in the water treatment community ACS EST
    Eng., 2 (3) (2021), pp. 337-346 Google Scholar Raissi et al., 2019 M. Raissi,
    P. Perdikaris, G.E. Karniadakis Physics-informed neural networks: a deep learning
    framework for solving forward and inverse problems involving nonlinear partial
    differential equations J. Comput. Phys., 378 (2019), pp. 686-707, 10.1016/J.JCP.2018.10.045
    View PDFView articleView in ScopusGoogle Scholar Ribeiro et al., 2016 M.T. Ribeiro,
    S. Singh, C. Guestrin Model-agnostic interpretability of machine learning. ArXiv
    Preprint ArXiv, 1606 (2016), p. 05386 Google Scholar Rudin, 2019 C. Rudin Stop
    explaining black box machine learning models for high stakes decisions and use
    interpretable models instead Nat. Mach. Intell., Vol. 1 (Issue 5) (2019), 10.1038/s42256-019-0048-x
    Google Scholar Sabrina et al., 2022 F. Sabrina, S. Sohail, F. Farid, S. Jahan,
    F. Ahamed, S. Gordon An interpretable artificial intelligence based smart agriculture
    system Comput., Mater. Contin., 72 (2) (2022), 10.32604/cmc.2022.026363 Google
    Scholar Saggi and Jain, 2022 M.K. Saggi, S. Jain A survey towards decision support
    system on smart irrigation scheduling using machine learning approaches Arch.
    Comput. Methods Eng. (2022), 10.1007/s11831-022-09746-3 Google Scholar Samadi
    et al., 2020 S. Samadi, M. Pourreza-Bilondi, C.A.M.E. Wilson, D.B. Hitchcock Bayesian
    model averaging with fixed and flexible priors: theory, concepts, and calibration
    experiments for rainfall-runoff modeling J. Adv. Model. Earth Syst., 12 (7) (2020),
    10.1029/2019MS001924 Google Scholar Sharma et al., 2021 A. Sharma, A. Jain, P.
    Gupta, V. Chowdary Machine learning applications for precision agriculture: a
    comprehensive review IEEE Access, 9 (2021), pp. 4843-4873, 10.1109/ACCESS.2020.3048415
    View in ScopusGoogle Scholar Shen et al., 2018 C. Shen, E. Laloy, A. Elshorbagy,
    A. Albert, J. Bales, F.J. Chang, S. Ganguly, K.L. Hsu, D. Kifer, Z. Fang, K. Fang,
    D. Li, X. Li, W.P. Tsai HESS Opinions: Incubating deep-learning-powered hydrologic
    science advances as a community Hydrol. Earth Syst. Sci., 22 (11) (2018), pp.
    5639-5656, 10.5194/HESS-22-5639-2018 View in ScopusGoogle Scholar Shrestha and
    Shukla, 2015 N.K. Shrestha, S. Shukla Support vector machine based modeling of
    evapotranspiration using hydro-climatic variables in a sub-tropical environment
    Agric. For. Meteorol., 200 (2015), 10.1016/j.agrformet.2014.09.025 Google Scholar
    Sidhu et al., 2020 R.K. Sidhu, R. Kumar, P.S. Rana Machine learning based crop
    water demand forecasting using minimum climatological data Multimed. Tools Appl.,
    79 (19–20) (2020), pp. 13109-13124, 10.1007/S11042-019-08533-W View in ScopusGoogle
    Scholar Sihi et al., 2022 D. Sihi, B. Dari, A.P. Kuruvila, G. Jha, K. Basu Explainable
    machine learning approach quantified the long-term (1981–2015) impact of climate
    and soil properties on yields of major agricultural crops across CONUS Front.
    Sustain. Food Syst., 6 (2022), 10.3389/fsufs.2022.847892 Google Scholar Sirignano
    and Spiliopoulos, 2018 J. Sirignano, K. Spiliopoulos DGM: a deep learning algorithm
    for solving partial differential equations J. Comput. Phys., 375 (2018), pp. 1339-1364,
    10.1016/J.JCP.2018.08.029 View PDFView articleView in ScopusGoogle Scholar Su
    et al., 2021 D. Su, H. Kong, Y. Qiao, S. Sukkarieh Data augmentation for deep
    learning based semantic segmentation and crop-weed classification in agricultural
    robotics Comput. Electron. Agric., 190 (2021), 10.1016/j.compag.2021.106418 Google
    Scholar Sun and Ren, 2014 C. Sun, L. Ren Assessing crop yield and crop water productivity
    and optimizing irrigation scheduling of winter wheat and summer maize in the Haihe
    plain using SWAT model Hydrol. Process., 28 (4) (2014), 10.1002/hyp.9759 Google
    Scholar Sun et al., 2017 Sun, L., Yang, Y., Hu, J., Porter, D., & Marek, T. (2017).
    Reinforcement learning control for water-efficient agricultural irrigation. In
    2017 IEEE International Symposium on Parallel and Distributed Processing with
    Applications and 2017 IEEE International Conference on Ubiquitous Computing and
    Communications (ISPA/IUCC), 1334–1341. https://ieeexplore.ieee.org/abstract/document/8367433/.
    Google Scholar Tabas and Samadi, 2022 S.S. Tabas, S. Samadi Variational Bayesian
    dropout with a Gaussian prior for recurrent neural networks application in rainfall-runoff
    modeling Environ. Res. Lett., 17 (6) (2022) Google Scholar Tace et al., 2022 Y.
    Tace, M. Tabaa, S. Elfilali, C. Leghris, H. Bensag, E. Renault Smart irrigation
    system based on IoT and machine learning Energy Rep., 8 (2022), 10.1016/j.egyr.2022.07.088
    Google Scholar Torres-Sanchez et al., 2020 R. Torres-Sanchez, H. Navarro-Hellin,
    A. Guillamon-Frutos, R. San-Segundo, M.C. Ruiz-Abellón, R. Domingo-Miguel A Decision
    Support System for Irrigation Management: Analysis and Implementation of Different
    Learning Techniques 2020, Vol. 12, 548 Water, 12 (2) (2020), p. 548, 10.3390/W12020548
    View in ScopusGoogle Scholar Tseng et al., 2018 Tseng, D., Wang, D., Chen, C.,
    & Miller, L. (2018). Towards automating precision irrigation: Deep learning to
    infer local soil moisture conditions from synthetic aerial agricultural images.
    In 2018 IEEE 14th International Conference on Automation Science and Engineering
    (CASE), 284–291. https://ieeexplore.ieee.org/abstract/document/8560431/. Google
    Scholar 2017 USDA. (2017). 2017 Census of Agriculture. (United States Department
    of Agriculture - National Agricultural Statistics Service). https://www.nass.usda.gov/Publications/AgCensus/2017/index.php.
    Google Scholar Vellidis et al., 2016 Vellidis, G., V. Liakos, W. Porter, M. Tucker,
    X. Liang. 2016. A Dynamic Variable Rate Irrigation System. In Proceedings of the
    13th International Conference on Precision Agriculture July 31 – August 3, 2016,
    St. Louis, Missouri, USA. International Society of Precision Agriculture, Monticello,
    IL. Google Scholar Wagner et al., 2022 A. Wagner, L. Waite, M. Wierzba, F. Hoffstaedter
    FAIRly big: a framework for computationally reproducible processing of large-scale
    data Sci. Data, 9 (1) (2022), p. 80 https://www.nature.com/articles/s41597-022-01163-2
    View in ScopusGoogle Scholar Wilkinson et al., 2016 M.D. Wilkinson, M. Dumontier,
    Ij.J. Aalbersberg, G. Appleton, M. Axton, A. Baak, N. Blomberg, J.W. Boiten, L.B.
    da Silva Santos, P.E. Bourne, J. Bouwman, A.J. Brookes, T. Clark, M. Crosas, I.
    Dillo, O. Dumon, S. Edmunds, C.T. Evelo, R. Finkers, …, B. Mons The FAIR Guiding
    Principles for scientific data management and stewardship 2016 3:1 Sci. Data,
    3 (1) (2016), pp. 1-9, 10.1038/sdata.2016.18 View in ScopusGoogle Scholar Windheuser
    et al., 2023 L. Windheuser, R. Karanjit, R. Pally, S. Samadi, N.C. Hubig An end-to-end
    flood stage prediction system using deep neural networks Earth Space Sci., 10
    (1) (2023), 10.1029/2022EA002385 Google Scholar Wolanin et al., 2020 A. Wolanin,
    G. Mateo-Garciá, G. Camps-Valls, L. Gómez-Chova, M. Meroni, G. Duveiller, Y. Liangzhi,
    L. Guanter Estimating and understanding crop yields with explainable deep learning
    in the Indian Wheat Belt Environ. Res. Lett., 15 (2) (2020), 10.1088/1748-9326/ab68ac
    Google Scholar Wu et al., 2020 Q. Wu, Y. Chen, J. Meng Dcgan-based data augmentation
    for tomato leaf disease identification IEEE Access, 8 (2020), 10.1109/ACCESS.2020.2997001
    Google Scholar Yang et al., 2020 Y. Yang, J. Hu, D. Porter, T. Marek, K. Heflin,
    H. Kong, L. Sun Deep reinforcement learning-based irrigation scheduling Trans.
    ASABE, 63 (3) (2020), pp. 549-556, 10.13031/TRANS.13633 View in ScopusGoogle Scholar
    Zhang et al., 2021 J. Zhang, K. Guan, B. Peng, C. Jiang, W. Zhou, Y. Yang, M.
    Pan, T. Franz, D.M. Heeren, D.R. Rudnick Challenges and opportunities in precision
    irrigation decision-support systems for center pivots Environ. Res. Lett., 16
    (5) (2021), Article 053003 https://iopscience.iop.org/article/10.1088/1748-9326/abe436/meta
    CrossRefView in ScopusGoogle Scholar Zhao et al., 2023 X. Zhao, L. Zhang, G. Zhu,
    C. Cheng, J. He, S. Traore, V.P. Singh Exploring interpretable and non-interpretable
    machine learning models for estimating winter wheat evapotranspiration using particle
    swarm optimization with limited climatic data Comput. Electron. Agric., 212 (2023),
    10.1016/j.compag.2023.108140 Google Scholar Zhou et al., 2017 L. Zhou, S. Pan,
    J. Wang, A.V. Vasilakos Machine learning on big data: Opportunities and challenges
    Neurocomputing, 237 (2017), pp. 350-361, 10.1016/J.NEUCOM.2017.01.026 View PDFView
    articleView in ScopusGoogle Scholar Zhou, 2020 N. Zhou Intelligent control of
    agricultural irrigation based on reinforcement learning J. Phys.: Conf. Ser.,
    1601 (2020), p. 52031, 10.1088/1742-6596/1601/5/052031 Google Scholar Zhu et al.,
    2019 Y. Zhu, N. Zabaras, P.S. Koutsourelakis, P. Perdikaris Physics-constrained
    deep learning for high-dimensional surrogate modeling and uncertainty quantification
    without labeled data J. Comput. Phys., 394 (2019), pp. 56-81, 10.1016/J.JCP.2019.05.024
    View PDFView articleView in ScopusGoogle Scholar Zhu et al., 2019 Z. Zhu, M. Wulder,
    D. Roy, C. Woodcock Benefits of the free and open Landsat data policy Remote Sens.
    Environ., 224 (2019), pp. 382-385 https://www.sciencedirect.com/science/article/pii/S0034425719300719
    View PDFView articleView in ScopusGoogle Scholar Cited by (0) © 2024 The Author(s).
    Published by Elsevier B.V. Recommended articles Straw-derived biochar optimizes
    water consumption, shoot and root characteristics to improve water productivity
    of maize under reduced nitrogen Agricultural Water Management, Volume 294, 2024,
    Article 108722 Ru Guo, …, Xiaoli Chen View PDF Optimal irrigation for wheat-maize
    rotation depending on precipitation in the North China Plain: Evidence from a
    four-year experiment Agricultural Water Management, Volume 294, 2024, Article
    108726 Lei Yang, …, Zhaohai Zeng View PDF Exploring the differences of moisture
    traceability methods based on MixSIAR model under different nitrogen applications
    of wheat in the Arid Region of Northwest China Agricultural Water Management,
    Volume 294, 2024, Article 108716 Yingbo Liu, …, Taisheng Du View PDF Show 3 more
    articles Article Metrics Captures Readers: 15 View details About ScienceDirect
    Remote access Shopping cart Advertise Contact and support Terms and conditions
    Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices
    All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply."'
  inline_citation: '>'
  journal: Agricultural Water Management
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Application of machine learning approaches in supporting irrigation decision
    making: A review'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Holguin I.
  - Errapotu S.M.
  citation_count: '0'
  description: Advances in sensor and communication technologies have transformed
    traditional homes into smart homes, equipped with sensors and actuators for various
    functionalities like smart lighting, temperature control, irrigation, solar monitoring,
    entertainment, and security. This transition is powered by the Internet of Things
    (IoT) architecture, enabling smart home hubs to integrate and control devices
    with different communication protocols. However, this shift has also introduced
    new security and privacy issues in the Smart Home IoT (SH-IoT) environment. To
    address these challenges, new communication protocols with cryptographic features
    have been developed, and a unified standard called Matter has been created to
    promote interoperability among different device manufacturers. This paper presents
    a comprehensive survey of recent trends and advances in the smart home IoT landscape,
    focusing on communication protocols, their security issues and protection features
    against vulnerabilities in the SH-IoT environment.
  doi: 10.1109/CSNet59123.2023.10339739
  full_citation: '>'
  full_text: '>

    "IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account
    Personal Sign In Browse My Settings Help Access provided by: University of Nebraska
    - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards
    Authors Citations ADVANCED SEARCH Conferences >2023 7th Cyber Security in Ne...
    Smart Home IoT Communication Protocols and Advances in their Security and Interoperability
    Publisher: IEEE Cite This PDF Ismael Holguin; Sai Mounika Errapotu All Authors
    200 Full Text Views Abstract Document Sections I. Introduction II. Smart Home-IoT
    Architecture III. Smart Home IoT Communication Protocols-Operation and Security
    IV. Conclusion and Future Works Authors Figures References Keywords Metrics Abstract:
    Advances in sensor and communication technologies have transformed traditional
    homes into smart homes, equipped with sensors and actuators for various functionalities
    like smart lighting, temperature control, irrigation, solar monitoring, entertainment,
    and security. This transition is powered by the Internet of Things (IoT) architecture,
    enabling smart home hubs to integrate and control devices with different communication
    protocols. However, this shift has also introduced new security and privacy issues
    in the Smart Home IoT (SH-IoT) environment. To address these challenges, new communication
    protocols with cryptographic features have been developed, and a unified standard
    called Matter has been created to promote interoperability among different device
    manufacturers. This paper presents a comprehensive survey of recent trends and
    advances in the smart home IoT landscape, focusing on communication protocols,
    their security issues and protection features against vulnerabilities in the SH-IoT
    environment. Published in: 2023 7th Cyber Security in Networking Conference (CSNet)
    Date of Conference: 16-18 October 2023 Date Added to IEEE Xplore: 11 December
    2023 ISBN Information: ISSN Information: DOI: 10.1109/CSNet59123.2023.10339739
    Publisher: IEEE Conference Location: Montreal, QC, Canada Funding Agency: SECTION
    I. Introduction Advances in sensor and communication technologies have revolutionized
    home living, introducing unprecedented comfort and personalization options for
    users. The emergence of the Internet of Things (IoT) enabled smart devices has
    given rise to a new industry of consumer electronics, catering specifically to
    Smart Home-Internet of Things (SH-IoT) environments. TVs, vacuums, temperature
    controls, and irrigation systems when coupled with the internet have all transformed
    how people interact with and manage their homes. To facilitate communication among
    the increasing number of smart devices in homes, various communication protocols
    have been adopted. The Internet Protocol (IP) is still the most widely used, but
    its power consumption limits its application in battery-powered devices for SH-IoT.
    As a result, other protocols like Zigbee, Z-wave, and Bluetooth Low Energy (BLE)
    have been developed, each forming its own network for communication. However,
    this diversification raised the need for security features in smart homes devices
    such as encryption and authentication to safeguard against breaches and to prevent
    unauthorized access. Given the growing interest in smart home IoT,this survey
    discusses advances in SH-IoT protocols, their security features, and developments
    in new interoperability standards. SECTION II. Smart Home-IoT Architecture A.
    IoT Elements in Smart Homes Smart home IoT relies on smart devices and applications,
    offering a wide range of functionalities. These devices include sensors for monitoring
    mail delivery, tracking solar energy consumption/generation, and controlling various
    aspects like temperature, lighting, garage doors, appliances, entertainment, and
    home security. The application platform gathers data from home devices through
    sensors and uses software to create a personalized user experience [1]. Fig. 1.
    Smart Home IoT Architecture Show All B. Layers in Smart Home-IoT Architecture
    SH-IoT architecture is structured into three layers in a top-down approach: Cloud
    Layer: Servers and cloud-based infrastructure Fog Layer or Gateway Layer: Network
    gateway devices like routers that serve as intermediaries between cloud and edge
    devices. Edge Layer: Consists of devices such as smartphones and tablets and sensored
    devices like thermostats and lights. C. Sh-IoT Communication Network Structures
    In this section, we will briefly discuss communication network structures related
    to smart home environments: (1) Wide Area Network (WAN) is a network configuration
    used to communicate data between large distances (used in smart home neighborhoods).
    The internet is a WAN setup as it interconnects different computers for sending
    and receiving data packets. (2) Local Area Network (LAN) as the name entails is
    a network confined to a smaller area such as a home (home area network) or business.
    LAN tends to have a higher transmission rate than WAN but within shorter distances,
    its similar to WAN, and typically has one device (modem/router) acting as a door
    in communicating to the internet. (3) Wireless Personal Area Network (WPAN) is
    a network that is typically used with short-range communication protocols such
    as Bluetooth, Zigbee, Z-wave, Thread, BLE, and as of Fall 2022, Matter. WPAN has
    a low data rate, making it slower than LAN, but the topology is more versatile
    and can be configured to be a star or mesh structure. SECTION III. Smart Home
    IoT Communication Protocols-Operation and Security In this section, we will discuss
    widely used SH-IoT protocols, their advanced security features, and configurations.
    SH-IoT communications protocols and their security mechanisms are listed in Fig
    2. A. Bluetooth Bluetooth is a wireless communication protocol found in most smart
    devices, operating within the IEEE 802.15 for WPAN standards. It creates a Wireless
    Personal Area Network, allowing Bluetooth-enabled devices to connect and share
    data, such as audio and images. Bluetooth operates in the 2.4GHz to 2.48GHz unlicensed
    band and supports Piconet (star), or Scatternet (mesh) topologies, with one master
    and up to seven slaves. It has a data rate of 1Mbps or 3Mbps depending on the
    version of Bluetooth. Bluetooth is vulnerable to various attacks, including eavesdropping,
    man-in-the-middle (MITM), denial of service (DoS), and message modification. To
    address security concerns, different security modes are defined, ranging from
    no security required to authenticate link keys and encryption algorithms for data
    integrity [2]. The modes for Bluetooth Security are defined here [2]: Mode 1:Devices
    are never considered to be secure in any implementation. Mode 2:Security procedures
    occur during the setup of the Service Layer, i.e., security is in effect after
    a link is established but not before logical channel is established. The concept
    of device authorization is introduced in this mode. Mode 3:Security procedures
    occur during the setup of the Link Layer before the physical link is fully established.
    This mode of operation makes authentication and encryption a hard requirement
    for all connections established between devices. This mode makes it impossible
    for service discovery to take place until authentication, encryption, and authorization
    have been completed. Mode 4:Security procedures occur during the setup of the
    Service Layer, similar to mode 2. However, mode 4 implements Secure Simple Pairing(SSP),
    in which Elliptic Curve Diffie-Hellman (ECDH) [3] [4] key agreement is utilized
    for link key generation. The P-192 Elliptic Curve was used for the link key generation
    until Bluetooth 4.0. Bluetooth 4.1 introduced the Secure Connections feature,
    which now implements P-256 Elliptic Curve for link key generation, and upgraded
    the authentication algorithm to FIPS-approved 256-bit Hash Message Authentication
    Code Secure Hash Algorithm [5] (HMAC-SHA-256). The encryption algorithm was also
    upgraded in 4.1 to FIPS-approved AES-Counter with CBC-MAC (AES-CCM) to ensure
    data integrity [2]. B. Bluetooth Low Energy (BLE)/Bluetooth Smart BLE was introduced
    in Bluetooth 4.0 and updated in 4.1 and 4.2 versions, specifically for devices
    with low computation power requirements [2]. BLE was initially created to be able
    to implement a Bluetooth stack in coin cell battery-powered devices, by periodically
    engaging in data transmission. It usually is in sleep mode, i.e., BLE remains
    in sleep mode unless a connection initiates, significantly reducing power consumed.
    One difference between Bluetooth and BLE is key generation. BLE generates a Long-Term
    Key (LTK), which is fundamentally similar to the Link Key. In BLE legacy pairing
    the LTK is generated by one of the devices, which then sends it to the other device
    during the pairing. BLE also was upgraded in Bluetooth 4.1 and the same security
    algorithms apply [2]. BLE is unencrypted by default, it is important to select
    a security mode. C. Zigbee (Now the Connectivity Standard Alliance) Designed as
    a low data rate wireless personal area protocol, Zigbee has found its application
    in smart home IoT environments. The low data rate feature makes it useful for
    controlling home lighting, smart switches/dimmers and occupancy sensors to name
    a few applications; its mesh topology makes it very useful as a Personal Area
    Network (PAN). Zigbee has two bands on which it operates, on 868/915MHz providing
    a data rate of around 20-40Kbps, and 2450MHz providing a data rate of around 250Kbps.
    Zigbee protocol stack consists of four layers; the application layer, the network
    layer, the MAC layer, and the physical layer. The security in Zigbee is implemented
    in the network layer when enabled. If it is enabled then AES 128-bit symmetric
    keys [6] are used, the keys can either be preinstalled or obtained after the joining
    process [7]. A Zigbee node can support over 240 end points, each end point specifies
    a specific application. The topology of Zigbee consists of the Coordinator, Router,
    and End Devices. The controller/coordinator is always the first device that is
    setup when configuring a Zigbee network. The controller picks the channel and
    PAN ID i.e., the device is responsible for establishing the PAN. Once the PAN
    is established other Zigbee devices may join its network such as router and End
    devices. The controller is always powered by the main line in a home (i.e., outlet),
    and it never goes into sleep mode. The controller can act as a router if needed
    to help in routing data through the network, and can trigger the acceptance of
    other routers [7]. End devices have limited authority in the network, they cannot
    give authorization to devices to join the network or assist in data routing. End
    devices are battery-powered, and are put to sleep periodically to help in power
    consumption [7]. D. Z-Wave Z-wave is a low-bandwidth communication protocol commonly
    used in smart home IoT applications like security sensors and alarms. It operates
    in the ISM band, with specific frequencies for the USA (908.42MHz) and Europe
    (868.42MHz). The protocol uses a master-slave mesh network topology, comprising
    controllers (primary and secondary) and slaves. Controllers initiate commands
    to the slave nodes, with the primary controller hosting the routing table and
    controlling node additions and removals. Slaves execute or relay commands as instructed
    by the controller. Z-Wave ensures network encapsulation using a 32-bit identifier
    Home ID for each controller. To enhance security, Z-wave implements the S2 framework
    based on Elliptic Curve [4] Diffie-Hellman [3] cryptography, providing resistance
    to attacks. It also incorporates AES 128-bit [6] symmetric cryptography for additional
    protection. Previous vulnerabilities related to a hard-coded default key have
    been addressed through firmware updates in the S2 framework [8]. Fig. 2. SH-IoT
    Protocols and Security Features Show All E. Thread Thread standard is low powered,
    low latency wireless mesh network protocol based on IPv6 over low-power wireless
    area networks (6LoWPAN). It is based on the IEEE 802.15.4 standard for low rate
    WPAN (LoWPAN). Thread comprises of a Physical layer and MAC layer that operate
    with 250kbps data rate in 2.4GHz band for link layer communication [9]. IEEE 802.15.4
    standard''s Carrier Sense Multiple AccessCollision Avoidance (CSMA-CA) is the
    basis for Thread''s reliable transmission. CSMA-CA allows multiple devices to
    share 2.4GHz band, and initiates transmission only after confirming the channel
    is empty. Thread was designed to be a battery supply friendly protocol, even though
    it uses IPv6 it compresses the packet headers to minimize the size of the transmitted
    packet [9]. Thread network comprises of full thread devices and minimal thread
    devices. Full thread devices set constitutes of a Router that manages the routing
    needs of the network, a Leader that can make decisions as well as act as router,
    Router-Eligible End Devices (REED) that are non routing devices with capabilities
    to act as router when called by leader, and Full End Devices (FED) which are full
    thread devices that cannot be promoted to routers but can act as border routers.
    Thread network is dynamic in nature, if the Leader is knocked offline for some
    reason, network will select a different router to be the Leader creating zeros
    point of failures in the network. Full thread devices that can be border routers,
    act as hub and create IPv6 subnets of the thread network (since devices are IP-addressable),
    essentially becoming gateways [9]. Minimal thread devices set constitutes of Minimal
    End Devices (MED) which cannot forward messages but only can communicate with
    parent router, Sleepy End Devices (SED) are similar to MEDs whose radios are turned
    off and periodically wakes up to check for communication with parent router, and
    Synchronized Sleepy End Devices (SSED) are similar to SEDs whose radios are turned
    off and wake up at scheduled intervals to check for communication with parent
    router. Thread implements AES-CCM [10] based network-wide key for payload encryption,
    in which the cipher works by implementing a check tag, appends some data to individual
    messages that can later be verified against the network-wide key, to verify if
    a message originated from where it says it did and to ensure that message integrity
    has not been violated. A new device joining thread network is oblivious to what
    the network key is. Since key cannot be sent over in an unsecured manner due to
    risks in compromise, Thread uses Password-Authenticated Key Exchange (PAKE) method
    to send key in a secure manner [9]. F. Matter/Project Chip (Connected Home Over
    IP) Matter is the newest standard released in October 2022, created by the Zigbee
    alliance now called Connectivity Standards Alliance (CSA) which includes companies
    like Apple, Google, Amazon, Samsung, Comcast and many other silicon valley manufacturers,
    to achieve “interoperability” between devices in smart home IoT environment. Matter
    is similar to the interoperability standard DNP3 developed for smart grid environment
    [11]. Matter is built on the internet protocol that enables communication with
    Thread, Ethernet, and WiFi devices in a network. Matter standard was designed
    with robust security as a top priority and to provide capabilities to detect and
    recover from attacks. Matter supports a comprehensive approach with authentication
    and attestation for commissioning, message integrity, and secure over the air
    firmware updates. It implements AES in CCM mode [10] with 128 bit keys for integrity
    and confidentiality, AES in CTR mode is used for protecting identifiers to preserve
    privacy, and SHA-256 [5] for integrity. It uses ECC for enabling interoperability,
    along with use for digital signatures, key exchanges, standard key derivation,
    and true random number generation [11]. Matter development has attracted over
    500 industry leading companies to join the alliance in creating a secure and robust
    communication standard for SH-IoT environment, with many of them being security
    focused developers. SECTION IV. Conclusion and Future Works In this work, we discussed
    most widely used SH-IoT protocols, their communication networks and topologies,
    their security and interoperability features. In future works we will be presenting
    findings from our packet level security testing with border router prototypes
    and edge devices in SH-IoT communications. ACKNOWLEDGEMENT This work was supported
    by the US Department of Energy (DoE) National Nuclear Security Administration
    research grant under Award Number DE-NA0004016. Authors Figures References Keywords
    Metrics More Like This Security and Privacy of Medical Internet of Things Devices
    for Smart Homes 2020 7th International Conference on Internet of Things: Systems,
    Management and Security (IOTSMS) Published: 2020 A Review on Impact of Internet
    of Things (IoT) on Individual Privacy in Smart Home Systems 2021 2nd International
    Conference on Intelligent Engineering and Management (ICIEM) Published: 2021 Show
    More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS
    VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: 2023 7th Cyber Security in Networking Conference, CSNet 2023
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Smart Home IoT Communication Protocols and Advances in their Security and
    Interoperability
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Dhal S.
  - Wyatt B.M.
  - Mahanta S.
  - Bhattarai N.
  - Sharma S.
  - Rout T.
  - Saud P.
  - Acharya B.S.
  citation_count: '2'
  description: Climate change, land degradation, and limited land and water resources
    have challenged our ability to meet the food demand of a rapidly growing population.
    To tackle this challenge, modern agricultural systems are relying on new technologies
    like the Internet of Things (IoT) to improve agricultural productivity and resource
    use efficiency. Although IoT has gained considerable attention in the last few
    years, the key concepts of IoT and their applicability across different domains
    of agriculture are still new to many researchers, practitioners, managers, and
    policymakers. In this paper, we provide a comprehensive review of the use of different
    IoT platforms, wireless sensor networks, and other associated technologies like
    remote sensing, cloud computing, and big data analytics in digital agriculture.
    The review also explores the use of communication technologies, microcontrollers,
    and machine learning in smart irrigation and decision support systems. The necessity
    of interoperability (data transfer and communication without human interference)
    among devices is discussed in detail with regard to facilitating and exchanging
    agricultural data more effectively. The discussion also includes opportunities
    and challenges in standardizing IoT; developing energy-efficient and affordable
    technologies; and improving data collection, transfer, storage, processing, security,
    anonymity, and privacy. This paper further calls for collaborative research in
    sensor and communication technologies in the agricultural sector.
  doi: 10.1002/agj2.21385
  full_citation: '>'
  full_text: '>

    "UNCL: University Of Nebraska - Linc Acquisitions Accounting Search within Login
    / Register JOURNALS MAGAZINES OTHER PUBLICATIONS BOOKS Membership Agronomy Journal
    SPECIAL SECTION: MACHINE LEARNING IN AGRICULTURE Full Access Internet of Things
    (IoT) in digital agriculture: An overview Sambandh Dhal,  Briana M. Wyatt,  Shikhadri
    Mahanta,  Nishan Bhattarai,  Sadikshya Sharma,  Tapas Rout,  Pradip Saud,  Bharat
    Sharma Acharya First published: 27 May 2023 https://doi.org/10.1002/agj2.21385Citations:
    1 Assigned to Associate Editor Kathleen Yeater. SECTIONS PDF TOOLS SHARE Abstract
    Climate change, land degradation, and limited land and water resources have challenged
    our ability to meet the food demand of a rapidly growing population. To tackle
    this challenge, modern agricultural systems are relying on new technologies like
    the Internet of Things (IoT) to improve agricultural productivity and resource
    use efficiency. Although IoT has gained considerable attention in the last few
    years, the key concepts of IoT and their applicability across different domains
    of agriculture are still new to many researchers, practitioners, managers, and
    policymakers. In this paper, we provide a comprehensive review of the use of different
    IoT platforms, wireless sensor networks, and other associated technologies like
    remote sensing, cloud computing, and big data analytics in digital agriculture.
    The review also explores the use of communication technologies, microcontrollers,
    and machine learning in smart irrigation and decision support systems. The necessity
    of interoperability (data transfer and communication without human interference)
    among devices is discussed in detail with regard to facilitating and exchanging
    agricultural data more effectively. The discussion also includes opportunities
    and challenges in standardizing IoT; developing energy-efficient and affordable
    technologies; and improving data collection, transfer, storage, processing, security,
    anonymity, and privacy. This paper further calls for collaborative research in
    sensor and communication technologies in the agricultural sector. Abbreviations
    ANFIS Adaptive Neuro-Fuzzy Inference System ARPANET Advanced Research Projects
    Agency Network DSS decision support system EVI enhanced vegetation index FAO the
    Food and Agriculture Organization of the United Nations GPS global position satellite
    IaaS Infrastructure as a Service ICAO International Civil Aviation Organization
    ICT information communication technology LAI leaf area index LiDAR light detection
    and ranging MCC mobile cloud computing MDWI maximum difference water index MSI
    moisture stress index NDII normalized difference infrared index NDVI normalized
    difference vegetation index NIR near-infrared NodeMCU Node MicroController Unit
    OSAVI optimized soil adjusted vegetation index PaaS platform as a service PLSR
    partial least square regression RAM random access memory RDVI renormalized difference
    vegetation index RFID radio frequency identification RGB red, green, and blue
    SaaS Software as a Service SAVI soil adjusted vegetation index SoC system on chip
    WDRVI wide dynamic range vegetation index WSN wireless sensor network 1 BACKGROUND
    The global food system is currently under pressure due to rising population, economic
    growth, land degradation, and increased demand for animal-based products (Keating
    et al., 2014; Lal, 2013). For example, global food production needs to be increased
    by about 70% to ensure food security for an estimated world population of more
    than 9.7 billion people in 2050 (Cole et al., 2018; FAO, 2017). Further, climate
    change is projected to affect global food production and efforts to increase food
    productivity. Notably, crop production across the globe has already experienced
    negative effects from warming temperatures, changes in precipitation patterns,
    and increased extreme weather events (IPCC, 2022; Paudel et al., 2014). This will
    likely be exacerbated by climate change in the future (Hasegawa et al., 2021;
    Lobell et al., 2008; Rosenzweig & Parry, 1994). As such, researchers, scientists,
    policymakers, and organizations like the Food and Agriculture Organization of
    the United Nations (FAO) call for a radical transformation in global agricultural
    and food systems. Therefore, improved technologies that aim at enhancing production
    and supply-chain efficiencies under a resource-constrained environment are crucial
    to ensuring food security in the face of climate change (FAO, 2017). One such
    technology is the Internet of Things (IoT), which has recently shown the potential
    to provide solutions to several challenges associated with increased agricultural
    productivity under climatic changes and variability (Figure 1). FIGURE 1 Open
    in figure viewer Uses of the Internet of Things (IoT) in agriculture (Source:
    Salam, 2022, used with permission). Although there is no single definition of
    IoT, it could be broadly described as a system of devices, software programs,
    sensors, and other technologies that are either connected or are able to become
    connected via the Internet to exchange information and data (Borgia, 2014). The
    first application of IoT is believed to be an information-sharing network used
    by US defense sectors in 1969, then called the Advanced Research Projects Agency
    Network. The chronological timeline detailing the evolution process of various
    technologies within IoT since 1969 is summarized in Table 1 (Balas et al., 2019).
    In recent years, there has been an exponential increase in the number of common
    devices that might be considered to be a part of the IoT framework, including
    cell phones, televisions, thermostats, vehicles, refrigerators, home lighting
    systems, and smart watches among many others. Such IoT infrastructure is projected
    to substantially impact the global economy, with more than 100 billion connections
    (Huawei Technologies Co., 2015) and a financial impact of more than $11 trillion
    by 2025 (Manyika et al., 2015). Their impact is largely apparent in the agricultural
    sector, which currently contributes up to 60% of the national gross domestic product
    in many countries (The World Bank, 2019). TABLE 1. Chronological evolution of
    the technologies in Internet of Things (IoT) domain. Year Evolution Reference
    1969 Used by academic and research fraternity in the form of ARPANET to share
    information among defense sectors Townsend (2001) 1973 Used in RFID tags to lock
    and unlock doors; barcode scanners Suresh et al. (2014) 1974 Embedded computer
    systems were implemented using single on-board computers Eickhoff (2011) 1984
    Used in coke vending machines to generate the temperature and availability of
    the drink product Wu et al. (2014) 1990 Became popular in business and consumer
    markets Remondes and Afonso (2019) 1991 The concept of “ubiquitous computing”
    became popular Lyytinen et al.(2002) Mid 1990s Sensor nodes were designed to sense
    and detect data from embedded devices Han et al. (2005) 1999 IoT was used in “Device
    to Device” communication Asadi et al. (2014) 2000 IoT was used for routing and
    inventory management (used by LG to make smart refrigerators) Zhang et al. (2018)
    2003 IoT was used by the US Army in their System Architecture and Virtual Integration
    (SAVI) program Simi et al. (2013) 2010 IoT was used for surveillance, security,
    and transportation applications Jyothi and Vardhan (2016) 2015 IoT was used for
    locating people and objects Sharma and Lohan (2019) 2020 IoT was used for monitoring
    and controlling distant objects such as water levels in tanks in crop fields Rajalakshmi
    and Mahalakshmi (2016) The use of IoT in agriculture emerged due to advancements
    in data science, remote sensing, and computer technologies, and the need for optimizing
    decisions regarding agricultural management practices (King, 2017). Specifically,
    IoT use in precision and smart agriculture is notable with applications in data-informed,
    site-specific, and real-time management and decision-making. International Society
    of Precision Agriculture defines precision agriculture as “a management strategy
    that gathers, processes and analyzes temporal, spatial and individual data and
    combines it with other information to support management decisions according to
    estimated variability for improved resource use efficiency, productivity, quality,
    profitability and sustainability of agricultural production.” Smart agriculture
    refers to farming using softwares, sensors, automation, and data technologies.
    Digital agriculture seeks to utilize data from precision farming and the power
    of Artificial Intelligence. Digital agricultural technologies and the use of IoT
    are illustrated in Figure 1. Development of pilot research farms is already underway
    in several countries to determine the feasibility of IoT-informed decision-making
    for improving the efficiency and sustainability of agricultural production. Some
    examples include the Accelerating Precision Agriculture to Decision Agriculture
    (P2D) project in Australia (Zhang et al., 2017) and SmartAgriHubs (Chatzikostas
    et al., 2019) and SmartAgriFood (Kaloxylos et al., 2012) in Europe. Yet, the adaptation
    of IoT technology in the agricultural sector is still in its infancy (Villa-Henriksen
    et al., 2020). IoT enables us to gather information from enclosed proximity to
    the physical location using fog computing, edge computing, communication protocols,
    and sensor technologies. They show potential in improving decision-making and
    productivity in various stages of agricultural production. Examples include the
    use of wireless in-field sensors in improving the measurement of soil moisture
    and permittivity (Salam, 2020; Bogena et al., 2010), autonomous precision irrigation
    systems (Dong et al., 2013), and identification and tracking of livestock animals
    (Trotter et al., 2010). Satellites, unmanned aerial vehicles (UAVs), and new remote
    sensing approaches (e.g., PlanetLab) are increasingly used in IoT. For example,
    UAVs have been used for plant height estimation (Anthony et al., 2014; Herwitz
    et al., 2004), biomass estimation (Sinha et al., 2015), crop yield prediction
    (Ashapure et al., 2020; Panday et al., 2020), detection of weeds (De Castro et
    al., 2017), soil nitrogen management (Ballester et al., 2017), crop disease detection
    (Sugiura et al., 2016), and estimation of the leaf area index (LAI) (Hunt et al.,
    2008). Despite the growing interest of the agricultural research community in
    integrating IoT-enabled devices into production, to date, such technologies are
    not widely adopted by producers due to concerns associated with cost and return
    on investment (Narwane et al., 2022; Pillai & Sivathanu, 2020). More specifically,
    there is a need to understand the benefits and utilities of IoT from different
    perspectives (users, developers, and researchers) to fully utilize its potential
    to improve crop production under limited resources and climate change. Therefore,
    in this paper, we review existing literature and discuss the concepts, applications,
    potential challenges, and opportunities associated with IoT with a specific focus
    on its application in digital agriculture. First, we provide the concepts and
    technical details of different components of IoT, followed by its applications
    in digital agriculture, and associated challenges and opportunities. Overall,
    this review is expected to provide useful insights into how IoT could be integrated
    into the smart agriculture framework for improving crop productivity and food
    security in the face of climatic change and variability. Core Ideas Different
    platforms, sensors, and structures of IoT in digital agriculture were reviewed.
    The application of IoT in data management, interoperability, and precision farming
    was reviewed. Potential of IoT to improve agricultural quality and productivity
    was highlighted. Challenges and opportunities of IoT in digital agriculture were
    discussed. 2 COMPONENTS OF THE IOT The key components of the IoT include IoT platforms,
    wireless sensor networks (WSNs), and the IoT structure. An IoT platform can be
    defined as an on-premises software suite or a cloud service (IoT platform as a
    service [PaaS]) that monitors and may manage and control different kinds of endpoints,
    generally through apps installed on the platform. Similarly, WSN refers to an
    infrastructure-less wireless network that is installed ad hoc in a large number
    of wireless sensors to monitor system, physical, or environmental factors. The
    structure of IoT largely consists of devices, network structure, and cloud technology
    that allow IoT devices to communicate with each other. These components are discussed
    separately below. 2.1 IoT platforms IoT platforms provide proprietary or open-source
    suite for controlling devices and data in IoT system. Various IoT platforms, both
    proprietary and open source, are currently available to handle data from diverse
    sources using different devices. They serve functions like ingestion, filtering,
    aggregation, storing, and computation of data (Jayaraman et al., 2016). These
    platforms support specific microcontrollers, transceivers, data and extension
    memory, and programming. Some select platforms in agriculture are available from
    Tzounis et al. (2017) and are discussed in detail as follows. 2.1.1 FarmBot FarmBot
    is an open-source precision agricultural project platform that consists of a farming
    machine, software, and a repository for farming data. The three main components
    of FarmBot include mechanisms for seed planting, a nutrient delivery system, and
    a universal tool mounting system. FarmBot is generally used in urban farming for
    monitoring plant growth parameters and predicting a suitable harvest date at a
    future point in time (Nugraha et al., 2020). FarmBot can plant seeds with a regular
    watering schedule and can be remotely accessed with ease from Internet-connected
    devices (Murdyantoro et al., 2019). It takes the location of each plant into account
    to facilitate essential nutrients and water application for optimal plant growth
    based on feedback from the online database of records from various agricultural
    fields. The main purpose of FarmBot technology is to optimize the quality and
    quantity of agricultural produce and to enhance resource efficiency. Arduino,
    an open-source hardware and software company, which manufactures microcontrollers,
    is used to control the FarmBot and is connected to the Internet using a Raspberry
    Pi 3 board. A decision support system (DSS) has been implemented to help in data-driven
    design, access to the open repository, and real-time control of the parameters.
    An Android application can be designed to monitor the stepper motor location to
    carry out different farm operations, plant seeds using the vacuum pump in the
    field, and capture images. 2.1.2 Raspberry Pi Raspberry Pi is a small, low-cost
    computer chip capable of being used with a computer monitor, mouse, and keyboard.
    The basic structure of a Raspberry Pi includes random access memory (RAM), a processor,
    USB ports, general purpose input/output pins, an Ethernet port, a full HDMI port,
    a camera interface, a display interface, and a micro SD card slot (Balamurugan
    et al., 2017). The Raspberry Pi has been used in a wide variety of applications
    in agricultural systems. The growing availability of Raspberry Pi with high processing
    capacity has enabled many remote sensing tasks in agriculture, including crop
    imaging, determination of soil fertility, crop yield estimation, and spraying
    of fertilizers (Mathe et al., 2022). Flores et al. (2016) utilized a Raspberry
    Pi as a local server to display the relative humidity, air temperature, soil moisture,
    soil electrical conductivity, and soil pH through the use of a graphical user
    interface. Kamath et al. (2019) used a Raspberry Pi to monitor weeds in paddy
    crops and Bluetooth 4.0 to send data to remote base station using visual sensor
    nodes. These sensor readings were then processed using machine learning models
    (e.g., support vector machines and random forests) to distinguish weeds from paddy
    crops using shape features. 2.1.3 IRIS Mote An IRIS Mote (Crossbow) is a computing
    system consisting of a microcomputer plus one or more sensors that are connected
    wirelessly via a radio link. The IRIS Mote has one of the highest communication
    ranges (close to 500 m) using a 2.4 GHz IEEE 802.15.4 wireless module. It also
    includes an Intel XScale processor, 8 KB of RAM, 512 KB of flash memory, and a
    transmission rate of 250 kbps. The expansion connector has eight channel analog
    inputs. The IRIS Mote handles task scheduling and input/output processing (Liu
    et al., 2015) using an open-source TinyOS operating system based on an ATMega1281
    low-power microcontroller (Sivagami et al., 2010). The transmission current of
    IRIS Mote is 10–17 mA, whereas the receiver current is 16 mA. The indoor communication
    range of the device is greater than 300 m, and the outdoor communication range
    is greater than 50 m (Narayanan et al., 2016). The underground communication range
    is reduced to less than 30 m due to interference in radio frequency communication.
    The IRIS Mote is used in small agricultural fields to monitor climatic and hydrologic
    parameters like rain, sunlight, humidity, and temperature of a system. 2.1.4 Zolertia
    The Zolertia Z1 Mote (Zolertia S.L., Barcelona, Spain) is a platform designed
    for WSNs. It is compatible with TinyOS, OpenWSN, and RIOT OS. It supports analog
    and digital sensors and includes an MSP432 microcontroller, 8 KB of RAM, and 92
    KB of flash memory. It can operate in the temperature range of −25 to −85°C. It
    is designed to work in the range of 0.3–3.6 V, powered by two 1.5 V AA standard
    batteries (Zolertia, 2010). Agricultural use of Zolertia has previously been reported
    in greenhouse-based tomato farming, where the attenuation of radio waves in the
    2.4 GHz freeband was measured using a received signal strength indicator (Cama-Pinto
    et al., 2021). Zolertia Z1 Mote has also been used in determining agro-climatic
    variables like temperature and soil moisture in cassava (Manihot spp.) production
    (Caicedo-Ortiz et al., 2018). 2.1.5 Node MicroController Unit Node MicroController
    Unit (NodeMCU) is an open-source IoT platform with an ESP8266 microcontroller
    and Wi-Fi system on chip (SoC) from Expressif Systems, and hardware, which runs
    on an ESP-12 module. This firmware runs on Lua scripting language (Vanaja et al.,
    2018). It functions the same way as a Raspberry Pi in the case of agricultural
    applications and may be connected to various sensors for real-time monitoring
    of soil moisture, relative humidity, and air temperature. In one study, NodeMCU
    was used to monitor the environmental conditions of indoor greenhouses (Wan et
    al., 2019). A cloud-based platform has been used to store the environmental sensor
    readings and has been used for automatic irrigation systems for controlling agriculture
    pumps and remote monitoring systems resulting in increased economic benefits (Bentabet,
    2020). 2.1.6 Intel Galileo/Edison The Intel Galileo (Intel) board is based on
    Intel architecture (Intel Quark SoC X1000, 400 MHz processor) and is designed
    to have powerful functionalities with minimum power consumption. This allows users
    to apply shields compatible with Intel Galileo and extend the functionality of
    the board. It comprises two levels—legacy controlled blocks and microbuses. The
    legacy-controlled blocks are used for specific functions using dedicated channels.
    It has a dedicated point-to-point connection to connect to standard modules like
    Wi-Fi, Bluetooth, and SIM card modules for cell phones. The issues of these boards
    within agriculture are similar to that of the Raspberry Pi (Silpa et al., 2018).
    These boards are used in a house environment monitoring system, which helps in
    producing high-quality crops with minimal labor costs (Ajith et al., 2020). Some
    other applications are observed in the monitoring of soil pH and nutrients of
    cultivated crops (Sakthisudhan et al., 2019). 2.2 Wireless sensor network WSN
    is an important component of IoT, and its use in the agricultural sector has been
    widely discussed (Mahbub, 2020; Sanjeevi et al., 2020). A WSN is a wireless network
    consisting of spatially distributed sensors and sensor nodes to monitor physical
    or environmental conditions and transfer data to a base station. These systems
    are often inexpensive, scalable, and consist of mobile nodes (Kiani & Seyyedabbasi,
    2018). Briefly, the WSN system consists of two major components, sensor nodes
    and sink nodes (base station) (Kocakulak & Butun, 2017). The sensor node consists
    of a power unit, a sensing unit, and a computing unit. These nodes may be placed
    inside or outside an agricultural field to continuously feed data to the base
    station. Depending on the ad hoc system configuration or network type, the sensor
    node could behave as a data originator or router. Sensor nodes can collect real-time
    physical or environmental conditions such as temperature, vibration, or motion
    time and produce sensory data (Pottie, 1998; Senouci & Mellouk, 2016). At the
    same time, the sink node collects sensor data and communicates with the end user
    via a direct connection. This connection between the sensor and sink nodes is
    established via the Internet, satellite, or any wireless link, and the data is
    accessed through an app or end-user interface. 2.3 IoT structure IoT structure
    is a system that helps in connecting objects to the Internet through information-sensing
    equipment to establish data exchange and communication and to monitor and manage
    digital systems (Ye et al., 2014). To achieve such functions, IoT uses the perception,
    network, and application layers, as well as the security strategy for each layer,
    as a part of its framework (Gou et al., 2013). The IoT structural hierarchy is
    shown in Figure 2 (Zhong et al., 2015), but more generalized structural components
    are discussed in sub-sections below. Different layers within the hierarchy are
    crucial to address issues like computational loss, poor access control, data leaks,
    malware risks, and cyberattacks (apriorit.com/dev-blog). FIGURE 2 Open in figure
    viewer Hierarchy of the Internet of Things (IoT) structure. 2.3.1 The perception
    layer The perception layer is the foundation of IoT and is the interface between
    the physical world and the digital world. This layer functions as “nerve endings”
    collecting measured signals and transporting those signals to the rest of the
    system (Yang et al., 2012). It uses radio frequency identification technology,
    barcode technology, sensor, and positioning technology to complete information
    collection and helps in controlling the perception by the actuators. The main
    security issues in a perception layer are related to information collection and
    transmission as most sensors have a simple structure and processor and do not
    have complex security protection capabilities (Zhao & Ge, 2013). 2.3.2 The network
    layer The network layer is generally composed of two layers—the network access
    layer and the network transmission layer. The access layer consists of a base
    station node and a gateway. Current methods of network access are Wi-Fi, Ad Hoc,
    Mesh, and Zigbee. The network transmission layer is responsible for the transmission
    and exchange of information, including satellite, mobile, and optical fiber communication
    networks. It is analogous to a person''s nervous system and brain, which are used
    to transmit and cope with the information from the perception layer. The most
    common security issues in a network layer occur when a number of malicious nodes
    send data at the same time, which may lead to a denial of service attack (Bello
    et al., 2017). 2.3.3 The application layer The application layer is generally
    composed of two layers—the application support layer and the application presentation
    layer. The support layer is responsible for data storage, information processing,
    and the exchange of information. The presentation layer is used for processing
    data from the application support layer. It uses technology with multimedia, virtual
    reality, and human–computer interfaces to connect the IoT and the user. The main
    security issues concerning the application layer may include data access permission,
    identity authentication, data protection and recovery, big data handling, and
    software vulnerabilities, among others (Karagiannis et al., 2015). 3 APPLICATIONS
    OF IOT IN DIGITAL AGRICULTURE Digital agriculture is directly linked with IoT.
    Indeed, IoT offers multiple applications in the production, circulation, and modernization
    of farming businesses (Chen & Jin, 2012; Ozdogan et al., 2017). The term “digital
    agriculture” refers to the on-farm and off-farm uses and applications of data
    based on location, weather, energy use, or other factor using sensors, machines,
    or satellites to monitor animals, plants, or soil (Klerkx et al., 2019). It integrates
    concepts from precision and smart farming. The basic framework (Tang et al., 2002)
    of digital agriculture includes: Agricultural databases that include information
    about farmlands, climatic conditions, and socioeconomic background that relates
    agricultural activities to the human society. Real-time monitoring and updating
    of information in the database about meteorology, vegetation, and soil information
    on and under the ground using in situ and satellite-based sensors. A network transmission
    and processing system to analyze collected information, make decisions, and transfer
    signals in controlling the functions of agricultural machinery. The actuation
    framework that includes digitized sowing and harvesting devices enabled with Geographic
    Information System and Global Position Satellite systems. Different crop, soil,
    and weather sensors are increasingly used in monitoring plant growth, diseases,
    pests, yield, weather variables (temperature, humidity, rain, air, etc.), and
    soil physical–chemical and hydraulic properties (Acharya et al., 2017; Sehgal
    et al., 2005). Sensors are used in real-time monitoring and reporting of agricultural
    parameters in the value chain, cloud computing, and integration of these processes
    with advanced technologies like UAVs and satellites to enable highly efficient,
    qualitative, profitable, and environmentally sound agricultural decision-making.
    Sensor-based data is also utilized in formulating predictive models to forecast
    crop yield (Supit et al., 2012). Some applications of IoT systems in digital agriculture
    are discussed as follows. 3.1 UAVs in digital agriculture Traditionally, satellites
    have been used to detect spectral responses from plants and soil (Dematte et al.,
    2018). However, satellite data is often of coarse resolution that is not applicable
    for canopy and plot scale applications and is not available regularly due to cloud
    cover and sensor property. UAVs provide a noninvasive and cost-effective approach
    to collect data at a much finer scale at the desired time scale. UAVs are defined
    as “a set of configurable elements consisting of a remotely piloted aircraft,
    its associated remote pilot station(s), the required command and control links,
    and any other system elements as may be required, at any point during flight operation”
    (International Civil Aviation Organization, ICAO). UAV-derived images can be processed
    to monitor and predict plant growth parameters, disease and pest incidence, yield,
    and different soil physical and hydraulic properties. Nowadays, smart technologies
    have been built into UAVs by integrating open-source technology, autonomous programs,
    smart sensors, and payloads (Puri et al., 2017). Different hyperspectral, multispectral,
    and light detection and ranging (LiDAR) sensors can be mounted to the UAVs for
    near real-time monitoring of vegetation conditions, extraction of soil and vegetation
    indices (Ni et al., 2018), and predicting LAI. For example, multispectral sensors
    are increasingly used to calculate the normalized difference vegetation index,
    normalized difference red-edge index, leaf water content index, soil-adjusted
    vegetation index, enhanced vegetation index, tile drainage, and plant water status
    by capturing the reflectance including those in visible, near-infrared, and shortwave
    regions of the electromagnetic radiation (Tables 2 and 3). TABLE 2. Different
    sensors used in unmanned aerial vehicles (UAVs) and their advantages and disadvantages
    (Modified from Acharya et al., 2021). Sensors Advantages Disadvantages Red/green/blue
    (RGB) Portable, common, relatively inexpensive, provide high-quality RGB images
    for ortho-imagery and digital surface model, easy to integrate with different
    platforms Wider bandwidth and lower spectral resolution lack geometric and radiometric
    calibration Multispectral Multiple wavelengths allow geometric reconstruction
    and radiometric calibration Relatively costly, image processing relatively complex
    compared to RGB, radiometric, and atmospheric corrections may be required, limited
    compatibility to UAVs Hyperspectral High spectral resolution data across various
    wavelengths of the visible and near infrared spectrum Higher cost than multispectral,
    low signal-to-noise ratio, limited compatibility with standard UAVs and flight
    control software packages, radiometric and atmospheric corrections may be required
    Microwave High spatial resolution, useful under low visibility weather conditions
    (e.g., cloud cover) Sensitive to surface roughness Thermal Sense a wide range
    of temperatures, relatively cheaper Thermally sensitive, vignetting effects, low
    spatial resolution, radiometric corrections required, sensitive to change in surface
    roughness LiDAR Generates dense cloud points, high-quality data, direct geometric
    measurements Higher cost, limited compatibility with UAVs, requires ground filtering
    corrections TABLE 3. Selected vegetative indices and their application in agriculture
    (Modified from Acharya et al., 2021). Indices Equation Use Normalized difference
    vegetation index, NDVI Crop monitoring Wide dynamic range vegetation index, WDRVI
    Crop monitoring Renormalized difference vegetation index, RDVI Crop monitoring
    Optimized soil adjusted vegetation index, OSAVI** Soil color, moisture Enhanced
    vegetation index, EVI Crop monitoring Moisture stress index, MSI Canopy water
    content Normalized difference water index, NDWI Canopy water content Normalized
    difference infrared index, NDII Canopy water content Maximum difference water
    index, MDWI Canopy water content Soil adjusted vegetation index, SAVI Soil color,
    moisture, background variability Abbreviations: L, soil adjustment factor; NIR,
    near-infrared; R, red. There are several types of UAV systems used for agricultural
    applications (Table 4; Acharya et al., 2021). Two widely used UAVs include fixed-wing
    and rotary-wing UAVs (Dileep et al., 2020). Fixed-wing UAVs use airplane-like
    wings to generate lift and to move forward. Some of their properties include lower
    cost, higher endurance, and greater flight speed as compared to rotary-wing UAVs.
    Contrastingly, rotary-wing UAVs use rotor blades and are characterized by vertical
    takeoff and landing capacity, lower flight altitude, and lower flight speed. UAVs
    may be used for mid-season crop health monitoring of vegetative indices using
    near-infrared and other regions of the electromagnetic spectrum that cannot be
    sensed by the human eye (Table 3; Cancela et al., 2019; Ren et al., 2020; Veroustraete,
    2015). Pathak et al. (2020) reported the use of UAVs in spraying herbicides on
    up to 20–40 ha per day and to further eradicate farmers’ direct contact with poisonous
    chemicals and hazardous operational conditions. UAVs can be used to generate variable-rate
    application maps from the images to determine the strength of nutrient uptake
    in a single field. This has the potential to further minimize fertilizer costs
    and optimize crop yield (Kulbacki et al., 2018). UAV-based LiDAR systems and software
    have shown potential in stitching together thousands of high-quality aerial photographs
    to develop 3D maps for monitoring soil erosion and developing conservation strategies
    (Acharya et al., 2021). More recently, new types of aerial imagery and satellite
    (e.g., PlanetLab) have shown tremendous potential in monitoring crops, making
    informed decisions, and increasing yield (Cai et al., 2019). TABLE 4. Applications
    of unmanned aerial vehicles (UAVs) in the agricultural domain (adapted and modified
    from Puri et al., 2017). Agricultural UAVs Usage Honeycomb AgDrone system, Wilsonville,
    OR, USA Most sophisticated with ability to cover 600–800 acres of land in an hour
    DJI Matrice 100, Shenzhen, China Includes GPS, flight controller, and navigation
    system, efficient in diverse environmental conditions DJI T600 Inspire 1, Shenzhen,
    China Fast charging, 4 K video recording, camera control, and easy navigational
    capabilities DJI Agras MG-1, Shenzhen, China Equipped with four nozzles for accurate
    spraying of fertilizers over the entire field EBEE SQ-SenseFly, Berlin, Germany
    Equipped with multispectral sensors and has automatic 3D flight planning Lancaster
    5 Precision Hawk, Raleigh, NC, USA Able to detect humidity, temperature, and pressure
    as well as incident light in real time SOLO AGCO Edition, Duluth, GA, USA Includes
    cloud-based advanced mapping software and Agribotix imaging for high-resolution
    aerial imaging and field and crop monitoring 3.2 Cloud-based information communication
    technology (ICT) systems The main purpose of cloud-based information communication
    technology (ICT) systems is to provide tools to software developers to develop
    a variety of cloud-based services to monitor plant growth parameters and predict
    crop yield (Kaloxylos et al., 2012). This infrastructure consists of data collection,
    statistical analysis, and the creation of commands to control farming equipment.
    In a practical setup, data is generally transferred from a local farm management
    system to the cloud repository associated with the monitoring service in order
    to keep track of the farm activities. The data is subsequently analyzed by an
    expert online system such as an e-agriculturist, and outputs are made directly
    available to the farmers. An ICT system has three major components (Patil et al.,
    2012). The first is an information collection layer, which consists of a sensor-based
    climatic and agricultural dataset. Data may include but is not limited to air
    temperature, relative humidity, air pressure, atmospheric gas concentrations;
    names, models, and prices of agricultural products; operating status of agricultural
    equipment, and locations of agricultural products. The second layer is the transport
    or network layer, which is responsible for transmitting and processing data received
    from the sensor layer above. Finally, the application layer analyzes and processes
    information to cultivate digital awareness. One of the leading examples of a cloud-based
    ICT system is GeoFarmer (Eitzinger et al., 2019). GeoFarmer consists of a modular
    design, which is interoperable through an application programming interface. It
    follows open access standards regarding existing tools and technologies and the
    system is designed and developed in accordance with user needs. Further, the entire
    process and lessons learned in the development process are documented. Similar
    software architecture has been defined in FIWARE, an open-source platform for
    a smart digital future, which focuses on agricultural sensors with reprogrammable
    firmware and a set of interfaces already embedded in the General Packet Radio
    Service board. Cloud-based systems have been applied to monitor pesticide use
    and safety in vegetable crops (Qian et al., 2018). Interfaces of such systems
    consist of guidelines for pesticide purchasing and application, optimal harvest
    time estimation, and a feedback system formulation to monitor the health of vegetables.
    A mobile-based cloud architecture was implemented through AgroMobile (Prasad et
    al., 2013), which enhances smart agricultural practices with the help of image
    processing techniques, image visualization, and cloud-based data processing. A
    similar precision agriculture technique using cloud computing has been proposed
    in enhancing the capacity for special education leadership for aggregate farming
    in the cloud (Castillejo et al., 2020) to increase efficiency and productivity
    and reduce labor costs. Other applications include quality control in greenhouse
    production, and monitoring soil moisture levels, humidity, and temperature in
    agricultural plots. 3.3 Big data in agriculture Big data refers to datasets that
    are too large to be analyzed by traditional data processing software and applications.
    The integration of big data technologies and best farming practices has the potential
    to facilitate improved crop production, plant protection, postharvest analysis,
    and environmental conservation. The major applications of big data in different
    topologies of digital agriculture are available from Sarker et al. (2019) and
    are briefly discussed here. The first application of big data is in precision
    agriculture. Thus, data collected using sensor-enabled hardware and software tools
    is used for assessing, controlling, and improving crop management, crop performance,
    and environmental quality. The second application is prescription agriculture,
    where big data is used to prescribe agronomic practices for optimizing yield.
    The third application is in enterprise agriculture, which includes the agribusiness
    platform and links field data to inventory, logistics, machinery, and profit.
    Finally, the fourth application is in automated agriculture, where farm data and
    environmental data are used to automate agriculture through robotic technologies.
    The data lifecycle in agriculture consists of data generation, warehousing, cleaning,
    annotation, and processing to optimize or improve agricultural production while
    maintaining the quality of the environment (Chaterji et al., 2020). In the following
    section, we briefly describe each of these steps. Data generation may involve
    the use of site-specific or public data. Site-specific datasets, such as soil
    nutrient composition and fertilizer usage, are generally privately held. Examples
    of public data may include topographic or soil textural information of a location.
    Data warehousing allows the data to be integrated from multiple sources and then
    restructured for improved performance. Data annotation is a data labeling technique
    that translates an encoded value to raw data. Because classical WSNs have limitations
    in interpreting and understanding the context of raw sensor data, annotation is
    highly recommended for end-user applications (Khan et al., 2015). On the other
    hand, getting rid of the corrupt or inaccurate values from the tables is a very
    important step in processing and helps to eradicate outliers from the dataset.
    Finally, processing imagery data results in more useful formats, which is largely
    accomplished by using a variety of analysis techniques such as Artificial Intelligence.
    Despite the considerable importance of big data in modernizing agriculture, a
    dearth of publicly available, high-quality datasets remains a formidable challenge
    to farming using alternate techniques. A combination of machine learning and IoT
    may be crucial in filling those gaps and in designing interactive wireless sensor–actuator
    networks for the commercial application of alternative farming systems (e.g.,
    Aquaponics) (Dhal et al., 2022a, 2022b; Dhal, Jungbluth, et al., 2022). 3.4 Digital
    twins in agriculture Digital twins generally refer to a digital replica of real-world
    entities mirroring their behavior and states over the entire lifetime in a virtual
    world. It is generally a standardization of real-world variables and can be used
    irrespective of place, time, and human observation (Botín-Sanabria et al., 2022).
    A digital twin in agriculture has been described as a multi-physical, multi-scale,
    and probabilistic simulation model of complex production. It uses a combination
    of in situ sensors and physical models to mirror physical life. Information from
    sensors and satellite data is taken as input to design digital twins (Verdouw
    et al., 2021) and is utilized in reproducing historical statistics and predicting
    future values. The process involves data integration, Artificial Intelligence,
    and machine learning. Digital twins show potential for aiding in planning and
    managing soil operations, irrigation, robotics, and farm machineries (Nasirahmadi
    & Hensel, 2022). WSNs in farmlands and cloud servers that run machine learning
    algorithms can detect plant diseases, weed clusters, and nutrient deficiencies
    (Angin et al., 2020). Indeed, significant progress has been made in using digital
    twins in the field of arable farming, dairy farming, greenhouse horticulture,
    and livestock rearing (Howard et al., 2020; Verdouw et al., 2017). For example,
    digital twins have been designed to monitor the health of cows (Bos taurus) and
    pigs (Sus domesticus), model firmness and loss of vitamin content in mango (Mangifera
    indica), identify diseases and pests in olives (Olea europaea) and other crops,
    assist in fleet management and tracking machinery, and identify pesticide exposure
    in bees (Apis mellifera) (Pylianidis et al., 2021). These applications of the
    digital twins within the agricultural sector have been observed in seven major
    fields: real-time monitoring of data, energy consumption analysis, system failure
    analysis and prediction, optimization of resources, behavioral analysis, technological
    integration, and virtual maintenance (Angin et al., 2020). More recently, the
    concept of digital twins has been applied in postharvest management by categorizing
    simulations into three stages: input, throughput, and output (Dyck et al., 2022).
    This enables monitoring of moisture and temperature of grain to ensure safe storage
    and movement within the elevator. Further, a sensor network could be used in storage
    to ensure the optimal quality of grains. 4 ADVANTAGES OF USING IOT IN AGRICULTURE
    The demand for agricultural products will increase as the global population grows
    and as climate change occurs (Bradshaw & Brook, 2014). IoT shows the potential
    to lower the impact of these challenges while meeting this demand for agricultural
    products. Indeed, IoT offers a potential solution to increase agricultural efficiency
    and productivity while saving time, labor, and money. Because of the cost and
    time effectiveness of IoT systems, the use and installation of IoT devices in
    the agricultural industry are increasing by nearly 20% annually and are expected
    to reach 225 million devices by 2024 (Elijah et al., 2018). In addition, the expansion
    of cellular service and 5G connectivity introduced by satellite and cellular network
    companies in rural areas have boosted the use of IoT in recent years (Di et al.,
    2019; Chen et al., 2022). The advancement of IoT connectivity to personal and
    portable electronic items, such as cell phones, iPads, and tablets, along with
    the introduction of advanced WSNs and machine learning facilitates real-time data
    retrieval, processing, and decision-making. The advantages of IoT in agriculture
    include interoperability, wide advantages of WSN, and data management using cloud
    and fog computing. In the following section, we discuss these advantages in detail.
    4.1 Interoperability The data collected through WSNs and sensor nodes is made
    available using apps, equipment, and products to communicate and process them
    in a way that does not require any involvement from end users, which is called
    interoperability (Tzounis et al., 2017). In other words, interoperability is the
    data communication approach that allows using different information systems to
    transfer and comprehend information. The interoperability process consists of
    two methods. The first method makes the data available through a local area network
    or a wide area network. The second method shares the data via software or hardware
    between different systems and machines. In the utilization of IoT, interoperability
    plays a vital role in facilitating and exchanging effectively organized data between
    information systems. Interoperability provides multiple benefits, such as system
    adaptability, better productivity, data unity, improved data protection, fewer
    errors, and lower data acquisition costs. The interoperability functionality includes
    three approaches, which include syntactical, structural, and semantical approaches
    (Aydin & Aydin, 2020). Syntactic interoperability allows the use of two or more
    systems simultaneously to communicate and share data even if the interface or
    language is not the same. Structural interoperability defines the standard data
    exchange format from one system to another to understand the information clearly.
    Moreover, semantic interoperability allows connecting two or more systems and
    sharing data between them in a meaningful way. 4.2 Smart irrigation and decision
    support The use of sensors and communication technologies, microcontrollers, and
    actuators has the potential to improve water use efficiency, reduce the cost of
    irrigation, and increase crop productivity (Abbasi et al., 2019). For example,
    UAVs are increasingly used in monitoring plant water use efficiency, which provides
    a base to select plant varieties for breeding and crop improvement, particularly
    in water-limited systems. Soil moisture sensors using capacitance or frequency
    domain technology are able to continuously monitor soil moisture in determining
    irrigation rate and time. Farmers may use mobile phones or wireless personal digital
    assistants to remotely control data loggers and monitor and analyze moisture for
    irrigation scheduling and automation. The applications of different machine learning
    algorithms in developing irrigation support systems are shown in Table 5. The
    irrigation DSS allows a weekly schedule to meet the irrigation water needs of
    a plantation based on inputs to a data-driven model. Some automated and smart
    irrigation systems using WSN, the Internet, cloud computing, and optimization
    tools are discussed in Krishnan et al. (2020) and Ramachandran et al. (2018),
    among others. TABLE 5. Application of machine learning techniques as decision
    support systems in Internet of Things (IoT)-based agricultural applications. Application
    of IoT in irrigation decision support, input, and salient features Reference Input
    variables: Temperature, relative humidity, wind speed, rainfall, dew point, vapor
    pressure deficit Machine learning model used in formulating decision system: partial
    least square regression (PLSR) and adaptive neuro-fuzzy inference system (ANFIS)
    Navarro-Hellín et al. (2016) Input variables: User programed areas, crop types,
    and water supply Major Features: On-board decision system considering existing
    resources, irrigational cost-savings Balafoutis et al. (2017) Input variables:
    Geographic location of experimental plots, crop type, sowing and harvest dates,
    soil texture, and irrigation method Output variables: Soil water balance, irrigation
    scheduling Main Feature: Database for data repository Simionesei et al. (2020)
    Major features: Water management, irrigation estimations, irrigation layouts designing,
    scheduling water deliveries, and recording water consumption Mateos et al. (2002)
    Major features: FAO-56 dual crop coefficient approach used in simulating soil
    water balance taking online weather forecast into account, and based on that,
    future irrigation schedules formulated Li et al. (2018) Input variables: Forecasted
    rainfall and water stress index Major features: Two irrigation scheduling methods
    (decision support system [DSS]-based and soil-moisture based) have been proposed
    to improve cotton yield and water productivity Chen et al. (2020) Irrigation scheduling
    has been formulated using Fuzzy logic methods Giusti and Marsili-Libelli (2015)
    Output variable: Irrigation schedules Machine learning model: Linear regression,
    random forest regression and support vector regression Torres-Sanchez et al. (2020)
    4.3 Smart greenhouse One application of WSNs includes the conversion of a traditional
    greenhouse into a “smart greenhouse” (Kodali et al., 2016). The sensors automatically
    adjust the greenhouse climatic conditions, such as air pressure, relative humidity,
    air temperature, and light conditions, according to a particular set of instructions.
    The real-time greenhouse environment may be monitored via email and SMS alerts
    on mobile phones. For example, the installation of soil moisture sensors in the
    greenhouse activates an irrigation system only when the soil is dry. Recently,
    the use of solar-powered IoT sensors (Hou & Gao, 2010) has made building smart
    greenhouses an inexpensive and popular choice. 4.4 Data management With an increase
    in the application of IoT in multiple sectors and high-performance computing trends,
    the conventional database system has failed to meet the need and demand for massive
    sensor-derived data storage. In this regard, cloud base and fogging data storage
    in IoT platforms play a vital role in managing, transferring, and analyzing data
    into meaningful information using analytical tools. Cloud and fog computing have
    their characteristics to process data burdens and preferences, but they supplement
    each other. Using predictive analytics, a farmer could better predict weather
    conditions, maintain crop quality, and enhance soil fertility to formulate better
    plans and decisions related to crop harvesting and enhance crop quality and productivity.
    4.4.1 Cloud computing Cloud-based data management provides an option for computing
    resources on a pay-per-use basis. It is an extension of cluster and grid computing
    that collects resources at one central place and utilizes them for high-performance
    computing employing wireless connections (Qian et al., 2009; Armburst et al.,
    2020; Dillon et al., 2010). Such a computing system could be divided into two
    parts: front end and backend. The front end consists of client devices, such as
    computers, cell phones, tablets, and iPads, whereas the backend consists of data
    storage and processing located far away from the client. Cloud computing architecture
    provides three types of services, such as Infrastructure as a Service (IaaS),
    PaaS, and Software as a Service (SaaS) (Dempsey & Kelliher, 2018; Jagli et al.,
    2018; Laghari et al., 2016). IaaS platform is a remote data center that provides
    the right to change or configure storage capacity, processing power, and networking
    to their needs. PaaS provides a development platform for an application developer
    to create, test, and launch an application. SaaS deals with ready-made software
    tailored to various business needs and customer services. Cloud technology is
    also used to deliver mobile applications and is called mobile cloud computing
    (MCC). This method handles the information and relocates the storage from mobile
    devices to intense and centralized computing platforms situated in the cloud (Huang,
    2011). MCC takes the pressure off mobile devices by harnessing the power of cloud
    infrastructure. Many cloud service providers are compatible with Windows or Linux
    operating systems, such as Amazon Web Service, Server Space (ITGLOBAL), Microsoft
    Azure (Microsoft Corporation), Google Cloud Platform (Google LLC), IBM Cloud Services
    (International Business Machines Corporation), Adobe Creative Cloud (Adobe Inc),
    and Dropbox (Dropbox Inc). 4.4.2 Fog computing The motivation behind fog computing
    is the need for real-time computing. It is an extension of cloud computing that
    consists of multiple edge nodes directly connected to the physical device. As
    the nodes are physically much closer to the device, it seems more advanced and
    provides better performance than cloud computing for handling user requests and
    emerging standards (Atlam et al., 2018; Khan et al., 2017). Fog computing can
    include cloudlets, a small-scale and robust data center located at the edge of
    the network system to perform computation without sending it to a distant server.
    Thus, fog computing acts as an intermediary between computing hardware and a remote
    server, controls the information being sent to the server, and processes it locally.
    It supports heterogeneous devices to provide greater interoperability than cloud
    computing. However, the security and privacy concerns in Fog computing are big
    issues due to the prevalence of wireless networks from a business point of view
    compared to cloud computing and deserve further research (Khan et al., 2017).
    Because of attacks, such as jamming attacks, and sniffer attacks, numerous organizations
    are focusing on considerable research on the security issue of Fog computing,
    including Cisco, Microsoft Corporation, ARM Holding Plc, and Dell Inc. Farmers
    benefit from cloud and fog data management by registering into the system application.
    The application is often designed to store farmers’ details, agronomic marketing
    details, agronomic vendors, and agricultural service providers, such as fertilizer,
    pesticides, seed, and equipment, and information on the government''s scheme.
    Indeed, cloud and fog data management systems have both advantages and disadvantages
    (Table 6), which largely determine the choice of using one over another. TABLE
    6. Pros and cons of cloud and fog computing in Internet of Things (IoT). Cloud
    for IoT Fog for IoT Pros Cons Pros Cons Improved performance between IoT sensors
    and data processing system High latency because of the distance between client
    devices and data processing centers Low latency because users are geographically
    closer to Fog to get an instant response A more complicated system in data processing
    and storage/decentralized computing Storage capacity can be scalable to store
    and share enormous amounts of data Downtime due to interruption in network and
    multiple connected channels No issues with bandwidth and connection because multiple
    interconnected channels are involved in sending the data Additional expense requires
    routers, hubs, and gateways Virtual processing capabilities on demand via remote
    data center Security and privacy could be limited because thousands of gigabytes
    of data are being transferred simultaneously High security because numerous nodes
    are involved in the complex distribution system Potential for cyberattacks, such
    as jamming and sniffer due to the extension of network''s edge Reduced cost because
    of lower licensing fees than the cost of equipment and maintenance Rescheduling
    of failure management is slow Power efficiency and improved user experiences because
    each node runs efficiently and provides instant response to the users Limited
    scalability—because it cannot be scalable as the cloud 5 CHALLENGES AND OPPORTUNITIES
    OF USING IOT IN AGRICULTURE Data-driven agricultural practices are largely focused
    on precision, predictive, smarter, and efficient farming practices with minimal
    use of resources and enhanced agricultural automation (Ayaz et al., 2019; Patil
    et al., 2012). Therefore, the usage of IoT in agriculture is inevitable with the
    increasing demand for food, land, and changes in climatic conditions. However,
    IoT in agriculture presents several challenges. These challenges and opportunities
    are observed at different levels of data handling and analysis: Collection, data
    transmission, processing and storage, and the application of the data inferred
    (i.e., inference drawn from available data without much expense of resources;
    Tzounis et al., 2017) and are discussed in detail as follows. 5.1 Data collection
    Different IoT sensors are typically designed for a particular agriculture practice
    (Dholu & Ghodinde, 2018). The use of such sensors in different locations and climates
    is often challenging and may require either modification in design or further
    calibration. An ideal sensor should be user-friendly, efficient, robust, and able
    to withstand variable weather conditions. Although experts in the field can set
    up, install, and connect equipment, the application of data by farmers on day-to-day
    basis demands skills and training. The collection of real-time data is increasingly
    important in precision farming and requires an active Internet connection, which
    further presents a major challenge in IoT applications in underdeveloped countries
    and rural areas in the United States (Federal Communications Commission, 2020).
    Although IoT has been widely used in the field of precision agriculture, only
    proprietary solutions are currently being implemented, which creates difficulties
    with device compatibility and connectivity. There is a pressing need to discover
    other approaches that employ interoperable hardware built on open standards and
    platforms. Lower priced alternatives to expensive proprietary solutions can be
    found in the form of many already available products that are built on open hardware,
    at least in part (Stočes et al., 2016). Scaling up the use of integrated IoT technologies
    beyond early adopters is important, especially by making existing solutions easier
    to use and more affordable, thereby improving their selection and use by farmers
    and food companies. Therefore, business models that work for small companies and
    systematic analysis of associated costs and benefits may be necessary. More effort
    is necessary in improving the utilization of IoT technologies in a wide range
    of climates, crops, and soils. Efforts could be centered on the development of
    IoT devices for harsh environments (open air, dirt, dust, moisture, animal manure,
    cold storage, hot cleaning treatments, etc.) and for natural objects (plants,
    animals, square meters of soil, perishable food products), which have limited
    ways to embed IoT devices in the objects themselves. This is especially true for
    devices that use new technologies because there has already been a lot of progress
    in adapting more mature technologies (Verdouw et al., 2017). Indeed, IoT includes
    a large variety of heterogeneous devices; therefore, it is challenging to achieve
    high levels of compatibility among devices if they employ dissimilar standards
    and protocols. In order to overcome such obstacles, standard IoT protocols ought
    to be designed (Abbasi et al., 2019). There are several challenges associated
    with UAV deployments in the agricultural sector, including limited flight durations
    (<1 h), small coverage area, high costs, large amounts of imagery data resulting
    from flights, and geometric and radiometric correction issues. Further, UAVs could
    interfere with civilian aircraft and generate safety issues. There are often stringent
    national laws issued by aviation authorities in each country regarding flying
    UAVs. Typically, the only permission granted is for educational or experimental
    purposes. In the United States, the maximum flight altitude is 120 m above ground
    level, and UAVs are not permitted to fly at night. Finally, processing large volumes
    of imagery data requires special skills, time, and software, often demanding the
    use of machine learning, communication technologies, and data repositories. 5.2
    Data transmission, storage, and processing IoT systems must communicate, store,
    and process the data they have acquired. Data transmission is made feasible with
    adequate connectivity. Many parts of the world, including the United States, have
    poor or no broadband and Internet connection. A significant obstacle to IoT applications
    is the access to internet. Presence of agricultural fields in distinct locations
    limits Internet use and other connectivity (Antony et al., 2020). The data collected
    from one agricultural landscape is often not applicable in other areas. Although
    proper storage and security of the collected data are important, the cost of storage
    and further analysis and processing of stored data to develop an inference for
    its application in the fields remains challenging. New technologies, such as Starlink
    (https://www.starlink.com), free TV band/channels, and other communication channels,
    could be exploited to substitute Internet at remote locations. Further, it is
    important to consider human factors when sharing and communicating information
    between farms, regions, and enterprises. 5.3 Data security Security of routing
    protocols is a major challenge in WSNs. Privacy issues in WSNs are either data-oriented
    or context-oriented. The former is largely associated with handling, preserving,
    and integrity of datasets. The latter deals with contextual information like location
    and time (Abbasi et al., 2019). Indeed, data security, anonymity, and privacy
    present both formidable challenges and opportunities to coordinate data transfer,
    availability, and usability securely for both small and large stakeholders. Agricultural
    data can be difficult to mine because of its volume, noise, gaps, and heterogeneity.
    This, however, provides opportunities for data imputation, standardization of
    IoT, integration of multiple domains, and collaborative research in sensor and
    communication technologies (Abbasi et al., 2019; Verdouw et al., 2017). There
    are opportunities for developing high-throughput phenotypic platforms through
    new sensors or improvements in existing sensors, robotics, remotely sensing vehicles,
    communication technologies, and deep learning methods. 5.4 Application of the
    inferred data IoT provides a foundation for smart logistics, intelligent transportation,
    and affordable agricultural application to address climatic challenges, improve
    resource utilization and efficiency, and increased productivity (Chen & Jin, 2012).
    However, challenges remain in efficient data transmission systems and adaptation
    of outputs by farmers. Indeed, farmers must be technology savvy to understand
    and utilize information. Certain changes may be necessary at farmers’ fields,
    which may incur additional expenses for data collection or processing. Rural farmers
    are often hesitant to adopt new technology. The use of IoT in agriculture is challenging
    due to the complexity of agricultural fields and farming operations. Research
    in IoT is often constrained by short-term funding; thus, limiting data collection
    processes. Antony et al. (2020) reported that 2 to 3 years of funding in the agriculture
    sector is relatively ineffective as plants’ cropping cycle may vary with weather
    conditions. However, the need to feed the growing population has bestowed opportunities
    in utilizing recent advances in IoT (Mahanta et al., 2022) in greenhouse farming,
    vertical farming, hydroponic, and plant phenotyping. Nevertheless, we see a plethora
    of opportunities to utilize WSNs, digital twins, machine learning, and cloud computing
    in soil and crop monitoring, irrigation scheduling, water quality analysis, plant
    breeding, weed control, disease, and pest identification, pesticide spray, reuse
    and recycling of wastes, and livestock management. 6 CONCLUSION This paper reviewed
    the application of different IoT platforms, WSNs, and technologies like UAVs,
    cloud computing, and big data analytics in agricultural production systems and
    value chains, such as crop monitoring, irrigation support, weed and pest control,
    fertilizer application, and soil health assessment. The literature, in general,
    indicates the use of sensors, actuators, microcontrollers, and machine learning
    in automated and smart irrigation systems and agricultural decision support. Different
    red, green, and blue, hyperspectral, multispectral, and LiDAR sensors could be
    mounted on UAVs for improved agricultural monitoring and forecasting to enable
    highly efficient, qualitative, and profitable farm products. Big data, data mining,
    and real-time analysis show promise to support and improve precision, prescription,
    enterprise, and automated agriculture. Cloud and fog data storage in IoT platforms,
    however, appear to be crucial in managing, transferring, and analyzing big agricultural
    data. This review also reveals opportunities in improving data security, anonymity,
    and usability, and developing high-throughput phenotypic platforms through new
    sensors or improvements in existing sensors, robotics, remote vehicles, communication
    technologies, and deep learning methods. Overall, IoT can improve production levels,
    cost-effectiveness, product quality, safety, and traceability through innovation,
    automation, and control while advancing the much-needed digital transformation
    of the agricultural sector in the face of climate change. AUTHOR CONTRIBUTIONS
    Sambandh Dhal: Conceptualization; data curation; formal analysis; methodology;
    visualization; writing—original draft; writing—review and editing. Briana Wyatt:
    Conceptualization; methodology; visualization; writing—original draft; writing—review
    and editing. Shikhadri Mahanta: Methodology; writing—original draft; writing—review
    and editing. Nishan Bhattarai: Conceptualizatoin; methodology; writing—original
    draft; writing—review and editing. Sadikshya Sharma: Conceptualization; writing—original
    draft; writing—review and editing. Tapas Rout, Pradip Saud: Writing—original draft;
    writing—review and editing. Bharat Sharma Acharya: Conceptualization; data curation;
    methodology; project administration; supervision; visualization; writing—original
    draft; writing—review and editing. ACKNOWLEDGMENTS The authors express their sincere
    thanks to two anonymous reviewers and the editor for their valuable comments and
    suggestions, which helped to improve the manuscript substantially. CONFLICT OF
    INTEREST STATEMENT The authors declare that they have no conflict of interests
    or personal relationships that could have appeared to influence the work reported
    in this paper. DISCLAIMER The authors are responsible for the views expressed
    in this paper and do not necessarily represent or reflect the views and policies
    of their universities or organization. REFERENCES Citing Literature Early View
    Online Version of Record before inclusion in an issue Figures References Related
    Information Recommended Digital agriculture platforms: Driving data‐enabled agricultural
    innovation in a world fraught with privacy and security concerns Bryan C. Runck,  Alison
    Joglekar,  Kevin A. T. Silverstein,  Connie Chan-Kang,  Philip G. Pardey,  James
    C. Wilgenbusch Agronomy Journal IoT and ML‐based automatic irrigation system for
    smart agriculture system Anoop E G,  G. Josemin Bala Agronomy Journal RETRACTED:
    Real‐time agricultural field monitoring and smart irrigation architecture using
    the internet of things and quadrotor unmanned aerial vehicles Rajalakshmi Selvaraj,  Venu
    Madhav Kuthadi,  S. Baskar Agronomy Journal Adoption of Precision Agriculture
    Technologies by U.S. Corn Producers Stan G. Daberkow,  William D. McBride Proceedings
    of the Fourth International Conference on Precision Agriculture, [1] Artificial
    intelligence in farming: Challenges and opportunities for building trust Maaz
    Gardezi,  Bhavna Joshi,  Donna M. Rizzo,  Mark Ryan,  Edward Prutzer,  Skye Brugler,  Ali
    Dadkhah Agronomy Journal Download PDF © 2024 American Society of Agronomy, Crop
    Science Society of America, and Soil Science Society of America AGRONOMY.ORG,
    CROPS.ORG, SOILS.ORG MEMBERSHIP: AGRONOMY, CROPS, SOILS MEETINGS CCA SITE CAREERPLACEMENT.ORG
    Advertising Submit an article Author Resources Editorial Policies Librarian Resources
    Contact Publications Additional links ABOUT WILEY ONLINE LIBRARY Privacy Policy
    Terms of Use About Cookies Manage Cookies Accessibility Wiley Research DE&I Statement
    and Publishing Policies HELP & SUPPORT Contact Us Training and Support DMCA &
    Reporting Piracy OPPORTUNITIES Subscription Agents Advertisers & Corporate Partners
    CONNECT WITH WILEY The Wiley Network Wiley Press Room Copyright © 1999-2024 John
    Wiley & Sons, Inc or related companies. All rights reserved, including rights
    for text and data mining and training of artificial technologies or similar technologies."'
  inline_citation: '>'
  journal: Agronomy Journal
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Internet of Things (IoT) in digital agriculture: An overview'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors: []
  citation_count: '0'
  description: 'The proceedings contain 75 papers presendted at a virtual meeting.
    The special focus in this conference is on Information and Communication Technology
    for Competitive Strategies. The topics include: Model-Based Design Technique to
    Monitor Vehicle Exhaust Emissions; image Matching Techniques: A Review; A Survey
    on In-Order 5-Stage Pipeline RISC-V Processor Implementation; investigating Gammatone
    Filterbank-Based i-Vectors for Speaker Verification Task; a Review on Single-Phase
    Integrated Battery Chargers for Electric Vehicles; centralized Library Management
    System: An E-governance Approach for Improving Accessibility of Library Resources
    of Bangladesh; predict Future Events Over Smart Environment Through Modified Apriori
    Algorithm; data Encryption Basing on the Existence of Eulerian Circuits in a Group
    of Random Graphs; stock Market Prices and Returns Forecasting Using Deep Learning
    Based on Technical and Fundamental Analysis; data Sharing Approach for Personal
    Health Record by Session Password and Access Key in Cloud Storage; Reconnaissance
    for Penetration Testing Using Active Scanning of MITRE ATT&CK; real-Time Patient
    Monitoring System and Security Using Internet Protocols for Medical Industry;
    Cooperative Multi-Agent Nash Q-Learning (CMNQL) for Decision Building in Retail
    Shop; Automatic Brain Tumor Segmentation on Pre-operative MRI using Region Growing
    Algorithm; data Integrity Verification Schemes in Cloud Computing Environment:
    A Survey; wireless Sensor Network-Based Automation of Irrigation in India; intelligent
    IoT-Based Monitoring Rover for Smart Agriculture Farming in Rural Areas; a Comprehensive
    Framework for the IoT-Based Smart Home Automation Using Blynk; digitization of
    Measuring Scales in Social Science Research Area; does Stock Exchange Influence
    Economic Growth? An Exploratory Study from the Prospective of Gambia; online Learning
    App; preface.'
  doi: null
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: Lecture Notes in Networks and Systems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 6th International Conference on Information and Communication Technology
    for Competitive Strategies, ICTCS 2021
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Gyrard A.
  - Jaimini U.
  - Gaur M.
  - Shekharpour S.
  - Thirunarayan K.
  - Sheth A.
  citation_count: '3'
  description: 'Background: Current health applications (e.g., Google Fit) based on
    devices (e.g., Fitbit) often are limited to data visualization, summarization,
    or statistics-based models to understand and explore the patient data. The data
    must be more meaningful for the patient in a contextualized and personalized manner.
    Objective: A knowledge-based reasoning architecture is designed to collect, manage,
    integrate, and analyze multimodal health data from sources such as smart phone
    applications, wearable devices, Internet of Things (IoT) devices, and environmental
    sensors. The architecture and associated methods with several use cases are demonstrated
    in the chapter. Methods: A personalized health knowledge graph is developed to
    capture personalized and contextualized patient data from smartphone applications,
    wearables, and environmental sensors. It converts the data into knowledge using
    relevant medical knowledge from existing ontologies. The personalized health knowledge
    graph and its use cases consists of (1) Kno.e.sis asthma ontology, whose core
    model (e.g., patient) is generic enough to be reused for other use cases, and
    (2) a rule-based reasoning engine, which infers high-level abstractions from data
    annotated with Kno.e.sis asthma ontology to provide suggestions to patients. Results:
    The designed architecture is comprised of components compliant with each other:
    (1) A personalized health knowledge graph, which integrates cross-domain knowledge
    (asthma, weather, W3C SOSA SSN, smart home), (2) an automatic semantic annotation
    engine, (3) a rule (IF THEN ELSE) data set, which reuses domain expertise, (4)
    a rule-based inference engine to automatically infer new abstractions, and (5)
    a generic query engine to query inferred data and provides suggestions for a better
    health management. The architecture reuses and integrates knowledge in a machine-processable
    form to replace human interpretation as a long-term goal. Conclusion: The knowledge
    graph based reasoning is comprised of a set of tutorials with SPARQL queries and
    end-to-end scenarios (e.g., asthma, obesity, allergies to food). The methodology
    used to develop the knowledge graph can be generalized, refined, and reused for
    other diseases or even to other domains such as agriculture with smart irrigation
    to deal with different crop types, robotics in smart home for ageing people, smart
    energy, etc. The health knowledge graph can be used as a gold standard to design
    KG made with Machine Learning algorithms automatically.'
  doi: 10.1016/B978-0-32-391773-5.00016-9
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln Access through another institution
    University of Nebraska-Lincoln Libraries does not subscribe to this content on
    ScienceDirect. Article preview Abstract Cited by (3) Semantic Models in IoT and
    eHealth Applications Intelligent Data-Centric Systems 2022, Pages 199-225 Chapter
    10 - Reasoning over personalized healthcare knowledge graph: a case study of patients
    with allergies and symptoms Author links open overlay panel Amelie Gyrard a, Utkarshani
    Jaimini a c, Manas Gaur a c, Saeedeh Shekharpour b, Krishnaprasad Thirunarayan
    a, Amit Sheth a c Show more Add to Mendeley Share Cite https://doi.org/10.1016/B978-0-32-391773-5.00016-9
    Get rights and content Abstract Background: Current health applications (e.g.,
    Google Fit) based on devices (e.g., Fitbit) often are limited to data visualization,
    summarization, or statistics-based models to understand and explore the patient
    data. The data must be more meaningful for the patient in a contextualized and
    personalized manner. Objective: A knowledge-based reasoning architecture is designed
    to collect, manage, integrate, and analyze multimodal health data from sources
    such as smart phone applications, wearable devices, Internet of Things (IoT) devices,
    and environmental sensors. The architecture and associated methods with several
    use cases are demonstrated in the chapter. Methods: A personalized health knowledge
    graph is developed to capture personalized and contextualized patient data from
    smartphone applications, wearables, and environmental sensors. It converts the
    data into knowledge using relevant medical knowledge from existing ontologies.
    The personalized health knowledge graph and its use cases consists of (1) Kno.e.sis
    asthma ontology, whose core model (e.g., patient) is generic enough to be reused
    for other use cases, and (2) a rule-based reasoning engine, which infers high-level
    abstractions from data annotated with Kno.e.sis asthma ontology to provide suggestions
    to patients. Results: The designed architecture is comprised of components compliant
    with each other: (1) A personalized health knowledge graph, which integrates cross-domain
    knowledge (asthma, weather, W3C SOSA SSN, smart home), (2) an automatic semantic
    annotation engine, (3) a rule (IF THEN ELSE) data set, which reuses domain expertise,
    (4) a rule-based inference engine to automatically infer new abstractions, and
    (5) a generic query engine to query inferred data and provides suggestions for
    a better health management. The architecture reuses and integrates knowledge in
    a machine-processable form to replace human interpretation as a long-term goal.
    Conclusion: The knowledge graph based reasoning is comprised of a set of tutorials
    with SPARQL queries and end-to-end scenarios (e.g., asthma, obesity, allergies
    to food). The methodology used to develop the knowledge graph can be generalized,
    refined, and reused for other diseases or even to other domains such as agriculture
    with smart irrigation to deal with different crop types, robotics in smart home
    for ageing people, smart energy, etc. The health knowledge graph can be used as
    a gold standard to design KG made with Machine Learning algorithms automatically.
    References (0) Cited by (3) SAREF4EHAW-compliant knowledge discovery and reasoning
    for IoT-based preventive health and well-being: IoT-based preventive health and
    well-being knowledge discovery and reasoning 2022, Semantic Models in IoT and
    eHealth Applications Show abstract A naturopathy knowledge graph and recommendation
    system to boost the immune system: KISS: Knowledge-based Immune System Suggestion
    2022, Semantic Models in IoT and eHealth Applications Show abstract A Smart Multimodal
    Biomedical Diagnosis Based on Patient’s Medical Questions and Symptoms 2023, 5G-Based
    Smart Hospitals and Healthcare Systems: Evaluation, Integration, and Deployment
    View full text Copyright © 2022 Elsevier Inc. All rights reserved. Recommended
    articles Role of IoT and semantics in e-Health Semantic Models in IoT and eHealth
    Applications, 2022, pp. 19-37 Abinaya Inbamani, …, Thirumeni Mariammal BERT based
    clinical knowledge extraction for biomedical knowledge graph construction and
    analysis Computer Methods and Programs in Biomedicine Update, Volume 1, 2021,
    Article 100042 Ayoub Harnoune, …, Bouchra El Asri The security and privacy aspects
    in semantic web enabled IoT-based healthcare information systems Semantic Models
    in IoT and eHealth Applications, 2022, pp. 89-116 Ozgu Can Show 3 more articles
    Article Metrics Citations Citation Indexes: 3 Captures Readers: 16 Social Media
    Shares, Likes & Comments: 22 View details About ScienceDirect Remote access Shopping
    cart Advertise Contact and support Terms and conditions Privacy policy Cookies
    are used by this site. Cookie settings | Your Privacy Choices All content on this
    site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights
    are reserved, including those for text and data mining, AI training, and similar
    technologies. For all open access content, the Creative Commons licensing terms
    apply."'
  inline_citation: '>'
  journal: Semantic Models in IoT and eHealth Applications
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Reasoning over personalized healthcare knowledge graph: a case study of
    patients with allergies and symptoms'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Nagasubramanian G.
  - Sakthivel R.K.
  - Patan R.
  - Sankayya M.
  - Daneshmand M.
  - Gandomi A.H.
  citation_count: '48'
  description: Internet of Things (IoT) in the agriculture field provides crops-oriented
    data sharing and automatic farming solutions under single network coverage. The
    components of IoT collect the observable data from different plants at different
    points. The data gathered through IoT components, such as sensors and cameras,
    can be used to be manipulated for a better farming-oriented decision-making process.
    This work proposes a system that observes the crops' growth and leaf diseases
    continuously for advising farmers in need. To provide analytical statistics on
    plant growth and disease patterns, the proposed framework uses machine learning
    (ML) techniques, such as support vector machine (SVM) and convolutional neural
    network (CNN). This framework produces efficient crop condition notifications
    to terminal IoT components which are assisting in irrigation, nutrition planning,
    and environmental compliance related to the farming lands. In this regard, this
    work proposes ensemble classification and pattern recognition for crop monitoring
    system (ECPRC) to identify plant diseases at the early stages. The proposed ECPRC
    uses ensemble nonlinear SVM (ENSVM) for detecting leaf and crop diseases. In addition,
    this work performs comparative analysis between various ML techniques, such as
    SVM, CNN, naïve Bayes, and K -nearest neighbors. In this experimental section,
    the results show that the proposed ECPRC system works optimally compared to the
    other systems.
  doi: 10.1109/JIOT.2021.3072908
  full_citation: '>'
  full_text: '>

    "IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account
    Personal Sign In Browse My Settings Help Access provided by: University of Nebraska
    - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards
    Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Internet of Things
    Journal >Volume: 8 Issue: 16 Ensemble Classification and IoT-Based Pattern Recognition
    for Crop Disease Monitoring System Publisher: IEEE Cite This PDF Gayathri Nagasubramanian;
    Rakesh Kumar Sakthivel; Rizwan Patan; Muthuramalingam Sankayya; Mahmoud Daneshmand;
    Amir H. Gandomi All Authors 39 Cites in Papers 1692 Full Text Views Abstract Document
    Sections I. Introduction II. Literature Review III. Proposed Approach IV. Results
    V. Conclusion Authors Figures References Citations Keywords Metrics Abstract:
    Internet of Things (IoT) in the agriculture field provides crops-oriented data
    sharing and automatic farming solutions under single network coverage. The components
    of IoT collect the observable data from different plants at different points.
    The data gathered through IoT components, such as sensors and cameras, can be
    used to be manipulated for a better farming-oriented decision-making process.
    This work proposes a system that observes the crops'' growth and leaf diseases
    continuously for advising farmers in need. To provide analytical statistics on
    plant growth and disease patterns, the proposed framework uses machine learning
    (ML) techniques, such as support vector machine (SVM) and convolutional neural
    network (CNN). This framework produces efficient crop condition notifications
    to terminal IoT components which are assisting in irrigation, nutrition planning,
    and environmental compliance related to the farming lands. In this regard, this
    work proposes ensemble classification and pattern recognition for crop monitoring
    system (ECPRC) to identify plant diseases at the early stages. The proposed ECPRC
    uses ensemble nonlinear SVM (ENSVM) for detecting leaf and crop diseases. In addition,
    this work performs comparative analysis between various ML techniques, such as
    SVM, CNN, naïve Bayes, and K-nearest neighbors. In this experimental section,
    the results show that the proposed ECPRC system works optimally compared to the
    other systems. Published in: IEEE Internet of Things Journal ( Volume: 8, Issue:
    16, 15 August 2021) Page(s): 12847 - 12854 Date of Publication: 13 April 2021
    ISSN Information: DOI: 10.1109/JIOT.2021.3072908 Publisher: IEEE SECTION I. Introduction
    Ensemble classification and pattern recognition for crop monitoring system (ECPRC)
    for plant disease recognition supports the farmer to take proactive decisions
    at the beginning point of the disease growth. Manual or visual recognition of
    these diseases from the observed plant portions (patterns) is inaccurate and inefficient.
    Moreover, the way of recognition requires a well-talented botanist. The issues
    that occur during conventional approaches can be rectified using ECPRC automatically.
    ECPRC focuses on the development of spontaneous recognition and classification
    of the crop diseases from the gathered high-resolution multispectral images, hyperspectral
    images, and stereotype images. For example, sugar beet leaves are usually infected
    by the diseases like Downy mildew, rust, Cercospora leaf spot, and phoma leaf
    spot. In this regard, Rao and Sridhar [1] and Sreekantha and Kavya [2] analyzed
    the intelligent crop monitoring and irrigation system to help in the growth of
    the plants. Shaikh et al. [15] analyzed the green technologies applications in
    the agriculture fields. Ray [3] and Tzounis et al. [7] explained the Internet
    of Things (IoT) future trends and architectures, respectively. IoT devices include
    high-resolution spectral cameras, agriculture sensors, and a Raspberry Pi controller
    which has been manipulating the plant images using machine learning (ML) algorithms.
    The images taken by the cameras are processed by extracting the leaf portions
    of the images. Then, the extracted leaf regions are segmented using Otsu’s method.
    Once the leaf regions are segmented, the disease portions are identified by using
    the Sobel edge detection approach for pointing disease-infected points in the
    leaves. These image processing techniques are used to spot the disease in the
    plant leaves but not to classify them efficiently. In order to achieve disease
    pattern-wise classifications, and recognition of diseases, many ML approaches
    are taken by the researchers. For example, agricultural researchers, Marjanin
    [4], focused on the problems and solutions of agriculture development. Further,
    the other researchers developed the techniques, such as support vector machine
    (SVM), PCA, convolutional neural network (CNN) [14], [17], [18], decision trees,
    backpropagation neural networks, and K -nearest neighbors’ classification for
    the disease classification. On the way, Lee et al. [8] pointed out phytophthora
    infest diseases on the tomatoes. They used various IoT components to build the
    system. Likewise, Xu et al. [9] applied SVM cotton mold diseases based on their
    visual marks. The main scope of this proposed ECPRC scheme is to develop a versatile
    crop disease monitoring system and IoT-based automatic decision-making system.
    Existing works mainly focus on offline or outdated data items for leaf disease
    detection. This is taken as a serious problem, which is the scope of the proposed
    work, that aims to provide real-time IoT data analysis. The other contribution
    of this work is to develop ML- and DL-based multiclassification models for detecting
    the real-time IoT (sensors) inputs gathered from various leaves. In addition,
    this work mainly concentrates on the efficient application of ensemble nonlinear
    SVM (ENSVM), K -nearest, and CNN in leaf disease detection. The comparative experimental
    analysis helps to analyze the leaf patterns and disease particles from different
    perspectives. The overall article is organized as follows. Section II gives the
    literature review, Section III provides the proposed work, Section IV provides
    the results, and finally, Section V ends with the conclusion. SECTION II. Literature
    Review The agriculture field requires more attention to be developed with intelligent
    monitoring and decision-making systems. Different types of research were carried
    out to identify various crop diseases. Rao and Sridhar [1] used several strategies
    to precise the captured indications in the cotton leaves. The images used in this
    work were maintained at nominal resolutions. These images were preprocessed and
    located in a separate image database. The conventional edge detection and classification
    techniques were used by the authors to identify the cotton leaf diseases. In addition
    to that, K -nearest classification was used to extract the color features of different
    leaves and SVM was applied to identify the diseases in plant leaves efficiently.
    Sreekantha and Kavya [2] projected a disease monitoring system for cotton plant
    diseases. The diseases were recognized by them using the images, that reflect
    the disease spot marks on the cotton leaves. The authors processed the images
    under commercial mobile cameras in an uncontrolled situation of the farmland.
    This type of image processing makes the leaf segmentation critical. This work
    used two different types of sequenced classifiers. At the first stage, the classifier
    isolates the leaf from the image background using local image features. After
    that, the classifier spots out the diseases using the hue and luminance of the
    image. This kind of research signs is good to apply ML techniques for the disease
    monitoring system in IoT-based farming fields. On this research path, Marjani
    [4] delivered a grayscale morphology-based leaf nerve extraction system. To extract
    the leaf features, the color images of the leaves were converted into grayscale
    images based on the intensity and hue contents of the image. Then, grayscale morphology
    technique was taken to remove a color confusing section of the image. The next
    step is used to identify the grayscale variations for the leaf part and nerve
    part. In the end, an optimal threshold value is determined to isolate the nerve
    part of the leaf from others. These works were mainly used to recognize the leaf
    features which are helpful to identify the disease portions at different points
    of any leaf. Further, Rajeswari et al. [5] identified the applications of X-ray
    image processing to spot the plant diseases. In this work, the leaf’s 2-D images
    were used for extracting the geometrical features and digital morphological features.
    The goal of this research work was to familiarize the appropriate features from
    the leaf patterns for future agricultural research. Mahdavinejad et al. [6] proposed
    the ANN-based plant-type identification system from the given leaf images. In
    addition to the image processing techniques, the authors used the properties of
    the given leaf image (leaf aspect ratio, apex attributes, deviation ratio, and
    leaf angle). These leaf properties were given to ANN as a set of input. The authors
    collected around 550 leaf patterns for various plants. According to that, they
    trained more than 400 leaves and acquired 93% accuracy in the plant identification.
    Srinivasalu et al. [13] used SVM for recognizing the cotton plant diseases, such
    as bacterial infections, Cercospora, and Alternaria. This work was extended in
    which, the results produced by SVM were given to the Android platform for better
    projection. This system makes the IoT platform work with ML techniques. There
    are many research works which have made their contributions in the field of the
    crop monitoring system. The proposed ECPRC concentrates on the sugar beets diseases,
    which is common in India. In this work, ENSVM (vital) is applied for the classification
    of the diseases. The conventional SVM has basic classification rules which are
    not effectively adaptable for multiple disease classification. However, ENSVM
    has multiple subclassifiers compared to the other techniques. ML is a technology
    used to train the computer system for making decisions based on the learning techniques.
    ML techniques are generally used to give learning capability to the computer systems.
    This is called the skill to learn. There are various ML techniques available.
    They are: supervised learning; unsupervised learning; clustering and classification;
    data preprocessing; dimensionality reduction; multilayer perceptron; nonparametric
    methods; hidden Markov model. Among these techniques, this proposed work uses
    an SVM with ensemble nonlinear classification. Unlike SVM (linear), ensemble nonlinear
    classification uses multilayer classifiers, which support uncertain conditions
    of leaf pattern detections. This helps to project more efficient classified results
    on disease detection. Similarly, CNN is applied for detecting leaf diseases. CNN
    is a type of multilayer perceptron model. Mainly, it is applied with many layers
    of filters. The filter types may be implemented as 5×5,4×4,3×3,… CNN does convolution
    at the beginning of filter sections to split the image patterns. Finally, it does
    deconvolution for getting the integrated results. The multilayer perceptron is
    referred to the fully connected neural networks. This means each neuron of a particular
    layer is connected to all neurons in the succeeding layer. However, CNNs take
    the benefits of the hierarchical pattern in the leaf data and create more complex
    leaf patterns for generating meaningful complex data. This gives more accurate
    results in disease detection. Finally, this proposed work uses the K -means clustering
    technique for finding the classes of various disease patterns in a leaf. K -means
    clustering is a technique, which uses the vector quantization approach. This is
    mainly derived from the signal processing technique. The technique is developed
    from the steps of cluster analysis in the data mining domain. The K -means clustering
    technique was developed of the classification partitions with n number of continuous
    observations into k time of cluster units. Each observation gathered at different
    time intervals belongs to any one of the clusters. The clustered observations
    maintain the mean value. This is nonpolynomial (NP) hard in the computational
    aspect. This has a direct conceptual relationship with the K -nearest neighbor
    classification. The proposed system uses this technique for leaf disease classification.
    SECTION III. Proposed Approach In this proposed system, temperature sensors, soil
    moisture sensors, and light sensors are used to measure the temperature value,
    moisture level, and light intensity level of the plants, respectively. The data
    gathered from these sensors are manipulated by the Arduino UNO microprocessor
    unit. Fig. 1 provides the overall system architecture for the process of disease
    detection. Fig. 1. Basic system architecture. Show All Then, the values are used
    by ENSVM and CNN to identify the plant disease. To achieve this disease analysis,
    ENSVM- and CNN-based algorithms are used to make a training sample of leaf images
    and optimal threshold values for the leaf features. There are three modules in
    this proposed system. They are: hardware module; analysis module; decision-making
    module. The hardware module contains the Arduino controller unit, sensors, and
    cameras, and the analysis module maintains ML techniques activation. This module
    covered training and testing information about the leaves and leaf patterns. In
    the sensing module, the following sensors are used in the farming field. They
    are used to monitor each and every point in the plant. In addition to that, multiple
    sensors are deployed to measure environmental conditions. These components are
    connected via relays to the respective terminal devices, such as water motor and
    other computer systems. The design of the IoT architecture depends upon the components
    required to achieve the goal. Ray [10] analyzed different types of IoT architectures
    in detail. The components involved in the IoT system include any communicating
    device, terminal device, wireless sensor nodes, and networks. Ojha et al. [11]
    discussed the adaptation of the wireless sensor network in the IoT design. The
    represented components can communicate with the mobile phones to give the manipulated
    results regarding the disease classification, sensed environmental objects, and
    farmer suggestions. This kind of farming suggestion is given by the ML algorithms,
    SVM and CNN. Apart from these techniques, the component selection process is inevitable.
    Table I illustrates the details of the components used in this proposed work.
    Fig. 2 gives the specific pattern from the general structure in Fig. 1 to identify
    the plant disease. TABLE I IoT Components Fig. 2. ECPRC modules description. Show
    All A. ENSVM-Based Disease Identification SVM is an ML technique which is used
    to analyze and classify the given problem in a supervised manner. The supervised
    classification using SVM uses different classes of disease patterns and leaf patterns
    to classify the observed plant diseases. This proposed ECPRC uses ENSVM. The ENSVM
    manages the data classification by dividing the classifiers into several subfunctions
    to spot out the disease variations. This is the advantage of detecting various
    leaf diseases. Zhang et al. [16] used ensemble SVM (ENSVM) for pattern identification
    for cognitive tasks identification. As same as, this proposed system as discussed
    in Algorithm 1, uses ENSVM for leaf disease pattern identification. The ENSVM
    classifies the input image patterns into several classes, c and subclasses, with
    n samples and k patterns c∈{−n,+n} with respect to c=sign(f(k)). (1) View Source
    f(k) is a nonlinear grouping of kernels m ( ki , k ) calculating the resemblances
    between the training vector a and the given pattern vector, k , and ki . Here,
    ci represents the individual classifier unit in the multiclassifier module, where
    i varies from 1 to n . ai means the inputs of the individual classifier unit ci
    f (k) n = ∑ k=0 n aici⋅m (ki,k) n−k . (2) View Source ENSVM supports multiple
    classifier units according to various leaf patterns. The classifiers CS 1 ,…,
    CS j use the production rules, PR 1 ,…, PR j PRj (k) n = ∑ k=1 n PR j n−k . (3)
    View Source Algorithm 1 ENSVM-Based Disease Detection Input: Dataset P L , Classifier
    Splits, Samples m; Output: Classified data instances Step 1: Split the image data
    into subsets { I k j } s j=1 Step 2: Find sample disease instances, I D Step 3:
    Acquire ENSVM AS j from each subset I k j Step 4: A representation of sample estimation
    ∈ R x×s M=est (samp,  AS n ) (4) View Source Step 5: Learn the EMSVM samples Step
    6: Return the samples Step 7: Execute Smoothening function, SENSVM, S(n,a)=n+
    ∑ n=1 ∞ 1 B(log(1+Bn)) (5) View Source B-log distribution Step 8: Redo for all
    observed leaves, Ln. Fig. 3 illustrates the general process of ENSVM and the other
    classifiers in the ECPRC framework. In this figure, sensors and relays are shown
    in the hardware part. The ECPRC engine helps to activate either ENSVM or CNN activities
    once the data are received from the sensors. In addition, the overall units are
    controlled by the Arduino UNO module. The processed data can be stored anywhere
    as in cloud storage, local storage area, or remote database. This data is accessible
    from any place when it is hosted in the Internet domain. Preferably, they can
    be stored in portable cloud storage for providing security, accessibility, availability,
    and easy handling tasks. The ENSVM classifier handles the given testing data using
    the training data set. The training data set contains around 600 leaf patterns
    and 35 disease patterns. Fig. 3. ECPRC process for crop disease monitoring. Show
    All The disease patterns may belong to several disease classes. The ENSVM is also
    used to identify the nutrients in each leaf. However, this can be analyzed by
    CNN when compared to ENSVM. Apart from disease identification, ENSVM helps to
    give accurate chlorophyll, potassium, and nitrogen levels in plants. As same as,
    Lee et al. [12] used various types of prediction systems for big data systems.
    B. CNN-Based Disease Detection CNN has three different layers, such as the input
    layer, the output layer, and the hidden layer as same all the neural networks
    as depicted in Fig 4. CNN holds multiple stages of functions as follows: input
    phase; convolution phase; detector phase; pooling phase; normalization phase;
    output phase. Fig. 4. CNN structure. Show All CNN reduces the neural connections
    and complexity of the network functions to increase performance execution. Algorithm
    2 describes CNN-based crop disease detection. Dahikar and Rode [14] used CNN for
    predicting and recognizing the crop yield in the agricultural lands. This motivates
    the proposed system to use CNN for disease prediction in the leaves. Compared
    to SVM and ENSVM, CNN uses trained neuron functions and layers of filters for
    isolating different disease sectors with high-quality rate. The following algorithm
    is proposed using CNN which detects the diseases based on filtering applied over
    spectral features of the leaf images. This works better than ENSVM’s subclassifiers.
    Algorithm 2 CNN-Based Disease Detection Input: Image dataset, Samples Output:
    Disease Detections Step 1: Input image Im (raw image) has 32X32X3 size with RGB
    band (spectral bands) Step 2: Each image segments are weighted by convolutional
    layer function and form the neurons Step 3: Image filters are applied (15 Filters)
    Step 4: Relu activation function is applied on leaf elements with respect to a
    computed threshold value. Step 5: The down sampling operations have been activated
    using the pooling procedure using spatial details, SP 1 ,…,  SP m . Step 6: Compute
    classes and scores for different leaves and create CIFAR-10 set. Step 7: Create
    score-based disease symptoms in each leaf. Step 8: Redo the operations The main
    aim is to utilize the metaclassifier activities of ENSVM and CNN for detecting
    multiple leaf diseases. The motivation of this work lies in the usage of ML-based
    trained classifiers units of both ENSVM and CNN (DL) on dot spots identifications.
    These classifiers help to categorize multiple dot spots under multiple classes,
    which is an efficient way of detecting the disease classification. The main advantage
    of using ENSVM is providing subclassifiers for various element properties. But
    this is limited in ML aspects. In advance, CNN is used with multifiltering components
    (DL). The image segmentation, edge detection, and denoising processes of the crop
    disease detection system are implemented using the MATLAB tool. The Android studio
    is used to develop an application in mobile phone for successful monitoring of
    diseases and decision-making processes. In addition to these tools, the microprocessor
    uses an inbuilt operating system that governs the data gathered from different
    sensors. In CNN, m×m neural network layers are followed by a convolutional layer.
    For filter Fs, with f×f , dimension, the output of the convolutional layer is,
    (m−f+1)×(m−f+1) . Here, the prenonlinearity is denoted as p ℓ jk . The weighted
    filter components are computed for preceding neural layers as pℓjk= ∑ s=0 m ⋅
    ∑ l=0 m ( n k )Fsl x k−1 (j+s)(k+l) n−k . (6) View Source Then, CNN uses a nonlinear
    function x ℓ jk=σ( x ℓ jk). (7) View Source Here, σ —nonlinear function, and x
    ℓ jk —filters applied for input leaf sequences. The convolution and pooling phases
    are designed using 256 filters maximum as given in Table II. Further, Table II
    illustrates the details of the neural layers, filter sizes, and channels used
    to reconstruct the spectral images of the leaves at high-intensity levels. TABLE
    II CNN Phases SECTION IV. Results The input image of a leaf is given with RGB
    spectral information. The high-spectral image taken by HySpexHD camera is converted
    into its equivalent grayscale image. 75% of the data from the data set are used
    for training purposes and the remaining 25% are used for testing purposes. Fig.
    5(a) illustrates an RGB spectral image of the leaves and Fig. 5(b) depicts a grayscale
    image of the leaves. In the grayscale image, the dots in leaves are spotted clearly
    than the basic spectral view. Fig. 6(a) shows the noise coefficients of a given
    image, which gives unwanted depiction in an image. This phase helps to identify
    the leaves alone in the image. Further, these noise coefficients are used for
    denoising the image. Fig. 5. Input image patterns. (a) Given RGB image. (b) Grayscale
    image. Show All Fig. 6. Image recreation. (a) Noise coefficients. (b) Filtered
    output. Show All In addition, Fig. 6(b) gives another outcome, which filtered
    the leaf images. This filters the noise data. By comparing the training sets of
    these kinds of leaves, ENSVM and CNN identify the disease type. Fig. 7(a) provides
    a binary image to identify the exact leaves portion in the image. Then, the color
    enhancement helps to improve the contrast of the image to increase the visual
    interpretation of the image [Fig. 7(b)]. The Arduino UNO controller and the sensor
    units are illustrated with the display modules. Fig. 8 gives the reading of the
    temperature sensor (Celsius) and the humidity sensor (%) units with respect to
    the different croplands. The readings of the sensor vary from field to field.
    This kind of assistantship helps to clarify the environmental issues of the crop
    disease monitoring system. Fig. 7. Image enhancement. (a) Binary image. (b) Color-enhanced
    image. Show All Fig. 8. Sample sensor readings. Show All Be sure that the symbols
    in your equation have been defined. Fig. 8 represents the level of temperature
    and humidity in different agriculture fields. The temperature and the humidity
    of the field are linear to each other. Fig. 9 illustrates the defects in plant
    leaves (dark shades and dot spots). Fig. 9. Defects identification. Show All True
    positive and false negative are accurate decisions. This means true positive refers
    to the detection of disease and false-negative states the successful detection
    of a disease-less leaf. In contrast, true negative illustrates the disease where
    the leaf has no disease. As same as, false-positive gives a false alarm for disease
    detection. The variations of CNN and ENSVM with respect to their accuracy and
    recall rate, respectively. This shows that CNN gives better results than ENSVM.
    The K -nearest gives a moderate classification rate compared to the other two
    proposed techniques. In this manner, Table III provides a comparison between CNN,
    ENSVM, and K -nearest classification techniques. The techniques, such as Naïve
    Bayes, K -nearest, and other conventional approaches, are compared to the CNN
    and ENSVM, where the later approaches use multiple subclassification layers and
    spectral features-based filters. Moreover, these techniques are not more complex
    to create overhead in tiny IoT devices. It is very important to detect diseases
    from leaves using high-level spectral features and more subclassifiers than more
    complexity. TABLE III Quality Measurements The results are compared with the existing
    techniques [16] to evaluate the proposed system performance. The existing system
    uses ENSVM and Gaussian models for pattern identification with the task evaluation.
    In their models, they used a limited set of patterns and applied ML techniques
    only. But the proposed system deals with both ML and DL techniques. In addition,
    most of the techniques consider offline data sets. But the proposed system takes
    the real-time sensor data to gain real efficiency. Fig. 10 represents the connections
    of the agriculture monitoring system, temperature sensor, soil moisture sensor,
    and light intensity sensor. They are connected and the signals are amplified and
    sent for manipulating to the Arduino controller unit. LCD is used to display the
    values from the sensors. GSM is used to send the alert message to the farmer.
    Fig. 10. Connection of monitoring system. Show All Fig. 11 provides the various
    quality measurements in terms of recall, sensitivity, specificity, and precision
    for various techniques. Figs. 12 and 13 describe the performance and the comparative
    analysis of various ML techniques and ENSVM technique. Fig. 12 illustrates the
    absolute error rate in leaf pattern recognition. Fig. 13 depicts the computation
    overhead created by each ML and DL technique. In this comparison, CNN and ENSVM
    perform notably. Particularly, ENSVM effectively detects the leaf patterns. At
    the same time, CNN detects the leaf patterns and disease spots with minimal errors.
    The reason is that CNN is mainly implemented for image pattern recognition purposes.
    Fig. 11. Quality measurements. Show All Fig. 12. Error rate. Show All Fig. 13.
    Computation overhead. Show All Fig. 13 reveals the computation overhead of all
    the techniques. In this comparison, CNN produces little more overhead than ENSVM
    and other techniques. As CNN is a DL network, it has more complex filter functions
    than other systems. But the need for efficiency is important in disease identification.
    Thus, the overhead can be ignored. Other techniques, such as K -nearest, SVM,
    Bayesian network, and Naïve Bayes, produce limited overhead. However, they lack
    in accuracy rate. The evaluation process is experimented for increasing the number
    of leaf samples. SECTION V. Conclusion The ECPRC system was implemented to provide
    both environmental observance-based crop disease monitoring system. In this work,
    IoT infrastructures were deployed to monitor and capture the leaf images in hyperspectral
    modes. The hyperspectral images of the leaves were processed to track the disease
    points. These images were stored in cloud storage systems to be handled by ENSVM
    and CNN. CNN and ENSVM were used to train the IoT infrastructures to detect the
    various types of leaf diseases. In addition, the other ML techniques, such as
    K -nearest, Bayesian, Naïve Bayes, and conventional SVM techniques, were compared
    with each other for ensuring the real-time application of the intelligent crop
    disease monitoring system. In the future, this work is to be extended using a
    huge data set of multiple plants and its parts using the deep learning approaches.
    Authors Figures References Citations Keywords Metrics More Like This Prediction
    of Temperature and Humidity at Telkom University Landmark Tower (TULT) Using Support
    Vector Machine (SVM) and Internet of Things (IoT) 2023 International Conference
    on Data Science and Its Applications (ICoDSA) Published: 2023 Malware Detection
    Using Genetic Cascaded Support Vector Machine Classifier in Internet of Things
    2022 Second International Conference on Computer Science, Engineering and Applications
    (ICCSEA) Published: 2022 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Internet of Things Journal
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Ensemble Classification and IoT-Based Pattern Recognition for Crop Disease
    Monitoring System
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Chen Y.
  - You J.
  - Xing Z.
  - Hu H.
  - Mei G.
  - Shi Z.
  - Liu H.
  citation_count: '8'
  description: 'It is needed to solve the problems such as relatively low input-output
    ratio and environmental pollution for Chinese agriculture, with the large amount
    of agricultural production and consumption. In the background of changing international
    situation and frequent natural disasters, transforming traditional agricultural
    production methods in China is an urgent. Driven by emerging technologies such
    as artificial intelligence, internet of things, cloud platform, automatic control,
    and new generation communication and so on, precision agriculture came out and
    was undoubtedly an effective way. Precision agriculture has become a common choice
    for developing sustainable and high-yield agriculture around the world. In order
    to obtain the development orientation of precision agriculture and successful
    practices in the world, this paper reviews the studies on precision agriculture
    developing status. The aim of this paper is to refine the experiences of precision
    agriculture developing in the main developed countries and regions and take a
    look at the precision agriculture development in China. Adopting the method of
    systematic literature analyzing and summary, Section 1 studies the development
    status of precision agriculture in the main developed countries and regions, such
    as America, Japan, European Union and Israel. The idea of precision agriculture
    was first proposed in America. Until today, America has developed mature precision
    agriculture system, which benefits from the highly developed technologies. Considering
    the serious contradiction between large population and less farmland, during 1970s,
    Japan took measures of consolidating farmland on a large scale and building farmland
    infrastructure and so on to improve the agricultural production conditions. The
    agricultural community was also formed to operate collaboratively the agricultural
    production. The development of precision agriculture in European Union is driving
    by digital technologies. The water-saving agriculture represented by drip-irrigation
    and sprinkler-irrigation has made remarkable results in Israel. The development
    experiences of precision agriculture in the main developed countries and regions
    enlighten us that: 1) the leading by government is the key; 2) the informatization
    construction is the foundation; 3) the advanced technology is the core; 4) the
    cultivation of new type of farmers is the guarantee. Section 2 analyzed the basements
    and weaknesses for developing precision agriculture in China. The weaknesses are
    the emphasis in this section. First, the farmland in China is scattered and the
    infrastructure is not perfect. Taking the informatization perspective, even though
    number of agriculture related information systems exist, the data and information
    are not interoperable between these systems. Second, at the present stage, we
    cannot acquire the temporal and spatial continuous agricultural information due
    to the rarity domestic satellite data and ground sensors for agriculture monitoring.
    Third, automatic variable operating system and equipment are lacking since the
    technology integration of information technology, communication and agricultural
    machine has not been achieved. Fourth, insufficient high-quality agricultural
    talents. Facing these weakness and Chinese conditions, Section 3 provided five
    suggestions to develop precision agriculture in China. Firstly, our government
    should overall plan and give guarantee in police making, infrastructure construction
    and financial support, etc. Secondly, we should improve the agricultural production
    condition through expanding moderately the operating scale of farmland and constructing
    the field infrastructure net and the national agricultural information platform.
    Thirdly, the key technology research, such as the information retrieval using
    remote sensing and technology integration of communication, automatic controlling,
    spatial information and smart machinery must be focused. Fourthly, the new type
    of personnel in agricultural field can be cultivated. Fifthly, pilot demonstration
    can be carried out according to the regional difference.'
  doi: 10.11975/j.issn.1002-6819.2021.11.036
  full_citation: '>'
  full_text: '>

    "EI CSA CABI 卓越期刊 CA Scopus CSCD 核心期刊 首页 关于我刊 编委会 投稿指南 期刊浏览 获奖文章 农业工程期刊 期刊订阅 联系我们
    EI收录本刊数据 English 文章导航 >  农业工程学报  > 2021  >  37(11) : 315-324.  > DOI: 10.11975/j.issn.1002-6819.2021.11.036
    引用本文: 陈媛媛, 游炯, 幸泽峰, 胡华浪, 梅国涛, 石智峰, 刘海启. 世界主要国家精准农业发展概况及对中国的发展建议[J]. 农业工程学报, 2021,
    37(11): 315-324. DOI: 10.11975/j.issn.1002-6819.2021.11.036 Citation: Chen Yuanyuan,
    You Jiong, Xing Zefeng, Hu hualang, Mei Guotao, Shi Zhifeng, Liu Haiqi. Review
    of precision agriculture development situations in the main countries in the world
    and suggestions for China[J]. Transactions of the Chinese Society of Agricultural
    Engineering (Transactions of the CSAE), 2021, 37(11): 315-324. DOI: 10.11975/j.issn.1002-6819.2021.11.036
    世界主要国家精准农业发展概况及对中国的发展建议 陈媛媛1,  游炯1,  幸泽峰1,  胡华浪1,  梅国涛2,  石智峰1,  刘海启1 1. 农业农村部耕地利用遥感重点实验室/农业农村部规划设计研究院，北京
    100121 2. 潍柴雷沃重工股份有限公司，潍坊 260000 基金项目: 农业农村部规划设计研究院自主研发项目（ZZYFXKFZ201904）；国家重点研发计划（2016YFB0501505）
    Review of precision agriculture development situations in the main countries in
    the world and suggestions for China Chen Yuanyuan1,  You Jiong1,  Xing Zefeng1,  Hu
    hualang1,  Mei Guotao2,  Shi Zhifeng1,  Liu Haiqi1 1. Key Laboratory of Cultivated
    Land Use, Ministry of Agriculture and Rural Affairs/Academy of Agricultural Planning
    and Engineering, Ministry of Agriculture and Rural Affairs, Beijing 100121, China
    2. Weichai Lovol Heavy Industry Co., Ltd, Weifang 260000, China 摘要 摘要 HTML全文 图(0)
    表(0) 参考文献(76) 相关文章 施引文献(71) 资源附件(0) 摘要: 中国是一个农业生产和消费大国，同时也面临着投入产出比率相对较低、环境污染等一系列问题，尤其在国际形势变化、自然灾害频发的背景下，中国传统农业生产方式亟需转型升级。在人工智能、物联网、云平台等新兴技术的带动下，精准农业孕育而生，成为了全球农业实现绿色、高产的有效途径。该文瞄准世界精准农业发展较好的发达国家和地区，通过文献梳理和总结，凝练出政府引导、信息化建设、科技支撑、新型农民培育等发达国家和地区发展精准农业的成功经验。在此基础上，着眼于中国大田种植，分析中国发展精准农业的基础，从农田配套设施及信息化建设、农业信息获取、自动变量作业系统及装备等方面充分认识中国发展精准农业的薄弱环节。该文旨在厘清中国精准农业的发展方向，借鉴国际经验，提出中国精准农业今后的发展建议，如强化政府组织领导作用、加强基础设施和信息化建设、聚焦核心技术研发、培养新型农业人才、分区域试点示范。   关键词:
    精准农业  /  信息技术  /  战略与政策  /  发达国家和地区  /  中国  /  发展建议   Abstract: It is needed to
    solve the problems such as relatively low input-output ratio and environmental
    pollution for Chinese agriculture, with the large amount of agricultural production
    and consumption. In the background of changing international situation and frequent
    natural disasters, transforming traditional agricultural production methods in
    China is an urgent. Driven by emerging technologies such as artificial intelligence,
    internet of things, cloud platform, automatic control, and new generation communication
    and so on, precision agriculture came out and was undoubtedly an effective way.
    Precision agriculture has become a common choice for developing sustainable and
    high-yield agriculture around the world. In order to obtain the development orientation
    of precision agriculture and successful practices in the world, this paper reviews
    the studies on precision agriculture developing status. The aim of this paper
    is to refine the experiences of precision agriculture developing in the main developed
    countries and regions and take a look at the precision agriculture development
    in China. Adopting the method of systematic literature analyzing and summary,
    Section 1 studies the development status of precision agriculture in the main
    developed countries and regions, such as America, Japan, European Union and Israel.
    The idea of precision agriculture was first proposed in America. Until today,
    America has developed mature precision agriculture system, which benefits from
    the highly developed technologies. Considering the serious contradiction between
    large population and less farmland, during 1970s, Japan took measures of consolidating
    farmland on a large scale and building farmland infrastructure and so on to improve
    the agricultural production conditions. The agricultural community was also formed
    to operate collaboratively the agricultural production. The development of precision
    agriculture in European Union is driving by digital technologies. The water-saving
    agriculture represented by drip-irrigation and sprinkler-irrigation has made remarkable
    results in Israel. The development experiences of precision agriculture in the
    main developed countries and regions enlighten us that: 1) the leading by government
    is the key; 2) the informatization construction is the foundation; 3) the advanced
    technology is the core; 4) the cultivation of new type of farmers is the guarantee.
    Section 2 analyzed the basements and weaknesses for developing precision agriculture
    in China. The weaknesses are the emphasis in this section. First, the farmland
    in China is scattered and the infrastructure is not perfect. Taking the informatization
    perspective, even though number of agriculture related information systems exist,
    the data and information are not interoperable between these systems. Second,
    at the present stage, we cannot acquire the temporal and spatial continuous agricultural
    information due to the rarity domestic satellite data and ground sensors for agriculture
    monitoring. Third, automatic variable operating system and equipment are lacking
    since the technology integration of information technology, communication and
    agricultural machine has not been achieved. Fourth, insufficient high-quality
    agricultural talents. Facing these weakness and Chinese conditions, Section 3
    provided five suggestions to develop precision agriculture in China. Firstly,
    our government should overall plan and give guarantee in police making, infrastructure
    construction and financial support, etc. Secondly, we should improve the agricultural
    production condition through expanding moderately the operating scale of farmland
    and constructing the field infrastructure net and the national agricultural information
    platform. Thirdly, the key technology research, such as the information retrieval
    using remote sensing and technology integration of communication, automatic controlling,
    spatial information and smart machinery must be focused. Fourthly, the new type
    of personnel in agricultural field can be cultivated. Fifthly, pilot demonstration
    can be carried out according to the regional difference.   Keywords: precision
    agriculture  /  information technology  /  strategy and policy  /  developed countries
    and regions  /  China  /  suggestion   We recommend Technique innovation and research
    fields of modern agricultural and ecological water-saving in the future Kang Shaozhong
    et al., Transactions of the Chinese Society of Agricultural Engineering, 2003
    Key technologies and practice of unmanned farm in China LUO Xiwen et al., Transactions
    of the Chinese Society of Agricultural Engineering Design and implementation of
    spatial differentiation-based system for identifying spatial features of well-facilitated
    farmland construction Li Shaoshuai et al., Transactions of the Chinese Society
    of Agricultural Engineering, 2020 Exploration and development prospect of eco-unmanned
    farm modes Lan Yubin et al., Transactions of the Chinese Society of Agricultural
    Engineering, 2021 Design of the detection system for the unmanned navigation parameters
    of field agricultural machines based on improved AOA mode Xie Binbin et al., Transactions
    of the Chinese Society of Agricultural Engineering, 2021 Results from Survey Instruments
    Used to Assess Technology Adoption for Tree Fruit Production Katie Ellis et al.,
    HortTechnology, 2010 FULL TIME-SPACE GOVERNANCE STRATEGY AND TECHNOLOGY FOR CROPLAND
    NON-POINT POLLUTION CONTROL IN CHINA Lihong XUE et al., Frontiers of Agricultural
    Science and Engineering, 2023 STRENGTHENING NON-POINT SOURCE POLLUTION CONTROL
    TO PROMOTE AGRICULTURAL GREEN DEVELOPMENT Wen XU et al., Frontiers of Agricultural
    Science and Engineering, 2023 Smart System for Automated Irrigation Using Internet
    of Things Devices Rhuanito Soranz Ferrarezi et al., HortTechnology, 2021 Security
    certification for critical information infrastructures: The Italian certification
    body approach Franchina et al., Journal of Business Continuity & Emergency Planning,
    2007 Powered by PDF下载 ( 653 KB) XML下载 导出引用 点击查看大图 计量 文章访问数:  864 HTML全文浏览量:  19
    PDF下载量:  567 被引次数: 71 出版历程 收稿日期:  2021-01-07 修回日期:  2021-05-07 发布日期:  2021-05-31
    分享 友情链接> Industrial Crops and Products Biomass & Bioenergy Biosystems Engineering
    Aquacultural Engineering International Journal of Agricultural and Biological
    Engineering 版权所有 © 农业工程学报 京ICP备06025802号-3 地址：北京朝阳区麦子店街41号（100125） 电话：010-59197078/7077/7076
    邮箱：tcsae@tcsae.org 邮件订阅 RSS 今日头条 抖音号 视频号 淘宝 微店 本系统由北京仁和汇智信息技术有限公司开发  "'
  inline_citation: '>'
  journal: Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural
    Engineering
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Review of precision agriculture development situations in the main countries
    in the world and suggestions for China
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Gupta D.
  - Bhatt P.
  - Bhatt S.
  citation_count: '4'
  description: The application of Internet of Things (IoT) and Machine Learning (ML)
    to the agricultural industry has enabled the development and creation of smart
    farms and precision agriculture. The growth in the number of smart farms and potential
    cooperation between these farms has given rise to the Cooperative Smart Farming
    (CSF) where different connected farms collaborate with each other and share data
    for their mutual benefit. This data sharing through CSF has various advantages
    where individual data from separate farms can be aggregated by ML models and be
    used to produce actionable outputs which then can be utilized by all the farms
    in CSFs. This enables farms to gain better insights for enhancing desired outputs,
    such as crop yield, managing water resources and irrigation schedules, as well
    as better seed applications. However, complications may arise in CSF when some
    of the farms do not transfer high-quality data and rather rely on other farms
    to feed ML models. Another possibility is the presence of rogue farms in CSFs
    that want to snoop on other farms without actually contributing any data. In this
    paper, we analyze the behavior of farms participating in CSFs using game theory
    approach, where each farm is motivated to maximize its profit. We first present
    the problem of defective farms in CSFs due to lack of better data, and then propose
    a ML framework that segregates farms and automatically assign them to an appropriate
    CSF cluster based on the quality of data they provide. Our proposed model rewards
    the farms supplying better data and penalize the ones that do not provide required
    data or are malicious in nature, thus, ensuring the model integrity and better
    performance all over while solving the defective farms problem.
  doi: 10.1109/BigData50022.2020.9377935
  full_citation: '>'
  full_text: '>

    "IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account
    Personal Sign In Browse My Settings Help Access provided by: University of Nebraska
    - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards
    Authors Citations ADVANCED SEARCH Conferences >2020 IEEE International Confe...
    A Game Theoretic Analysis for Cooperative Smart Farming Publisher: IEEE Cite This
    PDF Deepti Gupta; Paras Bhatt; Smriti Bhatt All Authors 4 Cites in Papers 254
    Full Text Views Abstract Document Sections I. Introduction II. Related Work III.
    Cooperative Smart Farming IV. Cooperative Smart Farming Game V. Proposed Approach
    - A Fair Strategy Show Full Outline Authors Figures References Citations Keywords
    Metrics Footnotes Abstract: The application of Internet of Things (IoT) and Machine
    Learning (ML) to the agricultural industry has enabled the development and creation
    of smart farms and precision agriculture. The growth in the number of smart farms
    and potential cooperation between these farms has given rise to the Cooperative
    Smart Farming (CSF) where different connected farms collaborate with each other
    and share data for their mutual benefit. This data sharing through CSF has various
    advantages where individual data from separate farms can be aggregated by ML models
    and be used to produce actionable outputs which then can be utilized by all the
    farms in CSFs. This enables farms to gain better insights for enhancing desired
    outputs, such as crop yield, managing water resources and irrigation schedules,
    as well as better seed applications. However, complications may arise in CSF when
    some of the farms do not transfer high-quality data and rather rely on other farms
    to feed ML models. Another possibility is the presence of rogue farms in CSFs
    that want to snoop on other farms without actually contributing any data. In this
    paper, we analyze the behavior of farms participating in CSFs using game theory
    approach, where each farm is motivated to maximize its profit. We first present
    the problem of defective farms in CSFs due to lack of better data, and then propose
    a ML framework that segregates farms and automatically assign them to an appropriate
    CSF cluster based on the quality of data they provide. Our proposed model rewards
    the farms supplying better data and penalize the ones that do not provide required
    data or are malicious in nature, thus, ensuring the model integrity and better
    performance all over while solving the defective farms problem. Published in:
    2020 IEEE International Conference on Big Data (Big Data) Date of Conference:
    10-13 December 2020 Date Added to IEEE Xplore: 19 March 2021 ISBN Information:
    DOI: 10.1109/BigData50022.2020.9377935 Publisher: IEEE Conference Location: Atlanta,
    GA, USA SECTION I. Introduction Farming is one the earliest activities undertaken
    by humans to build civilizations. Feeding the ever-increasing world population
    is a huge challenge and the role farming in meeting this challenge cannot be overstated.
    The recent recognition of the World Food Program (WFP)1 as the Nobel Peace Prize
    recipient underlines the importance food security plays in our lives. Consequently,
    it is equally important to ensure that sustainable farming practices are followed
    so that land is not overused and exploited. Internet of Things (IoT) technology
    can serve as a critical asset to enhance agricultural practices and enable efficient
    and sustainable farming. With the application of IoT and Machine Learning (ML)
    algorithms in the farming sector, a new domain of smart agriculture has emerged.
    Using IoT to monitor and measure different aspects of soil, land and crops can
    lead to development of better and more sophisticated farms that use data-driven
    models and applications to enhance their production, which is also known as smart
    farming and/or precision agriculture today. With the rapid diffusion of smart
    devices and IoT technology in the agriculture domain, farms have grown more advanced,
    technically competent and production efficient [1]. The use of IoT has been abundant
    and in turn led to the creation of a technology based smart ecosystem. Such a
    connected system enabled by smart devices and key technologies as cloud and edge
    computing leads to the creation of smart farms which generates large amounts of
    data. This large amount of data can be analyzed using ML and Artificial Intelligence
    (AI) technologies to extract crucial insights and implications. The need for such
    smart farms has been stressed in research and is equally important for the sustenance
    of smart cities [2], [3]. As smart cities develop so should the infrastructure
    around farming, as it is not only an extension but a necessary derivative of the
    fully connected IoT architecture. However, the increase in number of smart connected
    farms has not been without issues. There is a possibility of adversaries sabotaging
    farms, malicious agents compromising the functioning of such farms or even cyber-attacks
    against smart farming adopters [4], [5]. It is therefore important to have strong
    security in place that thwarts such attacks and better data management practices
    so that informed decisions can be made that do not jeopardize smart farm outputs.
    Another reason to ensure data security and management is to increase the farm
    owners’ confidence in the ability of technology to actually provide them with
    visible benefits. The benefits accruing from data analysis of smart farms can
    either be related to greater production output, or better land use, or even the
    discovery of efficient seed application techniques. The use of cloud computing
    as well as web-based services has ushered in a new era where smart farms plan
    better yield management, adopt responsible farming practices, and indulge in sustainable
    techniques. It is for this reason that IT has been so readily deployed and used
    in the agriculture sector, giving rise to the smart farms concept [6]. Smart farming
    involves the adoption of IoT devices to automate processes on regular farms, such
    as irrigation and seed application. It also involves collecting data on the soil
    quality, moisture and crop yield metrics. Such data can drive new knowledge discovery
    which benefits and informs the entire agricultural industry of new and efficient
    ways to farm and grow crops. Also, as new developments take place in the IoT industry
    and advances are made in data usage techniques, it is equally important that these
    improvements rapidly percolate to the agriculture domain primarily to the associated
    smart farms. The increasing number of smart farms demands cooperation between
    each other which allows these farms to learn efficient farming techniques by applying
    data-driven models to smart farm data and share resources among each other. This
    type of cooperation between several smart farms is known as Cooperative Smart
    Farming (CSF). While CSF is an attractive framework to benefit multiple farms
    together, it is important to understand that there are also security and privacy
    issues that could arise in this framework. Data privacy could be a major concern
    for some smart farms, thus, it is essential to address security and privacy in
    CSFs. There may be different types of farms participating in a CSF. A farm, which
    has low-quality agriculture data generated from IoT devices, always wants to be
    a part of CSF to take benefit from other farms. A farm, which has huge number
    of resources and high-quality agriculture data, does not receive any benefit in
    CSF. Therefore, there is an issue for smart farms to become a member of CSF and
    contribute effectively as member of the CSF. In this paper, we address the research
    problem of unfair collaboration among smart farms in a CSF by proposing a CSF
    game model, and a novel fair strategy which enforces each smart farm to cooperate
    in CSF based on the clusters formed to achieve benefit through AI assisted application.
    The main contributions of this paper are as follows. We identify the issue of
    unfair collaboration among farms in cooperative smart farming. For instance, some
    smart farms which generate low-quality data to build machine learning model can
    take advantage from other farms which have high-quality data. We present two different
    use case scenarios including different types of smart farms in a CSF along with
    rationality assumption. We propose a fair strategy to enforce farms to cooperate
    in CSF to build ML model. We present a proposed implementation framework that
    can be employed and extended to enable CSF use case scenarios utilizing a real-world
    cloud-enabled IoT platform, Amazon Web Services (AWS). The rest of paper is organized
    as follows. Section II presents relevant work on CSF, security and privacy issues
    in CSF, and game theoretic models used in smart farming. Cooperative smart farming
    use case scenarios along with rational assumption are discussed in Section III.
    Section IV shows cooperative smart farming game and also shows the game analysis
    in same section. Section V presents proposed fair strategy. Section VI discuss
    proposed implementation framework for enabling CSF using real-world cloud-enabled
    IoT platform. Section VII concludes the paper with future research directions.
    SECTION II. Related Work In this section, we discuss the relevant work in perspective
    of three specific areas - cooperative smart farming (CSF), security and privacy
    issues in CSFs, and game theory application in the context of smart farming. A.
    Cooperative Smart Farming Farming has always been a community activity and in
    its truest sense a communal one that includes a participatory process. Therefore,
    even though individual farms operating alone may be efficient revenue maximizers,
    it is still an evident fact that significant benefits can accrue to those participating
    in a cooperative bloc [7]. Similar to cooperation in the traditional sense of
    farming, where farmers share resources such as seeds and equipment; a CSF scenario
    in the technical sense involves sharing of data collected by numerous sensors,
    devices, and other resources. The reasons to indulge in CSF are not only economic
    ones but also ones of security. For instance, the participating farms share data
    which can lead to better crop output. Meanwhile, the data shared can also be analyzed
    to figure out threats to crops and protect them from damage [8]. Such critical
    insights are only possible with the help of IoT devices that relay data from the
    farms in the cooperative hosted on cloud or edge servers. These farms reinforced
    with IoT devices come under the purview of smart farms which have been researched
    in many studies [9], [10]. Smart farms also employ remote sensing techniques to
    keep track of the covered land, monitor crop health and even classify weeds [11].
    Moreover, the use of technology in smart farms has been so far advanced as distinguishing
    between different plowing techniques and classifying them according to plowing
    depth [12]. The use of Unmanned Aerial Vehicles (UAV) has been consistent in smart
    farms along with the use of IoT devices. An emerging setting for smart and cooperative
    farming is indoor farming, especially greenhouses, where IoT devices that share
    data with the cloud have been utilized to replicate the results achieved in outdoor
    farms [13]. In terms of implementation, there have been several instantiations
    of smart and connected farming ecosystems. These smart farms have been fitted
    with a variety of IoT devices that can interact with each other and also with
    the users to run different tasks. Similarly, REST-APIs have been used to encourage
    the cooperative development of applications and solutions to speed up adoption
    of the concept of smart and cooperative farming [14]. Data Modeling has been another
    important tool used in smart farming to perform a range of tasks, such as the
    very basic ones like feed modeling to more environmentally responsible ones as
    reducing methane emissions [15]. With many IoT devices in place, there is a sizable
    generation of continuous data streams in smart and cooperative farms. Big data
    technologies play an important role in the collection, storage and analysis of
    data and its conversion to meaningful information, which can in turn help in overall
    farm management and streamlining of farm processes [16]. Fig. 1: Cooperative Smart
    Farming Architecture Show All With regard to the advances in smart farms, AI techniques
    are increasingly being used in the smart farming domain today. ML models and techniques
    too have begun to play a prominent role in enhancing the capabilities of smart
    farms. Image processing using artificial neural networks have been used to monitor
    plants both during growth and harvest periods for detecting diseases as well as
    for grading them [13]. In addition to plants, ML has also been used to predict
    soil and land properties even the propensity of droughts to occur [17]. Also,
    with respect to autonomous operations in smart farms, models have been developed
    to minimize the instances of human intervention required for monitoring crops
    [18]. Another interesting application of AI capabilities in the smart farming
    context has been for weed classification where spectral images collected by small
    Micro Aerial Vehicles (MAVs) have been used to identify the weeds that may pose
    a danger to the surrounding plants or crops [19]. B. Security and Privacy issues
    on Cooperative Smart Farming The use of IoT devices in the smart farms has surely
    transformed the cooperative farming landscape, however it has also ushered in
    the risks attached to such devices. These risks translate to the various security
    and privacy risks that target IoT devices in general. Since a major part of the
    infrastructure of a cooperative smart farm is built around participating farms
    sharing data with each other, if a particular data source becomes corrupted, then
    it can have far reaching implications for all the farms in the bloc. Privacy by
    design is critical in such scenarios to protect the privacy sensitive information
    of any member farm from being subject to unwanted disclosure [20]. Also, security
    of the data being circulated in CSF bloc is equally important, essentially with
    respect to the three triad - confidentiality, integrity, and availability. If
    this data is tampered with, then it can lead to devastating consequences such
    as wiping out entire crop harvest or withering of plants because of inefficient
    application of fertilizers. Therefore, it is crucial to ensure security and privacy
    be robust in smart farms. Security and privacy issues in CSF architecture relate
    to authorization and trust, authentication and sever communication as well as
    compliance and regulations [4], [21]. Access control plays an important part in
    regulating the level of access to the many different IoT devices that may be present
    within CSF architecture. Federated access control reference model [22] is used
    to enhance the privacy of security of big data platforms. Similarly, there have
    been prior work on access control models for developing flexible access control
    models for securing access and data communication in IoT [23]–[26], and cloud-enabled
    IoT platforms [27]–[29]. Data is transferred quite a bit among the cooperative
    smart farms as well as shared with the cloud servers responsible for aggregating
    the data for analysis. To combat these security threats there can be a number
    of solutions. A potential one solution is the application of Blockchain, with
    which the data transferred among the farms can be verified for its validity [30],
    and another solution is based on trustworthy evaluation framework [31]. Also,
    with the increasing popularity of smart farms, another security challenge that
    arises is that these farms inadvertently play host to a plethora of security challenges
    [32]. However, enforcement of data transfer agreements and verifying the approved
    learning received from the cloud servers is a very important task in the connected
    farm system. Further, the issue of security and privacy in smart farming is not
    only restricted to data alone but encompasses both the human and technology components
    of CSF architecture. It is important that the farm owners are aware and trained
    on the latest threats that may pose a danger to their farms. On the other hand,
    the technology providers and vendors should provide end users with applications
    and software that is free from flaws and secure by design [33]. To enhance the
    security in smart farms, researchers have also looked at using a private cloud
    infrastructure that combines data from heterogeneous sources to provide privacy
    secure data analytic capabilities to individual farms [34]. Such a solution can
    be ported into a collaborative mechanism that can effectively serve participating
    smart farms in a cooperative bloc. Ensuring proper device authentication of smart
    devices with low computing power, that are embedded in connected farm systems,
    can also act as an effective deterrent against cyber-attacks and minimize security
    violations [35]. Fig. 2: Cooperative Smart Farming Model Show All C. Game Theory
    in Smart Farming This paper [36] investigates the utilization of game theory models
    for automated analysis of hyperspectral imagery data. The authors discuss two
    models on feature-level fusion and decision fusion for hypertemporal-hyperspectral
    datasets, and both models are implemented under the assumption where all players
    are rational. In agriculture, this research [37] presents game theory model for
    decision making in risky situations. In beginning, a farmer makes plans for obtaining
    feasible goals and then simply carry out the plans. Later, he/she can face various
    uncertain issues in agriculture production. This study [38] provides possible
    solutions to actual decision problems of Iowa farmers. This paper [39] deals with
    the application of game theory with solution to handle an agricultural economics
    problem. This study claims to establish Nash Equilibrium for an agricultural company
    that is considered together with its three sub-units. Gupta et al. [40] presents
    a novel fair strategy for collaborative deep learning game, where all mobile edge
    devices [41] choose any strategy to make own profit. The past studies show that
    no research has analyzed the farm’s rational behavior in CSF. Therefore, we develop
    a game model for farms in CSF and analyze the game. SECTION III. Cooperative Smart
    Farming Cooperatives are formal corporation which are financed, controlled, and
    owned by members for correlative advantage [42]–[44]. These cooperative (co-op)
    work is based on membership agreement, which has operational rules along with
    conditions and provide the benefit of shared resources. Such cooperatives operate
    in different sectors, such as grocery suppliers, water supplies, credit unions,
    utilities, farm suppliers, transportation and childcare. According to United States
    Department of Agriculture (USDA) [45], the importance of co-ops is more meaningful
    in the rural communities. Figure 1 presents the multi-layer architecture of CSF,
    where physical layer has Internet of Agriculture Things (IoAT) devices, the edge
    layer provides local real-time computation and analysis needed for smart resources,
    and cloud layer comprises of cloud services and co-op level. A. A Use Case We
    present a use case of multiple participating smart farms in a CSF bloc which is
    based on a game theory-based model. Participating smart farms are rational choice
    makers and will only become members of CSF bloc if they get tangible benefits
    from it. These benefits have to be more beneficial than would normally accrue
    to the farms if they operated alone based on their own capabilities. In this setting
    as shown in Figure 2, CSF bloc provides its members, Farm A and Farm B, the benefits
    from a shared ML model. This model can provide numerous insights related to various
    factors, such as plant and soil health, soil and water quality, and crop output
    and yield management information, based on data collected from Farm A and Farm
    B. Therefore, if a smart farm wishes to use the information provided by the model,
    then it has to register and join CSF bloc so that it can avail of the learning
    from the model. This ML model is trained on the cloud or edge server with data
    that is transferred to it from the participating farms. Generally, we assume that
    the larger the dataset collected from different farms the better ML model will
    be; thus, there will be an inherent incentive for the participating farms to become
    a member of CSF bloc and share their data in order to get better insights about
    their farming practices and in turn get more profits in the long run. Fig. 3:
    Cooperative Smart Farm Model - Threat Scenario 1 Show All If a smart farm does
    not need the information being provided by the model, then it will not choose
    to join CSF bloc. For example, if a smart farm needs information about soil moisture
    or soil pH levels and the model only provides insights about water quality and
    yield management, then the farm will not participate in the bloc. Similarly, if
    earlier ML model in a bloc used to provide the soil moisture information, but
    going forward, due to a lack of good quality data the model stops providing that
    specific information, then a smart farm can choose to defect from CSF bloc. Also,
    if a smart farm is technically superior and has abundant data and ML capabilities,
    then it will not join a CSF bloc. Instead it will operate alone, relying on its
    own capabilities. Similarly, if a participating smart farm acquires such superior
    capabilities while being a member of a CSF bloc then, it can choose to defect
    from the bloc. However, we envision that these scenarios are only fringe options
    that depends on different types of participating farms and may or may not be seen
    often in the context of our smart farms based CSF architecture. B. Threat Model
    1) Scenario 1 In a CSF bloc, there are two farms – Farm A and Farm B. Farm A has
    various sensors, smart devices, robust data collection procedures in place, sophisticated
    instruments that collects high-quality data with regard to crop yield per hectare,
    soil moisture, water quality, irrigation schedules etc. Farm B does not have such
    advanced sensors, devices, and methods to collect good quality data. Both farms
    share data with a cloud ML model with the instruments they have installed on their
    farms. Figure 3 shows this scenario. The data collection (what metrics are collected),
    storage (where are they storing and where – IoT Hub or Edge computing servers,
    or cloud) and sharing schedule (data is sent hourly, or daily or weekly) may be
    different or standardized for different participating farms. The cloud ML model
    uses data across different farms and trains model to make predictions regarding
    pesticide application, seeds needed per hectare, minimum irrigation levels needed
    to ensure good crop yield, predict scarcity of soil nutrients etc. The ML model
    shares the data with all the farms irrespective of their size or quality of the
    data contribution. In this scenario, Farm A has good devices, data collected from
    those devices, and resources; however, Farm B does not have good farm devices,
    data, and resources. Therefore, the ML model should process the data from Farms
    A and Farm B and then provide outputs/insights based on the quality of data that
    each farm shared rather than providing both with the same insights, as is the
    general case with the ML model learning. Figure 3 shows both current learning
    and insights sharing mechanism with solid green lines, and our proposed mechanism
    with dashed lines. Fig. 4: Cooperative Smart Farm - Threat Scenario 2 Show All
    2) Scenario 2 Figure 4 depicts the second threat scenario where one of the farms
    could have malicious intents. Here, the scenario also consists of two farms, Farm
    A and Farm B, where Farm A is a technologically advanced farm compared to Farm
    B and Farm A provides better quality data to the ML model, similar to scenario
    1. Now, Farm B decides to act rogue and stop sharing the entire data it collects,
    or does not replace outdated or broken IoT devices, or Farm B has malicious intentions
    and does not collect good quality data. For instance, the malicious intent can
    either be competitors trying to sabotage a CSF and smart farms participating in
    that CSF, or data injection attacks from hackers for ruining crops for other farms
    and their ML model outputs. In scenario 1, Farm B still gets the ML model’s prediction
    without actually cooperating and participating in the smart farming architecture.
    In scenario 2, Farm B actively tries to sabotage the whole CSF infrastructure
    by compromising the data source from which the ML model is trained. With our game
    theory-based fair strategy approach (described in later section) proposed in this
    paper, we try to solve this problem and ensure that the participating smart farms
    are equal and honest in all respects. As a consequence of providing high-quality
    and true data, the smart farms receive models and their outputs/insights that
    accurately represent the aggregate learning from CSF bloc. C. Rationality Assumption
    Prior research in smart farming [46] have presented cyber-attacks on smart farming
    infrastructure where farmers or IoT devices are controlled by adversary. Malicious
    participants could arbitrarily deviate from suggested protocol in CSF or could
    arbitrarily drop communication between edge gateways and cloud. However, here
    we assume that farms are honest in a selfish environment. In the context of this
    paper, rationality means that a rational farm earns maximum profit by collaboration
    or individual modeling in CSF. SECTION IV. Cooperative Smart Farming Game In this
    section, we present a game model of CSF with multiple member farms in selfish
    environment. This game model involves with N-players and is addressing the threat
    scenario 1 as discussed in III. This game model refers as a cooperative smart
    farming game G. In this game, IoT devices send their generated data to centralized
    cloud where data supports all the member farms through ML models. Co-op allows
    to aggregate only that data, which is generated from members of CSF and builds
    ML model for AI-assisted applications. This updated global ML model provide insight
    to all participating member farms via AI-assisted application, where exists a
    social dilemma for all defection behavior. Table 1 shows game approach between
    two players, one has high-quality data and other has low-quality data. List of
    symbols are shown in Table 2. A. Game Theoretic Model Game theory allows for modeling
    situations of conflict and for predicting the behavior of participants when they
    interact with each other. In CSF game G, farms which sign a co-op agreement to
    be part of CSF are participants. They interact with each other through co-op cloud
    level without having any knowledge about each other. The Game G is a static game,
    because all participants must choose their strategy. The Game G is a tuple (P,
    S, U), where P is the set of players, S is the set of strategies and U is the
    set of payoff values. Players (P ): The set of players P= ∑ N i=1 P i corresponds
    to the set of member farms which signed co-op agreement and allows to send generated
    data from their IoT devices through edge gateways to build ML model in CSF game
    G. Strategy (S): Each participant Pi can choose between two actions si (i) Cooperative
    (CP ) or (ii) Defective (DF ). Hence the set of strategies in this game is S ={CP,DF
    }. Strategy of each participant Pi determines whether Pi participates in CSF.
    In particular, if a participant Pi plays CP strategy, i.e., the member farm allows
    IoT devices to send the generated data to centralized cloud and extract model
    results via AI-assisted applications. In cooperative strategy, participant pays
    full cost. In contrast, if a participant Pi neither sends the generated data through
    IoT devices to the cloud nor utilize the global ML model, i.e., the member farm
    Pi plays DF strategy. Thus, participants saves various costs including membership
    costs co, communication costs cm, cm′ and storage cost cs. Here, this participant
    is not part of CSF and builds ML model individually. Payoff (U): The goal of each
    participants in CSF game G is to maximize their utility, which is a function of
    the accuracy and its costs. In this game, we do not consider any malicious or
    threat activities from players; hence, the accuracy based on AI assisted application
    is benefit for each player. The players pay various costs including communication
    costs cm, cm′, storage cost cs, and membership cost co, and also pay penalty cp
    if any player breaks co-op membership agreement. Total cost c t i to participate
    in CSF can be characterized as c t i = c o + c p + c m + c m ′ + c s (1) View
    Source TABLE I: Game Table Between Two Players Here, the benefit and the cost
    are not on the same scale as the first depends on the accuracy of ML model while
    the latter on different types of associated costs. To make them comparable, we
    introduce a coefficient: the benefit is multiplied with B. Now, we compute the
    payoff of player Pi in this game. If we assume that the player Pi is cooperative,
    i.e., Pi∈CP. Similarly, if Pi is defective, i.e., Pi∈DF, and these payoffs can
    be defined as follows. u i (CP)=B( a co−op )−( c o + c p + c m + c m ′ + c s )
    u i (DF)=B(a)−( c plocal ) (2) (3) View Source TABLE II: List of Symbols Fig.
    5: A Sample of Model Attributes Show All Based on the above calculated utilities,
    we analyze the game G as discussed in the game analysis. The most fundamental
    game-theoretic concept, Nash Equilibrium, which is introduced by John Nash [47]
    is used to solve strategic behavior of participants. Definition 1. A Nash Equilibrium
    is a concept of game theory where none of the players can unilaterally change
    their strategy to increase their payoff. In a non-cooperative game, players do
    not have any motivation to deviate unilaterally from the given strategy. The prisoner’s
    dilemma is a standard example to analyze a game and shows that two rational players
    cooperate, come out with best outcome, and the players do not cooperate with one
    another, then they choose defecting strategy in the hope of attaining individual
    gain at the rival’s expense. In prisoners’ dilemma defecting strategy strictly
    dominates the cooperation strategy. Hence, the only Nash Equilibrium in prisoners’
    dilemma, is a mutual defection. Fig. 6: Proposed Implementation of Cooperative
    Smart Farming (CSFs) in AWS cloud Show All Based on the cost and benefit of player
    to build ML model, we build a CSF game model G. In the following theorems, we
    show that the CSF game G is a public good game. Theorem 1. In cooperative smart
    farming game G, if each participant builds its local machine learning model individually,
    then we can establish All-Defective strategy profile as a Nash Equilibrium. Proof.
    Let us consider all N participants follow defective-DF strategy where all participants
    neither send their generated data from IoT devices through gateways to cloud,
    nor upload any updated ML model/extract any results from cloud, i.e., no membership
    fees co, no communication between IoT devices and cloud. So, participants do not
    pay any communication costs cm, cm′, and storage cost cs. Now each participant
    Pi trains local data sets Di to build its ML model individually and pays only
    computation cost cplocal. None of participants cannot change his strategy profile
    unilaterally. Let us assume if a participant deviates from defect-DF strategy
    to cooperate-CP strategy unilaterally, then participant will pay some costs (co+
    cm + cm′ +cs + cp), which is greater than cplocal. The payoff of cooperate-CP
    strategy is less than defect-DF strategy, so All-DF is a Nash equilibrium profile
    and G is a public good game. Theorem 2 shows that we can never enforce an All-Cooperative
    CP strategy in game G, and therefore, we could not establish a Nash Equilibrium.
    Theorem 2. In cooperative smart farming game G, if each participant builds its
    local ML model, then we cannot establish All-Cooperative strategy profile as a
    Nash Equilibrium. Proof. We first assume that all N participants are members of
    CSF (i.e., All-cooperative CP strategy profile) and pays mandatory costs (membership
    cost, communication costs, and storage cost) and optional cost (penalty cost).
    We can compute the payoff of each participant Pi by Equation (2). Hence, if a
    participant will deviate from the cooperation and play defection unilaterally,
    its payoff would be equal to Equation (3), which is always greater than cooperative
    payoff. Hence, each participant has incentive to deviate unilaterally and increases
    its payoff. Then, the All cooperate-CP strategy profile is never a Nash Equilibrium.
    SECTION V. Proposed Approach - A Fair Strategy We present the proposed model to
    ensure member farms in CSF can be maintained with a fair-game strategy. Figure
    3 and Figure 4 present CSF models of use case threat scenario 1 and scenario 2,
    which we discussed in section III. Our goal is to design a mechanism for eliciting
    cooperation in CSF and solves the issue discussed in scenario 1 where one farm
    (Farm A) has advanced and good quality devices and provide good quality data.
    The proposed fair strategy enforces member farms for cooperation in CSF; however,
    Theorem 1 and 2 proves that member farm defect from CSF game, i.e., after some
    number of iterations, member farm will not be part a of CSF if they will not get
    any benefit from other member farms. The quality of each dataset of each participant
    is calculated based on data attributes at co-op level. The generated data is classified
    using Support Vector Machine (SVM) algorithm and a result of sample data attributes
    is shown in Figure 5. This shows different categories of data items and hierarchy
    of attributes - soil data, irrigation data, yield data, and sharing schedule for
    data and resources. Each of these categories are further broken down into other
    attributes that provide detailed information about these attributes. For instance,
    soil data include moisture and nutrient content, irrigation data include water
    quality and watering schedule, etc. Based on such identified attributes for a
    ML model, we can define the data being collected and transmitted by smart farms
    to the CSF is quality data or not. As shown in Table 1, the best strategy is to
    classify the smart farms based on the quality of data they provide to the model
    and co-op, such as high-quality data farms should participate in high-quality
    CSF, and low-quality data farms can be grouped together and should participate
    in low-quality CSF. We believe that this strategy will allow the smart farms to
    co-operate in CSFs and take maximum benefit from it, and can reduce the problem
    of defective farms. However, further research on data attributes for ML models
    to efficiently classify the smart farms is necessary. We plan to focus on this
    aspect in our future work. In the context of the CSF game G, before the start
    of the game, each participant has to choose his strategy between CP and DG to
    play the CSF game G. However, in the beginning of this game, each participant
    is in dilemma to choose strategy, which can depend on other participant’s strategy.
    In CSF, each member farm does not know about the quality and quantity of other
    participant’s data. Here, we propose a novel fair strategy employing K-means clustering
    at co-op cloud level. K-means clustering is an unsupervised ML technique, whose
    purpose is to segment a data set into K clusters. The co-op cloud will create
    clusters based on quality and quantity of their dataset to enforce in CSF game
    G. Algorithm 1 shows our proposed strategy using data attributes (which would
    be defined for qualitative and quantitative data by co-ops) and K-means clustering.
    Using this algorithm and classified dataset, we can generate sustainable CSFs
    without the issue defective farms. Algorithm 1 Proposed Fair Strategy SECTION
    VI. Proposed Implementation In this section, we present a proposed implementation
    for CSF using proposed fair strategy utilizing AWS cloud and IoT platform, shown
    in Figure 6. In CSF, various smart member farms collaborate with each other. As
    shown in Figure 6, the data is collected from different smart member farms, which
    need to be classified using SVM algorithm. This proposed implementation utilizes
    AWS IoT core2 in cloud, AWS Greengrass3 running on edge gateways (e.g., Raspberry
    Pi enabled gateway) that can enable edge computing as required, and IoT devices/things
    corresponding to specific use cases requirements. The edge gateway can be enabled
    using Raspberry Pi4 that host the AWS Greengrass deployment, and customized lambda5
    functions that can run on the gateway for edge communication and computation,
    sending notifications, or enforcing access control and privacy policies. AWS Greengrass
    allows farmers to securely connect their smart devices at the edge of the network
    to gather data. When connectivity is re-established, the data will synchronize
    with AWS cloud and its IoT services using MQTT/HTTP protocols. For enabling a
    secure architecture, AWS IoT core provides mutual authentication based on certificates
    and encryption for secure data transfer and also enable different access control
    levels, which have been discussed in [27], [28]. The data can be stored at AWS
    cloud storage and be analyzed at the co-op level for classified member farms based
    on the quality and quantity of their data attributes. The member farms cluster
    will be created using proposed fair strategy at co-op cloud level, then the member
    farms will be part of CSF. AWS IoT analytic service can be used to analyze the
    data using specific ML models and provide meaningful insights to the member smart
    farms through the smart farm applications as shown in the top layer of the proposed
    implementation architecture. SECTION VII. Conclusion In this paper, we present
    a system model of cooperative smart farm (CSF) and introduce the problem of strategic
    behavior of farmers in CSF. We analyze rational behavior of member farms in CSF
    using game theory model. We also analyze the Nash Equilibrium strategy profile
    for each scenario, where member farms are enforced to cooperate based on some
    data attributes identified by CSFs and using our proposed fair strategy in CSF.
    This work presents an extensive understanding of non-cooperative behavior of member
    farms in CSF. For future work, we plan to do further research on data attributes
    identification for ML models that can be used by CSFs to better classify the smart
    farms based on the quality and quantity of data. We also plan to implement the
    model with farming data set and evaluate the accuracy of ML model using proposed
    fair strategy. Authors Figures References Citations Keywords Metrics Footnotes
    More Like This A Game Theory Study of Big Data Analytics in Internet of Things
    IEEE Transactions on Network and Service Management Published: 2023 Towards Disaster
    Resilient Smart Cities: Can Internet of Things and Big Data Analytics Be the Game
    Changers? IEEE Access Published: 2019 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: '>'
  journal: Proceedings - 2020 IEEE International Conference on Big Data, Big Data
    2020
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: A Game Theoretic Analysis for Cooperative Smart Farming
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Shi Z.
  - Zhang S.
  - Zhang Y.
  - Yu S.
  - Xu Z.
  citation_count: '2'
  description: Based on the technologies of automation control, network communication
    and measurement, an integrated monitoring and control equipment for irrigation
    canal gates was designed, developed, and applied and verified in Jingdian Irrigation
    District of Gansu Province. The results show that the canal gates integrated measurement
    and control system can realize the automatic monitoring, collection and calculation
    analysis of the irrigation area flow data, which improves the measurement accuracy.
    It can also store, query and display the data, realize the data sharing, and form
    the irrigation district water resources management database. The remote automatic
    control and adjustment of canal discharge is realized, which improves the management
    level and efficiency. This research of the integrated canal gate measurement and
    control system provides powerful technical support for the scientific management
    of water resources in large-scale irrigation districts in China, providing a useful
    exploration for the development of the gate water measurement technology.
  doi: 10.3969/j.issn.1674-8530.18.0190
  full_citation: '>'
  full_text: '>

    "VISIT DOI.ORG DOI NOT FOUND 10.3969/j.issn.1674-8530.18.0190 This DOI cannot
    be found in the DOI System. Possible reasons are: The DOI is incorrect in your
    source. Search for the item by name, title, or other metadata using a search engine.
    The DOI was copied incorrectly. Check to see that the string includes all the
    characters before and after the slash and no sentence punctuation marks. The DOI
    has not been activated yet. Please try again later, and report the problem if
    the error continues. WHAT CAN I DO NEXT? If you believe this DOI is valid, you
    may report this error to the responsible DOI Registration Agency using the form
    here. You can try to search again from DOI.ORG homepage REPORT AN ERROR DOI: URL
    of Web Page Listing the DOI: Your Email Address: Additional Information About
    the Error: More information on DOI resolution: DOI Resolution Factsheet The DOI
    Handbook Privacy Policy Copyright © 2023 DOI Foundation. The content of this site
    is licensed under a Creative Commons Attribution 4.0 International License. DOI®,
    DOI.ORG®, and shortDOI® are trademarks of the DOI Foundation."'
  inline_citation: '>'
  journal: Paiguan Jixie Gongcheng Xuebao/Journal of Drainage and Irrigation Machinery
    Engineering
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Integrated measurement and control system for irrigation canal gates in large-scale
    irrigation districts
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Singh S.
  - Haneef F.
  - Kumar S.
  - Ongsakul V.
  citation_count: '15'
  description: The paper identifies the factors that build a framework of Internet
    of Things (IoT) adoption in agriculture by using modified TISM (total interpretive
    structural modelling). This study uses modified total interpretive structural
    modelling (m-TISM) and MICMAC methods for developing and analysing the relationship
    between elements that impact adoption of IoT in the agricultural sector. In this
    process, a framework for successful IoT adoption in this sector is devised. Through
    an extensive literature review, this study identifies eight factors that can influence
    the adoption of IoT in agriculture. The result shows that government initiative,
    crop management, irrigation management, and soil quality management have high
    driving and low dependence power. Technology is the linkage factor. The interoperability
    and reliability, control and automation, privacy and security, and IoT adoption
    have high dependence power. In this study, m-TISM is used to illustrate the relationship
    and describe the logic between different IoT adoption factors. The study has implications
    for academicians and practitioners.
  doi: 10.1504/JGBA.2020.111013
  full_citation: '>'
  full_text: '>

    "Login Help Sitemap Home For Authors For Librarians Orders Inderscience Online
    News Home Full-text access for editors A framework for successful IoT adoption
    in agriculture sector: a total interpretive structural modelling approach by Surabhi
    Singh; Farha Haneef; Sumit Kumar; Viput Ongsakul J. for Global Business Advancement
    (JGBA), Vol. 13, No. 3, 2020  Abstract: The paper identifies the factors that
    build a framework of Internet of Things (IoT) adoption in agriculture by using
    modified TISM (total interpretive structural modelling). This study uses modified
    total interpretive structural modelling (m-TISM) and MICMAC methods for developing
    and analysing the relationship between elements that impact adoption of IoT in
    the agricultural sector. In this process, a framework for successful IoT adoption
    in this sector is devised. Through an extensive literature review, this study
    identifies eight factors that can influence the adoption of IoT in agriculture.
    The result shows that government initiative, crop management, irrigation management,
    and soil quality management have high driving and low dependence power. Technology
    is the linkage factor. The interoperability and reliability, control and automation,
    privacy and security, and IoT adoption have high dependence power. In this study,
    m-TISM is used to illustrate the relationship and describe the logic between different
    IoT adoption factors. The study has implications for academicians and practitioners.
    Online publication date: Thu, 05-Nov-2020 The full text of this article is only
    available to individual subscribers or to users at subscribing institutions.   Existing
    subscribers: Go to Inderscience Online Journals to access the Full Text of this
    article. Pay per view: If you are not a subscriber and you just want to read the
    full contents of this article, buy online access here. Complimentary Subscribers,
    Editors or Members of the Editorial Board of the J. for Global Business Advancement
    (JGBA): Login with your Inderscience username and password:     Username:        Password:          Forgotten
    your password?  Want to subscribe? A subscription gives you complete access to
    all articles in the current issue, as well as to all articles in the previous
    three years (where applicable). See our Orders page to subscribe. If you still
    need assistance, please email subs@inderscience.com    Keep up-to-date Our Blog
    Follow us on Twitter Visit us on Facebook Our Newsletter (subscribe for free)
    RSS Feeds New issue alerts Return to top Contact us About Inderscience OAI Repository
    Privacy and Cookies Statement Terms and Conditions Help Sitemap © 2024 Inderscience
    Enterprises Ltd."'
  inline_citation: '>'
  journal: Journal for Global Business Advancement
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'A framework for successful IoT adoption in agriculture sector: A total interpretive
    structural modelling approach'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Cheema M.J.M.
  - Khan M.A.
  citation_count: '11'
  description: Feeding global population by 2050 requires 60% increase in the agricultural
    production. Agricultural transformation has a role to play for food security,
    poverty reduction and economic growth. However, sustainability and climate risk
    management are the challenges. The recent advancements in information technology
    (I. T) delivered smart devices, computing and sensor technologies. Application
    of those smart technologies have the potential to enable agricultural industry
    meets its productivity and sustainability challenge as well as solving indigenous
    agricultural problems of the developing nations. The geospatial data archives
    and real-time data from satellites, UAVs, RFIDs in combination with weather data,
    digitized soil data, and other real-time data streams coming from in-situ smart
    sensors can now give us a better understanding of the interaction between crops,
    weather and soils than ever before. Further the analytics of that big data assisted
    by machine learning can provide decision support in this regard. The customized
    I. T packages are required where, e-farm production system based on precision
    agriculture techniques, crops and livestock management, precision irrigation applications,
    crop water and pest/disease management, wireless moisture sensing networks, wireless
    communication in UAVs used for vegetation health detection, rainfall monitoring
    system based on mobile communication data, cloud services for knowledgebase on
    soils, nutrients, yields by making soil, nutrient and yield maps and disseminating
    through mobile networks and variable rate application based on GPS and GIS systems.
    Every passing day, the use of internet and smartphones is enhancing rapidly. The
    cloud-based services for big data analytics in agriculture and data sharing apps
    with linkages to integrated platforms and models are the future of farming in
    both modern and developing world.
  doi: 10.1007/978-3-030-23169-9_19
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Innovations in Sustainable Agriculture
    pp 585–597Cite as Home Innovations in Sustainable Agriculture Chapter Information
    Technology for Sustainable Agriculture Muhammad Jehanzeb Masud Cheema & Muhammad
    Azeem Khan  Chapter First Online: 30 October 2019 1421 Accesses 5 Citations Abstract
    Feeding global population by 2050 requires 60% increase in the agricultural production.
    Agricultural transformation has a role to play for food security, poverty reduction
    and economic growth. However, sustainability and climate risk management are the
    challenges. The recent advancements in information technology (I.T) delivered
    smart devices, computing and sensor technologies. Application of those smart technologies
    have the potential to enable agricultural industry meets its productivity and
    sustainability challenge as well as solving indigenous agricultural problems of
    the developing nations. The geospatial data archives and real-time data from satellites,
    UAVs, RFIDs in combination with weather data, digitized soil data, and other real-time
    data streams coming from in-situ smart sensors can now give us a better understanding
    of the interaction between crops, weather and soils than ever before. Further
    the analytics of that big data assisted by machine learning can provide decision
    support in this regard. The customized I.T packages are required where, e-farm
    production system based on precision agriculture techniques, crops and livestock
    management, precision irrigation applications, crop water and pest/disease management,
    wireless moisture sensing networks, wireless communication in UAVs used for vegetation
    health detection, rainfall monitoring system based on mobile communication data,
    cloud services for knowledgebase on soils, nutrients, yields by making soil, nutrient
    and yield maps and disseminating through mobile networks and variable rate application
    based on GPS and GIS systems. Every passing day, the use of internet and smartphones
    is enhancing rapidly. The cloud-based services for big data analytics in agriculture
    and data sharing apps with linkages to integrated platforms and models are the
    future of farming in both modern and developing world. Keywords Unmanned aerial
    vehicles Big data Real-time data analytics GPS GIS Plant phenomics Internet of
    everything Internet-of-things Access provided by University of Nebraska-Lincoln.
    Download chapter PDF 1 Introduction The world’s population is expected to increase
    by one-third until 2050. Majority of those additional two billion people will
    be living in the developing countries. It is expected that more people will be
    living in large population centers and big cities. If the current trends continue
    then the agricultural production will have to increase by 60% to meet the demands
    for food and feed by 2050 (Faurès et al. 2013). Therefore, farming industry has
    become ever more important than before. In this scenario, agricultural transformation
    from conventional to technology based, can play a pivotal role to feed growing
    global population and provide the foundation for economic growth and poverty reduction.
    Challenge is to sustainably increase the food production to provide food as well
    as economic opportunities in both rural and urban communities (Ahmad and Farooq
    2010). The progress in modern agricultural industry transformation can be traced
    back to decade of 1960s. The decadal progress in agriculture sector is provided
    in Table 1. In mid-1960s, the breakthrough in wheat and rice production in Asia
    brought up the famous Green Revolution that symbolized the process of using agricultural
    science to develop modern techniques for the developing world. It started from
    Mexico with the “quiet” wheat revolution and in 1960s and 1970s India, Pakistan
    and the Philippines received world attention for their agricultural progress.
    Over the past four decades in Developing Asia, the irrigated area has more than
    doubled – to 176 million hectares (mha). Fertilizer consumption has increased
    more than 30-fold and tractor in use has increased from 0.2 to 4.6 million that
    can be considered as a positive. What the world would have been like without the
    technological advances that have occurred, had the global grain yields of 1950s
    still prevailed in twenty-first Century we would have needed more than 1.8 billion
    ha additional land to equal the current global harvest (Borlaug 2002). Table 1
    Decade wise agricultural technology innovation and advancement during the past
    60 years Full size table An unprecedented systemic transformation is needed at
    a speed and scale to meet the current and future challenges of food security.
    The future agricultural systems need to be more productive, use inputs efficiently,
    have less variability and greater stability in their outputs. Moreover, the changing
    climate also needs the agricultural systems to be more resilient to, risks, shocks
    and long-term climate variability. The objective of reducing inputs and production
    costs as well as increasing yield and profitability can be addressed by changing
    the farming methods from conventional to conservation. However, more productive
    and more resilient agriculture can be practiced through a major shift in the way
    land, water, soil nutrients and genetic resources are managed for enhanced resource
    use efficiency. This transformation can also improve producers’ access to markets
    and a transformed agricultural system can reduce greenhouse gas emissions per
    unit of production and increase carbon sinks. The real transformation has been
    experienced by the advent of Information technology (I.T). It has brought up a
    revolution; the world is becoming ever more connected through it. The building
    blocks needed to make I.T based Agriculture a reality, has started to come together
    in the past few years. The estimated sale of I.T based agricultural gadgets has
    been increase manifolds as estimated by BI Intelligence (2015) and depicted in
    Fig. 1. We now have the ability to run complex computations at huge scales: a
    100 times increase in computing power. The development of cloud computing resources
    and technologies can allow us to run calculations across hundreds of machines
    and turn that back into one simple actionable solution. A shift in progress of
    technology delivered smart devices those are smaller, faster and cheaper. While
    computing and sensor technologies are in use in the developed world for the last
    two decades, their application in agriculture has not been fully utilized. Smart
    digital services have the potential to help agricultural industry meet its productivity
    and sustainability challenges. Overall, technologies can be utilized effectively
    to solve indigenous agricultural problems of the developing nations. Fig. 1 Agricultural
    IoT devices marketed in various countries. (Estimates based on BI Intelligence,
    2015) Full size image 2 Big Data in Agriculture The world is becoming digitized.
    We now can know more about the land that we farm than ever before. The availability
    of geospatial data archives and real-time data sets from satellites and Unmanned
    Aerial Vehicles (UAVs) in combination with weather data, digitized soil data,
    and other real-time data streams coming from in-situ smart sensors can give us
    a better understanding of the interaction between crops, weather and soil that
    we would never had before, in ways that are cheaper and faster (Fig. 2). All that
    bulk of data (Big Data) along with computational power is worthless unless we
    can turn it into a simple actionable solution that we can put in the hands of
    the farmer. Fig. 2 Conceptual I.T based agricultural data flow system Full size
    image Over the past years an increasing trend towards data-driven agriculture
    has been identified among farmers. According to an estimate provided by BI Intelligence
    (2016), It is estimated that 0.65 million data points are being generated every
    day from the agricultural farms that will reach up to 0.65 million. It is expected
    that more than 2.3 million data points will be generated by 2030 as many growers
    are pushing big data solutions to obtain qualitative and quantitative data to
    improve decisions regarding agricultural management and to increase their crop
    yields. Data in agriculture can be big in many ways. For example, in case of determining
    spatiotemporal variation of actual crop water use in irrigated areas at regional
    scales, a large number of Landsat scenes will cover the area every 16 days, where
    each Landsat scene occupy a storage space of approximately 1000 MB, and if approximately
    20 images were usable for each year of study and for every scene. It makes a total
    more than 500 images per year (for a typical regional scale study) and more than
    1500 images in a 3-year study. For that case, satellite-imagery (one of the input-information)
    only amounts to more than 15 terabytes, whereas the products generated during
    the course of scientific work (evapotranspiration in this case) are 10 times more
    than the original input data. Similarly, a flight of unmanned aerial vehicle covering
    agriculture area of one village (approx. 60 squares) for multispectral and thermal
    sensing generated 1.25 TB of raw data, that will be multiplied accordingly for
    additional flights during the growing season for pattern recognition, change detection
    and crop yield estimation through image processing and analytics. These projects
    are two examples of the work being carried out in digital and precision/climate-smart
    agriculture that is challenging the state of the art in computation, data storage
    and sharing. The climate-smart agriculture’s reliance on I.T. and digital data
    extends far beyond these examples. Data can also be big because of its lasting
    significance agro-ecological zones, soil survey maps, or the observation of other
    unique events. Also, data can be big because of descriptive challenges that may
    require contextual explanation and metadata. Because digital data can easily be
    shared and replicated and so re-combinable, they present tremendous reuse opportunities,
    accelerating investigations already under way and taking advantage of past investments
    in science. To encourage and enable reuse, data must be well preserved in workable
    formats. In some cases, data loss is economic loss (e.g. experiment have to be
    re-run), or it may also be an opportunity lost forever. Data are assets, and to
    achieve the greatest pay-off from these investments, researchers and institutions
    should document and implement data-management and data-sharing plans that address
    the full life cycle of data. The life cycle management of scientific data presents
    many challenges and opportunities. The challenges are great, but they can be solved
    by focused efforts and collaboration between funders, institutions and scientists.
    To facilitate data reuse, data disciplinary standards should be encouraged that
    will ultimately open the doors for development of disciplinary repositories for
    specific classes of data accessible and manageable through specialized software
    tools. The US National Institutes of Health (NIH) genetic sequence database (GenBank),
    the US Department of Agriculture (USDA) cropland database (CropScape), the US
    Geological Survey (USGS) land-cover and water database (GLOVIS) and the US National
    Virtual Observatory (USVO) are good examples of what is possible here. The repository
    of big data help to optimize inputs and increase crop yield thus helping farmers
    to get better agricultural produce. The historic trends of particular crop at
    every field can helpful in better predicting harvesting potentials. The evidence-based
    analysis of this big data can assist agricultural experts to predict and monetize
    crop yields while the farmers can get information regarding their crops and marketing
    places. 3 Data Analytics Management and Forecasting 3.1 Data Analytics The analytics
    of the big data can add value to lives of farmers and sustainability of the farms.
    Farmers cannot make sustainable farming choices based exclusively on large amounts
    of data collected at farm level. In addition to that, they also have limited time
    to digest large amount of data to find trends and/or irregularities. Therefore,
    it is difficult for them to gain actionable insights from all the crop sensors,
    drones and automated tractors. A farm management tool or software with the right
    blend of data and machine learning can help a farmer quickly decide which crops
    (down to the level of the plant) need insecticide, and then apply the chemicals
    spraying in a way that limits environmental impact and increase resource use efficiency.
    Moreover, it can also provide an opportunity to the banks and other monetary institutions
    to better assess the agricultural loans and risks associated with it. For example,
    in Pakistan, a pilot has been successfully tested to analyze the farmer’s ability
    to pay back loans to the banks. The data on land records; crop and soil health
    gathered by the multi spectral cameras on board UAV provided sufficient information
    on farmers’ pay back ability. The analytics of the data helped in improving farmers’
    income and productivity through provision of financial & technical services and
    adoption of good practices. Data analysis will be complex for more challenging
    problems of the agricultural system as well as at the individual farm level. However,
    with more involvement of deep learning and artificial intelligence in agriculture,
    it will gradually become possible to find the exact causes of low productivity
    and making real time decisions to take actions. 3.1.1 Real Time Data Analytics
    An alternative term Operational Intelligence (OI) is also used for Real-Time Data
    Analytics (RDA), a method that tracks the behavior of live systems, integrating
    streaming data with customer needs. RDA is implemented in situations requiring
    insight on a daily, frequent basis and enables farmers to analyze what’s happening
    on the farm and take immediate actions and see the results of their actions. RDA
    complements intelligent decision making by providing insight into new unstructured
    and semi-structured data in real-time. It handles Big Data in ways intelligent
    decision-making cannot. The RDA assisted streaming analytics can help agribusinesses
    make functioning decisions, adapt to the business environment and serve customers
    better when it really matters. RDA refers to a class of analytics that uses real-time
    data processing and data visualization into the processes and events while they
    occur. It is well equipped to address the integral challenges of big data by continuously
    monitoring and running query analysis against a range of high velocity and high
    volume big data sources. It associates and analyzes large volumes of (real time)
    streaming data arriving from diverse sources in order to link related events,
    discover problems, and reveal opportunities intelligently, that need immediate
    attention. 3.1.2 Intelligent Decision Making The intelligent decision making in
    agriculture is based on structured and static data collected from different sources
    to identify long-term trends in historical data of days, weeks, or even months
    long. Data generated by smart sensors collected at farms, on the field or during
    transportation offer a wealth of information about soil, seeds, livestock, crops,
    costs, farm equipment or the use of water and fertilizer. Data analytics in agriculture,
    can help farmers analyze real time data of weather, soil moisture, market trend
    or prices, GPS signals from farm machines and provide insights on how to optimize
    the resources to increase yield. It can further improve farm planning to make
    smarter decisions about the level of resources needed and their distribution strategy
    in order to prevent waste. Daily operations can be made more efficient with improved
    system performance. Additionally, the risk of natural mistakes can be reduced
    as management has a clear picture of what aspects are working successfully and
    those which can be classified as waste. The intelligent decision making has variety
    of uses in agricultural industry in particular as forecasted data, environmental
    impact, competitive advantage and waste reduction. The Agri-business Intelligence
    organizations have deployed many such dedicated analytic platforms including data
    accelerators, data appliances, and cloud based solutions to speed up the performance.
    These technologies may still not deliver true real-time data for informed decision-making,
    but they are enabling the update of data far more frequently and deliver answers
    to queries sooner. Taking everything into consideration, the intelligent decision
    making in smart farming leads to decreased expenditure and increased profits.
    The improved production through precision agriculture along with tailored marketing
    for sales using informed intelligence through smart farming to identify trends
    could lead to an extremely efficient agricultural business. 3.1.3 Tools for Big
    Agricultural Data Analysis As discussed earlier, the real-time data analytics
    depends on advanced technologies. All models used to process big data need to
    be fault-tolerant, scale with data, and have flexibility in the use of resources.
    High performance computing platforms that can provide real-time operation in seconds
    and milliseconds are of critical importance. The events need to be handled as
    they arrive for real-time insights, so high performance should characterize the
    chosen solution. Fresh streaming data can be pooled with archived data to support
    decision-making effectively and accurately. For example, the parallelism of Hadoop
    is excellent in batch processing of collected data but it has high latency. However,
    integration of a streaming data platform for continuous data analytics and streaming
    integration, real-time and interactive processing requirements presents a challenge
    that can be solved with further research in this domain. Data needs to be collected,
    processed, stored, and then finally operated for analytics including machine learning.
    In a typical streaming architecture data is gathered from several smart sensors
    that can be spread across a geographical area in an agricultural system. Then
    a distributed funnel mechanism is needed to put data into a set of available servers.
    Chen and Zhang (2014), reviewed technological solutions for data streams processing
    and open-source real-time processing systems, including Hadoop Online, S4, Storm,
    Flume, Spark streaming, Kafka, Scribe, HStreaming, Impala, and relevant messaging
    technologies. Despite the diversity the real-time systems are very similar. However,
    to come up with an efficient framework for gathering, processing and analyzing
    Big Data in agriculture in a near real-time or even better in a real-time perspective
    further research is required. 3.2 Data Management and Forecasting Every industry
    has their own experiences and challenges when it comes to dealing with big data
    and advanced analytics. Agriculture is no different, but progress is being made.
    An excellent example of using big data analytics to support sustainable farming
    practices is a research conducted by CIAT (International Center for Tropical Agriculture)
    in Colombia with assistance from Colombian government and CGIAR Research Program
    on Climate Change, Agriculture and Food Security. The CIAT research used data
    from FEDEARROZ (National Federation of Rice Growers in Colombia) to learn the
    exact causes of shrunken rice crop yields between 2007 and 2012. By analyzing
    past data and considering climate predictions, they made site-specific recommendations
    for crop variety and exact planting dates that are projected to increase yield
    to numbers that surpassed previous rice harvests. These site-specific interventions
    to reduce inputs and increase yields are referred to the term precision farming
    or interchangeably Precision Agriculture (PA). Real-time assessment of operational
    conditions (e.g. weather or disease alerts) and to carry out agile actions require
    reconfiguration features. These features usually include intelligent assistance
    in implementation, maintenance and use of the technology. For that, a PA grower
    must utilize information gathered from a series of smart devices and systems that
    communicate via the Internet to study and observe crop fields. These smart devices
    may be, temperature and soil moisture sensors, GPS farming apps and modules for
    automated machinery, satellite data, as well as drones used for aerial imaging.
    Where precision agriculture only takes in-field variability into account, the
    smart farming enhances PA by analyzing management tasks not only on location but
    also on data, enhanced by contextual and situational awareness, triggered by real-time
    events (Wolfert et al. 2014). 4 Precision Agriculture Lack of information at right
    time is causing massive losses to the farmers’ income and agricultural sustainability.
    The variability of soil from one field to the other, the variability in weather
    and crops that are planted, means the difference in optimal input for the field
    can vary three to four times from one field to the next, from 1 year to the other.
    So as a farmer, there is no way other than to put together these complex variables
    and come to a solution. Unfortunately, majority of our farmers stick back to the
    practices they know. They fall back to what is familiar or conventional and so
    majority of them barely having enough food to feed their families. Nowadays, farming
    practices are being supported by biotechnology, remote sensing, cloud computing
    and Internet-of-Things (IoT) (Li 2018) or Internet of Everything (IoE) (Dey et
    al. 2015). Internet of Everything refers to the intelligent connection of farmers/people,
    processes, data and things. IoE builds on top of the IoT, enhancing the power
    of the Internet to improve business outcomes. Rapid developments in the IoT and
    Cloud Computing are making smart farming possible. It is helpful in managing farms
    and crops database including farm location and size, cultivated area, inputs,
    time of sowing and harvesting as well as yield. Development of crop information
    management system can help the farmers to make quality and timely decisions. A
    system with a common repository that is able to collect, manage, analyze and disseminate
    the quality decision based on the data streams coming from different sources including,
    satellites, UAVs, in-situ sensors, and ambient weather conditions. Such big repository
    needs to be developed associated with high performance computing powers that can
    handle the flow of big data. Sustainably producing the right quantity and quality
    of food to take on food security challenge can be enabled by technologies. Invent
    of artificial intelligence and I.T have opened new horizons in the field of agriculture.
    Now work is being carried out to make real time agricultural robots and auto steering
    technologies to reduce labor requirements. Advanced precision agriculture technologies
    that deploy machine vision, big data analytics and advanced robotics could allow
    farmers to apply the optimal amount of inputs for each crop and assist with the
    management of livestock and aquaculture, thereby boosting yields and reducing
    water use and greenhouse gas emissions . To produce the highest yield with the
    least impact on the environment and use less water, resources and chemicals, while
    feeding our increasing population is a huge challenge. Now, new innovative technologies
    are taking on that challenge. These modern tools provide farmers with a collection
    of data about the status of the soil, insects, crops, livestock, water, and weather,
    etc. The ability to collect such detailed data has the potential to revolutionize
    agriculture and move farming toward more efficient and sustainable practices.
    The PA concept is well adopted in the various developed countries of the world.
    For example, it started in USA and Europe in early 1980s and early 1990s respectively.
    Figure 3 provides an insight of adoption rate of various technologies in Nebraska,
    USA. The spatial variability of soils was mapped and yield monitors were developed
    to map the spatial yield variability. The researchers further developed precision
    seed drills and variable rate applicators for spot application of seed, fertilizer
    and pesticides. Fig. 3 Precision agriculture technologies adoption in Nebraska,
    USA. (Source: University of Nebraska-Lincoln) Full size image The agricultural
    systems with on-board sensors were developed for automated fertilizer spreading
    and agro-chemical spraying. Use of Unmanned Arial Vehicle for agriculture (AgUAV)
    is also a hot topic of research and these are being used for crop monitoring,
    yield mapping and agrochemical spraying. Japanese are working extensively on sensor
    development, digital and hyper spectral image processing on-board UAVs. Information
    technologies platforms are in use for predictions of optimized local farming practices
    for the farmers. They provide information to the participant farmers on crop and
    soil health, weather conditions, socio-economic characteristics, labor and inputs
    availability and other related variables (Cheema et al. 2018). The flow of information
    is well described by Gebbers and Adamchuk (2010) and summarized in Fig. 4. Fig.
    4 Precision agriculture information flow for a cropping season. (Source: Gebbers
    and Adamchuk (2010)) Full size image Information technology can be used in providing
    a precision agriculture package by developing e-farm production system based on
    Precision Agriculture techniques, Crop and livestock management (RFIDs), precision
    irrigation applications, Crop water and pest/disease management, Wireless moisture
    sensing networks, Wireless communication in UAVs used for vegetation health detection,
    Rainfall monitoring system based on mobile communication data, Cloud services
    for knowledgebase on soils, nutrients, yields by making soil, nutrient and yield
    maps and disseminating through mobile networks and variable rate application based
    on GPS and GIS systems. 5 Communication and Information Sharing The innovations
    in Information Communication Technology (ICT) brought changes in many sectors
    yet agriculture and food systems have been slow to benefit from these innovations.
    There exists a great potential to harness the power of digital and I.T. It can
    promote timely as well as evidence-based decisions to improve the entire agriculture
    sector of the developing nations. Awareness and capacity building, better planning
    and community involvement is needed for agricultural breakthroughs. Since ICT
    particularly the IoT and related big data analytics provide electronic monitoring
    of crops, as well as related environmental, soil, fertilization, and irrigation
    conditions. Such a monitoring data can be used to identify which crop varieties
    will meet the challenge enhanced productivity at the particular farm anywhere
    in world. The plant phenomics (an area of biology concerned with the measurement
    of phenomes—the physical and biochemical traits of organisms—as they change in
    response to genetic mutation and environmental influences) is used to characterize
    the crop varieties. Therefore, association of monitoring and related data analysis
    results with specific crop varieties (i.e., plant genes and phenotypes) will revolutionize
    the way food is produced globally. Majority of the smart farming solutions are
    currently point based and limited to the use of specific IoT devices (e.g., a
    specific soil moisture sensor), with no further support for data analysis or sharing.
    To obtain a meaningful solution by using these IoT devices, a significant effort
    is required to integrate and correlate the data obtained from different IoT devices,
    e.g., data sets acquired from, a fertilizer sprayer (made by one manufacturer),
    soil moisture sensors (made by a different manufacturer). Development of such
    integrated model that permits a) effortless integration and use of any IoT sensor
    or device b) supports the scalable data analytics and c) allows plant biologists
    and farmers/growers to analyze and visualize plant performance data, will take
    us a step closer towards the ultimate goal (Jayaraman et al. 2016). Because use
    of internet and smartphones is enhancing rapidly. The data sharing apps with linkages
    to integrated platforms and models are future of farming and agricultural marketing.
    According to the 2015 report of International Telecommunications Union, 3.2 billion
    people were using the Internet across the globe of which 2 billion were from developing
    countries and similarly 92 of every 100 inhabitants in these countries have mobile
    phone subscriptions (ITU 2015). Therefore, the integration of I.T and agriculture
    can provide an opportunity to the farmers to attain maximum benefits by increasing
    yield, improving production, managing harvest and marketing the produce. However,
    more research is required to make customized solution and platforms to provide
    solutions tailored to specific farming scenarios in developing countries. The
    customized platforms for data sharing, manipulation and decision support are the
    key here. Where farmers can remotely monitor their equipment, crops livestock,
    stats about feeding and produce as well as market trends and information. That
    technology can even assist them to run prediction analysis for the crops, livestock
    and market. One of the biggest names in farming equipment John Deere is using
    integrated platform to connect its self-driving farm vehicles to the internet
    and display data of crop yields (BI 2015). All of these techniques are making
    data driven farming a reality. More and more data sources either in-situ, on-farm,
    low altitude or satellites can provide useful information to improve production,
    minimize inputs and environmental services from agriculture. 6 Conclusion The
    world is on the crossover of a technological revolution in the agriculture industry.
    The future of farming is in collecting and analyzing big data. Advanced analytics
    and precision agriculture will be the key to harness the technology and convert
    knowledge to farming practices in order to maximize efficiency. IoT based technologies
    with the involvement of modern instruments (sensors, computers, UAVs and satellites)
    have the potential to systematically change the traditional system of farming
    towards a low input, high efficiency and sustainable farming. These technologies
    will inevitably prove essential for taking on, what would likely be an insurmountable
    challenge, sustainably increasing our food supplies. The application of information
    technologies in agriculture wills not only help farmers to improve economy but
    also help the country to regulate overall economy and trade. Current wave of mobile
    technology proliferation in rural areas could provide opportunity to the farmers
    to improve agricultural productivity based on decisions made backed by better
    information based on big data analytics. With just a click on a smartphone, farmers
    can remove the guessing from their daily work and make the best choices that benefit
    their business and the sustainability of the land. References Ahmad M, Farooq
    U (2010) The state of food security in Pakistan: future challenges and coping
    strategies. Pak Dev Rev:903–923 Google Scholar   Business Insider (BI) Intelligence
    (2015) The internet of things: examining how the IoT will affect the world, Technical
    report. Business Insider, New York. November 2015 Google Scholar   BI Intelligence
    (2016) The internet of everything. Report. Available at http://www.businessinsider.com/intelligence/bi-intelligence-iot-research-bundle
    Borlaug NE (2002) The green revolution revisited and the road ahead. Nobelprize.
    org, Stockholm Google Scholar   Cheema MJM, Mahmood HS, Latif MA, Nasir AK (2018)
    Chapter 8: Precision agriculture and ICT: future farming. In: Khan IA, Khan MS
    (eds) Developing sustainable agriculture in Pakistan. CRC Press/Taylor & Francis
    Group, Boca Raton, pp 33487–32742 Google Scholar   Chen CP, Zhang CY (2014) Data-intensive
    applications, challenges, techniques and technologies: a survey on big data. Inf
    Sci 275:314–347 Article   Google Scholar   Dey S, Saha JK, Karmakar NC (2015)
    Smart sensing: chipless RFID solutions for the Internet of everything. IEEE Microw
    Mag 16(10):26–39 Article   Google Scholar   Faurès JM, Bartley D, Bazza M, Burke
    J, Hoogeveen J, Soto D, Steduto P (2013) Climate smart agriculture sourcebook.
    FAO, Rome, p 557 Google Scholar   Gebbers R, Adamchuk VI (2010) Precision agriculture
    and food security. Science 327(5967):828–831 Article   CAS   Google Scholar   ITU
    (2015) Key ICT indicators for developed and developing countries and the world.
    Available at: www.itu.int/en/ITU-D/Statistics/.../ITU_Key_2005-2013_ICT_data.xls.
    Accessed 7 Apr 2016 Jayaraman PP, Yavari A, Georgakopoulos D, Morshed A, Zaslavsky
    A (2016) Internet of things platform for smart farming: experiences and lessons
    learnt. Sensors 16(11):1884 Article   Google Scholar   Li Y (2018) Problems of
    application of internet of things in agricultural informationization and recommendations
    for Shandong Province. Asian Agric Res 10(2):51–54 Google Scholar   Wolfert J,
    Sørensen CG, Goense D, (2014) A future internet collaboration platform for safe
    and healthy food from farm to fork, global conference (SRII), 2014 annual SRII.
    IEEE, San Jose, pp 266–273 Google Scholar   Download references Author information
    Authors and Affiliations Center for Advanced Studies in Agriculture and Food Security,
    University of Agriculture, Faisalabad, Pakistan Muhammad Jehanzeb Masud Cheema
    & Muhammad Azeem Khan Faculty of Agricultural Engineering and Technology, University
    of Agriculture, Faisalabad, Pakistan Muhammad Jehanzeb Masud Cheema & Muhammad
    Azeem Khan Corresponding author Correspondence to Muhammad Jehanzeb Masud Cheema
    . Editor information Editors and Affiliations Department of Crop Sciences, College
    of Agricultural and Marine Sciences, Sultan Qaboos University, Al-Khoud, Oman
    Muhammad Farooq Agronomy and Crop Sciences Research and Education Center, University
    of Teramo, Teramo, Italy Michele Pisante Rights and permissions Reprints and permissions
    Copyright information © 2019 Springer Nature Switzerland AG About this chapter
    Cite this chapter Cheema, M.J.M., Khan, M.A. (2019). Information Technology for
    Sustainable Agriculture. In: Farooq, M., Pisante, M. (eds) Innovations in Sustainable
    Agriculture. Springer, Cham. https://doi.org/10.1007/978-3-030-23169-9_19 Download
    citation .RIS.ENW.BIB DOI https://doi.org/10.1007/978-3-030-23169-9_19 Published
    30 October 2019 Publisher Name Springer, Cham Print ISBN 978-3-030-23168-2 Online
    ISBN 978-3-030-23169-9 eBook Packages Biomedical and Life Sciences Biomedical
    and Life Sciences (R0) Share this chapter Anyone you share the following link
    with will be able to read this content: Get shareable link Provided by the Springer
    Nature SharedIt content-sharing initiative Publish with us Policies and ethics
    Download book PDF Download book EPUB Sections Figures References Abstract Introduction
    Big Data in Agriculture Data Analytics Management and Forecasting Precision Agriculture
    Communication and Information Sharing Conclusion References Author information
    Editor information Rights and permissions Copyright information About this chapter
    Publish with us Discover content Journals A-Z Books A-Z Publish with us Publish
    your research Open access publishing Products and services Our products Librarians
    Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC
    Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy
    rights Accessibility statement Terms and conditions Privacy policy Help and support
    129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln
    (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Innovations in Sustainable Agriculture
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Information technology for sustainable agriculture
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Dutta R.
  - Mueller H.
  - Liang D.
  citation_count: '5'
  description: According to wiki definition, there are four design principles in Industry
    4.0. These principles support companies in identifying and implementing Industry
    4.0 scenarios, namely, Interoperability, Information transparency, Technical assistance,
    Decentralized decisions. In this paper we have discussed our work on an implementation
    of a machine learning based interactive architecture for industrial scale prediction
    for dynamic distribution of water resources across the continent, keeping the
    four corners of Industry 4.0 in place. We report the possibility of producing
    most probable high resolution estimation regarding the water balance in any region
    within Australia by implementation of an intelligent system that can integrate
    spatial-temporal data from various independent sensors and models, with the ground
    truth data produced by 250 practitioners from the irrigation industry across Australia.
    This architectural implementation on a cloud computing platform linked with a
    freely distributed mobile application, allowing interactive ground truthing of
    a machine learning model on a continental scale, shows accuracy of 90% with 85%
    sensitivity of correct surface soil moisture estimation with end users at its
    complete control. Along with high level of information transparency and interoperability,
    providing on-demand technical supports and motivating users by allowing them to
    customize and control their own local predictive models, show the successfulness
    of principles in Industry 4.0 in real environmental issues in the future adaptation
    in various industries starting from resource management to modern generation soft
    robotics.
  doi: 10.1109/SYSCON.2018.8369547
  full_citation: '>'
  full_text: '>

    "IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account
    Personal Sign In Browse My Settings Help Access provided by: University of Nebraska
    - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards
    Authors Citations ADVANCED SEARCH Conferences >2018 Annual IEEE Internationa...
    An interactive architecture for industrial scale prediction: Industry 4.0 adaptation
    of machine learning Publisher: IEEE Cite This PDF Ritaban Dutta; Heiko Mueller;
    Daniel Liang All Authors 3 Cites in Papers 532 Full Text Views Abstract Document
    Sections I. Motivation II. Interactive Platform: I-EKbase III. Interactive Ground
    Truthing IV. Unsupervised Knowledge Representation V. Predictive Analytics Experiments
    Show Full Outline Authors Figures References Citations Keywords Metrics Abstract:
    According to wiki definition, there are four design principles in Industry 4.0.
    These principles support companies in identifying and implementing Industry 4.0
    scenarios, namely, Interoperability, Information transparency, Technical assistance,
    Decentralized decisions. In this paper we have discussed our work on an implementation
    of a machine learning based interactive architecture for industrial scale prediction
    for dynamic distribution of water resources across the continent, keeping the
    four corners of Industry 4.0 in place. We report the possibility of producing
    most probable high resolution estimation regarding the water balance in any region
    within Australia by implementation of an intelligent system that can integrate
    spatial-temporal data from various independent sensors and models, with the ground
    truth data produced by 250 practitioners from the irrigation industry across Australia.
    This architectural implementation on a cloud computing platform linked with a
    freely distributed mobile application, allowing interactive ground truthing of
    a machine learning model on a continental scale, shows accuracy of 90% with 85%
    sensitivity of correct surface soil moisture estimation with end users at its
    complete control. Along with high level of information transparency and interoperability,
    providing on-demand technical supports and motivating users by allowing them to
    customize and control their own local predictive models, show the successfulness
    of principles in Industry 4.0 in real environmental issues in the future adaptation
    in various industries starting from resource management to modern generation soft
    robotics. Published in: 2018 Annual IEEE International Systems Conference (SysCon)
    Date of Conference: 23-26 April 2018 Date Added to IEEE Xplore: 31 May 2018 ISBN
    Information: Electronic ISSN: 2472-9647 DOI: 10.1109/SYSCON.2018.8369547 Publisher:
    IEEE Conference Location: Vancouver, BC, Canada SECTION I. Motivation Australia
    has an uneven distribution of water resources across the continent. There is a
    relative abundance in the north where few people resides whereas in the densely
    populated southern regions water scarcity has been a long-lasting issue for the
    past decades, especially in the agricultural sector where irrigation is the lifeline
    of the industry. This paper proposes and investigates a novel approach of using
    data-driven machine learning based interactive architecture to overcome the drawbacks
    of conventional water balance modelling approaches due to the fact that the spatial
    and temporal resolution are limited as well as relying highly on condition-specified
    field experiments as a control group. Machine learning based approaches always
    require ground truthing to achieve a desirable predictive model and prediction
    accuracy, bringing significant limitations in industry scale adaptation. It requires
    continuous human intervention and interaction. Convention of Industry 4.0 Workgroups,
    namely, WG2, WG3, and WG4, tell us the principal expectation and motivation behind
    an adaptation of Industry 4.0 in The Real Environment, The Economic Environment
    and Human Beings and Work; whereas cyber-physical systems, the Internet of things,
    cloud computing, predictive analytics and cognitive computing are at core. We
    aim to expand the adaptation of Industry 4.0 standards from the world of manufacturing
    to a broad range of complex predictive decision making problems, by introducing
    an architecture that allows users to interact directly with ground truthing of
    predictive models to improve accuracy in a standardized manner [1]–[4]. SECTION
    II. Interactive Platform: I-EKbase Intelligent Environmental Knowledgebase (i-ekbase)
    is an autonomous Big Data Analytics Engine running a CLOUD system. i-ekbase is
    an easy to use fully automated geographic information system (GIS), primarily
    focussing on precision agricultural and biodiversity monitoring applications,
    automatically integrating data from various satellites with local weather data,
    farmers'' knowledge and applying Machine Learning techniques to create a Data
    Driven Future for global Agriculture. i-ekbase is regularising satellite remote
    sensing for all purpose precision agricultural monitoring on a mobile device,
    for greater benefit to global Agri-community and to increase Agri-business profitability.
    i-ekbase services provide weekly/daily large area wise resource management map
    products, including normalised vegetation index (NDVI), soil moisture, biomass,
    surface temperature, vegetation landscape maps for supporting remote digital scouting,
    large area wise farm monitoring and decision support system and rapid intervention
    of a management issue. Fig. 1. Snapshot of the i-EKbase visual interactive system
    based on big data integration over large farming areas. Show All Fig. 2. Snapshot
    of the i-EKbase visual mobile application based interactive system based on industry
    4.0 concepts. Show All Initially heterogeneous data sources, namely, Bureau of
    Meteorology-Long Paddock (SILO), Australian Water Availability Project (AWAP),
    Australian Soil Resource Information System (ASRIS), Australian Cosmic Ray Soil
    Moisture Sensor Network (CosmOz), and Australian Digital Elevation (DED) databases
    were integrated along with NASA''s LANDSAT and European Space Agency''s Sentinel-satellite
    based data, to develop the regularized visual systems (base map products are being
    delivered to Cloud based Web and Mobile applications simultaneously) to start
    with the proposed interaction with the end users to create a truly Industry 4.0
    environment [3]. SECTION III. Interactive Ground Truthing We report the possibility
    of producing most probable high resolution estimation regarding the water balance
    in any region within Australia by implementation of an intelligent system that
    can integrate spatial-temporal data from various independent sensors and models,
    with the ground truth data produced by 250 practitioners from the irrigation industry
    across Australia. During the experimental period, participating farmers used i-ekbase
    mobile app to interact with their farm maps, took real measurement of biomass,
    NDVI, soil moisture and surface temperature, before drawing polygons on touch
    screen and entering values to create ground truth profiles on the cloud system.
    These profiles were used as primary integrated observed knowledge about the farm
    to create the probabilistic hot-spot map. Each pixel on the Google earth represents
    15m-resolution analytical outcome from the big data integration. Soil moisture,
    soil surface temperature, water consumption and NDVI values of each pixel were
    used to train a simple data driven model to train a supervised knowledge predictor.
    The refined threshold of these variables was modeled based on the ground truth
    collected and also by close consultation with farm manager. This predictive system
    was trained based on farm''s historical records and hyperspectral ground truth
    data as training targets. Fig. 3. User defined ground truthing via interactive
    architecture (called fieldnote), transfering the power of data to the users. Show
    All Ground Truth data profile created by the users were then stored and displayed
    instantaneously on all i-ekbase system for future reference, machine learning
    model adaptation and improvement of overall accuracy of the resource management
    maps. There was no other way to interact such a large number of real time users
    and adapt ground truth data, than through a cloud based efficient interactive
    architecture [4]. Fig. 4. System design was focused and justified as an industry
    4.0 adaptation, as this system continuously adapting the four pillars of industry
    4.0, interoperability, information transparency, technical assistance. Show All
    Fig. 5. Illustrates the recommended application flow, which can be simplified
    as a two stage process: Stage 1, Google maps overview of all available stations
    in australia as an overlay layer representation; stage 2, traffic light style
    indication of irrigation water balance status of the user-specified station. On
    the mobile app, the user is able to locate the point of interest on the google
    map and correct the status of environmental resource with actual physical sensor
    based reading and local knowledge, hence updating the predictive classification
    paradigm dynamically and interactively. Show All SECTION IV. Unsupervised Knowledge
    Representation Clustering algorithms based on Principal Component Analysis (PCA),
    Fuzzy-C-Means (FCM) were used to process integrated data. The objective of this
    analysis was to establish a list of least correlated attributes which were contributing
    towards the most data variance. In the PCA method each orthogonal (principal)
    vector accounts for a certain amount of variance in the data, with a decreasing
    degree of importance. FCM clustering provided partitioning results with additional
    information sup-plied by the cluster membership values indicating the degrees
    of belongingness, where ‘C’ was the total number of clusters. FCM was applied
    on the selected least correlated attributes from PCA to estimate the natural grouping
    of the data. Fig. 6. Representation of the knowledge recommendation layer. PCA-FCM-SOM
    based knowledge recommendations stored as RDF along with the existing RDF based
    i-EKbase. Show All World Wide Web Consortium (W3C) introduced a format called
    Resource description framework (RDF) which is now a standard model for machine
    readable data presentation. It decomposes data into the pieces (subject, object
    and predicate) and gives a uniform resource identifier (URI) for each resource
    or object. Through the URIs, it is possible to read the information about the
    particular resource on the web by using the HTTP access. The RDF has features
    that facilitate data integration even if the underlying schema differs, and it
    specially supports the evaluation of schemas over time without requiring the entire
    data consumer to be changed. This dynamic data analysis provided ranked attributes
    (according to their importance) which were effectively a valuable recommendation
    (Fig. 6) about the whole integrated data set for any future application design.
    PCA–FCM Clustering outputs and final membership function outputs were used to
    design and initialize the SOM. The SOM algorithm was developed by Kohonen to transform
    an incoming signal pattern of arbitrary dimension into a one or two-dimensional
    discrete map. Analyses carried out using Kohonen''s Artificial Neural Network
    (ANN) fall into the category of “unsupervised learning”, in which the relevant
    multivariate algorithms seek “clusters” in the data. PCA and FCM analysis were
    used to guide the SOM clustering in terms of initializing the weights. A SOM of
    [36 × 1] network size was created to capture the natural grouping [5]–[10]. SECTION
    V. Predictive Analytics Experiments An comparison study of various supervised
    machine learning methods (including Linear Regression, Bayesian Ridge Regression,
    Logistic Regression, Linear Discriminant Analysis (LDA), Adaptive neuro-Fuzzy
    Inference System (ANFIS), Multi-Layer Perceptron (MLP), and Radial basis Function
    network (RBFN)), that exploits the class labels of the samples to identify feature
    projections that potentially maximize class discrimination, was conducted to showcase
    some parametric evaluation of the i-EKbase system (Table 1). Supervised learning
    algorithms were trained and tested against the ground truth provided by the participating
    users, showcasing the possibility of Industry 4.0 Adaptation of Machine Learning.
    Table I. Predictive learners performance A conventional 10-fold cross-validation
    was performed using the 50% randomized holdout to have a better estimation of
    the classifier performance. Best result shows that from this particular data set
    up to 90% prediction accuracy is achievable with 85% specificity and 79% sensitivity.
    This was a combination of unsupervised feature selection and supervised classification
    to test the generalisation capability of the selected features from the actual
    environmental data set increasing dynamically every day on the cloud system [1]–[10].
    SECTION VI. Adaptation in Industry 4.0 Pivot Irrigation Sustainable pivot irrigation
    based cropping and water resource management in a catchment with very limited
    water, are heavily dependent on catchments water balance model. I-EKbase was applied
    for an expert agricultural decision support system related to the catchment water
    balance model. The purpose of applying SOM on the database was to provide visual
    recommendations about the soil moisture variability on paddock, by combining user
    provided ground truth data with environmental data, applying machine learning
    techniques for predictive solution on a large area with full interoperability
    and information transparency. In this was power, control and quality of the modelling
    and associated services were passed on to the end user in a very much decentralized
    manner, respecting the four pillars of Industry 4.0 [5]–[14]. Fig 7(a). A typical
    example of pivot irrigation with robotic water spraying pivot. Show All Fig. 7(b).
    Depicts a SOM layer showing neurons as gray-blue patches and their direct neighbor
    relations with red lines. The neighbor patches are colored from black to yellow
    to show how close each neuron''s weight vector is to its neighbors, while various
    machine learning techniques were applied on the industry 4.0 compliant i-EKbase
    platform. Show All Fig. 7(c). Final outcome of a preditive irrigation map of the
    pivot based on provided point based ground truth. This spatial variation provides
    optimized assistance to guide and control the water spraying to imporve efficiency
    of water management. Show All SECTION VII. Future Adaptation in Material Industry
    In future we aim to expand theme of Industry 4.0 adaptation of machine learning
    and the newly developed architectural framework in our other projects and completely
    different industries, especially in modern manufacturing and material optimization
    for soft-robotics. Newly discovered and experimented Shape memory polymers (SMPs)
    are increasingly being used for application solutions in automotive, aerospace,
    construction and commercial field. But being a nascent field there is little knowledge
    on the shape recovery behaviour of laminates with a SMP film and there are only
    methods reported in literature for quantifying the material behaviour. Through
    various experimental data gathering and analysis, influences of different variables
    that affect the recovery behaviour of thermoplastic shape memory polyurethanes
    based laminates including ambient temperature (45 °C and 65 °C), material modulus,
    and adhesive strength have been investigated to develop a physical model to formulate
    the recovery behaviour of the material. It has been identified that a fundamental
    optimization problem that needs to be solved is to maximize the final angle recovery
    ratios and recovery rates of a material to increase the overall efficiency of
    a targeted SMP material [15]–[18]. In this future study we aim to develop a state-of-the-art
    test rig facility to conduct various experiments on a targeted SMP and capture
    useful behavioural changes by collecting contributing variables. On the other
    hand we will employ digital imaging technology to capture visual recovery related
    footprint of the material''s recovery phenomenon as a ground truth of the desired
    behavioural aspect with full interoperability and information transparency to
    make it compliant with Industry 4.0 standards. In the modelling phase, various
    machine learning techniques will be tried and tested based on the experimental
    datasets to develop an optimized and predictive data driven model to emulate the
    SMP recovery behaviour. The novel model could be adapted for various SMPs and
    accurate predictability could help to discover a new class of decorative films
    capable of improved formability and shape recovery in polymer laminates. ACKNOWLEDGMENT
    The authors would like to acknowledge Commonwealth Scientific and Industrial Research
    Organisation, Australia for supporting of these research and case study projects.
    Authors Figures References Citations Keywords Metrics More Like This Package Proposal
    for Data Pre-Processing for Machine Learning Applied to Precision Irrigation 2023
    6th Conference on Cloud and Internet of Things (CIoT) Published: 2023 A Novel
    Methodology for Modeling Ground Water Changes in Irrigation using Machine Learning
    Techniques 2020 2nd International Conference on Innovative Mechanisms for Industry
    Applications (ICIMIA) Published: 2020 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: '>'
  journal: 12th Annual IEEE International Systems Conference, SysCon 2018 - Proceedings
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'An interactive architecture for industrial scale prediction: Industry 4.0
    adaptation of machine learning'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Verdouw C.
  - Robbemond R.
  - Kruize J.W.
  citation_count: '5'
  description: Production processes in horticulture are increasingly industrialized.
    Greenhouses have developed towards high-tech production plants that are highly
    automated by advanced systems for climate control, irrigation, crop monitoring,
    harvesting, internal transportation, sorting and packaging. At the same time,
    horticultural production nowadays is a complex managerial task, which needs advanced
    management information. However, this information is often registered manually
    in enterprise management systems. This paper aims to contribute to a better integration
    of production automation systems and enterprise management systems in the Dutch
    horticulture. It investigates the current situation and existing related standards
    (ISOBUS and ISA-95). Moreover, the paper identifies barriers for the adoption
    of integration solutions, including the economic situation, a decrease of the
    high-end market, a low willingness to cooperate, a relative low scale of growers,
    a high perceived complexity and path dependency, a negative perception of the
    relative advantage and a limited willingness of growers to invest.
  doi: null
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: CEUR Workshop Proceedings
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Integration of production control and enterprise management systems in horticulture
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Chander R.P.V.
  - Elias S.
  - Shivashankar S.
  - Manoj P.
  citation_count: '18'
  description: Any physical Thing is a smart object, if it is embedded with sensor(s),
    actuator(s), a microcontroller and a low power radio. More often these components
    can be fabricated in chip, as small as the size of a human thumb finger. The main
    vision of 'Web of Things' (WoTs) is to realize connectivity of the Web to billions
    of such smart objects. Applications can be built on top of standards like IPv6
    over Low Power Wireless Personal Area Networks (6LoWPAN) at the L3 layer and IEEE
    802.15.4 at the L2 layer of the network stack. Some of the popular applications
    include smart metering, building and home automation, healthcare, asset management,
    environmental monitoring and industrial automation. One of the main challenges
    for application developers is interoperability among the services provided by
    smart objects of disparate environments. This paper deals with interoperability
    at the application layer. We present an approach using the REST principles, for
    smart plant-watering application. The proposed approach can be adapted to any
    kind of applications involving smart objects. The paper also specifies an efficient
    syndication algorithm for event notifications from Things. We empirically show
    that our proposed approach achieves interoperability as well as performs efficiently.
    © 2012 IEEE.
  doi: 10.1109/PDGC.2012.6449842
  full_citation: '>'
  full_text: '>

    "IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account
    Personal Sign In Browse My Settings Help Access provided by: University of Nebraska
    - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards
    Authors Citations ADVANCED SEARCH Conferences >2012 2nd IEEE International C...
    A REST based design for Web of Things in smart environments Publisher: IEEE Cite
    This PDF Ramaswamy Pillai Vinob chander; Susan Elias; Subramanian Shivashankar;
    Manoj P All Authors 8 Cites in Papers 674 Full Text Views Abstract Document Sections
    I. Introduction II. Related Work III. Overview of 6LoWPAN and CoAP IV. MOTIVATION
    AND CONTRIBUTIONS V. AN ASYNCHRONOUS/SYNCHRONOUS REST BASED DESIGN FOR SMARTER
    WEB OF THINGS APPLICATIONS Show Full Outline Authors Figures References Citations
    Keywords Metrics Abstract: Any physical Thing is a smart object, if it is embedded
    with sensor(s), actuator(s), a microcontroller and a low power radio. More often
    these components can be fabricated in chip, as small as the size of a human thumb
    finger. The main vision of “Web of Things” (WoTs) is to realize connectivity of
    the Web to billions of such smart objects. Applications can be built on top of
    standards like IPv6 over Low Power Wireless Personal Area Networks (6LoWPAN) at
    the L3 layer and IEEE 802.15.4 at the L2 layer of the network stack. Some of the
    popular applications include smart metering, building and home automation, healthcare,
    asset management, environmental monitoring and industrial automation. One of the
    main challenges for application developers is interoperability among the services
    provided by smart objects of disparate environments. This paper deals with interoperability
    at the application layer. We present an approach using the REST principles, for
    smart plant-watering application. The proposed approach can be adapted to any
    kind of applications involving smart objects. The paper also specifies an efficient
    syndication algorithm for event notifications from Things. We empirically show
    that our proposed approach achieves interoperability as well as performs efficiently.
    Published in: 2012 2nd IEEE International Conference on Parallel, Distributed
    and Grid Computing Date of Conference: 06-08 December 2012 Date Added to IEEE
    Xplore: 07 February 2013 ISBN Information: DOI: 10.1109/PDGC.2012.6449842 Publisher:
    IEEE Conference Location: Solan, India SECTION I. Introduction “Internet of computers”
    allows users to communicate and exchange information in an efficient way. While
    at one end, processing power and storage of computing devices are increasing;
    technology also is making devices smaller and cheaper, making them pervasive,
    wearable and mobile. These small devices are fitted with sensors and actuators
    that make them smarter (can sense, respond, communicate etc.). These devices collaborate
    among themselves and with the Web, which aligns them to be part of the “Web of
    Things” architecture. A recent estimate from Ericsson says that there will be
    more of Things connected to the Internet than users. The Advertisement on the
    Business Week Technology, June 29, 2009, reads, “By 2020 - Internet of Things
    would connect tens of billions of devices wirelessly”. According to [8], the Internet
    of Things is evolving more than its core (e.g. routers and servers) and the quickly
    growing fringe (e.g. personal computers and smart phones) to trillions of small
    embedded devices in the physical world. Both the citations view connecting of
    Things to the Internet at the IP layer of the TCP/IP stack, thereby referring
    to “Internet of Things”. This paper focuses on the application layer of the stack
    and hence we refer to it as “Web of Things”. It can be seen that billions of devices
    would generate huge amounts of data that needs to be managed efficiently and automatically.
    Unlike, the traditional Internet of Computers where humans are directly or indirectly
    involved in the management of data. Hence, huge engineering challenges are involved
    in making this vision come true. It invloves scalability, security, interoperability,
    semantics and more in maintaining and regulating such a network. Web services
    enable disparate, heterogeneous environments to communicate among each other effectively.
    They can be realized by either Simple Object Access Protocol (SOAP) approach or
    Representational State Transfer (RESTful) approach. SOAP is an xml based Remote
    Procedure Call (RPC) solution while the latter is a much more lightweight solution
    where resources are managed by HTTP interactions. SOAP is the standard used for
    exchanging messages in an interoperable manner for Web Services in Enterprises
    providing features like security, transactions, scalability etc. Though lightweight
    solutions based on SOAP, like Device Profile for Web Services (DPWS) exist, they
    are still heavy for constrained environments with low power, low bandwidth, low
    ROM/RAM. SOAP wraps the the header(where most of the required features are specified)
    and the payload in its envelope to be transported over TCP every time. RESTful
    style is more suitable for embedded applications compared to SOAP due to its advantages
    like minimal parsing complexity, statelessness, tight integration with HTTP and
    less overhead [8]. Although RESTful style is light, they are not totally suitable
    for realizing the vision of WoT (Web of Things) for following reasons: (i) synchronous
    in nature (ii) header compression overhead (iii) inefficient over lossy wireless
    multihop-networks (iv) pull based. As a solution to these problems in constrained
    environments, the IETF Constrained RESTful Environment (CoRE) Working Group is
    developing Web protocol for embedded web services, called as Constrained Application
    Protocol (CoAP) [9]. In simple terms CoAP can be seen similar to HTTP, following
    the REST architectural style, but geared towards M2M (Machine 2 Machine) applications,
    as it is asynchronous in nature working on top of UDP. The CoAP protocol is in
    its draft version-II, expiring on January 2013 as of this paper. The remainder
    of this paper is organized as follows: Section II provides some related work with
    respect to Web Services on Constrained Environments. Section III gives an overview
    of CoAP and 6LoWPAN. Section IV describes our proposed design based on CoAP for
    a real-time application. Section V has experimental results. Section VI has conclusion
    and future works. SECTION II. Related Work In traditional Internet of computers,
    Web Service is the proven efficient solution for interoperability among heterogeneous
    environments. RESTful Web service fit better than SOAP based ones as a solution
    for Constrained M2M applications. [6] is a RESTful 6LoWPAN based application framework
    for smart homes addressing service discovery and service description. Also a syndication
    mechanism based on RESTful messaging (RMS) system is specified. The response times
    of web service (REST-based) requests is very less compared to SOAP based one [11].
    A REST based implementation for home device control application on a 100Mbps LAN
    environment is shown in [2]. [3] demonstrates WoTs using Sun SPOTs, PLOGGS and
    RFID providing a holistic view for a scalable and efficient resource oriented
    architecture based on REST. Data platform as a middleware between physical objects
    and the virtual digital world is designed for vehicular networks [10]. [1] (earlier
    known as pachube), is a REST based cloud for monitoring and controlling smart
    objects. We see that all these methods are based on REST architecture. SECTION
    III. Overview of 6LoWPAN and CoAP 6LoWPAN networks generally have throughput of
    10s of kbps, and motes in these environments quite often have small ROM/RAM with
    8-bit microcontrollers. Essentially these networks use IPv6 over Low Power Wireless
    Area Networks. 6LoWPAN, specified in RFC 4919 and 4944 became a IETF standard
    in 2007. It does stateless header compression of IPV6 headers in hexadecimal,
    from around 48 Bytes to 6 Bytes giving room of around 100 Bytes for the payload,
    for any low power radio standards. Also, the edge router compresses the known
    network information, leaving only the unique MAC identifiers for the individual
    motes. This is lossless too, as the entire address is got back when exiting the
    network. 6LoWPAN makes use of a Neighbor Discovery scheme that is node initiated
    with a node registration mechanism and supports Duplicate Address Detection (DAD)
    and recovery. Mobility in 6LoWPAN networks may be either at micro, macro or at
    network level, which are handled through mobile IPv6 and Network Mobility (Nemo).
    Routing is supported at both L2 and L3 levels. The IETF Routing over Low Power
    and lossy Networks (ROLL) Working Group has specified an efficient protocol for
    Low Power and Lossy Networks (LLNs). It is called Routing Protocol for LLNs (RPL)
    which is a RFC standard 6550, March 2012. The 6LoWPAN architecture is shown in
    Fig. 1 [7] Fig. 1. The 6LoWPAN Architecture Show All Fig. 2. Layering in CoAP
    Show All The work in progress CoAP protocol by the IETFs CoRE Working Group is
    a web protocol (like HTTP) optimized for M2M applications in 6LoWPAN networks.
    CoAP supports the following features: it is a web protocol, uses UDP binding with
    optional reliability, has a low header overhead (fixed 4 bytes), URI and content-type
    support, has proxy and caching capabilities, security binding to Datagram Transport
    Layer Security (DTLS). CoAP (Fig. 2) logically have two parts: a messaging model
    for asynchronous exchange of messages over UDP and a request/response interaction
    model. CoAP interaction is similar to the client/server model (CoAP end points).
    Fig. 3 shows an example of a simple message flow for a GET request by a client
    and the server responding back with a piggybacked message. Unlike HTTP, CoAP operates
    over UDP, with reliable unicast and best effort multicast support. A CoAP endpoint
    keeps track of open Confirmable messages it sent that are waiting for a response.
    It provides simple congestion control through exponential-backoff mechanism. In
    cases when a Server might need longer time to obtain the representation of resource,
    it sends an immediate ACK stopping the client from further retransmissions. Fig.
    3. CON request and piggybacked response Show All SECTION IV. MOTIVATION AND CONTRIBUTIONS
    Motivation behind efficient interoperable Web Service approach is the automatic
    management of systems in areas like power grids, industrial automation, logistics,
    environmental intelligence, health care, etc. Work done by Dominique Guinard [3]
    featuring the “energie visible” project is a major breakthrough towards an efficient
    Web of Things architecture, focusing on interoperablility. Jing He et al. propose
    a smart web service based on Context of Things [5] using semantics and reasoning
    for a plant-watering application. Although REST principles are used for building
    smart Web Service, we can not make use of the service effectively in a 6LoWPAN
    network consisting of constrained devices. So, we propose to use semantic and
    composition principles for smart web services. We extend this by supporting most
    tiniest of IPv6 enabled devices. We present a modified framework where the communication
    between end-users and sensors is more efficient. We also propose an efficient
    Publish/Subscribe mechanism to notify the resource state changes to the users.
    SECTION V. AN ASYNCHRONOUS/SYNCHRONOUS REST BASED DESIGN FOR SMARTER WEB OF THINGS
    APPLICATIONS The proposed framework is shown in Fig. 4. It is an extension to
    the Smart Web Service based on Context of things proposed by [5]. We replace RESTful
    Web Service with CoAP. The raw data sensed(Fig. 4), is given more insight when
    added with contextual information and domain knowledge bases. A sensor event detection
    service uses these semantic services to infer whether watering is required for
    the plant or not. We propose to use an asynchronous approach with an effective
    PUSH mechanism. It can also be extended for applications involving multiple sensors
    from different vendors, interacting among each other and with the Web. Section
    “A” shows our proposed framework for M2M applications and “B” an improved PUBLISH/SUBSCRIBE
    mechanism. Fig. 4. An extended framework supporting tiny embedded devices Show
    All A. PROPOSED FRAMEWORK FOR M2M APPLICATIONS Work by J. He et al. uses HTTP
    throughout for message exchanges and therefore uses TCP and thus synchronous in
    nature. This may not be suitable for sensors with 8 bit microcontrollers, with
    low power, low ROM/RAM, and low throughput. Moreover, although the eventing service
    triggers the actuator, clients still need to poll. We propose a design that uses
    both synchronous and asynchronous transmissions supporting tiny embedded devices
    yet making use of semantics and mashups making them smarter. A sensor is assumed
    to be IPv6-ready (with a micro implementation of the IP stack) that makes use
    of the 6LoWPAN adaptation layer. Many such devices (even for 8 bit microcontrollers)
    with 6LoWPAN support exist in the market. We make use of CoAP to transfer the
    message from the sensor rather than HTTP. CoAP uses UDP, thus asynchronous in
    nature. The sensor data passes through a CoAP-HTTP mapper before it is given contextual
    information and is composed. We call this mapper rather than a gateway, as the
    conversion overhead is less than a typical gateway, and the CoAP specification
    has mechanisms for this mapping as well. Web services composition and addition
    of contextual information make use of TCP over IPv4/v6 (through tunneling) and
    the output inferred is fed to a HTTP-CoAP mapper which notifies the Thing about
    the action required to be performed. This information is in turn notified to the
    client if he has subscribed to the Thing. The Client may then act according to
    the application. In the case of plant-watering scenario, he may send a CoAP message
    that waters the plant. Fig. 4, shows our extended framework. B. IMPROVED PUBLISH/SUBSCRIBE
    MECHANISM Our approach for Publish/Subscribe mechanism is a modified strategy
    based on the work in progress “Observing” [4] protocol extension of CoAP, for
    observing resource changes. The CoAP message format (Fig. 5) with fixed header
    size of 4 Bytes, allows options (if any) to be specified, along with the payload.
    Logically, CoAP uses a messaging model and a request/response model. The messaging
    model takes care of the asynchronous interactions and the latter uses method and
    response codes for request/response interactions. Four types of messages are defined
    in the protocol. Confirmable (CON), Non-Confirmable (NON), Acknowledgement (ACK),
    and Reset (RST). A CON message needs to be acknowledged and a NON message need
    not be. Fig. 5. CoAP Message Format Show All Fig. 6. Observe option Show All Rather
    than more of server controlled nature for the frequency of notification messages
    (clients can though custom control using parameterized resource uris) in Observing,
    our approach make use of timestamps / notification period, specified in addition
    to the observe option, along with the request, reducing the number of transmissions
    involved (Acknowledge-ments from the observer and CON messages by the subject
    and retransmissions by the subject). We introduce an option called as duration
    that is used in our proposed design. Using this option along with the Observe
    option (for applications where notifications are required for a small interval
    of time, say every 5 minutes for 30 minutes) is very efficient reducing the number
    of message exchanges. Without duration, if an observer (still interested with
    a resource) forgets to acknowledge a response from the subject, he is removed
    from the observers list eventually. The observer re-registers his interest again.
    Clients (Observers) interested in receiving notifications of state changes in
    resources need to register their interests with the server (subject). How often
    observers are notified and under what conditions resources are changed is controlled
    by the subject. But for how long an observer is interested with a resource may
    be decided by the observer. An observer interested with a subject sends a CON
    GET request along with the observe option (Elective option No. 10) whose value
    is zero on transmission and is ignored on reception. The Observe option is shown
    in Fig. 6 An observer, in addition to the observe option in a GET request specifies
    another Elective option: duration (No. 22) (22 is not a IANA [Internet Assigned
    Numbers Authority] consideration yet/may be added to the CoAP options Number Registry)
    whose value is an uint that specifies a number representing the duration (in secs)
    the observer is interested with the resource. A subject (with the obs attribute
    set) receiving such a request, knows that the observer is interested in subscribing
    to the resource and that the observer is interested with the resource for the
    specified duration. It then adds the observer to its list of observers. The subject,
    in the ACK message along with the payload also sends a notification message to
    the observer indicating the client that it has been subscribed. The subject keeps
    sending notifications for any resource changes according to a notification frequency
    (Max-Age) determined by the subject, for the specified duration in the GET request.
    If an observer doesn''t like the notification interval set by Max-Age option (getting
    frequent or less-frequent notifications) of the subject, he may at any point in
    time send a NON GET to the same resource specifying a different value for the
    Max-Age option. The subject receiving such a request understands that the Max-Age
    option should be set to this new value as specified in GET request. Every further
    notification is sent according to this changed value. Notifications are sent only
    as NONs. An observer may however unsubscribe for notifications from resources
    prior to the duration expiry by sending a NON GET request with duration set to
    zero or with no observe option, or a RST for a NON notification by the subject
    (may attempt more than once). The subject then deletes the observer from its list
    of observers. This approach has the advantage of minimizing the number of exchanges
    done between an observer and a subject. In Observing, a subject sends the notifications
    in both CONs and NONs. It is through CONs, now and then, wherein a subject ensures
    that an observer is still interested in receiving notifications. If the observers
    do not send an ACK, the subject assumes that the observer is not interested in
    receiving further notifications and deletes the observer from its observers list.
    An observer interested with further notifications should send an ACK back to the
    subject. Also, retransmissions occur at exponentially increasing intervals till
    an ACK is received. Algorithm 1 illustrates (ignoring dropouts and timeouts for
    simplicity) our publish-subscribe mechanism. SECTION VI. PERFORMANCE EVALUATION
    Experiments were carried out to evaluate the advantages of CoAP over HTTP for
    the proposed design. We used Cooja, Wireshark and Copper on Contiki 2.6 to perform
    our experiments on emulated TMote skys and found that CoAP for WoTs are more efficient
    than using HTTP. Fig. 7 shows motes exchanging CoAP messages. Mote 2 is a CoAP
    server, 1 a border router and 3 through 19 being clients requesting for the resources
    in 2 in a multihop fashion. Fig. 8 shows the motes making the requests to the
    server. Fig. 9 shows the copper browser accessing a resource on a CoAP server.
    The Copper plugin for Firefox can be used to monitor and manage the resources
    efficiently over CoAP. It supports resource discovery, GET, PUT, POST, DELETE.
    Fig. 10 shows a NON for a periodic push resource, with an ACK being sent for an
    earlier CON. Fig. 11 shows a CON for a periodic push resource, with an ACK being
    sent for an earlier CON. ACKs from client are generated even after the client
    cancels the observation. These are for the remaining CONs before cancel, which
    needs to be acknowledged. Fig. 12 shows push for the plant-watering monitoring
    server only with NONs. Users may cancel the observation if not interested, where
    a RST for the same resource is sent and the server removes the client from the
    observer''s list. Fig. 13 shows the RST sent from the client. Fig. 14 shows the
    action taken using the actuator to water the plant when required. Fig. 15 and
    Fig. 16 shows the power utilization of the motes with and without CoAP. Even with
    skys “ON” 100 percent, Radio Duty Cycling (RDC) is more efficient with motes using
    CoAP mechanism than with HTTP. Also the round trip time is lesser. SECTION Algorithm
    1: The algorithm for client controlled PUSH Fig. 7. CoAP messages exchanged between
    SKY RPL Root(green), CoAP server (yellow) and the clients (pink) Show All Fig.
    8. CoAP requests Show All Fig. 9. Plant state accessed through CoAP Show All Fig.
    10. NON with ACK from client for a previous CON Show All Fig. 11. CON with ACK
    from client for a previous CON Show All Fig. 12. NONs only for syndication Show
    All Fig. 13. RST monitoring Show All Fig. 14. actuator invoked to water the plant
    Show All Fig. 17 shows this for ten requests being made by CoAP and HTTP clients.
    The simulation was setup with four intermediate hops before the requests reached
    the destination. The X-axis in the figure represents time in seconds. SECTION
    VII. CONCLUSION AND FUTURE WORK With many devices already being IP-enabled, Wireless
    Embedded Internet over IPv6 is predicted to be the next biggest revolution for
    automated, efficient, smarter and scalable Web of Things applications. Making
    this a reality involves numerous challenges like interoperability (device level/network
    level/application level), resource discovery, composability, security, etc. This
    paper deals with interoperability at the application level and provides a novel
    approach for an efficient, extendible, and smart, web service using CoAP as web
    protocol. CoAP has the following advantages: asynchronous in nature, designed
    for 6LoWPAN networks, multicasting, built-in resource discovery, and security.
    CoAP is analyzed for its efficiency over HTTP and has been experimentally evaluated
    for Round trip time and RDC. Further an algorithm for an efficient PUSH scheme
    has also been proposed and evaluated. Experimental results are encouraging to
    further improve the proposed work. Message exchange is still synchronous in parts
    of our design where semantics is involved. Efficient mehanisms to make this part
    of our design CoAP based could be a potential future work. Approaches like compression
    and fragmentation, use of microdata and Efficient XML Interchange (EXI) can be
    explored. Fig. 15. TX and RX for 12 skys exchanging CoAP messages Show All Fig.
    16. TX and RX for skys exchanging http messages Show All Fig. 17. RTTs for CoAP
    and http Show All Authors Figures References Citations Keywords Metrics More Like
    This Using IPv6 and 6LoWPAN for home automation networks 2011 IEEE International
    Conference on Consumer Electronics -Berlin (ICCE-Berlin) Published: 2011 IETF
    IoT based wireless communication for latency-sensitive use cases in building automation
    2016 IEEE 25th International Symposium on Industrial Electronics (ISIE) Published:
    2016 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details
    PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: Proceedings of 2012 2nd IEEE International Conference on Parallel, Distributed
    and Grid Computing, PDGC 2012
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: A REST based design for Web of Things in smart environments
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors: []
  citation_count: '0'
  description: 'Like natural ecosystems, the cyber ecosystem comprises a variety of
    diverse participants - private firms, non-profits, governments, individuals, processes,
    and cyber devices (computers, software, and communications technologies) - that
    interact for multiple purposes. Today in cyberspace, intelligent adversaries exploit
    vulnerabilities and create incidents that propagate at machine speeds to steal
    identities, resources, and advantage. The rising volume and virulence of these
    attacks have the potential to degrade our economic capacity and threaten basic
    services that underpin our modern way of life. This discussion paper explores
    the idea of a healthy, resilient - and fundamentally more secure - cyber ecosystem
    of the future, in which cyber participants, including cyber devices, are able
    to work together in near-real time to anticipate and prevent cyber attacks, limit
    the spread of attacks across participating devices, minimize the consequences
    of attacks, and recover to a trusted state. In this future cyber ecosystem, security
    capabilities are built into cyber devices in a way that allows preventive and
    defensive courses of action to be coordinated within and among communities of
    devices. Power is distributed among participants, and near-real time coordination
    is enabled by combining the innate and interoperable capabilities of individual
    devices with trusted information exchanges and shared, configurable policies.
    To illuminate such a cyber ecosystem in action, one might look at today''s practice
    known as “continuous monitoring,” in which system managers use a variety of software
    products to automatically detect and report known security vulnerabilities in
    network nodes. In some cases, system managers further configure their systems
    to automatically remediate detected security deficiencies. To offer an analogy,
    continuous monitoring is to a healthy cyber ecosystem as smoke detectors and sprinkler
    systems are to a “smart” building. At the other end of sophistication in the orderly
    management of a complex system, we draw inspiration from the human body''s immune
    system. To paint a picture that mirrors the body''s ability to defend itself is
    complex. It might include layered defenses and countermeasures that work in tandem;
    specialized roles; powerful methods for rapidly identifying attackers; surge capabilities;
    and the ability to learn and rapidly adapt. A companion analogy may be made to
    the public health system and the Centers for Disease Control and Prevention (CDC).
    Here, cyber equivalent functions might include threat and incident watch, data
    dissemination, threat analysis, intervention recommendations, and coordination
    of preventive actions. Automation is one of three interdependent building blocks
    of a healthy cyber ecosystem, along with interoperability and authentication.
    Automation can increase speed of action, optimize decision making, and ease adoption
    of new security solutions. A healthy cyber ecosystem might employ an automation
    strategy of fixed, local defenses supported by mobile and global defenses at multiple
    levels. Such a strategy could enable the cyber ecosystem to sustain itself and
    supported missions while fighting through attacks. Further, it could enable the
    ecosystem to continuously strengthen itself against the cyber equivalent of autoimmune
    disorders. Interoperability can broaden and strengthen collaboration, create new
    intelligence, hasten and spread learning, and improve situational awareness. This
    paper posits three types of interoperability - semantic (i.e., shared lexicon
    based on common understanding), technical, and policy - as fundamental to integrating
    disparate cyber participants into a comprehensive cyber defense system. It examines
    how the cybersecurity community has achieved some early successes by explicitly
    separating the management of security information from the management of security
    functions in an approach called security content automation. Such successes include:
    developing naming conventions and shared lists and catalogs of the fundamental
    elements that we identify here as the ecosystem; creating and using machine readable
    languages and formats for expressing security policies or encoding security transactions;
    and developing and using knowledge repositories for best practices, benchmarks,
    profiles, standards, templates, checklists, tools, guidelines, rules and principles,
    among others. The paper also looks at some challenges associated with expanding
    this approach to ensure a widely distributed, automated, collective defense. Authentication
    can improve trust in ways that enhance privacy and decision making. It is integral
    to many capabilities beyond cyber defense, and the paper looks to the emerging
    National Strategy for Trusted Identities in Cyberspace (NSTIC), detailed below,
    to build a shared foundation. The paper calls for identification and authentication
    technologies that deliver across five operational objectives: security, affordability,
    ease of use and administration, scalability, and interoperability. Additionally,
    the paper calls for consumer guides that rate technologies across all five objectives
    and assist system developers and owners in making phased improvements and selections.
    For automated cyber defense, it calls for strong standards-based device authentication,
    including for software, handheld devices, and small, often wireless, devices composing
    massively scalable grids. The paper also draws on current research on network-enabled
    enterprises that is recasting traditional notions of command and control in the
    direction of focus and convergence. Focus provides the context and defines the
    purposes of an endeavor, but is agnostic regarding who might be in charge or particular
    lines of authority. Convergence refers to the goal-seeking process that guides
    actions and effects, but recognizes that control works in an unconventional manner
    in highly distributed systems. The paper presents a five-level maturity model
    for ecosystem focus and convergence that is associated with increasing agility
    and provides an approach for defining how to achieve and employ these various
    levels. Ecosystem maturity is further explored through a discussion of healthy
    attributes-eight for the ecosystem and eighteen for participants and exchanges.
    The paper concludes with a brief discussion of incentives and recommendations
    for the way ahead. It posits that the slow adoption of available best practices
    and technologies in the face of increasing cyber attacks indicates an imbalance
    of incentives and proposes that better and more widely disseminated aggregated
    and anonymized information about the frequency and actual harm of cyber attacks
    is needed. Despite the many open questions remaining, the field is ripe for planning
    and action.'
  doi: null
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: 'Security in Cyberspace: Select Assessments and Policy Considerations'
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Enabling distributed security in cyberspace: Building a healthy and resilient
    cyber ecosystem with automated collective action'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

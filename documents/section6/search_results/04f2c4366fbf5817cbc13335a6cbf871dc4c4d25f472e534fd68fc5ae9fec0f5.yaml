- DOI: https://doi.org/10.1109/mnet.2019.1800543
  analysis: '>'
  authors:
  - Ali Alnoman
  - Shree Krishna Sharma
  - Waleed Ejaz
  - Alagan Anpalagan
  citation_count: 52
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy IEEE.org IEEE Xplore IEEE
    SA IEEE Spectrum More Sites Subscribe Donate Cart Create Account Personal Sign
    In Browse My Settings Help Institutional Sign In All Books Conferences Courses
    Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals & Magazines
    >IEEE Network >Volume: 33 Issue: 6 Emerging Edge Computing Technologies for Distributed
    IoT Systems Publisher: IEEE Cite This PDF Ali Alnoman; Shree Krishna Sharma; Waleed
    Ejaz; Alagan Anpalagan All Authors 42 Cites in Papers 1500 Full Text Views Abstract
    Document Sections Introduction Computing in Distributed IoT Systems: Challenges
    and Potential Solutions Classification of Emerging Edge-IoT Technologies Proposed
    Optimization Framework for Edge-IoT Systems Use Case Study Show Full Outline Authors
    Figures References Citations Keywords Metrics Abstract: The ever-increasing growth
    of connected smart devices and IoT verticals is leading to the crucial challenges
    of handling the massive amount of raw data generated by distributed IoT systems
    and providing timely feedback to the end-users. Although the existing cloud computing
    paradigm has an enormous amount of virtual computing power and storage capacity,
    it might not be able to satisfy delay-sensitive applications since computing tasks
    are usually processed at the distant cloud-servers. To this end, edge/fog computing
    has recently emerged as a new computing paradigm that helps to extend cloud functionalities
    to the network edge. Despite several benefits of edge computing including geo-distribution,
    mobility support and location awareness, various communication and computing related
    challenges need to be addressed for future IoT systems. In this regard, this article
    provides a comprehensive view of the current issues encountered in distributed
    IoT systems and effective solutions by classifying them into three main categories,
    namely, radio and computing resource management, intelligent edge-IoT systems,
    and flexible infrastructure management. Furthermore, an optimization framework
    for edge-IoT systems is proposed by considering the key performance metrics including
    throughput, delay, resource utilization and energy consumption. Finally, an ML
    based case study is presented along with some numerical results to illustrate
    the significance of ML in edge- IoT computing. Published in: IEEE Network ( Volume:
    33, Issue: 6, Nov.-Dec. 2019) Page(s): 140 - 147 Date of Publication: 15 May 2019
    ISSN Information: DOI: 10.1109/MNET.2019.1800543 Publisher: IEEE Introduction
    The next generation of Information and Communication Technology is characterized
    by the ubiquity of smart devices and machines that perform intelligent functions
    by autonomously sensing, analyzing, and exchanging information via the Internet.
    From E-health, smart homes and intelligent transportation to industrial manufacturing
    and supply chain, Internet of Things (IoT) is intended to provide humanity with
    an easier, safer and more intelligent lifestyle. However, the rapid growth of
    IoT applications has increased the number of connected “Things” to unprecedented
    levels. The number of connected devices is forecasted to reach about 125 billion
    (IHS Markit) by 2030, and Machine-to-Machine (M2M) communications, which constitutes
    a large proportion of IoT applications, is expected to occupy almost 45 percent
    of the entire network traffic by 2022 [1]. Sign in to Continue Reading Authors
    Figures References Citations Keywords Metrics More Like This Workload Allocation
    Mechanism for Minimum Service Delay in Edge Computing-Based Power Internet of
    Things IEEE Access Published: 2019 Resource Management for Pervasive-Edge-Computing-Assisted
    Wireless VR Streaming in Industrial Internet of Things IEEE Transactions on Industrial
    Informatics Published: 2021 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE network
  limitations: '>'
  pdf_link: null
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: Emerging Edge Computing Technologies for Distributed IoT Systems
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/coniiti.2018.8587095
  analysis: '>'
  authors:
  - Alberto Pacheco
  - Pablo H. Zapata Cano
  - Ever Flores
  - Edgar Espinosa Trujillo
  - Pedro Márquez
  citation_count: 16
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy IEEE.org IEEE Xplore IEEE
    SA IEEE Spectrum More Sites Subscribe Donate Cart Create Account Personal Sign
    In Browse My Settings Help Institutional Sign In All Books Conferences Courses
    Journals & Magazines Standards Authors Citations ADVANCED SEARCH Conferences >2018
    Congreso Internacional d... A Smart Classroom Based on Deep Learning and Osmotic
    IoT Computing Publisher: IEEE Cite This PDF Alberto Pacheco; Pablo Cano; Ever
    Flores; Edgar Trujillo; Pedro Marquez All Authors 15 Cites in Papers 636 Full
    Text Views Abstract Document Sections I. Introduction II. Method III. A Smart
    Classroom Test Bed IV. Performance Results V. Conclusions Authors Figures References
    Citations Keywords Metrics Abstract: The biggest growth rate of network traffic
    in the coming years will be for smartphones and Internet-connected devices, which
    relentless tend to perform increasingly demanding tasks on continuously increasing
    amounts of data. Machine Learning and Edge Computing are emerging as effective
    paradigms for processing huge amounts of data supplied by the Internet of Things
    and Smart Cities. An osmotic computing architecture for an IoT smart classroom
    is used for testing a deep learning model for person recognition. A comparative
    performance study and analysis was made by means of selecting a single deep learning
    model, that it was tried to be adapted to run over the cloud, a fog microserver
    and a mobile edge computing device. The results obtained shown some promising
    results and also limitations for the edge and fog computing side that will need
    to be addressed in order to minimize latencies and achieve real-time responses
    for the present IoT application. Published in: 2018 Congreso Internacional de
    Innovación y Tendencias en Ingeniería (CONIITI) Date of Conference: 03-05 October
    2018 Date Added to IEEE Xplore: 27 December 2018 ISBN Information: DOI: 10.1109/CONIITI.2018.8587095
    Publisher: IEEE Conference Location: Bogota, Colombia I. Introduction The ‘Smart’
    City concept: a) is profoundly complex, and has been mutated from prior adjectives
    such as digital, creative, knowledge-based, sustainable, resilience-driven or
    intelligent cities [1]–[4]; b) it combines different indicators, fields and technological
    perspectives, such as the ICT -based ‘hard’ perspective in the 1990s [5], and
    the recent Artificial Intelligence (AI) and the Big Data ‘soft’ perspectives;
    c) is scalable to ‘smart’ rooms, homes, buildings, villages, cities or nations,
    and can be approached from diverse paradigms, such as smart living, ambient-assisted
    living, or cyber-physical systems [1], [2]. Ramaprasad et al. [1] reported more
    than 36 smart city definitions, and proposes a unified Smart City Ontology (SCO),
    which is able to instantiate thousands of variations from six domains (Table I):
    outcomes, stakeholders, semiotics, structure, functions, and focus. Table I. The
    smart city ontology framework (sco) DOMAINS ELEMENTS 1. Outcomes Quality, sustainability,
    equity, livability, resilience 2. Stakeholders Citizens, professionals, institutions,
    businesses… 3. Semiotics Data, pattern, stream, information, knowledge… 4. Structure
    Architecture, services, systems, infrastructure… 5. Functions Sense, identify,
    monitor, control, translate, notify 6. Focus Economical, environmental, social,
    cultural… Sign in to Continue Reading Authors Figures References Citations Keywords
    Metrics More Like This Performance Evaluation of Containerization in Edge-Cloud
    Computing Stacks for Industrial Applications: A Client Perspective IEEE Open Journal
    of the Industrial Electronics Society Published: 2021 Performance Modeling of
    Openstack Cloud Computing Platform Using Performance Evaluation Process Algebra
    2015 International Conference on Cloud Computing and Big Data (CCBD) Published:
    2015 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details
    PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: A Smart Classroom Based on Deep Learning and Osmotic IoT Computing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/aisp48273.2020.9073062
  analysis: '>'
  authors:
  - Anwesha Banerjee
  - Bhabendu Kumar Mohanta
  - Soumyashree S. Panda
  - Debasish Jena
  - Srichandan Sobhanayak
  citation_count: 14
  full_citation: '>'
  full_text: '>

    IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account
    Personal Sign In Browse My Settings Help Access provided by: University of Nebraska
    - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards
    Authors Citations ADVANCED SEARCH Conferences >2020 International Conference...
    A Secure IoT-Fog Enabled Smart Decision Making system using Machine Learning for
    Intensive Care unit Publisher: IEEE Cite This PDF Anwesha Banerjee; Bhabendu Kumar
    Mohanta; Soumyashree S. Panda; Debasish Jena; Srichandan Sobhanayak All Authors
    13 Cites in Papers 265 Full Text Views Abstract Document Sections I. Introduction
    II. Related Work III. Proposed Work IV. Security Analysis Using Blockchain V.
    Conclusion Authors Figures References Citations Keywords Metrics Abstract: Internet
    of Things(IoT) is a connection of smart things and act quickly in any environment.
    Fog computing based framework has been used to be integrated with IoT to enable
    real-time processing at the network edge, aiming to improve the users experience
    and resilience of the services in case of emergency. With the advantage of distributed
    architecture and close to end-users, fog edge computing can provide faster response
    and greater quality of service for IoT applications. In this paper, we have proposed
    a framework that uses, fog computing along with IoT and machine learning to provide
    a better and smarter healthcare experience. The security of the framework is ensured
    by application of Blockchain technology. Published in: 2020 International Conference
    on Artificial Intelligence and Signal Processing (AISP) Date of Conference: 10-12
    January 2020 Date Added to IEEE Xplore: 23 April 2020 ISBN Information: ISSN Information:
    DOI: 10.1109/AISP48273.2020.9073062 Publisher: IEEE Conference Location: Amaravati,
    India SECTION I. Introduction The healthcare services requires to undergo remodelling
    from the existing framework that focuses on providing doctor facility to another
    framework that focuses on the individual patients. The alternative framework focuses
    on continuous surveillance on the health condition of patients and hence staying
    a step forward in keeping the diseases under control (Moosavi et al., 2015) [1].
    Radio frequency technology forms the basis of the framework which provides common
    networking performances (Abdmeziem and Tandjaoui, 2015) [2]. The connection mindful,
    active applications are customized according to the need of a person. Communication
    with connected devices is carried using reliable trusted channels. Handling of
    fluctuating availability, and data-creating characteristics of devices as well
    as heterogeneous devices, by the aid of modern approaches have come up as a requirement
    due to the enormous increment in the Iot services [2] [3]. Smart health cards
    are an integral part of the smart healthcare.It provides the security and protects
    the privacy of the data of the patients. Nevertheless, smart health cards are
    susceptible to threats and attacks like larceny, insider misuse,loss, hacking,
    unintentional actions, cyberattack and internal attack (Aman and Snekkenes, 2016)
    [4]. An efficient authentication architecture for healthcare systems that are
    based on IoT is proposed by Moosavi et al. (2015) [1] . The proposed architecture
    utilizes a distributed smart e-health gateway to ensure security.Due to its distributed
    nature,the gateway is prone to be abused on medical sensor nodes derived from
    the end-user. Security threats or abuse of private information can possibly act
    as an obstruction in the process of the public utilizing IoT-based health care
    frameworks. Hence ,network infrastructures that ensures security for long- or
    short- range transmission are needed to alleviate threats within the architecture.
    Personalized services that can be provided in a smart city domain is proposed
    by Gaur et al. (2015) [5]. It facilitates communication between WSNs and ICTs
    by utilizing semantic web technologies and the DempsterShafer uncertainty theory
    .Elderly individuals and Alzheimer’s patients are aided by this architecture with
    their quotidian breathing exercises. The architecture sends notifications to the
    users in those occasions when they are unable to complete their breathing exercises
    or fail to remember to do so. Individuals dwelling in a smart society can also
    be benefited by this framework because it can aid as a smart platform by utilizing
    the networking information that are acquired from various different smart cities.
    Nonetheless, the architecture has a drawback that it is unable cover a vast geographical
    region (i.e., it focuses on the portions of the smart city which is of utmost
    importance) and is yet to be tested. Therefore, an architectural proposition that
    is able to cover a whole city without leaving any portions of the city unnoticed
    and designing of experiments based on the idea explored above, must also be done.
    SECTION II. Related Work In the current scenario , Internet of Things is gaining
    insurmountable importance with every passing day.Also its significance in the
    scope of remote monitoring system is escalating day by day . The remote monitoring
    systems include Healthcare monitoring, assets or vehicle monitoring, parking management,
    energy grid monitoring etc. Particularly, a great deal of research is happening
    in the sphere of medical equipment, patient care by accommodating newly developed
    electronics technology. A fixed route,bus tracking model has been presented in
    [6] which is a simple and elegant solution. A smart phone based application and
    LED display panel is used to display the location after a particular time interval.
    Students attending classes in colleges or universities in big campuses are highly
    benefited by this mode. Lei et al. [7] proposed a scheme for secure key management
    in an Intelligent Transportation System (ITS). The scheme utilizes the benefits
    of Blockchain for secure key transfer between ITS infrastructures. Recently Blockchain
    technology is being used extensively to build a true decentralized or distributed
    and secure framework for IoT use cases. In [8], Khan et al. suggested that the
    intrinsic features (Address space, Data Authentication and Integrity, Governance,
    Secure Communication) of Blockchain can be exploited to address many privacy and
    security related problems of IoT systems. A system that can detect water pollution
    is very beneficial for pollution management. A water monitoring system that works
    in real-time is discussed in [9]. An assorted set of sensors that constitute the
    system is used to measure the humidity or temperature, pH level etc. Data collected
    from sensors are directly sent to the base station for continuous surveillance
    the pollution level in the water. A patient monitoring system that works in real
    time for Intensive Care Unit (ICU) has been proposed in [10]. Different sensors
    have been used to measure the heart rate, temperature, upper blood pressure, lower
    blood pressure, ECG etc. Data from these sensors are used for continuous vigilance
    of the patient in ICU from different locations, which improves the efficiency
    and quality of service. Next in [11], Guo et al. combined Blockchain with Attribute
    Based Signature (ABS) scheme to resist collusion attack in a multiple authority
    healthcare system. [12] has proposed a monitoring system that provides interrupted
    service to the patients in a Intensive Care Unit. It uses an equipment that remotely
    acquires and posts data to the concerned individual who is responsible for the
    particular ICU at a particular instant of time. The physiological signals include
    Diastolic and Systolic Blood Pressure (BP),ECG, EEG, Saturation Point of Oxygen
    in a blood. The data obtained from the aforementioned cardiac monitors are send
    to the cloud server and the data is posted to the database. Following this, pre-existing
    specific software is used for the processing of the data and the outcomes are
    displayed on the screen of a computer or laptop only if the cellular Android devices
    are not within the range of the IoT. Fig. 1. Internet of Things (IoT) Applications
    Show All Fig. 2. Internet of Things (IoT) Applications Show All Fig. 3. Internet
    of Things (IoT) Applications Show All SECTION III. Proposed Work In our proposal
    , We present with a scenario where smart healthcare is a reality.Almost every
    healthcare institution has at least one functioning intensive care unit for treatment
    of patients who are undergoing critical ailments. Here we consider a scenario
    where in a particular healthcare institution , data about the bio-metric attributes
    of the patients admitted in the intensive care unit is collected and processed
    in real-time,thus enabling the concerned authority to be informed when there is
    a need for the patient to be attended. A. Framework to be implemented In the use-case
    scenario under consideration, there are three living entities related to the intensive
    care unit environment-the patients, the attendants, and the doctors. It is shown
    in figure 1. We propose that a small group of doctors is assisted by an attendant
    and that attendant is responsible for attending all the patients who are being
    treated by the before mentioned group of doctors. Figure 2 describes the bonding
    between the attendant, the patients and the group of doctors. Fig. 4. Internet
    of Things (IoT) Applications Show All An intensive care unit may have more than
    one attendant. Each attendant is linked to the respective group of doctors and
    is responsible for attending the corresponding patients. 1) Real-time data collection
    using IOT devices The intensity of the care provided in the ICU requires many
    monitoring devices. The patients in the ICU are being constantly monitored and
    data regarding the bio-metric attributes are visible on the monitors of the special
    equipment used in ICU. In the process of constant monitoring, real-time data such
    as the blood pressure, oxygen saturation heart rate, temperature and ECG of the
    patient is visible on the monitor. Other attributes like central venous pressure,
    pulmonary arterial pressure (PAP) readings, cardiac output reading are also sometimes
    monitored. These data are collected by the smart devices that in turn sends these
    data to the fog devices. The fog devices store the real-time data for a small
    interval of time, generally three to four hours. After every three hours, the
    data stored in the fog devices is uploaded in the cloud storage. Figure 3 gives
    a diagrammatic representation of the process. 2) Decision making through machine
    learning techniques The data about the physiological signals of the patient is
    collected by the smart devices and is sent to the fog devices. The data thus collected
    is retained in each fog device for at-most three hours. While the data is retained
    in the fog devices, each of the fog devices uses it’s computing power to deploy
    machine learning techniques to test and decide whether data about the physiological
    signals collected in real-time is demonstrating any need for the patient to be
    attended by the attendant. If the condition is fulfilled by the physiological
    signals and the need for attention is real, the attendant will receive a notification
    in his or her mobile device. The notification will constitute the snapshot of
    the latest data collected about physiological signals and the message that the
    patient needs attention. The attendant on receiving the notification will attend
    the patient and see if the case is fatal or it could be it handled by the attendant
    himself. If the case is fatal, the attendant informs the doctor responsible for
    the treatment of the concerned patient.Figure 4 gives a diagrammatic representation
    of the process. 3) Secure data flow using Blockchain With the technological advent
    of the Blockchain, works have been going on for using Blockchain for security
    in IoT devices. Proposals have been made and research is still going in this matter.
    In our work, we propose a security measure for the framework using Blockchain.
    In current time, all the devices used in the intensive care unit for monitoring
    of the patient can be connected to the internet. All IoT devices nowadays are
    equipped with an identifier that encodes the manufacturer, model number and production
    series. The approach proposed by us requires the IoT devices to be equipped with
    tamper-proof memory space. The temper proof memory space of an IoT device can
    be used by the manufacturer to store the private key while the corresponding public
    key related to the IoT device is stored in the Blockchain along with the unique
    ID and an identifier that encodes the manufacturer, model number and production
    series. So, the public key of all the authorized IoT devices is publicly available
    to all the fog nodes. Thus it is ensured that when the IoT devices send out data
    to the fog devices, all the data packets are digitally signed. The fog devices
    can verify the authenticity of the data thus received by accessing the public
    key stored in the Blockchain. Similarly, each of the fog nodes and the mobile
    devices of the attendants and doctors is assigned with a private/public key-pair.
    The private keys of all the devices are required to be stored in the temper proof
    memory space while the public key is stored in the Blockchain along with the unique
    ID. Thus after the data collected by the IoT devices are verified for authenticity
    by the fog nodes, when an alert message is sent from the fog nodes to the mobile’s
    device, it is digitally signed by the private key of the fog node. On receiving
    the alert message, the attendant’s mobile devices will check for the authenticity
    and integrity of the message by accessing the public key stored in the Blockchain.
    In a similar manner, when an alert message is sent from the attendant’s mobile
    device, it is digitally signed by the private key of the mobile device. Thus,
    the doctor’s mobile device on receiving the message can check the authenticity
    and integrity of the message by accessing the public key of the attendant’s mobile
    device. Figure 6 gives a pictorial representation of the public key of the devices
    to be stored in the blockchain. B. Procedure In this subsection, we briefly describe
    the procedure in which the proposed framework will be functioning with an example.
    Fig. 5. Internet of Things (IoT) Applications Show All 1) IOT devices Each patient
    in the intensive care unit has a set of IoT devices associated with him which
    is collecting real-time data about the physiological signals. For the patient
    admitted in the bed with the unique ID as X, let the corresponding group of IoT
    devices be identified by unique IDs having the format ’IOT_XY’ where Y is the
    ID of the IoT device. Thus the first IoT device of the patient admitted in bed
    number 2 is identified by the ID ’IOT_21’. As mentioned earlier, each of the IoT
    devices will possess an Elliptic Curve (EC) private/public key-pair. The private
    key PrK_IOT_XY is stored in the temper proof memory space of the IoT device while
    the public key PbK_IOT XY is stored in the Blockchain along with its unique ID
    ’IOT_XY’. Each of the data packets is digitally signed by using Elliptic Curve
    Signature Algorithm (ECDSA) and by using the private key of the IoT device. In
    this subsection, we briefly describe the procedure in which the proposed framework
    will be functioning with an example. 2) Fog nodes Fog computing, in general, refers
    to the de-centralized computing infrastructure in which data, compute, storage
    and applications are located somewhere between the data source and the cloud.
    Here in our proposed approach, each patient’s data is stored and processed in
    a fog node dedicated for the purpose. Each fog node is identified by a unique
    ID ’ F_x’. Each of the fog devices is also having an elliptic curve private/public
    key pair. The private key PrK_F_X is stored safely in a temper proof memory space
    whereas the public key PbK_F_X is stored in the blockchain along with the unique
    ID of the fog node ’F_X’. As mentioned before, the message sent from the fog device
    is digitally signed by using Elliptic Curve Signature Algorithm (ECDSA) [13] .
    In our proposed work, the computation done in the fog node does not begin until
    two to three hours after the patient is shifted to the ICU. In those initial hours,
    data about the physiological signal is collected and the machine learning model
    is trained using this data keeping all the constraints in mind. Once the model
    is trained, all the new data received by the fog node is classified in two classes
    - attention needed or attention not needed and the later steps are followed accordingly.
    The data received by the fog node is retained by the fog node for three hours.A
    Raspberry Pi3 can be used as a fog node to interact with the IoT devices After
    every three hours interval, the machine learning model is retrained with the data
    collected in the last three hours. While the retraining is going on, the pre-trained
    model still continues to function. Thus, two instances of the same model will
    be running simultaneously for a brief period of time required for retraining.
    Once the retraining is completed, this newly trained model replaces the previous
    model. After the replacement, the data is from the fog mode is pushed to the cloud
    for storage. 3) Machine learning techniques for decision making The bio-metric
    attributes like blood pressure, oxygen saturation, heart rate, and temperature
    have a standard set of values that are expected in a healthy human being. A healthy
    human being has a heart rate within the range 70 to 110 beats per minute whereas
    if the heart rate of a patient is between 20 to 30 beats per minute, it can be
    fatal. If an ICU patient is having his or her heart rate either less than 50 beats
    per minute or more than 120 beats per minute, then the patient needs immediate
    attention. Blood pressure is the force that moves blood through our circulatory
    system. It is measured in millimeters of mercury (mmHg) and is written as two
    numbers. The first (or top) number is the systolic blood pressure which is the
    highest level one’s blood pressure reaches when one’s heart is beating. The second
    (or bottom) number is the diastolic blood pressure which is the lowest level one’s
    blood pressure reaches as one’s heart relaxes between beats. The ideal reading
    of blood pressure in a healthy human being is in the range from 120 over 80 (120/80).
    In aged people, the normal blood pressure reading is in the range from 150 over
    100 (150/100) whereas, in young people (age range in between 20 to 30 years old
    ), it is normally in the range from 120 over 70 (120/70). The blood pressure reading
    of middle-aged man is normally within the range from 150 over 100 (150/100). The
    normal blood pressure reading depends on the age and sex of the person. If the
    systolic blood pressure is more than 200 mmHg, then the patient is prone to have
    a cerebral stroke. On the other hand, if the systolic blood pressure is less than
    90 mmHg, then the patient is suffering from hypotension. SpO2 stands for peripheral
    capillary oxygen saturation, which is an estimate of the amount of oxygen in the
    blood. Sp02 is actually the percentage of oxygenated hemoglobin (hemoglobin containing
    oxygen) compared to the total amount of hemoglobin in the blood (oxygenated and
    non-oxygenated hemoglobin). For a healthy human being, the value of Sp02 ranges
    between 95-100 percent. If the value of Sp02 is less than 70 percent, then the
    patient needs immediate attention whereas if its value is below 50 percent, it
    is fatal for the patient. Fig. 6. Internet of Things (IoT) Applications Show All
    Normal body temperature varies from person to person and depends on age, activity,
    and time of day. The average normal body temperature of a healthy human being
    is generally accepted as 98.6F (37C). Different studies have shown that body temperature
    can widely vary from 97F to 99F. If a patient is having body temperature outside
    this range, then he or she needs immediate treatment. All these physiological
    signals, namely - blood pressure, heart rate, Sp02 and body temperature, acts
    as both independent or dependent variables depending on the health condition of
    the person under consideration. So taking all these above constraints into account,
    we have proposed an approach for all the fog nodes to deploy their computing power
    and make decisions using machine learning techniques. Assuming that the physiological
    signals behave as independent variables in most cases, we suggest the classification
    algorithm that can be deployed for the two-class classification problem is Naive
    Bayes Classifier. In Naive Bayes Classifier, the attributes are assumed to be
    conditionally independent for a given class label. Thus, it is the best-suited
    classification algorithm when the physiological signals behave as independent
    variables. If the physiological signals do not behave as totally independent variables,
    then we suggest deploying logistic regression as the classification algorithm.
    But there are some issues like logistic regression requires there to be little
    or no multi-collinearity among the independent variables, that is the independent
    variables should not be too highly correlated with each other. Also, logistic
    regression assumes linearity of independent variables. Other classification algorithms
    can also be used but it should be kept in mind the computational burden should
    not be too high as the computation is done in fog devices that have limited resource.
    Hence, deep neural networks are suggested not to be used for this purpose. C.
    Security of the framework using Blockchain As mentioned earlier, each of the IoT
    devices is identified by a unique ID ’IOT_XY’ and its corresponding public key
    which is denoted by PbK_IOT_XY is stored in the Blockchain. Similarly, the unique
    ID of each of the fog nodes (’F_X’) along with its public key PbK_X is stored
    in the Blockchain. In a similar manner, unique IDs used for identifying the mobile
    devices of the attendants and doctors are respectively following the format as
    ’MA_Z’ and ’MD_ZW’. Hence, the mobile device of the second doctor in the group
    of doctors linked to the first attendant is identified by ’MD 12’. The unique
    IDs of the mobile devices along with the public keys are stored in the Blockchain.
    As Blockchain is an immutable ledger, thus the IDs and their corresponding public
    keys cannot be tampered. So, when data packets from the IoT devices are digitally
    signed and sent to the fog devices, the fog devices can easily check the authenticity
    of the digital signature by accessing the public key corresponding to the IoT
    device, from the Blockchain. Similarly, when the message is being sent by the
    fog nodes to the mobile devices of the attendant or from the mobile device of
    the attendant to the doctor’s mobile device, they can also check for authenticity.
    Also, the Blockchain stores a copy of the mapping of the attendants to the doctors.
    As, the attendants or doctors do not leave the job at the hospitals frequently,
    so the Blockchain need not be modified frequently. SECTION IV. Security Analysis
    Using Blockchain Blockchain is an upcoming technology which is finding its use
    in many new domains. One such domain is IOT security. A. Authorization The unique
    ID of IoT devices, fog devices and mobile devices that are authorized by the hospital
    authority will only be stored in the Blockchain. As Blockchain is immutable, hence
    it is not possible for a foreign entity to modify the list of authorized devices.
    Thus, unauthorized devices if any can easily be detected. B. Authentication Every
    time a data packet from the IoT device is received by the fog device, it is checked
    for authenticity. Each of the data packets is digitally signed by using the private
    key of the IoT devices. Hence the authenticity can be validated by using the public
    key of the same. C. Non-repudiation Non-repudiation means that the signer cannot
    successfully claim they did not sign a message, whereas conjointly claiming that
    the secrecy of their private key remains intact. As we are using digital signature
    in our proposed approach, non-repudiation is ensured. D. Integrity All the data
    packets and messages that are sent from one device to another in our proposed
    framework, are digitally signed. The digital signature can provide data/message
    integrity. Generally, digital signatures include a hashing algorithm. The verification
    procedure includes proof that the correct hash over the data was signed by the
    sender. SECTION V. Conclusion The framework proposed by us ensure better and secure
    monitoring of the critical patients in the ICU. The framework not only aids the
    patients or the doctors but also the attendants present in the ICU. The real-time
    data about the physiological signals of the patients are collected by the IoT
    devices and send to the fog nodes for further processing. In the fog nodes, different
    machine learning techniques are implemented to decide whether the patient in observation
    requires immediate attention from the attendant. If the answer is positive, then
    the attendant is informed. The attendant after attending the patient informs the
    concerned doctor if it is necessary. The security of this whole system is provided
    using Blockchain. The drawback of the framework is the assumption that each patient
    is treated by only one doctor which may not be the case in real life. Also, the
    framework is yet to be implemented and experiments on this idea also need to be
    developed. Authors Figures References Citations Keywords Metrics More Like This
    Internet of Things for In-Home Health Monitoring Systems: Current Advances, Challenges
    and Future Directions IEEE Journal on Selected Areas in Communications Published:
    2021 Health Monitoring in Smart Homes Utilizing Internet of Things 2019 IEEE/ACM
    International Conference on Connected Health: Applications, Systems and Engineering
    Technologies (CHASE) Published: 2019 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: A Secure IoT-Fog Enabled Smart Decision Making system using Machine Learning
    for Intensive Care unit
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/bs.adcom.2019.09.003
  analysis: '>'
  authors:
  - J. Pushpa
  - S Kalyani
  citation_count: 9
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full volume
    Outline Abstract Keywords 1. Introduction 2. Illustrating the epoch-making IoT
    journey 3. The use cases of fog/edge computing 4. Fog and edge computing on digital
    twin 5. Facets of digital twin 6. Collaboration with fog computing 7. Collaboration
    with edge computing 8. Use cases of digital twin collaboration with fog 9. Benefits
    10. Conclusion References Further reading Vitae Show full outline Cited by (12)
    Figures (13) Show 7 more figures Advances in Computers Volume 117, Issue 1, 2020,
    Pages 51-77 Chapter Three - Using fog computing/edge computing to leverage Digital
    Twin Author links open overlay panel J. Pushpa a, S.A. Kalyani b Show more Add
    to Mendeley Share Cite https://doi.org/10.1016/bs.adcom.2019.09.003 Get rights
    and content Abstract Recreating a real-world entity as a virtual object has already
    been studied in most of the field, but making the cloned object more intelligent
    and healer of real-time physical object will give a new vision on technology.
    Digital Twin is fitting into the above statement. It uses a combination of machine
    learning, artificial intelligence, the IoT, and big data to evolve as a ubiquitous
    solution for all kinds of issues. Digital Twin can build on many form based on
    the requirement which is basically designed to resolve the challenges of the real
    world entity. Digital Twin is not limited to solving issues with standalone systems,
    single entities and machinery problems; it is also suitable for all kinds of data
    management and controlling issues. Digital Twin can extend its reach by embedding
    with edge or fog computing which can reduce connectivity and latency issues in
    networks. In this chapter, methodologies for leveraging Digital Twin using fog/edge
    computing will be discussed along with suitable use cases, such as wind turbines,
    product management, healthcare centers, and so on. We also discuss the financial
    benefits, tangible benefits, and connectivity model. Previous chapter in volume
    Next chapter in volume Keywords Financial benefitTangible benefitsConnectivity
    modelProduct managementDigital twinGatewayLoad balancerPropellerProjectionAnalyzer
    Download : Download high-res image (420KB) Download : Download full-size image
    Visualizing a digital twin. 1. Introduction Digital Twin is a facet of the Internet
    of Things (IoT) which has emerged in response to new requirements in industries
    and as a step toward a new digital world. Digital Twin can be defined as a virtual
    device or monitoring device of a physical entity which can be adopted by all factors
    in the world. Between 2002 and 2020, many blogs, articles, and research papers
    studied the concept of digital twin to understand its potentiality and applicability.
    Most cloud vendors are looking forward the cloud based service to digital twin
    which gives the facilities to share resources, reuse existing components, and
    create data-centric systems. The world is moving toward digitization where data
    transmission is high between users and connected devices, and also many coordination
    device are increasing as end devices increases. Completing all those requests
    using computing devices requires high bandwidth and channels, and also a modulator
    to boost the signal if it approaches the cloud. Cloud computing provides different
    services such as IaaS, SaaS, and NaaS which can be applied to many industrial
    settings to facilitate the new technology. With the emergence of new trends and
    technologies in recent years, cloud computing and the Internet of Things are some
    of the widely used technologies of today. We have seen tremendous growth in the
    number of IoT devices and dependencies on these devices. The ever-increasing growing
    increase in the number of IoT devices in the industry has led to a huge data deluge.
    These massive amounts of data coming from IoT devices which are at the edge of
    the networks need to be processed. For this, huge amounts of data need to be transferred
    to and from the data centers or the cloud over the network, pushing network bandwidth
    to the limit. Despite improvements in network technology, data centers cannot
    guarantee acceptable transfer rates and response times which may be critical for
    applications. Though the cloud provides different services, the cost is also increased
    in terms of delay, accessibility, and throughput, due to distance, approach ability
    and its heavy resources. Digital Twin is a technique commonly implemented on IoT
    devices which are mostly defined in confined region and are low power devices.
    Hence cloud computing is not an appropriate solution for those devices. Real-time
    data processing, easy access, high throughput, low latency, and quick analysis
    are some of the prime parameters in digital twin and also for real-time devices.
    Edge computing may be the solution for it. The digital twin framework not only
    contains the components of physical entity but also integrates with current technology
    to project the possible cases. Edge computing is a cloud technology which is locally
    available in the HAN and PAN which is evolved to achieve prime parameters of networks
    for real-time systems. In other words, all the processing can be performed at
    a location which is physically closer to the data source itself, thus leveraging
    bandwidth, speed, maintenance, automation, etc. In order to achieve this, we need
    a faster, cheaper, and smarter approach than the traditional approach which typically
    gathers and then sends data through networks to the cloud or other environments
    for processing. The edge computing platform provides some capabilities to edge
    devices which reduce the traffic toward the cloud which in turn reduces the numbers
    of coordinators and modulators in the network. Edge computing consists of the
    idea of pushing the computational services or functionalities either completely
    or partially to the edge of the network is Edge Computing. This chapter discusses
    edge computing for digital twin, and also fog computing which increases the efficiency
    and response to edge devices. Fog computing and edge computing are used interchangeably
    in cloud environments; they look similar but operate differently. Fog computing
    is also a cloud technology in the local area network (LAN) which acts like an
    intermediate layer between edge devices and cloud devices. As discussed by the
    pod group from IoT for all [1], fog computing is a mini cloud within a LAN which
    builds a data center-like cloud to service the multiple connected nodes in an
    intra-network. Download : Download high-res image (261KB) Download : Download
    full-size image Manifestation. In an oracle document [2] regarding the attribute
    of physical model is mentioned such as name, location, sensor, observed and desired
    attributes. It is also important to consider other attributes of links such as
    rate of data transfer, data format, and standards; technology integration techniques
    should also be specified. This chapter discusses the characteristics of fog and
    edge computing along with their services on digital twin, and the comparative
    studies that identify the benefits of each. We also study a few of the use cases
    of digital twin and some of the fields within which it can be evolved. 2. Illustrating
    the epoch-making IoT journey The mesmerizing number of smart sensors and actuators
    being deployed in specific environments ultimately produces massive volumes of
    data. Currently, the collected data is faithfully transmitted over the internet
    or any private network to faraway cloud infrastructures in order to be concertedly
    and calculatedly crunched to extract exceptional insights. Clouds are widely considered
    to be the best bet for doing batch or historical processing through the renowned
    Hadoop framework so cloud-based analytics is the overwhelming practice. However,
    the emerging trend is to come with micro-scale clouds in between the ground-level
    sensors and the cyber-level cloud applications toward fog analytics. This specialized
    cloud, which is being formed out of networked and resource-intensive devices in
    that environment, removes the constricting stress on the traditional clouds. The
    proximate processing gets accomplished through these micro-clouds while the device
    data security and privacy are maintained. This kind of cloud-in-the-middle approach
    is capable of unearthing fresh IoT use cases. As any micro-cloud is very near
    the data-emitting sensors and sensor-attached assets, faster and cost-efficient
    processing and responses are being achieved. 2.1. It is all about the extreme
    and deeper connectivity As the inventive paradigm of networked embedded devices
    expands into multiple business domains and industry verticals such as manufacturing
    facilities and floors, healthcare centers, retail stores, luxury hotels, spacious
    homes, energy grids, and transportation systems, there is a greater scope for
    deriving sophisticated applications not only for businesses but also for individual
    consumers. The world is becoming more and more connected. Recent devices include
    as standard connectivity features, and there is a wide range of a vast number
    of hitherto unconnected legacy devices. Furthermore, there is a wide range of
    resource-constrained devices ranging from heart rate monitors to temperature and
    humidity sensors, and enabling these to be integrated with other devices and web
    applications is a significant challenge. Thus, connectivity solutions and platforms
    are being brought in to enable every tangible device to be connected. Connectivity
    is required not only with adjacent devices in the vicinity but also with remotely
    held applications and data sources on the web/cloud. 2.2. The enormous volumes
    of IoT data We have been investigating transaction systems extensively. IT infrastructures,
    platforms, and applications are designed to be appropriate for streamlining and
    speeding up transactions. However, with the faster penetration of devices and
    digitized entities, there is a relook. That is, operational systems are becoming
    more prevalent and prominent. In the impending IoT era, a sensor or smart device
    that is monitoring temperature, humidity, vibration, accelerations or numerous
    other variables could potentially generate data that need to be handled by back-end
    systems in some way every millisecond. For example, a typical Formula One car
    carries 150–300 sensors, and more controllers, sensors, and actuators are being
    continuously incorporated to achieve more automation. Today, all these sensors
    already capture data in milliseconds. Racecars generate 100–200 KB of data per
    second, amounting to several terabytes in a racing season. There are twin challenges
    for back-end systems. Storage concerns and real-time processing of data are equally
    important. Missing a few seconds of sensor data, or being unable to analyze it
    efficiently and rapidly, can lead to risks and, in some cases, to disasters. 2.3.
    Major IoT data types There are three major data types that will be common to most
    IoT projects: Measurement data: Sensors monitor and measure the various parameters
    of the environment as well as the states of physical, mechanical, electrical,
    and electronics systems. Heterogeneous and multiple sensors read and transmit
    data very frequently; therefore, with a larger number of sensors and frequent
    readings, the total data size is bound to grow exponentially. This is the crux
    of the IoT era. A particular company in the oil and gas industry is already dealing
    with more than 100 TB of such data per day. Event data: Any status change, any
    break-in of the threshold value, any noteworthy incident or untoward accident,
    and any decision-enabling data are simply categorized as event data. With devices
    assisting people in their daily assignments and engagements, the number of these
    events is likely to shoot up. We have powerful simple and complex event processing
    engines in order to discover and disseminate knowledge out of event data. Interaction
    and transaction data: With the extreme and deeper connectivity among devices,
    the quality and quantity of purpose-specific interactions between devices are
    going to be greater. Several devices with unique functionality can connect and
    collaborate to achieve composite functions. Transaction operations are also enabled
    in devices. Not only inter-device communication but also human-device communication
    is fairly happening. Diagnostics data: The delectable advancements in the IoT
    domain have led to millions of networked embedded devices and smart objects, and
    information, transactional, analytical, and operational systems. There are online,
    off-premise, and on-demand applications, data sources, and services in plenty.
    The application portfolio is consistently on the rise for worldwide enterprises.
    There are software infrastructure solutions, middleware, databases, data virtualization
    and knowledge visualization platforms, and scores of automation tools. The health
    of each of these systems is very important for the success of any business transaction.
    Diagnostics data provide an insight into the overall health of a machine, system,
    or process. The data might show not only the overall health of a system but also
    whether the monitoring of that system is working effectively. Precisely speaking,
    IoT data are going to be big and we have techniques and platforms for big data
    processing. However, the intriguing challenge is to do real-time processing of
    IoT big data. Researchers are working to unearth path-breaking algorithms to extract
    timely insights out of big data. Fog computing is one such concept prescribed
    as a viable and venerable answer for the impending data-driven challenges. The
    IoT is turning out to be a primary enabler of the digital transformation of any
    kind of enterprising businesses. Companies are eagerly looking toward pioneering
    digital technologies to create and sustain their business competitiveness. The
    IoT and other digital technologies are helping companies to facilitate process
    enhancement, create newer business models, optimize the IT infrastructures, bring
    forth competent architectures, empower workforce efficiency and innovation, etc.
    The IoT closes the gap between the physical and cyber worlds, and helps to connect
    physical and digital environments. Data collected from connected devices are subjected
    to a variety of investigations to extract reliable insights. 3. The use cases
    of fog/edge computing The rapid growth of personal, social, and professional devices
    in our daily environments has seeded this inimitable computing style. Communication
    becomes wireless, sensors and devices are heterogeneous and large in number, geo-distribution
    becomes the new normal, interconnectivity and interactions among various participants
    emit a lot of data, etc. Massive amounts of data are being generated and gathered
    at the edges of networks. Usually, these data are transported back to the cloud
    for storage and processing, which requires high bandwidth connectivity. In order
    to save network bandwidth, there is a valid proposition of using a moderately
    sized platform in between to do a kind of pre-processing in order to filter out
    the flabs. Differently enabled cameras, for example, generate images and videos
    that would aggregate easily in the range of terabytes. Instead of clogging expensive
    and scarce network bandwidths, a kind of fog/edge processing can be initiated
    to ease networks. That is, reasonably powerful devices in the environment that
    is being monitored can be individually or collectively leveraged to process cameras-emitted
    files in real-time. That is, the data gleaned can be subsequently segmented and
    shared to different nearby devices in order to do the distributed processing quickly.
    With more devices being added to mainstream computing and the amount of data getting
    stocked is growing exponentially, the distributed computing concept has soared
    in the recent past and is being touted as the best way forward for the data-centric
    world. There are a number of convincing use cases for fog/edge computing. Fog
    devices locally collect, cleanse, store, process, and even analyze data in order
    to facilitate real-time analytics and informed decisions. Research papers describe
    how connected vehicles, smart grids, wireless sensor and actuator networks, etc.
    are more appropriate and relevant for people with the fast-moving fog computing
    paradigm. Smart building, manufacturing floors, smart traffic and retail, and
    smart cities are some of the often-cited domains wherein the raging fog idea chips
    in with real benefits. Augmented reality (AR), content delivery, and mobile data
    analytics are also very well documented as direct beneficiaries of fog computing.
    One use case for fog computing is a smart traffic light system, which can change
    its signals based on surveillance of incoming traffic to prevent accidents or
    reduce congestion. Data could also be sent to the cloud for longer-term analytics.
    Other use cases include: rail safety; power restoration from a smart grid network;
    and cybersecurity. There are connected cars (for vehicle-to-vehicle and vehicle-to-cloud
    communication), and smart city applications include intelligent lighting and smart
    parking meters. 3.1. Smart homes A home security application is discussed in depth
    in a research paper. There is a myriad of home security products (smart locks,
    video/audio recorders, security sensors and monitors, alarms, presence, occupancy,
    and motion sensors, etc.). These are standalone solutions and due to disparate
    data transport protocols and data formats, these products do not interoperate
    with one another. However, fog computing has simplified the process of dynamically
    integrating these diverse security products in order to enhance the timeliness
    and trustworthiness of any security information. Fog computing platform is unique
    in that it can be flexibly deployed on a virtual machine or in a Docker container.
    Existing and new sensors and actuators are registered and connected with the fog
    platform, which ensures a seamless and spontaneous interoperation between different
    and distributed devices and machines to achieve the goal. This ad hoc collaboration
    capability senses any kinds of security threats and immediately stimulates the
    necessary countermeasures through connected actuators. Energy management, device
    clustering and coordination, ambient assisted living (AAL), activity recognition/context-awareness
    for formulating and firming up people-centric services, etc. are getting streamlined
    with the fog computing nuances. 3.2. Smart grids A smart electric grid is an electricity
    distribution network with smart meters deployed at various locations to measure
    the real-time power consumption level. A centrally hosted SCADA server frequently
    gathers and analyzes status data to send out appropriate information to power
    grids so that they can adapt accordingly. If there is any palpable increment in
    power usage or any kind of emergency, this information will be instantaneously
    conveyed to the power grid for action. Employing fog computing, the centralized
    SCADA server can be supplemented by one or more decentralized microgrids. This
    salient setup improves scalability, cost-efficiency, security, and rapid response
    of the power system. This also helps to integrate distributed and different power
    generators (solar panels, wind farms, etc.) with the main power grid. Energy load-balancing
    applications may run on edge devices such as smart meters and microgrids. Based
    on energy demand, availability, and the lowest price, these devices automatically
    switch to alternative energies like solar and wind. 3.3. Smart vehicles The fog
    concept can also be extended to vehicular networks. The fog nodes can be deployed
    along the roadside, and send and receive information to and from vehicles. Vehicles
    through their in-vehicle infotainment systems can interact with the roadside fog
    systems as well as with other vehicles on the road. Thus, this kind of ad hoc
    network leads to a variety of applications such as traffic light scheduling, congestion
    mitigation, precaution sharing, parking facility management, traffic information
    sharing, etc. A video camera that senses an ambulance''s flashing lights can automatically
    change streetlights to open lanes for this vehicle to pass through traffic. Smart
    streetlights interact locally with sensors and detect the presence of pedestrians
    and bikers, and measure the distances and speeds of approaching vehicles. 3.4.
    Smarter security Security and surveillance cameras are being fitted in different
    important junctions such as airports, nuclear installations, government offices,
    retail stores, etc. Furthermore, nowadays smartphones are embedded with powerful
    cameras to take selfies as well as produce photos of others. Still, as well as
    running images can be captured and communicated to nearby fog nodes as well as
    to faraway cloud nodes in order to readily process the photos and compare them
    with the face images of radicals, extremists, fundamentalists, terrorists, arsonists,
    trouble-makers, etc., in the already stored databases. Furthermore, through image
    processing and analytics, it is possible to extract useful information in the
    form of unusual gestures, movements, etc. All these data empower security and
    police officials to proceed in their investigations with clarity and confidence.
    Fig. 3 pictorially conveys how the fog cloud facilitates real-time sensor data
    processing and historical sensor data processing at nearby or faraway clouds (public,
    private, and hybrid) (Fig. 1). Download : Download high-res image (361KB) Download
    : Download full-size image Fig. 1. The fog ensures zero latency toward real-time
    applications. 3.5. Smart buildings Like homes, office and corporate buildings
    are stuffed with a number of sensors for minute monitoring, precise measurement,
    and management. There is a school of thought that multiple sensor values, when
    blended, generate more accurate data. There are advanced sensor data fusion algorithms,
    and hence smart sensors and actuators work in tandem to automate and accelerate
    several manual tasks. For providing a seamless and smart experience to employees
    and visitors, the building automation domain is on a fast trajectory with a series
    of innovations and improvisations in the IT space. That is, computing becomes
    pervasive, communication is ambient, sensing is ubiquitous, actuation is intelligently
    accomplished, etc. The computer vision and perception topics are gathering momentum,
    knowledge engineering and enhancement are becoming common and cheap, and decision-enablement
    is gradually being perfected. The edge devices participating in and contributing
    to the edge cloud facilitate multiple things intelligently so that the strategic
    goal of building automation through networking and integration may be accomplished.
    Traditional approach: Manual operation Today, a medium-sized office building could
    have hundreds of sensors on its equipment. A great example is chillers, a product
    needed to cool a building. The product manufacturer (http://www.johnsoncontrols.com)
    monitors chillers remotely using predictive diagnostics to identify and solve
    issues before they become problems. The company uses internal operational data
    and historical records to plan machine maintenance more effectively, leading to
    better operational efficiency and decreasing energy usage, in addition to increasing
    reliability and equipment life span. Even better, the company has external data
    resources like weather patterns and grid demand costs to drive greater operational
    savings. Download : Download high-res image (224KB) Download : Download full-size
    image Chiller product. There are several other industry verticals and business
    domains keen to gain immense benefits from the decisive and impressive advancements
    in the field of fog computing. 4. Fog and edge computing on digital twin In many
    sectors like business, IT, industries, and also in power management wants foster
    collaboration for making any critical decision toward the progress. Cloud services,
    artificial intelligence (AI), and machine learning have been introduced by technical
    workers to integrate technologies and satisfy their requirements. When smart devices
    are introduced into the market to make something easy and connect anything anywhere,
    then the requirements toward technology increase in terms of performance, real-time
    response, and resilience and fault tolerance. Hence, to achieve these parameters,
    a new concept is evolved according to the basic “divide and conquer” approach.
    As we discussed in Section 1, cloud computing provides centralized architecture
    and satisfies the above requirements, but some of the limitations such as round-trip
    time and heavy resources to approach cloud center such as bandwidth, gateways
    modulator require more which increase cost. To overcome these limitations, fog
    and edge computing were developed. As shown in Fig. 2, fog computing looks like
    cloud computing near smart devices, which are also known as IoT devices, and edge
    computing looks as if the cloud is integrated to those edge devices. Download
    : Download high-res image (258KB) Download : Download full-size image Fig. 2.
    Bandwidth utilization. The diagram shows that he number of gateways is greater
    between IoT devices and the cloud, and the link represents the bandwidths (green
    = high bandwidth, black = medium bandwidth, and yellow = low bandwidth) required
    for data transmission, which are also high. This concludes that if the distance
    between the devices for data transmission is less than better to choose fog/edge
    computing. 4.1. Fog computing Fog computing is a distributed architecture which
    can provide services such as computing, storage, communication, and many others
    like cloud center. These resources are available near IoT/Arduino/edge devices.
    Fog computing overcomes the limitations of cloud computing, which are as follows.
    4.1.1. Limitations of cloud computing 1. Response time delay. 2. Bandwidth utilization.
    3. Connectivity. 4. Security. Fog computing addresses these challenges by placing
    the required services near the edge device. As discussed by Bonomi [3], fog computing
    is a virtualized cloud center which collaborates with and distributes its service
    to any new technology or a standards to make the connectivity stronger and quicker.
    Some of the characteristics of fog computing are as follows: • Supports mobility.
    • Scalability by using grid topology. • Performance with better response time.
    • Heterogeneity by supporting different devices. The above-discussed features
    facilitate agility, proactiveness, and logistical data for artificial or machine
    learning devices. The digital twin of any entity require enormous amounts of data,
    both historical and current, to predict and analyze the future consequences. Hence
    the internet and connectivity also play major roles in digital twin, and incorporating
    fog in digital twin makes the process robust. 4.2. Edge computing Edge computing
    is a technology which enables data analyzing, storage, and utilization in edge
    devices. It allows collecting, aggregating, and communicating of the data along
    with providing intelligent logistics to give optimal solutions. Edge computing
    is a form of cloud computing and is also called micro-cloud services, which are
    integrated in edge devices. A glance around at any devices used will find that
    they are are smart, quick, and robust, such as Google Home, Smart Home, smart
    home appliances, drones, Amazon Dash buttons, and many more. A research group
    estimated that the drastic growth of these smart devices may reach around 75.44
    billion by 2025. One of the backbone technologies is edge computing; it is a gateway
    between edge devices to connect to the internet with minor latency which is suitable
    for real-time applications. Edge computing is capable of managing applications,
    providing security, connectivity, and also scalability. It involves not only the
    software components but also hardware which interacts with the user and makes
    faster decisions. Some of the vendors for edge computing [4] in markets are: 1.
    FUJITSU IoT Solution: provides edge computing to bridge the gap between operational
    and tradition devices in an industrial context. 2. FogHorn: provides edge computing
    for IoT. 3. Saguna: provides a multiple-access edge cloud. 4. ClearBlade: orchestrates
    multiple layer and edge computing devices. Many more, including Google, Cisco,
    and Microsoft, are providing edge gateways and analytics. The role of edge computing
    is vital on digital twin, as it: • provides application logic to the components
    in a model; • filters the streaming data before reaching the destination; • provides
    diversified data to the components; • enables synchronization between devices
    or components; • maintains the statistical information of devices; • offers an
    easy access point; and • enables peer-to-peer connectivity through mesh topology.
    5. Facets of digital twin Digital twin is a virtual representation of physical
    devices used in most IoT devices to build and engineer with a defect-proof model.
    Technically it is a concept to simulate each and every dynamical movement of data
    from electrons to elements. It not only simulates but also gives status and condition
    according to the load and age of the model. Hence collaboration of digital devices
    with edge/fog computing with artificial intelligence makes models robust and perfect.
    So the facet of digital twin is not only the simulated model but also dynamic
    model. Hence, it is a device that serves the following purposes, among many others:
    • prediction • analysis • simulation • projection • demonstration • collaboration
    (Fig. 3). Download : Download high-res image (259KB) Download : Download full-size
    image Fig. 3. Facets of digital twin. (a) Prediction: Digital twin is a model
    which can take a data set of different patterns from machine data and experiment
    with data fusion to predict the possibilities. (b) Analysis: Analyzing the gathered
    data from all the relevant component through any of the data science techniques
    can give an appropriate input to predict. (c) Simulation: Digital twin is not
    just a simulator to simulate the system, but also provides ideas about upcoming
    challenges and adopts the new properties to rebuild the model. (d) Projection:
    Projection is basically used as a business process to integrate the requirements
    and identify a solution if one is needed. (e) Collaboration: Digital twin can
    collaborate with any technologies to bridge the gap between past and future. It
    can integrate with cloud/fog/edge or any AI to improve the efficiency. (f) Demonstration:
    A sample model can be demonstrated and the available data experimented with for
    refinement. Fig. 4 visualizes the collaboration feature of digital twin. Download
    : Download high-res image (79KB) Download : Download full-size image Fig. 4. Digital
    twin collaboration. Those properties of digital twin prove that it can integrate
    with any standards and technology to build a fault-proof model. 6. Collaboration
    with fog computing Digital twin is an extended feature of the IoT which provides
    deeper insights into any model to automate and re-engineer it to fix the bugs
    and make it agile. Further to the discussion of fog computing and its capabilities,
    we shall now consider the scope of collaboration of fog computing with digital
    twin by discussing the step to build digital twin. The role of fog computing bridges
    the gap between digital twin and the internet. Step 1: Construct the simulation
    model of physical model components. Step 2: Store all the training data between
    components. (Storage) Step 3: Sense all the external factor impacts on the model.
    (Connectivity with low latency) Step 4: Compute the logic (algorithms) for all
    “if else” statements. (Computing power) Step 5: Identify the point of failure
    and rebind quickly. (Server/traditional structure) Step 6: Provide for scalability
    through integration or coupling. (Standards) Step 7: Finally, resultant value
    impacts on markets. (Global view) Download : Download high-res image (304KB) Download
    : Download full-size image In the above-discussed steps, the highlighted parameters
    are the external components or the facilities required by digital twin. Fog computing
    not only provides the cloud services such as computing, storage, and infrastructure
    but also concentrates on performance and response time, which are prime factors
    in real-time application. As discussed in “A Fog Computing and Cloudlet Based
    Augmented Reality System for the Industry 4.0 Shipyard” [5], fog computing addresses
    the challenges such as transmission delay and network traffic latency, which are
    high in cloud and progressively less in fog computing. 7. Collaboration with edge
    computing 7.1. Edge computing Edge computing is a distributed computing paradigm
    which brings data storage and computation or processing closer to the location
    where it is needed to improve response times and save bandwidth. By pushing computation
    to the edge of the network, it is possible to analyze data in real-time which
    is crucial in industries such as manufacturing, healthcare, telecommunication,
    finance, etc. Edge computing is a mesh network of micro-data centers that process
    or store critical data locally and push all the received data to central data
    centers or cloud storage repositories (Fig. 5). Download : Download high-res image
    (344KB) Download : Download full-size image Fig. 5. (Top) Cloud computing and
    (bottom) edge computing. An ideal situation for edge computing deployment would
    be in circumstances where IoT devices have poor network connectivity and also
    as it is not very efficient for IoT devices to be always connected to the cloud.
    Edge computing can be used in areas such as financial services and manufacturing,
    which are sensitive to latency. Latency of even milliseconds in processing of
    information may be untenable for such applications. Edge computing reduces latency
    as data need not be transferred to the cloud or data center over the network for
    processing. The aim of edge computing is to push computation to the edge of the
    network away from data centers, exploiting the capabilities of smart objects,
    cell phones, and network gateways to provide services and processing on behalf
    of the cloud. An example of edge computing deployment would be an oil rig in the
    ocean that has many sensors generating massive amounts of data which perhaps confirm
    the proper functioning of the rig. However, most of the data generated by those
    sensors may be inconsequential and hence do not have to be sent across the network
    as soon as the data are produced. Thus, the local data computing system compiles
    the data and generates daily reports, and sends the data to the cloud or a central
    data center for storage, thus sending only important data and minimizing the amount
    of data transferred across the network, saving network bandwidth and also reducing
    latency. Another example which explains the benefits of edge computing is the
    usage of web browsers by internet users. Thousands of people are connected to
    the internet at any given point of time. One of the most widely used applications
    by these users is the web browser. Browsers are used to watch videos, for research,
    etc., and are operating on more and more devices such as cell phones, set-top
    boxes, and stick PCs. The usability and display speed of the web browser depends
    upon the performance of the device. If the device does not perform very efficiently,
    the latency increases which can be very stressful for the user. Edge computing
    can be deployed in order to overcome the latency thus created. An edge server
    can be placed between the cloud and physically closer to the user. The Nippon
    Telegraph and Telephone Public Corporation (NTT) has developed the NTT web browser
    which can offload part of the workload of the devices to the edge servers. The
    processing is done by the edge servers, freeing the device of the task, thus reducing
    latency. The content is displayed at a much faster rate than through a standard
    web browser. Edge computing dates back to the 1990s and is still considered a
    new paradigm, despite its age. Edge is a new buzzword which simply means processing
    and analyzing data along the edge of a network, nearer to the point of data collection,
    so that data become actionable. The objective of edge computing is to solve the
    proximity problem, thus solving the latency problem. Since edge computing does
    not depend only on the cloud for processing, outage reduction and intermittent
    connectivity can be improved. In addition, by ensuring reliable operations in
    remote locations, unplanned downtime as well as server downtime can be avoided.
    7.2. Collaboration We can maximize the benefits of edge computing by combining
    it with other technologies. One such collaboration by which businesses can derive
    advantage involves combining it with Digital Twin technology. Edge computing has
    the potential to minimize risk in real-time whereas Digital Twin can predict future
    events accurately, which can benefit businesses to a great extent [6]. Digital
    Twin is a virtual or digitized model of a service, product, or a process or any
    IoT. More than one digital twin can be developed for any particular object based
    on its industrial context. It is a virtual representation of the components and
    dynamics of the real-world entity which facilitates operations of the product
    as well. Processing can be simulated using digital twin which can accurately predict
    the product''s behavior under different conditions such as weather changes or
    as the product ages. This will help in making required changes in the product
    and making it a better one [5]. Digital Twin provide significant advantages in
    a cloud-based environment. What if we deployed a digital twin along the edge of
    a network? Edge-deployed Digital Twin gives way to new autonomous systems—real-time
    artificial intelligent systems based on self-learning. By developing a virtual
    model of the physical asset, greater flexibility can be achieved to define, evolve,
    build, and leverage twins for real-time IoT. Digital Twin resides in and is maintained
    in the cloud, fed with data from its environment through devices, sensors, or
    simulations. Digital twins are used to understand past and present operations,
    and to predict future events by leveraging with machine learning approaches to
    build a better system by detecting anomalies and forecasting failures. Edge computing
    provides advanced processing and cloud-based analytics that enable faster and
    localized decision making at the edge [1]. Deploying the digital twin at the edge
    will make it possible to build smarter applications. Moving the digital twin to
    the edge of the network facilitates smarter applications for the following reasons:
    • Reduction in latency: In a cloud-based digital twin, the delay caused by cloud
    access is not acceptable. Edge-deployed digital twin reduces the latency, and
    applications that require sub-second latencies can be derived. • Analytics generated
    by the digital twin can guide local control and vice versa. An anomaly that could
    cause a problem in future can be fixed without human intervention. • Using machine
    learning approach on streaming data, digital twin can evolve much faster and acquire
    the ability to self-learn. • Edge computing technology implements decentralization
    of data, and distribution in the network; therefore, it will not be possible for
    hackers to corrupt data. In addition, transfer of sensitive information over networks
    will be minimized and thus data security will be enhanced. Data encoding and implementing
    virtual private networks become have very important with the growth of edge computing
    technology [3]. • Edge computing also facilitates scaling of IoT networks much
    faster and as required [1]. Edge-deployed digital twin also provides business
    benefits such as the following: − Because cloud storage and analysis can be costly.
    Edge-deployed digital twin reduces cloud hosting costs as all the data need not
    be sent to the cloud. − As the data processing is performed at the edge of the
    network, the volume of data that has to be transmitted to the cloud reduces. −
    Sensitive data need not be sent to the cloud. − Analytics can be performed even
    when the digital twin is disconnected. By merging these two emerging technologies,
    we can develop devices which can exhibit intelligence and possess immense decision-making
    capabilities without human intervention. We can create a future which we have
    never imagined before. Many systems and products combining these two technologies
    have been developed and deployed in various areas of business which impart both
    tangible and intangible benefits to the organization. The following section discusses
    some of the use cases which substantiate the above statement. 8. Use cases of
    digital twin collaboration with fog 8.1. Drones in agricultural fields A drone
    is a flying agent to perform a specific task in any given area. Some of the experience
    shared by the students in IoT lab to design the drone fails successively in building
    process due to the imbalance in propeller and after they use the digital twin
    to simulate the drone and successfully built after simulating by providing proper
    parameter. This kind of experiment takes place in many areas to reap the benefits
    of IoT devices. At the same time, many new thoughts arrive as the requirement
    increases lead to the failure of existing IoT devices to support. Hence digital
    twin bridges the gap and collaborates with the internet to provide the service
    on demand with micro-latency through fog computing. As shown in Fig. 6, Skyx''s
    developed a drone for auto-piloting in agricultural fields to manage and monitor
    crops development; this was also suitable for real-time controlling. Download
    : Download high-res image (261KB) Download : Download full-size image Fig. 6.
    Auto-piloting in agricultural fields. 8.2. Automotive industry The automotive
    industry has introduced electric cars into the market in recent years. There has
    been a growing demand for these electric cars which were developed with a benevolent
    intent of saving the environment. Though these cars are currently manually driven,
    the industry is aiming to convert these manually driven cars to self-driven bots.
    Edge computing and simulation technologies can help bridge the gap and make self-driven
    cars a reality [6]. In cloud-based technology, data processing and storage are
    done remotely, whereas in edge computing, data are processed at a location which
    is in close physical proximity to the data source, facilitating transfer of data
    at a faster rate. Using this technology, cars could make decisions such as when
    to apply a brake, start driving, make turns, increase speed, etc. much faster
    [6]. By combining this with digital twin technology and simulation, future events
    can be predicted which can help the vehicles to navigate better and avoid collisions
    by making appropriate decisions whenever the need arises. Download : Download
    high-res image (169KB) Download : Download full-size image Self-driven car. By
    enhancing and implementing this technology in the automotive industry, development
    costs can be reduced, efficiency improved, and sustainability can be enhanced
    by automobile manufacturers. 8.3. Windmills Consider the hypothetical situation
    of a windmill where a hierarchy of digital twins can be used. In this example,
    the digital twins are organized in a hierarchy where the low-level digital twin
    represents individual components and the higher-level digital twin represents
    subsystems which control these devices. Twins at various levels send the messages
    downward to the lower levels for controlling, as a result of which signals are
    generated that will in turn be sent to the devices. The application logic has
    to be divided between the cloud and the edge. Digital twins enable to successfully
    migrate low-level event handling operations to the edge and higher-level digital
    twins can operate in the cloud or wherever the computing resources are located
    (Fig. 7). Download : Download high-res image (217KB) Download : Download full-size
    image Fig. 7. Windmill. The use of digital twin technology does not require all
    device-specific operations to be migrated to the edge of the network. Instead,
    the low-level twin can the functionalities of the device directly, and the high-level
    twin implements a machine learning approach and performs predictive analytics
    based on data received by the low-level twin. Thus, it is a good idea to move
    the low-level twin to the edge and hence reduced response time and processing
    can be achieved without any interruption. The high-level twin can reside wherever
    the computing resources are located or in the cloud for the predictive analytics
    algorithm to be executed [2]. 8.4. Workplaces The workplace environment can be
    checked in real-time by deploying edge computing with digital twin technology.
    By creating virtual representations of buildings and office spaces and integrating
    these with edge computing, the environment can be monitored in real-time, potential
    risks and dangers can be avoided, and suitable measures can be taken to avoid
    accidents and disasters. A few use cases were discussed in the above section,
    but this is not all. Although edge computing and Digital Twin technology are being
    implemented extensively in various sectors of business and industry, the combination
    of these technologies is also being deployed in today''s business which can provide
    real-time, intelligent solutions for organizations. We are heading toward a future
    which we have never experienced before. 9. Benefits Collective data analysis to
    compare the performance on digital twin between cloud, fog, and edge computing
    was carried out with a list of parameters including: • speed • bandwidth • response
    time • latency • throughput. As shown in Fig. 8, drastic improvement in edge computing
    with respect to the above-listed network parameters signifies the integration
    of digital twin with fog/edge computing. Download : Download high-res image (53KB)
    Download : Download full-size image Fig. 8. Response time. 10. Conclusion Digital
    twin technology empowers edge/fog devices to be intelligent in their actions and
    reactions. As the future beckons for edge/fog clouds for realizing and running
    real-time and insight-driven applications and services, the role and responsibility
    of having and using digital twins for all the participating physical twins are
    bound to become more significant. Furthermore, the analytical capabilities of
    both physical and digital twins are useful in making edge/fog devices (physical
    twins) adaptive, adjustive, and autonomous. This chapter focused on describing
    how the digital representation of edge devices is ultimately helping to empower
    them to be intelligent in decisions, deals, and deeds. References [1] https://www.iotforall.com/fog-vs-edge-computing-do-differences-matter/
    Google Scholar [2] https://docs.oracle.com/en/cloud/paas/iot-cloud/iotgs/iot-digital-twin-framework.html
    Google Scholar [3] F. Bonomi, R. Milito, J. Zhu, Sateesh Addepalli Cisco Systems
    Inc Fog Computing and Its Role in the Internet of Things (2012) 170 W Tasman Dr.
    San Jose, CA 95134, USA Google Scholar [4] https://www.zdnet.com/article/10-edge-computing-vendors-to-watch
    Google Scholar [5] https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6022113/ Google
    Scholar [6] https://www.electronicdesign.com/communications/understanding-wireless-routing-iot-networks
    Google Scholar Further reading [7] https://www.forbes.com/sites/ralphjennings/2019/08/15/taiwan-will-easily-overcome-chinas-ban-on-82000-tourists-per-month/#6a208ec55781
    [8] https://cloudblogs.microsoft.com/industry-blog/manufacturing/2018/08/20/the-cloud-enables-next-generation-digital-twin/
    [9] https://agfundernews.com/skyx-crop-spraying-drone-raises-seed.html [10] K.M.
    Alam, M. Saini, A. El Saddik, et al. IEEE Access, 3 (2015), pp. 343-357 View in
    Scopus [11] kazi Masudul Alam and Abdulmotaleb el Saddik C2PS: a digital twin
    architecture reference model for the cloud-based cyber-physical systems IEEE Access,
    5 (2017), pp. 2050-2061 Google Scholar [12] https://www.eclipse.org/ditto/intro-digitaltwins.html
    [13] https://www.logistics.dhl/content/dam/dhl/global/core/documents/pdf/glo-core-digital-twins-in-logistics.pdf
    Cited by (12) Digital twins in industry 4.0 2021, Design and Operation of Production
    Networks for Mass Personalization in the Era of Cloud Technology Show abstract
    Process Safety and Big Data 2021, Process Safety and Big Data From modeling and
    simulation to Digital Twin: evolution or revolution? 2024, Simulation Multi-Tier
    Computing-Enabled Digital Twin in 6G Networks 2023, arXiv Traditional and Blockchain
    Based IoT and IIoT Security in the Context of Agriculture: A Survey 2023, Wireless
    Personal Communications Digital Twins in the Construction Industry: A Comprehensive
    Review of Current Implementations, Enabling Technologies, and Future Directions
    2023, Sustainability (Switzerland) View all citing articles on Scopus J. Pushpa
    is a research scholar in VTU Belgaum. Her areas of specialization are software
    defined networking, edge computing, and fog computing. She has gained experience
    in the IT industry and in teaching organizations, and is currently working as
    an Assistant Professor in Jain University, Bangalore. S.A. Kalyani is serving
    as an Assistant Professor in East West College and has enormous knowledge in the
    area of artificial intelligence and working on data science. View Abstract Copyright
    © 2020 Elsevier Inc. All rights reserved. Part of volume The Digital Twin Paradigm
    for Smarter Systems and Environments: The Industry Use Cases Edited by Pethuru
    Raj, Preetha Evangeline Download full volume Recommended articles Article Metrics
    Citations Citation Indexes: 9 Captures Readers: 79 View details About ScienceDirect
    Remote access Shopping cart Advertise Contact and support Terms and conditions
    Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices
    All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply.'
  inline_citation: '>'
  journal: Advances in computers
  limitations: '>'
  pdf_link: null
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: Using fog computing/edge computing to leverage Digital Twin
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/cloudcom.2019.00027
  analysis: '>'
  authors:
  - Chikako Takasaki
  - Atsuko Takefusa
  - Hidemoto Nakada
  - Masato Oguchi
  citation_count: 5
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy IEEE.org IEEE Xplore IEEE
    SA IEEE Spectrum More Sites Donate Cart Create Account Personal Sign In Browse
    My Settings Help Access provided by: University of Nebraska - Lincoln Sign Out
    All Books Conferences Courses Journals & Magazines Standards Authors Citations
    ADVANCED SEARCH Conferences >2019 IEEE International Confe... A Study of Action
    Recognition Using Pose Data Toward Distributed Processing Over Edge and Cloud
    Publisher: IEEE Cite This PDF Chikako Takasaki; Atsuko Takefusa; Hidemoto Nakada;
    Masato Oguchi All Authors 5 Cites in Papers 145 Full Text Views Abstract Document
    Sections I. Introduction II. Background III. Machine Learning Methods Applied
    in this Study IV. Experiments V. Related Work Show Full Outline Authors Figures
    References Citations Keywords Metrics Abstract: With the development of cameras
    and sensors, and the spread of cloud computing, life logs can be acquired and
    stored in general households for various services using the logs. However, it
    is difficult to analyze moving images acquired by a home sensor in real time using
    machine learning because the data size and the computational complexity are large.
    New computing paradigm called edge computing or fog computing, which enables distributed
    computing over edge and cloud, has the possibility to address this issue. The
    feature vectors are extracted from moving images by preprocessing on the sensor
    side and the only small feature vectors are sent to the cloud and used for learning.
    But, it is not clear how accurately we can recognize actions using only the feature
    vectors in the learning and inferring. We investigate the accuracies of action
    recognition with various machine learning methods using feature vector information
    obtained from moving images. We use the pose estimation library OpenPose for detection
    of the feature vectors and recognize actions using logistic regression, random
    forest, support vector machine, and neural network (NN) models, general NN and
    LSTM, as machine learning methods. The experimental results show that it is possible
    to recognize an action with 80% accuracy or higher when using random forest and
    neural network models. We also discuss a method to further improve the accuracy
    based on the experimental results. Published in: 2019 IEEE International Conference
    on Cloud Computing Technology and Science (CloudCom) Date of Conference: 11-13
    December 2019 Date Added to IEEE Xplore: 28 January 2020 ISBN Information: Electronic
    ISSN: 2330-2186 DOI: 10.1109/CloudCom.2019.00027 Publisher: IEEE Conference Location:
    Sydney, NSW, Australia SECTION I. Introduction The development of cameras and
    sensors and the spread of cloud computing has enabled people to acquire and store
    life logs in ordinary homes. These data have been used for services such as watching
    over children, elderly people and pets and for security systems. M. Mohammadi
    et al. [1] introduced applications in various fields that analyze a large amount
    of stream data generated from Internet of Things (IoT) devices (sensors) with
    machine learning, such as smart homes, smart cities, healthcare, and agriculture.
    In addition, they stated that it is promising to use machine learning to analyze
    large scale stream data and achieve application objectives. However, it is difficult
    to analyze moving images acquired in a home sensor with machine learning in real
    time because the data size and the computational complexity of the analysis are
    large and high performance servers and storage are not installed in ordinary homes.
    Although we can use abundant computing resources in a cloud, the network bandwidth
    between the sensor and the cloud is limited, and it is very difficult to analyze
    with the processing latency expected by each application. Hence, distributed processing
    called edge computing [2] or fog computing [3], processing the part of the calculation
    on the sensor side or with the edge device near the sensor side, is effective.
    The advantage of preprocessing on the sensor side is not only the reduction of
    processing latency but also privacy protection and the reduction of communication
    costs. Collecting and accumulating moving images that can identify individuals
    taken at home in the cloud may invade the privacy of application users. In addition,
    when a mobile network is used for communication between the sensor and the cloud,
    the pay-per-use manner is generally applied according to the transfer amount.
    It is necessary to reduce the transfer data size as much as possible in order
    to reduce not only the communication latency, but also its costs. Therefore, we
    address these issues by collecting and analyzing only feature vectors in the cloud.
    The feature vectors are extracted from moving images by preprocessing on the sensor
    side and the only small feature vectors are sent to the cloud. However, since
    the amount of information contained in the original video data is also reduced
    significantly by preprocessing, it is not clear how accurately we can recognize
    actions using only the feature vectors in the learning and inferring. We investigate
    the accuracies of action recognition with various machine learning methods using
    feature vector information obtained from moving images. We use OpenPose [4] [5]
    [6] [7], a pose estimation library to extract feature vectors of key human points
    using deep learning, and employ logistic regression, random forest, support vector
    machine (SVM), and neural network models as machine learning methods. We use a
    neural network (NN) model and a long short-term memory (LSTM) model built with
    the deep learning framework Keras [8]. We perform action recognition using feature
    vectors extracted from only one image and feature vectors that consider a time
    series of 10 images from the same video. The experimental results show that it
    is possible to recognize an action with 80 % accuracy or higher when using random
    forest and neural network models. We also discuss a method to further improve
    the accuracy based on the experimental results. Fig. 1. Assumed system for analyzing
    moving images. Show All SECTION II. Background We assume an action recognition
    system as shown in Fig. 1. Feature vectors are extracted from moving images acquired
    by a camera installed in each ordinary home. The feature vector data are transferred
    from the sensor side to the cloud and the data are collected in the cloud. Then,
    the system performs action recognition via a machine learning process. We investigate
    whether actions can be sufficiently identified using only the feature vectors
    extracted on the sensor side without using moving images or still images and which
    machine learning method can achieve high accuracy. We will explain the related
    technologies used in this research below. A. OpenPose OpenPose is a pose estimation
    library that extracts key points such as human joints in real time using deep
    learning. It has been developed by Carnegie Mellon University and other institutions.
    It is possible to detect 135 key points, not only of a person’s body but also
    of the face and hands, that are included in the video or image. It is also possible
    to conduct the analysis with only the camera’s image and video without using a
    special sensor such as an acceleration sensor. Additionally, by using the GPU,
    OpenPose can analyze in real time even if the image or video contains multiple
    people. B. Keras Keras is a library for implementing a neural network, developed
    as part of the research for the Open-ended NeuroElectronic Intelligent Robot Operating
    System (ONEIROS) project. It supports TensorFlow, Theano and the Microsoft Cognitive
    Toolkit as a backend, focusing on enabling the description of a network model
    very easily and conducting experiments quickly. Three features make prototyping
    easy and fast: modularity, extensibility, and user-friendliness. Because Keras
    operates seamlessly on CPUs and GPUs, it is capable of high-speed operation and
    is also compatible with convolution and recurrent neural networks and their combination.
    Fig. 2. Key points obtained by OpenPose. Show All Fig. 3. Some of the coordinate
    values obtained by OpenPose. Show All SECTION III. Machine Learning Methods Applied
    in this Study In this paper, we compare the action recognition accuracies of some
    machine learning methods using the coordinate data of key points extracted from
    images using OpenPose. In the experiments, we performed action recognition using
    dataset (1), i.e., one still image and the dataset (2), i.e., multiple still images
    considering time series. For the datasets, we used images acquired from STAIR
    Actions [9], which is a collection of approximately 1000 videos of 100 daily actions
    such as walking and cooking. A. Datasets First, from the STAIR Actions datasets,
    we cut out 1 second from each video of the writing, reading a newspaper and bowing
    categories and extracted 10 still images per video at intervals of 0.1 seconds.
    For each still image, we obtained x and y coordinates of 25 key points on the
    image using OpenPose and created data of 50 feature vectors. An example of the
    key points extracted by OpenPose is shown in Fig. 2, and a part of the feature
    vector data from this image is shown in Fig. 3. TABLE I Number of Data In Each
    Category of Stair Actions. Fig. 4. Distribution of dataset (1), one still image.
    Show All The time taken to extract key points using OpenPose averaged 2.14 sec
    per 10 images, and the time taken to deduce per 1000 data was 0.096 sec for the
    NN model and 0.283 sec for the LSTM model. The number of data in each category
    is shown in Table I. We used 70% as training data and 30% as validation data in
    the experiments using dataset (1), the still image. At this time, we made the
    images extracted from the same video belong to the same dataset, that is, the
    training dataset or validation dataset. Fig. 4 shows the data compressed into
    2 dimensions and visualized using t-SNE [10], which is a method of expressing
    the closeness between two points with a probability distribution and performing
    dimensional compression. In this figure, the purple, green and yellow dots represent
    categories of writing, reading newspaper and bowing, respectively, and it shows
    that the data of each category are dispersed. In the experiments using dataset
    (2), the multiple still images, we created data of 500 features by arranging 50
    features of 10 images acquired from each video in chronological order from the
    first image to recognize actions as stream data in consideration of a time series.
    The number of data in each category is one-tenth of those in Table I, and Fig.
    5 shows the visualized state using t-SNE. In this figure, the purple, green and
    yellow dots represent categories of writing, reading a newspaper and bowing, respectively.
    Compared to Fig. 4, this figure shows that the data are roughly grouped by category,
    although the number of data is less than that of Fig. 4. Fig. 5. Distribution
    of dataset (2), multiple still images considering time series. Show All TABLE
    II the Accuracies of Action Recognition By Each Method Using Dataset (1). B. Machine
    learning methods In each experiment, we measure the action recognition accuracy
    using the following five methods. Logistic regression Random forest Support vector
    machine (SVM) Neural network (NN) model built with Keras LSTM model built with
    Keras 1) Logistic regression is a model that regresses to a logistic function
    and outputs the probability of belonging to a class. 2) Random forest is a model
    that determines the result by the majority of the prediction results of multiple
    decision trees. 3) SVM is a model optimized to maximize the margin of the projected
    high-dimensional space using a kernel function, and we used RBF as the kernel
    function in this experiment. 4) NN is a model that simulates human neurons, and
    we used fully connected NN. In addition, we adjusted the parameters to improve
    the action recognition accuracy using NN. We also introduced dropout and batch
    normalization to NN with the following three patterns and measured the action
    recognition accuracies. 4a) NN+ Dropout 4b) NN+ Batch Normalization (BN) 4c) NN+Dropout,
    BN Dropout is a method to prevent overfitting by invalidating and learning a part
    of the nodes in each layer and forcibly reducing the degree of freedom of the
    network to improve general performance. In this experiment, we learn with the
    20% of the nodes invalidated. Batch normalization is a method to improve the accuracy
    and speed of learning by normalizing by calculating the mean and variance of the
    input batch and adjusting the scale and shift. TABLE III Parameters Used In Learning
    By Each Method Using Dataset (1). In the experiments using data considering time
    series, we also perform experiment using 5) LSTM, which is an extension of Recurrent
    neural network (RNN) in order to consider the context of feature vectors for a
    longer time. The RNN is a model related to the recursive neural network, which
    has the advantage of being able to use continuous information such as sentences.
    RNN cannot use long-term dependency although the information calculated at the
    previous time can be stored and used in the later calculations. LSTM solves this
    disadvantage by introducing Constant error carousel (CEC) units, input gate, output
    gate, forget gate, and peephole connections, and makes it possible to learn long-term
    data dependency. RNN might be able to consider enough dependencies in the experiments
    with the small number of steps. However, we use LSTM that can learn longer-term
    dependencies in order to consider the large number of images acquired from videos
    in the future. Additionally, we introduce dropout to prevent overfitting. There
    are two types called dropout and recurrent dropout for LSTM; dropout represents
    the proportion of invalidated nodes in the linear transformation of input, and
    recurrent dropout represents the proportion of invalidated nodes in the linear
    transformation of recursion. We set the nodes invalidation rate to 20% and measure
    the action recognition accuracies with the following three patterns. 5a) LSTM
    + Dropout 5b) LSTM + Recurrent dropout 5c) LSTM +Dropout, Recurrent dropout SECTION
    IV. Experiments A. Action recognition using dataset (1), data of one image First,
    we explain experimental results using dataset (1), the one still image dataset.
    Table II shows the action recognition accuracies for each method using feature
    vector data extracted from dataset (1). In this table, the values represent the
    best accuracy for performing a grid search using cross-validation by logistic
    regression, random forest and SVM with the parameters shown in Table III. In logistic
    regression, the C represents the strength of regularization, and it is indicated
    that a larger C weakens the regularization. We set seven parameters in the random
    forest: bootstrap, criterion, max-depth, max-feature, min_samples_leaf, min_samples_split
    and n_estimator. The bootstrap parameter indicates whether to perform bootstrap
    sampling at the time of decision tree construction, and the criterion is the standard
    to divide the data of the decision tree. The max-depth and max-features parameters
    are used to set the maximum depth and the number of leaf nodes of the decision
    tree, respectively, and the min_samples_leaf and min_samples_split parameters
    represent the minimum number of samples required for the structure of leaf nodes
    and the division of nodes, respectively. The n-estimator represents the number
    of decision trees used for bagging to measure the accuracy of multiple decision
    trees and decide the majority. In SVM, we set the value of C, which indicates
    the degree of misclassification, and the gamma, which indicates the complexity
    of the boundary. In NN, the value in Table II is the accuracy when we performed
    cross-validation with division number 3 using the model with the 3 middle layers
    of 50 nodes and 1600 epochs. The comparison of 1) to 4) in Table II shows that
    the NN scored the highest accuracy and recognized over 80% of the actions. In
    addition, from the state of learning by NN shown in Fig. 6, the loss of validation
    increased as the number of epochs increased, while the loss of training converged
    to 0, showing overfitting, and the losses of 4a) and 4c) shows that the overfitting
    is suppressed by introducing dropout. Next, we measured the action recognition
    accuracy by changing the number of middle layers and nodes in the middle layers
    in order to optimize the parameters of the NN model. We performed a grid search
    using cross-validation in heat map with the number of middle layers changed from
    3 to 6 and the number of nodes changed to 50, 75, 100 and 125. According to this
    result, the highest accuracy is 0.834 when the model is set to 5 middle layers
    and 75 nodes. The accuracy tends to improve when the number of middle layers is
    3 or 4 and the number of nodes is 100 or more. Hence, reducing the range of the
    number of nodes and using more detailed parameter settings may improve the accuracy.
    Then, we performed a grid search using cross-validation of the NN model with the
    5 middle layers of 75 nodes, which scored the highest accuracy with and without
    dropout and batch normalization. From this result, when the vertical axis is true,
    it indicates that batch normalization has been introduced; otherwise, it indicates
    that it has not been introduced. This result shows that the model that introduced
    dropout with 30% invalidation and that did not introduce a batch normalization
    ratio scored the highest in accuracy when we used the setting with five middle
    layers and 75 nodes. Finally, the action recognition accuracy obtained in these
    experiments is not sufficient, and it is expected to be improved by setting and
    comparing the number of nodes and the dropout invalidation ratio more finely.
    Fig. 6. Losses and accuracies during learning by NN. Show All B. Action recognition
    using dataset (2), data considering time series of 10 images Next, we describe
    experimental the results using dataset (2), which is the multiple still image
    dataset. Table IV shows the action recognition accuracies of each method when
    using dataset (2) in which the feature vectors extracted from 10 images acquired
    from the same moving image are arranged in chronological order, and Table V shows
    the parameters of logistic regression, random forest and SVM. In NN, the values
    in Table IV are the accuracies when learning using the model with 3 middle layers
    of 500 nodes and 1600 epochs; a dropout of invalidation ratio of 20%, and batch
    normalization are both introduced to prevent overfitting. The accuracy using random
    forest was the highest, at 0.828, and we were able to improve the NN accuracy
    by introducing dropout, batch normalization and both to NN. Next, we measured
    the action recognition accuracies by changing the number of middle layers and
    nodes in the middle layers to optimize the parameters of the NN model. We performed
    a grid search using cross-validation when the number of middle layers was changed
    from 3 to 6 and the number of nodes was changed to 500, 600, 700 and 800 in heat
    map. When the number of middle layers is set to 4 and the number of nodes is set
    to 700, the accuracy is the highest. In addition, we performed a grid search with
    and without introducing dropout and batch normalization using this NN model. The
    model set to 5 middle layers and 700 nodes and introducing dropout with an invalidation
    ratio of 0.2 scored the highest accuracy, and the accuracy tended to improve when
    changing the node invalidation ratio of dropout in the range of 0.0 to 0.2 without
    introducing batch normalization. Hence, the accuracy may be improved by adjusting
    the parameters in more detail in this range. TABLE IV the Accuracies of Action
    Recognition By Each Method Using Dataset (2), Data Considering A Time Series.
    TABLE V Parameters Used In Learning By Each Method Using Dataset (2), Data Considering
    A Time Series. C. Action recognition by LSTM Fig. 7 shows the configuration of
    the LSTM model. After learning the features acquired from each image from a fully
    connected NN (MLP) of 2 layers, we give the output from NN to LSTM as the input
    for each time step and classify the actions using the output of the last step.
    The accuracies when the number of time steps is set to 10, 20 and 30 and the number
    of nodes is set to 50 and 100 are shown in Table VI. The result with 30 steps
    and 100 nodes shows the best performance while the accuracies with 20 steps are
    the lowest. We can see that the accuracies does not always improve as the number
    of time steps increases although the number of feature vectors increases in proportion
    to the time steps. Fig. 7. Configuration of LSTM model. Show All Fig. 8. Comparison
    of the accuracy using the LSTM model regarding the introduction of dropout. Show
    All Next, we introduced dropout because there is a tendency of overfitting like
    the learning by the fully connected NN model. Fig. 8 shows the accuracies for
    each time step setting with dropout only, recurrent dropout only, and both dropout
    and recurrent dropout. In the experiments, the invalidation rate is set to 20%
    and the number of nodes in LSTM is set to 50 and 100, respectively. Since the
    convergence is not sufficient with 1600 epoch training, we set the number of epochs
    to 3000. From the results, the accuracy tended to improve when only dropout is
    used for the LSTM model with both 50 and 100 nodes. Nevertheless, the suppression
    of overfitting by the introduction of dropout is not enough. We expect further
    improvement of the accuracies by performing data normalization and augmentation.
    D. Discussion 1) Improvement of the action recognition accuracy: We performed
    action recognition experiments using dataset (1), a single still image, and dataset
    (2), multiple still images considering a time series, and could obtain over 80%
    accuracy in the experiments using random forest, NN and LSTM. However, in the
    experiments using NN and LSTM, cross-validation is performed with only two parameters
    regarding the number of middle layers and nodes or the introduction of dropout
    and batch normalization; thus, we need to perform further experiments with all
    of these parameters and compare their accuracies. In addition, when comparing
    the recognition using datasets (1) and (2), it is easier to capture the action
    feature with dataset (2), but the number of leaning data is smaller. TABLE 6 The
    Accuracies of Action Recognition By 5) Lstm. Compared with the learning using
    the fully connected NN model, the learning using LSTM was less effective in suppressing
    overfitting by dropout. This result may be caused by the overfitting of the MLP
    before the LSTM block because the dropout only for the LSTM block in the LSTM
    models is set in the experiments. Therefore, we will examine the introduction
    of dropout to MLP and the various configuration of the LSTM model. From the results
    of learning using the fully connected NN model and the LSTM model, we normalized
    and augmented the feature vector data because the introduction of dropout was
    not enough to suppress overfitting. In the normalization process, we used the
    maximum and minimum values of the coordinate values of all the images acquired
    from the same moving image. In the augmentation process, we add the horizontally
    inverted and the ± 5 o and± 10orotated data of each moving image. Fig. 9 shows
    the losses during learning with the LSTM with 50 nodes and 10 steps, and Fig.
    10 and Fig. 11 shows the learning losses using normalized and augmented data using
    the same LSTM settings, respectively. From the figures, the learning results using
    the normalized and augmented data become stable and their convergences become
    faster. The suppression effect of overfitting is also resolved. Finally, we investigate
    the moving image misclassification in the learning using NN and LSTM. Fig. 12
    shows the classification rate when the fully connected NN model with 3 layers
    and 500 nodes in the middle layer is used, and Fig. 13 shows the classification
    rate when the LSTM model with 50 nodes and 10 steps is used. The horizontal axis
    represents the categories inferred by the model, and the vertical axis represents
    the correct categories. The identification rate is different for each category,
    and the bowing category is the easiest to identify. Table VII shows the percentage
    of misclassified moving images in the both NN and LSTM experiments. The match
    rate of misclassified moving images in all three categories is only 50% to 60%,
    and approximately half of them are correctly classified by either model. Therefore,
    ensemble learning with LSTM and NN can improve the accuracy. Fig. 9. Losses of
    the LSTM (50 nodes, 10 steps) model. Show All Fig. 10. Losses of the LSTM (50
    nodes, 10 steps) model after normalization. Show All Fig. 11. Losses of the LSTM
    (50 nodes, 10 steps) model after augmentation. Show All Fig. 12. Classification
    rate at the learning by NN (3 middle layers, 500 nodes) model. Show All Fig. 13.
    Classification rate at the learning by LSTM (10 steps, 50 nodes) model. Show All
    TABLE VII Match Rate of Misclassified Moving Images of Nn and Lstm. 2) Distributed
    processing with sensor and cloud: Fig. 14 shows the comparison of the data sizes
    of raw video, images converted from the video at a frame rate of 10 and JSON-formatted
    feature vectors of the images for each category. The quantity of data has been
    reduced to less than half by converting from video to image and to less than 1/100
    by converting to the feature vectors. The figure shows that we could greatly reduce
    the transfer quantity by preprocessing on the sensor side. We also investigate
    processing times for extracting feature vectors and machine leaning, respectively.
    Table VIII shows the spec of the cluster nodes used in the experiments. The experiments
    show that the average calculation time of 5 mals for key point extraction using
    OpenPose per 10 images and the time required for machine learning inference per
    1000 data. The image size is up to vertical 1980 pixels and horizontal 1080 pixels.
    The average calculation time was 2.14 sec and the inference time was 0.096 sec
    using the NN model and 0.283 sec using the LSTM model. The time required for OpenPose
    processing is longer than the time required for inference of machine learning,
    and the processing on the sensor side is heavy. To perform real time processing,
    it is necessary to balance preprocessing, communication and learning times in
    order to meet the total latency allowed by the target service. It is possible
    to employ more complex models that combine multiple machine learning methods if
    the target service allows a latency of a few seconds. Fig. 14. Comparison of data
    volume before and after the pre-processing of moving images. Show All TABLE VIII
    The Performance of the Cluster Nodes Used In the Experiments. SECTION V. Related
    Work There have been several studies on human action recognition using deep learning.
    It has become possible to recognize more complex motions with high accuracy by
    using various deep learning methods such as Convolutional Neural Network (CNN)
    and LSTM. Hara et al. [11] investigated behavior identification from video input
    using various 3D CNNbased methods that perform convolution in three-dimensional
    space where one-dimensional time space is added to a two-dimensional space. They
    showed improved action identification performance using a 3D CNN based on a residual
    network (ResNet) [12]. Pigou et al. [13] pooled features to consider temporal
    information in a video and showed performance improvements by combining recursion
    and temporal convolution. Li et al. [14] performed multi-class human action classification
    by CNN using data obtained by RFID. Fragkiadaki et al. [15] recognized and predicted
    human action by generating human pose motion captures using a model with an encoder
    and decoder before and after LSTM. Ordõñ ez et al. [16] performed recognition
    using data combining accelerometer, gyroscope and magnetometer by a mode combining
    CNN and LSTM. However, the computational complexity for such action recognition
    process is too large to analyze using deep learning in ordinary homes. Various
    distributed processing methods using edge computing or fog computing to analyze
    using data obtained from IoT devices have been studied to address these issues.
    Li et al. [17] proposed a method to analyze data obtained from IoT devices using
    deep learning. Since the processing capacity in an IoT device is limited, they
    used edge computing to construct a deep learning application for the IoT devices,
    and designed and evaluated an offload strategy for performance optimization. Tang
    et al. [18] proposed a hierarchical distributed fog computing architecture that
    supports massive infrastructure integration for future smart cities. Yang [19]
    investigated the models and architectures of four typical fog computing systems,
    and analyzed the design space for the four dimensions of system, data, human,
    and optimization. In this research, we investigate whether we can sufficiently
    recognize actions using only the coordinate values of human key points included
    in the moving image without using the original video data. The purpose is to ensure
    enough recognition accuracy even after reducing the quantity of data and separating
    the processing at the edge and cloud to analyze the moving images in real time.
    SECTION VI. Conclusions We used feature vectors generated from video of STAIR
    Actions using OpenPose and measured the action recognition accuracy with multiple
    machine learning methods. The experiments to recognize actions from one still
    image showed that the accuracy of NN is highest. In addition, the accuracy could
    be improved by performing cross-validation with regard to NN parameter adjustment.
    In the action recognition experiments using multiple still images considering
    a time series, the action recognition accuracy by LSTM is highest although the
    accuracy is not yet sufficient at this point. Moreover, we improved the overfitting
    by introducing dropout. We also found that only half of the moving images misclassified
    by the recognition using NN and LSTM matched. Therefore, it is possible to improve
    performance by the ensemble learning because NN and LSTM learned different features.
    In the future, we will propose the method to recognize actions required for surveillance
    and security services using all 100 categories provided in the STAIR Actions dataset
    to apply to actual services. Furthermore, we will implement the action recognition
    model in a distributed environment over the edge side and the cloud side since
    we aim to recognize actions in real time. We will also find the feasible trade-off
    point between the analysis time and recognition accuracy. ACKNOWLEDGEMENT This
    paper is partially supported by the New Energy and Industrial Technology Development
    Organization (NEDO), JSPS KAKENHI Grant Number JP19H04089, and ROIS NII Open Collaborative
    Research 2019-19S050l. Authors Figures References Citations Keywords Metrics More
    Like This Efficient Privacy-Preserving Machine Learning in Hierarchical Distributed
    System IEEE Transactions on Network Science and Engineering Published: 2019 Using
    Machine Learning Ensemble Methods to Predict Execution Time of e-Science Workflows
    in Heterogeneous Distributed Systems IEEE Access Published: 2019 Show More IEEE
    Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW
    PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: A Study of Action Recognition Using Pose Data Toward Distributed Processing
    Over Edge and Cloud
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/access.2019.2924045
  analysis: '>'
  authors:
  - Vikas Hassija
  - Vinay Chamola
  - Vikas Saxena
  - Divyansh Jain
  - Pranav Goyal
  - Biplab Sikdar
  citation_count: 830
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy IEEE.org IEEE Xplore IEEE
    SA IEEE Spectrum More Sites Subscribe Donate Cart Create Account Personal Sign
    In Browse My Settings Help Institutional Sign In All Books Conferences Courses
    Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals & Magazines
    >IEEE Access >Volume: 7 A Survey on IoT Security: Application Areas, Security
    Threats, and Solution Architectures Publisher: IEEE Cite This PDF Vikas Hassija;
    Vinay Chamola; Vikas Saxena; Divyansh Jain; Pranav Goyal; Biplab Sikdar All Authors
    830 Cites in Papers 64720 Full Text Views Open Access Comment(s) Under a Creative
    Commons License Abstract Document Sections I. Introduction II. Security Critical
    Application Areas of IoT III. Sources of Security Threats in IoT Applications
    IV. Improvements and Enhancements Required for Upcoming IoT Applications V. IoT
    Security Using Blockchain Show Full Outline Authors Figures References Citations
    Keywords Metrics Abstract: The Internet of Things (IoT) is the next era of communication.
    Using the IoT, physical objects can be empowered to create, receive, and exchange
    data in a seamless manner. Various IoT applications focus on automating different
    tasks and are trying to empower the inanimate physical objects to act without
    any human intervention. The existing and upcoming IoT applications are highly
    promising to increase the level of comfort, efficiency, and automation for the
    users. To be able to implement such a world in an ever-growing fashion requires
    high security, privacy, authentication, and recovery from attacks. In this regard,
    it is imperative to make the required changes in the architecture of the IoT applications
    for achieving end-to-end secure IoT environments. In this paper, a detailed review
    of the security-related challenges and sources of threat in the IoT applications
    is presented. After discussing the security issues, various emerging and existing
    technologies focused on achieving a high degree of trust in the IoT applications
    are discussed. Four different technologies, blockchain, fog computing, edge computing,
    and machine learning, to increase the level of security in IoT are discussed.
    This paper presents a detailed survey of IoT security. First of all the security
    critical IoT applications are discussed. Next, the security threats at different
    layers i...View more Published in: IEEE Access ( Volume: 7) Page(s): 82721 - 82743
    Date of Publication: 20 June 2019 Electronic ISSN: 2169-3536 DOI: 10.1109/ACCESS.2019.2924045
    Publisher: IEEE Funding Agency: CCBY - IEEE is not the copyright holder of this
    material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/
    to obtain full-text articles and stipulations in the API documentation. SECTION
    I. Introduction The pace of connecting physical devices around us to the Internet
    is increasing rapidly. According to a recent Gartner report, there will be around
    8.4 billion connected things worldwide in 2020. This number is expected to grow
    to 20.4 billion by 2022 [1]. The use of IoT applications is increasing in all
    parts of the world. The major driving countries in this include western Europe,
    North America, and China [1]. The number of machine to machine (M2M) connections
    is expected to grow from 5.6 billion in 2016 to 27 billion in 2024 [1]. This leap
    in numbers itself declares IoT to be one of the major upcoming markets that could
    form a cornerstone of the expanding digital economy. The IoT industry is expected
    to grow in terms of revenue from 892billionin2018to 4 trillion by 2025 [2]. M2M
    connections cover a broad range of applications like smart cities, smart environment,
    smart grids, smart retail, smart farming, etc. [3]. Figure 1 shows the past, present
    and future architecture of IoT. In future, the devices are not only expected to
    be connected to the Internet and other local devices but are also expected to
    communicate with other devices on the Internet directly. Apart from the devices
    or things being connected, the concept of social IoT (SIoT) is also emerging.
    SIoT will enable different social networking users to be connected to the devices
    and users can share the devices over the Internet [4]. FIGURE 1. Present and future
    architecture of IoT. Show All With all this vast spectrum of IoT applications
    comes the issue of security and privacy. Without a trusted and interoperable IoT
    ecosystem, emerging IoT applications cannot reach high demand and may lose all
    their potential. Along with the security issues faced generally by the Internet,
    cellular networks, and WSNs, IoT also has its special security challenges such
    as privacy issues, authentication issues, management issues, information storage
    and so on. Table 1 summarizes various factors due to which securing IoT environment
    is much more challenging than securing normal information technology (IT) devices.
    Due to all these issues and vulnerabilities, the IoT applications create a fertile
    ground for different kinds of cyber threats. There have been various security
    and privacy attacks on the already deployed IoT applications worldwide. Mirai
    attack in the last quarter of 2016 was estimated to infect around 2.5 million
    devices connected to the Internet and launch distributed denial of service (DDoS)
    attack [5]. After Mirai, Hajime and Reaper are the other big botnet attacks launched
    against a large number of IoT devices [5]. IoT devices, being low powered and
    less secure, provide a gateway to the adversaries for entering into home and corporate
    networks, thereby giving easy access to the user’s data. Also, the domain of IoT
    is expanding beyond mere things or objects. There have been various successful
    attempts to implant IoT devices into the human body to monitor the live condition
    of various organs [6]. Attackers can target such devices to track the location
    of a particular individual or falsify data. Such an attack has not taken place
    yet in real life but can be highly dangerous, if such devices are compromised.
    TABLE 1 Comparison of Security of IT Devices and IoT Devices Cyber Physical Systems
    (CPS) is another area benefitting from the growth of IoT. In CPS physical objects
    in the environment are monitored, and actions are taken based on the physical
    changes. Since CPS encompass assets of critical importance (e.g., power grids,
    transportation systems), security vulnerabilities in such systems have serious
    consequences. However, security challenges for CPS have their unique characteristics
    and are outside the scope of this paper. In any IoT ecosystem or environment,
    there are four important layers. The first layer includes the use of various sensors
    and actuators to perceive the data or information to perform various functionalities.
    Based on that, in the second layer, a communication network is used to transmit
    the collected data. Most of the evolving IoT applications deploy the third layer,
    called a middleware layer, to act as a bridge between the network and application
    layer. Finally, on the fourth layer, there are various IoT based end-to-end applications
    like smart grids, smart transport, smart factories, etc. All of these four layers
    have security problems specific to them. Apart from these layers, various gateways
    connect these layers and help in the data movement. There are certain security
    threats specific to these gateways as well. In this paper, a detailed survey of
    IoT security solutions in the existing literature is presented. First of all,
    the fundamental constraints to achieve high levels for security in IoT applications
    are presented. The goal of this paper is to highlight the major existing and upcoming
    solutions for IoT security. Specifically, the four major classes of IoT security
    solutions namely: (1) blockchain based solutions; (2) fog computing based solutions;
    (3) machine learning based solutions and (4) edge computing based solutions are
    highlighted. Table 3 gives a list of acronyms related to IoT used in this paper.
    TABLE 2 Related Surveys on IoT Security TABLE 3 List of Acronyms A. Related Surveys
    and Our Contributions There are various existing surveys on IoT security and privacy
    issues. Yuchen et al. [10] have summarized various security issues in IoT applications.
    Authors of [11] have discussed the security issues specific to location-based
    services in IoT. The authors target the particular problems related to localization
    and positioning of the IoT devices. Anne et al. in [12] focus mainly on the security
    issues related to IoT middleware and provide a detailed survey of related existing
    protocols and their security issues. M. Guizani et al. in [14] have surveyed various
    trust management techniques for IoT along with their pros and cons. Security mechanisms
    for IoT security such as software defined networking (SDN) and network function
    virtualization (NFV) are discussed in [13]. In [8] the authors have compared edge
    computing with traditional cloud systems to secure IoT systems. Jie Lin et al.
    in [9] have discussed the relationship between IoT and fog computing. Some of
    the security issues related to fog computing have also been discussed. Authors
    of [7] have discussed vulnerabilities faced by IoT in brief. Table 2 summarizes
    the main contributions of the previous comprehensive surveys on IoT security.
    Although there are several works in this direction, they are specific to certain
    limited aspects of IoT. This calls the need for a detailed survey on all the existing
    and upcoming security challenges in IoT applications. This paper will help the
    reader to get a detailed idea of the state-of-the-art in IoT security and will
    give them a general understanding of the area. The main contributions of this
    work are as follows: A classification of different IoT applications and specific
    security and privacy issues related to those applications. A detailed explanation
    of different threat sources in different layers of IoT. Detailed and realistic
    recommendations to improve the IoT infrastructure to facilitate secure communications.
    Review on the proposed countermeasures to the security issues in IoT. An assessment
    of the open issues, challenges and future research directions for developing secure
    IoT applications. B. Organization The organization of the rest of the paper is
    as follows: Section II describes various application areas of IoT where high security
    is required. Section III discusses various sources of threats in an IoT environment.
    In section IV various constraints and requirements to be considered while developing
    a secure IoT application are reviewed. Four major IoT security approaches, i.e.,
    blockchain, fog computing, machine learning, and edge computing are presented
    in Section V, VI, VII, and VIII, respectively. Section IX describes various open
    issues, challenges and upcoming research opportunities in IoT security and finally,
    Section X concludes the paper. SECTION II. Security Critical Application Areas
    of IoT Security is highly critical in almost all IoT applications that have already
    been deployed or are in the process of deployment. The applications of IoT are
    increasing very rapidly and penetrating most of the existing industries. Although
    operators support these IoT applications through existing networking technologies,
    several of these applications need more stringent security support from technologies
    they use. In this section various security critical IoT applications are discussed.
    Smart Cities: Smart cities involve extensive use of emerging computation and communication
    resources for increasing the overall quality of life of the people [15]. It includes
    smart homes, smart traffic management, smart disaster management, smart utilities,
    etc. There is a push to make cities smarter, and governments worldwide are encouraging
    their development through various incentives [16]. Although the use of smart applications
    is intended to improve the overall quality of life of the citizens, it comes with
    a threat to the privacy of the citizens. Smart card services tend to put the card
    details and purchase behavior of the citizens at risk. Smart mobility applications
    may leak the location traces of the users. There are applications using which
    parents can keep track of their child. However, if such applications are hacked,
    then the safety of the child can come to risk. Smart Environment: Smart environment
    includes various IoT applications such as fire detection in forests, monitoring
    the level of snow in high altitude regions, preventing landslides, early detection
    of earthquakes, pollution monitoring, etc. All these IoT applications are closely
    related to the life of human beings and animals in those areas. The government
    agencies involved in such fields will also be relying on the information from
    these IoT applications. Security breaches and vulnerability in any area related
    to such IoT applications can have serious consequences. In this context, both
    false negatives and false positives can lead to disastrous results for such IoT
    applications. For example, if the application starts detecting earthquakes falsely,
    then it will lead to monetary losses for the government and businesses. On the
    other hand, if the application is not able to predict the earthquake, then it
    will lead to the loss of both property and life. Therefore, smart environment
    applications have to be highly precise, and security breaches and data tampering
    must be avoided. Smart Metering and Smart Grids: Smart metering includes applications
    related to various measurements, monitoring, and management. The most common application
    of smart metering is smart grids, where the electricity consumption is measured
    and monitored. Smart metering may also be used to address the problem of electricity
    theft [17]. Other applications of smart metering include monitoring of water,
    oil and gas levels in storage tanks and cisterns. Smart meters are also used to
    monitor and optimize the performance of solar energy plants by dynamically changing
    the angle of solar panels to harvest the maximum possible solar energy. There
    also exist some IoT applications that use smart meters to measure the water pressure
    in water transport systems or to measure the weight of goods. However, smart metering
    systems are vulnerable to both physical and cyber-attacks as compared to analog
    meters that can be tampered only by physical attacks. Also, smart meters or advanced
    metering infrastructure (AMI) are intended to perform functions beyond generic
    energy usage recording. In a smart home area network (HAN) all electric equipment
    at home are connected to smart meters and the information collected from these
    equipments can be used for load and cost management. Intentional intrusion in
    such communication systems by the consumer or an adversary may modify the collected
    information, leading to monetary loss for the service providers or consumers [18].
    Security and Emergencies: Security and emergencies is another important area where
    various IoT applications are being deployed. It includes applications such as
    allowing only authorized people in restricted areas etc. Another application in
    this domain is the detection of leakage of hazardous gases in industrial areas
    or areas around chemical factories. Radiation levels can also be measured in the
    areas around nuclear power reactors or cellular base stations and alerts can be
    generated when the radiation level is high. There are various buildings whose
    systems have sensitive data or that house sensitive goods. Security applications
    can be deployed to protect sensitive data and goods. IoT applications that detect
    various liquids can also be used to prevent corrosion and break downs in such
    sensitive buildings. Security breaches in such applications can also have various
    serious consequences. For example, the criminals may try to enter the restricted
    areas by attacking the vulnerabilities in such applications. Also, false radiation
    level alarms can have serious immediate and long term impacts. For example, if
    infants are exposed to high levels of radiation, then it may lead to serious life
    threatening diseases in long term. Smart Retail: IoT applications are being extensively
    used in the retail sector. Various applications have been developed to monitor
    the storage conditions of the goods as they move along the supply chain. IoT is
    also being used to control the tracking of products in the warehouses so that
    restocking can be done optimally. Various intelligent shopping applications are
    also being developed for assisting the customers based on their preferences, habits,
    allergies to certain components, etc. Mechanisms to provide the experience of
    online shopping to offline retailers using augmented reality techniques have also
    been developed. Various companies in retail have faced security issues in deploying
    and using various IoT applications. Some of these companies include Apple, Home
    Depot, JP Morgan Chase and Sony [19]. Adversaries may try to compromise the IoT
    applications associated with storage conditions of the goods and may try to send
    wrong information about the products to the users in order to increase the sale.
    If security features are not implemented in smart retail, attackers may steal
    debit and credit card information, phone numbers, email-addresses, etc. of the
    customers which can lead to monetary losses for the customers and retailers. Smart
    Agriculture and Animal Farming: Smart agriculture includes monitoring soil moisture,
    controlling micro-climate conditions, selective irrigation in dry zones, and controlling
    humidity and temperature. Usage of such advanced features in agriculture can help
    in achieving high yields and can save farmers from monetary losses. Control of
    temperature and humidity levels in various grain and vegetable production can
    help in preventing fungus and other microbial contaminants. Controlling the climate
    conditions can also help in increasing the vegetable and crop yield and quality.
    Just like crop monitoring, there are IoT applications to monitor the activities
    and the health condition of farm animals by attaching sensors to the animals.
    If such applications are compromised, then it may lead to the theft of animals
    from the farm and adversaries may also damage the crops. Home Automation: Home
    automation is one of the most widely used and deployed IoT applications. This
    includes applications such as those for remotely controlling electrical appliances
    to save energy, systems deployed on windows and doors to detect intruders, etc.
    Monitoring systems are being applied to track energy and water supply consumption,
    and users are being advised to save cost and resources. Authors in [20] have proposed
    the use of logic based security algorithms to enhance security level in homes.
    Intrusions are detected by comparing the user actions at key locations of the
    home with normal behavior of the user in these locations. However, attackers may
    gain unauthorized access of the IoT devices in the home and try to harm the users.
    For instance, cases of home burglaries have increased rapidly after the deployment
    of various home automation systems [20]. There have also been various cases in
    the past where the adversaries try to analyze the type and volume of Internet
    traffic to/from the smart home for judging the behavior and presence of the residents.
    SECTION III. Sources of Security Threats in IoT Applications As discussed in Section
    I, any IoT application can be divided into four layers: (1) sensing layer; (2)
    network layer; (3) middleware layer; and (4) application layer. Each of these
    layers in an IoT application uses diverse technologies that bring a number of
    issues and security threats. Figure 2 shows various technologies, devices, and
    applications at these four layers. This section discusses various possible security
    threats in IoT applications for these four layers. Figure 3 shows the possible
    attacks on these four layers. The special security issues associated with the
    gateways that connect these layers are also discussed in this section. FIGURE
    2. Layers in IoT system. Show All FIGURE 3. Types of attacks on IoT. Show All
    A. Security Issues at Sensing Layer The sensing layer mainly deals with physical
    IoT sensors and actuators. Sensors sense the physical phenomenon happening around
    them [21]–[23]. Actuators, on the other hand, perform a certain action on the
    physical environment, based on the sensed data. There are various kinds of sensors
    for sensing different kinds of data, e.g., ultrasonic sensors, camera sensors,
    smoke detection sensors, temperature and humidity sensors, etc. There can be mechanical,
    electrical, electronic or chemical sensors used to sense the physical environment.
    Various sensing layer technologies are used in different IoT applications like
    RFID, GPS, WSNs, RSNs, etc. Major security threats that can be encountered at
    the sensing layer are as follows: Node Capturing: IoT applications comprise of
    several low power nodes such as sensors and actuators. These nodes are vulnerable
    to a variety of attacks by the adversaries. The attackers may try to capture or
    replace the node in the IoT system with a malicious node. The new node may appear
    to be the part of the system but is controlled by the attacker. This may lead
    to compromising the security of the complete IoT application [24]. Malicious Code
    Injection Attack: The attack involves the attacker injecting some malicious code
    in the memory of the node. Generally, the firmware or software of IoT nodes are
    upgraded on the air, and this gives a gateway to the attackers to inject malicious
    code. Using such malicious code, the attackers may force the nodes to perform
    some unintended functions or may even try to access the complete IoT system. False
    Data Injection Attack: Once the node is captured, the attacker may use it to inject
    erroneous data onto the IoT system. This may lead to false results and may result
    in malfunctioning of the IoT application. The attacker may also use this method
    to cause a DDoS attack. Side-Channel Attacks (SCA): Apart from direct attacks
    on the nodes, various side-channel attacks may lead to leaking of sensitive data.
    The microarchitectures of processors, electromagnetic emanation and their power
    consumption reveal sensitive information to adversaries. Side channel attacks
    may be based on power consumption, laser-based attacks, timing attacks or electromagnetic
    attacks. Modern chips take care of various countermeasures to prevent these side-channel
    attacks while implementing the cryptographic modules. Eavesdropping and Interference:
    IoT applications often consist of various nodes deployed in open environments
    [25]. As a result, such IoT applications are exposed to eavesdroppers. The attackers
    may eavesdrop and capture the data during different phases like data transmission
    or authentication. Sleep Deprivation Attacks: In such type of attacks the adversaries
    try to drain the battery of the low-powered IoT edge devices. This leads to a
    denial of service from the nodes in the IoT application due to a dead battery.
    This can be done by running infinite loops in the edge devices using malicious
    code or by artificially increasing the power consumption of the edge devices.
    Booting Attacks: The edge devices are vulnerable to various attacks during the
    boot process. This is because the inbuilt security processes are not enabled at
    that point. The attackers may take advantage of this vulnerability and try to
    attack the node devices when they are being restarted. As edge devices are typically
    low powered and at times go through sleep-wake cycles, it is thus essential to
    secure the boot process in these devices. B. Security Issues at Network Layer
    The key function of the network layer is transmitting the information received
    from the sensing layer to the computational unit for processing. The major security
    issues that are encountered at the network layer are as follows. Phishing Site
    Attack: Phishing attacks often refer to attacks where several IoT devices can
    be targeted by a minimal effort put by the attacker. The attackers expect that
    at least few of the devices will become a victim of the attack. There is a possibility
    of encountering phishing sites in the course of users visiting web pages on the
    Internet. Once the user’s account and password are compromised, the whole IoT
    environment being used by the user becomes vulnerable to cyber attacks. The network
    layer in IoT is highly vulnerable to phishing sites attacks [26]. Access Attack:
    Access attack is also referred to as advanced persistent threat (APT). This is
    a type of attack in which an unauthorized person or an adversary gains access
    to the IoT network. The attacker can continue to stay in the network undetected
    for a long duration. The purpose or intention of this kind of attack is to steal
    valuable data or information, rather than to cause damage to the network. IoT
    applications continuously receive and transfer valuable data and are therefore
    highly vulnerable to such attacks [27]. DDoS/DoS Attack: In this kind of attacks,
    the attacker floods the target servers with a large number of unwanted requests.
    This incapacitates the target server, thereby disrupting services to genuine users.
    If there are multiple sources used by the attacker to flood the target server,
    then such an attack is termed as DDoS or distributed denial of service attack.
    Such attacks are not specific to IoT applications, but due to the heterogeneity
    and complexity of IoT networks, the network layer of the IoT is prone to such
    attacks. Many IoT devices in IoT applications are not strongly configured, and
    thus become easy gateways for attackers to launch DDoS attacks on the target servers.
    The Mirai botnet attack as discussed in Section I used this vulnerability and
    blocked various servers by constantly propagating requests to the weakly configured
    IoT devices [28]. Data Transit Attacks: IoT applications deal with a lot of data
    storage and exchange. Data is valuable, and therefore it is always the target
    of hackers and other adversaries. Data that is stored in the local servers or
    the cloud has a security risk, but the data that is in transit or is moving from
    one location to another is even more vulnerable to cyber attacks. In IoT applications,
    there is a lot of data movement between sensors, actuators, cloud, etc. Different
    connection technologies are used in such data movements, and therefore IoT applications
    are susceptible to data breaches. Routing Attacks: In such attacks, malicious
    nodes in an IoT application may try to redirect the routing paths during data
    transit. Sinkhole attacks are a specific kind of routing attack in which an adversary
    advertises an artificial shortest routing path and attracts nodes to route traffic
    through it. A worm-hole attack is another attack which can become serious security
    threat if combined with other attacks such as sinkhole attacks. A warm-hole is
    an out of band connection between two nodes for fast packet transfer. An attacker
    can create a warm-hole between a compromised node and a device on the internet
    and try to bypass the basic security protocols in an IoT application. C. Security
    Issues at Middleware Layer The role of the middleware in IoT is to create an abstraction
    layer between the network layer and the application layer. Middleware can also
    provide powerful computing and storage capabilities [29]. This layer provides
    APIs to fulfill the demands of the application layer. Middleware layer includes
    brokers, persistent data stores, queuing systems, machine learning, etc. Although
    the middleware layer is useful to provide a reliable and robust IoT application,
    it is also susceptible to various attacks. These attacks can take control of the
    entire IoT application by infecting the middleware. Database security and cloud
    security are other main security challenges in the middleware layer. Various possible
    attacks in the middleware layer are discussed as follows. Man-in-the-Middle Attack:
    The MQTT protocol uses publish-subscribe model of communication between clients
    and subscribers using the MQTT broker, which effectively acts as a proxy. This
    helps in decoupling the publishing and the subscribing clients from each other
    and messages can be sent without the knowledge of the destination. If the attacker
    can control the broker and become a man-in-the-middle, then he/she can get complete
    control of all communication without any knowledge of the clients. SQL Injection
    Attack: MIddleware is also susceptible to SQL Injection (SQLi) attacks. In such
    attacks, attacker can embed malicious SQL statements in a program [30], [31].
    Then, the attackers can obtain private data of any user and can even alter records
    in the database [32]. Open Web Application Security Project (OWASP) has listed
    SQLi as a top threat to web security in their OWASP top 10 2018 document [33].
    Signature Wrapping Attack: In the web services used in the middleware, XML signatures
    are used [34]. In a signature wrapping attack, the attacker breaks the signature
    algorithm and can execute operations or modify eavesdropped message by exploiting
    vulnerabilities in SOAP (Simple Object Access Protocol) [35]. Cloud Malware Injection:
    In cloud malware injection, the attacker can obtain control, inject malicious
    code or can inject a virtual machine into the cloud. The attacker pretends to
    be a valid service by trying to create a virtual machine instance or a malicious
    service module. In this way, the attacker can obtain access to service requests
    of the victim’s service and can capture sensitive data which can be modified as
    per the instance. Flooding Attack in Cloud: This attack works almost the same
    as DoS attack in the cloud and affects the quality of service (QoS). For depleting
    cloud resources, the attackers continuously send multiple requests to a service.
    These attacks can have a big impact on cloud systems by increasing the load on
    the cloud servers. D. Security Issues at Gateways Gateway is a broad layer that
    has an important role in connecting multiple devices, people, things and cloud
    services. Gateways also help in providing hardware and software solutions for
    IoT devices. Gateways are used for decrypting and encrypting IoT data and translating
    protocols for communication between different layers [36]. IoT systems today are
    heterogeneous including LoraWan, ZigBee, Z-Wave and TCP/IP stacks with many gateways
    in between. Some of the security challenges for IoT gateway are discussed below.
    Secure On-boarding: When a new device or sensor is installed in an IoT system,
    it is imperative to protect encryption keys. Gateways act as an intermediary between
    the new devices and the managing services, and all the keys pass through the gateways.
    The gateways are susceptible to man-in-the-middle attacks and eavesdropping to
    capture the encryption keys, especially during the on-boarding process. Extra
    Interfaces: Minimizing the attack surface is an important strategy that needs
    to be kept in mind while installing the IoT devices [37]. Only the necessary interfaces
    and protocols should be implemented by an IoT gateway manufacturer. Some of the
    services and functionalities should be restricted for end-users to avoid backdoor
    authentication or information breach. End-to-End Encryption: True end-to-end application
    layer security is required to ensure the confidentiality of the data [38]. The
    application should not let anyone other than the unique recipient to decrypt the
    encrypted messages. Although Zigbee and Zwave protocols support encryption, this
    is not end-to-end encryption, because, in order to translate the information from
    one protocol to another, the gateways are required to decrypt and re-encrypt the
    messages. This decryption at the gateway level makes the data susceptible to data
    breaches. Firmware updates: Most IoT devices are resource constrained, and therefore
    they do not have an user interface or the computation power to download and install
    the firmware updates. Generally, gateways are used to download and apply the firmware
    updates. The current and new version of the firmware should be recorded, and validity
    of the signatures should be checked for secure firmware updates. E. Security Issues
    at Application Layer The application layer directly deals with and provides services
    to the end users. IoT applications like smart homes, smart meters, smart cities,
    smart grids, etc. lie in this layer. This layer has specific security issues that
    are not present in other layers, such as data theft and privacy issues. The security
    issues in this layer are also specific to different applications. Many IoT applications
    also consist of a sub-layer between the network layer and application layer, usually
    termed as an application support layer or middleware layer. The support layer
    supports various business services and helps in intelligent resource allocation
    and computation. Major security issues encountered by the application layer are
    discussed below. Data Thefts: IoT applications deal with lot of critical and private
    data. The data in transit is even more vulnerable to attacks than data at rest,
    and in IoT applications, there is a lot of data movement. The users will be reluctant
    to register their private data on IoT applications if these applications are vulnerable
    to data theft attacks. Data encryption, data isolation, user and network authentication,
    privacy management, etc. are some of the techniques and protocols being used to
    secure IoT applications against data thefts. Access Control Attacks: Access control
    is authorization mechanism that allows only legitimate users or processes to access
    the data or account. Access control attack is a critical attack in IoT applications
    because once the access is compromised, then the complete IoT application becomes
    vulnerable to attacks. Service Interruption Attacks: These attacks are also referred
    to as illegal interruption attacks or DDoS attacks in existing literature. There
    have been various instances of such attacks on IoT applications. Such attacks
    deprive legitimate users from using the services of IoT applications by artificially
    making the servers or network too busy to respond. Malicious Code Injection Attacks:
    Attackers generally go for the easiest or simplest method they can use to break
    into a system or network. If the system is vulnerable to malicious scripts and
    misdirections due to insufficient code checks, then that would be the first entry
    point that an attacker would choose. Generally, attackers use XSS (cross-site
    scripting) to inject some malicious script into an otherwise trusted website.
    A successful XSS attack can result in the hijacking of an IoT account and can
    paralyze the IoT system. Sniffing Attacks: The attackers may use sniffer applications
    to monitor the network traffic in IoT applications. This may allow the attacker
    to gain access to confidential user data if there are not enough security protocols
    implemented to prevent it [39]. Reprogram Attacks: If the programming process
    is not protected, then the attackers can try to reprogram the IoT objects remotely.
    This may lead to the hijacking of the IoT network [40]. SECTION IV. Improvements
    and Enhancements Required for Upcoming IoT Applications Personal computers (PC)
    and smartphones have a number of security features built into them, e.g., firewalls,
    anti-virus softwares, address space randomization, etc. These safety shields are,
    in general, missing in various IoT devices that are already in the market. There
    are various security challenges that the IoT applications are facing currently.
    A well-defined framework and standard for an end-to-end IoT application is not
    yet available. An IoT application is not a standalone application, and it is an
    assembled product which includes work from many individuals and industries. At
    every layer starting from sensing to the application, several diverse products
    and technologies are being used. These include a large number of sensors and actuators
    at the edge nodes. There are multiple communication standards like cellular network,
    WiFi, IEEE 802.15.4, Insteon, dash7, Bluetooth, etc. A handshake mechanism is
    required between all these standards. Apart from this, various connectivity technologies
    are being used at different levels in the same IoT application like Zigbee, 6LOWPAN,
    wireless HART, Z-Wave, ISA100, Bluetooth, NFC, RFID, etc. Over and above this,
    the generic HTTP protocol cannot be used in the application layer. HTTP is not
    suitable for resource-constrained environments because it is heavy-weight and
    thus incurs a large parsing overhead. Therefore, at the application layer also
    there are many alternate protocols that have been deployed for IoT environments.
    Some of them are MQTT, SMQTT, CoAP, XMPP, AMQP, M3DA, JavascriptIoT, etc. Due
    to the intense diversity of protocols, technologies, and devices in an IoT application,
    the significant trade-offs are between cost effectiveness, security, reliability,
    privacy, coverage, latency, etc. If one metric for improvement is optimized, it
    may result in the degradation of other metric. For example, imposing too many
    security checks and protocols in all data transactions in IoT applications may
    end up increasing the cost and latency of the application, thereby, making it
    unsuitable for the users. A typical IoT application consists of a big chain of
    connected devices, technologies, domains, and geographies. Even if one of the
    device or technology or their combination is left weak, then that may be the cause
    of a security threat for the entire application. The chain is considered to be
    as strong as the weakest link. There has been a large increase in the number of
    weak links in IoT applications recently. For example, even basic IoT applications
    such as smart bulbs and smart door locks can be used as a weak link in a smart
    home IoT application to extract the user’s WiFi password [41] and [42]. The large
    number of IoT devices being deployed around the world to make it smart generates
    a large amount of environment and user-related data. A lot of private information
    can be inferred from this data, and that can be another cause of threat for an
    individual and society at large [7]. As a result, significant improvements and
    enhancements in the current IoT application structure and framework are required
    to make it reliable, secure and robust. In this regard: Rigorous penetration testing
    for IoT devices is necessary to quantify the level of risk involved in deploying
    these devices in different applications. Based on the risk involved, a priority
    list can be made and the devices can be deployed appropriately in different applications.
    Encryption techniques are being used in IoT system at different layers and protocols.
    However, there are various levels of encrypt, decrypt, and re-encrypt cycles in
    the complete system. These cycles make the system vulnerable to attacks. End to
    end encryption would be a promising solution to prevent different attacks. Authenticate-always
    protocols need to be implemented. Whenever a device wants to interact with another
    device, an authentication process should be implemented. Digital certificates
    can be a promising solution to provide seamless authentication with bound identities
    that are tied to cryptographic protocols. Any IoT security framework being implemented
    should be tested and confirmed for scalability. The security protocols should
    not be working only for a limited set of users. The real threats start coming
    only when the application becomes public and starts being used widely in the public
    domain. Therefore, proper strategy and planning are required. A mechanism based
    on encryption techniques like RSA, SHA256, or hash chains is required to secure
    the user and environment data from being captured. IoT devices need to be designed
    in a way that they can transmit the sensed data in a secure and encrypted way.
    This will help in gaining the trust of the individuals, government agencies and
    industries in IoT applications. Since the IoT devices and applications are growing
    rapidly, an approach needs to be designed to handle the cost and capacity constraints
    that are expected to be encountered shortly. A paradigm shift from a centralized
    approach to some decentralized approach might be needed, where devices can automatically
    and securely communicate with each other. This can help in reducing the cost of
    managing the applications and can reduce the issues of capacity constraints [43].
    Since most of the IoT applications use cloud services for data storage and retrieval,
    the risks caused by the cloud should also be considered. Cloud is a public platform
    used by multiple users and there may be malicious users on the cloud who can be
    the cause of threat for IoT related data. The data should be stored as ciphertext
    in the cloud and the cloud should not be allowed to decrypt any ciphertext. This
    can further enhance data security and can save us from the generic risks of using
    cloud services [44]. Apart from the challenges from outside entities, there are
    various scenarios where the sensors in an IoT application start collecting or
    sending erroneous data. These errors might be easy to handle in case of a centralized
    architecture but can become a bottleneck in case of an autonomous decentralized
    architecture. Faulty reading or transmitting of data can lead to undesirable results.
    Thus, mechanism needs to be identified to validate the data flow, especially in
    case of a distributed architecture [45]. Since the ultimate goal of all IoT applications
    is to create an autonomous system that needs minimum human interventions, the
    use of some artificial intelligence (AI) based techniques or algorithms to secure
    IoT devices might be useful. This can help in reducing the analysis and communication
    load on IoT environment [46]. There are various techniques and approaches in the
    existing literature for securing IoT environments and applications. These solutions
    may be divided into four categories: (1) blockchain based solutions; (2) fog computing
    based solutions; (3) machine learning based solutions and (4) edge computing based
    solutions. Figure 4 shows various works in different domains that have used the
    above-mentioned solutions for securing the IoT environments [47]–[97]. In the
    following sections, these solutions are described in detail. FIGURE 4. Research
    papers addressing IoT security using various security techniques. Show All SECTION
    V. IoT Security Using Blockchain Blockchain and IoT are important technologies
    that will have a high impact on the IT and communication industry. These two technologies
    focus on improving the overall transparency, visibility, level of comfort and
    level of trust for the users. The IoT devices provide real-time data from sensors
    and blockchain provides the key for data security using a distributed, decentralized
    and shared ledger [108]. The basic idea behind the blockchain is simple: it is
    a distributed ledger (also called replicated log files). The entries in the blockchain
    are chronological and time-stamped. Each entry in the ledger is tightly coupled
    with the previous entry using cryptographic hash keys. A Merkle tree is used to
    store the individual transactions and the root hash of the tree is stored in the
    blockchain. In the figure, T1,T2,T3,⋯,Tn represent the individual transactions.
    The transactions are cryptographically hashed and stored on the leaf nodes of
    the tree as Ha,Hb,Hc and so on. The hash of the child nodes are concatenated and
    a new root hash is generated. The final root hash (e.g., H1 and H2 ) is stored
    on the blockchain. Just the root hash can be verified in order to make sure that
    all the transactions associated with that root hash are secure and have not been
    tampered with. Even if a single transaction is changed, all the hash values on
    that particular side of the tree will change. The ledger maintainer or the miner
    verifies the logs or transactions and generates a key that enables the latest
    transaction to become the part of complete ledger. This process makes the latest
    entries available to all the nodes in the network. Due to the presence of cryptographic
    hash keys in each block, it is too time-consuming and difficult for the adversaries
    to tamper with the blocks [109]. The miners do not have any personal interest
    in the transactions, and they are mining just to earn their incentives. The miners
    do not know the identity of the owners of the transactions. Over and above, there
    are multiple miners working on the same set of transactions, and there is a strong
    competition between them to add the transactions to the blockchain. All these
    unique features empower the blockchain to be a strong, tamper-proof, distributed
    and open data structure for IoT data [110]. Figure 5 shows the complete flow of
    a transaction from being initialized to being committed to the distributed chain.
    There are various platforms and frameworks being developed in academia and industry
    that support the creation and maintenance of blockchain. Some examples of such
    platforms are Ethereum, Hyperledger fabric, Ripple, etc. [111]. FIGURE 5. Working
    process of blockchain. Show All A. Permissioned and Permission-Less Blockchain
    There are two types of blockchain architectures based on the type of data being
    added and the nature of application using blockchain. In permission-less blockchain,
    there is no specific permission required for a user to become the part of the
    blockchain network or to become a miner. Anyone can join or leave this network
    of permission-less blockchain. The best example of permission-less blockchains
    is Bitcoin. Although the throughput of transactions is not very high, the permission-less
    blockchains can support a large number of nodes in the network. On the other hand,
    the permissioned blockchains have a defined set of rules to participate in the
    blockchain network. The miners are also the authorized persons and the blocks
    are allowed to be added to the chain only after their validation. The blockchain
    of Ripple and Hyperledger are two prime examples of permissioned blockchain. The
    permissioned concept of blockchain improves the overall throughput of transactions
    as compared to permission-less blockchains. Figure 6 shows the sample architecture
    of a blockchain and the way every block is connected to all the previous blocks
    based on cryptographic hashing. FIGURE 6. Basic blockchain architecture. Show
    All B. Benefits of Blockchain in IoT The usage of blockchain has many advantages
    in IoT applications. Table 4 gives a summary of some specific challenges in IoT
    security and their possible solutions using blockchain. Various security issues
    faced by IoT applications have already been discussed in Section III. The key
    benefits of using blockchain in IoT applications are discussed below. Data coming
    from IoT devices can be stored in Blockchain: The IoT applications include a large
    variety of devices connected to each other. These devices are further connected
    and controlled by other devices. This setup is further connected to the cloud
    to enable IoT applications to be used from any location. Due to this large space
    for data movement, blockchain is a promising solution to store the data and prevent
    it from being misused. Irrespective of the layer in an IoT application, blockchain
    can act as a suitable solution to store and transmit data. Distributed nature
    of blockchain allowing secure data storage: Since the blockchain architecture
    is distributed in nature, it can avoid the risk of being a single point of failure
    as is faced by various IoT applications based on the cloud. Irrespective of the
    distance between the devices, the data generated by them can be easily stored
    on the blockchain in a secure manner [112]. Data encryption using the hash key
    and verified by miners: In blockchain, only the 256-bit hash key for the data
    can be stored, rather than storing the actual data. The actual data can be stored
    on the cloud and the hash key can be mapped with the original data. If there is
    any change in the data, the hash of the data will change. This makes the data
    secure and private. The size of blockchain will also not get affected by the size
    of the data as only the hash values are stored in the chain. Only the intended
    parties, who are authorized to use that data can access the data from the cloud
    using the hash of the data. Every set of data being stored on blockchain is properly
    verified by different miners in the network, and therefore the probability of
    storing corrupt data from the devices reduces by using blockchain as a solution.
    Prevention from data loss and spoofing attacks: In spoofing attacks on IoT applications,
    a new adversary node enters into the IoT network and starts imitating to be the
    part of the original network. By spoofing, the adversary can easily capture, observe
    or inject data in the network. Blockchain acts as a promising solution to prevent
    such attacks. Each legitimate user or device is registered on blockchain, and
    devices can easily identify and authenticate each other without the need for central
    brokers or certification authorities [113]. Being low powered in nature, IoT devices
    inherit the risk of losing data. There might be cases where due to some external
    environmental issues the data is lost by both the sender and the receiver. Use
    of blockchain can prevent such losses as once the block is added in the chain
    there is no way to remove it [114]. Blockchain to prevent unauthorized access:
    Many IoT applications involve a lot of frequent communication between various
    nodes. The communication in blockchain takes place using the public and private
    keys, and therefore only the intended party or node can access the data. Even
    if the unintended party is able to access the data, the contents of the data will
    be incomprehensible as the data is encrypted with keys. Therefore, the blockchain
    data structure tries to handle various security issues faced by IoT applications.
    Proxy-based architecture in blockchain for resource-constrained devices: Although
    blockchain provides various security features for a distributed environment, IoT
    has a specific challenge of resource constraints. Being highly resource-constrained,
    IoT devices cannot store large ledgers. There have been various works in this
    direction to facilitate the use of blockchain in IoT. Proxy-based architecture
    is one of the promising solutions that can help IoT devices to use blockchain.
    Proxy servers can be deployed in the network, to store the resources in an encrypted
    form. The encrypted resources can be downloaded by the client from the proxy servers
    [115]. Elimination of centralized cloud servers: Blockchain can enhance the security
    of IoT systems because it ultimately eliminates the centralized cloud servers
    and makes the network peer-to-peer. Centralized cloud servers are the prime target
    of the data thieves. Using blockchain, the data will be distributed among all
    the nodes of the network and will be encrypted using a cryptographic hash function.
    TABLE 4 Challenges in IoT and Possible Blockchain Solution C. Merkle Tree Merkle
    tree is an add-on that can be added to the blockchain data structure to enhance
    the security of IoT devices. This can also help in reducing the overall number
    of blocks being added in the chain. A Merkle tree is like a binary tree where
    every node contains two child nodes except the leaf nodes. The leaf nodes contain
    the data or transactions, and the roots are the hash values of the data on the
    leaf nodes [116]. Based on the size of the tree, multiple transactions can be
    combined to generate a single root hash. Rather than treating each transaction
    as a block, each root hash can be considered as a block in the chain. This can
    help us in reducing the number of blocks. Also, due to multiple levels of hashing,
    at every level in the tree, the security of the data is enhanced [117]. IoT devices
    involve a lot of small communications among each other and therefore using Merkle
    tree along with blockchain can be a promising solution [118]. D. IOTA IOTA is
    another upcoming and highly promising solution to secure IoT. IOTA is also a DLT
    (Distributed Ledger Technology) as blockchain. IOTA is specially designed for
    resource-constrained IoT devices. Every incoming request in the network is required
    to validate the previous two requests. Using this process of cumulative validations,
    IOTA can provide a high level of security at the device or edge level. The tip
    selection algorithm is used for request verification. A cumulative weight is created
    for all requests. Higher the weight of a device in the network, more secure the
    device is. IOTA uses a tangle data structure as compared to the chain data structure
    in blockchain [119]. SECTION VI. IoT Security Using Fog Computing A. Evolution
    of Fog From Cloud IoT and cloud computing are two independent technologies which
    have many applications. IoT has provided users with a large number of smart devices
    and applications. Similarly, a cloud provides a very effective solution to store
    and manage data which can be accessed from anywhere and is widely used by many
    organizations. IoT is generating an unprecedented amount of data, which puts a
    lot of strain on the Internet infrastructure. The integration of cloud and IoT
    has introduced an era of new opportunities and challenges for processing, storing,
    managing and securing data more effectively. Industry and research groups have
    tried to solve some issues faced by the IoT by integrating it with the cloud.
    The benefits of this integration are not enough to address all the issues faced
    by IoT. Therefore, the concept of fog computing was introduced by Cisco in 2012.
    Fog computing complements cloud computing rather than replacing it. B. Fog Computing
    Architecture The main task of fog computing is to handle the data generated by
    IoT devices locally for better management and thus requires an architecture consisting
    of different layers. It has two frameworks that are Fog-Device framework and Fog-Cloud-Device
    framework [120]. The former framework consists of device and fog layer and the
    latter framework consists of device, fog and cloud layer. The arrangement of layers
    is done based on their storing and computational powers. The communication between
    different layers is done using wired (e.g., optical fiber, Ethernet) or wireless
    communication (e.g., WiFi, Bluetooth, etc.). In Fog-Device framework, the fog
    nodes provide various services to a user without involving cloud servers. However,
    in Fog-Cloud-Device framework the simple decisions are taken at the fog layer,
    whereas, the complex decisions are taken on cloud [121]. The architecture of Fog-Cloud-Device
    framework is shown in Figure 7. The authors of [122] have considered the fog computing
    architecture theoretically and mathematically while comparing the performance
    of fog computing paradigm with traditional cloud computing framework based on
    service latency and energy consumption. Fog computing reduces the data traffic
    between cloud and network edge by 90% and average response time for a user by
    20% when compared with cloud-only model [123]. Authors in [124] have discussed
    the definition and concept of fog computing in-depth, comparing it with similar
    concepts such as mobile-edge computing (MEC) and mobile cloud computing (MCC).
    Authors in [124] have also introduced some applications like real-time video analytics
    and augmented reality (AR), mobile big data analytics, and content delivery and
    caching for fog computing. FIGURE 7. Fog computing architecture. Show All C. Advantages
    of Fog Over Cloud IoT devices generate large volumes of data every day. Moving
    this data to the cloud in real-time for analysis is not feasible. Therefore, the
    concept of fog computing has been developed. Figure 7 shows the placement and
    functionality of fog layer in an IoT application. Fog computing refers to extending
    cloud computing and its services to the edge of the network. Fog computing is
    a decentralized infrastructure for analysis of data and computing and can be used
    to store and process time-sensitive data efficiently and quickly. Its main goal
    is to enhance security, prevent data thefts, minimize the data stored on the cloud
    and to increase the overall efficiency of IoT applications. The latency in fog
    computation is less than cloud computation because the fog layer is placed much
    closer to the devices than the cloud. Only the selected and important data is
    sent to the cloud for long-term storage. Fog computing applications include smart
    vehicles, smart homes, smart agriculture, health-care, smart traffic lights, smart
    retail, software-defined networks, etc. Sending the immense amount of data generated
    by IoT devices to the cloud for processing and analyzing would be costly and time-consuming.
    Along with minimizing network bandwidth requirements, fog computing also reduces
    the frequency of two-way communication between IoT devices and the cloud [125].
    In fog architecture, the data is collected at devices called fog nodes which can
    analyze 40 percent of it [126]. It offloads traffic from the core network minimizing
    the latency of IoT devices. A fog node can be any device like a router, switch,
    or a video surveillance camera which has computing, storage, and network connectivity.
    These fog nodes can be installed anywhere like on a factory floor or in a vehicle,
    provided it has a network connection. Data is directed to the fog node, aggregation
    node or cloud based on its time-sensitivity. Fog nodes make the communication
    in IoT application secure by providing cryptographic computations. Mere sensors
    and IoT devices do not always have the necessary inbuilt resources for that purpose
    [127]. D. Solutions Provided by Fog Computing to Overcome IoT Security Threats
    In regard to the attacks discussed in Section III, the solution that fog computing
    provides or can provide to overcome those security threats are discussed below.
    Man-in-the-middle attack: Fog acts as a security layer between end-user and cloud
    or IoT system. All threats or attacks on the IoT systems need to pass through
    the fog layer in between, and this layer can identify and mitigate unusual activities
    before they are passed to the system. Data transit attacks: Data storage and management
    is much better if performed on the secure fog nodes, as compared to the IoT devices.
    Data will be better protected if it is stored on the fog nodes as compared to
    storing the data on the end-user devices. Fog nodes also help in making the user
    data more available. Eavesdropping: Using fog nodes, the communication takes place
    between the end-user and the fog node only, rather than routing the information
    through the entire network. The chances of an adversary trying to eavesdrop reduces
    a lot because the traffic on the network is reduced. Resource-constraint issues:
    Most of the IoT devices are resource constrained and the attackers take advantage
    of this fact. They try to damage the edge devices and use them as the weak links
    to enter the system. Fog nodes can support the edge devices and can prevent them
    from being affected by such attacks. A nearby fog node can perform the more sophisticated
    security functions necessary for protection. Incident response services: Fog nodes
    can be programmed to provide real-time incident response services. Fog nodes can
    generate a flag to the IoT system or the end users as soon as they encounter a
    suspicious data or request. Fog computing allows for malware detection and problem
    resolution in transit. In many critical applications, it might not be possible
    to stop the entire system to resolve malware incidences. Fog nodes can help in
    such resolutions while the system is up and running. E. Security Challenges and
    Solutions in Fog Layer Although fog layer provides various features and security
    aspects for IoT applications, the movement of data and computation to fog layer
    creates new vulnerabilities [120]. Therefore, before implementing fog-assisted
    IoT applications, these security and privacy goals of fog computing are required
    to be studied. In this section, various features provided by fog layer, privacy
    and security challenges faced, and proposed solutions to overcome them are discussed.
    Table 5 summarizes these issues and proposed solutions. Real-Time Services: Fog
    computing tends to provide a near real-time service in the IoT systems by performing
    computation near the data generation points. Intrusion detection: Policy violations
    and malicious activities on fog nodes and IoT devices will not be discovered if
    no proper intrusion detection mechanism is implemented. The attacks might not
    impact the whole architecture of fog computing, but the attacker can control the
    local services. Attacks targeting local services can be detected by fog nodes
    by collaborating with their adjacent nodes. By observing program behavior and
    host file systems, the attack on the cloud can be detected [163]. Identity authentication:
    There are various entities involved in the process of offering and accessing real-time
    services like fog nodes, service providers and users. Trusting all the entities
    involved is an arduous task, and creates security challenges for IoT services
    and user’s data. Accessibility of services should be given only to authentic and
    credible users; otherwise, attackers may compromise the server and exploit services
    and user privacy. Therefore, to prevent attackers from illegitimately accessing
    services, identity authentication mechanisms are needed. To provide secure services,
    some efficient identity authentication mechanisms have been proposed in the past
    [146]–[149], [164], [165]. Transient Storage: Users can store and maintain their
    data on fog nodes temporarily with the help of transient storage. On the one hand,
    it helps in managing data easily on local storage, but on the other hand, it creates
    new challenges and security issues, especially for maintaining data privacy. Identifying
    and protecting sensitive data: Data stored in IoT devices may include social events,
    traffic conditions, personal activities, temperature and so on. Some of the data
    might be personal or sensitive while some data may be made public. Furthermore,
    for different users, the same data has different security levels. Therefore, it
    is important to identify and protect the sensitive data from the large volume
    of information. Sharing data securely: To provide security, data uploaded on fog
    nodes is first encrypted. No one other than its owner can read that data once
    it is encrypted. This creates a problem for data sharing. To overcome this challenge,
    some cryptographic techniques such as key-aggregate encryption, proxy re-encryption,
    and attribute-sharing, have been proposed in [166]. Data Dissemination: The data
    cannot be transferred to the fog node without encryption, due to security issues.
    Due to this movement of encrypted data to the fog node, many desirable features
    are sacrificed such as sharing, searching, and aggregation. Searching data securely:
    As discussed in transient storage, data is encrypted before uploading. However,
    once it is encrypted, searching or retrieving on the ciphertext becomes difficult
    for owners as well as other entities. In order to retrieve the information from
    encrypted text, search-able encryption and its privacy levels are defined in [145].
    A dynamic symmetric search-able scheme is introduced in [167]. Data aggregation:
    Fog nodes might need to aggregate the data in certain cases to prevent data leakage
    and reduce communication overhead. It is important to develop secure aggregation
    algorithms to prevent data thefts. Various homomorphic encryption schemes, such
    as BGN encryption [168] and Paillier encryption [169], have been proposed to achieve
    secure data aggregation. Decentralized Computation: The data stored on the fog
    nodes can be processed and analyzed for better results. However, such computations
    have several threats and risks associated with them. For example, attackers can
    not only control the analyzed results, but can also expose processed data. Server-aided
    computation: Tasks which cannot be executed by IoT devices themselves are computed
    with the help of fog nodes. However, this can lead to exposure of data to attackers,
    if the fog nodes which received data from IoT are already compromised. Server-aided
    computation is one such method whose aim is to provide secure computation [131].
    Verifiable computation: Users rely on the fog nodes to compute their data. There
    must be a secure mechanism to verify the computation results coming from the fog
    node. Authors in [170], [171] have proposed certain multi-user mechanisms that
    help with verifiable computation. TABLE 5 Characteristics and Solutions Provided
    by Fog Computing SECTION VII. IoT Security Using Machine Learning The area of
    machine learning (ML) has attracted significant interest over recent years. Many
    domains are using ML for their development, and it is being used for IoT security
    as well. ML appears to be a promising solution to protect IoT devices against
    cyber attacks by providing a different approach for defending against attacks
    as compared to other traditional methods. A. Solutions Provided by ML to Overcome
    Security Threats In regard to the attacks discussed in Section III, the solutions
    provided by ML to overcome these security threats are discussed below. DoS Attack:
    DoS attacks on IoT devices or originating from IoT devices are a serious concern.
    One approach to prevent such attacks is to use a Multi-Layer Perceptron (MLP)
    based protocol that secures networks against DoS attacks [172]. The authors of
    [173] have proposed a particle swarm optimization and back propagation algorithm
    to train a MLP that helps in enhancing the security of wireless networks. ML techniques
    help in increasing the deduction accuracy and securing IoT devices vulnerable
    to DoS attacks. Eavesdropping: Attackers may eavesdrop on messages during data
    transmission. To provide protection from such attacks, ML techniques such as Q-learning
    based offloading strategy [174] or non-parametric Bayesian techniques [175] can
    be used. Schemes such as Q-learning and Dyna-Q are ML techniques that may also
    be used to protect devices from eavesdropping. Evaluation of these schemes via
    experiments and reinforcement learning is presented in [176]. Spoofing: Attacks
    from spoofers can be avoided by using Q-learning [176], Dyna-Q [176], Support
    Vector Machines (SVM) [177], Deep Neural Network (DNN) model [178], incremental
    aggregated gradient (IAG) [46], and distributed FrankWolfe (dFW) [179] techniques.
    These techniques not only increase the detection accuracy and classification accuracy
    but also help in reducing the average error rate and false alarm rate. Privacy
    Leakage: Collection of personal information such as health data, location, or
    photos puts the user’s privacy at stake. Privacy-preserving scientific computations
    (PPSC) [180] should be employed for preventing privacy leakage. A commodity integrity
    detection algorithm (CIDA) which is based on the Chinese remainder theorem (CRT)
    is another technique that has been proposed to develop IoT application trust [181].
    Digital Fingerprinting: Digital fingerprinting is one of the upcoming and promising
    solutions to secure IoT systems and to help the end users gain sufficient trust
    in the applications. Fingerprints are being widely used to unlock smartphones,
    approve payments, unlock the car and home doors, etc. Due to its low cost, reliability,
    acceptability and high-security level, digital fingerprinting is emerging as a
    dominant bio-metric identification method [182]. Apart from the benefits of digital
    fingerprinting, there are various challenges to efficiently use this technique
    in IoT, such as fingerprint classification, image enhancement, feature matching,
    etc. Various machine learning based algorithms have been developed to provide
    some non-traditional solutions to overcome these challenges [183], some of which
    are discussed below. Support Vector Machine: SVM is a training algorithm for non-linear
    and linear classifications, principal component analysis, text categorization,
    speaker identification, and regression. It maximizes the gap between the decision
    boundary and training patterns. Authors of [184] have discussed the use of SVM
    in digital fingerprinting in detail. They have also compared it with other traditional
    models. A feature vector is built based on pixel values of the fingerprint, and
    it is used to train the SVM. Various patterns behind the fingerprint are analyzed,
    and then the matching of a fingerprint is done based on patterns identified. Artificial
    Neural Networks: ANN is one of the most commonly used algorithms in the machine
    learning. It offers many advantages like fault tolerance, adaptive learning, and
    generalization. In [185] a framework has been proposed for using ANN to identify
    fingerprints digitally. The digital values of various features in the fingerprint
    like minutiae, ridge ending, and bifurcation is applied as the input to the neural
    network for training purpose using back propagation algorithm of ANN. The verification
    of the fingerprint is done based on the previous experiential values stored in
    the database. The fundamental need in IoT is to secure all the systems and devices
    that are connected to the network. The role of ML is to use and train algorithms
    to detect anomalies in IoT devices or to detect any unwanted activity taking place
    in IoT system to prevent data loss or other issues. Therefore, ML provides a promising
    platform to overcome the difficulties faced in securing IoT devices. Further contributions
    in this field are required to maintain the growth of IoT. SECTION VIII. IoT Security
    Using Edge Computing Edge and fog computing are both extensions of cloud computing
    which is widely used by various organizations. Cloud, fog and edge may appear
    similar but they constitute different layers of IoT applications. The main difference
    between cloud, fog and edge computing is the location of intelligence and power
    computation. The cloud is deployed at a much larger scale that needs to process
    huge amount of data and is situated at comparatively more distance from its users
    [186]. To overcome the problems faced by cloud computing, edge computing is used
    as a solution where a small edge server is placed between the user and the cloud/fog.
    Some processing activity is performed at the edge server, rather than the cloud.
    Edge computing architecture consists of edge devices, cloud server and fog nodes
    as shown in Figure 8 [187]. FIGURE 8. Edge computing architecture. Show All In
    an edge computing framework the computation and analysis power is provided at
    the edge itself. The devices in an application can create a network among themselves
    and can cooperate among each other to compute the data [63]. Consequently, a lot
    of data can be saved from going outside the device, either to cloud or to fog
    nodes, and this can enhance the security of the IoT application. Edge computing
    also helps in providing low communication cost by preventing the need of moving
    all the data to the cloud [66]. A. Using Edge Computing to Secure and Improve
    IoT In regard to the attacks discussed in Section III, the solutions that edge
    computing provides or can provide to overcome these security threats are discussed
    below. Data Breaches: In edge computing, all the data is stored and processed
    within the device or local network. There is no movement of the data from the
    data originator to the processor. This prevents the data from being in transit
    and thereby prevents the risk of data thefts and data breaches. In fog computing
    there is some movement of data from a device to fog layer and adversaries can
    take advantage of this movement [188]. Data Compliance Issues: Many countries
    have strict regulatory acts to prevent data movement outside their boundaries,
    e.g., European Union’s GDPR (General Data Protection Regulation). Using edge computing,
    organizations can keep the data within their borders and ensure compliance with
    data sovereignity laws [189]. Safety Issues: With the increase in the deployment
    of cyber-physical systems, security and safety are considered as integral issues.
    If there is even a little delay in responses, then that may lead to physical safety
    issues. For example, if the sensors in a car predict that a crash is about to
    happen, then the airbags have to be deployed immediately. If the sensors completely
    rely on sending all the data to the cloud and waiting for the response from the
    cloud to perform any action, then that may be too late to prevent injuries or
    loss of life. Surveillance cameras can also be empowered using edge computing
    and they can themselves analyze the anomalies and can send the summarized and
    suspected data to the data centers to achieve faster response times. Bandwidth
    Issues: IoT application generate a lot of data at very high rate. Most of this
    data is raw and of relatively low-value. Sending all the data to the cloud involves
    a lot of bandwidth cost as well, along with the security challenges of data movement.
    If edge computing is used, then a lot of data cleaning and aggregation can be
    done at the edge nodes and only the summarized data, if required, needs to be
    sent to the cloud [190]. B. Challenges in Edge Layer Although edge computing provides
    various features to increase the security and performance of IoT applications,
    there are various challenges associate with completely relying on the edge layer
    for all computation. Edge devices include sensors, RFID devices, actuators, tags,
    and embedded devices. The edge layer is highly susceptible to attacks in an IoT
    system. If the edge layer is compromised, then the entire system may be compromised.
    MQTT and COAP are the most popular protocols for the edge layer. Both these protocols
    do not use any security layer by default. Although the option to add an optional
    security layer in the form of TLS for MQTT and DTLS for COAP is present, it creates
    additional overhead in terms of processing and bandwidth. Issues specific to edge
    devices include sleep deprivation attacks, battery draining attacks, and outage
    attacks. Edge devices are typically resource constrained, and the most important
    resource they rely upon is the battery backup. The foremost and easiest way to
    attack the edge devices is to somehow deplete the battery of an edge device. For
    example, an attacker might force the edge device to do some power hungry or infinite
    loop computation [191]. The process of striking a balance between storing and
    processing data on edge or cloud is very important. Keeping too much data on edge
    may also lead to overwhelming of the edge devices and may impact the entire application.
    SECTION IX. Open Issues, Challenges, and Future Research Directions There are
    some performance and security issues in the use of blockchain, fog computing,
    edge computing and machine learning for IoT security that are yet to be solved.
    This section discusses some of these issues. The security of blockchain depends
    on its method of implementation and the use of software and hardware in that implementation.
    Since all the transactions made by users in blockchain are public, there is a
    possibility that private information of users can be revealed. Also, as the number
    of miners increases, the size of blockchain also increases continuously. This
    increases the cost of storage and reduces the speed of distribution over the whole
    network, giving rise to issues like scalability and availability of blockchain
    [192]. Since fog computing is a nontrivial extension of cloud computing, some
    of the issues such as security and privacy will continue to persist [120]. Therefore,
    before implementing fog-assisted IoT applications, these security and privacy
    goals of fog computing are required to be studied. Some of the challenges and
    research issues on security and privacy in IoT environments and the solutions
    provided by fog computing are discussed in [127]. There are many machine learning
    algorithms in existence. Therefore, it is imperative to select a proper algorithm
    suitable for the application. Selecting a wrong algorithm would result in producing
    “garbage” output and will lead to loss of effort, effectiveness and accuracy.
    Similarly, choosing the wrong data set will lead to “garbage” input producing
    incorrect results. The success of a machine learning solution depends on these
    factors as well as diversity in selecting data. If the data is not clustered and
    classified, the prediction accuracy will be lower. Also, the historical data may
    contain many ambiguous values, outliers, missing values, and meaningless data.
    IoT applications are creating a huge amount of data, and therefore it is a difficult
    task to clean and preprocess that data accurately. Various features like attribute
    creation, linear regression, multiple regression, removing redundancies and compressing
    data are required to effectively use machine learning for securing the IoT. In
    case of edge computing, data security and user privacy are the main concerns.
    An user’s private data can be leaked and misused if a house that is deployed with
    IoT devices is subjected to cyber attacks. For example, a person’s presence or
    absence at home can be revealed simply by observing the electricity or water usage
    data. Since the data is computed at the edge of data resource (e.g., home), therefore,
    the user has to be aware of some of the measures like securing WiFi connections.
    Secondly, data at edge should be owned fully by the user, and he/she should have
    control on which data to be shared. Some of the future research directions in
    this field are: The edge devices are most resource constrained devices in the
    IoT and are therefore uniquely vulnerable to attacks. Penetration studies show
    that while it takes very little power to implement best practice security for
    the edge nodes, they are still highly vulnerable to a variety of malicious attacks.
    The gateways between different layers in the IoT system need to be secured. Gateways
    provide an easy entry point for the attackers into the IoT system. End to end
    encryption, rather than specific encryption techniques for specific protocols
    would be a promising solution to secure the data passing through the gateways.
    The data should be decrypted only at the intended destination and not at the gateways
    for protocol translation. Inter-fog sharing of resources is one of the areas where
    further work needs to be done. As of now, when the fog layer is unable to process
    the requests due to heavy load, the requests are forwarded to the cloud. There
    can be resource sharing between neighboring fog layers to prevent unwanted requests
    to be transferred to the cloud. The current blockchain architecture is highly
    limited in terms of the number of nodes in permissioned networks and in terms
    of throughput in permissionless networks. Various consensus algorithms are being
    designed to support high throughput along with a large number of nodes or users.
    Fog layer can be made more intelligent using various ML and AI techniques. Fog
    layer must be able to decide the duration for which the data in the fog should
    be retained and when the data should be discarded or shifted to the cloud for
    prolonged storage. More efficient and reliable consensus mechanisms can be designed
    to reach consensus among the nodes along with preventing rampant use of computation
    power. The current consensus algorithms are highly resource hungry and less efficient.
    The tamper-proof feature of blockchain is ending up into a collection of a lot
    of garbage data and addresses. There is a lot of invalid data that is never deleted
    like the addresses of the destructed smart contracts. This affects the performance
    of the overall application and better ways need to be designed to efficiently
    handle the garbage data in the blockchain. Data analysis in near real-time and
    in the proximity of the IoT node is crucial for successful deployment of IoT applications.
    Various ML-based algorithms can be designed to analyze the data in the node itself
    to prevent the data transit for analysis. This can further enhance the security
    of the application by preventing data movement. SECTION X. Conclusion In this
    survey, we have presented various security threats at different layers of an IoT
    application. We have covered the issues related to the sensing layer, network
    layer, middleware layer, gateways, and application layer. We have also discussed
    the existing and upcoming solutions to IoT security threats including blockchain,
    fog computing, edge computing, and machine learning. Various open issues and issues
    that originate from the solution itself have also been discussed. The state-of-the-art
    of IoT security has also been discussed with some of the future research directions
    to enhance the security levels is IoT. This survey is expected to serve as a valuable
    resource for security enhancement for upcoming IoT applications. Authors Figures
    References Citations Keywords Metrics More Like This A Survey on Security and
    Privacy Issues in Edge-Computing-Assisted Internet of Things IEEE Internet of
    Things Journal Published: 2021 The Performance Evaluation of Blockchain-Based
    Security and Privacy Systems for the Internet of Things: A Tutorial IEEE Internet
    of Things Journal Published: 2021 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/8600701/08742551.pdf
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: 'A Survey on IoT Security: Application Areas, Security Threats, and Solution
    Architectures'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1155/2017/9324035
  analysis: '>'
  authors:
  - Pallavi Sethi
  - Smruti R. Sarangi
  citation_count: 910
  full_citation: '>'
  full_text: ">\nReview Article\nInternet of Things: Architectures, Protocols, and\
    \ Applications\nPallavi Sethi and Smruti R. Sarangi\nDepartment of Computer Science,\
    \ IIT Delhi, New Delhi, India\nCorrespondence should be addressed to Smruti R.\
    \ Sarangi; srsarangi@cse.iitd.ac.in\nReceived 12 August 2016; Accepted 18 December\
    \ 2016; Published 26 January 2017\nAcademic Editor: Rajesh Khanna\nCopyright ©\
    \ 2017 Pallavi Sethi and Smruti R. Sarangi. This is an open access article distributed\
    \ under the Creative Commons\nAttribution License, which permits unrestricted\
    \ use, distribution, and reproduction in any medium, provided the original work\
    \ is\nproperly cited.\nThe Internet of Things (IoT) is defined as a paradigm in\
    \ which objects equipped with sensors, actuators, and processors\ncommunicate\
    \ with each other to serve a meaningful purpose. In this paper, we survey state-of-the-art\
    \ methods, protocols, and\napplications in this new emerging area. This survey\
    \ paper proposes a novel taxonomy for IoT technologies, highlights some of\nthe\
    \ most important technologies, and profiles some applications that have the potential\
    \ to make a striking difference in human\nlife, especially for the differently\
    \ abled and the elderly. As compared to similar survey papers in the area, this\
    \ paper is far more\ncomprehensive in its coverage and exhaustively covers most\
    \ major technologies spanning from sensors to applications.\n1. Introduction\n\
    Today the Internet has become ubiquitous, has touched\nalmost every corner of\
    \ the globe, and is affecting human life in\nunimaginable ways. However, the journey\
    \ is far from over. We\nare now entering an era of even more pervasive connectivity\n\
    where a very wide variety of appliances will be connected to\nthe web. We are\
    \ entering an era of the “Internet of Things”\n(abbreviated as IoT). This term\
    \ has been defined by different\nauthors in many different ways. Let us look at\
    \ two of the most\npopular definitions. Vermesan et al. [1] define the Internet\n\
    of Things as simply an interaction between the physical and\ndigital worlds. The\
    \ digital world interacts with the physical\nworld using a plethora of sensors\
    \ and actuators. Another\ndefinition by Pe˜na-L´opez et al. [2] defines the Internet\
    \ of\nThings as a paradigm in which computing and networking\ncapabilities are\
    \ embedded in any kind of conceivable object.\nWe use these capabilities to query\
    \ the state of the object and to\nchange its state if possible. In common parlance,\
    \ the Internet\nof Things refers to a new kind of world where almost all\nthe\
    \ devices and appliances that we use are connected to a\nnetwork. We can use them\
    \ collaboratively to achieve complex\ntasks that require a high degree of intelligence.\n\
    For this intelligence and interconnection, IoT devices are\nequipped with embedded\
    \ sensors, actuators, processors, and\ntransceivers. IoT is not a single technology;\
    \ rather it is an\nagglomeration of various technologies that work together in\n\
    tandem.\nSensors and actuators are devices, which help in interact-\ning with\
    \ the physical environment. The data collected by the\nsensors has to be stored\
    \ and processed intelligently in order to\nderive useful inferences from it. Note\
    \ that we broadly define\nthe term sensor; a mobile phone or even a microwave\
    \ oven\ncan count as a sensor as long as it provides inputs about its\ncurrent\
    \ state (internal state + environment). An actuator is a\ndevice that is used\
    \ to effect a change in the environment such\nas the temperature controller of\
    \ an air conditioner.\nThe storage and processing of data can be done on the\n\
    edge of the network itself or in a remote server. If any prepro-\ncessing of data\
    \ is possible, then it is typically done at either\nthe sensor or some other proximate\
    \ device. The processed\ndata is then typically sent to a remote server. The storage\n\
    and processing capabilities of an IoT object are also restricted\nby the resources\
    \ available, which are often very constrained\ndue to limitations of size, energy,\
    \ power, and computational\ncapability. As a result the main research challenge\
    \ is to\nensure that we get the right kind of data at the desired level\nof accuracy.\
    \ Along with the challenges of data collection,\nand handling, there are challenges\
    \ in communication as\nwell. The communication between IoT devices is mainly\n\
    wireless because they are generally installed at geographically\ndispersed locations.\
    \ The wireless channels often have high\nHindawi\nJournal of Electrical and Computer\
    \ Engineering\nVolume 2017, Article ID 9324035, 25 pages\nhttps://doi.org/10.1155/2017/9324035\n\
    2\nJournal of Electrical and Computer Engineering\nApplication \nlayer\nNetwork\n\
    layer\nPerception\nlayer\nBusiness layer\nApplication layer\nProcessing layer\n\
    Transport layer\nPerception layer\nA\nB\nFigure 1: Architecture of IoT (A: three\
    \ layers) (B: five layers).\nrates of distortion and are unreliable. In this scenario\
    \ reliably\ncommunicating data without too many retransmissions is an\nimportant\
    \ problem and thus communication technologies\nare integral to the study of IoT\
    \ devices.\nNow, after processing the received data, some action\nneeds to be\
    \ taken on the basis of the derived inferences. The\nnature of actions can be\
    \ diverse. We can directly modify the\nphysical world through actuators. Or we\
    \ may do something\nvirtually. For example, we can send some information to other\n\
    smart things.\nThe process of effecting a change in the physical world\nis often\
    \ dependent on its state at that point of time. This\nis called context awareness.\
    \ Each action is taken keeping in\nconsideration the context because an application\
    \ can behave\ndifferently in different contexts. For example, a person may\nnot\
    \ like messages from his office to interrupt him when he is\non vacation.\nSensors,\
    \ actuators, compute servers, and the commu-\nnication network form the core infrastructure\
    \ of an IoT\nframework. However, there are many software aspects that\nneed to\
    \ be considered. First, we need a middleware that can\nbe used to connect and\
    \ manage all of these heterogeneous\ncomponents. We need a lot of standardization\
    \ to connect\nmany different devices. We shall discuss methods to exchange\ninformation\
    \ and prevailing standards in Section 7.\nThe Internet of Things finds various\
    \ applications in health\ncare, fitness, education, entertainment, social life,\
    \ energy\nconservation, environment monitoring, home automation,\nand transport\
    \ systems. We shall focus on these application\nareas in Section 9. We shall find\
    \ that, in all these application\nareas, IoT technologies have significantly been\
    \ able to reduce\nhuman effort and improve the quality of life.\n2. Architecture\
    \ of IoT\nThere is no single consensus on architecture for IoT, which\nis agreed\
    \ universally. Different architectures have been pro-\nposed by different researchers.\n\
    2.1. Three- and Five-Layer Architectures. The most basic\narchitecture is a three-layer\
    \ architecture [3–5] as shown in\nFigure 1. It was introduced in the early stages\
    \ of research in\nthis area. It has three layers, namely, the perception, network,\n\
    and application layers.\n(i) The perception layer is the physical layer, which\
    \ has\nsensors for sensing and gathering information about\nthe environment. It\
    \ senses some physical parameters\nor identifies other smart objects in the environment.\n\
    (ii) The network layer is responsible for connecting to\nother smart things, network\
    \ devices, and servers. Its\nfeatures are also used for transmitting and processing\n\
    sensor data.\n(iii) The application layer is responsible for delivering\napplication\
    \ specific services to the user. It defines\nvarious applications in which the\
    \ Internet of Things\ncan be deployed, for example, smart homes, smart\ncities,\
    \ and smart health.\nThe three-layer architecture defines the main idea of the\n\
    Internet of Things, but it is not sufficient for research on\nIoT because research\
    \ often focuses on finer aspects of the\nInternet of Things. That is why, we have\
    \ many more layered\narchitectures proposed in the literature. One is the five-\n\
    layer architecture, which additionally includes the processing\nand business layers\
    \ [3–6]. The five layers are perception,\ntransport, processing, application,\
    \ and business layers (see\nFigure 1). The role of the perception and application\
    \ layers\nis the same as the architecture with three layers. We outline\nthe function\
    \ of the remaining three layers.\n(i) The transport layer transfers the sensor\
    \ data from\nthe perception layer to the processing layer and vice\nversa through\
    \ networks such as wireless, 3G, LAN,\nBluetooth, RFID, and NFC.\n(ii) The processing\
    \ layer is also known as the middleware\nlayer. It stores, analyzes, and processes\
    \ huge amounts\nof data that comes from the transport layer. It can\nmanage and\
    \ provide a diverse set of services to the\nlower layers. It employs many technologies\
    \ such as\ndatabases, cloud computing, and big data processing\nmodules.\nJournal\
    \ of Electrical and Computer Engineering\n3\n(iii) The business layer manages\
    \ the whole IoT system,\nincluding applications, business and profit models,\n\
    and users’ privacy. The business layer is out of the\nscope of this paper. Hence,\
    \ we do not discuss it\nfurther.\nAnother architecture proposed by Ning and Wang\
    \ [7] is\ninspired by the layers of processing in the human brain. It\nis inspired\
    \ by the intelligence and ability of human beings\nto think, feel, remember, make\
    \ decisions, and react to the\nphysical environment. It is constituted of three\
    \ parts. First is\nthe human brain, which is analogous to the processing and\n\
    data management unit or the data center. Second is the spinal\ncord, which is\
    \ analogous to the distributed network of data\nprocessing nodes and smart gateways.\
    \ Third is the network\nof nerves, which corresponds to the networking components\n\
    and sensors.\n2.2. Cloud and Fog Based Architectures. Let us now discuss\ntwo\
    \ kinds of systems architectures: cloud and fog computing\n(see the reference\
    \ architectures in [8]). Note that this classifi-\ncation is different from the\
    \ classification in Section 2.1, which\nwas done on the basis of protocols.\n\
    In particular, we have been slightly vague about the nature\nof data generated\
    \ by IoT devices, and the nature of data\nprocessing. In some system architectures\
    \ the data processing\nis done in a large centralized fashion by cloud computers.\n\
    Such a cloud centric architecture keeps the cloud at the\ncenter, applications\
    \ above it, and the network of smart things\nbelow it [9]. Cloud computing is\
    \ given primacy because it\nprovides great flexibility and scalability. It offers\
    \ services such\nas the core infrastructure, platform, software, and storage.\n\
    Developers can provide their storage tools, software tools,\ndata mining, and\
    \ machine learning tools, and visualization\ntools through the cloud.\nLately,\
    \ there is a move towards another system archi-\ntecture, namely, fog computing\
    \ [10–12], where the sensors\nand network gateways do a part of the data processing\
    \ and\nanalytics. A fog architecture [13] presents a layered approach\nas shown\
    \ in Figure 2, which inserts monitoring, prepro-\ncessing, storage, and security\
    \ layers between the physical\nand transport layers. The monitoring layer monitors\
    \ power,\nresources, responses, and services. The preprocessing layer\nperforms\
    \ filtering, processing, and analytics of sensor data.\nThe temporary storage\
    \ layer provides storage functionalities\nsuch as data replication, distribution,\
    \ and storage. Finally, the\nsecurity layer performs encryption/decryption and\
    \ ensures\ndata integrity and privacy. Monitoring and preprocessing are\ndone\
    \ on the edge of the network before sending data to the\ncloud.\nOften the terms\
    \ “fog computing” and “edge computing”\nare used interchangeably. The latter term\
    \ predates the former\nand is construed to be more generic. Fog computing originally\n\
    termed by Cisco refers to smart gateways and smart sensors,\nwhereas edge computing\
    \ is slightly more penetrative in nature.\nThis paradigm envisions adding smart\
    \ data preprocessing\ncapabilities to physical devices such as motors, pumps,\
    \ or\nlights. The aim is to do as much of preprocessing of data\nas possible in\
    \ these devices, which are termed to be at the\nStorage layer \nPreprocessing\
    \ layer \nMonitoring layer \nPhysical layer\nSecurity layer\nTransport layer\n\
    Figure 2: Fog architecture of a smart IoT gateway.\nedge of the network. In terms\
    \ of the system architecture,\nthe architectural diagram is not appreciably different\
    \ from\nFigure 2. As a result, we do not describe edge computing\nseparately.\n\
    Finally, the distinction between protocol architectures\nand system architectures\
    \ is not very crisp. Often the protocols\nand the system are codesigned. We shall\
    \ use the generic 5-\nlayer IoT protocol stack (architectural diagram presented\
    \ in\nFigure 2) for both the fog and cloud architectures.\n2.3. Social IoT. Let\
    \ us now discuss a new paradigm: social IoT\n(SIoT). Here, we consider social\
    \ relationships between objects\nthe same way as humans form social relationships\
    \ (see [14]).\nHere are the three main facets of an SIoT system:\n(i) The SIoT\
    \ is navigable. We can start with one device\nand navigate through all the devices\
    \ that are con-\nnected to it. It is easy to discover new devices and\nservices\
    \ using such a social network of IoT devices.\n(ii) A need of trustworthiness\
    \ (strength of the relation-\nship) is present between devices (similar to friends\
    \ on\nFacebook).\n(iii) We can use models similar to studying human social\nnetworks\
    \ to also study the social networks of IoT\ndevices.\n2.3.1. Basic Components.\
    \ In a typical social IoT setting, we\ntreat the devices and services as bots\
    \ where they can set up\nrelationships between them and modify them over time.\
    \ This\nwill allow us to seamlessly let the devices cooperate among\neach other\
    \ and achieve a complex task.\nTo make such a model work, we need to have many\n\
    interoperating components. Let us look at some of the major\ncomponents in such\
    \ a system.\n(1) ID: we need a unique method of object identifica-\ntion. An ID\
    \ can be assigned to an object based on\ntraditional parameters such as the MAC\
    \ ID, IPv6\nID, a universal product code, or some other custom\nmethod.\n4\nJournal\
    \ of Electrical and Computer Engineering\n(2) Metainformation: along with an ID,\
    \ we need some\nmetainformation about the device that describes its\nform and\
    \ operation. This is required to establish\nappropriate relationships with the\
    \ device and also\nappropriately place it in the universe of IoT devices.\n(3)\
    \ Security controls: this is similar to “friend list” set-\ntings on Facebook.\
    \ An owner of a device might place\nrestrictions on the kinds of devices that\
    \ can connect\nto it. These are typically referred to as owner controls.\n(4)\
    \ Service discovery: such kind of a system is like\na service cloud, where we\
    \ need to have dedicated\ndirectories that store details of devices providing\n\
    certain kinds of services. It becomes very important\nto keep these directories\
    \ up to date such that devices\ncan learn about other devices.\n(5) Relationship\
    \ management: this module manages rela-\ntionships with other devices. It also\
    \ stores the types\nof devices that a given device should try to connect\nwith\
    \ based on the type of services provided. For\nexample, it makes sense for a light\
    \ controller to make\na relationship with a light sensor.\n(6) Service composition:\
    \ this module takes the social IoT\nmodel to a new level. The ultimate goal of\
    \ having such\na system is to provide better integrated services to\nusers. For\
    \ example, if a person has a power sensor\nwith her air conditioner and this device\
    \ establishes\na relationship with an analytics engine, then it is\npossible for\
    \ the ensemble to yield a lot of data about\nthe usage patterns of the air conditioner.\
    \ If the social\nmodel is more expansive, and there are many more\ndevices, then\
    \ it is possible to compare the data with\nthe usage patterns of other users and\
    \ come up with\neven more meaningful data. For example, users can\nbe told that\
    \ they are the largest energy consumers in\ntheir community or among their Facebook\
    \ friends.\n2.3.2. Representative Architecture. Most architectures pro-\nposed\
    \ for the SIoT have a server side architecture as well.\nThe server connects to\
    \ all the interconnected components,\naggregates (composes) the services, and\
    \ acts as a single point\nof service for users.\nThe server side architecture\
    \ typically has three layers. The\nfirst is the base layer that contains a database\
    \ that stores details\nof all the devices, their attributes, metainformation,\
    \ and their\nrelationships. The second layer (Component layer) contains\ncode\
    \ to interact with the devices, query their status, and use\na subset of them\
    \ to effect a service. The topmost layer is the\napplication layer, which provides\
    \ services to the users.\nOn the device (object) side, we broadly have two layers.\n\
    The first is the object layer, which allows a device to connect to\nother devices,\
    \ talk to them (via standardized protocols), and\nexchange information. The object\
    \ layer passes information to\nthe social layer. The social layer manages the\
    \ execution of\nusers’ applications, executes queries, and interacts with the\n\
    application layer on the server.\n3. Taxonomy\nLet us now propose taxonomy for\
    \ research in IoT tech-\nnologies (see Figure 3). Our taxonomy is based on the\n\
    architectural elements of IoT as presented in Section 2.\nThe first architectural\
    \ component of IoT is the perception\nlayer. It collects data using sensors, which\
    \ are the most\nimportant drivers of the Internet of Things [15]. There are\n\
    various types of sensors used in diverse IoT applications.\nThe most generic sensor\
    \ available today is the smartphone.\nThe smartphone itself has many types of\
    \ sensors embedded\nin it [16] such as the location sensor (GPS), movement\nsensors\
    \ (accelerometer, gyroscope), camera, light sensor,\nmicrophone, proximity sensor,\
    \ and magnetometer. These are\nbeing heavily used in different IoT applications.\
    \ Many other\ntypes of sensors are beginning to be used such as sensors for\n\
    measuring temperature, pressure, humidity, medical param-\neters of the body,\
    \ chemical and biochemical substances, and\nneural signals. A class of sensors\
    \ that stand out is infrared\nsensors that predate smartphones. They are now being\
    \ used\nwidely in many IoT applications: IR cameras, motion detec-\ntors, measuring\
    \ the distance to nearby objects, presence of\nsmoke and gases, and as moisture\
    \ sensors. We shall discuss\nthe different types of sensors used in IoT applications\
    \ in\nSection 5.\nSubsequently, we shall discuss related work in data pre-\nprocessing.\
    \ Such applications (also known as fog comput-\ning applications) mainly filter\
    \ and summarize data before\nsending it on the network. Such units typically have\
    \ a little\namount of temporary storage, a small processing unit, and\nsome security\
    \ features.\nThe next architectural component that we shall discuss\nis communication.\
    \ We shall discuss related work (in Sec-\ntion 7) on different communication technologies\
    \ used for\nthe Internet of Things. Different entities communicate over\nthe network\
    \ [17–19] using a diverse set of protocols and\nstandards. The most common communication\
    \ technologies\nfor short range low power communication protocols are\nRFID (Radio\
    \ Frequency Identification) and NFC (Near Field\nCommunication). For the medium\
    \ range, they are Bluetooth,\nZigbee, and WiFi. Communication in the IoT world\
    \ requires\nspecial networking protocols and mechanisms. Therefore,\nnew mechanisms\
    \ and protocols have been proposed and\nimplemented for each layer of the networking\
    \ stack, accord-\ning to the requirements imposed by IoT devices.\nWe shall subsequently\
    \ look at two kinds of software com-\nponents: middleware and applications. The\
    \ middleware cre-\nates an abstraction for the programmer such that the details\n\
    of the hardware can be hidden. This enhances interoperability\nof smart things\
    \ and makes it easy to offer different kinds of\nservices [20]. There are many\
    \ commercial and open source\nofferings for providing middleware services to IoT\
    \ devices.\nSome examples are OpenIoT [21], MiddleWhere [22], Hydra\n[23], FiWare\
    \ [24], and Oracle Fusion Middleware. Finally, we\ndiscuss the applications of\
    \ IoT in Section 9. We primarily\nfocus on home automation, ambient assisted living,\
    \ health\nand fitness, smart vehicular systems, smart cities, smart\nenvironments,\
    \ smart grids, social life, and entertainment.\nJournal of Electrical and Computer\
    \ Engineering\n5\nHealth and fitness\nHome automation\nSocial life &\nentertainment\n\
    Applications\nNear field\ncommunication\nWireless sensor\nnetworks\nCommunication\n\
    (networking)\nMiddleware\nMedical sensors\nMobile phone\nsensors\nPerception\n\
    (sensors)\nSmart transport\nSmart environment\nPreprocessing\nChemical/\nbiosensors\n\
    Internet Protocol\nfor smart objects\nSmart\nagriculture\nLow power\nLink layer\n\
    Adaptation layer\nRouting Protocol\nApplication Protocol\nEnergy\nconservation\n\
    Supply chain\nand logistics\nInfrared sensors\nEnvironmental\nsensors\nLocation\
    \ sensor\nMovement sensors\nCamera\nMicrophone\nLight sensor\nProximity sensor\n\
    Magnetometer\nNeural sensors\nService oriented\nEvent based\nSemantic based\n\
    Database oriented\nApplication specific\nLow power WiFi\nZigbee\nBluetooth low\n\
    energy\nLow power\ntechnologies\nRFID and WSN\nintegration\nRFID\nFigure 3: Taxonomy\
    \ of research in IoT technologies.\n4. Related Survey Papers\nOur taxonomy describes\
    \ the technologies in the IoT domain\nand is classified on the basis of architectural\
    \ layers. We\nhave tried to cover all subareas and recent technologies in\nour\
    \ taxonomy. There have been many survey papers on the\nInternet of Things in the\
    \ past. Table 1 shows how our survey\nis different from other highly cited surveys\
    \ in the literature.\nLet us first consider our novel contributions. Our paper\n\
    looks at each and every layer in the IoT stack, and as a\nresult the presentation\
    \ is also far more balanced. A novel\naddition in our survey is that we have discussed\
    \ different IoT\narchitectures. This has not been discussed in prior surveys on\n\
    the Internet of Things. The architecture section also considers\nnewer paradigms\
    \ such as fog computing, which have also\nhitherto not been considered. Moreover,\
    \ our survey nicely\ncategorizes technologies based on the architectural layer\n\
    that they belong to. We have also thoroughly categorized\nthe network layer and\
    \ tried to consolidate almost all the\ntechnologies that are used in IoT systems.\
    \ Such kind of a\nthorough categorization and presentation of technologies is\n\
    novel to the best of our knowledge.\nAlong with these novel contributions our\
    \ survey is far\nmore comprehensive, detailed, and exhaustive as compared\nto\
    \ other surveys in the area. Most of the other surveys look\nat only one or two\
    \ types of sensors, whereas we describe\n9 types of sensors with many examples.\
    \ Other surveys\nare also fairly restricted when they discuss communication\n\
    technologies and applications. We have discussed many types\nof middleware technologies\
    \ as well. Prior works have not\ngiven middleware technologies this level of attention.\
    \ We\ncover 10 communication technologies in detail and consider\na large variety\
    \ of applications encompassing smart homes,\nhealth care, logistics, transport,\
    \ agriculture, environment,\nsmart cities, and green energy. No other survey in\
    \ this area\nprofiles so many technologies, applications, and use cases.\n5. Sensors\
    \ and Actuators\nAll IoT applications need to have one or more sensors to\ncollect\
    \ data from the environment. Sensors are essential\ncomponents of smart objects.\
    \ One of the most important\naspects of the Internet of Things is context awareness,\
    \ which\nis not possible without sensor technology. IoT sensors are\nmostly small\
    \ in size, have low cost, and consume less power.\nThey are constrained by factors\
    \ such as battery capacity and\nease of deployment. Schmidt and Van Laerhoven\
    \ [25] provide\nan overview of various types of sensors used for building\nsmart\
    \ applications.\n5.1. Mobile Phone Based Sensors. First of all, let us look at\n\
    the mobile phone, which is ubiquitous and has many types\nof sensors embedded\
    \ in it. In specific, the smartphone is\na very handy and user friendly device\
    \ that has a host of\nbuilt in communication and data processing features. With\n\
    the increasing popularity of smartphones among people,\nresearchers are showing\
    \ interest in building smart IoT solu-\ntions using smartphones because of the\
    \ embedded sensors\n[16, 26]. Some additional sensors can also be used depending\n\
    6\nJournal of Electrical and Computer Engineering\nTable 1: Comparison with other\
    \ surveys on the basis of topics covered.\nSurvey paper\nSensors\nFog computing\n\
    Middleware\nCommunication\nApplications\nOther\n“Internet of Things: A\nSurvey,”\
    \ Atzori et al.,\n2010\nRFID\nNot covered\nService oriented\narchitecture\nCommunication\n\
    standards, IEEE 802.15.4,\nWSN, Zigbee,\n6LoWPAN, NFC,\nWireless Hart, M2M,\n\
    EPC global, ROLL\nrouting\nSmart home, health,\nlogistics, transport,\nagriculture,\
    \ social,\nenvironment\nIssues related to security,\nprivacy, naming,\naddressing\n\
    “Internet of Things\n(IoT): A Vision,\nArchitectural Elements,\nand Future Directions,”\n\
    Gubbi et al., 2013\nRFID\nNot covered\nService oriented\narchitecture\nWSN, addressing\n\
    schemes\nPersonal and home,\nenterprise, utilities,\nmobile\nCloud centric IoT\n\
    “The Internet of\nThings—A Survey of\nTopics and Trends,”\nWhitmore et al., 2014\n\
    RFID\nNot covered\nSemantic middleware\nWSN, NFC, WSN\nSmart infrastructure,\n\
    health care, supply\nchains/logistics\nSecurity and plrivacy\nOur survey\nCovered\
    \ various types of\nsensors: environmental,\nmedical, neural,\nchemical, infrared,\n\
    mobile phone sensors,\nRFID\nFog computing/smart\ngateway layered\narchitecture\
    \ of IoT\nIssues addressed by\nmiddleware, types of\nmiddleware: event\nbased,\
    \ service based,\nsemantic, database,\napplication specific\nAll layers of IP\
    \ stack,\nprotocols and standards\nof each layer, IEEE\n802.15.4, 6LoWPAN,\nNFC,\
    \ ROLL routing,\nCOAP, MQTT, LPWAN,\nlow energy wireless\ncommunication\ntechnologies:\
    \ BLE,\nZigbee, RFID-WSN\nintegration\nSmart home, health,\nlogistics, transport,\n\
    social, environment,\nagriculture, energy\nVarious architectures of\nIoT\nJournal\
    \ of Electrical and Computer Engineering\n7\nupon the requirements. Applications\
    \ can be built on the\nsmartphone that uses sensor data to produce meaningful\n\
    results. Some of the sensors inside a modern smartphone are\nas follows.\n(1)\
    \ The accelerometer senses the motion and acceleration\nof a mobile phone. It\
    \ typically measures changes in\nvelocity of the smartphone in three dimensions.\
    \ There\nare many types of accelerometers [27].\nIn a mechanical accelerometer,\
    \ we have a seismic\nmass in a housing, which is tied to the housing\nwith a spring.\
    \ The mass takes time to move and is\nleft behind as the housing moves, so the\
    \ force in\nthe spring can be correlated with the acceleration.\nIn a capacitive\
    \ accelerometer, capacitive plates are\nused with the same setup. With a change\
    \ in velocity,\nthe mass pushes the capacitive plates together, thus\nchanging\
    \ the capacitance. The rate of change of\ncapacitance is then converted into acceleration.\
    \ In\na piezoelectric accelerometer, piezoelectric crystals\nare used, which when\
    \ squeezed generate an electric\nvoltage. The changes in voltage can be translated\
    \ into\nacceleration.\nThe data patterns captured by the accelerometer can\nbe\
    \ used to detect physical activities of the user such as\nrunning, walking, and\
    \ bicycling.\n(2) The gyroscope detects the orientation of the phone\nvery precisely.\
    \ Orientation is measured using capac-\nitive changes when a seismic mass moves\
    \ in a partic-\nular direction.\n(3) The camera and microphone are very powerful\
    \ sen-\nsors since they capture visual and audio information,\nwhich can then\
    \ be analyzed and processed to detect\nvarious types of contextual information.\
    \ For example,\nwe can infer a user’s current environment and the\ninteractions\
    \ that she is having. To make sense of the\naudio data, technologies such as voice\
    \ recognition\nand acoustic features can be exploited.\n(4) The magnetometer detects\
    \ magnetic fields. This can\nbe used as a digital compass and in applications\
    \ to\ndetect the presence of metals.\n(5) The GPS (Global Positioning System)\
    \ detects the\nlocation of the phone, which is one of the most\nimportant pieces\
    \ of contextual information for smart\napplications. The location is detected\
    \ using the prin-\nciple of trilateration [28]. The distance is measured\nfrom\
    \ three or more satellites (or mobile phone towers\nin the case of A-GPS) and\
    \ coordinates are computed.\n(6) The light sensor detects the intensity of ambient\
    \ light.\nIt can be used for setting the brightness of the screen\nand other applications\
    \ in which some action is to be\ntaken depending on the intensity of ambient light.\
    \ For\nexample, we can control the lights in a room.\n(7) The proximity sensor\
    \ uses an infrared (IR) LED,\nwhich emits IR rays. These rays bounce back when\n\
    they strike some object. Based on the difference in\ntime, we can calculate the\
    \ distance. In this way, the\ndistance to different objects from the phone can\
    \ be\nmeasured. For example, we can use it to determine\nwhen the phone is close\
    \ to the face while talking. It\ncan also be used in applications in which we\
    \ have\nto trigger some event when an object approaches the\nphone.\n(8) Some\
    \ smartphones such as Samsung’s Galaxy S4 also\nhave a thermometer, barometer,\
    \ and humidity sensor\nto measure the temperature, atmospheric pressure,\nand\
    \ humidity, respectively.\nWe have studied many smart applications that use sensor\n\
    data collected from smartphones. For example, activity detec-\ntion [29] is achieved\
    \ by applying machine learning algorithms\nto the data collected by smartphone\
    \ sensors. It detects activi-\nties such as running, going up and down stairs,\
    \ walking, driv-\ning, and cycling. The application is trained with patterns of\n\
    data using data sets recorded by sensors when these activities\nare being performed.\n\
    Many health and fitness applications are being built to\nkeep track of a person’s\
    \ health continuously using smart-\nphones. They keep track of users’ physical\
    \ activities, diet,\nexercises, and lifestyle to determine the fitness level and\n\
    give suggestions to the user accordingly. Wang et al. [30]\ndescribe a mobile\
    \ application that is based completely on a\nsmartphone. They use it to assess\
    \ the overall mental health\nand performance of a college student. To track the\
    \ location\nand activities in which the student is involved, activity\nrecognition\
    \ (accelerometer) and GPS data are used. To keep\na check on how much the student\
    \ sleeps, the accelerometer\nand light sensors are used. For social life and conversations,\n\
    audio data from a microphone is used. The application also\nconducts quick questionnaires\
    \ with the students to know\nabout their mood. All this data can be used to assess\
    \ the stress\nlevels, social life, behavior, and exercise patterns of a student.\n\
    Another application by McClernon and Choudhury [31]\ndetects when the user is\
    \ going to smoke using context\ninformation such as the presence of other smokers,\
    \ location,\nand associated activities. The sensors provide information\nrelated\
    \ to the user’s movement, location, visual images, and\nsurrounding sounds. To\
    \ summarize smartphone sensors are\nbeing used to study different kinds of human\
    \ behavior (see\n[32]) and to improve the quality of human life.\n5.2. Medical\
    \ Sensors. The Internet of Things can be really\nbeneficial for health care applications.\
    \ We can use sensors,\nwhich can measure and monitor various medical parameters\n\
    in the human body [33]. These applications can aim at\nmonitoring a patient’s\
    \ health when they are not in hospital or\nwhen they are alone. Subsequently,\
    \ they can provide real time\nfeedback to the doctor, relatives, or the patient.\
    \ McGrath and\nScanaill [34] have described in detail the different sensors that\n\
    can be worn on the body for monitoring a person’s health.\nThere are many wearable\
    \ sensing devices available in the\nmarket. They are equipped with medical sensors\
    \ that are\ncapable of measuring different parameters such as the heart\nrate,\
    \ pulse, blood pressure, body temperature, respiration\nrate, and blood glucose\
    \ levels [35]. These wearables include\n8\nJournal of Electrical and Computer\
    \ Engineering\nFigure 4: Smart watches and fitness trackers (source:https://www\n\
    .pebble.com/ and http://www.fitbit.com/).\nFigure 5: Embedded skin patches (source:\
    \ MC10 Electronics).\nsmart watches, wristbands, monitoring patches, and smart\n\
    textiles.\nMoreover, smart watches and fitness trackers are becom-\ning fairly\
    \ popular in the market as companies such as Apple,\nSamsung, and Sony are coming\
    \ up with very innovative\nfeatures. For example, a smart watch includes features\
    \ such\nas connectivity with a smartphone, sensors such as an\naccelerometer,\
    \ and a heart rate monitor (see Figure 4).\nAnother novel IoT device, which has\
    \ a lot of promise are\nmonitoring patches that are pasted on the skin. Monitoring\n\
    patches are like tattoos. They are stretchable and disposable\nand are very cheap.\
    \ These patches are supposed to be worn\nby the patient for a few days to monitor\
    \ a vital health\nparameter continuously [15]. All the electronic components\n\
    are embedded in these rubbery structures. They can even\ntransmit the sensed data\
    \ wirelessly. Just like a tattoo, these\npatches can be applied on the skin as\
    \ shown in Figure 5.\nOne of the most common applications of such patches is to\n\
    monitor blood pressure.\nA very important consideration here is the context [34].\n\
    The data collected by the medical sensors must be combined\nwith contextual information\
    \ such as physical activity. For\nexample, the heart rate depends on the context.\
    \ It increases\nwhen we exercise. In that case, we cannot infer abnormal\nheart\
    \ rate. Therefore, we need to combine data from different\nsensors for making\
    \ the correct inference.\nFigure 6: Brain sensing headband with embedded neurosensors\n\
    (source: http://www.choosemuse.com/).\n5.3. Neural Sensors. Today, it is possible\
    \ to understand\nneural signals in the brain, infer the state of the brain, and\n\
    train it for better attention and focus. This is known as\nneurofeedback [36]\
    \ (see Figure 6). The technology used for\nreading brain signals is called EEG\
    \ (Electroencephalography)\nor a brain computer interface. The neurons inside\
    \ the brain\ncommunicate electronically and create an electric field, which\n\
    can be measured from outside in terms of frequencies. Brain\nwaves can be categorized\
    \ into alpha, beta, gamma, theta, and\ndelta waves depending upon the frequency.\n\
    Based on the type of wave, it can be inferred whether\nthe brain is calm or wandering\
    \ in thoughts. This type of\nneurofeedback can be obtained in real time and can\
    \ be used\nto train the brain to focus, pay better attention towards things,\n\
    manage stress, and have better mental well-being.\n5.4. Environmental and Chemical\
    \ Sensors. Environmental\nsensors are used to sense parameters in the physical\
    \ environ-\nment such as temperature, humidity, pressure, water pollu-\ntion,\
    \ and air pollution. Parameters such as the temperature\nand pressure can be measured\
    \ with a thermometer and\nbarometer. Air quality can be measured with sensors,\
    \ which\nsense the presence of gases and other particulate matter in the\nair\
    \ (refer to Sekhar et al. [37] for more details).\nChemical sensors are used to\
    \ detect chemical and bio-\nchemical substances. These sensors consist of a recognition\n\
    element and a transducer. The electronic nose (e-nose) and\nelectronic tongue\
    \ (e-tongue) are technologies that can be\nused to sense chemicals on the basis\
    \ of odor and taste,\nrespectively [38]. The e-nose and e-tongue consist of an\
    \ array\nof chemical sensors coupled with advance pattern recognition\nsoftware.\
    \ The sensors inside the e-nose and e-tongue produce\ncomplex data, which is then\
    \ analyzed through pattern recog-\nnition to identify the stimulus.\nThese sensors\
    \ can be used in monitoring the pollution\nlevel in smart cities [39], keeping\
    \ a check on food quality\nin smart kitchens, testing food, and agricultural products\
    \ in\nsupply chain applications.\nJournal of Electrical and Computer Engineering\n\
    9\n5.5. Radio Frequency Identification (RFID). RFID is an iden-\ntification technology\
    \ in which an RFID tag (a small chip with\nan antenna) carries data, which is\
    \ read by a RFID reader. The\ntag transmits the data stored in it via radio waves.\
    \ It is similar\nto bar code technology. But unlike a traditional bar code, it\n\
    does not require line of sight communication between the tag\nand the reader and\
    \ can identify itself from a distance even\nwithout a human operator. The range\
    \ of RFID varies with the\nfrequency. It can go up to hundreds of meters.\nRFID\
    \ tags are of two types: active and passive. Active tags\nhave a power source\
    \ and passive tags do not have any power\nsource. Passive tags draw power from\
    \ the electromagnetic\nwaves emitted by the reader and are thus cheap and have\
    \ a\nlong lifetime [40, 41].\nThere are two types of RFID technologies: near and\
    \ far\n[40]. A near RFID reader uses a coil through which we pass\nalternating\
    \ current and generate a magnetic field. The tag has\na smaller coil, which generates\
    \ a potential due to the ambient\nchanges in the magnetic field. This voltage\
    \ is then coupled\nwith a capacitor to accumulate a charge, which then powers\n\
    up the tag chip. The tag can then produce a small magnetic\nfield that encodes\
    \ the signal to be transmitted, and this can\nbe picked up by the reader.\nIn\
    \ far RFID, there is a dipole antenna in the reader, which\npropagates EM waves.\
    \ The tag also has a dipole antenna on\nwhich an alternating potential difference\
    \ appears and it is\npowered up. It can then use this power to transmit messages.\n\
    RFID technology is being used in various applications\nsuch as supply chain management,\
    \ access control, identity\nauthentication, and object tracking. The RFID tag\
    \ is attached\nto the object to be tracked and the reader detects and records\n\
    its presence when the object passes by it. In this manner,\nobject movement can\
    \ be tracked and RFID can serve as a\nsearch engine for smart things.\nFor access\
    \ control, an RFID tag is attached to the\nauthorized object. For example, small\
    \ chips are glued to the\nfront of vehicles. When the car reaches a barricade\
    \ on which\nthere is a reader, it reads the tag data and decides whether it\n\
    is an authorized car. If yes, it opens automatically. RFID cards\nare issued to\
    \ the people, who can then be identified by a RFID\nreader and given access accordingly.\n\
    The low level data collected from the RFID tags can be\ntransformed into higher\
    \ level insights in IoT applications\n[42]. There are many user level tools available,\
    \ in which all the\ndata collected by particular RFID readers and data associated\n\
    with the RFID tags can be managed. The high level data can\nbe used to draw inferences\
    \ and take further action.\n5.6. Actuators. Let us look at some examples of actuators\
    \ that\nare used in the Internet of Things. An actuator is a device,\nwhich can\
    \ effect a change in the environment by converting\nelectrical energy into some\
    \ form of useful energy. Some\nexamples are heating or cooling elements, speakers,\
    \ lights,\ndisplays, and motors.\nThe actuators, which induce motion, can be classified\
    \ into\nthree categories, namely, electrical, hydraulic, and pneumatic\nactuators\
    \ depending on their operation. Hydraulic actuators\nfacilitate mechanical motion\
    \ using fluid or hydraulic power.\nPneumatic actuators use the pressure of compressed\
    \ air and\nelectrical ones use electrical energy.\nAs an example, we can consider\
    \ a smart home system,\nwhich consists of many sensors and actuators. The actuators\n\
    are used to lock/unlock the doors, switch on/off the lights or\nother electrical\
    \ appliances, alert users of any threats through\nalarms or notifications, and\
    \ control the temperature of a\nhome (via a thermostat).\nA sophisticated example\
    \ of an actuator used in IoT is\na digital finger, which is used to turn on/off\
    \ the switches\n(or anything which requires small motion) and is controlled\n\
    wirelessly.\n6. Preprocessing\nAs smart things collect huge amount of sensor data,\
    \ compute\nand storage resources are required to analyze, store, and\nprocess\
    \ this data. The most common compute and storage\nresources are cloud based because\
    \ the cloud offers massive\ndata handling, scalability, and flexibility. But this\
    \ will not be\nsufficient to meet the requirements of many IoT applications\n\
    because of the following reasons [43].\n(1) Mobility: most of the smart devices\
    \ are mobile. Their\nchanging location makes it difficult to communicate\nwith\
    \ the cloud data center because of changing net-\nwork conditions across different\
    \ locations.\n(2) Reliable and real time actuation: communicating with\nthe cloud\
    \ and getting back responses takes time.\nLatency sensitive applications, which\
    \ need real time\nresponses, may not be feasible with this model. Also,\nthe communication\
    \ may be lossy due to wireless links,\nwhich can lead to unreliable data.\n(3)\
    \ Scalability: more devices means more requests to the\ncloud, thereby increasing\
    \ the latency.\n(4) Power constraints: communication consumes a lot of\npower,\
    \ and IoT devices are battery powered. They\nthus cannot afford to communicate\
    \ all the time.\nTo solve the problem of mobility, researchers have pro-\nposed\
    \ mobile cloud computing (MCC) [44]. But there are\nstill problems associated\
    \ with latency and power. MCC also\nsuffers from mobility problems such as frequently\
    \ changing\nnetwork conditions due to which problems such as signal\nfading and\
    \ service degradation arise.\nAs a solution to these problems, we can bring some\n\
    compute and storage resources to the edge of the network\ninstead of relying on\
    \ the cloud for everything. This concept\nis known as fog computing [11, 45] (also\
    \ see Section 2.2).\nThe fog can be viewed as a cloud, which is close to the\n\
    ground. Data can be stored, processed, filtered, and analyzed\non the edge of\
    \ the network before sending it to the cloud\nthrough expensive communication\
    \ media. The fog and cloud\nparadigms go together. Both of them are required for\
    \ the\noptimal performance of IoT applications. A smart gateway\n[13] can be employed\
    \ between underlying networks and the\ncloud to realize fog computing as shown\
    \ in Figure 7.\nThe features of fog computing [11] are as follows:\n(1) Low latency:\
    \ less time is required to access computing\nand storage resources on fog nodes\
    \ (smart gateways).\n10\nJournal of Electrical and Computer Engineering\nSmart\
    \ devices\nSmart gateway\nLocal real time analysis \npreprocessing\nﬁltering\n\
    Cloud data center \nGlobal data analytics\nstorage\ndata\ndata\nFigure 7: Smart\
    \ gateway for preprocessing.\n(2) Location awareness: as the fog is located on\
    \ the edge\nof the network, it is aware of the location of the\napplications and\
    \ their context. This is beneficial as\ncontext awareness is an important feature\
    \ of IoT\napplications.\n(3) Distributed nodes: fog nodes are distributed unlike\n\
    centralized cloud nodes. Multiple fog nodes need to\nbe deployed in distributed\
    \ geographical areas in order\nto provide services to mobile devices in those\
    \ areas.\nFor example, in vehicular networks, deploying fog\nnodes at highways\
    \ can provide low latency data/video\nstreaming to vehicles.\n(4) Mobility: the\
    \ fog supports mobility as smart devices\ncan directly communicate with smart\
    \ gateways\npresent in their proximity.\n(5) Real time response: fog nodes can\
    \ give an immediate\nresponse unlike the cloud, which has a much greater\nlatency.\n\
    (6) Interaction with the cloud: fog nodes can further\ninteract with the cloud\
    \ and communicate only that\ndata, which is required to be sent to the cloud.\n\
    The tasks performed by a smart gateway [46] are col-\nlecting sensor data, preprocessing\
    \ and filtering collected\ndata, providing compute, storage and networking services\n\
    to IoT devices, communicating with the cloud and sending\nonly necessary data,\
    \ monitoring power consumption of IoT\ndevices, monitoring activities and services\
    \ of IoT devices, and\nensuring security and privacy of data. Some applications\
    \ of\nfog computing are as follows [10, 11]:\n(1) Smart vehicular networks: smart\
    \ traffic lights are\ndeployed as smart gateways to locally detect pedes-\ntrians\
    \ and vehicles through sensors, calculate their\ndistance and speed, and finally\
    \ infer traffic conditions.\nThis is used to warn oncoming vehicles. These sensors\n\
    also interact with neighboring smart traffic lights\nto perform traffic management\
    \ tasks. For example,\nif sensors detect an approaching ambulance, they\ncan change\
    \ the traffic lights to let the ambulance\npass first and also inform other lights\
    \ to do so. The\ndata collected by these smart traffic lights are locally\nanalyzed\
    \ in real time to serve real time needs of traffic\nmanagement. Further, data\
    \ from multiple gateways\nis combined and sent to the cloud for further global\n\
    analysis of traffic in the city.\n(2) Smart grid: the smart electrical grid facilitates\
    \ load\nbalancing of energy on the basis of usage and avail-\nability. This is\
    \ done in order to switch automatically\nto alternative sources of energy such\
    \ as solar and\nwind power. This balancing can be done at the edge\nof the network\
    \ using smart meters or microgrids\nconnected by smart gateways. These gateways\
    \ can\nanalyze and process data. They can then project future\nenergy demand,\
    \ calculate the availability and price of\npower, and supply power from both conventional\
    \ and\nalternative sources to consumers.\n7. Communication\nAs the Internet of\
    \ Things is growing very rapidly, there are a\nlarge number of heterogeneous smart\
    \ devices connecting to\nthe Internet. IoT devices are battery powered, with minimal\n\
    compute and storage resources. Because of their constrained\nnature, there are\
    \ various communication challenges involved,\nwhich are as follows [19]:\n(1)\
    \ Addressing and identification: since millions of smart\nthings will be connected\
    \ to the Internet, they will\nhave to be identified through a unique address,\
    \ on the\nbasis of which they communicate with each other. For\nthis, we need\
    \ a large addressing space, and a unique\naddress for each smart object.\n(2)\
    \ Low power communication: communication of data\nbetween devices is a power consuming\
    \ task, specially,\nwireless communication. Therefore, we need a solu-\ntion that\
    \ facilitates communication with low power\nconsumption.\n(3) Routing protocols\
    \ with low memory requirement and\nefficient communication patterns.\n(4) High\
    \ speed and nonlossy communication.\n(5) Mobility of smart things.\nIoT devices\
    \ typically connect to the Internet through\nthe IP (Internet Protocol) stack.\
    \ This stack is very complex\nand demands a large amount of power and memory from\n\
    the connecting devices. The IoT devices can also connect\nlocally through non-IP\
    \ networks, which consume less power,\nand connect to the Internet via a smart\
    \ gateway. Non-IP\ncommunication channels such as Bluetooth, RFID, and NFC\nare\
    \ fairly popular but are limited in their range (up to a\nfew meters). Therefore,\
    \ their applications are limited to small\npersonal area networks. Personal area\
    \ networks (PAN) are\nJournal of Electrical and Computer Engineering\n11\nbeing\
    \ widely used in IoT applications such as wearables\nconnected to smartphones.\
    \ For increasing the range of such\nlocal networks, there was a need to modify\
    \ the IP stack so as to\nfacilitate low power communication using the IP stack.\
    \ One\nof the solutions is 6LoWPAN, which incorporates IPv6 with\nlow power personal\
    \ area networks. The range of a PAN with\n6LoWPAN is similar to local area networks,\
    \ and the power\nconsumption is much lower.\nThe leading communication technologies\
    \ used in the IoT\nworld are IEEE 802.15.4, low power WiFi, 6LoWPAN, RFID,\nNFC,\
    \ Sigfox, LoraWAN, and other proprietary protocols for\nwireless networks.\n7.1.\
    \ Near Field Communication (NFC). Near Field Communi-\ncation [47–49] is a very\
    \ short range wireless communication\ntechnology, through which mobile devices\
    \ can interact with\neach other over a distance of few centimeters only. All types\
    \ of\ndata can be transferred between two NFC enabled devices in\nseconds by bringing\
    \ them close to each other. This technology\nis based on RFID. It uses variations\
    \ in the magnetic field\nto communicate data between two NFC enabled devices.\n\
    NFC operates over a frequency band of 13.56 MHz, which is\nthe same as high frequency\
    \ RFID. There are two modes of\noperation: active and passive. In the active mode,\
    \ both the\ndevices generate magnetic fields, while in the passive mode,\nonly\
    \ one device generates the field and the other uses load\nmodulation to transfer\
    \ the data. The passive mode is useful in\nbattery powered devices to optimize\
    \ energy use. One benefit\nof the requirement of close proximity between devices\
    \ is that\nit is useful for secure transactions such as payments. Finally,\nnote\
    \ that NFC can be used for two-way communication\nunlike RFID. Consequently, almost\
    \ all smartphones in the\nmarket today are NFC enabled.\n7.2. Wireless Sensor\
    \ Networks (WSN) Based on IP for Smart\nObjects. Many times, data from a single\
    \ sensor is not useful\nin monitoring large areas and complex activities. Different\n\
    sensor nodes need to interact with each other wirelessly. The\ndisadvantage of\
    \ non-IP technologies such as RFID, NFC,\nand Bluetooth is that their range is\
    \ very small. So, they\ncannot be used in many applications, where a large area\
    \ needs\nto be monitored through many sensor nodes deployed in\ndiverse locations.\
    \ A wireless sensor network (WSN) consists\nof tens to thousands of sensor nodes\
    \ connected using wireless\ntechnologies. They collect data about the environment\
    \ and\ncommunicate it to gateway devices that relay the information\nto the cloud\
    \ over the Internet. The communication between\nnodes in a WSN may be direct or\
    \ multihop. The sensor nodes\nare of a constrained nature, but gateway nodes have\
    \ suffi-\ncient power and processing resources. The popular network\ntopologies\
    \ used in a WSN are a star, a mesh, and a hybrid\nnetwork. Most of the communication\
    \ in WSN is based on the\nIEEE 802.15.4 standard (discussed in Section 7.3). There\
    \ are\nclearly a lot of protocols that can be used in IoT scenarios.\nLet us discuss\
    \ the design of a typical IoT network protocol\nstack with the most popular alternatives.\n\
    7.3. IoT Network Protocol Stack. The Internet Engineering\nTask Force (IETF) has\
    \ developed alternative protocols for\ncommunication between IoT devices using\
    \ IP because IP is a\nflexible and reliable standard [50, 51]. The Internet Protocol\n\
    for Smart Objects (IPSO) Alliance has published various\nwhite papers describing\
    \ alternative protocols and standards\nfor the layers of the IP stack and an additional\
    \ adaptation\nlayer, which is used for communication [51–54] between\nsmart objects.\n\
    (1) Physical and MAC Layer (IEEE 802.15.4). The IEEE\n802.15.4 protocol is designed\
    \ for enabling communication\nbetween compact and inexpensive low power embedded\n\
    devices that need a long battery life. It defines standards and\nprotocols for\
    \ the physical and link (MAC) layer of the IP\nstack. It supports low power communication\
    \ along with low\ncost and short range communication. In the case of such\nresource\
    \ constrained environments, we need a small frame\nsize, low bandwidth, and low\
    \ transmit power.\nTransmission requires very little power (maximum one\nmilliwatt),\
    \ which is only one percent of that used in WiFi or\ncellular networks. This limits\
    \ the range of communication.\nBecause of the limited range, the devices have\
    \ to operate\ncooperatively in order to enable multihop routing over\nlonger distances.\
    \ As a result, the packet size is limited to\n127 bytes only, and the rate of\
    \ communication is limited to\n250 kbps. The coding scheme in IEEE 802.15.4 has\
    \ built in\nredundancy, which makes the communication robust, allows\nus to detect\
    \ losses, and enables the retransmission of lost\npackets. The protocol also supports\
    \ short 16-bit link addresses\nto decrease the size of the header, communication\
    \ overheads,\nand memory requirements [55].\nReaders can refer to the survey by\
    \ Vasseur et al. [54]\nfor more information on different physical and link layer\n\
    technologies for communication between smart objects.\n(2) Adaptation Layer. IPv6\
    \ is considered the best protocol for\ncommunication in the IoT domain because\
    \ of its scalability\nand stability. Such bulky IP protocols were initially not\n\
    thought to be suitable for communication in scenarios with\nlow power wireless\
    \ links such as IEEE 802.15.4.\n6LoWPAN, an acronym for IPv6 over low power wireless\n\
    personal area networks, is a very popular standard for\nwireless communication.\
    \ It enables communication using\nIPv6 over the IEEE 802.15.4 [52] protocol. This\
    \ standard\ndefines an adaptation layer between the 802.15.4 link layer\nand the\
    \ transport layer. 6LoWPAN devices can communicate\nwith all other IP based devices\
    \ on the Internet. The choice\nof IPv6 is because of the large addressing space\
    \ available\nin IPv6. 6LoWPAN networks connect to the Internet via a\ngateway\
    \ (WiFi or Ethernet), which also has protocol support\nfor conversion between\
    \ IPv4 and IPv6 as today’s deployed\nInternet is mostly IPv4. IPv6 headers are\
    \ not small enough\nto fit within the small 127 byte MTU of the 802.15.4 standard.\n\
    Hence, squeezing and fragmenting the packets to carry\nonly the essential information\
    \ is an optimization that the\nadaptation layer performs.\nSpecifically, the adaptation\
    \ layer performs the following\nthree optimizations in order to reduce communication\
    \ over-\nhead [55]:\n12\nJournal of Electrical and Computer Engineering\n(i) Header\
    \ compression 6loWPAN defines header com-\npression of IPv6 packets for decreasing\
    \ the overhead\nof IPv6. Some of the fields are deleted because they\ncan be derived\
    \ from link level information or can be\nshared across packets.\n(ii) Fragmentation:\
    \ the minimum MTU size (maximum\ntransmission unit) of IPv6 is 1280 bytes. On\
    \ the other\nhand, the maximum size of a frame in IEEE 802.15.4\nis 127 bytes.\
    \ Therefore, we need to fragment the IPv6\npacket. This is done by the adaptation\
    \ layer.\n(iii) Link layer forwarding 6LoWPAN also supports mesh\nunder routing,\
    \ which is done at the link layer using\nlink level short addresses instead of\
    \ in the network\nlayer. This feature can be used to communicate within\na 6LoWPAN\
    \ network.\n(3) Network Layer. The network layer is responsible for\nrouting the\
    \ packets received from the transport layer. The\nIETF Routing over Low Power\
    \ and Lossy Networks (ROLL)\nworking group has developed a routing protocol (RPL)\
    \ for\nLow Power and Lossy Networks (LLNs) [53].\nFor such networks, RPL is an\
    \ open routing protocol,\nbased on distance vectors. It describes how a destination\n\
    oriented directed acyclic graph (DODAG) is built with\nthe nodes after they exchange\
    \ distance vectors. A set of\nconstraints and an objective function is used to\
    \ build the\ngraph with the best path [53]. The objective function and\nconstraints\
    \ may differ with respect to their requirements. For\nexample, constraints can\
    \ be to avoid battery powered nodes\nor to prefer encrypted links. The objective\
    \ function can aim\nto minimize the latency or the expected number of packets\n\
    that need to be sent.\nThe making of this graph starts from the root node. The\n\
    root starts sending messages to neighboring nodes, which\nthen process the message\
    \ and decide whether to join or not\ndepending upon the constraints and the objective\
    \ function.\nSubsequently, they forward the message to their neighbors.\nIn this\
    \ manner, the message travels till the leaf nodes and a\ngraph is formed. Now\
    \ all the nodes in the graph can send\npackets upwards hop by hop to the root.\
    \ We can realize a point\nto point routing algorithm as follows. We send packets\
    \ to a\ncommon ancestor, from which it travels downwards (towards\nleaves) to\
    \ reach the destination.\nTo manage the memory requirements of nodes, nodes are\n\
    classified into storing and nonstoring nodes depending upon\ntheir ability to\
    \ store routing information. When nodes are in a\nnonstoring mode and a downward\
    \ path is being constructed,\nthe route information is attached to the incoming\
    \ message\nand forwarded further till the root. The root receives the\nwhole path\
    \ in the message and sends a data packet along with\nthe path message to the destination\
    \ hop by hop. But there is\na trade-off here because nonstoring nodes need more\
    \ power\nand bandwidth to send additional route information as they\ndo not have\
    \ the memory to store routing tables.\n(4) Transport Layer. TCP is not a good\
    \ option for communi-\ncation in low power environments as it has a large overhead\n\
    owing to the fact that it is a connection oriented protocol.\nTherefore, UDP is\
    \ preferred because it is a connectionless\nprotocol and has low overhead.\n(5)\
    \ Application Layer. The application layer is responsible for\ndata formatting\
    \ and presentation. The application layer in\nthe Internet is typically based\
    \ on HTTP. However, HTTP is\nnot suitable in resource constrained environments\
    \ because\nit is fairly verbose in nature and thus incurs a large parsing\noverhead.\
    \ Many alternate protocols have been developed for\nIoT environments such as CoAP\
    \ (Constrained Application\nProtocol) and MQTT (Message Queue Telemetry Transport).\n\
    (a) Constrained Application Protocol: CoAP can be\nthought of as an alternative\
    \ to HTTP. It is used\nin most IoT applications [56, 57]. Unlike HTTP, it\nincorporates\
    \ optimizations for constrained applica-\ntion environments [50]. It uses the\
    \ EXI (Efficient\nXML Interchanges) data format, which is a binary\ndata format\
    \ and is far more efficient in terms of\nspace as compared to plain text HTML/XML.\
    \ Other\nsupported features are built in header compression,\nresource discovery,\
    \ autoconfiguration, asynchronous\nmessage exchange, congestion control, and support\n\
    for multicast messages. There are four types of mes-\nsages in CoAP: nonconfirmable,\
    \ confirmable, reset\n(nack), and acknowledgement. For reliable transmis-\nsion\
    \ over UDP, confirmable messages are used [58].\nThe response can be piggybacked\
    \ in the acknowledge-\nment itself. Furthermore, it uses DTLS (Datagram\nTransport\
    \ Layer Security) for security purposes.\n(b) Message Queue Telemetry Transport:\
    \ MQTT is a\npublish/subscribe protocol that runs over TCP. It was\ndeveloped\
    \ by IBM [59] primarily as a client/server\nprotocol. The clients are publishers/subscribers\
    \ and\nthe server acts as a broker to which clients connect\nthrough TCP. Clients\
    \ can publish or subscribe to a\ntopic. This communication takes place through\
    \ the\nbroker whose job is to coordinate subscriptions and\nalso authenticate\
    \ the client for security. MQTT is\na lightweight protocol, which makes it suitable\
    \ for\nIoT applications. But because of the fact that it runs\nover TCP, it cannot\
    \ be used with all types of IoT\napplications. Moreover, it uses text for topic\
    \ names,\nwhich increases its overhead.\nMQTT-S/MQTT-SN is an extension of MQTT\
    \ [60],\nwhich is designed for low power and low cost devices. It is\nbased on\
    \ MQTT but has some optimizations for WSNs as\nfollows [61]. The topic names are\
    \ replaced by topic IDs, which\nreduce the overheads of transmission. Topics do\
    \ not need\nregistration as they are preregistered. Messages are also split\n\
    so that only the necessary information is sent. Further, for\npower conservation,\
    \ there is an offline procedure for clients\nwho are in a sleep state. Messages\
    \ can be buffered and later\nread by clients when they wake up. Clients connect\
    \ to the\nbroker through a gateway device, which resides within the\nsensor network\
    \ and connects to the broker.\n7.4. Bluetooth Low Energy (BLE). Bluetooth Low\
    \ Energy, also\nknown as “Bluetooth Smart,” was developed by the Bluetooth\nJournal\
    \ of Electrical and Computer Engineering\n13\nSpecial Interest Group. It has a\
    \ relatively shorter range and\nconsumes lower energy as compared to competing\
    \ protocols.\nThe BLE protocol stack is similar to the stack used in classic\n\
    Bluetooth technology. It has two parts: controller and host.\nThe physical and\
    \ link layer are implemented in the controller.\nThe controller is typically a\
    \ SOC (System on Chip) with a\nradio. The functionalities of upper layers are\
    \ included in the\nhost [62]. BLE is not compatible with classic Bluetooth. Let\n\
    us look at the differences between classic Bluetooth and BLE\n[63, 64].\nThe main\
    \ difference is that BLE does not support data\nstreaming. Instead, it supports\
    \ quick transfer of small packets\nof data (packet size is small) with a data\
    \ rate of 1 Mbps.\nThere are two types of devices in BLE: master and slave.\n\
    The master acts as a central device that can connect to various\nslaves. Let us\
    \ consider an IoT scenario where a phone or PC\nserve as the master and mobile\
    \ devices such as a thermostat,\nfitness tracker, smart watch, or any monitoring\
    \ device act\nas slaves. In such cases, slaves must be very power efficient.\n\
    Therefore, to save energy, slaves are by default in sleep mode\nand wake up periodically\
    \ to receive packets from the master.\nIn classic Bluetooth, the connection is\
    \ on all the time even\nif no data transfer is going on. Additionally, it supports\
    \ 79\ndata channels (1 MHz channel bandwidth) and a data rate\nof 1 million symbols/s,\
    \ whereas, BLE supports 40 channels\nwith 2 MHz channel bandwidth (double of classic\
    \ Bluetooth)\nand 1 million symbols/s data rate. BLE supports low duty\ncycle\
    \ requirements as its packet size is small and the time\ntaken to transmit the\
    \ smallest packet is as small as 80 \U0001D707s. The\nBLE protocol stack supports\
    \ IP based communication also.\nAn experiment conducted by Siekkinen et al. [65]\
    \ recorded\nthe number of bytes transferred per Joule to show that BLE\nconsumes\
    \ far less energy as compared to competing protocols\nsuch as Zigbee. The energy\
    \ efficiency of BLE is 2.5 times better\nthan Zigbee.\n7.5. Low Power WiFi. The\
    \ WiFi alliance has recently devel-\noped “WiFi HaLow,” which is based on the\
    \ IEEE 802.11ah\nstandard. It consumes lower power than a traditional WiFi\ndevice\
    \ and also has a longer range. This is why this protocol\nis suitable for Internet\
    \ of Things applications. The range of\nWiFi HaLow is nearly twice that of traditional\
    \ WiFi.\nLike other WiFi devices, devices supporting WiFi HaLow\nalso support\
    \ IP connectivity, which is important for IoT\napplications. Let us look at the\
    \ specifications of the IEEE\n802.11ah standard [66, 67]. This standard was developed\
    \ to\ndeal with wireless sensor network scenarios, where devices\nare energy constrained\
    \ and require relatively long range\ncommunication. IEEE 802.11ah operates in\
    \ the sub-gigahertz\nband (900 MHz). Because of the relatively lower frequency,\n\
    the range is longer since higher frequency waves suffer from\nhigher attenuation.\
    \ We can extend the range (currently 1 km)\nby lowering the frequency further;\
    \ however, the data rate\nwill also be lower and thus the tradeoff is not justified.\n\
    IEEE 802.11ah is also designed to support large star shaped\nnetworks, where a\
    \ lot of stations are connected to a single\naccess point.\n7.6. Zigbee. It is\
    \ based on the IEEE 802.15.4 communication\nprotocol standard and is used for\
    \ personal area networks\nor PANs [68]. The IEEE 802.15.4 standard has low power\n\
    MAC and physical layers and has already been explained\nin Section 7.3. Zigbee\
    \ was developed by the Zigbee alliance,\nwhich works for reliable, low energy,\
    \ and cheap communi-\ncation solutions. The range of Zigbee device communication\n\
    is very small (10–100 meters). The details of the network and\napplication layers\
    \ are also specified by the Zigbee standard.\nUnlike BLE, the network layer here\
    \ provides for multihop\nrouting.\nThere are three types of devices in a Zigbee\
    \ network:\nFFD (Fully Functional Device), RFD (Reduced Functional\nDevice), and\
    \ one Zigbee coordinator. A FFD node can addi-\ntionally act as a router. Zigbee\
    \ supports star, tree, and mesh\ntopologies. The routing scheme depends on the\
    \ topology.\nOther features of Zigbee are discovery and maintenance of\nroutes,\
    \ support for nodes joining/leaving the network, short\n16-bit addresses, and\
    \ multihop routing.\nThe framework for communication and distributed appli-\n\
    cation development is provided by the application layer.\nThe application layer\
    \ consists of Application Objects (APO),\nApplication Sublayer (APS), and a Zigbee\
    \ Device Object\n(ZDO). APOs are spread over the network nodes. These are\npieces\
    \ of software, which control some underlying device\nhardware (examples: switch\
    \ and transducer). The device and\nnetwork management services are provided by\
    \ the ZDO,\nwhich are then used by the APOs. Data transfer services\nare provided\
    \ by the Application Sublayer to the APOs and\nZDO. It is responsible for secure\
    \ communication between the\nApplication Objects. These features can be used to\
    \ create a\nlarge distributed application.\n7.7. Integration of RFID and WSN.\
    \ RFID and wireless sensor\nnetworks (WSN) are both important technologies in\
    \ the IoT\ndomain. RFID can only be used for object identification, but\nWSNs\
    \ serve a far greater purpose. The two are very different\nbut merging them has\
    \ many advantages. The following\ncomponents can be added to RFID to enhance its\
    \ usability:\n(a) Sensing capabilities\n(b) Multihop communication\n(c) Intelligence\n\
    RFID is inexpensive and uses very little power. That is\nwhy its integration with\
    \ WSN is very useful. The integration\nis possible in the following ways [69,\
    \ 70]:\n(a) Integration of RFID tags with sensors: RFID tags\nwith sensing capabilities\
    \ are called sensor tags. These\nsensor tags sense data from the environment and\n\
    then the RFID reader can read this sensed data from\nthe tag. In such cases, simple\
    \ RFID protocols are\nused, where there is only single hop communication.\nRFID\
    \ sensing technologies can be further classified\non the basis of the power requirement\
    \ of sensor tags as\nexplained earlier in the section on RFIDs (active and\npassive)\
    \ (see Section 5.5).\n14\nJournal of Electrical and Computer Engineering\n(b)\
    \ Integration of RFID tags with WSN nodes: the com-\nmunication capabilities of\
    \ sensor tags are limited to a\nsingle hop. To extend its capabilities, the sensor\
    \ tag is\nequipped with a wireless transceiver, little bit of Flash\nmemory, and\
    \ computational capabilities such that it\ncan initiate communication with other\
    \ nodes and\nwireless devices. The nodes can in this fashion be used\nto form\
    \ a wireless mesh network. In such networks,\nsensor tags can communicate with\
    \ each other over a\nlarge range (via intermediate hops). With additional\nprocessing\
    \ capabilities at a node, we can reduce the\nnet amount of data communicated and\
    \ thus increase\nthe power efficiency of the WSN.\n(c) Integration of RFID readers\
    \ with WSN nodes: this\ntype of integration is also done to increase the range\n\
    of RFID tag readers. The readers are equipped with\nwireless transceivers and\
    \ microcontrollers so that\nthey can communicate with each other and therefore,\n\
    the tag data can reach a reader, which is not in the\nrange of that tag. It takes\
    \ advantage of multihop\ncommunication of wireless sensor network devices.\nThe\
    \ data from all the RFID readers in the network\nultimately reaches a central\
    \ gateway or base station\nthat processes the data or sends it to a remote server.\n\
    These kinds of integrated solutions have many applica-\ntions in a diverse set\
    \ of domains such as security, healthcare,\nand manufacturing.\n7.8. Low Power\
    \ Wide-Area-Networks (LPWAN). Let us now\ndiscuss a protocol for long range communication\
    \ in power\nconstrained devices. The LPWAN class of protocols is low bit-\nrate\
    \ communication technologies for such IoT scenarios.\nLet us now discuss some\
    \ of the most common technolo-\ngies in this area.\nNarrow band IoT: it is a technology\
    \ made for a large\nnumber of devices that are energy constrained. It is\nthus\
    \ necessary to reduce the bit rate. This protocol\ncan be deployed with both the\
    \ cellular phone GSM\nand LTE spectra. The downlink speeds vary between\n40 kbps\
    \ (LTE M2) and 10 Mbps (LTE category 1).\nSigfox: it is one more protocol that\
    \ uses narrow band\ncommunication (≈10 MHz). It uses free sections of\nthe radio\
    \ spectrum (ISM band) to transmit its data.\nInstead of 4G networks, Sigfox focuses\
    \ on using\nvery long waves. Thus, the range can increase to a\n1000 kms. Because\
    \ of this the energy for transmission\nis significantly lower (<0.1%) than contemporary\
    \ cell\nphones.\nAgain the cost is bandwidth. It can only transmit\n12 bytes per\
    \ message, and a device is limited to 140\nmessages per day. This is reasonable\
    \ for many kinds of\napplications: submarine applications, sending control\n(emergency)\
    \ codes, geolocation, monitoring remote\nlocations, and medical applications.\n\
    Weightless: it uses a differential binary phase shift\nkeying based method to\
    \ transmit narrow band sig-\nnals. To avoid interference, the protocol hops across\n\
    frequency bands (instead of using CSMA). It sup-\nports cryptographic encryption\
    \ and mobility. Along\nwith frequency hopping, two additional mechanisms\nare\
    \ used to reduce collisions. The downlink service\nuses time division multiple\
    \ access (TDMA) and the\nuplink service uses multiple subchannels that are first\n\
    allocated to transmitting nodes by contacting a cen-\ntral server. Some applications\
    \ include smart meters,\nvehicle tracking, health monitoring, and industrial\n\
    machine monitoring.\nNeul: this protocol operates in the sub-1 GHz band.\nIt uses\
    \ small chunks of the TV whitespace spectrum\nto create low cost and low power\
    \ networks with very\nhigh scalability. It has a 10 km range and uses the\nWeightless\
    \ protocol for communication.\nLoRaWAN: this protocol is similar to Sigfox. It\
    \ targets\nwide area network applications and is designed to be\na low power protocol.\
    \ Its data rates can vary from\n0.3 kbps to 50 kbps, and it can be used within\
    \ an\nurban or a suburban environment (2–5 kms range\nin a crowded urban area).\
    \ It was designed to serve\nas a standard for long range IoT protocols. It thus\n\
    has features to support multitenancy, enable multiple\napplications, and include\
    \ several different network\ndomains.\n7.9. Lightweight Application Layer Protocols.\
    \ Along with\nphysical and MAC layer protocols, we also need application\nlayer\
    \ protocols for IoT networks. These lightweight protocols\nneed to be able to\
    \ carry application messages, while simulta-\nneously reducing power as far as\
    \ possible.\nOMA Lightweight M2M (LWM2M) is one such protocol.\nIt defines the\
    \ communication protocol between a server and\na device. The devices often have\
    \ limited capabilities and are\nthus referred to as constrained devices. The main\
    \ aims of the\nOMA protocol are as follows:\n(1) Remote device management.\n(2)\
    \ Transferring service data/information between differ-\nent nodes in the LWM2M\
    \ network.\nAll the protocols in this class treat all the network\nresources as\
    \ objects. Such resources can be created, deleted,\nand remotely configured. These\
    \ devices have their unique\nlimitations and can use different kinds of protocols\
    \ for\ninternally representing information. The LWM2M protocol\nabstracts all\
    \ of this away and provides a convenient interface\nto send messages between a\
    \ generic LWM2M server and a\ndistributed set of LWM2M clients.\nThis protocol\
    \ is often used along with CoAP (Constrained\nApplication Protocol). It is an\
    \ application layer protocol\nthat allows constrained nodes such as sensor motes\
    \ or small\nembedded devices to communicate across the Internet. CoAP\nseamlessly\
    \ integrates with HTTP, yet it provides additional\nfacilities such as support\
    \ for multicast operations. It is ideally\nJournal of Electrical and Computer\
    \ Engineering\n15\nsuited for small devices because of its low overhead and\n\
    parsing complexity and reliance on UDP rather than TCP.\n8. Middleware\nUbiquitous\
    \ computing is the core of the Internet of Things,\nwhich means incorporating\
    \ computing and connectivity in\nall the things around us. Interoperability of\
    \ such heteroge-\nneous devices needs well-defined standards. But standard-\n\
    ization is difficult because of the varied requirements of\ndifferent applications\
    \ and devices. For such heterogeneous\napplications, the solution is to have a\
    \ middleware platform,\nwhich will abstract the details of the things for applications.\n\
    That is, it will hide the details of the smart things. It\nshould act as a software\
    \ bridge between the things and the\napplications. It needs to provide the required\
    \ services to the\napplication developers [20] so that they can focus more on\n\
    the requirements of applications rather than on interacting\nwith the baseline\
    \ hardware. To summarize, the middleware\nabstracts the hardware and provides\
    \ an Application Program-\nming Interface (API) for communication, data management,\n\
    computation, security, and privacy.\nThe challenges, which are addressed by any\
    \ IoT middle-\nware, are as follows: [20, 71, 72].\n(1) Interoperability and programming\
    \ abstractions: for\nfacilitating collaboration and information exchange\nbetween\
    \ heterogeneous devices, different types of\nthings can interact with each other\
    \ easily with the help\nof middleware services. Interoperability is of three\n\
    types: network, semantic, and syntactic. Network\ninteroperability deals with\
    \ heterogeneous interface\nprotocols for communication between devices. It\ninsulates\
    \ the applications from the intricacies of\ndifferent protocols. Syntactic interoperability\
    \ ensures\nthat applications are oblivious of different formats,\nstructures,\
    \ and encoding of data. Semantic interop-\nerability deals with abstracting the\
    \ meaning of data\nwithin a particular domain. It is loosely inspired by\nthe\
    \ semantic web.\n(2) Device discovery and management: this feature\nenables the\
    \ devices to be aware of all other devices\nin the neighborhood and the services\
    \ provided by\nthem. In the Internet of Things, the infrastructure is\nmostly\
    \ dynamic. The devices have to announce their\npresence and the services they\
    \ provide. The solution\nneeds to be scalable because the devices in an IoT\n\
    network can increase. Most solutions in this domain\nare loosely inspired by semantic\
    \ web technologies.\nThe middleware provides APIs to list the IoT devices,\ntheir\
    \ services, and capabilities. In addition, typically\nAPIs are provided to discover\
    \ devices based on their\ncapabilities. Finally, any IoT middleware needs to\n\
    perform load balancing, manage devices based on\ntheir levels of battery power,\
    \ and report problems in\ndevices to the users.\n(3) Scalability: a large number\
    \ of devices are expected to\ncommunicate in an IoT setup. Moreover, IoT appli-\n\
    cations need to scale due to ever increasing require-\nments. This should be managed\
    \ by the middleware\nby making required changes when the infrastructure\nscales.\n\
    (4) Big data and analytics: IoT sensors typically collect\na huge amount of data.\
    \ It is necessary to analyze\nall of this data in great detail. As a result a\
    \ lot of\nbig data algorithms are used to analyze IoT data.\nMoreover, it is possible\
    \ that due to the flimsy nature\nof the network some of the data collected might\
    \ be\nincomplete. It is necessary to take this into account\nand extrapolate data\
    \ by using sophisticated machine\nlearning algorithms.\n(5) Security and privacy:\
    \ IoT applications are mostly\nrelated to someone’s personal life or an industry.\n\
    Security and privacy issues need to be addressed in\nall such environments. The\
    \ middleware should have\nbuilt in mechanisms to address such issues, along with\n\
    user authentication, and the implementation of access\ncontrol.\n(6) Cloud services:\
    \ the cloud is an important part of an\nIoT deployment. Most of the sensor data\
    \ is analyzed\nand stored in a centralized cloud. It is necessary for\nIoT middleware\
    \ to seamlessly run on different types\nof clouds and to enable users to leverage\
    \ the cloud\nto get better insights from the data collected by the\nsensors.\n\
    (7) Context detection: the data collected from the sensors\nneeds to be used to\
    \ extract the context by applying\nvarious types of algorithms. The context can\
    \ subse-\nquently be used for providing sophisticated services\nto users.\nThere\
    \ are many middleware solutions available for the\nInternet of Things, which address\
    \ one or more of the\naforementioned issues. All of them support interoperabil-\n\
    ity and abstraction, which is the foremost requirement of\nmiddleware. Some examples\
    \ are Oracle’s Fusion Middleware,\nOpenIoT [21], MiddleWhere [22], and Hydra [23].\
    \ Middle-\nwares can be classified as follows on the basis of their design\n[72]:\n\
    (1) Event based: here, all the components interact with\neach other through events.\
    \ Each event has a type and\nsome parameters. Events are generated by producers\n\
    and received by the consumers. This can be viewed\nas a publish/subscribe architecture,\
    \ where entities can\nsubscribe for some event types and get notified for\nthose\
    \ events.\n(2) Service oriented: service oriented middlewares are\nbased on Service\
    \ Oriented Architectures (SOA), in\nwhich we have independent modules that provide\
    \ ser-\nvices through accessible interfaces. A service oriented\nmiddleware views\
    \ resources as service providers.\nIt abstracts the underlying resources through\
    \ a set\nof services that are used by applications. There is\n16\nJournal of Electrical\
    \ and Computer Engineering\na service repository, where services are published\n\
    by providers. The consumers can discover services\nfrom the repository and then\
    \ bind with the provider\nto access the service. Service oriented middleware\n\
    must have runtime support for advertising services\nby providers and support for\
    \ discovering and using\nservices by consumers.\nHYDRA [23] is a service oriented\
    \ middleware. It\nincorporates many software components, which are\nused in handling\
    \ various tasks required for the devel-\nopment of intelligent applications. Hydra\
    \ also pro-\nvides semantic interoperability using semantic web\ntechnologies.\
    \ It supports dynamic reconfiguration\nand self-management.\n(3) Database oriented:\
    \ in this approach, the network\nof IoT devices is considered as a virtual relational\n\
    database system. The database can then be queried\nby the applications using a\
    \ query language. There\nare easy to use interfaces for extracting data from\n\
    the database. This approach has issues with scaling\nbecause of its centralized\
    \ model.\n(4) Semantic: semantic middleware focuses on the inter-\noperation of\
    \ different types of devices, which commu-\nnicate using different formats of\
    \ data. It incorporates\ndevices with different data formats and ontologies and\n\
    ties all of them together in a common framework.\nThe framework is used for exchanging\
    \ data between\ndiverse types of devices. For a common semantic for-\nmat, we\
    \ need to have \U0001D441 adapters for communication\nbetween \U0001D441 devices\
    \ because; for each device, we need\nadapters to map \U0001D441 standards to one\
    \ abstract standard\n[73]. In such a semantic middleware [74], a semantic\nlayer\
    \ is introduced, in which there is a mapping from\neach resource to a software\
    \ layer for that resource.\nThe software layers then communicate with each\nother\
    \ using a mutually intelligible language (based\non the semantic web). This technique\
    \ allows multiple\nphysical resources to communicate even though they\ndo not\
    \ implement or understand the same protocols.\n(5) Application specific: this\
    \ type of middleware is used\nspecifically for an application domain for which\
    \ it\nis developed because the whole architecture of this\nmiddleware software\
    \ is fine-tuned on the basis of\nrequirements of the application. The application\
    \ and\nmiddleware are tightly coupled. These are not general\npurpose solutions.\n\
    8.1. Popular IoT Middleware\n8.1.1. FiWare. FiWare is a very popular IoT middleware\n\
    framework that is promoted by the EU. It has been designed\nkeeping smart cities,\
    \ logistics, and shop floor analytics in\nmind. FiWare contains a large body of\
    \ code, reusable mod-\nules, and APIs that have been contributed by thousands\
    \ of\nFiWare developers. Any application developer can take a\nsubset of these\
    \ components and build his/her IoT application.\nA typical IoT application has\
    \ many producers of data\n(sensors), a set of servers to process the data, and\
    \ a set\nof actuators. FiWare refers to the information collected by\nsensors\
    \ as context information. It defines generic REST APIs\nto capture the context\
    \ from different scenarios. All the context\ninformation is sent to a dedicated\
    \ service called a context\nbroker. FiWare provides APIs to store the context\
    \ and also\nquery it. Moreover, any application can register itself as a\ncontext\
    \ consumer, and it can request the context broker for\ninformation. It also supports\
    \ the publish-subscribe paradigm.\nSubsequently, the context can be supplied to\
    \ systems using\ncontext adapters whose main role is to transform the data (the\n\
    context) based on the requirements of the destination nodes.\nMoreover, FiWare\
    \ defines a set of SNMP APIs via which we\ncan control the behavior of IoT devices\
    \ and also configure\nthem.\nThe target applications are provided APIs to analyze,\n\
    query, and mine the information that is collected from the\ncontext broker. Additionally,\
    \ with advanced visualization\nAPIs, it is possible to create and deploy feature\
    \ rich applica-\ntions very quickly.\n8.1.2. OpenIoT. OpenIoT is another popular\
    \ open source\ninitiative. It has 7 different components. At the lowest level,\n\
    we have a physical plane. It collects data from IoT devices\nand also does some\
    \ preprocessing of data. It has different\nAPIs to interface with different types\
    \ of physical nodes and\nget information from them.\nThe next plane is the virtualized\
    \ plane, which has 3\ncomponents. We first have the scheduler, which manages the\n\
    streams of data generated by devices. It primarily assigns\nthem to resources\
    \ and takes care of their QoS requirements.\nThe data storage component manages\
    \ the storage and archival\nof data streams. Finally, the service delivery component\n\
    processes the streams. It has several roles. It combines\ndata streams, preprocesses\
    \ them, and tracks some statistics\nassociated with these streams such as the\
    \ number of unique\nrequests or the size of each request.\nThe uppermost layer,\
    \ that is, the application layer, also\nhas 3 components: request definition,\
    \ request presentation,\nand configuration. The request definition component helps\n\
    us create requests to be sent to the IoT sensors and storage\nlayers. It can be\
    \ used to fetch and query data. The request\npresentation component creates mashups\
    \ of data by issuing\ndifferent queries to the storage layer, and finally the\
    \ configu-\nration component helps us configure the IoT devices.\n9. Applications\
    \ of IoT\nThere are a diverse set of areas in which intelligent applica-\ntions\
    \ have been developed. All of these applications are not\nyet readily available;\
    \ however, preliminary research indicates\nthe potential of IoT in improving the\
    \ quality of life in our soci-\nety. Some uses of IoT applications are in home\
    \ automation,\nfitness tracking, health monitoring, environment protection,\n\
    smart cities, and industrial settings.\n9.1. Home Automation. Smart homes are\
    \ becoming more\npopular today because of two reasons. First, the sensor\nand\
    \ actuation technologies along with wireless sensor net-\nworks have significantly\
    \ matured. Second, people today trust\nJournal of Electrical and Computer Engineering\n\
    17\nSecurity\nEnergy\nconservation\nHassle-free\nlifestyle\nEntertainment\nAutomatic\
    \ operation\nof appliances\nGas sensors\nSmoke\nsensors\nHealth\nCare\nSmart\n\
    meters\nSmart\nThermostat\nCommunication\nwith smart grid\nRemote\nmonitoring\n\
    Smart\nlocks\nSmart\nirrigation\nSmart\nTV\nSecurity\ncameras\nFigure 8: Block\
    \ diagram of a smart home system.\ntechnology to address their concerns about\
    \ their quality of\nlife and security of their homes (see Figure 8).\nIn smart\
    \ homes, various sensors are deployed, which\nprovide intelligent and automated\
    \ services to the user. They\nhelp in automating daily tasks and help in maintaining\
    \ a\nroutine for individuals who tend to be forgetful. They help\nin energy conservation\
    \ by turning off lights and electronic\ngadgets automatically. We typically use\
    \ motion sensors for\nthis purpose. Motion sensors can be additionally used for\n\
    security also.\nFor example, the project, MavHome [75], provides an\nintelligent\
    \ agent, which uses various prediction algorithms\nfor doing automated tasks in\
    \ response to user triggered events\nand adapts itself to the routines of the\
    \ inhabitants. Predic-\ntion algorithms are used to predict the sequence of events\n\
    [76] in a home. A sequence matching algorithm maintains\nsequences of events in\
    \ a queue and also stores their frequency.\nThen a prediction is made using the\
    \ match length and\nfrequency. Other algorithms used by similar applications use\n\
    compression based prediction and Markov models.\nEnergy conservation in smart\
    \ homes [77] is typically\nachieved through sensors and context awareness. The\
    \ sen-\nsors collect data from the environment (light, temperature,\nhumidity,\
    \ gas, and fire events). This data from heterogeneous\nsensors is fed to a context\
    \ aggregator, which forwards the\ncollected data to the context aware service\
    \ engine. This engine\nselects services based on the context. For example, an\
    \ appli-\ncation can automatically turn on the AC when the humidity\nrises. Or,\
    \ when there is a gas leak, it can turn all the lights off.\nSmart home applications\
    \ are really beneficial for the\nelderly and differently abled. Their health is\
    \ monitored and\nrelatives are informed immediately in case of emergencies.\n\
    Floors are equipped with pressure sensors, which track the\nmovement of an individual\
    \ across the smart home and also\nhelp in detecting if a person has fallen down.\
    \ In smart homes,\nCCTV cameras can be used to record events of interest. These\n\
    can then be used for feature extraction to find out what is\ngoing on.\nIn specific,\
    \ fall detection applications in smart environ-\nments [78–80] are useful for\
    \ detecting if elderly people have\nfallen down. Yu et al. [80] use computer vision\
    \ based tech-\nniques for analyzing postures of the human body. Sixsmith\net al.\
    \ [79] used low cost infrared sensor array technology,\nwhich can provide information\
    \ such as the location, size,\nand velocity of a target object. It detects dynamics\
    \ of a fall\nby analyzing the motion patterns and also detects inactivity\nand\
    \ compares it with activity in the past. Neural networks\nare employed and sample\
    \ data is provided to the system for\nvarious types of falls. Many smartphone\
    \ based applications\nare also available, which detect a fall on the basis of\
    \ readings\nfrom the accelerometer and gyroscope data.\nThere are many challenges\
    \ and issues with regard to smart\nhome applications [81]. The most important\
    \ is security and\nprivacy [82] since all the data about the events taking place\
    \ in\nthe home is being recorded. If the security and trustworthi-\nness of the\
    \ system are not guaranteed, an intruder may attack\nthe system and may make the\
    \ system behave maliciously.\nSmart home systems are supposed to notify the owners\
    \ in case\nthey detect such abnormalities. This is possible using AI and\nmachine\
    \ learning algorithms, and researchers have already\nstarted working in this direction\
    \ [83]. Reliability is also an\nissue since there is no system administrator to\
    \ monitor the\nsystem.\n9.2. Smart Cities\n9.2.1. Smart Transport. Smart transport\
    \ applications can\nmanage daily traffic in cities using sensors and intelligent\n\
    information processing systems. The main aim of intelligent\ntransport systems\
    \ is to minimize traffic congestion, ensure\n18\nJournal of Electrical and Computer\
    \ Engineering\nDatacenter\nGateway\nSend status to cloud\nabout availability\n\
    Search for nearest\navailable parking\nParking space with sensors\nFigure 9: Block\
    \ diagram of a smart parking system.\neasy and hassle-free parking, and avoid\
    \ accidents by prop-\nerly routing traffic and spotting drunk drivers. The sensor\n\
    technologies governing these types of applications are GPS\nsensors for location,\
    \ accelerometers for speed, gyroscopes for\ndirection, RFIDs for vehicle identification,\
    \ infrared sensors\nfor counting passengers and vehicles, and cameras for record-\n\
    ing vehicle movement and traffic. There are many types of\napplications in this\
    \ area (refer to [84]):\n(1) Traffic surveillance and management applications:\n\
    vehicles are connected by a network to each other,\nthe cloud, and to a host of\
    \ IoT devices such as GPS\nsensors, RFID devices, and cameras. These devices\n\
    can estimate traffic conditions in different parts of the\ncity. Custom applications\
    \ can analyze traffic patterns\nso that future traffic conditions can be estimated.\
    \ Yu et\nal. [85] implement a vehicle tracking system for traffic\nsurveillance\
    \ using video sequences captured on the\nroads.\nTraffic congestion detection\
    \ can also be implemented\nusing smartphone sensors such as accelerometers\n[86]\
    \ and GPS sensors. These applications can detect\nmovement patterns of the vehicle\
    \ while the user is\ndriving. Such kind of information is already being\ncollected\
    \ by Google maps and users are using it to\nroute around potentially congested\
    \ areas of the city.\n(2) Applications to ensure safety: smart transport does\n\
    not only imply managing traffic conditions. It also\nincludes safety of people\
    \ travelling in their vehicles,\nwhich up till now was mainly in the hands of\
    \ drivers.\nThere are many IoT applications developed to help\ndrivers become\
    \ safer drivers. Such applications mon-\nitor driving behavior of drivers and\
    \ help them drive\nsafely by detecting when they are feeling drowsy or\ntired\
    \ and helping them to cope with it or suggesting\nrest [87, 88]. Technologies\
    \ used in such applications\nare face detection, eye movement detection, and\n\
    pressure detection on the steering (to measure the\ngrip of the driver’s hands\
    \ on the steering).\nA smartphone application, which estimates the\ndriver’s driving\
    \ behavior using smartphone sensors\nsuch as the accelerometer, gyroscope, GPS,\
    \ and cam-\nera, has been proposed by Eren et al. [89]. It can\ndecide whether\
    \ the driving is safe or rash by analyzing\nthe sensor data.\n(3) Intelligent\
    \ parking management (see Figure 9): in a\nsmart transportation system, parking\
    \ is completely\nhassle free as one can easily check on the Internet to\nfind\
    \ out which parking lot has free spaces. Such lots\nuse sensors to detect if the\
    \ slots are free or occupied by\nvehicles. This data is then uploaded to a central\
    \ server.\n(4) Smart traffic lights: traffic lights equipped with sens-\ning,\
    \ processing, and communication capabilities are\ncalled smart traffic lights.\
    \ These lights sense the\ntraffic congestion at the intersection and the amount\n\
    of traffic going each way. This information can be\nanalyzed and then sent to\
    \ neighboring traffic lights\nor a central controller. It is possible to use this\n\
    information creatively. For example, in an emergency\nsituation the traffic lights\
    \ can preferentially give way\nto an ambulance. When the smart traffic light senses\n\
    an ambulance coming, it clears the path for it and\nalso informs neighboring lights\
    \ about it. Technologies\nused in these lights are cameras, communication tech-\n\
    nologies, and data analysis modules. Such systems\nhave already been deployed\
    \ in Rio De Janeiro.\n(5) Accident detection applications: a smartphone appli-\n\
    cation designed by White et al. [90] detects the occur-\nrence of an accident\
    \ with the help of an accelerometer\nand acoustic data. It immediately sends this\
    \ informa-\ntion along with the location to the nearest hospital.\nJournal of\
    \ Electrical and Computer Engineering\n19\nSome additional situational information\
    \ such as on-\nsite photographs is also sent so that the first respon-\nders know\
    \ about the whole scenario and the degree of\nmedical help that is required.\n\
    9.2.2. Smart Water Systems. Given the prevailing amount of\nwater scarcity in\
    \ most parts of the world, it is very important\nto manage our water resources\
    \ efficiently. As a result most\ncities are opting for smart solutions that place\
    \ a lot of meters\non water supply lines and storm drains. A good reference\n\
    in this area is the paper by Hauber-Davidson and Idris [91].\nThey describe various\
    \ designs for smart water meters. These\nmeters can be used to measure the degree\
    \ of water inflow and\noutflow and to identify possible leaks. Smart water metering\n\
    systems are also used in conjunction with data from weather\nsatellites and river\
    \ water sensors. They can also help us predict\nflooding.\n9.2.3. Examples of\
    \ Smart Cities. Barcelona and Stockholm\nstand out in the list of smart cities.\
    \ Barcelona has a CityOS\nproject, where it aims to create a single virtualized\
    \ OS for\nall the smart devices and services offered within the city.\nBarcelona\
    \ has mainly focused on smart transportation (as\ndiscussed in Section 9.2.1)\
    \ and smart water. Smart transporta-\ntion is implemented using a network of sensors,\
    \ centralized\nanalysis, and smart traffic lights. On similar lines Barcelona\n\
    has sensors on most of its storm drains, water storage tanks,\nand water supply\
    \ lines. This information is integrated with\nweather and usage information. The\
    \ result of all of this is\na centralized water planning strategy. The city is\
    \ able to\nestimate the water requirements in terms of domestic usage\nand industrial\
    \ usage and for activities such as landscaping and\ngardening.\nStockholm started\
    \ way back in 1994, and its first step in\nthis direction was to install an extensive\
    \ fiber optic system.\nSubsequently, the city added thousands of sensors for smart\n\
    traffic and smart water management applications. Stockholm\nwas one of the first\
    \ cities to implement congestion charging.\nUsers were charged money, when they\
    \ drove into congested\nareas. This was enabled by smart traffic technologies.\
    \ Since\nthe city has a solid network backbone, it is very easy to\ndeploy sensors\
    \ and applications. For example, recently the\ncity created a smart parking system,\
    \ where it is possible to\neasily locate parking spots nearby. Parking lots have\
    \ sensors,\nwhich let a server know about their usage. Once a driver\nqueries\
    \ the server with her/his GPS location, she/he is guided\nto the nearest parking\
    \ lot with free slots. Similar innovations\nhave taken place in the city’s smart\
    \ buildings, snow clearance,\nand political announcement systems.\n9.3. Social\
    \ Life and Entertainment. Social life and entertain-\nment play an important role\
    \ in an individual’s life. Many\napplications have been developed, which keep\
    \ track of such\nhuman activities. The term “opportunistic IoT” [92] refers\n\
    to information sharing among opportunistic devices (devices\nthat seek to make\
    \ contact with other devices) based on\nmovement and availability of contacts\
    \ in the vicinity. Personal\ndevices such as tablets, wearables, and mobile phones\
    \ have\nsensing and short range communication capabilities. People\ncan find and\
    \ interact with each other when there is a common\npurpose.\nCircle Sense [93]\
    \ is an application, which detects social\nactivities of a person with the help\
    \ of various types of sensor\ndata. It identifies the social circle of a person\
    \ by analyzing\nthe patterns of social activities and the people present in\n\
    those activities. Various types of social activities and the set\nof people participating\
    \ in those activities are identified. It\nuses location sensors to find out where\
    \ the person is and\nuses Bluetooth for searching people around her. The system\n\
    has built in machine learning algorithms, and it gradually\nimproves its behavior\
    \ with learning.\nAffective computing [94] is a technology, which recog-\nnizes,\
    \ understands, stimulates, and responds to the emotions\nof human beings. There\
    \ are many parameters, which are\nconsidered while dealing with human affects\
    \ such as facial\nexpressions, speech, body gestures, hand movements, and\nsleep\
    \ patterns. These are analyzed to figure out how a person\nis feeling. The utterance\
    \ of emotional keywords is identified\nby voice recognition and the quality of\
    \ voice by looking at\nacoustic features of speech.\nOne of the applications of\
    \ affective computing is Camy,\nan artificial pet dog [95], which is designed\
    \ to interact with\nhuman beings and show affection and emotions. Many sen-\n\
    sors and actuators are embedded in it. It provides emotional\nsupport to the owner,\
    \ encourages playful and active behavior,\nrecognizes its owner, and shows love\
    \ for her and increases\nthe owner’s communication with other people. Based on\
    \ the\nowner’s mood, Camy interacts with the owner and gives her\nsuggestions.\n\
    Logmusic [96] is an entertainment application, which\nrecommends music on the\
    \ basis of the context, such as the\nweather, temperature, time, and location.\n\
    9.4. Health and Fitness. IoT appliances have proven really\nbeneficial in the\
    \ health and wellness domains. Many wearable\ndevices are being developed, which\
    \ monitor a person’s health\ncondition (see Figure 10).\nHealth applications make\
    \ independent living possible for\nthe elderly and patients with serious health\
    \ conditions. Cur-\nrently, IoT sensors are being used to continuously monitor\n\
    and record their health conditions and transmit warnings in\ncase any abnormal\
    \ indicators are found. If there is a minor\nproblem, the IoT application itself\
    \ may suggest a prescription\nto the patient.\nIoT applications can be used in\
    \ creating an Electronic\nHealth Record (EHR), which is a record of all the medical\n\
    details of a person. It is maintained by the health system. An\nEHR can be used\
    \ to record allergies, surges in blood sugar\nand blood pressure.\nStress recognition\
    \ applications are also fairly popular\n[97]. They can be realized using smartphone\
    \ sensors. Wang\net al. describe an application [30], which measures the stress\n\
    level of a college student and is installed on the student’s\nsmartphone. It senses\
    \ the locations the student visits during\nthe whole day, the amount of physical\
    \ activity, amount of\nsleep and rest, and her/his interaction and relationships\
    \ with\nother people (audio data and calls). In addition, it also\nconducts surveys\
    \ with the student by randomly popping up\n20\nJournal of Electrical and Computer\
    \ Engineering\nSmart devices with sensors: connected to \ngateway device (e.g.,\
    \ a smartphone)\nUser/patient\nGet health information\nfrom cloud\nSend data to\
    \ and from cloud,\nPerforms some processing on data \nDatacenter\nPerforms data\
    \ analysis on\nmeasurements of sensors\nMonitor\nuser’s health\nAnalyze the \n\
    measure-\nments\nSend feedback \nto cloud/ \npatient\nFigure 10: Block diagram\
    \ of a smart healthcare system.\na question in the smartphone. Using all of this\
    \ data and\nanalyzing it intelligently, the level of stress and academic\nperformance\
    \ can be measured.\nIn the fitness sector, we have applications that monitor\n\
    how fit we are based on our daily activity level. Smartphone\naccelerometer data\
    \ can be used for activity detection by\napplying complex algorithms. For example,\
    \ we can measure\nthe number of steps taken and the amount of exercise done\n\
    by using fitness trackers. Fitness trackers are available in the\nmarket as wearables\
    \ to monitor the fitness level of an indi-\nvidual. In addition, gym apparatus\
    \ can be fitted with sensors\nto count the number of times an exercise is performed.\
    \ For\nexample, a smart mat [98] can count the number of exercise\nsteps performed\
    \ on it. This is implemented using pressure\nsensors on the mat and then by analyzing\
    \ the patterns of\npressure, and the shape of the contact area.\n9.5. Smart Environment\
    \ and Agriculture. Environmental\nparameters such as temperature and humidity\
    \ are important\nfor agricultural production. Sensors are used by farmers in\n\
    the field to measure such parameters and this data can be\nused for efficient\
    \ production. One application is automated\nirrigation according to weather conditions.\n\
    Production using greenhouses [99] is one of the main\napplications of IoT in agriculture.\
    \ Environmental parameters\nmeasured in terms of temperature, soil information,\
    \ and\nhumidity are measured in real time and sent to a server for\nanalysis.\
    \ The results are then used to improve crop quality and\nyield.\nPesticide residues\
    \ in crop production are detected using\nan Acetylcholinesterase biosensor [100].\
    \ This data is saved\nand analyzed for extracting useful information such as the\n\
    sample size, time, location, and amount of residues. We can\nJournal of Electrical\
    \ and Computer Engineering\n21\nthus maintain the quality of the crop. Moreover,\
    \ a QR code\ncan be used to uniquely identify a carton of farm produce.\nConsumers\
    \ can scan the QR code and check the amount\nof pesticides in it (via a centralized\
    \ database) online before\nbuying.\nAir pollution is an important concern today\
    \ because it is\nchanging the climate of the earth and degrading air quality.\n\
    Vehicles cause a lot of air pollution. An IoT application\nproposed by Manna et\
    \ al. [39] monitors air pollution on the\nroads. It also tracks vehicles that\
    \ cause an undue amount of\npollution. Electrochemical toxic gas sensors can also\
    \ be used\nto measure air pollution. Vehicles are identified by RFID tags.\nRFID\
    \ readers are placed on both sides of the road along with\nthe gas sensors. With\
    \ this approach it is possible to identify\nand take action against polluting\
    \ vehicles.\n9.6. Supply Chain and Logistics. IoT tries to simplify real\nworld\
    \ processes in business and information systems [101].\nThe goods in the supply\
    \ chain can be tracked easily from\nthe place of manufacture to the final places\
    \ of distribution\nusing sensor technologies such as RFID and NFC. Real\ntime\
    \ information is recorded and analyzed for tracking.\nInformation about the quality\
    \ and usability of the product can\nalso be saved in RFID tags attached with the\
    \ shipments.\nBo and Guangwen [102] explain an information transmis-\nsion system\
    \ for supply chain management, which is based\non the Internet of Things. RFID\
    \ tags uniquely identify a\nproduct automatically and a product information network\n\
    is created to transmit this information in real time along\nwith location information.\
    \ This system helps in automatic\ncollection and analysis of all the information\
    \ related to supply\nchain management, which may help examine past demand\nand\
    \ come up with a forecast of future demand. Supply chain\ncomponents can get access\
    \ to real time data and all of this\ninformation can be analyzed to get useful\
    \ insights. This will\nin the long run improve the performance of supply chain\n\
    systems.\n9.7. Energy Conservation. The smart grid is information and\ncommunication\
    \ technology enabled modern electricity gen-\neration, transmission, distribution,\
    \ and consumption system\n[103].\nTo make electric power generation, transmission,\
    \ and\ndistribution smart, the concept of smart grids adds intel-\nligence at\
    \ each step and also allows the two-way flow of\npower (back from the consumer\
    \ to the supplier). This can\nsave a lot of energy and help consumers better understand\n\
    the flow of power and dynamic pricing. In a smart grid,\npower generation is distributed.\
    \ There are sensors deployed\nthroughout the system to monitor everything. It\
    \ is actually a\ndistributed network of microgrids [104]. Microgrids generate\n\
    power to meet demands of local sites and transmit back\nthe surplus energy to\
    \ the central grid. Microgrids can also\ndemand energy from the central grid in\
    \ case of a shortfall.\nTwo-way flow of power also benefits consumers, who are\n\
    also using their own generated energy occasionally (say, solar,\nor wind power);\
    \ the surplus power can be transmitted back so\nthat it is not wasted. The user\
    \ will also get paid for that power.\nSome of the IoT applications in a smart\
    \ grid are online\nmonitoring of transmission lines for disaster prevention and\n\
    efficient use of power in smart homes by having a smart meter\nfor monitoring\
    \ energy consumption [105].\nSmart meters read and analyze consumption patterns\
    \ of\npower at regular and peak load times. This information is\nthen sent to\
    \ the server and also made available to the user. The\ngeneration is then set\
    \ according to the consumption patterns.\nIn addition, the user can adjust her/his\
    \ use so as to reduce\ncosts. Smart power appliances can leverage this information\n\
    and operate when the prices are low.\n10. Design Considerations in an IoT System\n\
    Now, that we have profiled most of the IoT technologies, let\nus look at some\
    \ of the design considerations for designing a\npractical IoT network.\nThe first\
    \ consideration is the design of the sensors. Even\nthough there might not be\
    \ much of a choice regarding\nthe sensors, there is definitely a lot of choice\
    \ regarding\nthe processing and networking capabilities that are bundled\nalong\
    \ with the sensors. Our choices range from small sub-\nmW boards meant for sensor\
    \ motes to Arduino or Atom\nboards that consume 300–500 mW of power. This choice\n\
    depends on the degree of analytics and data preprocessing\nthat we want to perform\
    \ at the sensor itself. Secondly, there\nis an issue of logistics also. To create\
    \ a sub-mW board, we\nneed board design expertise, and this might not be readily\n\
    available. Hence, it might be advisable to bundle a sensor with\ncommercially\
    \ available embedded processor kits.\nThe next important consideration is communication.\
    \ In\nIoT nodes, power is the most dominant issue. The power\nrequired to transmit\
    \ and receive messages is a major fraction\nof the overall power, and as a result\
    \ a choice of the networking\ntechnology is vital. The important factors that\
    \ we need\nto consider are the distance between the sender and the\nreceiver,\
    \ the nature of obstacles, signal distortion, ambient\nnoise, and governmental\
    \ regulations. Based on these key\nfactors, we need to choose a given wireless\
    \ networking\nprotocol. For example, if we just need to communicate\ninside a\
    \ small building, we can use Zigbee, whereas if we\nneed communication in a smart\
    \ city, we should choose\nSigfox or LoraWAN. In addition, often there are significant\n\
    constraints on the frequency and the power that can be spent\nin transmission.\
    \ These limitations are mainly imposed by\ngovernment agencies. An apt decision\
    \ needs to be made by\ntaking all of these factors into account.\nLet us then\
    \ come to the middleware. The first choice that\nneeds to be made is to choose\
    \ between an open source mid-\ndleware such as FiWare or a proprietary solution.\
    \ There are\npros and cons of both. It is true that open source middleware\nis\
    \ in theory more flexible; however, they may have limited\nsupport for IoT devices.\
    \ We ideally want a middleware\nsolution to interoperate with all kinds of communication\n\
    protocols and devices; however, that might not be the case.\nHence, if we need\
    \ strict compatibility with certain devices and\nprotocols, a proprietary solution\
    \ is better. Nevertheless, open\nsource offerings have cost advantages and are\
    \ sometimes\neasier to deploy. We also need to choose the communication\n22\n\
    Journal of Electrical and Computer Engineering\nprotocol and ensure that it is\
    \ compatible with the firewalls\nin the organizations involved. In general choosing\
    \ a protocol\nbased on HTTP is the best from this point of view. We also\nneed\
    \ to choose between TCP and UDP. UDP is always better\nfrom the point of view\
    \ of power consumption. Along with\nthese considerations, we also need to look\
    \ at options to store\nsensor data streams, querying languages, and support for\n\
    generating dynamic alerts.\nFinally, let us consider the application layer. Most\
    \ IoT\nframeworks provide significant amount of support for cre-\nating the application\
    \ layer. This includes data mining, data\nprocessing, and visualization APIs.\
    \ Creating mashups and\ndashboards of data is nowadays very easy to do given the\n\
    extensive support provided by IoT frameworks. Nevertheless,\nhere the tradeoff\
    \ is between the features provided and the\nresources that are required. We do\
    \ not need a very heavy\nframework if we do not desire a lot of features. This\
    \ call needs\nto be taken by the application developers.\n11. Conclusion\nIn this\
    \ survey paper we presented a survey of the current\ntechnologies used in the\
    \ IoT domain as of 2016. Currently,\nthis field is in a very nascent stage. The\
    \ technologies in\nthe core infrastructure layers are showing signs of maturity.\n\
    However, a lot more needs to happen in the areas of IoT\napplications and communication\
    \ technologies. These fields\nwill definitely mature and impact human life in\
    \ inconceivable\nways over the next decade.\nCompeting Interests\nThe authors\
    \ declare that there is no conflict of interests\nregarding the publication of\
    \ this paper.\nReferences\n[1] O. Vermesan, P. Friess, P. Guillemin et al., “Internet\
    \ of things\nstrategic research roadmap,” in Internet of Things: Global Tech-\n\
    nological and Societal Trends, vol. 1, pp. 9–52, 2011.\n[2] I. Pe˜na-L´opez, Itu\
    \ Internet Report 2005: The Internet of Things,\n2005.\n[3] I. Mashal, O. Alsaryrah,\
    \ T.-Y. Chung, C.-Z. Yang, W.-H. Kuo,\nand D. P. Agrawal, “Choices for interaction\
    \ with things on Inter-\nnet and underlying issues,” Ad Hoc Networks, vol. 28,\
    \ pp. 68–\n90, 2015.\n[4] O. Said and M. Masud, “Towards internet of things: survey\
    \ and\nfuture vision,” International Journal of Computer Networks, vol.\n5, no.\
    \ 1, pp. 1–17, 2013.\n[5] M. Wu, T.-J. Lu, F.-Y. Ling, J. Sun, and H.-Y. Du, “Research\n\
    on the architecture of internet of things,” in Proceedings of the\n3rd International\
    \ Conference on Advanced Computer Theory and\nEngineering (ICACTE ’10), vol. 5,\
    \ pp. V5-484–V5-487, IEEE,\nChengdu, China, August 2010.\n[6] R. Khan, S. U. Khan,\
    \ R. Zaheer, and S. Khan, “Future internet:\nthe internet of things architecture,\
    \ possible applications and key\nchallenges,” in Proceedings of the 10th International\
    \ Conference\non Frontiers of Information Technology (FIT ’12), pp. 257–260,\n\
    December 2012.\n[7] H. Ning and Z. Wang, “Future internet of things architecture:\n\
    like mankind neural system or social organization framework?”\nIEEE Communications\
    \ Letters, vol. 15, no. 4, pp. 461–463, 2011.\n[8] M. Weyrich and C. Ebert, “Reference\
    \ architectures for the\ninternet of things,” IEEE Software, vol. 33, no. 1, pp.\
    \ 112–116, 2016.\n[9] J. Gubbi, R. Buyya, S. Marusic, and M. Palaniswami, “Internet\n\
    of Things (IoT): a vision, architectural elements, and future\ndirections,” Future\
    \ Generation Computer Systems, vol. 29, no. 7,\npp. 1645–1660, 2013.\n[10] F.\
    \ Bonomi, R. Milito, P. Natarajan, and J. Zhu, “Fog computing:\na platform for\
    \ internet of things and analytics,” in Big Data and\nInternet of Things: A Road\
    \ Map for Smart Environments, pp. 169–\n186, Springer, Berlin, Germany, 2014.\n\
    [11] F. Bonomi, R. Milito, J. Zhu, and S. Addepalli, “Fog computing\nand its role\
    \ in the internet of things,” in Proceedings of the 1st\nACM MCC Workshop on Mobile\
    \ Cloud Computing, pp. 13–16,\n2012.\n[12] I. Stojmenovic and S. Wen, “The fog\
    \ computing paradigm:\nscenarios and security issues,” in Proceedings of the Federated\n\
    Conference on Computer Science and Information Systems (Fed-\nCSIS ’14), pp. 1–8,\
    \ IEEE, Warsaw, Poland, September 2014.\n[13] M. Aazam and E.-N. Huh, “Fog computing\
    \ and smart gateway\nbased communication for cloud of things,” in Proceedings\
    \ of the\n2nd IEEE International Conference on Future Internet of Things\nand\
    \ Cloud (FiCloud ’14), pp. 464–470, Barcelona, Spain, August\n2014.\n[14] L. Atzori,\
    \ A. Iera, and G. Morabito, “SIoT: giving a social struc-\nture to the internet\
    \ of things,” IEEE Communications Letters,\nvol. 15, no. 11, pp. 1193–1195, 2011.\n\
    [15] M. Swan, “Sensor mania! The internet of things, wearable\ncomputing, objective\
    \ metrics, and the quantified self 2.0,” Jour-\nnal of Sensor and Actuator Networks,\
    \ vol. 1, no. 3, pp. 217–253,\n2012.\n[16] N. D. Lane, E. Miluzzo, H. Lu, D. Peebles,\
    \ T. Choudhury, and A.\nT. Campbell, “A survey of mobile phone sensing,” IEEE\
    \ Com-\nmunications Magazine, vol. 48, no. 9, pp. 140–150, 2010.\n[17] L. Atzori,\
    \ A. Iera, and G. Morabito, “The Internet of Things: a\nsurvey,” Computer Networks,\
    \ vol. 54, no. 15, pp. 2787–2805, 2010.\n[18] A. Whitmore, A. Agarwal, and L.\
    \ Da Xu, “The internet of\nthings—a survey of topics and trends,” Information\
    \ Systems\nFrontiers, vol. 17, no. 2, pp. 261–274, 2015.\n[19] D. Zeng, S. Guo,\
    \ and Z. Cheng, “The web of things: a survey,”\nJournal of Communications, vol.\
    \ 6, no. 6, pp. 424–438, 2011.\n[20] S. Bandyopadhyay, M. Sengupta, S. Maiti,\
    \ and S. Dutta, “Role\nof middleware for internet of things: a study ,” International\n\
    Journal of Computer Science & Engineering Survey, vol. 2, no.\n3, pp. 94–105,\
    \ 2011.\n[21] J. Soldatos, N. Kefalakis, M. Hauswirth et al., “Openiot: open\n\
    source internet of-things in the cloud,” in Interoperability and\nOpen-Source\
    \ Solutions for the Internet of Things: International\nWorkshop, FP7 OpenIoT Project,\
    \ Held in Conjunction with Soft-\nCOM 2014, Split, Croatia, September 18, 2014,\
    \ Invited Papers, vol.\n9001 of Lecture Notes in Computer Science, pp. 13–25,\
    \ Springer,\nBerlin, Germany, 2015.\n[22] A. Ranganathan, J. Al-Muhtadi, S. Chetan,\
    \ R. Campbell, and\nM. D. Mickunas, “Middlewhere: a middleware for location\n\
    awareness in ubiquitous computing applications,” in ACM/IFIP/\nUSENIX International\
    \ Conference on Distributed Systems Plat-\nforms and Open Distributed Processing\
    \ Middleware 2004, pp.\n397–416, Springer, New York, NY, USA, 2004.\nJournal of\
    \ Electrical and Computer Engineering\n23\n[23] M. Eisenhauer, P. Rosengren, and\
    \ P. Antolin, “A development\nplatform for integrating wireless devices and sensors\
    \ into ambi-\nent intelligence systems,” in Proceedings of the 6th IEEE Annual\n\
    Communications Society Conference on Sensor, Mesh and Ad Hoc\nCommunications and\
    \ Networks Workshops (SECON Workshops\n’09), pp. 1–3, IEEE, Rome, Italy, June\
    \ 2009.\n[24] T. Zahariadis, A. Papadakis, F. Alvarez et al., “FIWARE lab:\nmanaging\
    \ resources and services in a cloud federation support-\ning future internet applications,”\
    \ in Proceedings of the 7th IEEE/\nACM International Conference on Utility and\
    \ Cloud Computing\n(UCC ’14), pp. 792–799, IEEE, London, UK, December 2014.\n\
    [25] A. Schmidt and K. Van Laerhoven, “How to build smart\nappliances?” IEEE Personal\
    \ Communications, vol. 8, no. 4, pp.\n66–71, 2001.\n[26] W. Z. Khan, Y. Xiang,\
    \ M. Y. Aalsalem, and Q. Arshad, “Mobile\nphone sensing systems: a survey,” IEEE\
    \ Communications Sur-\nveys & Tutorials, vol. 15, no. 1, pp. 402–427, 2013.\n\
    [27] Accelerometers, Chris Woodford, http://www.explainthatstuff\n.com/accelerometers.html.\n\
    [28] How Do Global Positioning Systems, or GPS, Work?, 2005,\nhttps://www.nasa.gov/audience/foreducators/topnav/materials/\n\
    listbytype/How Do Global Positioning Systems.html#\n.VmxoY5Ph5z0.\n[29] A. Anjum\
    \ and M. U. Ilyas, “Activity recognition using smart-\nphone sensors,” in Proceedings\
    \ of the IEEE 10th Consumer Com-\nmunications and Networking Conference (CCNC\
    \ ’13), pp. 914–\n919, Las Vegas, Nev, USA, January 2013.\n[30] R. Wang, F. Chen,\
    \ Z. Chen et al., “Studentlife: assessing mental\nhealth, academic performance\
    \ and behavioral trends of college\nstudents using smartphones,” in Proceedings\
    \ of the ACM Inter-\nnational Joint Conference on Pervasive and Ubiquitous Com-\n\
    puting (UbiComp ’14), pp. 3–14, Seattle, Wash, USA, September\n2014.\n[31] F.\
    \ J. McClernon and R. R. Choudhury, “I am your smartphone,\nand i know you are\
    \ about to smoke: the application of mobile\nsensing and computing approaches\
    \ to smoking research and\ntreatment,” Nicotine and Tobacco Research, vol. 15,\
    \ no. 10, pp.\n1651–1654, 2013.\n[32] L. Pei, R. Guinness, R. Chen et al., “Human\
    \ behavior cognition\nusing smartphone sensors,” Sensors, vol. 13, no. 2, pp.\
    \ 1402–1424,\n2013.\n[33] N. Bui and M. Zorzi, “Health care applications: a solution\n\
    based on the internet of things,” in Proceedings of the 4th Inter-\nnational Symposium\
    \ on Applied Sciences in Biomedical and Com-\nmunication Technologies (ISABEL\
    \ ’11), ACM, Barcelona, Spain,\nOctober 2011.\n[34] M. J. McGrath and C. N. Scanaill,\
    \ “Body-worn, ambient, and\nconsumer sensing for health applications,” in Sensor\
    \ Technolo-\ngies, pp. 181–216, Springer, 2013.\n[35] A. Pantelopoulos and N.\
    \ G. Bourbakis, “A survey on wearable\nsensor-based systems for health monitoring\
    \ and prognosis,”\nIEEE Transactions on Systems, Man and Cybernetics Part C:\n\
    Applications and Reviews, vol. 40, no. 1, pp. 1–12, 2010.\n[36] J. H. Gruzelier,\
    \ “EEG-neurofeedback for optimising perfor-\nmance. I: a review of cognitive and\
    \ affective outcome in healthy\nparticipants,” Neuroscience and Biobehavioral\
    \ Reviews, vol. 44,\npp. 124–141, 2014.\n[37] P. K. Sekhar, E. L. Brosha, R. Mukundan,\
    \ and F. H. Garzon,\n“Chemical sensors for environmental monitoring and home-\n\
    land security,” The Electrochemical Society Interface, vol. 19, no.\n4, pp. 35–40,\
    \ 2010.\n[38] N. Bhattacharyya and R. Bandhopadhyay, “Electronic nose\nand electronic\
    \ tongue,” in Nondestructive Evaluation of Food\nQuality, pp. 73–100, Springer,\
    \ Berlin, Germany, 2010.\n[39] S. Manna, S. S. Bhunia, and N. Mukherjee, “Vehicular\
    \ pollution\nmonitoring using IoT,” in International Conference on Recent\nAdvances\
    \ and Innovations in Engineering, ICRAIE 2014, ind,\nMay 2014.\n[40] R. Want,\
    \ “An introduction to RFID technology,” IEEE Pervasive\nComputing, vol. 5, no.\
    \ 1, pp. 25–33, 2006.\n[41] X. Zhu, S. K. Mukhopadhyay, and H. Kurata, “A review\
    \ of\nRFID technology and its managerial applications in different\nindustries,”\
    \ Journal of Engineering and Technology Management,\nvol. 29, no. 1, pp. 152–167,\
    \ 2012.\n[42] E. Welbourne, L. Battle, G. Cole et al., “Building the internet\n\
    of things using RFID: the RFID ecosystem experience,” IEEE\nInternet Computing,\
    \ vol. 13, no. 3, pp. 48–55, 2009.\n[43] M. Yannuzzi, R. Milito, R. Serral-Gracia,\
    \ D. Montero, and M.\nNemirovsky, “Key ingredients in an IoT recipe: fog computing,\n\
    cloud computing, and more fog computing,” in Proceedings\nof the IEEE 19th International\
    \ Workshop on Computer Aided\nModeling and Design of Communication Links and Networks\n\
    (CAMAD ’14), pp. 325–329, Athens, Greece, December 2014.\n[44] H. T. Dinh, C.\
    \ Lee, D. Niyato, and P. Wang, “A survey of mobile\ncloud computing: architecture,\
    \ applications, and approaches,”\nWireless Communications and Mobile Computing,\
    \ vol. 13, no. 18,\npp. 1587–1611, 2013.\n[45] I. Stojmenovic, “Fog computing:\
    \ a cloud to the ground support\nfor smart things and machine-to-machine networks,”\
    \ in Pro-\nceedings of the Australasian Telecommunication Networks and\nApplications\
    \ Conference (ATNAC ’14), pp. 117–122, Melbourne,\nAustralia, November 2014.\n\
    [46] M. Aazam, P. P. Hung, and E.-N. Huh, “Smart gateway based\ncommunication\
    \ for cloud of things,” in Proceedings of the 9th\nIEEE International Conference\
    \ on Intelligent Sensors, Sensor\nNetworks and Information Processing (IEEE ISSNIP\
    \ ’14), IEEE,\nApril 2014.\n[47] P. Agrawal and S. Bhuraria, “Near field communication,”\
    \ SET-\nLabs Bridfings, vol. 10, no. 1, pp. 67–74, 2012.\n[48] V. Coskun, B. Ozdenizci,\
    \ and K. Ok, “A survey on near field\ncommunication (NFC) technology,” Wireless\
    \ Personal Commu-\nnications, vol. 71, no. 3, pp. 2259–2294, 2013.\n[49] K. Curran,\
    \ A. Millar, and C. Mc Garvey, “Near Field Com-\nmunication,” International Journal\
    \ of Electrical and Computer\nEngineering (IJECE), vol. 2, no. 3, 2012.\n[50]\
    \ Z. Sheng, S. Yang, Y. Yu, A. Vasilakos, J. Mccann, and K.\nLeung, “A survey\
    \ on the ietf protocol suite for the internet of\nthings: standards, challenges,\
    \ and opportunities,” IEEE Wireless\nCommunications, vol. 20, no. 6, pp. 91–98,\
    \ 2013.\n[51] J. P. Vasseur and A. Dunkels, “Ip for smart objects,” White Paper\n\
    1, IPSO Alliance, 2008.\n[52] D. Culler and S. Chakrabarti, “6lowpan: incorporating\
    \ IEEE\n802.15. 4 into the IP architecture, IPSO Alliance,” White Paper,\n2009.\n\
    [53] J. Vasseur, N. Agarwal, J. Hui, Z. Shelby, P. Bertrand, and C.\nChauvenet,\
    \ “Rpl: the ip routing protocol designed for low power\nand lossy networks,” Internet\
    \ Protocol for Smart Objects (IPSO)\nAlliance 36, 2011.\n[54] J. P. Vasseur, C.\
    \ P. Bertrand, B. Aboussouan et al., “A survey of\nseveral low power link layers\
    \ for IP smart objects,” White Paper,\nIPSO Alliance, 2010.\n24\nJournal of Electrical\
    \ and Computer Engineering\n[55] J. W. Hui and D. E. Culler, “Extending IP to\
    \ low-power, wireless\npersonal area networks,” IEEE Internet Computing, vol.\
    \ 12, no.\n4, pp. 37–45, 2008.\n[56] W. Colitti, K. Steenhaut, N. De Caro, B.\
    \ Buta, and V. Dobrota,\n“Evaluation of constrained application protocol for wireless\n\
    sensor networks,” in Proceedings of the 18th IEEE Workshop on\nLocal and Metropolitan\
    \ Area Networks (LANMAN ’11), pp. 1–6,\nIEEE, Chapel Hill, NC, USA, October 2011.\n\
    [57] Z. Shelby, K. Hartke, and C. Bormann, “The constrained\napplication protocol\
    \ (CoAP),” Tech. Rep., IETF, 2014.\n[58] B. C. Villaverde, D. Pesch, R. De Paz\
    \ Alberola, S. Fedor, and\nM. Boubekeur, “Constrained application protocol for\
    \ low power\nembedded networks: a survey,” in Proceedings of the 6th Interna-\n\
    tional Conference on Innovative Mobile and Internet Services in\nUbiquitous Computing\
    \ (IMIS ’12), pp. 702–707, Palermo, Italy,\nJuly 2012.\n[59] D. Locke, “MQ telemetry\
    \ transport (MQTT) v3. 1 protocol\nspecification,” IBM developerWorks Technical\
    \ Library, 2010,\nhttp://www.ibm.com/developerworks/webservices/library/ws-\n\
    mqtt/index.html.\n[60] U. Hunkeler, H. L. Truong, and A. Stanford-Clark, “MQTT-S—\n\
    a publish/subscribe protocol for wireless sensor networks,” in\nProceedings of\
    \ the 3rd IEEE/Create-Net International Conference\non Communication System Software\
    \ and Middleware (COM-\nSWARE ’08), pp. 791–798, Bangalore, India, January 2008.\n\
    [61] A. Stanford-Clark and H. Linh Truon, “MQTT for sensor\nnetworks (MQTT-S)\
    \ protocol specification,” International Busi-\nness Machines Corporation Version\
    \ 1, 2008.\n[62] C. Gomez, J. Oller, and J. Paradells, “Overview and evaluation\n\
    of bluetooth low energy: an emerging low-power wireless\ntechnology,” Sensors,\
    \ vol. 12, no. 9, pp. 11734–11753, 2012.\n[63] K.-H. Chang, “Bluetooth: a viable\
    \ solution for IoT? [Industry\nPerspectives],” IEEE Wireless Communications, vol.\
    \ 21, no. 6, pp.\n6–7, 2014.\n[64] C. F. Hughes, Bluetooth low energy [Ph.D. thesis],\
    \ Arizona State\nUniversity, 2015.\n[65] M. Siekkinen, M. Hiienkari, J. K. Nurminen,\
    \ and J. Nieminen,\n“How low energy is bluetooth low energy? Comparative mea-\n\
    surements with ZigBee/802.15.4,” in Proceedings of the IEEE\nWireless Communications\
    \ and Networking Conference Work-\nshops (WCNCW ’12), pp. 232–237, Paris, France,\
    \ April 2012.\n[66] B. Shanmuga Sundaram, “A quantitative analysis of 802.11ah\n\
    wireless standard,” International Journal of Latest Research in\nEngineering and\
    \ Technology, vol. 2, 2016.\n[67] W. Sun, M. Choi, and S. Choi, “Ieee 802.11 ah:\
    \ a long range 802.11\nwlan at sub 1 ghz,” Journal of ICT Standardization, vol.\
    \ 1, no. 1,\npp. 83–108, 2013.\n[68] P. Baronti, P. Pillai, V. W. C. Chook, S.\
    \ Chessa, A. Gotta, and Y.\nF. Hu, “Wireless sensor networks: a survey on the\
    \ state of the\nart and the 802.15.4 and ZigBee standards,” Computer Commu-\n\
    nications, vol. 30, no. 7, pp. 1655–1695, 2007.\n[69] H. Liu, M. Bolic, A. Nayak,\
    \ and I. Stojmenovi´c, “Taxonomy\nand challenges of the integration of RFID and\
    \ wireless sensor\nnetworks,” IEEE Network, vol. 22, no. 6, pp. 26–32, 2008.\n\
    [70] A. Mitrokotsa and C. Douligeris, “Integrated RFID and sensor\nnetworks: architectures\
    \ and applications,” in RFID and Sensor\nNetworks: Architectures, Protocols, Security\
    \ and Integrations, pp.\n511–535, Auerbach Publications, 2009.\n[71] M. A. Chaqfeh\
    \ and N. Mohamed, “Challenges in middleware\nsolutions for the internet of things,”\
    \ in Proceedings of the\n13th International Conference on Collaboration Technologies\
    \ and\nSystems (CTS ’12), pp. 21–26, Denver, Colo, USA, May 2012.\n[72] M. A.\
    \ Razzaque, M. Milojevic-Jevric, A. Palade, and S. Cla,\n“Middleware for internet\
    \ of things: a survey,” IEEE Internet of\nThings Journal, vol. 3, no. 1, pp. 70–95,\
    \ 2016.\n[73] Z. Song, A. A. C´ardenas, and R. Masuoka, “Semantic mid-\ndleware\
    \ for the internet of things,” in Proceedings of the 2nd\nInternational Internet\
    \ of Things Conference (IoT ’10), December\n2010.\n[74] A. Katasonov, O. Kaykova,\
    \ O. Khriyenko, S. Nikitin, and\nV. Terziyan, “Smart semantic middleware for the\
    \ internet of\nthings,” in Proceedings of the 5th International Conference on\n\
    Informatics in Control, Automation and Robotics (ICINCO ’08),\npp. 169–178, Funchal,\
    \ Portugal, May 2008.\n[75] D. J. Cook, M. Youngblood, E. O. Heierman III et al.,\n\
    “MavHome: an agent-based smart home,” in Proceedings of the\n1st IEEE International\
    \ Conference on Pervasive Computing and\nCommunications (PerCom ’03), pp. 521–524,\
    \ March 2003.\n[76] S. K. Das, D. J. Cook, A. Bhattacharya, E. O. Heierman III,\
    \ and\nT.-Y. Lin, “The role of prediction algorithms in the MavHome\nsmart home\
    \ architecture,” IEEE Wireless Communications, vol.\n9, no. 6, pp. 77–84, 2002.\n\
    [77] D.-M. Han and J.-H. Lim, “Design and implementation of smart\nhome energy\
    \ management systems based on ZigBee,” IEEE\nTransactions on Consumer Electronics,\
    \ vol. 56, no. 3, pp. 1417–\n1425, 2010.\n[78] N. Noury, T. Herv´e, V. Rialle\
    \ et al., “Monitoring behavior\nin home using a smart fall sensor and position\
    \ sensors,” in\nProceedings of the 1st Annual International IEEE-EMBS Special\n\
    Topic Conference on Microtechnologies in Medicine and Biology\n(MMB ’00), pp.\
    \ 607–610, Lyon, France, October 2000.\n[79] A. Sixsmith and N. Johnson, “A smart\
    \ sensor to detect the falls\nof the elderly,” IEEE Pervasive Computing, vol.\
    \ 3, no. 2, pp. 42–\n47, 2004.\n[80] M. Yu, A. Rhuma, S. M. Naqvi, L. Wang, and\
    \ J. Chambers, “A\nposture recognition-based fall detection system for monitoring\n\
    an elderly person in a smart home environment,” IEEE Trans-\nactions on Information\
    \ Technology in Biomedicine, vol. 16, no. 6,\npp. 1274–1286, 2012.\n[81] W. Keith\
    \ Edwards and R. E. Grinter, “At home with ubiquitous\ncomputing: seven challenges,”\
    \ in Ubicomp 2001: Ubiquitous\nComputing, pp. 256–272, Springer, 2001.\n[82] R.\
    \ J. Robles and T.-H. Kim, “A Review on security in smart\nhome development,”\
    \ International Journal of Smart Home, vol.\n15, 2010.\n[83] R. J. Robles, T.-H.\
    \ Kim, D. Cook, and S. Das, “A review on\nsecurity in smart home development,”\
    \ International Journal of\nAdvanced Science and Technology, vol. 15, 2010.\n\
    [84] G. Dimitrakopoulos, “Intelligent transportation systems based\non internet-connected\
    \ vehicles: fundamental research areas and\nchallenges,” in Proceedings of the\
    \ 11th International Conference\non ITS Telecommunications (ITST ’11), pp. 145–151,\
    \ IEEE, Saint\nPetersburg, Russia, August 2011.\n[85] S.-H. Yu, J.-W. Hsieh, Y.-S.\
    \ Chen, and W.-F. Hu, “An automatic\ntraffic surveillance system for vehicle tracking\
    \ and classifica-\ntion,” in Image Analysis, pp. 379–386, Springer, 2003.\n[86]\
    \ M. Lv, L. Chen, G. Chen, and D. Zhang, “Detecting traffic\ncongestions using\
    \ cell phone accelerometers,” in Proceedings of\nthe International Joint Conference\
    \ on Pervasive and Ubiquitous\nComputing (UbiComp ’14), pp. 107–110, Seattle,\
    \ Wash, USA,\nSeptember 2014.\n[87] W. Hu, X. Hu, J.-Q. Deng et al., “Mood-fatigue\
    \ analyzer: towards\ncontext-aware mobile sensing applications for safe driving,”\n\
    Journal of Electrical and Computer Engineering\n25\nin Proceedings of the 1st\
    \ ACM Workshop on Middleware for\nContext-Aware Applications in the IoT (M4IOT\
    \ ’14), pp. 19–24,\nACM, Bordeaux, France, December 2014.\n[88] H. Singh, J. S.\
    \ Bhatia, and J. Kaur, “Eye tracking based driver\nfatigue monitoring and warning\
    \ system,” in Proceedings of the\nIndia International Conference on Power Electronics\
    \ (IICPE ’10),\npp. 1–6, New Delhi, India, January 2011.\n[89] H. Eren, S. Makinist,\
    \ E. Akin, and A. Yilmaz, “Estimating\ndriving behavior by a smartphone,” in Proceedings\
    \ of the IEEE\nIntelligent Vehicles Symposium (IV ’12), pp. 234–239, Madrid,\n\
    Spain, June 2012.\n[90] J. White, C. Thompson, H. Turner, B. Dougherty, and D.\
    \ C.\nSchmidt, “WreckWatch: automatic traffic accident detection\nand notification\
    \ with smartphones,” Mobile Networks and Appli-\ncations, vol. 16, no. 3, pp.\
    \ 285–303, 2011.\n[91] G. Hauber-Davidson and E. Idris, “Smart water metering,”\n\
    Water, vol. 33, no. 3, pp. 56–59, 2006.\n[92] B. Guo, D. Zhang, Z. Wang, Z. Yu,\
    \ and X. Zhou, “Opportunistic\nIoT: Exploring the harmonious interaction between\
    \ human\nand the internet of things,” Journal of Network and Computer\nApplications,\
    \ vol. 36, no. 6, pp. 1531–1539, 2013.\n[93] G. Liang, J. Cao, and W. Zhu, “CircleSense:\
    \ a pervasive comput-\ning system for recognizing social activities,” in Proceedings\
    \ of the\n11th IEEE International Conference on Pervasive Computing and\nCommunications\
    \ (PerCom ’13), pp. 201–206, IEEE, San Diego,\nCalif, USA, March 2013.\n[94] R.\
    \ W. Picard and R. Picard, Affective Computing, vol. 252, MIT\nPress, Cambridge,\
    \ UK, 1997.\n[95] Y.-K. Row and T.-J. Nam, “CAMY: applying a pet dog analogy\n\
    to everyday ubicomp products,” in Proceedings of the ACM\nInternational Joint\
    \ Conference on Pervasive and Ubiquitous\nComputing (UbiComp ’14), pp. 63–74,\
    \ Seattle, Wash, USA,\nSeptember 2014.\n[96] M. Lee and J.-D. Cho, “Logmusic:\
    \ context-based social music\nrecommendation service on mobile device,” in Proceedings\
    \ of\nthe ACM International Joint Conference on Pervasive and Ubiq-\nuitous Computing\
    \ (UbiComp ’14), pp. 95–98, Seattle, Wash,\nUSA, September 2014.\n[97] K. Frank,\
    \ P. Robertson, M. Gross, and K. Wiesner, “Sensor-\nbased identification of human\
    \ stress levels,” in Proceedings of\nthe IEEE International Conference on Pervasive\
    \ Computing and\nCommunications Workshops (PerCom Workshops ’13), pp. 127–\n132,\
    \ San Diego, Calif, USA, March 2013.\n[98] M. Sundholm, J. Cheng, B. Zhou, A.\
    \ Sethi, and P. Lukowicz,\n“Smart-mat: recognizing and counting gym exercises\
    \ with low-\ncost resistive pressure sensing matrix,” in Proceedings of the\n\
    ACM International Joint Conference on Pervasive and Ubiq-\nuitous Computing (UbiComp\
    \ ’14), pp. 373–382, Seattle, Wash,\nUSA, September 2014.\n[99] J.-C. Zhao, J.-F.\
    \ Zhang, Y. Feng, and J.-X. Guo, “The study\nand application of the IOT technology\
    \ in agriculture,” in Pro-\nceedings of the 3rd IEEE International Conference\
    \ on Computer\nScience and Information Technology (ICCSIT ’10), pp. 462–465,\n\
    Chengdu, China, July 2010.\n[100] G. Zhao, Y. Guo, X. Sun, and X. Wang, “A system\
    \ for pesticide\nresidues detection and agricultural products traceability based\n\
    on acetylcholinesterase biosensor and internet of things,” Inter-\nnational Journal\
    \ of Electrochemical Science, vol. 10, no. 4, pp.\n3387–3399, 2015.\n[101] P.\
    \ Ferreira, R. Martinho, and D. Domingos, “Iot-aware business\nprocesses for logistics:\
    \ limitations of current approaches,” in\nProceedings of the Inforum Conference,\
    \ vol. 3, pp. 612–613, 2010.\n[102] Y. Bo and H. Guangwen, “Supply chain information\
    \ transmis-\nsion based on RFID and internet of things,” in Proceedings\nof the\
    \ Second ISECS International Colloquium on Computing,\nCommunication, Control,\
    \ and Management (CCCM ’09), pp.\n166–169, Sanya, China, August 2009.\n[103] S.\
    \ Karnouskos, “The cooperative internet of things enabled\nsmart grid,” in Proceedings\
    \ of the 14th IEEE International Sym-\nposium on Consumer Electronics (ISCE ’10),\
    \ pp. 7–10, June 2010.\n[104] H. Farhangi, “The path of the smart grid,” IEEE\
    \ Power and\nEnergy Magazine, vol. 8, no. 1, pp. 18–28, 2010.\n[105] J. Liu, X.\
    \ Li, X. Chen, Y. Zhen, and L. Zeng, “Applications of\ninternet of things on smart\
    \ grid in China,” in Proceedings of\nthe 13th International Conference on Advanced\
    \ Communication\nTechnology: Smart Service Innovation through Mobile Interactiv-\n\
    ity (ICACT ’11), pp. 13–17, February 2011.\nInternational Journal of\nAerospace\n\
    Engineering\nHindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\n\
    Robotics\nJournal of\nHindawi Publishing Corporation\nhttp://www.hindawi.com\n\
    Volume 2014\nHindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\n\
    \ Active and Passive  \nElectronic Components\nControl Science\nand Engineering\n\
    Journal of\nHindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\n\
    \ International Journal of\n Rotating\nMachinery\nHindawi Publishing Corporation\n\
    http://www.hindawi.com\nVolume 2014\nHindawi Publishing Corporation \nhttp://www.hindawi.com\n\
    \ Journal of\nEngineering\nVolume 2014\nSubmit your manuscripts at\nhttps://www.hindawi.com\n\
    VLSI Design\nHindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\n\
    Hindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\nShock and\
    \ Vibration\nHindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\n\
    Civil Engineering\nAdvances in\nAcoustics and Vibration\nAdvances in\nHindawi\
    \ Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\nHindawi Publishing\
    \ Corporation\nhttp://www.hindawi.com\nVolume 2014\nElectrical and Computer \n\
    Engineering\nJournal of\nAdvances in\nOptoElectronics\nHindawi Publishing Corporation\
    \ \nhttp://www.hindawi.com\nVolume 2014\nThe Scientific \nWorld Journal\nHindawi\
    \ Publishing Corporation \nhttp://www.hindawi.com\nVolume 2014\nSensors\nJournal\
    \ of\nHindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\nModelling\
    \ & \nSimulation \nin Engineering\nHindawi Publishing Corporation \nhttp://www.hindawi.com\n\
    Volume 2014\nHindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\n\
    Chemical Engineering\nInternational Journal of\n Antennas and\nPropagation\nInternational\
    \ Journal of\nHindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\n\
    Hindawi Publishing Corporation\nhttp://www.hindawi.com\nVolume 2014\nNavigation\
    \ and \n Observation\nInternational Journal of\nHindawi Publishing Corporation\n\
    http://www.hindawi.com\nVolume 2014\nDistributed\nSensor Networks\nInternational\
    \ Journal of\n"
  inline_citation: '>'
  journal: Journal of Electrical and Computer Engineering
  limitations: '>'
  pdf_link: http://downloads.hindawi.com/journals/jece/2017/9324035.pdf
  publication_year: 2017
  relevance_score1: 0
  relevance_score2: 0
  title: 'Internet of Things: Architectures, Protocols, and Applications'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/comst.2019.2904897
  analysis: '>'
  authors:
  - Chaoyun Zhang
  - Paul Patras
  - Hamed Haddadi
  citation_count: 1115
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Loading [MathJax]/extensions/TeX/boldsymbol.js
    IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account
    Personal Sign In Browse My Settings Help Access provided by: University of Nebraska
    - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards
    Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Communications Surveys
    &... >Volume: 21 Issue: 3 Deep Learning in Mobile and Wireless Networking: A Survey
    Publisher: IEEE Cite This PDF Chaoyun Zhang; Paul Patras; Hamed Haddadi All Authors
    1028 Cites in Papers 33708 Full Text Views Abstract Document Sections I. Introduction
    II. Related High-Level Articles and the Scope of This Survey III. Deep Learning
    101 IV. Enabling Deep Learning in Mobile Networking V. Deep Learning: State-of-the-Art
    Show Full Outline Authors Figures References Citations Keywords Metrics Footnotes
    Abstract: The rapid uptake of mobile devices and the rising popularity of mobile
    applications and services pose unprecedented demands on mobile and wireless networking
    infrastructure. Upcoming 5G systems are evolving to support exploding mobile traffic
    volumes, real-time extraction of fine-grained analytics, and agile management
    of network resources, so as to maximize user experience. Fulfilling these tasks
    is challenging, as mobile environments are increasingly complex, heterogeneous,
    and evolving. One potential solution is to resort to advanced machine learning
    techniques, in order to help manage the rise in data volumes and algorithm-driven
    applications. The recent success of deep learning underpins new and powerful tools
    that tackle problems in this space. In this paper, we bridge the gap between deep
    learning and mobile and wireless networking research, by presenting a comprehensive
    survey of the crossovers between the two areas. We first briefly introduce essential
    background and state-of-the-art in deep learning techniques with potential applications
    to networking. We then discuss several techniques and platforms that facilitate
    the efficient deployment of deep learning onto mobile systems. Subsequently, we
    provide an encyclopedic review of mobile and wireless networking research based
    on deep learning, which we categorize by different domains. Drawing from our experience,
    we discuss how to tailor deep learning to mobile environments. We complete this
    survey by pinpointing current challenges and open future directions for research.
    Published in: IEEE Communications Surveys & Tutorials ( Volume: 21, Issue: 3,
    thirdquarter 2019) Page(s): 2224 - 2287 Date of Publication: 13 March 2019 ISSN
    Information: DOI: 10.1109/COMST.2019.2904897 Publisher: IEEE Authors Figures References
    Citations Keywords Metrics Footnotes More Like This Payment Type Classification
    on Urban Taxi Big Data using Deep Learning Neural Network 2018 International Conference
    on Advanced Computer Science and Information Systems (ICACSIS) Published: 2018
    Comparative Analysis of Neural Networks and Deep Learning using Wireless Communication
    2022 2nd International Conference on Advance Computing and Innovative Technologies
    in Engineering (ICACITE) Published: 2022 Show More IEEE Personal Account CHANGE
    USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile
    Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS
    Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT
    Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use |
    Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy
    A not-for-profit organization, IEEE is the world''s largest technical professional
    organization dedicated to advancing technology for the benefit of humanity. ©
    Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE Communications Surveys and Tutorials
  limitations: '>'
  pdf_link: null
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: 'Deep Learning in Mobile and Wireless Networking: A Survey'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1049/iet-wss.2020.0091
  analysis: '>'
  authors:
  - Amina El Attaoui
  - Salma Largo
  - Soufiane Kaissari
  - Achraf Benba
  - Abdelilah Jilbab
  - Abdennaser Bourouhou
  citation_count: 11
  full_citation: '>'
  full_text: '>

    Web Store Add shortcut Name URL Customize Chrome'
  inline_citation: '>'
  journal: IET wireless sensor systems
  limitations: '>'
  pdf_link: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/iet-wss.2020.0091
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: Machine learning‐based edge‐computing on a multi‐level architecture of WSN
    and IoT for real‐time fall detection
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/access.2020.2970143
  analysis: '>'
  authors:
  - Adil Rasheed
  - Omer San
  - Trond Kvamsdal
  citation_count: 739
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy IEEE.org IEEE Xplore IEEE
    SA IEEE Spectrum More Sites Subscribe Donate Cart Create Account Personal Sign
    In Personal Sign In * Required *Email Address *Password Forgot Password? Sign
    In Don''t have a Personal Account? Create an IEEE Account now. Create Account
    Learn more about personalization features. IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/8948470/08972429.pdf
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: 'Digital Twin: Values, Challenges and Enablers From a Modeling Perspective'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.dcan.2017.10.002
  analysis: '>'
  authors:
  - Mohammad Saeid Mahdavinejad
  - Mohammadreza Rezvan
  - Mohammadamin Barekatain
  - Peyman Adibi
  - Payam Barnaghi
  - Amit P. Sheth
  citation_count: 746
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Abstract Keywords 1. Introduction 2. Literature review 3. Internet of
    Things 4. Smart city 5. Taxonomy of machine learning algorithms 6. Discussion
    of taxonomy of machine learning algorithms 7. Research trends and open issues
    8. Conclusions Acknowledgments References Show full outline Figures (6) Tables
    (3) Table 1 Table 2 Table 3 Digital Communications and Networks Volume 4, Issue
    3, August 2018, Pages 161-175 Machine learning for internet of things data analysis:
    a survey Author links open overlay panel Mohammad Saeid Mahdavinejad a b, Mohammadreza
    Rezvan a b, Mohammadamin Barekatain c, Peyman Adibi a, Payam Barnaghi d, Amit
    P. Sheth b Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.dcan.2017.10.002
    Get rights and content Under a Creative Commons license open access Abstract Rapid
    developments in hardware, software, and communication technologies have facilitated
    the emergence of Internet-connected sensory devices that provide observations
    and data measurements from the physical world. By 2020, it is estimated that the
    total number of Internet-connected devices being used will be between 25 and 50
    billion. As these numbers grow and technologies become more mature, the volume
    of data being published will increase. The technology of Internet-connected devices,
    referred to as Internet of Things (IoT), continues to extend the current Internet
    by providing connectivity and interactions between the physical and cyber worlds.
    In addition to an increased volume, the IoT generates big data characterized by
    its velocity in terms of time and location dependency, with a variety of multiple
    modalities and varying data quality. Intelligent processing and analysis of this
    big data are the key to developing smart IoT applications. This article assesses
    the various machine learning methods that deal with the challenges presented by
    IoT data by considering smart cities as the main use case. The key contribution
    of this study is the presentation of a taxonomy of machine learning algorithms
    explaining how different techniques are applied to the data in order to extract
    higher level information. The potential and challenges of machine learning for
    IoT data analytics will also be discussed. A use case of applying a Support Vector
    Machine (SVM) to Aarhus smart city traffic data is presented for a more detailed
    exploration. Previous article in issue Next article in issue Keywords Machine
    learningInternet of ThingsSmart dataSmart City 1. Introduction Emerging technologies
    in recent years and major enhancements to Internet protocols and computing systems,
    have made communication between different devices easier than ever before. According
    to various forecasts, around 25–50 billion devices are expected to be connected
    to the Internet by 2020. This has given rise to the newly developed concept of
    Internet of Things (IoT). IoT is a combination of embedded technologies including
    wired and wireless communications, sensor and actuator devices, and the physical
    objects connected to the Internet [1], [2]. One of the long-standing objectives
    of computing is to simplify and enrich human activities and experiences (e.g.,
    see the visions associated with “The Computer for the 21st Century” [3] or “Computing
    for Human Experience” [4]). IoT requires data to either represent better services
    to users or enhance the IoT framework performance to accomplish this intelligently.
    In this manner, systems should be able to access raw data from different resources
    over the network and analyze this information in order to extract knowledge. Since
    IoT will be among the most significant sources of new data, data science will
    provide a considerable contribution to making IoT applications more intelligent.
    Data science is the combination of different scientific fields that uses data
    mining, machine learning, and other techniques to find patterns and new insights
    from data. These techniques include a broad range of algorithms applicable in
    different domains. The process of applying data analytics methods to particular
    areas involves defining data types such as volume, variety, and velocity; data
    models such as neural networks, classification, and clustering methods, and applying
    efficient algorithms that match with the data characteristics. By following our
    reviews, the following is deduced: First, because data is generated from different
    sources with specific data types, it is important to adopt or develop algorithms
    that can handle the data characteristics. Second, the great number of resources
    that generate data in real-time are not without the problem of scale and velocity.
    Finally, finding the best data model that fits the data is one of the most important
    issues for pattern recognition and for better analysis of IoT data. These issues
    have opened a vast number of opportunities in expanding new developments. Big
    data is defined as high-volume, high-velocity, and high variety data that demands
    cost-effective, innovative forms of information processing that enable enhanced
    insight, decision making, and process automation [5]. With respect to the challenges
    posed by big data, it is necessary to introduce a new concept termed smart data,
    which means: ”realizing productivity, efficiency, and effectiveness gains by using
    semantics to transform raw data into Smart Data” [6]. A more recent definition
    of this concept is: ”Smart Data provides value from harnessing the challenges
    posed by volume, velocity, variety, and veracity of Big Data, and in turn providing
    actionable information and improving decision making.” [7]. Finally, smart data
    can act as a good representative for IoT data. 1.1. The Contributions of this
    paper The objective here is to answer the following questions: A) How can machine
    learning algorithms be applied to IoT smart data? B) What is the taxonomy of machine
    learning algorithms that can be adopted in IoT? C) What are the characteristics
    of IoT data in the real world? D) Why is the smart city a typical use case of
    IoT applications? A) To understand which algorithm is more appropriate for processing
    and decision-making on smart data generated from the things in IoT, it is essential
    to consider the following three concepts. First, the IoT application (Section
    3). Second, the IoT data characteristics (Section 4.2), and third, the data-driven
    vision of machine learning algorithms (Section 5). We finally discuss the issues
    in Section 6. B) Around 70 articles in the field of IoT data analysis are reviewed,
    revealing that there exist eight major groups of algorithms applicable to IoT
    data. These algorithms are categorized according to their structural similarities,
    types of data they can handle, and the amount of data they can process in a reasonable
    time. C) Having reviewed the real-world perspective of how IoT data is analyzed
    by over 20 authors, many significant and insightful results have been revealed
    regarding data characteristics. We discuss the results in Section 6 and Table
    1. To gain a deeper insight into IoT smart data, patterns must be extracted and
    the generated data interpreted. Cognitive algorithms undertake interpretation
    and matching, much as the human mind would do. Cognitive IoT systems previously
    learn from generated data and improve when performing repeated tasks. Cognitive
    computing acts as a prosthetic for human cognition by analyzing massive amount
    of data and responding to questions that humans might have when making certain
    decisions. Cognitive IoT plays an important role in enabling the extraction of
    meaningful patterns from generated IoT smart data [8]. Table 1. Characteristic
    of smart data in smart cities. Smart city use cases Type of data Where data processed
    References Smart Traffic Stream/Massive Data Edge [14], [43] Smart Health Stream/Massive
    Data Edge/Cloud [44] Smart Environment Stream/Massive Data Cloud [45] Smart Weather
    Prediction Stream Data Edge [46] Smart Citizen Stream Data Cloud [47], [48] Smart
    Agriculture Stream Data Edge/Cloud [49] Smart Home Massive/Historical Data Cloud
    [50] Smart Air Controlling Massive/Historical Data Cloud [38] Smart Public Place
    Monitoring Historical Data Cloud [51] Smart Human Activity Control Stream/Historical
    Data Edge/Cloud [52], [53] D) A smart city has been selected as our primary use
    case in IoT for three reasons: First, among all of the reviewed articles the focus
    of 60 percent is on the field of the smart cities. Second, smart cities include
    many of the other use cases in IoT. Third, there are many open datasets for smart
    city applications that are easily accessible for researchers. Furthermore, a Support
    Vector Machine (SVM) algorithm is implemented on the Aarhus City smart traffic
    data to predict traffic hours during one day. By answering the above questions
    about IoT smart data and machine learning algorithms, we would be able to choose
    the best machine learning algorithm that can handle IoT smart data characteristics.
    Unlike similar surveys regarding machine learning and IoT, readers of this article
    would be able to obtain a deep and technical understanding of machine learning
    algorithms, IoT applications, and IoT data characteristics along with both technical
    and simple implementations. 1.2. Organization The rest of this paper is organized
    as follows. Related articles in this field are reviewed and reported in Section
    2. IoT applications and communication protocols, computing frameworks, IoT architecture,
    and smart city segments are reviewed, explained, summarized, and illustrated in
    Section 3. The quality of data, big data generation, sensor data integration,
    and semantic data annotation are reviewed in Section 4. Machine learning algorithms
    in eight categories based on recent studies on IoT data and frequency of machine
    learning algorithms are reviewed and summarized in Section 5. The matching of
    the algorithms to particular smart city applications is carried out in Section
    6, and the conclusion together with future research trends and open issues are
    presented in Section 7, Fig. 1 shows the structure of the survey. Download : Download
    high-res image (184KB) Download : Download full-size image Fig. 1. Organization
    of survey. 2. Literature review Since IoT represents a new concept for the Internet
    and smart data, it is a challenging area in the field of computer science. The
    important challenges for researchers with respect to IoT consist of preparing
    and processing data. Ref. [9] proposed four data mining models for processing
    IoT data. The first is a multi layer model, based on a data collection layer,
    a data management layer, an event processing model, and a data mining service
    layer. The second model is a distributed data mining model, proposed for data
    deposition at different sites. The third is a grid-based data mining model where
    the authors seek to implement heterogeneous, large scale, and high performance
    applications. The final model is a data mining model from a multi technology integration
    perspective, where a corresponding framework for the future Internet is described.
    Ref. [10] performed research into warehousing Radio Frequency Identification (RFID)
    data, with a focus specifically on managing and mining RFID stream data. Ref.
    [11] introduced a systematic method for reviewing data mining knowledge and techniques
    in most common applications. In this study, they reviewed some data mining functions
    like classification, clustering, association analysis, time series analysis, and
    outline detection. They revealed that the data generated by data mining applications,
    such as e-commerce, industry, healthcare, and city governance are similar to that
    of the IoT data. Following their findings, they assigned the most popular data
    mining functionality to the application and determined which data mining functionality
    was the most appropriate for processing each specific application''s data. Ref.
    [12] ran a survey to respond to some of the challenges in preparing and processing
    data on the IoT through data mining techniques. The authors divided their research
    into three major sections. In the first and second sections, they explain IoT,
    the data, and the challenges that exist in this area, such as building a model
    for mining, and mining algorithms for IoT. In the third section, they discuss
    the potential and open issues that exist in this field. Here, it is summarized
    that data mining on IoT data involves three major concerns: First, it must be
    shown that processing the data will solve the chosen problems. Next, the data
    characteristics must be extracted from the generated data, and then, the appropriate
    algorithm is chosen according to the taxonomy of algorithms and data characteristics.
    Ref. [13] attempted to explain the smart city infrastructure in IoT and discussed
    advanced communication to support added-value services for the administration
    of the city and citizens thereof. The authors provide a comprehensive review of
    enabling technologies, protocols, and architectures for smart city. In the technical
    part of the article, the authors reviewed the data of Padova Smart City. 3. Internet
    of Things The purpose of Internet of Things (IoT) is to develop a smarter environment
    and a simplified life-style by saving time, energy, and money. Through this technology,
    expenses in different industries can be reduced. The enormous investments and
    many studies running on IoT have made IoT a growing trend in recent years. IoT
    consists of a set of connected devices that can transfer data among one another
    in order to optimize their performance; these actions occur automatically and
    without human awareness or input. IoT includes four main components: 1) sensors,
    2)processing networks, 3) data analysis data, and 4) system monitoring. The most
    recent advances made in IoT began when RFID tags were put into use more frequently,
    lower cost sensors became more available, web technology developed, and communication
    protocols changed [14], [15]. The IoT is integrated with various technologies,
    and connectivity is a necessary and sufficient condition for it to function. Therefore,
    communication protocols are constituents of this technology that should be enhanced
    [16], [17]. In IoT, communication protocols can be divided into three major components:
    (1) Device to Device (D2D): this type of communication enables communication between
    nearby mobile phones. This represents the next generation of cellular networks.
    (2) Device to Server (D2S): in this type of communication device, all the data
    is sent to the servers, which can be close or far from the devices. This type
    of communication is mostly applied to cloud processing. (3) Server to Server (S2S):
    in this type of communication, servers transmit data between each other. This
    type of communication is mostly applied for cellular networks. Processing and
    preparing data for these communications is a critical challenge. To respond to
    this challenge, different kinds of data processing, such as analytics at the edge,
    stream analysis, and IoT analysis at the database, must be applied. The decision
    to apply any of the mentioned processes depends on the particular application
    and its needs [18]. Fog and cloud processing are two analytical methods adopted
    for processing and preparing data before transferring it to other things. The
    whole task of IoT is summarized as follows: First, sensors and IoT devices collect
    information from the environment. Next, knowledge is extracted from the raw data.
    Then, data is ready for transferring to other objects, devices, or servers through
    the Internet. 3.1. Computing framework Another important part of IoT is the computing
    framework of processing data, the most famous of which are fog and cloud computing.
    IoT applications use both frameworks depending on the application and process
    location. In some applications, data should be processed upon generation, while
    in other applications it is not necessary to process data immediately. The instant
    processing of data and the network architecture that supports it is known as fog
    computing. Collectively, these are applied for edge computing [19]. 3.1.1. Fog
    computing Here, the architecture of fog computing is applied to migrating information
    from a data center task to the edge of the servers. This architecture is built
    based on the edge servers. Fog computing provides limited computing, storage,
    and network services, also providing logical intelligence and filtering of data
    for data centers. This architecture has been and is being implemented in vital
    areas like eHealth and military applications [20], [21]. 3.1.2. Edge computing
    In this architecture, processing is run at a distance from the core, toward the
    edge of the network. This type of processing enables data to be initially processed
    at edge devices. Devices at the edge may not be connected to the network in a
    continuous manner, and so they require a copy of the master data/reference data
    for offline processing. Edge devices have different features such as 1) enhancing
    security, 2) filtering and cleaning data, and 3) storing local data for local
    use [22]. 3.1.3. Cloud computing Here, data for processing is sent to data centers,
    and after being analyzed and processed, they become accessible. This architecture
    has high latency and high load balancing, indicating that this architecture is
    not sufficient for processing IoT data because most processing should run at high
    speeds. The volume of this data is high, and big data processing will increase
    the CPU usage of the cloud servers [23]. There are various types of cloud computing:
    (1) Infrastructure as a Service (IaaS): where the company purchases all the equipment
    like hardware, servers, and networks. (2) Platform as a Service (PaaS): where
    all the equipment above is placed for rent on the Internet. (3) Software as a
    Service(SaaS): where a distributed software model is presented. In this model,
    all practical software will be hosted by a service provider and is accessible
    to the users through the Internet [24]. (4) Mobile Backend as a Service (MBaaS):
    also known as Backend as a Service (BaaS), provides a web or mobile application
    with a path in order to connect the application to the backend cloud storage.
    MBaaS provides features like user management, push notifications, and integration
    with social network services. This cloud service benefits from an Application
    Programming Interface (API) and software Development Kits (SDK). 3.1.4. Distributed
    computing This architecture is designed for processing high volumes of data. In
    IoT applications, because the sensors generate data in a repetitive manner, big
    data challenges are encountered [22], [25]. To overcome this phenomenon, distributed
    computing is designed to divide data into packets, and assign the packets to different
    computers for processing. This distributed computing has different frameworks
    like Hadoop and Spark. When migrating from cloud to fog and distributed computing,
    the following phenomena occur: 1) a decrease in network loading, 2) an increase
    in data processing speed, 3) a reduction in CPU usage, 4) a reduction in energy
    consumption, and 5) an ability to process a higher volume of data. Because the
    smart city is one of the primary applications of IoT, the most important use cases
    of the smart city and their data characteristics are discussed in the following
    sections. 4. Smart city Cities always demand services to enhance the quality of
    life and make existing services more efficient. In the last few years, the concept
    of smart cities has played an important role in academia and industry [26]. With
    an increase in the population and complexity of city infrastructures, cities seek
    methods to handle large-scale urbanization problems. IoT plays a vital role in
    collecting data from the city environment. IoT enables cities to use live status
    reports and smart monitoring systems to react more intelligently to emerging situations
    such as earthquakes and volcanoes. By adopting IoT technologies in city, the majority
    of the city''s assets can be connected to one another, making them more readily
    observable, and consequently, more easy to monitor and manage. The purpose of
    building smart cities is to improve services like traffic management, water management,
    and energy consumption, as well as improving the quality of life for the citizens.
    The objective of smart cities is to transform rural and urban areas into places
    of democratic innovation [27]. Such smart cities seek to decrease the expenses
    in public health, safety, transportation, and resource management, thus assisting
    their economies [28]. In Ref. [29], the authors believe that in the long term,
    the vision for a smart city would be that all the cities'' systems and structures
    will monitor their own conditions and carry out self-repair upon need. 4.1. Use
    case A city has an important effect on society because the city touches all aspects
    of human life. A smart city can assist in having a comfortable life. The use cases
    for smart cities consist of smart energy, smart mobility, smart citizens, and
    urban planning. This division is based on a review of the latest studies in this
    field and the most recent reports released by McKinsey and Company. 4.1.1. Smart
    energy Smart energy is one of the most important research areas of IoT because
    it is essential to reduce overall power consumption [30]. It offers high-quality
    and affordable environmentally friendly energy. Smart energy includes a variety
    of operational and energy measures, including Smart energy applications, smart
    leak monitoring, and renewable energy resources, etc. Using smart energy (i.e.,
    deployment of a smart grid) implies a fundamental re-engineering of the electricity
    services [31]. The smart grid is one of the most important applications of smart
    energy. It includes many high-speed time series data to monitor key devices. For
    managing this kind of data, [32] introduced a method to manage and analyze time
    series data in order to make them organized on demand. Moreover, the smart energy
    infrastructure will become more complex in the future, and therefore [33] proposed
    a simulation system to test new concepts and optimization approaches and forecast
    future consumption. Another important application of smart energy is leak monitoring
    systems. The objective of such a system is to model a water or gas management
    system that would optimize energy resource consumption [34], [35]. 4.1.2. Smart
    mobility Mobility is another important aspect of any city. Through IoT, city officials
    can improve the quality of life in the city. Smart mobility can be divided into
    the following three major components: (1) Autonomous cars: IoT will have a broad
    range of effects on how vehicles are run. The most important question is about
    how IoT can improve vehicle services. IoT sensors and wireless connections make
    it possible to create self-driving cars and monitor vehicle performance. With
    the data collected from vehicles, the most popular/congested routes can be predicted,
    and decisions can be made to decrease traffic congestion. Self-driving cars can
    improve passenger safety because they have the ability to monitor the driving
    of the other cars. (2) Traffic control: Optimizing the traffic flow by analyzing
    sensor data is another part of mobility in the city. For traffic control, traffic
    data will be collected from cars, road cameras, and counter sensors installed
    on roads. (3) Public transportation: IoT can improve the public transportation
    system management by providing accurate location and routing information to a
    smart transportation system. It can assist passengers in making better decisions
    in their schedules as well as decrease the amount of wasted time. There exist
    different perspectives on how to build smart public transportation systems. These
    systems need to manage different kinds of data like vehicle location data and
    traffic data. Smart public transportation systems should be real-time oriented
    in order to make proper decisions in real-time as well as use historical data
    analysis [36]. For instance, [37] proposed a mechanism that considers smart city
    devices as graph nodes, and the authors used big data solutions to solve these
    issues. 4.1.3. Smart citizens This use case for smart cities covers a broad range
    of areas in human lives, such as environmental monitoring, crime monitoring, and
    social health. The environment with all its components is fundamental and vital
    for life. Consequently, making progress in technology is guaranteed to enhance
    security. Close monitoring devoted to crime would also contribute to overall social
    health. 4.1.4. Urban planning Another important aspect in use cases for the smart
    city is reaching long-term decisions. Because the city and environment both play
    major roles in human life, reaching decisions in this context is critical. By
    collecting data from different sources, it is possible to make a decision for
    the future of the city. Making decisions affecting the city infrastructure, design,
    and functionality is called urban planning. IoT is beneficial in this area because
    through smart city data analysis, the authorities can predict which part of the
    city will be more crowded in the future and find solutions for the potential problems.
    A combination of IoT and urban planning would have a major effect on scheduling
    future infrastructure improvements. 4.2. Smart city data characteristics Smart
    city devices generate data in a continuous manner, indicating that the data gathered
    from traffic, health, and energy management applications would generate a sizable
    volume. In addition, because the data generation rate varies for different devices,
    processing data with different generation rates is a challenge. For example, the
    frequency of GPS sensor updates is measured in seconds, while the frequency of
    updates for temperature sensors may be measured hourly. Whether the data generation
    rate is high or low, there always exists a danger of losing important information.
    To integrate the sensory data collected from heterogeneous sources is challenging
    [14], [38]. Ref. [39] applied big data analytic methods to distinguish the correlation
    between the temperature and traffic data in Santander, Spain. Ref. [40] proposed
    a new framework integrating big data analysis and Industrial Internet of Things
    (IIoT) technologies for Offshore Support Vessels (OSV) based on a hybrid CPU/GPU
    high-performance computing platform. Another characteristic is the dynamic nature
    of the data. Data for autonomous cars is an example of dynamic data because the
    sensor results will change based on different locations and times. The quality
    of the collected data is important, particularly for smart city data, which have
    different qualities due to the fact that they are generated from heterogeneous
    sources. According to Ref. [41], the quality of information from each data source
    depends on three factors: 1) Error in measurements or precision of data collection.
    2) Devices'' noise in the environment. 3) Discrete observation and measurements.
    To achieve a better Quality of Information (QoI), it is necessary to extract higher
    levels of abstraction and provide actionable information to other services. QoI
    in smart data depends on the applications and characteristics of data. There exist
    different solutions to improve QoI. For example, to improve the accuracy of data,
    selecting trustworthy sources and combining the data from multiple resources is
    of key importance. By increasing the frequency and density of sampling, the precision
    of the observations and measurements will be improved, which would lead to a reduction
    in environmental noise. The data characteristics in both IoT and the smart city
    are illustrated in Fig. 2. Semantic data annotation is another prime solution
    to enhancing data quality. Smart devices generate raw data with low-level abstractions.
    For this reason, the semantic models provide interpretable descriptions of data,
    its quality, and its original attributes [28]. Semantic annotation is beneficial
    in interpretable and knowledge-based information fusion [42]. Smart data characteristics
    in smart cities are tabulated in brief, in Table 1. Download : Download high-res
    image (132KB) Download : Download full-size image Fig. 2. Data characteristics.
    5. Taxonomy of machine learning algorithms Machine learning is a subfield of computer
    science, and is a type of Artificial Intelligence (AI) that provides machines
    with the ability to learn without explicit programming. Machine learning evolved
    from pattern recognition and computational learning theory. Here, some essential
    concepts of machine learning are discussed as well as the frequently applied machine
    learning algorithms for smart data analysis. A learning algorithm takes a set
    of samples as an input named a training set. In general, there exist three main
    categories of learning: supervised, unsupervised, and reinforcement [54], [55],
    [56]. In an informal sense, in supervised learning, the training set consists
    of samples of input vectors together with their corresponding appropriate target
    vectors, also known as labels. In unsupervised learning, no labels are required
    for the training set. Reinforcement learning deals with the problem of learning
    the appropriate action or sequence of actions to be taken for a given situation
    in order to maximize payoff. This article focuses on supervised and unsupervised
    learning since they have been and are still widely applied in IoT smart data analysis.
    The objective of supervised learning is to learn how to predict the appropriate
    output vector for a given input vector. Applications where the target labels consist
    of a finite number of discrete categories are known as classification tasks. Cases
    where the target labels are composed of one or more continuous variables are known
    as regression tasks [57]. Defining the objective of unsupervised learning is difficult.
    One of the major objectives is to identify sensible clusters of similar samples
    within the input data, known as clustering. Moreover, the objective may be the
    discovery of a useful internal representation of the input data by preprocessing
    the original input variable in order to transfer it into a new variable space.
    This preprocessing stage can significantly improve the result of the subsequent
    machine learning algorithm and is named feature extraction [55]. The frequently
    applied machine learning algorithms for smart data analysis and IoT use cases
    are shown in Table 2 and Table 3 accordingly. Table 2. Overview of frequently
    used machine learning algorithms for smart data analysis. Machine learning algorithm
    Data processing tasks Section Representative references K-Nearest Neighbors Classification
    5.1.1 [58], [59] Naive Bayes Classification 5.1.2 [60], [61] Support Vector Machine
    Classification 5.1.3 [62], [63], [64], [65] Linear Regression Regression 5.2.1
    [66], [67], [68] Support Vector Regression Regression 5.2.2 [69], [70] Classification
    and Regression Trees Classification/Regression 5.3.1 [71], [72], [73] Random Forests
    Classification/Regression 5.3.2 [74] Bagging Classification/Regression 5.3.3 [75]
    K-Means Clustering 5.4.1 [76], [77], [78] Density-Based Spatial Clustering of
    Applications with Noise Clustering 5.4.2 [79], [80], [81] Principal Component
    Analysis Feature extraction 5.5.1 [82], [83], [84], [85], [86] Canonical Correlation
    Analysis Feature extraction 5.5.2 [87], [88] Feed Forward Neural Network Regression/Classification/Clustering/Feature
    extraction 5.6.1 [57], [89], [90], [91], [92], [93] One-class Support Vector Machines
    Anomaly detection 5.8.1 [94], [95] Table 3. Overview of applying machine learning
    algorithms to Internet of Things use cases. Machine learning Algorithm IoT, Smart
    City use cases Metric to Optimize References Classification Smart Traffic Traffic
    Prediction, Increase Data Abbreviation [14], [43] Clustering Smart Traffic, Smart
    Health Traffic Prediction, Increase Data Abbreviation [14], [43], [44] Anomaly
    Detection Smart Traffic, Smart Environment Traffic Prediction, Increase Data Abbreviation,
    Finding Anomalies in Power Dataset [14], [43], [45] Support Vector Regression
    Smart Weather Prediction Forecasting [46] Linear Regression Economics, Market
    analysis, Energy usage Real Time Prediction, Reducing Amount of Data [48], [148]
    Classification and Regression Trees Smart Citizens Real Time Prediction, Passengers
    Travel Pattern [47], [48] Support Vector Machine All Use Cases Classify Data,
    Real Time Prediction [48], [109] K-Nearest Neighbors Smart Citizen Passengers''
    Travel Pattern, Efficiency of the Learned Metric [47], [96] Naive Bayes Smart
    Agriculture, Smart Citizen Food Safety, Passengers Travel Pattern, Estimate the
    Numbers of Nodes [47], [49], [148] K-Means Smart City, Smart Home, Smart Citizen,
    Controlling Air and Traffic Outlier Detection, fraud detection, Analyze Small
    Data set, Forecasting Energy Consumption, Passengers Travel Pattern, Stream Data
    Analyze [38], [47], [50], [52], [116], [117] Density-Based Clustering Smart Citizen
    Labeling Data, Fraud Detection, Passengers Travel Pattern [47], [52], [109] Feed
    Forward Neural Network Smart Health Reducing Energy Consumption, Forecast the
    States of Elements, Overcome the Redundant Data and Information [21], [126], [148]
    Principal Component Analysis Monitoring Public Places Fault Detection [51] Canonical
    Correlation Analysis Monitoring Public Places Fault Detection [51] One-class Support
    Vector Machines Smart Human Activity Control Fraud Detection, Emerging Anomalies
    in the data [52], [53] In the following subsections, we assume that we are given
    a training set containing N training samples denoted as , where is the ith M-dimensional
    training input vector and is the corresponding desired P-dimensional output vector.
    Moreover, we collect the M-dimensional input vectors in a matrix, written as ,
    and we also collect their corresponding desired output vectors in a matrix written
    as . However, in Section 5.4 the training set does not contain the desired output
    vectors. 5.1. Classification 5.1.1. K-nearest neighbors In K-Nearest Neighbors
    (KNN), the objective is to classify a new given unseen data point by looking at
    the K given data points in the training set that are closest to it in the input
    or feature space. Therefore, to find the K nearest neighbors of the new data point,
    we need to use a distance metric, such as Euclidean distance, norm, angle, Mahalanobis
    distance or Hamming distance. To formulate the problem, let us denote the new
    input vector (data point) by x, its K nearest neighbors by , the predicted class
    label for x by y, and the class variable by a discrete random variable t. Additionally,
    denotes the indicator function: if s is true and otherwise. The form of the classification
    task is (1) i.e., the input vector x will be labeled by the mode of its neighbors''
    labels [58]. One limitation of KNN is that it requires storing the entire training
    set, which makes KNN unscalable to large data sets. In [59], the authors have
    addressed this issue by constructing a tree-based search with a one-off computation.
    Moreover, there exists an online version of KNN classification. It is worth noting
    that KNN can also be used for regression tasks [55]. However, we will not explain
    this here, because it is not a frequently employed algorithm for smart data analysis.
    Ref. [96] proposes a new framework for learning a combination of multiple metrics
    for a robust KNN classifier. Furthermore, [47] compares KNN with a rough-set-based
    algorithm for classifying the travel pattern regularities. 5.1.2. Naive Bayes
    Given a new, unseen data point (input vector) , naive Bayes classifiers, which
    are a family of probabilistic classifiers, classify z based on applying Bayes''
    theorem with the “naive” assumption of independence between the features (attributes)
    of z given the class variable t. By applying Bayes'' theorem, we have (2) and
    by applying the naive independence assumption and some simplifications, we have
    (3) Therefore, the form of the classification task is (4) where y denotes the
    predicted class label for z. Different naive Bayes classifiers use different approaches
    and distributions to estimate and [61]. Naive Bayes classifiers require a small
    number of data points to be trained, and can deal with high-dimensional data points,
    and also are fast and highly scalable [60]. Moreover, they are a popular model
    for applications, such as spam filtering [97], text categorization, and automatic
    medical diagnosis [98]. Ref. [49] used this algorithm to combine factors to evaluate
    the trust value and calculate the final quantitative trust of agricultural product.
    5.1.3. Support vector machine Classical Support Vector Machines (SVMs) are non-probabilistic,
    binary classifiers that aim to find the dividing hyperplane that separates both
    classes of the training set with the maximum margin. Then, the predicted label
    of a new, unseen data point is determined based on which side of the hyperplane
    it falls [62]. First, we discuss the linear SVM that finds a hyperplane that is
    a linear function of the input variable. To formulate the problem, we denote the
    normal vector to the hyperplane by w and the parameter for controlling the offset
    of the hyperplane from the origin along its normal vector by b. Moreover, to ensure
    that SVMs can deal with outliers in the data, we introduce a variable , called
    a slack variable, for every training point , which gives the distance by which
    this training point violates the margin in units of . This binary linear classification
    task is described using a constrained optimization problem of the form (5) where
    parameter determines how heavily a violation is punished [64], [63]. It should
    be noted that although we used the norm here for the penalty term , there exist
    other penalty terms, such as the norm, which should be chosen with respect to
    the needs of the application. Moreover, the parameter C is a hyperparameter which
    can be chosen via cross-validation or Bayesian optimization. There exist various
    techniques to solve the constrained optimization problem of equation (5), such
    as quadratic programming optimization [99], sequential minimal optimization [100],
    and P-packSVM [101]. One important property of SVMs is that the resulting classifier
    only uses a few training points, which are called support vectors, to classify
    a new data point. In addition to performing linear classification, SVMs can perform
    a non-linear classification, which finds a hyperplane that is a non-linear function
    of the input variable. To do so, we implicitly map an input variable into high-dimensional
    feature spaces in a process called a kernel trick [64]. In addition to performing
    binary classification, SVMs can perform multiclass classification. There are various
    methods to achieve this, such as One-vs-all (OVA) SVM, All-vs-all (AVA) SVM [54],
    Structured SVM [102], and the Weston and Watkins [103] version. SVMs are among
    the best off-the-shelf supervised learning models that are capable of effectively
    dealing with high-dimensional data sets and are efficient in terms of memory usage,
    owing to the employment of support vectors for prediction. One significant drawback
    of this model is that it does not directly provide probability estimates. When
    given a solved SVM model, its parameters are difficult to interpret [104]. SVMs
    are useful in many real-world applications such as hand-written character recognition
    [105], image classification [106], and protein classification [107]. Finally,
    we should note that SVMs can be trained in an online fashion, which is addressed
    in [108]. Ref. [109] proposed a method on the Intel Lab Dataset. This data set
    consists of four environmental variables (temperature, voltage, humidity and light)
    collected through S4 Mica2Dot sensors over 36 days at a per-second rate. 5.2.
    Regression 5.2.1. Linear regression In linear regression, the objective is to
    learn a function . This is a mapping and is a linear combination of a fixed set
    of linear or nonlinear functions of the input variable, denoted as and called
    basic functions. The form of is (6) where w is the weight vector or matrix , and
    . There exists a broad range of basic functions, such as polynomial, gaussian,
    radial, and sigmoidal basic functions, which should be chosen with respect to
    the application [68], [66]. For training the model, there exists a range of approaches:
    Ordinary Least Square, Regularized Least Squares, Least-Mean-Squares (LMS) and
    Bayesian Linear Regression. Among these, LMS is of interest since it is fast,
    scalable to large data sets, and it learns the parameters online by applying the
    technique of stochastic gradient descent, also known as sequential gradient descent
    [67], [55]. By using suitable basic functions it can be shown that arbitrary nonlinearities
    in the mapping from the input variable to the output variable can be modeled.
    However, the assumption of fixed basis functions leads to significant shortcomings
    with this approach. For example, an increase in the dimension of the input space
    is coupled with rapid growth in the number of basis functions [55], [66], [56].
    Linear regression can process at a high rate [48], and this algorithm can be used
    to analyze and predict the energy usage of buildings. 5.2.2. Support vector regression
    The SVM model described in Section 5.1.3 can be extended to solve regression problems
    through a process called Support Vector Regression (SVR). Analogous to support
    vectors in SVMs, the resulting SVR model depends only on a subset of the training
    points, owing to the rejection of training points that are close to the model
    prediction [69]. Various implementations of SVR exist such as epsilon-support
    vector regression and nu-support vector regression [70]. The authors of [46] proposed
    a hybrid method to obtain accurate temperature and humidity data predictions.
    5.3. Combining models 5.3.1. Classification and regression trees In Classification
    and Regression Trees (CART), the input space is partitioned into axis-aligned
    cuboid regions , and then a separate classification or regression model is assigned
    to each region to predict the label for data points fall into that region [71].
    Given a new, unseen input vector (data point) x, the process for predicting the
    corresponding target label can be explained by the traversal of a binary tree
    corresponding to a sequential decision-making process. An example of a model for
    classification is one that predicts a particular class for each region, and the
    example of regression is a model that predicts a constant for each region. To
    formulate the classification task, we denote a class variable by a discrete random
    variable t and the predicted class label for x by y. The classification task takes
    the form (7) where is the indicator function described in Section 5.1.1. This
    equation states that x will be labeled by the most common (mode) label in its
    corresponding region [73]. To formulate the regression task, we denote the value
    of the output vector by t and the predicted output vector for x by y. The regression
    task is expressed as (8) i.e., the output vector for x will be the mean of the
    output vectors of data points in its corresponding region [73]. Download : Download
    high-res image (284KB) Download : Download full-size image To train CART, the
    structure of the tree should be determined based on the training set. This means
    determining the split criterion at each node, along with the threshold parameter
    value. Finding the optimal tree structure is an NP-complete problem, and therefore
    a greedy heuristic, which constructs the tree top-down and chooses the best split
    node-by-node, is used to train CART. To achieve a better generalization and reduce
    overfilling, some stopping criteria should be used for constructing the tree.
    Possible stopping criterion are the maximum depth reached, whether the distribution
    in the branch is pure, whether the benefit of splitting is below a certain threshold,
    and whether the number of samples in each branch is below the criteria threshold.
    Moreover, after constructing the tree a pruning procedure can be used to reduce
    overfitting [72], [55], [56]. Algorithm 1 describes how to train CART. The major
    strength of CART is its human interpretability, owing to its tree structure. Additionally,
    it is fast and scalable to large data sets. However, it is very sensitive to the
    choice of the training set [110]. Another shortcoming of this model concerns unsmooth
    labeling of the input space since each region of the input space is associated
    with exactly one label [73], [55]. Ref. [47] proposes an efficient and effective
    data-mining procedure that models the travel patterns of transit riders in Beijing,
    China. 5.3.2. Random forests In random forests, instead of training a single tree,
    an army of trees are trained. Each tree is trained on a subset of the training
    set, chosen randomly along with a replacement, using a randomly chosen subset
    of M input variables (features) [74]. From here, there are two scenarios for predicting
    the label of a new, unseen data point: (1) in classification tasks, this is set
    as the mode of the labels predicted by each tree; (2) in regression tasks it is
    set as the mean of the labels predicted by each tree. There is a tradeoff between
    different values of M. A value of M that is too small leads to random trees with
    poor prediction power, whereas a value of M that is too large leads to very similar
    random trees. Random forests have a very high accuracy, but this comes at the
    cost of losing human interpretability [111]. Additionally, they are fast and scalable
    to large data sets, and have many real-world applications, such as body pose recognition
    [112] and body part classification. 5.3.3. Bagging Bootstrap aggregating, also
    called bagging, is an ensemble technique that aims to improve the accuracy and
    stability of machine learning algorithms and reduce overfitting. In this technique,
    K new M sized training sets are generated by randomly choosing data points from
    the original training set with replacements. Then, on each new generated training
    set, a machine learning model is trained. The predicted label of a new, unseen
    data point is set as the mode of the labels predicted by each model in the case
    of classification tasks, and is set as the mean in the case of regression tasks.
    There are various machine learning models, such as CART and neural networks, for
    which the bagging technique can improve the results. However, bagging degrades
    the performance of stable models such as KNN [75]. Examples of practical applications
    include customer attrition prediction [113] and preimage learning [114], [115].
    5.4. Clustering 5.4.1. K-means In the K-means algorithm, the objective is to cluster
    the unlabeled data set into K clusters (groups), where data points belonging to
    the same cluster must have some similarities. In the classical K-means algorithm,
    the distance between data points is the measure of similarity. Therefore, K-means
    seeks to find a set of K cluster centers, denoted as , such that the distances
    between data points and their nearest center are minimized [77]. To denote the
    assignment of data points to the cluster centers, we use a set of binary indicator
    variables , so that if the data point is assigned to the cluster center , then
    . We formulate the problem as follows: (9) Algorithm 2 describes how to learn
    the optimal cluster centers and the assignment of the data points }. Download
    : Download high-res image (209KB) Download : Download full-size image In practice,
    K-means is a very fast and highly scalable algorithm. Moreover, there is an online
    stochastic version of K-means [78]. However, this approach has many limitations
    because of the use of Euclidean distance as the measure of similarity. For instance,
    it has limitations regarding the types of data variables that can be considered,
    and cluster centers are not robust against outliers. Additionally, the K-means
    algorithm assigns each data point only one of the clusters, which may lead to
    inappropriate clusters in some cases [76]. Ref. [116] used MapReduce to analyze
    the numerous small data sets and proposes a cluster strategy for a high volume
    of small data based on the K-means algorithm. Ref. [47] applied K-Means++ to cluster
    and classify travel pattern regularities. Ref. [117] introduced a real-time event
    processing and clustering algorithm for analyzing sensor data, by using the OpenIoT1
    middleware as an interface for innovative analytical IoT services. 5.4.2. Density-based
    spatial clustering of applications with noise In a Density-Based approach to Spatial
    Clustering of Applications with Noise (DBSCAN), the objective is to cluster a
    given unlabeled data set based on the density of its data points. In this model,
    groups of dense data points (data points with many close neighbors) are considered
    as clusters and data points in regions with low-density are considered as outliers
    [80]. Ref. [79] present an algorithm to train a DBSCAN model. In practice, DBSCAN
    is efficient on large datasets, and is fast and robust against outliers. Furthermore,
    it is capable of detecting clusters of arbitrary shape (i.e., spherical, elongated,
    and linear). Moreover, the model determines the number of clusters based on the
    density of the data points, unlike K-means, which requires the number of clusters
    to be specified [79]. However, there are some disadvantages associated with DBSCAN.
    For example, in the case of a data set with large differences in densities, the
    resulting clusters are destitute. Additionally, the performance of the model is
    highly sensitive to the distance metric that is used for determining if a region
    is dense [81]. It is worth, however, noting that DBSCAN is among the most widely
    used clustering algorithms with numerous real-world applications such as anomaly
    detection in temperature data [118] and X-ray crystallography [79]. The authors
    of [109] believe that knowledge discovery in data streams is an important task
    for research, business, and community. They applied DBSCAN to a data stream to
    reveal the number of existing classes and subsequently label the data. Furthermore,
    in [52] this algorithm is adopted to determine the arbitrary shape of a cluster.
    The DBSCAN algorithm produces sets of clusters of arbitrary shape and outlying
    objects. 5.5. Feature extraction 5.5.1. Principal component analysis In Principle
    Component Analysis (PCA), the objective is to orthogonally project data points
    onto an L dimensional linear subspace, called the principal subspace, which has
    the maximal projected variance [83], [85]. Equivalently, the objective can be
    defined as finding a complete orthonormal set of L linear M-dimensional basis
    vectors and the corresponding linear projections of data points such that the
    average reconstruction error (10) is minimized, where is the average of all data
    points [82], [55]. Download : Download high-res image (200KB) Download : Download
    full-size image Algorithm 3 describes how the PCA technique achieves these objectives.
    Depending on how is calculated, the PCA algorithm can have different run times,
    i.e., , , and [119], [55], [120]. To deal with high dimensional data sets, there
    is alternative version of the PCA algorithm based on the iterative expectation
    maximization technique. In this algorithm, the covariance matrix of the dataset
    is not explicitly calculated, and its most computationally demanding steps are
    . In addition, this algorithm can be implemented in an online fashion, which can
    also be advantageous in cases where M and N are large [84], [56]. PCA is one of
    the most important preprocessing techniques in machine learning. Its application
    involves data compression, whitening, and data visualization. Examples of its
    practical applications are face recognition, interest rate derivative portfolios,
    and neuroscience. Furthermore, there exists a kernelized version of PCA, called
    KPCA, which can find nonlinear principal components [86], [84]. 5.5.2. Canonical
    correlation analysis Canonical Correlation Analysis (CCA) is a linear dimensionality
    reduction technique that is closely related to PCA. Unlike PCA, which deals with
    one variable, CCA deals with two or more variables. Its objective is to find a
    corresponding pair of highly cross-correlated linear subspaces so that within
    one of the subspaces there is a correlation between each component and a single
    component from the other subspace. The optimal solution can be obtained by solving
    a generalized eigenvector problem [87], [88], [55]. Ref. [51] compared PCA with
    CCA for detecting intermittent faults and masking failures of indoor environments.
    5.6. Neural network One of the shortcomings of linear regression is that it is
    necessary to decide the types of basic functions. It is often difficult to choose
    the optimal basic functions. Therefore, in neural networks we fix the number of
    basic functions, but allow the model to learn the parameters of the basic functions.
    There exist many different types of neural networks, with different architectures,
    use cases, and applications. In subsequent subsections, we discuss the successful
    models used in smart data analysis. Note that neural networks are fast to process
    new data, because they are compact models. However, in contrast they usually require
    a large amount of computation to be trained. Moreover, they are easily adaptable
    to regression and classification problems [91], [90]. 5.6.1. Feed forward neural
    network Feed Forward Neural Networks (FFNN), also known as Multilayer Perceptrons
    (MLP), are the most common type of neural networks in practical applications.
    To explain this model, we begin with a simple two-layer FFNN model. Assume that
    we have D basic functions and our objective is to learn the parameters of these
    basic functions together with the function f discussed in Section 5.2.1. The form
    of the classification or regression task is (11) where , , , and . Fig. 3 visualizes
    this FFNN model. The elements of the input vector x are units (neurons) in the
    input layer, are the units in the hidden layer, and are the units in the output
    layer, which outputs f. Note that the activities of the units in each layer are
    determined by a nonlinear function of the activities in the previous layer. In
    machine learning literature, is also called an activation function. The activation
    function in the last layer is chosen with respect to the data processing task.
    For example, for a regression task we use a linear activation function, and for
    multiclass classification we use a softmax activation function [57], [91], [55].
    Download : Download high-res image (131KB) Download : Download full-size image
    Fig. 3. A two-layer feed forward neural network. Note that each output neuron
    is connected to each input neuron, i.e., it is a fully connected neural network.
    With enough hidden units, an FFNN with at least two layers can approximate an
    arbitrary mapping from a finite input space to a finite output space [121], [122],
    [123]. However, finding the optimum set of weights w for an FFNN is an NP-complete
    problem [124]. To train the model, there exist a range of learning methods, such
    as stochastic gradient descent, adaptive delta, adaptive gradient, adaptive moment
    estimation, Nesterov''s accelerated gradient, and RMSprob. There also exist a
    range of methods to enhance the generalization of the model and reduce overfitting,
    such as weight decay, weight-sharing, early stopping, Bayesian fitting of neural
    nets, dropout, and generative pre-training [92], [89]. A two-layer FFNN has the
    properties of restricted representation and generalization. Moreover, compactly
    represented functions with l layers may require an exponential size with layers.
    Therefore, an alternative approach would be an FFNN with more than one hidden
    layers, i.e., a deep neural network, in which different high-level features share
    low-level features [93], [90]. Significant results using deep neural networks
    have led them to be the most commonly employed classifiers in machine learning
    [125], [57]. Ref. [126] presented a method to forecast the states of IoT elements
    based on an artificial neural network. The presented architecture of the neural
    network is a combination of a multilayered perceptron and a probabilistic neural
    network. Furthermore, [21] applied an FFNN for processing health data. 5.7. Time
    series and sequential data So far in this article, the discussed algorithms have
    all dealt with set of data points that are independent and identically distributed
    (i.i.d.). However, in many cases the set of data points are not i.i.d., and often
    result from time series measurements, such as the daily closing value of the Dow
    Jones Industrial Average or acoustic features at successive time frames. An example
    of a non-i.i.d. set of data points in a context other than a time series is a
    character sequence in a German sentence. In these cases, data points consist of
    sequences of pairs rather than being drawn in an i.i.d. manner from a joint distribution
    and such the sequences exhibit significant sequential correlations [127], [55].
    In a sequential supervised learning problem, when data points are sequential,
    we are given a training set consisting of N samples, where each of these is a
    pair of sequences. In each sample, and . Given a new, unseen input sequence x,
    the goal is to predict the desired output sequence y. Moreover, there exists a
    closely related problem called a time-series prediction problem, in which the
    goal is to predict the desired st element of a sequence . The key difference is
    that unlike in sequential supervised learning, where the entire sequence is available
    prior to any prediction, in a time-series prediction only the prefix of the sequence,
    up to the current time , is available. In addition, in sequential supervised learning
    the entire output sequence y must be predicted, whereas in time-series prediction
    the true observed values of the output sequence up to time t are given. It is
    worth noting that there is another closely-related task, called sequence classification,
    in which the goal is to predict the desired single categorical output y given
    an input sequence x [127]. There are a variety of machine learning models and
    methods that can deal with these tasks. Examples of these models and methods are
    hidden Markov models [128], [129], sliding-window methods [130], Kalman filter
    [131], conditional random fields [132], recurrent neural networks [133], [57],
    graph transformer networks [89], and maximum entropy Markov models [134]. In addition,
    sequential time series and sequential data exists in many real-world applications,
    including speech recognition [135], handwriting recognition [136], musical score
    following [137], and information extraction [134]. 5.8. Anomaly detection The
    problem of identifying items or patterns in a data set that do not conform to
    other items or an expected pattern is referred to as anomaly detection, and these
    unexpected patterns are called anomalies, outliers, novelties, exceptions, noise,
    surprises, or deviations [138], [139]. There are many challenges in the task of
    anomaly detection that distinguish it from a binary classification task. For example,
    an anomalous class is often severely underrepresented in the training set. In
    addition, anomalies exhibit considerably more diverse behavior than a normal system,
    and are sparse by nature [140], [139]. There are three broad categories of anomaly
    detection techniques, based on the extent to which the labels are available. In
    supervised anomaly detection techniques, a binary (abnormal and normal) labeled
    data set is given, and then a binary classifier is trained. This should deal with
    the problem of unbalanced data set resulting from the existence of few data points
    with an abnormal label. Semi-supervised anomaly detection techniques require a
    training set that contains only normal data points. Anomalies are then detected
    by building the normal behavior model of the system, and then testing the likelihood
    of the generation of the test data point by the learned model. Unsupervised anomaly
    detection techniques deal with an unlabeled data set, by making the implicit assumption
    that most of the data points are normal [139]. Anomaly detection is of use in
    many real-world applications, such as system health monitoring, credit card fraud
    detection, intrusion detection [141], detecting eco-system disturbances, and military
    surveillance. Moreover, anomaly detection can be used as a preprocessing algorithm
    for removing outliers from a data set, which can significantly improve the performance
    of subsequent machine learning algorithms, especially in supervised learning tasks
    [142], [143]. In the following subsection, we shall explain one-class support
    vector machines, which represent one of the most popular techniques for anomaly
    detection. Ref. [45] constructed a novel outlier detection algorithm that uses
    statistical techniques to identify outliers and anomalies in power datasets collected
    from smart environments. 5.8.1. One-class support vector machines One-class support
    vector machines (OCSVMs) represent a semi-supervised anomaly detection technique,
    and are an extension of the SVMs discussed in Section 5.1.3 for unlabeled data
    sets. Given a training set drawn from an underlying probability distribution P,
    OCSVMs aim to estimate a subset S of the input space such that the probability
    that a drawn sample from P lies outside of S is bounded by a fixed value between
    0 and 1. This problem is approached by learning a binary function f that captures
    the input regions where the probability density lives. Therefore, f is negative
    in the complement of S. The functional form of f can be computed by solving a
    quadratic programming problem [94], [95]. One-class SVMs are useful in many anomaly
    detection applications, such as anomaly detection in sensor networks [144], system-called
    intrusion detection [145], network intrusion detection [146], and anomaly detection
    in wireless sensor networks [147]. Ref. [52] reviewed various techniques for stream
    data outlier detection and the related issues in detail. Ref. [53] employed one-class
    SVM to detect anomalies by modeling complex normal patterns in the data. In the
    following section, we discuss how to overcome the challenges of applying machine
    learning algorithms to IoT smart data. 6. Discussion of taxonomy of machine learning
    algorithms To reach suitable decisions for smart data analysis, it is necessary
    to determine which task should be accomplished out of structure discovery, finding
    unusual data points, predicting values, predicting categories, or feature extraction.
    To discover the structure of unlabeled data, clustering algorithms can provide
    the most appropriate tools. K-means, described in 5.4.1, is the most well-known
    and frequently applied clustering algorithm, and can handle a large volume of
    data with a broad range of data types. Refs. [50], [52] proposed a method for
    applying the K-means algorithm for managing smart city and smart home data. DB-scan,
    described in 5.4.2, is another clustering algorithm the structure of data from
    unlabeled data, and is applied in [109], [52], [47] to cluster smart citizen behavior.
    To find unusual data points and anomalies in smart data, two important algorithms
    can be applied. Namely, these are the one-class SVM and PCA-based anomaly detection
    methods explained in 5.5.1, which can train anomalies and noisy data with a high
    performance. Refs. [52], [53] applied a one-class SVM to monitor and detect human
    activity anomalies. In order to predict values and classify sequenced data, the
    linear regression and SVR methods described in 5.2.1 and 5.2.2, respectively,
    are the two frequently applied algorithms. The objective of the models applied
    in these algorithms is to process and train data of high velocity. For example,
    [48], [46] applied a linear regression algorithm for real-time prediction. Another
    fast training algorithm is the classification and regression tree described in
    5.3.1, which has been applied to classify smart citizen behaviors [48], [47].
    To predict the categories of data, neural networks are suitable learning models
    for function approximation problems. Moreover, because smart data should be accurate
    and requires a long training time, a multi-class neural network can provide an
    appropriate solution. For instance, the FFNN explained in 5.6.1 has been applied
    to reduce future energy consumption, by predicting how data will be generated
    in the future and how the redundancy of this data will be removed [21], [126],
    [148]. The SVM explained in 5.1.3 is another popular classification algorithm,
    which is capable of handling massive amounts of data and classifying their different
    types. Because SVM can handle a high volume and a variety of types of data, it
    is commonly applied in most smart data processing algorithms. For example, [109],
    [48] applied SVM to classify traffic data. PCA and CCA, described in 5.5.1 and
    5.5.2, respectively, are the two algorithms most commonly applied for extracting
    features of data. Moreover, CCA can show the correlation between two categories
    of data. A type of PCA or CCA can also be applied to discover anomalies. Ref.
    [51] applied PCA and CCA to monitor public places and detect events in social
    areas. The chosen algorithm should be implemented and developed to reach the correct
    decisions. A sample implemented code is available from the open source GitHub
    license at https://github.com/mhrezvan/SVM-on-Smart-Traffic-Data. 7. Research
    trends and open issues As discussed previously, data analysis provides a significant
    contribution to IoT. In order to exploit the full potential of data analysis for
    extracting new insights from data, IoT must overcome some major challenges. These
    can be categorized into three different types. 7.1. IoT data characteristics Because
    the data is the basis of extracting knowledge, it is vital to have high quality
    information. This condition can affect the accuracy of knowledge extraction in
    a direct manner. Because IoT produces a high volume, fast velocity, and different
    varieties of data, preserving the data quality is a challenging task. Although
    many solutions have been introduced to solve these problems, none of them can
    handle all aspects of data characteristics in an accurate manner, because of the
    distributed nature of big data management solutions and real-time processing platforms.
    The abstraction of IoT data is low; that is, the data that comes from different
    resources in IoT consists mostly of raw data, and not sufficient for analysis.
    A wide variety of solutions have been proposed, while most of these require further
    improvement. For instance, semantic technologies tend to enhance the abstraction
    of IoT data through annotation algorithms, while they require further effort to
    overcome its velocity and volume. 7.2. IoT applications IoT applications fall
    into different categories according to their unique attributions and features.
    Certain issues should be consider for running data analysis in IoT applications
    in an accurate manner. First, the privacy of collected data is highly critical,
    because data collection processes can include personal or critical business data,
    which is inevitable to solve the privacy issues. Second, according to the vast
    number of resources and simply-designed hardware in IoT, it is vital to consider
    security parameters, such as network security and data encryption. Otherwise,
    by ignoring security in the design and implementation, an infected network of
    IoT devices can lead to a crisis. 7.3. IoT data analytic algorithms According
    to the characteristic of smart data, analytic algorithms should be able to handle
    big data. That is, IoT requires algorithms that can analyze data that comes from
    a variety of sources in real-time. Many attempts have been made to address this
    issue. For example, deep learning algorithms, which are a form of neural networks
    incorporating evolution can reach a high accuracy rate if they have enough data
    and time. Deep learning algorithms can easily be influenced by noisy smart data.
    Furthermore, neural network-based algorithms lack interpretation, that is, data
    scientists cannot understand the reasons for the model results. In the same manner,
    semi-supervised algorithms, which model a small amount of labeled data with a
    large amount of unlabeled data, can assist IoT data analysis. 8. Conclusions IoT
    consists of a vast number of different devices that are connected with each other
    and transmit huge amounts of data. The smart city is one of the most important
    applications of IoT, and provides various services in domains such as energy,
    mobility, and urban planning. These services can be enhanced and optimized by
    analyzing the smart data collected from these areas. To extract knowledge from
    collected data, many data analytic algorithms can be applied. Choosing a suitable
    algorithm for specific IoT or smart city application is an important issue. In
    this article, many IoT data analytic studies are reviewed to address this issue.
    Here, three facts should be considered in applying data analytic algorithms to
    smart data. The first is that different applications in IoT and smart cities have
    their own characteristics, such as the number of devices and types of the data
    that they generate. The second is that the generated data will have specific features
    that should be considered. The third is that the taxonomy of algorithms is another
    important aspect in applying data analysis to smart data. The findings in this
    article make it easy to choose a suitable algorithm for a particular problem.
    The analytic algorithms fall into eight categories, described in detail. This
    is followed by reviewing application specifics of smart city use cases. The characteristics
    and qualities of smart data are described in detail. In the discussion section,
    the manner in which data characteristics and application specifics can lead to
    choosing a proper data analytic algorithms is reviewed. In the regarding future
    trends, section recent issues and the future path for research in the field of
    smart data analytics are discussed. Acknowledgments The authors would like to
    thank Dr. Mohammadsaeid Ehsani and Mr. Ajit Joakar for their comments on the draft
    of the paper. We also thank Dr. Alireza Ahrabian and Utkarshani Jiamini for reviewing
    our paper. References [1] L. Atzori, A. Iera, G. Morabito The internet of things:
    a survey Comput. Netw., 54 (15) (2010), pp. 2787-2805 View PDFView articleView
    in ScopusGoogle Scholar [2] C. Cecchinel, M. Jimenez, S. Mosser, M. Riveill An
    architecture to support the collection of big data in the internet of things 2014
    IEEE World Congress on Services, IEEE (2014), pp. 442-449 View in ScopusGoogle
    Scholar [3] M. Weiser The computer for the 21st century Mob. Comput. Commun. Rev.,
    3 (3) (1999), pp. 3-11 CrossRefGoogle Scholar [4] A. Sheth Computing for human
    experience: semantics-empowered sensors, services, and social computing on the
    ubiquitous web IEEE Internet Comput., 14 (1) (2010), pp. 88-91 View in ScopusGoogle
    Scholar [5] J. Manyika, M. Chui, B. Brown, J. Bughin, R. Dobbs, C. Roxburgh, A.H.
    Byers Big Data: The Next Frontier for Innovation, Competition, and Productivity
    McKinsey Global Institute (2011) 156 p Google Scholar [6] A. Sheth Transforming
    big data into smart data: deriving value via harnessing volume, variety, and velocity
    using semantic techniques and technologies Data Engineering (ICDE), 2014 IEEE
    30th International Conference on, IEEE (2014) 2–2 Google Scholar [7] Amit Sheth
    Transforming big data into smart data: deriving value via harnessing volume, variety
    and velocity using semantics and semantic web keynote at the 21st Italian Symposium
    on Advanced Database Systems, June 30-July 03 (2013) Roccella Jonica, Italy Google
    Scholar [8] A. Sheth Internet of things to smart iot through semantic, cognitive,
    and perceptual computing IEEE Intell. Syst., 31 (2) (2016), pp. 108-112 View in
    ScopusGoogle Scholar [9] S. Bin, L. Yuan, W. Xiaoyi Research on data mining models
    for the internet of things 2010 International Conference on Image Analysis and
    Signal Processing, IEEE (2010), pp. 127-132 View in ScopusGoogle Scholar [10]
    H. Gonzalez, J. Han, X. Li, D. Klabjan Warehousing and analyzing massive rfid
    data sets 22nd International Conference on Data Engineering (ICDE’06), IEEE (2006)
    83–83 Google Scholar [11] F. Chen, P. Deng, J. Wan, D. Zhang, A.V. Vasilakos,
    X. Rong Data mining for the internet of things: literature review and challenges
    Int. J. Distrib. Sens. Netw., 2015 (2015), p. 12 View in ScopusGoogle Scholar
    [12] C.-W. Tsai, C.-F. Lai, M.-C. Chiang, L.T. Yang Data mining for internet of
    things: a survey IEEE Commun. Surv. Tutor., 16 (1) (2014), pp. 77-97 View in ScopusGoogle
    Scholar [13] A. Zanella, N. Bui, A. Castellani, L. Vangelista, M. Zorzi Internet
    of things for smart cities IEEE Internet Things J., 1 (1) (2014), pp. 22-32 Google
    Scholar [14] Y. Qin, Q.Z. Sheng, N.J. Falkner, S. Dustdar, H. Wang, A.V. Vasilakos
    When things matter: a survey on data-centric internet of things J. Netw. Comput.
    Appl., 64 (2016), pp. 137-153 View PDFView articleView in ScopusGoogle Scholar
    [15] M. Ma, P. Wang, C.-H. Chu Ltcep: efficient long-term event processing for
    internet of things data streams 2015 IEEE International Conference on Data Science
    and Data Intensive Systems, IEEE (2015), pp. 548-555 CrossRefView in ScopusGoogle
    Scholar [16] Payam Barnaghi, Amit Sheth The Internet of things: The story so far
    IEEE Internet Things, 915 (2014) Google Scholar [17] Z. Sheng, S. Yang, Y. Yu,
    A.V. Vasilakos, J.A. McCann, K.K. Leung A survey on the ietf protocol suite for
    the internet of things: standards, challenges, and opportunities IEEE Wirel. Commun.,
    20 (6) (2013), pp. 91-98 View in ScopusGoogle Scholar [18] F. Bonomi, R. Milito,
    J. Zhu, S. Addepalli Fog computing and its role in the internet of things Proceedings
    of the First Edition of the MCC Workshop on Mobile Cloud Computing, ACM (2012),
    pp. 13-16 CrossRefGoogle Scholar [19] M. Aazam, E.-N. Huh Fog computing micro
    datacenter based dynamic resource estimation and pricing model for iot 2015 IEEE
    29th International Conference on Advanced Information Networking and Applications,
    IEEE (2015), pp. 687-694 CrossRefView in ScopusGoogle Scholar [20] Y. Shi, G.
    Ding, H. Wang, H.E. Roman, S. Lu The fog computing service for healthcare Future
    Information and Communication Technologies for Ubiquitous HealthCare (Ubi-HealthTech),
    2015 2nd International Symposium on, IEEE (2015), pp. 1-5 Google Scholar [21]
    F. Ramalho, A. Neto, K. Santos, N. Agoulmine, et al. Enhancing ehealth smart applications:
    a fog-enabled approach 2015 17th International Conference on E-health Networking,
    Application & Services (HealthCom), IEEE (2015), pp. 323-328 CrossRefView in ScopusGoogle
    Scholar [22] A. Joakar A Methodology for Solving Problems with DataScience for
    Internet of Things Open Gardens (blog) (July 21, 2016) http://www.opengardensblog.futuretext.com/archives/2016/07/a-methodology-for-solvingproblems-with-datascience-for-internet-of-things.html
    [23] A. Papageorgiou, M. Zahn, E. Kovacs Efficient auto-configuration of energy-related
    parameters in cloud-based iot platforms Cloud Networking (CloudNet), 2014 IEEE
    3rd International Conference on, IEEE (2014), pp. 236-241 CrossRefView in ScopusGoogle
    Scholar [24] L. Wang, R. Ranjan Processing distributed internet of things data
    in clouds IEEE Cloud Comput., 2 (1) (2015), pp. 76-80 Google Scholar [25] H. Zhao,
    C. Huang A data processing algorithm in epc internet of things Cyber-enabled Distributed
    Computing and Knowledge Discovery (CyberC), 2014 International Conference on,
    IEEE (2014), pp. 128-131 CrossRefView in ScopusGoogle Scholar [26] R. Petrolo,
    V. Loscrì, N. Mitton Towards a smart city based on cloud of things, a survey on
    the smart city vision and paradigms Trans. Emerg. Telecommun. Technol., 28 (2017),
    p. e2931 View in ScopusGoogle Scholar [27] E. Von Hippel Democratizing innovation:
    the evolving phenomenon of user innovation J. für Betriebswirtschaft, 55 (1) (2005),
    pp. 63-78 CrossRefView in ScopusGoogle Scholar [28] D. Puiu, P. Barnaghi, R. Tönjes,
    D. Kümper, M.I. Ali, A. Mileo, J.X. Parreira, M. Fischer, S. Kolozali, N. Farajidavar,
    et al. Citypulse: large scale data analytics framework for smart cities IEEE Access,
    4 (2016), pp. 1086-1108 View in ScopusGoogle Scholar [29] B. Bowerman, J. Braverman,
    J. Taylor, H. Todosow, U. Von Wimmersperg The vision of a smart city 2nd International
    Life Extension Technology Workshop, Paris, vol. 28 (2000) Google Scholar [30]
    J. Pan, R. Jain, S. Paul, T. Vu, A. Saifullah, M. Sha An internet of things framework
    for smart energy in buildings: designs, prototype, and experiments IEEE Internet
    Things J., 2 (6) (2015), pp. 527-537 View in ScopusGoogle Scholar [31] J. Torriti
    Demand side management for the european supergrid: occupancy variances of european
    single-person households Energy Policy, 44 (2012), pp. 199-206 View PDFView articleView
    in ScopusGoogle Scholar [32] Y. Wang, J. Yuan, X. Chen, J. Bao Smart grid time
    series big data processing system 2015 IEEE Advanced Information Technology, Electronic
    and Automation Control Conference (IAEAC), IEEE (2015), pp. 393-400 CrossRefView
    in ScopusGoogle Scholar [33] S. Karnouskos, T.N. De Holanda Simulation of a smart
    grid city with software agents Computer Modeling and Simulation, 2009. EMS’09.
    Third UKSim European Symposium on, IEEE (2009), pp. 424-429 View in ScopusGoogle
    Scholar [34] D.R. Nagesh, J.V. Krishna, S. Tulasiram A real-time architecture
    for smart energy management Innovative Smart Grid Technologies (ISGT), 2010, IEEE
    (2010), pp. 1-4 Google Scholar [35] T. Robles, R. Alcarria, D. Martín, A. Morales,
    M. Navarro, R. Calero, S. Iglesias, M. López An internet of things-based model
    for smart water management Advanced Information Networking and Applications Workshops
    (WAINA), 2014 28th International Conference on, IEEE (2014), pp. 821-826 CrossRefView
    in ScopusGoogle Scholar [36] Z. Zhao, W. Ding, J. Wang, Y. Han A hybrid processing
    system for large-scale traffic sensor data IEEE Access, 3 (2015), pp. 2341-2351
    View in ScopusGoogle Scholar [37] M.M. Rathore, A. Ahmad, A. Paul, G. Jeon Efficient
    graph-oriented smart transportation using internet of things generated big data
    2015 11th International Conference on Signal-image Technology & Internet-based
    Systems (SITIS), IEEE (2015), pp. 512-519 CrossRefView in ScopusGoogle Scholar
    [38] C. Costa, M.Y. Santos Improving cities sustainability through the use of
    data mining in a context of big city data The 2015 International Conference of
    Data Mining and Knowledge Engineering, vol. 1, IAENG (2015), pp. 320-325 View
    in ScopusGoogle Scholar [39] A.J. Jara, D. Genoud, Y. Bocchi Big data in smart
    cities: from poisson to human dynamics Advanced Information Networking and Applications
    Workshops (WAINA), 2014 28th International Conference on, IEEE (2014), pp. 785-790
    CrossRefView in ScopusGoogle Scholar [40] H. Wang, O.L. Osen, G. Li, W. Li, H.-N.
    Dai, W. Zeng Big data and industrial internet of things for the maritime industry
    in northwestern Norway TENCON 2015-2015 IEEE Region 10 Conference, IEEE (2015),
    pp. 1-5 Google Scholar [41] P. Barnaghi, M. Bermudez-Edo, R. Tönjes Challenges
    for quality of data in smart cities J. Data Inf. Qual. (JDIQ), 6 (2–3) (2015),
    p. 6 View in ScopusGoogle Scholar [42] A. Sheth, C. Henson, S.S. Sahoo Semantic
    sensor web IEEE Internet Comput., 12 (4) (2008), pp. 78-83 View in ScopusGoogle
    Scholar [43] M.A. Kafi, Y. Challal, D. Djenouri, M. Doudou, A. Bouabdallah, N.
    Badache A study of wireless sensor networks for urban traffic monitoring: applications
    and architectures Proc. Comput. Sci., 19 (2013), pp. 617-626 View PDFView articleView
    in ScopusGoogle Scholar [44] D. Toshniwal, et al. Clustering techniques for streaming
    data-a survey Advance Computing Conference (IACC), 2013 IEEE 3rd International,
    IEEE (2013), pp. 951-956 Google Scholar [45] V. Jakkula, D. Cook Outlier detection
    in smart environment structured power datasets Sixth International Conference
    on Intelligent Environments (IE), 2010, IEEE (2010), pp. 29-33 CrossRefView in
    ScopusGoogle Scholar [46] P. Ni, C. Zhang, Y. Ji A hybrid method for short-term
    sensor data forecasting in internet of things 2014 11th International Conference
    on Fuzzy Systems and Knowledge Discovery (FSKD) (2014) Google Scholar [47] X.
    Ma, Y.-J. Wu, Y. Wang, F. Chen, J. Liu Mining smart card data for transit riders''
    travel patterns Transp. Res. Part C Emerg. Technol., 36 (2013), pp. 1-12 View
    PDFView articleView in ScopusGoogle Scholar [48] W. Derguech, E. Bruke, E. Curry
    An autonomic approach to real-time predictive analytics using open data and internet
    of things Ubiquitous Intelligence and Computing, 2014 IEEE 11th Intl Conf on and
    IEEE 11th Intl Conf on and Autonomic and Trusted Computing, and IEEE 14th Intl
    Conf on Scalable Computing and Communications and its Associated Workshops (UTC-ATC-ScalCom),
    IEEE (2014), pp. 204-211 View in ScopusGoogle Scholar [49] W. Han, Y. Gu, Y. Zhang,
    L. Zheng Data driven quantitative trust model for the internet of agricultural
    things Internet of Things (IOT), 2014 International Conference on the, IEEE (2014),
    pp. 31-36 View in ScopusGoogle Scholar [50] A.M. Souza, J.R. Amazonas An outlier
    detect algorithm using big data processing and internet of things architecture
    Proc. Comput. Sci., 52 (2015), pp. 1010-1015 View PDFView articleView in ScopusGoogle
    Scholar [51] D.N. Monekosso, P. Remagnino Data reconciliation in a smart home
    sensor network Expert Syst. Appl., 40 (8) (2013), pp. 3248-3255 View PDFView articleView
    in ScopusGoogle Scholar [52] M. Shukla, Y. Kosta, P. Chauhan Analysis and evaluation
    of outlier detection algorithms in data streams International Conference on Computer,
    Communication and Control (IC4), 2015, IEEE (2015), pp. 1-8 CrossRefGoogle Scholar
    [53] A. Shilton, S. Rajasegarar, C. Leckie, M. Palaniswami Dp1svm: a dynamic planar
    one-class support vector machine for internet of things environment International
    Conference on Recent Advances in Internet of Things (RIoT), 2015, IEEE (2015),
    pp. 1-6 CrossRefGoogle Scholar [54] D. Barber Bayesian Reasoning and Machine Learning
    Cambridge University Press (2012) Google Scholar [55] C.M. Bishop Pattern Recognition
    and Machine Learning Springer (2006) Google Scholar [56] K.P. Murphy Machine Learning:
    a Probabilistic Perspective MIT press (2012) Google Scholar [57] I.G.Y. Bengio,
    A. Courville Deep Learning, Book in Preparation for MIT Press (2016) Google Scholar
    [58] T. Cover, P. Hart Nearest neighbor pattern classification IEEE Trans. Inf.
    Theory, 13 (1) (1967), pp. 21-27 Google Scholar [59] H.V. Jagadish, B.C. Ooi,
    K.-L. Tan, C. Yu, R. Zhang Idistance: an adaptive b+-tree based indexing method
    for nearest neighbor search ACM Trans. Database Syst. (TODS), 30 (2) (2005), pp.
    364-397 CrossRefView in ScopusGoogle Scholar [60] A. McCallum, K. Nigam, et al.
    A comparison of event models for naive bayes text classification AAAI-98 Workshop
    on Learning for Text Categorization, vol. 752, Citeseer (1998), pp. 41-48 Google
    Scholar [61] H. Zhang The optimality of naive bayes AA, 1 (2) (2004), p. 3 View
    PDFView articleCrossRefGoogle Scholar [62] C. Cortes, V. Vapnik Support-vector
    networks Mach. Learn., 20 (3) (1995), pp. 273-297 View in ScopusGoogle Scholar
    [63] I. Guyon, B. Boser, V. Vapnik Automatic capacity tuning of very large vc-dimension
    classifiers Advances in Neural Information Processing Systems (1993) 147–147 Google
    Scholar [64] N. Cristianini, J. Shawe-Taylor An Introduction to Support Vector
    Machines and Other Kernel-based Learning Methods Cambridge university press (2000)
    Google Scholar [65] B. Scholkopf, A.J. Smola Learning with Kernels: Support Vector
    Machines, Regularization, Optimization, and beyond MIT press (2001) Google Scholar
    [66] J. Neter, M.H. Kutner, C.J. Nachtsheim, W. Wasserman Applied Linear Statistical
    Models, vol. 4, Irwin Chicago (1996) [67] G.A. Seber, A.J. Lee Linear Regression
    Analysis, vol. 936, John Wiley & Sons (2012) [68] D.C. Montgomery, E.A. Peck,
    G.G. Vining Introduction to Linear Regression Analysis John Wiley & Sons (2015)
    Google Scholar [69] A. Smola, V. Vapnik Support vector regression machines Adv.
    Neural Inf. Process. Syst., 9 (1997), pp. 155-161 Google Scholar [70] A.J. Smola,
    B. Schölkopf A tutorial on support vector regression Statistics Comput., 14 (3)
    (2004), pp. 199-222 View in ScopusGoogle Scholar [71] L. Breiman, J. Friedman,
    C.J. Stone, R.A. Olshen Classification and Regression Trees CRC press (1984) Google
    Scholar [72] A.M. Prasad, L.R. Iverson, A. Liaw Newer classification and regression
    tree techniques: bagging and random forests for ecological prediction Ecosystems,
    9 (2) (2006), pp. 181-199 CrossRefView in ScopusGoogle Scholar [73] W.-Y. Loh
    Classification and regression trees Wiley Interdiscip. Rev. Data Min. Knowl. Discov.,
    1 (1) (2011), pp. 14-23 CrossRefView in ScopusGoogle Scholar [74] L. Breiman Random
    forests Mach. Learn., 45 (1) (2001), pp. 5-32 Google Scholar [75] L. Breiman Bagging
    predictors Mach. Learn., 24 (2) (1996), pp. 123-140 Google Scholar [76] A. Likas,
    N. Vlassis, J.J. Verbeek The global k-means clustering algorithm Pattern Recognit.,
    36 (2) (2003), pp. 451-461 View PDFView articleView in ScopusGoogle Scholar [77]
    A. Coates, A.Y. Ng Learning feature representations with K-Means G. Montavon,
    G.B. Orr, K.R. Müller (Eds.), Neural Networks: Tricks of the Trade. Lecture Notes
    in Computer Science, vol. 7700, Springer, Berlin, Heidelberg (2012) Google Scholar
    [78] V. Jumutc, R. Langone, J.A. Suykens Regularized and sparse stochastic k-means
    for distributed large-scale clustering Big Data (Big Data), 2015 IEEE International
    Conference on, IEEE (2015), pp. 2535-2540 View in ScopusGoogle Scholar [79] M.
    Ester, H.-P. Kriegel, J. Sander, X. Xu, et al. A density-based algorithm for discovering
    clusters in large spatial databases with noise Kdd, vol. 96 (1996), pp. 226-231
    Google Scholar [80] H.-P. Kriegel, P. Kröger, J. Sander, A. Zimek Density-based
    clustering Wiley Interdiscip. Rev. Data Min. Knowl. Discov., 1 (3) (2011), pp.
    231-240 CrossRefView in ScopusGoogle Scholar [81] R.J. Campello, D. Moulavi, J.
    Sander Density-based clustering based on hierarchical density estimates Pacific-asia
    Conference on Knowledge Discovery and Data Mining, Springer (2013), pp. 160-172
    CrossRefView in ScopusGoogle Scholar [82] K. Pearson Liii. on lines and planes
    of closest fit to systems of points in space Lond. Edinb. Dublin Philos. Mag.
    J. Sci., 2 (11) (1901), pp. 559-572 CrossRefGoogle Scholar [83] H. Hotelling Analysis
    of a complex of statistical variables into principal components J. Educ. Psychol.,
    24 (6) (1933), p. 417 CrossRefView in ScopusGoogle Scholar [84] I. Jolliffe Principal
    Component Analysis Wiley Online Library (2002) Google Scholar [85] H. Abdi, L.J.
    Williams Principal component analysis Wiley Interdiscip. Rev. Comput. Stat., 2
    (4) (2010), pp. 433-459 CrossRefView in ScopusGoogle Scholar [86] R. Bro, A.K.
    Smilde Principal component analysis Anal. Methods, 6 (9) (2014), pp. 2812-2831
    View in ScopusGoogle Scholar [87] H. Hotelling Relations between two sets of variates
    Biometrika, 28 (3/4) (1936), pp. 321-377 Google Scholar [88] F.R. Bach, M.I. Jordan
    Kernel independent component analysis J. Mach. Learn. Res., 3 (Jul) (2002), pp.
    1-48 View in ScopusGoogle Scholar [89] Y. LeCun, L. Bottou, Y. Bengio, P. Haffner
    Gradient-based learning applied to document recognition Proc. IEEE, 86 (11) (1998),
    pp. 2278-2324 Google Scholar [90] X. Glorot, Y. Bengio Understanding the difficulty
    of training deep feedforward neural networks Aistats, vol. 9 (2010), pp. 249-256
    Google Scholar [91] R.C. Eberhart Neural Network PC Tools: a Practical Guide Academic
    Press (2014) Google Scholar [92] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian
    Sun Deep residual learning for image recognition In Proceedings of the IEEE conference
    on computer vision and pattern recognition (2016), pp. 770-778 Google Scholar
    [93] Y. LeCun, Y. Bengio, G. Hinton Deep learning Nature, 521 (7553) (2015), pp.
    436-444 CrossRefView in ScopusGoogle Scholar [94] B. Schölkopf, J.C. Platt, J.
    Shawe-Taylor, A.J. Smola, R.C. Williamson Estimating the support of a high-dimensional
    distribution Neural Comput., 13 (7) (2001), pp. 1443-1471 View in ScopusGoogle
    Scholar [95] G. Ratsch, S. Mika, B. Scholkopf, K.-R. Muller Constructing boosting
    algorithms from svms: an application to one-class classification IEEE Trans. Pattern
    Anal. Mach. Intell., 24 (9) (2002), pp. 1184-1199 View in ScopusGoogle Scholar
    [96] C.-T. Do, A. Douzal-Chouakria, S. Marié, M. Rombaut Multiple metric learning
    for large margin knn classification of time series Signal Processing Conference
    (EUSIPCO), 2015 23rd European, IEEE (2015), pp. 2346-2350 CrossRefView in ScopusGoogle
    Scholar [97] V. Metsis, I. Androutsopoulos, G. Paliouras Spam Filtering with Naive
    Bayes-which Naive Bayes? CEAS (2006), pp. 27-28 View in ScopusGoogle Scholar [98]
    G.I. Webb, J.R. Boughton, Z. Wang Not so naive bayes: aggregating one-dependence
    estimators Mach. Learn., 58 (1) (2005), pp. 5-24 CrossRefView in ScopusGoogle
    Scholar [99] N.I. Gould, P.L. Toint Numerical Analysis Group Internal Report A
    Quadratic Programming Bibliography, vol. 1 (2000), p. 32 [100] John Platt Sequential
    Minimal Optimization: A Fast Algorithm for Training Support Vector Machines (1998)
    Google Scholar [101] Z.A. Zhu, W. Chen, G. Wang, C. Zhu, Z. Chen P-packsvm: parallel
    primal gradient descent kernel svm 2009 Ninth IEEE International Conference on
    Data Mining, IEEE (2009), pp. 677-686 CrossRefView in ScopusGoogle Scholar [102]
    C.-N.J. Yu, T. Joachims Learning structural svms with latent variables Proceedings
    of the 26th Annual International Conference on Machine Learning, ACM (2009), pp.
    1169-1176 CrossRefView in ScopusGoogle Scholar [103] J. Weston, C. Watkins, et
    al. Support Vector Machines for Multi-class Pattern Recognition, vol. 99, ESANN
    (1999), pp. 219-224 [104] C.-W. Hsu, C.-J. Lin A comparison of methods for multiclass
    support vector machines IEEE Trans. Neural Netw., 13 (2) (2002), pp. 415-425 View
    in ScopusGoogle Scholar [105] H.-C. Kim, S. Pang, H.-M. Je, D. Kim, S.Y. Bang
    Constructing support vector machine ensemble Pattern Recognit., 36 (12) (2003),
    pp. 2757-2767 View PDFView articleView in ScopusGoogle Scholar [106] G.M. Foody,
    A. Mathur A relative evaluation of multiclass image classification by support
    vector machines IEEE Trans. Geosci. Remote Sens., 42 (6) (2004), pp. 1335-1343
    View in ScopusGoogle Scholar [107] C.S. Leslie, E. Eskin, W.S. Noble The spectrum
    kernel: a string kernel for svm protein classification Pacific symposium on Biocomputing,
    vol. 7 (2002), pp. 566-575 Google Scholar [108] T. Poggio, G. Cauwenberghs Incremental
    and decremental support vector machine learning Adv. neural Inf. Process. Syst.,
    13 (2001), p. 409 Google Scholar [109] M.A. Khan, A. Khan, M.N. Khan, S. Anwar
    A novel learning method to classify data streams in the internet of things Software
    Engineering Conference (NSEC), 2014 National, IEEE (2014), pp. 61-66 View in ScopusGoogle
    Scholar [110] H. Trevor, T. Robert, F. Jerome The Elements of Statistical Learning:
    Data Mining, Inference and Prediction 1(8), Springer-Verlag, New York (2001),
    pp. 371-406 Google Scholar [111] R. Caruana, A. Niculescu-Mizil An empirical comparison
    of supervised learning algorithms Proceedings of the 23rd International Conference
    on Machine Learning, ACM (2006), pp. 161-168 CrossRefGoogle Scholar [112] J. Shotton,
    T. Sharp, A. Kipman, A. Fitzgibbon, M. Finocchio, A. Blake, M. Cook, R. Moore
    Real-time human pose recognition in parts from single depth images Commun. ACM,
    56 (1) (2013), pp. 116-124 CrossRefView in ScopusGoogle Scholar [113] T. Au, M.-L.I.
    Chin, G. Ma Mining Rare Events Data by Sampling and Boosting: a Case Study, in:
    International Conference on Information Systems, Technology and Management Springer
    (2010), pp. 373-379 CrossRefView in ScopusGoogle Scholar [114] A. Sahu, G. Runger,
    D. Apley Image denoising with a multi-phase kernel principal component approach
    and an ensemble version 2011 IEEE Applied Imagery Pattern Recognition Workshop
    (AIPR), IEEE (2011), pp. 1-7 CrossRefGoogle Scholar [115] A. Shinde, A. Sahu,
    D. Apley, G. Runger Preimages for variation patterns from kernel pca and bagging
    IIE Trans., 46 (5) (2014), pp. 429-456 View in ScopusGoogle Scholar [116] X. Tao,
    C. Ji Clustering massive small data for iot 2nd International Conference on Systems
    and Informatics (ICSAI), 2014, IEEE (2014), pp. 974-978 CrossRefView in ScopusGoogle
    Scholar [117] H. Hromic, D. Le Phuoc, M. Serrano, A. Antonić, I.P. Žarko, C. Hayes,
    S. Decker Real time analysis of sensor data for the internet of things by means
    of clustering and event processing 2015 IEEE International Conference on Communications
    (ICC), IEEE (2015), pp. 685-691 CrossRefView in ScopusGoogle Scholar [118] M.
    Çelik, F. Dadaşer-Çelik, A.Ş. Dokuz Anomaly detection in temperature data using
    dbscan algorithm Innovations in Intelligent Systems and Applications (INISTA),
    2011 International Symposium on, IEEE (2011), pp. 91-95 CrossRefView in ScopusGoogle
    Scholar [119] G.H. Golub, C.F. Van Loan Matrix Computations, vol. 3, JHU Press
    (2012) [120] L. Sirovich Turbulence and the dynamics of coherent structures part
    i: coherent structures Q. Appl. Math., 45 (3) (1987), pp. 561-571 CrossRefGoogle
    Scholar [121] G. Cybenko Approximation by superpositions of a sigmoidal function,
    Mathematics of control Signals Syst., 2 (4) (1989), pp. 303-314 View in ScopusGoogle
    Scholar [122] K. Hornik Approximation capabilities of multilayer feedforward networks
    Neural Netw., 4 (2) (1991), pp. 251-257 View PDFView articleView in ScopusGoogle
    Scholar [123] K. Fukushima Neocognitron: a self-organizing neural network model
    for a mechanism of pattern recognition unaffected by shift in position Biol. Cybern.,
    36 (4) (1980), pp. 193-202 Google Scholar [124] W. Blum, D. Burghes, N. Green,
    G. Kaiser-Messmer Teaching and learning of mathematics and its applications: first
    results from a comparative empirical study in england and Germany Teach. Math.
    Appl., 11 (3) (1992), pp. 112-123 CrossRefView in ScopusGoogle Scholar [125] J.
    Schmidhuber Deep learning in neural networks: an overview Neural Netw., 61 (2015),
    pp. 85-117 View PDFView articleView in ScopusGoogle Scholar [126] I. Kotenko,
    I. Saenko, F. Skorik, S. Bushuev Neural network approach to forecast the state
    of the internet of things elements XVIII International Conference on Soft Computing
    and Measurements (SCM), 2015, IEEE (2015), pp. 133-135 CrossRefView in ScopusGoogle
    Scholar [127] T.G. Dietterich Machine learning for sequential data: a review Joint
    IAPR International Workshops on Statistical Techniques in Pattern Recognition
    (SPR) and Structural and Syntactic Pattern Recognition (SSPR), Springer (2002),
    pp. 15-30 CrossRefView in ScopusGoogle Scholar [128] L.E. Baum, J.A. Eagon, et
    al. An inequality with applications to statistical estimation for probabilistic
    functions of markov processes and to a model for ecology Bull. Am. Math. Soc.,
    73 (3) (1967), pp. 360-363 CrossRefView in ScopusGoogle Scholar [129] L.R. Rabiner
    A tutorial on hidden markov models and selected applications in speech recognition
    Proc. IEEE, 77 (2) (1989), pp. 257-286 View in ScopusGoogle Scholar [130] T.J.
    Sejnowski, C.R. Rosenberg Parallel networks that learn to pronounce english text
    Complex Syst., 1 (1) (1987), pp. 145-168 Google Scholar [131] R.E. Kalman, R.S.
    Bucy New results in linear filtering and prediction theory J. Basic Eng., 83 (1)
    (1961), pp. 95-108 CrossRefGoogle Scholar [132] J. Lafferty, A. McCallum, F. Pereira
    Conditional random fields: probabilistic models for segmenting and labeling sequence
    data Proceedings of the Eighteenth International Conference on Machine Learning,
    vol. 1, ICML (2001), pp. 282-289 Google Scholar [133] R.J. Williams, D. Zipser
    A learning algorithm for continually running fully recurrent neural networks Neural
    Comput., 1 (2) (1989), pp. 270-280 CrossRefGoogle Scholar [134] A. McCallum, D.
    Freitag, F.C. Pereira Maximum Entropy Markov Models for Information Extraction
    and Segmentation, vol. 17, Icml (2000), pp. 591-598 View in Scopus [135] H. Sak,
    A.W. Senior, F. Beaufays Long Short-term Memory Recurrent Neural Network Architectures
    for Large Scale Acoustic Modeling (2014), pp. 338-342 Interspeech CrossRefView
    in ScopusGoogle Scholar [136] A. Graves, M. Liwicki, S. Fernández, R. Bertolami,
    H. Bunke, J. Schmidhuber A novel connectionist system for unconstrained handwriting
    recognition IEEE Trans. Pattern Anal. Mach. Intell., 31 (5) (2009), pp. 855-868
    View in ScopusGoogle Scholar [137] B. Pardo, W. Birmingham Modeling form for on-line
    following of musical performances Proceedings of the National Conference on Artificial
    Intelligence, vol. 20, AAAI Press; MIT Press, Menlo Park, CA; Cambridge, MA; London
    (1999), p. 1018 2005 Google Scholar [138] V.J. Hodge, J. Austin A survey of outlier
    detection methodologies Artif. Intell. Rev., 22 (2) (2004), pp. 85-126 View in
    ScopusGoogle Scholar [139] V. Chandola, A. Banerjee, V. Kumar Anomaly detection:
    a survey ACM Comput. Surv. (CSUR), 41 (3) (2009), p. 15 View in ScopusGoogle Scholar
    [140] Z.Á. Milacski, M. Ludersdorfer, A. Lőrincz, P. van der Smagt Robust detection
    of anomalies via sparse methods International Conference on Neural Information
    Processing, Springer (2015), pp. 419-426 CrossRefView in ScopusGoogle Scholar
    [141] D.E. Denning An intrusion-detection model IEEE Trans. Softw. Eng., 2 (1987),
    pp. 222-232 View in ScopusGoogle Scholar [142] I. Tomek An experiment with the
    edited nearest-neighbor rule IEEE Trans. Syst. Man Cybern., 6 (1976), pp. 448-452
    View in ScopusGoogle Scholar [143] M.R. Smith, T. Martinez Improving classification
    accuracy by identifying and removing instances that should be misclassified Neural
    Networks (IJCNN), The 2011 International Joint Conference on, IEEE (2011), pp.
    2690-2697 View in ScopusGoogle Scholar [144] S. Rajasegarar, C. Leckie, J.C. Bezdek,
    M. Palaniswami Centered hyperspherical and hyperellipsoidal one-class support
    vector machines for anomaly detection in sensor networks IEEE Trans. Inf. Forensics
    Secur., 5 (3) (2010), pp. 518-533 View in ScopusGoogle Scholar [145] K.A. Heller,
    K.M. Svore, A.D. Keromytis, S.J. Stolfo One class support vector machines for
    detecting anomalous windows registry accesses Proc. Of the Workshop on Data Mining
    for Computer Security, vol. 9 (2003) Google Scholar [146] M. Zhang, B. Xu, J.
    Gong An anomaly detection model based on one-class svm to detect network intrusions
    2015 11th International Conference on Mobile Ad-hoc and Sensor Networks (MSN),
    IEEE (2015), pp. 102-107 CrossRefView in ScopusGoogle Scholar [147] Y. Zhang,
    N. Meratnia, P. Havinga Adaptive and online one-class support vector machine-based
    outlier detection techniques for wireless sensor networks Advanced Information
    Networking and Applications Workshops, 2009. WAINA’09. International Conference
    on, IEEE (2009), pp. 990-995 CrossRefView in ScopusGoogle Scholar [148] S. Hu
    Research on data fusion of the internet of things Logistics, Informatics and Service
    Sciences (LISS), 2015 International Conference on, IEEE (2015), pp. 1-5 View in
    ScopusGoogle Scholar Cited by (0) © 2018 Chongqing University of Posts and Telecommunications.
    Production and hosting by Elsevier B.V. Recommended articles Phosphate regulates
    chondrogenesis in a biphasic and maturation-dependent manner Differentiation,
    Volume 95, 2017, pp. 54-62 Biming Wu, …, Rhima M. Coleman View PDF A routing protocol
    for urban vehicular ad hoc networks to support non-safety applications Digital
    Communications and Networks, Volume 4, Issue 3, 2018, pp. 189-199 S.K. Bhoi, …,
    R.R. Swain View PDF A new protocol for concurrently allocating licensed spectrum
    to underlay cognitive users Digital Communications and Networks, Volume 4, Issue
    3, 2018, pp. 200-208 Sabyasachi Chatterjee, …, Mita Nasipuri View PDF Show 3 more
    articles Article Metrics Citations Citation Indexes: 695 Patent Family Citations:
    1 Policy Citations: 4 Captures Readers: 1723 Mentions References: 2 Social Media
    Shares, Likes & Comments: 3 View details About ScienceDirect Remote access Shopping
    cart Advertise Contact and support Terms and conditions Privacy policy Cookies
    are used by this site. Cookie settings | Your Privacy Choices All content on this
    site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights
    are reserved, including those for text and data mining, AI training, and similar
    technologies. For all open access content, the Creative Commons licensing terms
    apply.'
  inline_citation: '>'
  journal: Digital communications and networks (Online)
  limitations: '>'
  pdf_link: null
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: 'Machine learning for internet of things data analysis: a survey'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/mvt.2019.2921208
  analysis: '>'
  authors:
  - Zhengquan Zhang
  - Yue Xiao
  - Zheng Ma
  - Ming Xiao
  - Zhiguo Ding
  - Xianfu Lei
  - George K. Karagiannidis
  - Pingzhi Fan
  citation_count: 1338
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy IEEE.org IEEE Xplore IEEE
    SA IEEE Spectrum More Sites Subscribe Donate Cart Create Account Personal Sign
    In Browse My Settings Help Institutional Sign In All Books Conferences Courses
    Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals & Magazines
    >IEEE Vehicular Technology Mag... >Volume: 14 Issue: 3 6G Wireless Networks: Vision,
    Requirements, Architecture, and Key Technologies Publisher: IEEE Cite This PDF
    Zhengquan Zhang; Yue Xiao; Zheng Ma; Ming Xiao; Zhiguo Ding; Xianfu Lei; George
    K. Karagiannidis; Pingzhi Fan All Authors 1302 Cites in Papers 32523 Full Text
    Views Abstract Document Sections Background 6G Vision, Usage Scenarios, and Requirements
    Large-Dimensional and Autonomous 6G Networks AI-Enabled Innovative Wireless Network
    Design Promising Technologies for 6G Networks Show Full Outline Authors Figures
    References Citations Keywords Metrics Abstract: A key enabler for the intelligent
    information society of 2030, 6G networks are expected to provide performance superior
    to 5G and satisfy emerging services and applications. In this article, we present
    our vision of what 6G will be and describe usage scenarios and requirements for
    multi-terabyte per second (Tb/s) and intelligent 6G networks. We present a large-dimensional
    and autonomous network architecture that integrates space, air, ground, and underwater
    networks to provide ubiquitous and unlimited wireless connectivity. We also discuss
    artificial intelligence (AI) and machine learning [1], [2] for autonomous networks
    and innovative air-interface design. Finally, we identify several promising technologies
    for the 6G ecosystem, including terahertz (THz) communications, very-large-scale
    antenna arrays [i.e., supermassive (SM) multiple-input, multiple-output (MIMO)],
    large intelligent surfaces (LISs) and holographic beamforming (HBF), orbital angular
    momentum (OAM) multiplexing, laser and visible-light communications (VLC), blockchain-based
    spectrum sharing, quantum communications and computing, molecular communications,
    and the Internet of Nano-Things. Published in: IEEE Vehicular Technology Magazine
    ( Volume: 14, Issue: 3, September 2019) Page(s): 28 - 41 Date of Publication:
    18 July 2019 ISSN Information: DOI: 10.1109/MVT.2019.2921208 Publisher: IEEE Funding
    Agency: A key enabler for the intelligent information society of 2030, 6G networks
    are expected to provide performance superior to 5G and satisfy emerging services
    and applications. In this article, we present our vision of what 6G will be and
    describe usage scenarios and requirements for multi-terabyte per second (Tb/s)
    and intelligent 6G networks. We present a large-dimensional and autonomous network
    architecture that integrates space, air, ground, and underwater networks to provide
    ubiquitous and unlimited wireless connectivity. We also discuss artificial intelligence
    (AI) and machine learning [1], [2] for autonomous networks and innovative air–interface
    design. Finally, we identify several promising technologies for the 6G ecosystem,
    including terahertz (THz) communications, very-large-scale antenna arrays [i.e.,
    supermassive (SM) multiple-input, multiple-output (MIMO)], large intelligent surfaces
    (LISs) and holographic beamforming (HBF), orbital angular momentum (OAM) multiplexing,
    laser and visible-light communications (VLC), blockchain-based spectrum sharing,
    quantum communications and computing, molecular communications, and the Internet
    of Nano-Things. Sign in to Continue Reading Authors Figures References Citations
    Keywords Metrics More Like This A Privacy-Preserving Authentication, Authorization,
    and Key Agreement Scheme for Wireless Sensor Networks in 5G-Integrated Internet
    of Things IEEE Access Published: 2020 Internet of Things and Wireless Sensor Networks
    for Smart Agriculture Applications: A Survey IEEE Access Published: 2023 Show
    More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS
    VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE vehicular technology magazine
  limitations: '>'
  pdf_link: null
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: '6G Wireless Networks: Vision, Requirements, Architecture, and Key Technologies'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/access.2020.3001277
  analysis: '>'
  authors:
  - Quoc-Viet Pham
  - Fang Fang
  - Vu Nguyen Ha
  - Md. Jalil Piran
  - Mai T. P. Le
  - Long Bao Le
  - Won-Joo Hwang
  - Zhiguo Ding
  citation_count: 498
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy IEEE.org IEEE Xplore IEEE
    SA IEEE Spectrum More Sites Subscribe Donate Cart Create Account Personal Sign
    In Personal Sign In * Required *Email Address *Password Forgot Password? Sign
    In Don''t have a Personal Account? Create an IEEE Account now. Create Account
    Learn more about personalization features. IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/8948470/09113305.pdf
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: 'A Survey of Multi-Access Edge Computing in 5G and Beyond: Fundamentals,
    Technology Integration, and State-of-the-Art'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/mcom.2017.1600863
  analysis: '>'
  authors:
  - Tuyen X. Tran
  - Abolfazl Hajisami
  - Parul Pandey
  - Dario Pompili
  citation_count: 708
  full_citation: '>'
  full_text: '>

    IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Subscribe Donate Cart Create
    Account Personal Sign In Browse My Settings Help Institutional Sign In All Books
    Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED
    SEARCH Journals & Magazines >IEEE Communications Magazine >Volume: 55 Issue: 4
    Collaborative Mobile Edge Computing in 5G Networks: New Paradigms, Scenarios,
    and Challenges Publisher: IEEE Cite This PDF Tuyen X. Tran; Abolfazl Hajisami;
    Parul Pandey; Dario Pompili All Authors 672 Cites in Papers 4 Cites in Patents
    14273 Full Text Views Abstract Document Sections Introduction State of the Art
    MEC vs. C-RAN Case Study I: Mobile Edge Orchestration Case Study II: Collaborative
    Video Caching and Processing Show Full Outline Authors Figures References Citations
    Keywords Metrics Abstract: MEC is an emerging paradigm that provides computing,
    storage, and networking resources within the edge of the mobile RAN. MEC servers
    are deployed on a generic computing platform within the RAN, and allow for delay-sensitive
    and context-aware applications to be executed in close proximity to end users.
    This paradigm alleviates the backhaul and core network and is crucial for enabling
    low-latency, high-bandwidth, and agile mobile services. This article envisions
    a real-time, context-aware collaboration framework that lies at the edge of the
    RAN, comprising MEC servers and mobile devices, and amalgamates the heterogeneous
    resources at the edge. Specifically, we introduce and study three representative
    use cases ranging from mobile edge orchestration, collaborative caching and processing,
    and multi-layer interference cancellation. We demonstrate the promising benefits
    of the proposed approaches in facilitating the evolution to 5G networks. Finally,
    we discuss the key technical challenges and open research issues that need to
    be addressed in order to efficiently integrate MEC into the 5G ecosystem. Published
    in: IEEE Communications Magazine ( Volume: 55, Issue: 4, April 2017) Page(s):
    54 - 61 Date of Publication: 14 April 2017 ISSN Information: DOI: 10.1109/MCOM.2017.1600863
    Publisher: IEEE Introduction Over the last few years, our daily lifestyle is increasingly
    exposed to a plethora of mobile applications for entertainment, business, education,
    health care, social networking, and so on. At the same time, mobile data traffic
    is predicted to continue doubling each year. To keep up with these surging demands,
    network operators have to spend enormous efforts to improve users'' experience
    while maintaining healthy revenue growth. To overcome the limitations of current
    radio access networks (RANs), two emerging paradigms have been proposed: • Cloud
    RAN (C-RAN), which aims at the centralization of base station (BS) functions via
    virtualization • Mobile edge computing (MEC), which proposes to empower the network
    edge Sign in to Continue Reading Authors Figures References Citations Keywords
    Metrics More Like This Workload Re-Allocation for Edge Computing With Server Collaboration:
    A Cooperative Queueing Game Approach IEEE Transactions on Mobile Computing Published:
    2023 A Sophisticated Ad Hoc Cloud Computing Environment Built by the Migration
    of a Server to Facilitate Distributed Collaboration 2012 26th International Conference
    on Advanced Information Networking and Applications Workshops Published: 2012
    Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT
    OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE communications magazine (Print)
  limitations: '>'
  pdf_link: null
  publication_year: 2017
  relevance_score1: 0
  relevance_score2: 0
  title: 'Collaborative Mobile Edge Computing in 5G Networks: New Paradigms, Scenarios,
    and Challenges'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1002/spe.2813
  analysis: '>'
  authors:
  - Rajiv Ranjan
  - Massimo Villari
  - Haiying Shen
  - Omer Rana
  - Rajkumar Buyya
  citation_count: 2
  full_citation: '>'
  full_text: '>

    Web Store Add shortcut Name URL Customize Chrome'
  inline_citation: '>'
  journal: 'Software: Practice and Experience'
  limitations: '>'
  pdf_link: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/spe.2813
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: Software tools and techniques for fog and edge computing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1002/spe.3006
  analysis: '>'
  authors:
  - Neeraj Kumar
  - Anish Jindal
  - Massimo Villari
  - Satish Narayana Srirama
  citation_count: 7
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy UNCL: University Of Nebraska
    - Linc Acquisitions Accounting Search within Login / Register Software: Practice
    and Experience EDITORIAL Free Access Resource management of IoT edge devices:
    Challenges, techniques, and solutions Neeraj Kumar,  Anish Jindal,  Massimo Villari,  Satish
    Narayana Srirama First published: 28 June 2021 https://doi.org/10.1002/spe.3006Citations:
    4 [Corrections added on 06 July 2021, after first online publication: the second
    affiliation of Satish Narayana Srirama has been added.] SECTIONS PDF TOOLS SHARE
    With the growth in the Internet of things (IoT) paradigm, there has been a tremendous
    makeshift in how the distributed devices work to achieve a common goal. However,
    it remains essential that all these devices work in a coherent manner to perform
    a collective action. This makes the task of resource provisioning extremely important
    in such a paradigm. The end-user level in IoT mostly comprises of low computation
    and communication powered devices. Improper utilization of the available resources
    in such a scenario burdens the complete system and degrades the quality of service.
    In such a scenario, the use of cloud computing techniques can help to manage the
    resources effectively. More so, with the emergence of relatively newer cloud-based
    technologies such as edge and fog computing, resource management in the IoT has
    become far more effective. These technologies bring the computation and communication
    capabilities closer to the IoT devices where some of the services can be offloaded
    to the edge devices. These devices are called IoT edge devices and they provide
    a unique opportunity to tackle some of the existing and pertinent issues for resource
    management in IoT paradigms; yet at the same time, they face their own set of
    challenges. However, the use of IoT edge devices in a traditional IoT paradigm
    results in better utilization of the available resources as well as improving
    the overall quality of service. Keeping this in mind, this special issue addressed
    some of the aspects related to resource management in IoT edge devices with the
    focus on various challenges faced, and potential techniques and solutions to address
    such challenges by leveraging IoT edge devices. We received numerous submissions
    in the issue, and we accepted 13 high-quality submissions for publication as a
    result after following a rigorous review process. Each of the accepted papers
    is summarized as follows. In the first paper, Khan et al.1 presented “A cache-based
    approach toward improved scheduling in fog computing” for efficient resource allocation
    in the fog computing environment, while maintaining the quality of service. The
    authors use first-in first-out scheme to place the jobs in queue and cache the
    job type, fog server, arrival time, time to leave, and internal processing time.
    The jobs are then moved from the queue by the fog broker which selects fog server
    having sufficient required power and resources to execute the job. The authors''
    proposed cache-based scheme showed promising results in terms of reducing the
    execution time, latency, processing delays and power consumption as compared to
    the conventional first-come-first-serve and shortest job first policies. The second
    paper on “Extensive review of cloud resource management techniques in industry
    4.0: Issue and challenges” by Dewangan et al.2 sheds light on various types of
    resource provisioning schemes and classified those into different categories (to
    help understand them better) on the basis of the underlying technique and their
    overall objective. This survey helps to understand the optimal schemes for catering
    to different performance metrics such as time, cost, energy, service level of
    agreement rate, power consumption, resource utilization, etc. Moreover, the authors
    also highlighted some of the current research challenges in the domain of resource
    management. The next paper, “An energy efficient and low overhead fault mitigation
    technique for internet of thing edge devices reliable on-chip communication” by
    Ibrahim et al.3 presents a coding scheme to make the network-on-chip fault-tolerant.
    The network-on-chip provides communication backbone in the underlying network
    for which the proposed scheme handled both single and multibit adjacent bit errors.
    The next paper in this issue is on “Design and data analytics of electronic human
    resource management activities through Internet of Things in an organization”
    by Nasar et al.4 The authors focus on designing a data analytical human resource
    management system for IoT devices in an organization for ensuring the policies,
    strategies, and practices within the organization. The activities covered under
    this improved system include e-recruitment, e-Selection, e-performance management,
    e-learning, and e-compensation and the performance of the system was validated
    on four Kaggle databases. In the fifth paper on “A Mobile Data Offloading Framework
    based on a Combination of Blockchain and Virtual Voting”, Hassija et al.5 enable
    mobile users to offload computation tasks to resource-rich mobile-devices in order
    to reduce energy consumption and enhance performance. The authors used directed
    acyclic graphs (DAGs) for mobile offloading algorithm where the users can securely
    submit a transaction (powered by blockchain) request for task offloading a DAG,
    while a game-theoretic scheme was employed in order to model the interactions
    between various mobile devices for bargaining cost and time. The sixth paper by
    Lu is on “Security of Internet of Things edge devices”.6 The paper focuses on
    securing the edge nodes and edge gateways in IoT to meet its future security needs
    to eliminate the data leakage risk. The edge nodes were optimized by using a cache
    replacement algorithm, namely Max-PSN and the results illustrate that the proposed
    mechanism performed superiorly to the lead frequently used and least recently
    used algorithms with respect to the hit rate and average response speed of centralized
    and distributed systems. In the seventh paper, Balasubramanian and Jolfaei present
    “A scalable framework for healthcare monitoring application using the Internet
    of Medical Things”.7 The authors made use of IoT for providing real-time alarm
    and assistance in order to ease the activities of pregnant women by merging the
    advantages of event-driven and assistive care loop framework architecture. In
    the next paper, Bodkhe and Tanwar shed some light on “Secure data dissemination
    techniques for IoT applications: Research challenges and opportunities”.8 As the
    name suggests, the authors presented a comprehensive summary of secure data dissemination
    schemes present in the existing literature for IoT applications along with their
    potential research issues and possible countermeasures. The majority of the researched
    literature in this survey covers the Internet of Vehicles, Internet of Drones,
    and Internet of Battlefield things with respective open issues and challenges
    of each of these. As countermeasures, the authors researched opportunities in
    the directions of the requirement of secure dissemination protocols, efficient
    data aggregation methods, and cluster-based data dissemination. The ninth paper
    on “Comparative study of support vector machines and random forests machine learning
    algorithms on credit operation” by Teles et al.9 compares the support vector machine
    (SVM) and random forest (RF) scheme for their application to predict financial
    risks on credit operation. The outcomes of this paper suggest that while both
    can be effectively used for the specified task, RF has an advantage of the speed
    and operational simplicity over SVM; while SVM has the benefit of higher classification
    accuracy. The tenth paper presented by Zhao et al. titled “Message-Sensing Classified
    Transmission Scheme Based on Mobile Edge Computing in the Internet of Vehicles”.10
    The authors make use of mobile edge computing for secure message transmission
    by prioritizing secure messages using the analytic hierarchy process to guarantee
    a higher transmission level for urgent messages. Moreover, using the Lagrangian
    relaxation method, an optimal task offloading model was devised for delay and
    energy loss by assigning different weight factors to these parameters. The next
    paper is “FPFTS: A Joint Fuzzy PSO Mobility-aware Approach to Fog Task Scheduling
    Algorithm for IoT Devices” by Javanmardi et al.11 The authors build a fog task
    scheduler leveraging the particle swarm optimization along with fuzzy theory to
    assign tasks of the users to fog devices. The proposed task schedular was tested
    on iFogSim simulator and results show that it outperformed first-come-first-serve
    and delay-priority algorithms with respect to delay and network utilization. Zhang
    et al.,12 in their paper “Service offloading oriented edge server placement in
    smart farming” made use of the edge resources to support the real-time intelligent
    controls in smart farming. The authors presented a service offloading oriented
    architecture for reducing delay in data transmission from sensors to the edge
    servers while balancing the load on the servers and optimizing the energy consumption.
    The final accepted paper in this special issue is on “A metaheuristic optimization
    approach for energy efficiency in the IoT networks” by Iwendi et al.13 The authors
    proposed a hybrid metaheuristic algorithm, namely, WOA-SA, for optimizing the
    energy consumption of the sensors in IoT-based wireless sensor networks. The two
    metaheuristic approaches, namely, whale optimization algorithm and simulated annealing
    for choosing the cluster heads in order to optimize the energy consumption in
    the network. The proposed approach was found to be more effective than its counterparts
    in terms of load, temperature, residual energy, and cost function. We sincerely
    hope that after reading the accepted contributions in this special issue would
    help the readers of the journal and a wider research community to gain knowledge
    on the presented research challenges, techniques and solutions, and encourage
    them to further work on different aspects of resource management in IoT devices.
    ACKNOWLEDGEMENTS We thank the editor-in-chief and editorial board members for
    providing us with the opportunity to conduct a special issue in Software: Practice
    and Experience. We also like to thank the administrative staff, reviewers and
    most importantly, the authors, for their help and contributions in successful
    organization of this issue. REFERENCES Citing Literature Volume51, Issue12 Special
    Issue:Resource management of IoT edge devices: Challenges, techniques, and solutions
    December 2021 Pages 2357-2359 References Related Information Recommended iFogSim:
    A toolkit for modeling and simulation of resource management techniques in the
    Internet of Things, Edge and Fog computing environments Harshit Gupta,  Amir Vahid
    Dastjerdi,  Soumya K. Ghosh,  Rajkumar Buyya Software: Practice and Experience
    ManIoT: A 2‐tier management platform for heterogeneous IoT devices and applications
    Josué B. Antunes,  István L. Denés,  Tiago O. Castro,  Daniel F. Macedo,  Aldri
    L. dos Santos International Journal of Network Management BCEdge: Blockchain‐based
    resource management in D2D‐assisted mobile edge computing Ao Zhou,  Qibo Sun,  Jinglin
    Li Software: Practice and Experience Deep Learning Approach for Resource Optimization
    in Blockchain, Cellular Networks, and IoT: Open Challenges and Current Solutions
    Upinder Kaur,  Shalu Machine Learning Approach for Cloud Data Analytics in IoT,
    [1] Addressing the Challenges in Federating Edge Resources Ahmet Cihat Baktir,  Cagatay
    Sonmez,  Cem Ersoy,  Atay Ozgovde,  Blesson Varghese Fog and Edge Computing: Principles
    and Paradigms, [1] Download PDF Additional links ABOUT WILEY ONLINE LIBRARY Privacy
    Policy Terms of Use About Cookies Manage Cookies Accessibility Wiley Research
    DE&I Statement and Publishing Policies Developing World Access HELP & SUPPORT
    Contact Us Training and Support DMCA & Reporting Piracy OPPORTUNITIES Subscription
    Agents Advertisers & Corporate Partners CONNECT WITH WILEY The Wiley Network Wiley
    Press Room Copyright © 1999-2024 John Wiley & Sons, Inc or related companies.
    All rights reserved, including rights for text and data mining and training of
    artificial technologies or similar technologies.'
  inline_citation: '>'
  journal: Software, practice & experience/Software, practice and experience
  limitations: '>'
  pdf_link: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/spe.3006
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: 'Resource management of <scp>IoT</scp> edge devices: Challenges, techniques,
    and solutions'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.jmsy.2018.01.006
  analysis: '>'
  authors:
  - Fei Tao
  - Qinglin Qi
  - Ang Liu
  - Andrew Kusiak
  citation_count: 1034
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Historical perspectives
    on manufacturing data 3. Lifecycle of manufacturing data 4. Data-driven smart
    manufacturing 5. Case study 6. Conclusion and future work Acknowledgments References
    Show full outline Cited by (1082) Figures (7) Show 1 more figure Tables (1) Table
    1 Journal of Manufacturing Systems Volume 48, Part C, July 2018, Pages 157-169
    Data-driven smart manufacturing Author links open overlay panel Fei Tao a, Qinglin
    Qi a, Ang Liu b, Andrew Kusiak c Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.jmsy.2018.01.006
    Get rights and content Highlights • The evolution of manufacturing data was reflected
    in accordance with four ages. • The lifecycle of manufacturing big data was illustrated
    as a series of phases. • A framework of data driven smart manufacturing is proposed,
    and the characteristics are discussed. • Several application scenarios of the
    proposed framework are outlined. • A case is given out to illustrate the implementation
    of the proposed framework. Abstract The advances in the internet technology, internet
    of things, cloud computing, big data, and artificial intelligence have profoundly
    impacted manufacturing. The volume of data collected in manufacturing is growing.
    Big data offers a tremendous opportunity in the transformation of today’s manufacturing
    paradigm to smart manufacturing. Big data empowers companies to adopt data-driven
    strategies to become more competitive. In this paper, the role of big data in
    supporting smart manufacturing is discussed. A historical perspective to data
    lifecycle in manufacturing is overviewed. The big data perspective is supported
    by a conceptual framework proposed in the paper. Typical application scenarios
    of the proposed framework are outlined. Previous article in issue Next article
    in issue Keywords Big dataSmart manufacturingManufacturing dataData lifecycle
    1. Introduction Manufacturers are embracing the notion of a convergence between
    the cyber and physical world. Manufacturing strategies have been developed, such
    as Industry 4.0 in Germany, Industrial Internet in the US, and the Made in China
    2025 initiative. These programs promote the application of modern information
    technologies (new-IT) in manufacturing, which drives the development of smart
    manufacturing [1]. Smart manufacturing aims to convert data acquired across the
    product lifecycle into manufacturing intelligence in order to yield positive impacts
    on all aspects of manufacturing [2]. In the modern manufacturing industry, data
    generated by manufacturing systems is experiencing explosive growth, which has
    reached more than 1000 EB annually [3]. The systematic computational analysis
    of manufacturing data will lead to more informed decisions, which will in turn
    enhance the effectiveness of smart manufacturing [4]. In other words, data-driven
    manufacturing can be regarded as a necessary condition for smart manufacturing.
    Therefore, data is becoming a key enabler for enhancing manufacturing competitiveness
    [5], and manufacturers are beginning to recognize the strategic importance of
    data. The value of big data does not hinge solely on the sheer volume of data
    under consideration, but rather on the information and knowledge that lies hidden
    in it. The emergence of New IT as the Internet of Things (IoT), cloud computing,
    mobile Internet, and artificial intelligence (AI), can be strategically leveraged
    and effectively integrated in support of data-driven manufacturing. For example,
    a number of innovative IoT solutions [6,7] promote the deployment of sensors in
    manufacturing to collect real-time manufacturing data. Cloud computing [8,9] enables
    networked data storage, management, and off-site analysis. Analysis results can
    be easily accessed by users through various mobile devices [10]. Artificial Intelligence
    (AI) solutions enable “smart” factories to make timely decisions with minimal
    human involvement [11]. Efforts to explore the applicability of big data in manufacturing
    have been initiated. A number of studies examining big data in manufacturing,
    including industrial automation [12], have emerged in recent years. Big data as
    a driver of industrial competitiveness was investigated in [13]. Dubey et al.
    [14] illustrate the unique role of big data analytics in sustainable manufacturing.
    Zhang et al. [15] propose a big data analytics architecture for clean manufacturing
    and maintenance processes. Other researchers have explored the role of big data
    in equipment maintenance [16], fault detection [17], fault prediction [18], and
    cost estimation [19], etc. In light of the inborn intelligence of big data, manufacturing
    systems must be made more “smart” to achieve the all-round monitoring, simulation,
    and optimization of production activities. The rest of this paper is organized
    as follows. The evolvement history of manufacturing data is reviewed in Section
    2. The lifecycle of manufacturing data is discussed in Section 3. The revolutionizing
    paradigm of big data driven smart manufacturing is presented in Section 4, followed
    by an illustrative case study showcased in Section 5. Finally, conclusions are
    drawn in Section 6. 2. Historical perspectives on manufacturing data As shown
    in Fig. 1, for a long time, information was documented on paper while manufacturing
    was realized by handicraft, therefore, the integration between information technology
    and manufacturing technology was neither beneficial nor feasible. Since the advent
    of ENIAC (i.e., the first electronic computer) in 1940s, the rapid development
    of information technology (IT) has been driving manufacturing toward informatization.
    The first numerical controlled (NC) milling machine was developed in the 1950s,
    which announced that manufacturing entered the NC era. Since the 1960s, the development
    of integrated circuits has paved the way for the advancement of computer hardware
    and software. Since the 1980s, TCP/IP, local area network (LAN), World Wide Web
    (WWW), and search engine emerged one after another to meet the increasing needs
    for data storage, indexing, processing, and exchange. All of these information
    technologies were widely applied in manufacturing. As a result, many advanced
    manufacturing technologies were put forward, such as computer integrated manufacturing
    (CIM), computer aided design (CAD), manufacturing execution system (MES), computer
    aided manufacturing (CAM), enterprise resource planning (ERP), and networked manufacturing
    (NM), etc. Recently, the rise of New IT (e.g., Internet of Things, cloud computing,
    big data analytics, and artificial intelligence) continues to revolutionize the
    manufacturing paradigm, leading to a series of new manufacturing concepts, for
    instance, manufacturing grid, cyber-physical manufacturing system, cloud manufacturing,
    etc. Due to the deep fusion between IT and manufacturing, the degree of manufacturing
    smartness is progressively elevated. As a result, the manufacturing data also
    becomes increasingly richer. The evolution of manufacturing data in four stages
    is discussed (see Fig. 1). Download : Download high-res image (783KB) Download
    : Download full-size image Fig. 1. Evolution of data in manufacturing. 2.1. Data
    in the handicraft age Prior to the First Industrial Revolution, the human society
    had been in the manual manufacturing stage for a long time. Artefacts were predominantly
    designed and manufactured by artisans [20]. As the most basic form of manufacturing,
    handicraft activities were of low complexity. As a result, the data generated
    in the production process was limited as it existed mostly in the form of human
    experience. In addition, experience was mostly transmitted verbally from one generation
    to the next, primarily based on apprenticeships. The key information and data
    could be easily lost, making production and quality control impossible to achieve.
    Due to the extremely low quantity and quality, the manufacturing data generated
    in the handicraft age was neither emphasized nor fully exploited. However, since
    handcrafting involves a high levels of human creativity, even today, it is used
    to manufacture luxury products (e.g., jewelry, watch, leather bag). 2.2. Data
    in the machine age Generally speaking, the machine age consisted of two phases.
    As a result of the first industrial revolution, machines were employed as production
    tools in the early factories, leading to a significant increase in the scale of
    manufacturing. During this period, the relationship between humans and machines
    in production was highly complementary (i.e., early machines could only be operated
    by skilled operators to deliver their functions). Therefore, manufacturers began
    to emphasize two particular kinds of manufacturing data: worker-related data and
    machine-related data. Worker-related data (e.g., attendance, productivity, and
    performance) was used to facilitate decisions about issues such as salary structure,
    performance benchmarking, and work schedules. Machine-related data was used to
    support decisions concerning machine maintenance, repair, and replacement. Compared
    to the handicraft age, nevertheless, the First Industry Revolution introduced
    no significant changes to the way data was collected, stored, analyzed, transferred,
    and managed. As a matter of fact, workers still handled data manually based on
    empirical experience. As a result of the Second Industrial Revolution (or the
    Technological Revolution), machine tools and interchangeable parts were widely
    incorporated into the “new” manufacturing process (e.g., the Bessemer process)
    in modern factories, leading to significant increases in manufacturing efficiency,
    and the manufacturing paradigm shifted to the mass production model [21]. The
    Second Industrial Revolution triggered some notable changes in the way data was
    processed. In particular, because of the division of work between managers and
    workers, manufacturing data was increasingly handled by educated managers. Moreover,
    managers began to employ more systematic methods to document and analyze manufacturing
    data. The raw data was extensively recorded in written documents (e.g., instructions,
    logbooks, notes, and charts) rather than stored in human memory. Scientific methods
    were used to determine the dependency relationships between different datasets.
    During this period, manufacturers began to exploit manufacturing data for cost
    reduction, quality control, and inventory management. In particular, statistical
    models were introduced to analyze a variety of quality-related manufacturing data,
    such as production planning, throughput yield, product quality, failure rate,
    raw material consumption, and scrap rate. In summary, in the machine age, although
    a larger quantity of manufacturing data was analyzed through scientific methods,
    data was still handled manually by human operators (i.e., managers), as opposed
    to computers. Therefore, the utilization rate of manufacturing data remained relatively
    low. 2.3. Data in the information age In the information age (or the digital age),
    information technologies were widely applied in manufacturing processes. As a
    consequence, the quantity of manufacturing data that companies were able to collect
    grew exponentially. A number of factors contributed to this growth in data. First,
    information systems (e.g., CRM, MES, ERP, SCM, PDM, etc.) were widely employed
    by manufacturers to facilitate production management. Second, computer systems
    (such as CAD, CAE, CAM, and FEA) were widely used to aid the creation, simulation,
    modification, and optimization of new products as well as manufacturing processes.
    Third, industrial robots and automatic machinery were commonly used in modern
    factories. More and more, electronic devices and digital computers were employed
    to automatically control production equipment. The evolvements in information
    technologies paved the way for manufacturers to achieve meeting customer needs
    better, quicker, and cheaper [22]. In the information age, data was stored in
    computer systems and managed by information systems. For example, customer data
    (e.g., home address, phone number, demographics), sales data (e.g., type, quantity,
    price, and shipping date of finished products), supply chain data (e.g., type,
    quantity, price and supplier of raw materials), financial data (e.g., assets,
    real property, tangible property, utility, intangible property, etc.), production
    planning data, bill of materials, inventory data (e.g., type, quantity, location
    of material and finished products in the warehouse), and maintenance data are
    all managed by CRM, MES, ERP, SCM, PLM, etc. Therefore, it could be easily exchanged
    among different departments or organizations. The efficiency of data analysis
    was significantly enhanced due to the use of computational models, although analysis
    results still needed to be interpreted by human operators in order to make decisions.
    During this period, manufacturers began to leverage data to promote some advanced
    manufacturing models, such as mass customization, sustainable manufacturing, flexible
    manufacturing, intelligent manufacturing, and cloud manufacturing. Nevertheless,
    information silos (information systems that cannot communicate with other systems)
    were still common. There were no effective ways to analyze unstructured, scattered,
    repetitive, and isolated data. As a result, it was still difficult, especially
    for small- and medium-sized manufacturing enterprises, to benefit from the value
    of data. 2.4. Data in the big data age Along with the rise of IoT technologies,
    cloud computing, big data analytics, AI, and other technological advances, came
    the age of big data [23]. In manufacturing, big data refers to large amounts of
    multi-source, heterogeneous data generated throughout the product lifecycle [24],
    which is characterized by 5 Vs [25], i.e., high volume (i.e., huge quantities
    of data), variety (i.e., the data itself comes in different forms and is generated
    by diverse sources), velocity (i.e., the data is generated and renewed at very
    high speed), veracity (i.e., the data is associated with a level of bias, inconsistency,
    incompleteness, ambiguities, latency, noises, and approximation), and value (i.e.,
    huge value hidden in the data). Generally speaking, big data generated by manufacturing
    processes can be classified according to the following categories: a) Management
    data collected from manufacturing information systems (e.g., MES, ERP, CRM, SCM,
    and PDM). Information systems possess a variety of data that is related to product
    planning, order dispatch, material management, production planning, maintenance,
    inventory management, sales and marketing, distribution, customer service, and
    financial management. b) Equipment data collected from smart factories by Industrial
    IoT technologies, which includes data related to real-time performance, operating
    conditions, and the maintenance history of production equipment. c) User data
    collected from internet sources such as ecommerce platforms (e.g., Amazon, Walmart,
    and Taobao) and social networking platforms (e.g., Twitter, Facebook, LinkedIn,
    and YouTube). This type of data encompasses user demographics, user profiles,
    user preferences towards products/services, as well as user behavior (e.g., data
    about online browsing, searching, purchasing, and reviewing history). d) Product
    data collected from smart products and product-service systems by IoT technologies,
    including product performance, context of use (e.g., time, location, and weather),
    environmental data (e.g., temperature, humidity, and air quality) and user biological
    data. e) Public data collected from governments through open databases. Such datasets
    deal with data related to intellectual property, civic infrastructure, scientific
    development, environmental protection, and health-care. For manufacturers, public
    data can be used to guarantee that manufacturing processes and manufactured products
    strictly comply with government regulations and industry standards. In the big
    data age, empowered by the New ITs, manufacturer’s ability to collect, store and
    process data is significantly enhanced. Recently, there emerged a number of cost-effective
    and flexible data collection, storage, and processing solutions such as the Internet
    of Things and cloud computing. As a result, manufacturing enterprises of different
    scales, even including SMEs, can benefit from the value of data. In manufacturing,
    effective analysis of big data enables manufacturers to deepen their understanding
    of customers, competitors, products, equipment, processes, services, employees,
    suppliers, and regulators. Therefore, big data can help manufacturers to make
    more rational, responsive, and informed decisions, and enhance their competitiveness
    in the global market. The comparison of manufacturing data in different ages is
    shown in Table 1. Table 1. Comparison of manufacturing data in different manufacturing
    ages. Empty Cell Data Source Data Collection Data Storage Data Analysis Date Transfer
    Data Management Handicraft Age Human experience Manual collection Human memory
    Arbitrary Verbal communication N/A Machine Age Human and machines Manual collection
    Written documents Systematic Written documents Human operators Information Age
    Human, machines, information and computer systems Semi-automated collection Databases
    Conventional algorithms Digital files Information systems Big Data Age Machines,
    product, user, information systems, public data Automated collection Cloud services
    Big data algorithms Digital files Cloud and AI 3. Lifecycle of manufacturing data
    Data is a key enabler for smart manufacturing. However, data is not useful unless
    it is “translated” into concrete information content and context that can be directly
    understood by users [26]. Generally, before getting the concrete information from
    data, the data needs to pass through multiple steps. The complete journey of data
    collection, transmission, storage, pre-processing, filtering, analysis, mining,
    visualization, and application can be referred to the “data lifecycle” [27]. Manufacturing
    data is exploited at various points in the data lifecycle. As illustrated in Fig.
    2, a typical manufacturing data lifecycle consists of data collection, transmission,
    storage, processing, visualization, and application. Download : Download high-res
    image (1MB) Download : Download full-size image Fig. 2. Manufacturing data lifecycle.
    3.1. Data sources The volume of data collected across the entire manufacturing
    value-chain and product lifecycle is increasing at an unprecedented rate. As discussed
    in Section 2.4, the manufacturing data comes from equipment, products, human operators,
    information systems, and networks. 3.2. Data collection Data from different sources
    is collected in a variety of ways. Above all, it is collected by means of the
    IoT, whereby equipment and product data can be instantly collected through smart
    sensors, RFID (radio frequency identification), and other sensing devices, making
    it possible to monitor equipment and product health in real time [28,29]. For
    instance, built-in sensors make it possible to continuously measure, monitor,
    and report the ongoing operational status of manufacturing equipment and products,
    such as temperature, pressure, and vibration. RFID enables the automatic identification,
    tracking, and management of a large number of workpieces, as well as the materials
    necessary for production. Moreover, the emerging mobile Internet paves the way
    for user data collection through smart terminals (e.g., devices like PCs, phones,
    laptops, and tablets). Through SDKs (software development kits) or APIs (application
    programming interfaces), for example, basic user data can be collected, including
    the number of users, user profiles, location, and time. In addition, web crawling
    [30] is a widely used data acquisition technique for collecting public data based
    on certain conditions predefined by engineers and AI. Web crawling refers to the
    technology of deploying “crawlers” (i.e., computer programs) to browse public
    web pages and collect desirable information. The web crawling technology enables
    manufacturers to acquire public data in an automatic and efficient manner. Last
    but not least, management data from manufacturing information systems can be acquired
    and used at any time through database technologies. 3.3. Data storage The large
    volume of collected data from manufacturing processes must be securely stored
    and effectively integrated. Generally speaking, the various types of manufacturing
    data can be classified into structured (e.g. digit, symbols, tables, etc.), semi-structured
    (e.g., trees, graphs, XML documents, etc.), and unstructured data (e.g., logs,
    audios, videos, images, etc.) [31]. Traditionally, manufacturing enterprises focused
    heavily on structured data storage, since it was difficult to directly manage
    unstructured data within enterprise databases. Object-based storage architecture
    enables collections of data to be stored and managed as objects; this provides
    a more flexible solution for integrating semi-structured and unstructured data
    [32]. Also, through cloud computing [33], data storage can be achieved in a highly
    cost effective, energy efficient, and flexible fashion. In addition, by virtue
    of cloud services, the distribution and heterogeneity of data are shielded, enabling
    a highly scalable and shareable mode of data storage. 3.4. Data processing Data
    processing refers to a series of operations conducted to discover knowledge from
    a large volume of data. Data must be converted to information and knowledge for
    manufacturers to make informed and rational decisions. Above all, data must be
    carefully preprocessed to remove redundant, misleading, duplicate, and inconsistent
    information. Specifically, data cleaning involves the following activities: missing
    value, format, duplicate, and garbage data cleaning. Data reduction is the process
    of transforming the massive volume of data into ordered, meaningful, and simplified
    forms by means of feature or case selection [34]. After data reduction had been
    completed, the cleaned and simplified data is exploited through data analysis
    and mining to generate new information. The effectiveness of data analysis can
    be significantly enhanced through a variety of techniques, including machine learning,
    large-scale computing, and the use of forecasting models. Some advanced data mining
    methods include clustering, classification, association rules, regression, prediction,
    and deviation analysis [27]. Through the above data processing efforts, understandable
    knowledge can be derived from a large quantity of dynamic and ambiguous raw data
    [35]. 3.5. Data visualization Visualization is intended to clearly convey and
    communicate information through graphical means, enabling end users to comprehend
    data in a much more explicit fashion [10]. The most commonly used visualization
    techniques include statement, chart, diagrams, graphs, and virtual reality [36].
    Real-time data can be visualized online via users’ smart terminals. Through visualization,
    the results of data processing are made more accessible, straightforward, and
    user-friendly. 3.6. Data transmission Data is continuously flowing among different
    information systems, cyber-physical systems, and human operators. Data transmission,
    therefore, plays a critical role in maintaining communications and interactions
    among distributed manufacturing systems and resources. The recent advances in
    IoT, Internet, and communication networks substantially consolidated the technological
    foundation of real-time, reliable, and secure transmission of different types
    of data. As a result, distributed manufacturing resources can be effectively integrated
    almost anytime and anywhere. 3.7. Data applications Data has entered almost all
    aspects of daily production and operation in manufacturing enterprises [37]. First,
    during the design phase, through data analytics, new insights are revealed about
    customers, competitors, and markets. Based on the understanding developed through
    data analytics, designers can accurately and rapidly translate customer voices
    to product features and quality requirements [38]. As a result, manufacturers
    will become “closer” to customers, and agiler in terms of coping with a dynamic,
    changing market. Second, during production, the manufacturing process and equipment
    are monitored and tracked in real time. In this way, the manufactures can keep
    abreast of changes. Data analytics can lead to informed decisions concerning whether,
    when, and how to adjust manufacturing processes and equipment. Additionally, data
    can facilitate the control and improvement of product quality. Data analytics
    can provide early warnings of quality defects and rapid diagnosis of root causes,
    both of which can be rapidly determined. Accordingly, manufacturing systems can
    be adjusted in a timely manner to control product quality. Lastly, with respect
    to product utilization and MRO, potential product malfunctions can be identified
    at an early stage [39], which makes precautionary actions possible, such as preventive
    maintenance, fault prediction, and automatic upgrade. For instance, through the
    development of prediction models, analysis of historical data can be used to predict
    the fault occurrence [40]. 4. Data-driven smart manufacturing 4.1. The connotations
    of data-driven smart manufacturing Manufacturing enterprises utilize big data
    analytics to exploit the data from manufacturing to refine manufacturing process,
    improving the flexibility and smart level of manufacturing. By taking full advantage
    of manufacturing data, manufacturing is shifted from primary processes to smart
    processes, thus improving the production efficiency and the performance of a product.
    4.1.1. Data-driven smart manufacturing framework The manufacturing data is collected,
    stored, processed, and analyzed by means of big data technologies. As a result,
    the degree of manufacturing intelligence can be significantly elevated. As shown
    in Fig. 3, the data-driven smart manufacturing framework consists of four modules,
    namely, the manufacturing module, the data driver module, the real-time monitor
    module, and the problem processing module. a) Manufacturing module: this module
    accommodates different kinds of manufacturing activities. It consists of a variety
    of information systems and manufacturing resources, which can be summarized as
    man-machine-material-environment. The inputs to this module are raw materials,
    whereas the outputs are finished products. During the input-output transformation
    process, various data is collected from human operators, production equipment,
    information systems, and industrial networks. b) Data driver module: this module
    provides the driving force for smart manufacturing throughout the different stages
    of the manufacturing data lifecycle. As inputs, the data from the manufacturing
    module is transmitted to cloud-based data centers to be further analyzed. Afterwards,
    explicit information and actionable recommendations exploited from different kinds
    of raw data are used to direct the actions (e.g., product design, production planning,
    and manufacturing execution) in the manufacturing module. The real-time monitoring
    module and problem-processing module are also both powered by the data driver
    module. c) Real-time monitoring module: this module plays a role in monitoring
    the manufacturing process in real time in order to ensure product quality. Driven
    by the data driver module, this module is enabled to analyze the real-time running
    status of manufacturing facilities. As a result, manufacturers can keep abreast
    of changes in the manufacturing process, so as to develop the optimal operational
    control strategies. For example, when a machine is idling, material is distributed
    and a trajectory is tracked. The manufacturing process can be adjusted in correspondence
    to specific product quality defects. As a result, the real-time monitoring module
    can make the manufacturing facilities run more efficiently. d) Problem processing
    module: this module functions to identify and predict emerging problems (e.g.,
    equipment faults or quality defects), diagnose root causes, recommend possible
    solutions, estimate solution effectiveness, and evaluate potential impacts on
    other manufacturing activities. Based on real-time information and analysis of
    historical and ongoing data provided by the data driver module, either human operators
    or artificial intelligence applications can make informed decisions, not only
    to address current problems, but also to prevent similar problems from happening
    in the future. The proactive maintenance enabled by this module will enhance smooth
    functioning of manufacturing processes. Download : Download high-res image (1MB)
    Download : Download full-size image Fig. 3. The framework of data-driven smart
    manufacturing. The structured process of data collection, integration, storage,
    analysis, visualization and application is generally applicable for a variety
    of different industries. In that regard, the proposed data-driven smart manufacturing
    framework is intended to be universally valuable. With respect to the distinction
    between SMEs and big companies, depending on the resource availability, they can
    choose different strategies to achieve the data-driven smart manufacturing in
    different scales. For example, unlike those bigger companies that can afford to
    build an exclusive cloud infrastructure for data storage and analysis, SMEs can
    employ on-demand cloud computing services that are provided by third parties such
    as Amazon and Alibaba. Regardless where and how data is processed, the key value
    propositions of data-driven manufacturing are essentially the same for both SMEs
    and big companies. Manufacturing data helps decision makers understand changes
    in the shortest possible time, make accurate judgments regarding them, and develop
    rapid response measures to troubleshoot issues. As a consequence, production plans,
    manufacturing activities, and resources can be closely coordinated to promote
    smart manufacturing. 4.1.2. Characteristics of data-driven smart manufacturing
    The data-driven smart manufacturing shares the following five characteristics
    (see Fig. 4): (1) It enables customer-centric product development by exploiting
    user data for customized product design. For instance, user demographics, demands,
    preferences, and behaviors can be precisely quantified using big data analytics,
    so that more personalized products and services can be designed. (2) It enables
    self-organization by exploiting manufacturing resources and task data for smart
    production planning. For instance, production plans can be created based on both
    internal and external data from different manufacturing sites. The appropriate
    manufacturing resources are chosen to form the optimal configuration, which meets
    all of the demands of the manufacturing task to implement production plans. (3)
    It enables self-execution by exploiting a variety of data from the manufacturing
    process for precise control. For instance, appropriate raw material and parts
    can be sent to any manufacturing site that requires them at any time, and manufacturing
    equipment can automatically machine raw material or assemble parts where necessary.
    (4) It enables self-regulation by exploiting real-time status data for manufacturing
    process monitoring. For instance, a manufacturing system can automatically respond
    to unexpected events (e.g., a shortage of manufacturing resources or a change
    in manufacturing tasks), by making its behaviors controllable, not only by human
    operators but also through AI systems. (5) It enables self-learning and self-adaption
    by exploiting historical and real-time data for proactive maintenance and quality
    control. For instance, machine faults and quality defects can be predicted and
    prevented before they occur so that manufacturing systems can proactively adapt
    to cope with potential issues. Download : Download high-res image (528KB) Download
    : Download full-size image Fig. 4. Characteristics and applications of data-driven
    smart manufacturing. In summary, data-driven smart manufacturing provides a full
    range of services to manufacturing enterprises. One of the most important benefits
    is the ability to enable significant increases in manufacturing efficiency and
    remarkable improvements in product performance. Taking into account the characteristics
    outlined above and the manufacturing data lifecycle, the paradigm of data-driven
    smart manufacturing can be best exemplified through specific applications. 4.2.
    Data-driven-smart manufacturing application Manufacturing converts raw material
    inputs into finished product outputs and value-added services through the coordination
    of relevant manufacturing facilities, resources, and activities. Some of the most
    promising applications that can be implemented during the manufacturing process
    include applications to enable smart design, smart planning, materials distribution
    and tracking, manufacturing process monitoring, quality control, and smart equipment
    maintenance (see Fig. 5). Download : Download high-res image (797KB) Download
    : Download full-size image Fig. 5. Data-driven smart manufacturing application.
    4.2.1. Smart design The importance of design cannot be overstated, since it determines
    most of a product’s manufacturing costs. In the big data era, product design is
    shifting towards data-driven design [41]. Product design begins by researching
    and understanding customer demands, behaviors, and preferences. This type of data
    can be collected from both Internet and IoT sources. In the case of Internet data,
    customers are becoming increasingly good at sharing their first-hand experiences
    of using a product on the Internet, through portals such as social networking
    sites, ecommerce platforms, and product/service review sites [42]. In the case
    of IoT sources, rich user data (e.g., biological data, behavior data, and user-product
    interactions) can now be gathered from a growing number of increasingly popular
    smart products (e.g., smartphones and wearable devices) that are connected to
    IoT infrastructure. The holistic consideration of harnessing user-related big
    data improves the capacity for manufacturers to translate customer voices into
    product features and quality requirements. In addition, it enables designers to
    streamline design processes, promote product innovations, and develop more customized
    products for end users [43] [44]. Moreover, compared to traditional methods (e.g.,
    interviews, surveys, etc.), in virtue of cloud-based high performance computing,
    big data analytics enables users to not only accelerate computationally expensive
    tasks (e.g., market preferences and customer demands analysis, etc.), but also
    reduce costs [45]. 4.2.2. Smart planning and process optimization Even before
    manufacturing of a product begins, production planning is necessary to determine
    the production capacity of a manufacturing facility, as well as the availability
    of resources and materials. Big data analytics can make production planning and
    shop floor scheduling more intelligent [46]. First of all, a variety of data,
    such as customer orders, manufacturing resource status, production capacities,
    supply chain data, sales data, and inventory data is analyzed using big data analytics
    methods. Based on the information gathered from these approaches, hypernetwork
    based manufacturing resource supply-and-demand matching and scheduling [47] can
    be carried out to rapidly locate available resources. Next, production plans are
    developed using intelligent optimization algorithms to determine the optimal configuration
    of manufacturing resources and the execution procedures for the task [48,49].
    In addition, process optimization is also an important consideration before manufacturing
    begins. Big data analytics aid in assessing and optimizing technological processes.
    By analyzing various types of process data, including historical data and data
    on the patterns and relationships inherent to particular processing steps, the
    correlation between different technological parameters and the effect of these
    parameters on yield and quality can be determined. Adjusting technological processes
    in relation to these parameters can result in improved productivity and product
    quality, as well as reduced costs. 4.2.3. Material distribution and tracking Material
    distribution is determined through production planning and actual production progress,
    as well as various on-site urgency requirements. In the ideal scenario, the right
    material should be delivered to right equipment at the right time, so that it
    can be processed through the right operations. To support this ideal, a variety
    of material-related data, including inventory data, logistics data, and progression
    data can be managed [50]. Material data is analyzed in association with multi-source
    data related to material flow (e.g., data from human operators, machines, vehicles,
    etc.). In performing these analyses, material distribution can be determined in
    terms of material kind, quantity, delivery time and method in order to support
    optimal manufacturing logistics. For example, material can be dispatched on time,
    according to the actual production pace and conditions, to ensure smooth production
    (i.e., avoiding unnecessary production delays, interruptions, or production stoppages).
    Moreover, traceability of materials [51] is necessary to ensure that certain types
    of materials strictly comply with their corresponding quality criteria norms and
    standards. By deploying identification tags, material conditions (e.g., location,
    status, and quality) can be tracked in real time throughout the entire production
    process. For example, RFID-enabled positioning system in AGV enables the efficient
    delivery of material within the manufacturing sites [52]. Based on big data analytics,
    operational data conducive to product quality control and product defect traceability
    can be generated during production. 4.2.4. Manufacturing process monitoring The
    manufacturing process consists of multiple manufacturing factors. These factors
    (e.g., manufacturing equipment, material, environment, and technological parameters)
    can affect the manufacturing process and influence changes in product quality.
    In addition, they can also interact with each other. Therefore, it is particularly
    important to monitor different steps of the manufacturing process in real time.
    However, it is often difficult to systematically trace which factors affect manufacturing
    processes. Fortunately, big data provides effective technical support for monitoring
    manufacturing processes. Assisted by the predictive capacity of big data analytics,
    the most suitable design range for each manufacturing factor can be prescribed.
    Once a factor falls outside its acceptable range, the problem will be flagged,
    and alerts and recommendations will be sent to operators to make timely adjustments;
    this can ensure greater uniformity in the manufacturing process. Taking the production
    abnormities in shop-floor for example, the abnormities (e.g., tardiness of order)
    are often caused by anomalous events, such as equipment failure, lack of material,
    and operation deviation, etc. Before the occurrence of production abnormities,
    the anomalous events often reveal certain patterns that can be captured by a variety
    of data (e.g., material consumption data, energy consumption data, rotation rate,
    vibration, torque, etc.) in time series. Since such data is mostly time-dependent,
    it cannot be effectively processed by means of static models [53]. Furthermore,
    the big data cannot be processed by traditional data analysis methods, which are
    computationally intractable [53]. By synthetizing the factors of time and causality
    [54], an early-warning model of production abnormities in shop-floor can be established
    based on relevant big data algorithms, for instance, decision tree (e.g., ID3
    and C4.5) and neural network [55,56]. By mining the feature patterns and the trend
    of abnormal events in time series, it is possible to predict, in advance, whether
    and when production abnormities will occur. With higher flexibility, accuracy
    and less computing time, big data analytics can deal with multi-source data and
    massive data. Taking balanced use into consideration, manufacturing processes
    can be dynamically adjusted based on big data analytics. 4.2.5. Product quality
    control Various data-driven quality control techniques are being developed for
    smart manufacturing [57]. A variety of sensors, RFIDs and machine vision applications
    can be employed to collect product quality data, such as geometric parameters
    (e.g., thickness, length and surface roughness), location parameters (e.g., coordinate),
    tolerance parameters (e.g., concentricity), machining parameter (e.g., pressure,
    speed, temperature and machining time), etc. [24]. Big data analytics can serve
    the all-around quality monitoring, early warning of quality defects, and rapid
    diagnosis of root causes [58]. Based on historical data and process condition
    data gathered from machines and their operating environment, the binary classification
    of quality conditions can be used to predict whether and how certain conditions
    are related to quality defects [57]. Bayesian inference method can be used to
    analyze the data of process parameters and defective products to identify the
    most influential parameters and their appropriate range [59]. In addition, the
    root cause analysis together with the weighted association rule mining can be
    used to identify the root causes of product failures [60]. Thus, product quality
    defects can be detected, diagnosed, and addressed in a timely manner. In particular,
    less explicit causes of production issues, such as couplings between different
    equipment and inefficient procedures, can be illuminated by means of data integration
    and data mining. As a result, not only can low quality or failed products be automatically
    identified and removed, but factors that result in quality defects can also be
    eliminated or controlled. In addition, in conjunction with machine learning, big
    data analytics will eventually equip manufacturing enterprises with a particular
    kind of case-based reasoning capacity. Lessons learned from one quality control
    case can be transferred to another to prevent the recurrence of similar problems
    in the future. As a result, quality management can be embedded into every step
    of the manufacturing process, from raw materials to finished product. 4.2.6. Smart
    equipment maintenance Data analytics can accurately predict and diagnose equipment
    faults and component lifetime [61,62]; such information can be used to enable
    informed maintenance decisions. In combination with the equipment status data
    from smart sensors - as well as domain knowledge, previous experience, and historical
    records concerning equipment maintenance - big data analytics can predict the
    tendency for equipment capacity to deteriorate, the lifespan of components, and
    the cause and extent of certain faults [46]. In addition, seasonal, periodic,
    combinational, and other patterns of equipment faults can also be discovered through
    big data analytics. With this information, precautionary actions can be performed
    to prevent faults. Because of the predictive capacity of big data analytics, the
    equipment maintenance paradigm is transformed from passive to proactive maintenance,
    thus prolonging equipment life and minimizing maintenance costs [63]. Energy consumption
    [64,65] is also an important reference for equipment faults or abnormalities.
    By establishing a multi-dimensional energy consumption analysis model, big data
    related to energy consumption can help to uncover energy fluctuations and abnormalities
    or peaks in real time. To ensure normal production, the corresponding production
    processes, equipment, and energy supplies can be dynamically adjusted to achieve
    optimization in real time. 5. Case study In this section, a case study is presented
    to illustrate some practical aspects of the proposed framework. This case describes
    a silicon wafer production line (illustrated in Fig. 6). Silicon wafers are one
    of the most important components of crystalline silicon photovoltaic cells, which
    play a critical role in improving solar energy products. As shown in Fig. 6.,
    from the input of silicon ingots to the output of silicon wafers, the manufacturing
    process involves a series of production activities, including loading material,
    cutting, chamfering and polishing, viscos, slicing, degumming and cleaning, sorting,
    and packaging. Accordingly, the production line consists of multiple pieces of
    equipment associated with these processes. Download : Download high-res image
    (1MB) Download : Download full-size image Fig. 6. Data-driven smart silicon wafer
    production. As shown in Fig. 6, a variety of different types of multi-source and
    heterogeneous data generated in the production process are continuously accumulated.
    Data from the production process is integrated with information from orders and
    production plans. With the support of big data analytics, intelligent algorithms
    and predictive models analyze this data in order to optimize the manufacturing
    process. As a result, big data analytics enables intelligent material assignment,
    as well as tracking, predictive maintenance, and energy efficiency management.
    For material distribution and tracking, RFID tags are embedded into materials,
    and external readers are deployed to collect material data. The material data
    is represented as 9-tuples, i.e., Material = {ID, time, location, batch, type,
    quantity, sender, receiver, item code}. Material data is collected every time
    when the material goes through each RFID reader. From the input of silicon ingots
    to the output of silicon wafers, a huge volume of data is generated. Material
    identification is achieved through the data fusion technology in accordance with
    the set single recognition confidence. If the actual result is lower than the
    set confidence, an alarm is sent to the operator through mobile terminals (e.g.
    smartphone and tablet computer) for manual processing. Furthermore, through analysis
    of the material data, the operator can monitor in real time where and how the
    material is being processed at any particular time point. Lastly, a dynamic material
    distribution scheme is developed to constantly capture the location, batch, type
    and quantity of to-be-delivered material. In addition, delivery instructions and
    routes are visualized for operators through mobile terminals. The whole material
    dataset, including when, where, and which production process the material was
    going through, can be retrieved and reviewed at any time. Second, for the purpose
    of fault diagnosis and prediction, sensors are embedded in production equipment
    to detect a variety of data, including variables such as location, weight, temperature,
    humidity, vibration, and flow rate. Real-time data is used to determine which
    equipment requires service, repair, and even replacement. In this case study,
    for example, vibration data is used to diagnose running state of the multi-wire
    slicing machine by means of multiple vibration sensors. The vibration data can
    be leveraged to characterize the operational patterns of the multi-wire slicing
    machine. Firstly, the noisy and redundant data is removed through a denoising
    method based on wavelet transform module maxima. Next, the feature extraction
    method based on attribute reduction is used to extract feature parameters from
    the vibration data. Finally, based on the BP neural network, a smart failure diagnosis
    is performed. Specifically, under normal circumstances, the vibration signal should
    demonstrate a relatively stable pattern. When the equipment is worn or unexpected
    faults occur, the vibration signal would deviate from the normal pattern, which
    will automatically trigger a warning to be sent to the operator through mobile
    terminals. Through analysis of the vibration signal, equipment anomalies can be
    predicted and diagnosed. Finally, with respect to energy efficiency management,
    energy consumed in the manufacturing process is measured by smart meters installed
    in each piece of production equipment. The data goes through a multi-dimensional
    analysis. Firstly, through the hierarchical cluster analysis, the energy consumption
    patterns for a fixed period of time are discovered in order to improve energy
    efficiency. One advantage of the hierarchical cluster analysis method is that
    it no longer requires the time-consuming modeling and computing. By analyzing
    the daily, weekly, monthly and yearly energy consumption, the change law of energy
    consumption over time can be formulated. The results of hierarchical cluster analysis
    can be visualized, as shown in Fig. 7(a). The predictive analytics of energy consumption
    is performed based on the autoregressive integrated moving average (ARIMA) algorithm.
    As shown in Fig. 7(b), the red curves represent the monthly, weekly and daily
    records of energy consumption, through which, manufacturers can clearly see the
    trends and characteristics of energy consumption in both short term and long term,
    and hence make energy plans accordingly. Moreover, by comparing real-time data
    with historical data, the overall patterns and/or trends of energy consumption
    changes can be evaluated; this information is useful for determining whether and
    when to conduct a comprehensive overhaul. In addition, unusual fluctuations in
    energy consumption can serve as additional indicators of abnormalities in production
    processes. Download : Download high-res image (535KB) Download : Download full-size
    image Fig. 7. The software interfaces of energy consumption analysis. 6. Conclusion
    and future work The volumes of dynamically changing data generated throughout
    the lifecycle of products constitutes is growing. The data collected can be used
    to increase efficiency of manufacturing industry. This paper has provided contributions
    to smart manufacturing in three perspectives. (1) historical perspective: the
    evolution of manufacturing data was reflected in accordance with four manufacturing
    eras: the handicraft age, the machine age, the information age, and the big data
    age; (2) development perspective: the lifecycle of big manufacturing data was
    illustrated as a series of phases that includes data generation, collection, transmission,
    storage and integration, processing and analysis, visualization and application;
    (3) envisioning the future of data in manufacturing perspective: the role of data
    analytics in manufacturing was discussed, in particular with respect to promising
    applications in smart manufacturing. There are multiple limitations that should
    be considered. Firstly, the current data collection technologies are not fully
    ready for smart data perception, especially when dealing with heterogeneous devices
    that are equipped with different communication interfaces and protocols [29].
    Secondly, although the cloud-based data storage and analytics is proven to be
    a feasible technological solution, there remain some unresolved issues (e.g.,
    network unavailability, overfull bandwidth, and unacceptable latency time, etc.,)
    that limit its applicability for the low-latency and real-time applications [66].
    Thirdly, although it is commonly agreed that the integration between the physical
    and cyber worlds is a key feature of smart manufacturing, the vast majority of
    previous researches mainly focused on data collected from the physical world instead
    of data from virtual models [37]. That being said, this paper serves as a preliminary
    exploration of data-driven smart manufacturing and its potential applications.
    With respect to future work, there are some promising directions that can be pursued
    by interested researchers: (1) The key technologies for data perception and collection
    from heterogeneous equipment, such as IoT gateways or industrial Internet hub)
    can be incorporated into the data-driven smart manufacturing framework. The devices
    that are compatible with the heterogeneous interfaces and communication protocols
    will be more conducive to data collection and data transmission. (2) The new technologies
    for data storage and processing, such as fog computing and edge computing, can
    be incorporated into the proposed framework. Fog computing and edge computing
    can extend the manufacturer’s data computing, storage, and networking capabilities
    from the cloud to the edge, which will significantly reduce bandwidth requirement,
    latency time, and service downtime [67]. (3) The digital twin technologies can
    be incorporated into the proposed framework. Digital twin enables manufacturers
    to manage the real-time, two-way, and coevolving mapping between a physical object
    and its digital representation, which paves the way for the deep cyber-physical
    integration. In combination with digital twin, the data-driven smart manufacturing
    will be made more responsive, adaptable, and predictive. Acknowledgments This
    work is financially supported in part by the Beijing Nova Program in China under
    Grant Z161100004916063, in part by National Natural Science Foundation of China
    (NSFC) under Grant 51522501, and in part by the National Key Research and Development
    Program of China under Grant 2016YFB1101700. References [1] F. Tao, Q. Qi New
    IT driven service-oriented smart manufacturing: framework and characteristics
    IEEE Trans Syst Man Cybern Syst (2017), 10.1109/TSMC.2017.2723764 Google Scholar
    [2] P. O’Donovan, K. Leahy, K. Bruton, D.T.J. O’Sullivan An industrial big data
    pipeline for data-driven analytics maintenance applications in large-scale smart
    manufacturing facilities J Big Data, 2 (25) (2015), pp. 1-26, 10.1186/s40537-015-0034-z
    View in ScopusGoogle Scholar [3] S. Yin, O. Kaynak Big data for modern industry:
    challenges and trends [point of view] Proc IEEE, 103 (2) (2015), pp. 143-146 View
    in ScopusGoogle Scholar [4] G. Shao, S.J. Shin, S. Jain Data analytics using simulation
    for smart manufacturing Proceedings of the 2014 Winter Simulation Conference (2014),
    pp. 2192-2203 View in ScopusGoogle Scholar [5] A. Kusiak Smart manufacturing must
    embrace big data Nature, 544 (7648) (2017), pp. 23-25 CrossRefView in ScopusGoogle
    Scholar [6] D. Mourtzis, E. Vlachou, N. Milas Industrial big data as a result
    of IoT adoption in manufacturing Procedia CIRP, 55 (2016), pp. 290-295 View PDFView
    articleView in ScopusGoogle Scholar [7] F. Tao, Y. Zuo, L.D. Xu, L. Zhang IoT-based
    intelligent perception and access of manufacturing resource toward cloud manufacturing
    IEEE Trans Ind Inf, 10 (2) (2014), pp. 1547-1557 View in ScopusGoogle Scholar
    [8] I.A.T. Hashem, I. Yaqoob, N.B. Anuar, S. Mokhtar, A. Gani, S.U. Khan The rise
    of big data on cloud computing: review and open research issues Inf Syst, 47 (2015),
    pp. 98-115 View PDFView articleView in ScopusGoogle Scholar [9] F. Tao, Y. Cheng,
    L.D. Xu, L. Zhang, B.H. Li CCIoT-CMfg: cloud computing and internet of things-based
    cloud manufacturing service system IEEE Trans Ind Inf, 10 (2) (2014), pp. 1435-1442
    View in ScopusGoogle Scholar [10] M.D. Lee, M.A. Butavicius, R.E. Reilly Visualizations
    of binary data: a comparative evaluation Int J Hum Comput Stud, 59 (5) (2003),
    pp. 569-602 View PDFView articleView in ScopusGoogle Scholar [11] T. Wuest, D.
    Weimer, C. Irgens, K.D. Thoben Machine learning in manufacturing: advantages,
    challenges, and applications Prod Manuf Res, 4 (1) (2016), pp. 23-45 CrossRefView
    in ScopusGoogle Scholar [12] M. Obitko, V. Jirkovský, J. Bezdíček Big data challenges
    in industrial automation Proceedings of International Conference on Industrial
    Applications of Holonic and Multi-Agent Systems (2013), pp. 305-316 CrossRefView
    in ScopusGoogle Scholar [13] A. Galletti, D.C. Papadimitriou How big data analytics
    are perceived as a driver for competitive advantage: A qualitative study on food
    retailers (2013), pp. 1-58 Master Thesis Google Scholar [14] R. Dubey, A. Gunasekaran,
    S.J. Childe, S.F. Wamba, T. Papadopoulos The impact of big data on world-class
    sustainable manufacturing Int J Adv Manuf Technol, 84 (1–4) (2016), pp. 631-645
    CrossRefView in ScopusGoogle Scholar [15] Y. Zhang, S. Ren, Y. Liu, S. Si A big
    data analytics architecture for cleaner manufacturing and maintenance processes
    of complex products J Clean Prod, 142 (2017), pp. 626-641 View PDFView articleView
    in ScopusGoogle Scholar [16] A. Bahga, V.K. Madisetti Analyzing massive machine
    maintenance data in a computing cloud IEEE Trans Parallel Distrib Syst, 23 (10)
    (2012), pp. 1831-1843 View in ScopusGoogle Scholar [17] H. Lee Framework and development
    of fault detection classification using IoT device and cloud environment J Manuf
    Syst, 43 (2017), pp. 257-270 View PDFView articleView in ScopusGoogle Scholar
    [18] S. Munirathinam, B. Ramadoss Big data predictive analytics for proactive
    semiconductor equipment maintenance Proceedings of 2014 IEEE International Conference
    on Big Data (2014), pp. 893-902 View in ScopusGoogle Scholar [19] S.L. Chan, Y.
    Lu, Y. Wang Data-driven cost estimation for additive manufacturing in cyber manufacturing
    J Manuf Syst, 46 (2018), pp. 115-126 View PDFView articleView in ScopusGoogle
    Scholar [20] B. Schleich, N. Anwer, L. Mathieu, S. Wartzack Shaping the digital
    twin for design and production engineering CIRP Ann Manuf Technol, 66 (2017) (2017),
    pp. 141-144 View PDFView articleView in ScopusGoogle Scholar [21] S.J. Hu Evolving
    paradigms of manufacturing: from mass production to mass customization and personalization
    Procedia CIRP, 7 (2013), pp. 3-8 View PDFView articleView in ScopusGoogle Scholar
    [22] A. Balakrishnan, S.R. Kumara, S. Sundaresan Manufacturing in the digital
    age: exploiting information technologies for product realization Inf Syst Front,
    1 (1) (1999), pp. 25-50 View in ScopusGoogle Scholar [23] J. Bughin, M. Chui,
    J. Manyika Clouds, big data, and smart assets: ten tech-enabled business trends
    to watch McKinsey Q, 56 (1) (2010), pp. 75-86 View in ScopusGoogle Scholar [24]
    J. Li, F. Tao, Y. Cheng, L. Zhao Big data in product lifecycle management Int
    J Adv Manuf Technol, 81 (1–4) (2015), pp. 667-684 CrossRefView in ScopusGoogle
    Scholar [25] M. Chen, S. Mao, Y. Liu Big data: a survey Mobile Networks Appl,
    19 (2) (2014), pp. 171-209 CrossRefView in ScopusGoogle Scholar [26] J. Lee, E.
    Lapira, B. Bagheri, H.A. Kao Recent advances and trends in predictive manufacturing
    systems in big data environment Manuf Lett, 1 (1) (2013), pp. 38-41 View PDFView
    articleGoogle Scholar [27] A. Siddiqa, I.A.T. Hashem, I. Yaqoob, M. Marjani, S.
    Shamshirband, A. Gani, et al. A survey of big data management: taxonomy and state-of-the-art
    J Network Comput Appl, 71 (2016), pp. 151-166 View PDFView articleView in ScopusGoogle
    Scholar [28] Y. Zhang, G. Zhang, J. Wang, S. Sun, S. Si, T. Yang Real-time information
    capturing and integration framework of the internet of manufacturing things Int
    J Comput Integr Manuf, 28 (8) (2015), pp. 811-822 CrossRefView in ScopusGoogle
    Scholar [29] F. Tao, J. Cheng, Q. Qi IIHub: an industrial internet-of-Things hub
    towards smart manufacturing based on cyber-Physical system IEEE Trans Ind Inf
    (2017), 10.1109/TII.2017.2759178 Google Scholar [30] A. Guerriero, F. Ragni, C.
    Martines A dynamic URL assignment method for parallel web crawler Proceedings
    of 2010 IEEE International Conference on Computational Intelligence for Measurement
    Systems and Applications (2010), pp. 119-123 CrossRefView in ScopusGoogle Scholar
    [31] A. Gandomi, M. Haider Beyond the hype: big data concepts, methods, and analytics
    Int J Inf Manage, 35 (2) (2015), pp. 137-144 View PDFView articleView in ScopusGoogle
    Scholar [32] B. Nicolae, G. Antoniu, L. Bougé, D. Moise, A. Carpen-Amarie BlobSeer:
    next-generation data management for large scale infrastructures J Parallel Distrib
    Comput, 71 (2) (2011), pp. 169-184 View PDFView articleView in ScopusGoogle Scholar
    [33] D. Agrawal, A. El Abbadi, S. Antony, S. Das Data management challenges in
    cloud computing infrastructures Proceedings of 6th international workshop on databases
    in networked information systems (2010), pp. 1-10 CrossRefView in ScopusGoogle
    Scholar [34] J. Huang, Y.F. Li, M. Xie An empirical analysis of data preprocessing
    for machine learning-based software cost estimation Inf Software Technol, 67 (2015),
    pp. 108-127 View PDFView articleView in ScopusGoogle Scholar [35] E. Begoli, J.
    Horey Design principles for effective knowledge discovery from big data Proceedings
    of 2012 Software Architecture and European Conference on Software Architecture
    (2012), pp. 215-218 CrossRefView in ScopusGoogle Scholar [36] S. Mittal, M.A.
    Khan, D. Romero, T. Wuest Smart manufacturing: characteristics, technologies and
    enabling factors Proceedings of the Institution of Mechanical Engineers Part B:
    J Eng Manuf (2017), 10.1177/0954405417736547 Google Scholar [37] F. Tao, J. Cheng,
    Q. Qi, M. Zhang, H. Zhang, F. Sui Digital twin-driven product design, manufacturing
    and service with big data Int J Adv Manuf Technol (2017), 10.1007/s00170-017-0233-1
    Google Scholar [38] Y. Liu, J. Jin, P. Ji, A. Harding, R.Y. Fung Identifying helpful
    online reviews: a product designer’s perspective Comput Aided Des, 45 (2) (2013),
    pp. 180-194 View PDFView articleView in ScopusGoogle Scholar [39] A. Bennane,
    S. Yacout LAD-CBM; new data processing tool for diagnosis and prognosis in condition-based
    maintenance J Intell Manuf, 23 (2) (2012), pp. 265-275 CrossRefView in ScopusGoogle
    Scholar [40] A. Kusiak, A. Verma Analyzing bearing faults in wind turbines: a
    data-mining approach Renew Energ, 48 (2012), pp. 110-116 View PDFView articleView
    in ScopusGoogle Scholar [41] A. Kusiak, F.A. Salustri Computational intelligence
    in product design engineering: review and trends IEEE Trans Syst Man Cybern Part
    C (Appli Rev), 37 (5) (2007), pp. 766-778 View in ScopusGoogle Scholar [42] J.
    Qi, Z. Zhang, S. Jeon, Y. Zhou Mining customer requirements from online reviews:
    a product improvement perspective Inf Manage, 53 (8) (2016), pp. 951-963 View
    PDFView articleView in ScopusGoogle Scholar [43] Kusiak A. Innovation A data-driven
    approach Int J Prod Econ, 122 (1) (2009), pp. 440-448 Google Scholar [44] C. Da
    Cunha, B. Agard, A. Kusiak Selection of modules for mass customisation Int J Prod
    Res, 48 (5) (2010), pp. 1439-1454 CrossRefView in ScopusGoogle Scholar [45] D.
    Wu, X. Liu, S. Hebert, W. Gentzsch, J. Terpenny Democratizing digital design and
    manufacturing using high performance cloud computing: performance evaluation and
    benchmarking J Manuf Syst, 43 (2017), pp. 316-326 View PDFView articleView in
    ScopusGoogle Scholar [46] W. Ji, L. Wang Big data analytics based fault prediction
    for shop floor scheduling J Manuf Syst, 43 (2017), pp. 187-194 View PDFView articleView
    in ScopusGoogle Scholar [47] Y. Cheng, F. Tao, L. Zhang, D. Zhao Dynamic supply-demand
    matching for manufacturing resource services in service-oriented manufacturing
    systems: a hypernetwork-based solution framework Proceedings of ASME International
    Manufacturing Science and Engineering Conference (MSEC2015), 2015 (2015), pp.
    8-12 CrossRefGoogle Scholar [48] Z. Song, A. Kusiak Multiobjective optimization
    of temporal processes IEEE Trans Syst Man Cybern Part B (Cybern), 40 (3) (2010),
    pp. 845-856 View in ScopusGoogle Scholar [49] F. Tao, D. Zhao, Y. Hu, Z. Zhou
    Resource service composition and its optimal-selection based on particle swarm
    optimization in manufacturing grid system IEEE Trans Ind Inf, 4 (4) (2008), pp.
    315-327 2008 View in ScopusGoogle Scholar [50] R.Y. Zhong, S. Lan, C. Xu, Q. Dai,
    G.Q. Huang Visualization of RFID-enabled shopfloor logistics big data in cloud
    manufacturing Int J Adv Manuf Technol, 84 (1–4) (2016), pp. 5-16 CrossRefView
    in ScopusGoogle Scholar [51] R.Y. Zhong, G.Q. Huang, S. Lan, Q.Y. Dai, X. Chen,
    T. Zhang A big data approach for logistics trajectory discovery from RFID-enabled
    production data Int J Prod Econ, 165 (2015), pp. 260-272 View PDFView articleView
    in ScopusGoogle Scholar [52] S. Lu, C. Xu, R.Y. Zhong, L. Wang A RFID-enabled
    positioning system in automated guided vehicle for smart factories J Manuf Syst,
    44 (2017), pp. 179-190 View PDFView articleView in ScopusGoogle Scholar [53] S.J.
    Qin Survey on data-driven industrial process monitoring and diagnosis Annu Rev
    Control, 36 (2) (2012), pp. 220-234 View PDFView articleView in ScopusGoogle Scholar
    [54] S.J. Qin Process data analytics in the era of big data AIChE J, 60 (9) (2014),
    pp. 3092-3100 CrossRefView in ScopusGoogle Scholar [55] J. Abonyi, J.A. Roubos,
    F. Szeifert Data-driven generation of compact: accurate, and linguistically sound
    fuzzy classifiers based on a decision-tree initialization Int J Approximate Reasoning,
    32 (1) (2003), pp. 1-21 View PDFView articleCrossRefView in ScopusGoogle Scholar
    [56] G.E. Hinton, R.R. Salakhutdinov Reducing the dimensionality of data with
    neural networks Science, 313 (5786) (2006), pp. 504-507 CrossRefGoogle Scholar
    [57] A. Kim, K. Oh, J.Y. Jung, B. Kim Imbalanced classification of manufacturing
    quality conditions using cost-sensitive decision tree ensembles Int J Comput Integr
    Manuf (2017), 10.1080/0951192X.2017.1407447 Google Scholar [58] G. Köksal, İ.
    Batmaz, M.C. Testik A review of data mining applications for quality improvement
    in manufacturing industry Expert Syst Appl, 38 (10) (2011), pp. 13448-13467 View
    PDFView articleView in ScopusGoogle Scholar [59] A. Sata, B. Ravi Bayesian inference-based
    investment-casting defect analysis system for industrial application Int J Adv
    Manuf Technol, 90 (9–12) (2017), pp. 3301-3315 CrossRefView in ScopusGoogle Scholar
    [60] Y. He, C. Zhu, Z. He, C. Gu, J. Cui Big data oriented root cause identification
    approach based on Axiomatic domain mapping and weighted association rule mining
    for product infant failure Comput Ind Eng, 109 (2017), pp. 253-265 View PDFView
    articleView in ScopusGoogle Scholar [61] A. Verma, Z. Zhang, A. Kusiak Modeling
    and prediction of gearbox faults with data-mining algorithms J Solar Energy Eng,
    135 (3) (2013) 031007-1-11 Google Scholar [62] X.S. Si, W. Wang, C.H. Hu, D.H.
    Zhou Remaining useful life estimation–A review on the statistical data driven
    approaches Eur J Oper Res, 213 (1) (2011), pp. 1-14 View PDFView articleView in
    ScopusGoogle Scholar [63] Z. Zhang, X. He, A. Kusiak Data-driven minimization
    of pump operating and maintenance cost Eng Appl Artif Intell, 40 (2015), pp. 37-46
    View PDFView articleView in ScopusGoogle Scholar [64] D. Mourtzis, E. Vlachou,
    N. Milas, G. Dimitrakopoulos Energy consumption estimation for machining processes
    based on real-time shop floor monitoring via wireless sensor networks Procedia
    CIRP, 57 (2016), pp. 637-642 View PDFView articleView in ScopusGoogle Scholar
    [65] Y. Zuo, F. Tao, A.Y.C. Nee An Internet of things and cloud-based approach
    for energy consumption evaluation and analysis for a product Int J Comput Integr
    Manuf (2017), 10.1080/0951192X.2017.1285429 Google Scholar [66] J. Pizoń, L. Jerzy
    Perspectives for fog computing in manufacturing Appl Comput Sci, 12 (3) (2016),
    pp. 37-46 Google Scholar [67] D. Wu, S. Liu, L. Zhang, J. Terpenny, R.X. Gao,
    T. Kurfess, et al. A fog computing-based framework for process monitoring and
    prognosis in cyber-manufacturing J Manuf Syst, 43 (2017), pp. 25-34 View PDFView
    articleGoogle Scholar Cited by (1082) Monitoring manufacturing systems using AI:
    A method based on a digital factory twin to train CNNs on synthetic data 2024,
    CIRP Journal of Manufacturing Science and Technology Show abstract Predictive
    maintenance in Industry 4.0: A systematic multi-sector mapping 2024, CIRP Journal
    of Manufacturing Science and Technology Show abstract Data-driven system for intelligent
    monitoring and optimization of froth flotation circuits using Artificial Neural
    Networks and Genetic Algorithms 2024, Journal of Process Control Show abstract
    Can digital economy development contribute to urban carbon emission reduction?
    - Empirical evidence from China 2024, Journal of Environmental Management Show
    abstract A dynamic feature selection-based data-driven quality prediction method
    for soft sensing in the diesel engine assembly system 2024, Advanced Engineering
    Informatics Show abstract CONWIP control in the digitized world: The case of the
    cyber-physical jobshop 2024, International Journal of Production Economics Show
    abstract View all citing articles on Scopus View Abstract © 2018 The Society of
    Manufacturing Engineers. Published by Elsevier Ltd. All rights reserved. Part
    of special issue Special Issue on Smart Manufacturing Edited by Dazhong Wu, Brian
    A. Weiss, Thomas Kurfess, Lihui Wang, Jim Davis Download full issue Other articles
    from this issue Cybersecurity for digital manufacturing July 2018 Dazhong Wu,
    …, Janis Terpenny View PDF A systematic development method for cyber-physical
    machine tools July 2018 Chao Liu, …, Xun Xu View PDF Part data integration in
    the Shop Floor Digital Twin: Mobile and cloud technologies to enable a manufacturing
    execution system July 2018 Pedro Daniel Urbina Coronado, …, Thomas Kurfess View
    PDF View more articles Recommended articles Article Metrics Citations Citation
    Indexes: 1007 Policy Citations: 1 Captures Readers: 1676 Mentions Blog Mentions:
    1 View details About ScienceDirect Remote access Shopping cart Advertise Contact
    and support Terms and conditions Privacy policy Cookies are used by this site.
    Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024
    Elsevier B.V., its licensors, and contributors. All rights are reserved, including
    those for text and data mining, AI training, and similar technologies. For all
    open access content, the Creative Commons licensing terms apply.'
  inline_citation: '>'
  journal: Journal of manufacturing systems
  limitations: '>'
  pdf_link: null
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: Data-driven smart manufacturing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.future.2019.10.043
  analysis: '>'
  authors:
  - Shreshth Tuli
  - Nipam Basumatary
  - Sukhpal Singh Gill
  - Mohsen Kahani
  - Rajesh Arya
  - Gurpreet Singh Wander
  - Rajkumar Buyya
  citation_count: 390
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Related work 3. Background
    technologies 4. System architecture 5. Healthfog design 6. Implementation 7. Performance
    evaluation 8. Conclusions and future work Declaration of Competing Interest Acknowledgments
    Software Availability References Vitae Show full outline Cited by (448) Figures
    (17) Show 11 more figures Tables (2) Table 1 Table 2 Future Generation Computer
    Systems Volume 104, March 2020, Pages 187-200 HealthFog: An ensemble deep learning
    based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated
    IoT and fog computing environments Author links open overlay panel Shreshth Tuli
    a b, Nipam Basumatary a c, Sukhpal Singh Gill d, Mohsen Kahani a e, Rajesh Chand
    Arya f, Gurpreet Singh Wander f, Rajkumar Buyya a Show more Share Cite https://doi.org/10.1016/j.future.2019.10.043
    Get rights and content Highlights • HealthFog is a real-life healthcare application
    platform for heart patients • HealthFog integrates ensemble deep learning with
    Edge computing. • HealthFog analyzes and identifies the Heart Diseases automatically.
    • HealthFog delivers diverse healthcare configurations for different user requirements.
    • HealthFog efficiently manages the data of heart patients. • HealthFog optimizes
    performance parameters and deployed using FogBus. Abstract Cloud computing provides
    resources over the Internet and allows a plethora of applications to be deployed
    to provide services for different industries. The major bottleneck being faced
    currently in these cloud frameworks is their limited scalability and hence inability
    to cater to the requirements of centralized Internet of Things (IoT) based compute
    environments. The main reason for this is that latency-sensitive applications
    like health monitoring and surveillance systems now require computation over large
    amounts of data (Big Data) transferred to centralized database and from database
    to cloud data centers which leads to drop in performance of such systems. The
    new paradigms of fog and edge computing provide innovative solutions by bringing
    resources closer to the user and provide low latency and energy efficient solutions
    for data processing compared to cloud domains. Still, the current fog models have
    many limitations and focus from a limited perspective on either accuracy of results
    or reduced response time but not both. We proposed a novel framework called HealthFog
    for integrating ensemble deep learning in Edge computing devices and deployed
    it for a real-life application of automatic Heart Disease analysis. HealthFog
    delivers healthcare as a fog service using IoT devices and efficiently manages
    the data of heart patients, which comes as user requests. Fog-enabled cloud framework,
    FogBus is used to deploy and test the performance of the proposed model in terms
    of power consumption, network bandwidth, latency, jitter, accuracy and execution
    time. HealthFog is configurable to various operation modes which provide the best
    Quality of Service or prediction accuracy, as required, in diverse fog computation
    scenarios and for different user requirements. Previous article in issue Next
    article in issue Keywords Fog computingInternet of thingsHealthcareDeep learningEnsemble
    learningHeart patient analysis 1. Introduction Fog and Cloud computing paradigms
    have emerged as a backbone of modern economy and utilize Internet to provide on-demand
    services to users [1]. Both of these domains have captured significant attention
    of industries and academia. But because of high time delay, cloud computing is
    not a good option for applications requiring real-time response. Technological
    developments like edge computing, fog computing, Internet of Things (IoT), and
    Big Data have gained importance due to their robustness and ability to provide
    diverse response characteristics based on target application [2]. These emerging
    technologies provide storage, computation, and communication to edge devices,
    which facilitate and enhance mobility, privacy, security, low latency, and network
    bandwidth so that fog computing can perfectly match latency-sensitive or real-time
    applications [2], [3], [4], [5], [6], [7], [8], [9], [10], [11]. Now, cloud computing
    frameworks also extend support to emerging application paradigms such as IoT,
    Fog computing, Edge, and Big Data through service and infrastructure [12], [13].
    Fog computing uses routers, compute nodes and gateways to provide services with
    minimum possible energy consumption, network latency and response time. Mutlag
    et al. [7] explored the challenges of Fog computing in healthcare applications
    and identified that latency and response time are the most important and difficult
    to optimize Quality of Service (QoS) parameters in real time fog environments.
    Healthcare is one of the prominent application areas that requires accurate and
    real-time results, and people have introduced Fog Computing in this field which
    leads to a positive progress. With Fog computing, we bring the resources closer
    to the users thus decreasing the latency and thereby increasing the safety measure.
    Getting quicker results implies fast actions for critical heart patients. But
    faster delivery of results is not enough as with such delicate data we cannot
    compromise with the accuracy of the result. One way to obtain high accuracies
    is by using state-of-the-art analysis softwares typically those that employ deep
    learning and their variants trained on a large dataset. In the recent years, deep
    learning [14] has seen an exponential growth in the fields ranging from computer
    vision [3] to speech recognition, but has more recently been proven useful in
    natural language processing, sequence prediction, and mixed modality data settings.
    Moreover, ensemble learning [15] is used to get the best of multiple classifiers.
    One of the ensemble methods is called bagging classifier where the estimator fits
    trains the base classifier on random subsets of data and then aggregates their
    individual predictions either by voting or by averaging to get the final prediction.
    Such estimators help in reducing the variance as compared to a single estimator
    by introducing randomization into the dataset distribution procedure. Another
    advancement of deep learning has been to predict and classify healthcare data
    with extremely high accuracies [14]. However, recent deep learning models for
    healthcare applications are highly sophisticated and require large number of computational
    resources both for training and prediction [16]. It also takes large amount of
    time to train these complex neural networks and analyze data using them. The higher
    the accuracy required, the more sophisticated the network and higher is the prediction
    time [17]. This has been a major problem for healthcare and similar IoT applications
    where it is critical to obtain results in real-time. As computation on the Edge
    has the great advantage of reducing response time, this gives a new direction
    of research of integrating complex ensemble deep learning models with Edge Computing
    such that we obtain high accuracy results in real-time. One of the fundamental
    aims of this work is to bridge this gap and provide a computing platform that
    not only provides low latency results by leveraging edge resources but also is
    able to use deep learning based frameworks to provide highly accurate results.
    There has been some work to bring computation to the Edge devices, closer to the
    patient to reduce result delivery time. Some of these works still depend on simulations
    [4] and have not provided a deploy-able framework. This work also aims to fill
    this void in healthcare industry. Usually, detecting heart problems is difficult
    [18], [19] and many times people do not even get to know that they are in critical
    condition till they get heart related problems like tachycardia or even stroke.
    Conventionally symptoms of heart problems are difficult to identify and requires
    an experienced doctor to observe the patient to ascertain that he/she has a heart
    problem. This is difficult to do practically due to shortage of doctors as most
    countries still do not trust computer systems to be able to detect heart problems
    with the required accuracy and explain-ability [20], [21]. Existing healthcare
    systems that are deployed on IoT driven Fog or cloud computing frameworks connect
    pre-configured devices for patient data processing such that the results are delivered
    to users within the deadline time. Many prior works have tried to use IoT to predict
    health problems related to heart but are unable to ascertain with the accuracies
    required by the stringent regulations of medical standardization agencies. In
    recent past, as deep learning has gained popularity more recent technologies can
    even surpass doctors in heart disease detection accuracy [22], [23]. This work
    aims to bring together deep learning and IoT in healthcare industry in hope that
    it motivates medical standardization agencies to adopt this model providing low
    latency and high accuracy to mitigate the problem of lack of doctors. There exist
    very few works that aim to bring together these two paradigms like [24], but none
    utilize the distributed nature of edge computing to improve accuracy by utilizing
    ensemble deep learning models. We present more comprehensive comparisons in Sections
    2 Related work, 7.9 Analysis with related work. Moreover, extension of deep learning
    models to allow ensembling of results is a non trivial extension as it requires
    careful balance of accuracy improvement and latency increase to provide the most
    desired service quality. Furthermore, building on previous works like [2], [9],
    [24], HealthFog provides a novel architecture for healthcare computation integrating/harnessing
    diverse backend frameworks like FogBus [6] and Aneka [25] making it a scalable
    model. Prior works have reported that there are two major types of healthcare
    data collection schemes for heart patients using different devices (IoT sensors
    and file input data). The first is Little data which is processed at fog nodes
    and the second is Big data processed at Cloud Data Centers (CDC) [1], [12]. The
    healthcare patient data is received by the network at high speeds (250 MB per
    minute or more) [1]. Existing frameworks are not versatile enough to capture and
    provide results for both types of data scenarios and thus there is a need to utilize
    edge and cloud resources in order to cater to applications with these types of
    data volumes. Data is stored and processed on edge nodes or cloud servers after
    collection and aggregation of data from smart devices of IoT networks. To provide
    efficient compute services to heart patients and other users requiring real-time
    results, an integrated Edge-Fog-Cloud based computation model is required to deliver
    healthcare and other latency sensitive results with low response time, minimum
    energy consumption and high accuracy. The lack of such models or frameworks that
    integrate the power of high accuracy of deep learning models simultaneously with
    low latency of edge computing nodes motivated this work. In this work, we propose
    a Fog based Smart Healthcare System for Automatic Diagnosis of Heart Diseases
    using deep learning and IoT called HealthFog. HealthFog provides healthcare as
    a lightweight fog service and efficiently manages the data of heart patients which
    is coming from different IoT devices. HealthFog provides this service by using
    the FogBus framework [6] and demonstrates application enablement and engineering
    simplicity for leveraging fog resources to achieve the same. The key contributions
    of this paper are: • Proposed a generic system architecture for development of
    ensemble deep learning on fog computing • Developed a lightweight automatic heart
    patient data diagnosis system using ensemble deep learning called HealthFog. •
    Deployed HealthFog using FogBus framework for integration of IoT-Edge-Cloud for
    real-time data analysis. • Demonstrated and analyzed the HealthFog deployment
    in terms of various performance metrics like accuracy, response time, network
    bandwidth and energy consumption. All analysis has been done for heart patient
    data for prediction if the patient has a heart problem or not. The rest of the
    paper is organized as follows. Section 2 presents related work of existing healthcare
    systems. Background of FogBus and Aneka are is provided in Section 3. Proposed
    model is presented in Section 4 and its design and implementation is described
    in Section 5. Section 7 describes the experimental setup and presents the results
    of performance evaluation. Section 8 presents conclusions with future work proposed.
    2. Related work Fog computing environment is an emerging paradigm for efficient
    processing of healthcare data, which is coming from different IoT devices. Fog
    computing is capable to handle the data of heart patients at edge devices or fog
    nodes with large computing capacity to reduce latency, response time or delay
    because edge devices are closer to the IoT devices than cloud data center. Table
    1. Comparison of existing models with HealthFog. Work Fog IoT Deep Ensemble Heart
    disease Performance parameters prediction Power Latency Execution Arbitration
    Network Jitter Testing Training computing learning learning system consumption
    Empty Cell time time bandwidth Empty Cell accuracy accuracy LCHM [26] FogCepCare
    [5] IoT e-health service [27] ECGH [28] AMS [29] GRAM [30] SFG [31] HEDL [24]
    FEMI [32] FIH [33] FogLearn [34] SADL [35] CoSHE [36] EOTC [37] SLA-HBDA [38]
    CFBA [39] HealthFog (this work) Gia et al. [26] proposed a Low Cost Health Monitoring
    (LCHM) model to gather the health information of different heart patients. Moreover,
    sensor nodes monitor and analyze the Electro Cardio Graphy (ECG) in a real-time
    manner for processing of heart patients data efficiently, but LCHM has more response
    time which reduces the performance. Further, sensor nodes gather ECG, respiration
    rate, and body temperature and transmits to a smart gateway using wireless communication
    mode to take automatic decision quickly to help patient. Orange Pi One based small-scale
    testbed is used to test the performance of LCHM model in terms of execution time,
    but LCHM consumes more energy during collection and transmission of data. He et
    al. [5] proposed an IoT based healthcare management model called FogCepCare to
    integrate cloud layer with sensor layer to find out the health status of heart
    patients and reduces the execution time of job processing at runtime. FogCepCare
    uses the partitioning and clustering approach and a communication and parallel
    processing policy to optimize the execution time. The performance of FogCepCare
    is compared with existing model using simulated cloud environment and optimizes
    the execution time but this work lacks the evaluation of performance in terms
    of important QoS parameters such as power consumption, latency, accuracy etc.
    Ali and Ghazal [27] proposed an IoT e-health service based an application using
    Software Defined Network (SDN), which collects data through smartphone in the
    form of voice control and finds the health status of patients. Further, an IoT
    e-health service finds the type of heart attack using mobile application based
    conceptual model but performance of the proposed application is not evaluated
    on cloud environments. Akrivopoulos et al. [28] proposed an ECG-based Healthcare
    (ECGH) system to diagnose cardiac abnormalities [40] using ECG but has low accuracy
    and high response time of detecting abnormal events because they are fetching
    data directly without using data analytics or other feature extraction techniques.
    Further, the data transmission to cloud server in case of large number of requests
    increases latency and consumes more energy consumption, which degrades the performance
    of the system. Manikandan et al. [29] proposed an Autonomous Monitoring System
    (AMS) model for Internet of Medical Things (IoMT) to provide healthcare facilities.
    In this research work, a reward-based mechanism designed which utilizes the Analytical
    Hierarchy Process (AHP) for fair distribution of energy among the nodes. The simulated
    cloud environment is used to test the performance of the AMS model in terms of
    energy consumption and AMS model performs better than FGCS method but the communication
    time among nodes leads to high latency of processing a patient request. Choi et
    al. [30] proposed a Graph-based Attention Model (GRAM) for healthcare representation
    learning that supplements electronic health records with hierarchical information
    inherent to medical ontologies. Further, the performance of GRAM is optimized
    in terms of training accuracy. GRAM uses predictive analysis to predict the chances
    of heart attack and compared the performance of GRAM with Recurrent Neural Network
    (RNN) using very small dataset and performs better than RNN in terms of training
    accuracy. The performance of GRAM can be degraded in case of large datasets. Nicholas
    et al. [31] proposed a Smart Fog Gateway (SFG) model for end-to-end analytics
    in wearable IoT devices and demonstrated the role of the SFG in orchestrating
    the process of data conditioning, intelligent filtering, smart analytics, and
    selective transfer to the cloud for long-term storage and temporal variability
    monitoring. SFG model optimizes the performance in terms of execution time and
    energy consumption, but it does not consider latency as a performance parameter.
    Iman et al. [24] proposed Hierarchical Edge-based deep learning (HEDL) based healthcare
    IoT system to investigate the feasibility of deploying the Convolutional Neural
    Network (CNN) based classification model as an example of deep learning methods.
    Further, a case study of ECG classifications is used to test the performance of
    proposed system in terms of accuracy and execution time. Liangzhi et al. [32]
    proposed Fog based Efficient Manufacture Inspection (FEMI) system using deep learning
    for smart industry to process a large amount of data in an efficient manner. Further,
    FEMI system adapts the CNN model to the fog computing environment, which significantly
    improves its computing efficiency and optimizes the performance only in terms
    of testing accuracy. Mahmud et al. [33] proposed a Fog-based IoT-Healthcare (FIH)
    solution structure and explore the integration of Cloud-Fog services in interoperable
    Healthcare solutions extended upon the traditional Cloud-based structure. Further,
    iFogSim simulator [39] is used to test the performance of FIH solution in terms
    of power consumption and latency only. The performance of FIH solution can be
    evaluated in terms of execution time and accuracy. Rabindra and Rojalina [34]
    proposed a fog-based machine learning model for smart system big data analytics
    called FogLearn for application of K-means clustering in Ganga River Basin Management
    and real-world feature data for detecting diabetes patients suffering from diabetes
    mellitus. Alvin et al. [35] proposed a Scalable and Accurate deep learning (SADL)
    model with electronic health records of patients based on the Fast Healthcare
    Interoperability Resources (FHIR) format. The deep learning methods in SADL model
    using FHIR representation are capable of accurately predicting multiple medical
    events from multiple centers without site-specific data harmonization. Further,
    proposed approach is validated using de-identified Electronic Health Record (EHR)
    data from two US academic medical centers with 216,221 adult patients hospitalized
    for at least 24 h and improves the accuracy of prediction. Table 1 compares the
    proposed model (HealthFog) with existing models. Pham et al. [36] proposed a Cloud-based
    Smart Home Environment (CoSHE) to deliver home healthcare to provide human’s contextual
    information and monitors the vital signs using robot assistant. Initially, CoSHE
    uses non-invasive wearable sensors to gather the audio, motion and physiological
    signals and delivers the contextual information in terms of the resident’s daily
    activity. Further, the CoSHE allows healthcare professionals to explore behavioral
    changes and daily activities of a patient to monitor the health status periodically.
    Moreover, the case study of robotic assistance is presented to test the performance
    of CoSHE by utilizing Google APIs. However, CoSHE is general healthcare application
    to collect and process patient data at small scale without data analytics and
    they have not evaluated on real cloud environment to test its performance in terms
    of QoS parameters. Alam et al. [37] proposed a general Edge-of-Things Computation
    (EoTC) framework for healthcare service provisioning to optimize the cost of data
    processing. Further, a portfolio optimization solution is presented for the selection
    of Virtual Machines (VMs) and designed Alternating Direction Method of Multipliers
    (ADMM) based distributed provisioning technique for efficient processing of healthcare
    data. Further, experimental results demonstrate that EoTC framework performs better
    than greedy approach in terms of cost, but this framework lacks in performance
    evaluation in terms of QoS parameters. Sahoo et al. [38] proposed a Service Level
    Agreement (SLA) based Healthcare Big Data Analytic (SLA-HBDA) architecture to
    perform the ranking of patient’s data, which improves its processing speed. Further,
    an efficient data distribution technique is developed to allocate batch and streaming
    data using Spark platform to predict the health status of the patient. SLA-HBDA
    architecture improves the performance in terms of accuracy as compared to Naive-Bayes
    (NB) algorithm but it does not consider latency and other important QoS parameters.
    Abdelmoneem et al. [39] proposed a Cloud-Fog Based Architecture (CFBA) for IoT
    based healthcare applications to monitor the health status of the patience. Further,
    a task scheduling and allocation mechanism is proposed for the processing of healthcare
    data by distributing the healthcare tasks in an efficient manner. The performance
    of CBFA is evaluated using iFogSim simulator [41] in terms of only latency. Research
    work [36], [37], [38], [39] developed general healthcare applications at small
    scale and none of the work focused on heart patient-based healthcare application
    to diagnose the health status of heart patients. Sanaz et al. [9] proposed an
    end-to-end security scheme for mobility enabled healthcare IoT, which uses Datagram
    Transport Layer Security (DTLS) handshake protocol to establish secure communication
    among various interconnected smart gateways without requiring any reconfiguration
    at the device layer. Further, the proposed scheme is implemented using simulation
    environment (Cooja) and demonstrate that the proposed scheme is effective in reducing
    communication overhead by 26% and latency by 16%. Building on this work, HealthFog
    aims to deploy healthcare applications on real systems and fog nodes providing
    a more promising solution. Amir et al. [2] proposed a system called Smart e-Health
    Gateway to exploit the strategic position of such gateways at the edge of the
    network to provide various services such as embedded data mining, real-time local
    data processing and local storage. Further, it distributes the burden of various
    sensors by creating a Geo-distributed intermediary layer of intelligence between
    Cloud and sensor nodes, which increases the reliability, energy efficient and
    scalability. Further, proposed system is validated using an mobile application
    of IoT-based Early Warning Score (EWS) health monitoring. Building on this work,
    HealthFog architecture provides additional features of being able to use distributed
    deep learning models in ensembling fashion to further increase the prediction
    accuracy and provide more precise results for critical heart patients. There is
    a need to solve the following challenges [5], [24], [26], [27], [28], [29], [30],
    [31], [32], [33], [34], [35], [36], [38], [39], [41], [42], [43], [44] to recognize
    the full capability of IoT based fog-computing for healthcare systems: (a) An
    efficient IoT based Healthcare application is needed which can process a large
    amount of heart patients data with minimum energy consumption and low response
    time, (b) a well-organized resource scheduling technique is needed for fog computing
    environments to execute user workloads with maximum resource utilization to fulfill
    the deadline of workloads and (c) ensemble deep learning based fog computing model
    to automatically diagnose the heart disease severity in patients in real-time.
    Download : Download high-res image (581KB) Download : Download full-size image
    Fig. 1. HealthFog Architecture. 3. Background technologies FogBus [6] is a framework
    for development and deployment of integrated Fog-Cloud environments with structured
    communication and platform independent execution of applications. FogBus connects
    various IoT sensors which can be healthcare sensors with gateway devices to send
    data and tasks to fog worker nodes. The resource management and task initiation
    is done on fog broker nodes. To ensure data integrity, privacy and security, FogBus
    uses blockchain, authentication and encryption techniques which increase the reliability
    and robustness of the fog environment. FogBus uses HTTP RESTful APIs for communication
    and seamlessly integrates fog setup with Cloud using Aneka software platform [25].
    Aneka [25] is a software platform and framework facilitating the development and
    deployment of distributed applications onto clouds. Aneka provides developers
    with APIs for exploiting virtual resources on the cloud. The core components of
    the Aneka framework are designed and implemented in a service-oriented fashion.
    Dynamic provisioning is the ability to dynamically acquire resources and integrate
    them into existing infrastructures and software systems. In the most common case,
    resources are Virtual Machines (VMs) acquired from an Infrastructure-as-a-Service
    (IaaS) cloud provider. Dynamic provisioning in Aneka happens as part of the Fabric
    Services by offering provisioning services for allocating virtual nodes from public
    cloud providers to complement local resources. This is mainly achieved as a result
    of the interaction between two services: the Scheduling Service and the Resource
    Provisioning Service. Aneka currently supports four different programming models
    [25]: Bag of tasks model, Distributed threads model, MapReduce model, and Parameter
    sweep model. In HealthFog, we used the Bag of tasks model for task distribution
    across cloud VMs. HealthFog uses FogBus to harness fog resources and Aneka to
    harness cloud resources. 4. System architecture The HealthFog model is an IoT
    based fog-enabled cloud computing model for healthcare, which can manage the data
    of heart patients effectively and diagnose the health status to identify heart
    disease severity. HealthFog integrates diverse hardware instruments through software
    components and allows structured and seamless end-to-end integration of Edge-Fog-Cloud
    for fast and accurate delivery of results. Fig. 1 presents the architecture of
    HealthFog which comprises of various hardware and software components that are
    described next. 4.1. Healthfog hardware components The HealthFog model comprises
    of following hardware components: 1. Body Area Sensor Network: Three different
    types of sensors constitute this component: medical sensors, activity sensors
    and environment sensors. Medical sensors include Electro Cardio Gram (ECG) sensor,
    Electro Encephalo Gram (EEG) sensor, Electro Myo Graphy (EMG) sensor, oxygen level
    sensor, temperature sensor, respiration rate sensor and glucose level sensor.
    This component senses the data from heart patient and transfers to connected gateway
    devices. 2. Gateway: There are three different types of Gateway devices (mobile
    phones, laptop and tablets), which are acting as a fog device to collect sensed
    data from different sensors and forward this data to Broker/Worker nodes for further
    processing. 3. FogBus Modules: The FogBus framework comprises of the following:
    (a) Broker node: This component receives the job requests and/or input data from
    Gateway devices. Request input module receives job requests from Gateway devices
    just before transferring the data. Security Management module provides secure
    communication between different components and protects the collected data from
    unauthorized access or malicious tampering of data to improve system credibility
    and data integrity. Arbitration module (part of Resource Manager in broker node)
    takes as input the load statistics of all worker nodes and decides which node
    or subset of nodes to send jobs to in real time. (b) Worker node: This is the
    component that performs tasks allocated by the Resource Manager of the Broker
    node. Worker nodes can comprise of embedded devices and Single Board Computers
    (SBC) like Raspberry Pis. In HealthFog, Worker nodes can contain sophisticated
    deep learning models to process and analyze the input data and generate results.
    Apart from this, the Worker node can include other components for data processing,
    data filtering and mining, Big Data analytics and storage. The Worker nodes directly
    get the input data from the Gateway devices, generate results and share with the
    same. In HealthFog model, the Broker node can also behave as a Worker node. (c)
    Cloud Data Center: When the fog infrastructure becomes overloaded, services are
    latency tolerant or the input data size is much larger than average size, then
    HealthFog harnesses resources of Cloud Data Centers (CDC). This makes it more
    robust, capable of performing heavy load tasks quickly and also makes data processing
    location independent. 4.2. Healthfog software components The HealthFog model comprises
    of the following software components: Download : Download high-res image (150KB)
    Download : Download full-size image Fig. 2. Resource Scheduling in HealthFog.
    • Data filtering and pre-processing: The first step after data input is to pre-process
    it. This includes data filtering using data analytics tools. The filtered data
    is reduced to a smaller dimension using Principal Component Analysis (PCA) using
    Set Partitioning In Hierarchical Trees (SPIHT) algorithm [45] and encrypted using
    Singular Value Decomposition (SVD) technique [46] with the goal of extracting
    key components of data feature vectors that affect the health status of patients.
    Based on the extracted data, it automatically makes the decision, which recommends
    medication and suitable check-up based on the continuous training data of healthcare
    providers and doctors and stores in database for re-training when required. •
    Resource Manager: This comprises of two modules: workload manager and arbitration
    module [6]. Workload manager maintains job request and task queues for data processing.
    It also handles bulk of data which needs to be processed. The Arbitration module
    schedules the provisioned fog or cloud resources for processing of tasks queued
    and maintained by the workload manager. Arbitration module resides in the Broker
    node and decides which Fog computing node should be forwarded the data to obtain
    the results, the Broker itself, Fog worker node or the Cloud Data Center [6].
    The main goal is to divide tasks to different devices to balance load and provide
    optimum performance. HealthFog allows users to set their own load balancing and
    arbitration schemes based on the application requirements. The current scheme
    is described as a flowchart in Fig. 2. • Deep learning Module: This module uses
    the dataset to train a Neural Network to classify data-points which are feature
    vectors obtained after pre-processing the data obtained from the Body Area Sensor
    Network. Based on the task allocated by the Resource Manager, it also predicts
    and generates results for the data obtained from the Gateway devices. • Ensembling
    Module: This module receives prediction results from different models and uses
    voting to decide the output class which is whether the patient has heart disease
    or not. This module resides in the FogBus node which is assigned the task and
    is responsible for distributing data and collecting results from other worker
    nodes. 4.3. Healthfog topology The HealthFog components described previously share
    large amount of data, information and control signals among themselves. To facilitate
    this stable network communication is necessary. In addition, the communication
    should be persistent and fault-tolerant. Taking all these into account, the components
    are structured in a topology shown in Fig. 1. The communication across all devices
    on the Edge is facilitated using FogBus [6] and that with Cloud VM is using Aneka
    [25]. The Network topology in HealthFog follows Master-Slave fashion where the
    Broker Node (Master) controls the Worker Nodes (Slaves). In HealthFog all the
    edge devices including the Gateway devices, Broker node and Worker nodes are present
    in the same Local Area Network (LAN). The Resource Manager software component
    resides in the Broker Node and thus the Gateway devices send job requests to it.
    The arbitration results obtained from the Resource Manager is received by the
    Gateway device which instructs it where to send the data. Three scenarios arise
    here: (1) Broker processing data as Worker Node, (2) Another Worker node to send
    data and (3) Cloud Data Center based processing. Based on the scenario, the Gateway
    device may send the data directly to Worker node or Broker node (with/without
    cloud forwarding). Broker may provide computation services for tasks only when
    it has sufficient resources and/or the worker nodes are overloaded. If the data
    is to be forwarded to Cloud, then it goes through the Broker node as the Gateway
    may not have access to the Virtual Private Network (VPN) in which the Cloud Virtual
    Machine is present. Apart from this, the Worker nodes periodically send heartbeat
    packets to the Broker to indicate that they are alive. These packets also include
    load information that is used by the Resource manager for load balancing. Download
    : Download high-res image (368KB) Download : Download full-size image Fig. 3.
    Communication sequence in HealthFog. 4.4. Sequence of communication In HealthFog,
    all hardware components interact based on predefined protocols described in Fig.
    3 for the three scenarios defined earlier: Broker Only, Worker Node or Cloud.
    In every scenario the Gateway first sends a Job request to the Broker node. Based
    on the scenario, the Broker node sends the Gateway either the Worker IP address
    (of the same LAN) or Master IP address (with/without cloud forwarding). In the
    Broker only case, the Broker node may or may not check loads of workers. If all
    workers have heavy loads or all are compromised and Cloud is disabled, then the
    Broker sends the Gateway devices its IP without cloud forwarding. If there exist
    workers not heavily loaded then the Broker sends the IP address of least loaded
    Worker node to the Gateway device. Increasing the number of Workers would increase
    the arbitration time as more load checks need to be done. In non-cloud case, the
    Gateway device sends job i.e. input data for analysis to Worker/Broker node which
    then run pre-processing, prediction model and send results back to Gateway device.
    In cloud forwarding case, as the Gateway device may not be on the VPN, so it sends
    the input data to Broker node which then forwards it to the CDC. This also ensures
    that the IoT sensors and gateway devices are protected from malicious entities
    and hackers as they may not be connected to Internet but only the LAN with other
    Fog nodes. Due to larger resource availability at Cloud, the Execution time is
    expected to be lower but latency higher due to communication overheads and queuing
    delay at both Broker and CDC. When ensemble is enabled then the data received
    by the Broker/worker node is forwarded to all other edge nodes and majority class
    is chosen by the worker node to which the data was sent using bagging. 5. Healthfog
    design The fog computing model described in Section 4 takes heart patient data
    as input from the sensors and sends back results which comprise of whether the
    patient has heart disease or not, with the confidence of the claim. This is implemented
    with components which include data pre-processing modules, ensemble deep learning
    modules and gateway interface described next. 5.1. Heart patient data pre-processing
    The data obtained from common pule-oximeters or ECG devices is in plain graphical
    format and needs to be pre-processes to find values of many features of the input
    to the deep learning model [47], [48]. This requires application specific domain
    knowledge to be fed into the system. Normalizing the age data as it was slightly
    skewed as shown in Fig. 4. Similarly, the Rest Blood Pressure (BPS) data is also
    skewed and patients having a heat disease showed a higher blood pressure compared
    to patients not having a heart disease. Patient cholesterol levels also show some
    target specific behavior, the healthy patients’ distribution is leptokurtic. Even
    with maximum heart rate, healthy people have quite higher maximum heart rate (around
    160) compared to those with heart disease (around 150). Other features like chest
    pain and fasting blood sugar had to be converted from continuous values to categorical
    values. Also, the slope of the peak exercise ST segment and the heart status as
    retrieved from Thallium test. Download : Download high-res image (144KB) Download
    : Download full-size image Fig. 4. Age distribution. 5.2. Ensemble deep learning
    application We have used an ensemble of deep neural network as a model for the
    predictive analysis, and for our application the model is used for binary classification
    problem. The model is first trained on the heart patient data in the Cleveland
    Dataset and corresponding known output class and then the trained model is used
    for predicting results of real time data input as shown in Fig. 5. Download :
    Download high-res image (335KB) Download : Download full-size image Fig. 5. Training
    and Testing of the application. We divide the data into training, validation and
    testing set in the ratio of 70:10:20. The training set is used for training the
    model, the validation set is used for tuning the model and the test set is used
    for testing how the model performs on new data. The trained model can be stored
    in all the nodes which are capable of processing by first storing in a common
    database. Other approach can be to train models separately by distributing the
    training dataset points across different models. In distributed training, data
    distribution uses techniques like boosting which randomly samples data from the
    dataset with replacement and sends to different edge nodes for training individual
    models [15]. At diagnosis time, whenever a node is assigned a task, it gets the
    patient’s data which is a vector of size 13. This data is fed as input to the
    model, makes a forward pass on the deep neural network and outputs 1 or 0 i.e
    whether the patient has heart disease or not. At diagnosis time, we use the ensemble
    method of Bagging to combine the results of various models to provide more accurate
    results. The worker that gets the input data multicasts it to other worker nodes.
    Each worker then adds this to its queue and the prediction results of each worker
    node are sent back to the worker assigned for this task. Then the majority prediction
    class obtained in by bagging is sent it to the gateway device. HealthFog allows
    users to disable this feature when the results needed are latency critical. In
    Section 7 we show that ensemble learning gives better accuracies but also has
    higher response time and network overheads. 5.3. Android interface and communication
    An android executable named FastHeartTest was used in the Gateway device to send
    data to the Broker/Worker nodes. The application interface is shown in Fig. 6.
    This application allows the Gateway to act as a mediator between the Body Sensor
    Network and the Worker nodes. The communication is achieved using HTTP RESTful
    APIs. We used HTTP POST to upload input data from and download results to the
    Gateway device. Each Worker node, the Broker node and CDC contains a pre-trained
    deep learning model and pre-processing softwares. Download : Download high-res
    image (276KB) Download : Download full-size image Fig. 6. Gateway Interface of
    HealthFog. 6. Implementation The components mentioned in Section 5 were implemented
    in various programming languages. The pre-processing and ensemble deep learning
    components were implemented using Python. The pre-processing module normalizes
    the data based on the maximum and minimum values of the field parameters in the
    dataset and their distribution. The ensemble deep learning application used SciKit
    learn Library [49]. We have used BaggingClassifier of the SciKit learn Library
    to implement our voting scheme. The model takes the type of base classifier which
    is deep neural network in our case and the number of classifiers as input. Now
    the model randomly distributes the data among the classifiers to train them. At
    diagnosis time it takes all predicted classes as input and outputs the majority
    prediction. The following are the parameters of the best base model on our data
    set after tuning: • Size of input layer: 13 (number of features of the data) •
    Size of output layer: 2 (Binary classification; whether the patient has heart
    disease or not) • Number of hidden layers: 3 • Layer descriptions: Fully connected
    (FC) layer with 20 nodes, FC layer with 20 nodes and FC Layer with 10 nodes •
    Optimizer: Adam • Activation function: ReLU • Learning rate: 0.0001 The Android
    application was built using MIT’s App Inventor1 and communicated with the FogBus
    Broker node. The android application saves the data attributes in a Comma Separated
    Value (.csv) file and uploads it to the broker node using HTTP POST to the Data
    Catalogue Module. Download : Download high-res image (166KB) Download : Download
    full-size image Fig. 7. Different modules in HealthFog. The broker node also has
    an Arbitration Module which decides which worker node to select for task execution.
    This worker selection process is done as per the default FogBus policy of selecting
    worker with minimum CPU load. Whichever worker is selected, is sent the CSV file
    for analysis. The Execution Interface Module in each worker receives the data
    and instantiates the Ensemble Deep Learning code for analysis of the data. The
    returned result is sent back to the Worker/Broker node which sent the data file.
    The result is ensembled using the bagging strategy and forwarded to the gateway
    device (android application). A diagrammatic representation of different modules
    and their interaction is shown in Fig. 7. 7. Performance evaluation To demonstrate
    the feasibility and efficacy of the proposed HealthFog model, we implemented and
    deployed it on actual Fog framework of devices using the FogBus framework [6].
    The model has been used for a real-world application of detecting Heart problems
    for patients instantly using state-of the art deep learning techniques using a
    Fog based computing environment. We have analyzed the accuracy and response times
    with network and energy overheads to show that the HealthFog model is productive
    and has low overheads. 7.1. Experimental setup The system setup for the HealthFog
    evaluation and the hardware configurations are described below: • Gateway Device:
    Samsung Galaxy S7 with android 9 • Broker/Master Node: Dell XPS 13 with Intel(R)
    Core(TM) i5-7200 CPU @ 2.50 GHZ, 8.00 GB DDR4 RAM and 64-bit Windows 10. The deployment
    used Apache HTTP Server 2.4.34. • Worker Node: Raspberry Pi 3B＋, ARM Cortex-A53
    quad-core SoC CPU @ 1.4 GHz and 1 GB LPDDR2 SDRAM and IEEE 802.11 Wifi. Raspbian
    Stretch Operating system with Apache HTTP server 2.4.34. • Public Cloud: Microsoft
    Azure B1s Machine, 1vCPU, 1 GB RAM, 2 GB SSD, Windows Server 2016. Fig. 8 depicts
    the real implementation of this system model. During the experiments, data parameters
    are recorded using Microsoft Performance Monitor at the Master and the Azure VM
    whereas at the Raspberry Pi circuits NMON Performance Monitor is used [50], [51].
    To measure the network bandwidth consumption Microsoft Network Monitor 3.4 was
    used at the Broker node [52] and the vnStat [53] tool in Raspberry Pis. Download
    : Download high-res image (298KB) Download : Download full-size image Fig. 8.
    Real HealthFog deployed model and test setup. 7.2. Dataset For the experimental
    results, we have considered the data of heart patients to find the presence of
    heart disease in the patient [44], [47], [48], [54], which is an integer valued
    0 (no presence) or 1 (presence). The Cleveland database [44] is used to conduct
    the experiments which was created by Andras Janosi (M.D.) at the Gottsegen Hungarian
    Institute of Cardiology, Hungary and others. The patient names and their patient
    numbers are kept confidential. We have used 14 important attributes of data to
    find out the status of patient health: (1) age: age in years, (2) sex: two values
    (1 male; 0 female), (3) cp: chest pain type: - Value 1: typical angina – Value
    2: atypical angina – Value 3: non-anginal pain – Value 4: asymptomatic, (4) trestbps:
    resting blood pressure (in mm Hg on admission to the hospital), (5) chol: serum
    cholesterol in mg/dl, (6) fbs: (fasting blood sugar 120 mg/dl) (1 true; 0 false),
    (7) restecg: resting electro-cardiographic results – Value 0: normal – Value 1:
    having ST-T wave abnormality (T wave inversions and/or ST elevation or depression
    of 0.05 mV) – Value 2: showing probable or definite left ventricular hypertrophy
    by Estes’ criteria, (8) thalach: maximum heart rate achieved, (9) exang: exercise
    induced angina (1 yes; 0 no), (10) oldpeak ST depression induced by exercise relative
    to rest, (11) slope: the slope of the peak exercise ST segment – Value 1: upsloping
    – Value 2: flat – Value 3: downsloping, (12) ca: number of major vessels (0–3)
    colored by flourosopy, (13) thal: 3 normal; 6 fixed defect; 7 reversable defect,
    (14) target (num): diagnosis of heart disease (angiographic disease status) –
    Value 0: 50% diameter narrowing – Value 1: 50% diameter narrowing (in any major
    vessel). Table 2 describes the details of just 10 heart patients. Table 2. Sample
    patient record data from Cleveland database. age sex cp trestbps chol fbs restecg
    thalach exang oldpeak slope ca thal target 63 1 3 145 233 1 0 150 0 2.3 0 0 1
    1 37 1 2 130 250 0 1 187 0 3.5 0 0 2 1 41 0 1 130 204 0 0 172 0 1.4 2 0 2 1 56
    1 1 120 236 0 1 178 0 0.8 2 0 2 1 57 0 0 120 354 0 1 163 1 0.6 2 0 2 1 62 0 0
    140 268 0 0 160 0 3.6 0 2 2 0 63 1 0 130 254 0 0 147 0 1.4 1 1 3 0 53 1 0 140
    203 1 0 155 1 3.1 0 0 3 0 56 1 2 130 256 1 0 142 1 0.6 1 1 1 0 48 1 1 110 229
    0 1 168 0 1 0 0 3 0 7.3. Framework characteristics experiments Using the dataset
    mentioned in Section 7.2, we test our model on how well it performs to predict
    if the patient has a heart disease or not based on the values of the parameters
    specified for each patient. The dataset was divided into two parts of 70%, 10%
    and 20% of the whole data. The first part was used to train the model, the second
    for validation and tweaking the model parameters. The last part was used for testing
    the model performance. To measure the performance of the HealthFog model the following
    characteristics were observed and analyzed: 1. Prediction accuracies: The dataset
    consists of 1807 examples out of which 1355 were used for training the model and
    452 were used for testing. The training examples were divided equally across all
    worker/broker nodes equally to obtain their respective trained deep learning models.
    As the number of Fog nodes increases to use all resources for training the dataset
    examples would have to be distributed to all nodes. This reduces the training
    time but also the test accuracy. To observe such effects, the training and test
    accuracies were analyzed. We define accuracy more formally as the percentage of
    the total patients for which the model predicts correctly if they have heart disease
    or not. We compare accuracies for different fog settings, by changing the number
    of edge nodes and with or without ensembling of results. 2. Time characteristics:
    A representative subset of the different timing parameters shown in Fig. 3 were
    also observed and studied. These include arbitration time, latency, execution
    time and jitter. We compare these timing parameters for different fog settings
    by having no edge nodes or up to 2 edge nodes (with or without ensembling) or
    having a cloud only computation infrastructure. 3. Network bandwidth usage: As
    the scenario i.e. Broker only, Workers or Cloud and the number of Worker nodes
    affect the network consumption this was studied to find out the network usage
    in different cases. Similar to the experiments for timing parameters, we compare
    the network bandwidth consumption for the different fog scenarios. This was done
    to find out the dependence of bandwidth consumption with different fog configurations
    that HealthFog provides. 4. Power consumption: Energy being a crucial reason of
    shift from cloud to fog domains, we also studied the power consumption in different
    scenarios. Based on the power consumption studies and other experiments described
    earlier we discuss how different HealthFog configurations can be used for various
    user and application requirements. 7.4. Prediction accuracies Fig. 9 shows the
    variation of training accuracy with number of Edge nodes (Broker plus Worker nodes).
    We can observe that the training accuracy gradually increases as the number of
    worker nodes increase. This is because each node learns a model for the data received
    by it, and as the number of nodes increase, the number of examples received by
    each node becomes lesser and hence training the model for multiple epochs over-fit
    the samples and hence training accuracy increases. Fig. 10 shows the variation
    of test data accuracy as the number of Edge nodes increase. As expected, test
    accuracy decreases with higher number of nodes because each node gets a smaller
    subset of training data and hence is unable to generalize the model. Another observation
    is that ensemble learning always gives much better accuracy than the without ensemble
    case (best or average). Download : Download high-res image (414KB) Download :
    Download full-size image Fig. 9. Training accuracy with number of edge nodes.
    Download : Download high-res image (387KB) Download : Download full-size image
    Fig. 10. Test accuracy with number of edge nodes. 7.5. Prediction confidence Whenever
    the deep learning model predicts whether the patient has heart disease or not
    it generates two probabilities: (probability of no disease) and (probability of
    heart disease), such that . The confidence measure of a prediction is quantified
    as and thus has range [0, 100]. Thus, if prediction probabilities is (0.5, 0.5)
    then the confidence is 0 and when they are (0.9, 0.1) then the prediction class
    is 0% and confidence is 80%. Fig. 11 shows the variation of confidence of the
    binary classifier for the complete test dataset, subset on which the model predicted
    correctly and that where prediction was incorrect. We see that the confidence
    is higher for the datapoints where the prediction was correct compared to those
    datapoints where the prediction was incorrect. The maximum confidence with which
    the model predicts incorrectly is 49.7%, thus if confidence is less that 50% then
    our model suggests the patient to consult the doctor as the prediction may be
    unreliable. Download : Download high-res image (262KB) Download : Download full-size
    image Fig. 11. Confidence of the model for different subsets of Cleveland Data.
    7.6. Timing characteristics Fig. 12 shows the variation of arbitration time at
    the Broker node for different Fog scenarios: (1) Broker only, (2) Single Worker
    node, (3) Two worker nodes and (4) Cloud. We see that arbitration time is negligible
    (nearly 115 ms) when the task is to be sent directly to Broker/Master or Cloud.
    As the number of edge nodes increase, the Broker needs to check loads at every
    Worker node and find the minimum load worker to send task, hence the arbitration
    time increases as number of Edge nodes increase. When the data is sent to worker
    nodes for ensemble learning, then also the broker does not need to do any load
    checking as majority class choice needs to be done by one of the worker nodes,
    thus arbitration time is similar to without ensembling case. Fig. 13 shows the
    variation of latency, which as per Fig. 3 is the addition of communication time
    and queuing delay. We see that if the task is sent to Broker or any of the edge
    nodes, then the latency is nearly same as all communication is through single
    hop data transfers. In ensemble case, the latency is slightly higher. For cloud
    setting, the latency is very high due to multi-hop transfer of data outside the
    LAN. Download : Download high-res image (258KB) Download : Download full-size
    image Fig. 12. Arbitration time in different cases. Jitter is the variation of
    response time for consecutive job requests. It is a critical parameter for most
    real-time applications including health data analysis. Fig. 14 (log vertical scale)
    shows the variation of jitter with the Fog configurations. We observe that jitter
    is higher for Broker only case compared to the case where tasks are sent to worker
    nodes. This is because of other tasks including arbitration, resource management
    and security checking are also performed by Broker. As the workers increase, due
    to difference in loads of workers jitter slightly increases for two edge nodes
    compared to single edge node. Jitter is also high in ensemble case. Jitter is
    very high when tasks are sent to CDC. Download : Download high-res image (250KB)
    Download : Download full-size image Fig. 13. Latency in different cases. Fig.
    15 shows the variation of execution time. As expected, the execution time in Cloud
    setup is very low due to higher resource availability. Broker execution time is
    lesser than the worker nodes as HealthFog workers are Raspberry Pis which have
    processor with low clock frequency. Also, when ensemble prediction is enabled
    then the execution time is higher because the worker node now needs to check which
    class is majority among all predicted classes. Download : Download high-res image
    (249KB) Download : Download full-size image Fig. 14. Jitter in different cases.
    Download : Download high-res image (281KB) Download : Download full-size image
    Fig. 15. Execution time in different cases. 7.7. Network bandwidth usage characteristics
    Fig. 16 shows the variation of Network bandwidth usage of all edge nodes in different
    scenarios. We see that as the worker nodes increase, the network usage also increase
    because more heartbeat packets, security checks and data transfer (with cloud)
    are required. In ensemble case, as data is sent to all worker nodes the network
    bandwidth consumption is highest. Download : Download high-res image (307KB) Download
    : Download full-size image Fig. 16. Network usage in different cases. Download
    : Download high-res image (232KB) Download : Download full-size image Fig. 17.
    Power consumption in different cases. 7.8. Power characteristics We also tested
    HealthFog energy consumption characteristics in different scenarios. As shown
    in Fig. 17, the power consumption of CDC is very high compared to the Broker node
    (laptop) or Worker nodes (Raspberry Pi). This leads to very high power consumption
    in Cloud case compared to Edge case. As the number of Worker nodes increase, the
    power consumption of the HealthFog framework also increases. 7.9. Analysis with
    related work Other works that propose computing models for healthcare applications
    in Fog Computing do not consider various aspects which HealthFog does. Many prior
    works [27], [29], [30], [34], [35], [36], [38] do not leverage resources close
    to the edge of the network. As per Fig. 13, such models provide a much higher
    latency as all computation is done on the cloud and hence has higher data transfer
    times. With the advancement of deep learning based prediction models, HealthFog
    is able to use state-of-the-art Neural Network models for highly accurate prediction
    of health characteristics of patients. Other works like [2], [9] or [5], [26],
    [27], [28], [29], [31], [37], [39] lack the ability to integrate such models and
    hence provide lower disease detection accuracy. This is crucial to provide low
    latency and highly accurate results in critical healthcare applications especially
    those concerned with heart related problems like heart attack, stroke or arrhythmia.
    Furthermore, works that use deep learning [24], [30], [32] do not use ensembling
    methods to provide even better results by leveraging fog resources for parallel
    computation and providing significantly higher accuracy. As shown by results in
    Section 7.4, with ensemble, the prediction accuracy increases by 16% for the case
    with 5 edge nodes which is significantly higher than what existing systems (not
    leveraging ensemble deep learning) can provide. Moreover, unlike prior work HealthFog
    uses the FogBus framework [6] to provide a diverse set of configurations with
    different accuracy, response time, network and power usage characteristics. Based
    on different application and user requirements different configurations can be
    used as described in the following section. This allows users to customize the
    framework as per their needs. This non-trivial extension of integration and synchronization
    among fog computing nodes allows execution ensemble based deep learning models
    which not only improves disease detection accuracy but is also adaptive as per
    diverse requirements. Hence, HealthFog provides a novel architecture of healthcare
    computation not offered by existing works. 7.10. Discussion and recommendations
    In earlier work [6], the power of FogBus and comparisons with earlier such Fog
    frameworks were demonstrated showing how FogBus provides more efficient implementation
    of applications harnessing the Edge and Cloud resources. This work developed a
    latency and accuracy sensitive application of Heart patient analysis using the
    FogBus framework with engineering simplicity and in low time to efficiently use
    Edge and Cloud resources. The application deployment system provided different
    configurations that provide better accuracy or latency based on user requirements.
    Based on the experimental results we propose HealthFog to be used in the following
    settings based on the target applications: • For latency critical and lightweight
    tasks or energy constraint environments, worker nodes should be used. This provides
    very low result delivery time due to close proximity of worker nodes. If energy
    and network bandwidth constraints exist then ensemble bagging should be disabled
    but if not, enabling bagging would give better accuracy. • For heavy and latency
    tolerant tasks CDC configuration must be used otherwise such tasks would not be
    able to successfully complete on resource constraint edge worker nodes. 8. Conclusions
    and future work Healthcare as a service is a huge project. In this research work,
    we only focus on the healthcare aspects for heart patients by proposing a novel
    Fog based Smart Healthcare System for Automatic Diagnosis of Heart Diseases using
    deep learning and IoT called HealthFog. HealthFog provides healthcare as a fog
    service and efficiently manages the data of heart patients which is coming from
    different IoT devices. HealthFog integrates deep learning in Edge computing devices
    and deployed it for a real-life application of Heart Disease analysis. Prior works
    for such Heart Patient analysis did not utilize deep learning and hence had very
    low prediction accuracy which renders them useless in practical settings. Deep
    learning based models with very high accuracy require very high compute resources
    (CPU and GPU) both for training and prediction. This work allowed complex deep
    learning networks to be embedded in Edge computing paradigms using novel communication
    and model distribution techniques like ensembling which allowed high accuracy
    to be achieved with very low latencies. This was also validated for real-life
    heart patient data analysis by training neural networks on popular datasets and
    deploying a working system that provides prediction results in real-time. We used
    FogBus framework to validate HealthFog in fog computing environment and tested
    the efficiency of proposed system in terms of power consumption, network bandwidth,
    latency, jitter, training accuracy, testing accuracy and execution time. As part
    of the future work, we propose to extend HealthFog to allow cost-optimal execution
    given different QoS characteristics and fog-cloud cost models. Currently HealthFog
    works with file based input data which can be converted to seamlessly integrated
    to take data directly from sensors to make it user-friendly. Moreover, the model
    training strategy used currently uses separate training at each worker node. The
    trained models at each node have combined using various ensemble model of bagging.
    More intelligent ensemble models can be deployed for further improving the accuracy.
    Further, proposed architecture can be made robust and generic to incorporate other
    fog computing applications such as agriculture, healthcare, weather forecasting,
    traffic management and smart city. HealthFog can also be extended towards other
    important domains of healthcare such as diabetes, cancer and hepatitis, which
    can provide efficient services to corresponding patients. Declaration of Competing
    Interest The authors declare that they have no known competing financial interests
    or personal relationships that could have appeared to influence the work reported
    in this paper. Acknowledgments This research work is supported by the Melbourne-Chindia
    Cloud Computing (MC3) Research Network, Australia and Australian Research Council
    . We would like to thank the editor, area editor and anonymous reviewers for their
    valuable comments and suggestions to help and improve our research paper. We would
    also like to thank Samodha Pallewatta, Shashikant Ilager (CLOUDS Lab, University
    of Melbourne) and Shikhar Tuli (Indian Institute of Technology, Delhi) for their
    valuable comments on improving the quality of presentation. Software Availability
    We released HealthFog as an open source software. The implementation code with
    experiment scripts and results can be found at the GitHub repository: https://github.com/Cloudslab/HealthFog.
    References [1] Islam S.M.R., Kwak D., Kabir M.D.H., Hossain M., Kwak K.S. The
    Internet of Things for health care: a comprehensive survey IEEE Access, 3 (2015),
    pp. 678-708 View in ScopusGoogle Scholar [2] Rahmani A.M., Gia T.N., Negash B.,
    Anzanpour A., Azimi I., Jiang M., Liljeberg P. Exploiting smart e-health gateways
    at the edge of healthcare Internet-of-Things: a fog computing approach Future
    Gener. Comput. Syst., 78 (2018), pp. 641-658 View PDFView articleView in ScopusGoogle
    Scholar [3] Tuli Shreshth, Basumatary Nipam, Buyya Rajkumar Edgelens: Deep learning
    based object detection in integrated IoT, fog and cloud computing environments
    Proceedings of the 4th IEEE International Conference on Information Systems and
    Computer Networks, ISCON 2019, Mathura, India, November 21–22, IEEE Press, USA
    (2019) Google Scholar [4] Gill Sukhpal Singh, Arya Rajesh Chand, Wander Gurpreet
    Singh, Buyya Rajkumar Fog-based smart healthcare as a Big Data and cloud service
    for heart patients using IoT International Conference on Intelligent Data Communication
    Technologies and Internet of Things, Springer, Cham (2018), pp. 1376-1383 Google
    Scholar [5] He S., Cheng B., Wang H., Huang Y., Chen J. Proactive personalized
    services through fog-cloud computing in large-scale IoT-based healthcare application
    China Commun., 14 (11) (2017), pp. 1-16 Google Scholar [6] Tuli Shreshth, Mahmud
    Redowan, Tuli Shikhar, Buyya Rajkumar FogBus: A blockchain-based lightweight framework
    for edge and fog computing J. Syst. Softw., 154 (2019), pp. 22-36 View PDFView
    articleView in ScopusGoogle Scholar [7] Mutlag Ammar Awad, Ghani Mohd Khanapi
    Abd, al Arunkumar Net, Mohamed Mazin Abed, Mohd Othman Enabling technologies for
    fog computing in healthcare IoT systems Future Gener. Comput. Syst., 90 (2019),
    pp. 62-78 View PDFView articleView in ScopusGoogle Scholar [8] Moysiadis Vasileios,
    Sarigiannidis Panagiotis, Moscholios Ioannis Towards distributed data management
    in fog computing Wirel. Commun. Mob. Comput., 2018 (2018) Google Scholar [9] Moosavi
    Sanaz Rahimi, Gia Tuan Nguyen, Nigussie Ethiopia, Rahmani Amir M., Virtanen Seppo,
    Tenhunen Hannu, Isoaho Jouni End-to-end security scheme for mobility enabled healthcare
    Internet of Things Future Gener. Comput. Syst., 64 (2016), pp. 108-124 View PDFView
    articleView in ScopusGoogle Scholar [10] Ibrahim Abdullahi, Arif Suki, Hassan
    Suhaidi Ubiquitous shift with information centric network caching using fog computing
    Computational Intelligence in Information Systems, Springer, Cham (2015), pp.
    327-335 Google Scholar [11] Satyanarayanan Mahadev The emergence of edge computing
    Computer, 50 (1) (2017), pp. 30-39 View in ScopusGoogle Scholar [12] Goyal Abhishek,
    Narang Kanika, Ahluwalia Gautam, Sohal P.M., Singh Bhupinder, Chhabra Shibba T.,
    Aslam Naved, Mohan Bishav, Wander Gurpreet S. Seasonal variation in 24 h blood
    pressure profile in healthy adults-A prospective observational study J. Hum. Hypertens.
    (2019), p. 1 View PDFView articleGoogle Scholar [13] Singh Gill Sukhpal, Garraghan
    Peter, Buyya Rajkumar ROUTER: Fog enabled cloud based intelligent resource management
    approach for smart home IoT devices J. Syst. Softw. (2019) Google Scholar [14]
    Faust Oliver, Hagiwara Yuki, Hong Tan Jen, Lih Oh Shu, Rajendra Acharya U. Deep
    learning for healthcare applications based on physiological signals: A review
    Comput. Methods Programs Biomed., 161 (2018), pp. 1-13 View PDFView articleView
    in ScopusGoogle Scholar [15] Dietterich Thomas G. Ensemble methods in machine
    learning International Workshop on Multiple Classifier Systems, Springer, Berlin,
    Heidelberg (2000), pp. 1-15 CrossRefGoogle Scholar [16] Zhao Xianlong, Yang Kexin,
    Chen Qimei, Peng Duo, Jiang Hao, Xu Xianze, Shuang Xinzhuo Deep learning based
    mobile data offloading in mobile edge computing systems Future Gener. Comput.
    Syst. (2019) Google Scholar [17] Tjen-Sien Lim, Loh Wei-Yin, Shih Yu-Shan A comparison
    of prediction accuracy, complexity, and training time of thirty-three old and
    new classification algorithms Mach. Learn., 40 (3) (2000), pp. 203-228 Google
    Scholar [18] Naeije Robert, Hemnes Anna Ryan The Difficult Diagnosis of Pulmonary
    Vascular Disease in Heart Failure (2016), pp. 308-310 CrossRefView in ScopusGoogle
    Scholar [19] Papa Marco, Camesasca Chiara, Santoro Francesco, Zoia Elena, Fragasso
    Gabriele, Giannico Salvatore, Sergio L., Chierchia F., et al. Echocardiography
    in detecting anomalous pulmonary venous connection: four false positive cases
    Heart, 73 (4) (1995), pp. 355-358 CrossRefView in ScopusGoogle Scholar [20] Buch
    Varun H., Ahmed Irfan, Maruthappu Mahiben Artificial intelligence in medicine:
    current trends and future possibilities Br. J. Gen. Pract., 68 (668) (2018), pp.
    143-144 CrossRefView in ScopusGoogle Scholar [21] Panch Trishan, Mattie Heather,
    Celi Leo Anthony The inconvenient truth about AI in healthcare NPJ Digit. Med.,
    2 (2019) Google Scholar [22] Juarez-Orozco L.E., Martinez-Manzanera F.M., Van
    Der Zant R.J.J., Knol O., Knuuti J. 241 deep learning in quantitative PET myocardial
    perfusion imaging to predict adverse cardiovascular events Eur. Heart J. Cardiovasc.
    Imaging, 20 (Supplement_3) (2019) jez145-005 Google Scholar [23] Acharya U. Rajendra,
    Fujita Hamido, Oh Shu Lih, Hagiwara Yuki, Tan Jen Hong, Adam Muhammad Application
    of deep convolutional neural network for automated detection of myocardial infarction
    using ECG signals Inform. Sci., 415 (2017), pp. 190-198 View PDFView articleView
    in ScopusGoogle Scholar [24] Azimi Iman, Takalo-Mattila Janne, Anzanpour Arman,
    Rahmani Amir M., Soininen Juha-Pekka, Liljeberg Pasi Empowering healthcare IoT
    systems with hierarchical edge-based deep learning 2018 IEEE/ACM International
    Conference on Connected Health: Applications, Systems and Engineering Technologies,
    CHASE, IEEE (2018), pp. 63-68 CrossRefView in ScopusGoogle Scholar [25] Vecchiola
    Christian, Chu Xingchen, Buyya Rajkumar Aneka: a software platform for NET-based
    cloud computing High Speed and Large Scale Scientific Computing 18 (2009), pp.
    267-295 View in ScopusGoogle Scholar [26] T.N. Gia, M. Jiang, V.K. Sarker, A.M.
    Rahmani, T. Westerlund, P. Liljeberg, H. Tenhunen, Low-cost fog-assisted health-care
    IoT system with energy-efficient sensor nodes. In: 13th IEEE International Conference
    Wireless Communications and Mobile Computing, 2017, pp. 1765–1770. Google Scholar
    [27] S. Ali, M. Ghazal, Real-time Heart Attack Mobile Detection Service (RHAMDS)
    An IoT use case for software defined networks. In: 30th IEEE Canadian Conference
    on Electrical and Computer Engineering, 2017, pp. 1–6. Google Scholar [28] O.
    Akrivopoulos, D. Amaxilatis, A. Antoniou, I. Chatzigiannakis, Design and evaluation
    of a person-centric heart monitoring system over fog computing infrastructure.
    In: Ist ACM International Workshop on Human-centered Sensing, Networking, and
    Systems, 2017, pp. 25–30. Google Scholar [29] Manikandan Rajasekaran, Yassine
    Abdulsalam, Shamim Hossain M., Mohammed F. Alhamid Amir M., Guizani Mohsen Autonomous
    monitoring in healthcare environment: Reward-based energy charging mechanism for
    IoMT wireless sensing nodes Future Gener. Comput. Syst., 98 (2019), pp. 565-576
    Google Scholar [30] Choi Edward, Bahadori Mohammad Taha, Song Le, Stewart Walter
    F., Sun Jimeng GRAM: graph-based attention model for healthcare representation
    learning Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge
    Discovery and Data Mining, ACM (2017), pp. 787-795 CrossRefView in ScopusGoogle
    Scholar [31] Constant Nicholas, Borthakur Debanjan, Abtahi Mohammadreza, Dubey
    Harishchandra, Mankodiya Kunal Fog-assisted wiot: A smart fog gateway for end-to-end
    analytics in wearable internet of things (2017) arXiv preprint arXiv:1701.08680
    Google Scholar [32] Li Liangzhi, Ota Kaoru, Dong Mianxiong Deep learning for smart
    industry: efficient manufacture inspection system with fog computing IEEE Trans.
    Ind. Inf., 14 (10) (2018), pp. 4665-4673 CrossRefView in ScopusGoogle Scholar
    [33] Mahmud Redowan, Koch Fernando Luiz, Buyya Rajkumar Cloud-fog interoperability
    in IoT-enabled healthcare solutions Proceedings of the 19th International Conference
    on Distributed Computing and Networking, ACM (2018), p. 32 Google Scholar [34]
    Barik Rabindra K., Priyadarshini Rojalina, Dubey Harishchandra, Kumar Vinay, Mankodiya
    Kunal FogLearn: leveraging fog-based machine learning for smart system big data
    analytics Int. J. Fog Comput., 1 (1) (2018), pp. 15-34 CrossRefGoogle Scholar
    [35] Alvin Rajkomar, Oren Eyal, Chen Kai, Dai Andrew M., Hajaj Nissan, Hardt Michaela,
    Liu Peter J., et al. Scalable and accurate deep learning with electronic health
    records NPJ Digit. Med., 1 (1) (2018), p. 18 Google Scholar [36] Pham Minh, Mengistu
    Yehenew, Do Ha, Sheng Weihua Delivering home healthcare through a cloud-based
    smart home environment (CoSHE) Future Gener. Comput. Syst., 81 (2018), pp. 129-140
    View PDFView articleView in ScopusGoogle Scholar [37] Alam Md Golam Rabiul, Munir
    Md Shirajum, Uddin Md Zia, Alam Mohammed Shamsul, Dang Tri Nguyen, Hong Choong
    Seon Edge-of-things computing framework for cost-effective provisioning of healthcare
    data J. Parallel Distrib. Comput., 123 (2019), pp. 54-60 View PDFView articleView
    in ScopusGoogle Scholar [38] Kumar Sahoo Prasan, Mohapatra Suvendu Kumar, Wu Shih-Lin
    SLA based healthcare big data analysis and computing in cloud network J. Parallel
    Distrib. Comput., 119 (2018), pp. 121-135 View in ScopusGoogle Scholar [39] Abdelmoneem
    Randa M., Benslimane Abderrahim, Shaaban Eman, Abdelhamid Sherin, Ghoneim Salma
    A cloud-fog based architecture for IoT applications dedicated to healthcare ICC
    2019-2019 IEEE International Conference on Communications, ICC, IEEE (2019), pp.
    1-6 CrossRefView in ScopusGoogle Scholar [40] Dharambir K.Sanghera, Bejar Cynthia,
    Sapkota Bishwa, Wander Gurpreet S., Ralhan Sarju Frequencies of poor metabolizer
    alleles of 12 pharmacogenomic actionable genes in Punjabi Sikhs of Indian origin
    Sci. Rep., 8 (1) (2018), Article 15742 Google Scholar [41] Gupta Harshit, Dastjerdi
    Amir Vahid, Ghosh Soumya K., Buyya Rajkumar iFogSim: A toolkit for modeling and
    simulation of resource management techniques in the Internet of Things, edge and
    fog computing environments Softw. - Pract. Exp., 47 (9) (2017), pp. 1275-1296
    CrossRefView in ScopusGoogle Scholar [42] Farahani B., Firouzi F., Chang V., Badaroglu
    M., Constant N., Mankodiya K. Towards fog-driven IoT ehealth: Promises and challenges
    of IoT in medicine and healthcare Future Gener. Comput. Syst., 78 (2018), pp.
    659-676 View PDFView articleView in ScopusGoogle Scholar [43] Mäkitalo N., Ometov
    A., Kannisto J., Andreev S., Koucheryavy J., Mikkonen T. Safe, secure executions
    at the network edge: Coordinating cloud, edge, and fog computing IEEE Softw.,
    35 (1) (2017), pp. 30-37 View in ScopusGoogle Scholar [44] Dua D., Graff C. UCI
    Machine Learning Repository University of California, School of Information and
    Computer Science, Irvine, CA (2019) http://archive.ics.uci.edu/ml Google Scholar
    [45] Hsieh J.H., Lee R.C., Hung K.C., Shih M.J. Rapid and coding-efficient SPIHT
    algorithm for wavelet-based ECG data compression Integr. VLSI J., 60 (2018), pp.
    248-256 View PDFView articleView in ScopusGoogle Scholar [46] Liu T.Y., Lin K.Y.,
    Wu H.C. ECG data encryption then compression using singular value decomposition
    IEEE J. Biomed. Health Inform. (2017) Google Scholar [47] Kato Norihiro, Loh Marie,
    Takeuchi Fumihiko, Verweij Niek, Wang Xu, Zhang Weihua, Kelly Tanika N., et al.
    Trans-ancestry genome-wide association study identifies 12 genetic loci influencing
    blood pressure and implicates a role for DNA methylation Nature Genet., 47 (11)
    (2015), p. 1282 CrossRefView in ScopusGoogle Scholar [48] Sanghera Dharambir K.,
    Been Latonya, Ortega Lyda, Wander Gurpreet S., Mehra Narinder K., Aston Christopher
    E., Mulvihill John J., Ralhan Sarju Testing the association of novel meta-analysis-derived
    diabetes risk genes with type II diabetes and related metabolic traits in Asian
    Indian Sikhs J. Hum. Genet., 54 (3) (2009), p. 162 CrossRefView in ScopusGoogle
    Scholar [49] Pedregosa Fabian, Varoquaux Gaël, Gramfort Alexandre, Michel Vincent,
    Thirion Bertrand, Grisel Olivier, Blondel Mathieu, et al. Scikit-learn: Machine
    learning in Python J. Mach. Learn. Res., 12 (2011), pp. 2825-2830 Google Scholar
    [50] Mircosoft Windows performance toolkit (2019) https://docs.microsoft.com/en-us/windows-hardware/test/wpt/.
    (Online; Accessed 28-May-2019) Google Scholar [51] SplunkBase performance monitor
    (2019) https://splunkbase.splunk.com/app/1753/. (Online; Accessed 28-May-2019)
    Google Scholar [52] Microsoft network monitor 3.4 (2019) https://www.microsoft.com/en-au/download/details.aspx?id=4865.
    (Online; accessed 28-May-2019) Google Scholar [53] vnStat network monitoring tool
    (2019) https://humdi.net/vnstat/. (Online; Accessed 28-May-2019) Google Scholar
    [54] Malik Rainer, Chauhan Ganesh, Traylor Matthew, Sargurupremraj Muralidharan,
    Okada Yukinori, Mishra Aniket, Rutten-Jacobs Loes, et al. Multiancestry genome-wide
    association study of 520,000 subjects identifies 32 loci associated with stroke
    and stroke subtypes Nature Genet., 50 (4) (2018), p. 524 CrossRefView in ScopusGoogle
    Scholar Cited by (448) An IoT enabled computational model and application development
    for monitoring cardiovascular risks 2024, e-Prime - Advances in Electrical Engineering,
    Electronics and Energy Show abstract IoT-based vital sign monitoring: A literature
    review 2024, Smart Health Show abstract Enhanced decision-making in healthcare
    cloud-edge networks using deep reinforcement and lion optimization algorithm 2024,
    Biomedical Signal Processing and Control Show abstract FedHealthFog: A federated
    learning-enabled approach towards healthcare analytics over fog computing platform
    2024, Heliyon Show abstract Modern computing: Vision and challenges 2024, Telematics
    and Informatics Reports Show abstract Opportunities and challenges of artificial
    intelligence and distributed systems to improve the quality of healthcare service
    2024, Artificial Intelligence in Medicine Show abstract View all citing articles
    on Scopus Shreshth Tuli, is an undergraduate student at the Department of Computer
    Science and Engineering at Indian Institute of Technology — Delhi, India. He is
    a national level Kishore Vaigyanic Protsahan Yojana (KVPY) scholarship holder
    for excellence in science and innovation. He is working as a visiting research
    fellow at the Cloud Computing and Distributed Systems (CLOUDS) Laboratory, Department
    of Computing and Information Systems, the University of Melbourne, Australia.
    Most of his projects are focused on developing technologies for future requiring
    sophisticated hardware–software integration. His research interests include Internet
    of Things (IoT), Fog Computing, Network Design, Blockchain and deep learning.
    Nipam Basumatary is an undergraduate student at Department of Computer Science
    and Engineering at Indian Institute of Technology, Madras. He is working as a
    visiting research fellow at Cloud Computing and Distributed Systems (CLOUD) Laboratory,
    Department of Computing and Information Systems, the University of Melbourne,
    Australia. His research interests include Machine Learning, deep learning, Internet
    of Things (IoT) and Fog Computing. Sukhpal Singh Gill is a Lecturer (Assistant
    Professor) in Cloud Computing at School of Electronic Engineering and Computer
    Science (EECS), Queen Mary University of London, UK. Prior to this, Dr. Gill has
    held positions as a Research Associate at the School of Computing and Communications,
    Lancaster University, UK and also as a Postdoctoral Research Fellow at the Cloud
    Computing and Distributed Systems (CLOUDS) Laboratory, School of Computing and
    Information Systems, The University of Melbourne, Australia. Dr. Gill was a research
    visor at Monash University, University of Manitoba and Imperial College London.
    He was a recipient of several awards, including the Distinguished Reviewer Award
    from Software: Practice and Experience (Wiley), 2018, and served as the PC member
    for venues such as UCC, SE-CLOUD, ICCCN, ICDICT and SCES. His one review paper
    has been nominated and selected for the ACM 21st annual Best of Computing Notable
    Books and Articles as one of the notable items published in computing — 2016.
    He has published more than 50 papers as a leading author in highly ranked journals
    and conferences with H-index 18. His research interests include Cloud Computing,
    Fog Computing, Software Engineering, Internet of Things and Big Data. For further
    information on Dr. Gill, please visit: www.ssgill.me. Mohsen Kahani is a profess
    or of computer engineering, IT director and head of Web Technology Laboratory
    at Ferdowsi University of Mashhad and visiting Researcher at Cloud Computing and
    Distributed Systems (CLOUDS) Laboratory, School of Computing and Information Systems,
    The University of Melbourne, Australia. His research interests includes semantic
    wen, software engineering, natural language processing and process mining. Rajesh
    Chand Arya is a Consultant Cardiac Anesthesiologist at Department of Cardiology,
    Hero Heart Institute Dayanand Medical College and Hospital, Ludhiana, Punjab,
    India. He has 12 years of Cardiac Anesthesia experience after post-graduation.
    Special interest in Trans Esophageal Echo (TEE) & Pediatric, Cardiac Anesthesia.
    He has delivered more than 20 guest lectures at national & international level.
    Gurpreet Singh Wander is a Chief Cardiologist at Department of Cardiology, Hero
    Heart Institute Dayanand Medical College and Hospital (DMC & H), Ludhiana, Punjab,
    India. He joined DMC & H in 1988. He has been awarded BC Roy Award in 2007 and
    K. Sharan Award by national IMA in 2005. He is a Member of Govern Board of API
    for 6 years. Dr. Wander has 200+ research publications in top ranked venues which
    include 5 publications in Nature journals (Nature genetics, Journal of Human Genetics,
    Scientific Reports and Journal of Human Hypertension). Rajkumar Buyya is a Redmond
    Barry Distinguished Professor and Director of the Cloud Computing and Distributed
    Systems (CLOUDS) Laboratory at the University of Melbourne, Australia. He is also
    serving as the founding CEO of Manjrasoft, a spin-off company of the University,
    commercializing its innovations in Cloud Computing. He served as a Future Fellow
    of the Australian Research Council during 2012–2016. He has authored over 700
    publications and seven text books including “Mastering Cloud Computing” published
    by McGraw Hill, China Machine Press, and Morgan Kaufmann for Indian, Chinese and
    international markets respectively. He is one of the highly cited authors in computer
    science and software engineering worldwide (h-index=127, g-index=281, 84900+ citations).
    “A Scientometric Analysis of Cloud Computing Literature” by German scientists
    ranked Dr. Buyya as the World’s Top-Cited (1) Author and the World’s Most-Productive
    (1) Author in Cloud Computing. Recently, Dr. Buyya is recognized as a “Web of
    Science Highly Cited Researcher” in both 2016 and 2017 by Thomson Reuters, a Fellow
    of IEEE, and Scopus Researcher of the Year 2017 with Excellence in Innovative
    Research Award by Elsevier for his outstanding contributions to Cloud computing.
    He served as the founding Editor-in-Chief of the IEEE Transactions on Cloud Computing.
    He is currently serving as Editor-in-Chief of Journal of Software: Practice and
    Experience, which was established over 45 years ago. For further information on
    Dr. Buyya, please visit his cyberhome: www.buyya.com. 1 MIT App Inventor 2: http://ai2.appinventor.mit.edu/.
    View Abstract © 2019 Elsevier B.V. All rights reserved. Recommended articles A
    wearable sensor-based activity prediction system to facilitate edge computing
    in smart healthcare system Journal of Parallel and Distributed Computing, Volume
    123, 2019, pp. 46-53 Md. Zia Uddin View PDF Fog Computing-inspired Smart Home
    Framework for Predictive Veterinary Healthcare Microprocessors and Microsystems,
    Volume 78, 2020, Article 103227 Munish Bhatia View PDF Task offloading in edge
    computing for machine learning-based smart healthcare Computer Networks, Volume
    191, 2021, Article 108019 Mohammad Aazam, …, Eduardo Feo Flushing View PDF Show
    3 more articles Article Metrics Citations Patent Family Citations: 1 Citation
    Indexes: 397 Captures Readers: 579 Social Media Shares, Likes & Comments: 38 View
    details About ScienceDirect Remote access Shopping cart Advertise Contact and
    support Terms and conditions Privacy policy Cookies are used by this site. Cookie
    settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier
    B.V., its licensors, and contributors. All rights are reserved, including those
    for text and data mining, AI training, and similar technologies. For all open
    access content, the Creative Commons licensing terms apply.'
  inline_citation: '>'
  journal: Future Generation Computer Systems
  limitations: '>'
  pdf_link: null
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: 'HealthFog: An ensemble deep learning based Smart Healthcare System for Automatic
    Diagnosis of Heart Diseases in integrated IoT and fog computing environments'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/access.2020.2991734
  analysis: '>'
  authors:
  - Keyan Cao
  - Yefan Liu
  - Gongjie Meng
  - Qimeng Sun
  citation_count: 410
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy IEEE.org IEEE Xplore IEEE
    SA IEEE Spectrum More Sites Subscribe Donate Cart Create Account Personal Sign
    In Personal Sign In * Required *Email Address *Password Forgot Password? Sign
    In Don''t have a Personal Account? Create an IEEE Account now. Create Account
    Learn more about personalization features. IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/8948470/09083958.pdf
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: An Overview on Edge Computing Research
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/comst.2018.2849509
  analysis: '>'
  authors:
  - Pawani Porambage
  - Jude Okwuibe
  - Madhusanka Liyanage
  - Mika Ylianttila
  - Tarik Taleb
  citation_count: 526
  full_citation: '>'
  full_text: '>

    IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Subscribe Donate Cart Create
    Account Personal Sign In Browse My Settings Help Institutional Sign In All Books
    Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED
    SEARCH Journals & Magazines >IEEE Communications Surveys &... >Volume: 20 Issue:
    4 Survey on Multi-Access Edge Computing for Internet of Things Realization Publisher:
    IEEE Cite This PDF Pawani Porambage; Jude Okwuibe; Madhusanka Liyanage; Mika Ylianttila;
    Tarik Taleb All Authors 537 Cites in Papers 11307 Full Text Views Abstract Document
    Sections I. Introduction II. IoT and MEC Application Scenarios III. Technical
    Aspects of MEC Enabled IoT IV. Integration Technologies V. Projects Show Full
    Outline Authors Figures References Citations Keywords Metrics Abstract: The Internet
    of Things (IoT) has recently advanced from an experimental technology to what
    will become the backbone of future customer value for both product and service
    sector businesses. This underscores the cardinal role of IoT on the journey toward
    the fifth generation of wireless communication systems. IoT technologies augmented
    with intelligent and big data analytics are expected to rapidly change the landscape
    of myriads of application domains ranging from health care to smart cities and
    industrial automations. The emergence of multi-access edge computing (MEC) technology
    aims at extending cloud computing capabilities to the edge of the radio access
    network, hence providing real-time, high-bandwidth, low-latency access to radio
    network resources. IoT is identified as a key use case of MEC, given MEC''s ability
    to provide cloud platform and gateway services at the network edge. MEC will inspire
    the development of myriads of applications and services with demand for ultralow
    latency and high quality of service due to its dense geographical distribution
    and wide support for mobility. MEC is therefore an important enabler of IoT applications
    and services which require real-time operations. In this survey, we provide a
    holistic overview on the exploitation of MEC technology for the realization of
    IoT applications and their synergies. We further discuss the technical aspects
    of enabling MEC in IoT and provide some insight into various other integration
    technologies therein. Published in: IEEE Communications Surveys & Tutorials (
    Volume: 20, Issue: 4, Fourthquarter 2018) Page(s): 2961 - 2991 Date of Publication:
    21 June 2018 ISSN Information: DOI: 10.1109/COMST.2018.2849509 Publisher: IEEE
    Funding Agency: I. Introduction Over the last four decades, the Internet has evolved
    from peer-to-peer networking to World-Wide-Web, and mobile-Internet to the Internet
    of Things (IoT) (Figure 1). IoT emerged as a huge paradigm shift by connecting
    a versatile and massive collection of smart objects to the Internet. With IoT,
    people and things are able to connect at any time to any place with anything and
    anyone, ideally using any path or network and any available services [1]. From
    the user and application points of view, fifth generation (5G) wireless networks
    will be highly capable mobile networks with high bandwidth (e.g., 10 Gbps), very
    low latency (e.g., 1 ms), and low operational cost which will lead to highly improved
    quality of service and quality of experience. Another significant advancement
    of the Internet will be the Tactile Internet; which is a highly advanced use case
    of human-to-machine and machine-to-machine interaction characterized by ultra
    low latency with extremely high availability, reliability and security. Fig. 1.
    Evolution of the Internet. Sign in to Continue Reading Authors Figures References
    Citations Keywords Metrics More Like This Toward Edge Intelligence: Multiaccess
    Edge Computing for 5G and Internet of Things IEEE Internet of Things Journal Published:
    2020 Future Edge Cloud and Edge Computing for Internet of Things Applications
    IEEE Internet of Things Journal Published: 2018 Show More IEEE Personal Account
    CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS
    Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL
    INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT
    & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms
    of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy
    Policy A not-for-profit organization, IEEE is the world''s largest technical professional
    organization dedicated to advancing technology for the benefit of humanity. ©
    Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE Communications surveys and tutorials/IEEE communications surveys and
    tutorials
  limitations: '>'
  pdf_link: null
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: Survey on Multi-Access Edge Computing for Internet of Things Realization
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.future.2017.04.036
  analysis: '>'
  authors:
  - Bahar Farahani
  - Farshad Firouzi
  - Victor Chang
  - Mustafa Badaroglu
  - Nicholas Constant
  - Kunal Mankodiya
  citation_count: 690
  full_citation: '>'
  full_text: '>

    403 Forbidden Code: AccessDenied Message: Access Denied RequestId: Z0AGYQ1N18QK1WCY
    HostId: v4KsJUQioEREo8U9ajZaZnb3oObypNIFksbtgT6K5dpvLQ4SxYksXZ4CHJJ2i7SbNuo0W6RF134='
  inline_citation: '>'
  journal: Future generation computer systems
  limitations: '>'
  pdf_link: http://manuscript.elsevier.com/S0167739X17307677/pdf/S0167739X17307677.pdf
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: 'Towards fog-driven IoT eHealth: Promises and challenges of IoT in medicine
    and healthcare'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/access.2018.2866491
  analysis: '>'
  authors:
  - Ranesh Kumar Naha
  - Saurabh Garg
  - Dimitrios Georgakopoulos
  - Prem Prakash Jayaraman
  - Longxiang Gao
  - Yong Xiang
  - Rajiv Ranjan
  citation_count: 374
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy IEEE.org IEEE Xplore IEEE
    SA IEEE Spectrum More Sites Donate Cart Create Account Personal Sign In Browse
    My Settings Help Access provided by: University of Nebraska - Lincoln Sign Out
    All Books Conferences Courses Journals & Magazines Standards Authors Citations
    ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 6 Fog Computing: Survey
    of Trends, Architectures, Requirements, and Research Directions Publisher: IEEE
    Cite This PDF Ranesh Kumar Naha; Saurabh Garg; Dimitrios Georgakopoulos; Prem
    Prakash Jayaraman; Longxiang Gao; Yong Xiang; Rajiv Ranjan All Authors 360 Cites
    in Papers 14746 Full Text Views Open Access Comment(s) Abstract Document Sections
    I. Introduction II. Overview of Fog Computing III. Difference Between Fog and
    Cloud Computing Paradigm IV. Related Paradigms and Technologies V. Architecture
    of Fog Computing Show Full Outline Authors Figures References Citations Keywords
    Metrics Abstract: Emerging technologies such as the Internet of Things (IoT) require
    latency-aware computation for real-time application processing. In IoT environments,
    connected things generate a huge amount of data, which are generally referred
    to as big data. Data generated from IoT devices are generally processed in a cloud
    infrastructure because of the on-demand services and scalability features of the
    cloud computing paradigm. However, processing IoT application requests on the
    cloud exclusively is not an efficient solution for some IoT applications, especially
    time-sensitive ones. To address this issue, Fog computing, which resides in between
    cloud and IoT devices, was proposed. In general, in the Fog computing environment,
    IoT devices are connected to Fog devices. These Fog devices are located in close
    proximity to users and are responsible for intermediate computation and storage.
    One of the key challenges in running IoT applications in a Fog computing environment
    are resource allocation and task scheduling. Fog computing research is still in
    its infancy, and taxonomy-based investigation into the requirements of Fog infrastructure,
    platform, and applications mapped to current research is still required. This
    survey will help the industry and research community synthesize and identify the
    requirements for Fog computing. This paper starts with an overview of Fog computing
    in which the definition of Fog computing, research trends, and the technical differences
    between Fog and cloud are reviewed. Then, we investigate numerous proposed Fog
    computing architectures and describe the components of these architectures in
    detail. From this, the role of each component will be defined, which will help
    in the deployment of Fog computing. Next, a taxonomy of Fog computing is proposed
    by considering the requirements of the Fog computing paradigm. We also discuss
    existing research works and gaps in resource allocation and scheduling, fault
    tolerance, simulation tools, and Fog-based microser... (Show More) Taxonomy of
    Fog computing based on the requirements. Published in: IEEE Access ( Volume: 6)
    Page(s): 47980 - 48009 Date of Publication: 22 August 2018 Electronic ISSN: 2169-3536
    DOI: 10.1109/ACCESS.2018.2866491 Publisher: IEEE Funding Agency: SECTION I. Introduction
    Individuals and organizations are increasingly becoming dependent on computers
    and smart devices to deal with daily tasks. These devices are generating data
    via various sensors and applications. As a result, organizations are generating
    and storing huge amounts of data on a regular basis [1]. After the proliferation
    of IoT, data generated by sensors has increased enormously. With this sudden increase
    in the volume of data being produced and inability of conventional databases to
    process various forms of structured and unstructured data, big data analytics
    has attained great attention in recent years. Every organization is now prioritizing
    the analysis of collected data to extract useful insights in order to make important
    decisions [2]. Nowadays, organizations need a dynamic IT infrastructure because
    of the shift to cloud computing due to its accessibility, scalability, and pay-per-use
    features. The most common services provided by the cloud are known as Software
    as a Service (SaaS), Platform as a Service (PaaS), and Infrastructure as a Service
    (IaaS), all of which are heading towards Anything as a Service (XaaS) [3]. However,
    data generated from billions of sensors, referred to as big data, cannot be transferred
    and processed in the cloud. In addition, some IoT applications need to be processed
    faster than the cloud’s current capability. This problem can be solved by using
    the Fog computing paradigm, which harnesses the processing power of devices located
    near users (idle computing power) to support utilization of storage, processing,
    and networking at the edge [4]. Fog computing is a decentralized computing concept,
    which does not exclusively rely on any central component like cloud computing
    [5], [6]. It is able to overcome the high latency problem of the cloud by using
    idle resources of various devices near users. However, Fog computing relies on
    the cloud to do complex processing. Unlike cloud computing, Fog computing is a
    decentralized computing concept, where the many devices around us, which have
    computation capacity, are utilized. Currently, even a low- specification smartphone
    has processing capacity, sometimes with multiple cores. Hence, many devices like
    smartphones, switches, routers, base stations, and other network management devices
    equipped with processing power and storage capacity can act as Fog devices. The
    resources of these devices are idle outside of peak hours. Many research issues
    relating to Fog computing are emerging due to its ubiquitous connectivity and
    heterogeneous organization. In the Fog computing paradigm, key issues are the
    requirements and the deployment of Fog computing environment. This is because
    the devices that exist in Fog environments are heterogeneous: therefore, the question
    that arises is how will Fog computing tackle the new challenges of resource management
    and failure handling in such a heterogeneous environment? Hence, it is necessary
    to investigate the very basic requirements for all other related aspects such
    as deployment issues, simulations, resource management, fault tolerance, and services.
    Several reviews [5], [7]–[12] have been done on Fog computing. Here, we present
    the focus and survey domains of these review works in brief. Similar concepts
    of Fog computing, definitions, application scenarios, and numerous issues are
    described by one study [7]. Hu et al. [8] presented the hierarchical architecture
    of Fog computing and technologies like computing, communication, and storage technologies,
    namely resource management, security, and privacy protection that support Fog
    deployment and application. Baccarelli et al. [9] surveyed Fog computing and the
    Internet of Everything (IoE) with an integrated point of view of Fog computing
    and IoE. Varshney and Simmhan [10] reviewed various dimensions of application
    characteristics, system architecture, and platform abstractions of edge, Fog,
    and cloud ecosystems. Perera et al. [11] reviewed the Fog computing domain from
    the platform perspectives of developers and end users towards building a sustainable
    sensing infrastructure for smart city applications. Mahmud et al. [5] presented
    a taxonomy of Fog computing according to the identified challenges and its key
    features. The proposed taxonomy provides a classification of the existing works
    in Fog computing. Mouradian et al. [12] reviewed Fog architecture and algorithms
    based on six different evaluation criteria, namely heterogeneity, QoS management,
    scalability, mobility, federation, and interoperability. However, none of the
    studies had investigated taxonomy based on the requirements of infrastructure,
    platform, and application in Fog computing. Moreover, none of them comprehensively
    investigated fault tolerance, resource management, or microservices in Fog computing.
    We consider the aforementioned current issues and discuss these extensively and
    also highlight how cloud computing-related solutions could be employed in the
    Fog in some cases. The contributions of this review work can be summarized as
    follows: Present the research trends in Fog computing by investigating the number
    of published research works and search occurrences in Google Scholar. Review of
    several Fog computing architectures and presentation of a detailed architecture,
    as most of the previous researchers only presented high-level architecture. Present
    a taxonomy by considering the requirements of infrastructure, platform, and application
    in the Fog computing paradigm. Identify Fog computing research gaps in resource
    allocation and scheduling, fault tolerance, simulation tools, and Fog-based microservices.
    Address the limitations of current research works and some open issues in infrastructure,
    platform, and applications. From this survey, the industry and research community
    will be able to gain insight into the requirements for building a Fog computing
    environment with a better understanding of resource management in the Fog. The
    remainder of this paper is organized as follows: Section II surveys definitions
    and research trends in Fog computing. A technical comparison between Fog and cloud
    paradigms presents in section III. Section IV discusses computing paradigms similar
    to Fog computing. Section V presents related works on Fog computing architecture
    and discusses the components of the Fog computing architecture. Section VI shows
    the taxonomy of Fog computing by reviewing its requirements. Section VII presents
    various application dimension of Fog computing. Section VIII discusses current
    state-of-the-art Fog computing technology. Section IX presents open issues and
    future research direction. Section X concludes the paper. SECTION II. Overview
    of Fog Computing The term ‘Fog computing’ was proposed in 2012 by researchers
    from Cisco Systems [13]. Processing application logic and data at the edge is
    not a new concept. The concept of Edge computation emerged around the 2000s [14],
    [15] and another similar concept, cloudlets, was introduced in 2009 [16]. Both
    Cloudlets and Fog computing are the advancements of a similar concept, which revolves
    around processing at the edge level. While cloudlets are applied in the mobile
    network, Fog computing is applied to connected things such as IoT, which plays
    into the concept of IoT [17]. Fog is both a virtualized and non-virtualized computing
    paradigm that provides networking, storage, and computation services amid cloud
    servers and IoT devices [4], [13]. However, these services are not completely
    located at the network edge. The Fog is a distributed computing approach that
    mainly focuses on facilitating applications, which require low latency services
    [18], Fog computing also supports non-latency aware services. It is obvious that
    using idle computation resources near the users will improve overall service performance,
    if the volume of processing were not that high. A huge number of heterogeneous
    nodes will be connected to the Fog. These nodes include sensors and actuators
    among others [13]. Computation is performed in Fog devices when necessary and
    storage facilities are also available for a short period of time, at least in
    most Fog devices. Time-sensitive computation in the Fog is done without the involvement
    of third parties, and in most cases, is done by the Fog processing devices. According
    to Yi et al. [7], the Fog computing paradigm supports the running of new services
    or basic network functions and applications in a sandboxed environment similar
    to cloudlets. However, the subject is still a research challenge because the question
    of how the Fog will provide these service still remains. In addition, will the
    Fog have cloud service providers or will it be like a single entity as a whole?
    Figure 1 shows a basic model of Fog Computing. Fog devices, Fog servers, and gateways
    are the basic computation components in the Fog environment. Any device that has
    computation, networking, and storage capabilities can act as a Fog device. These
    devices include set-top boxes, switches, routers, base stations, proxy servers
    or any other computing device. Fog servers that manage several Fog devices and
    Fog gateways are responsible for translation services between heterogeneous devices
    in the Fog computing environment. Fog gateways also provide translation services
    between IoT, Fog, and cloud layers. New challenges in this emerging computing
    paradigm have emerged in the past couple of years. FIGURE 1. A model of Fog computing.
    Show All In this section, we discuss the various definitions of Fog computing
    and define Fog computing from our point of view. In addition, we discuss and analyze
    research trends in Fog computing. Finally, we compare the technical differences
    between Fog computing and cloud computing. A. Definition of Fog Computing Fog
    computing is a distributed computing paradigm where processing is done at the
    edge of the network with seamless integration of the cloud infrastructure. It
    enables a computing facility for IoT environments or other latency sensitive application
    environments. It is estimated that about 50 billion “things” will be connected
    to the Internet by 2020 [19]. Transferring all data from all connected devices
    for processing on the cloud will need massive amounts of bandwidth and storage.
    All devices are not connected to the controller via IP but connected by some other
    IoT industrial protocols. Because of this, a translation process is also needed
    for the processing or storing of information from IoT devices. Various researchers
    have defined Fog computing in different ways. Some examples are as follows: “Fog
    computing is a highly virtualized platform that provides compute, storage, and
    networking services between IoT devices and traditional cloud computing data centers,
    typically, but not exclusively located at the edge of network.” [13] “Fog computing
    is a scenario where a huge number of heterogeneous (wireless and sometimes autonomous)
    ubiquitous and decentralised devices communicate and potentially cooperate among
    them and with the network to perform storage and processing tasks without the
    intervention of third parties. These tasks can be for supporting basic network
    functions or new services and applications that run in a sandboxed environment.
    Users leasing part of their devices to host these services get incentives for
    doing so.” [20] “The term Fog computing or Edge Computing means that rather than
    hosting and working from a centralized cloud, Fog systems operate on network ends.
    It is a term for placing some processes and resources at the edge of the cloud,
    instead of establishing channels for cloud storage and utilization.” [21] The
    first definition of Fog computing was presented by Bonomi et al. [13], where they
    addressed the computing paradigm as a highly virtualized platform. However, some
    IoT devices such as smartphones are not virtualized but could also be a part of
    the Fog infrastructure, as some processing could still be done. According to Cisco
    [22], the Fog computing paradigm provides an ideal place to analyze most data
    near the devices that produce and act on that data instantaneously. The Fog is
    located near things that are able to process and act on the data generated. The
    devices that are within the Fog environment are known as Fog devices. These nodes
    can be deployed at any place with a connectivity to the network: on the power
    pole, on the factory floor, alongside the road, alongside the railway line, in
    a vehicle, inside a shopping mall, on an oil rig, etc. A device that has processing,
    storage, memory, and network capability can act as a Fog device. Although the
    Fog extends the cloud, technically it resides in between the cloud and IoT devices
    and handles processing and storage tasks in close proximity to the user. Yi et
    al. [7] stated that the definition given by Vaquero and Rodero-Merino [20] is
    debatable and a definition that can distinguish clearly between Fog computing
    and other related computing paradigms is still required. The definition given
    by IBM [21] represents Edge and Fog computing as the same computing paradigm.
    According to Shi et al. [23], Fog computing focuses more on the infrastructure
    side while edge computing focuses more on the things’ side. Furthermore, Edge
    computing is not spontaneously associated with any cloud-based services such as
    SaaS, IaaS, and PaaS [5]. In brief, Table 1 summarizes Fog definitions provided
    by various research works. TABLE 1 Summary of Fog Computing Definitions Considering
    the above definitions, we define Fog computing as follows: Fog computing is a
    distributed computing platform where most of the processing will be done by virtualized
    and non-virtualized end or edge devices. It is also associated with the cloud
    for non-latency-aware processing and long-term storage of useful data by residing
    in between users and the cloud. In our definition, we considered all devices with
    computing and storage capacity as Fog devices and also more precisely identified
    the role of the cloud in the Fog computing environment. B. Fog Computing Research
    Trends Growing attention towards processing data closer to the users has been
    observed among industries and the academia in the past few years. Handling IoT-generated
    data at the edge level will help improve overall processing time. In this section,
    we investigate Fog and other related technological trends for the past few years
    in the research community. According to the Gartner hype cycle, in July 2017 [24],
    the peak emerging technology is the smart home, which would perform better with
    the incorporation of the Fog computing environment. A Hype Cycle [24] represents
    common patterns of new trending technologies. Fog computing can also enable latency-aware
    smart home services in a more efficient and convenient way, especially for emergency
    response smart home applications. According to the Gartner hype cycle demonstration,
    some other influencing technologies include virtual assistants, autonomous vehicles,
    IoT platforms, smart robots, edge computing, and smart workspaces, which are required
    to support latency-aware applications. All these mentioned technologies could
    benefit from the support of the Fog computing paradigm due to latency sensitiveness,
    connectivity to the cloud, and edge-level data processing capability. Except for
    the autonomous vehicle technology, all other aforementioned technologies will
    reach the market adoption threshold in the next 10 years. Besides the hype cycle
    analysis, we analyzed the search occurrence of Fog and other related technologies
    in Google Scholar. In addition, the number of papers available in different digital
    libraries related to the Fog was also analyzed. Google Scholar search occurrences
    of various similar technologies to Fog were investigated in the past few years,
    as presented in Figure 2. According to the data, edge computing is the topmost
    searched item in Google Scholar compared to other similar technologies. However,
    the search trend decreased by more than three times in the past eight years for
    edge computing. Mobile cloud computing and mobile edge computing are the other
    two top-searched computing paradigm after edge computing. The lowest trend observed
    was for dew computing and Fog dew computing. While the trend for edge computing
    is decreasing, Fog computing related to scholarly searches is increasing year
    by year, and has increased by 2.5 times from 2010 to 2017. This shows that Fog
    computing is the fastest growing research area in academia and will have a great
    impact on the industry as well. FIGURE 2. Search occurrence of similar technologies
    like the Fog in Google Scholar. Show All Fog computing topic search in the Web
    of Science shows that the number of scholarly articles has more than doubled between
    2015 and 2016, as per Figure 3. The first paper with ‘Fog computing’ in its title
    was published in 2012. Since then, about 564 journal and conference articles have
    been published on this topic in the four major digital libraries (Web of Science,
    Science Direct, IEEE Xplore, and ACM), as presented in Figure 4. Cloud computing
    first emerged in 2008 [25]. This shows that Fog computing publications have dramatically
    increased, as no study in this area was seen in the couple of years following
    the introduction of cloud computing research in 2008 (see Figure 5). FIGURE 3.
    No. of Fog computing-related papers in the Web of Science (as Feb 2018). Show
    All FIGURE 4. Number of publications with ”Fog computing” in the title in the
    four major digital libraries. Show All FIGURE 5. Published articles with the title
    cloud computing in the Web of Science. Show All From our observation, it is obvious
    that the interest in Fog computing research is rapidly increasing. Idle resources
    in the form of devices near users can be utilized within the Fog computing concept.
    Thus, a clear direction to market the adoption and technological development of
    Fog deployment has emerged. SECTION III. Difference Between Fog and Cloud Computing
    Paradigm Fog computing architectures are based on Fog clusters where multiple
    Fog devices participate to cooperate with the processing. On the other hand, datacenters
    are the main physical components of clouds. Because of this, cloud computing has
    high operational costs and energy consumption. By comparison, energy consumption
    and operation costs in the Fog computing paradigm is low. The Fog is located closer
    to the user, so the distance between users and Fog devices could be one or a few
    hops, which is also agreed by Hu et al. [8]. However, according to Mahmud et al.
    [26], the distance between users to the Fog is one or two hops. Again, Luan et
    al. [27] argued that the distance should be one hop with wireless connectivity.
    Yet, all agreed with the distance between the users to the cloud, which is a multi-hop
    distance. Due to the distance, communication latency for the cloud is always high
    compared to the Fog. The cloud is a more centralized approach while the Fog is
    a more distributed approach based on geographical orchestration [26]. Real-time
    Interaction is not possible for the cloud due to its high latency, but this problem
    can be easily resolved by Fog computing. On the other hand, the rate of failure
    in the Fog is high because of wireless connectivity, decentralized management,
    and power failure [26], [28]–[30]. Most devices in Fog environments will be connected
    wirelessly since smart gadgets and handheld devices will be participating in Fog
    systems [31]. These devices, and other network management devices, are mostly
    decentralized. These devices could fail when software is not managed correctly.
    Users may not be aware of malicious software that could lead to device failure.
    Moreover, Fog processing could fail in other cases as well, for example, each
    Fog device is responsible for performing its own application processing. So, the
    IoT application processing in a Fog device always takes second priority. If the
    Fog device is fully utilized by the application of the device itself, then it
    will fail to do any Fog processing. Hence, the scheduling of applications and
    resources in the Fog is more complex. In addition, failure handling in the Fog
    is competitive because of power failure, which is only an issue because the devices
    run on battery power. Altogether, Table 2 shows the technical differences between
    the cloud and the Fog. TABLE 2 Technical Difference Between Fog and Cloud Definitely,
    it cannot be said that the Fog can replace the cloud. We cannot even conclude
    that the Fog is better than the cloud either, both contribute differently via
    fulfilling different perspectives and requirements. SECTION IV. Related Paradigms
    and Technologies Fog computing uses computing resources near underlying networks,
    located between the traditional cloud and edge devices, to provide better and
    faster application processing and services [13]. Several similar computing paradigms
    exist besides Fog computing such as Mobile Cloud Computing (MCC), Mobile-Edge
    Computing (MEC), Edge Computing, Dew Computing, and Fog-dew computing. In cloud
    computing, all IoT devices are directly connected to the cloud and computation
    totally depends on the cloud. However, all the above similar technologies do not
    exclusively depend on the cloud, but depend on some intermediate devices for computation;
    some of them do not even require a connection to the cloud. Figure 6 shows the
    high-level architecture of these technologies. FIGURE 6. High level architecture
    of Mobile Cloud Computing (MCC), Mobile Edge Computing (MEC), Edge Computing (EC),
    Dew Computing (DC), Fog Computing (FC) and Fog Dew Computing (FDC). Show All A.
    Mobile Cloud Computing (MCC) Remote execution of offloaded mobile services is
    done with the support of MCC near end users [32], [33]. MCC overcomes the computational,
    energy, and storage resource limitation of smart mobile devices. Generally, a
    lightweight cloud server (cloudlet) is placed at the edge of the network [34]
    to overcome these issues. MCC is a mobile computing technology, which provides
    unrestricted functionality, mobility, and storage facility through heterogeneous
    network connectivity. This technology also provides unified elastic computing
    resources by following the pay-per-use model. It also provides access to data,
    application, and cloud via the Internet for mobile users. It is expected that
    this technology will be applied in education, urban and rural development, healthcare,
    and more realistic social networking in the future [32]. Nowadays, many computation-intensive
    applications are widely available, such as Augmented Reality, computer vision
    and graphics, speech recognition, machine learning, planning and decision-making,
    and natural language processing applications. However, simply designing powerful
    mobile devices will not meet the requirements for these applications [33]. Rather,
    the applications require edge processing as well as collaboration with the cloud
    for complex processing. Thus, mobile computing demands fundamental changes to
    cloud computing, for example, a low-latency middle tier, programming models to
    enable seamless remote execution, basic mobile cloud services such as presence
    services, cloud infrastructure optimization for mobile applications, memcache
    services, and so on [33]. The convergence of mobile cloud computing is predicated
    on a reliable, end-to-end network, and high bandwidth, which isdifficult to guarantee
    in harsh environments. One of the solutions to this deep-rooted problem is the
    VM-based cloudlets located at a closer location to the mobile device [34]. B.
    Mobile Edge Computing (MEC) MEC proposes the co-location of computing and storage
    resources at the base stations of cellular networks [35]. MEC could either be
    connected or disconnected to cloud datacenters in a remote location. Hence, MEC
    supports two- or three-tier hierarchical application deployments along with end
    mobile devices [36]. In a MEC ecosystem, a new device called the MEC server needs
    to be deployed near base station towers to provide processing and storage capabilities
    at the edge. Four participants are involved in this computing paradigm, which
    are the mobile end users, network operators, Internet infrastructure provider
    (InPs),and application service provider. Mobile end users are the main consumer
    of the system and request their service via user equipment (UE). Network operators
    manage and maintain the operation of base stations, mobile core network, and MEC
    servers. InPs maintain Internet connectivity and routers. Application service
    providers host the application services in the content delivery networks (CDN)
    or within a data centers. Processing of requests from the UE will search out the
    closest MEC. The MEC server is capable of processing user request instead of forwarding
    it to remote Internet services. In a case where it is not possible to process
    or complete a request at the MEC sever; the request will be forwarded to remote
    CDNs or data centers [35]. According to Klas [36], MEC is the evolution of mobile
    base stations. It is a natural development. It is a collaborative deployment of
    telecommunication and IT networking. This computing paradigm enables new vertical
    business segments and services to individual end users and enterprise consumers.
    Various services could be delivered through this computing paradigm including
    IoT, location services, augmented reality, caching service, video analytics, and
    local content distribution. It can deliver real-time low-latency access of local
    content or by caching content at the MEC server. However, the main limitation
    of this system is the installation of the MEC server, which is specifically dedicated
    to MEC services. Scaling is another big issue with the increase in resource demand
    over time. C. Edge Computing Edge devices or edge servers provide computation
    facilities in Edge computing. In general, edge computing does not spontaneously
    associate with any types of cloud-based services and concentrates more on the
    IoT device side [23]. One study defined the edge as any network or computing resource
    near the path between cloud data centers and data sources [23]. Any smart device
    or sensor could have data sources but the edge is different. For example, a cloudlet
    and a micro datacenter is the edge of the mobile application and cloud, whereas
    the IoT gateway is the edge between IoT sensors and cloud. Similarly, if a cloud
    application is running on a smartphone, then the smartphone is the edge of the
    application and the cloud [37]. The main motivation of edge computing is that
    the computation should be done at a closer location to the data sources. In the
    edge computing concept, things are not only consuming data but also produce data
    by taking part in processing. Edge devices can perform computation task from the
    cloud besides requesting services and content. Data storage, computing offloading,
    processing, and caching will be done by an edge node. The edge device is also
    capable of distributing requests and providing service on behalf of the cloud
    to the users. In such scenarios, edge devices need to be well designed to meet
    privacy requirements, reliability measures, and security concerns [23]. D. Dew
    Computing (DC) In the current computing hierarchy, Dew Computing [38] is situated
    at the ground level of the cloud and Fog computing environment [39]. DC goes beyond
    the concept of service, storage, and network, to a sub-platform, which is based
    on a microservice concept for which its computing hierarchy is vertically distributed
    [39]. The DC approach facilitates resources such as sensors, tablets, and smartphones
    that are seamlessly connected to a network. Because of this, DC covers a wide
    range of ad-hoc-based networking technologies [39]. Skala et al. [39] argued that
    DC is much more useful in everyday life compared to Fog computing. Fog supports
    IoT-based applications, which demand less latency and real-time capability and
    a dynamic network configuration while DC is microservice concept and thus is not
    dependent on any centralized device, server, or cloud. They provide an example
    in which DC could be integrated into a smart traffic control system, where data
    collection and processing units will be located in between the traffic signals.
    These units generate a collective overview of the current traffic conditions.
    In such a way, a car with low fuel will be notified before entering heavy congestion,
    or a hybrid car will be informed of switching to conventional fuel before approaching
    the congestion. As a result, cars with less fuel will be rescued from unwanted
    situations and hybrid cars could reduce exhaust smoke densities significantly.
    Although the concept is microservice-based, the processing is completed in Fog
    devices. In the Fog computing concept, it is not crucial that applications must
    be dependent on the cloud or require the storing of results in the cloud. On the
    other hand, if such traffic processing information were stored, it would help
    strategic decision-making to improve traffic management. Dew computing is an emerging
    research area and its goal is to use the full potential of cloud and local resources
    [40]. E. Fog-Dew Computing In the architecture of Fog-dew computing, IoT devices
    need not have an active Internet connection while being connected to the community
    server. The community server will interact with the cloud and is responsible for
    providing services to the IoT devices [41]. Cloud computing always needs an Internet
    connection, which is the main drawback of the cloud. While the cloud is unable
    to serve users without an Internet connection, Fog-dew computing facilitates offline
    services without an Internet connection. However, there are some exceptions. For
    example, the navigation app, Waze, allows users to navigate offline. This feature
    was also recently added to Google Maps. In this case, a map information file for
    a specific area is downloaded to the user device and allows users to navigate
    during an offline state. Another example is Google Drive and Dropbox, where users
    can delete, create, and update files and folders in offline mode and then sync
    once the device is connected to the Internet. However, these services are not
    purely offline-we may not rely on the Internet directly but we cannot completely
    ignore Internet connection. The situation becomes more complex when a single user
    uses multiple offline devices alongside the complexity that arises in a multiuser
    environment. Such situations could be mitigated with the help of Fog-dew computing.
    In summary, in the Fog computing paradigm, IoT devices are connected to the cloud
    via Fog devices. Fog devices are connected to the cloud through the core network.
    Fog computing is a combination of MEC and MCC [7] but the main goal of all Fog-related
    paradigms is to perform processing at the edge. These related paradigms differ
    from each other based on Internet and cloud connectivity. Also, the amount of
    processing that needs to be done at the edge differs based on service requirements.
    Furthermore, the type of devices that will be used for computation and storage
    purposes is also another issue. In summary, Table 3 shows the characteristics
    of the above-discussed related computing paradigms along with the Fog computing
    paradigm. TABLE 3 Summary of Similar Technologies Like Fog SECTION V. Architecture
    of Fog Computing For market adoption and deployment, Fog computing must have a
    standard architecture. There is no available standard architecture to date. However,
    many research works have presented Fog computing architectures. In this section,
    we firstly discuss the high-level architecture of Fog computing. Furthermore,
    we summarize some proposed architectures for Fog computing. Finally, we present
    a detailed architecture for Fog computing with a comprehensive description of
    each component of the architecture. A. High-Level Architecture of Fog Computing
    In high-level architecture, the Fog computing paradigm has three different layers,
    as shown in Figure 7. The most important layer is the Fog layer. This layer consists
    of all intermediate computing devices. Traditional virtualization technologies
    can be used at this plane, similar to the cloud. However, considering the resource
    availability, employing container-based virtualization is more appropriate. This
    layer accumulates sensor-generated data from the IoT layer and sends an actuation-related
    request after processing. Although it seems that the big data problem is solved
    by processing generated data at the edge level, billions of devices will create
    big data issue. In fact, it is possible to employ small- and medium-scale big
    data processing at this level. Many research works have been undertaken to process
    big data in the Fog plane [47]–[53]. FIGURE 7. High level Fog computing architecture.
    Show All The bottommost layer is the IoT plane, which consists of all connected
    devices. The devices on this plane perform the sensing and actuation process.
    For time-sensitive applications, processing should be done on the Fog plane exclusively
    while the cloud can perform other processing that is not time-sensitive. However,
    the Fog layer will manage what needs to be sent to the cloud and what should not.
    The users are able to get services from both the Fog and cloud based on their
    request. However, the cloud plane will manage complex processing and storage.
    B. Various Proposed Architectures for Fog Computing Layered representation is
    the best way to represent Fog architecture. Many works have been done to quantify
    the layer-based concept of Fog architecture [4], [27], [54]–[58]. From our review,
    we found that researchers have proposed three [27], [56]–[58], four [55], five
    [4], and six [54] layers in the Fog architecture. Everyone has their own justifications
    for their claims. If we ignored the user plane, it is obvious that Fog architecture
    could be defined as three different levels from the high level. As we proceed
    to the more implementation-type level, the number of layers in the architecture
    would vary, giving rise to five [4] and six [54] levels in the Fog computing layer.
    Aazam and Huh [54] presented six different layers based on specific tasks. On
    the other hand, Dastjerdi et al. [4] defined five different layers based on network
    perspective. Other high-level architectures in Fog computing were also presented
    by various researchers including the hierarchical Fog architecture [59], [60],
    OpenFog architecture [61], Fog network architecture [62], Fog architecture for
    Internet of energy [9], Fog computing Architecture based on nervous system [63],
    and IFCIoT architecture [64]. After reviewing the literature stated above, we
    define the components of Fog computing architecture, which is presented in the
    following subsection. C. Components of Fog Computing Architecture Fog computing
    architecture consists of several layers. Each layer and its components are shown
    in Figure 8. In this subsection, we discuss various components of the Fog computing
    architecture. The components are divided into several groups based on their functionality,
    which is defined as the layer. These functionalities will enable IoT devices to
    communicate with various Fog devices, servers, gateways, and the cloud. A detailed
    explanation of each layer is given below, where a smart transportation use case
    is considered in the explanation. FIGURE 8. Components of Fog computing architecture.
    Show All 1) Physical Layer The basic data source for Fog computing is the various
    forms of data emitted by the sensors [57]. These data could be generated from
    smart devices, temperature sensors, humidity sensors, smart homes, the CCTV surveillance
    system, traffic monitoring system, self-driving vehicles, and so on. For instance,
    if we wanted to implement a smart traffic management and monitoring system, we
    need to get updated traffic conditions of all roads from various sensors, roadside
    devices, and cameras, which will help manage traffic signals. It is also necessary
    to predict future traffic demand by collecting data from various GPS sensors.
    Besides physical sensors, the role of virtual sensors is also important [54],
    if a road accident occurred, it would not be possible to decide using just a single
    sensor whether the road should be blocked or traffic should keep going. The road
    might have one or more lanes- one lane may be affected by this occurrence while
    another lane could enable the traffic flow to continue, but the traffic handling
    capacity will be decreased due to this occurrence. In this case, a virtual sensor
    might help obtain an immediate decision on road conditions, traffic multiplexing,
    and traffic rerouting. Hence, the physical layer consists of physical and virtual
    sensors, where any data generation device could fall into any of these groups.
    2) Fog Device, Server, and Gateway Layer The Fog device, Fog server, or Fog gateway
    could be a standalone device or an IoT device [57], [59], [62]. However, it is
    obvious that the Fog server should have a higher configuration than the Fog device
    and gateway since it manages several Fog devices. Various factors are involved
    so that the Fog server can run. These include its role, hardware configuration,
    connectivity, number of devices it can manage, and so on. Whether the Fog server
    is distinct or part of an IoT device is defined by its role. A group of physical
    and virtual sensors will be connected to a Fog device. Similarly, a group of Fog
    devices will be connected to a Fog server. In this context, the Fog server should
    have higher processing and storage capacity compared to the Fog device. A specific
    cluster of Fog devices, which are connected to the same server, can communicate
    with each other when required. In the smart transportation use case, some application
    processing might depend on other Fog clusters. For example, if an application
    needed to find a fuel-efficient route, it might need information about other sensor
    clusters or Fog device clusters. To reach an appropriate decision, processing
    needs to be done in multiple Fog devices and servers. The Fog server and device
    layer are responsible for managing and maintaining information on hardware configuration,
    storage configuration, and connectivity of device and servers. This layer also
    manages the computation requirements requested by various applications. Computation
    requirements depend on data flow and the total number of IoT devices connected
    to the Fog device, as well as the total number of Fog devices connected to the
    Fog server. The communication between several Fog servers is maintained by this
    layer. For example, a Cisco IOx-supported 800 series router can be used as a Fog
    device and Cisco Fog data service devices can be used as the Fog server [65],
    [66]. 3) Monitoring Layer The monitoring layer always keeps track of the system
    performance and resources [54], services, and responses. System monitoring components
    help choose the appropriate resources during operation. Various applications run
    in smart transportation system scenarios. Therefore, it is obvious that a situation
    could arise when resource availability will be negative for computation or storage
    on a Fog device. A similar case could happen to the Fog server. To tackle these
    kinds of situations, the Fog device and servers will seek help from other peers.
    Thus, the system monitoring component will help decide such things efficiently.
    The resource demand component monitors current resource demand and can predict
    future demand for resources based on current resource usage and user activities.
    In this way, the system will be able to deal with any awkward situations where
    resource outage might occur. Performance prediction monitors can predict Fog computing
    performance based on system load and resource availability. This component is
    required to maintain appropriate QoS requirements in service level agreements.
    If SLA violation occurs frequently, then the cost of the system for the provider
    will be increased because of the penalty. Although performance prediction cannot
    eliminate this issue completely, it will be able to minimize overall SLA violation
    by predicting the performance and usage of the system. 4) Pre and Post-Processing
    Layer This layer contains multiple components, which specifically work on basic
    and advanced data analysis. At this level, acquired data are analyzed and filtered,
    and data trimming and reconstruction are also done when necessary. After processing
    the data, the data flow component decides whether the data needs to be stored
    locally or should be sent to the cloud for long-term storage [59]. The main challenge
    in Fog computing is to process data at the edge and minimize the volume of data
    that needs to be stored; this phenomenon is referred to as stream processing.
    In the smart transportation system use case, data will be generated from many
    sensors. These generated data will be analyzed and filtered in real time to get
    insight into the generated data. All generated data might not have any use. In
    some cases, it would not even be a good idea to store all generated data. As an
    example, if data is generated from a sensor each second, the mean value of data
    within a minute or within an hour may be stored depending on application requirements.
    Data can be trimmed in this way and a vast amount of storage space can be saved.
    In another case, if the difference among data values in some period of time is
    not that big, but might affect performance, then less numbers of reading within
    a minute can be taken. In such a way, it will be possible to filter a vast amount
    of generated data. Although the accuracy may not be 100%, application requirements
    might still be fulfilled to some extent. Data reconstruction is one of the components
    of this layer. This module takes care of faulty and incomplete data generated
    by the sensors. Similarly, if one or more sensors fail during operation, this
    component will reconstruct the data based on the data generation pattern to prevent
    interruption or any other application failure. 5) Storage Layer The storage module
    is responsible for storing data through storage virtualization. The data backup
    component ensures availability of data and mitigates the loss of data. In the
    storage virtualization concept, a pool of storage devices connected by a network
    acts as a single storage device, which is easier to manage and maintain. One of
    the key benefits of storage virtualization is to provide enterprise-class functionality
    using less-expensive storage or commodity hardware. Thus, the storage layer facilitates
    storage virtualization in order to minimize the complexity of the storage system.
    In a system, storage might fail at any point during system operation [67]. Therefore,
    it is crucial to backup important data to mitigate any unwanted situations. The
    data backup module in this layer takes care of periodic or customized data backup
    schemes. 6) Resource Management Layer The components in this layer maintain the
    allocation of resources, and scheduling, and deal with energy saving issues. The
    reliability component maintains the reliability of application scheduling and
    resource allocation. Scalability ensures the scalability of Fog resources during
    peak hours where resource demand is high. The cloud deals with horizontal scalability
    while Fog computing aims to provide both horizontal and vertical scalability [9].
    There are many distributed system resources for network, processing, and storage.
    This is a critical issue for distributed resources, which use application processing.
    Thus, resource allocation, deallocation, and reallocation will happen in which
    the resource allocation component manages and maintains resource allocation related
    issues. Another vital issue is that many applications will run in the Fog computing
    environment simultaneously. Hence, proper scheduling of these applications is
    required. The application scheduling component takes care of these applications
    based on various objectives. This layer also has energy saving components, which
    manage resources in an energy-efficient manner. Energy efficiency also positively
    affects the environment and helps minimize operational cost. Reliability components
    handle the requirement for the reliability of a system based on various reliability
    measures and metrics. Fog computing is a complex system that needs to take care
    of all IoT devices, Fog devices, and the cloud. Therefore, a device or connection
    might fail at any level, so reliability management is an important issue. 7) Security
    Layer All security-related issues such as encryption of communications and secure
    data storage will be maintained by the components in this layer, which also preserve
    the privacy of Fog users. Fog computing is intended to be deployed as a form of
    utility computing like cloud computing. However, in the cloud computing concept,
    the user connects to the cloud for services, but in the Fog computing concept
    the user will connect to the Fog infrastructure for the services while the Fog
    middleware will manage and maintain communications with the cloud. Hence, a user
    intending to connect to a service must be authorized by the provider. Therefore,
    the authentication component in the security layer processes authentication requests
    from users, so they can connect to the Fog computing service environment [27].
    To maintain security, it is crucial to maintain encryption between communications,
    so that security breaches by outsiders will not occur. The encryption component
    encrypts all connections from and to IoT devices and to the cloud. Fog computing
    components are mostly connected via a wireless connection, so security concerns
    are crucial. Some services in a smart city or smart house privacy are also an
    issue because of the involvement of user-related data in these types of systems.
    The Fog computing paradigm should not disclose user information without their
    consent. In the current age, the majority of users normally accept the security
    policy of the provider without reading it. Thus, special consideration of privacy
    should be undertaken for such services that involve user-related critical information.
    8) Application Layer Although the Fog was developed to serve IoT applications
    [58], several other applications based on Wireless Sensor Network (WSN) and CDN
    also support Fog computing. Any application that has latency-aware characteristics
    will be able to take advantage of Fog computing. This includes any type of utility-based
    service that could fit within Fog computing by providing better service quality
    and cost-effectiveness. For example, Augmented Reality-based applications should
    adopt Fog computing because of its nature. It is clear that Augmented Reality
    will transform the modern world in the near future. The needs of real-time processing
    for Augmented Reality applications can be addressed by Fog computing, which can
    maintain continuous improvement of Augmented Reality-related services. SECTION
    VI. Taxonomy of Fog Computing The Fog computing taxonomy is presented in Figure
    9. This taxonomy is derived by considering existing literature and the overall
    viewpoint on Fog computing. The proposed taxonomy focuses on the requirements
    perspective for infrastructure, platform, and application. FIGURE 9. Taxonomy
    of Fog computing based on the requirements of infrastructure, platform, and applications.
    Show All Firstly, by considering infrastructure, we identify infrastructure and
    network requirements, and the types of devices in a Fog computing environment.
    Secondly, for platform resource allocation and scheduling, security and privacy
    concern, service requirements, management, and multitenancy were determined. Finally,
    we defined application requirements, user requirements, and application modeling
    taxonomy for Fog computing. This taxonomy will help the research community and
    enterprises to gain better understanding and insight into the real-world deployment
    of Fog computing requirements, architecture, and devices. Figure 9 shows the taxonomy
    of Fog computing. A detailed description of each branch of the taxonomy is presented
    in this section. A. Infrastructure Fog computing infrastructure requirements depend
    on the network, devices, and their requirements. All Fog devices, network devices,
    and gateways existing in the Fog environment that participates in computation
    are also part of the Fog infrastructure. Infrastructure denotes the physical components
    of the Fog environment. 1) Infrastructure Requirements The many connected tiny
    devices are the primary elements in a Fog computing environment. These devices
    are located everywhere and help to connect all things around us. It is estimated
    that the world will see 50 billion handheld devices by 2020. Beside these devices,
    a huge number of sensors and actuators will also be put in place. Therefore, a
    proper infrastructural facility is needed to support this vast computing environment
    [20]. An example of how the number of sensors is increasing day by day is given
    in The Economist report titled, “Augmented Business”, which describes the implant
    sensors on cattle ears that could help to monitor their activity, health, and
    movements. This could help increase overall productivity. The implant of sensors
    affixed in one cow produces about 200 MB of information in a year. In another
    example, with sensor technology, Rolls-Royce is able to forecast when engines
    will more likely fail. From such a prediction, customers can plan engine changes.
    Heidelberger Druckmaschinen has huge printing presses equipped with more than
    1,000 sensors. These are the examples of distinct uses of sensors in specific
    domains. However, this phenomenon will change completely when the distinct parts
    are connected to generate more efficient and effective decisions. Therefore, the
    Fog infrastructure must have the capability to provide physical resources for
    computation, networking, storage, and memory to achieve efficient Fog computing
    services. 2) Network Requirements The network is one of the key bottlenecks in
    the Fog computing environment, where billions of connected devices generate and
    consume data at the edge of the network [68]. Most of the sensing and actuating
    devices require low bandwidth but a higher number of devices will be connected
    at the same time. Therefore, existing network connection technologies like LAN,
    MAN, WAN, or PAN need to be investigated further and amendments will be needed
    to cope with the Fog computing environment to facilitate countless IoT devices.
    Network operators are increasingly investing in new wireless access technology
    research because of the number of devices per user is increasing day by day. For
    instance, in the cellular mobile network, base stations have a limited number
    of link points [20]. As the number of things increase, these stations will need
    to support increasing numbers of devices. Fog devices must act as a router for
    neighboring IoT devices and as a primary processing unit for IoT application in
    the Fog environment. Each Fog device should have a resilient connectivity to the
    lower and upper layer devices. Mobile ad-hoc networks could act as a basis for
    the Fog network because of their mobility and lower cost feature [20]. Hence,
    connection and mobility are the main requirements for the Fog network. 3) Fog
    Devices Fog computing is basically intended to support IoT-related technologies
    to perform processing at the edge level. Mine projects [69], [70] at the middle
    of the sea, airline fleets or a ship [70] can be equipped with a huge number of
    sensors, so it is impossible to send and store all generated data in real-time
    into the cloud. Some intermediate computation, processing, and services will be
    done by Fog computing devices. Thus, the Fog layer must have sensor management
    devices, Fog processing, and storage devices and Fog gateway devices. All of these
    devices will work collaboratively to manage and perform tasks in the Fog plane.
    Here, we discuss the devices that are needed for Fog computing deployment. a:
    IoT Devices IoT devices are the devices that have sensing and actuating capability.
    A sensor is able to sense the environment, while an actuator acts on it when necessary.
    One of the most common types of sensor in IoT devices is the temperature sensor.
    The temperature sensor has various functions depending on different domains such
    as at home, in factories, and in the agriculture field. This sensor is also used
    to sense the temperature of soil, water, and plants in order to take proper action
    needed to improve service outcome. Another type of useful sensor is the pressure
    sensor, used especially in agriculture, smart vehicles, and aircrafts. Sensors
    are also used to estimate the volume of water used by the agricultural sector
    for cultivation and other uses. Surprisingly, a huge percentage of this water
    is wasted due to leaky irrigation systems and inefficient use of fresh water.
    Efficient use of the pressure sensor will help solve this problem. The pressure
    sensor is able to determine the flow of water and reduce water waste. The pressure
    sensor is also used in smart vehicles to determine the forces acting on it, and
    in aircrafts to determine altitude. Different groups of sensors are used for different
    IoT environments. For example, in healthcare, the most-used sensors are chemical,
    IR, pressure, and temperature sensors as well as other biosensors. On the other
    hand, in a smartphone, the most-used sensors are the gyroscope, GPS, and proximity
    sensors. One of the applications of the proximity sensor is to determine the presence
    of ear to dim or turn off the phone backlight to improve battery efficiency. This
    sensor is also used to monitor parking space since it can determine the presence
    of an object without touching it. It can also be used in a wide temperature range
    and is not affected by color. Its detection process also is not effected by dirt,
    oil, or water. There are many other sensors out there that enable IoT, which include
    GPS sensors, water quality sensors, level sensors, chemical/gas sensors, smoke
    sensors, IR sensors, humidity sensors, sound and vibration sensors, motion sensors,
    acceleration sensors, and machine vision sensors. There are five main types of
    actuators-magnetic or thermal, electrical, hydraulic, pneumatic, and mechanical.
    The actuator has a controlling or moving mechanism, a motor, which acts on various
    inputs. The raw application data comes from various sensors like speed sensors,
    cameras, temperature sensors, vehicle monitoring sensors, or GPS sensors. A typical
    sensor generates 10 data samples every second [71]. Sensors convert environmental
    variables such as smoke, heat, light, temperature, humidity, sound, and so on
    into electrical signals. These sensors are varied and can be micro-electro-mechanical
    systems (MEMS)-based, CMOS-based or LED sensors. Communication among sensors could
    be done by ZigBee, Bluetooth, Z-Wave or 6LoWPAN standards for short distance communication
    [72]. There is a necessity for communication among sensors in some cases where
    one sensing output is dependent on other collective sensor outputs. These sensors
    will be connected to Fog devices through wireless connections. However, Fog devices
    collect and process data based on application requirements. Some example of research
    works based on sensors can be improved by taking advantage of Fog computing. Aziz
    et al. [73] proposed a real-time health monitoring system using particular sensors
    in which the proposed architecture was based on GSM and GPS technologies. The
    system specifically monitors the body temperature and blood pressure of patients.
    The study used an Arduino microcontroller, dfrobot GPS/GPRS/GSM module v3.0.3,
    a heartbeat pulse sensor, and a lilypad temperature sensor for hardware implementation.
    In another study, a web-based application was developed for doctors and nurses
    with SMS functionality, which will be used as an emergency case. The system is
    able to generate GPS location, body temperature, and blood pressure. Butt et al.
    [74] investigated wearable technology such as SensHand, Gloves-based system, electromyography-based
    and hybrid systems, leap motion, and smartwatches. The development of these kinds
    of technology must be integrated with the smart home system and Fog-like architecture
    in order to deal with emergency situations. Some devices such as the smartphone
    can be considered as both an IoT and Fog device. In the same way, if some sensors
    and actuators were installed in the Raspberry Pi, the device could also act as
    both an IoT and Fog device. b: Fog Processing Devices Any device that has computing
    capability, storage, and network connectivity can act as a Fog processing device.
    It could be a network controller, switch, router, server, or a video surveillance
    camera. A Cisco 800 series router can be used as a Fog device where the IoT application
    can be run on the device and the device supporting Cisco IOx. To date, only Cisco
    800 series routers are supporting IOx with Linux kernel with virtualization support
    [44]. Most of these devices have a 266-400 MHz MPC8272 processor with 16 KB Cache,
    64 MB random access memory and 20 MB processor board flash memory. The user can
    host an application on these routers. These routers have two cores-Cisco IOS runs
    on one core and another core is used for running IOx services. Another type of
    Fog processing device is the Fog server. A Fog server can control several Fog
    devices in a specific domain. Cisco offers two flavors of Fog computing server
    deployment. One is the Cisco Fog Director, which can be deployed on any type of
    server with Cisco-recommended server specifications [66]. Another example of a
    Fog device manufactured by Cisco is the Fog data services, which are specifically
    designed for IoT [65]. However, Cisco Fog data services can only be deployed on
    Cisco UCS E and C Series Servers. Both will act as Fog servers; however, Cisco
    Fog data services are especially designed for an IoT environment. However, various
    organizations and bodies need to work beyond the proprietary solutions for fast
    technological advancement and technology adoption with a limited budget. Fog devices
    and Fog servers should be deployed in such a way that any type of network management
    device with storage and processing capability can act as a Fog device. Similarly,
    the usual type of server must be able to act as a Fog server. This could be an
    ordinary PC since Fog is not dedicated to performing very complex processing.
    However, further investigation is necessary to explore the minimum system requirement
    for a device that can act as a Fog device or Fog server. Connectivity between
    Fog devices and Fog servers will be via Ethernet or wireless or a serial connection
    in some cases. As an example, Cisco UCS E and C Series Servers, which are generally
    used as Fog servers, are connected to the network via Ethernet. On the other hand,
    Cisco 800 series routers are connected via serial ports that support Fog computation.
    c: Gateway Devices for Fog Many hardware boards are currently available in the
    market including Arduino Yun, Intel Edison, Raspberry Pi, Beaglebone Black, Arduino
    + Shields, Netduino, Tessel 2, and so on. These boards are currently used as IoT
    and gateway devices and can also be used as Fog gateway devices and as Fog devices.
    These boards have a built-in processor, wired and wireless adapter, and a USB
    port. Fog computing supports device heterogeneity, where a gateway could also
    be a part of the Fog computing environment. Constant et al. [75] developed a Fog
    gateway using Intel Edison and Raspberry Pi. Their proposed Fog gateway integrated
    the data conditioning process, smart analytics, intelligent filtering, and transfer
    to the cloud, which needs long-term storage and temporal variability monitoring.
    The IoT gateway supports various data types and communication protocols between
    devices and sensors. It also unifies the data format from various sensors. Current
    IoT gateways provide a solution for communication and do not support fully automatic
    configurations of newly added IoT devices [76]. Guoqiang et al. [77] proposed
    a smart IoT gateway with three key benefits. The proposed gateway has a unified
    external interface and pluggable architecture. It has a flexible protocol to translate
    various sensor data into a uniform format. The study designed a customized device
    with a Samsung S5PV210 mobile application processor as its gateway. However, this
    gateway did not have any fault tolerance or security features. B. Platform The
    platform manages applications and infrastructure in the Fog environment. It takes
    care of resource allocation, scheduling, fault tolerance, multi-tenancy, security,
    and privacy in Fog computing. Based on the taxonomy of the Fog, we discuss the
    requirements of the platform for Fog computing in this section. 1) Resource Allocation
    and Scheduling Heterogeneous devices are the main challenges in developing proper
    resource allocation and scheduling in the Fog. If we wanted to use the computation
    power of idle devices, we need to schedule tasks on these devices efficiently.
    Otherwise, IoT application processing in the Fog will face complex issues, which
    will hinder the fulfillment of the latency awareness goal. Two of the key requirements
    for resource allocation and scheduling are availability and efficiency. Resources
    in the Fog are not dedicated, and thus availability should be ensured. On the
    other hand, lack of efficient resource allocation and scheduling might lead to
    unwanted delays in the overall processing. 2) Service Requirements Fog services
    can be defined as single or multiple user requests, where the user will constantly
    be updated of the outcome of the service until he or she has a subscription to
    that service. This means that the service outcome will not be fixed and will keep
    changing until the end of the service. The Fog device and Fog server perform the
    intermediate processing, which occurs in between user request and service output.
    The Fog server may communicate with the cloud for processing and information retrieval
    when necessary. For instance, if we considered selecting the best path based on
    real-time traffic in a smart transportation system, the Fog service will keep
    updating on the best path until the end of the journey. In this case, we need
    to take into account mitigation of fault, service quality, network latency, and
    power consumption in order to maintain the standard of the service. a: Fault Tolerance
    Fault tolerance allows a system to keep performing even when a part of the system
    has failed. This failure might be software failure, hardware failure, or network
    failure. The solution for fault tolerance will result in a fully operational system
    where the system will continue its operation with a lower capability instead of
    shutting down totally [78]. Fault tolerance is mostly investigated in the cloud
    [79]–[89]. However, it is necessary to investigate fault tolerance in the Fog
    as well. Although many research works have addressed the need to explore fault
    tolerance issues [5], [9], [64] in Fog computing, none have actually investigated
    the issue. We discuss in more detail the issue of fault tolerance in Section VIII-B.
    b: Quality of Service (QoS) QoS is an important service requirement for Fog computing,
    which is based on reliability, network delay, throughput, and energy consumption.
    Besides these, resource management, power-consumption model, scheduling policy,
    and power failure handling are also important to ensure QoS. If some sensors fail
    for any reason, the accuracy of the outcome or action could be affected. Fog is
    intended to work with latency-sensitive systems; hence, it should maintain high
    reliability with a strict QoS assurance. Otherwise, the latency awareness criteria
    will not be fulfilled. Madsen et al. [90] suggested that the availability of different
    methodologies and algorithms work with the reliability of network connectivity
    and information, to ensure accuracy, which is crucial for building Fog computing-based
    projects. 3) Security and Privacy In this technological era, people are inevitably
    sharing personal information when using different applications and web services.
    Our personal information is no longer personal; it now belongs to many tech giants
    because we are using their free services on a regular basis [91]. A simple example
    is that if anyone used an Android phone without any security settings, the built-in
    Android OS will automatically run GPS and map services, for which it can collect
    all location-related activities about the user. Therefore, information about when
    and which country a user has visited, where a user has dined in, which route a
    user uses for going to the office, home, and so on will be made available to these
    companies. However, these tech giants might argue that they do not disclose our
    data to others, as they can only see our data in our timeline only. However, a
    recent Facebook incident fails to convince us of the honesty of these tech giants
    [92]. The Fog computing paradigm is completely distributed and not intended to
    be centrally managed most of the time. Sensitive data might be processed in an
    intermediate device when the application does not have full control of the device.
    On the other hand, the user will not have full control over the Fog applications.
    Users will require more protective and innovative ways to retain their privacy
    and protect it from any potential and very harmful entities [20]. Similarly, Fog
    application providers also need to develop security to protect their application
    from unwanted data theft. Three different types of security need to be ensured:
    network connection security, data security, and user privacy. Network connection
    security and data security are applicable from both the user and provider perspectives.
    Moreover, user privacy is also important because Fog processing is carried out
    on user data in most cases. 4) Multi-Tenancy Multiple tenants for the same services
    with an isolated runtime for each tenant are referred to as multi-tenancy service.
    Multi-tenancy is important for Fog because of the limited resources in a Fog environment.
    By enabling multi-tenancy, one instance will run in a Fog device and will serve
    multiple tenants (users). Multi-tenancy could be container-based or could be the
    usual virtualization-based. Container-based virtualization is a more lightweight
    and powerful virtualization solution, which the Fog can adopt, to provide the
    fastest processing solution. Container-based virtualization does not need to emulate
    the operating system to facilitate virtualization; thus, it will be easier to
    manage and migrate. Multi-tenancy is a requirement for the platform, and needs
    to be defined before deployment. Multi-tenancy may incur performance degradation
    and security issues [29]; thus, adequate and secure isolation is needed. 5) Management
    The management of the Fog can be centralized or decentralized. Since the devices
    in a Fog environment belong to different domains, centralized management is not
    always possible. Alternatively, processing of IoT applications will be done in
    different Fog clusters, so management will follow a distributed nature in this
    case. In summary, the management of the platform in a Fog must be defined. In
    the case of decentralized management, similar processes must be deployed for different
    Fog devices to handle management issues. C. Application Applications have to fulfill
    certain requirements to execute in a Fog environment. Here, we discuss the features
    required by the applications for execution. 1) Application Requirements a: Scalability
    The number of IoT devices are increasing very swiftly day by day all over the
    world, which raises a new issue of scalability. Thus, we need to deal with the
    scaling of devices and services in the Fog computing environment. Dependency on
    cloud computing has been observed for IoT application processing by many research
    works, where trillions of IoT devices are involved, such as that of Li et al.
    [93]. However, implementation of the whole application in the cloud in such an
    environment where IoT devices are generating a huge amount of data is neither
    feasible nor efficient. IoT devices are not only stationary but also mobile in
    most cases. Hence, maintaining frequently changing device states and availability
    in the cloud is not an easy task. Also, with the growing number of IoT devices,
    it would be more critical for IoT applications to query and select IoT devices
    [59]. The Fog computing system must be an autonomous system where application
    execution by the participating device will be done automatically including scalability.
    b: Heterogeneity For any IoT system, the heterogeneous device is a fundamental
    characteristic where device heterogeneity co-exists at any level in the Fog computing
    paradigm. Abstraction of device complexity is also required to some extent. Device
    heterogeneity does not only refer to the diversity of services and protocols,
    but also the assortment of horizontal and vertical levels of the Fog architecture
    [59]. To address this heterogeneity, Giang et al. [59], classified three types
    of Fog devices: compute, input/output (IO), and edge nodes. Edge nodes are the
    sensors and the actuators, IO nodes are the resource-limited devices mostly responsible
    for brokering communications, and computing nodes offer computing facilities.
    Of the three types of nodes, IO and compute nodes are mostly dynamic and customizable
    or programmable as required. It is possible to implement all three nodes in a
    single device based on its capability and design goal. The smart gateway is an
    example of such implementation. In order to use the capability of various types
    of devices in an IoT environment, it is obvious that the application must be designed
    in such a way that it might be able to perform its task execution on multiple
    devices regardless of its capacity and location. More precisely, the application
    should able to use maximum available computation resources through middleware.
    c: Interaction Timeliness The perception-action (PA) cycle is the basic function
    of a nervous system, which maintains circular flow between sensory organisms and
    its actions towards the functionality of that sensing. The PA cycle is also a
    characteristic of IoT applications, where the cloud and Fog infrastructure satisfies
    timeliness requirements and application logic for communication. Giang et al.
    [59] identified four interaction models for the PA cycle in a Fog environment.
    Examples of these models are: (i) in a local network, communication between devices,
    which is considered as an immediate cycle action, (ii) interaction with the cloud
    from a device of a local network, which is generally for time-insensitive actions,
    (iii) an interaction generated by the cloud to a device in a local network, which
    requires semi-immediate actions, and (iv) communication among IoT-related applications
    in the cloud. However, their work considered the role of the Fog server, which
    manages and maintains several Fog devices in a specific cluster. On the other
    hand, PA interaction can be divided into immediate, semi-immediate, and delayed
    action to leverage IoT application requirements more efficiently. Delayed action
    can be performed on the type of processing that does not have any timeliness issues
    and could be processed by the cloud infrastructure. d: Mobility Device mobility
    is a natural probability and is one of the key requirements for implementing an
    IoT platform [59]. From the Fog perspective, it is not only the edge devices that
    will be mobile but also computing and storage devices in the Fog layer. Managing
    mobile devices in two different planes and syncing them with each other is challenging.
    To ensure resource availability and successful task completion, task distribution,
    duplication, and migration is required. This mechanism is already considered in
    the cloud but there is a need to reinvestigate them by considering mobility [94].
    2) User Requirements User requirements can be changed by various constraints.
    First of all, a user may want to complete the submitted task within a specific
    time binding, which is referred to as the deadline. Secondly, the user may set
    some constraints for the budget. Thirdly, in the case of some users, they may
    not care about the budget but the response time is of utmost importance. Fourthly,
    some users may want tolerable accuracy. This means that the user may not seek
    accurate results but rather fast results that could be provided with some reasonable
    errors. Aazam and Huh [54] suggested that pre-allocation and prediction of resources
    rely on user behavior and the probability of future utilization of resources.
    Dastjerdi et al. [4], [95] stated that edge devices perform optimization by considering
    user behavior and network condition. 3) Application Modeling Two types of application
    modeling are possible by considering the requirements of applications in the Fog.
    Most IoT devices generate tuples periodically, which can be considered as a stream.
    These streams need to be processed in real time to get accurate results. Alternatively,
    the application that does the processing based on previously stored sets of data
    could include microservice-based applications. The advantage of microservice is
    that it can bind all functionality and required libraries in a single service,
    which can run above the microservice controller without dependency. Hence, application
    modeling in Fog could be stream-based or microservice-based. SECTION VII. Dimension
    of Fog Computing-Based Applications Several applications require a Fog computing
    infrastructure to provide smooth services. These include smart transportation
    systems, Augmented and Virtual reality, healthcare, video streaming, smart homes,
    and smart cities. Requirements of platform and applications are also needed in
    order to provide services. In this section, we discuss some research works, which
    specifically address the application of Fog computing. We evaluate each work based
    on their contribution on the Fog infrastructure, platform, and applications as
    defined in our taxonomy. It is obvious that all three kinds of services are interrelated.
    However, each researcher only focused on one or more of these aspects. Mapping
    related works with our proposed taxonomy will help in finding the research gaps
    in Fog computing applications. A. Smart Transportation System Several research
    works have been carried out on smart transportation systems that use Fog computing.
    In this section we discuss a few works that have been done on the Fog-based smart
    transportation system and then identify key issues that need to be addressed.
    Truong et al. [96] pproposed a Vehicular Ad-hoc Network (VANETs) architecture
    called Fog Software Defined Networking (FSDN), which combines SDN and Fog together
    to provide a better solution. As SDN has programmability, flexibility, global
    knowledge, and scalability features and Fog has location awareness and time sensitivity,
    the combination of these two will leverage on the key challenges in VANETs. The
    proposed system is able to augment communication among vehicles, infrastructure,
    and base stations via centralized control, besides reducing latency and optimizing
    the utilization of resources. However, the central SDN controller of the proposed
    system is where the bottleneck of the proposed system occurs. The system is focused
    on infrastructure and network requirements. The Fog controller is used for service
    implementation. The work did not focus on platform and application requirements.
    Investigation of VANETs in Fog has also been done in Giang et al. [97], where
    they explored how smart transportation applications (VANETs) are developed using
    the Fog Computing approach. Driving vehicles in an urban area requires immediate
    decision on various activities such as route changing, lane change, slowing down
    speed, looking at obstacles, and so on. Hence, applications need to gather all
    related details to act on these activities. The authors discussed Fog-based smart
    transportation application requirements such as programming abstraction and application
    models. The work explored application modeling but not other application aspects
    nor infrastructure or platform. B. Vehicles as Fog Infrastructure Hou et al. [98]
    proposed the idea of Vehicular Fog Computing (VFC), which will use the vehicle
    as an infrastructure for computation and communication. The VFC architecture utilizes
    vehicle computation resources by providing service to the edge devices located
    near them. It will aggregate abundant resources of each moving car by which service
    quality can be enhanced. Using quantitative analysis on different scenarios, they
    discovered an interesting relationship among connectivity, mobility, communication
    capability, and parking behavior. These four characteristics help us understand
    resource utilization of vehicle resources, which will help achieve better utilization
    of unused resources. C. Augmented and Virtual Reality Augmented Reality applications
    are extremely time sensitive; a small delay can lead to serious errors in user
    experience. Thus, Fog computing-based solutions will have great potential in this
    domain [4]. These statements are also applicable for connected Virtual Reality
    (VR) or VR-based games. Zao et al. [99] proposed an augmented brain computer interaction
    game, which utilized the Fog and cloud infrastructure. The Fog performed real-time
    analysis such as signal processing that needs to classify the brain state and
    other analyses such as model classification updated from the cloud. However, their
    work only focused on the Fog infrastructure but neglected most aspects regarding
    platform and application. D. Healthcare The Fog computing approach also enables
    real-time sensor-based healthcare services. Rahmani et al. [100] proposed a Fog-assisted
    system architecture for the healthcare system. A smart e-health gateway is the
    key component of this architecture, which will process the generated data from
    the sensors and generate an Early Warning Score (EWS) to notify for any medical
    emergency. They considered many aspects of our taxonomy; but it is necessary to
    investigate each aspect extensively, which this study did not. Another Fog-based
    healthcare architecture was proposed by Mahmud et al. [26]. Their work mainly
    focused on network delay, power consumption, and communication optimization in
    Fog-based healthcare service. However, platform, application, and user requirements
    were not investigated. E. Smart City Smart city-related applications need to process
    sensor data on a real-time basis, where Fog computing can play a major role. Giordano
    et al. [101] proposed a Rainbow architecture, which supports various applications
    in a smart city. The proposed Rainbow framework evaluated three smart city applications
    including noise pollution mapping, urban drainage networks, and smart street.
    The work proposed a distributed agent-based approach in the intermediate layer
    in between the physical infrastructure and cloud. However, the work did not focused
    on application and platform aspects except for application modeling. Table 4 shows
    a summary of the above-discussed Fog-based applications mapped to our proposed
    taxonomy. In summary, it can be concluded that most of the works have focused
    on infrastructure and application modeling. There is a research gap on application-
    and platform-related aspects, which need to be explored further. TABLE 4 Evaluation
    of Existing Works on Fog Applications SECTION VIII. State-of-the-Art Fog Computing
    In this section, we focus on some existing research works on Fog computing. We
    discuss research works from four different research areas of Fog computing. These
    areas are resource allocation and scheduling, failure handling, simulation tools,
    and microservices. A. Resource Allocation and Scheduling in Fog Computing Fog
    computing is fast evolving and growing rapidly due to its edge-level computation
    and heterogeneous nature. In this section, we present several research works,
    which have been done in the past couple of years. We also summarize the presented
    research works with a comparative discussion to address research gaps in this
    area. Most of the reviewed works are related to resource allocation and scheduling
    in the cloud and Fog environment. However, some works have only been done in the
    Fog environment. 1) Resource Allocation and Scheduling for Fog-Cloud Environment
    Alsaar et al. [102] proposed resource allocation methods for a collaborative platform
    composed of Fog and cloud paradigms. Their proposed algorithm is grounded on linearized
    decision tree rules by considering three different conditions for managing user
    request and for balancing workload. The conditions are VM capacity, completion
    time, and service size. Each condition has two branches: the VM capacity branches
    out to enough or not enough; the completion time consists of now or later, and
    the service size is divided into small or large. In some cases, this includes
    services in the queue, which will be represented with yes or no. They utilized
    1/m/m/1, with (1)/ representing cloud broker, /(m) for many paths, /(m) for many
    Fog brokers, and /(1) for IoT device users. Using this method, the total overhead
    for big data processing in the system was reduced. In their work, the availability
    of cloud servers and the Fog was guaranteed and a fast response time to satisfy
    QoS was achieved. The SLA for users was also different, where shared and reserved
    resource was provided. However, availability and QoS were not studied extensively.
    Deng et al. [103] presented a framework for workload allocation in the cloud and
    Fog environment to examine power consumption-delay trade-off issues. They defined
    the workload allocation problem into primary and sub-problems, which can be solved
    via related sub-systems. They employed a Hungarian algorithm and Generalized Benders
    Decomposition (GBD) algorithm to solve the problem. Numerical and simulation results
    were presented to prove that the Fog is a complement to the cloud. However, the
    complex nature of workload and resource was not studied in their work. Brogi et
    al. [104] prototyped a tool known as ‘FogTorch ∏ ’ which is capable of fulfilling
    hardware, software, and QoS requirements before deploying a composite application
    in the Fog infrastructure. The proposed tool manipulates Monte Carlo simulations
    and only considers communication link QoS. Resource consumption and QoS assurance
    terms were undertaken for classifying the eligibility of deployments. The proposed
    algorithm was based on the preprocessing phase and backtracking search phase.
    To find eligible deployment, the preprocessing used input from results derived
    by the backtracking search algorithm. However, availability and latency are more
    important in the Fog environment compared to resource consumption and communication
    links. In order to ensure efficient use of resources and network infrastructure
    in the Fog and cloud environment, Taneja and Davy [105] proposed a Module Mapping
    Algorithm, which efficiently deploys IoT Application Modules in the composite
    Fog-Cloud Infrastructure. They employed lower-bound searches and compared function
    algorithms to find an eligible network node in the Fog and cloud. The Module Mapping
    algorithm returned a map with nodes, which are appropriate for completing the
    computation operation. If the application requires faster processing, the application
    will be deployed close to the source device. However, the work considered CPU,
    RAM, and bandwidth to find the best resources. In such a case, the cloud resource
    will always be the best resource, so it will be necessary to consider other parameters
    such as response time and availability of the specified resources. Yin et al.
    [52] studied a Fog-assisted big data streaming scenario, where Fog devices are
    responsible for preprocessing raw data for applications hosted in the cloud using
    the unused resources of Fog devices. In their work, the software-defined network
    (SDN) controller continuously adjusted the volume of data to be sent to the Fog
    device for pre-processing. The collaborative computation problem was defined as
    a social welfare maximization problem and a hybrid alternating direction method
    of multiplier (H-ADMM) algorithm was proposed to minimize computation burden via
    the dynamic distribution of Fog devices, cloud, and SDN using message exchanging.
    The formulation of social welfare maximization problem determined the size of
    data that will be assigned to a Fog device. During the formulation, loss of information
    value by preprocessing and the operation cost of the Fog and cloud were considered.
    The work completely depended on the cloud for post-processing, but pre- and post-processing
    could have been done in the Fog to support time-sensitive real-time applications.
    Aazam et al. [106] proposed a dynamic resource estimation algorithm by integrating
    the historical record of cloud service customer (CSC) in a Fog environment based
    on the relinquish probability. The minimum relinquish probability value is 0.1
    and this value will be increased based on the history of the user. However, for
    fair resource estimation, the relinquish probability will be 0.3 for new customers.
    For existing and returning customers, the characteristics of the customer are
    known, so the probability value can be calculated easily. In this way, resource
    underutilization could be minimized and the chances of profit loss will be low.
    2) Resource Allocation and Scheduling for a Fog Environment A resource allocation
    strategy based on priced timed Petri nets (PTPNs) was proposed by Ni et al. [107]
    for Fog computing. The main idea of this work is that the user can choose the
    satisfying resources autonomously from a pre-allocated resource group. With credibility
    evaluation for both users and Fog infrastructure, their proposed strategy comprehensively
    considers the cost for time and price to complete the tasks. The user that has
    a high credit limit will be able to allocate highly reliable resources to complete
    their tasks. Due to the dynamic nature of creditability of users and resources,
    there will be some deviation in calculating them properly. To maintain QoS, the
    resources will be ordered according to their processing capacity and divided into
    several groups. Moreover, users with similar credibility will be assigned to several
    groups. Pooranian et al. [108] proposed a simple algorithm to find an optimal
    solution for resource allocation. They considered the problem as a bin packing
    penalty aware problem where servers are bins and VMs are the pack. Based on idle
    energy, maximum frequency, and maximum energy, each server will be palatalized
    and rewarded. The method will calculate how many VMs could be allocated in t time
    slot on a server. The VMs will be served based on their frequency and time limitations.
    As a consequence of penalty, a server will be punished in the form of being banned
    from use for a few iterations. Once the server passes the iteration freeze, it
    will return to the stream to perform further computation. The penalty and reward
    methods are applied to minimize exponentially increasing energy consumption. Sun
    and Zhang [63] proposed a crowd-funding algorithm for a Fog environment, integrating
    idle resources in the local network. An incentive mechanism was used to encourage
    resource owners to participate in the computation and enthusiastically perform
    their tasks. Through the comprehensive reward and punishment mechanism, it is
    ensured that the participant will positively perform the tasks. This work is similar
    to the above-described literature proposed by Pooranian et al. [108]. However,
    in this case, the reward and punishment go to the participant rather than the
    physical server. 3) Summary of Resource Allocation and Scheduling in Fog Based
    on the related research on resource allocation and scheduling in the Fog, a summary
    is presented in Table 5. From this table, we can see that most of the researchers
    have focused on resource allocation in the Fog. More research works are therefore
    required to investigate resource sharing and workload allocation. Also, further
    investigation is needed to address energy-efficiency, load balancing, SLA, and
    QoS in the Fog. We identified two major issues in Fog computing research. Firstly,
    researchers tend to use a synthetic workload to validate their methods and algorithms.
    Secondly, most of the researchers used cloud-based simulations, which are not
    that convincing because the Fog is more heterogeneous and dynamic in nature. Thus,
    further investigation into workload generation and simulations in the Fog need
    to be undertaken. TABLE 5 Summary of Resource Allocation and Scheduling Research
    in Fog B. Fault Tolerance in Fog Computing The Fog computing paradigm is a highly
    distributed heterogeneous platform where the probability of device failure is
    very high compared to the cloud. Since the Fog is evolving, no study has yet been
    done on fault tolerance in Fog computing. However, fault tolerance has been mostly
    studied in the cloud computing paradigm. Often, fault tolerance is measured by
    availability. In the cloud, faults are handled by proactive fault tolerance and
    reactive fault tolerance techniques at either the workflow level or task level.
    Reactive fault tolerance techniques are used to reduce the impact of failures
    on a system when the failures have actually occurred. Techniques based on this
    policy are job migration, checkpoint/restart, replication, rollback and recovery,
    task resubmission, user-defined exception handling, and workflow rescue. Proactive
    fault tolerance predicts the faults pro-actively and replaces the suspected components
    with other working components; thus, avoiding recovery from faults and errors.
    Proactive Fault Tolerance uses self-healing, preemptive migration, and software
    rejuvenation, which are the few proactive fault tolerance techniques in the cloud.
    According to Sharma et al. [110], the causes of failure in the cloud varies, and
    include software and hardware failure, service failure, overflow failure, power
    outage, outdated systems, network failure, cyber attacks, and human errors. It
    is crucial to handle faults in Fog computing for which the fault needs to be considered
    at every step, not only for processing but also for the transmit-and-receive process
    [111]. In this section, we discuss some existing research works on fault tolerance
    in cloud computing. We specifically focus on resource and task failure mechanisms.
    Then, we summarize the existing works and present a research direction for failure
    handling in Fog computing. Jiang and Hsu [112] proposed a two-level standby design
    for handling server failure in the cloud system. In their proposed system, cold
    and warm standby of the system is made available. Once any server fails, the warm
    standby system will replace the failed server and the failed server will be sent
    to the repair house. After repairing, the system will be placed in the cold standby
    group. The systems in the cold standby group are in a completely switched off
    mode. The work proposed a model to determine the necessary number of cold and
    warm standby systems in the cloud. However, this type of hardware failure handling
    is not suitable for the Fog because most of the time Fog computing devices will
    not be under the property of the Fog provider. Hence, task migration is the best
    solution for hardware failure and this should be reactive in most cases, except
    where the Fog device belongs to the provider. Latiff et al. [113] proposed a cloud-scheduling
    scheme based on a check-pointed league championship algorithm. They employed a
    task migration method for independent task execution failure. In their proposed
    method, the system state will be saved periodically by check-pointing, so the
    task need not start from the beginning once it fails. When the task fails, it
    will be assigned to an underloaded VM and the league championship algorithm will
    be employed to schedule the failed tasks. Wu et al. [114] proposed a fault tolerance
    technique using migration to the cloud. The failure handling method is proactive,
    which always monitors the host and continuously tries to predict the chances of
    failure. If the prediction becomes true, the system will look up other available
    resources and then migration will be performed. The proposed method will monitor
    CPU temperature, memory usage, and CPU fan speed, etc. To employ such a technique
    in Fog computing, further investigation is needed because the types of device
    in Fog are diverse. A combined method of check-pointing and migration-based proactive
    failure handling was proposed by Egwutuoha et al. [115] for HPC and cloud. In
    the proposed method, the authors used a Lm-sensors open source software tool for
    computer health monitoring. From the monitoring data, they defined rule-based
    monitoring depending on temperature, fan speed, voltage, and processor utilization
    to predict failure. The rules are denoted as 1, 2, and 3, representing normal,
    warning, and critical state, respectively. They employed three different policies
    for migration. The first depends on the necessity lease additional node. The second
    removes the node, which is unhealthy based on the state. In the third, the critical
    state publishes to the head node. Finally, the system administrator is notified
    for further action. This type of approach might increase the overhead in the Fog;
    however, further exploration is essential. A recent study shows that proactive
    fault tolerance is the best solution for the cloud compared to redundant solutions
    [88]. However, failure prediction accuracy is the key factor for these kinds of
    solutions. Their work considered software, hardware, and unstable behavior to
    predict the failure of the infrastructure. More specifically, they defined failure
    based on an error formula err=(ActualTime−PredictedTime)/ActualTime×100% , which
    was derived from [118] and [119]. A combination of the proactive and reactive
    method was applied by Gao et al. [118] to handle task failure in the cloud environment.
    The crash detection method and replication factor were proposed in this work to
    handle failures. Table 6 shows a summary of the investigated literature on fault
    tolerance in the cloud. TABLE 6 Summary of Investigated Fault Tolerance Literature
    in Cloud Because of its unstable nature of failure and heterogeneous characteristics,
    the hybrid failure handling method is more appropriate for the Fog computing environment.
    C. Simulation Tools for Fog Computing Simulation and modeling in Fog computing
    are still in their infancy. However, a few research works have been done on Fog
    computing simulation, which are focused on some specific aspect of Fog computing.
    Aazam and Huh [54] focused on resource prediction and pricing in Fog computing.
    The Proposed Fog-based resource management model is able to estimate the required
    resources based on the probability of user behavior of future resource use. Validation
    and performance evaluation was done using simulation. However, they did not consider
    service heterogeneity, QoS, or device mobility factors. Another work proposed
    by Dastjerdi et al. [4] focused on dag of the query for incident detection in
    a smart city use case. Both of these works used CloudSim [119] to validate their
    method along with an experimental evaluation. The first toolkit for Fog simulation
    was developed by Gupta et al. [120], known as iFogSim. The toolkit is used for
    the simulation and modeling of IoT resource management techniques in the Fog and
    edge computing paradigms. The most challenging problem is the design of resource
    management techniques, which determine analytic application distribution among
    edge devices, which will improve the throughput and reduce latency. The proposed
    simulator is capable of measuring the impact of resource management techniques
    in terms of network congestion, latency, cost, and energy consumption. The simulator
    was validated using two use cases and the authors also proposed a Fog computing
    environment architecture. Challenges in Fog computing deployment are include incorporating
    Fog with Emerging Technologies such as 5G Technologies [121], Network Function
    Virtualization (NFV), and Software-defined Networking (SDN). In this case, a simulator
    with container, SDN, and NFV support is crucial. Table 7 presents the key features
    of these two simulators that are mostly used by various researchers for Fog computing
    simulation. These two simulation tools did not focus on network parameters such
    as bandwidth distribution of the link and round-trip delay of the various media.
    These two parameters heavily affect the simulation results where minimization
    of latency is the key goal in a Fog computing environment. Secondly, both tools
    did not consider container-based virtualization. In a Fog computing environment,
    there are many devices that will participate in computation, where hypervisor-based
    virtualization is nearly impossible to implement due to the lower memory and processing
    power of these devices. TABLE 7 Simulation Tools Used for Fog Simulation and Their
    Key Features D. Fog-Based Micro Services A microservice is an independent process
    and Software-Oriented Architecture (SOA) that interacts by message passing. The
    SOA of microservice does not hinder or favor any specific programming model. It
    provides design and implementation guidelines for distributed applications to
    partition each component independently. Each of the components addresses a specific
    functionality. The functionality of the components can be accessed by message
    passing and is possible to implement in any mainstream programming language internally.
    In this way, this principle helps developers and project managers to develop each
    module independently and test it with a few related functions. Some microservices,
    also known as high-level microservices, are mainly responsible for coordination
    with other microservices [124]. The organizational approach of microservices accelerates
    the development cycle, nourishes ownership, encourages innovation, improves scalability,
    and enhances the maintainability of software applications. Using this approach,
    software becomes a small independent service and interacts over unambiguous APIs.
    These services are preserved via self-contained small teams [125]. The agility
    and independent distributed nature of microservice deployment makes it a good
    solution for Fog-based IoT application development. Independent processes and
    interaction via message passing features has made microservices more convenient
    for IoT applications. In the Fog, there is a limitation of resources, so developing
    microservices in the Fog will minimize the growing complexity of the big system
    by dividing it into a set of small independent services. Microservice is taking
    modularity to a subsequent level by incorporating high cohesion and loose coupling
    of distributed systems. 1) Current Research Aspects of Microservice Recently,
    microservice-based applications have started gaining popularity [124]. Fog-based
    microservices have not been investigated extensively; hence, it is an open research
    area. However, some research works have been done in this emerging research area,
    with most of the efforts being related to IoT. Butzin et al. [126] investigated
    the use of microservices in IoT and claimed that the architectural goal of IoT
    and microservices are similar. However, they actually have different features
    in terms of various aspects. First of all, microservice has a self-containment
    feature where all dependencies and libraries are packed with the application in
    a single image. On the other hand, for IoT, all libraries are not generally wrapped
    with the application. However, both use similar types of virtualization and web
    protocols. Microservice also has a continuous integration and delivery feature
    while in IoT these are not available or only partly exist. Vresk and Čavrak [127]
    proposed a microservice-based middleware for IoT to support device heterogeneity,
    various communication protocols, and services. They presented a data model and
    address model for microservice-based IoT. Brito et al. [128] proposed a service
    orchestration architecture for Fog using microservices. The authors defined the
    resource manager as a microservice. Khazaei et al. [129] proposed a generic programmable
    self-managing microservice-based platform for IoT. In the platform, microservices
    will exist in all layers in a cascading manner and an autonomic management system
    will scale the microservice. A similar type of IoT framework was proposed by Sun
    et al. [130]. In their architecture of nine components, all are microservices
    except for the core service. The work proved that microservices are far better
    than the monolithic approach in terms of scalability, flexibility, and platform
    independence. However, still, microservice-based IoT architecture suffers from
    various issues such as faults in the network, network delay, message serialization,
    cooperative transaction processing, and other distributed computing scenarios.
    Li et al. [131] proposed a cooperative-based model specifically for smart sensing
    devices; it is possible to enhance the performance of such a service by undertaking
    a micro-service based concept. Krivic et al. [132] proposed a management solution
    for Machine-to-Machine (M2M) device communication in an IoT system using collaborative
    microservice. They argued that microservices could act as the agent in an agent-based
    system since each microservice is responsible for performing a specific task and
    acts collaboratively to achieve the system goal. Container-based virtualization
    is the best solution for deploying microservices since the container supports
    OS virtualization and packs all dependencies in a single image. A container is
    able to manage physical hardware resource needed by an application with its OS
    kernel utilities [133]. 2) Microservices and IoT Applications Many research works
    have suggested Fog-based processing for IoT applications in smart transportation
    systems [96]–[98], Augmented and Virtual Reality [99], [134], [135], and healthcare
    [26], [136], [137]. Fog computing is also suitable for video streaming, smart
    homes, smart cities, and CDN. The common characteristics of these applications
    are time-sensitiveness, which make Fog computing a promising emerging computing
    paradigm. The main drawback of the Fog, however, is resource limitation and failure.
    Thus, using microservices for Fog-based IoT applications will minimize these drawbacks.
    Microservices are standalone, lightweight, and easily deliverable. To mitigate
    resource limitation, the microservice-based container is the best solution so
    far. In the same way, it will also minimize the cost of failure by deploying the
    application immediately. Many open research issues can be addressed by implementing
    Fog-based micro services; these include service management, scheduling, monitoring,
    fault tolerance, security, and privacy. E. Fog Based Mobile Computing The number
    of smartphone and mobile device users in urban areas as well as in rural areas
    is increasing day by day. As a result, mobile users are now requesting high-volume
    content collaboratively. Providing service for all requested contents in an area
    where mobile users are densely populated is a really challenging task for service
    providers [138]. The high number of concurrent content requests will only make
    the situation worse. One of the best solutions to cope with this problem is to
    offload content near the users, so that the users could get better service. This
    content offloading process can be supported by mobile Fog computing. In mobile
    Fog computing, content will be offloaded to the Fog device, which is located closer
    to the users. However, content management in Fog nodes is a current research issue.
    Depending on the demand of the contents, offloading should be distributed on the
    Fog nodes. Constant monitoring and efficient cache management is crucial to deal
    with resource-limited Fog nodes. A few research works have been done on mobile
    Fog computing. This section chronologically discusses the research works that
    have been done in this particular research area in the past couple of years. Hong
    et al. [94] proposed a high-level programming model that supports large-scale
    geospatially distributed time-sensitive applications. The proposed Mobile Fog
    programming model has two design goals. The initial goal is to provide a simplified
    application development for an enormous number of heterogenous devices, which
    are distributed in a wide area. The next goal is the dynamic scaling of resources
    based on resource demand. They developed an API for their programming model and
    evaluated it using two application models: vehicle tracking using a camera and
    traffic monitoring using a Mobility-driven distributed Complex Event Processing
    (MCEP) system. However, they did not focus on process placement or process migration.
    Shi et al. [139] proposed a P2P inspired communication model between the mobile
    device cloud and mobile nodes to share resources and computation task among mobile
    devices. In their work, they utilized a Constrained Application Protocol (CoAP)
    for implementing microservices. This work introduced the M2M approach in Fog computing
    while the classical Fog is actually hierarchy based. Content offloading in the
    mobile Fog was investigated by Khan et al. [138]. They defined mobile Fog as co-located
    self-organizing mobile nodes, which offer distributed resources at the edge. The
    aim of this work was to collaborate nodes for content caching, which will maximize
    the availability of the content and minimize operational cost. The proposed coalition
    game helps find the best co-located candidates near the users for sharing storage
    and self-organizing. Wang et al. [140] proposed a three-layer hierarchy framework
    using a Fog structure to bridge the communication between WSNs and the cloud.
    They designed a routing algorithm for bridging communication by considering the
    number of hops and energy consumption. They defined the Fog node as a sink, which
    will transfer data from sensor to the cloud. The proposed framework consists of
    routing layer, Fog layer, and sink layer. In the Fog layer, a sink acts as the
    Fog nodes as well to minimize transmission delay. However, there is a lack of
    security and privacy concern being addressed in mobile Fog computing. Roman et
    al. [141] addressed security and privacy for all edge-level computing. This included
    a usual thread in a network system mobile Fog that requires extra measures of
    authentication, trust, access control, protocol, and network security. SECTION
    IX. Open Issues and Future Research Directions A. Infrastructure-Related Issues
    The Fog is an evolving technology, expanding in such a way that it needs to reach
    market adoption to support all kinds of time-sensitive applications. The Fog has
    become an enactment of research efforts by various academies and industries. One
    of the key initiatives is the Open Fog Consortium (OpenFog), which was founded
    by the ARM, Cisco, Dell, Intel, Microsoft and Princeton University in November
    2015 [31]. Foxconn, General Electric, Hitachi, Sakura Internet, ShanghaiTech University,
    and ZTE are the contributing members of this nonprofit consortium. They are accelerating
    digital innovation with the blending of 5G wireless technology, IoT, and embedded
    AI by providing open interoperable architecture. However, many open challenges
    exist for this sprout-level computing paradigm. In this section, we discuss the
    research challenges and address the future directions for Fog computing research.
    Figure 10 shows some important research issues in Fog computing. FIGURE 10. Fog
    computing research issues. Show All 1) Deployment Issues From the deployment viewpoint,
    OpenFog is defined as an N-tier environment. However, the excessive increase in
    number of levels in the Fog layer might cause latency problems in the newly emerging
    Fog computing paradigm. Therefore, the number of tiers based on the use case must
    be determined. Deployment decisions will be undertaken based on requirements such
    as type and amount of task that will be done by each tier, total number of sensors,
    Fog device capability, in between the latency and reliability of Fog devices.
    Still, it is necessary to investigate how these requirements will be fulfilled.
    Application and resource scaling is also an important issue during deployment.
    Based on the requirement of the application and resource, scaling and shrinking
    without interrupting current services could be undertaken. In this regard, placement
    might also affect Fog deployment. 2) Standard Architecture for Fog Computing Up
    until now, there has been no defined standard architecture for Fog computing.
    The OpenFog consortium released two versions of the Fog architecture in February
    2016 [61] and February 2017 [142]. Their first draft was an initial overview of
    the Fog architecture. In their second draft, the Fog architecture was discussed
    in more detail. In their proposed architecture, they considered many key aspects
    of Fog architecture including performance, manageability, security, data analytics,
    and control. However, further research needs to be undertaken to explore and gain
    deeper insight into each layer with proper validation. 3) Interoperability and
    Federation of Fog Because of the Fog, users are able to process their request
    near them, which will minimize latency. However, what will happen if an increasing
    number of multiple latency-aware applications requests are sent in one shot to
    the Fog device and the Fog device is unable to handle that many requests? Will
    it be passed to the cloud for processing? If it is passed to the cloud, then latency
    requirements will not be satisfied. Thus, interoperability and federation among
    Fog clusters and Fog servers are necessary. Hence, if a Fog device is fully utilized,
    it will send requests to peer Fog devices or Fog servers for processing instead
    of sending them to the cloud. B. Platform-Related Issues 1) Resource Management
    Resources are most dynamic and heterogeneous in a Fog environment because of the
    diversity of devices and their available resources. All devices known as Fog devices
    are responsible for performing the computation of their own application. For example,
    a computer that relies on office staff to perform some ordinary email and documentation
    works might be a part of the Fog and might also act as a Fog device. In such a
    case, the amount of resources available for Fog computation is dynamic but predictable
    via the analysis of the long-term activity of its resources. This prediction is
    necessary because once the Fog task execution starts, and over a period of time,
    the status of the resources might change due to the request by the application
    for which the device is responsible for. If we compared this to the cloud, it
    is possible to know how much resources are currently available and whether or
    not they are exclusively used for cloud-based application requests. However, the
    Fog aims to use idle resources available on any Fog device with Fog computation
    always taking second priority. Hence, resource allocation and scheduling in the
    Fog is more challenging than traditional resource allocation and scheduling in
    the cloud. 2) Failure Management Fog device failure probability is always high
    because the devices are distributed and the management of Fog devices is not central.
    Hence, the devices could fail for many reasons; this could be due to hardware
    failure, software failure, or because of user activity. Besides these problems,
    some other reasons include connectivity, mobility, and power source, which also
    play a big role. Most of the devices in a Fog environment might be connected via
    wireless connections; it is obvious that wireless connections are not always reliable.
    The majority of devices that are connected via wireless are mobile, so these devices
    could change location to different clusters frequently. One other characteristic
    of these devices is that they are battery powered and might fail anytime. Hence,
    dealing with the complex nature of failure is very difficult. Also, it is necessary
    to ensure SLA by defining QoS parameters. So, the question is: What are the SLAs
    and how should they be defined? Also: What QoS parameters must be considered,
    so that the consumer and providers can retain a win-win situation? 3) Communication
    Between Different Layers The Fog should ensure uninterrupted connection with the
    devices to ensure application requirements of time-sensitive applications are
    met. If the application were to control an autonomous car or drone and if it were
    responsible for emergency surveillance, then failure in connectivity might cause
    serious harm. Even if connectivity to the cloud fails, the Fog still needs to
    ensure continuous connectivity. Thus, cross-layer connectivity among IoT devices,
    Fog, and cloud are of the utmost importance. The connection type and protocols
    used by IoT devices and Fog devices might be different. Therefore, how these issues
    will be handled is an important research issue. 4) User Participation Management
    Efficient Fog service management depends on the participation of users in Fog
    computation. However, how can user participation be managed? How do we deploy
    minimum resources in the case where no one wants to participate? We need to address
    these problems clearly with a feasible solution. One of the methods to increase
    user participation is through incentive and reward-based policies. With such policies,
    any user that participates in Fog computation will benefit. Even a user, who participates
    to complete his own request, will be rewarded by getting some discount based on
    his participation. However, this area needs to be addressed because the overall
    success of Fog computation depends on the participation of Fog devices, which
    are owned by various people and organizations. 5) Security and Privacy Fog devices
    are managed by different operators based on their location and ownership. Nobody
    would want to contribute to Fog computation if device control were compromised.
    Thus, how the security of a participant device will be maintained if the device
    were to take part in Fog computation is a big question. Another key security issue
    for this scenario is participant user data security. A participant device might
    have critical information. How will safety be guaranteed in such a case? On the
    other hand, critical data might be processed in a device, which is owned by a
    black hat hacker. How will safety and privacy be ensured then? Security issues
    also exist during cross-layer communication. Similar to the distributed nature
    of the Fog, security management should also be distributed, which will not be
    dependent on any central component. C. Application-Related Issues 1) Application
    Service Management Billions of IoT devices will be handled by the Fog paradigm,
    which will handle time-sensitive and time-insensitive applications. The degree
    of service, availability, and quality is most diverse in the Fog. Hence, service
    management is a typical issue for the entire Fog realm. Services should be microservice-based,
    so that agility and management issues can be handled properly. Further research
    is necessary to explore the possibility of Fog-based solutions. 2) Application
    Modeling Modeling Fog applications is complex because the application should collect
    data from different IoT devices, which use different protocols and sets of codes.
    Thus, it is challenging to model generic applications, which can be deployed with
    minimal effort. To solve this issue, a standard form of communication protocol
    is necessary, so that the modeled application can communicate and work with different
    types of IoT devices. SECTION X. Conclusion The Fog computing paradigm is currently
    in its infancy, so an extensive investigation is required for this emerging technology.
    In this survey, we presented and discussed the overview, architecture, state-of-the-art
    and other similar technologies in Fog computing. Based on the literature, we derived
    a taxonomy for Fog computing by analyzing the requirement of Fog infrastructure,
    platform, and applications. We also covered resource allocation and scheduling,
    fault tolerance, simulation tools, and microservices in Fog computing. Finally,
    we presented some challenging and open research issues. We strongly believe that
    this comprehensive survey will bring to light IoT application execution for a
    Fog computing environment as well as point towards the direction for current and
    future research in this rapidly growing research area. In this way, this computing
    paradigm, which is still immature, will be propelled towards achieving market
    adoption in the near future. ACKNOWLEDGEMENT The authors would like to sincerely
    thank Professor Rajkumar Buyya for his insightful comments and discussion on improving
    the overall quality of the paper. Authors Figures References Citations Keywords
    Metrics More Like This The Application of Fog Computing and Internet of Things
    Technology in Music Resource Management Model IEEE Access Published: 2020 Deep
    Reinforcement Learning-Based Dynamic Resource Management for Mobile Edge Computing
    in Industrial Internet of Things IEEE Transactions on Industrial Informatics Published:
    2021 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details
    PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE access
  limitations: '>'
  pdf_link: null
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: 'Fog Computing: Survey of Trends, Architectures, Requirements, and Research
    Directions'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.jclepro.2016.10.006
  analysis: '>'
  authors:
  - Biljana Risteska Stojkoska
  - Kire Trivodaliev
  citation_count: 984
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Review methodology 3.
    In-depth analysis of literature 4. Challenges and solutions 5. Conclusions References
    Show full outline Cited by (1020) Figures (5) Tables (6) Table 1 Table 2 Table
    3 Table 4 Table 5 Table 6 Journal of Cleaner Production Volume 140, Part 3, 1
    January 2017, Pages 1454-1464 Review A review of Internet of Things for smart
    home: Challenges and solutions Author links open overlay panel Biljana L. Risteska
    Stojkoska, Kire V. Trivodaliev Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.jclepro.2016.10.006
    Get rights and content Highlights • A review of state-of-the-art Internet of Things
    applications for smart grid and home. • Definition of smart home holistic framework
    with key features from literature review. • General description of a smart home
    management model based on the holistic framework. • Discussion of current and
    future challenges for Internet of Things based solutions. Abstract Although Internet
    of Things (IoT) brings significant advantages over traditional communication technologies
    for smart grid and smart home applications, these implementations are still very
    rare. Relying on a comprehensive literature review, this paper aims to contribute
    towards narrowing the gap between the existing state-of-the-art smart home applications
    and the prospect of their integration into an IoT enabled environment. We propose
    a holistic framework which incorporates different components from IoT architectures/frameworks
    proposed in the literature, in order to efficiently integrate smart home objects
    in a cloud-centric IoT based solution. We identify a smart home management model
    for the proposed framework and the main tasks that should be performed at each
    level. We additionally discuss practical design challenges with emphasis on data
    processing, as well as smart home communication protocols and their interoperability.
    We believe that the holistic framework ascertained in this paper can be used as
    a solid base for the future developers of Internet of Things based smart home
    solutions. Previous article in issue Next article in issue Keywords Internet of
    ThingsSmart homeHolistic frameworkSmart grid 1. Introduction With the expected
    growth in world population, the demand for energy will continuously increase.
    Current power grids were built decades ago, and despite the fact that they are
    regularly upgraded, their capability to fulfill future demands is uncertain. Existing
    reserves of fossil fuels are limited and impose harmful emissions, making social
    and environmental implications and impact inevitable. The result of this current
    state is the transition of the traditional centralized grid towards a distributed
    hybrid energy generation system that heavily relies on renewable energy sources,
    such as wind and solar systems (Lund et al., 2015), biomass, fuel cells, and tidal
    power. Smart grid is a concept that integrates information and communication technologies
    (ICT) with grid power systems, in order to achieve efficient and intelligent energy
    generation and consumption (Iyer and Agrawal, 2010). It is characterized by a
    two-way flow of both electricity and information. Approaches in smart grid include
    novel solutions that would effectively exploit the existing power grid in order
    to reduce or eliminate blackouts, voltage sags and overloads. Utilities could
    benefit, as the load demand in critical situations would decrease. If demand is
    greater than the total generation, these systems could prevent the grid failure
    or major blackouts, and increase the reliability, quality, security and safety
    of the power grid. Smart grid solutions can be applied in every part of the grid:
    production, transmission and distribution. Recently, a fourth part of the smart
    grid, i.e. the smart home has become a major (mainstream) research and application
    interest in smart grid. Smart home refers to the use of ICT in home control, ranging
    from controlling appliances to automation of home features (windows, lighting,
    etc.). A key element of the smart home is the usage of intelligent power scheduling
    algorithms, which will provide residents with the ability to make optimal, a priori
    choices about how to spent electricity in order to decrease energy consumption.
    Another term commonly used is smart house or home automation. The combination
    of information technologies and advanced communication and sensing systems, creates
    a variety of new potential applications. New advanced concepts, such as pervasive
    or ubiquitous computing (Greenfield, 2006), where computing is made to appear
    everywhere and anywhere, hold a huge potential for application in smart grid (Parikh
    et al., 2010). Smart devices or objects, capable of communication and computation,
    ranging from simple sensor nodes to home appliances and sophisticated smart phones
    are present everywhere around us. The heterogeneous network composing of such
    objects comes under the umbrella of a concept with a fast growing popularity,
    referred to as Internet of Things (IoT). IoT represents a worldwide network of
    uniquely addressable interconnected objects. According to Gubbi et al. (2013),
    IoT is an “interconnection of sensing and actuating devices providing the ability
    to share information across platforms through a unified framework, developing
    a common operating picture for enabling innovative applications. This is achieved
    by seamless ubiquitous sensing, data analytics and information representation
    with Cloud computing as the unifying framework.” Therefore, the Internet of Things
    aims to improve one''s comfort and efficiency, by enabling cooperation among smart
    objects. The standard IoT usually consists of many Wireless Sensor Networks (WSN)
    and Radio-frequency identification (RFID) devices. Wireless Sensor Network is
    a paradigm that was tremendously explored by the research community in the last
    two decades (Oppermann et al., 2014). A WSN consists of smart sensing devices
    that can communicate through direct radio communication. RFID devices are not
    as sophisticated. They mainly consist of two parts: an integrated circuit with
    some computational capabilities and an antenna for communication. The concept
    of IoT, combined with smart metering, has the potential to transform residential
    houses, homes and offices into energy-aware environments. There is an increasing
    interest in the research community to incorporate the IoT paradigm in the smart
    grid concept, particularly in smart home solutions. The trends of web search popularity
    for the terms: Internet of Things, Smart Grid and Smart Home since 2004 are shown
    in Fig. 1. According to these statistics by Google, the trends will further increase
    for the terms Internet of Things and Smart Home. Download : Download high-res
    image (179KB) Download : Download full-size image Fig. 1. Interest over time according
    to Google trends since 2004 for terms Internet of Things, Smart Grid and Smart
    Home. In this paper, we present a holistic approach to the integration of state-of-the-art
    IoT (or near IoT) solutions into the smart home, taking into account both home
    energy management considerations and architectural challenges and solutions with
    emphasis on data processing issues, networking and interoperability features of
    smart home protocols. For this purpose, we surveyed the IoT frameworks present
    in the literature, analyzed these state-of-the-art solutions and defined challenges
    for future research. Section two presents the methodology used in this paper in
    order to select the most appropriate recent developments as published in the literature
    covering the topics of Internet of Things, smart grid, and smart home. The in-depth
    analysis of the results, as identified by our methodology, is given in Section
    3. Our analysis is conducted in a threefold manner. Initially, possible and existing
    IoT and near IoT applications are analyzed in view of different parts of the smart
    grid where such solutions are and/or can be applied, with focus on the smart home.
    Afterwards, a generalization is given of the existing solutions in a new generic
    holistic framework that incorporates key features from the literature review as
    identified by our methodology. The analysis is concluded by overviewing a general
    smart home management model for the IoT based holistic framework by defining its
    integral levels and their main tasks as observed in the analyzed state-of-the-art
    solutions. The fourth section discusses challenges associated with IoT constrained
    resources (energy, memory capacity and processing capabilities), along with networking,
    interoperability issues, big data analyses, security and privacy. An overview
    of useful guidelines and solutions needed to face these challenges is given. Finally,
    this paper is concluded in the fifth section. 2. Review methodology This section
    presents the methodology used in the paper in order to select the most appropriate
    recent developments as published in the literature covering the topics of Internet
    of Things, smart grid, and smart home. The literature was searched using the online
    service Google Scholar (GS) (https://scholar.google.com/). The main advantages
    of using GS as opposed to other similar resources like Scopus and Web of Science
    are freedom, ease of use, and a broader universe of cited and citing items (Franceschet,
    2010). Google Scholar has a high coverage for high quality studies, is highly
    sensitive and could be the first, and even more so a standalone choice for systematic
    reviews or meta-analysis (Gehanno et al., 2013). Only publications, excluding
    patents and citations were searched. All results provided by GS were sorted according
    to their relevance. Google Scholar''s ranking algorithm relies heavily on an article''s
    citation count, but also puts a high weighting on words in the title (Beel and
    Gipp, 2009). Currently GS does not search for synonyms of queried keywords; hence,
    all synonyms have to be rewritten and queried separately. Only publications between
    years 2010 and 2016 were considered. Papers prior to 2010 were not considered
    since most of the advances in this area have happened within the last few years
    (GS retrieves 130 publications with keyword “Internet of Things” in the title
    published before 2010, and 7650 publication published after 2010), which is in
    line with the Google trends as shown in Fig. 1. The following terms were allowed:
    “Wireless Sensor Network”, “Internet of Things”, “IoT”, “Smart Grid”, “Smart Home”
    and “Home Automation” to appear anywhere in the text of the publications. We consider
    the terms “Home Automation” and “Smart Home” to be synonyms, as well as the terms
    “IoT”, “Internet of Things” and “Wireless Sensor Networks” (since Wireless Sensor
    Networks together with RFID are the two main technologies which enable the development
    of IoT). Most of the research challenges in IoT have its origin in WSN; hence,
    some of the IoT solutions are simply borrowed from WSN (Mainetti et al., 2011).
    The general query form we use is “term1” AND “term2” AND “term3”, where term1
    = (“Wireless Sensor Networks” OR “Internet of Things” OR “IoT”), term2 = (“Smart
    Home” OR “Home Automation”), and term3 = “Smart Grid”, and thus perform six searches.
    The queries and the total number of publications retrieved by GS are given in
    Table 1. Table 1. Number of publications found by GS engine for different queries.
    Query# Term1 Term2 Term3 Total number of results Query 1 “Wireless Sensor Network”
    “Smart Home” “Smart Grid” 919 Query 2 “Wireless Sensor Network” “Home Automation”
    “Smart Grid” 775 Query 3 “Internet of Things” “Smart Home” “Smart Grid” 1430 Query
    4 “Internet of Things” “Home Automation” “Smart Grid” 1000 Query 5 “IoT” “Smart
    Home” “Smart Grid” 1050 Query 6 “IoT” “Home Automation” “Smart Grid” 747 Only
    the first 100 results per query were considered for further analysis in this paper.
    There are overlaps between the result sets of the different queries so the final
    set of unique publications is around 150. For example, if we consider only the
    top 20 results there are a total of 74 unique publications, with multiple publications
    appearing in the results of more than one query. Fig. 2 shows the number of these
    overlaps, and additionally the average GS ranking for each group are given (e.g.
    papers that appear in the results of a single query have an average ranking of
    12.54). Download : Download high-res image (203KB) Download : Download full-size
    image Fig. 2. Total number of publications appearing in the top 20 results for
    the six queries. The number associated with each bar refers to the average ranking
    of the publications in the group. The unique set of publications was further filtered
    content-wise i.e. whether the publication has pertinent material regarding wireless
    sensor networks or Internet of Things solution/s for smart home and/or smart grid.
    First a number of papers were excluded based on the content of their abstract.
    Next, we considered the whole text of the remaining papers and retained only those
    in line with our review. The final remaining papers were analyzed in-depth. The
    finding is that the papers can be semantically divided in two main categories:
    WSN solutions and IoT concepts. The first category includes papers that provide
    real-life working implementations of WSN in different domains like habitat monitoring,
    home monitoring, etc. They can be considered the seeds of future IoT applications.
    The papers in the second category revolve around the IoT paradigm and provide
    concepts, frameworks, visions, and challenges of future “to be implemented” IoT
    solutions. Hence, this work separately elaborates the papers in the two categories
    in the forthcoming Section (3). We firstly expatiate on papers in context of WSN
    implementations (3.1), then we survey papers in line with IoT solutions (3.2 and
    3.3). 3. In-depth analysis of literature This section presents the in-depth analysis
    of the results as identified by our methodology. The analysis is conducted in
    a threefold manner. Initially, possible and existing IoT and near IoT applications
    are analyzed in view of different parts of the smart grid where such solutions
    are and/or can be applied, with focus on the smart home. Afterwards, a generalization
    is given of the existing solutions in a new generic holistic framework that incorporates
    key features from the literature review as identified by our methodology. The
    analysis is concluded by overviewing a general smart home management model for
    the IoT based holistic framework by defining its integral levels and their main
    tasks as observed in the analyzed state-of-the-art solutions. 3.1. State-of-the-art
    (near) Internet of Things solutions in smart grid and smart home The integration
    of IoT within the smart grid will bring a new perspective to electricity management,
    with benefit for all parties involved. Table 2 differentiates the potential IoT
    applications regarding different aspects (parts) of the smart grid (Cardenas et
    al., 2014, Gungor et al., 2010, Parikh et al., 2010). Much of the pioneering research
    is hindered with a lot of challenges, especially when dealing with the first three
    aspects (generation, transmission and distribution) of the smart grid. The problems
    are mostly due to the harsh conditions in which sensor devices are deployed. Experimental
    results using IEEE 802.15.4-compliant sensor networks show that wireless links
    (including both line-of-sight (LOS) and non-LOS (NLOS) scenarios) in the smart
    grid have high packet error rates and variable link capacity due to electromagnetic
    interference, equipment noise, obstruction, etc. (Gungor and Korkmaz, 2012). Wireless
    nodes impose additional constraints, i.e. the memory and processing limitations
    of the sensor nodes and their limited power resources. Table 2. Potential IoT
    applications for smart grid. Energy providers Energy generation Transmission Distribution
    Consumers Real-time generation monitoring Transmission lines controlling Underground
    cable system monitoring Wireless automatic meter reading (smart metering) Power
    plants controlling Power monitoring Transformers stations controlling Home (Residential)
    energy management Alternative energy sources controlling Solar panels management
    Residential (distributed) production monitoring Predicting future solar panels
    and wind turbine production (using sensor data like temperature or humidity) Fortunately,
    most of these challenges are not present in the fourth, consumer side of the smart
    grid, i.e. the smart home. For example, sensors are usually connected to home
    appliances and the battery life problem becomes superfluous as the devices have
    a steady power supply. Furthermore, strong electromagnetic fields are not associated
    with home grid infrastructure. Still, IoT for smart home is subject to challenges
    like reliability, privacy, and security (Iyer, 2011). Modern homes equipped with
    smart meters, smart appliances, smart power outlets and sensing devices enable
    the development of energy-aware smart homes (Fig. 3). Although the smart home
    has been a dream for both utilities and consumers for a long time, such implementations
    are still very rare (Monacchi et al., 2013). On the other side, there are plenty
    of existing commercial solutions and advanced Demand Side Management (DSM) systems
    focused on large industrial consumers (Finn and Fitzpatrick, 2014, Palensky and
    Dietrich, 2011). Almost all of them fail to integrate small residential consumers.
    Download : Download high-res image (439KB) Download : Download full-size image
    Fig. 3. Smart home. IoT carries the potential to overcome this gap and to provide
    services that will foster the development of intelligent solutions for the common
    people. The main goal of IoT is to advance a better and safe society, where “Everything
    is a service” (public safety, environment, health care, production, etc.). In
    this subsection we present relevant attempts from the literature as identified
    by our methodology. The papers discussed here semantically fall in a category
    regarding near IoT solutions for smart home, mainly from the neighboring fields
    of wireless sensor networks, home automation, and smart grid. Novel architectures
    in terms of state-of-the-art software technologies with focus on domestic environments
    and habitat monitoring are proposed in Monacchi et al. (2013) and Stojkoska and
    Davcev (2009). In Monacchi et al. (2013) the authors promote design guidelines
    for collecting and integrating household data, thus enabling data interoperability.
    In Stojkoska and Davcev (2009), a web interface is developed in order to increase
    the interaction between the deployed WSN and its end users. Authors of Kamilaris
    et al. (2011) propose a solution for a Web-based energy-aware smart home framework
    that enables smart appliances to the Web. They have developed a graphical user
    interface to ease the interaction. The evaluation of their solution is done using
    a WSN organized in a star topology and also a multihop topology (up to three hops)
    for larger apartments (smart homes of around 100 m2). VillaSmart (Caracaş et al.,
    2013) is associated with the ECOGRID EU (EcoGrid EU, 2015) project. The authors
    have installed a modular and extensible WSN in a test and reference household
    called VILLASMART. These authors are modeling the energy behavior of the building.
    These thermal models are improved using indoor and outdoor WSN readings (air and
    water temperature, solar radiation sensor, weather conditions and power consumption
    information), thus achieving more precise predictions of indoor temperature. Using
    the standard resistance-capacitance (RC) model, the maximum prediction error achieved
    is 1.790C. The IEEE 802.15.4 standard in the 2.4 GHz is used for indoor communication.
    The model parameter determination is done with the grey-box estimation method.
    In Srbinovska et al. (2015) a WSN is installed for vegetable greenhouse monitoring
    and a control system for agriculture is developed. This system helps farmers increase
    the crop production and quality by remotely controlling different parts of the
    greenhouse, like drip irrigation and fan facilities. In Risteska Stojkoska et
    al. (2014), the authors present a framework for temperature regulation inside
    commercial and administrative buildings, with focus on design and implementation
    of specific network topologies and node localization within the system. 3.2. Holistic
    IoT-based framework for smart home It is expected that smart objects will be dominant
    on the market in the next few years and will become omnipresent in households,
    which will impose the need for new and improved services for smart homes (Karnouskos,
    2011). For these reasons, the need for IoT based solutions will be incontestable.
    Most recent publications focus on developing a general IoT framework that is suitable
    for broader range of application domains. In Lee and Lee (2015), the authors identity
    five IoT technologies as essential for building successful IoT solutions: radio
    frequency identification, wireless sensor networks, middleware, cloud computing
    and software for application development. They also identify three IoT categories
    for enterprise applications: monitoring and control, big data and business analytics,
    and information sharing and collaboration. In(Da Xu et al., 2014), the list of
    enabling technologies is enhanced with Near Field Communication, location based
    services and social networks. They suggest a four-layer architecture made up of:
    sensing, networking, service and interface. The role of the cloud is missing;
    therefore, it is not clear how services would be enabled. Liu et al. (2014) presents
    a middleware that supports naming, addressing, storage and look-up services. The
    idea is to develop a middleware at the top of the existing systems, thus to achieve
    easier integration of existing applications into IoT environments. Once again,
    the cloud is omitted as an enabling technology that should support all these services.
    The monitoring of production processes in industry using IoT is investigated in
    Shrouf and Miragliotta (2015). The authors propose a detailed framework that is
    focused on energy management, with possibilities for in-house or cloud-based data
    mining and decision making. The role of the third-party solution designers is
    not specified in the framework. Readers can also refer to (Gubbi et al., 2013,
    He et al., 2014, Xu et al., 2014) for interesting work regarding IoT architectures.
    With respect to these publications, the framework presented in this paper can
    be considered a modified version of the most general model we found in literature
    (Da Xu et al., 2014), augmented with the cloud in the middle, and adapted to a
    particular application domain, i.e. smart home. This multi-level hierarchical
    holistic framework based on Internet of Things is used as a wrapper or generalization
    of all the key features of IoT solutions for smart homes identified in the literature.
    The graphical representation of the framework is given in Fig. 4. Within the framework
    data is sent wirelessly and is shown using dashed lines. The yellow lines correspond
    to a bidirectional electricity flow. The following paragraphs summarize each level
    of the framework. Download : Download high-res image (641KB) Download : Download
    full-size image Fig. 4. Multi level IoT framework for smart home. 3.2.1. Smart
    home All household devices equipped with interfaces for wireless communication,
    make up the home WSN. Each home has a WSN, and the sensed data from each device
    is forwarded to a central station, which we refer to as home sink or home hub.
    Each node in the home WSN is considered a smart device and has moderate computation
    and communication capabilities. The home hub can be any one device (smart meter,
    PC, tablet or smartphone) that has some data storage capacity, can perform local
    processing and can communicate with devices outside the home WSN. In the case
    of smart residential complexes or smart buildings, the counterpart of the home
    hub is identified as residential sink or residential hub. The residential hub
    needs to have an additional feature, as compared to the home hub, which is that
    it is responsible for managing data from/to shared distributed production sources.
    This is rather important, as renewable sources are usually shared among consumers,
    one example being a residential building with a PV system on the roof, where the
    PV system is used by all households in the building. Within the framework, each
    distributed renewable energy source is considered a smart device. 3.2.2. Cloud
    All data from different sources is accumulated in the cloud (households'' data,
    sensor measurements from the transmission/distribution lines or from the production
    sites, etc.). The cloud should provide massive data storage and processing infrastructure.
    It is the most advanced level of the framework (Da Xu et al., 2014, Lee and Lee,
    2015). As stated in Gubbi et al. (2013), the cloud “promises high reliability,
    scalability and autonomy” for the next generation of IoT applications. The cloud
    is the central part of this system, hence our framework can be considered as “cloud
    centric” or “cloud based”. 3.2.3. Utility This level corresponds to the remaining
    parts of the smart grid, apart from the smart home: production, transmission and
    distribution. Each part independently sends data directly to the cloud. The typical
    information that can be exchanged with the utility is: price of electricity, weather
    forecast, distribution/transmission line status, current and future consumption
    of a microgrid, current and future production of the distributed production sources
    associated with a microgrid, etc (Sajjad et al., 2014). 3.2.4. Third party Third
    party applications are developed using the cloud data (Gubbi et al., 2013). Other
    terms that are interchangeably used are business applications, industry oriented
    applications or user-specific IoT application. Namely, third party application
    developers get data from the cloud (private or public) and use this data to deliver
    solutions in the form of web based or mobile applications (Fan et al., 2010).
    3.2.5. User interfaces This level represents user interfaces that deliver data
    to the end users (notifications, recommendations, smart device controls, etc)
    (Da Xu et al., 2014). Raw tabular data referring to monthly (or even daily) household
    consumption is hard to be interpreted by the users. A more sophisticated visualization
    tool is needed to present not only the overall household consumption, but also
    the consumption at device/appliance level (Liu et al., 2014). This is particularly
    useful, since consumers will be able to learn more about different appliances
    in their home, especially ones that cannot be controlled automatically, like non-flexible
    devices, hence enabling the users to control them intuitively taking into account
    their consuming nature. Third party applications should put an effort toward developing
    intuitive visual user interfaces for the consumers and frequently evaluate those
    using Quality of Experience (QoE) metrics. 3.3. Smart home management systems
    An energy management system is defined as an interface between a utility company
    and smart devices that consume power. It aims to provide benefits for both parties
    (utilities and consumers), somewhat biased towards the consumers. Another term
    commonly used is Demand Side Management (DSM). It represents a set of technologies
    that enable monitoring and controlling the consumption/production at consumer
    level in order to perform power balancing in future energy systems (Atzeni et
    al., 2013, Rezvani et al., 2015, Siano, 2014). In the context of IoT solutions
    for smart home, the traditional DSM model is shifted toward the cloud centric
    model. The cloud based approach offers centralized optimization that considers
    a huge set of parameters; hence it is expected to outperform the energy management
    as compared to a traditional approach. Fig. 5 shows the general Smart home management
    model adopted for our holistic framework. The main tasks that should be performed
    at each level are presented as follows. Download : Download high-res image (391KB)
    Download : Download full-size image Fig. 5. General smart home management model.
    3.3.1. Smart objects/smart devices Home appliances, lights, or sensors attached
    to production or transmission lines in a smart grid system can be considered smart
    objects. They can sense, actuate, process data and communicate. In order to sense
    and actuate, they need to perform A/D and D/A conversions (Byun et al., 2012).
    These devices periodically perform sensing and send (wirelessly of wired) sensed
    data to the hub. Moreover, if protocols allow it, sensed data can be sent directly
    to the cloud. If possible, smart devices should perform basic data processing
    before they send the sensed data (Stojkoska et al., 2012, Viani et al., 2013).
    Actuating can be also controlled remotely. In the context of DSM, home appliances
    can be divided in three categories: non flexible, flexible and dual nature appliances
    (Erol-Kantarci and Mouftah, 2010). The non-flexible appliances are those that
    are associated with baseline loads or non-preemptive tasks (like light, TV, PC,
    hair drier) and cannot be controlled by the system (Ullah et al., 2013). The flexible
    appliances are associated with regular loads or preemptive tasks (like heating
    or air-conditioning) and can be automatically operated by the system. The dual
    nature appliances sometimes can act as flexible, but sometimes as non-flexible
    (like washing machine, dish washer or laundry). For example, sometimes the consumer
    does not care about the exact time the dish washer will operate, as long as it
    is within a predefined time frame. These appliances usually present burst loads
    (Khan et al., 2014, Ullah et al., 2013). The smart appliances (both flexible and
    dual nature) are equipped with smart power outlets that are able to measure their
    power consumption and to control their operation in real-time. 3.3.2. Hubs The
    hub is a device that is responsible for collecting raw and/or processed data from
    the smart devices and forwarding them to the cloud (Zhu et al., 2010). Whenever
    possible, the hub has to perform local data processing (Viani et al., 2013), in
    order to reduce the data flow towards the cloud. Furthermore, in a smart home
    scenario, the hub can send commands to the smart devices acting as a local scheduler,
    regulator, or load balancer (Byun et al., 2012). In the case of a residential
    hub, it can send commands to the devices that regulate the electricity flow to/from
    the nanogrid, i.e. to manage the operations of buying/selling electricity from/to
    the grid. The hub understands the communication protocols used by the smart devices.
    Hubs are needed to enable the interoperability between the smart objects, since
    the devices generally cannot communicate with each other (Gubbi et al., 2013,
    Heile, 2010). Hence, sometimes a household needs more than one hub. In the future,
    when full interoperability among smart devices is achieved, it is expected that
    hubs will be superfluous in the model. 3.3.3. Cloud The cloud is the most complex
    part of the home management. The main task of the cloud is to store the data (Zhou
    et al., 2013). Because of the high data volume, traditional approaches should
    be modified to meet the new requirements. New methods and algorithms based on
    machine learning techniques, time series processing and advanced analytics are
    to be employed (Da Xu et al., 2014, Gubbi et al., 2013). Third-party applications
    typically assume that the data being used is unchanging i.e. the data is usable
    by applications on a non-real-time basis. In the cloud the event-based data is
    converted to query-based processing. This is a crucial step towards bridging the
    differences of real-time IoT networking and the third-party application world.
    The data should be stored persistently and abstracted at multiple levels so that
    they could be easily combined, recomputed and/or aggregated with previously stored
    data, with the possibility of some data coming from non-IoT sources (Da Xu et
    al., 2014). Even more importantly the different levels of abstraction will simplify
    the application access and usage since data will be presented in a manner required
    by applications. 3.3.4. Third party Third party should develop applications for
    the end users in the form of schedulers, regulators, and load balancers (Fan et
    al., 2010). A scheduler is a tool responsible for defining time slots in which
    the dual nature appliances will be active. A regulator is a tool responsible for
    the management of flexible devices, i.e. it will regulate the operation of air
    conditioners, heaters, dehumidifiers, etc. Load balancing should optimize energy
    consumption, considering current electricity price on the market and availability
    of electricity produced by the local renewable sources, if available. All these
    tools need advanced algorithms that use much more parameters than those obtained
    by the home devices. They should perform the complex tasks of mining and knowledge
    extraction from the available data in the cloud in order to create consumer and
    household profiles, or in simpler words the available smart home data should lead
    to the creation of personalized recommendations for all users (Liu et al., 2014).
    4. Challenges and solutions In this section, some guidelines for future developers
    of IoT solutions on how to make good choices when dealing with different challenges
    associated with practical issues are presented. 4.1. Edge (fog) computing Edge
    computing or fog computing is the process of data processing at the edge of the
    network. In this paradigm it is expected that the knowledge extraction process
    starts as early as the time the data is sensed i.e. at the sensor side. There
    are many reasons to employ this approach, but some of the more prominent ones
    are the energy saving, data volume reduction and latency reduction. Each object/entity
    in the IoT can consume a huge amount of energy if its communication is not optimized.
    For smart objects, in terms of energy consumption, local computation is an operation
    cheaper than communication. Hence, the effort should be shifted toward developing
    lightweight algorithms for local data processing. This approach will decrease
    the data volume and will avoid sending huge portions of raw data. Instead, only
    metadata will be transmitted (data about the data). Reducing the number of transmissions
    among IoT devices is also very important in order to avoid latency issues and
    saturation of the wireless channels. For these reasons, different data reduction
    techniques should be employed to minimize the communication overhead. There are
    three main techniques used for data reduction: data compression, data prediction
    and in-network processing (Stojkoska et al., 2012). For example, if data is not
    needed in real time, data compression (like delta compression) can be used. Otherwise,
    different filters can be used for real-time sensor data prediction, most of them
    based on adaptive filtering techniques, like moving average (MA), autoregressive
    (AR) model, autoregressive moving average (ARMA), least mean square (LMS), and
    LMS with variable step size (LMS-VSS) (Risteska Stojkoska et al., 2014, Stojkoska
    et al., 2012). Prediction is performed at each device and at the hub, i.e. predictions
    are made simultaneously on both sides. If the sensed value differs significantly
    from the predicted value (the difference is above a predefined threshold emax),
    the smart device should send the measurement/data to the hub. Otherwise, the predicted
    value is considered to be “reliable” and is used to feed the filter for future
    predictions. This paradigm is known as “dual prediction scheme” (Santini and Romer,
    2006). In-network processing is the process of consecutive data processing on
    their way to the destination. As data travel through intermediate nodes, some
    aggregating operations are performed. 4.2. Big data The IoT-generated data come
    in big amounts, are variable in terms of structure, often arrive at real-time,
    and might be of uncertain provenance. This volume, velocity and variety (not to
    mention variable veracity) make the storing and analytics solution, which will
    generate useful insights, a very complex one (Zaslavsky et al., 2013). Traditional
    SQL-queried relational database management systems (RDBMSs) are unsuitable for
    the task, which is why big data solutions are needed. The IoT Cloud (Alamri et
    al., 2013, Botta et al., 2016) will enable the long-time storage and complex analysis
    of this data. The challenge of handling big data is a critical one, since the
    overall performance is directly proportional to the properties of the data management
    service (Dobre and Xhafa, 2014). A constellation of tools has evolved to service
    the market, most notably Apache''s open-source Hadoop distributed data processing
    system, plus various NoSQL databases and a range of business intelligence platforms.
    There are multiple vendors that operate in different parts of the analytics pipeline
    (data integration, data storage, core analytics and data presentation), as well
    as ''full-stack'' vendors like IBM, Microsoft, Oracle, SAP and Software AG. Both
    proprietary and open source solutions adopt alternative database technologies
    for big data (Copie et al., 2013): time-series, key-value, document store, wide
    column stores, and graph databases. However, to date there is no simple answer
    to the big data management question in the Cloud (Zaslavsky et al., 2013). The
    problem becomes even more cumbersome when the factor of data integrity is taken
    into account, not only because of its impact on the quality of service, but also
    for its security and privacy related aspects especially on outsourced data (Liu
    et al., 2015). 4.3. Networking Networking protocols for Internet of Things solutions
    can be divided in smart device networks and traditional networks that are designed
    primarily for high data rates. Smart home networking protocols are expected to
    adopt the protocols already established in Wireless Sensor Networks and Machine-to-Machine
    (M2M) communications, with no clear winner so far (Chen et al., 2012). Adding
    many advanced features to the protocol increases the cost, and reduces the ease-of-use.
    Designing an appealing protocol is not a trivial task, and is usually a tradeoff
    between the cost and the performances. In perspective of the topology to be used,
    mesh is the most suitable choice of network topology for wireless communication
    due to the presence of obstacles in the home, like walls, furniture, etc. Dual-mesh,
    which means that the network operates as both wired and wireless, is an appropriate
    solution for households that have a previously installed wired home automation
    system. There are many protocols designed for smart home solutions. Some of them
    dated back from the period when smart home was reserved for the wealthy households,
    and many new that try to combine the old design principles with the newly developed
    technologies. X10 is the oldest protocol that was initially wired, but new modifications
    make it dual-mesh. Insteon is another example of a dual-mesh protocol, which was
    recently integrated into Google owned Nest, Apple''s HomeKit platform and Apple
    Watch (Darbee, 2013). The more recent protocols work only wirelessly (ZigBee,
    Z-Wave, 6lowpan, EnOcean, etc.). There are different ways to classify protocols,
    and none of them is exhaustive enough. Using Google Scholar, we queried for publications
    that cover each of these protocols and the summary statistics for the number of
    publications is given in Table 3. This data is of November 2015. Table 3. Number
    of publications according to Google Scholar. Empty Cell Zigbee 6lowpan Z-Wave
    Bacnet X10 EnOcean Insteon Without patents 228000 9790 5770 6700 1840 1520 720
    With patents 264000 9010 7650 7550 1890 2440 1080 Table 3 shows that ZigBee is
    the most popular protocol, but this is true only for the scientific research and
    academia (ZigBee, 2015). In practice, the Z-Wave is the one that has the most
    manufacturers, mainly due to their interoperability. According to Z-Wave Alliance,
    over 35 million Z-Wave products have been sold since they began selling in 2005
    (Z-Wave Alliance, 2015). The basic features of ZigBee, Z-Wave and Insteon are
    shown in Table 4. Theoretically, a Z-Wave network is limited to a maximum of 232
    Z-Wave devices, but most vendors recommend using about 30–50 (Darbee, 2013). For
    example, MiOS LTD with their Vera products recommends 50 devices for Vera Lite,
    and 100 devices for Vera 3 (MiOS, 2015). Table 4. Basic features of ZigBee, Z-Wave
    and Insteon. Empty Cell ZigBee Z-Wave Insteon Media wireless (radio) wireless
    (radio) wireless (radio) and wired (powerline) Frequency 2.4 GHz (worldwide),
    915 MHz (Americas and Australia) and 868 MHz (Europe) <1 GHz, (868.42 MHz Europe;
    908.42 MHz United States; 916 MHz Israel; 919.82 MHz Hong Kong; 921.42 MHz Australian/New
    Zealand) single frequency of 915 MHz Network topology mesh Mesh dual-mesh Vendors
    Texas Instruments, Atmel, Silcon Labs, Freescale, etc. Sigma Designs Smartlabs,
    Logitech Maximum number of nodes 65000 (theoretically), 500 (in practice) 232
    (theoretically), 50–100 (in practice) 16777216 Range 10 to 100 m line-of-sight
    30 m open-air, < 30 m indoor 40 m Modulation Binary phase-shift keying (BPSK)
    for 868 and 915 MHz bands, or offset quadrature phase-shift keying (OQPSK) for
    2.4 GHz Gaussian, frequency-shift keying (GFSK) manchester channel encoding Frequency-shift
    keying (FSK) The price is another aspect that can be considered when choosing
    the right protocol. A ZigBee Licence costs $3500 per year, while Z-Wave charges
    $750 per device model for the logo (Darbee, 2013). A more detailed comparison
    of the smart home protocols can be found in Withanage et al. (2014). Each level
    of the IoT framework should have particular features. We identify and summarize
    the required capabilities of IoT devices at each level in Table 5. Table 5. Capabilities
    of IoT parts for smart home management system. Empty Cell Network topology Communication
    protocols Computational capabilities Memory requirements Smart Device mesh/star
    ZigBee/Z-Wave//Bluetooth/Insteon/X10, etc. low low Hub mesh/star ZigBee/Z-Wave//Bluetooth/Insteon/X10,
    etc; LTE/optical fiber/Wi-Fi intermediate low to intermediate Cloud not applicable
    LTE/optical fiber/Wi-Fi very high very high Third party not applicable LTE/optical
    fiber/Wi-Fi high application dependent, from intermediate to high 4.4. Interoperability
    Currently, the main issue for the development of a generic smart home solution
    is the cost associated with integrating smart home devices (Ko et al., 2011).
    Interoperability is the key to open markets to competitive solutions in IoT (Lu
    et al., 2011, Misra et al., 2015). Leading companies in the world that are producing
    smart devices are working toward achieving full interoperability that will ensure
    easy integration with the existing Internet. Z-Wave products are already interoperable
    with their previous versions, while ZigBee Allience with its Zigbee 3.0 has announced
    this feature to be implemented by the end of 2015. ZigBee has formed many committees
    that aim to define product properties required for different vendors to build
    interoperable devices for different public application profiles, like Home Automation,
    Health Care, Remote Control, etc. Still, products are not necessarily interoperable
    across these profiles and across revisions within a profile. On the other side,
    X10 and Insteon are fully interoperable with each other (Darbee, 2013). Table
    6 summarizes the interoperability features of these protocols. Table 6. Interoperability
    features of Insteon, X10, Z-Wave and ZigBee. Empty Cell Insteon X10 Z-Wave ZigBee
    ZigBee invisible to each other No No No Z-Wave invisible to each other No Yes
    X10 Yes Yes Insteon Yes 4.5. Security and privacy One of the most important issues
    of the emergent requirements facing the smart grid development is related to cyber
    security, both for the wireless and the wired parts of the systems (Ning et al.,
    2013, Schneps-Schneppe et al., 2012). The smart grid can be a target for cyber
    terrorists, which emerges as a critical concern for system designers. Because
    of the way in which data is transmitted, IoT is inherently vulnerable to most
    of the common attacks of wireless networks. Hence, IoT requires a security policy,
    but the cost for providing it needs to be as low as possible. Different approaches
    that provide security lightweight crypto-primitives should be investigated (Altolini
    et al., 2013), in order to provide authenticity (the device is not a malicious
    object), integrity (transmitted data is identical with the received data) and
    confidentiality (make data unreadable to others) (Dimitrievski et al., 2006).
    5. Conclusions This paper addresses the vision that the residential buildings
    would shift themselves toward modern households that would be an evolution of
    the passive household. They would have their own solar panels and small wind turbines
    to produce their own energy, thus they would be able to buy/sell energy from/to
    the smart power grid. As it is expected for smart objects to become omnipresent
    on the market and respectively in consumers'' households within the next few years,
    the need for IoT-based services for smart home will be inevitable. In this paper,
    a methodology is developed using different search queries to select the most relevant
    papers from the literature that address this topic. Selected papers were semantically
    divided into two main categories: WSN solutions and IoT concepts. This was rather
    expected considering that WSN is the pivotal technology which enabled the development
    of IoT. Although the WSN solutions are real life implementations that integrate
    devices inside a smart home, two disadvantages are identified, as they: • work
    separately and the data is used only for local optimization; • make an assumption
    of a fully (or near fully) automated home, which is a costly solution for most
    of the households. The second category of papers concerning IoT mainly presents
    concepts, theoretical frameworks and visions for possible smart home/grid solutions.
    There is a lack of a unifying platform that would transform these separate individual
    applications into a single infrastructure, a platform that can be further used
    for advanced data mining and knowledge extraction. The desired solution should
    aggregate all available smart home data within a self-learning engine in order
    to create personalized recommendations for all users, regardless of the level
    of automation present at their homes. The solution should not entail any additional
    cost for the consumers, as it should not require any particular hardware. The
    main contribution of this paper is the IoT based holistic framework, which incorporates
    different components from IoT architectures/frameworks proposed in the literature.
    This integral IoT framework is specific to the smart home application domain,
    with the cloud being the central element in the system that serves not only to
    collect and store data, but also as a gateway to third-parties interested in developing
    applications. In this context, we additionally survey the smart home management
    system, and we identify a model with a set of specific tasks that should be performed
    at each level in order to meet the system requirements. As a second contribution,
    this paper discusses challenges for IoT based smart home solutions, with emphasis
    on practical issues like data processing, networking and interoperability of smart
    home protocols. Fog and edge computing are promising approaches for improving
    the energy saving inside the IoT network by reducing the number of transmissions
    between the IoT devices. Although there are some publications that investigate
    this potential, a lot of research and work still needs to be done. New big data
    solutions and algorithms are needed to deal with the potentially vast amount of
    data generated within the IoT. A constellation of tools has already appeared in
    the last few years, as there are multiple vendors that operate in different parts
    of the analytics pipeline. Another big issue is the interoperability, which is
    a prerequirement for opening the markets to competitive solutions in IoT. The
    current situation is that devices with different protocols cannot communicate,
    and, more important, the products with the same protocols are not necessarily
    interoperable across different profiles and across revisions within the same profile.
    References Alamri et al., 2013 A. Alamri, W.S. Ansari, M.M. Hassan, M.S. Hossain,
    A. Alelaiwi, M.A. Hossain A survey on sensor-cloud: architecture, applications,
    and approaches Int. J. Distrib. Sens. Netw., 2013 (2013) Google Scholar Altolini
    et al., 2013 D. Altolini, V. Lakkundi, N. Bui, C. Tapparello, M. Rossi Low power
    link layer security for iot: implementation and performance analysis 2013 9th
    International Wireless Communications and Mobile Computing Conference (IWCMC),
    IEEE (2013), pp. 919-925 CrossRefView in ScopusGoogle Scholar Atzeni et al., 2013
    I. Atzeni, L.G. Ordóñez, G. Scutari, D.P. Palomar, J.R. Fonollosa Demand-side
    management via distributed energy generation and storage optimization IEEE Trans.
    Smart Grid, 4 (2013), pp. 866-876 View in ScopusGoogle Scholar Beel and Gipp,
    2009 J. Beel, B. Gipp Google Scholar''s ranking algorithm: an introductory overview
    Proceedings of the 12th International Conference on Scientometrics and Informetrics
    (ISSI’09). Rio de Janeiro (Brazil) (2009), pp. 230-241 View in ScopusGoogle Scholar
    Botta et al., 2016 A. Botta, W. de Donato, V. Persico, A. Pescapé Integration
    of cloud computing and internet of things: a survey Future Gener. Comput. Syst.,
    56 (2016), pp. 684-700 View PDFView articleView in ScopusGoogle Scholar Byun et
    al., 2012 J. Byun, B. Jeon, J. Noh, Y. Kim, S. Park An intelligent self-adjusting
    sensor for smart home services based on ZigBee communications IEEE Trans. Consum.
    Electron., 58 (2012), pp. 794-802 View in ScopusGoogle Scholar Caracaş et al.,
    2013 A. Caracaş, F.L. Mueller, O. Sundström, C. Binding, B. Jansen VillaSmart:
    wireless sensors for system identification in domestic buildings IEEE PES ISGT
    Europe 2013, IEEE (2013), pp. 1-5 CrossRefGoogle Scholar Cardenas et al., 2014
    J.A. Cardenas, L. Gemoets, J.H.A. Rosas, R. Sarfi A literature survey on smart
    grid distribution: an analytical approach J. Clean. Prod., 65 (2014), pp. 202-216
    View PDFView articleView in ScopusGoogle Scholar Chen et al., 2012 M. Chen, J.
    Wan, F. Li Machine-to-machine communications: architectures, standards and applications
    KSII Trans. Internet Inf. Syst. TIIS, 6 (2012), pp. 480-497 View in ScopusGoogle
    Scholar Copie et al., 2013 A. Copie, T.-F. Fortiş, V.I. Munteanu Benchmarking
    cloud databases for the requirements of the internet of things Information Technology
    Interfaces (ITI), Proceedings of the ITI 2013 35th International Conference on,
    IEEE (2013), pp. 77-82 View in ScopusGoogle Scholar Da Xu et al., 2014 L. Da Xu,
    W. He, S. Li Internet of things in industries: a survey IEEE Trans. Ind. Inf.,
    10 (2014), pp. 2233-2243 Google Scholar Darbee, 2013 P. Darbee INSTEON: Compared
    (2013) (White Paper) Google Scholar Dimitrievski et al., 2006 A. Dimitrievski,
    B. Stojkoska, K. Trivodaliev, D. Davcev Securing Communication in WSN Trough Use
    of Cryptography NATO-ARW, Suceava (2006) Google Scholar Dobre and Xhafa, 2014
    C. Dobre, F. Xhafa Intelligent services for big data science Future Gener. Comput.
    Syst., 37 (2014), pp. 267-281 View PDFView articleView in ScopusGoogle Scholar
    EcoGrid EU, 2015 EcoGrid EU, http://www.eu-ecogrid.net/, (Accessed December, 2015).
    Google Scholar Erol-Kantarci and Mouftah, 2010 M. Erol-Kantarci, H.T. Mouftah
    Wireless sensor networks for domestic energy management in smart grids Communications
    (QBSC), 2010 25th Biennial Symposium on, IEEE (2010), pp. 63-66 CrossRefView in
    ScopusGoogle Scholar Fan et al., 2010 Z. Fan, G. Kalogridis, C. Efthymiou, M.
    Sooriyabandara, M. Serizawa, J. McGeehan The new frontier of communications research:
    smart grid and smart metering Proceedings of the 1st International Conference
    on Energy-efficient Computing and Networking, ACM (2010), pp. 115-118 CrossRefGoogle
    Scholar Finn and Fitzpatrick, 2014 P. Finn, C. Fitzpatrick Demand side management
    of industrial electricity consumption: promoting the use of renewable energy through
    real-time pricing Appl. Energy, 113 (2014), pp. 11-21 View PDFView articleView
    in ScopusGoogle Scholar Franceschet, 2010 M. Franceschet A comparison of bibliometric
    indicators for computer science scholars and journals on Web of Science and Google
    Scholar Scientometrics, 83 (2010), pp. 243-258 CrossRefView in ScopusGoogle Scholar
    Gehanno et al., 2013 J.-F. Gehanno, L. Rollin, S. Darmoni Is the coverage of google
    scholar enough to be used alone for systematic reviews BMC Med. Inf. Decis. Mak.,
    13 (2013), p. 7 Google Scholar Greenfield, 2006 A. Greenfield Everyware: the Dawning
    Age of Ubiquitous Computing New Riders, Berkeley, CA (2006) Google Scholar Gubbi
    et al., 2013 J. Gubbi, R. Buyya, S. Marusic, M. Palaniswami Internet of Things
    (IoT): a vision, architectural elements, and future directions Future Gener. Comput.
    Syst., 29 (2013), pp. 1645-1660 View PDFView articleView in ScopusGoogle Scholar
    Gungor and Korkmaz, 2012 V.C. Gungor, M.K. Korkmaz Wireless link-quality estimation
    in smart grid environments Int. J. Distrib. Sens. Netw., 8 (2012) Google Scholar
    Gungor et al., 2010 V.C. Gungor, B. Lu, G.P. Hancke Opportunities and challenges
    of wireless sensor networks in smart grid IEEE Trans. Ind. Electron., 57 (2010),
    pp. 3557-3564 View in ScopusGoogle Scholar He et al., 2014 W. He, G. Yan, L. Da
    Xu Developing vehicular data cloud services in the IoT environment IEEE Trans.
    Ind. Inf., 10 (2014), pp. 1587-1595 View in ScopusGoogle Scholar Heile, 2010 B.
    Heile Smart grids for green communications [Industry Perspectives] IEEE Wirel.
    Commun., 17 (2010), pp. 4-6 View in ScopusGoogle Scholar Iyer and Agrawal, 2010
    G. Iyer, P. Agrawal Smart power grids 42nd Southeastern Symposium on System Theory
    (SSST), IEEE (2010), pp. 152-155 CrossRefView in ScopusGoogle Scholar Iyer, 2011
    S. Iyer Cyber security for smart grid, cryptography, and privacy Int. J. Digit.
    Multimed. Broadcast., 2011 (2011) Google Scholar Kamilaris et al., 2011 A. Kamilaris,
    V. Trifa, A. Pitsillides HomeWeb: an application framework for Web-based smart
    homes Telecommunications (ICT), 2011 18th International Conference on, IEEE (2011),
    pp. 134-139 CrossRefView in ScopusGoogle Scholar Karnouskos, 2011 S. Karnouskos
    Crowdsourcing information via mobile devices as a migration enabler towards the
    smartgrid Smart Grid Communications (SmartGridComm), 2011 IEEE International Conference
    on, IEEE (2011), pp. 67-72 CrossRefView in ScopusGoogle Scholar Khan et al., 2014
    M. Khan, N. Javaid, M. Arif, S. Saud, U. Qasim, Z. Khan Peak load scheduling in
    smart grid communication environment 28th International Conference on Advanced
    Information Networking and Applications, IEEE (2014), pp. 1025-1032 CrossRefView
    in ScopusGoogle Scholar Ko et al., 2011 J. Ko, A. Terzis, S. Dawson-Haggerty,
    D.E. Culler, J.W. Hui, P. Levis Connecting low-power and lossy networks to the
    internet IEEE Commun. Mag., 49 (2011), pp. 96-101 View in ScopusGoogle Scholar
    Lee and Lee, 2015 I. Lee, K. Lee The Internet of Things (IoT): applications, investments,
    and challenges for enterprises Bus. Horiz., 58 (2015), pp. 431-440 View PDFView
    articleView in ScopusGoogle Scholar Liu et al., 2015 C. Liu, C. Yang, X. Zhang,
    J. Chen External integrity verification for outsourced big data in cloud and IoT:
    a big picture Future Gener. Comput. Syst., 49 (2015), pp. 58-67 View PDFView articleView
    in ScopusGoogle Scholar Liu et al., 2014 C.H. Liu, B. Yang, T. Liu Efficient naming,
    addressing and profile services in Internet-of-Things sensory environments Ad
    Hoc Netw., 18 (2014), pp. 85-101 View PDFView articleView in ScopusGoogle Scholar
    Lu et al., 2011 C.-W. Lu, S.-C. Li, Q. Wu Interconnecting ZigBee and 6LoWPAN wireless
    sensor networks for smart grid applications Sensing Technology (ICST), 2011 Fifth
    International Conference on, IEEE (2011), pp. 267-272 View in ScopusGoogle Scholar
    Lund et al., 2015 P.D. Lund, J. Mikkola, J. Ypyä Smart energy system design for
    large clean power schemes in urban areas J. Clean. Prod., 103 (2015), pp. 437-445
    View PDFView articleView in ScopusGoogle Scholar Mainetti et al., 2011 L. Mainetti,
    L. Patrono, A. Vilei Evolution of wireless sensor networks towards the internet
    of things: a survey Software, Telecommunications and Computer Networks (SoftCOM),
    2011 19th International Conference on, IEEE (2011), pp. 1-6 CrossRefGoogle Scholar
    MiOS, 2015 MiOS, http://faq.mios.com/content/1/6/en/how-many-z_wave-devices-can-be-added.html,
    (Accessed December, 2015). Google Scholar Misra et al., 2015 P. Misra, V. Rajaraman,
    K. Dhotrad, J. Warrior, Y. Simmhan An Interoperable Realization of Smart Cities
    with Plug and Play Based Device Management (2015) arXiv preprint arXiv:1503.00923
    Google Scholar Monacchi et al., 2013 A. Monacchi, D. Egarter, W. Elmenreich Integrating
    households into the smart grid Modeling and Simulation of Cyber-physical Energy
    Systems (MSCPES), 2013 Workshop on, IEEE (2013), pp. 1-6 Google Scholar Ning et
    al., 2013 H. Ning, H. Liu, L.T. Yang Cyberentity security in the internet of things
    Computer, 46 (2013), pp. 46-53 View in ScopusGoogle Scholar Oppermann et al.,
    2014 F.J. Oppermann, C.A. Boano, K. Römer A Decade of Wireless Sensing Applications:
    Survey and Taxonomy, the Art of Wireless Sensor Networks Springer (2014), pp.
    11-50 CrossRefView in ScopusGoogle Scholar Palensky and Dietrich, 2011 P. Palensky,
    D. Dietrich Demand side management: demand response, intelligent energy systems,
    and smart loads IEEE Trans. Ind. Inf., 7 (2011), pp. 381-388 View in ScopusGoogle
    Scholar Parikh et al., 2010 P.P. Parikh, M.G. Kanabar, T.S. Sidhu Opportunities
    and challenges of wireless communication technologies for smart grid applications
    IEEE PES General Meeting, IEEE (2010), pp. 1-7 CrossRefGoogle Scholar Rezvani
    et al., 2015 A. Rezvani, M. Gandomkar, M. Izadbakhsh, A. Ahmadi Environmental/economic
    scheduling of a micro-grid with renewable energy resources J. Clean. Prod., 87
    (2015), pp. 216-226 View PDFView articleView in ScopusGoogle Scholar Risteska
    Stojkoska et al., 2014 B. Risteska Stojkoska, A. Popovska Avramova, P. Chatzimisios
    Application of wireless sensor networks for indoor temperature regulation Int.
    J. Distrib. Sens. Netw., 2014 (2014) Google Scholar Sajjad et al., 2014 I.A. Sajjad,
    R. Napoli, G. Chicco Future business model for cellular microgrids 4th International
    Symposium on Business Modeling and Software Design (BMSD) (2014), pp. 209-216
    View in ScopusGoogle Scholar Santini and Romer, 2006 S. Santini, K. Romer An adaptive
    strategy for quality-based data reduction in wireless sensor networks Proceedings
    of the 3rd International Conference on Networked Sensing Systems (INSS 2006) (2006),
    pp. 29-36 Google Scholar Schneps-Schneppe et al., 2012 M. Schneps-Schneppe, A.
    Maximenko, D. Namiot, D. Malov Wired Smart Home: energy metering, security, and
    emergency issues Ultra Modern Telecommunications and Control Systems and Workshops
    (ICUMT), 2012 4th International Congress on, IEEE (2012), pp. 405-410 CrossRefView
    in ScopusGoogle Scholar Shrouf and Miragliotta, 2015 F. Shrouf, G. Miragliotta
    Energy management based on Internet of Things: practices and framework for adoption
    in production management J. Clean. Prod., 100 (2015), pp. 235-246 View PDFView
    articleView in ScopusGoogle Scholar Siano, 2014 P. Siano Demand response and smart
    grids—A survey Renew. Sustain. Energy Rev., 30 (2014), pp. 461-478 View PDFView
    articleView in ScopusGoogle Scholar Srbinovska et al., 2015 M. Srbinovska, C.
    Gavrovski, V. Dimcev, A. Krkoleva, V. Borozan Environmental parameters monitoring
    in precision agriculture using wireless sensor networks J. Clean. Prod., 88 (2015),
    pp. 297-307 View PDFView articleView in ScopusGoogle Scholar Stojkoska and Davcev,
    2009 B. Stojkoska, D. Davcev Web interface for habitat monitoring using wireless
    sensor network Wireless and Mobile Communications, 2009. ICWMC''09. Fifth International
    Conference on, IEEE (2009), pp. 157-162 CrossRefView in ScopusGoogle Scholar Stojkoska
    et al., 2012 B.R. Stojkoska, D. Solev, D. Davcev Variable step size LMS Algorithm
    for Data Prediction in wireless sensor networks Sens. Transducers, 14 (2012),
    p. 111 Google Scholar Ullah et al., 2013 M. Ullah, A. Mahmood, S. Razzaq, M. Ilahi,
    R. Khan, N. Javaid A Survey of Different Residential Energy Consumption Controlling
    Techniques for Autonomous DSM in Future Smart Grid Communications (2013) arXiv
    preprint arXiv:1306.1134 Google Scholar Viani et al., 2013 F. Viani, F. Robol,
    A. Polo, P. Rocca, G. Oliveri, A. Massa Wireless architectures for heterogeneous
    sensing in smart home applications: concepts and real implementation Proc. IEEE,
    101 (2013), pp. 2381-2396 View in ScopusGoogle Scholar Withanage et al., 2014
    C. Withanage, R. Ashok, C. Yuen, K. Otto A comparison of the popular home automation
    technologies 2014 IEEE Innovative Smart Grid Technologies-Asia (ISGT ASIA), IEEE
    (2014), pp. 600-605 CrossRefView in ScopusGoogle Scholar Xu et al., 2014 B. Xu,
    L. Da Xu, H. Cai, C. Xie, J. Hu, F. Bu Ubiquitous data accessing method in IoT-based
    information system for emergency medical services IEEE Trans. Ind. Inf., 10 (2014),
    pp. 1578-1586 View in ScopusGoogle Scholar Z-Wave Alliance, 2015 Z-Wave Alliance,
    http://products.z-wavealliance.org/, (Accessed December, 2015). Google Scholar
    Zaslavsky et al., 2013 A. Zaslavsky, C. Perera, D. Georgakopoulos Sensing as a
    Service and Big Data (2013) arXiv preprint arXiv:1301.0159 Google Scholar Zhou
    et al., 2013 J. Zhou, T. Leppänen, E. Harjula, M. Ylianttila, T. Ojala, C. Yu,
    H. Jin Cloudthings: a common architecture for integrating the internet of things
    with cloud computing Computer Supported Cooperative Work in Design (CSCWD), 2013
    IEEE 17th International Conference on, IEEE (2013), pp. 651-657 CrossRefView in
    ScopusGoogle Scholar Zhu et al., 2010 Q. Zhu, R. Wang, Q. Chen, Y. Liu, W. Qin
    Iot gateway: bridgingwireless sensor networks into internet of things Embedded
    and Ubiquitous Computing (EUC), 2010 IEEE/IFIP 8th International Conference on,
    IEEE (2010), pp. 347-352 CrossRefView in ScopusGoogle Scholar ZigBee, 2015 ZigBee,
    http://www.zigbee.org/, (Accessed December, 2015). Google Scholar Cited by (1020)
    Machine learning-based gait health monitoring for multi-occupant smart homes 2024,
    Internet of Things (Netherlands) Show abstract Smart home energy management systems:
    Research challenges and survey 2024, Alexandria Engineering Journal Show abstract
    Blockchain-based cloud-fog collaborative smart home authentication scheme 2024,
    Computer Networks Show abstract Conductive chenille yarn-based triboelectric carpet
    fabrics with enhanced flexibility and comfort for smart home monitoring 2024,
    Materials Today Energy Show abstract IfNot: An approach towards mitigating interest
    flooding attacks in Named Data Networking of Things 2024, Internet of Things (Netherlands)
    Show abstract Rational design and optimization of self-powered instantaneous dual-parameter
    triboelectric sensor 2024, Sensors and Actuators A: Physical Show abstract View
    all citing articles on Scopus View Abstract © 2016 Elsevier Ltd. All rights reserved.
    Recommended articles Regeneration of activated carbon from babassu coconut refuse,
    applied as a complementary treatment to conventional refinery hydrotreatment of
    diesel fuel Journal of Cleaner Production, Volume 140, Part 3, 2017, pp. 1465-1469
    Caroline Carriel Schmitt, …, Carlos Itsuo Yamamoto View PDF Smart home technologies
    in everyday life: do they address key energy challenges in households? Current
    Opinion in Environmental Sustainability, Volume 31, 2018, pp. 65-70 Sergio Tirado
    Herrero, …, Yolande Strengers View PDF Supporting end users to control their smart
    home: design implications from a literature review and an empirical investigation
    Journal of Systems and Software, Volume 144, 2018, pp. 295-313 Danilo Caivano,
    …, Fabio Cassano View PDF Show 3 more articles Article Metrics Citations Citation
    Indexes: 945 Policy Citations: 5 Captures Readers: 2043 Mentions News Mentions:
    2 References: 1 Social Media Shares, Likes & Comments: 78 View details About ScienceDirect
    Remote access Shopping cart Advertise Contact and support Terms and conditions
    Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices
    All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply.'
  inline_citation: '>'
  journal: Journal of cleaner production
  limitations: '>'
  pdf_link: null
  publication_year: 2017
  relevance_score1: 0
  relevance_score2: 0
  title: 'A review of Internet of Things for smart home: Challenges and solutions'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.iot.2019.100118
  analysis: '>'
  authors:
  - Sukhpal Singh Gill
  - Shreshth Tuli
  - Minxian Xu
  - Inderpreet Singh
  - Karan Vijay Singh
  - Dominic Lindsay
  - Daria Smirnova
  - Manmeet Singh
  - Udit Jain
  - Haris Pervaiz
  - Bhanu Sehgal
  - Sukhwinder Singh Kaila
  - Sanjay Misra
  - Mohammad Sadegh Aslanpour
  - Harshit Mehta
  - Vlado Stankovski
  - Peter Garraghan
  citation_count: 248
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Graphical abstract Keywords 1. Introduction 2. Background:
    history of decades 3. Triumvirate: IoT + AI + Blockchain 4. Impact of new paradigms
    and technologies on cloud computing: open challenges and trends 5. Insights of
    triumvirate to the cloud computing evolution: A vision 6. A conceptual model for
    cloud futurology: Holistic view 7. Summary and conclusions Declaration of Competing
    Interest Acknowledgments References Show full outline Cited by (313) Figures (5)
    Internet of Things Volume 8, December 2019, 100118 Review article Transformative
    effects of IoT, Blockchain and Artificial Intelligence on cloud computing: Evolution,
    vision, trends and open challenges Author links open overlay panel Sukhpal Singh
    Gill a, Shreshth Tuli b, Minxian Xu c, Inderpreet Singh d q, Karan Vijay Singh
    e r, Dominic Lindsay f, Shikhar Tuli g, Daria Smirnova f, Manmeet Singh h i, Udit
    Jain b, Haris Pervaiz f, Bhanu Sehgal j, Sukhwinder Singh Kaila k, Sanjay Misra
    l m, Mohammad Sadegh Aslanpour n, Harshit Mehta o s, Vlado Stankovski p, Peter
    Garraghan f Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.iot.2019.100118
    Get rights and content Highlights • Transformative effects of emerging paradigms
    and technologies on cloud computing systems. • To study the history and evolution
    of cloud computing from year 1958. • To identify the influence of triumvirate
    “IoT + AI + Blockchain” on cloud computing. • Vision and trends for academicians,
    practitioners and researchers working in cloud. • Cloud futurology model to manage
    next-generation computing systems holistically. Abstract Cloud computing plays
    a critical role in modern society and enables a range of applications from infrastructure
    to social media. Such system must cope with varying load and evolving usage reflecting
    societies’ interaction and dependency on automated computing systems whilst satisfying
    Quality of Service (QoS) guarantees. Enabling these systems are a cohort of conceptual
    technologies, synthesized to meet demand of evolving computing applications. In
    order to understand current and future challenges of such system, there is a need
    to identify key technologies enabling future applications. In this study, we aim
    to explore how three emerging paradigms (Blockchain, IoT and Artificial Intelligence)
    will influence future cloud computing systems. Further, we identify several technologies
    driving these paradigms and invite international experts to discuss the current
    status and future directions of cloud computing. Finally, we proposed a conceptual
    model for cloud futurology to explore the influence of emerging paradigms and
    technologies on evolution of cloud computing. Graphical abstract Download : Download
    full-size image Previous article in issue Next article in issue Keywords Cloud
    computingQuality of ServiceCloud applicationsCloud paradigms and technologiesIoTBlockchainArtificial
    Intelligence 1. Introduction The last two decades have seen active research in
    the definition and evolution of cloud computing. Driven by innovation in networking
    and distributed architectures, cloud computing is a manifestation of distributed
    systems research since the initial conception of the client server model in 1958
    [2]. Due to the rapid growth of cloud computing, it has been adopted as an important
    utility across all aspects of society, from academia, governmental institutions
    and industry. Characteristics of cloud computing such as dynamic, metered access
    to a shared pools of computing resources [1] have enabled the realization of new
    technologies and paradigms to fulfill the demands of emerging applications including
    scientific, healthcare, agriculture, smart city, and traffic management [3]. Presently,
    well-known cloud providers such as Facebook, Google and Amazon utilize large-scale
    Cloud Data Centers (CDCs) to provision heterogeneous Quality of Service (QoS)
    requirements. Furthermore, cloud computing platforms are able to provide a unified
    interface over heterogeneous resource found in the Internet of Things (IoT)-based
    applications which improve the reliability of cloud services [4]. There is a need
    to sign a Service Level Agreement (SLA) between cloud user and provider to deliver
    the required service in specified time and budget based on QoS parameters. Substantial
    growth in end-user demand and data volume has resulted in the creation of more
    CDCs at ever growing scale, which in turn increases system energy consumption,
    CO2 emissions, and waste heat that requires cooling infrastructure for removal.
    To address the problem of energy consumption, there is a need for new resource
    scheduling policies to reduce the energy consumption without impacting QoS such
    as deadline, reliability, availability, cost, security and privacy [5]. To increase
    the reliability of the cloud computing systems, there is a need to develop new
    fault tolerant mechanisms, which can maintain the cloud service quality during
    the occurrence of hardware or software faults. Moreover, security can be improved
    by using new technology called Blockchain (it is distributed ledgers within Cloud)
    to protect the communication from attackers, which can further increase reliability
    of the computing systems [46]. The diversity of large distributed application
    means there is a requirement for effective big data analytics mechanisms to process
    the required data in an efficient manner using innovative data processing techniques
    [61,66]. Further, new programming models such as serverless computing enable new
    patterns of resource consumption, autonomically driven by application utilization.
    Lightweight virtualization provided by container technologies, can improve utilization
    in clouds, and enable low latency provisioning of application environments [150].
    Further, the emergence of fog computing reduces the latency and response time
    of processing in IoT devices but still research challenges within this domain
    are not solved effectively. New resource provisioning and scheduling polices are
    required for fog and cloud computing using Artificial Intelligence (AI) based
    deep learning techniques to predict the resource requirement in advance for geographically
    disparate resources [47,140]. Cloud Computing is emerging as a new tool for solving
    the complex challenges faced by the Earth Sciences researchers both in the context
    of compute and analysis [139]. It offers a promising hope for the community which
    presently relies on dedicated supercomputers coming at a huge cost and can regularly
    go through slag periods or inefficiencies. The introduction of cloud computing
    as a supplicant or replacement of dedicated supercomputers is an interesting hypothesis.
    Due to continuous growing research in the field of cloud computing, there are
    various new research areas such as quantum computing, software-defined network,
    software engineering, bitcoin currency, 5G network and beyond are emerged. 1.1.
    Our contributions Earlier methodical surveys and system reviews have been identified
    previous innovations, however innovations in the field of cloud computing require
    a revisit of paradigms (IoT, AI, and Blockchain) driving cloud computing. There
    is a requirement for a systematic review to evaluate, upgrade, and integrate the
    existing research presented in this field with respect to the emerging paradigms
    and technologies such as IoT, AI and Blockchain. This systematic review presents
    an updated study to evaluate and discover the research challenges based on the
    available existing research along with the evolution and history of computing
    systems as per new frontiers as an amalgamation of these technologies having a
    high impact on cloud computing and related domains. Finally, we offers critical
    insights and points out possible future work. We proposed a conceptual model which
    integrates and enables computation using a plethora of technological advancements
    and provides an enhanced and holistic setup for next generation computing environments.
    The motivation behind this systematic review is to study the history of computing
    and identify how the emergence of triumvirate “IoT + AI + Blockchain” will transform
    cloud computing to solve complex problems of next generation computing. Further,
    the international experts of different cloud computing research areas come together
    and discuss the existing research and proposed future research directions for
    academicians, practitioners and researchers working in the field of cloud computing.
    This is the first systematic review which explores the evolution of computing
    paradigms and technologies and the influence of triumvirate (Blockchain, IoT and
    Artificial Intelligence) to the evolution of cloud computing. The rest of the
    article is structured as follows: Section 2 presents the background of cloud computing
    paradigms and techniques and their evolution. Section 3 presents the drivers (IoT,
    AI and Blockchain) of cloud computing. Section 4 presents the impact of new paradigms
    and technologies on cloud computing along with their future research opportunities
    and open challenges. Section 5 presents the insights of triumvirate to the cloud
    computing evolution. Section 6 presents a conceptual model for cloud futurology.
    Finally, Section 7 summarizes the research article. 2. Background: history of
    decades Computing systems have evolved from year 1958 to improve the use of hardware
    resources in an efficient way. During these decades of computing, there have been
    various types of computing paradigms and technologies have been developed and
    invented, which contributes extensively to the current research in the field of
    computing. 2.1. Evolution of computing paradigms and technologies: a journey Initially,
    one system can execute one specific task at a time and multiple systems are needed
    to run parallelly to execute multiple tasks concurrently [1]. A secure communication
    network is required to exchange data among different computing systems. Fig. 1
    shows the evolution of computing technology along with their objectives and focus
    of study from year 1958. • Client server: This is distribution application or
    centralized system developed in 1960 to divide the workloads or tasks among resource
    providers (servers) and clients are service requesters [1]. Computer network is
    used to communicate between servers and clients and server shares resources with
    clients to execute their workloads in a load balancing manner [2]. Email and World
    Wide Web (WWW) are two important examples of client server model. In this model,
    clients cannot communicate with each other directly [7]. • Supercomputer: It is
    a system with high performance computing capability to execute computationally
    intensive tasks in different scientific fields such as molecular modeling, climate
    research and quantum mechanics [3]. Energy usage and heat management in supercomputers
    remained a main research challenge thought its evolution since 1960 [7]. The important
    examples of supercomputers are Multivac, HAL-9000 and The Machine Stops [2]. •
    Proprietary mainframe: This is large-high speed computer, which can further support
    various devices and workstations, are used to process large amount of data such
    as transaction processing, consumer statistics and census [4]. Mainframe computers
    can provide reliability and security and achieves high throughput through virtualization
    [7]. In year 2017, IBM launched latest version of mainframe IBM z14 [2]. The performance
    of mainframe computer is excellent, but these computers are quite expensive. •
    Cluster computing: This technology uses fast local area network to communicate
    available computing nodes and clustering middleware is used to make coordination
    among different computing nodes [5]. The main objective of cluster computing is
    to execute a single task using different interconnected computing nodes to improve
    the performance of computing environment [1]. • Open massively parallel processing
    (MPP) and symmetric multi-processing (SMP): There are two main types of parallel
    processing environments: massively parallel processing (MPP) and symmetric multiprocessing
    (SMP) systems [1], [2], [3]. In SMP environment, other hardware resources (disk
    space, memory) are shared by multiple processors but using a single operating
    system. The sharing of resources effects the computing speed of the completion
    of a particular job [7]. In MPP environment, only file system is shared but there
    is no sharing of resources during execution of job. The scalability can be improved
    by adding computers and related disk and memory resources. • Grid computing: This
    technology enables to achieve a common objective using distributed computing resources
    and executes non-interactive workloads, which contains huge number of files [4,5].
    The single grid is dedicated to an execution of a specific application [7]. Grid
    computing provides services such as resource allocation and management service,
    secure infrastructure and monitoring and discovery service. • Commodity clusters:
    It is also called commodity cluster computing, which offers low cost computation
    of user workloads by using huge numbers of computing resources in a concurrent
    manner [2,4]. Different vendors are using open standards to manufacture commodity
    computers to reduce the variation among products of vendors [7]. Presently, off-the-shelf
    commodity computers are available to fulfill the business computing requirements
    quickly. • Peer to peer: It is a distributed architecture to divide the workload
    or task among different peers or computing nodes and peers can communicate with
    each other directly at application layer [4,7]. In Peer to peer architecture,
    peers can access different resources such as processing power, disk storage or
    network bandwidth without the requirement of central coordinator. TCP/IP network
    is using to exchange data among peers. The main applications of peer to peer architecture
    are multimedia, file-sharing networks and content delivery. • Web services: This
    technology enables the communication among different electronic devices through
    World Wide Web using different types of machine-readable file formats such as
    JavaScript Object Notation (JSON) and Extensible Markup Language (XML) [1,2].
    Basically, web service provides the user interface to end user for the interaction
    with database server [7]. • Virtualized clusters: It is an implementation of a
    real computing system to perform similar functions using virtualized environment
    [1]. Virtualized cluster enables the sharing of resources among different Virtual
    Machines (VM) to execute workloads or tasks [2]. VM hypervisor provides the software
    layer-based virtualization to execute on top of operating system or on the bare
    metal [7]. VM based computing systems saves resource cost and executes the large
    number of workloads using same resources. • HPC system: This is the tool which
    is used to solve large problems (which requires high computing power) of business,
    engineering and science [5]. High Performance Computing (HPC) system contains
    different types of computing resources to solve different types of problems and
    access these resources are controlled by batch system or scheduler [5,7]. HPC
    systems are sharing resources and it can access different resources remotely and
    execute workloads or tasks using scheduling of parallel resources. • IaaS, PaaS,
    SaaS: There are different types of web services, which can be accessed via Internet
    such as SaaS (Software as a Service), PaaS (Platform as a Service) and IaaS (Infrastructure
    as a Service) [6]. SaaS offers software functionality as a service without any
    maintenance and initial cost with high quality and an example of SaaS is Gmail.
    PaaS offers the framework, where user can deploy their application with required
    scalability and an example of PaaS is Microsoft. IaaS offers infrastructure resources
    such as network, memory, storage and processor to execute workloads or tasks in
    a cost and time optimized manner and an example of IaaS is Amazon. • Cloud computing:
    The cloud services are generally denoted by – XaaS where X = {I, P, S…} and practice
    of using remote resources to execute user tasks (processing, management and storage
    of data) through Internet [6]. Cloud computing enables sharing of resources to
    reduce execution cost and increase availability of service. There are four different
    types of cloud computing models: public, private, hybrid and community. The Quality
    of Service (QoS) parameters such as reliability, security and energy efficiency
    are important to deliver an efficient cloud service. • Fog computing: This is
    latest architecture which performs significant amount of storage and computation
    using end devices or fog nodes and Internet is used to establish communication
    among these devices [151]. Fog computing comprise of data plane and control plane
    [6]. Data plane provide services at the edge of network to reduce latency and
    increase QoS, while control plane is part of router and decides network topology
    [8]. Further, fog computing supports Internet of Things (IoT) devices such as
    mobile phones, sensors, health monitoring devices. • Internet of Things: IoT devices
    are network devices such as actuators, software, home appliances and sensors and
    Internet connectivity is used to exchange data among these network devices [8].
    There are number of applications of IoT in different fields such as agriculture,
    healthcare, weather forecasting, transportation, smart home and industrial robotics
    [152,153]. • Edge computing: It is a distributed computing paradigm, which performs
    computation on distributed edge devices and it enables the data collection and
    communication over network [6]. Further, edge computing moves the large volume
    of data by processing at edge devices instead of cloud server, which improves
    the QoS, reduce latency and transmission cost [8,154,155]. The time sensitive
    applications can take more advantage from edge computing, but it needs continuous
    Internet connection to perform dedicated functions within given time. Download
    : Download full-size image Fig. 1. Evolution of computing paradigms and technologies.
    3. Triumvirate: IoT + AI + Blockchain Cloud computing becomes an intelligent computing
    with the emergence of innovative technologies and paradigms such as Internet of
    Things, Blockchain and Artificial Intelligence. 3.1. Internet of Things (IoT)
    The modern Internet integrates objects known as Things, equipped with sensing,
    actuating and networking capabilities with dynamic monitoring and control services.
    Such devices are pervasive in modern life and can be found in homes, public transport,
    motorways and vehicles [22]. As such, IoT applications are able to operate across
    heterogeneous domains and enable rich analyses and management of complex interactions
    [150]. Thus, IoT devices and service are able to address challenges in a wide
    range of application domains, including e-health, infrastructure, building management
    systems, manufacturing and transport [23], [24], [25]. The Internet of Things
    possess several characteristics central to their operation, including: (I) Systems
    are often highly dynamic and network membership must cope with volatility, where
    a device may appear and reaper across several networks [24], (II) devices are
    highly heterogeneous in terms of both computing performance and functional capabilities,
    and as such system must cope with limited processing, memory and persistent storage
    [26] and (III) Systems are managed and controlled by multiple stakeholders, requiring
    federated mechanisms for secure management of collected IoT data [25]. Historically
    IoT applications have offloaded processing, and persistent storage to cloud services,
    however as the number of ‘Things’ grows, these services fail to support real time
    demand of IoT devices [24, 27]. This is because such systems operate in physical
    environments, across large geographic ranges, and as such require low latency
    response times, and have high density data ingestion requirements/bandwidths [46].
    Fog/Edge computing extends cloud system boundaries, by decentralizing resource
    orchestration from datacenters to edge networks [25]. Organized as hierarchal
    networks of Fog nodes or cloudlets [28] providing deployment of ingestion, processing
    and management services. Geographic locality allows lower response latencies and
    increase''s ingestion bandwidth by horizontally scaling resources, whilst consuming
    less energy and enabling resource mobility when compared to cloud services. These
    characteristics enable IoT applications to scale in terms of a both logical scale
    and geographic range, whilst providing real-time response latencies, and as such
    Fog/Edge computing can be considered a future architecture of IoT applications
    [23]. Smart e-health applications are able to monitor patient data in real-time,
    by collecting data from implantable and wearable devices forming personal area
    networks [61]. Smart-Gateways collect and perform local processing of data collected
    from devices, including noise filtering from medical devices, data compression
    and fusion, and analyses allowing detection of dangerous trends in a patient''s
    health. Whilst long term trends can be analyzed at cloud layers [22,29]. Furthermore,
    Fog enabled IoT systems are adaptable and can change their behavior according
    to state determined by collected sensors’ data. For instance, a smart gateway
    collecting samples from a pacemaker can increase its sample prior to a heart attack,
    detected via pre-processing at the fog layer [22,25,29]. The Internet of Energy
    (IoE) paradigm introduces the notion of smart grids and energy management [30].
    In which distributed networks energy generators capable of monitoring power consumption
    and generator, or battery capacity and providing coarse grained statistics about
    grid health. Whilst ‘Smart-Meters’ are able to monitor capacity, generation and
    usage at a finer granularity and report energy demands to utility providers [25,30,31].
    As such, IoT is enabling technology of future systems, such as electronic vehicles,
    and micro-grids. Furthermore, such a grid can provide safer, more reliable and
    robust power delivery, to meet changing consumer demands [32]. The interested
    readers can further explore using extensive surveys on IoT [8,22,[24], [25], [26].
    3.2. Blockchain Recently Fog, Edge and Cloud computing paradigms have gained significant
    popularity both in industry and academia. With their increased usage in real-life
    scenarios; security, privacy and integrity of data in such frameworks has gained
    high importance [9]. Malicious deletion, theft and corruption of data due to ransomware,
    trojans and viruses, etc. has been a menace in this domain [10]. Maintaining integrity
    of data and ensuring that data is not sent by unregistered source are very important
    for the credibility of the systems [14]. Being used in mission critical applications
    like hospital care, Smart cities, transportation, surveillance, the tolerance
    in such systems is very low. As most Edge devices have compute and storage limitations;
    difficult constraints arise in providing an optimal scheme for data protection
    and maintaining integrity. To ensure data is protected, Blockchain technology
    has been adopted in the IoT domain and other real time systems. Theoretically,
    Blockchain is a suite of distributed ledgers that can record and track the value
    of a commodity [11,129]. Whenever new data is added to the system, it is converted
    to a Block where a Proof of Work (PoW) is created, which is a hash value difficult
    to produce without changing the PoW of all blocks preceding it in the ledger.
    Miners in the Fog system mine the blocks and generate and validate such PoWs.
    Once a miner completes the proof of work, it publishes the new block in the network
    and the rest of the network verifies its validity before adding it to the chain.
    Moreover, this fraudulent manipulation of data in a Blockchain will not be successful
    unless 50% of its distributed copies are individually reformed by following the
    same set of operations. Thus, it becomes very hard to alter any data in Blockchain
    within rigid time limit. To support and operate with the Blockchain, network peers
    must provide, the following functionality: routing, storage, wallet services and
    mining [12]. Despite such problems there have been many efforts to provide robust
    frameworks that integrate Blockchain with Fog computing [15], [16], [17]. Most
    such frameworks like FogBus in [15] maintain a dynamically allocated mining strategy
    where some nodes which are less utilized at a point of time mine and validate
    the chains and others are used for load distribution, compute and data collection.
    If any worker reports error in terms of Blockchain tampering or signature forgery,
    then the Blockchain in majority of the network is copied to that node. Other additional
    features that they provide are encryption with dynamic exchange of public key
    pairs for identity authentication. Although, the key concept of Blockchain is
    simple, it faces from several challenges while integrating with Fog computing
    frameworks. Storage capacity and scalability are highly debated due to high cost
    and maintenance overheads [13]. Even though, only full nodes (nodes that can fully
    validate the transactions or blocks) store the full chain, the storage requirements
    are significant. Another weakness of Blockchain is the anonymity and privacy of
    data. Privacy as such is not embedded in the design of Blockchain and hence third-party
    software are required to achieve this. This may lead to unoptimized implementations
    which are more expensive in terms of compute and storage requirements. Many open
    challenges and directions are still existing where Blockchains can be improved
    in IoT frameworks. Resource limitation is the main limiting factor for high quality
    data protection and reliability. Due to resource constraints, highly sophisticated
    encryption or key generation cannot be integrated with such chains of data. Only
    limited cryptographic algorithms can be deployed. More efficient algorithms can
    be developed keeping in mind of the resource constraints. Another important direction
    is the modification of such chains in high fault rate settings where the edge
    nodes can be compromised at any instant of times. Revalidating blocks and copying
    chains from the majority network leads to large overhead on network and I/O bandwidth
    requirements. Most frameworks also work in a Master–Slave fashion and hence have
    single point of failure. This is natural in heterogeneous environments. Significant
    research is needed to ensure redundancy while keeping in views the costs and reliability
    trade-offs. Also, the Blockchain vulnerabilities still affect Fog frameworks [18].
    Effective consensus mechanisms need to be developed that can validate blocks with
    limited sharing and copying of blocks. The interested readers can further explore
    using extensive survey on Blockchain [179]. 3.3. Artificial Intelligence Artificial
    Intelligence (AI) aims to make IoT and Fog nodes aware of the workload environment
    and continuously adapt to provide better QoS characteristics, reduce power consumption
    or overall cost of the infrastructure. AI encompasses various search algorithms,
    machine learning, reinforcement learning and planning [146]. In the modern world
    of data intensive tasks with growing fog and cloud deployments, more and more
    intelligence are required at different levels to provide optimum task scheduling
    decisions, VM migrations, etc. to optimize mentioned previously under various
    constraints. These constraints can range from computation capabilities, bandwidth
    limits to SLA or deadline requirements of tasks. There have been several works
    that aim at leveraging AI techniques to improve the performance of fog and cloud
    systems [144,145,[147], [148], [149]. Different works focus on optimum scheduling
    policies for cloud, virtualization algorithms, distribution systems among others.
    They use search methods like genetic algorithms, supervised machine learning and
    even deep reinforcement learning to optimize their objective functions [154,155].
    AI provides a lucrative avenue to optimize large systems with huge amounts of
    data with engineering simplicity and efficiency by allowing automated decision
    making instead of human encoded heuristics which provide more efficient decisions
    very quickly. Cloud computing is growing quickly, and CDCs become an important
    part of eminent industries such as Facebook, Microsoft, Google, Amazon [58]. However,
    it is difficult to monitor the performance of large-scale cloud data centers manually.
    Yotascale is a next generation computing and automatic performance monitor solution
    to reduce the accountability on humans. Yotascale uses historical data to make
    forward predictions or decisions about cloud costs using Artificial Intelligence
    and helps to save more cost. Further, real-time analysis can be done using Yotascale
    to detect anomalous trends using deep learning techniques (supervised/unsupervised
    techniques or prediction models), finds the root cause and gives future predictions
    about cloud usage and its cost. The interested readers can further explore using
    extensive surveys on AI [180,181]. 4. Impact of new paradigms and technologies
    on cloud computing: open challenges and trends Cloud computing is evolving very
    rapidly, and various number of researchers and academicians are working actively
    to solve the research challenges existing within the cloud computing domain. We
    have identified various research areas related to cloud computing, which utilizes
    its available technologies and paradigms in an efficient manner to solve the current
    problems. Fig. 2 shows the emerging research areas for future practitioners, industries,
    academicians and researchers. Download : Download full-size image Fig. 2. Emerging
    research areas. We have given the foundations of emerging paradigms and technologies
    for researchers, academicians and practitioners in this section and their corresponding
    future research directions and open challenges are presented at the end of every
    subsection. 4.1. QoS and SLA Quality of Service (QoS) is an important challenge
    of cloud computing systems, which can predict the performance of the system at
    runtime [6]. The QoS parameters such as execution time, cost, scalability, elasticity,
    latency, reliability etc. can measures the performance of the computing system
    [46]. QoS parameters are defined using Service Level Agreement (SLA), which is
    an official document signed between cloud user and provider based on different
    QoS parameters [157]. In this era, there are wide range of IoT applications which
    have different QoS parameters based on their domain, purpose and requirement [52]
    with more stringent security requirement which can utilize Blockchain and related
    technologies. Further, SLA can be measured using a metric called SLA violation
    rate, which can estimate the deviation of actual SLA from the required (estimated/predicted)
    and decides about the compensation in case of SLA violation [53]. QoS is progressively
    important when comprising cloud services because damaging QoS in one of the services
    can hazardously affect the QoS of whole computing system. To offer an efficient
    cloud service, there is a need to provision the required amount of cloud resources,
    which can fulfill the QoS of an application such as budget, response time and
    deadline [55,56]. Therefore, cloud providers must ensure to provision enough resources
    to avoid or reduce the SLA violation rate in order to execute the user workloads
    within their specified deadline and budget. The future of next-generation computing
    systems depends on the QoS-aware resource management mechanisms, which can identify
    and satisfy the QoS requirements of the computing system [6,58]. There are various
    research challenges [59,61,63,66,67] are existing which hinders the achievement
    of QoS in an efficient manner. Firstly, there is an unavailability of cloud resources
    to execute an application at runtime, which increases the execution time and reduce
    the performance of the system. Secondly, there is a need of an efficient SLA-aware
    resource management mechanisms reduces the SLA violation rate and maintain the
    performance of the computing system. Thirdly, there are different SLA standards
    for the different cloud providers and there is a need of centralized SLA standard
    to achieve the common goal of multi-cloud environment. Finally, there is a need
    to find out the trade-off among different QoS requirements due to wide range of
    IoT applications are running on cloud computing systems using AI based supervised/unsupervised
    learning techniques or prediction models. Open challenges and trends: The interested
    readers can further explore using extensive survey on QoS and SLA [166]. The open
    challenges and future research directions for QoS and SLA are summarized as follows:
    1. There is a need to find out the trade-off among different QoS requirements
    due to wide range of IoT applications are running on cloud computing systems.
    2. Applications should be able to provide optimum QoS and SLA characteristics
    with minimal overhead for maintaining data integrity with Blockchain. 3. AI based
    approaches have entirely changed the landscape of IoT applications, also the portable
    devices for transmitting multimedia content in IoT application has become very
    necessary for the end-users. 4.2. Fog computing Fog computing is the form of distributed
    computing paradigm which acts as a middle layer between IoT devices and the cloud
    data centers [150]. Fog is supplement to the cloud, not a replacement. Fog can
    never replace cloud completely as we still need cloud to handle big or complex
    data problem. Fog just provides more or less services which cloud does not provide
    in the same time limit or latency requirements [151]. Fog reduces latency so the
    applications which need low response time (as real-time applications i.e., traffic
    system, emergency system, healthcare system etc.) go for fog services instead
    of cloud services. However, it fails when the data is very heavy to process by
    its local nodes [46]. If the application is not time sensitive, then use of computing
    services of cloud datacenter is more beneficial. The term cloudlet is used to
    denote small data centers, which have almost the same types of features as the
    large data center, but in small capacity, like they can process small data not
    very large data [61]. They are close to the site of data production. Cloudlet
    can be single computer or group of computers with Internet connectivity. Cloudlets
    reduce the incoming bandwidth required by the centralized data center. It was
    becoming very difficult to timely handle large amount of data in centralized cloud
    environment. Huge data production by IoT devices is also the reason to accept
    fog computing paradigm as these data cannot be handled by the current cloud system
    even with high computation ability [128]. Apart from low latency, various services
    like mobility support, security, good performance and low bandwidth requirement
    are also provided by the fog. Fog generally provides a resource rich middle layer
    between the end devices and the cloud system to meet the above objectives. It
    acts as a bridge between end users and the cloud system. Fog nodes are also attached
    with the cloud with the help of Internet to use its computing power and storage
    services. Fog nodes generally analyses the data produced by these end devices
    and sensors [152]. Then the important output data is sent to cloud so that further
    processing and storage can be taken place. Therefore, the concept of edge computing
    came into existence. It provides the computing service at the edge of network
    [129]. Many applications need very less response time, it is not possible to handle
    them at very far located data center and reply them back on time. Thus, small
    data center, cloudlet with little processing power are established at the edge
    or near data generation site. They can handle these applications in time. Possible
    areas where this type of system is needed such as healthcare system [61,153],
    traffic system, emergency system etc. But the problem with technology is that
    it needs more complex resource management strategy. Cloudlet also faces some issues
    which are as following: (1) VM handling services must be easily transferable from
    one cloudlet to another cloudlet as these devices are mobile, they also need to
    switch among cloudlets for easy operation. (2) Since, there can be any number
    of cloudlets near end user devices, so there must be a policy to first search,
    choose and then join with the best cloudlet from many cloudlets before the provisioning.
    (3) Cloudlets are needed to be more efficient in provisioning as they are connected
    with the mobile devices. Thus, the behavior of these devices is quite dynamic
    as they are mobile. In IoT applications, every simple entity can also become part
    of it using a device like Radio Frequency IDentification (RFID) tag etc. That
    can act like data connecting device which will connect these simple devices via
    Internet. Number of devices connected to IoT is increasing exponentially. This
    cannot be handled by IoT alone, therefore, amalgamation with fog and cloud is
    done to perform the action efficiently which reduces latency and response time.
    Moreover, security threats on such devices have risen in recent years leading
    to increased requirements of security and data integrity technologies like Blockchain.
    As this amalgamation becomes more popular different challenges arise. With the
    rise in compute requirements, more and more tasks need to be executed with better
    QoS. The scheduling of these applications is complex due to several factors. Firstly,
    due to the heterogeneity of the computation resources and the hierarchy of fog
    nodes, there is significant differences in the compute capabilities, speed, response
    time and energy consumption between edge and cloud resources. Moreover, the mobility
    of the IoT devices changes the response time and bandwidth capacities dynamically.
    Furthermore, the tasks are stochastic in nature of their arrival, expected completion
    times, QoS requirements which makes this problem too complex. Most existing job
    scheduling algorithms are based on heuristics [141], [142], [143]. Other works
    use adaptive techniques to optimize job placement and migration decisions [144,145].
    Still, the current works focus on the aspect of scheduling with a limited perspective.
    It is well known that heuristics work for generic cases and fail to respond to
    the dynamic changes to the environments. The adaptive schedulers still lack the
    ability to optimize for a diverse set of user or application requirements and
    no model or scheduling architecture exists which aims to optimize multiple objectives
    simultaneously. Some works focus on optimizing energy, other focus on response
    time or SLA violations. However, for the diverse needs of users, there is a requirement
    of schedulers which can optimize multiple metrics at once, prioritizing those
    that the application needs. There can be a convex combination of multiple such
    metrics and higher weight can be given to those that are of primary importance.
    For example, mission critical applications like surveillance, healthcare can have
    an optimization object with higher weight to response time. Scientific applications
    can give higher weight to quality of results. Energy sensitive applications like
    smart cities can have an all-round objective with more weight to energy. Similarly,
    for other applications such functions can be modified. In this regard, AI based
    techniques can be leveraged to provide more efficient and robust algorithms for
    enhanced and user requirement directed task placement. Open challenges and trends:
    The interested readers can further explore using extensive survey on Fog Computing
    [167]. The open challenges and future research directions for Fog Computing are
    summarized as follows: 1. Generic interfaces are required for fog gateways to
    be able interact with the plethora of IoT devices. 2. Blockchain APIs must be
    runnable on resource constraint fog/edge nodes. 3. State of the art AI techniques
    can be used for proper task scheduling on heterogeneous fog environments. 4.3.
    Energy management The amount of data collected and processed has been increased
    manifold in the past few decades. This trend has been forcing the computation
    and thus the power consumption capabilities of Cloud platforms to extremes. There
    has been an increase in the electricity consumption of cloud datacenters by about
    20% to 25% every year [72]. Due to this, a turn has been observed towards distributed
    computing, resulting in increasing popularity of Fog and Edge Computing platforms.
    The shift from centralized Cloud-based computing to edge devices and networks
    immensely helps in reducing latency [73], improving Spectral Efficiency (SE) and
    increasing cost effectivity. However, this comes with its challenges. In many
    mission critical and remote sensing applications, intermittent power supply, if
    not the power delivery itself poses serious challenges. With the massively growing
    number of IoT devices [74] and the increasing data collected, the data-handling
    capacity, computation capability and bandwidth requirements of networks are being
    pushed to its limits. On the other hand, smaller IoT devices with low computation
    power, storage and battery are being developed [128]. Thus, increasing the efficiency
    of Fog/Edge nodes has become crucial. At the same time, maintaining the sustainability
    of the Cloud datacenters and reducing carbon footprint [75,76] has also gained
    importance. All of this has to be done without compromising on the Quality of
    Service (QoS) [6]. Despite the challenges, several developments can be seen in
    this field. Energy management has been tackled in three major levels, namely software,
    hardware and intermediate. Software-level efficiency optimization techniques and
    algorithms (like Mobile Edge-Computing offloading in [77]), backed by simulation
    models [78] have been developed. On the hardware side, application specific devices
    have been developed to deliver high performance and reduce the power footprint
    [79]. Wireless Sensor Networks (WSNs) have discussed energy conservation in detail
    [80,81]. At the intermediate level, resource management and active Fog/Edge-node
    sleep duration scheduling techniques and other energy conservation architectures
    [10] have been employed. For sustainable Cloud Computing, a comprehensive taxonomy
    has been proposed [58]. Many open challenges and directions for improvement remain
    where efficiency and sustainability of Fog/Edge/Cloud platforms can be improved
    [47]. More sophisticated algorithms need to be developed to encode information
    into a smaller number of bits to reduce the bandwidth budget and thus the transceiver''s
    power requirement (which is much more significant than the CPU itself). Common
    encoders in almost every mobile device can be exploited to employ encoding techniques
    without the requirement for extra/dedicated hardware. However, an increasing amount
    of data sharing, and loss has made it difficult to reduce the theoretical bandwidth.
    Another direction is to develop thermal-aware resource scheduling for reduced
    heating, thus improving (SoCs) and memories, CPU and data usage planning need
    to be modeled at the transistor level, using 3D thermal simulation architectures
    developed. Finally, the goal is to reduce power consumption to bare minimum, so
    that energy harnessing/scavenging techniques can be used to power both the CPU
    and the transceiver, making the node a completely independent entity. Therefore,
    reduction in the granularity of the Fog/Edge network can be achieved resulting
    in widely dispersed, redundant and more fault tolerant frameworks [139]. Other
    domains like energy constrained Blockchain models can be explored with other adaptive
    AI based learning models for more efficient energy scheduling. Open challenges
    and trends: The interested readers can further explore using extensive survey
    on Energy Management [58]. The open challenges and future research directions
    for Energy Management are summarized as follows: 1. Enhanced algorithms for efficient
    data encoding for reduced bandwidth consumption and energy efficient communication
    in data intensive IoT devices. 2. Blockchain design should allow energy constraint
    execution. 3. Using novel AI motivated techniques for more efficient thermal aware
    scheduling of tasks and resources. 4.4. Resource management Resource management
    in distributed systems is a challenging task due to the scale of modern data centers.
    The diverse nature of network devices, components and communication technologies
    in large-scale distributed systems makes the complexity of resource management
    techniques increase [52]. Therefore, there is a demand for new resource allocation
    approaches that would contribute to stability and efficiency of such systems.
    Resource management is a core concept within distributed systems (including Cloud,
    IoT, Fog computing), however there must be assurances that such systems exhibit
    high performance, latency-sensitivity, reliability, and energy-efficiency [46,47].
    These systems do not simply comprise the software layer, but must also factor
    in other systems including networking, server architecture, and even cooling.
    The security of cloud system can be increased by utilizing the Blockchain technology
    during the sharing of resources or VM migration. There is a need to explore new
    techniques for resource management for computing systems by considering a holistic
    view of the system by utilizing AI techniques [47]. Further, experiment driven
    approaches can be explored to investigate techniques to optimize resource management
    approaches. There is a need to incorporate data abstraction in resource management
    and its one example of a cluster management system is Borg [58]. This system hides
    details about resource management so that users can focus on development of applications.
    Borg logically partitions the whole cluster into cells, each one containing a
    Borgmaster (controller) and a Borglet that starts and stops tasks in a cell [5].
    The master handles client Remote Procedure Calls (RPCs) that can request to create
    a job or to read data, and it also communicates with the Borglets. This is a very
    scalable centralized architecture. The key design feature is that even if a master
    or a Borglet goes down, the already launched tasks will keep running. In order
    to enable fair sharing of commodity clusters, a platform called Mesos can be used
    [6]. It manages sharing of commodity clusters between different frameworks that
    run on these clusters. The main principle is using resource offers. Mesos decides
    how many resources to allocate to each framework based on framework''s constraints,
    while those in turn decide which offers to accept. Therefore, the burden of making
    scheduling decisions falls on frameworks. Besides, Mesos allows the development
    of specialized frameworks (such as Spark) that could significantly improve performance.
    A framework called YARN is used to perform resource management and scheduling
    [7]. It allows applications to request resources on different levels of topology
    – machines, nodes, racks etc. YARN resource manager is the main component responsible
    for making allocation decisions [63]. Just like Mesos, it lets commodity clusters
    to be shared among many frameworks. YARN also has built-in fault tolerance that
    hides the complexity of fault detection and recovery from its users [130]. Open
    challenges and trends: The interested readers can further explore using extensive
    survey on Resource Management [6,52,56]. The open challenges and future research
    directions for Resource Management are summarized as follows: 1. QoS-aware autonomic
    resource management is required to run IoT based applications without violation
    of SLA at runtime. 2. Proper Blockchain mining and hash generation allocation
    must be done for load balanced execution. 3. New resource provisioning and scheduling
    polices are required for fog and cloud computing using AI based deep learning
    techniques to predict the resource requirement in advance for geographically disparate
    resources. 4.5. Fault tolerance Cloud provider should provide the continuous service
    to users while maintaining the reliability of the cloud services even in the presence
    of faults [63]. There is a one mechanism called fault tolerance, which is used
    to provide the service in an efficient manner while satisfying the QoS requirements
    of the computing system. The faults occur during the working of computing system
    can be software, hardware or network. Further, the fault tolerance ensures the
    robustness and availability of cloud services [47]. The other issues related to
    reliability in cloud computing are timeout failures, overflow failures and resource
    missing failures. The other failures can be generated by catastrophic failures,
    which often leads to cascading systems failures. There are various proactive and
    reactive fault tolerance techniques are proposed to deal with such kind of failures
    [63]. Checkpointing is the most popular fault tolerance technique, which is used
    for long running process by saving the states after every change. Further, checkpoint
    is used when there would be any failure to start from the same point. Another
    renown technique is replication-based fault tolerance, which replicates the nodes
    or tasks to finish the job within their required deadline [58]. Task migration-based
    fault tolerance technique can migrate job to another machine if current machine
    is busy or suffering from some failures. To maintain the reliability of the computing
    systems, the existing fault tolerance techniques need failure-aware provisioning
    models, autonomic reliability-aware resource management technique and service
    reliability mechanisms, trustworthy data integrity (Blockchain) [52]. Reliability
    in cloud computing makes an impact on QoS while delivering the cloud service in
    an efficient manner. One of the most important challenge in cloud computing is
    how to provide an efficient and reliable cloud service while reducing the energy
    consumption as well as carbon footprints [58]. There is a need of Reliability-aware
    cloud as a service to offer resilience with required QoS and system performance
    [6]. Further, an efficient resource management needs to consider different failure
    and workload models to execute different types of applications such healthcare,
    smart city and agriculture [46]. Failure prediction in cloud computing systems
    is also a challenging task and which can also affect the reliability of the system
    [63]. There is a need to consider various machine or deep learning techniques
    [128,129] to predict the failures and achieve the required reliability of the
    cloud service to maintain the QoS. For IoT applications, the replication-based
    fault tolerant techniques are efficient, which can improve the latency and response
    time of task. Further, to handle the big data applications, there is a need of
    reliable cloud storage system to provide an efficient retrieval system for processing
    of big data. Open challenges and trends: The interested readers can further explore
    using extensive survey on Fault Tolerance [63]. The open challenges and future
    research directions for Fault Tolerance are summarized as follows: 1. For IoT
    applications, the replication-based fault tolerant techniques are efficient, which
    can improve the latency and response time of task. 2. An analytical modeling framework
    for Practical Byzantine Fault Tolerance (PBFT) – a consensus method for Blockchain
    in IoT networks is required to define the viable area for the wireless PBFT networks
    which guarantees the minimum number of replica nodes required for achieving the
    protocol''s safety and liveliness. 3. There is a need to consider various machine
    or deep learning techniques to predict the failures and achieve the required reliability
    of the cloud service to maintain the QoS. 4.6. Security and privacy Recently,
    in research and industry, there has been a massive shift from personal computing
    to IoT, Edge and Cloud computing to provide smarter and more efficient services
    to end users. For this big shift in paradigm, many issues and challenges have
    arisen in the privacy and security pertaining to the data on these devices. Due
    to various characteristics of Edge computing like low latency, geographic distribution,
    mobility of end device, and high processing, heterogeneity, etc [58,128]. The
    security and privacy properties need to be more robust and versatile. Moreover,
    the diversity of applications and heterogeneity of devices makes it difficult
    to develop seamlessly connected software platforms. To study these security and
    related concerns in cloud and fog computing paradigm, the following factors become
    prominent: (1) Trust and privacy of end users (2) Internode source authentication
    and validation (3) Impenetrable communications among, sensors, compute and broker
    nodes (4) Identification and protection of the systems against malicious attacks
    (5) Robust data management and tamper proof databases (Blockchain) [93]. Existing
    work in this area focus to solve challenges like detection and recovery from malicious
    or malfunctioning nodes, identification of and safeguard against attacks, prevention
    of malicious threats, safeguarding user-information against theft, dynamic mutual
    authentication [95,96]. Recent work has made possible to identity and location
    privacy for Unmanned Aerial Vehicle (UAV) assisted compute nodes, keeping in mind
    their integration in the distributed frameworks [97]. Also, in Fog forensics,
    other works have provided digital evidence by reconstructing past computing events
    and identified how the key characteristics are different from cloud forensics
    [94]. Mobility management, interference mitigation, and resource optimization
    in Fog Radio Access Networks (F-RAN''s) [98] are some of the main topics which
    have had many contributions in recent past. New models have emerged for diverse
    applications addressing privacy issues. Some such directions include face identification
    and resolution, vehicular crowd-sensing, geo-location sensing and data analysis,
    storage architectures and data centers with renewable nodes, fog based public
    cloud computing [82,83,92,99,100]. Such works have addressed concerns regarding
    many vulnerabilities including protection against data theft, man in the middle
    attacks, user anonymity, location privacy, forward secrecy, secure user level
    key-management, among others [87]. Many of the privacy and security models developed
    for fog/cloud computing face some limitations in terms of their scalability to
    the next generation edge computing shift [88]. Due to the inherently decentralized
    nature of fog computing, many unforeseen security threats arise in the fog layer
    and IoT devices which are not a concern in cloud computing [84], [85], [86]. Threats
    to edge focused networks include Advanced Persistent Threats (APT attacks), threats
    caused by bi-directional communication, malware, Distributed Denial of Service
    (DDoS) attacks, micro servers lacking hardware protection mechanisms in edge data
    centers, restricting the authentication protocols that can be deployed [89], [90],
    [91]. These works also highlight future directions in Mobile Edge computing framework
    including high speed pertaining to real-time encryption using nodal collaboration
    of edge networks. In prior works, security issues are exploited from a narrow
    perspective and computing capabilities of both edge and remote resources have
    not been fully leveraged [85]. Once cloud computing-like capabilities are brought
    to the edge of the network, novel situations arise. Some such situations include
    collaboration between heterogeneous edge data centers, migrating services at a
    local and global scale, concurrence to end users, Quality of Services, real-time
    applications, load balancing, server overflow problems, detection of stolen devices,
    robust and reliable inter node communication. These are the avenues for future
    research. To solve these problems, other domain ideas can be explored like clustering
    model-based security analysis (AI based prediction models) which is useful in
    DDoS attack mitigation in server systems and in intrusion detection systems, evolutionary
    game theoretic approaches to the privacy models inspired by the adversarial attack
    models, communication protocols in Sensor cloud systems. The security mechanisms
    also need to consider the existence of mobile devices using these data-centers.
    Open challenges and trends: The interested readers can further explore using extensive
    survey on Security and Privacy [168]. The open challenges and future research
    directions for Security and Privacy are summarized as follows: 1. Due to the inherently
    decentralized nature of fog computing, many unforeseen security threats arise
    in the fog layer and IoT devices which are not a concern in cloud computing. 2.
    With integrity, Blockchain structures should also allow other security measures
    for data like encryption, signature management, etc. 3. AI based security-aware
    techniques can be explored like clustering model-based security analysis which
    is useful in DDoS attack mitigation in server systems and in intrusion detection
    systems. 4.7. Software-Defined Network There is a need to enable the concept of
    networking virtualization in cloud is called Software-Defined Network (SDN) and
    utilize SDN for cloud computing by extending the idea of virtualization of all
    the cloud resources such as network, storage and compute [131]. Further, it improves
    the abstraction of physical resources and automation and optimization of configuration
    process. SDN paradigm provides a platform to enable flexibility or agility in
    network, which can be create a cost-effective communication among modern cloud
    datacenters. Further, SDN based cloud computing reduces the power consumption
    while optimizing the network virtualization. Network functions virtualization
    (NFV) is another emerging networking paradigm which forwards network functions
    such as Domain Name Service (DNS), load balancing and intrusion detection while
    executing software-based applications [132]. Moreover, NFV improves the elasticity
    of network function and increases the flexibility and agility of the service,
    which further reduces the cost [133]. Further, an efficient VM migration policy
    can be used for VM consolidation in virtualized network to reduce energy consumption.
    There are different research challenges are still open for academicians and researchers.
    Firstly, there is a need provide the security mechanism for SDN-based cloud computing
    to secure the transfer of data among different cloud datacenters [134]. Toosi
    et al. [116] developed a low-cost Raspberry-Pi-based micro datacenter for software
    defined cloud computing, which saves cost, but reliability of service is still
    questionable. Secondly, the trade-off between cost and energy consumption is still
    existing due to replication of SDN enabled cloud infrastructures. In future, there
    is a need to deploy SDN-based cloud computing environment, which can reduce energy
    consumption and increase reliability while providing the network virtualization
    service in a cost-effective manner. Further, we can extend existing data integration
    in such SDN environments to support Blockchain technologies with enhanced data
    distribution and results collection techniques motivated from AI based models.
    Open challenges and trends: The interested readers can further explore using extensive
    survey on Software-Defined Network [131]. The open challenges and future research
    directions for Software-Defined Network are summarized as follows: 1. There is
    a need provide the security mechanism for SDN-based cloud computing to secure
    the transfer of data among different CDCs using IoT devices. 2. Decentralization
    and virtualization chain of data is required for Blockchains to work in SDN paradigm.
    3. There is a need to deploy SDN-based cloud computing environment using AI learning
    models, which can reduce energy consumption and increase reliability while providing
    the network virtualization service in a cost-effective manner. 4.8. Big data analytics
    and data science A complicated procedure of examining large datasets to uncover
    hidden patterns [33], market trends, correlations and preferences specific to
    customers that can help the companies to make well informed decisions [127]. In
    simple words, these technologies help in analyzing data sets and then to draw
    conclusions from it using cloud computing platform. It is a form of analytics
    which involves elements as statistical algorithms, predictive models etc. Driven
    by high computing powered systems, it offers several advantages including effective
    marketing, revenue opportunities, operational efficiency etc [43], [44], [45].
    It allows professionals to analyze the growing volumes of unstructured, semi structured
    and structured data. There are few research directions in this area as discussed
    below: 4.8.1. Healthcare Large amount of data is generated in the healthcare industry
    [34] ranging from medical health records, X-ray reports, diet regime, record keeping
    etc. In order to give efficient cloud services, it is necessary to analyze this
    healthcare ecosystem-based data. Also, there is a need to build a fog, edge or
    cloud-based system for real time analysis on the enormous data set (collected
    by IoT devices). Including this, there is a need to keep this data tamper proof
    using Blockchain models. Further, future research directions can be: • Patient
    services: Big data analytics-based systems can provide evidence-based medicines,
    giving faster relief to the patients as they can detect diseases at the earlier
    stages based on the clinical data available. This will help in minimizing drug
    doses to avoid side effect and reducing readmission rates thereby reducing cost
    for the patients. Customized patient treatment could be delivered by monitoring
    the effect of dosages of medicine continuously and looking on analysis of the
    data generated by the patients who already suffered from the same disease using
    cloud computing system. • Detecting diseases: Viral diseases can be predicted
    earlier before spreading, based on the real time analysis. This can be identified
    by analyzing the history of the patients suffering from a disease in a particular
    geo-location [39]. This helps the healthcare professionals to advise the victims
    by taking necessary preventive measures. • Hospital management: Hospital''s inventory
    could be planned and managed in advance to tackle problems like seasonal demand,
    uncertainty and economies of scale. 4.8.2. Government Any government of the nation
    also generates petabytes of data [58]. Big data-based systems can assist government
    in providing value added services to its citizens. These systems could help the
    government in financial, healthcare, education budget planning by understanding
    the data patterns and the relationship between them with the help of machine learning
    algorithms [35,63]. Further, future research directions can be: • Unemployment:Analyzing
    the market conditions and data of students before, government can predict the
    jobs. Cloud computing-based system enables government to create curriculum for
    trainings in order to absorb youth in the different domains and organizations.
    • Decision making: By analyzing the sentiments and predicting the future trends,
    government can improve the quality and speed of decision making [38]. The government
    could take advantage of big data-based cloud computing systems in understanding
    current conditions and acceptability of the society before taking any action.
    It will help in creating more acceptability of the government in citizens. 4.8.3.
    Retail With new sources of data like social media, geo location sensor data (IoT
    or edge devices), it has created more opportunities for retail companies to get
    competitive advantage and unprecedented value. Cloud based Big Data analytic systems
    can make best decisions flows, uncover hidden patterns and understand customer
    behavior. To better understand the value of big data analytics in the retail industry
    [36], let us take a look at the following use cases, which are currently in production
    in various leading retail companies. • Conversion and campaign: Customers today
    interact more than they were before, and these interactions are happening on new
    platforms like social media. So, retail companies can get holistic view of customers
    and understand their preferences [40]. Data Science and engineering is capable
    of correlating customer purchase histories and profile information, with their
    behavior on social media sites. And these relations can reveal unexpected insights,
    in turn helping the retailer is likely to have higher conversion rates and reductions
    in customer acquisition cost. Using data science platforms, retailers can: – Analyze
    the impact of different promotional campaigns on customer behavior. – Use customer
    purchase history to identify the needs then generate personalize promotions catering
    to customer''s needs. – Monitor customer social media activity to make timely
    offers to customers to incent online purchases. • Customer churn prediction: Data-driven
    customer insights are critical to tackle challenge of customer churn prediction
    [41,42]. It is done by predicting future churn from data of the past. Retailers
    can look at characteristics of customers that have churned before in order to
    predict something about current customers. 4.8.4. Operational analytics Improvement
    in complicated product life cycles cause retailers to employ big data-based technologies
    to deploy product distribution strategies to reduce time and costs associated
    with them [43]. The key to utilizing data science and cloud computing platforms
    is to increase operational efficiency by unlocking insights buried in sensor and
    machine data through machine learning and pattern recognition techniques. These
    analyses help in predicting trends, patterns and outliers that can improve decisions
    [37] and save millions of dollars in computing world. Open challenges and trends:
    The interested readers can further explore using extensive surveys on Big Data
    Analytics [57,66] and Data Science [169]. The open challenges and future research
    directions for Big Data Analytics and Data Science are summarized as follows:
    1. There is a need of bio-inspired based big data analytics mechanisms to process
    the data of edge devices of IoT applications at runtime. 2. Efficient Blockchain
    data structures need to be developed for efficient storage and retrieval of large
    amounts of data. 3. Cloud based Big Data analytic systems can utilize the AI based
    techniques to make best decisions flows, uncover hidden patterns and understand
    customer behavior. 4.9. Data processing Before diving deep into data processing,
    Let us try to understand “What is the need of data processing in today''s world?”.
    The present world is overwhelmed with information from various sources such as
    IoT devices, social media, smartphones (IoT or edge devices), medical health records,
    click stream data, ecommerce etc. According to DOMO''s research, “By 2020, it
    is estimated that 1.7 MB of data will be created every second for every person
    on earth” [103]. Imagine, with current 7.7 billion population of the world, 13
    petabytes of data will be created per second leading to 1 Million petabytes a
    day. So, with this rapid generation of data, organizations are endeavoring to
    find the best tools to deal with this raw data and make sense out of it. The processing
    of data is central to any data-related problem. It is one of the most interesting,
    time consuming phase of an analytics project. Nearly 70–80% time of a data analyst/scientists
    is spent in cleaning and processing the data to make it usable for any kind of
    statistical modeling. In simple terms, data processing is basically the collection
    and manipulation of data to get useful information out of it, which then can be
    used for analytics, business intelligence, machine learning, deep learning and
    reporting purposes etc. The processing of data can incorporate anything from collection,
    reporting, aggregation, summarization, validation, structuring the unstructured
    data or vice versa etc. Data can be of any kind like time-series, images, videos,
    textual etc. Depending on the size of data, processing can be done on a single
    core machine to multi-core or on cloud and GPU servers [104]. The processing of
    big data can be broadly classified into three categories: • Batch processing–
    an efficient technique to process large amounts of data collected over a period
    of time from various IoT or edge devices. • Real time processing– deals with a
    continuous stream of data inputs and involves processing of data in near real
    time i.e. with minimal latency and maximum security (Blockchain). • Hybrid processing–
    takes the volume aspect of batch processing and velocity aspect of real time processing
    and it is useful in applications that require analysis of huge volumes of static
    along with streaming data. Apache Hadoop (a framework that allows distribution
    of large data processing across various connected computers using MapReduce programming
    model) [105] and Apache Spark (a unified analytics engine with in-memory data
    processing capabilities and having built-in modules for SQL, machine learning,
    streaming and graph processing) are the two main open source tools that are widely
    used across industry for the processing of big data [63,128]. A lot of other data
    processing tools for specific data types, tasks are also available in the market
    but these two precisely dominate the industry. With organizations investing heavily
    on Advanced Data Analytics and the growth of data in terms of volume, variety
    and velocity increasing, it is becoming expensive and demanding for organizations
    to scale on-premises infrastructure [57]. As a result of this, cloud is becoming
    a natural choice for these organizations for storage and processing of data. More
    and more companies are moving towards cloud services being offered by the big
    tech giants like AWS (Amazon Web Services) by Amazon, Microsoft Azure, IBM Cloud,
    GCP (Google Cloud Platform) and Google for data processing [61]. These cloud providers
    have wide variety of tools to manage, compute and do analysis on data depending
    upon the volume, variety and velocity of data one has. So, these cost-effective
    cloud services are not only providing organizations with advanced tools for faster
    data processing but are also handling the agility and scalability aspects of big
    data and thus leading to revenue growth [66]. The management of data and extraction
    of knowledge are two important parts of grand organizations and business companies.
    The speed of generation of data at both user and system end leads to various research
    issues in both research community and industry [59]. The infrastructure uses to
    manage data is growing swiftly as collected from IoT or edge devices, which leads
    to formation of large cloud data centers (CDC) [58]. The various flexible data
    management models (NoSQL/relational) are using in CDCs to handle the current data
    requirements. Further, modern large CDCs are more susceptible to failures and
    needs effective fault tolerance technique for effective management of data within
    CDC [63]. Moreover, IoT and scientific applications are increasing which further
    needs effective data management mechanism within large scale distributed system.
    Big Data and Deep Mining models motivated from AI and machine learning techniques
    can be used for effective analysis of large-scale data. Open challenges and trends:
    The interested readers can further explore using extensive survey on Data Processing
    [170]. The open challenges and future research directions for Data Processing
    are summarized as follows: 1. IoT and scientific applications are increasing which
    further needs effective data management mechanism within large scale distributed
    system. 2. To ensure data is protected, Blockchain technology has been adopted
    in the IoT domain and other real time systems. 3. AI provides a lucrative avenue
    to optimize large systems with huge amounts of data with engineering simplicity
    and efficiency by allowing automated decision making instead of human encoded
    heuristics which provide more efficient decisions very quickly. 4.10. Application
    design It is estimated that 50 billion devices will be online and 40% of the world''s
    data will come from them with total expenditure of $1.7 trillion by 2020 [58].
    This exponential growth of Internet based smart devices and IoT applications such
    as healthcare services, real time traffic control systems, precision agriculture,
    smart cities etc. require faster processing, data storage and privacy along with
    secure and reliable communication [46,59,61]. Also, as the data generated by these
    devices are used to solve real time problems, integrity, consistency and availability
    of data must be guaranteed. Designing these complex applications for IoT devices
    is a challenge in itself. So, we need to come out with application designs/architectures
    that are not only scalable to handle humongous amount of data from these devices
    but also reliable and fast enough to give efficient performance [135]. So, following
    are the major concerns that need to be taken care of while designing these applications
    with cloud infrastructure. • Latency: Time taken by a data packet for a round
    trip from IoT devices to cloud and back. It is a big concern for time sensitive
    data as a millisecond can make a huge difference leading to unwanted results [46].
    For e.g., disaster sensing device fires alarm after the occurrence of a disaster
    would not solve the problem. Extremely time sensitive data should be analyzed
    very near to the data source to provide response in near real time. • Bandwidth:
    If all the data generated by these devices are sent to cloud for storage and analysis,
    then the traffic generated by these devices will be simply gigantic and will consume
    all the bandwidth, which is not desirable. Also, as the physical distance between
    the device and cloud increases, transmission latency increases with it, increasing
    response time and stressing out the user. So, some work needs to be offloaded
    from the cloud, which can be done by allowing some processing to be done on an
    edge server that is positioned between cloud and device and physically closer
    to the device. The fog computing allows IoT data storage and some processing locally
    at IoT devices and thus, avoids an excessive exploitation of Cloud resources [46].
    Also, the fog provides reliability to time-sensitive and data-intensive applications
    that are large-scale and geospatially distributed [6]. Subsequently, fog computing
    might be viewed as the best decision to empower the IoT to give reliable and secure
    services/resources to numerous IoT users. Big Data Analytics, IoT devices, fog
    and edge computing are becoming the driving forces for smart city initiatives
    throughout the world. Fog computing has great applicability in transportation
    such as vehicle to vehicle communications, managing smart sensor-based traffic
    control systems and also controlling autonomous vehicles, self-parking etc [46,128].
    It is also a more sustainable approach due to its low energy usage, small footprints
    and governments in various countries can use these applications to make the life
    of the citizens more secure and environment friendly. It can also be used in emergency
    services like fire, natural disasters by early notification of emergency situations
    to support smart decision making. Farming applications help to oversee agriculture
    data like precipitation, wind speed and temperature to improve the use of climate
    and land in a productive way, which can assist farmers to have a productive yield
    [59]. An IoT agriculture platform for cloud and fog computing is proposed in [101],
    which can be utilized for pest management image analysis and monitoring, agricultural
    monitoring automation etc. that can help farmers in better utilization of resources.
    In [102], authors have proposed a fog computing application for precision agriculture
    that can assist in agricultural land management using AI based intelligent systems.
    Also, it is progressively penetrating into the healthcare domain [61]. A lot of
    wearable gadgets like fit bit, blood pressure and heart rate monitoring cuffs,
    are being used to monitor different parts of human body and also collect information
    for diagnosis and interpretation. These devices have made remote healthcare monitoring
    feasible and hence doctors can monitor patients'' wellbeing remotely and for the
    most part has given patients more authority over their lives and treatment. Also,
    companies like Apple with CareKit, HealthKit, ResearchKit and Google with Google
    fit, Microsoft building their health data management on top of Azure are clear
    examples that tech giants are investing heavily into digital healthcare [6,7,11].
    Open challenges and trends: The interested readers can further explore using extensive
    survey on Application Design [135]. The open challenges and future research directions
    for Application Design are summarized as follows: 1. How to design a new application
    for smart cities to manage IoT based data effectively? 2. Storage capacity and
    scalability of applications are highly debated due to high cost and maintenance
    overheads while providing Blockchain based security. 3. Artificial Intelligence
    algorithms can be used for processing of application data collected from various
    IoT based applications such as healthcare, agriculture, smart home etc. 4.11.
    Serverless computing Cloud application is basically comprising of three components:
    application logic, business logic and database server [6]. To improve the design
    of existing cloud applications, serverless computing paradigm is emerged [135].
    In serverless application, database server and application logic located in the
    cloud while business logic is forwarded to the end user, which can be accessed
    by using web or mobile application for execution on provisioned resources without
    renting the resources (VMs). With the help of serverless computing, the different
    research challenges such fault tolerance, load balancing and under or over provisioning
    of resources are solved [58]. Further, serverless computing also decreases the
    coding part of developers and reduces the burden on cloud administrator for management
    of resources. Serverless provides two different kinds of service: (1) Function
    as a Service (FaaS) and Backend as a Service (BaaS) and these services are supported
    by Amazon AWS, Google Cloud and Microsoft Azure [128]. Cloud user only runs their
    application without knowing the internal details about servers, which are managed
    by cloud provider. Serverless computing comes with many challenges and issues.
    Most works do not consider various aspects important for scheduling tasks on such
    execution models. One such aspect is server start-up time for infrequently used
    applications where servers are spun-down when the application is not in use. This
    severely affects the performance of application and QoS. Recent works like [19]
    do focus on this aspect but from a limited perspective. Another aspect is bandwidth
    consumption in Bag-of-Tasks models where multiple tasks commonly share files.
    These files need not be uploaded to cloud nodes separately for each task and task
    placement can be more intelligent to maximize file sharing capability. Yet another
    aspect important in such models is the security and privacy of applications and
    critical data [20]. As mentioned in [21], most modern serverless computing models
    are being implemented by integrating the edge of the network. These edge devices
    are resource-constrained and cannot support the heavy security applications and
    firewalls developed for common personal computers. Special applications and algorithms
    need to be developed to allow more secure communication as well as ensure the
    privacy of data for modern computing platforms which include edge devices as part
    of the datacenters. Open challenges and trends: The interested readers can further
    explore using extensive survey on Serverless Computing [171]. The open challenges
    and future research directions for Serverless Computing are summarized as follows:
    1. New IoT based applications are required to be developed to allow more secure
    communication as well as ensure the privacy of data for modern computing platforms
    which include edge devices as part of the datacenters. 2. Edge devices of IoT
    application are resource-constrained and cannot support the heavy security applications
    and firewalls developed for common personal computers, so there is a need to implement
    Blockchain technology to improve security. 3. AI systems improve the design of
    application for serverless computing. 4.12. Deep learning Deep learning is a class
    of machine learning programming technology that is based around learning from
    large data sets [154,155]. The core of deep learning is to get high level interactive
    features from the raw data. Lately deep learning has been powering Reinforcement
    Learning to help realize the field of Deep Reinforcement Learning which is offering
    hope in crafting better models in the future [129]. The intersection of deep learning
    and cloud computing is creating interesting applications wherein both the fields
    are complementing each other. We would first discuss how cloud computing is supporting
    data scientists and later move on to how deep learning has been leveraging solutions
    to various traditional problems in cloud computing [49], [50], [51]. Teerapittayanon
    et al. [48] have demonstrated the use of edge and IoT end devices in realizing
    a distributed training of a deep neural network. Traditionally distributed learning
    has been avoided due to communication cost, however they propose joint training
    bringing this cost down by 20×. Cloud computing is also helping reduce the energy
    consumption of deep neural networks by reducing the feature size achieved through
    splitting the network architecture between mobile and cloud [54]. There are various
    other applications of cloud computing assisted deep learning leading to value
    addition in various fields including robotics, autonomous driving, healthcare,
    personal assistance and defense. The advances in deep learning have to be realized
    by performing continuous training on the real time data. Cloud Chaser [60] is
    a technique in which the computational load is borne by the cloud and the power
    of deep learning can be harnessed on low computing capacity devices. Big Data
    Analytics can be effectively performed by employing a hybrid “Machine Learning + Cloud
    Computing” approach [57]. Hence a cloud-based deep learning approach is becoming
    very popular. Recent advances in deep learning and its wide popularity has led
    to a demand for learning the models on devices presently accessible to the users.
    A privacy preserving approach wherein on-device deep learning can be realized
    using cloud has been developed by Wang et al. [62]. Similar work has been carried
    out by various other groups trying to make deep learning on mobile devices a reality
    [50]. Nguyen et al. [49] have developed a deep learning model to thwart cyber-attacks
    in the context of mobile cloud realm. A Hybrid approach of running deep neural
    network partially over an IoT device and the cloud can lead to preserving the
    privacy over mobile devices [51]. They show a high accuracy (95.84%) with robustness
    using variety of datasets. Security has traditionally been the reason hindering
    adoption of cloud computing by users which can be addressed using deep learning
    as shown by many authors recently A persisting problem with cloud computing is
    managing and monitoring of large cloud clusters. Stefanini et al. [70] have shown
    that deep learning (DeepConv and DeepFFT) can be used to classify clusters with
    similar behavior which may improve the scalability of managing a data center.
    QoS violations can be detected ahead in time by “Seer” which is a cloud-based
    debugging system using deep learning and spatial and temporal data of cloud systems
    [64]. The prediction of workload for VMs on cloud has been carried out by [65,68,69].
    Li et al. [71] have developed a system using cloud computing and deep learning
    with the aim of minimizing power consumption by cloud clusters. Open challenges
    and trends: The interested readers can further explore using extensive survey
    on Deep Learning [172]. The open challenges and future research directions for
    Deep Learning are summarized as follows: 1. An ensemble deep learning based smart
    healthcare system is required for automatic diagnosis of heart diseases in integrated
    IoT and Fog computing environments. 2. Deep learning-based techniques are required
    to improve the Blockchain structures. 3. How to enable deep learning on IoT devices
    to improve real world performance in Artificial Intelligence based intelligent
    systems? 4.13. Cloud containers Container technologies are quite popular in this
    cloud computing community with the origin of Dockers to execute the user workloads
    in an efficient manner. Container technology offers a lightweight cloud environment
    to deploy applications because containers are self-contained and stand-alone,
    which can reduce data dependency among various units during the execution of user
    workloads [130]. Container allows the resource sharing among various applications
    while running in an isolation manner. The various kernel features of Linux OSs
    such as libcontainer and control groups (cgroups) are considered in container
    technology. Namespaces and cgroups are used by Docker to execute self-dependent
    containers within a physical node and offer run resources (network, storage, memory
    and processor) in an isolated manner. Moreover, namespace separates the view of
    an application in running environment and simplifies the application deployment
    and increases the implementation efficiency. Further, container technology becomes
    a benchmark to develop, publish and execute applications in an isolated manner
    and denoted as a Container as a Service (CaaS) [130]. CaaS has three main advantages
    [63,47]: (1) container starts very rapidly and takes less than a second to launch,
    (2) it uses very less amount of resources as compared to VMs and (3) container
    technology allows to run more instances concurrently. Based on the current research
    in container technology, there are few research challenges are open which can
    be addressed in the future. Firstly, there is a weakness in security of containers
    due to the sharing of kernel as compared to VMs, which can be improved in the
    future by developing new security mechanisms by using Unikernel. Secondly, the
    performance improvement of containers is long task and there is a need to consider
    slack time to optimize the performance. Finally, there is a need to manage the
    user''s QoS based container clusters using emerging cloud computing technologies
    such as Swarm and Kubernetes. Open challenges and trends: The interested readers
    can further explore using extensive survey on Cloud Containers [173]. The open
    challenges and future research directions for Cloud Containers are summarized
    as follows: 1. Container technology can be utilized a cloud environment to deploy
    IoT applications to reduce data dependency among various units during the execution
    of user workloads. 2. There is a weakness in security of containers due to the
    sharing of kernel as compared to VMs, which can be improved in the future by adapting
    Blockchain technology. 3. There is a need to manage the user''s QoS based container
    clusters using emerging ensemble machine learning techniques such as Swarm and
    Kubernetes. 4.14. Quantum computing Quantum computing is branch of computing in
    which we harness and exploit the laws of quantum mechanics to process the data.
    Classical computers cannot solve problems of certain size and complexity. Quantum
    computers leverage the phenomena of superposition and entanglement to solve the
    hard problems [136]. Superposition is phenomena by which quantum computer can
    be in multiple states at the same time. While entanglement is the phenomena of
    having strong correlation between two or more quantum particles that they are
    inextricably linked, even if they are separated by large distance. Due to these
    two principles, a quantum computer can do large number calculations simultaneously
    [38]. Think of it this way: whereas a classical computer works with ones and zeros,
    a quantum computer will have the advantage of using ones, zeros and “superpositions”
    of ones and zeros [137]. Certain difficult tasks that have long been thought impossible
    (or “intractable”) for classical computers will be achieved quickly and efficiently
    by a quantum computer. The future directions [136], [137], [138],156] for this
    research area are: 1. Optimization: Consider an example of management company,
    which wants to invest in large cap value, medium cap value and blue-chip companies
    to generate large returns while rebalancing the asset classes to protect investments.
    By combining dynamic asset allocation through the use of quantum computers, they
    can solve this kind of hard problem optimally. These kinds of problems exist in
    various domains like airline traffic scheduling, financial analysis, system design
    etc. they are the one of the most complex problems [40] of the world with potential
    to transform the lives of the people. Quantum computers will be able to calculate
    the one-way functions, including Blockchains that are used to secure the Internet
    and financial transactions. 2. Machine learning and AI: Quantum computing can
    transform field of machine learning field too. Object detection in which it is
    very easy for humans to pick different objects from the photograph. But for traditional
    computers it is a difficult task. As the programmers do not know how to write
    code that can infer many objects by its own. Machine learning is one of the approaches
    to solve this problem in which algorithms recognize the objects by getting trained
    on large datasets [41]. As the amount of data and its combinations involved in
    this process are very large. So, it becomes a computationally expensive problem
    for the traditional systems to handle. Quantum computers make these types of problems
    easy as they can do enormous calculations simultaneously. 3. Material simulation:
    Quantum computers make simulating the materials feasible, the material simulation
    field can lead to development in various IoT based application in robotic, chemical
    and optical industry [39]. Open challenges and trends: The interested readers
    can further explore using extensive survey on Quantum Computing [174]. The open
    challenges and future research directions for Quantum Computing are summarized
    as follows: 1. Quantum computers make simulating the materials feasible, the material
    simulation field can lead to development in various IoT based application in robotic,
    chemical and optical industry. 2. Quantum computers will be able to calculate
    the one-way functions, including Blockchains that are used to secure the Internet
    and financial transactions. 3. Quantum computing can transform field of machine
    learning field too. Object detection in which it is very easy for humans to pick
    different objects from the photograph. As the programmers do not know how to write
    code that can infer many objects by its own. Machine learning is one of the approaches
    to solve this problem in which algorithms recognize the objects by getting trained
    on large datasets. 4.15. Bitcoin currency Blockchain was originally developed
    for digital currency Bitcoin and proposed as solution for settlement of transactions
    [106]. The Blockchain is an incorruptible chain of data blocks validated with
    PoW of economic transactions that can also be programmed to record not just for
    financial transactions but virtually everything of value [107]. Blockchains, like
    Bitcoins and Ethereum offer a new paradigm to run distributed applications. The
    developers define smart contracts for Bitcoin currency transactions, and the contracts
    are executed on the Blockchain virtual machines. Therefore, the Blockchain uses
    a distributed runtime environment with distributed consensus. The Bitcoin supporting
    network also allows block of data to be distributed across ledgers via peer to
    peer network without central management. Anyone can join the network, and the
    data in Blockchain is validated by the participants to make the data secure and
    open. This feature can be taken advantage by cloud computing, especially for the
    security of cloud storage. Cloud infrastructures provide computing power to run
    large applications and process huge amount of data. However, to manage the huge
    data storage, the centralized data centers connected with the Fog or IoT devices
    at the network edge cannot offer an efficient way to provide high availability,
    real-time and low latency services [108]. To address these issues, distributed
    cloud architecture rather than the traditional network architecture is needed.
    Blockchain offers some necessary features to build a distributed cloud [109],
    [110], [111], such as: (1) It can facilitate resource usage via distributed applications
    to enable fine-grained control on resources. (2) QoS can be improved as Blockchain
    can provide traceable resource usage, thus the user and service provider can verify
    whether the QoS is ensured. (3) A market place that everyone can advertise their
    computing resources and find the needed resources using AI based techniques or
    prediction models. Comparing to cloud computing, Blockchains only have limited
    computing resources to execute distributed applications, e.g. limited storage,
    inefficient virtual machines and protocol with high latency. Therefore, for the
    latency-aware applications and resource-intensive applications, these issues should
    be overcome. Combining Blockchain and cloud together to establish the Blockchain-based
    distributed cloud can bring new benefits and overcome existing limitations. The
    Blockchain-based distributed cloud allows on-demand resource, secure and low-cost
    access to infrastructure, the data is also brought to be closer to the owner and
    consumer [15]. Meanwhile, Blockchain-based distributed cloud is possible to overcome
    the expensive and high energy consumption features of clouds. Another future direction
    that Blockchain can benefit is improving the security of cloud storage. User data
    can be split into small blocks and added one more security layer, then the small
    blocks can be stored in distributed locations. The hacker can only get a chuck
    of the data rather than the whole file. The hackers who want to alter the data
    can also be removed from the network, and the altered data can be recovered from
    redundant copy. Open challenges and trends: The interested readers can further
    explore using extensive survey on Bitcoin Currency [175]. The open challenges
    and future research directions for Bitcoin Currency are summarized as follows:
    1. How IoT botnets affect the “Internet of money” cryptocurrency? 2. The Blockchain
    is an incorruptible digital ledger of economic transactions that can also be programmed
    to record not just for financial transactions but virtually everything of value.
    Blockchains, like Bitcoins and Ethereum offer a new paradigm to run distributed
    applications. 3. There is a need to investigate how Machine Learning (ML) techniques
    perform in the prediction of cryptocurrency prices. 4.16. Software engineering
    Software Engineering (SE) and cloud computing are very close paradigms. For example
    – service-oriented SE combines the best features of the services and cloud computing
    and thus gives several benefits to software development process and applications.
    The only difference between Services oriented SE and cloud computing is that –
    the service-oriented SE focuses on architectural design (service discovery and
    composition) and cloud computing focuses on the effective delivery of services
    to users through flexible and scalable resource virtualization and load balancing
    [163]. Software Engineering not only evolves hardware technologies, but also involves
    customers and software developers [112]. Cloud computing and virtualization allow
    users to create VMs and cloud services for projects and software''s with automatic
    management [113]. With cloud services, the software development teams can combine
    development, test and delivery processes seamlessly. Cloud computing can enhance
    the software engineering process in the following ways: 1. The development process
    can be speed up. Cloud computing and virtualization offer sufficient computing
    resources, so that developers can use multiple virtual machines rather than stick
    to a single physical machine. 2. Cloud computing enables the development activity
    into a more parallel way, as the time to install the necessary applications can
    be reduced by fetching cloud services, which can lead to a more efficient development
    process. 3. Cloud instances and virtualization can greatly enhance the integration
    and delivery process. With adequate virtualization resources from their own cloud
    or public cloud, development can make the build and test process faster, which
    are quite time-consuming. 4. Code versions management becomes easier. Code branching
    is necessary in the code refactoring or function increment in software development.
    Cloud computing relieves the efforts to buy or rent physical machines for storing
    the codes. 5. Cloud environment provide interfaces to facilitate users’ access
    to applications and can improve service QoS via dynamic resource provisioning.
    In conclusion, cloud computing removes the heavy dependencies of development servers
    on fixed physical machines and makes the development process in software engineering
    more efficiently [114]. Cloud computing makes the software development process
    to be more efficiently. However, some challenges exist in combining software engineering
    and cloud computing, and these challenges should be addressed. Data migration
    is one of the challenges. Since cloud providers offer different APIs for offering
    cloud services, if the software''s and data need to be migrated to another cloud,
    software''s may need to be reimplemented and some software''s can be the legacy
    system [115]. To address this issue, when developing and deploying software''s
    in clouds, unnecessary dependencies on specific APIs should be avoided. Another
    challenge is the reliability and availability. If all the data are migrated to
    clouds from local, when the cloud is attacked by hackers or influenced by unpredicted
    disaster, the data is hard to recover. This requires the developers to prepare
    local backup. Cloud computing provides new possibilities for software engineering
    researchers to explore multilateral software development [2]. Several researchers
    attempted to use cloud computing for reducing the cost of operation, delivery
    and software development [164]. In [164] authors explored how to replace Learning
    Management Systems (LMS) services with a cloud platform for sharing the knowledge
    and collaboration among university students. Software systems are being replaced
    by cloud-based systems to save the cost and maximum utilization of resources.
    In recent years when data is increasing on exponential rate then it is not easy
    to use the old traditional way of handling the data. The emerging technologies
    based on IoT, Blockchain, machine learning, and Artificial Intelligence are opening
    a new area of research in software engineering and the major issue in these technologies
    are handling the huge amount and variety of data. These researches also giving
    the opportunity to new researches and the new ways of handling the data in the
    cloud and this results for starting of upgraded technologies like – Fog Computing
    – first used by Cisco in order to extend the current cloud computing infrastructure
    [165]. Software companies working for building enterprise software are building
    an abstraction layer and offering it as a service, called Blockchain-as-a-Service
    [165]. All these emerging areas are new but heavily depend on software engineering.
    Open challenges and trends: The interested readers can further explore using extensive
    survey on Software Engineering [176]. The open challenges and future research
    directions for Software Engineering are summarized as follows: 1. To investigates
    the feasibility of IoT based Software engineering solutions on how organizations
    can deliver high business value through technology and operations strategy engagements
    at the same time can generate Return On Investment (ROI) by effectively utilizing
    the possibilities of IoT in business. 2. There is a need for software engineers
    to devise specialized tools and techniques for Blockchain-oriented software development.
    3. How to program the system “automatically” using Artificial Intelligence instead
    of writing the software code manually? 4.17. 5G and beyond Next generation networks
    promise not only extremely high data rates and low latency, but also ubiquitous
    coverage and massive IoT. Today, dense network deployment is one of the effective
    strategies to meet the capacity and connectivity demands of the fifth-generation
    (5G) cellular system [117]. 5G is the fifth generation of cellular mobile communications,
    preceded by 4G (LTE/WiMax), 3G (UMTS), and 2G (GSM) systems. 5G are expected to
    provide high-speed data rates, reduced latency, reduced energy consumption, effective
    cost, enhanced system capacity, and massive simultaneous device connectivity [118].
    One of the main objectives of 5G networks is to support applications that involve
    a high density of devices. In this regard, the concepts of massive Machine-Type
    Communications (mMTC), enhanced Mobile BroadBand (eMBB) and Ultra-Reliable Low-Latency
    Communications (URLLC) are being developed to support such applications [119].
    5G will bring major advances in the network and communications systems by providing
    ultra-high-speed data transmission that can be 100 times faster than the existing
    4G [120]. Edge computing as an evolution of cloud computing shifts the application
    hosting paradigm from the centralized data centers to the network edge, closer
    to consumers and the data generated by applications [121]. Edge computing is considered
    one of the main enablers for satisfying the demanding Key Performance Indicators
    (KPIs) of 5G such as enhanced mobile broadband, low latency and massive connectivity.
    The boosting computation-intensive applications in the Internet of Things (IoT)
    era along with the growing number of mission-critical tasks in emerging networks
    is a main bottleneck in the design of the real-time communication systems [122,123].
    In order to tackle the massive computing demands and the scarcity of the resources
    (i.e., small size and low power) available at the mobile device, Mobile Edge Computing
    (MEC) is considered as a promising solution to enhance mobile user''s computation
    capability and realize low-latency communications [124]. Cloud-like MEC server
    along with the Access Point (AP) at the edge of networks [125]. The advantage
    of MEC enables the resource-limited mobile users to offload tasks for remote execution
    at the more powerful MEC server in their proximity, which brings the benefit of
    improved computation capacity and reduced latency [126]. The advent of 5G and
    cloud computing will enhance the capacity, functionality, and flexibility of a
    network operators to offer new range of services [117]. Open challenges and trends:
    The interested readers can further explore using extensive survey on 5G and Beyond
    [177]. The open challenges and future research directions for 5G and Beyond are
    summarized as follows: 1. The boosting computation-intensive applications in the
    IoT era along with the growing number of mission-critical tasks in emerging 5G
    networks is a main bottleneck in the design of the real-time communication systems.
    2. 5G networks needs to use Blockchain technology to deliver secure communication.
    3. Data analytics on massive amount of data collected from the massive number
    of sensors in the Industrial IoT use cases can be managed in cost effective manner
    by using 5G based Artificial systems. 4.18. Autoscaling Elasticity feature of
    cloud computing has brought about the opportunity for utilizing self-adaptive
    solutions to minimize the cost of resources while preserving QoS. Self-additivity
    is realized through resource auto-scaling, aka planning, reconfiguration and provisioning.
    Auto-scaling, i.e. dynamically adjustment of computing resources like Virtual
    Machines (VMs), is a widely investigated mechanism [178], by which researchers
    mainly seek for (a) horizontal adjustments, i.e., adding/removing VMs; (b) vertical
    adjustments, i.e., adding/removing resources of VMs [158]; (c) decision-making
    methods, including analytical modeling, control theory, and machine learning [1];
    (d) leveraging varied pricing model, i.e., On-Demand, Reserved and Spot [159];
    and, (e) substituting light-weight container-based machines with hypervisors [160].
    Motivated by QoS requirements, particularly latency, auto-scaling mechanisms are
    always facing two main questions: how to reach a scaling decision timely? And,
    how to execute the decision timely? To reach timely decision, first and foremost
    is to use forecasting using AI. However, conventional machine learning might be
    inefficient when it comes to IoT applications requiring timely error correction,
    as they lack automotive correction without human-intervention. Besides, while
    the need for timely execution and provisioning of resources, in seconds, in cloud
    was about to be accomplished by utilizing container-based solution and by providing
    burstable performance resource [161], latency-critical IoT applications and microservices
    requiring responds in the scale of millisecond appeared—deteriorating the situation.
    A smart car, for instance, continuously senses the wheel speed, the pedestrians’
    movement, and vehicle surrounding; if tailgating is about to happen, for example,
    it must decide in milliseconds and activate the brake-by-wire system, otherwise
    a disaster might happen. This challenge requires auto-scaling mechanisms for IoT
    applications to be aware of mobility, geo-distribution, and location, for which
    cloud is unable to provide solutions lonely because of unstable and long-delay
    links between cloud and users [156]. In fact, cloud naturally conflicts with Industry
    4.0 (i.e. digitization of manufacturing) principles, e.g. real-time controlling
    and decentralized decision-making, hence auto-scaling needs extending. Filling
    such gaps requires two main actions: (a) collaboration between insular clouds
    and (b) bringing the computing close to users/IoT applications—Fog/Edge computing.
    However, such collaborative environments, firstly, raise serious monetization
    concerns for cloud providers [162]. Secondly, although Fog/Edge can extend auto-scaling
    mechanisms execution so that they can be performed by devices in the close proximity
    to users or in fog nodes at the edge of network, as well as cloud, such decentralized
    environments demands the actual realization of 5G networks which is still in the
    infant stages of development. Further, effort could be intelligent prediction
    and decision-making which is becoming the first-class citizens of every optimization
    problem; however, tradition machine learning models, for instance, return inaccurate
    predictions in some cases which require to be fixed by the programmers, conflicting
    with latency requirements of applications. Open challenges and trends: The interested
    readers can further explore using extensive survey on Autoscaling [178]. The open
    challenges and future research directions for Autoscaling are summarized as follows:
    1. Extending auto-scaling across the compute continuum from IoT devices to cloud
    in order for timely execution/processing of scaling decisions is a challenging
    problem that needs to be addressed. 2. Blockchain-enabled auto-scaling utilizing
    Blockchain capabilities such as Smart SCs in order for addressing first security
    concerns and second unsolved monetization problem in federated cloud for services
    provided in collaborative computing is a new challenge. 3. Self-correction prediction
    and multi-objective auto-scaling using AI for the trade-off between performance
    and cost can be accomplished using Deep Learning. Recently, deep learning, i.e.
    automation of predictive analytics—a subset of AI—has gain more attention for
    solving the problems which have not been yet solved. 5. Insights of triumvirate
    to the cloud computing evolution: A vision The purpose of the study would be to
    see how the three new technologies (Blockchain, IoT and Artificial Intelligence)
    will influence the evolution of cloud computing. We reviewed 140 research papers
    in this systematic review and presented them in a categorized manner and it comprises
    of most recent research work related to cloud computing paradigms and technologies.
    We discussed the research issues addressed and open challenges that need more
    attention in future to conduct next level research. Fig. 3 shows the insights
    of the triumvirate (Blockchain, IoT and Artificial Intelligence) to the evolution
    of cloud computing. Download : Download full-size image Fig. 3. Insights of triumvirate
    to the cloud computing evolution. 6. A conceptual model for cloud futurology:
    Holistic view To resolve the above-mentioned challenges, there is a requirement
    of conceptual model to explore the influence of three emerging paradigms (Blockchain,
    IoT and Artificial Intelligence) on evolution of cloud computing. Fig. 4 shows
    the conceptual model, which describes the transformation effects of paradigms
    and technologies on cloud computing evolution. The model integrates the three
    paradigms: IoT, Blockchain and Artificial Intelligence to provide a holistic view
    of an abstract design encompassing multiple domains in computer science. Various
    components of IoT including sensors and actuators communicate with the gateway,
    all connected through 5G technology. The user interacts with the model using app
    interface on the gateway device with compute costing through Bitcoin (or related
    cryptocurrency) technology. The gateway layer also contains basic pre-processing
    data engine and various IoT applications for task generation and result collection
    in seamless fashion. The tasks are sent to and managed by the Broker nodes which
    authenticate payments and other transactions with sophisticated energy and resource
    management modules, backed with fault tolerance and security systems. These nodes
    are also connected to the database and external controllers through SDN. The computation
    tasks are executed on fog or cloud machines (physical or virtual) having robust
    data analytics, deep learning and Blockchain mining capabilities. Software engineering
    and autoscaling allow end-to-end integration with cloud allowing resource availability
    from server-based deployments to serverless frameworks. The model is enhanced
    by quantum computing technologies. Overall, the model integrates and enables computation
    using a plethora of technological advancements and provides an enhanced and holistic
    setup for next generation computing environments. Download : Download full-size
    image Fig. 4. A conceptual model for cloud futurology. 7. Summary and conclusions
    Cloud computing is an emerging paradigm, enabling on demand, metered access to
    compute resources (Process, Memory, Storage, etc.) driving technological innovation
    and enabling geographically distributed applications. In this review paper, we
    have presented the systematic review of computing paradigms and technologies and
    the influence of triumvirate (Blockchain, IoT and Artificial Intelligence) to
    the evolution of cloud computing. The history and background of computing paradigms
    and technologies has been presented and designed its evolution. Further, the research
    areas related to cloud computing have been identified, discussed and the research
    issues and challenges are highlighted. We have proposed a conceptual model to
    explore the influence of three emerging paradigms (Blockchain, IoT and Artificial
    Intelligence) on evolution of cloud computing. We hope that this systemic review
    will be beneficial for researchers who want to do research in any area concerning
    to cloud computing. Declaration of Competing Interest We do not have any conflicts
    of interest. Acknowledgments We would like to thank the editor, area editor and
    anonymous reviewers for their valuable comments and suggestions to help and improve
    our research paper. References [1] B.P. Rimal, Choi E., I. Lumb A taxonomy and
    survey of cloud computing systems Proceedings of the Fifth International Joint
    Conference on INC, IMS and IDC (NCM''09), IEEE (2009), pp. 44-51 CrossRefView
    in ScopusGoogle Scholar [2] M.J Flynn Very high-speed computing systems Proc.
    IEEE, 54 (12) (1966), pp. 1901-1909 View in ScopusGoogle Scholar [3] T.L. Casavant,
    J.G. Kuhl A taxonomy of scheduling in general-purpose distributed computing systems
    IEEE Trans. Softw. Eng., 14 (2) (1988), pp. 141-154 View in ScopusGoogle Scholar
    [4] Yu J., R. Buyya A taxonomy of workflow management systems for grid computing
    J. Grid Comput., 3 (3–4) (2005), pp. 171-200 CrossRefView in ScopusGoogle Scholar
    [5] K. Compton, S. Hauck Reconfigurable computing: a survey of systems and software
    ACM Comput. Surv. (CSUR), 34 (2) (2002), pp. 171-210 View in ScopusGoogle Scholar
    [6] S. Singh, I. Chana QoS-aware autonomic resource management in cloud computing:
    a systematic review ACM Comput. Surv. (CSUR), 48 (3) (2016), p. 42 Google Scholar
    [7] The Evolution of Distributed Systems. Available Online:https://medium.com/microservices-learning/the-evolution-of-distributed-systems-fec4d35beffd,
    2018. Google Scholar [8] F. Bonomi, R. Milito, Zhu J., S. Addepalli Fog computing
    and its role in the internet of things Proceedings of the First Edition of the
    MCC Workshop on Mobile Cloud Computing, ACM (2012), pp. 13-16 CrossRefGoogle Scholar
    [9] A. Alrawais, et al. Fog computing for the internet of things: security and
    privacy issues IEEE Internet Comput., 21 (2) (2017), pp. 34-42 View in ScopusGoogle
    Scholar [10] Wang Y., T. Uehara, R. Sasaki Fog computing: issues and challenges
    in security and forensics Proceedings of the 39th IEEE Annual Computer Software
    and Applications Conference, 3, IEEE (2015) Google Scholar [11] S. Nakamoto, Bitcoin:
    a peer-to-peer electronic cash system, 2008 Google Scholar [12] Antonopoulos A.M.Mastering
    Bitcoin Unlocking Digital Cryptocurrencies O''Reilly Media, Inc. (2014) Google
    Scholar [13] A. Reyna, et al. On blockchain and its integration with IoT. Challenges
    and opportunities Fut. Gen. Comput. Syst., 88 (2018), pp. 173-190 View PDFView
    articleView in ScopusGoogle Scholar [14] A. Kosba, A. Miller, Shi E., Wen Z.,
    C. Papamanthou Hawk: the blockchain model of cryptography and privacy-preserving
    smart contracts Proceedings of the 2016 IEEE Symposium on Security and Privacy
    (SP), San Jose, CA, USA, IEEE (2016), pp. 839-858 CrossRefView in ScopusGoogle
    Scholar [15] S. Tuli, R. Mahmud, S. Tuli, R. Buyya FogBus: a blockchain-based
    lightweight framework for edge and fog computing J. Syst. Softw., 154 (2019),
    pp. 22-36 August 2019 View PDFView articleView in ScopusGoogle Scholar [16] A.
    Stanciu Blockchain based distributed control system for edge computing Proceedings
    of the 21st International Conference on Control Systems and Computer Science (CSCS),
    IEEE (2017) Google Scholar [17] M. Samaniego, R. Deters Blockchain as a service
    for IoT Proceedings of the2016 IEEE International Conference on Internet of Things
    (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber,
    Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData), IEEE (2016)
    Google Scholar [18] Li X., Jiang P., Chen T., Luo X., Wen Q. A survey on the security
    of blockchain systems Fut. Gen. Comput. Syst. (2017), 10.1016/j.future.2017.08.020
    Google Scholar [19] S. Singh, I. Chana Q-aware: quality of service based cloud
    resource provisioning Comput. Electr. Eng., 47 (2015), pp. 138-160 View PDFView
    articleView in ScopusGoogle Scholar [20] S.S. Gill, I. Chana, M. Singh, R. Buyya
    RADAR: self‐configuring and self‐healing in resource management for enhancing
    quality of cloud services Concurr. Comput. Pract. Exp., 31 (1) (2019), p. e4834
    View in ScopusGoogle Scholar [21] A Glikson, S Nastic, S. Dustdar Deviceless edge
    computing: extending serverless computing to the edge of the network Proceedings
    of the 10th ACM International Systems and Storage Conference, ACM (2017), p. 28
    View in ScopusGoogle Scholar [22] J. Gubbi, R. Buyya, S. Marusic, M. Palaniswami
    Internet of things (IoT): a vision, architectural elements, and future directions
    Fut. Gen. Comput. Syst., 29 (7) (2013), pp. 1645-1660 View PDFView articleView
    in ScopusGoogle Scholar [23] E.M. Tordera et al., “What is a Fog Node a Tutorial
    on Current Concepts Towards a Common Definition,” 2016. Google Scholar [24] F.
    Bonomi, R. Milito, Zhu J., S. Addepalli Fog computing and its role in the internet
    of things characterization of fog computing Proceedings of the First Edition of
    the MCC Workshop on Mobile Cloud Computing (2012), pp. 13-15 View in ScopusGoogle
    Scholar [25] Lin J., Yu W., Zhang N., Yang X., Zhang H., W. Zhao A survey on internet
    of things: architecture, enabling technologies, security and privacy, and applications
    IEEE Internet Things J., 4 (5) (2017), pp. 1125-1142 View in ScopusGoogle Scholar
    [26] S. Singh, I. Chana, M. Singh The journey of QoS-aware autonomic cloud computing
    IT Prof., 19 (2) (2017), pp. 42-49 View in ScopusGoogle Scholar [27] S.N. Shirazi,
    A. Gouglidis, A. Farshad, D. Hutchison The extended cloud: review and analysis
    of mobile edge computing and fog from a security and resilience perspective IEEE
    J. Sel. Areas Commun., 35 (11) (2017), pp. 2586-2595 View in ScopusGoogle Scholar
    [28] M. Iorga, L. Feldman, R. Barton, M.J. Martin, N. Goren, and C. Mahmoudi,
    “Fog computing conceptual model: recommendations of the national institute of
    standards and technology,” NIST Spec. Publ., pp. 500–325, 2018. [Online] Available:
    https://doi.org/10.6028/NIST.SP.500-325. Google Scholar [29] A.M. Rahmani, et
    al. Exploiting smart e-Health gateways at the edge of healthcare Internet-of-Things:
    a fog computing approach Fut. Gen. Comput. Syst., 78 (2018), pp. 641-658 View
    PDFView articleView in ScopusGoogle Scholar [30] X. Fang, S. Member, S. Misra,
    G. Xue, and D. Yang, “Smart Grid – The New and Improved Power Grid :,” pp. 1–37,
    2011. Google Scholar [31] H. Madsen, G. Albeanu, B. Burtschy, F. Popentiu-Vladicescu
    Reliability in the utility computing era: towards reliable fog computing Proceedings
    of the International Conference on Systems, Signals and Image Processing (2013),
    pp. 43-46 CrossRefView in ScopusGoogle Scholar [32] Lin J., Yu W., Yang X. Towards
    multistep electricity prices in smart grid electricity markets IEEE Trans. Parallel
    Distrib. Syst., 27 (1) (2016), pp. 286-302 View in ScopusGoogle Scholar [33] D.
    Michie, D.J. Spiegelhalter, C.C. Taylor Machine learning Neural Stat. Classif.,
    13 (1994), pp. 1-298 View in ScopusGoogle Scholar [34] Chen M., Hao Y., Hwang
    K., Wang L., Wang L. Disease prediction by machine learning over big data from
    healthcare communities IEEE Access, 5 (2017), pp. 8869-8879 View in ScopusGoogle
    Scholar [35] M.I. Jordan, T.M. Mitchell Machine learning: trends, perspectives,
    and prospects Science, 349 (6245) (2015), pp. 255-260 CrossRefView in ScopusGoogle
    Scholar [36] Jia L., Zhao Q., Tong L. Retail pricing for stochastic demand with
    unknown parameters: an online machine learning approach Proceedings of the 51st
    Annual Allerton Conference on Communication, Control, and Computing (Allerton),
    IEEE (2013), pp. 1353-1358 View in ScopusGoogle Scholar [37] R. Carbonneau, K.
    Laframboise, R. Vahidov Application of machine learning techniques for supply
    chain demand forecasting Eur. J. Oper. Res., 184 (3) (2008), pp. 1140-1154 View
    PDFView articleView in ScopusGoogle Scholar [38] A. Steane Quantum computing Rep.
    Progr. Phys., 61 (2) (1998), p. 117 View in ScopusGoogle Scholar [39] M.N. Leuenberger,
    D. Loss Quantum computing in molecular magnets Nature, 410 (6830) (2001), p. 789
    View in ScopusGoogle Scholar [40] Han K.H., Kim J.H. Quantum-inspired evolutionary
    algorithm for a class of combinatorial optimization IEEE Trans. Evol. Comput.,
    6 (6) (2002), pp. 580-593 View in ScopusGoogle Scholar [41] M. Schuld, I. Sinayskiy,
    F. Petruccione An introduction to quantum machine learning Contemp. Phys., 56
    (2) (2015), pp. 172-185 CrossRefView in ScopusGoogle Scholar [42] Lloyd, S., Mohseni,
    M. and Rebentrost, P., 2013. Quantum Algorithms for Supervised and Unsupervised
    Machine Learning. arXiv:1307.0411. Google Scholar [43] I. Singh, S. Singh Framework
    for targeting high value customers and potential churn customers in telecom using
    big data analytics Int. J. Educ. Manag. Eng., 7 (1) (2017), pp. 36-45 CrossRefGoogle
    Scholar [44] I. Singh, S. Singh Model for targeting customers based on analytics
    in telecom domain Int. J. Mod. Educ. Comput. Sci., 8 (11) (2016), p. 43 CrossRefGoogle
    Scholar [45] I. Singh, K.V. Singh, S. Singh Big data analytics based recommender
    system for value added services (VAS) Proceedings of the Sixth International Conference
    on Soft Computing for Problem Solving, Singapore, Springer (2017), pp. 142-150
    CrossRefView in ScopusGoogle Scholar [46] S.S. Gill, P. Garraghan, R. Buyya ROUTER:
    fog enabled cloud based intelligent resource management approach for smart home
    IoT devices J. Syst. Softw., 154 (2019), pp. 125-138 View PDFView articleView
    in ScopusGoogle Scholar [47] S.S. Gill, P. Garraghan, V. Stankovski, G. Casale,
    K Ruppa, S.K.G. Thulasiram, K. Ramamohanarao, R. Buyya Holistic resource management
    for sustainable and reliable cloud computing: an innovative solution to global
    challenge J. Syst. Softw., 155 (2019), pp. 104-129 View PDFView articleView in
    ScopusGoogle Scholar [48] S. Teerapittayanon, B. McDanel, H.T. Kung Distributed
    deep neural networks over the cloud, the edge and end devices Proceedings of the
    37th IEEE International Conference on Distributed Computing Systems (ICDCS), IEEE
    (2017), pp. 328-339 CrossRefView in ScopusGoogle Scholar [49] K.K. Nguyen, D.T.
    Hoang, D. Niyato, Wang P., D. Nguyen, E. Dutkiewicz Cyberattack detection in mobile
    cloud computing: a deep learning approach Proceedings of the 2018 IEEE Wireless
    Communications and Networking Conference (WCNC), IEEE (2018), pp. 1-6 CrossRefGoogle
    Scholar [50] A.E. Eshratifar, A. Esmaili, M. Pedram, 2019. BottleNet: A Deep Learning
    Architecture for Intelligent Mobile Cloud Computing Services. arXiv:1902.01000.
    Google Scholar [51] S.A. Osia, A.S. Shamsabadi, A. Taheri, K. Katevas, S. Sajadmanesh,
    H.R. Rabiee, N.D. Lane, H. Haddadi, 2017. A Hybrid Deep Learning Architecture
    for Privacy-Preserving Mobile Analytics. arXiv:1703.02952. Google Scholar [52]
    S. Singh, I. Chana A survey on resource scheduling in cloud computing: issues
    and challenges J. Grid Comput., 14 (2) (2016), pp. 217-264 View in ScopusGoogle
    Scholar [53] S. Singh, I. Chana, R. Buyya STAR: SLA-aware autonomic management
    of cloud resources IEEE Trans. Cloud Comput. (2017), pp. 1-14, 10.1109/TCC.2017.2648788
    Google Scholar [54] A.E. Eshratifar, M. Pedram Energy and performance efficient
    computation offloading for deep neural networks in a mobile cloud computing environment
    Proceedings of the 2018 on Great Lakes Symposium on VLSI, ACM (2018), pp. 111-116
    CrossRefView in ScopusGoogle Scholar [55] S. Singh, I. Chana Consistency verification
    and quality assurance (CVQA) traceability framework for saas Proceedings of the
    3rd IEEE International Advance Computing Conference (IACC), IEEE (2013), pp. 1-6
    Google Scholar [56] S. Singh, I. Chana Cloud resource provisioning: survey, status
    and future research directions Knowl. Inf. Syst., 49 (3) (2016), pp. 1005-1069
    CrossRefView in ScopusGoogle Scholar [57] C. Wu, R. Buyya, K. Ramamohanarao, 2016.
    Big Data Analytics= Machine Learning+ Cloud Computing. arXiv:1601.03115. Google
    Scholar [58] S.S. Gill, R. Buyya A taxonomy and future directions for sustainable
    cloud computing: 360 degree view ACM Comput. Surv. (CSUR), 51 (5) (2018), p. 104
    View in ScopusGoogle Scholar [59] S.S. Gill, I. Chana, R. Buyya IoT based agriculture
    as a cloud and big data service: the beginning of digital India J. Organ. End
    User Comput. (JOEUC), 29 (4) (2017), pp. 1-23 View in ScopusGoogle Scholar [60]
    Luo Z., A. Small, L. Dugan, S. Lane Cloud Chaser: real time deep learning computer
    vision on low computing power devices Proceedings of the Eleventh International
    Conference on Machine Vision (ICMV 2018), 11041, International Society for Optics
    and Photonics (2019, March), Article 110412Q View in ScopusGoogle Scholar [61]
    S.S. Gill, R.C. Arya, G.S. Wander, R. Buyya Fog-based smart healthcare as a big
    data and cloud service for heart patients using IoT Proceedings of the International
    Conference on Intelligent Data Communication Technologies and Internet of Things,
    Cham, Springer (2018), pp. 1376-1383 Google Scholar [62] Wang J., Zhang J., Bao
    W., Zhu X., Cao B., Yu P.S. Not just privacy: improving performance of private
    deep learning in mobile cloud Proceedings of the 24th ACM SIGKDD International
    Conference on Knowledge Discovery & Data Mining, ACM (2018), pp. 2407-2416 Google
    Scholar [63] S.S. Gill, R. Buyya Failure management for reliable cloud computing:
    a taxonomy, model and future directions Comput. Sci. Eng. (2018), pp. 1-10, 10.1109/MCSE.2018.2873866
    Google Scholar [64] He Y., Yu F.R., Zhao N., Leung V.C., Yin H. Software-defined
    networks with mobile edge computing and caching for smart cities: a big data deep
    reinforcement learning approach IEEE Commun. Mag., 55 (12) (2017), pp. 31-37 View
    in ScopusGoogle Scholar [65] M. Roopaei, P. Rad, M. Jamshidi Deep learning control
    for complex and large scale cloud systems Intell. Autom. Soft Comput., 23 (3)
    (2017), pp. 389-391 CrossRefView in ScopusGoogle Scholar [66] S.S. Gill, R. Buyya
    Bio-Inspired algorithms for big data analytics: a survey, taxonomy, and open challenges
    Big Data Analytics for Intelligent Healthcare Management, Academic Press (2019),
    pp. 1-17 View PDFView articleCrossRefView in ScopusGoogle Scholar [67] S. Singh,
    I. Chana Enabling reusability in agile software development Int. J. Comput. Appl.,
    50 (13) (2012), pp. 33-40 CrossRefGoogle Scholar [68] B. Kehoe, S. Patil, P. Abbeel,
    K. Goldberg A survey of research on cloud robotics and automation IEEE Trans.
    Autom. Sci. Eng., 12 (2) (2015), pp. 398-409 View in ScopusGoogle Scholar [69]
    Xu Z., Wang Y., Tang J., Wang J., M.C. Gursoy A deep reinforcement learning based
    framework for power-efficient resource allocation in cloud RANs Proceedings of
    the 2017 IEEE International Conference on Communications (ICC), IEEE (2017, May),
    pp. 1-6 Google Scholar [70] M. Stefanini, R. Lancellotti, L. Baraldi, S. Calderara,
    2019. A Deep Learning Based Approach to VM Behavior Identification in Cloud Systems.
    arXiv:1903.01930. Google Scholar [71] Li P., Li J., Huang Z., Gao C.Z., Chen W.B.,
    K. Chen Privacy-preserving outsourced classification in cloud computing Clust.
    Comput., 21 (1) (2018), pp. 277-286 CrossRefView in ScopusGoogle Scholar [72]
    Li X., Jiang X., P. Garraghan, Wu Z. 2018. Holistic energy and failure aware workload
    scheduling in Cloud datacenters Fut. Gen. Comput. Syst., 78 (2018), pp. 887-900
    View PDFView articleGoogle Scholar [73] F. Bonomi ‘Connected vehicles, the internet
    of things, and fog computing Proceedings of the Eighth ACM International Workshop
    on Vehicular InterNetworking (VANET), Las Vegas, USA (2011), pp. 13-15 Google
    Scholar [74] S. Tuli, N. Basumatary, S.S. Gill, M. Kahani, R.C. Arya, G.S. Wander,
    R. Buyya HealthFog: an ensemble deep learning based smart healthcare system for
    automatic diagnosis of heart diseases in integrated IoT and fog computing environments
    Fut. Gen. Comput. Syst., 103 (2019), pp. 1-14 CrossRefView in ScopusGoogle Scholar
    [75] S. Singh, I. Chana, M. Singh, R. Buyya SOCCER: self-optimization of energy-efficient
    cloud resources Clust. Comput., 19 (4) (2016), pp. 1787-1800 CrossRefView in ScopusGoogle
    Scholar [76] R. Buyya, S.S. Gill Sustainable cloud computing: foundations and
    future directions Bus. Technol. Digit. Transform. Strat. Cutter Consort., 21 (6)
    (2018), pp. 1-9 View in ScopusGoogle Scholar [77] Zhang K., et al. Mobile edge
    computing and networking for green and low-latency internet of things IEEE Commun.
    Mag., 56 (5) (2018), pp. 39-45 CrossRefView in ScopusGoogle Scholar [78] F. Jalali,
    et al. Fog computing may help to save energy in cloud computing IEEE J. Sel. Areas
    Commun., 34 (5) (2016), pp. 1728-1739 View in ScopusGoogle Scholar [79] Google
    Edge TPU, [Online] Available: https://cloud.google.com/edge-tpu/ [Accessed 15
    4 2019]. Google Scholar [80] J.A. Khan, H.K. Qureshi, A. Iqbal Energy management
    in wireless sensor networks: a survey Comput. Electr. Eng., 41 (2015), pp. 159-176
    View PDFView articleView in ScopusGoogle Scholar [81] D. Ventura, et al. ARIIMA:
    a real IoT implementation of a machine-learning architecture for reducing energy
    consumption Proceedings of the International Conference on Ubiquitous Computing
    and Ambient Intelligence, Cham, Springer (2014) Google Scholar [82] Zhang Q.,
    Cheng L., R. Boutaba Cloud computing: state-of-the-art and research challenges
    J. Internet Serv. Appl., 1 (1) (2010), pp. 7-18 CrossRefView in ScopusGoogle Scholar
    [83] Wang H., Wang Z., J. Domingo-Ferrer Anonymous and secure aggregation scheme
    in fog-based public cloud computing Fut. Gen. Comput. Syst., 78 (2018), pp. 712-719
    View PDFView articleView in ScopusGoogle Scholar [84] S.S. Gill, R. Buyya SECURE:
    self-protection approach in cloud resource management IEEE Cloud Comput., 5 (1)
    (2018), pp. 60-72 CrossRefView in ScopusGoogle Scholar [85] R. Roman, J. Lopez,
    M. Mambo Mobile edge computing, Fog et al.: a survey and analysis of security
    threats and challenges Fut. Gen. Comput. Syst., 78 (2018), pp. 680-698 View PDFView
    articleView in ScopusGoogle Scholar [86] S. Singh, I. Chana EARTH: energy-aware
    autonomic resource scheduling in cloud computing J. Intell. Fuzzy Syst., 30 (3)
    (2016), pp. 1581-1600 View in ScopusGoogle Scholar [87] Liu X., Yang Y., Choo
    K.-K.R., Wang H. Security and privacy challenges for Internet-of-Things and fog
    computing Wirel. Commun. Mob. Comput., 2018 (2018), pp. 1-3 Google Scholar [88]
    F. Manco, J. Martins, K. Yasukata, J. Mendes, S. Kuenzer, F. Huici The case for
    the superfluid cloud Proceedings of the 7th USENIX Workshop on Hot Topics in Cloud
    Computing (HotCloud 15) (2015) Google Scholar [89] I. Stojmenovic, Wen S., Huang
    X., Luan H. An overview of fog computing and its security issues Concurr. Comput.
    Pract. Exp., 28 (10) (2016), pp. 2991-3005 CrossRefView in ScopusGoogle Scholar
    [90] Feng S., Xiong Z., D. Niyato, Wang P. Dynamic resource management to defend
    against advanced persistent threats in fog computing: a game theoretic approach
    IEEE Trans. Cloud Comput. (2019), pp. 1-12, 10.1109/TCC.2019.2896632 Google Scholar
    [91] S. Khan, S. Parkinson, Qin Y. Fog computing security: a review of current
    applications and security solutions J. Cloud Comput., 6 (1) (2017), p. 19 View
    PDFView articleCrossRefGoogle Scholar [92] C. Modi, D. Patel A feasible approach
    to intrusion detection in virtual network layer of Cloud computing Sādhanā, 43
    (7) (2018), p. 114 View in ScopusGoogle Scholar [93] M. Mukherjee, R. Matam, Shu
    L., L. Maglaras, M.A. Ferrag, N. Choudhury, V. Kumar Security and privacy in fog
    computing: challenges IEEE Access, 5 (2017), pp. 19293-19304 View in ScopusGoogle
    Scholar [94] E. Novak, Li Q. Near-pri: private, proximity based location sharing
    Proceedings of the IEEE INFOCOM Conference on Computer Communications, IEEE (2014),
    pp. 37-45 View in ScopusGoogle Scholar [95] Shi Y., S. Abhilash, Hwang K. Cloudlet
    mesh for securing mobile clouds from intrusions and network attacks Proceedings
    of the 3rd IEEE International Conference on Mobile Cloud Computing, Services,
    and Engineering, IEEE (2015), pp. 109-118 View in ScopusGoogle Scholar [96] Shin
    S.W., Gu G. CloudWatcher: network security monitoring using openflow in dynamic
    cloud networks Proceedings of the International Conference on Network Protocols
    (ICNP) 2012, IEEE (2012), pp. 1-6 Google Scholar [97] Song D.X., D. Wagner, A.
    Perrig Practical techniques for searches on encrypted data Proceeding 2000 IEEE
    Symposium on Security and Privacy, S&P, IEEE (2000), pp. 19-55 Google Scholar
    [98] M. Tsugawa, A. Matsunaga, J.A.B. Fortes Cloud computing security: what changes
    with software-defined networking? Secure Cloud Computing, Springer, New York,
    NY (2014), pp. 77-93 CrossRefView in ScopusGoogle Scholar [99] D. Willis, A. Dasgupta,
    S. Banerjee ParaDrop: a multi-tenant platform to dynamically install third party
    services on wireless gateways Proceedings of the 9th ACM Workshop on Mobility
    in the Evolving Internet Architecture, ACM (2014), pp. 43-48 CrossRefGoogle Scholar
    [100] K.-K. Yap, Y. Yiakoumis, M. Kobayashi, S. Katti, G. Parulkar, N. McKeown
    Separating Authentication, Access and Accounting: A Case Study with OpenWiFi Open
    Networking Foundation (2011) Technical Report Google Scholar [101] Hsu T.-C.,
    Yang H., Chung Y.-C., Hsu C.-H. A creative iot agriculture platform for cloud
    fog computing Sustain. Comput. Inf. Syst. (2018), 10.1016/j.suscom.2018.10.006
    Google Scholar [102] E. Guardo, D. Stefano, Alessandro, L. Corte, Aurelio, M.
    Sapienza, M. Scatà A fog computing-based IoT framework for precision agriculture
    J. Internet Technol., 19 (2018), pp. 1401-1411, 10.3966/160792642018091905012
    View in ScopusGoogle Scholar [103] O.H. Lee, 2019, https://flybits.com/resources/blog/big-data-transforming-banking/.
    Google Scholar [104] Ji C., Li Y., Qiu W., U. Awada, Li K. Big data processing
    in cloud computing environments Proceedings of the 12th International Symposium
    on Pervasive Systems, Algorithms and Networks, San Marcos, TX (2012), pp. 17-23
    CrossRefView in ScopusGoogle Scholar [105] J. Dean, S. Ghemawat MapReduce: simplified
    data processing on large clusters Commun. ACM, 51 (1) (2008), pp. 107-113 January
    2008 CrossRefView in ScopusGoogle Scholar [106] M. Mettler Blockchain technology
    in healthcare: The revolution starts here Proceedings of the 18th IEEE International
    Conference on e-Health Networking, Applications and Services (Healthcom), IEEE
    (2016), pp. 1-3 CrossRefGoogle Scholar [107] D. Tapscott, A. Tapscott Blockchain
    Revolution: How the Technology Behind Bitcoin is Changing Money, Business, and
    the World Penguin (2016) Google Scholar [108] T.M. Fernández-Caramés, P. Fraga-Lamas
    A review on the use of blockchain for the internet of things IEEE Access, 6 (2018),
    pp. 32979-33001 CrossRefView in ScopusGoogle Scholar [109] M. Parekh, How Helpful
    is Blockchain Technology in Cloud Storage, Open Source for You, 2018. URL:https://opensourceforu.com/2018/11/how-helpful-is-blockchain-technology-in-cloud-storage/.
    Google Scholar [110] G. Fedak, How can Blockchain Improve Cloud Computing, iEXec,
    2016. URL:https://medium.com/iex-ec/how-blockchain-can-improve-cloud-computing-1ca24c270f4f.
    Google Scholar [111] A. Dorri, S.S. Kanhere, R. Jurdak, et al. Blockchain for
    IoT security and privacy: the case study of a smart home Proceedings of the 2017
    IEEE International Conference on Pervasive Computing and Communications Workshops
    (PerCom Workshops), IEEE (2017), pp. 618-623 View in ScopusGoogle Scholar [112]
    R. Guha, D. Al-Dabass Impact of web 2.0 and cloud computing platform on software
    engineering Proceedings of the 2010 International Symposium on Electronic System
    Design, IEEE (2010), pp. 213-218 View in ScopusGoogle Scholar [113] W.A. Simm,
    et al. SE in ES: opportunities for software engineering and cloud computing in
    environmental science Proceedings of the 40th International Conference on Software
    Engineering: Software Engineering in Society, ACM (2018) Google Scholar [114]
    N. Kannan, 6 Ways the Cloud Enhances Agile Software Development, Enterprise Architecture,
    2012, URL:https://www.cio.com/article/2393022/6-ways-the-cloud-enhances-agile-software-development.html.
    Google Scholar [115] Yau S., H. An Software engineering meets services and cloud
    computing Computer, 44 (10) (2011), pp. 47-53 View in ScopusGoogle Scholar [116]
    A.N. Toosi, J. Son, R. Buyya Clouds-Pi: a low-cost raspberry-Pi based micro data
    center for software-defined cloud computing IEEE Cloud Comput., 5 (5) (2018),
    pp. 81-91 Google Scholar [117] R.I. Ansari, H. Pervaiz, S.A. Hassan, C. Chrysostomou,
    M.A. Imran, S. Mumtaz, R. Tafazolli A new dimension to spectrum management in
    IoT empowered 5G networks Proceedings of the 2019 IEEE Network (2019) Google Scholar
    [118] S. Singh, I. Chana, Efficient cloud workload management framework, Master''s
    Thesis, Thapar University, Patiala, Punjab, India, 2013. Google Scholar [119]
    5G will bring cloud computing to everyone, Cloud Computing by David Linthicum,
    InfoWorld, 2018, [Online] Available: https://www.infoworld.com/article/3308378/5g-will-bring-cloud-computing-to-everyone.html.
    Google Scholar [120] J.G. Andrews, et al. What will 5G be? IEEE J. Sel. Areas
    Commun., 32 (6) (2014), pp. 1065-1082 View in ScopusGoogle Scholar [121] S. Singh,
    I. Chana, QoS-aware Autonomic Resource Provisioning and Scheduling for Cloud Computing,
    PhD Thesis, Thapar University, Patiala, Punjab, India, 2016. Google Scholar [122]
    How 5G Will Accelerate Cloud Business Investment, 2019, [Online] Available: https://www.comparethecloud.net/articles/how-5g-will-accelerate-cloud-business-investment/.
    Google Scholar [123] S. Kekki et.al., MEC in 5G Networks, ETSI White Paper No.
    28, First edition, 2018, ISBN No. 979-10-92620-22-1 Google Scholar [124] Wang
    C.-X., F. Haider, Gao X., You X.-H., Yang Y., Yuan D., H.M. Aggoune, H. Haas,
    S. Fletcher, E. Hepsaydir Cellular architecture and key technologies for 5G wireless
    communication networks IEEE Commun. Mag., 52 (2) (2014), pp. 122-130 View in ScopusGoogle
    Scholar [125] Li S., et al. Energy-efficient resource allocation for industrial
    cyber physical IoT systems in 5G era IEEE Trans. Ind. Inform., 14 (6) (2018),
    pp. 2618-2628 CrossRefView in ScopusGoogle Scholar [126] Wang C., Liang C., Yu
    F.R., Chen Q., Tang L. Computation offloading and resource allocation in wireless
    cellular networks with mobile edge computing IEEE Trans. Wirel. Commun., 16 (8)
    (2017), pp. 4924-4938 View in ScopusGoogle Scholar [127] A. Ndikumana et al.,
    Joint communication, computation, caching, and control in big data multi-access
    edge computing, IEEE Transactions on Mobile Computing, 2019. doi:10.1109/TMC.2019.2908403.
    Google Scholar [128] R. Buyya, S.N. Srirama, G. Casale, R. Calheiros, Y. Simmhan,
    B. Varghese, E. Gelenbe, et al. A manifesto for future generation cloud computing:
    research directions for the next decade ACM Comput. Surv. (CSUR), 51 (5) (2018),
    p. 105 Google Scholar [129] S. Tuli, N. Basumatary, R. Buyya EdgeLens: deep learning
    based object detection in integrated IoT, fog and cloud computing environments
    Proceedings of the 4th IEEE International Conference on Information Systems and
    Computer Networks, ISCON 2019, IEEE Press, USA, Mathura, India (2019) November
    21-22 Google Scholar [130] M.A. Rodriguez, R. Buyya Container‐based cluster orchestration
    systems: a taxonomy and future directions Softw. Pract. Exp., 49 (5) (2019), pp.
    698-719 CrossRefView in ScopusGoogle Scholar [131] J. Son, R. Buyya A taxonomy
    of software-defined networking (SDN)-enabled cloud computing ACM Comput. Surv.
    (CSUR), 51 (3) (2018), p. 59 View in ScopusGoogle Scholar [132] J. Son, R. Buyya
    Priority-aware VM allocation and network bandwidth provisioning in software-defined
    networking (SDN)-enabled clouds IEEE Trans. Sustain. Comput., 4 (1) (2018), pp.
    17-28 CrossRefView in ScopusGoogle Scholar [133] A.N. Toosi, R. Buyya Acinonyx:
    dynamic flow scheduling for virtual machine migration in SDN-enabled clouds Proceedings
    of the 2018 IEEE Intl Conf on Parallel & Distributed Processing with Applications,
    Ubiquitous Computing & Communications, Big Data & Cloud Computing, Social Computing
    & Networking, Sustainable Computing & Communications (ISPA/IUCC/BDCloud/SocialCom/SustainCom),
    IEEE (2018), pp. 886-894 Google Scholar [134] He T.Z., A.N. Toosi, R. Buyya Performance
    evaluation of live virtual machine migration in SDN-enabled cloud data centers
    J. Parallel Distrib. Comput., 131 (2019), pp. 55-68 View PDFView articleView in
    ScopusGoogle Scholar [135] S.S. Gill, R. Buyya Sustainable cloud computing realization
    for different applications: a manifesto Digital Business, Springer, Cham (2019),
    pp. 95-117 CrossRefView in ScopusGoogle Scholar [136] L.S. Bishop, A.W. Cross,
    I. Faro Sertage, J.M. Gambetta. “Job Processing in Quantum Computing Enabled Cloud
    Environments.” U.S. Patent Application, Google Patents, 15/719,872, filed April
    4, 2019. Google Scholar [137] M. Caleffi, A.S. Cacciapuoti, G. Bianchi. Quantum
    Internet: From Communication to Distributed Computing!, in: Proceedings of the
    5th ACM International Conference on Nanoscale Computing and Communication Article
    No. 3 Reykjavik, Iceland — September 05 - 07, 2018, 1–4. Google Scholar [138]
    Zhang H., H. Leipold, R. Kosut, D. Lidar Demonstration of channel-optimized quantum
    error correction on cloud-based quantum computers Proceedings of the 2019 APS
    Meeting Abstracts (2019) Google Scholar [139] N. Jindal, S. Chandran, P.R. Panda,
    S. Prasad, A. Mitra, K. Singhal, S. Gupta, S. Tuli DHOOM: reusing design-for-debug
    hardware for online monitoring Proceedings of the 56th Annual Design Automation
    Conference 2019, ACM (2019), p. 99 Google Scholar [140] A.N. Toosi, R.O. Sinnott,
    R. Buyya Resource provisioning for data-intensive applications with deadline constraints
    on hybrid clouds using Aneka Fut. Gen. Comput. Syst., 79 (2018), pp. 765-775 Google
    Scholar [141] O. Skarlat, M. Nardelli, S. Schulte, M. Borkowski, P. Leitner Optimized
    IoT service placement in the fog Serv. Oriented Comput. Appl., 11 (4) (2017),
    pp. 427-443 CrossRefView in ScopusGoogle Scholar [142] A. Beloglazov, R. Buyya
    Optimal online deterministic algorithms and adaptive heuristics for energy and
    performance efficient dynamic consolidation of virtual machines in cloud data
    centers Concurr. Comput. Pract. Exp., 24 (13) (2012), pp. 1397-1420 CrossRefView
    in ScopusGoogle Scholar [143] S.S. Gill, R. Buyya, I. Chana, M. Singh, A. Abraham
    BULLET: particle swarm optimization based scheduling technique for provisioned
    cloud resources J. Netw. Syst. Manag., 26 (2) (2018), pp. 361-400 View in ScopusGoogle
    Scholar [144] Cheng M., Li J., S. Nazarian DRL-cloud: deep reinforcement learning-based
    resource provisioning and task scheduling for cloud service providers Proceedings
    of the 23rd Asia and South Pacific Design Automation Conference, IEEE Press (2018),
    pp. 129-134 View in ScopusGoogle Scholar [145] S.S. Gill, I. Chana, M. Singh,
    R. Buyya CHOPPER: an intelligent QoS-aware autonomic resource management approach
    for cloud computing Clust. Comput., 21 (2) (2018), pp. 1203-1241 View in ScopusGoogle
    Scholar [146] S.J. Russell, P. Norvig Artificial Intelligence: A Modern Approach
    Pearson Education Limited, Malaysia (2016) Google Scholar [147] D. Talia Cloud
    computing and software agents: towards cloud intelligent services Proceedings
    of the 2011 WOA, 11 (2011), pp. 2-6 View in ScopusGoogle Scholar [148] S. Singh,
    I. Chana Resource provisioning and scheduling in clouds: QoS perspective J. Supercomput.,
    72 (3) (2016), pp. 926-960 CrossRefView in ScopusGoogle Scholar [149] S. Singh,
    I. Chana QRSF: QoS-aware resource scheduling framework in cloud computing J. Supercomput.,
    71 (1) (2015), pp. 241-292 CrossRefView in ScopusGoogle Scholar [150] B. Di Martino,
    M. Rak, M. Ficco, A. Esposito, S.A. Maisto, S. Nacchia Internet of things reference
    architectures, security and interoperability: a survey Internet Things, 1–2 (2018),
    pp. 99-112 View PDFView articleView in ScopusGoogle Scholar [151] A.R. Rao, D.
    Clarke Perspectives on emerging directions in using IoT devices in blockchain
    applications Internet Things (2019), 10.1016/j.iot.2019.100079 Google Scholar
    [152] A. Kaur, V.P. Singh, S.S. Gill The future of cloud computing: opportunities,
    challenges and research trends Proceedings of the 2nd International Conference
    on I-SMAC (IoT in Social, Mobile, Analytics and Cloud), IEEE, Palladam, India
    (2018), pp. 213-219 CrossRefView in ScopusGoogle Scholar [153] L. Bittencourt,
    R. Immich, R. Sakellariou, N. Fonseca, E. Madeira, M. Curado, L. Villas, L. DaSilva,
    Lee C., O. Rana The internet of things, fog and cloud continuum: integration and
    challenges Internet Things, 3–4 (2018), pp. 134-155 View PDFView articleView in
    ScopusGoogle Scholar [154] A.A. Alli, M.M. Alam SecOFF-FCIoT: machine learning
    based secure offloading in fog-cloud of things for smart city applications Internet
    Things, 7 (2019), Article 100070 View PDFView articleView in ScopusGoogle Scholar
    [155] A. Dawoud, S. Shahristani, C. Raun, Deep learning and software-defined networks
    Towards secure IoT architecture Internet Things, 3–4 (2018), pp. 82-89 View PDFView
    articleView in ScopusGoogle Scholar [156] A.K. Fedorov, E.O. Kiktenko, A.I. Lvovsky.
    Quantum Computers Put Blockchain Security at Risk. (2018): 465. Google Scholar
    [157] S. Singh, I. Chana Formal specification language based IaaS cloud workload
    regression analysis Proceedings of IEEE International Conference on Control, Computing,
    Communication and Materials-2013 (ICCCCM-2013), UIT, Allahabad, India (2013),
    pp. 1-6 Google Scholar [158] L.M. Vaquero, L. Rodero-Merino, R. Buyya Dynamically
    scaling applications in the cloud ACM SIGCOMM Comput. Commun. Rev., 41 (1) (2011),
    pp. 45-52 CrossRefView in ScopusGoogle Scholar [159] M.S. Aslanpour, M. Ghobaei-Arani,
    A. Nadjaran Toosi Auto-scaling web applications in clouds: a cost-aware approach
    J. Netw. Comput. Appl., 95 (2017) Google Scholar [160] He S., Guo L., Guo Y.,
    Wu C., M. Ghanem, Han R. Elastic application container: a lightweight approach
    for cloud resource provisioning Proceedings of the 2012 IEEE 26th International
    Conference on Advanced Information Networking and Applications (AINA) (2012),
    pp. 15-22 CrossRefView in ScopusGoogle Scholar [161] Wang C., B. Urgaonkar, N.
    Nasiriani, G. Kesidis Using burstable instances in the public cloud: why, when
    and how? Proc. ACM Meas. Anal. Comput. Syst., 1 (1) (2017), p. 11 View PDFView
    articleGoogle Scholar [162] S. Gec, D. Lavbič, M. Bajec, and V. Stankovski, “Smart
    Contracts for Container-Based Video Conferencing Services: Architecture and Implementation,”
    arXiv:1808.03832, 2018. Google Scholar [163] Yau S., H. An Software engineering
    meets services and cloud computing Computer, 44 (10) (2011), pp. 47-53 View in
    ScopusGoogle Scholar [164] T. Østerlie Cloud Computing: Impact on Software Engineering
    Research and Practice Norwegian University of Science and Technology (NTNU) (2009)
    Google Scholar [165] I. Scirlet, (2018), Cloud Technology in the Era of IoT, Blockchain,
    Machine Learning and AI, White paper, available athttps://blog.usejournal.com/cloud-technology-in-the-era-of-iot-blockchain-machine-learning-and-ai-4f1a19476b32.
    Google Scholar [166] I. Chana, S. Singh Quality of service and service level agreements
    for cloud environments: issues and challenges Cloud Computing, Springer, Cham
    (2014), pp. 51-72 CrossRefGoogle Scholar [167] Hu P., S. Dhelim, Ning H., Qiu
    T. Survey on fog computing: architecture, key technologies, applications and open
    issues J. Netw. Comput. Appl., 98 (2017), pp. 27-42 View PDFView articleView in
    ScopusGoogle Scholar [168] M.A. Khan, K. Salah IoT security: review, blockchain
    solutions, and open challenges Fut. Gen. Comput. Syst., 82 (2018), pp. 395-411
    View PDFView articleView in ScopusGoogle Scholar [169] M.S. Mahdavinejad, M. Rezvan,
    M. Barekatain, P. Adibi, P. Barnaghi, A.P. Sheth Machine learning for internet
    of things data analysis: a survey Digit. Commun. Netw., 4 (3) (2018), pp. 161-175
    View PDFView articleView in ScopusGoogle Scholar [170] M.D. de Assuncao, A. da
    Silva Veith, R. Buyya Distributed data stream processing and edge computing: a
    survey on resource elasticity and future directions J. Netw. Comput. Appl., 103
    (2018), pp. 1-17 Google Scholar [171] T. Lynn, P. Rosati, A. Lejeune, Vincent
    Emeakaroha A preliminary review of enterprise serverless cloud computing (function-as-a-service)
    platforms Proceedings of the 2017 IEEE International Conference on Cloud Computing
    Technology and Science (CloudCom), IEEE (2017), pp. 162-169 CrossRefView in ScopusGoogle
    Scholar [172] S. Pouyanfar, S. Sadiq, Yan Y., Tian H., Tao Y., M.P. Reyes, M.-L.
    Shyu, Chen S.-C., S.S. Iyengar A survey on deep learning: algorithms, techniques,
    and applications ACM Comput. Surv. (CSUR), 51 (5) (2018), p. 92 View in ScopusGoogle
    Scholar [173] E. Casalicchio Container orchestration: a survey Systems Modeling:
    Methodologies and Tools, Springer, Cham (2019), pp. 221-235 CrossRefGoogle Scholar
    [174] L. Gyongyosi, S. Imre A survey on quantum computing technology Comput. Sci.
    Rev., 31 (2019), pp. 51-71 View PDFView articleView in ScopusGoogle Scholar [175]
    F. Tschorsch, B. Scheuermann Bitcoin and beyond: a technical survey on decentralized
    digital currencies IEEE Commun. Surv. Tutor., 18 (3) (2016), pp. 2084-2123 View
    in ScopusGoogle Scholar [176] Xu L.D., He W., Li S. Internet of things in industries:
    a survey IEEE Trans. Ind. Inf., 10 (4) (2014), pp. 2233-2243 View in ScopusGoogle
    Scholar [177] Li S., Xu L.D., Zhao S. 5G internet of things: a survey J. Ind.
    Inf. Integr., 10 (2018), pp. 1-9 View PDFView articleGoogle Scholar [178] Qu C.,
    R.N. Calheiros, R. Buyya Auto-scaling web applications in clouds: a taxonomy and
    survey ACM Comput. Surv. (CSUR), 51 (4) (2018), p. 73 Google Scholar [179] D.
    Valdeolmillos, Y. Mezquita, A. González-Briones, J. Prieto, J.M. Corchado Blockchain
    technology: a review of the current challenges of cryptocurrency International
    Congress on Blockchain and Applications, Springer, Cham (2019), pp. 153-160 View
    in ScopusGoogle Scholar [180] K. Salah, M. Habib Ur Rehman, N. Nizamuddin, A.
    Al-Fuqaha Blockchain for AI: review and open research challenges IEEE Access,
    7 (2019), pp. 10127-10149 CrossRefView in ScopusGoogle Scholar [181] B. Çaliş,
    S. Bulkan A research survey: review of AI solution strategies of job shop scheduling
    problem J. Intell. Manuf., 26 (5) (2015), pp. 961-973 CrossRefView in ScopusGoogle
    Scholar Cited by (313) Analyzing the suitability of IEEE 802.11ah for next generation
    Internet of Things: A comparative study 2024, Ad Hoc Networks Show abstract The
    adoption of artificial intelligence in human resources management practices 2024,
    International Journal of Information Management Data Insights Show abstract Enabling
    edge-driven Dataspace integration through convergence of distributed technologies
    2024, Internet of Things (Netherlands) Show abstract Addressing IoT storage constraints:
    A hybrid architecture for decentralized data storage and centralized management
    2024, Internet of Things (Netherlands) Show abstract Modern computing: Vision
    and challenges 2024, Telematics and Informatics Reports Show abstract Transforming
    digital value chain ecosystems for dual-carbon target: An exploration of the BDS-RAS
    framework 2024, Computers and Industrial Engineering Show abstract View all citing
    articles on Scopus View Abstract © 2019 Elsevier B.V. All rights reserved. Recommended
    articles Blockchain for cloud exchange: A survey Computers & Electrical Engineering,
    Volume 81, 2020, Article 106526 Shaoan Xie, …, Muhammad Imran View PDF ROUTER:
    Fog enabled cloud based intelligent resource management approach for smart home
    IoT devices Journal of Systems and Software, Volume 154, 2019, pp. 125-138 Sukhpal
    Singh Gill, …, Rajkumar Buyya View PDF Blockchain and AI amalgamation for energy
    cloud management: Challenges, solutions, and future directions Journal of Parallel
    and Distributed Computing, Volume 143, 2020, pp. 148-166 Aparna Kumari, …, Neeraj
    Kumar View PDF Show 3 more articles Article Metrics Citations Citation Indexes:
    264 Policy Citations: 3 Captures Readers: 728 Social Media Shares, Likes & Comments:
    145 View details About ScienceDirect Remote access Shopping cart Advertise Contact
    and support Terms and conditions Privacy policy Cookies are used by this site.
    Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024
    Elsevier B.V., its licensors, and contributors. All rights are reserved, including
    those for text and data mining, AI training, and similar technologies. For all
    open access content, the Creative Commons licensing terms apply.'
  inline_citation: '>'
  journal: Internet of things (Amsterdam. Online)
  limitations: '>'
  pdf_link: null
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: 'Transformative effects of IoT, Blockchain and Artificial Intelligence on
    cloud computing: Evolution, vision, trends and open challenges'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/comst.2020.2986444
  analysis: '>'
  authors:
  - Fatima Hussain
  - Rasheed Hussain
  - Syed Ali Hassan
  - Ekram Hossain
  citation_count: 409
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy IEEE.org IEEE Xplore IEEE
    SA IEEE Spectrum More Sites Donate Cart Create Account Personal Sign In Browse
    My Settings Help Access provided by: University of Nebraska - Lincoln Sign Out
    All Books Conferences Courses Journals & Magazines Standards Authors Citations
    ADVANCED SEARCH Journals & Magazines >IEEE Communications Surveys &... >Volume:
    22 Issue: 3 Machine Learning in IoT Security: Current Solutions and Future Challenges
    Publisher: IEEE Cite This PDF Fatima Hussain; Rasheed Hussain; Syed Ali Hassan;
    Ekram Hossain All Authors 414 Cites in Papers 15479 Full Text Views Abstract Document
    Sections I. Introduction II. Motivation of Using ML in IoT Security III. Security
    Challenges and Threat Models in IoT IV. IoT Security and Machine Learning V. Survey
    of the Existing Machine Learning-and Deep Learning-Based Solutions for IoT Security
    Show Full Outline Authors Figures References Citations Keywords Metrics Footnotes
    Abstract: The future Internet of Things (IoT) will have a deep economical, commercial
    and social impact on our lives. The participating nodes in IoT networks are usually
    resource-constrained, which makes them luring targets for cyber attacks. In this
    regard, extensive efforts have been made to address the security and privacy issues
    in IoT networks primarily through traditional cryptographic approaches. However,
    the unique characteristics of IoT nodes render the existing solutions insufficient
    to encompass the entire security spectrum of the IoT networks. Machine Learning
    (ML) and Deep Learning (DL) techniques, which are able to provide embedded intelligence
    in the IoT devices and networks, can be leveraged to cope with different security
    problems. In this paper, we systematically review the security requirements, attack
    vectors, and the current security solutions for the IoT networks. We then shed
    light on the gaps in these security solutions that call for ML and DL approaches.
    Finally, we discuss in detail the existing ML and DL solutions for addressing
    different security problems in IoT networks. We also discuss several future research
    directions for ML- and DL-based IoT security. Published in: IEEE Communications
    Surveys & Tutorials ( Volume: 22, Issue: 3, thirdquarter 2020) Page(s): 1686 -
    1721 Date of Publication: 08 April 2020 ISSN Information: DOI: 10.1109/COMST.2020.2986444
    Publisher: IEEE Funding Agency: Authors Figures References Citations Keywords
    Metrics Footnotes More Like This The Performance Evaluation of Blockchain-Based
    Security and Privacy Systems for the Internet of Things: A Tutorial IEEE Internet
    of Things Journal Published: 2021 Security and Privacy Concerns Associated with
    the Internet of Things(IoT) and the Role of Adapting Blockchain and Machine Learning
    - A Systematic Literature Review 2023 46th MIPRO ICT and Electronics Convention
    (MIPRO) Published: 2023 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE Communications surveys and tutorials
  limitations: '>'
  pdf_link: null
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: 'Machine Learning in IoT Security: Current Solutions and Future Challenges'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

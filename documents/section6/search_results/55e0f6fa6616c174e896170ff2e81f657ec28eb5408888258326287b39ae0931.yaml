- DOI: https://doi.org/10.3390/rs13030531
  analysis: '>'
  authors:
  - Caiwang Zheng
  - Amr Abd-Elrahman
  - Vance M. Whitaker
  citation_count: 44
  full_citation: '>'
  full_text: '>

    This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details                 Deny Allow selection
    Allow all     Journals Topics Information Author Services Initiatives About Sign
    In / Sign Up Submit   Search for Articles: Remote Sensing All Article Types Advanced   Journals
    Remote Sensing Volume 13 Issue 3 10.3390/rs13030531 Submit to this Journal Review
    for this Journal Propose a Special Issue Article Menu Academic Editor Alfredo
    Huete Subscribe SciFeed Recommended Articles Related Info Link More by Authors
    Links Article Views 10709 Citations 44 Table of Contents Abstract Introduction
    Remote Sensing Platforms and Sensors Machine and Deep Learning Analysis Methods
    Fruit Traits Leaf and Canopy Traits Abiotic/Biotic Stress Detection Discussion
    and Outlook Conclusions Author Contributions Funding Institutional Review Board
    Statement Informed Consent Statement Data Availability Statement Conflicts of
    Interest Appendix A Appendix B References Altmetric share Share announcement Help
    format_quote Cite question_answer Discuss in SciProfiles thumb_up Endorse textsms
    Comment first_page settings Order Article Reprints Open AccessEditor’s ChoiceReview
    Remote Sensing and Machine Learning in Crop Phenotyping and Management, with an
    Emphasis on Applications in Strawberry Farming by Caiwang Zheng 1,2,*, Amr Abd-Elrahman
    1,2 and Vance Whitaker 1,3 1 Gulf Coast Research and Education Center, University
    of Florida, Wimauma, FL 33598, USA 2 School of Forest Resources and Conservation,
    University of Florida, Gainesville, FL 32603, USA 3 Department of Horticultural
    Sciences, University of Florida, Gainesville, FL 32611, USA * Author to whom correspondence
    should be addressed. Remote Sens. 2021, 13(3), 531; https://doi.org/10.3390/rs13030531
    Submission received: 10 December 2020 / Revised: 18 January 2021 / Accepted: 27
    January 2021 / Published: 2 February 2021 (This article belongs to the Special
    Issue Digital Agriculture with Remote Sensing) Download keyboard_arrow_down     Browse
    Figures Versions Notes Abstract Measurement of plant characteristics is still
    the primary bottleneck in both plant breeding and crop management. Rapid and accurate
    acquisition of information about large plant populations is critical for monitoring
    plant health and dissecting the underlying genetic traits. In recent years, high-throughput
    phenotyping technology has benefitted immensely from both remote sensing and machine
    learning. Simultaneous use of multiple sensors (e.g., high-resolution RGB, multispectral,
    hyperspectral, chlorophyll fluorescence, and light detection and ranging (LiDAR))
    allows a range of spatial and spectral resolutions depending on the trait in question.
    Meanwhile, computer vision and machine learning methodology have emerged as powerful
    tools for extracting useful biological information from image data. Together,
    these tools allow the evaluation of various morphological, structural, biophysical,
    and biochemical traits. In this review, we focus on the recent development of
    phenomics approaches in strawberry farming, particularly those utilizing remote
    sensing and machine learning, with an eye toward future prospects for strawberries
    in precision agriculture. The research discussed is broadly categorized according
    to strawberry traits related to (1) fruit/flower detection, fruit maturity, fruit
    quality, internal fruit attributes, fruit shape, and yield prediction; (2) leaf
    and canopy attributes; (3) water stress; and (4) pest and disease detection. Finally,
    we present a synthesis of the potential research opportunities and directions
    that could further promote the use of remote sensing and machine learning in strawberry
    farming. Keywords: artificial intelligence; Fragaria; machine learning; phenomics;
    phenotyping; plant breeding; precision agriculture Graphical Abstract 1. Introduction
    According to the Food and Agriculture Organization (FAO)’s Future of Food and
    Agriculture: Alternative Pathways to 2050 report, the global population will reach
    almost 10 billion in 2050 [1], which mandates a continued increase in crop production.
    Meanwhile, agriculture is under increasing resource constraints within the context
    of climate change, with decreasing water and land resources. Precision agriculture
    is an important approach to help meet this goal of a continuous increase in crop
    production. Precision agriculture is an operation and management system supported
    by information technology that makes targeted measurements of plant growth, plant
    health, soil conditions, and other factors [2,3]. Through the integration of the
    Global Navigation Satellite System (GNSS), Geographic Information System (GIS),
    and remote sensing technologies, precision agriculture can help achieve a number
    of specific goals, such as (1) conduction of farmland surveys; (2) site-specific
    precision application of fertilizers, pesticides, and irrigation management schemes;
    and (3) fine-scale monitoring of crop status, soil moisture, diseases, and pests
    [2]. Implementing informed and science-based decision-making protocols can increase
    profits and productivity, environmental sustainability, crop quality, and ultimately
    food security [4]. Recently, applications of precision agriculture have gradually
    spread throughout the world as the adoption of auto-guidance systems, yield monitoring
    technology, and variable rate technology (VRT) in agriculture has increased in
    both developed and developing countries over the past 20 years [5]. Another important
    application of precision agriculture is in plant phenotyping, particularly within
    the context of breeding and genetic research. Phenotyping is broadly defined as
    the acquisition and evaluation of complex plant traits, such as geometric structure,
    abiotic stress tolerance, disease resistance, yield, and other physiological and
    biochemical characteristics. The measurement of economically important traits
    is essential to plant breeding [6]. With the combination of remote sensing, computer
    vision, and robotics, high-throughput plant phenotyping platforms have been developed.
    These systems usually use multiple sensors to measure various traits, such as
    color, texture, plant height, area, volume, degree of wilting, fresh weight, number
    of flowers/fruits, and quality of fruits [7]. This information enables scientists
    to establish a connection between genotype and phenotype, thus allowing them to
    select resilient varieties with high yield potential in the target environment.
    Of course, the same technologies and similar approaches are also valuable for
    crop management, specifically determination of nutrient needs, water, and pesticide
    requirements, as well as the detection of weeds, pathogens, and pests [8]. At
    present, plant phenotyping is the primary bottleneck in both plant breeding and
    crop management. Connecting phenotype to genotype in a set of target environments
    is the basic goal [9]. Next-generation advances in DNA sequencing technology and
    genome assembly methodology have dramatically increased the throughput and lowered
    the cost of genotyping. However, connecting this mountain of genomic information
    to the expression of traits is still a knotty problem [10]. The greatest challenge
    at present is to rapidly acquire large-scale plant phenotyping data with high
    dimensionality, density, and accuracy from single molecules to entire organisms.
    While new phenomics technology has significantly relieved some bottlenecks, many
    questions remain on how to efficiently define and extract complex traits as well
    as improve accuracy and throughput [11]. New advances in remote sensing and machine
    learning have the capacity to solve many of these problems. Strawberry (Fragaria
    × ananassa) is a very popular fruit among consumers by virtue of its appealing
    appearance, flavor, and health benefits [12]. The latest statistics from the FAO
    show that the world’s strawberry yield and cultivated area from 1961 to 2018 grew
    at annual rates of about 1.82% and 2.44%, respectively (Figure 1). A large portion
    of the research conducted during this period focused on the medical benefits of
    strawberries to human health [6]. The high-value market for strawberries has significantly
    promoted the breeding of new varieties worldwide, including in Europe, Asia, and
    North America [13], which is now driving the need for high-throughput phenotyping
    techniques. Accurate and rapid acquisition of heritable traits of interest is
    critical to improving the strawberry breeding selection accuracy. Remote sensing
    and machine learning can greatly relieve the heavy burden of manual work for strawberry
    phenotyping, such as plant height measurement and fruit quality evaluation. How
    to effectively improve accuracy and throughput is a hot research theme. On the
    other hand, strawberry is a highly perishable and labor-intensive crop that can
    benefit greatly from precision agriculture approaches. The fruits have many developmental
    stages and when ripe are very sensitive to environmental and management conditions.
    Plant development and fruit production can continually cycle and change over a
    6-month period, depending on the growing region. Therefore, real-time and intelligent
    monitoring of plant health and development as well as fruit quality assessment
    is essential for crop management and strategy formulation. The combination of
    remote sensing and machine learning is considered to have huge potential and a
    broad application space in these areas. Figure 1. Global trends in strawberry
    yield and harvested area from 1961 to 2018 [14]. In this manuscript, we reviewed
    the use of remote sensing and machine learning in agricultural applications, especially
    focusing on the latest advances in strawberry phenotyping and management. The
    manuscript also presented a synthesis of potential research opportunities and
    directions that could further support strawberry farming. A rigorous two-step
    approach was adopted to search and screen the literature related to remote sensing
    and machine learning applications, with an emphasis on strawberry. Details of
    the adopted approach and the number of articles on each topic are shown in Appendix
    A and Figure A1, respectively. 2. Remote Sensing Platforms and Sensors Remote
    sensing technology has developed rapidly in recent years, with sensors providing
    higher spatial, temporal, and spectral resolution images. Remotely sensed data
    are acquired by mounting sensors on multiple platforms, including satellites,
    unmanned aerial vehicles (drones), and ground-based vehicles. The unparalleled
    advantage of satellite observation lies in its large area of coverage, which allows
    for collecting various types of datasets, routinely on a global scale. A summary
    of agricultural data sources by Huang et al. [15] presented 28 optical and synthetic
    aperture radar (SAR) satellites for plant vegetation studies, with spatial resolutions
    varying from 0.3 m to 1 km. Research on the agriculture-related applications of
    satellite sensors focuses on several aspects, including crop type classification
    [16], soil property determination [17,18,19], crop mapping and spatial statistics
    [20], crop yield forecasting and canopy parameter estimation [21], and irrigation/drought
    evaluation [19,22]. For example, Sentinel-2 remote sensing imagery was used to
    retrieve various biophysical parameters of winter wheat, including the leaf area
    index, leaf chlorophyll content, and canopy chlorophyll content, utilizing vegetation
    indices and radiative transfer modeling [23]. A combination of two indices, enhanced
    vegetation index (EVI) and vegetation optical depth (VOD), derived from optical
    (MODIS) and microwave (Soil Moisture Active Passive Satellite, SMAP) remote sensors,
    respectively, was used to make a prediction of the corn, soybean, and wheat yield
    on the county scale, with an accuracy of over 76% [24]. In contrast to satellites,
    unmanned aerial vehicles (UAVs), or drones, can carry low-cost sensors and can
    operate on a flexible on-demand schedule. Due to higher spatial resolution, low
    cost, and high maneuverability, drones have become one of the most widely used
    remote sensing platforms in agriculture. Yang et al. [7] investigated the current
    progress and future prospects of UAVs as a remote sensing platform by reviewing
    96 articles. Radoglou-Grammatikis et al. [25] further made a comprehensive survey
    of UAV applications in precision agriculture. Currently, non-destructive crop
    monitoring and smart spraying are two of the primary UAV applications. Moreover,
    the integration of UAVs, wireless sensor networks (WSNs), and the Internet of
    Things (IoT) and the maturity of 5th-generation (5G) technology can make several
    applications such as pesticide application, irrigation, crop monitoring, and soil
    property analysis more precise, timely, and efficient [26,27,28,29]. Compared
    with satellites and drones, ground-based platforms enable close-range detection
    of plant characteristics and generally serve as ground truth information sources
    for sensor calibration and data quality control. Ground-based platforms can be
    categorized into sensors mounted on fixed platforms, such as towers or booms (fixed
    scanning systems); handheld field measuring instruments; and sensors mounted on
    mobile ground vehicles [30,31]. Currently, the main sensors used in remote sensing
    agricultural applications consist of passive multispectral, hyperspectral, visible
    RGB (VIS), and near-infrared (NIR) sensors, fluorescence spectroscopy and imaging
    sensors, light detection and ranging (LiDAR), and synthetic aperture radar (SAR)
    [32]. High-resolution RGB images are widely used in vegetation classification;
    identification of plant leaves, canopy, and fruits; and estimation of geometric
    attributes. Multispectral and hyperspectral imaging provides spectral information
    about various parameters related to physiological and biochemical attributes,
    such as the leaf area index (LAI), crop water content, leaf/canopy chlorophyll
    content, and nitrogen content [7,33]. These parameters are very useful for crop
    growth evaluation and yield prediction. Fluorescence remote sensing is efficient
    in retrieving the chlorophyll and nitrogen content, nitrogen-to-carbon ratio,
    and LAI [34]. LiDAR has the advantage of a high point-cloud density, which is
    useful for obtaining horizontal and vertical structural characteristics of plants
    [35]. A synthetic aperture radar can function in very low visibility weather conditions
    (e.g., cloud cover). It has been extensively explored in crop classification,
    crop growth monitoring, and soil moisture monitoring [36,37,38]. Specific uses
    of different sensor types in different agricultural applications are elaborated
    by Yang et al. [7]. Strawberry is different from most agronomic crops like corn,
    soybeans, and wheat in various aspects. It is clonally propagated, and a single
    plant is relatively small in size but has a complex growth habit that includes
    several parts such as the crown, leaves, runners, inflorescences, and fleshy fruits.
    Higher-spatial-resolution imagery is needed to reveal the canopy structure and
    identify the fruits. Handheld sensors as well as sensors mounted on UAVs and ground-based
    platforms have been used to study various strawberry phenotyping traits. Some
    commonly used UAV types for agriculture applications are elaborated by Radoglou-Grammatikis
    et al. [25]. Ground-based platforms (e.g., tractors) were used to collect high-quality
    images and generate a 3D point cloud for strawberry plants [39]. Handheld non-imaging
    spectrometers that cover a wide spectral range (350–2500 nm) and provide continuous
    spectral reflectance could be used to study strawberry physiological characteristics
    [40]. Additionally, many researchers designed various types of phenotyping platforms
    for strawberry disease detection and fruit quality evaluation. Multispectral or
    hyperspectral sensors mounted on various platforms have been used for specific
    purposes, such as powdery mildew disease detection, fruit grading, and fruit 3D
    construction [41]. Some platforms and topics discussed in this review are shown
    in Figure 2. Figure 2. Strawberry traits can be assessed using a variety of sensors
    mounted on multiple platforms. 3. Machine and Deep Learning Analysis Methods Machine
    learning (ML) is one of the most effective ways to process and analyze the vast
    amounts of data obtained by today’s remote sensing techniques. In general, machine
    learning used in the agricultural field can be grouped into four categories: (1)
    crop monitoring, including yield estimation, disease and weed detection, species
    recognition, and crop quality assessment; (2) livestock management, such as animal
    welfare and livestock production; (3) water regulation, for example, plant evapotranspiration
    estimation; and (4) soil management, including the identification and prediction
    of soil temperature and moisture content [42]. Traditional machine learning methods,
    such as support vector machines (SVMs), artificial neural networks (ANNs), and
    random forests (RFs), require the extraction of key features from image or LiDAR
    datasets that sufficiently represent the characteristics of the studied objects
    or phenomena [43,44]. The quality of selected features is critical to the classification
    or prediction performance [45]. However, finding the best feature subset can be
    a time-consuming and subjective process, especially for highly dimensional datasets
    and in problems with a complex domain (e.g., crop yield estimation) [46]. For
    example, Sabanci et al. [47] extracted 12 features of wheat grains from high-resolution
    RGB images, including grain dimension (length, width, perimeter, and area), spectral
    band (red, green, and blue), and texture (contrast, correlation, energy, homogeny,
    and entropy) information. These features were imported into an ANN model to classify
    the wheat into two types, bread and durum, with an accuracy higher than 97%. Deep
    learning (DL) has emerged as perhaps the most important branch of machine learning.
    Deep learning refers to the extension of ANNs to accommodate neural networks with
    a relatively large number of layers that enable hierarchical data representation
    [48,49]. Mainstream deep learning models at present include deep neural networks
    (DNNs) [50,51], recurrent/recursive neural networks (RNNs) for sequence or time
    data processing [52], convolutional neural networks (CNNs) for image analysis
    [53,54], deep generative models [55], and auto-encoder networks [56]. In contrast
    to conventional ML algorithms, DL models can achieve optimal discrimination features
    by determining a set of parameters during the training process; thus a specific
    step for feature extraction is not required [49,57]. The main disadvantages of
    DL methods are the need for massive training datasets, computing capacity, and
    training time [58]. Improving existing DL methods and creating novel algorithms
    have been the goals of numerous studies involving agricultural applications. Kamilaris
    et al. [59] reviewed the agricultural problems solved using DL, common DL models
    and frameworks, data sources and corresponding preprocessing procedures, and the
    overall performance of DL by summarizing 40 studies. They identified land cover
    classification, crop type estimation, crop phenology, fruit and weed detection,
    and fruit grading as the current main applications of DL in the agriculture field.
    DL may also have significant potential in seed identification, soil and leaf nitrogen
    content determination, and irrigation management. In addition, they identified
    the potential for long short-term memory (LSTM) or other RNN models in yield prediction,
    disease management, and water needs assessment based on consecutive observations.
    Overall, deep learning has experienced remarkable developmental progress and already
    has a number of operational applications in agriculture. 4. Fruit Traits 4.1.
    Fruit/Flower Detection Automated counting of fruits and flowers from images is
    a critical step in autonomous robotic harvesting and yield prediction [60]. In
    recent years, numerous studies have been conducted on this topic, mainly aimed
    at developing new image-based object detection and localization algorithms to
    improve recognition accuracy. Traditional image segmentation methods use morphological
    operations to generate binary images and separate fruits from the background according
    to the similarity of color, spatial texture, and geometric shape. For example,
    Feng et al. [61] introduced a strawberry stem detection and fruit classification
    workflow, which used the OHTA color space to segment the fruit from black-and-white
    plastic sheets, extracted the principal inertia axis feature to define the stem
    position, made a judgment of strawberry ripeness based on the hue intensity and
    saturation (HIS) color space, and then selectively harvested strawberry fruits
    according to fruit ripeness and shape. However, this segmentation method is not
    yet robust and stable enough for application in commercial settings that have
    variable lighting conditions, observation angles, object orientations, relative
    positions, and various clustering and occlusion situations. Recently, CNNs have
    evolved to be the most powerful approach for solving target identification and
    classification problems. The superiority of a CNN in image recognition lies in
    its ability to extract increasingly complex visual concepts and features through
    hierarchical structures. The first few layers can be used to learn simple local
    features, and the deeper hidden layers can capture more complicated semantic information,
    such as shape and texture. Koirala et al. [47] reviewed the use of deep learning
    in fruit detection and yield prediction. The author elaborated on the applications
    of current state-of-the-art DL frameworks in target recognition, including the
    faster regional convolutional neural network (Faster RCNN), single-shot multibox
    detector (SSD), and you only look once (YOLO), and in detectors, including the
    Oxford Visual Geometry Group network (VGGNet), the Residual Network (ResNet),
    and the Zeiler and Fergus network (ZFNet). Fruit weight and yield estimation were
    also discussed, which demonstrates the superiority of deep learning in analyzing
    multi-dimensional remote sensing data. With regard to strawberry flower/fruit
    counting, Lin et al. [62] applied RCNN, Fast RCNN, and Faster RCNN models for
    the identification of strawberry flowers from the image, with an accuracy of 63.4%,
    76.7%, and 86.1%, respectively. The Faster RCNN framework demonstrated good performance
    even if strawberry flowers were occluded by foliage, under shadow, and overlapped
    by other flowers. Another DL framework (SSD) was implemented by Lamb et al. [63]
    for strawberry detection. The authors modified the training images and network
    structure to optimize the detection precision and execution speed. This system
    with a sparse CNN can run quickly on mobile low-power hardware with an average
    precision of 84.2%. Yu et al. [64] further adapted a Mask-RCNN model for mature
    strawberry detection in the RGB image and achieved an accuracy of 95.78% even
    in a non-structural environment, particularly for overlapping and hidden fruits
    and those under varying illumination. Zhou et al. [65] proposed a robust deep
    learning architecture named improved Faster-RCNN, which adopted a transfer training
    technology based on Faster RCNN and greatly reduced the number of strawberry images
    required for training the network. The average fruit extraction accuracy was more
    than 86%. 4.2. Fruit Maturity/Ripeness During strawberry ripening, the fruit surface
    color typically goes through green, white, pink, and red stages, concurrent with
    the accelerated biosynthesis of pigments (e.g., carotenoids and anthocyanins)
    over a period of up to 30 days. Fruit ripening is a complicated process, with
    a variety of internal physical and chemical changes, which is mainly controlled
    by the synthesis and action of hormones [66]. Azodanlou et al. [67] found that
    as the fruit matures, there is an increase in volatile organic compounds (VOCs)
    and sugars, as well as a decrease in acidity. Meanwhile, structural changes in
    cell wall polysaccharides, especially the dissolution of pectin, contributes to
    fruit softening. The state of ripeness at harvest directly determines fruit quality
    and shelf life. Unripe fruits have lower nutrient values but are more resistant
    to physical injury. Overripe fruits are more susceptible to the external environment
    and fungal infection [68]. Rahman et al. [69] found that the shelf life of strawberry
    fruits picked at the 1/3rd maturity stage and the full maturity stage were about
    7.8 and 2.4 days, respectively, regardless of the genotype. Therefore, early evaluation
    of fruit ripeness and the determination of optimal harvest time are crucial to
    reducing waste in the supply chain and improving fruit quality [70]. Traditional
    strawberry ripeness assessment is implemented visually and subjectively based
    on the appearance, aroma, color distribution and intensity, as well as texture
    [71,72]. Standard maturity evaluation methods are quantitative, measuring the
    contents of internal quality attributes, such as firmness, soluble solids content
    (SSC), titratable acidity (TA), and total anthocyanins [73]. However, this technique
    is destructive, slow and requires expensive specialized devices and expertise
    [74]. Researchers have spent considerable efforts developing simple, non-invasive,
    and high-throughput ways to estimate the ripeness stage of strawberry fruits.
    Most of the studies have focused on extracting spatial and spectral information
    from representative wavelength bands (usually R, G, and NIR bands) to discriminate
    between strawberries at different growth stages. Raut et al. [75] proposed a direct
    color-mapping method to evaluate the redness of strawberries based on RGB images
    and sort them into pre-mature, mature, and over-mature classes. Jiang et al. [76]
    selected the wavelengths 535, 675, and 980 nm and introduced eight spectral indices
    to automatically identify immature, nearly mature, and mature strawberries using
    the Fisher linear discriminant (FLD) model, with a prediction accuracy over 95%.
    Guo et al. [77] combined spectral reflectance and textural indicators (correlation,
    contrast, entropy, and homogeneity) of 11 optimal wavelengths from hyperspectral
    images and used the SVM algorithm to classify ripe, mid-ripe, and unripe fruits,
    with an accuracy higher than 85%. Yue et al. [78] assessed strawberry maturity
    in the greenhouse using only a smart phone equipped with 535 and 670 nm optical
    filters, which were chosen to capture anthocyanin and chlorophyll contents, respectively.
    Absorptance data for the two wavelengths served as variables in three regression
    classification methods (multivariate linear, multivariate nonlinear, and SoftMax
    regression). The multivariate nonlinear model yielded an identification accuracy
    of over 94%. Gao et al. [79] further used the AlexNet CNN deep learning model
    to categorize the strawberry fruits into ripe and early-ripe stages using hyperspectral
    datasets, achieving 98.6% classification accuracy. Recently, data collection processes,
    feature extraction and classification algorithms have been integrated into a real-time
    strawberry ripeness evaluation and decision-making system developed for harvesting
    robots [80]. 4.3. Fruit Quality and Postharvest Monitoring Postharvest operations,
    including sorting, grading, and spoilage stage monitoring, are of great significance
    for price determination, fulfillment of orders with specific quality standards,
    and sales strategy formulation [81]. In terms of strawberry grading, manual selection
    is widely based on the shape, size, color, maturity, and imperfection of the fruits
    [82]. Compared with apples and citrus fruits, strawberries are more vulnerable
    to damage due to their high moisture content, lack of exocarp protection, and
    susceptibility to fungal infection [12]. From the moment of harvest, strawberry
    fruits begin to lose nutrition and generally spoil after three days without cold
    storage, potentially generating toxins harmful to human health [83]. Therefore,
    it is helpful to have a rapid and non-invasive inspection method for postharvest
    strawberry monitoring. As with ripeness evaluation, emerging computer vision and
    machine learning technologies have enabled the development of automatic, real-time,
    and non-destructive fruit-grading systems. Liming et al. [84] designed an intelligent
    strawberry-grading system by integrating conveyer belts, cameras, and other auxiliary
    devices and employing multi-attribute decision-making theory to grade the strawberry
    fruit into three or four classes based on color, shape (13 feature parameters),
    and size. The final accuracy was above 90%. Mahendra et al. [85] compared seven
    types of features and used the SVM classifier to categorize the fruits into two
    groups: good and damaged. They found that the speeded-up robust features (SURF)
    were most effective in classification, with an accuracy of 90.73%. Sustika et
    al. [81] evaluated the capability of six CNN architectures (the baseline CNN,
    AlexNet, GoogLeNet, VGGNet, Xception, and MobileNet) for the binary classification
    (good or bad) of strawberry fruit and its classification into four grading levels
    (1–4 ranking) using RGB images. The study indicated that VGGNet’s performance
    was the best, producing 96.49% and 89.12% accuracy for the binary and the four-grade-level
    classification, respectively. Péneau et al. [86] represented the consumer perception
    of freshness quantitatively by establishing the relationship between the fruit’s
    physiochemical parameters (appearance, odor, texture, and flavor) and consumer/expert
    ratings of freshness. Dong et al. [87] used long-path Fourier-transform infrared
    spectroscopy (FTIR) technology to capture the spectral characteristics of VOCs
    generated after different lengths of storage and then detect changes in VOC (esters,
    alcohols, ethylene, etc.) abundance. A principal component analysis (PCA) was
    implemented on the spectral data to distinguish fresh, slightly spoiled, and spoiled
    strawberries. As for storage time estimation, Weng et al. [12] collected the spectral
    data for strawberries from 0 to 60 h of storage with an interval of 6 h, using
    hyperspectral imaging technology. SVMs and RFs were then used to classify strawberry
    samples from different storage times with an accuracy of 100%. Partial least-squares
    regression (PLSR) [88] analysis has also been used to estimate the storage time
    with a prediction accuracy approaching 100%. 4.4. Internal Fruit Attributes As
    discussed in the previous section, fruit quality is broadly assessed by many parameters
    associated with the external attributes of the fruit, including appearance, texture,
    and flavor. However, the determination of internal fruit attributes (sugar content,
    juiciness, acidity, color, etc.) is also very important. NIR spectroscopy and
    multiple/hyperspectral imaging technology have been effective for evaluating internal
    fruit quality attributes in a non-contact manner. A difference between spectroscopy
    and imaging is that the former can only obtain single-point information, while
    the latter can provide spatial distribution. The VIS/NIR spectral range is usually
    selected for internal fruit attribute studies because it provides information
    about O–H, C–H, and N–H absorptions [89]. Spectroscopy and hyperspectral image
    data are highly redundant and require preprocessing and analysis. Most research
    on the retrieval of internal fruit attributes adopts the following steps: data
    pretreatment (spectral correction and noise reduction), optimal sensitive wavelength
    selection, feature extraction, and prediction model construction. ElMasry et al.
    [90] estimated the moisture content (MC), SSC, and pH of strawberry fruits using
    hyperspectral images. Optimal wavelengths were selected for the MC, SSC, and pH,
    using β-coefficients from partial least-squares models. Multiple linear regression
    (MLR) models were then applied to retrieve fruit quality attributes using the
    spectral data of optimal wavelengths, with prediction accuracies of 87%, 80%,
    and 92% for the MC, TSS, and pH, respectively. Unlike many researchers who only
    used the spectral information directly as input variables, Weng et al. [91] extracted
    the spectral information about optimal wavelengths, 9 color features obtained
    from color histograms and moments, and 36 textural features simultaneously from
    the hyperspectral images for the detection of soluble solid content (SSC), pH,
    and vitamin C. Spectral and color features achieved the best prediction for SSC,
    with an R2 coefficient of 0.94. In terms of pH, optimal prediction was obtained
    using spectral features only, with an R2 of 0.85. A combination of spectral and
    textural features helped improve the estimation of vitamin C, with an R2 of 0.88.
    At present, the main parameters retrieved for the internal fruit quality of strawberry
    include firmness; vitamin C (VC); phenolic compounds; TA; total water-soluble
    sugar (TWSS) content; concentrations of glucose, fructose, and sucrose; SSC; pH;
    MC; and VC. A detailed summary of the acquisition of these parameters using spectroscopy
    and imaging technology is shown in Table 1. Table 1. Summary of articles addressing
    the estimation of internal fruit quality attributes of strawberry based on remote
    sensing and machine learning. 4.5. Fruit Shape Fruit shape is a critical parameter
    affecting the esthetic appearance and marketability of strawberries. Basic shape
    descriptors, such as length, width, and aspect ratio, can be manually measured
    with, for example, a vernier caliper. However, this method is not only labor intensive
    and time consuming but also limited in capturing the complex and multi-dimensional
    aspects of shape and uniformity. Currently, most shape classification studies
    are based on 2D digital images. Ishikawa et al. [103] extracted four types of
    shape descriptors from RGB images taken by a digital camera: (1) measured values,
    including contour line length, fruit length and width, and fruit width/length
    ratio; (2) ellipse similarity (ES) index, including the optimum ellipse area ratio
    and the boundary length ratio, which indicate the ellipse similarity of fruits;
    (3) elliptic Fourier descriptors (EFDs); and (4) chain code subtraction (CCS).
    Random forest analysis was conducted to categorize strawberry fruit shape into
    nine types: reniform, conical, cordate, ovoid, cylindrical, rhomboid, obloid,
    globose, and wedged. The recall ratio was used for accuracy evaluation since Kappa
    coefficients were not able to classify more than three types. The recall ratio
    ranged from 0.52 to 1, depending on shape type. Oo and Aung [104] proposed a simpler
    but efficient method for strawberry size estimation and shape classification based
    on RGB images. Only three parameters (diameter, length, and apex angle) were imported
    into a three-layer neural network for four classes. The estimation accuracy of
    diameter and length was 94% and 93%, respectively, for strawberries without calyx
    occlusion and 94% and 89% for those with calyx occlusion. The classification was
    between 94% and 97%. Feldmann et al. [105] further extracted 68 strawberry fruit
    shape features of four types (linear and geometric descriptors, outline-based
    descriptors, landmark-based descriptors, and binary-image-pixel-based descriptors)
    from digital images and introduced a method called principal progression of k
    clusters (PPKC), which can automatically discover potential shape classes. Relationships
    between four shape categories and features were built and used for the classification.
    The accuracy varied from 68% to 99%. Zhou et al. [65] used the length-to-width
    ratio of the minimum external rectangle obtained from RGB images to assess the
    plumpness of strawberry fruits. Strawberries were classified into three types
    based on this ratio: plump (0–0.5), approximately plump (0.5–0.8), and fully plump
    (0.8–1). However, this approach applies only for strawberries of globose type.
    Although 2D images can only reflect one dimension or plane characteristics, they
    are sufficient to determine shape properties to some extent. Today, imaging technology
    can obtain three-dimensional information. A 3D-shape-measuring system equipped
    with cameras, a rotation table, and an operation system was designed by He et
    al. [106], which generated 3D point clouds of strawberry fruits using photos from
    various angles and heights using structure from motion (SfM) methods. The errors
    were less than 0.6 mm for 90% and 0.3 mm for 80% or more of the strawberry fruits
    [107]. Construction of 3D strawberry architecture can provide information beyond
    basic descriptors. For example, uniformity is a key shape factor that is directly
    tied to fruit quality and sales volume. Li et al. [108] defined eight uniformity
    variables calculated from the 3D architecture of the strawberry fruit and evaluated
    the importance of each variable for manual uniformity assessment. The results
    showed that circularity of the maximum circumference had the closest predictive
    relationship with the manual uniformity score. A regular shape genetic locus was
    detected and found to be related to three uniformity parameters. 4.6. Strawberry
    Yield Prediction Strawberry harvesting can extend for many months depending on
    the growing system and environment, with dramatic variation in weekly yields.
    Forecasting strawberry yield ahead of time can help growers formulate labor/equipment
    allocation strategies during the harvesting period. Since weather fluctuation
    is a key factor, many studies have been conducted on how weather parameters (e.g.,
    solar radiation, wind, temperature) influence strawberry yield [109]. These significant
    influential factors were combined with other yield-associated traits as input
    for statistical models and machine learning methods to predict strawberry yield.
    For example, Misaghi et al. [110] applied three neural network models (multilayer
    perception (MLP), generalized feedforward neural network (GFNN), and modular neural
    network) for strawberry yield prediction using vegetation indices (normalized
    difference vegetation index (NDVI) and Soil Adjusted Vegetation Index (SAVI))
    and soil characteristic parameters, with up to 94% final accuracy. MacKenzie and
    Chandler [111] built a relational expression between flower counts, temperature
    data, and strawberry total weight, with a coefficient of determination of 0.84.
    Various meteorological parameters (e.g., net radiation, vapor pressure, relative
    humidity) were examined by Pathak et al. [109] for strawberry yield forecast using
    a principal component regression model, achieving 70% yield prediction accuracy.
    Hassan et al. [112] used hyperspectral remote sensing imagery to obtain LAI parameters
    and six vegetation indices (VIs) to explore the relationship between these parameters
    and yield under different growing conditions (organic and conventional). The prediction
    accuracy (R2) was higher than 0.7 except in the treatment using the black plastic
    mulch conventional system (<0.6). The result also showed that six VIs worked better
    than LAI as yield estimators. Maskey et al. [113] utilized predictive principal
    component regression (PPCR), neural network (NN), and random forest (RF) models
    to forecast strawberry yield using 26 parameters related to leaf and canopy properties,
    soil characteristics, and weather conditions. Each of the selected weather parameters
    was highly correlated with strawberry yield, and the neural network (NN) analysis
    provided the best prediction accuracy (95%). Nevertheless, these prediction models
    were generally spatially confined and need to be validated in field experiments.
    Another method for strawberry yield forecasting is to count fruit numbers and
    determine size and maturity using remote sensing images. Deep learning can play
    a crucial role in accomplishing this task. Using the Faster RCNN model, Chen et
    al. [114] predicted strawberry yield by identifying and counting strawberry flowers
    and immature and mature fruits from UAV high-resolution images obtained at two
    heights (2 m and 3 m). The results showed that the mean average precision was
    higher at 2 m (83%) than at 3 m (72%). 5. Leaf and Canopy Traits Leaf and canopy
    traits are generally divided into two types: architectural and biophysical/biochemical
    characteristics. Architectural traits refer to external geometric morphology,
    such as leaf length and width; leaf area; leaf inclination angle; leaf azimuth;
    and canopy height, width, size, and shape. These parameters affect the penetration
    of light through the canopy, light utility efficiency (LUE), and, ultimately,
    photosynthesis efficiency. Biophysical/biochemical parameters describe internal
    physiological characteristics of leaves and are highly associated with crop growth
    dynamics, nutritional status, and photosynthetic capacity. These parameters include
    the green area index (GAI), green fraction (GF), above-ground biomass (AGBM),
    LAI, leaf/canopy water content, leaf/canopy chlorophyll content, leaf/canopy nitrogen
    content, and leaf/canopy temperature, etc. At present, SfM analysis and LiDAR
    are two methods used to generate 3D point-cloud data and obtain 3D structural
    properties of leaves and canopies with desirable accuracy. SfM is a computer vision
    technique that aims to recover the three-dimensional geometry of objects by analyzing
    overlapping images taken from different perspectives [115]. The workflow involves
    several steps: (1) Image feature extraction and matching is performed, where matching
    algorithms are used to detect conjugate features or tie points between overlapped
    images. (2) Camera location and orientation estimation is done using the conjugate
    features in the images. A bundle-block adjustment process is then implemented
    to estimate the position and orientation of each camera at the exposure moment.
    (3) Orthoimage and 3D point-cloud production [116] is then conducted using more
    dense conjugate points detected through image matching. The point cloud can be
    rasterized to produce a digital surface model, which is used to generate ortho-rectified
    image mosaics. Light detection and ranging (LiDAR) is an active remote sensing
    method that utilizes laser to generate 3D point-cloud datasets [35]. Most LiDAR
    systems send laser pulses and compute the distance between the LiDAR source and
    the point where the LiDAR pulse hits an object (e.g., plant leaf) using the laser
    pulse travel time. Other navigation sensors are then used with the measured distance
    to compute the 3D location of the point. Dense 3D points can be created this way
    to accurately depict the surveyed objects. One of the major differences between
    LiDAR- and SfM-based datasets is the significantly higher cost associated with
    LiDAR measurements. LiDAR, however, is capable of producing 3D points along the
    LiDAR laser path, which can reveal some under-canopy information. Both methods
    have been widely used to extract height, size, and shape of various crop plants,
    such as blueberry, maize, and soybean [117,118,119]. Two main approaches have
    been commonly used to retrieve biophysical characteristics and related parameters:
    statistical modeling and radiative transfer modeling (RTM). The former aims to
    establish the relationship between features obtained from remote sensing and field
    measurements using traditional statistical modeling (e.g., regression analysis)
    and machine learning methods. Commonly used image features include spectral (e.g.,
    band values and vegetation indices) and textural information. More than a hundred
    VIs could be calculated using different light spectra combinations extracted from
    UAV hyperspectral imagery, supplying abundant information about vegetation vigor
    and health [120]. It is worth noting that the red edge region, which is defined
    as the wavelength position of the inflection point on the red-NIR reflectance
    slope, has raised wide interest among researchers for LAI and chlorophyll content
    estimation [121]. As an alternative to statistical modeling, RTM considers the
    physical process of interactions between the vegetation canopy and solar radiation.
    Through the simulation of canopy reflectance, canopy parameters can be retrieved
    by RTM as long as other input parameters (radiation intensity, observation angle,
    soil conditions, etc.) are known [122,123]. Kattenborn et al. [124] revealed how
    canopy reflectance is linked with functional traits using the PROSAIL radiative
    transfer model (combination of PROSPECT leaf optical properties model and SAIL
    canopy bidirectional reflectance model). Recently, several scholars have compared
    and combined these two approaches to implement leaf/canopy property retrieval
    [81,124,125]. Studies on phenotyping of strawberry leaves and canopies using remote
    sensing techniques are relatively rare. Luisa et al. [126] investigated the relationship
    between 11 spectral response indices and nitrogen (N) content of young, mature,
    and old leaves. The results showed that only green reflectance (550 nm) was responsive
    to N fertilization for individual leaves. At the canopy level, green reflectance
    (550 nm), red reflectance (680 nm), VI, and NDVI were highly correlated with N
    content, with an R2 of 0.5, 0.6, 0.56, and 0.56, respectively. Sandino et al.
    [127] adopted a basic computer vision method to estimate strawberry leaf coverage
    from RGB images with an accuracy of 90%. Procedures such as smoothing, dilatation,
    contour detection, threshold segmentation, and edge detection operations were
    used. Similarly, a more complex algorithm was introduced by Jianlun et al. [128]
    to segment the greenhouse strawberry leaf edge from the background noise in the
    images, which integrated the scale space wavelet transformation, canny edge detection,
    Otsu threshold segmentation, and morphological analysis approaches. Guan et al.
    [129] extracted planimetric canopy area, canopy surface area, canopy average height,
    standard deviation of canopy height, canopy volume, and canopy smoothness parameters
    from high-spatial-resolution RGB images (~0.5 mm) through SfM, object-based image
    analysis (OBIA), and GIS analysis. Three of the variables were used to predict
    the leaf area (R2 = 0.79) and dry biomass (R2 = 0.84) throughout the strawberry-growing
    season using multiple linear regression analysis. Abd-Elrahman et al. [130] built
    on this study by developing automated canopy delineation and canopy size metric
    extraction models to predict strawberry biomass at greater throughput. Takahashi
    et al. [131] applied Kinect (the depth sensor used in the Microsoft XBOX console)
    to detect plant height and leaf area receiving direct sunlight at different leaf
    layers over time under different environments. These parameters were compared
    to the yield, dry weight, and nitrogen content inside the leaf. Kokin et al. [132]
    used a thermal camera to examine the difference between the strawberry leaf surface
    temperature and ambient air temperature under night frost conditions, which reached
    a maximum of ~8 °C. 6. Abiotic/Biotic Stress Detection 6.1. Water Stress Water
    deficit stress refers to the inhibition effect on plant growth caused by soil
    water deficiency or high evaporation requirement in a low-humidity atmosphere.
    The detection of the plant response to water stress is critical to irrigation
    management. Current irrigation practices are generally based on indirect estimation
    of plant water demand or evaporation calculated from soil moisture content and
    meteorological data [133,134]. Gutiérrez et al. [135] developed an automated irrigation
    system equipped with a distributed wireless network of soil moisture and temperature
    sensors placed in the root zone of the plants. Through irrigation control based
    on soil moisture and temperature threshold values, 90% saving was achieved in
    water consumption compared to traditional irrigation practices. Morillo et al.
    [136] implemented precision drip irrigation for strawberries using crop water
    requirement estimates and optimum irrigation pulse design. The method incorporated
    soil water content and crop evapotranspiration data obtained from a local meteorological
    station. In contrast, monitoring physiological changes in plants due to water
    stress provides a more direct and intuitive way to assess water demand. Under
    water stress, a plant’s temperature increases due to stomatal closure and reduced
    transpiration. Severe water scarcity can lead to wilting and loss of key pigments
    such as chlorophyll, which cause irreversible damage to the photosynthesis process.
    Multiple remote sensors have been used to detect pre-symptom changes. Commonly
    used sensors for this approach include the thermal imager (TIR; 8–14 µm), VIS,
    NIR, shortwave infrared reflectance (400–2500 nm), and sun-induced fluorescence
    (SIF; 685 and 740 nm). Thermal infrared imaging has demonstrated advantages compared
    to other remote sensing spectral domains in crop water stress detection. Through
    the analysis of information in different spectral ranges, numerous indices sensitive
    to water stress were proposed, such as temperature-based indices (stress degree
    day (SDD), crop water stress index (CWSI), and water deficit index (WDI)) and
    leaf-water-content-related indices (water index (WI), leaf water index (LWI),
    moisture stress index (MSI), and normalized difference water index (NDWI)) [137].
    These indicators can quantitatively reflect the water deficit of leaves or canopy
    to some extent. As for strawberries, drought severely limits plant growth and
    reduces yield and fruit quality. Extensive research has been done to investigate
    responses of strawberries to water stress, including changes in yield and morphological,
    physiological, and biochemical properties. Drought-tolerant cultivars have been
    selected according to their adaptability to limited water supply [138]. Numerous
    parameters related to strawberry growth status, such as leaf area, leaf size,
    leaf longevity, dry mass, number of leaves per plant, leaf expansion rates, leaf
    chlorophyll content, chlorophyll stability index, leaf moisture content, stomatal
    conductance, photosynthetic rate, transpiration rate, root development, and plant
    height, exhibit a decreasing tendency under water stress [139,140,141]. Adak et
    al. [142] found that water deficit increased some biochemical features of fruits,
    such as total phenolics, total anthocyanins, antioxidant activity, and sugar content.
    Strawberry fruit weight and yield per unit declined by 59.72% and 63.62%, respectively,
    under water stress as compared to control conditions. It is helpful in crop management
    to provide a real-time, accurate assessment of water demand inside the strawberry
    plant. Peñuelas et al. [143] found that strawberry leaf temperature and the CWSI
    obtained by a handheld infrared thermometer were very useful in evaluating even
    mild water stress. Razavi et al. [144] used chlorophyll fluorescence to identify
    drought stress in strawberries. Delalieux et al. [145] compared plant height,
    NDVI, red edge inflection point (REIP), and pigment-specific simple ratio for
    chlorophyll b (PSSRb) differences between strawberries under two irrigation scenarios
    (20% and 100%) using the COmpact hyperSpectral Imaging (COSI) system. The study
    indicated that the growth inhibition caused by water shortage could be detected
    using these spectral characteristics. Li et al. [146] measured strawberry plant
    temperature, dry surface temperature (Tdry), wet surface temperature (Twet) for
    a single point, and the whole plant area using a TIR sensor. They found the CWSI
    to be significant in detecting strawberry water stress. More indicators were examined
    by Gerhards et al. [147], including surface temperature (TS), CWSI, sun-induced
    fluorescence (F687, F780), and TIR indices, as well as the visible and near infrared
    (VNIR)/short-wave infrared (SWIR), photochemical reflectance index (PRI), normalized
    difference vegetation index (NDVI), and moisture stress index (MSI). These results
    illustrate the great potential of remote sensing in water stress detection. 6.2.
    Pest and Disease Detection Strawberries are susceptible to many insects, mites,
    pests, and microorganisms (bacteria, fungi, and viruses) that regularly cause
    reductions in total and marketable yield [148,149]. Early diagnosis and control
    of strawberry pests and diseases is critical to avoiding yield losses. The occurrence
    of plant diseases is a process of pathological and physiological changes. Internal
    symptoms of diseased crops are eventually reflected as abnormal changes in external
    morphological characters, such as necrosis, rot, and deformity of strawberry roots,
    stems, leaves, flowers, and fruits. Visual identification of pathogen signs and
    plant disease symptoms performed by trained experts is the common practice. Nevertheless,
    this process is post-symptom, and its accuracy depends on the individual’s experience.
    Microscopic methods are not feasible for large-scale commercial detection of pest
    and disease problems [150]. Numerous studies have utilized remote sensing to recognize
    various strawberry diseases, such as powdery mildew, anthracnose crown rot, verticillium
    wilt, and gray mold (Figure 3). Reflectance at various spectral bands contains
    significant information about plant biophysical and biochemical properties, such
    as leaf pigment content (VIS: 400–700 nm), leaf internal structure and water content
    (NIR: 700–1100 nm), and the composition of leaf chemicals and water content (SWIR:
    1100–2500 nm) [139]. Consequently, remote-sensing-based plant disease detection
    methods focus on the optical characteristics of infected and healthy strawberry
    plants in the images acquired by one or more sensors. The majority of the current
    research in this area focuses on differentiating between healthy strawberries
    and those affected by a single disease. Machine learning (particularly deep learning)
    plays an important role in analyzing images for disease detection. For example,
    Park et al. [151] applied a CNN to classify healthy and diseased strawberry using
    RGB images taken by a smart phone, with 89.7% accuracy. Chang et al. [149] extracted
    40 textural indices from high-resolution RGB images and compared the performance
    of three supervised learning classifiers, ANNs, SVMs, and K-nearest neighbors
    (KNNs), in detecting the strawberry powdery mildew disease. The overall classification
    accuracy was 93.8% and 78.80% for the ANN and KNN classifiers, respectively. More
    studies addressing strawberry disease detection are detailed in Table 2. Figure
    3. Several common strawberry diseases. Used with permission from N. Peres [148].
    Table 2. Summary of recent articles investigating strawberry diseases using remote
    sensing and machine learning. 7. Discussion and Outlook The primary aim of this
    manuscript was to present an overview of how remote sensing and machine learning
    have been used in strawberry phenotyping and management. We reviewed studies that
    have applied state-of-art technological breakthroughs in machine and deep learning
    techniques to detect strawberry fruits and flowers from images with high accuracy.
    This work contributed greatly to autonomous robotic harvesting and yield prediction
    applications. Statistical models and machine learning methods were explored to
    evaluate strawberry fruit ripeness, estimate internal fruit attribute parameters,
    and monitor postharvest fruit quality based on RGB, multispectral, and hyperspectral
    image datasets. Various image-based fruit shape descriptors were suggested, such
    as fruit contour line length, uniformity, and ellipse similarity indexes. Structures
    from motion algorithms were used to generate 3D point clouds of strawberry fruits.
    Canopy and leaf images were analyzed to build models relating the biochemical
    content of leaves and spectral indexes as well as predict biophysical parameters,
    such as dry biomass and leaf area. Additionally, studies related to the detection
    of abiotic and biotic stressors were developed. Table A1 lists a categorized summary
    of the studies reviewed in this manuscript that were not presented in tabular
    form. Although remote sensing data acquisition and machine learning data analysis
    are already advancing the prospects of strawberry precision agriculture and phenomics
    applications, there is still an urgent need for further exploration. For example,
    questions related to how to expand the robustness and transferability of the statistical
    and machine learning models connecting fruit quality to image-based spectral and
    geometrical information are still active research topics. Deep learning is also
    very promising for further advances in fruit quality assessment. A deep learning
    method may enable obtaining multiple fruit quality parameters, such as shape,
    size, color, and internal attributes, simultaneously, which can help build a comprehensive
    evaluation system for strawberries and promote the automation of postharvest grading
    processes. Strawberry yield forecasting can be improved by integrating multiple
    variables such as weather condition, soil parameters, fruit/flower counts, canopy
    metrics, and various spectral indices from hyperspectral images as input. Many
    of these parameters, such as fruit and flower count and canopy size, can be extracted
    directly from the images using deep learning networks, which may effectively increase
    prediction accuracy and reduce manual work of feature extraction. Continuous,
    real-time observations of leaf and canopy phenotyping traits are critical to monitoring
    the growth and nutritional status of the plants. With the advancement of remote
    sensing technology, UAVs and updated ground-based platforms are being used extensively
    in agriculture. Sensors that are expensive and hard to access, like LiDAR and
    hyperspectral cameras, are gradually becoming more affordable. Thus, an increasing
    number of studies are being conducted on using remote sensing and machine learning
    to obtain structural (e.g., leaf width/length, leaf inclination angle, and canopy
    height and width), biophysical (e.g., LAI and biomass), and biochemical (e.g.,
    chlorophyll and nitrogen content) traits of agronomic crops, fruit trees, and
    vegetables. Strawberry fruit shape is mostly depicted and evaluated by features
    extracted from 2D and 3D information facilitated by SfM and LiDAR technologies.
    As those technologies become more ubiquitous, more fruit descriptors and novel
    assessment systems can be developed based on the 3D architecture of strawberries.
    Although SfM methods were applied to high-spatial-resolution RGB images [129,130]
    to calculate several strawberry canopy parameters (e.g., canopy area, average
    height, volume, and smoothness), LiDAR could be used to obtain detailed information
    about a strawberry plant’s structural properties. For example, Jiang et al. [166]
    analyzed LiDAR data and proposed various quantification factors for the bush architecture
    of blueberries, including bush morphology (height, width, and volume), crown size,
    and shape descriptors (path curve λ and five shape indices). This type of research
    can be readily transferred to the strawberry domain. Besides, there is a great
    deal of progress to be made in predicting strawberry biophysical parameters and
    the photosynthesis process, and there is much to learn from other crops. Paul
    et al. [167] applied Gaussian process regression and the SVM model to estimate
    the canopy-averaged chlorophyll content of pear trees based on convolutional auto-encoder
    features of hyperspectral data. Li et al. [168] summarized the development of
    remote sensing imaging technologies for retrieval and analysis of information
    about various nutrition parameters, such as nitrogen, phosphorus, potassium, calcium,
    iron, and magnesium. The study showed that a leaf or canopy nutritional distribution
    map can be generated, and the coefficient of determination (R2) of nitrogen even
    reached 0.91. Lu et al. [169] found that the total emitted solar-induced chlorophyll
    fluorescence (SIF) is more effective than top-of-canopy (TOC) SIF in the prediction
    of forest photosynthesis. Dechant et al. [170] further revealed the canopy structure
    is dominant in the relationship between SIF and gross primary production (GPP)
    for rice, wheat, and corn. Studies like these in strawberry are few. Multispectral
    and hyperspectral datasets, radiative transfer modeling, and machine learning
    analysis may be comprehensively applied to study strawberry’s biophysical properties
    and photosynthesis processes. Furthermore, in a general sense, there is still
    room for model and algorithm development and the fusion and application of multiple
    types of remote sensing images. At present, several studies have assessed the
    feasibility of different methods or parameters in the detection of biotic and
    abiotic strawberry stresses, focusing on single stressors at discrete time points.
    These works have tried to distinguish between healthy plants and those with a
    single disease, improving discrimination accuracies where possible, as shown in
    Table 2. For future high-throughput disease detection, there is a need to integrate
    multiple sensors and multiple time points to identify field areas and plants under
    stress automatically and rapidly, diagnose the stressor type and evaluate its
    severity, comprehensively assess plant health through time, and model and predict
    plant responses to management strategies. 8. Conclusions Strawberry is different
    from most agronomic crops like corn, soybean, and wheat in various aspects. It
    is generally grown on raised-bed structures instead of flat ground and is also
    grown in hydroponic systems and under greenhouse and plastic tunnel structures.
    Strawberry is clonally propagated and has a complex growth habit that includes
    several plant parts, such as the crown, leaves, runners, inflorescences, and fleshy
    fruits. The fruits have many developmental stages and when ripe are very sensitive
    to environmental and management conditions. Plant development and fruit production
    can continually cycle and change over a six-month period, depending on the growing
    region. These characteristics make phenotyping considerations complex for strawberry.
    Therefore, the methods developed in major row crops must be creatively adapted
    to strawberry. The development of ground-based devices, UAVs, and emerging field
    robotics is advancing the potential for monitoring strawberry growth throughout
    the entire growing cycle, from planting to final harvest. Remote sensing can provide
    massive amounts of data about crop condition and health via plant and fruit characteristics.
    This deepens our knowledge about the crop itself and allows more advanced management
    practices. Remote sensing may also be useful for postharvest evaluation of strawberry
    fruits. Spectral and textual information obtained from multiple sensors can capture
    both external and internal fruit traits. Further, available artificial intelligence
    options include an expanding array of deep learning techniques and computer vision
    analysis methods. This combination of advances in sensors and data extraction
    and analysis will continue to accelerate the use of precision agriculture in strawberry
    production and phenomics technology in strawberry breeding and genetics. Author
    Contributions Conceptualization, A.A.-E. and C.Z.; methodology, C.Z.; writing—original
    draft preparation, C.Z.; writing—review and editing, A.A.-E., V.W. and C.Z.; visualization,
    C.Z.; supervision, A.A.-E. and V.W.; project administration, A.A.-E. and V.W.;
    and funding acquisition, A.A.-E. and V.W. All authors have read and agreed to
    the published version of the manuscript. Funding This research received no external
    funding. Institutional Review Board Statement Not applicable. Informed Consent
    Statement Not applicable. Data Availability Statement No data used in this work.
    Conflicts of Interest The authors declare that they have no conflict of interest.
    Appendix A A two-step approach was adopted to search and screen the literature
    related to remote sensing and machine learning applications, with an emphasis
    on strawberry. In the first step, refereed articles about remote sensing, machine
    learning, phenotyping, and strawberries were collected from the IEEE Xplore, ScienceDirect,
    Web of Science, and Google Scholar scientific database portals. The following
    query was used, which included the keywords implemented in the search: [“machine
    learning” OR “deep learning” OR “computer vision” OR “remote sensing” OR “phenotyping”
    OR “phenomics”] AND [“strawberry”]. In the second step, we screened a total of
    79 papers resulting from the search, of which 60 dealt with strawberry phenotyping
    and 19 were related to strawberry management during growth and development. The
    number of articles on each topic is shown in Figure A1. Figure A1. Number of articles
    included in this review by topic. Appendix B Table A1. Summary of research articles
    on strawberry phenotyping and management using remote sensing and machine learning.    References
    FAO. The Future of Food and Agriculture—Alternative Pathways to 2050; Food and
    Agriculture Organization of the United Nations: Rome, Italy, 2018. [Google Scholar]
    Bongiovanni, R.; Lowenberg-DeBoer, J. Precision agriculture and sustainability.
    Precis. Agric. 2004, 5, 359–387. [Google Scholar] [CrossRef] Zhang, N.; Wang,
    M.; Wang, N. Precision agriculture—A worldwide overview. Comput. Electron. Agric.
    2002, 36, 113–132. [Google Scholar] [CrossRef] Liaghat, S.; Balasundram, S.K.
    A review: The role of remote sensing in precision agriculture. Am. J. Agric. Biol.
    Sci. 2010, 5, 50–55. [Google Scholar] [CrossRef] [Green Version] Say, S.M.; Keskin,
    M.; Sehri, M.; Sekerli, Y.E. Adoption of precision agriculture technologies in
    developed and developing countries. Online J. Sci. Technol. 2018, 8, 7–15. [Google
    Scholar] Costa, C.; Schurr, U.; Loreto, F.; Menesatti, P.; Carpentier, S. Plant
    phenotyping research trends, a science mapping approach. Front. Plant Sci. 2019,
    9, 1933. [Google Scholar] [CrossRef] [PubMed] [Green Version] Yang, G.; Liu, J.;
    Zhao, C.; Li, Z.; Huang, Y.; Yu, H.; Xu, B.; Yang, X.; Zhu, D.; Zhang, X.; et
    al. Unmanned aerial vehicle remote sensing for field-based crop phenotyping: Current
    status and perspectives. Front. Plant Sci. 2017, 8, 1111. [Google Scholar] [CrossRef]
    Chawade, A.; van Ham, J.; Blomquist, H.; Bagge, O.; Alexandersson, E.; Ortiz,
    R. High-throughput field-phenotyping tools for plant breeding and precision agriculture.
    Agronomy 2019, 9, 258. [Google Scholar] [CrossRef] [Green Version] Pasala, R.;
    Pandey, B.B. Plant phenomics: High-throughput technology for accelerating genomics.
    J. Biosci. 2020, 45, 1–6. [Google Scholar] [CrossRef] Pauli, D.; Chapman, S.C.;
    Bart, R.; Topp, C.N.; Lawrence-Dill, C.J.; Poland, J.; Gore, M.A. The quest for
    understanding phenotypic variation via integrated approaches in the field environment.
    Plant Physiol. 2016, 172, 622–634. [Google Scholar] [CrossRef] [Green Version]
    Yang, W.; Feng, H.; Zhang, X.; Zhang, J.; Doonan, J.H.; Batchelor, W.D.; Xiong,
    L.; Yan, J. Crop phenomics and high-throughput phenotyping: Past decades, current
    challenges, and future perspectives. Mol. Plant 2020, 13, 187–214. [Google Scholar]
    [CrossRef] [Green Version] Weng, S.; Yu, S.; Dong, R.; Pan, F.; Liang, D. Nondestructive
    detection of storage time of strawberries using visible/near-infrared hyperspectral
    imaging. Int. J. Food Prop. 2020, 23, 269–281. [Google Scholar] [CrossRef] [Green
    Version] Mezzetti, B.; Giampieri, F.; Zhang, Y.-T.; Zhong, C.-F. Status of strawberry
    breeding programs and cultivation systems in Europe and the rest of the world.
    J. Berry Res. 2018, 8, 205–221. [Google Scholar] [CrossRef] Food and Agriculture
    Organization of the United Nations. FAOSTAT Database; 2018. Available online:
    http://www.fao.org/faostat/en/?#data/QC (accessed on 20 November 2020). Huang,
    Y.; Chen, Z.-X.; Tao, Y.; Huang, X.-Z.; Gu, X.-F. Agricultural remote sensing
    big data: Management and applications. J. Integr. Agric. 2018, 17, 1915–1931.
    [Google Scholar] [CrossRef] Sicre, C.M.; Fieuzal, R.; Baup, F. Contribution of
    multispectral (optical and radar) satellite images to the classification of agricultural
    surfaces. Int. J. Appl. Earth Obs. Geoinf. 2020, 84, 101972. [Google Scholar]
    [CrossRef] Xu, Y.; Smith, S.E.; Grunwald, S.; Abd-Elrahman, A.; Wani, S.P. Incorporation
    of satellite remote sensing pan-sharpened imagery into digital soil prediction
    and mapping models to characterize soil property variability in small agricultural
    fields. ISPRS J. Photogramm. Remote. Sens. 2017, 123, 1–19. [Google Scholar] [CrossRef]
    [Green Version] Zhu, Q.; Luo, Y.; Xu, Y.-P.; Tian, Y.; Yang, T. Satellite soil
    moisture for agricultural drought monitoring: Assessment of SMAP-derived soil
    water deficit index in Xiang River Basin, China. Remote. Sens. 2019, 11, 362.
    [Google Scholar] [CrossRef] [Green Version] Du, T.L.T.; Bui, D.D.; Nguyen, M.D.;
    Lee, H. Satellite-based, multi-indices for evaluation of agricultural droughts
    in a highly dynamic tropical catchment, Central Vietnam. Water 2018, 10, 659.
    [Google Scholar] [CrossRef] [Green Version] Estel, S.; Mader, S.; Levers, C.;
    Verburg, P.H.; Baumann, M.; Kuemmerle, T. Combining satellite data and agricultural
    statistics to map grassland management intensity in Europe. Environ. Res. Lett.
    2018, 13, 074020. [Google Scholar] [CrossRef] Fieuzal, R.; Baup, F. Forecast of
    wheat yield throughout the agricultural season using optical and radar satellite
    images. Int. J. Appl. Earth Obs. Geoinf. 2017, 59, 147–156. [Google Scholar] [CrossRef]
    Sharma, A.K.; Hubert-Moy, L.; Buvaneshwari, S.; Sekhar, M.; Ruiz, L.; Bandyopadhyay,
    S.; Corgne, S. Irrigation history estimation using multitemporal landsat satellite
    images: Application to an intensive groundwater irrigated agricultural watershed
    in India. Remote. Sens. 2018, 10, 893. [Google Scholar] [CrossRef] [Green Version]
    Xie, Q.; Dash, J.; Huete, A.; Jiang, A.; Yin, G.; Ding, Y.; Peng, D.; Hall, C.C.;
    Brown, L.; Shi, Y. Retrieval of crop biophysical parameters from Sentinel-2 remote
    sensing imagery. Int. J. Appl. Earth Obs. Geoinf. 2019, 80, 187–195. [Google Scholar]
    [CrossRef] Mateo-Sanchis, A.; Piles, M.; Muñoz-Marí, J.; Adsuara, J.E.; Pérez-Suay,
    A.; Camps-Valls, G. Synergistic integration of optical and microwave satellite
    data for crop yield estimation. Remote. Sens. Environ. 2019, 234, 111460. [Google
    Scholar] [CrossRef] [PubMed] Radoglou-Grammatikis, P.; Sarigiannidis, P.; Lagkas,
    T.; Moscholios, I. A compilation of UAV applications for precision agriculture.
    Comput. Netw. 2020, 172, 107148. [Google Scholar] [CrossRef] Giles, D.; Billing,
    R. Deployment and Performance of a UAV for Crop Spraying. Chem. Eng. Trans. 2015,
    44, 307–312. [Google Scholar] Faiçal, B.S.; Freitas, H.; Gomes, P.H.; Mano, L.Y.;
    Pessin, G.; de Carvalho, A.C.; Krishnamachari, B.; Ueyama, J. An adaptive approach
    for UAV-based pesticide spraying in dynamic environments. Comput. Electron. Agric.
    2017, 138, 210–223. [Google Scholar] [CrossRef] Di Gennaro, S.F.; Matese, A.;
    Gioli, B.; Toscano, P.; Zaldei, A.; Palliotti, A.; Genesio, L. Multisensor approach
    to assess vineyard thermal dynamics combining high-resolution unmanned aerial
    vehicle (UAV) remote sensing and wireless sensor network (WSN) proximal sensing.
    Sci. Hortic. 2017, 221, 83–87. [Google Scholar] [CrossRef] Popescu, D.; Stoican,
    F.; Stamatescu, G.; Ichim, L.; Dragana, C. Advanced UAV–WSN System for Intelligent
    Monitoring in Precision Agriculture. Sensors 2020, 20, 817. [Google Scholar] [CrossRef]
    [Green Version] Abd-Elrahman, A.; Pande-Chhetri, R.; Vallad, G. Design and development
    of a multi-purpose low-cost hyperspectral imaging system. Remote. Sens. 2011,
    3, 570–586. [Google Scholar] [CrossRef] [Green Version] Jin, X.; Li, Z.; Atzberger,
    C. Editorial for the Special Issue “Estimation of Crop Phenotyping Traits using
    Unmanned Ground Vehicle and Unmanned Aerial Vehicle Imagery. Remote Sens. 2020,
    12, 940. [Google Scholar] [CrossRef] [Green Version] Weiss, M.; Jacob, F.; Duveiller,
    G. Remote sensing for agricultural applications: A meta-review. Remote. Sens.
    Environ. 2020, 236, 111402. [Google Scholar] [CrossRef] Mishra, P.; Asaari, M.S.M.;
    Herrero-Langreo, A.; Lohumi, S.; Diezma, B.; Scheunders, P. Close range hyperspectral
    imaging of plants: A review. Biosyst. Eng. 2017, 164, 49–67. [Google Scholar]
    [CrossRef] Corp, L.A.; McMurtrey, J.E.; Middleton, E.M.; Mulchi, C.L.; Chappelle,
    E.W.; Daughtry, C.S. Fluorescence sensing systems: In vivo detection of biophysical
    variations in field corn due to nitrogen supply. Remote. Sens. Environ. 2003,
    86, 470–479. [Google Scholar] [CrossRef] Wallace, L.; Lucieer, A.; Watson, C.;
    Turner, D. Development of a UAV-LiDAR system with application to forest inventory.
    Remote Sens. 2012, 4, 1519–1543. [Google Scholar] [CrossRef] [Green Version] Steele-Dunne,
    S.C.; McNairn, H.; Monsivais-Huertero, A.; Judge, J.; Liu, P.-W.; Papathanassiou,
    K. Radar remote sensing of agricultural canopies: A review. IEEE J. Sel. Top.
    Appl. Earth Obs. Remote. Sens. 2017, 10, 2249–2273. [Google Scholar] [CrossRef]
    [Green Version] McNairn, H.; Shang, J. A review of multitemporal synthetic aperture
    radar (SAR) for crop monitoring. In Multitemporal Remote Sensing. Remote Sensing
    and Digital Image Processing; Ban, Y., Ed.; Springer: Cham, Switzerland, 2016;
    Volume 20. [Google Scholar] [CrossRef] Liu, C.-A.; Chen, Z.-X.; Yun, S.; Chen,
    J.-S.; Hasi, T.; Pan, H.-Z. Research advances of SAR remote sensing for agriculture
    applications: A review. J. Integr. Agric. 2019, 18, 506–525. [Google Scholar]
    [CrossRef] [Green Version] Kuester, M.; Thome, K.; Krause, K.; Canham, K.; Whittington,
    E. Comparison of surface reflectance measurements from three ASD FieldSpec FR
    spectroradiometers and one ASD FieldSpec VNIR spectroradiometer. In Proceedings
    of the IGARSS 2001. Scanning the Present and Resolving the Future. Proceedings.
    IEEE 2001 International Geoscience and Remote Sensing Symposium (Cat. No.01CH37217),
    Sydney, NSW, Australia, 9–13 July 2001; pp. 72–74. [Google Scholar] Danner, M.;
    Locherer, M.; Hank, T.; Richter, K. Spectral Sampling with the ASD FieldSpec 4—Theory,
    Measurement, Problems, Interpretation; EnMAP Field Guides Technical Report; GFZ
    Data Services: Potsdam, Germany, 2015. [Google Scholar] [CrossRef] Mahmud, M.S.;
    Zaman, Q.U.; Esau, T.J.; Chang, Y.K.; Price, G.W.; Prithiviraj, B. Real-Time Detection
    of Strawberry Powdery Mildew Disease Using a Mobile Machine Vision System. Agronomy
    2020, 10, 1027. [Google Scholar] [CrossRef] Liakos, K.G.; Busato, P.; Moshou,
    D.; Pearson, S.; Bochtis, D. Machine learning in agriculture: A review. Sensors
    2018, 18, 2674. [Google Scholar] [CrossRef] [Green Version] Mochida, K.; Koda,
    S.; Inoue, K.; Hirayama, T.; Tanaka, S.; Nishii, R.; Melgani, F. Computer vision-based
    phenotyping for improvement of plant productivity: A machine learning perspective.
    GigaScience 2019, 8, giy153. [Google Scholar] [CrossRef] [Green Version] Cai,
    J.; Luo, J.; Wang, S.; Yang, S. Feature selection in machine learning: A new perspective.
    Neurocomputing 2018, 300, 70–79. [Google Scholar] [CrossRef] Miao, J.; Niu, L.
    A survey on feature selection. Procedia Comput. Sci. 2016, 91, 919–926. [Google
    Scholar] [CrossRef] [Green Version] Chlingaryan, A.; Sukkarieh, S.; Whelan, B.
    Machine learning approaches for crop yield prediction and nitrogen status estimation
    in precision agriculture: A review. Comput. Electron. Agric. 2018, 151, 61–69.
    [Google Scholar] [CrossRef] Sabanci, K.; Kayabasi, A.; Toktas, A. Computer vision-based
    method for classification of wheat grains using artificial neural network. J.
    Sci. Food Agric. 2017, 97, 2588–2593. [Google Scholar] [CrossRef] [PubMed] Koirala,
    A.; Walsh, K.B.; Wang, Z.; McCarthy, C. Deep learning–Method overview and review
    of use for fruit detection and yield estimation. Comput. Electron. Agric. 2019,
    162, 219–234. [Google Scholar] [CrossRef] Jakhar, D.; Kaur, I. Artificial intelligence,
    machine learning and deep learning: Definitions and differences. Clin. Exp. Dermatol.
    2020, 45, 131–132. [Google Scholar] [CrossRef] Miikkulainen, R.; Liang, J.; Meyerson,
    E.; Rawal, A.; Fink, D.; Francon, O.; Raju, B.; Shahrzad, H.; Navruzyan, A.; Duffy,
    N. Evolving deep neural networks. arXiv 2016, arXiv:1703.00548. [Google Scholar]
    Seifert, C.; Aamir, A.; Balagopalan, A.; Jain, D.; Sharma, A.; Grottel, S.; Gumhold,
    S. Visualizations of deep neural networks in computer vision: A survey. In Transparent
    Data Mining for Big and Small Data; Springer: Berlin/Heidelberg, Germany, 2017;
    pp. 123–144. [Google Scholar] Zhang, J.; Man, K.F. Time series prediction using
    RNN in multi-dimension embedding phase space. In Proceedings of the SMC’98 Conference
    Proceedings. 1998 IEEE International Conference on Systems, Man, and Cybernetics
    (Cat. No. 98CH36218), San Diego, CA, USA, 14 October 1998; pp. 1868–1873. [Google
    Scholar] Yu, S.; Jia, S.; Xu, C. Convolutional neural networks for hyperspectral
    image classification. Neurocomputing 2017, 219, 88–98. [Google Scholar] [CrossRef]
    Liu, T.; Abd-Elrahman, A. An object-based image analysis method for enhancing
    classification of land covers using fully convolutional networks and multi-view
    images of small unmanned aerial system. Remote. Sens. 2018, 10, 457. [Google Scholar]
    [CrossRef] [Green Version] Salakhutdinov, R. Learning deep generative models.
    Ann. Rev. Stat. Appl. 2015, 2, 361–385. [Google Scholar] [CrossRef] [Green Version]
    Pu, Y.; Gan, Z.; Henao, R.; Yuan, X.; Li, C.; Stevens, A.; Carin, L. Variational
    autoencoder for deep learning of images, labels and captions. arXiv 2016, arXiv:1609.08976.
    [Google Scholar] Bauer, A.; Bostrom, A.G.; Ball, J.; Applegate, C.; Cheng, T.;
    Laycock, S.; Rojas, S.M.; Kirwan, J.; Zhou, J. Combining computer vision and deep
    learning to enable ultra-scale aerial phenotyping and precision agriculture: A
    case study of lettuce production. Hortic. Res. 2019, 6, 1–12. [Google Scholar]
    [CrossRef] [Green Version] Zhang, L.; Zhang, L.; Du, B. Deep learning for remote
    sensing data: A technical tutorial on the state of the art. IEEE Geosci. Remote.
    Sens. Mag. 2016, 4, 22–40. [Google Scholar] [CrossRef] Kamilaris, A.; Prenafeta-Boldú,
    F.X. Deep learning in agriculture: A survey. Comput. Electron. Agric. 2018, 147,
    70–90. [Google Scholar] [CrossRef] [Green Version] Puttemans, S.; Vanbrabant,
    Y.; Tits, L.; Goedemé, T. Automated visual fruit detection for harvest estimation
    and robotic harvesting. In Proceedings of the 2016 sixth international conference
    on image processing theory, tools and applications (IPTA), Oulu, Finland, 12–15
    December 2016; pp. 1–6. [Google Scholar] [CrossRef] Feng, G.; Qixin, C.; Masateru,
    N. Fruit detachment and classification method for strawberry harvesting robot.
    Int. J. Adv. Robot. Syst. 2008, 5, 4. [Google Scholar] [CrossRef] Lin, P.; Chen,
    Y. Detection of Strawberry Flowers in Outdoor Field by Deep Neural Network. In
    Proceedings of the 2018 IEEE 3rd International Conference on Image, Vision and
    Computing (ICIVC), Chongqing, China, 27–29 June 2018; pp. 482–486. [Google Scholar]
    [CrossRef] Lamb, N.; Chuah, M.C. A strawberry detection system using convolutional
    neural networks. In Proceedings of the 2018 IEEE International Conference on Big
    Data (Big Data), Seattle, WA, USA, 10–13 December 2018; pp. 2515–2520. [Google
    Scholar] [CrossRef] Yu, Y.; Zhang, K.; Yang, L.; Zhang, D. Fruit detection for
    strawberry harvesting robot in non-structural environment based on Mask-RCNN.
    Comput. Electron. Agric. 2019, 163, 104846. [Google Scholar] [CrossRef] Zhou,
    C.; Hu, J.; Xu, Z.; Yue, J.; Ye, H.; Yang, G. A novel greenhouse-based system
    for the detection and plumpness assessment of strawberry using an improved deep
    learning technique. Front. Plant Sci. 2020, 11, 559. [Google Scholar] [CrossRef]
    Kafkas, E.; Koşar, M.; Paydaş, S.; Kafkas, S.; Başer, K. Quality characteristics
    of strawberry genotypes at different maturation stages. Food Chem. 2007, 100,
    1229–1236. [Google Scholar] [CrossRef] Azodanlou, R.; Darbellay, C.; Luisier,
    J.-L.; Villettaz, J.-C.; Amadò, R. Changes in flavour and texture during the ripening
    of strawberries. Eur. Food Res. Technol. 2004, 218, 167–172. [Google Scholar]
    Kader, A.A. Quality and its maintenance in relation to the postharvest physiology
    of strawberry. In The Strawberry into the 21st Century; Timber Press: Portland,
    OR, USA, 1991; pp. 145–152. [Google Scholar] Rahman, M.M.; Moniruzzaman, M.; Ahmad,
    M.R.; Sarker, B.; Alam, M.K. Maturity stages affect the postharvest quality and
    shelf-life of fruits of strawberry genotypes growing in subtropical regions. J.
    Saudi Soc. Agric. Sci. 2016, 15, 28–37. [Google Scholar] [CrossRef] [Green Version]
    Li, B.; Lecourt, J.; Bishop, G. Advances in non-destructive early assessment of
    fruit ripeness towards defining optimal time of harvest and yield prediction—A
    review. Plants 2018, 7, 3. [Google Scholar] Rico, D.; Martin-Diana, A.B.; Barat,
    J.; Barry-Ryan, C. Extending and measuring the quality of fresh-cut fruit and
    vegetables: A review. Trends Food Sci. Technol. 2007, 18, 373–386. [Google Scholar]
    [CrossRef] [Green Version] Kader, A.A. Quality parameters of fresh-cut fruit and
    vegetable products. In Fresh-Cut Fruits and Vegetables; CRC Press: Boca Raton,
    FL, USA, 2002; pp. 20–29. [Google Scholar] Liu, C.; Liu, W.; Lu, X.; Ma, F.; Chen,
    W.; Yang, J.; Zheng, L. Application of multispectral imaging to determine quality
    attributes and ripeness stage in strawberry fruit. PLoS ONE 2014, 9, e87818. [Google
    Scholar] [CrossRef] [PubMed] Bai, J.; Plotto, A.; Baldwin, E.; Whitaker, V.; Rouseff,
    R. Electronic nose for detecting strawberry fruit maturity. In Proceedings of
    the Florida State Horticultural Society, Crystal River, FL, USA, 6–8 June 2010;
    Volume 123, pp. 259–263. [Google Scholar] Raut, K.D.; Bora, V. Assessment of Fruit
    Maturity using Direct Color Mapping. Int. Res. J. Eng. Technol. 2016, 3, 1540–1543.
    [Google Scholar] Jiang, H.; Zhang, C.; Liu, F.; Zhu, H.; He, Y. Identification
    of strawberry ripeness based on multispectral indexes extracted from hyperspectral
    images. Guang Pu Xue Yu Guang Pu Fen Xi = Guang Pu 2016, 36, 1423–1427. [Google
    Scholar] [PubMed] Guo, C.; Liu, F.; Kong, W.; He, Y.; Lou, B. Hyperspectral imaging
    analysis for ripeness evaluation of strawberry with support vector machine. J.
    Food Eng. 2016, 179, 11–18. [Google Scholar] Yue, X.-Q.; Shang, Z.-Y.; Yang, J.-Y.;
    Huang, L.; Wang, Y.-Q. A smart data-driven rapid method to recognize the strawberry
    maturity. Inf. Proc. Agric. 2019. [Google Scholar] [CrossRef] Gao, Z.; Shao, Y.;
    Xuan, G.; Wang, Y.; Liu, Y.; Han, X. Real-time hyperspectral imaging for the in-field
    estimation of strawberry ripeness with deep learning. Artif. Intell. Agric. 2020,
    4, 31–38. [Google Scholar] [CrossRef] Xiong, Y.; Peng, C.; Grimstad, L.; From,
    P.J.; Isler, V. Development and field evaluation of a strawberry harvesting robot
    with a cable-driven gripper. Comput. Electron. Agric. 2019, 157, 392–402. [Google
    Scholar] [CrossRef] Sustika, R.; Subekti, A.; Pardede, H.F.; Suryawati, E.; Mahendra,
    O.; Yuwana, S. Evaluation of deep convolutional neural network architectures for
    strawberry quality inspection. Int. J. Eng. Technol. 2018, 7, 75–80. [Google Scholar]
    Usha, S.; Karthik, M.; Jenifer, R.; Scholar, P. Automated Sorting and Grading
    of Vegetables Using Image Processing. Int. J. Eng. Res. Gen. Sci. 2017, 5, 53–61.
    [Google Scholar] Shen, J.; Qi, H.-F.; Li, C.; Zeng, S.-M.; Deng, C. Experimental
    on storage and preservation of strawberry. Food Sci. Tech 2011, 36, 48–51. [Google
    Scholar] Liming, X.; Yanchao, Z. Automated strawberry grading system based on
    image processing. Comput. Electron. Agric. 2010, 71, S32–S39. [Google Scholar]
    [CrossRef] Mahendra, O.; Pardede, H.F.; Sustika, R.; Kusumo, R.B.S. Comparison
    of Features for Strawberry Grading Classification with Novel Dataset. In Proceedings
    of the 2018 International Conference on Computer, Control, Informatics and Its
    Applications (IC3INA), Tangerang, Indonesia, 1–2 November 2018; pp. 7–12. [Google
    Scholar] [CrossRef] Péneau, S.; Brockhoff, P.B.; Escher, F.; Nuessli, J. A comprehensive
    approach to evaluate the freshness of strawberries and carrots. Postharvest Biol.
    Technol. 2007, 45, 20–29. [Google Scholar] [CrossRef] Dong, D.; Zhao, C.; Zheng,
    W.; Wang, W.; Zhao, X.; Jiao, L. Analyzing strawberry spoilage via its volatile
    compounds using longpath fourier transform infrared spectroscopy. Sci. Rep. 2013,
    3, 2585. [Google Scholar] [CrossRef] [PubMed] [Green Version] Geladi, P.; Kowalski,
    B.R. Partial least-squares regression: A tutorial. Anal. Chim. Acta 1986, 185,
    1–17. [Google Scholar] [CrossRef] Wang, H.; Peng, J.; Xie, C.; Bao, Y.; He, Y.
    Fruit quality evaluation using spectroscopy technology: A review. Sensors 2015,
    15, 11889–11927. [Google Scholar] [CrossRef] [PubMed] [Green Version] ElMasry,
    G.; Wang, N.; ElSayed, A.; Ngadi, M. Hyperspectral imaging for nondestructive
    determination of some quality attributes for strawberry. J. Food Eng. 2007, 81,
    98–107. [Google Scholar] [CrossRef] Weng, S.; Yu, S.; Guo, B.; Tang, P.; Liang,
    D. Non-Destructive Detection of Strawberry Quality Using Multi-Features of Hyperspectral
    Imaging and Multivariate Methods. Sensors 2020, 20, 3074. [Google Scholar] [CrossRef]
    Liu, Q.; Wei, K.; Xiao, H.; Tu, S.; Sun, K.; Sun, Y.; Pan, L.; Tu, K. Near-infrared
    hyperspectral imaging rapidly detects the decay of postharvest strawberry based
    on water-soluble sugar analysis. Food Anal. Methods 2019, 12, 936–946. [Google
    Scholar] [CrossRef] Liu, S.; Xu, H.; Wen, J.; Zhong, W.; Zhou, J. Prediction and
    analysis of strawberry sugar content based on partial least squares prediction
    model. J. Anim. Plant Sci. 2019, 29, 1390–1395. [Google Scholar] Amodio, M.L.;
    Ceglie, F.; Chaudhry, M.M.A.; Piazzolla, F.; Colelli, G. Potential of NIR spectroscopy
    for predicting internal quality and discriminating among strawberry fruits from
    different production systems. Postharvest Biol. Technol. 2017, 125, 112–121. [Google
    Scholar] [CrossRef] LI, J.-B.; GUO, Z.-M.; HUANG, W.-Q.; ZHANG, B.-H.; ZHAO, C.-J.
    Near-infrared spectra combining with CARS and SPA algorithms to screen the variables
    and samples for quantitatively determining the soluble solids content in strawberry.
    Spectrosc. Spectr. Anal. 2015, 35, 372–378. [Google Scholar] Ding, X.; Zhang,
    C.; Liu, F.; Song, X.; Kong, W.; He, Y. Determination of soluble solid content
    in strawberry using hyperspectral imaging combined with feature extraction methods.
    Guang Pu Xue Yu Guang Pu Fen Xi = Guang Pu 2015, 35, 1020–1024. [Google Scholar]
    [PubMed] Sánchez, M.-T.; De la Haba, M.J.; Benítez-López, M.; Fernández-Novales,
    J.; Garrido-Varo, A.; Pérez-Marín, D. Non-destructive characterization and quality
    control of intact strawberries based on NIR spectral data. J. Food Eng. 2012,
    110, 102–108. [Google Scholar] [CrossRef] Nishizawa, T.; Mori, Y.; Fukushima,
    S.; Natsuga, M.; Maruyama, Y. Non-destructive analysis of soluble sugar components
    in strawberry fruits using near-infrared spectroscopy. Nippon Shokuhin Kagaku
    Kogaku Kaishi = J. Jpn. Soc. Food Sci. Technol. 2009, 56, 229–235. [Google Scholar]
    [CrossRef] [Green Version] Wulf, J.; Rühmann, S.; Rego, I.; Puhl, I.; Treutter,
    D.; Zude, M. Nondestructive application of laser-induced fluorescence spectroscopy
    for quantitative analyses of phenolic compounds in strawberry fruits (Fragaria
    × ananassa). J. Agric. Food Chem. 2008, 56, 2875–2882. [Google Scholar] [CrossRef]
    Tallada, J.G.; Nagata, M.; Kobayashi, T. Non-destructive estimation of firmness
    of strawberries (Fragaria × ananassa Duch.) using NIR hyperspectral imaging. Environ.
    Control. Biol. 2006, 44, 245–255. [Google Scholar] [CrossRef] [Green Version]
    Nagata, M.; Tallada, J.G.; Kobayashi, T.; Toyoda, H. NIR hyperspectral imaging
    for measurement of internal quality in strawberries. In Proceedings of the 2005
    ASAE Annual Meeting, Tampa, FL, USA, 17–20 July 2005. ASAE Paper No. 053131. [Google
    Scholar] Nagata, M.; Tallada, J.G.; Kobayashi, T.; Cui, Y.; Gejima, Y. Predicting
    maturity quality parameters of strawberries using hyperspectral imaging. In Proceedings
    of the ASAE/CSAE Annual International Meeting, Ottawa, ON, Canada, 1–4 August
    2004. Paper No. 043033. [Google Scholar] Ishikawa, T.; Hayashi, A.; Nagamatsu,
    S.; Kyutoku, Y.; Dan, I.; Wada, T.; Oku, K.; Saeki, Y.; Uto, T.; Tanabata, T.;
    et al. Classification of strawberry fruit shape by machine learning. Int. Arch.
    Photogramm. Remote. Sens. Spat. Inf. Sci. 2018, 42. [Google Scholar] [CrossRef]
    [Green Version] Oo, L.M.; Aung, N.Z. A simple and efficient method for automatic
    strawberry shape and size estimation and classification. Biosyst. Eng. 2018, 170,
    96–107. [Google Scholar] [CrossRef] Feldmann, M.J.; Hardigan, M.A.; Famula, R.A.;
    López, C.M.; Tabb, A.; Cole, G.S.; Knapp, S.J. Multi-dimensional machine learning
    approaches for fruit shape phenotyping in strawberry. GigaScience 2020, 9, giaa030.
    [Google Scholar] [CrossRef] He, J.Q.; Harrison, R.J.; Li, B. A novel 3D imaging
    system for strawberry phenotyping. Plant Methods 2017, 13, 1–8. [Google Scholar]
    [CrossRef] Kochi, N.; Tanabata, T.; Hayashi, A.; Isobe, S. A 3D shape-measuring
    system for assessing strawberry fruits. Int. J. Autom. Technol. 2018, 12, 395–404.
    [Google Scholar] [CrossRef] Li, B.; Cockerton, H.M.; Johnson, A.W.; Karlström,
    A.; Stavridou, E.; Deakin, G.; Harrison, R.J. Defining Strawberry Uniformity using
    3D Imaging and Genetic Mapping. bioRxiv 2020. [Google Scholar] [CrossRef] [PubMed]
    Pathak, T.B.; Dara, S.K.; Biscaro, A. Evaluating correlations and development
    of meteorology based yield forecasting model for strawberry. Adv. Meteorol. 2016,
    2016, 1–7. [Google Scholar] [CrossRef] [Green Version] Misaghi, F.; Dayyanidardashti,
    S.; Mohammadi, K.; Ehsani, M. Application of Artificial Neural Network and Geostatistical
    Methods in Analyzing Strawberry Yield Data; American Society of Agricultural and
    Biological Engineers: Minneapolis, MN, USA, 2004; p. 1. [Google Scholar] MacKenzie,
    S.J.; Chandler, C.K. A method to predict weekly strawberry fruit yields from extended
    season production systems. Agron. J. 2009, 101, 278–287. [Google Scholar] [CrossRef]
    Hassan, H.A.; Taha, S.S.; Aboelghar, M.A.; Morsy, N.A. Comparative the impact
    of organic and conventional strawberry cultivation on growth and productivity
    using remote sensing techniques under Egypt climate conditions. Asian J. Agric.
    Biol. 2018, 6, 228–244. [Google Scholar] Maskey, M.L.; Pathak, T.B.; Dara, S.K.
    Weather Based Strawberry Yield Forecasts at Field Scale Using Statistical and
    Machine Learning Models. Atmosphere 2019, 10, 378. [Google Scholar] [CrossRef]
    [Green Version] Chen, Y.; Lee, W.S.; Gan, H.; Peres, N.; Fraisse, C.; Zhang, Y.;
    He, Y. Strawberry yield prediction based on a deep neural network using high-resolution
    aerial orthoimages. Remote. Sens. 2019, 11, 1584. [Google Scholar] [CrossRef]
    [Green Version] Fonstad, M.A.; Dietrich, J.T.; Courville, B.C.; Jensen, J.L.;
    Carbonneau, P.E. Topographic structure from motion: A new development in photogrammetric
    measurement. Earth Surf. Proc. Landf. 2013, 38, 421–430. [Google Scholar] [CrossRef]
    [Green Version] Ozyesil, O.; Voroninski, V.; Basri, R.; Singer, A. A survey of
    structure from motion. arXiv 2017, arXiv:1701.08493. [Google Scholar] Patrick,
    A.; Li, C. High throughput phenotyping of blueberry bush morphological traits
    using unmanned aerial systems. Remote. Sens. 2017, 9, 1250. [Google Scholar] [CrossRef]
    [Green Version] Makanza, R.; Zaman-Allah, M.; Cairns, J.E.; Magorokosho, C.; Tarekegne,
    A.; Olsen, M.; Prasanna, B.M. High-throughput phenotyping of canopy cover and
    senescence in maize field trials using aerial digital canopy imaging. Remote.
    Sens. 2018, 10, 330. [Google Scholar] [CrossRef] [PubMed] [Green Version] Han,
    L.; Yang, G.; Dai, H.; Yang, H.; Xu, B.; Feng, H.; Li, Z.; Yang, X. Fuzzy Clustering
    of Maize Plant-Height Patterns Using Time Series of UAV Remote-Sensing Images
    and Variety Traits. Front. Plant Sci. 2019, 10, 926. [Google Scholar] [CrossRef]
    [PubMed] [Green Version] Xue, J.; Su, B. Significant remote sensing vegetation
    indices: A review of developments and applications. J. Sens. 2017, 2017, 1–17.
    [Google Scholar] [CrossRef] [Green Version] Hunt, E.R., Jr.; Doraiswamy, P.C.;
    McMurtrey, J.E.; Daughtry, C.S.; Perry, E.M.; Akhmedov, B. A visible band index
    for remote sensing leaf chlorophyll content at the canopy scale. Int. J. Appl.
    Earth Obs. Geoinf. 2013, 21, 103–112. [Google Scholar] [CrossRef] [Green Version]
    Clevers, J.G.; Kooistra, L. Using hyperspectral remote sensing data for retrieving
    canopy chlorophyll and nitrogen content. IEEE J. Sel. Top. Appl. Earth Obs. Remote.
    Sens. 2011, 5, 574–583. [Google Scholar] [CrossRef] Kattenborn, T.; Schmidtlein,
    S. Radiative transfer modelling reveals why canopy reflectance follows function.
    Sci. Rep. 2019, 9, 1–10. [Google Scholar] [CrossRef] [Green Version] Yuan, H.;
    Yang, G.; Li, C.; Wang, Y.; Liu, J.; Yu, H.; Feng, H.; Xu, B.; Zhao, X.; Yang,
    X. Retrieving soybean leaf area index from unmanned aerial vehicle hyperspectral
    remote sensing: Analysis of RF, ANN, and SVM regression models. Remote. Sens.
    2017, 9, 309. [Google Scholar] [CrossRef] [Green Version] Wolanin, A.; Camps-Valls,
    G.; Gómez-Chova, L.; Mateo-García, G.; van der Tol, C.; Zhang, Y.; Guanter, L.
    Estimating crop primary productivity with Sentinel-2 and Landsat 8 using machine
    learning methods trained with radiative transfer simulations. Remote. Sens. Environ.
    2019, 225, 441–457. [Google Scholar] [CrossRef] Luisa España-Boquera, M.; Cárdenas-Navarro,
    R.; López-Pérez, L.; Castellanos-Morales, V.; Lobit, P. Estimating the nitrogen
    concentration of strawberry plants from its spectral response. Commun. Soil Sci.
    Plant Anal. 2006, 37, 2447–2459. [Google Scholar] [CrossRef] Sandino, J.D.; Ramos-Sandoval,
    O.L.; Amaya-Hurtado, D. Method for estimating leaf coverage in strawberry plants
    using digital image processing. Rev. Bras. Eng. Agrícola Ambient. 2016, 20, 716–721.
    [Google Scholar] [CrossRef] [Green Version] Jianlun, W.; Yu, H.; Shuangshuang,
    Z.; Hongxu, Z.; Can, H.; Xiaoying, C.; Yun, X.; Jianshu, C.; Shuting, W. A new
    multi-scale analytic algorithm for edge extraction of strawberry leaf images in
    natural light. Int. J. Agric. Biol. Eng. 2016, 9, 99–108. [Google Scholar] Guan,
    Z.; Abd-Elrahman, A.; Fan, Z.; Whitaker, V.M.; Wilkinson, B. Modeling strawberry
    biomass and leaf area using object-based analysis of high-resolution images. J.
    Photogramm. Remote. Sens. 2020, 163, 171–186. [Google Scholar] [CrossRef] Abd-Elrahman,
    A.; Guan, Z.; Dalid, C.; Whitaker, V.; Britt, K.; Wilkinson, B.; Gonzalez, A.
    Automated Canopy Delineation and Size Metrics Extraction for Strawberry Dry Weight
    Modeling Using Raster Analysis of High-Resolution Imagery. Remote. Sens. 2020,
    12, 3632. [Google Scholar] [CrossRef] Takahashi, M.; Takayama, S.; Umeda, H.;
    Yoshida, C.; Koike, O.; Iwasaki, Y.; Sugeno, W. Quantification of Strawberry Plant
    Growth and Amount of Light Received Using a Depth Sensor. Environ. Control. Biol.
    2020, 58, 31–36. [Google Scholar] [CrossRef] [Green Version] Kokin, E.; Palge,
    V.; Pennar, M.; Jürjenson, K. Strawberry leaf surface temperature dynamics measured
    by thermal camera in night frost conditions. Agron. Res. 2018, 16. [Google Scholar]
    [CrossRef] Touati, F.; Al-Hitmi, M.; Benhmed, K.; Tabish, R. A fuzzy logic based
    irrigation system enhanced with wireless data logging applied to the state of
    Qatar. Comput. Electron. Agric. 2013, 98, 233–241. [Google Scholar] [CrossRef]
    Avşar, E.; Buluş, K.; Saridaş, M.A.; Kapur, B. Development of a cloud-based automatic
    irrigation system: A case study on strawberry cultivation. In Proceedings of the
    2018 7th International Conference on Modern Circuits and Systems Technologies
    (MOCAST), Thessaloniki, Greece, 7–9 May 2018; pp. 1–4. [Google Scholar] Gutiérrez,
    J.; Villa-Medina, J.F.; Nieto-Garibay, A.; Porta-Gándara, M.Á. Automated irrigation
    system using a wireless sensor network and GPRS module. IEEE Trans. Instrum. Meas.
    2013, 63, 166–176. [Google Scholar] [CrossRef] Morillo, J.G.; Martín, M.; Camacho,
    E.; Díaz, J.R.; Montesinos, P. Toward precision irrigation for intensive strawberry
    cultivation. Agric. Water Manag. 2015, 151, 43–51. [Google Scholar] [CrossRef]
    Gerhards, M.; Schlerf, M.; Mallick, K.; Udelhoven, T. Challenges and future perspectives
    of multi-/Hyperspectral thermal infrared remote sensing for crop water-stress
    detection: A review. Remote. Sens. 2019, 11, 1240. [Google Scholar] [CrossRef]
    [Green Version] Grant, O.M.; Davies, M.J.; Johnson, A.W.; Simpson, D.W. Physiological
    and growth responses to water deficits in cultivated strawberry (Fragaria× ananassa)
    and in one of its progenitors, Fragaria chiloensis. Environ. Exp. Bot. 2012, 83,
    23–32. [Google Scholar] [CrossRef] Nezhadahmadi, A.; Faruq, G.; Rashid, K. The
    impact of drought stress on morphological and physiological parameters of three
    strawberry varieties in different growing conditions. Pak. J. Agric. Sci. 2015,
    52, 79–92. [Google Scholar] Grant, O.M.; Johnson, A.W.; Davies, M.J.; James, C.M.;
    Simpson, D.W. Physiological and morphological diversity of cultivated strawberry
    (Fragaria× ananassa) in response to water deficit. Environ. Exp. Bot. 2010, 68,
    264–272. [Google Scholar] [CrossRef] Klamkowski, K.; Treder, W. Response to drought
    stress of three strawberry cultivars grown under greenhouse conditions. J. Fruit
    Ornam. Plant Res. 2008, 16, 179–188. [Google Scholar] Adak, N.; Gubbuk, H.; Tetik,
    N. Yield, quality and biochemical properties of various strawberry cultivars under
    water stress. J. Sci. Food Agric. 2018, 98, 304–311. [Google Scholar] [CrossRef]
    [PubMed] Peñuelas, J.; Savé, R.; Marfà, O.; Serrano, L. Remotely measured canopy
    temperature of greenhouse strawberries as indicator of water status and yield
    under mild and very mild water stress conditions. Agric. For. Meteorol. 1992,
    58, 63–77. [Google Scholar] [CrossRef] Razavi, F.; Pollet, B.; Steppe, K.; Van
    Labeke, M.-C. Chlorophyll fluorescence as a tool for evaluation of drought stress
    in strawberry. Photosynthetica 2008, 46, 631–633. [Google Scholar] [CrossRef]
    Delalieux, S.; Delauré, B.; Tits, L.; Boonen, M.; Sima, A.; Baeck, P. High resolution
    strawberry field monitoring using the compact hyperspectral imaging solution COSI.
    Adv. Anim. Biosci. 2017, 8, 156. [Google Scholar] [CrossRef] Li, H.; Yin, J.;
    Zhang, M.; Sigrimis, N.; Gao, Y.; Zheng, W. Automatic diagnosis of strawberry
    water stress status based on machine vision. Int. J. Agric. Biol. Eng. 2019, 12,
    159–164. [Google Scholar] [CrossRef] Gerhards, M.; Schlerf, M.; Rascher, U.; Udelhoven,
    T.; Juszczak, R.; Alberti, G.; Miglietta, F.; Inoue, Y. Analysis of airborne optical
    and thermal imagery for detection of water stress symptoms. Remote. Sens. 2018,
    10, 1139. [Google Scholar] [CrossRef] [Green Version] Oliveira, M.S.; Peres, N.A.
    Common Strawberry Diseases in Florida. EDIS 2020, 2020. [Google Scholar] [CrossRef]
    Chang, Y.K.; Mahmud, M.; Shin, J.; Nguyen-Quang, T.; Price, G.W.; Prithiviraj,
    B. Comparison of Image Texture Based Supervised Learning Classifiers for Strawberry
    Powdery Mildew Detection. AgriEngineering 2019, 1, 434–452. [Google Scholar] [CrossRef]
    [Green Version] Mahlein, A.-K. Plant Disease detection by imaging sensors–parallels
    and specific demands for precision agriculture and plant phenotyping. Plant Dis.
    2016, 100, 241–251. [Google Scholar] [CrossRef] [PubMed] [Green Version] Park,
    H.; Eun, J.-S.; Kim, S.-H. Image-based disease diagnosing and predicting of the
    crops through the deep learning mechanism. In Proceedings of the 2017 International
    Conference on Information and Communication Technology Convergence (ICTC), Jeju,
    Korea, 18–20 October 2017; pp. 129–131. [Google Scholar] [CrossRef] Shin, J.;
    Chang, Y.K.; Heung, B.; Nguyen-Quang, T.; Price, G.W.; Al-Mallahi, A. Effect of
    directional augmentation using supervised machine learning technologies: A case
    study of strawberry powdery mildew detection. Biosyst. Eng. 2020, 194, 49–60.
    [Google Scholar] [CrossRef] De Lange, E.S.; Nansen, C. Early detection of arthropod-induced
    stress in strawberry using innovative remote sensing technology. In Proceedings
    of the GeoVet 2019. Novel Spatio-Temporal Approaches in the Era of Big Data, Davis,
    CA, USA, 8–10 October 2019. [Google Scholar] [CrossRef] Liu, Q.; Sun, K.; Zhao,
    N.; Yang, J.; Zhang, Y.; Ma, C.; Pan, L.; Tu, K. Information fusion of hyperspectral
    imaging and electronic nose for evaluation of fungal contamination in strawberries
    during decay. Postharvest Biol. Technol. 2019, 153, 152–160. [Google Scholar]
    [CrossRef] Cockerton, H.M.; Li, B.; Vickerstaff, R.; Eyre, C.A.; Sargent, D.J.;
    Armitage, A.D.; Marina-Montes, C.; Garcia, A.; Passey, A.J.; Simpson, D.W. Image-based
    Phenotyping and Disease Screening of Multiple Populations for resistance to Verticillium
    dahliae in cultivated strawberry Fragaria x ananassa. bioRxiv 2018, 497107. [Google
    Scholar] [CrossRef] [Green Version] Altıparmak, H.; Al Shahadat, M.; Kiani, E.;
    Dimililer, K. Fuzzy classification for strawberry diseases-infection using machine
    vision and soft-computing techniques. In Proceedings of the Tenth International
    Conference on Machine Vision (ICMV 2017), Vienna, Austria, 13–15 November 2017;
    p. 106961N. [Google Scholar] [CrossRef] Hecht-Nielsen, R. Theory of the backpropagation
    neural network. In Proceedings of the International 1989 Joint Conference on Neural
    Networks, Washington, DC, USA, 1989; Volume 1, pp. 593–605. [Google Scholar] [CrossRef]
    Siedliska, A.; Baranowski, P.; Zubik, M.; Mazurek, W.; Sosnowska, B. Detection
    of fungal infections in strawberry fruit by VNIR/SWIR hyperspectral imaging. Postharvest
    Biol. Technol. 2018, 139, 115–126. [Google Scholar] [CrossRef] Thompson, B. Stepwise
    Regression and Stepwise Discriminant Analysis Need Not Apply Here: A Guidelines;
    Sage Publications: Thousand Oaks, CA, USA, 1995. [Google Scholar] Lu, J.; Ehsani,
    R.; Shi, Y.; Abdulridha, J.; de Castro, A.I.; Xu, Y. Field detection of anthracnose
    crown rot in strawberry using spectroscopy technology. Comput. Electron. Agric.
    2017, 135, 289–299. [Google Scholar] [CrossRef] Abdel Wahab, H.; Aboelghar, M.;
    Ali, A.; Yones, M. Spectral and molecular studies on gray mold in strawberry.
    Asian J. Plant Pathol. 2017, 11, 167–173. [Google Scholar] [CrossRef] Yuhas, R.H.;
    Goetz, A.F.H.; Boardman, J.W. Discrimination among semi-arid landscape endmembers
    using the Spectral AngleMapper (SAM) algorithm. In Summaries of the Third Annual
    JPL Airborne Geoscience Workshop; AVIRIS Workshop: Pasadena, CA, USA, 1992; pp.
    147–149. [Google Scholar] Levine, M.F. Self-developed QWL measures. J. Occup.
    Behav. 1983, 4, 35–46. [Google Scholar] Yeh, Y.-H.; Chung, W.-C.; Liao, J.-Y.;
    Chung, C.-L.; Kuo, Y.-F.; Lin, T.-T. Strawberry foliar anthracnose assessment
    by hyperspectral imaging. Comput. Electron. Agric. 2016, 122, 1–9. [Google Scholar]
    [CrossRef] Yeh, Y.-H.F.; Chung, W.-C.; Liao, J.-Y.; Chung, C.-L.; Kuo, Y.-F.;
    Lin, T.-T. A comparison of machine learning methods on hyperspectral plant disease
    assessments. IFAC Proc. Vol. 2013, 46, 361–365. [Google Scholar] [CrossRef] [Green
    Version] Jiang, Y.; Li, C.; Takeda, F.; Kramer, E.A.; Ashrafi, H.; Hunter, J.
    3D point cloud data to quantitatively characterize size and shape of shrub crops.
    Hortic. Res. 2019, 6, 1–17. [Google Scholar] [CrossRef] [PubMed] [Green Version]
    Paul, S.; Poliyapram, V.; İmamoğlu, N.; Uto, K.; Nakamura, R.; Kumar, D.N. Canopy
    Averaged Chlorophyll Content Prediction of Pear Trees Using Convolutional Autoencoder
    on Hyperspectral Data. IEEE J. Sel. Top. Appl. Earth Obs. Remote. Sens. 2020,
    13, 1426–1437. [Google Scholar] [CrossRef] Li, D.; Li, C.; Yao, Y.; Li, M.; Liu,
    L. Modern imaging techniques in plant nutrition analysis: A review. Comput. Electron.
    Agric. 2020, 174, 105459. [Google Scholar] [CrossRef] Lu, X.; Liu, Z.; Zhao, F.;
    Tang, J. Comparison of total emitted solar-induced chlorophyll fluorescence (SIF)
    and top-of-canopy (TOC) SIF in estimating photosynthesis. Remote. Sens. Environ.
    2020, 251, 112083. [Google Scholar] [CrossRef] Dechant, B.; Ryu, Y.; Badgley,
    G.; Zeng, Y.; Berry, J.A.; Zhang, Y.; Goulas, Y.; Li, Z.; Zhang, Q.; Kang, M.;
    et al. Canopy structure explains the relationship between photosynthesis and sun-induced
    chlorophyll fluorescence in crops. Remote. Sens. Environ. 2020, 241, 111733. [Google
    Scholar] [CrossRef] [Green Version] Publisher’s Note: MDPI stays neutral with
    regard to jurisdictional claims in published maps and institutional affiliations.  ©
    2021 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open
    access article distributed under the terms and conditions of the Creative Commons
    Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/). Share
    and Cite MDPI and ACS Style Zheng, C.; Abd-Elrahman, A.; Whitaker, V. Remote Sensing
    and Machine Learning in Crop Phenotyping and Management, with an Emphasis on Applications
    in Strawberry Farming. Remote Sens. 2021, 13, 531. https://doi.org/10.3390/rs13030531
    AMA Style Zheng C, Abd-Elrahman A, Whitaker V. Remote Sensing and Machine Learning
    in Crop Phenotyping and Management, with an Emphasis on Applications in Strawberry
    Farming. Remote Sensing. 2021; 13(3):531. https://doi.org/10.3390/rs13030531 Chicago/Turabian
    Style Zheng, Caiwang, Amr Abd-Elrahman, and Vance Whitaker. 2021. "Remote Sensing
    and Machine Learning in Crop Phenotyping and Management, with an Emphasis on Applications
    in Strawberry Farming" Remote Sensing 13, no. 3: 531. https://doi.org/10.3390/rs13030531
    Note that from the first issue of 2016, this journal uses article numbers instead
    of page numbers. See further details here. Article Metrics Citations Crossref   36
    ads   10 Web of Science   31 Scopus   44 Google Scholar   [click to view] Article
    Access Statistics Article access statistics Article Views 9. Jan 19. Jan 29. Jan
    8. Feb 18. Feb 28. Feb 9. Mar 19. Mar 29. Mar 0k 2.5k 5k 7.5k 10k 12.5k For more
    information on the journal statistics, click here. Multiple requests from the
    same IP address are counted as one view.   Remote Sens., EISSN 2072-4292, Published
    by MDPI RSS Content Alert Further Information Article Processing Charges Pay an
    Invoice Open Access Policy Contact MDPI Jobs at MDPI Guidelines For Authors For
    Reviewers For Editors For Librarians For Publishers For Societies For Conference
    Organizers MDPI Initiatives Sciforum MDPI Books Preprints.org Scilit SciProfiles
    Encyclopedia JAMS Proceedings Series Follow MDPI LinkedIn Facebook Twitter Subscribe
    to receive issue release notifications and newsletters from MDPI journals Select
    options Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless otherwise stated
    Disclaimer Terms and Conditions Privacy Policy'
  inline_citation: '>'
  journal: Remote sensing (Basel)
  limitations: '>'
  pdf_link: null
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: Remote Sensing and Machine Learning in Crop Phenotyping and Management, with
    an Emphasis on Applications in Strawberry Farming
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/rs11212519
  analysis: '>'
  authors:
  - Jiandong Tang
  - Wenting Han
  - Liyuan Zhang
  citation_count: 16
  full_citation: '>'
  full_text: ">\nremote sensing  \nArticle\nUAV Multispectral Imagery Combined with\
    \ the\nFAO-56 Dual Approach for Maize Evapotranspiration\nMapping in the North\
    \ China Plain\nJiandong Tang 1,2, Wenting Han 3,* and Liyuan Zhang 4\n1\nCollege\
    \ of Water Resources and Architectural Engineering, Northwest A&F University,\
    \ Yangling 712100,\nChina; tjd@nwafu.edu.cn\n2\nKey Laboratory of Agricultural\
    \ Soil and Water Engineering in Arid and Semiarid Areas, Ministry of\nEducation,\
    \ Northwest A&F University, Yangling 712100, China\n3\nInstitute of Soil and Water\
    \ Conservation, Northwest A&F University, Yangling 712100, China\n4\nCollege of\
    \ Mechanical and Electronic Engineering, Northwest A&F University, Yangling 712100,\
    \ China;\nliyuanzhang@nwafu.edu.cn\n*\nCorrespondence: hwt@nwafu.edu.cn; Tel.:\
    \ +86-029-8709-1325\nReceived: 3 September 2019; Accepted: 23 October 2019; Published:\
    \ 28 October 2019\n\x01\x02\x03\x01\x04\x05\x06\a\b\x01\n\x01\x02\x03\x04\x05\x06\
    \a\nAbstract: As the key principle of precision farming, variation of actual crop\
    \ evapotranspiration (ET)\nwithin the ﬁeld serves as the basis for crop management.\
    \ Although the estimation of evapotranspiration\nhas achieved great progress through\
    \ the combination of diﬀerent remote sensing data and the FAO-56\ncrop coeﬃcient\
    \ (Kc) method, lack of the accurate crop water stress coeﬃcient (Ks) at diﬀerent\n\
    space–time scales still hinder its operational application to farmer practices.\
    \ This work aims to explore\nthe potential of multispectral images taken from\
    \ unmanned aerial vehicles (UAVs) for estimating the\ntemporal and spatial variability\
    \ of Ks under the water stress condition and mapping the variability of\nﬁeld\
    \ maize ET combined with the FAO-56 Kc model. To search for an optimal estimation\
    \ method,\nthe performance of several models was compared including models based\
    \ on Ks either derived\nfrom the crop water stress index (CWSI) or calculated\
    \ by the canopy temperature ratio (Tc ratio),\nand combined with the basal crop\
    \ coeﬃcient (Kcb) based on the normalized diﬀerence vegetation\nindex (NDVI).\
    \ Compared with the Ks derived from the Tc ratio, the CWSI-based Ks responded\
    \ well to\nwater stress and had strong applicability and convenience. The results\
    \ of the comparison show that\nET derived from the Ks-CWSI had a higher correlation\
    \ with the modiﬁed FAO-56 method, with an\nR2 = 0.81, root mean square error (RMSE)\
    \ = 0.95 mm/d, and d = 0.94. In contrast, ET derived from\nthe Ks-Tc ratio had\
    \ a relatively lower correlation with an R2 = 0.68 and RMSE = 1.25 mm/d. To obtain\n\
    the evapotranspiration status of the whole maize ﬁeld and formulate reasonable\
    \ irrigation schedules,\nthe CWSI obtained by a handheld infrared thermometer\
    \ was inverted by the renormalized diﬀerence\nvegetation index (RDVI) and the\
    \ transformed chlorophyll absorption in reﬂectance index (TCARI).\nThen, the whole\
    \ map of Ks can be derived from the VIs by the relationship between CWSI and Ks\n\
    and can be taken as the basic input for ET estimation at the ﬁeld scale. The ﬁnal\
    \ ET results based on\nmultispectral UAV interpolation measurements can well reﬂect\
    \ the crop ET status under diﬀerent\nirrigation levels, and greatly help to improve\
    \ irrigation scheduling through more precise management\nof deﬁcit irrigation.\n\
    Keywords: UAV multispectral imagery; dual crop coeﬃcient model; crop water stress\
    \ index (CWSI);\ncanopy temperature ratio; normalized diﬀerence vegetation index;\
    \ renormalized diﬀerence vegetation\nindex; transformed chlorophyll absorption\
    \ in reﬂectance index\nRemote Sens. 2019, 11, 2519; doi:10.3390/rs11212519\nwww.mdpi.com/journal/remotesensing\n\
    Remote Sens. 2019, 11, 2519\n2 of 22\n1. Introduction\nIn semiarid regions, the\
    \ climate is characterized by long periods of drought and strong interannual\n\
    variability in rainfall amounts and distribution, leading to high year-to-year\
    \ variability in agricultural\ndevelopment and production [1]. The North China\
    \ Plain is one of the most important agricultural\nregions because it accounts\
    \ for about one-ﬁfth of national food production. In this area, rainfall cannot\n\
    meet the crop water requirements, and the overexploitation of groundwater aggravates\
    \ water scarcity,\nreduces the groundwater table, and threatens sustainable agriculture\
    \ [2]. Irrigation is then necessary\nto prevent water stress and ensure proﬁtable\
    \ yields. To determine the optimal irrigation scheduling\nand adopt such strategies\
    \ eﬃciently, it is necessary to have reliable methods of providing information\n\
    about the temporal and spatial variability of crop evapotranspiration (ET) within\
    \ the ﬁeld scale [3].\nThe direct ET measured methods consist of the use of a\
    \ lysimeter, eddy covariance, Bowen ratio,\nand soil water balance. However, they\
    \ face important limitations due to expensive techniques and\nlow spatial representativeness\
    \ of measurements, particularly in agricultural ﬁelds characterized by a\nhigh\
    \ level of heterogeneity in terms of crops and water status [4]. The indirect\
    \ form can be made from\nempirical equations that use agronomic, biophysical,\
    \ and meteorological elements as input variables [5].\nAs the most widely used\
    \ method for the determination of ET, the FAO-56 dual crop coeﬃcient (Kc)\napproach,\
    \ published by the Food and Agriculture Organization in Irrigation and Drainage\
    \ Paper No.\n56 [6], has received favorable acceptance and application worldwide\
    \ [5,7]. The dual Kc approach\ndescribes the relationship between the daily evapotranspiration\
    \ of a given crop and the reference\nevapotranspiration (ET0) by separating the\
    \ single crop coeﬃcient into the basal crop coeﬃcient (Kcb),\nsoil water evaporation\
    \ (Ke) coeﬃcient, and water stress coeﬃcient (Ks). Although simple in design and\n\
    construction, the dual Kc method successfully incorporates a number of consistent\
    \ and compensating\nfactors that distinguishes the ET of any unique crop from\
    \ that of the reference ET [7]. However, the\nmethod is mainly used for the ET\
    \ estimation based on stationary measurements and cannot provide a\nﬁne estimation\
    \ due to inconsistent crop growth.\nTo explore the distribution of crop ET within\
    \ the ﬁeld scale, remote sensing technology provides a\ndependable basis [8].\
    \ The crop coeﬃcient generated from remote sensing based on canopy reﬂectance\n\
    responds to the actual crop condition, captures the variability among diﬀerent\
    \ local atmosphere\nconditions and ﬁeld spatial variability [9], and reﬂects the\
    \ heterogeneity of plant development in large\nirrigated ﬁelds [10–14]. Studies\
    \ have established diﬀerent inversion models between vegetation indices\n(VIs)\
    \ and Kcb [15–18]. For decades, satellite remote sensing images have been the\
    \ main data sources to\nintegrate the FAO-56 for the estimation of crop ET. For\
    \ example, Bellvert et al. [19] used a dataset of the\nvegetation index (NDVI)\
    \ derived from Landsat-8 to facilitate the estimation of the Kcb, and potential\n\
    crop water use. However, the low spatial and temporal resolution of satellite\
    \ data limits its further\napplication in estimating ET within the ﬁeld scale.\
    \ At the same time, cloud cover remains a signiﬁcant\nchallenge in satellite-based\
    \ remote sensing [20].\nAs one of the most important emerging remote-sensing platforms,\
    \ unmanned aerial vehicles\n(UAVs) have been gradually employed in precise agriculture.\
    \ Soon, UAVs will be vital tools for\ngrowers as they can cover large areas, and\
    \ take advantage of new sensing, mapping, and data analytical\ntechnologies [21–23].\
    \ Real time mapping and rapid image analysis also provide the early detection\
    \ of\nplant water status for timely irrigation scheduling [24]. Based on these\
    \ advantages, UAVs have broad\napplication prospects for more sophisticated ET\
    \ management within the ﬁeld scale. When dealing\nwith the estimation of ET based\
    \ on a combination of UAV and the dual Kc method under water stress\nconditions,\
    \ four parameters are required: ET0, Kcb, Ke, and Ks. ET0 can be estimated using\
    \ the FAO\nPenman–Monteith formula and the collected meteorological data [25].\
    \ Ke is clearly correlated with\nfoliage cover and irrigation/rainfall event,\
    \ and becomes negligible when the crop completely covers the\nsoil [26]. Many\
    \ studies have validated that Kcb has a strong correlation with NDVI and foliage\
    \ cover,\nand applied to practical water requirement monitoring [16,27]. For instance,\
    \ Han et al. [28] studied the\nfeasibility of UAV multispectral remote sensing\
    \ in the estimation of maize crop coeﬃcients at diﬀerent\ngrowth stages. The results\
    \ showed a strong relationship between UAV-measured NDVI and Kcb, with\nRemote\
    \ Sens. 2019, 11, 2519\n3 of 22\nan R2 value of 0.82. Although the assimilation\
    \ of FAO-56 and remote sensing data has made such great\nprogress, discrepancies\
    \ between the measured and simulated ET remained when water stress occurred.\n\
    The accurate estimation of Ks is the key to accurately estimate crop ET using\
    \ UAV remote sensing\ndata under water stress conditions. Speciﬁcally, Ks represents\
    \ the fraction of potential transpiration\nrate, with a value from 1 to 0, according\
    \ to the level of water stress, which is directly related to the\nwater content\
    \ in the root zone. Less attention has been paid on determining the water stress\
    \ coeﬃcient\nKs from the remote sensing data because there are diﬃculties in estimating\
    \ soil and root zone moisture\n(or root zone depletion) from remote sensing data\
    \ [29]. It is necessary to use a new indictor, which\nis easy to obtain and can\
    \ respond to real-time plant-water status. Studies [30,31] have proven that\n\
    canopy temperature (Tc) is closely related to soil water content, actual transpiration,\
    \ and crop water\nstress status. Therefore, Ks and canopy temperature are deﬁnitely\
    \ related to each other. Olivera et\nal. [32] used the vegetation and soil temperatures\
    \ retrieved from LST (land surface temperature) data\nderived from the eddy covariance\
    \ system to estimate the Ks. This method is based on the polygon\ndeﬁned in the\
    \ LST–VI space, which needs a large amount of temperature data and has a complex\n\
    analysis procedure. Recently, studies have evaluated indices based on Tc that\
    \ require less information\nfor detecting crop water stress and have shown that\
    \ Ks is related to several crop water stress indices.\nFor instance, Bausch et\
    \ al. [18] successfully used a ratio of canopy temperature as a substitute for\
    \ the\nsoil moisture based Ks. The ET diﬀerence between the two deﬁcit irrigation\
    \ treatments for the 25-day\ninvestigative period calculated by Tc ratio and water\
    \ balance techniques was 21 mm and 4 mm. Kullberg\net al. [33] observed that using\
    \ an appropriate Ks method had the potential to improve irrigation\nscheduling\
    \ to properly manage stress and ensure optimum crop yield under a limited irrigation\
    \ water\nsupply. A noted advantage of non-dimensional crop indices such as CWSI\
    \ (crop water stress index)\nis that they are typically considered to be scalable\
    \ to Ks for ET estimation (i.e., Ks = 1 − CWSI). This\nis also the basis behind\
    \ the Tc ratio approach, although it has dimensionality restrictions [34]. For\n\
    the estimation of Ks based on water stress indices, most studies have used handled\
    \ or stationary\ninfrared thermometers [33–35]. A ground-based platform is still\
    \ time consuming and labor intensive.\nAdditionally, like the estimation by counting\
    \ root zone depletion, it is impractical to estimate ET by\ncombining the Kcb\
    \ of large image pixels with Ks based on ground-point measurements due to the\n\
    heterogeneities of the crop and soil status.\nWith the development of agricultural\
    \ technology, high-resolution thermal imagery acquired by\nUAVs has been used\
    \ to map plant water stress indices such as the CWSI, and water deﬁcit index (WDI).\n\
    However, when Kcb and Ks are obtained from diﬀerent sensors (i.e., multispectral\
    \ and thermal sensors),\nthe problem of data fusion and matching will be obstacles\
    \ to ET estimation with the UAV system.\nFor example, as the image resolution\
    \ obtained by the two sensors is diﬀerent, image matching with\ndiﬀerent resolutions\
    \ requires a complicated process. Most importantly, the biggest eﬀect is not only\
    \ on\nthe pixel mixing due to the downscale, but on the georectiﬁcation and co-registration\
    \ of the images,\ntherefore, the asynchronous time and space of the Ks and Kcb\
    \ may inﬂuence the acquisition of maize\nET. Previous studies have indicated that\
    \ multispectral VIs have signiﬁcantly high correlation with\nwater stress indicators.\
    \ For example, Samuel et al. [36] summarized the common spectral vegetation\n\
    indices (VIs) that have been correlated to plant water stress. Studies [37–39]\
    \ suggested that the\nrenormalized diﬀerence vegetation index (RDVI) and transformed\
    \ chlorophyll absorption in reﬂectance\nindex (TCARI) are useful in plant stress\
    \ monitoring. Therefore, the synchronized acquisition of Kcb\nand Ks using one\
    \ sensor (i.e., a multispectral camera) should be explored.\nThis study aimed\
    \ to estimate more accurate ET maps with UAV-based multispectral images over\n\
    maize in the semiarid region of the North China Plain by applying the FAO-56 dual\
    \ Kc approach.\nMore speciﬁcally, we ﬁrst compared the ET derived from water stress\
    \ indices (CWSI and Tc ratio) and\nNDVI to that calculated with the modiﬁed FAO-56\
    \ dual Kc method by evaluating the suitable water\nstress indicator for local\
    \ maize ET estimation. Next, we investigated the potential of assimilating ET\n\
    estimation with VIs data (multispectral UAV) through the retrieve relation between\
    \ the water stress\nRemote Sens. 2019, 11, 2519\n4 of 22\nindex and VIs to eliminate\
    \ discrepancies caused by using data at diﬀerent scales and obtain a high\nresolution\
    \ (4.7 cm) spatial-temporal ET map.\n2. Materials and Methods\n2.1. Study Site\
    \ and Experimental Design\nA 1.13 ha research ﬁeld located in Zhaojun Town, Dalate\
    \ Banner, Ordos, Inner Mongolia, China\n(40◦26’0.29”N, 109◦36’25.99”E, Elev. 1010\
    \ m; Figure 1a) was chosen to conduct the study. Maize (Junkai\n918) was planted\
    \ on 20 May 2017 with a 0.58 m row spacing and 0.25 m plant spacing, and the row\n\
    direction was east–west. The maize emerged on 1 June, headed on 20 July, and was\
    \ harvested on 7\nSeptember (silage), with a 110-day lifespan.\nThe study ﬁeld\
    \ was divided into ﬁve treatment (TRT) zones (Figure 1b) with three diﬀerent levels\n\
    of irrigation at the vegetative, reproductive, and maturation growth stages. Each\
    \ treatment zone had\none sample plot (Figure 1b), and each sample plot had ﬁve\
    \ sample sites (Figure 1c). The ﬁve water\ntreatments are given in Table 1. The\
    \ total crop water requirement of the full watered maize ﬁeld during\nthe late\
    \ vegetative, reproductive, and maturation stages was 407 mm, which was close\
    \ to the total\napplied water (402 mm) of the control treatment zone (TRT 1).\
    \ Water for other TRTs was applied\nproportionally to that for TRT 1. Since TRTs\
    \ 1, 2, and 3 represented the three levels of irrigation, only\nthese zones were\
    \ taken for the analysis. Irrigation water was applied during the growing season\n\
    by using a centered pivot irrigation system (Valmont Industries Inc., USA), with\
    \ the coeﬃcient of\nuniformity of the ﬁrst span (research ﬁeld) of 82.7% with\
    \ a speed of 20%, or at 88.3% with a speed of\n40%, as calculated by the modiﬁed\
    \ formula of Heermann and Hein [40] by using R3000 sprinklers. The\namount of\
    \ water applied to each treatment was measured and recorded by MIK-2000H ﬂow meters\n\
    (Meacon Automation Technology Co. Ltd., Hangzhou, China), and the accuracy of\
    \ the ﬂow meters\nwas better than 1%. The actual amount of irrigation and rainfall\
    \ at each growth stage are shown in\nTable 1. The soil type is a loamy sand according\
    \ to the soil taxonomy of the United States Department of\nAgriculture. More detailed\
    \ information about the soil characteristics are listed in Table 2. To eliminate\n\
    the interference of nutritional stress and weeds, fertilizer and herbicide were\
    \ applied according to the\nplanting experience.\nRemote Sens. 2018, 10, x FOR\
    \ PEER REVIEW  \n4 of 22 \n \n2. Materials and Methods  \n2.1. Study Site and\
    \ Experimental Design \nA 1.13 ha research field located in Zhaojun Town, Dalate\
    \ Banner, Ordos, Inner Mongolia, China \n(40°26’0.29”N, 109°36’25.99”E, Elev.\
    \ 1010 m; Figure 1a) was chosen to conduct the study. Maize \n(Junkai 918) was\
    \ planted on 20 May 2017 with a 0.58 m row spacing and 0.25 m plant spacing, and\
    \ \nthe row direction was east–west. The maize emerged on 1 June, headed on 20\
    \ July, and was harvested \non 7 September (silage), with a 110-day lifespan.\
    \  \nThe study field was divided into five treatment (TRT) zones (Figure 1b) with\
    \ three different \nlevels of irrigation at the vegetative, reproductive, and\
    \ maturation growth stages. Each treatment \nzone had one sample plot (Figure\
    \ 1b), and each sample plot had five sample sites (Figure 1c). The \nfive water\
    \ treatments are given in Table 1. The total crop water requirement of the full\
    \ watered maize \nfield during the late vegetative, reproductive, and maturation\
    \ stages was 407 mm, which was close \nto the total applied water (402 mm) of\
    \ the control treatment zone (TRT 1). Water for other TRTs was \napplied proportionally\
    \ to that for TRT 1. Since TRTs 1, 2, and 3 represented the three levels of \n\
    irrigation, only these zones were taken for the analysis. Irrigation water was\
    \ applied during the \ngrowing season by using a centered pivot irrigation system\
    \ (Valmont Industries Inc., USA), with the \ncoefficient of uniformity of the\
    \ first span (research field) of 82.7% with a speed of 20%, or at 88.3% \nwith\
    \ a speed of 40%, as calculated by the modified formula of Heermann and Hein [40]\
    \ by using \nR3000 sprinklers. The amount of water applied to each treatment was\
    \ measured and recorded by \nMIK-2000H flow meters (Meacon Automation Technology\
    \ Co. Ltd., Hangzhou, China), and the \naccuracy of the flow meters was better\
    \ than 1%. The actual amount of irrigation and rainfall at each \ngrowth stage\
    \ are shown in Table 1. The soil type is a loamy sand according to the soil taxonomy\
    \ of \nthe United States Department of Agriculture. More detailed information\
    \ about the soil characteristics \nare listed in Table 2. To eliminate the interference\
    \ of nutritional stress and weeds, fertilizer and \nherbicide were applied according\
    \ to the planting experience. \n \nFigure 1. Location and treatment division of\
    \ research field: (a) location of research field in China; (b) \ntreatment zones\
    \ and locations of sampling plots, and (c) sampling sites in a plot. Each treatment\
    \ zone \nhad one sample plot and each sample plot had five sample sites. \nFigure\
    \ 1. Location and treatment division of research ﬁeld: (a) location of research\
    \ ﬁeld in China;\n(b) treatment zones and locations of sampling plots, and (c)\
    \ sampling sites in a plot. Each treatment\nzone had one sample plot and each\
    \ sample plot had ﬁve sample sites.\nRemote Sens. 2019, 11, 2519\n5 of 22\nTable\
    \ 1. Total applied water depth for each experimental treatment in the late vegetative,\
    \ reproductive,\nand maturation stages where (07.04–07.28), (07.29–08.20), and\
    \ (08.21–09.07) are the dates of the diﬀerent\ngrowth stages. The water amount\
    \ includes that of irrigation and precipitation, and the percentage of\nfull treatment\
    \ is shown in parentheses.\nTreatment\nApplied Water Depth/mm\nLate Vegetative\n\
    (07.04–07.28)\nReproductive\n(07.29–08.20)\nMaturation\n(08.21–09.07)\nTotal\n\
    TRT 1\n188 (100%)\n132 (100%)\n82 (100%)\n402\nTRT 2\n158 (84%)\n91 (69%)\n23\
    \ (28%)\n272\nTRT 3\n158 (84%)\n125 (95%)\n43 (52%)\n326\nTRT 4\n158 (84%)\n128\
    \ (97%)\n43 (52%)\n329\nTRT 5\n158 (84%)\n124 (94%)\n82 (100%)\n365\n2.2. Framework\
    \ and Parameters for Assimilating Remote Sensing Data into FAO-56 Crop Coeﬃcient\
    \ Method\nFigure 2 shows the assimilation of remote sensing data into the FAO-56\
    \ dual crop coeﬃcient\nmethod for the estimation of evapotranspiration in this\
    \ study. Unlike the traditional FAO-56 single\ncrop coeﬃcient method, canopy reﬂectance\
    \ was used to reﬂect crop growth and water stress, and then\nthe dual crop coeﬃcient\
    \ was obtained based on the UAV-measured spectral data. Finally, point-scale\n\
    evapotranspiration was extended to the whole ﬁeld through the UAV multispectral\
    \ images under\ndiﬀerent irrigation levels. Table 2 shows the soil characteristics\
    \ and parameters used in the modiﬁed\nFAO-56 dual crop coeﬃcient assimilation\
    \ procedure for maize.\nDear Dr. Li \n \nThe specific revisions as following:\
    \ \n \n1. In the second affiliation, the initial of this the word “semiarid” is\
    \ not capitalized. \n2. We found a spelling mistake in Figure 2, and the following\
    \ picture is correct. \n \nEvapotranspiration estimation based  on combination\
    \ UAV \nmulti-spectral remote sensing data with  FAO-56 dual crop \ncoefficient\
    \ method\nWater balance \nmethod\nKcb-Tab,Ks-FAO\nET-CWSI\nET-ratio\nOptimal method\
    \ \nfor ET estimation\nKcb-NDVI\nReflectance  data \nobtained within each \nsampling\
    \ plot\nSoil water content data\nComparison of crop \ncoefficients based on \n\
    different methods\nMeteorological , LAI, \nplant height\nET-FAO\n Ks, Kcb obtained\
    \ by \nVIs model \nIrrigation output\n UAV images\nComparison\nData acquisition\n\
    CET-WB\nET map  and CET-VIs of \nentire field\nComparison\nKs-CWSI\nKs-Tc ratio\n\
    \ \n \n3. The 0.418 in Equation (2) is wrong and the correct number is 0.408.\
    \ \n4. The correct Equation (14) and (15) are as follows: \n(\n)\n(\n)\n(\n)\n\
    (\n)\n                                                      \n/\n         \n \
    \                                                      \n0\n/\n0.195\n2.41*\n\
    0.47\n0.195\n/\n0.609\n1\n0.609\n/\nTCARI RDVI\nCWSI\nTCARI RDVI\nTCARI RDVI\n\
    TCARI RDVI\n\n\n=\n−\n\n\n\n\n\n\n  (14)  \n(\n)\n(\n)\n(\n)\n1   \
    \                                                        \n/\n0.195\n1 (2.41*\n\
    /\n0.47)      0.195\n/\n0.609\n0                                             \
    \              0.60\ns CWSI\nTCARI RDVI\nK\nTCARI RDVI\nTCARI RDVI\n−\n\n=\n\
    −\n−\n\n\n(\n)\n9\n/\nTCARI RDVI\n\n\n\n\n\n (15) \n \nFigure 2. Hierarchical\
    \ framework integrating the data obtained from an unmanned aerial vehicle\n(UAV)\
    \ remote sensing system and ground measurements into the FAO-56 dual crop coeﬃcient\
    \ method.\nLAI, leaf area index; CWSI, crop water stress index; NDVI, normalized\
    \ diﬀerence vegetation index; Kcb,\nbasal crop coeﬃcient; Ks, water stress coeﬃcient;\
    \ CET, cumulative evapotranspiration; VIs, vegetation\nindices; WB, soil–water\
    \ balance.\nRemote Sens. 2019, 11, 2519\n6 of 22\nTable 2.\nSoil characteristics\
    \ and parameters used in the modiﬁed FAO-56 dual crop coeﬃcient\nassimilation\
    \ procedure for maize.\nParameters\nValue\nSource\nSoil texture\nsand\n80.7%\n\
    observed\npowder\n13.7%\nobserved\nclay\n5.6%\nobserved\nAverage ﬁeld hold capacity\
    \ (θfc)\n0.13 m3/m−3\nobserved\nAverage permanent wilting point (θwp)\n0.056 m3m−3\n\
    observed\nAverage soil bulk density\n1.56 g/m3\nobserved\nMaximum crop height\n\
    2.73 m\nobserved\nMaximum eﬀective root depth (Zr, max)\n0.1 m\nFAO-56 [6]\nMinimum\
    \ eﬀective root depth (Zr, min)\n1 m\nFAO-56 [2]\nThe fraction of available soil\
    \ water (p)\n0.65\nZhao et al. [41]\nThe threshold water content (θj)\n0.084 m3m−3\n\
    observed\ncanopy extinction coeﬃcient for solar radiation (k)\n0.7\nDing et al.\
    \ [42]\nNDVImax (maximum NDVI value at full vegetation cover)\n0.87\nobserved\n\
    NDVImin (minimum NDVI value of bare soil)\n0.07\nobserved\n2.2.1. Meteorological\
    \ Factors and Soil Water Content\nThe weather data were obtained from an automated\
    \ weather station located on a grass reference\nsurface (0.95 ha) that was 1000\
    \ meters away from the research ﬁeld, with observations of rainfall, air\ntemperature\
    \ (Ta), humidity, net solar radiation (Rn), and wind speed (2 m above the reference\
    \ surface).\nExcept for rainfall, the data acquisition interval was 30 minutes.\n\
    Soil water content (SWC) was measured two or three times each week on the day\
    \ before or after\nirrigation within each sampling plot by the traditional gravimetric\
    \ method [43]. At each sampling\nplot, three sampling sites were randomly chosen\
    \ around the center. The samples were collected by soil\naugers at depths of 30\
    \ cm, 60 cm, 90 cm, and 120 cm. Soil samples were put in aluminum boxes to\navoid\
    \ the inﬂuence of evaporation. Basically, the gravimetric method involves taking\
    \ soil samples,\nweighing, oven-drying, and reweighing them, then expressing the\
    \ moisture content (i.e., loss in weight)\nas a percentage of the oven-dry weight.\
    \ This is the weight or mass basis of expressing soil moisture\ncontent. Then,\
    \ by multiplying the bulk density, the results can be expressed in terms of volume\
    \ [44].\nThe average SWC (θ) was estimated by interpolating the soil moisture\
    \ observations of the diﬀerent\ndepths belonging to the root-zone of maize.\n\
    2.2.2. Measurement of Maize Parameters\nMaize canopy temperature (Tc) and UAV\
    \ multispectral data were synchronously collected under\nclear sky at solar noon.\
    \ Tc was collected during the full foliage cover period (6–29 August 2017\nincluding\
    \ the reproductive and maturation stages). A handheld infrared thermometer (Raytek\
    \ ST60+,\nRaytek Inc., Santa Cruz, CA, USA) was used to measure Tc with a measurement\
    \ error of ±1 ◦C or\n±1% of the reading. The larger values were adopted in the\
    \ practical application. The temperature and\nspectral ranges of the Raytek ST60+\
    \ are −32–600 ◦C and 8–14 µm, respectively. The emissivity value\nwas set to 0.97\
    \ [45]. To avoid the interference of soil, the thermometer was used to sweep the\
    \ canopy\n(about 120◦) perpendicular to the row, 30 cm above the canopy, and at\
    \ a 15◦ horizontal angle. At each\nsample site, three measurements were made to\
    \ obtain the Tc. The values averaged over one sampling\nsite or over one plot\
    \ (yellow circle in Figure 1c) were taken to represent their status.\nThe main\
    \ plant parameters needed to run the modiﬁed FAO-56 model (see Section 2.2.3)\
    \ are\ncanopy height (h) and leaf area index (LAI). A random sampling method was\
    \ used to collect the LAI\nand plant height of maize. An LAI-2200C canopy analyzer\
    \ (LI-COR Biosciences, Lincoln, NE, USA)\nwas used to measure the LAI of maize;\
    \ 10 sampling points were randomly selected for each plot and\nthe average value\
    \ was obtained. For each plot plant height of maize, 15 representative maize plants\n\
    were randomly selected and measured by tape measure. Cubic spline interpolation\
    \ is a piecewise\nregression approach that uses third-order polynomials for interpolation\
    \ between a series of paired\nRemote Sens. 2019, 11, 2519\n7 of 22\ndata points\
    \ [14]. Thus, cubic spline was used to process the measured LAI and plant height\
    \ data, and\nthen the daily sequence of maize LAI and plant height data were obtained.\n\
    2.2.3. The Modiﬁed FAO-56 Dual Crop Coeﬃcient Method\nIn FAO-56, the actual ET\
    \ is deﬁned as the product of crop coeﬃcient (Kc) and reference\nevapotranspiration\
    \ (ET0) [26]. In the dual Kc model, Kc is split into two factors that separately\n\
    describe the evaporation (Ke) and transpiration (Kcb) components. The method has\
    \ been widely used\nin scheduling irrigation and improving agricultural production\
    \ [46]. FAO-56 ET is estimated as follows:\nET = ET0 ∗ (KcbKs + Ke),\n(1)\nwhere\
    \ ET is in mm/d; Ke is the evaporation coeﬃcient of the bare soil fraction; Kcb\
    \ is the basal crop\ncoeﬃcient; Ks is the water stress coeﬃcient; and ET0 is the\
    \ grass reference evapotranspiration in\nmm/d. The stages of canopy temperature\
    \ acquisition and ET estimation were in the period of high\ncoverage (i.e., vegetation\
    \ cover ranging from 0.79 to 0.84 as estimated by an empirical equation based\n\
    on NDVI [47]). With Ke = 0.25 × (1 − fc) [26], it had a minor inﬂuence on total\
    \ ET and was ignored.\nThe ET0 of this reference surface was estimated according\
    \ to the following Penman–Monteith\nequation:\nET0 =\n0.408∆(Rn − G) + γ\n900\n\
    T+273u2(es − ea)\n∆ + γ(1 + 0.34u2)\n,\n(2)\nwhere Rn is the net radiation at\
    \ the crop surface; G is the soil heat ﬂux density (as the magnitude of the\n\
    1-day or 10-day soil heat ﬂux beneath the grass reference surface is relatively\
    \ small, it may be ignored,\nthus Gday = 0 [26]); T is the mean daily air temperature\
    \ at 2 m height; u2 is the wind speed at 2 m\nheight; es is the saturation vapor\
    \ pressure; ea is the actual vapor pressure; ∆ is the slope vapor pressure\ncurve;\
    \ and γ is a psychrometric constant.\nThe basal crop coeﬃcient, Kcb, is generally\
    \ obtained from the guidelines of FAO-56 by looking-up\nthe tabulated value at\
    \ every growth stage and then linearly interpolating it to obtain the daily values.\n\
    The approach from the original FAO-56 dual Kc procedures cannot calculate the\
    \ daily actual value\nof Kcb [42]. Feng et al. [48] modiﬁed Kcb with LAI through\
    \ eddy covariance systems near the\nexperimentation site, which illustrated that\
    \ the modiﬁed dual crop coeﬃcient method could estimate\nmaize ET accurately on\
    \ the North China Plain. Therefore, in order to evaluate the dynamic changes of\n\
    ET in the maize ﬁeld more accurately, the canopy height and LAI were used to modify\
    \ the dynamic\nKcb. The modiﬁed FAO-56 Kcb value can be calculated by Equations\
    \ (3) and (4):\nKcb − Tab = Kc,min +\n\x10\nKcb,full − Kc,min\n\x11\n(1 − exp[−kLAI])\
    \ ,\n(3)\nKcb, full = min(1 + 0.1h, Kc,max) + [0.04(u2 − 2) − 0.004(RHmin − 45)]\n\
    \ \nh\n3\n!0.3\n,\n(4)\nwhere Kc,min is the minimum for bare soil (0.15); Kcb,full\
    \ is the estimated basal Kcb for vegetation having\nfull ground cover; Kc,max\
    \ is the maximum Kc (1.2); RHmin is the minimum relative humidity (%); and k\n\
    is the canopy attenuation coeﬃcient of radiation, and the value of k is listed\
    \ in Table 2.\nThe crop water stress coeﬃcient Ks related to the actual root zone\
    \ water content is a key parameter\nfor calculating and simulating soil water\
    \ conditions. Several linear and curvilinear functions have been\nproposed to\
    \ adjust for the eﬀects of decreasing available water on ET or for the Ks used\
    \ in Equation (1).\nThe simple linear model for estimating Ks as described in\
    \ FAO-33 is commonly used and calculated by\nEquation (5) ,which is an equivalent\
    \ expression to the FAO-56 Ks procedure [49].\nKs − FAO =\n\n1,\nθ ≥ θj\n\
    θ−θwp\nθj−θwp =\nθ−θwp\n(1−p)(θ fc−θwp), θwp < θ < θj\n,\n(5)\nRemote Sens. 2019,\
    \ 11, 2519\n8 of 22\nθj = (1 − p)\n\x10\nθfc − θwp\n\x11\n+ θwp ,\n(6)\nwhere\
    \ θ is the mean volumetric soil water in the crop root zone and θj is the threshold\
    \ water content,\nwhere transpiration decreases linearly due to water stress.\
    \ Ks = 1 for θ ≥ θj. p is the fraction of available\nsoil water that can be deleted\
    \ from the root zone before moisture stress. The θfc is the ﬁeld capacity,\nand\
    \ θwp is the permanent wilting point. All θ (m3 m−3) represent averages over the\
    \ eﬀective root zone\n(Zr). The rooting depth Zr (m) is assumed to vary between\
    \ a minimum value (maintained during the\ninitial crop growth stage at 0.1 m)\
    \ and a maximum value (that reached 1 m at the beginning of the\nmid-season stage).\
    \ The maximum value was measured in the ﬁeld and was equal to 1 m, according to\n\
    FAO-56 [6]. When the θ was lower than θj, the crop begins to reach the stress\
    \ period (Ks < 1), and if θ\nis less than θwp, the crop does not absorb water\
    \ from the root zone (Ks = 0). Values for Equations (5)\nand (6) are listed in\
    \ Table 2.\n2.2.4. UAV (Unmanned Aerial Vehicle) Multispectral System, Data Collection,\
    \ and VI (Vegetation\nIndex) Calculation\nIn this study, a hexacopter UAV multispectral\
    \ remote sensing system (Figure 3) was developed\nwith a Pixhawk autopilot (CUAV,\
    \ Guangzhou, China), a RedEdge multispectral camera (MicaSense,\nInc., USA), and\
    \ a MOY brushless gimbal (Moyouzhijia, Huizhou, China). Its maximum load was\n\
    5 kg, and the maximum ﬂight duration was 30 minutes. The RedEdge multispectral\
    \ camera has a\nfocal length of 5.5 mm, a ﬁeld-of-view angle of 47.2◦, and an\
    \ image resolution of 1280 × 960 pixels.\nThe bandwidths and central wavelengths\
    \ for the 5-band RedEdge are 20 nm at 475 nm (blue), 20 nm\nat 560 nm (green),\
    \ 10 nm at 668 nm (red), 10 nm at 717 nm (red edge), and 40 nm at 840 nm (near\n\
    infrared). The camera was equipped with a light intensity sensor and two 3 m ×\
    \ 3 m gray plates\n(Group 8 Technology, Provo, UT, USA). The light intensity sensor\
    \ can correct the inﬂuence of external\nlight changes on spectral images during\
    \ aerial photography. The gray plate has ﬁxed reﬂectivity; it can\ncorrect the\
    \ reﬂectivity of multispectral images, generate reﬂectivity images, and extract\
    \ the VI. The\nmultispectral images of the gray plate (reﬂectivity 58%) collected\
    \ simultaneously at the same height\nwere used to perform radiometric correction.\
    \ In Pix4DMapper a vignetting polynomial was used for\nradiometric correction.\
    \ Then, the spectral reﬂectance of the objects was obtained. Flight planning was\n\
    conducted with Mission Planner ground control station software, which allows the\
    \ user to generate\na route of waypoints as a function of the sensor ﬁeld of view\
    \ (FOV), the degree of overlap between\nimages, and the ground resolution needed.\n\
    \ \nprocedure [49]. \n\n\n\n                                             \
    \  \n  \n1,\n,\n1\nj\nwp\nwp\ns\nwp\nj\nj\nwp\nfc\nwp\nK\nFAO\np\n\n\n\n\n\
    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n ,\
    \ \n(5) \n\n\n\n1\nj\nfc\nwp\nwp\np\n\n\n\n\n\n\n\n\n \n, \n(6) \n\
    where θ is the mean volumetric soil water in the crop root zone and θj is the\
    \ threshold water content, \nwhere transpiration decreases linearly due to water\
    \ stress. Ks = 1 for θ ≥ θj. p is the fraction of \navailable soil water that\
    \ can be deleted from the root zone before moisture stress. The θfc is the field\
    \ \ncapacity, and θwp is the permanent wilting point. All θ (m3 m-3) represent\
    \ averages over the effective \nroot zone (Zr). The rooting depth Zr (m) is assumed\
    \ to vary between a minimum value (maintained \nduring the initial crop growth\
    \ stage at 0.1 m) and a maximum value (that reached 1 m at the beginning \nof\
    \ the mid-season stage). The maximum value was measured in the field and was equal\
    \ to 1 m, \naccording to FAO-56 [6]. When the θ was lower than θj, the crop begins\
    \ to reach the stress period (Ks \n< 1), and if θ is less than θwp, the crop does\
    \ not absorb water from the root zone (Ks = 0). Values for \nEquations (5) and\
    \ (6) are listed in Table 2. \n2.2.4. UAV (Unmanned Aerial Vehicle) Multispectral\
    \ System, Data Collection, and VI (Vegetation \nIndex) Calculation \nIn this study,\
    \ a hexacopter UAV multispectral remote sensing system (Figure 3) was developed\
    \ \nwith a Pixhawk autopilot (CUAV, Guangzhou, China), a RedEdge multispectral\
    \ camera (MicaSense, \nInc., USA), and a MOY brushless gimbal (Moyouzhijia, Huizhou,\
    \ China). Its maximum load was 5 \nkg, and the maximum flight duration was 30\
    \ minutes. The RedEdge multispectral camera has a focal \nlength of 5.5 mm, a\
    \ field-of-view angle of 47.2°, and an image resolution of 1280 × 960 pixels.\
    \ The \nbandwidths and central wavelengths for the 5-band RedEdge are 20 nm at\
    \ 475 nm (blue), 20 nm at \n560 nm (green), 10 nm at 668 nm (red), 10 nm at 717\
    \ nm (red edge), and 40 nm at 840 nm (near \ninfrared). The camera was equipped\
    \ with a light intensity sensor and two 3 m × 3 m gray plates \n(Group 8 Technology,\
    \ Provo, UT, USA). The light intensity sensor can correct the influence of external\
    \ \nlight changes on spectral images during aerial photography. The gray plate\
    \ has fixed reflectivity; it \ncan correct the reflectivity of multispectral images,\
    \ generate reflectivity images, and extract the VI. \nThe multispectral images\
    \ of the gray plate (reflectivity 58%) collected simultaneously at the same \n\
    height were used to perform radiometric correction. In Pix4DMapper a vignetting\
    \ polynomial was \nused for radiometric correction. Then, the spectral reflectance\
    \ of the objects was obtained. Flight \nplanning was conducted with Mission Planner\
    \ ground control station software, which allows the \nuser to generate a route\
    \ of waypoints as a function of the sensor field of view (FOV), the degree of\
    \ \noverlap between images, and the ground resolution needed. \n \nFigure 3. Schematic\
    \ diagram of the UAV multispectral remote sensing system developed in this study.\
    \ \nFigure 3. Schematic diagram of the UAV multispectral remote sensing system\
    \ developed in this study.\nDuring the study period (20 June to 29 August 2017),\
    \ 11 UAV ﬂights were conducted on sunny\ndays between 11:00 and 13:00 local time\
    \ (Chinese standard time, 11:44–13:44) with the RedEdge camera\nlens vertically\
    \ downward, and an 80% heading and side overlap. The ﬂight height, speed, and\
    \ pixel\nresolution were 70 m (relative ﬂying height), 5 m/s, and 4.7 cm, respectively.\
    \ A total of 2185 images (ﬁve\nbands) were collected during a single ﬂight and\
    \ Pix4DMapper software was used for image mosaicking.\nTo establish the regression\
    \ models between UAV-based multispectral VIs and crop coeﬃcients\n(NDVI vs. Kcb\
    \ and TRCAI/RDVI vs. Ks), three VIs were selected: NDVI [50], transformed chlorophyll\n\
    Remote Sens. 2019, 11, 2519\n9 of 22\nabsorption in reﬂectance index (TCARI) [51],\
    \ and the renormalized diﬀerence vegetation index\n(RDVI) [52]. In addition, cubic\
    \ spline interpolation was used to determine the VI values between two\nﬂight\
    \ overpasses. Their calculation equations are as follows:\nNDVI = ρnir − ρred\n\
    ρnir + ρred\n,\n(7)\nTCARI = 3\nh\x10\nρrededge − ρred\n\x11\n− 0.2\n\x10\nρrededge\
    \ − ρgreen\n\x11\x10\nρrededge/ρred\n\x11i\n,\n(8)\nRDVI =\nρnir − ρred\n√ρnir\
    \ + ρred\n,\n(9)\nwhere ρnir, ρred, ρrededge, and ρgreen are the reﬂectance values\
    \ of ground objects in the near-infrared, red,\nred-edge, and green bands, respectively.\n\
    2.2.5. Crop Coeﬃcient Estimation Using Reﬂectance Data\nReﬂectance-based basal\
    \ crop coeﬃcient (Kcb) methods have been used to improve the irrigation\nscheduling\
    \ of maize. NDVI is one of the most widely used indices for estimating crop parameters.\n\
    This index is highly sensitive to variations of LAI and the fraction of the ground\
    \ that is covered by\nvegetation, (fc). The NDVI has a linear relationship with\
    \ fc along the whole range of vegetation cover [47].\nAccordingly in this study,\
    \ Equation (10) was used for fc estimation. In this study, one 12 m × 12 m area\n\
    was selected as the spectral sampling plot in each treatment (yellow box in Figure\
    \ 1b). Studies [53,54]\nshowed that Kcb can be estimated from fc.\nfc =\nNDVI\
    \ − NDVImin\nNDVImax − NDVImin\n,\n(10)\nwhere NDVImin and NDVImax are the minimum\
    \ and the maximum values of the NDVI associated\nwith bare soil and dense vegetation,\
    \ respectively. Once fc has been obtained through Equation (10), the\nKcb can\
    \ be estimated as:\nKcb − NDVI = 1.13 fc + 0.14,\n(11)\nThe two diﬀerent Ks obtained\
    \ from CWSI and Tc ratio were derived from the handheld infrared\nthermometer,\
    \ with daily values taken around local times between 11:00 and 13:00 (local time),\
    \ which\nare approximate times of peak stress.\nJackson et al. [30] showed that\
    \ CWSI is inversely related to the water use of the crop under\nconsideration;\
    \ Ks can also be calculated from CWSI by:\nKs−CWSI = 1 − CWSI,\n(12)\nOne of the\
    \ widely used methods for estimating CWSI is based on measured canopy\ntemperature\
    \ [30,55]. The CWSI is deﬁned in Equation (13).\nCWSI = dTm − dTLL\ndTUL − dTLL\n\
    ,\n(13)\nwhere dTm, dTLL, and dTUL are the actual measurement, lower limit, and\
    \ upper limit of the\ncanopy–air temperature diﬀerence (Tc−Ta), respectively.\n\
    More detailed information about local\nCWSI measurements can be found in Zhang\
    \ et al. [39]. CWSI = 0 indicates no water stress, while\nCWSI = 1 indicates the\
    \ most severe stress.\nZhang et al. [39] established linear regression models\
    \ (R2 = 0.80, p < 0.001) between TRCAI/RDVI\nand CWSI (Equation (14)). The local\
    \ calibration of CWSI performed in [39] was also retained here.\nThus, we could\
    \ integrate the remote sensing data into the Ks model by establishing a stable\
    \ relationship\nbetween VIs and CWSI. According to the relationship between Ks\
    \ and CWSI (i.e., Ks = 1 − CWSI)\nRemote Sens. 2019, 11, 2519\n10 of 22\nand to\
    \ rescale the Ks value between 0 and 1, the linear regression models can been\
    \ shown as per\nEquation (15):\nCWSI =\n\n0\n(TCARI/RDVI ≤ 0.195)\n2.41\
    \ ∗ (TCARI/RDVI) − 0.47\n(0.195 < TCARI/RDVI < 0.609)\n1\n(0.609 ≤ TCARI/RDVI)\n\
    ,\n(14)\nKs−CWSI =\n\n1\n(TCARI/RDVI ≤ 0.195)\n1 − (2.41 ∗ (TCARI/RDVI)\
    \ − 0.47)\n(0.195 < TCARI/RDVI < 0.609)\n0\n(0.609 ≤ TCARI/RDVI)\n,\n(15)\nAn\
    \ alternative method to evaluate water stress that only requires the crop canopy\
    \ temperature\nwas proposed by Bausch et al. [35]. The relationship between Ks\
    \ and Tc ratio is as follows:\nKs−Tc ratio = Tc ratio = TcNS\nTc\n,\n(16)\nwhere\
    \ Tc ratio is a stress coeﬃcient proposed as a surrogate for the water stress\
    \ coeﬃcient Ks from\nFAO-56. Tc is the canopy temperature and TcNS is the temperature\
    \ of a fully irrigated, non-stressed\ncanopy, which was chosen as the lowest canopy\
    \ temperature observed at the given timestamp including\nall treatments [34].\
    \ This temperature ratio was found to be capable of quantitatively monitoring\n\
    water stress and can potentially be used in the place of the water stress coeﬃcient\
    \ when soil water\nmeasurements are not available.\n2.2.6. Evapotranspiration\
    \ Comparison and Statistical Analysis\nDue to the lack of validation information\
    \ from an eddy covariance tower or lysimeter, the ET\nestimated by the modiﬁed\
    \ dual Kc method [42,48] was used to validate the model. Ding et al. [42]\nfound\
    \ good agreement between the predicted ET and transpiration using the modiﬁed\
    \ model and\nthe measurements through the lysimeter for maize in 2010, with a\
    \ slope of linear regression of 0.99\n(R2 = 0.90) and 1.01 (R2 = 0.92). Feng et\
    \ al. [48] also obtained similar results and suggested that the\nmodiﬁed dual\
    \ crop coeﬃcient method was suitable for calculating the actual daily ET of the\
    \ main\ncrops across the North China Plain. Studies [56,57] also used the local\
    \ ET estimated by the FAO-56\nKc method to validate the derived ET from their\
    \ model. Thus, employing the ET data estimated by\nthe modiﬁed FAO-56 dual Kc\
    \ method as the validation set had certain accuracy in this study. The\nsimulated\
    \ daily ET of the maize derived from the two Ks methods and NDVI-based Kcb methods\n\
    (ET-CWSI and ET-ratio) were compared with the values obtained from the modiﬁed\
    \ FAO-56 dual\ncrop coeﬃcient method. The ET-CWSI, ET-ratio, and ET-FAO values\
    \ were compared by using a linear\nregression analysis and the statistical parameters\
    \ of the coeﬃcient of determination (R2), root mean\nsquare error (RMSE), and\
    \ index of agreement (d) were used as a relative measure of the diﬀerence\namong\
    \ variables. Perfect agreement would exist between the observed and modeled values\
    \ if d = 1.\nFinally, we compared the cumulative evapotranspiration (CET) obtained\
    \ by the VI method with\nthe water balance approach to evaluate the ability of\
    \ ET determination by UAV. Cumulative ET\nobtained by the soil–water balance [58]\
    \ was used as the reference ET, and a relatively simple relation is\nexpressed\
    \ as:\n(Pr + I) + U − RO − ET − DP − ∆SW = 0,\n(17)\nwhere Pr is the eﬀective\
    \ precipitation; I is the irrigation depth; U is the ground water replenishment;\n\
    RO is the runoﬀ from the soil surface; and DP is the deep percolation of water\
    \ moving out of the root\nzone. ∆SW is the change between the ﬁrst and last measurements\
    \ of soil water storage within the root\nzone. All terms are expressed in mm.\
    \ As soil water content sensors buried at diﬀerent depths in the\nﬁeld showed\
    \ that the soil moisture at 1.2 m changed little during the study period and the\
    \ terrain\nRemote Sens. 2019, 11, 2519\n11 of 22\ninclination was <5%, the U,\
    \ RO, and DP were also considered as zero. Based on the soil–water balance\n(Equation\
    \ (17)) and the above criteria, the CET was determined as follows:\nCET = Pr +\
    \ I − ∆SW,\n(18)\n3. Results\n3.1. Meteorological Conditions and Maize Status\n\
    The temporal evolution of ET0, daily average air temperature (ATa), and canopy\
    \ temperature\n(Tc) of three diﬀerent treatments for diﬀerent growth periods are\
    \ shown in Figure 4. The ATa and\nother meteorological data for the ET0 calculation\
    \ were obtained from an automatic weather station.\nObservations showed the three\
    \ parameters decreased as the maize growth period progressed. Driven\nby the ATa,\
    \ ET0 presented a similar pattern to ATa, which conformed to the standard Penman–Monteith\n\
    equation. The highest ATa and ET0 reached 28 ◦C and 9.69 mm during the studied\
    \ period. Although\nhigher air temperatures may increase ET0, it can also inﬂuence\
    \ Tc and aﬀect crop transpiration when Tc\nexceeds the suitable canopy temperature\
    \ for maize growth. The Tc of three diﬀerent water treatments\nused for calculating\
    \ the water stress index (CWSI and Tc ratio) showed a certain numeric gradient\
    \ from\n6 to 29 August 2017. Overall, Tc increased with the degree of water deﬁcit.\
    \ Average Tc of TRTs 1 (full\nirrigation), 2 (severe deﬁcit irrigation), and 3\
    \ (light deﬁcit irrigation) were 26.4 ◦C, 28.3 ◦C, and 26.5 ◦C,\nrespectively.\
    \ The highest Tc in TRT 2 reached 34 ◦C.\n \n\n\nr\n, \n(17) \nwhere Pr is the\
    \ effective precipitation; I is the irrigation depth; U is the ground water replenishment;\
    \ \nRO is the runoff from the soil surface; and DP is the deep percolation of\
    \ water moving out of the root \nzone. ΔSW is the change between the first and\
    \ last measurements of soil water storage within the \nroot zone. All terms are\
    \ expressed in mm. As soil water content sensors buried at different depths in\
    \ \nthe field showed that the soil moisture at 1.2 m changed little during the\
    \ study period and the terrain \ninclination was <5%, the U, RO, and DP were also\
    \ considered as zero. Based on the soil–water balance \n(Equation (17)) and the\
    \ above criteria, the CET was determined as follows: \nPr\nCET\nI\nSW\n\n \
    \ \n, \n(18) \n3. Results \n3.1. Meteorological Conditions and Maize Status \
    \ \nThe temporal evolution of ET0, daily average air temperature (ATa), and canopy\
    \ temperature \n(Tc) of three different treatments for different growth periods\
    \ are shown in Figure 4. The ATa and \nother meteorological data for the ET0 calculation\
    \ were obtained from an automatic weather station. \nObservations showed the three\
    \ parameters decreased as the maize growth period progressed. Driven \nby the\
    \ ATa, ET0 presented a similar pattern to ATa, which conformed to the standard\
    \ Penman–\nMonteith equation. The highest ATa and ET0 reached 28 °C and 9.69 mm\
    \ during the studied period. \nAlthough higher air temperatures may increase ET0,\
    \ it can also influence Tc and affect crop \ntranspiration when Tc exceeds the\
    \ suitable canopy temperature for maize growth. The Tc of three \ndifferent water\
    \ treatments used for calculating the water stress index (CWSI and Tc ratio) showed\
    \ a \ncertain numeric gradient from 6 to 29 August 2017. Overall, Tc increased\
    \ with the degree of water \ndeficit. Average Tc of TRTs 1 (full irrigation),\
    \ 2 (severe deficit irrigation), and 3 (light deficit irrigation) \nwere 26.4\
    \ °C, 28.3 °C, and 26.5 °C, respectively. The highest Tc in TRT 2 reached 34 °C.\
    \  \n \nFigure 4. Daily reference evapotranspiration (ET0), average daily air\
    \ temperature (Ta), and canopy \ntemperature (Tc) during the studied period. \n\
    LAI is closely related to canopy structure, leaf number, and size, and has a strong\
    \ effect on crop \ntranspiration. When the crop is under water stress, leaf growth\
    \ is affected (i.e., curl). Variation in the \nLAI can also influence canopy spectral\
    \ information such as the NDVI. Figure 5 shows the changes of \nthe NDVI and LAI\
    \ from the vegetative to maturation stages (20 June to 29 August 2017) under three\
    \ \ndifferent irrigation treatments. The growth variables, NDVI and LAI, exhibited\
    \ comparable seasonal \npatterns (i.e., first increased, and then decreased from\
    \ early crop development to maturation). Due \nto the saturation of the NDVI,\
    \ the maximum value of NDVI appeared faster than that of the LAI. The \nNDVI reached\
    \ its maximum value of 0.84 in the late vegetative stage (DOY 207), while the\
    \ LAI was \nFigure 4. Daily reference evapotranspiration (ET0), average daily\
    \ air temperature (Ta), and canopy\ntemperature (Tc) during the studied period.\n\
    LAI is closely related to canopy structure, leaf number, and size, and has a strong\
    \ eﬀect on crop\ntranspiration. When the crop is under water stress, leaf growth\
    \ is aﬀected (i.e., curl). Variation in the\nLAI can also inﬂuence canopy spectral\
    \ information such as the NDVI. Figure 5 shows the changes of\nthe NDVI and LAI\
    \ from the vegetative to maturation stages (20 June to 29 August 2017) under three\n\
    diﬀerent irrigation treatments. The growth variables, NDVI and LAI, exhibited\
    \ comparable seasonal\npatterns (i.e., ﬁrst increased, and then decreased from\
    \ early crop development to maturation). Due to\nthe saturation of the NDVI, the\
    \ maximum value of NDVI appeared faster than that of the LAI. The\nNDVI reached\
    \ its maximum value of 0.84 in the late vegetative stage (DOY 207), while the\
    \ LAI was\nstill increasing up until the late reproductive stage (DOY 223). The\
    \ average NDVI values for TRT 1,\nTRT 2, and TRT 3 were 0.69, 0.67, and 0.70 from\
    \ the late vegetative to maturation stages, respectively,\nwhich was in line with\
    \ the water stress levels. The NDVIs of TRT 1 and TRT 3 were approximately the\n\
    same during the study stages, even though TRT 3 experienced light drought. The\
    \ maximum diﬀerence\nbetween TRT 1 and TRT 3 was 0.03 on DOY 177. Furthermore,\
    \ responses of diﬀerent crop growth stages\nto crop water stress ere also diﬀerent.\
    \ The diﬀerences in the NDVI among the three treatments during\nthe reproductive\
    \ stage were smaller than those during the vegetative and maturation stages. For\n\
    Remote Sens. 2019, 11, 2519\n12 of 22\nexample, the diﬀerences between the NDVIs\
    \ of TRT 1 and TRT 2 for the vegetation, reproductive, and\nmaturation stages\
    \ were 0.06, 0.01, and 0.08, respectively. The LAI patterns of the diﬀerent treatments\n\
    presented larger diﬀerences than those of the NDVI. Especially from the middle\
    \ vegetative to middle\nreproductive stages, the maximum diﬀerence between the\
    \ LAIs of TRT 2 and TRT 3 was 0.73 on DOY\n207, illustrating that the LAI is more\
    \ sensitive to water stress than the NDVI. On the other hand, the\nabove facts\
    \ show that it is not feasible to estimate ET only from the NDVI under water stress\
    \ condition.\n \ng\ng\np\ny\nwhich was in line with the water stress levels. The\
    \ NDVIs of TRT 1 and TRT 3 were approximately \nthe same during the study stages,\
    \ even though TRT 3 experienced light drought. The maximum \ndifference between\
    \ TRT 1 and TRT 3 was 0.03 on DOY 177. Furthermore, responses of different crop\
    \ \ngrowth stages to crop water stress ere also different. The differences in\
    \ the NDVI among the three \ntreatments during the reproductive stage were smaller\
    \ than those during the vegetative and \nmaturation stages. For example, the differences\
    \ between the NDVIs of TRT 1 and TRT 2 for the \nvegetation, reproductive, and\
    \ maturation stages were 0.06, 0.01, and 0.08, respectively. The LAI \npatterns\
    \ of the different treatments presented larger differences than those of the NDVI.\
    \ Especially \nfrom the middle vegetative to middle reproductive stages, the maximum\
    \ difference between the LAIs \nof TRT 2 and TRT 3 was 0.73 on DOY 207, illustrating\
    \ that the LAI is more sensitive to water stress \nthan the NDVI. On the other\
    \ hand, the above facts show that it is not feasible to estimate ET only \nfrom\
    \ the NDVI under water stress condition. \n \nFigure 5. Seasonal variation of\
    \ NDVI (normalized difference vegetation index) and LAI (leaf area \nindex) under\
    \ different treatments during the vegetation to early maturation stages. V, R,\
    \ and M \nrepresent the vegetative, reproductive, and maturation stages, respectively.\
    \ \n3.2. Kcb and Ks Calculated by Different Methosd \nThe basal crop coefficient,\
    \ Kcb-Tab, calculated by the modified FAO-56 method (Equations (3) \nand (4)),\
    \ was used to assess the capability of the reflectance-based basal coefficient\
    \ model to provide \naccurate estimates of ET over the maize field under three\
    \ treatments. According to the results \ncomputed by two methods in Figure 6,\
    \ Kcb derived from UAV multispectral measurements closely \ntracked modified Kcb-Tab\
    \ over the crop cycle and two Kcb responded well to the LAI (Figure 5) in \ndifferent\
    \ grown stages. They increased fast in the vegetative stage and then entered an\
    \ asymptotic \nregime when the surface was almost covered by leaves (80%) in the\
    \ reproductive stage. During the \nlate reproductive stage, the Kcb values began\
    \ to decline and the slope of the decrease in TRTs 2 and \n3 were higher than\
    \ TRT 1 due to the water stress. The Kcb-Tab and Kcb-NDVI in the three treatments\
    \ \nalso showed certain value differences. In general, the Kcb values increased\
    \ with the irrigation levels. \nFor instance, the average observed Kcb-NDVI were\
    \ 0.86, 0.81, and 0.84 for TRT 1, 2, and 3, \nrespectively.  \nFigure 5. Seasonal\
    \ variation of NDVI (normalized diﬀerence vegetation index) and LAI (leaf area\
    \ index)\nunder diﬀerent treatments during the vegetation to early maturation\
    \ stages. V, R, and M represent the\nvegetative, reproductive, and maturation\
    \ stages, respectively.\n3.2. Kcb and Ks Calculated by Diﬀerent Methosd\nThe basal\
    \ crop coeﬃcient, Kcb-Tab, calculated by the modiﬁed FAO-56 method (Equations\
    \ (3)\nand (4)), was used to assess the capability of the reﬂectance-based basal\
    \ coeﬃcient model to provide\naccurate estimates of ET over the maize ﬁeld under\
    \ three treatments. According to the results computed\nby two methods in Figure\
    \ 6, Kcb derived from UAV multispectral measurements closely tracked\nmodiﬁed\
    \ Kcb-Tab over the crop cycle and two Kcb responded well to the LAI (Figure 5)\
    \ in diﬀerent\ngrown stages. They increased fast in the vegetative stage and then\
    \ entered an asymptotic regime when\nthe surface was almost covered by leaves\
    \ (80%) in the reproductive stage. During the late reproductive\nstage, the Kcb\
    \ values began to decline and the slope of the decrease in TRTs 2 and 3 were higher\
    \ than\nTRT 1 due to the water stress. The Kcb-Tab and Kcb-NDVI in the three treatments\
    \ also showed certain\nvalue diﬀerences. In general, the Kcb values increased\
    \ with the irrigation levels. For instance, the\naverage observed Kcb-NDVI were\
    \ 0.86, 0.81, and 0.84 for TRT 1, 2, and 3, respectively.\nRemote Sens. 2018,\
    \ 10, x FOR PEER REVIEW  \n13 of 22 \n \nFigure 6. Comparison of the Kcb values\
    \ calculated by using two methods in three different treatments: \nTRT 1 (a),\
    \ TRT 2 (b) and TRT 3 (c). The Kcb-NDVI values were retrieved from regression\
    \ model \n(Equations (10) and (11)) of Kcb vs. NDVI, and Kcb-Tab were calculated\
    \ by the modified FAO-56 \nmethod (Equations (4) and (5)).  \nKcb only accounts\
    \ for the potential evapotranspiration and the actual ET should be modified \n\
    with Ks for crops undergoing deficit-irrigation. Two Ks obtained by the water\
    \ stress indices CWSI \nand Tc ratio, which were calculated in turn by Tc, Ta,\
    \ and Tc NS derived from the measurements of the \nhandheld infrared thermometer,\
    \ were used to evaluate the effects of water deficit on crop ET. Figure \n7 shows\
    \ the daily values of irrigation/rainfall events and different Ks values from\
    \ various approaches \nfor TRT 1 (Figure 7a), TRT 2 (Figure 7b), and TRT 3 (Figure\
    \ 7c). The three Ks values increased after \ni i\ni\n/\ni f ll\nd d\nd\ni h\n\
    i i\ni\n/\ni f ll\ndi\nll\ni i\ni\n/\ni f ll\nFigure 6. Comparison of the Kcb\
    \ values calculated by using two methods in three diﬀerent treatments:\nTRT 1\
    \ (a), TRT 2 (b) and TRT 3 (c). The Kcb-NDVI values were retrieved from regression\
    \ model\n(Equations (10) and (11)) of Kcb vs. NDVI, and Kcb-Tab were calculated\
    \ by the modiﬁed FAO-56\nmethod (Equations (4) and (5)).\nRemote Sens. 2019, 11,\
    \ 2519\n13 of 22\nKcb only accounts for the potential evapotranspiration and the\
    \ actual ET should be modiﬁed\nwith Ks for crops undergoing deﬁcit-irrigation.\
    \ Two Ks obtained by the water stress indices CWSI\nand Tc ratio, which were calculated\
    \ in turn by Tc, Ta, and Tc NS derived from the measurements of the\nhandheld\
    \ infrared thermometer, were used to evaluate the eﬀects of water deﬁcit on crop\
    \ ET. Figure 7\nshows the daily values of irrigation/rainfall events and diﬀerent\
    \ Ks values from various approaches\nfor TRT 1 (Figure 7a), TRT 2 (Figure 7b),\
    \ and TRT 3 (Figure 7c). The three Ks values increased after\nirrigation/rainfall\
    \ and decreased with no irrigation/rainfall, responding well to irrigation/rainfall\
    \ events.\nThe Ks values for diﬀerent levels of deﬁcit irrigation in the reproductive\
    \ and maturation stages had\na clear numerical gradient. As TRT 1 was in the full\
    \ irrigation area, the Ks calculated by the soil\nwater content data (Equations\
    \ (5) and (6)) was equal to 1, but a considerable part of the Ks calculated\n\
    by the water stress indices was less than 1 (see Figure 7a). It is probable that\
    \ even a well-watered\ncrop could have a high canopy temperature because of very\
    \ hot day. TRT 2 presented the lowest\nKs values when compared with TRTs 1 and\
    \ 3. The averaged Ks-CWSI, Ks-Tc ratio, and Ks-FAO were\n0.94, 0.89, and 1 for\
    \ TRT 1; 0.72, 0.81, and 0.66 for TRT 2; and 0.91, 0.88, and 0.88 for TRT 3 (see\n\
    Table 3), respectively, indicating that TRTs 1 and 3 had less water stress than\
    \ TRT 2. The daily changes\nof Ks calculated by diﬀerent methods showed similar\
    \ patterns, as depicted in Figure 7, while the\nsensitivity of diﬀerent methods\
    \ to water deﬁcit was diﬀerent, and the speciﬁc values between the three\nmethods\
    \ displayed relatively large diﬀerences in this study. On the whole, Ks-CWSI and\
    \ Ks-FAO had\ngreater variability than Ks-Tc ratio under water stress conditions,\
    \ and the minimum Ks-FAO was as\nlow as 0.38, while Ks-Tc ratio was 0.63 in the\
    \ three treatments. Due to the drought resistance of crops,\na reduction of water\
    \ in the root zone does not immediately lead to crop stress. Thus, the canopy\n\
    temperature may be a more realistic parameter than soil water content to represent\
    \ the stress coeﬃcient\ndue to the complicated physiological processes that plants\
    \ undergo as they encounter water stress and\ncompensate for this stress.\n \n\
    \ \nFigure 6. Comparison of the Kcb values calculated by using two methods in\
    \ three different treatments: \nTRT 1 (a), TRT 2 (b) and TRT 3 (c). The Kcb-NDVI\
    \ values were retrieved from regression model \n(Equations (10) and (11)) of Kcb\
    \ vs. NDVI, and Kcb-Tab were calculated by the modified FAO-56 \nmethod (Equations\
    \ (4) and (5)).  \nKcb only accounts for the potential evapotranspiration and\
    \ the actual ET should be modified \nwith Ks for crops undergoing deficit-irrigation.\
    \ Two Ks obtained by the water stress indices CWSI \nand Tc ratio, which were\
    \ calculated in turn by Tc, Ta, and Tc NS derived from the measurements of the\
    \ \nhandheld infrared thermometer, were used to evaluate the effects of water\
    \ deficit on crop ET. Figure \n7 shows the daily values of irrigation/rainfall\
    \ events and different Ks values from various approaches \nfor TRT 1 (Figure 7a),\
    \ TRT 2 (Figure 7b), and TRT 3 (Figure 7c). The three Ks values increased after\
    \ \nirrigation/rainfall and decreased with no irrigation/rainfall, responding\
    \ well to irrigation/rainfall \nevents. The Ks values for different levels of\
    \ deficit irrigation in the reproductive and maturation \nstages had a clear numerical\
    \ gradient. As TRT 1 was in the full irrigation area, the Ks calculated by \n\
    the soil water content data (Equations (5) and (6)) was equal to 1, but a considerable\
    \ part of the Ks \ncalculated by the water stress indices was less than 1 (see\
    \ Figure 7a). It is probable that even a well-\nwatered crop could have a high\
    \ canopy temperature because of very hot day. TRT 2 presented the \nlowest Ks\
    \ values when compared with TRTs 1 and 3. The averaged Ks-CWSI, Ks-Tc ratio, and\
    \ Ks-FAO \nwere 0.94, 0.89, and 1 for TRT 1; 0.72, 0.81, and 0.66 for TRT 2; and\
    \ 0.91, 0.88, and 0.88 for TRT 3 (see \nTable 3), respectively, indicating that\
    \ TRTs 1 and 3 had less water stress than TRT 2. The daily changes \nof Ks calculated\
    \ by different methods showed similar patterns, as depicted in Figure 7, while\
    \ the \nsensitivity of different methods to water deficit was different, and the\
    \ specific values between the \nthree methods displayed relatively large differences\
    \ in this study. On the whole, Ks-CWSI and Ks-\nFAO had greater variability than\
    \ Ks-Tc ratio under water stress conditions, and the minimum Ks-FAO \nwas as low\
    \ as 0.38, while Ks-Tc ratio was 0.63 in the three treatments. Due to the drought\
    \ resistance of \ncrops, a reduction of water in the root zone does not immediately\
    \ lead to crop stress. Thus, the canopy \ntemperature may be a more realistic\
    \ parameter than soil water content to represent the stress \ncoefficient due\
    \ to the complicated physiological processes that plants undergo as they encounter\
    \ \nwater stress and compensate for this stress. \n \nFigure 7. Ks obtained by\
    \ using CWSI, Tc ratio, and soil moisture data for (a) TRT 1, (b) TRT 2, and (c)\
    \ \nTRT 3 from 6 to 29 August 2017. The depths (mm) of individual irrigation (I)\
    \ and precipitation (P) \nevents are plotted as vertical bars. \nTable 3. Mean\
    \ values of Ks-CWSI, Ks-Tc ratio, and Ks-FAO for each irrigation treatment from\
    \ 6 to 29 \nAugust 2017. \nFigure 7. Ks obtained by using CWSI, Tc ratio, and\
    \ soil moisture data for (a) TRT 1, (b) TRT 2, and (c) TRT\n3 from 6 to 29 August\
    \ 2017. The depths (mm) of individual irrigation (I) and precipitation (P) events\n\
    are plotted as vertical bars.\nTable 3. Mean values of Ks-CWSI, Ks-Tc ratio, and\
    \ Ks-FAO for each irrigation treatment from 6 to 29\nAugust 2017.\nTreatment\n\
    Ks-CWSI\nKs-Tc ratio\nKs-FAO\nTRT 1\n0.94\n0.89\n1\nTRT 2\n0.72\n0.81\n0.66\n\
    TRT 3\n0.90\n0.88\n0.88\n3.3. Model Selection for Estimating Crop ET\nMaize ET\
    \ for the three irrigation treatments during 6–29 August 2017 was calculated by\
    \ various\ntechniques. As the canopy temperature and soil water content (θ) acquisition\
    \ were in the period of\nhigh coverage, and two or three days after the irrigation\
    \ and precipitation. Thus, the minor inﬂuence of\nevaporation on total ET was\
    \ ignored. The derived ET from the combination of two water stress indices\nand\
    \ the combined NDVI-based Kcb (i.e., ET-CWSI and ET-ratio) were validated at the\
    \ ﬁeld scale using\nRemote Sens. 2019, 11, 2519\n14 of 22\nthe modiﬁed FAO-56\
    \ ET (ET-FAO) by using three performance measure criteria (i.e., coeﬃcient of\n\
    determination (R2), root mean square error (RMSE), and index of agreement (d)).\
    \ The value of d, which\nis presented in Figure 8a,b, was greater than 0.9 which\
    \ indicates that ET based on water stress had\na strong ﬁt for the ET-FAO. However,\
    \ ET-CWSI showed the least bias with an acceptable accuracy\nwith an R2 = 0.81\
    \ and RMSE of about 0.95 mm/day (NRMSE = 11.1%), while the ET-ratio had an\noverall\
    \ slightly lower correlation than the CWSI with a lower R2 = 0.68 and RMSE about\
    \ 1.26 mm/day\n(NRMSE = 14.6%). Thus, the validation results from the R2 and RMSE\
    \ viewpoints demonstrated that\nthe CWSI method was better than the Tc ratio and\
    \ could be used as a quantitative index to calculate\nmaize evapotranspiration\
    \ in this study.\n \nTRT 3 \n0.90  \n0.88  \n0.88 \n3.3. Model Selection for Estimating\
    \ Crop ET \nMaize ET for the three irrigation treatments during 6–29 August 2017\
    \ was calculated by various \ntechniques. As the canopy temperature and soil water\
    \ content (θ) acquisition were in the period of \nhigh coverage, and two or three\
    \ days after the irrigation and precipitation. Thus, the minor influence \nof\
    \ evaporation on total ET was ignored. The derived ET from the combination of\
    \ two water stress \nindices and the combined NDVI-based Kcb (i.e., ET-CWSI and\
    \ ET-ratio) were validated at the field \nscale using the modified FAO-56 ET (ET-FAO)\
    \ by using three performance measure criteria (i.e., \ncoefficient of determination\
    \ (R2), root mean square error (RMSE), and index of agreement (d)). The \nvalue\
    \ of d, which is presented in Figure 8a,b, was greater than 0.9 which indicates\
    \ that ET based on \nwater stress had a strong fit for the ET-FAO. However, ET-CWSI\
    \ showed the least bias with an \nacceptable accuracy with an R2 = 0.81 and RMSE\
    \ of about 0.95 mm/day (NRMSE = 11.1%), while the \nET-ratio had an overall slightly\
    \ lower correlation than the CWSI with a lower R2 = 0.68 and RMSE \nabout 1.26\
    \ mm/day (NRMSE = 14.6%). Thus, the validation results from the R2 and RMSE viewpoints\
    \ \ndemonstrated that the CWSI method was better than the Tc ratio and could be\
    \ used as a quantitative \nindex to calculate maize evapotranspiration in this\
    \ study.  \n \nFigure 8. Scatterplots of maize ET obtained by the modified FAO-56\
    \ dual crop coefficient method (ET-\nFAO) compared with (a) stress coefficient\
    \ CWSI (ET-CWSI), and (c) Tc ratio (ET-Tc ratio) methods in three \ntreatments.\
    \ Black dotted line is the 1:1 line from 6 to 29 August 2017. The regression relation,\
    \ \ncoefficient of determination (R2), root mean square error (RMSE), and index\
    \ of agreement (d) are also \nshown. \n3.4. Maize Evapotranspiration Maps Based\
    \ on UAV Multispectral Remote Sensing Imagery \nWe retrieved the maize evapotranspiration\
    \ map by combining the Ks map based on UAV \nTCARI/RDVI (Equation (15)) with the\
    \ Kcb map based on the NDVI, according to the FAO-56 dual \ncrop coefficient method.\
    \ Figure 9 and Table 4 show the results of ET on DOY 217, 221, 231, and 241 \n\
    during the reproductive and maturation stages. ET was seen to decrease with decreasing\
    \ irrigation \namong the three different irrigation levels. On DOY 217, the highest\
    \ value of ET in the study field \nreached approximately 8 mm because of the previous\
    \ day’s rainfall. In addition, different treatments \npresented similar mean ET\
    \ on DOY 217. On DOY 231 and 241, there were relatively less ET because \nFigure\
    \ 8. Scatterplots of ET obtained using two stress coeﬃcient methods vs. ET obtained\
    \ by modiﬁed\nFAO-56 dual crop coeﬃcient method in three treatments from 6 to\
    \ 29 August 2017. Methods include\nCWSI (a), Tc ratio (b). Black dotted line is\
    \ the 1:1 line. The regression relation, coeﬃcient of determination\n(R2), root\
    \ mean square error (RMSE), and index of agreement (d) are also shown.\n3.4. Maize\
    \ Evapotranspiration Maps Based on UAV Multispectral Remote Sensing Imagery\n\
    We retrieved the maize evapotranspiration map by combining the Ks map based on\
    \ UAV\nTCARI/RDVI (Equation (15)) with the Kcb map based on the NDVI, according\
    \ to the FAO-56 dual crop\ncoeﬃcient method. Figure 9 and Table 4 show the results\
    \ of ET on DOY 217, 221, 231, and 241 during\nthe reproductive and maturation\
    \ stages. ET was seen to decrease with decreasing irrigation among\nthe three\
    \ diﬀerent irrigation levels. On DOY 217, the highest value of ET in the study\
    \ ﬁeld reached\napproximately 8 mm because of the previous day’s rainfall. In\
    \ addition, diﬀerent treatments presented\nsimilar mean ET on DOY 217. On DOY\
    \ 231 and 241, there were relatively less ET because of higher\ntemperature and\
    \ less irrigation or rainfall, with maximum values of approximately 5 mm, and\
    \ 4 mm,\nrespectively. On DOY 221, 231 and 241, the minimum ET can be found in\
    \ TRT 2. In these three days,\nthe mean ET of TRT 2 was 5.72 mm, 4.23 mm and 1.33\
    \ mm, respectively. Especially on DOY 241, most\nof the maize was in a state of\
    \ almost no transpiration due to a long-term lack of irrigation/rainfall.\nRemote\
    \ Sens. 2019, 11, 2519\n15 of 22\n \nthe maize growth period in TRTs 2 and 3,\
    \ which illustrated that the prolonged water stress distinctly \ndetected spatial\
    \ fluctuations in field soil heterogeneity via its influences on maize evapotranspiration\
    \ \ncondition. For instance, in the deficit irrigation treatment TRTs 2 and 3,\
    \ CVs increased from 9% to \n34% and 8% to 18% with the accumulation of water\
    \ stress. On the other hand, a higher CV in TRT 2 \ndemonstrated that the dual\
    \ effect of soil heterogeneity and water stress could severely affect maize \n\
    ET. \n \nFigure 9. Maize evapotranspiration maps retrieved by combining CWSI-TCARI/RDVI\
    \ and Kcb-NDVI \nregression models (equation (14) and (15)). (a) and (b) are evapotranspiration\
    \ maps for the \nreproductive (DOY 217 and DOY221) stages. (c) and (d) are the\
    \ evapotranspiration maps for the \nmaturation (DOY 217 and DOY221) stages. \n\
    Table 4. Coefficient of variation (CV; %) and mean ET over each sample area under\
    \ different water \ntreatments on DOY 217, 221, 231, and 241. \nFigure 9. Maize\
    \ evapotranspiration maps retrieved by combining CWSI-TCARI/RDVI (Equation (14)\n\
    and (15)) and Kcb-NDVI (Equation (10) and (11)) regression models. (a) and (b)\
    \ are evapotranspiration\nmaps for the reproductive (DOY 217 and DOY221) stages.\
    \ (c) and (d) are the evapotranspiration maps\nfor the maturation (DOY231 and\
    \ DOY241) stages.\nTable 4. Coeﬃcient of variation (CV; %) and mean ET over each\
    \ sample area under diﬀerent water\ntreatments on DOY 217, 221, 231, and 241.\n\
    Time\nTRT 1\nTRT 2\nTRT 3\nMean (mm)\nCV (%)\nMean (mm)\nCV (%)\nMean (mm)\nCV\
    \ (%)\nDOY 217\n6.72\n10\n6.91\n8\n7.20\n8\nDOY 221\n6.41\n8\n5.72\n12\n6.68\n\
    7\nDOY 231\n5.05\n11\n4.23\n16\n4.94\n10\nDOY 241\n2.59\n13\n1.33\n34\n2.12\n\
    18\nThe diﬀerent soil texture and soil heterogeneity led to diﬀerent water, fertilizer,\
    \ gas, and heat\nconditions and diﬀerent crop growth status. We could even observe\
    \ the diﬀerences of ET in the\nsame treatment through the high spatial resolution\
    \ (4.7 cm) multispectral images. Table 4 shows the\ntreatment values of CV (coeﬃcient\
    \ of variation) and mean ET. The diﬀerent water treatments in spatial\nvariations\
    \ of ﬁeld ET capacity from the reproductive to maturation stage were distinct.\
    \ On the whole,\nCV increased with decreased ET and increased water stress. In\
    \ addition, CV increased over the maize\ngrowth period in TRTs 2 and 3, which\
    \ illustrated that the prolonged water stress distinctly detected\nspatial ﬂuctuations\
    \ in ﬁeld soil heterogeneity via its inﬂuences on maize evapotranspiration condition.\n\
    For instance, in the deﬁcit irrigation treatment TRTs 2 and 3, CVs increased from\
    \ 9% to 34% and 8% to\nRemote Sens. 2019, 11, 2519\n16 of 22\n18% with the accumulation\
    \ of water stress. On the other hand, a higher CV in TRT 2 demonstrated that\n\
    the dual eﬀect of soil heterogeneity and water stress could severely aﬀect maize\
    \ ET.\nNext, the cumulative daily values of ET from 6 to 29 August 2017 for the\
    \ three irrigation treatments\nwere calculated by two techniques. (1) The VIs\
    \ (the average value of the entire treatment zone) method,\nwhere daily crop water\
    \ requirement (ET) was calculated by multiplying the daily crop coeﬃcients of\n\
    daily ET0 (Equation (1)). As above-mentioned, crop coeﬃcients were derived through\
    \ the relationships\nbetween Kcb and NDVI, and between Ks and TRCAI/RDVI. In addition,\
    \ a cubic interpolation was\nused to determine the values of VIs (NDVI, TRCAI,\
    \ and RDVI) between two UAV ﬂights. (2) The water\nbalance approach (Equation\
    \ (18)). As presented in Table 5, the total water consumption of the three\ntreatments\
    \ for the study period were 75 mm, 53 mm, and 67 mm, respectively. The diﬀerence\
    \ between\nthe cumulative ET calculated by the VIs method and water balance approach\
    \ were 2.6 mm, 8.9 mm,\nand 5 mm, respectively. Note that the retrieved ET were\
    \ similar to the crop water consumption.\nTable 5. Cumulative ET from the 6–29\
    \ August 2017 investigative period calculated by the VI (vegetation\nindex) method\
    \ and water balance approach for the three irrigation treatments.\nTreatment\n\
    VIs (mm)\nWB (mm)\nTRT1\n72.4\n75\nTRT2\n61.9\n53\nTRT3\n72\n67\n4. Discussion\n\
    Daily ET represents the most important process for the determination of the surface\
    \ and\nmass-energy interaction for both water resource management and agricultural\
    \ practices. At present,\nthere are mainly two types of models for ET assessment.\
    \ The ﬁrst involves models using thermal band\nbased energy-balance approaches\
    \ (SEB) [59,60]. The second method utilizes the empirical VI model.\nThough the\
    \ surface energy balance models are able to estimate ET with ﬁne accuracy. Deﬁciencies\n\
    in the current suite of thermal data sources (e.g., plenty of data requirements,\
    \ biases, inaccurate\ncalibration, poor spatial or temporal resolution) can strongly\
    \ limit the applicability of such procedures\nfor the continuous monitoring of\
    \ ET at a high spatiotemporal resolution [61]. Due to the longstanding\nfamiliarity\
    \ and widespread use within the irrigation community of crop coeﬃcient approaches\
    \ and\ntheir relative operational simplicity, reﬂectance-based crop coeﬃcients\
    \ might elicit a successful and\nfar-reaching approach for improving irrigation\
    \ management [12]. Multispectral VIs calculated from\ncanopy reﬂectance can be\
    \ used to simulate real-time Kcb. Figure 6 shows that there was a strong\nsimilarity\
    \ between the Kcb-NDVI and Kcb-Table. With the help of UAVs, we can provide more\n\
    sophisticated Kcb information for irrigation management. Studies [29,62] showed\
    \ that the VI-Kcb\nmodel can perform well under well irrigation conditions, but\
    \ that it could be diﬃcult to capture actual\nET under the water stress condition.\
    \ Water stress evaluation (Ks) based on soil water storage in the root\nzone is\
    \ the traditional and common method, but is costly and there is a shortage of\
    \ representation. For\ninstance, Er-Raki et al. [29] reported that the original\
    \ FAO-56 model may overestimate eddy covariance\nmeasurements because of the misrepresentation\
    \ of the soil stress factor.\nTo deal with these defects, Ks estimation is mainly\
    \ divided into direct and indirect methods. In\nindirect methods, they usually\
    \ need to ﬁrst obtain the potential ET (PET) and actual ET, and then\ncalculate\
    \ Ks through the soil–water balance. It is diﬃcult to obtain the actual ET because\
    \ sophisticated\nand costly instruments such as eddy covariance and lysimeters\
    \ are generally limited. On the other\nhand, estimating Ks through the indirect\
    \ method is not only laborious, but is also not time-eﬀective.\nDiarra et al.\
    \ [63] highlighted the uncertainty of indirect assessment in detecting crop water\
    \ stress in\nlight of the decision making process for irrigation planning. Therefore,\
    \ the direct calculation of Ks\nis very important for the application of the FAO-56\
    \ dual Kc method. Some studies have employed\nwater stress indices derived from\
    \ temperature data as the proxy. For instance, Kullberg et al. [33] used\nfour\
    \ canopy temperature–based methods (CWSI, degrees above non-stressed (DANS), degrees\
    \ above\nRemote Sens. 2019, 11, 2519\n17 of 22\ncanopy threshold (DACT), and Tc\
    \ ratio derived from infrared thermal radiometer) to calculate Ks and\nestimate\
    \ ET in a deﬁcit irrigation experiment of corn. A similar observation was made\
    \ by this study\nwhen estimating Ks for maize with the CWSI. Figure 9 shows that\
    \ the Ks derived CWSI was useful to\nestimate ET, with an acceptable accuracy\
    \ of R2 = 0.81 and RMSE about 0.95 mm/day when compared\nwith the modiﬁed FAO-56\
    \ Kc method. Bausch et al. [35] also obtained similar results using Tc ratio.\
    \ The\napplicability of the water stress index may be diﬀerent in diﬀerent areas\
    \ and cultivation conditions,\nso it is necessary to choose the local appropriate\
    \ water stress index. Furthermore, the water stress\nindices based on canopy temperature\
    \ may be a more realistic parameter than soil–water content to\nrepresent the\
    \ stress coeﬃcient due to the complicated physiological processes that plants\
    \ undergo as\nthey encounter water stress [35]. In Figure 7, we can see that the\
    \ Ks values calculated by CWSI are\nnot 1, as are the FAO-56 Ks in full-irrigation\
    \ TRT 1. It is probable that even a well-watered crop could\nhave a high canopy\
    \ temperature because of other changes in microclimate such as air temperature\n\
    and vapor pressure deﬁcit (VPD) [64]. The change in the air temperature surrounding\
    \ the leaf will\nchange the leaf temperature and directly aﬀect the gradient of\
    \ water vapor between the leaf and the\natmosphere. Water deﬁcit stress and heat\
    \ stress may be induced by changes in available water, VPD,\nand increased ambient\
    \ air temperature [65].\nStationary infrared thermometers were mainly used for\
    \ validating the relationship between water\nstress indictors and Ks [33,35],\
    \ which can be greatly constrained by transport and operator costs and it\ncan\
    \ be diﬃcult to obtain large area images of crop. These shortcomings may cause\
    \ signiﬁcant errors\ndue to the diﬃculty of achieving a spatially-homogenous,\
    \ targeted soil, or plant water status. More\nimportantly, it is diﬃcult to obtain\
    \ Kcb and Ks on a large area at the same time. Kcb and Ks from\ndiﬀerent platforms\
    \ and scales will inevitably lead to errors in estimating ET, especially with\
    \ the high\nheterogeneities of soil and crops. Several studies [36,66,67] have\
    \ revealed the feasibility of mapping\ncrop water conditions using spectral vegetation\
    \ indices, taking advantage of the high spatial resolution\ncapabilities that\
    \ are more diﬃcult in the thermal region. The RDVI and TCARI were developed\n\
    to reduce the variability of the photosynthetically active radiation due to the\
    \ presence of diverse\nnon-photosynthetic materials and are useful in plant stress\
    \ monitoring to capture the changes in canopy\nstructures caused by water stress\
    \ [36,68]. Compared to the Ks calculated by on-site measurements, the\nKs based\
    \ on VI-Ks regression models could better reﬂect the water stress conditions of\
    \ maize at the\nﬁeld scale. Taking DOY 231 as an example, the mean ET could well\
    \ reﬂect TRT 2 (69%) and TRT 1\n(100%) in the reproductive stage, with the corresponding\
    \ values of 5.05 mm and 4.23 mm, respectively.\nTable 5 conﬁrmed the utility of\
    \ VIs to help constrain the ET components under three diﬀerent water\ntreatments.\
    \ Cumulative estimated ET diﬀered from the observed by only 2.6 mm, 8.9 mm, and\
    \ 5 mm\nfor TRTs 1, 2, and 3, respectively. The result during the 24-day investigative\
    \ period conﬁrmed that\nthe model may be suitable for clearly distinguishing the\
    \ diﬀerent irrigation schemes. In addition, we\ncould obtain accurate ET only\
    \ through the meteorological and UAV multispectral images.\nPrevious studies have\
    \ reported on combining the FAO-56 Kc model with Landsat [13,57,69],\nSPOT [25,70],\
    \ and Sentinel 2 [71] data to estimate the crop coeﬃcient and map crop water consumption.\n\
    However, with satellite remote sensing, a pixel represents a large area. It is\
    \ diﬃcult to observe the\nvariability in crop status on the ﬁeld scale and to\
    \ formulate precise irrigation plans. In addition, newly\nhigher resolution observation\
    \ platforms may be too costly for crop monitoring. In contrast, UAVs\ncan monitor\
    \ ﬁeld ET information scale up information from the leaf to canopy/ﬁeld levels\
    \ and maybe\nsuitable technology for actual problem scouting within the ﬁeld scale.\
    \ From the ET maps (Figure 9), we\ncan observe that the evapotranspiration of\
    \ crops varied even with the same treatment. Table 4 shows\nthe mean and CV values\
    \ of diﬀerent treatments due to the diﬀerent soil texture and soil heterogeneity\n\
    in the ﬁeld. Explicitly, because of the dual eﬀect of soil heterogeneity and water\
    \ stress, the CV of\nET reached 34% on DOY 241. Acquiring such data for planning\
    \ is probably the role most people\nenvisage when they think of UAV remote sensing\
    \ for precision agriculture. For example, Shi et al. [72]\nproposed a decision\
    \ support system for variable rate irrigation through ﬁeld ET maps acquired by\n\
    multispectral UAV images, which were inputs to the fuzzy inference system and\
    \ were successful in\nRemote Sens. 2019, 11, 2519\n18 of 22\nproviding a duty-cycle\
    \ control map for a central pivot variable rate irrigation system. Compared with\n\
    satellite remote sensing data, using UAV for ﬁeld information management has unique\
    \ advantages,\nbut there are still challenges in its application. UAV remote sensing\
    \ images usually need to be acquired\non-site by researchers, which may lead to\
    \ problems if the research area is remote and diﬃcult to reach,\nand the UAV cannot\
    \ take long-distance photographs due to battery power limitations, so there are\n\
    certain limitations in wider-range crop monitoring. Moreover, using UAVs for planning\
    \ has high costs\nfor data acquisition and analysis. To make monitoring economically\
    \ worthwhile for farmers, new\nmethods of analysis are needed to bring costs down.\
    \ Even so, UAV technology is now available to give\nfarmers the data products\
    \ they have long been requesting from remote sensing [73]. In sum, this study\n\
    demonstrates the feasibility of mapping maize crop ET under the water stress condition\
    \ and monitor\nits spatial variability at a ﬁeld scale by using UAV-based VI-Kcb\
    \ and VI-Ks regression models.\n5. Conclusions\nAs the most widely used approach\
    \ for calculating crop evapotranspiration (ET), the FAO-56 dual\nKc method has\
    \ been increasingly used and improved with remote sensing data. However, the accurate\n\
    estimation of the temporal and spatial variability of crop ET within the ﬁeld\
    \ scale is still a challenge,\nespecially when water stress occurs. To better\
    \ monitor water requirements under water stress and\nprovide a simpler and more\
    \ maneuverable method for farming practices, this study investigated\nwhether\
    \ an UAV-based multispectral remote sensing system could map the evapotranspiration\
    \ of\nmaize under diﬀerent levels of deﬁcit irrigation at the ﬁeld scale as a\
    \ supplement to the dual crop\ncoeﬃcient model. We conﬁrmed that CWSI can be a\
    \ better index assimilated into local maize ET\nestimation under deﬁcit irrigation.\
    \ The comparison results show that the ET derived from Ks-CWSI\nhad a higher correlation\
    \ with the modiﬁed FAO-56 Kc method, with a coeﬃcient of determination\nvalue\
    \ of 0.81, root mean square error value of 0.96 mm/d, and index of agreement value\
    \ of 0.94. Based\non which, a stable relationship between VIs and crop coeﬃcients\
    \ (Kcb and Ks) can be assimilated\ninto the FAO-56 dual Kc method for ﬁeld maize\
    \ ET estimation. Thanks to the UAV system, we could\nobtain high-resolution images\
    \ with higher frequencies for ﬁner irrigation management. In summary,\nthis study\
    \ demonstrates the feasibility of mapping maize crop evapotranspiration and monitoring\
    \ its\nspatial variability within the ﬁeld scale by using UAV-based multispectral\
    \ images under the water\nstress condition. Future experiments will incorporate\
    \ the ground validation (eddy covariance or\nlysimeter) of ET to provide an independent\
    \ assessment of model accuracy and use more convenient\nand reliable water stress\
    \ indices to evaluate crop stress and quantify crop evapotranspiration over a\n\
    longer crop growth period.\nAuthor Contributions: Conceptualization, J.T. and\
    \ W.H.; methodology, J.T. and L.Z.; software, J.T.; validation,\nW.H.; formal\
    \ analysis, J.T.; investigation, J.T. and L.Z.; writing—original draft preparation,\
    \ J.T.; writing—review\nand editing, L.Z.; visualization, J.T.; supervision, W.H;\
    \ project administration, W.H.; funding acquisition, W.H.; All\nauthors read and\
    \ approved the ﬁnal version.\nFunding: This study was supported by the 13th Five-Year\
    \ Plan for the Chinese National Key R&D Project\n(2017YFC0403203), the 111 Project\
    \ (No. B12007) and the Major Project of Industry–Education–Research Cooperative\n\
    Innovation in Yangling Demonstration Zone in China (2018CXY-23).\nAcknowledgments:\
    \ We are grateful to Guomin Shao for the data collection.\nConﬂicts of Interest:\
    \ The authors declare no conﬂicts of interest.\nReferences\n1.\nBelaqziz, S.;\
    \ Khabba, S.; Er-Raki, S.; Jarlan, L.; Le Page, M.; Kharrou, M.H.; Adnani, M.E.;\
    \ Chehbouni, A. A\nnew irrigation priority index based on remote sensing data\
    \ for assessing the networks irrigation scheduling.\nAgric. Water Manag. 2013,\
    \ 119, 1–9. [CrossRef]\n2.\nXu, X.; Zhang, M.; Li, J.; Liu, Z.; Zhao, Z.; Zhang,\
    \ Y.; Zhou, S.; Wang, Z. Improving water use eﬃciency and\ngrain yield of winter\
    \ wheat by optimizing irrigations in the North China Plain. Field Crops Res. 2018,\
    \ 221,\n219–227. [CrossRef]\nRemote Sens. 2019, 11, 2519\n19 of 22\n3.\nFerreira,\
    \ M. Stress Coeﬃcients for Soil Water Balance Combined with Water Stress Indicators\
    \ for Irrigation\nScheduling of Woody Crops. Horticulturae 2017, 3. [CrossRef]\n\
    4.\nAllen, R.G.; Pereira, L.S.; Howell, T.A.; Jensen, M.E. Evapotranspiration\
    \ information reporting: I. Factors\ngoverning measurement accuracy. Agric. Water\
    \ Manag. 2011, 98, 899–920. [CrossRef]\n5.\nDe Oliveira, L.A.; Casaroli, D.; Junior,\
    \ J.A.; Pego Evangelista, A.W. Evapotranspiration: A scientometric\nanalysis.\
    \ Cientiﬁca 2019, 47, 8–14. [CrossRef]\n6.\nAllen, R.; Pereira, L.; Raes, D.;\
    \ Smith, M. FAO Irrigation and drainage paper No. 56. Rome Food Agric. Organ.\n\
    U. N. 1998, 56, 26–40.\n7.\nPereira, L.; Allen, R.; Smith, M.; Raes, D. Crop evapotranspiration\
    \ estimation with FAO56: Past and future.\nAgric. Water Manag. 2015, 147, 4–20.\
    \ [CrossRef]\n8.\nKilic, A.; Allen, R.; Kjaersgaard, J.; Huntington, J.; Kamble,\
    \ B.; Trezza, R.; Ratcliﬀe, I. Operational Remote\nSensing of ET and Challenges.\
    \ Evapotranspiration—Remote Sens. Model. 2012. [CrossRef]\n9.\nGontia, N.K.; Tiwari,\
    \ K.N. Estimation of Crop Coeﬃcient and Evapotranspiration of Wheat (Triticum\
    \ aestivum)\nin an Irrigation Command Using Remote Sensing and GIS. Water Resour.\
    \ Manag. 2009, 24, 1399–1414.\n[CrossRef]\n10.\nBezerra, B.G.; Da Silva, B.B.;\
    \ Bezerra, J.R.C.; Soﬁatti, V.; Dos Santos, C.A.C. Evapotranspiration and crop\n\
    coeﬃcient for sprinkler-irrigated cotton crop in Apodi Plateau semiarid lands\
    \ of Brazil. Agric. Water Manag.\n2012, 107, 86–93. [CrossRef]\n11.\nBausch, W.C.;\
    \ Neale, C. Crop Coeﬃcients Derived from Reﬂected Canopy Radiation: A Concept.\
    \ Trans.\nASAE 1987, 30, 703–709. [CrossRef]\n12.\nHunsaker, D.; Barnes, E.; Clarke,\
    \ T.R.; Fitzgerald, G.; Pinter, P.J., Jr. Cotton irrigation scheduling using\n\
    remotely sensed and FAO-S6 basal crop coeﬃcients. Trans. ASAE 2005, 48, 1395–1407.\
    \ [CrossRef]\n13.\nCampos, I.; Balbontín, C.; González-Piqueras, J.; González-Dugo,\
    \ M.P.; Neale, C.M.U.; Calera, A. Combining\na water balance model with evapotranspiration\
    \ measurements to estimate total available soil water in\nirrigated and rainfed\
    \ vineyards. Agric. Water Manag. 2016, 165, 141–152. [CrossRef]\n14.\nSadler,\
    \ E.J.; Bauer, P.J.; Busscher, W.J. Site-Speciﬁc Analysis of a Droughted Corn\
    \ Crop: I. Growth and Grain\nYield. Agron. J. 2000, 92, 395–402. [CrossRef]\n\
    15.\nCampos, I.; Neale, C.M.U.; Calera, A.; Balbontín, C.; González-Piqueras,\
    \ J. Assessing satellite-based basal\ncrop coeﬃcients for irrigated grapes (Vitis\
    \ vinifera L.). Agric. Water Manag. 2010, 98, 45–54. [CrossRef]\n16.\nEr-Raki,\
    \ S.; Chehbouni, A.; Guemouria, N.; Duchemin, B.; Ezzahar, J.; Hadria, R. Combining\
    \ FAO-56 model\nand ground-based remote sensing to estimate water consumptions\
    \ of wheat crops in a semi-arid region.\nAgric. Water Manag. 2007, 87, 41–54.\
    \ [CrossRef]\n17.\nChoudhury, B.; Ahmed, N.; Idso, S.; Reginato, R.; Daughtry,\
    \ C. Relations between evaporation coeﬃcients\nand vegetation indices studied\
    \ by model simulations. Remote Sens. Environ 1994, 50, 1–17. [CrossRef]\n18.\n\
    Hunsaker, D.J.; Pinter, P.J.; Kimball, B.A. Wheat basal crop coeﬃcients determined\
    \ by normalized diﬀerence\nvegetation index. Irrig. Sci. 2005, 24, 1–14. [CrossRef]\n\
    19.\nBellvert, J.; Adeline, K.; Baram, S.; Pierce, L.; Sanden, B.; Smart, D. Monitoring\
    \ Crop Evapotranspiration\nand Crop Coeﬃcients over an Almond and Pistachio Orchard\
    \ Throughout Remote Sensing. Remote Sens.\n2018, 10. [CrossRef]\n20.\nMulla, D.J.\
    \ Twenty ﬁve years of remote sensing in precision agriculture: Key advances and\
    \ remaining\nknowledge gaps. Biosyst. Eng. 2013, 114, 358–371. [CrossRef]\n21.\n\
    Anderson, K.; Gaston, K.J. Lightweight unmanned aerial vehicles will revolutionize\
    \ spatial ecology. Front.\nEcol. Environ. 2013, 11, 138–146. [CrossRef]\n22.\n\
    Zhang, C.; Walters, D.; Kovacs, J.M. Applications of Low Altitude Remote Sensing\
    \ in Agriculture upon\nFarmers’ Requests—A Case Study in Northeastern Ontario,\
    \ Canada. PLoS ONE 2014, 9, e112894. [CrossRef]\n[PubMed]\n23.\nZhang, C.; Kovacs,\
    \ J.M. The application of small unmanned aerial systems for precision agriculture:\
    \ A review.\nPrecis. Agric. 2012, 13, 693–712. [CrossRef]\n24.\nGago, J.; Douthe,\
    \ C.; Coopman, R.E.; Gallego, P.P.; Ribas-Carbo, M.; Flexas, J.; Escalona, J.;\
    \ Medrano, H. UAVs\nchallenge to assess water stress for sustainable agriculture.\
    \ Agric. Water Manag. 2015, 153, 9–19. [CrossRef]\n25.\nEr-Raki, S.; Chehbouni,\
    \ A.; Duchemin, B. Combining Satellite Remote Sensing Data with the FAO-56 Dual\n\
    Approach for Water Use Mapping In Irrigated Wheat Fields of a Semi-Arid Region.\
    \ Remote Sens. 2010, 2.\n[CrossRef]\nRemote Sens. 2019, 11, 2519\n20 of 22\n26.\n\
    Allan, R.G.; Pereira, L.; Raes, D.; Smith, M. Crop evapotranspiration-Guidelines\
    \ for computing crop water\nrequirements-FAO Irrigation and drainage paper 56.\
    \ Fao Rome 1998, 300, D05109.\n27.\nTasumi, M.; Allen, R.G.A.; Duchemin, B. Satellite-based\
    \ ET mapping to assess variation in ET with timing of\ncrop development. Agric.\
    \ Water Manag. 2007, 88, 54–62. [CrossRef]\n28.\nHan, W.; Shao, G.; Ma, D.; Zhang,\
    \ H.; Wang, Y.; Niu, Y. Estimating Method of Crop Coeﬃcient of Maize\nBased on\
    \ UAV Multispectral Remote Sensing. Nongye Jixie Xuebao/Trans. Chin. Soc. Agric.\
    \ Mach. 2018, 49,\n134–143. [CrossRef]\n29.\nEr-Raki, S.; Chehbouni, A.; Hoedjes,\
    \ J.; Ezzahar, J.; Duchemin, B.; Jacob, F. Improvement of FAO-56 method\nfor olive\
    \ orchards through sequential assimilation of thermal infrared-based estimates\
    \ of ET. Agric. Water\nManag. 2008, 95, 309–321. [CrossRef]\n30.\nJackson, R.D.;\
    \ Idso, S.B.R.J.; Reginato, R.J.; Pinter, P. Canopy Temperature as a Crop Water\
    \ Stress Indicator.\nWater Resour. Res. 1981, 17, 1133–1138. [CrossRef]\n31.\n\
    Li, L.; Nielsen, D.C.; Yu, Q.; Ma, L.; Ahuja, L. Evaluating the Crop Water Stress\
    \ Index and its correlation with\nlatent heat and CO2 ﬂuxes over winter wheat\
    \ and maize in the North China plain. Agric. Water Manag. 2010,\n97, 1146–1155.\
    \ [CrossRef]\n32.\nOlivera-Guerra, L.; Merlin, O.; Er-Raki, S.; Khabba, S.; Escorihuela,\
    \ M.J. Estimating the water budget\ncomponents of irrigated crops: Combining the\
    \ FAO-56 dual crop coeﬃcient with surface temperature and\nvegetation index data.\
    \ Agric. Water Manag. 2018, 208, 120–131. [CrossRef]\n33.\nKullberg, E.G.; DeJonge,\
    \ K.C.; Chávez, J.L. Evaluation of thermal remote sensing indices to estimate\
    \ crop\nevapotranspiration coeﬃcients. Agric. Water Manag. 2017, 179, 64–73. [CrossRef]\n\
    34.\nDeJonge, K.C.; Taghvaeian, S.; Trout, T.J.; Comas, L.H. Comparison of canopy\
    \ temperature-based water\nstress indices for maize. Agric. Water Manag. 2015,\
    \ 156, 51–62. [CrossRef]\n35.\nBausch, W.; Trout, T.; Buchleiter, G. Evapotranspiration\
    \ adjustments for deﬁcit-irrigated corn using canopy\ntemperature: A concept.\
    \ Irrig. Drain. 2011, 60, 682–693. [CrossRef]\n36.\nIhuoma, S.O.; Madramootoo,\
    \ C.A. Recent advances in crop water stress detection. Comput. Electron. Agric.\n\
    2017, 141, 267–275. [CrossRef]\n37.\nBaluja, J.; Diago, M.P.; Balda, P.; Zorer,\
    \ R.; Meggio, F.; Morales, F.; Tardaguila, J. Assessment of vineyard\nwater status\
    \ variability by thermal and multispectral imagery using an unmanned aerial vehicle\
    \ (UAV). Irrig.\nSci. 2012, 30, 511–522. [CrossRef]\n38.\nRoujean, J.-L.; Breon,\
    \ F.-M. Estimating PAR absorbed by vegetation from bidirectional reﬂectance\n\
    measurements. Remote Sens. Environ. 1995, 51, 375–384. [CrossRef]\n39.\nZhang,\
    \ L.; Zhang, H.; Niu, Y.; Han, W. Mapping Maize Water Stress Based on UAV Multispectral\
    \ Remote\nSensing. Remote Sens. 2019, 11. [CrossRef]\n40.\nHeermann, D.F.; Hein,\
    \ P.R. Performance characteristics of self-propelled center-pivot sprinkler irrigation\n\
    system. Trans. ASAE 1968, 11, 11–15.\n41.\nZhao, N.-N.; Liu, Y.; Cai, J.-B. Calculation\
    \ of crop coeﬃcient and water consumption of summer maize. Shuili\nXuebao/J. Hydraul.\
    \ Eng. 2010, 41, 953–959.\n42.\nDing, R.; Kang, S.; Zhang, Y.; Hao, X.; Tong,\
    \ L.; Du, T. Partitioning evapotranspiration into soil evaporation\nand transpiration\
    \ using a modiﬁed dual crop coeﬃcient model in irrigated maize ﬁeld with ground-mulching.\n\
    Agric. Water Manag. 2013, 127, 85–96. [CrossRef]\n43.\nLv, Y.; Li, B. Soil Science;\
    \ China Agriculture Press: Beijing, China, 2006.\n44.\nReynolds, S.G. The gravimetric\
    \ method of soil moisture determination Part I A study of equipment, and\nmethodological\
    \ problems. J. Hydrol. 1970, 11, 258–273. [CrossRef]\n45.\nIdso, S.; Jackson,\
    \ R.; Ehrler, W.; Mitchell, S. A Method for Determination of Infrared Emittance\
    \ of Leaves.\nEcology 1969, 50, 899. [CrossRef]\n46.\nAllen, R. Using the FAO-56\
    \ dual crop coeﬃcient method over an irrigated region as part of an\nevapotranspiration\
    \ intercomparison study. J. Hydrol. 2000, 229, 27–41. [CrossRef]\n47.\nGonzález-Dugo,\
    \ M.P.; Mateos, L. Spectral vegetation indices for benchmarking water productivity\
    \ of irrigated\ncotton and sugarbeet crops. Agric. Water Manag. 2008, 95, 48–58.\
    \ [CrossRef]\n48.\nFeng, Y.; Cui, N.; Gong, D.; Wang, H.; Hao, W.; Mei, X. Estimating\
    \ rainfed spring maize evapotranspiration\nusing modiﬁed dual crop coeﬃcient approach\
    \ based on leaf area index. Nongye Gongcheng Xuebao/Trans.\nChin. Soc. Agric.\
    \ Eng. 2016, 32, 90–98. [CrossRef]\nRemote Sens. 2019, 11, 2519\n21 of 22\n49.\n\
    Jensen, M.; Allen, R. Evaporation, Evapotranspiration, and Irrigation Water Requirements;\
    \ American Society of\nCivil Engineers: Reston, WV, USA, 2016; Volume 2016, pp.\
    \ 1–744.\n50.\nRouse, J.W. Monitoring vegetation systems in the great plains with\
    \ ERTS. In Proceedings of the Third ERTS\nSymposium, NASA, Washington, DC, USA,\
    \ 10–14 December 1973; Volume 1, pp. 309–317.\n51.\nHaboudane, D. Integrated narrow-band\
    \ vegetation indices for prediction of crop chlorophyll content for\napplication\
    \ to precision agriculture. Remote Sens. Environ. 2002, 81, 416–426. [CrossRef]\n\
    52.\nZarco-Tejada, P.J.; González-Dugo, V.; Williams, L.E.; Suárez, L.; Berni,\
    \ J.A.; Goldhamer, D.; Fereres, E.\nA PRI-based water stress index combining structural\
    \ and chlorophyll eﬀects: Assessment using diurnal\nnarrow-band airborne imagery\
    \ and the CWSI thermal index. Remote Sens. Environ. 2013, 138, 38–50.\n[CrossRef]\n\
    53.\nTrout, T.; Johnson, L.; Gartung, J. Remote Sensing of Canopy Cover in Horticultural\
    \ Crops. HortScience\n2008, 43. [CrossRef]\n54.\nJohnson, L.F.; Trout, T.J. Satellite\
    \ NDVI Assisted Monitoring of Vegetable Crop Evapotranspiration in\nCalifornia’s\
    \ San Joaquin Valley. Remote Sens. 2012, 4. [CrossRef]\n55.\nIdso, S.B.; Jackson,\
    \ R.D.; Pinter, P.J.; Reginato, R.J.; Hatﬁeld, J.L. Normalizing the stress-degree-day\
    \ parameter\nfor environmental variability. Agric. Meteorol. 1981, 24, 45–55.\
    \ [CrossRef]\n56.\nElnmer, A.; Khadr, M.; Kanae, S.; Tawﬁk, A. Mapping daily and\
    \ seasonally evapotranspiration using remote\nsensing techniques over the Nile\
    \ delta. Agric. Water Manag. 2019, 213, 682–692. [CrossRef]\n57.\nFrench, N.A.;\
    \ Hunsaker, J.D.; Bounoua, L.; Karnieli, A.; Luckett, E.W.; Strand, R. Remote\
    \ Sensing of\nEvapotranspiration over the Central Arizona Irrigation and Drainage\
    \ District, USA. Agronomy 2018, 8.\n[CrossRef]\n58.\nRana, G.; Katerji, N. Measurement\
    \ and estimation of actual evapotranspiration in the ﬁeld under\nMediterranean\
    \ climate: A review. Eur. J. Agron. 2000, 13, 125–153. [CrossRef]\n59.\nBastiaanssen,\
    \ W.G.M.; Menenti, M.; Feddes, R.A.; Holtslag, A.A.M. A remote sensing surface\
    \ energy balance\nalgorithm for land (SEBAL). 1. Formulation. J. Hydrol. 1998,\
    \ 212, 198–212. [CrossRef]\n60.\nNorman, J.M.; Kustas, W.P.; Humes, K.S. Source\
    \ approach for estimating soil and vegetation energy ﬂuxes\nin observations of\
    \ directional radiometric surface temperature. Agric. For. Meteorol. 1995, 77,\
    \ 263–293.\n[CrossRef]\n61.\nCammalleri, C.; Anderson, M.C.; Gao, F.; Hain, C.R.;\
    \ Kustas, W.P. Mapping daily evapotranspiration at ﬁeld\nscales over rainfed and\
    \ irrigated agricultural areas using remote sensing data fusion. Agric. For. Meteorol.\n\
    2014, 186, 1–11. [CrossRef]\n62.\nGlenn, E.; Neale, C.; Hunsaker, D.; Nagler,\
    \ P. Vegetation Index-Based Crop Coeﬃcients to Estimate\nEvapotranspiration by\
    \ Remote Sensing in Agricultural and Natural Ecosystems. Hydrol. Process. 2011,\
    \ 25,\n4050–4062. [CrossRef]\n63.\nDiarra, A.; Jarlan, L.; Er-Raki, S.; Le Page,\
    \ M.; Aouade, G.; Tavernier, A.; Boulet, G.; Ezzahar, J.;\nMerlin, O.; Khabba,\
    \ S. Performance of the two-source energy budget (TSEB) model for the monitoring\
    \ of\nevapotranspiration over irrigated annual crops in North Africa. Agric. Water\
    \ Manag. 2017, 193, 71–88.\n[CrossRef]\n64.\nAllen, L.H.; Pan, D.; Boote, K.J.;\
    \ Pickering, N.B.; Jones, J.W. Carbon Dioxide and Temperature Eﬀects on\nEvapotranspiration\
    \ and Water Use Eﬃciency of Soybean. Agron. J. 2003, 95, 1071–1081. [CrossRef]\n\
    65.\nHatﬁeld, J.L.; Dold, C. Water-Use Eﬃciency: Advances and Challenges in a\
    \ Changing Climate. Front. Plant\nSci. 2019, 10, 103. [CrossRef]\n66.\nBehmann,\
    \ J.; Steinrücken, J.; Plümer, L. Detection of early plant stress responses in\
    \ hyperspectral images.\nISPRS J. Photogramm. Remote Sens. 2014, 93, 98–111. [CrossRef]\n\
    67.\nWang, X.; Zhao, C.; Guo, N.; Li, Y.; Jian, S.; Yu, K. Determining the Canopy\
    \ Water Stress for Spring Wheat\nUsing Canopy Hyperspectral Reﬂectance Data in\
    \ Loess Plateau Semiarid Regions. Spectrosc. Lett. 2015, 48,\n492–498. [CrossRef]\n\
    68.\nZarco-Tejada, P.J.; González-Dugo, V.; Berni, J.A.J. Fluorescence, temperature\
    \ and narrow-band indices\nacquired from a UAV platform for water stress detection\
    \ using a micro-hyperspectral imager and a thermal\ncamera. Remote Sens. Environ.\
    \ 2012, 117, 322–337. [CrossRef]\n69.\nMokhtari, A.; Noory, H.; Vazifedoust, M.;\
    \ Bahrami, M. Estimating net irrigation requirement of winter wheat\nusing model-\
    \ and satellite-based single and basal crop coeﬃcients. Agric. Water Manag. 2018,\
    \ 208, 95–106.\n[CrossRef]\nRemote Sens. 2019, 11, 2519\n22 of 22\n70.\nCammalleri,\
    \ C.; Ciraolo, G.; Minacapilli, M.; Rallo, G. Evapotranspiration from an Olive\
    \ Orchard using\nRemote Sensing-Based Dual Crop Coeﬃcient Approach.\nWater Resour.\n\
    Manag.\n2013, 27, 4877–4895.\n[CrossRef]\n71.\nVanino, S.; Nino, P.; De Michele,\
    \ C.; Falanga Bolognesi, S.; D’Urso, G.; Di Bene, C.; Pennelli, B.; Vuolo, F.;\n\
    Farina, R.; Pulighe, G.; et al. Capability of Sentinel-2 data for estimating maximum\
    \ evapotranspiration and\nirrigation requirements for tomato crop in Central Italy.\
    \ Remote Sens. Environ. 2018, 215, 452–470. [CrossRef]\n72.\nShi, X.; Han, W.;\
    \ Zhao, T.; Tang, J. Decision Support System for Variable Rate Irrigation Based\
    \ on UAV\nMultispectral Remote Sensing. Sensors 2019, 19. [CrossRef]\n73.\nHunt,\
    \ E.R.; Daughtry, C.S.T. What good are unmanned aircraft systems for agricultural\
    \ remote sensing and\nprecision agriculture? Int. J. Remote Sens. 2018, 39, 5345–5376.\
    \ [CrossRef]\n© 2019 by the authors. Licensee MDPI, Basel, Switzerland. This article\
    \ is an open access\narticle distributed under the terms and conditions of the\
    \ Creative Commons Attribution\n(CC BY) license (http://creativecommons.org/licenses/by/4.0/).\n"
  inline_citation: '>'
  journal: Remote Sensing
  limitations: '>'
  pdf_link: https://www.mdpi.com/2072-4292/11/21/2519/pdf?version=1573204980
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: UAV Multispectral Imagery Combined with the FAO-56 Dual Approach for Maize
    Evapotranspiration Mapping in the North China Plain
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.2134/agronmonogr57.2013.0030
  analysis: '>'
  authors:
  - Yanbo Huang
  - Steven J. Thomson
  citation_count: 6
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy UNCL: University Of Nebraska
    - Linc Acquisitions Accounting Search within Login / Register JOURNALS MAGAZINES
    OTHER PUBLICATIONS BOOKS Membership   Cotton, Volume 57, 2nd edition Full Access
    Remote Sensing for Cotton Farming Yanbo Huang,  Steven J. Thomson Book Editor(s):David
    D. Fang,  Richard G. Percy First published: 15 August 2015 https://doi.org/10.2134/agronmonogr57.2013.0030Citations:
    3 Book Series:Agronomy Monographs PDF TOOLS SHARE Summary Application of remote
    sensing technologies in agriculture began with the use of aerial photography to
    identify cotton root rot in the late 1920s. From then on, agricultural remote
    sensing has developed gradually until the introduction of precision farming technologies
    in the late 1980s and biotechnological innovations in the early 21st century.
    Remote sensing technologies for crop production management have advanced rapidly
    since then and are being developed for cotton growth monitoring, estimation of
    evapotranspiration and irrigation scheduling, nitrogen efficiency analysis, pest
    management (weeds, insects, and diseases), application of harvesting aids, and
    prediction of yield. In the next 10 yr or so, more specialized remote sensing
    analysis techniques for cotton management will be developed with improvements
    in unmanned aerial technologies and dual uses for agricultural aircraft. This
    chapter begins with the history of agricultural remote sensing, then discusses
    precision farming and the biotechnology interface for remote sensing on cotton,
    presents several research aspects of remote sensing for cotton, presents two research
    cases for remote sensing of cotton, discusses limitations of remote sensing for
    support of cotton management, and presents a perspective on remote sensing for
    cotton farming in the future. References Citing Literature Cotton, Volume 57,
    2nd edition References Related Information Recommended Temporal and Spatial Relationships
    between Within‐Field Yield Variability in Cotton and High‐Spatial Hyperspectral
    Remote Sensing Imagery P. J. Zarco-Tejada,  S. L. Ustin,  M. L. Whiting Agronomy
    Journal Sun‐Induced Fluorescence: A New Tool for Precision Farming Stefan W. Maier,  Kurt
    P. Günther,  Marion Stellmes Digital Imaging and Spectral Techniques: Applications
    to Precision Agriculture and Crop Physiology, [1] Soil Moisture Remote Sensing:
    State‐of‐the‐Science Binayak P. Mohanty,  Michael H. Cosh,  Venkat Lakshmi,  Carsten
    Montzka Vadose Zone Journal Modeling of Cotton Yields in the Amu Darya River Floodplains
    of Uzbekistan Integrating Multitemporal Remote Sensing and Minimum Field Data
    Zhou Shi,  Gerd R. Ruecker,  Marc Mueller,  Christopher Conrad,  Nazar Ibragimov,  John
    P. A. Lamers,  Christopher Martius,  Guenter Strunz,  Stefan Dech,  Paul L. G.
    Vlek Agronomy Journal © 2024 American Society of Agronomy, Crop Science Society
    of America, and Soil Science Society of America AGRONOMY.ORG, CROPS.ORG, SOILS.ORG
    MEMBERSHIP: AGRONOMY, CROPS, SOILS MEETINGS CCA SITE CAREERPLACEMENT.ORG Advertising
    Submit an article Author Resources Editorial Policies Librarian Resources Contact
    Publications Additional links ABOUT WILEY ONLINE LIBRARY Privacy Policy Terms
    of Use About Cookies Manage Cookies Accessibility Wiley Research DE&I Statement
    and Publishing Policies HELP & SUPPORT Contact Us Training and Support DMCA &
    Reporting Piracy OPPORTUNITIES Subscription Agents Advertisers & Corporate Partners
    CONNECT WITH WILEY The Wiley Network Wiley Press Room Copyright © 1999-2024 John
    Wiley & Sons, Inc or related companies. All rights reserved, including rights
    for text and data mining and training of artificial technologies or similar technologies.'
  inline_citation: '>'
  journal: Agronomy monograph/Agronomy
  limitations: '>'
  pdf_link: null
  publication_year: 2015
  relevance_score1: 0
  relevance_score2: 0
  title: Remote Sensing for Cotton Farming
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

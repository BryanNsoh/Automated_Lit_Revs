- analysis: '>'
  authors: []
  citation_count: '0'
  description: 'The proceedings contain 38 papers. The special focus in this conference
    is on Emerging Trends in Electrical, Electronic and Communications Engineering.
    The topics include: A Smart Precision Irrigation and Monitoring System; Performance
    Evaluation of an IPv6 IoT Network Based on 802.11 Standard; The Parser Function
    for D61 Files of Narda AMS 8061 Stations in EMF RATEL Monitoring System; Software
    Realization of the Exposure Assessment in EMF RATEL Monitoring System; forecasting
    Model for Voice and Internet Data Traffic During Peak Time Using Hidden Markov
    Model; Optimizing the Performance of Triple-Binary Turbo Codes with Hierarchical
    QAM and K-NN Based Classification; signal Distortion Identification Using Rough
    Flow Graphs; noise Mitigation in a Power Line Communication Channel; a Model for
    Classifying People at Risk of Diabetes Mellitus Using Social Media Analytics;
    a Machine Learning Approach for Idle State Network Anomaly Detection; a Jaya-Based
    Invasive Weed Optimization Technique for Load Frequency Control; Object Storage
    System Using Replication and Erasure Codes (OSSREC); improving Effectiveness of
    Honeypots: Predicting Targeted Destination Port Numbers During Attacks Using J48
    Algorithm; sirius: A Resource for Analyzing Drug-Disease Relationships for Drug
    Repositioning; enhancing Learning at Primary School Through Augmented Reality;
    analyzing the Prospects and Acceptance of Mobile-Based Marine Debris Tracking;
    the Analysis and the Need of Ubiquitous Learning to Engage Children in Coding;
    Adaptive Smart Car Park System (ASCaPS) Utilising CCTV Nodes and Mobile Technology;
    elderly Care Assistant: A Discreet Monitoring Tool; a Hybrid Approach for Recommender
    Systems in a Proximity Based Social Network; a Hybrid Optimisation Algorithm for
    Voltage Control.'
  doi: null
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: Lecture Notes in Electrical Engineering
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 2nd International Conference on Emerging Trends in Electrical, Electronic
    and Communications Engineering, ELECOM 2018
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Mahmoud S.H.
  - Gan T.Y.
  citation_count: '120'
  description: The implications of anthropogenic climate change, human activities
    and land use change (LUC) on the environment and ecosystem services in the coastal
    regions of Saudi Arabia were analyzed. Earth observations data was used to drive
    land use categories between 1970 and 2014. Next, a Markov-CA model was developed
    to characterize the dynamic of LUC between 2014 and 2100 and their impacts on
    regions' climate and environment. Non-parametric change point and trend detection
    algorithms were applied to temperature, precipitation and greenhouse gases data
    to investigate the presence of anthropogenic climate change. Lastly, climate models
    were used to project future climate change between 2014 and 2100. The analysis
    of LUC revealed that between 1970 and 2014, built up areas experienced the greatest
    growth during the study period, leading to a significant monotonic trend. Urban
    areas increased by 2349.61 km2 between 1970 and 2014, an average increase of >53.4
    km2/yr. The projected LUC between 2014 and 2100 indicate a continued increase
    in urban areas and irrigated cropland. Human alteration of land use from natural
    vegetation and forests to other uses after 1970, resulted in a loss, degradation,
    and fragmentation, all of which usually have devastating effects on the biodiversity
    of the region. Resulting in a statistically significant change point in temperature
    anomaly after 1968 with a warming trend of 0.24 °C/decade and a downward trend
    in precipitation anomaly of 12.2 mm/decade. Total greenhouse gas emissions including
    all anthropogenic sources showed a statistically significant positive trend of
    78,090 Kt/decade after 1991. This is reflected in the future projection of temperature
    anomaly between 1900 and 2100 with a future warming trend of 0.19 °C/decade. In
    conclusion, human activities, industrial revelation, deforestation, land use transformation
    and increase in greenhouse gases had significant implications on the environment
    and ecosystem services of the study area.
  doi: 10.1016/j.scitotenv.2018.03.290
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Graphical abstract Keywords 1. Introduction 2. Data
    and research methods 3. Anthropogenic climate change detection 4. Discussion of
    results 5. Conclusions and recommendations Acknowledgments References Show full
    outline Cited by (125) Figures (14) Show 8 more figures Tables (8) Table 1 Table
    2 Table 3 Table 4 Table 5 Table 6 Show all tables Science of The Total Environment
    Volume 633, 15 August 2018, Pages 1329-1344 Impact of anthropogenic climate change
    and human activities on environment and ecosystem services in arid regions Author
    links open overlay panel Shereif H. Mahmoud, Thian Y. Gan Show more Add to Mendeley
    Share Cite https://doi.org/10.1016/j.scitotenv.2018.03.290 Get rights and content
    Highlights • Use of EO data to drive land use categories between 1970 and 2014
    • Markov-CA to detect land use change pattern in the area • Human activates and
    land use change and their impacts on climate and environment. • Anthropogenic
    climate change detection and trend between 1900 and 2010 • Projections of land
    use trend between 1900 and 2010 and its potential anthropogenic climate change
    Abstract The implications of anthropogenic climate change, human activities and
    land use change (LUC) on the environment and ecosystem services in the coastal
    regions of Saudi Arabia were analyzed. Earth observations data was used to drive
    land use categories between 1970 and 2014. Next, a Markov-CA model was developed
    to characterize the dynamic of LUC between 2014 and 2100 and their impacts on
    regions'' climate and environment. Non-parametric change point and trend detection
    algorithms were applied to temperature, precipitation and greenhouse gases data
    to investigate the presence of anthropogenic climate change. Lastly, climate models
    were used to project future climate change between 2014 and 2100. The analysis
    of LUC revealed that between 1970 and 2014, built up areas experienced the greatest
    growth during the study period, leading to a significant monotonic trend. Urban
    areas increased by 2349.61 km2 between 1970 and 2014, an average increase of >53.4
    km2/yr. The projected LUC between 2014 and 2100 indicate a continued increase
    in urban areas and irrigated cropland. Human alteration of land use from natural
    vegetation and forests to other uses after 1970, resulted in a loss, degradation,
    and fragmentation, all of which usually have devastating effects on the biodiversity
    of the region. Resulting in a statistically significant change point in temperature
    anomaly after 1968 with a warming trend of 0.24 °C/decade and a downward trend
    in precipitation anomaly of 12.2 mm/decade. Total greenhouse gas emissions including
    all anthropogenic sources showed a statistically significant positive trend of
    78,090 Kt/decade after 1991. This is reflected in the future projection of temperature
    anomaly between 1900 and 2100 with a future warming trend of 0.19 °C/decade. In
    conclusion, human activities, industrial revelation, deforestation, land use transformation
    and increase in greenhouse gases had significant implications on the environment
    and ecosystem services of the study area. Graphical abstract Download : Download
    high-res image (281KB) Download : Download full-size image Previous article in
    issue Next article in issue Keywords Anthropogenic climate change, land use changeMarkov-CAHuman
    activitiesEnvironmentDeforestation 1. Introduction Some countries have suffered
    from significant impact of climate change, such as rising sea level, extreme weather
    events and changing hydrological cycle. However, human activities could also incur
    severe negative effects on our environment which in turn affect our livelihood
    worldwide. There have been studies on how land use change (LUC) and climate change
    have affected the ecosystems and the environment at various spatiotemporal scales
    (Perrings et al., 2011; Tong et al., 2012; Reeves et al., 2018). In this study,
    we assess how have LUC patterns and climate change impacted the environment and
    ecosystem services of coastal regions of Arabia. In recent years, studies show
    that human activities, including LUC and deforestation, have resulted in major
    global environmental change and impacts (Verburg et al., 2011; Sirami et al.,
    2017; Prestele et al., 2017). In Saudi Arabia, for instance, the impact of human
    exploitation of water resources is obvious in the Layla Aflaj lakes and deep waterholes
    of the Al-Kharj region. Since 1980s, excessive water consumption due to agriculture
    activities and domestic purposes have significantly depleted these resources (Schleusener
    et al., 2013). Sadly, valuable water sources from limited number of natural lakes
    in Arabia formed by groundwater aquifers over many centuries are now the region''s
    history. In the past, the region was characterized by heavy rainfall and was large
    occupied by shrubland and forests (Thouless et al., 1991). However, human activities
    and land use change had further decreased the already scarce water resources of
    this region, and similarly in other parts of the Arabian Peninsula. To mitigate
    the impact of severe droughts, growing population, and food security, multiple
    rainwater harvesting dams were constructed in high mountains to collect rainwater
    for all purposes, forestlands were replaced by agriculture fields and wild animals
    were hunted for food. Human and climate change impacts on the arid environment
    are generally not well documented, even though such information will help us to
    better understand how these human activities will affect natural resources in
    the arid environment, and what conservation plans would be helpful. In recent
    decades, many LUC studies have been conducted (Shalaby and Tateishi, 2007; Wang
    et al., 2009; Woldesenbet et al., 2017), of which some have considered extensive
    LUC as the main drivers to biodiversity loss, fragmentation, habitat reduction,
    and food security (Wilson and Weng, 2011; Nasta et al., 2017; Liang et al., 2017;
    Fu et al., 2017). It seems uncurbed human exploitation of natural resources could
    irreversibly impact the future of mankind in centuries to come. From remotely
    sensed data acquired by earth observation satellites, it is now possible to use
    a geographic information system to derive various LUC patterns, trends and magnitude
    of high temporal and spatial resolutions (Lu et al., 2004; Long et al., 2007;
    Shalaby and Tateishi, 2007). Various change detection methods have been employed
    in LUC studies, such as the principal component analysis (PCA), band differencing,
    band ratioing, neural network, support vector machine, and post-classification
    techniques (Ridd and Liu, 1998; Lu et al., 2004; Petrosillo et al., 2013). However,
    the Markov Chains method has dominated many LUC studies (Pontius and Malanson,
    2005). Researchers often combine this method with Cellular Automata (CA) to control
    the decision-making process and to enhance the ability to change/add or even modify
    factors that drives LUC in form of transition rules (Longley and Batty, 1996;
    Clarke and Gaydos, 1998; Zhang et al., 2009). Cellular Automata has been successfully
    utilized to project future LUC (Myint and Wang, 2006; Marshall and Randhir, 2008;
    Guan et al., 2011; Huishi et al., 2012; Huang et al., 2014). By combining these
    two methods to a LUC study conducted in Norman, Oklahoma, USA, Myint and Wang
    (2006) achieved an accuracy of 86% which is of acceptable accuracy (Anderson et
    al., 1976; Townshend, 1981). Similar accuracy was obtained by Marshall and Randhir
    (2008) to assess future land cover based on transition rules of Markov-CA. More
    recently, Guan et al. (2011) and Huishi et al. (2012) found that a combination
    of Markov-CA is more accurate than other LUC models. Past studies suggest that
    LUC patterns would affect local temperature and precipitation (e.g., Pielke et
    al., 2007). Weng (2001) concluded that rapid urbanization led to climate warming
    because of increasing CO2 emissions. Moreover, Pielke (2005) showed that rising
    concentration of greenhouse gases in the atmosphere is the best-known impact of
    human activities on climate change and LUC. Pettit''s test and Mann-Kendall test
    have been widely used to detect changes in climate data. Pettit''s test (Pettit,
    1979) is a popular non-parametric approach for detecting change points in the
    time series of climate variables (Ma et al., 2008; Mahé and Paturel, 2009; Martínez
    et al., 2010). The non-parametric Mann-Kendall (Sneyers, 1992) test is widely
    used to estimate trends in climate data and whether the trend is statistically
    significant (Zhang et al., 2000; Yue et al., 2002; Dawood, 2017). We investigated
    the impacts of anthropogenic climate change and LUC caused by human activities
    on the environment and ecosystem services of the study sites. To achieve our objectives,
    we used earth observations data (EO) of satellites to derive land use categories
    at different spatial and temporal scales in the Jizzan Province-Arabia for 1970–2014.
    Then, using the Markov-CA approach, the temporal/spatial dynamics of LUC patterns
    in the study area for 2014–2100 were derived and their impacts on the climate,
    environment, and water resources were analyzed. Pettit''s and Mann-Kendall tests
    were applied on temperature data over 1900–2010, and precipitation data over 1948–2014
    to detect change points and to estimate trends in the region. The impact of global
    warming due to increasing greenhouse gases were also analyzed between 1960 and
    2015. Lastly, future effects of LUC and climate change in the study area, were
    analyzed using RCP4.5, RCP6.0 and RCP8.5 climate change scenarios projected by
    climate models of CMIP5 and IPSL-CM5A-LR between 2014 and 2100. Without any major
    river, the water resources of Saudi Arabia depend heavily on precipitation and
    groundwater sources. Given evapotranspiration (ET) plays a major role in its climate
    and the fauna and flora of its desert environment, we have also estimated the
    potential ET of the study area over 1950–2016 and projected possible changes over
    2016–2100. 2. Data and research methods 2.1. Study area and data sets As the Jizzan
    Province (Fig. 1) lies on the coastal regions of Arabia (16°53′21″N 42°33′40″E),
    it has a different climate than the rest of Arabia. In the past Jizzan was dominated
    by forest, shrubland and different species of wild animals. The province also
    includes >100 islands in the Red Sea that in the past were rich in animals and
    biodiversity. Landsat cloud-free images for Jizzan in 1970, 1980, 1990, 2000,
    2010, and 2014 were obtained from the King Abdulaziz City for Science and Technology
    (KACST) (Table 1). Monthly precipitation data between 1948 and 2014 and temperature
    data between 1900 and 2010 were derived from the 20th Century Reanalysis V2 Dataset.
    CO2 and other greenhouse gas emissions data were obtained from the Carbon Dioxide
    Analysis Center of Environmental Sciences Division, USA. Download : Download high-res
    image (544KB) Download : Download full-size image Fig. 1. Location map of Jizzan
    Province. Kingdom of Saudi Arabia. Table 1. Earth observation data used in this
    study. Images Used for the study Resolution (m) Date of acquisition Format Product
    Type (Cloud Cover %) Landsat 1–5 MSS 30 06/03/1970 GEOTIFF L1T (0%) Landsat 1–5
    MSS 30 01./09/1980 GEOTIFF L1T (0%) Landsat 5 TM “Band 1–7” 30 24/02/1990 GEOTIFF
    L1T (0%) Landsat 7 ETM+ “Band 1–8” 30 04/01/2000 GEOTIFF L1T (0%) SPOT-5 “PSM”
    2.5 06/03/2000 GEOTIFF L1T (0%) Landsat 7 ETM+ 30 05/01/2010 GEOTIFF L1T (0%)
    Landsat 8 30 03/04/2014 GEOTIFF L1T (0%) 2.2. Land use classification and accuracy
    assessment Landsat images were preprocessed, made as mosaic, and geometrically
    corrected based on a rectified SPOT-5 “2.5m PSM” satellite image for the Jizzan
    province. This image also served as the reference image for land use classification
    and accuracy assessment. Then, these images were also atmospherically corrected
    by normalizing these images to the SPOT-5 image. Lastly, the Landsat images have
    been radiometrically normalized to the reference image based on manually identified
    16 pseudo-invariant features (PIFs). Two field surveys were set up, the first
    was before land use classification to collect ground control points (GCP). Five
    hundred GCP were collected in the first trip for land use classification, which
    was performed using these GCP and visual interpretations of Google Earth images.
    In the second trip, we collected 100 points for validating the classified images.
    The popular, Iso Cluster Unsupervised and Maximum Likelihood Classification was
    applied to the Landsat images, to classify the land use/cover (Baker et al., 2006;
    Panda et al., 2009; Mukherjee et al., 2010; Jiménez-Bello et al., 2012). Six land
    use/cover classes were identified in each land use map: water bodies, built-up
    areas, bare soil, sparse vegetation, irrigated cropland, forest and shrubland.
    The accuracy of these maps was assessed using both simple random and stratified
    random patterns. Further, a questionnaire consists of two types of questions was
    prepared to ask residents about anthropogenic effects on the region. The first
    type consists of preliminary questions such as areas of cultivated lands, and
    number of groundwater wells used to irrigate crops. The second type of questions
    consist of three tables, which include affirmative statements about social and
    environmental impacts of oil discovery, climate change and human activities in
    the study area. The questionnaire was set up under a five-point scale (strongly
    agree, agree, not sure, disagree, strongly disagree) to allow farmers to choose
    the extent of their agreement or disagreement to each statement. 2.3. Changes
    and dynamics of land use/cover The areal distribution of each land use class was
    estimated for all time periods to determine the dynamics and patterns of land
    use/cover change (LUC). LUC and trends were estimated in terms of gain, loss and
    net change for each temporal period by class. LUC drivers were then identified
    based on the Markov Chains transition probabilities. A coupled Markov-CA model
    was used to project changes and the future spatial distribution of LUC. From the
    results, we derive the transition probability matrix which represents the probability
    of each land use class to change to another class or to remain unchanged in the
    next time period. Next, transition area matrices were developed to estimate the
    total area expected to change at each period. Finally, based on the historical
    LUC in the area, conditional probability images, one for each land use/cover class
    was developed to show the likelihood of each class will change to other classes
    or not. Five historical transition matrices were constructed from the cross-tabulation
    of the land use/cover maps between 1970, 1980, 1990, 2000, 2010, and 2014. The
    time interval between the transition matrices was 10 years. The approach of Pastor
    et al. (1993) was adopted to transform transition probabilities to annual time
    steps to consider the differences in the lengths of the last period (2010–2014)
    (Table 3). Major drivers of land use dynamics in the study area for each study
    period were identified. As expected, urbanization and agriculture activities at
    the expenses of forestland and shrubland were the major drivers for LUC. To project
    future LUC in the study area, we first tested the model''s ability to simulate
    historical LUC based on the annualized transition matrices. Transition probabilities
    for future LUC are developed from trends observed in the past, e.g., the land
    use in 2010 was simulated on the basis of the 1990 and 2000 transition matrices.
    Various studies have adopted this approach (Araya and Cabral, 2010; Yang et al.,
    2014; Singh et al., 2015; Keshtkar and Voigt, 2016; Han and Jia, 2017). For instance,
    Araya and Cabral (2010) compared the actual land use map in 2010 derived from
    EO data with that simulated for 2010 based on LUC between 1990 and 2000. Similarly,
    Singh et al. (2015) used actual transition probabilities between 2000 and 2010
    to project LUC in 2020. In this study, we used the transition probability between
    1970 and 1980 to simulate LUC in 1990. Similarly, the 2000 land use map was simulated
    from the 1980–1990 transition matrix. Finally, the land use map of 2010 and 2014
    were simulated based on transition probability matrices of 1990–2000 and 2000–2010,
    respectively. The main limitation of the Markov-CA model is that it assumes factors
    of past changes remain the same in the future. However, using multiple actual
    land use maps as an accuracy assessment, high accuracies of projection could be
    obtained (Yagoub and Al Bizreh, 2014; Guan et al., 2011). Guan et al. (2011) used
    the transition probability matrix of 1997–2006 to project LUC for 2024, which
    then was set as the starting year to project LUC for 2033, but again based on
    the transition probability matrix of 1997–2006, and 2033 as the starting year
    to project the 2042 LUC. In our study, we followed this approach and applied the
    Kappa Index of Agreement (KIA) to validate the model performance by comparing
    the simulated land use map at each year against the actual land maps. KIA was
    also used to test for spatial and quantitative agreement between every two maps.
    Table 2 shows how well the land use maps were classified. The overall accuracy
    of the land use maps for 1970, 1980, 1990, 2000, 2010, and 2014 was assessed to
    be 80.52%, 84.33%, 85.17%, 84.9%, 87.2%, and 94.8% respectively. KAPPA indices
    for these maps estimated at 0.76, 0.755, 0.717, 0.82, 0.85, and 0.89, respectively
    are all of acceptable accuracy. Next, the Markov–CA model was used to project
    the future LUC and land use map at 2025 based on the transition probability of
    2010–2014, taking 2014 as the starting point. Then land use map at 2050 was simulated
    based on the same transition probability matrix but taking 2025 as the starting
    point. Finally, land use map at 2075 and 2100 was simulated taking 2050 and 2075
    as the starting point respectively. Table 2. Accuracy assessment and validation
    of land use-land cover maps. Empty Cell 1970 1980 1990 2000 2010 2014 LULC UA
    (%) PA (%) Kappa UA (%) PA (%) Kappa UA (%) PA (%) Kappa UA (%) PA (%) Kappa UA
    (%) PA (%) Kappa UA (%) PA (%) Kappa Water bodies 80.2 79 0.72 78.12 76.5 0.71
    86.8 77.6 0.69 89.1 90.9 0.82 79.61 70.4 0.88 93.21 94.6 0.86 Built up areas 79.9
    82.2 0.81 92.62 90.4 0.82 90.35 89.8 0.77 90.2 85.62 0.86 94.58 92.8 0.98 96.85
    94.36 1 Bare soil 84.2 84.8 0.62 88.22 78.2 0.71 88.12 85 0.67 79.6 75.43 0.83
    88.5 84.64 0.78 95.47 93.85 0.79 Sparsely vegetated 81.5 77.51 0.7 79.32 80.3
    0.68 75.41 80.2 0.735 81.3 91.5 0.9 91.7 79.3 0.76 94.65 96.92 0.84 Irrigated
    cropland 76.2 78.52 0.86 83.44 84.35 0.76 87.35 90.24 0.725 88.29 89 0.78 86.55
    90.4 0.845 92.69 94.54 0.89 Forest and shrubland 78.9 83.3 0.87 91.1 89.4 0.85
    84.9 86.23 0.71 79.5 78.41 0.75 93.32 94.6 0.86 93.74 96.77 0.94 OA 80.519 0.76
    84.33 0.755 85.17 0.717 84.90 0.82 87.20 0.85 94.80 0.89 UA, user''s accuracy;
    PA, producer''s accuracy; OA, overall accuracy. Table 3. Land use transitions
    probabilities 1970–2014. Empty Cell 1970–1980 Markov matrixa Empty Cell Empty
    Cell Empty Cell Empty Cell Empty Cell Empty Cell Code Land cover/use class Water
    bodies Built up areas Bare soil Sparsely vegetated Irrigated cropland Forest and
    shrubland 1 Water bodies 0 0.0491 0.0844 0.0055 0.0009 0.0005 2 Built up areas
    0.8597 0.1496 0.7078 0.0213 0.0014 0.0005 3 Bare soil 0.1194 0.0177 0.8893 0.082
    0.0044 0.0027 4 Sparsely vegetated 0.004 0.0032 0.7375 0.2412 0.0124 0.0049 5
    Irrigated cropland 0.0007 0.0007 0.203 0.6457 0.1185 0.0318 6 Forest and shrubland
    0.0005 0.0003 0.0672 0.4327 0.267 0.2328 Empty Cell 1980–1990 Markov matrixa Code
    Land cover/use class Water bodies Built up areas Bare soil Sparsely vegetated
    Irrigated cropland Forest and shrubland 1 Water bodies 0.9231 0.0461 0.0285 0.0013
    0.0006 0.0003 2 Built up areas 0.1102 0.2392 0.6506 0 0 0 3 Bare soil 0.0012 0.0167
    0.9072 0.07 0.003 0.002 4 Sparsely vegetated 0 0 0.6487 0.3317 0.0147 0.0049 5
    Irrigated cropland 0.0005 0 0 0.7752 0.1881 0.0362 6 Forest and shrubland 0.0002
    0.0004 0 0.3282 0.3078 0.3633 Empty Cell 1990–2000 Markov matrixa Code Land cover/use
    class Water bodies Built up areas Bare soil Sparsely vegetated Irrigated cropland
    Forest and shrubland 1 Water bodies 0.7992 0.0527 0.137 0.0093 0.0012 0.0006 2
    Built up areas 0.1278 0.053 0.7584 0.0562 0.0029 0.0017 3 Bare soil 0.0067 0.0188
    0.871 0.0944 0.0058 0.0033 4 Sparsely vegetated 0.0018 0.0118 0.8261 0.1452 0.0101
    0.005 5 Irrigated cropland 0.0005 0.0001 0.5817 0.3526 0.0449 0.0203 6 Forest
    and shrubland 0.0002 0 0.2593 0.4946 0.1474 0.0986 Empty Cell 2000–2010 Markov
    matrixa Code Land cover/use class Water bodies Built up areas Bare soil Sparsely
    vegetated Irrigated cropland Forest and shrubland 1 Water bodies 0.6152 0.0766
    0.248 0.0271 0.0238 0.0093 2 Built up areas 0.0399 0.5438 0.3791 0.0169 0.0164
    0.0039 3 Bare soil 0 0.1069 0.798 0.0577 0.0281 0.0083 4 Sparsely vegetated 0.0001
    0.0087 0.5982 0.2039 0.1613 0.0277 5 Irrigated cropland 0 0.0032 0.3339 0.2021
    0.3278 0.1329 6 Forest and shrubland 0 0.0017 0.0807 0.0817 0.3756 0.4604 Empty
    Cell 2010–2014 Markov matrixa Code Land cover/use class Water bodies Built up
    areas Bare soil Sparsely vegetated Irrigated cropland Forest and shrubland 1 Water
    bodies 0.4735 0.1019 0.342 0.0369 0.0325 0.0132 2 Built up areas 0.0477 0.4051
    0.4871 0.0303 0.0231 0.0068 3 Bare soil 0.0031 0.1354 0.7455 0.0644 0.04 0.0125
    4 Sparsely vegetated 0 0.0446 0.6555 0.1279 0.1282 0.0438 5 Irrigated cropland
    0 0.0177 0.4592 0.1584 0.2358 0.1289 6 Forest and shrubland 0.002 0.0005 0.1767
    0.1347 0.3598 0.3283 a Values are probabilities of transition. Table 4. Area measurements
    of land-cover/use within Jizzan province for each subperiod and the full period
    1970–2014. Empty Cell Empty Cell 1970 1980 1990 2000 2010 2014 Code Land cover/use
    class Area (Km2) Area (%) Area (Km2) Area (%) Area (Km2) Area (%) Area (Km2) Area
    (%) Area (Km2) Area (%) Area (Km2) Area (%) 1 Water bodies 70.470 0.535 100.918
    0.766 86.573 0.657 84.677 0.642 78.027 0.592 73.362 0.557 2 Built up areas 106.820
    0.810 139.392 1.057 532.915 4.043 1399.518 10.617 2223.766 16.870 2456.430 18.635
    3 Bare soil 5776.400 43.820 9395.668 71.276 10,147.186 76.981 9608.147 72.891
    7593.928 57.611 7020.124 53.256 4 Sparsely vegetated 5290.940 40.137 2817.407
    21.373 1842.248 13.976 1085.457 8.235 1129.829 8.571 1120.279 8.499 5 Irrigated
    cropland 1065.295 8.081 450.4329 3.417 549.1719 4.166 781.9578 5.932 1792.368
    13.598 1963.683 14.897 6 Forest and shrubland 872.1918 6.616 278.3241 2.111 23.4
    0.178 221.7375 1.682 363.5766 2.758 548.0865 4.158 Table 5. Detected land cover/use
    gains and losses within Jizzan province for each subperiod and the full period
    1970–2014. Empty Cell Empty Cell 1970–1980 1980–1990 1990–2000 2000–2010 2010–2014
    Code Land cover/use class Change (Km2) Change (%) Change (Km2) Change (%) Change
    (Km2) Change (%) Change (Km2) Change (%) Change (Km2) Change (%) 1 Water bodies
    −30.45 −0.23 14.35 0.11 1.90 0.01 6.65 0.05 4.67 5.98 2 Built up areas −32.57
    −0.25 −393.52 −2.99 −866.60 −6.57 −824.25 −6.25 −232.66 −10.46 3 Bare soil −3619.27
    −27.46 −751.52 −5.70 539.04 4.09 2014.22 15.28 573.80 7.56 4 Sparsely vegetated
    2473.53 18.76 975.16 7.40 756.79 5.74 −44.37 −0.34 9.55 0.85 5 Irrigated cropland
    614.86 4.66 −98.74 −0.75 −232.79 −1.77 −1010.41 −7.67 −171.32 −9.56 6 Forest and
    shrubland 593.87 4.51 254.92 1.93 −198.34 −1.50 −141.84 −1.08 −184.51 −50.75 Where
    (−) gain, (+) loss. Table 6. Change point and trend detection. Empty Cell Empty
    Cell Pettitt test Mann–Kendall test Empty Cell Empty Cell Years t P trend Tau
    Sen''s slope P trend Mb Ma T anomaly 1900–2010 1968 <0.0001 Ha 0.434 0.024 <0.0001
    + −0.206 0.326 Precipitation anomaly 1948–2014 1967 0.0001 Ha 0.133 −1.22 <0.0001
    − 7.9 −3.12 CO2 emissions (Kt) 1960–2015 1985 <0.0001 Ha 1 9434 <0.0001 + 78,660
    337,701 Other greenhouse gas emissions HFC, PFC and SF6 (Kt) 1971–2012 1984 <0.0001
    Ha 0.6 48.85 <0.0001 + 884.4 2025 Total greenhouse gas emissions (Kt of CO2 equivalent)
    1971–2012 1991 <0.0001 Ha 0.94 7809 <0.0001 + 196,902 348,896 Table 7. Area measurements
    of land cover/use projection 2025, 2050, 2075, and 2100. Empty Cell Empty Cell
    2025 2050 2075 2100 Code Land cover/use class Area (Km2) Area (%) Area (Km2) Area
    (%) Area (Km2) Area (%) Area (Km2) Area (%) 1 Water bodies 63.800 0.484 58.900
    0.447 50.102 0.380 43.669 0.331 2 Built up areas 2640.653 20.032 2732.886 20.732
    2753.937 20.892 2790.300 21.168 3 Bare soil 6498.476 49.298 6164.481 46.765 6100.740
    46.281 5970.401 45.292 4 Sparsely vegetated 1169.357 8.871 1182.924 8.974 1180.068
    8.952 1189.728 9.025 5 Irrigated cropland 2161.152 16.395 2279.9475 17.296 2313.637
    17.552 2400.4565 18.210 6 Forest and shrubland 648.5265 4.920 762.8256 5.787 783.4806
    5.944 787.4091 5.973 Table 8. Expected gains and losses during projected period
    (2014–2100). Empty Cell Empty Cell 2014–2025 2025–2050 2050–2075 2075–2100 Code
    Land cover/use class Change (Km2) Change (%) Change (Km2) Change (%) Change (Km2)
    Change (%) Change (Km2) Change (%) 1 Water bodies 9.562 13.034 4.900 7.680 8.798
    14.937 6.433 12.840 2 Built up areas −184.223 −7.500 −92.233 −3.493 −21.050 −0.770
    −36.363 −1.320 3 Bare soil 521.648 7.431 333.995 5.140 63.741 1.034 130.339 2.136
    4 Sparsely vegetated −49.078 −4.381 −13.567 −1.160 2.856 0.241 −9.660 −0.819 5
    Irrigated cropland −197.469 −10.056 −118.7955 −5.497 −33.6895 −1.478 −86.8195
    −3.753 6 Forest and shrubland −100.44 −18.326 −114.2991 −17.624 −20.655 −2.708
    −3.9285 −0.501 Where (−) gain, (+) loss. 3. Anthropogenic climate change detection
    Land-use change is a major player to climate change since it contributes to atmospheric
    CO2 emission (Dale et al., 2011). Therefore, we also analyzed CO2 and other greenhouse
    gases emissions and their by-product: hydrofluorocarbons (HFC), perfluorocarbons
    (PFC), sulfur hexafluoride (SF6), all anthropogenic CH4 and N2O sources in thousand
    metric tons (Kt) of CO2 equivalent. Change point and trend detections were applied
    to these data to detect climate change in the study area which might be attributed
    to LUC and increased global warming as suggested by Dale et al. (2011) and Searchinger
    et al. (2008). For the Jizzan province, we analyzed the variability of long-term
    monthly precipitation and temperature anomalies from the long-term mean precipitation
    of 1948 to 2016, and long-term mean temperature of 1900–2010, respectively. To
    detect trends and change points, we used nonparametric, Pettitt and Mann–Kendall
    tests (MK) on the time series of temperature, temperature anomaly, precipitation,
    precipitation anomaly, respectively. Change points were calculated as follows
    (Pettit, 1979): (1) where, (2) The change-point of the series is located at KT,
    provided that the statistic is significant. The significance probability of KT
    is approximated for p ≤ 0.05 with (3) The Mann–Kendall test was applied to estimate
    trends of climate data as follows: (4) Trend is estimated for a time series xi,i
    = 1, 2… n-1 and xj,j = i + 1, i + 2…. n. Each xi is reference and compared with
    remaining data points xj (see 2): (5) The variance statistic is calculated as
    follow: (6) where p is the number of groups in which each group consists of data
    points of equal values, and tj is the number of data points in the jth group.
    Using the following Z-transformation, S is approximately normally distributed:
    (7) The slope (Tj) is computed according to Sen (1968) as follow: (8) The magnitude
    of the trend is obtained from the slope estimator method (Sen, 1968). The sign
    of the slope indicates if the trend of the time series is positive or negative.
    Climate change scenarios of RCP4.5, RCP6.0 and RCP8.5 projected by climate models
    of CMIP5 and IPSL-CM5A-LR between 2014 and 2100 were used to project future warming
    in the study area. Future climate projections of these climate models were analyzed
    separately and then averaged for the study area. Statistical downscaling techniques
    of Frias et al. (2006) and Guo et al. (2014) based on empirical relationships
    between climate models'' output and local weather information were used to downscale
    climate models'' projections to local-scale. Again, the Pettit''s test and Mann-Kendall
    approach were used to detect change points and trends of climate projections that
    have been downscaled statistically. Given evapotranspiration (ET) plays a major
    role in the climate of a desert environment, the increase in ET has been linked
    to rising atmospheric CO2 concentration and climate warming (Kang et al., 1999;
    Abtew and Melesse, 2013). We estimated the potential ET of the study area over
    1950–2016 and projected possible changes over 2016–2100 of the study area using
    Penman Monteith''s method (Allen et al., 1998). Precipitation surplus (precipitation
    - PET), which represents the hydrologic impact of climate change in the region,
    was also estimated. 4. Discussion of results 4.1. Impact of land use dynamics
    on environment Impacts of climate change and human activities to the study area
    have not been documented even though environmental changes such as plant distributions
    have been going on for years. We have analyzed results of a survey based on questionnaire
    we developed with local farmers about possible environmental and social impacts
    of climate change and LUC on the study area. The local residence''s responses
    strongly advocated the high social and environmental costs associated with human
    activities such as mining of oil, LUC, and dams in the region are: loss of biodiversity
    and fertile soil, air and water pollution, degradation of farmland, damage to
    aquatic ecosystem, increased desertification and a decline in vegetative cover.
    Results of the analysis presented in Fig. 2a and b reveal a large expansion in
    urban areas after 1970s, and a decline in irrigated cropland, forest, shrubland,
    and sparse vegetation cover during 1970s and 1980s, respectively. During this
    period, many farmers left their agricultural land and migrated to cities for jobs,
    which led to a decline in vegetative cover and lumbering for industrial uses.
    The construction of five dams in 1970, 1998 and 2000 to store rainwater for agriculture
    activities and domestic purposes affected the biodiversity of the region, and
    significantly increased the LUC. The extent of LUC distribution over the study
    period (1970–2014) is presented in Table 4. Urbanized areas increased from 106.82
    km2 (0.81% of total area) in 1970 to 139.39 km2 (1%) in 1980, a 25% increase in
    10 years, while sparsely vegetated land declined dramatically from 5290.94 km2
    (40%) in 1970 to 2817.407 km2 (21%) in 1980. Download : Download high-res image
    (2MB) Download : Download full-size image Fig. 2. Spatial distribution of land
    use a) 1970, b) 1980, c) 1990, d) 2000, e) 2010, and f) 2014. There was an increase
    in areas of water bodies from 70.47 km2 (0.5% of the total area) in 1970 to 100.90
    km2 (0.8%) in 1980 due to the construction of rainwater retention facilities,
    which helped farmers to recover loss of agricultural land in later years. From
    1980 to 1990, areas of bare soil increased from 9395.7 km2 to 10,147.2 km2, urbanized
    areas increased from 1.057% to 4% of the total area, but areas of forest and shrubland
    significantly decreased from 278.3 km2 to 23.4 km2, which fortunately was restored
    to 221.7 km2 due to conservation efforts implemented in 2000. Sparse vegetative
    cover continued to decline, losing >975.0 km2 of its 1980 area to 1842.2 km2 in
    1990 and to 1085.4 km2 in 2000, which marginally increased between 2010 and 2014
    to 1120.0 km2 in 2014. Relative to 1980, irrigated cropland increased significantly
    from 450.4 km2 in 1980 to 1963.7 km2 over the 1990–2014 period. Table 5 shows
    LULCC (%) in the study area for each subperiod and the 1970–2014 period. Spatial
    patterns of LUCs in the Jizzan Province for 1970, 1980, 1990, 2000, 2010, and
    2014 given in Fig. 2 show that bare soil and sparse vegetative cover were dominant,
    but over the years urbanization expanded in the coastal regions. From 1990 to
    2014, urbanized areas replaced most of the water bodies and extended into coastal
    areas, and consequently areas of bare soil and water bodies declined markedly.
    The rate of urban expansion since 1970s was >53.4 km2 yr−1. LUC had significantly
    affected forest, shrubland and vegetation covers, which in turn might have affected
    ecosystems, natural habitat and biodiversity of the region. Human alteration of
    land use from natural vegetation and forests to other land uses typically results
    in a loss, degradation, and fragmentation of ecosystems, which tend to have negative
    effects on the biodiversity of the region, as also reported by local residents
    impacts over the years. Because of depleted groundwater resources, rainwater harvesting
    dams were constructed which substantially captured the surface water. The regional
    change in hydrology due to human activities resulted in the loss of forest covers,
    altered landscape patterns and ecosystem of the region. 4.2. Anthropogenic climate
    change and human activities We applied Pettit''s test to detect anthropogenic
    change points of the region, which reveals statistically significant change points
    in monthly temperature and temperature anomaly in 1968. The mean temperature anomaly
    increased significantly from −0.206 °C between 1900 and 1968 (Mb: average before
    the change point) to 0.326 °C (Ma: average after the change point) between 1968
    and 2010 (Table 6). The Mann–Kendall trend test also show a statistically significant
    warming trend of 0.24 °C per decade since 1968, which reflects the impact of anthropogenic
    climate change and LUC such as decline in forest, shrubland, and sparsely vegetated
    land since 1970 (Fig. 3) due to agricultural development which reached its zenith
    in 2000s. Download : Download high-res image (310KB) Download : Download full-size
    image Fig. 3. Temperature anomaly and trend. Similarly, from Pettitt''s test applied
    to monthly precipitation anomaly data for 1948–2014, a statistically significant
    change point was detected in 1967, as the mean precipitation anomaly declined
    from 7.9 mm/yr (Mb = 7.9 mm/yr) between 1948 and 1967 to −3.12 mm/yr (Ma = −3.12
    mm/yr) between 1967 and 2010 (Fig. 4). Trend analysis shows a statistically significant
    negative trend in precipitation anomaly of 12.2 mm/decade (Table 6). Download
    : Download high-res image (343KB) Download : Download full-size image Fig. 4.
    Precipitation anomaly and trend. Given rising temperature anomalies are mainly
    attributed to increasing concentrations of greenhouse gases due to burning of
    fossil fuels and the manufacture of cement (IPCC, 2013), we have analyzed changes
    to greenhouse gas emissions data between 1960 and 2015. We detected a statistically
    significant change point in CO2 emission data in 1985, such that CO2 emissions
    increased from 78,660 Kt/yr between 1960 and 1985 to 337,701 Kt/yr between 1985
    and 2015 (Fig. 5), because of increasing consumption of solid, liquid, and gas
    fuels and flaring after 1985. A trend analysis shows a statistically significant
    positive trend in CO2 emissions of 94,340 Kt/decade (Table 6). Download : Download
    high-res image (254KB) Download : Download full-size image Fig. 5. Carbon dioxide
    emissions time series and trend. Other greenhouse gases produced by industrial
    processes are such as hydrofluorocarbons (HFC), perfluorocarbons (PFC), and sulfur
    hexafluoride (SF6), as presented in Fig. 6. These greenhouse gases also show statistically
    significant change point in 1984, where the mean annual HFC, PFC, and SF6 emissions
    increased dramatically from 884.4 Kt/yr between 1971 and 1984 to 2025 Kt/yr between
    1984 and 2012, and an overall statistically significant positive trend of 488.5
    Kt/decade. The warming effects of these greenhouse gases and LUC such as urbanization,
    deforestation and construction of dams in the study area had resulted in the consistent,
    observed positive temperature trend since the mid-Twentieth Century. Fig. 7 shows
    the time series of total greenhouse gas emissions that include all anthropogenic
    sources, which show a statistically significant change point in 1991, with positive
    trend of 78,090 Kt/decade (Table 6). Download : Download high-res image (269KB)
    Download : Download full-size image Fig. 6. Other greenhouse gas emissions, HFC,
    PFC, and SF6. Download : Download high-res image (234KB) Download : Download full-size
    image Fig. 7. Total greenhouse gas emissions including all anthropogenic sources.
    From Fig. 8a that shows the historical and projected change in temperature anomalies
    between 1900 and 2100, it can be seen that significant warming trend started to
    occur in 1970s attributed to human activities such as industrial boom, deforestation,
    rapid urbanization and increase in greenhouse gas emissions. Future temperature
    anomalies in the study area simulated by global climate models of CMIP5 and IPSL-CM5A-LR
    under three climate scenarios (RCP4.5, RCP6.0 and RCP8.5) project a continuous
    warming trend between 2014 and 2100. Fig. 8b shows the time series of the average
    temperature anomaly simulated by all climate models between 1900 and 2100 with
    a statistically significant change point that occurred in 1999 and a projected
    warming trend of 0.19 °C/decade. Download : Download high-res image (902KB) Download
    : Download full-size image Fig. 8. Projection of temperature anomaly (a) average
    temperature anomaly trend (b). The warming trend in the study area varies spatially
    with the nature of land use. We compare the projected change with the projected
    LUC patterns over the study area. As a warming trend is expected to continue,
    especially in the mountains areas where the warming trend is projected at 0.55–0.83
    °C/decade between 2014 and 2050. In south and eastern parts of the Jizzan Province,
    warming is projected at 0.55 °C/decade (Fig. 9b), where Ragab and Prudhomme (2002)
    projected that the temperature may increase by 1.5–2.5 °C (0.41–0.7 °C/decade)
    in 2050. By 2075, mountains areas and its surroundings are projected to experience
    an increase in the mean annual temperature by 4.2–5 °C, a warming trend of 1.25–1.38
    °C/decade between 2050 and 2070, while the temperature of south and western parts
    of Jizzan province is projected to increase by 2.3 to 3.3 °C, a warming trend
    of 0.63–0.92 °C/decade between 2050 and 2075 (Fig. 9c). Download : Download high-res
    image (749KB) Download : Download full-size image Fig. 9. Average annual temperature
    (a) and future projection in 2050 (b) future projection in 2075 (c). The mean
    annual precipitation of Jizzan ranges spatially from 77 to 272 mm/year (Fig. 10a)
    with mountainous regions receiving the highest amount of 179–272 mm/year, followed
    by northeastern and northwestern regions with an annual rainfall ranging from
    140 to 272 mm/year. As expected, high spatial variability of rainfall in Jizzan
    also means that Jizzan has high hydrologic variability (e.g., Jiang et al., 2014;
    Mwale et al., 2009). However, the annual rainfall of Jizzan projected to 2050
    (Fig. 10b) is expected to decline by 6% in southeastern regions of Jizzan, and
    by 3% in northwestern, eastern, and southwestern regions which are occupied by
    built-up areas, crops, forest, and bare soil. The negative trend is projected
    to worsen from 2050 to 2075 (Fig. 10c), by as much as 8% in the mean annual rainfall
    in northwestern, eastern, and southwestern regions. However, the negative trend
    is projected to be only 2% in both the southeastern and central regions. Download
    : Download high-res image (793KB) Download : Download full-size image Fig. 10.
    Average annual precipitation (a) and future projection in 2050 (b) future projection
    in 2075 (c). 4.3. Land use change prediction The landuse of Jizzan is projected
    to increase in urbanization and irrigated cropland in 2025, 2050, 2075, and 2100
    as presented in Table 7 and Fig. 11. The bare soil area is projected to decrease
    from 7020.1 km2 in 2014 to 6498.4 km2 in 2025, while water bodies areas are projected
    to decrease from 73.4 km2 in 2014 to 63.8 km2 in 2025. In contrast, urban areas
    are projected to increase from 2456.4 km2 in 2014 to 2640.6 km2 in 2025, and then
    to 2732.9 km2 in 2050. Similarly, sparse vegetation, and forest and shrubland
    are projected to increase from 1120.3 km2 and 548.1 km2 in 2014 to 1169.3 km2
    and 648.5 km2 in 2025, respectively. In addition, irrigated cropland is projected
    to substantially increase from 1963.6 km2 in 2014 to 2161.2 km2 in 2025. By 2050,
    irrigated cropland is also projected to expand from an area of 2161 km2 in 2025
    to 2279.0 km2 in 2050, or a projected increase of 5% (Table 8). In contrast, bare
    soil is projected to decrease by 5%, sparse vegetative cover to decrease by 1%,
    but water bodies are projected to decrease significantly by almost 8% due to continued
    urbanization. For forest and shrubland, the model projected a 17% increase between
    2025 and 2050. By 2075, the model projected urban areas, irrigated cropland, forest,
    and shrubland to increase by 0.8%, 1.5%, and 3%, respectively, but water bodies,
    bare soil, and sparsely vegetated land are projected to decline by 15%, 1%, and
    0.2%, respectively. However, between 2075 and 2100, urban areas, irrigated cropland,
    forest and shrubland, and sparsely vegetated areas are projected to increase by
    1%, 4%, 0.5%, and 1% respectively. In contrast, water bodies are projected to
    decrease by 13% of its area in 2075, a slight decrease is also projected in bare
    soil by 2% of its area in 2075 (Table 8). Download : Download high-res image (889KB)
    Download : Download full-size image Fig. 11. Spatial distribution of projected
    LULC a) 2025, b) 2050, c) 2075, d) 2100. Urbanization further exacerbated the
    climate change impact of rising greenhouse gases in the province, as warming trend
    became statistically significant after 1970, which happened to be the year urbanization
    began to exhibit increasing trend. Spatially, the annual temperature is projected
    to increase most significantly within urban areas and mountainous regions by 2050
    and 2075. Mountainous areas are projected to be much warmer because the cooling
    effect of evapotranspiration is significantly reduced by deforestation, which
    were previously occupied by shrubland and forest reflects the impacts of deforestation
    in the warming trend. 4.4. Impacts of land use change and climate change on Fauna
    and Flora Results collected from the field survey and from the questionnaire reveal
    a strong agreement between our study and local residents, that increasing emissions
    of greenhouse gases and human activities have led to climate warming in the study
    area and a significant decline in its ecosystem services. For their survival,
    in the past 50 years, many wild animals had migrated to cities and villages in
    search of water, which may jeopardize human health and life. LUC due to urbanization
    of rural and mountainous areas have likely contributed to the decline in annual
    rainfall at about 12.2 mm/decade and the biodiversity of these areas. For example,
    the Arabian Baboon (Papio hamadryas) populations were partially controlled by
    their natural predators, leopards (Panthera pardus) and striped hyenas (Hyaena
    hyaena) but these predators have been hunted to extinction in these regions which
    have the habitats needed by the predators. On the other hand, these areas are
    facing serious threats of loosing of their habitats due to major agricultural
    expansion and irrigation projects (Biquand et al., 1992 and Winney et al., 2004).
    In other words, aforementioned human activities have led to significant degradation
    of the environment, impacts on the Afrotropical biodiversity of the region, coastal
    marine ecosystems, fragmentation and destruction of habitats. The draining of
    coastal areas for tourism and ornamental projects have caused marked declines
    of many species of mammals and birds that rely on this habitat for food (Nasser
    et al., 2015), either being eliminated or have migrated to other areas. Wading
    shorebirds, for example, have lost their niche due to the urbanization of most
    coastal areas in the Jizzan Province. The Farasan Islands, the first conservation
    protected area in Saudi Arabia, is home to the endangered Arabian gazelle, Gazella
    arabica (Lichtenstein), and serves as a rest area for many migratory bird in their
    migration route between Europe, northern Asia, and Africa. Farasan Ghazal is a
    distinctive subspecies of well-known Arabic gazelle, native to the islands. For
    the last fifty years, this island supported large populations of Farasan Ghazal
    because of low human impacts and consistent high annual rainfall (Thouless, 1991;
    Thouless and Al Bassri, 1991). Unfortunately, overhunting and a gradual decrease
    in the annual rainfall has led to a major collapse of this animal''s population.
    LUC has probably been a stronger driver of twentieth-century changes in wild plants
    and animals than climate change (Parmesan and Yohe, 2003). LUC pattern showed
    a large decline in flora and natural vegetation cover in the study area partly
    because rainwater, the only source of water that supports fauna and flora, has
    been decreasing in recent years. Moreover, significant deforestation, rapid urbanization,
    increased greenhouse gases have direct effects in plant distributions, as discussed
    before. Another impact of climate change is more ET loss, which in turn decrease
    the soil moisture and affecting plant growth (Narasimhan and Srinivasan, 2005).
    The annual ET time series estimated from local climatic factors for the study
    area over 1950–2014 (Fig. 12) has a statistically significant change point in
    1975 with positive trend of 5.5 mm/decade. The rising trend in ET would increase
    plant stress and enhance drought conditions. The annual ET is also projected to
    increase significantly from 1500 mm/yr in 2014 to about 1850 mm/yr in 2100. If
    precipitation surplus, the net flux of water from the atmosphere to the soil surface
    is positive, it means wet soil; if it is negative, we will expect dry soil (Swenson
    and Wahr, 2006). Fig. 13 shows a significant increase in water losses from the
    soil profile over time which means dry soil and it is expected to continue according
    to our future projection. Therefore, under diminishing soil moisture, warming
    trend and rapid urbanization, we expect the flora and natural vegetation cover
    in the study area to continue to decline in the 21st Century. Download : Download
    high-res image (313KB) Download : Download full-size image Fig. 12. Annual evapotranspiration
    trend and future projection. Download : Download high-res image (375KB) Download
    : Download full-size image Fig. 13. Annual precipitation surplus and future projection.
    5. Conclusions and recommendations We investigated the impact of anthropogenic
    climate change and human activities such as LUC on the environment and ecosystem
    services in the Jizzan Province, Arabia. First, we used earth observation data
    of the Landsat satellite to derive historical, 1970–2014, land use maps of Jizzan.
    Next, we used a Markov-CA model to project the dynamics of its LUC pattern over
    2014–2100 in response to human activities and their impacts on the study area''s
    climate, environment, and water resources. We applied Pettit''s and Mann-Kendall
    tests to detect change points and to estimate trends of temperature data of 1900–2010
    and precipitation data of 1948–2014 and their anomalies, respectively. We have
    also detected change points and estimated trends of data of CO2 and several rare
    gases emitted between 1960 and 2015. Climate scenarios (RCP4.5, RCP6.0 and RCP8.5)
    of the study area projected by climate models of CMIP5 were used to project future
    warming in the study area between 2014 and 2100. Urbanization and LUC has significant
    impact the ecosystems, biodiversity and natural habitats of the Jizzan province.
    In 1970s, human impacts were minimal. However, following the construction of rain-harvesting
    dams which capture most surface runoff, and with urban expansion at about 53.4
    km2 yr−1 which extended into coastal regions, areas of forest, shrubland, sparse
    vegetative cover, bare soil and water bodies declined markedly over 1990–2014.
    Likely due to climate change impact and urbanization, a statistically significant
    change point was detected in the monthly temperature data of Jizzan in 1968 and
    a warming trend of 0.24 °C per decade after 1970. The precipitation data also
    had a statistically significant change point in 1967, but a negative trend of
    12.2 mm/decade. Observed changes in the hydro-climatology of Jizzan are likely
    associated with significant LUC, such as urbanization and agricultural development
    (irrigated croplands) at the expense of vegetative cover, forest, shrubland, and
    sparse vegetative cover since 1970s. A statistically significant change point
    was detected in CO2 emissions data in 1985 and statistically significant positive
    trend of 94,340 Kt/decade. Other anthropogenic greenhouse gases mainly due to
    industrial processes also have a statistically significant positive trend of 488.5
    Kt/decade. On a whole, total greenhouse gas emissions including all anthropogenic
    sources have been increasing at a statistically significant trend of 78,090 Kt/decade
    after 1991. Therefore, it is very likely that long-term increasing emission of
    greenhouse gases, and aforementioned human activities have resulted in warming
    trends observed in the study area and globally. Future projection of temperature
    anomaly between 1900 and 2100 showed a statistically significant future warming
    trend of 0.19 °C/decade after 1999. The spatial distribution of the projected
    annual temperature in 2050 and 2075, also shows that the highest increase in temperature
    is within urban areas and the mountains regions. The increase in the warming trend
    in the mountains areas which were previously occupied by shrubland and forest
    reflects the impacts of deforestation in the warming trend. The warming trend
    in mountains regions is estimated at 0.55–0.83 °C/decade between 2014 and 2050,
    and at 0.55 °C/decade in south and eastern parts of Jizzan Province. Precipitation
    is projected to continue declining while LUC such as urbanization and irrigated
    cropland are projected to continue towards the end of the 21st Century. In conclusion,
    to reduce the impacts of climate change and LUC, conservation plans for the Jizzan
    Province are essential to mitigate the significant impact human activities and
    global warming on the environment and ecosystem services of the study area in
    the 21st Century. Acknowledgments This work is part of the doctoral research of
    the first author at the Department of Civil and Environmental Engineering, University
    of Alberta, and was funded by a recruitment scholarship of the University of Alberta,
    and the discovery grant of Natural Science and Engineering Research Council of
    Canada. The authors would like to thank the reviewers for their constructive comments
    which have improved the quality of the paper. References Abtew and Melesse, 2013
    W. Abtew, A. Melesse Climate change and evapotranspiration Evaporation and Evapotranspiration
    (2013), pp. 197-202 CrossRefGoogle Scholar Allen et al., 1998 R.G. Allen, L.S.
    Pereira, D. Raes, M. Smith Crop evapotranspiration-Guidelines for computing crop
    water requirements-FAO Irrigation and drainage paper 56 FAO, 300 (9) (1998), p.
    D05109 (Rome) Google Scholar Anderson et al., 1976 J. Anderson, E.E. Hardy, J.T.
    Roach, R.E. Witmer A Land Use and Land Cover Classification System for Use With
    Remote Sensor Data. US Geological Survey, Professional Paper (1976), p. 964 View
    in ScopusGoogle Scholar Araya and Cabral, 2010 Y.H. Araya, P. Cabral Analysis
    and modeling of urban land cover change in Setúbal and Sesimbra, Portugal Remote
    Sens., 2 (2010), pp. 1549-1563 CrossRefView in ScopusGoogle Scholar Baker et al.,
    2006 C. Baker, R. Lawrence, C. Montagne, D. Patten Mapping wetlands and riparian
    areas using Landsat ETM+ imagery and decision-tree-based models Wetlands, 26 (2)
    (2006), pp. 465-474 View in ScopusGoogle Scholar Biquand et al., 1992 S. Biquand,
    V. Biquand-Guyot, A. Boug, J.P. Gautier The distribution of Papio hamadryas in
    Saudi Arabia: ecological correlates and human influence Int. J. Primatol., 13
    (3) (1992), pp. 223-243 View in ScopusGoogle Scholar Clarke and Gaydos, 1998 K.C.
    Clarke, L.J. Gaydos Loose coupling a cellular automaton model and GIS: long-term
    urban growth prediction for San Francisco and Washington/Baltimore Int. J. Geogr.
    Inf. Sci., 12 (7) (1998), pp. 699-714 View in ScopusGoogle Scholar Dale et al.,
    2011 V.H. Dale, R.A. Erosion, K.L. Kline The land use–climate change–energy nexus
    Landsc. Ecol., 26 (6) (2011), pp. 755-773 CrossRefView in ScopusGoogle Scholar
    Dawood, 2017 M. Dawood Spatio-statistical analysis of temperature fluctuation
    using Mann-Kendall and Sen''s slope approach Clim. Dyn., 48 (3–4) (2017), pp.
    783-797 Google Scholar Frias et al., 2006 M.D. Frias, E. Zorita, J. Fernández,
    C. Rodriguez-Puebla Testing statistical downscaling methods in simulated climates
    Geophys. Res. Lett., 33 (19) (2006) Google Scholar Fu et al., 2017 Q. Fu, B. Li,
    Y. Hou, X. Bi, X. Zhang Effects of land use and climate change on ecosystem services
    in Central Asia''s arid regions: a case study in Altay prefecture, China Sci.
    Total Environ., 607 (2017), pp. 633-646 View PDFView articleView in ScopusGoogle
    Scholar Guan et al., 2011 D. Guan, H. Li, T. Inohae, W. Su, T. Nagaie, K. Hokao
    Modeling urban land use change by the integration of cellular automaton and Markov
    model Ecol. Model., 222 (20) (2011), pp. 3761-3772 View PDFView articleView in
    ScopusGoogle Scholar Guo et al., 2014 Y. Guo, J. Li, Y. Li Seasonal forecasting
    of North China summer rainfall using a statistical downscaling model J. Appl.
    Meteorol. Climatol., 53 (7) (2014), pp. 1739-1749 View in ScopusGoogle Scholar
    Han and Jia, 2017 Y. Han, H. Jia Simulating the spatial dynamics of urban growth
    with an integrated modeling approach: a case study of Foshan, China Ecol. Model.,
    353 (2017), pp. 107-116 View PDFView articleGoogle Scholar Huishi et al., 2012
    D. Huishi, H. Eerdun, Y. Yi, A. Jing Land Coverage Changes in the Hulun Buir Grassland
    of China Based on the Cellular Automata-Markov Model International Proceedings
    of Chemical, Biological & Environmental Engineering (2012), pp. 69-74 Google Scholar
    Huang et al., 2014 Q. Huang, C. He, Z. Liu, P. Shi Modeling the impacts of drying
    trend scenarios on land systems in northern China using an integrated SD and CA
    model Sci. China Earth Sci., 57 (4) (2014), pp. 839-854 CrossRefView in ScopusGoogle
    Scholar IPCC, 2013 IPCC Climate Change 2013: The Physical Science Basis Contribution
    of Working Group I to the Fifth Assessment Report of the Intergovernmental Panel
    on Climate Change (2013) 1535 pp Google Scholar Jiang et al., 2014 R.G. Jiang,
    T.Y. Gan, J. Xie, W. Ni Spatiotemporal variability of Alberta''s seasonal precipitation,
    their teleconnection with large-scale climate anomalies and sea surface temperature
    Int. J. Climatol., 34 (9) (2014), pp. 2899-2917, 10.1002/joc.3883 View in ScopusGoogle
    Scholar Jiménez-Bello et al., 2012 M.A. Jiménez-Bello, L.A. Ruiz, T. Hermosilla,
    J. Recio, D.S. Intrigliolo Use of remote sensing and geographic information tools
    for irrigation management of citrus trees Options Mediterranéennes B, 67 (2012),
    pp. 65-75 Google Scholar Kang et al., 1999 S. Kang, F. Zhang, Y. Liang Effects
    of soil water and the atmospheric CO2 concentration increase on evapotranspiration,
    photosynthesis, growth of wheat, maize and cotton Acta Agron. Sin., 25 (1999),
    pp. 55-63 View in ScopusGoogle Scholar Keshtkar and Voigt, 2016 H. Keshtkar, W.
    Voigt A spatiotemporal analysis of landscape change using an integrated Markov
    chain and cellular automata models Model. Earth Syst. Environ., 2 (1) (2016),
    p. 10 View in ScopusGoogle Scholar Liang et al., 2017 J. Liang, M. Zhong, G. Zeng,
    G. Chen, S. Hua, X. Li, Y. Yuan, H. Wu, X. Gao Risk management for optimal land
    use planning integrating ecosystem services values: a case study in Changsha,
    middle China Sci. Total Environ., 579 (2017), pp. 1675-1682 View PDFView articleView
    in ScopusGoogle Scholar Long et al., 2007 H. Long, G. Tang, X. Li, G.K. Heilig
    Socio-economic driving forces of land-use change in Kunshan, the Yangtze River
    Delta economic area of China J. Environ. Manag., 83 (3) (2007), pp. 351-364 View
    PDFView articleView in ScopusGoogle Scholar Longley and Batty, 1996 P. Longley,
    M. Batty Spatial Analysis: Modeling in a GIS Environment Geo-Information International,
    Cambridge, UK (1996), pp. 1-15 CrossRefGoogle Scholar Lu et al., 2004 D. Lu, P.
    Mausel, E. Brondízio, E. Moran Change detection techniques Int. J. Remote Sens.,
    25 (12) (2004), pp. 2365-2407 View in ScopusGoogle Scholar Ma et al., 2008 Z.
    Ma, S. Kang, L. Zhang, L. Tong, X. Su Analysis of impacts of climate variability
    and human activity on streamflow for a river basin in arid region of northwest
    China J. Hydrol., 352 (3) (2008), pp. 239-249 View PDFView articleView in ScopusGoogle
    Scholar Mahé and Paturel, 2009 G. Mahé, J.E. Paturel 1896–2006 Sahelian annual
    rainfall variability and runoff increase of Sahelian rivers Compt. Rendus Geosci.,
    341 (7) (2009), pp. 538-546 View PDFView articleCrossRefView in ScopusGoogle Scholar
    Marshall and Randhir, 2008 E. Marshall, T.O. Randhir Spatial modeling of land
    cover change and watershed response using Markovian cellular automata and simulation
    Water Resour. Res., 44 (4) (2008) Google Scholar Martínez et al., 2010 M.D. Martínez,
    C. Serra, A. Burgueño, X. Lana Time trends of daily maximum and minimum temperatures
    in Catalonia (ne Spain) for the period 1975–2004 Int. J. Climatol., 30 (2) (2010),
    pp. 267-290 CrossRefView in ScopusGoogle Scholar Mukherjee et al., 2010 S. Mukherjee,
    C.K. Singh, S. Shashtri, R. Avtar, S.K. Singh Monitoring change in land use and
    land cover in Rupnagar district of Punjab, India using Landsat and IRS LISS III
    satellite data Ecol. Quest., 13 (1) (2010), p. 73 CrossRefView in ScopusGoogle
    Scholar Mwale et al., 2009 D. Mwale, T.Y. Gan, K. Devito, Silins Precipitation
    variability & its relationship to hydrologic variability and physical features
    in Alberta Hydrol. Proc., 23 (21) (2009), pp. 3040-3056, 10.1002/hyp.7415 View
    in ScopusGoogle Scholar Myint and Wang, 2006 S.W. Myint, L. Wang Multicriteria
    decision approach for land use land cover change using Markov chain analysis and
    a cellular automata approach Can. J. Remote. Sens., 32 (6) (2006), pp. 390-404
    CrossRefView in ScopusGoogle Scholar Narasimhan and Srinivasan, 2005 B. Narasimhan,
    R. Srinivasan Development and evaluation of soil moisture deficit index (SMDI)
    and evapotranspiration deficit index (ETDI) for agricultural drought monitoring
    Agric. For. Meteorol., 133 (1–4) (2005), pp. 69-88 View PDFView articleView in
    ScopusGoogle Scholar Nasser et al., 2015 M.G.E.D. Nasser, A. Al-Ahmed, M.J. Ansari,
    M.Y. Shobrak Chewing lice (Phthiraptera) infesting breeding Suliformes (Aves:
    Aequornithes) of the Arabian Peninsula Afr. Invertebr., 56 (3) (2015), pp. 709-717
    CrossRefView in ScopusGoogle Scholar Nasta et al., 2017 P. Nasta, M. Palladino,
    N. Ursino, A. Saracino, A. Sommella, N. Romano Assessing long-term impact of land-use
    change on hydrological ecosystem functions in a Mediterranean upland agro-forestry
    catchment Sci. Total Environ., 605 (2017), pp. 1070-1082 View PDFView articleView
    in ScopusGoogle Scholar Panda et al., 2009 S.S. Panda, G. Hoogenboom, J. Paz Distinguishing
    blueberry bushes from mixed vegetation land use using high resolution satellite
    imagery and geospatial techniques Comput. Electron. Agric., 67 (1) (2009), pp.
    51-58 View PDFView articleView in ScopusGoogle Scholar Parmesan and Yohe, 2003
    C. Parmesan, G. Yohe A globally coherent fingerprint of climate change impacts
    across natural systems Nature, 421 (6918) (2003), p. 37 View in ScopusGoogle Scholar
    Pastor et al., 1993 J. Pastor, J. Bonde, C. Johnston, R.J. Naiman Markovian analysis
    of the spatially dependent dynamics of beaver ponds. Lectures on mathematics in
    the Life Sci., 23 (1993), pp. 5-27 Google Scholar Perrings et al., 2011 C. Perrings,
    A. Duraiappah, A. Larigauderie, H. Mooney The biodiversity and ecosystem services
    science-policy interface Science, 331 (6021) (2011), pp. 1139-1140 CrossRefView
    in ScopusGoogle Scholar Petrosillo et al., 2013 I. Petrosillo, T. Semeraro, N.
    Zaccarelli, R. Aretano, G. Zurlini The possible combined effects of land-use changes
    and climate conditions on the spatial-temporal patterns of primary production
    in a natural protected area Ecol. Indic., 29 (2013), pp. 367-375 View PDFView
    articleView in ScopusGoogle Scholar Pettit, 1979 A.N. Pettit A non-parametric
    approach to the change point problem Appl. Stat., 28 (1979), pp. 126-135 Google
    Scholar Pielke, 2005 R.A. Pielke Land use and climate change Science, 310 (5754)
    (2005), pp. 1625-1626 CrossRefView in ScopusGoogle Scholar Pielke et al., 2007
    R.A. Pielke, J. Adegoke, A. Beltrán-Przekurat, C.A. Hiemstra, J. Lin, U.S. Nair,
    D. Niyogi, T.E. Nobis An overview of regional land-use and land-cover impacts
    on rainfall Tellus B, 59 (3) (2007), pp. 587-601 View in ScopusGoogle Scholar
    Pontius and Malanson, 2005 G.R. Pontius, J. Malanson Comparison of the structure
    and accuracy of two land change models Int. J. Geogr. Inf. Sci., 19 (2005), pp.
    243-265 CrossRefView in ScopusGoogle Scholar Prestele et al., 2017 R. Prestele,
    A. Arneth, A. Bondeau, N. de Noblet-Ducoudré, T.A. Pugh, S. Sitch, E. Stehfest,
    P.H. Verburg Current challenges of implementing anthropogenic land-use and land-cover
    change in models contributing to climate change assessments Earth Syst. Dynam.,
    8 (2) (2017), p. 369 CrossRefView in ScopusGoogle Scholar Ragab and Prudhomme,
    2002 R. Ragab, C. Prudhomme Sw—soil and water: climate change and water resources
    management in arid and semi-arid regions: prospective and challenges for the 21st
    century Biosyst. Eng., 81 (1) (2002), pp. 3-34 View PDFView articleView in ScopusGoogle
    Scholar Reeves et al., 2018 M.C. Reeves, M.E. Manning, J.P. DiBenedetto, K.A.
    Palmquist, W.K. Lauenroth, J.B. Bradford, D.R. Schlaepfer Effects of climate change
    on rangeland vegetation in the Northern Rockies Climate Change and Rocky Mountain
    Ecosystems, Springer, Cham (2018), pp. 97-114 CrossRefView in ScopusGoogle Scholar
    Ridd and Liu, 1998 M. Ridd, J. Liu A comparison of four algorithms for change
    detection in an urban environment Remote Sens. Environ., 63 (1998), pp. 95-100
    View PDFView articleView in ScopusGoogle Scholar Schleusener et al., 2013 F. Schleusener,
    S. Kempe, H. Dirks, R. Rausch, P.D.P. Göbel Die Erdfälle von Layla und Al-Kharj–Einblicke
    in die Karst-Hydrogeologie des oberen Jura von Saudi Arabien Grundwasser, 18 (4)
    (2013), pp. 271-276 CrossRefView in ScopusGoogle Scholar Searchinger et al., 2008
    T. Searchinger, R. Heimlich, R.A. Houghton, F. Dong, A. Elobeid, J. Fabiosa, S.
    Tokgoz, D. Hayes, T.H. Yu Use of US croplands for biofuels increases greenhouse
    gases through emissions from land-use change Science, 319 (5867) (2008), pp. 1238-1240
    CrossRefView in ScopusGoogle Scholar Sen, 1968 P.K. Sen Estimates of the regression
    coefficient based on Kendall''s tau J. Am. Stat. Assoc., 63 (1968), pp. 1379-1389
    View in ScopusGoogle Scholar Shalaby and Tateishi, 2007 A. Shalaby, R. Tateishi
    Remote sensing and GIS for mapping and monitoring land cover and land-use changes
    in the northwestern coastal zone of Egypt Appl. Geogr., 27 (1) (2007), pp. 28-41
    View PDFView articleView in ScopusGoogle Scholar Singh et al., 2015 S.K. Singh,
    S. Mustak, P.K. Srivastava, S. Szabó, T. Islam Predicting spatial and decadal
    LULC changes through cellular automata Markov chain models using earth observation
    datasets and geo-information Environ. Process., 2 (1) (2015), pp. 61-78 Google
    Scholar Sirami et al., 2017 C. Sirami, P. Caplat, S. Popy, A. Clamens, R. Arlettaz,
    F. Jiguet, L. Brotons, J.L. Martin Impacts of global change on species distributions:
    obstacles and solutions to integrate climate and land use Glob. Ecol. Biogeogr.,
    26 (4) (2017), pp. 385-394 CrossRefView in ScopusGoogle Scholar Sneyers, 1992
    R. Sneyers On the use of statistical analysis for the objective determination
    of climate change Meteorologische Z. (1992), 1 (5) (1992), pp. 247-256 Google
    Scholar Swenson and Wahr, 2006 S. Swenson, J. Wahr Estimating large-scale precipitation
    minus evapotranspiration from GRACE satellite gravity measurements J. Hydrometeorol.,
    7 (2) (2006), pp. 252-270 View in ScopusGoogle Scholar Thouless, 1991 C. Thouless
    Conservation in Saudi Arabia Oryx, 25 (1991), pp. 222-228 CrossRefView in ScopusGoogle
    Scholar Thouless and Al Bassri, 1991 C.R. Thouless, K. Al Bassri Taxonomic status
    of the Farasan Island gazelle J. Zool., 223 (1991), pp. 151-159 CrossRefView in
    ScopusGoogle Scholar Thouless et al., 1991 C.R. Thouless, J.G. Grainger, M. Shobrak,
    K. Habibi Conservation status of gazelles in Saudi Arabia Biol. Conserv., 58 (1)
    (1991), pp. 85-98 View PDFView articleView in ScopusGoogle Scholar Tong et al.,
    2012 S.T. Tong, Y. Sun, T. Ranatunga, J. He, Y.J. Yang Predicting plausible impacts
    of sets of climate and land use change scenarios on water resources Appl. Geogr.,
    32 (2) (2012), pp. 477-489 View PDFView articleView in ScopusGoogle Scholar Townshend,
    1981 J.R.G. Townshend Terrain Analysis and Remote Sensing George Allen and Unwin,
    London, UK (1981) Google Scholar Verburg et al., 2011 P.H. Verburg, K. Neumann,
    L. Nol Challenges in using land use and land cover data for global change studies
    Glob. Chang. Biol., 17 (2) (2011), pp. 974-989 CrossRefView in ScopusGoogle Scholar
    Wang et al., 2009 H. Wang, X. Li, H. Long, Y. Gai, D. Wei Monitoring the effects
    of land use and cover changes on net primary production: a case study in China''s
    Yongding River basin For. Ecol. Manag., 258 (12) (2009), pp. 2654-2665 View PDFView
    articleView in ScopusGoogle Scholar Weng, 2001 Q. Weng A remote sensing? GIS evaluation
    of urban expansion and its impact on surface temperature in the Zhujiang Delta,
    China Int. J. Remote Sens., 22 (10) (2001), pp. 1999-2014 View in ScopusGoogle
    Scholar Wilson and Weng, 2011 C.O. Wilson, Q. Weng Simulating the impacts of future
    land use and climate changes on surface water quality in the Des Plaines River
    watershed, Chicago metropolitan statistical area, Illinois Sci. Total Environ.,
    409 (20) (2011), pp. 4387-4405 View PDFView articleView in ScopusGoogle Scholar
    Winney et al., 2004 B.J. Winney, R.L. Hammond, W. Macasero, B. Flores, A. Boug,
    V. Biquand, Sylvain Biquand, M.W. Bruford Crossing the Red Sea: phylogeography
    of the hamadryas baboon, Papio hamadryas Mol. Ecol., 13 (9) (2004), pp. 2819-2827
    View in ScopusGoogle Scholar Woldesenbet et al., 2017 T.A. Woldesenbet, N.A. Elagib,
    L. Ribbe, J. Heinrich Hydrological responses to land use/cover changes in the
    source region of the upper Blue Nile Basin, Ethiopia Sci. Total Environ., 575
    (2017), pp. 724-741 View PDFView articleView in ScopusGoogle Scholar Yagoub and
    Al Bizreh, 2014 M.M. Yagoub, A.A. Al Bizreh Prediction of land cover change using
    Markov and cellular automata models: case of Al-Ain, UAE, 1992–2030 J. Indian
    Soc. Remote Sens., 42 (3) (2014), pp. 665-671 CrossRefView in ScopusGoogle Scholar
    Yang et al., 2014 X. Yang, X.Q. Zheng, R. Chen A land use change model: integrating
    landscape pattern indexes and Markov-CA Ecol. Model., 283 (2014), pp. 1-7 View
    PDFView articleGoogle Scholar Yue et al., 2002 S. Yue, P. Pilon, G. Cavadias Power
    of the Mann-Kendall and Spearman''s Rho tests for detecting monotonic trends in
    hydrological series J. Hydrol., 259 (1) (2002), pp. 254-271 View PDFView articleView
    in ScopusGoogle Scholar Zhang et al., 2000 X. Zhang, L.A. Vincent, W.D. Hogg,
    A. Niitsoo Temperature and precipitation trends in Canada during the 20th century
    Atmosphere-Ocean, 38 (3) (2000), pp. 395-429 CrossRefView in ScopusGoogle Scholar
    Zhang et al., 2009 J. Zhang, L. Zhengjun, S. Xiaoxia Changing landscape in the
    three gorges reservoir area of Yangtze River from 1977 to 2005: land use/land
    cover, vegetation cover changes estimated using multi-source satellite data Int.
    J. Appl. Earth Obs. Geoinf., 11 (6) (2009), pp. 403-412 View PDFView articleView
    in ScopusGoogle Scholar Cited by (125) Assessment of land use/ land cover change
    derived catchment hydrologic response: An integrated parsimonious hydrological
    modeling and alteration analysis based approach 2024, Journal of Environmental
    Management Show abstract Investigating the spatio-temporal interactive relationship
    between land use structure and ecosystem services in urbanizing China 2024, Ecological
    Indicators Show abstract Spatio-temporal dynamics of land use transitions associated
    with human activities over Eurasian Steppe: Evidence from improved residual analysis
    2023, Science of the Total Environment Show abstract Spatiotemporal evolution
    and impact mechanism of ecological vulnerability in the Guangdong–Hong Kong–Macao
    Greater Bay Area 2023, Ecological Indicators Show abstract Environmental heterogeneity
    associated with boat activity shapes bacteria and microeukaryotic communities
    with discrepant response patterns 2023, Science of the Total Environment Show
    abstract The impact of heterogeneous human activity on vegetation patterns in
    arid environments 2023, Communications in Nonlinear Science and Numerical Simulation
    Show abstract View all citing articles on Scopus View Abstract © 2018 Elsevier
    B.V. All rights reserved. Recommended articles Carrier flies of multidrug-resistant
    Escherichia coli as potential dissemination agent in dairy farm environment Science
    of The Total Environment, Volume 633, 2018, pp. 1345-1351 Taila dos Santos Alves,
    …, Domingos da Silva Leite View PDF The impact of anthropogenic activities on
    marine environment in Jiaozhou Bay, Qingdao, China: A review and a case study
    Regional Studies in Marine Science, Volume 8, Part 2, 2016, pp. 287-296 Yuan Yuan,
    …, Zhaopeng Ren View PDF Impacts of climate change and human activities on vegetation
    cover in hilly southern China Ecological Engineering, Volume 81, 2015, pp. 451-461
    Jing Wang, …, Chunhua Zhang View PDF Show 3 more articles Article Metrics Citations
    Citation Indexes: 115 Policy Citations: 1 Captures Readers: 229 View details About
    ScienceDirect Remote access Shopping cart Advertise Contact and support Terms
    and conditions Privacy policy Cookies are used by this site. Cookie settings |
    Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V.,
    its licensors, and contributors. All rights are reserved, including those for
    text and data mining, AI training, and similar technologies. For all open access
    content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: Science of the Total Environment
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Impact of anthropogenic climate change and human activities on environment
    and ecosystem services in arid regions
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Islam M.S.
  - Khreich W.
  - Hamou-Lhadj A.
  citation_count: '27'
  description: Ensemble-based anomaly detection systems (ADSs), using Boolean combination,
    have been shown to reduce the false alarm rate over that of a single detector.
    However, the existing Boolean combination methods rely on an exponential number
    of combinations making them impractical, even for a small number of detectors.
    In this paper, we propose weighted pruning-based Boolean combination, an efficient
    approach for selecting and combining accurate and diverse anomaly detectors. It
    works in three phases. The first phase selects a subset of the available base
    diverse soft detectors by pruning all the redundant soft detectors based on a
    weighted version of Cohen's kappa measure of agreement. The second phase selects
    a subset of diverse and accurate crisp detectors from the base soft detectors
    (selected in Phase1) based on the unweighted kappa measure. The selected complementary
    crisp detectors are then combined in the final phase using Boolean combinations.
    The results on two large scale datasets show that the proposed weighted pruning
    approach is able to maintain and even improve the accuracy of existing Boolean
    combination techniques, while significantly reducing the combination time and
    the number of detectors selected for combination.
  doi: 10.1109/TR.2017.2787138
  full_citation: '>'
  full_text: '>

    "IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account
    Personal Sign In Browse My Settings Help Access provided by: University of Nebraska
    - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards
    Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Transactions on Reliabil...
    >Volume: 67 Issue: 1 Anomaly Detection Techniques Based on Kappa-Pruned Ensembles
    Publisher: IEEE Cite This PDF Md. Shariful Islam; Wael Khreich; Abdelwahab Hamou-Lhadj
    All Authors 26 Cites in Papers 630 Full Text Views Abstract Document Sections
    I. Introduction II. Related Research III. HMMs for Anomaly Detection Using System
    Call Sequences IV. ROC-Based Boolean Combination Techniques V. Proposed Weighted
    Pruning Technique Show Full Outline Authors Figures References Citations Keywords
    Metrics Footnotes Abstract: Ensemble-based anomaly detection systems (ADSs), using
    Boolean combination, have been shown to reduce the false alarm rate over that
    of a single detector. However, the existing Boolean combination methods rely on
    an exponential number of combinations making them impractical, even for a small
    number of detectors. In this paper, we propose weighted pruning-based Boolean
    combination, an efficient approach for selecting and combining accurate and diverse
    anomaly detectors. It works in three phases. The first phase selects a subset
    of the available base diverse soft detectors by pruning all the redundant soft
    detectors based on a weighted version of Cohen''s kappa measure of agreement.
    The second phase selects a subset of diverse and accurate crisp detectors from
    the base soft detectors (selected in Phase1) based on the unweighted kappa measure.
    The selected complementary crisp detectors are then combined in the final phase
    using Boolean combinations. The results on two large scale datasets show that
    the proposed weighted pruning approach is able to maintain and even improve the
    accuracy of existing Boolean combination techniques, while significantly reducing
    the combination time and the number of detectors selected for combination. Published
    in: IEEE Transactions on Reliability ( Volume: 67, Issue: 1, March 2018) Page(s):
    212 - 229 Date of Publication: 30 January 2018 ISSN Information: DOI: 10.1109/TR.2017.2787138
    Publisher: IEEE Nomenclature 5FCV Fivefold cross validation. ADFA−LD ADFA linux
    dataset. ADS Anomaly detection system. AUC Area under the curve. BBC2 Pair-wise
    brute-force Boolean combination. BW Baum–Welc. CANALI-WD CANALI Windows dataset.
    EM Expectation-maximization. FB Forward-backward. HIDS Host-based intrusion detection
    system. HMM Hidden Markov model. IBC Iterative Boolean combination. NIDS Network
    intrusion detection system. OC−SVM One-class support vector machine. PBC Pruning
    Boolean combination. ROC Receiver operating characteristics. ROCCH Receiver operating
    characteristics convex hull. STIDE Sequence time-delay embedding. WPBC2 Pair-wise
    weighted pruning Boolean combination. WPIBC Weighted pruning iterative Boolean
    combination. Notations avg Average value on fivefold cross validation results.
    fpr False positive rate outputted by a crisp detector. kp−fpr Kappa versus false
    positive rate plotting diagram. kp−tpr Kappa versus true positive rate plotting
    diagram. max Maximum value on fivefold cross validation results. min Minimum value
    on fivefold cross validation results. std Standard deviation on fivefold cross
    validation. tpr True positive rate outputted by a crisp detector. SECTION I. Introduction
    Intrusion detection systems (IDS) are divided into two categories: Network intrusion
    detection systems (NIDS) and host-based intrusion detection systems (HIDS). A
    NIDS monitors and analyzes network traffic. It is transparent (i.e., it can move
    in different locations) and independent (i.e., it can work in different network
    topologies). An HIDS works on a host computer and monitors user activities to
    detect unauthorized access, illegitimate modification of configuration files,
    and other unwanted behaviors. IDS can be further classified into two categories:
    1) Signature-based (or misuse) IDS; and 2) anomaly detection systems (ADSs). The
    former can only detect known attacks [30], whereas the latter, the focus of this
    paper, is capable of detecting novel attacks by analyzing deviations from the
    normal behavior of a system. Anomaly detection methods often vary in their design
    depending on the application domain [62], but the common practice is to train
    a model that characterizes the normal behavior of a system. The model is used
    later as a baseline to detect deviations (anomalies) from normalcy. When a trained
    model produces scores instead of a decision (i.e., normal or anomalous), it is
    called a soft detector. When it produces a decision instead of scores, it is called
    a crisp detector. A soft detector can be converted into one or more crisp detectors
    by setting different thresholds on the output scores. A single crisp detector,
    however, is known to generate an excessive number of false alarms, which is one
    of the main reasons that limits deployment of ADS in commercial settings [20].
    Training an anomaly detector is a one-class classification problem that depends
    on the normal (or healthy) data. The detector, which in our case is based on HMM,
    is trained using the normal traces and expected to represent the normal behavior
    of the system. It should be noted that we used HMM because it has been shown to
    provide best accuracy [41] compared to other classification techniques. Our approach,
    however, can be used with any other one-class classification method. The combination
    of several soft or crisp detectors requires a labeled dataset including both normal
    and anomalous traces to be able to select the best crisp detectors, and the Boolean
    combination functions to optimize the performance (i.e., minimize the fpr and
    maximize the tpr ). In practice, the evaluation of an ADS requires a labeled validation
    set to select the operating thresholds (e.g., tolerable fpr ). Our approach takes
    further advantage of this validation set to select the operating thresholds and
    Boolean functions that yield the most accurate and concise ensemble of detectors,
    which will be used during system operation. In this paper, we propose a weighted
    pruning of Boolean combinations that selects the best subset of diverse base soft
    detectors by pruning all the redundant ones. Each diverse base soft detector is
    then used independently to select the complementary crisp detectors instead of
    brute-force search like in PBC. The complementary crisp detectors are then combined
    by leveraging both pair-wise brute-force Boolean combination (BBC2) and iterative
    Boolean combination (IBC) [1], [21], which shows that the pruning approach can
    be used with any Boolean combination approach. We leverage both weighted and unweighted
    Cohen''s kappa [46], [58] in order to select the best subset of diverse base soft
    detectors. Weighted Cohen''s kappa is a special case of simple kappa (unweighted
    kappa) that is particularly used when the agreements between two detectors are
    ordinal instead of nominal. In our case, the scores of a soft detector are ordinal,
    and the decision of a crisp detector based on a given threshold is nominal. Our
    weighted pruning approach prunes both soft and crisp detectors based on the ordinal
    agreements and the nominal agreements between two detectors. The selected diverse
    and accurate crisp detectors are then used for Boolean combination. During combination,
    we leverage both the pair-wise and IBC s introduced by Barreno et al. [1] and
    Khreich et al. [21], respectively. The proposed pair-wise weighted pruning Boolean
    combination (namely called WPBC2) fuses and combines all possible pairs of crisp
    detectors generated from the selected diverse base soft detectors. Whereas, the
    weighted pruning iterative Boolean combination (namely called WPIBC) fuses and
    combines the selected diverse base soft detectors sequentially until no significant
    improvement is possible. Another major contribution of this paper is the evaluation
    of our approach for detecting anomalies at the system call levels. We compare
    the performance of WPBC2 and WPIBC to that achieved with the original BBC2 and
    IBC techniques. In addition, we compare the performance of our approaches to pruning
    Boolean combination (PBC) [45]. In sum, the main contributions of this paper are
    as follows. We propose an anomaly detection approach that enforces the diversities
    among the combined soft and crisp detectors using weighted and unweighted Cohen''s
    kappa [46]. The approach can be used with both pair-wise and IBC techniques [1],
    [21], and easily adaptable to other Boolean combination methods. We evaluate our
    approach on two large publicly available system call datasets: ADFA linux dataset
    (ADFA-LD) [6] and CANALI windows dataset (CANALI-WD) [47]. We show that our approach
    outperforms BBC2, IBC, and PBC by achieving lower false positive rate, while maintaining
    and improving the detection accuracy, measured using area under the curve (AUC).
    The organization of this paper is as follows. The related anomaly detection approaches
    are discussed in Section II. HMM-based ADSs using system call sequences are discussed
    in Section III. The convex hull under the receiver operating characteristics (ROC)
    space and related Boolean combination techniques are explained in Section IV.
    The proposed weighted pruning-based Boolean combination techniques are discussed
    in Section V. Section VI presents the proposed method for pruning the Boolean
    combination as well as the results of the experiments that are carried out on
    two benchmarks datasets of system call sequences. The effects of pruning-based
    Boolean combination are discussed in Section VII. The limitations of our approach
    are discussed in Section VIII. The conclusion and future work are reported in
    Section IX. SECTION II. Related Research Anomaly detection is an important component
    used to enhance system reliability and security in a variety of domains. In their
    detailed survey, Chandola et al. [62] showed that anomaly detection is used in
    a wide variety of applications such as fraud detection for credit cards, insurance
    or health care, intrusion detection for cyber-security, fault detection in safety
    critical systems, and military surveillance for enemy activities. Anomaly detection
    techniques have also been shown useful in enforcing the reliability of software
    and hardware systems. Murtaza et al. [67] presented an approach and a supporting
    tool to detect program functions that are likely to introduce faults in a software
    system by examining historical execution traces. Their approach can be used to
    enhance testing and other software verification methods. In a recent study, Sha
    et al. [68] proposed an approach based on anomaly detection to ensure the safety
    of cloud-based IT infrastructures. Bovenzi et al. [69] proposed an approach for
    revealing anomalies at the operating system level to support online diagnosis
    activities of complex software systems. Yang et al. [70] proposed an efficient
    method for detecting abnormal executions of Java programs using sequential pattern
    mining. Gizopoulos et al. [71] argued that the huge investment in the design and
    production of multicore processors may be put at risk because of reliability threats,
    mainly due to the existence of bugs and vulnerabilities, unless these systems
    are equipped with robust anomaly detection tools. They proposed multicore processor
    architectures that integrate solutions for online error detection, diagnosis,
    recovery, and repair during field operation. Several studies (e.g., [11], [41])
    showed that the temporal order of system calls issued by a process to request
    kernel services is effective in describing normal process behavior. This has led
    to a considerable amount of research studies that investigated various techniques
    for detecting anomalies at the system call level (see survey in [12]). Among these,
    sequence time-delay embedding (STIDE) and hidden Markov models (HMMs) are the
    most commonly used [41]. Ensemble methods have been proposed to improve the overall
    ADS accuracy by combining the outputs of several accurate and diverse models [7],
    [23], [25], [44]. In particular, combining the outputs from multiple crisp HMM
    detectors generated from multiple soft HMM detectors, each trained with a different
    number of states, in the ROC space, has been shown to provide a significant improvement
    in the detection accuracy of system call anomalies [11], [21], [41]. Among existing
    combination approaches, the pair-wise BBC2 combines all possible pairs of crisp
    detectors by fusing all types of Boolean functions [1]. BBC2 reported a significant
    improvement in reducing false alarms as compared to a single learned model [1].
    However, an exhaustive brute-force search to determine optimal combinations leads
    to an exponential number of combinations, which is prohibitive even for a small
    number of detectors [1]. To address this, Khreich et al. [21] proposed an IBC
    approach for combining relatively a large number of soft HMM detectors while avoiding
    the exponential explosion of BBC2. However, IBC produces a sequence of combination
    rules that grows linearly with both the number of soft HMM detectors and the number
    of iterations, which is difficult to analyze and understand. Furthermore, the
    algorithm is sensitive to the order of the combined crisp HMM detectors, making
    it challenging to find the best subset for combination operations. It is clear
    that if the number of combined crisp detectors (K) increases, the computation
    time and complexity also increase linearly for IBC and exponentially for BBC2.
    Moreover, we also know that the performance of an ensemble method is highly dependent
    on the diversity of combined detectors [27], [53]. The question is: how can we
    select the smallest and most diverse subset of detectors (among all the available
    ones) that can maintain or improve the detection accuracy (while reducing the
    false alarm rate) using the smallest number of Boolean combinations? In previous
    work [45], we proposed an effective PBC method based on Cohen''s kappa [5] coefficient
    (a statistical measure of the degree of agreement between two classifiers). MinMax-Kappa,
    a pruning technique of PBC, selects a small subset of diverse and accurate crisp
    HMM detectors based on measuring the kappa coefficients between each crisp HMM
    detector''s decision and the true decision labels (or ground truth) provided by
    the validation set (comprising both normal and attack traces). MinMax-Kappa computes
    the kappa values for all possible crisp HMM detectors, and then sets Min (minimum
    kappa value) and Max (maximum kappa value) boundaries with sorting them in an
    ascending order. After that, MinMax-Kappa selects 50% crisp HMM detectors whose
    kappa values are close to Min and another 50% crisp HMM detectors whose kappa
    values are close to Max. However, PBC uses the kappa coefficients between two
    crisp HMM detectors, it cannot ensure the diversity among soft HMM detectors.
    For example, if the scores of a subset of available soft HMM detectors on a validation
    set are almost the same, the responses of the crisp HMM detectors at a decision
    threshold of these redundant soft HMM detectors will probably be the same. Particularly,
    the computed kappa values for each crisp HMM detectors generated from these redundant
    soft HMM detectors will probably be almost equal. So, if the kappa value of one
    of these redundant crisp HMM detectors is close to Min or Max, the chances of
    selecting the rest of the redundant crisp HMM detectors are very high. Therefore,
    only one soft HMM detector from this subset of redundant soft HMM detectors should
    be used, whereas the rest of the redundant soft HMM detectors should be pruned
    before converting them into crisp HMM detectors. SECTION III. HMMs for Anomaly
    Detection Using System Call Sequences The sequences of system calls collected
    from the system call traces are known to provide a stable signature of normal
    behavior of a process [11], [41] , [47]. There are two properties of system call
    sequences that make them potential features for anomaly detection. The first property
    is uniqueness, where different processes generate different patterns of system
    call sequences. The second one is the matching probability, which tends to be
    low when an intruder is attempting to alter the normal sequential pattern of system
    calls of a process. Researchers from diverse disciplines use these two important
    properties of a system call sequence, which have been proposed in a large number
    of anomaly detection techniques such as neural network [15], k-nearest neighbors
    [29], Markov models [19], [31], and Bayesian models [24]. To the best of our knowledge,
    the very first approach for anomaly detection is based on sequence matching [11],
    [41]. During training, this approach builds the normal profile by segmenting the
    full-length sequences of system calls into a fixed-length contiguous subsequences
    using a fixed-size sliding window, shifted one by one symbol. In testing, an unknown
    sequence of system calls is also segmented into subsequences (as in training)
    and classified as normal if all subsequences are present in the normal profile.
    Otherwise, it is classified as an attack. HMM has been shown to be a very effective
    method to model a system''s behavior over time [36]. An HMM is a stochastic model
    for sequential data determined by the two interrelated mechanisms—a latent Markov
    chain having a finite number of states and a set of observation probability distributions,
    each one associated with a state. An HMM is typically determined by three parameters
    λ=(A,B,π) , which represent the states and transition probability distribution
    (A) of a system in a Markov process, the observation probability distribution
    (B) of observation sequences that comes from the temporal order of executions
    of a system, and the initial state probability distribution (π) of each hidden
    state in a Markov process. The first parameter A is usually hidden in an HMM.
    The only physical events are the observation sequence (B) that are associated
    with the hidden states of a Markov process. Fig. 1 illustrates a generic topology
    of an HMM, λ=(A,B,π) [48]. Fig. 1. General topology for an HMM model. Show All
    Number of hidden states (N) : To learn an HMM, we have to set the number of hidden
    states (N) in a Markov process. Let the distinct states be S i , i={0,1,…, N−1}
    . The notation X t = S i represents the hidden state sequence at time t. Number
    of observation symbols (M) : To learn an HMM, we have to set the number of observation
    symbols (M) . Let the distinct observation symbols be R k , k={0,1,…, M−1} . The
    notation O t = R k   represents the observed symbol R k at time t for the given
    observation sequence O−( O 0 , O 1 , …,  O T−1 ) , where T is the length of the
    observation sequence. State transition distribution (A) : The first row stochastic
    process is the hidden state transition probability distribution matrix A={ a ij
    } . A is an N×N square matrix, and the probability of each element { a ij } is
    denoted in (1) as a ij i,j =P(state  S j  at t+1|state  S i  at t) ={0,1,…,N−1}.
    (1) View Source The transition from one state to the next is a Markov process
    of order one [36] . This means the next state depends only on the current state
    and its probability value. As the original states are “hidden” in HMM, we cannot
    directly compute the probability values in the past. But we are able to observe
    the observation symbols for the current state S i at time t from a given observation
    sequence O to learn an HMM model. Observation symbol distribution (B) : The second
    row stochastic process is the observation symbol probability distribution matrix
    B={ b j ( R k )} . B is an N×M dimensional matrix that is computed based on the
    observation sequences (i.e., the temporal order of executions of a system). The
    probability of each element b j ( R k ) is denoted in (2) as b j  ( R k )= P(observation
    symbol  R k  at t|state S j  at t). (2) View Source Initial state distribution
    ( π ): The third row stochastic process is the initial state probability distribution
    π={ π i } . π is a 1×N row matrix, and the probability of each element { π j }
    is denoted in ( 3) as π i = P(state  S i  at t=0). (3) View Source A. Training
    an Ergodic HMM The behavior of a system can be discrete (e.g., symbols from a
    finite alphabet) or continuous (e.g., signals from a speech, music, etc.). In
    our case, the behavior of a process in UNIX or Windows system can be represented
    as a discrete sequence of system calls. Since a discrete HMM is a stochastic process
    for sequential data [36], [48], we can use it to learn the behavior of a process.
    A well-trained HMM model using the discrete normal sequences of system calls can
    be used as a potential model for detecting anomalies. Practically, training an
    HMM using a discrete sequence of observation O−( O 0 , O 1 , …,  O T−1 ) aims
    at maximizing the likelihood function P(O| λ) over the parameter space represented
    by A, B , and π . The Baum–Welch (BW) algorithm is one of the most commonly used
    expectation-maximization algorithm for learning the HMM parameters [2] . The BW
    algorithm is an iterative procedure to estimate the HMM parameters. It uses a
    forward-Backward (FB) algorithm [48] at each iteration to efficiently evaluate
    the likelihood function P(O| λ) , and then updates the model parameters until
    the likelihood function stops improving or a maximum number of iterations is reached.
    In our experiments, we have chosen the BW algorithm to train all HMMs using the
    system calls datasets. The user-defined three initial distributions of A, B ,
    and π , and two fixed-value parameters of M and N have an impact on the performance
    of HMM. The common solution for the initial distributions of A, B, and π is the
    random initialization and the use of validation set to select the best parameters
    [49] . We have also initialized the distributions of A, B, and π randomly and
    repeated the training process ten times. The initial distributions for which we
    obtain the highest AUC on the validation set are selected. The alphabet size M
    is defined by the number of distinct system calls in a system. However, it is
    difficult to define the number of states N in advance. The reason for that is
    a single HMM trained with a predefined number of states N may have limited chances
    to fit the underlying structure of the data [36]. In fact, the underlying distribution
    of sequences of system calls at different states varies according to the architectural
    complexity of a system and results in many local maxima of the log-likelihood
    function [20]. To tackle the variations in the underlying distribution of the
    sequences of system calls, ensemble HMMs have shown to be a better choice than
    a single HMM [7], [23]. The ensemble methods have reported that the diversity
    among the ensemble classifiers is an essential factor in increasing the accuracy.
    In particular, Khreich et al. [21] showed that the IBC of the responses of several
    accurate and diverse HMM detectors significantly increases the accuracy while
    reducing the number of false alarms. We have also trained different discrete-time
    ergotic HMMs with various N using the BW algorithm. These ergodic HMMs are the
    primary inputs to the proposed weighted pruning approach for Boolean combination.
    B. Soft and Crisp HMM Detectors In a binary classification problem, any trained
    model that produces a score instead of a decision (i.e., positive or negative)
    is called a soft detector. During operation, a trained HMM (λ) outputs a score
    computed by the FB algorithm. The score is the likelihood or the probability P(
    O 1:T | λ) for a given new observation sequence O 1:T . Normally, the score provided
    by λ should be significantly high, if the new observation sequence O 1:T is normal;
    otherwise, it is considered as an anomaly if the score is comparatively low. Since
    the output of a trained HMM is a score instead of a decision (normal or anomalous),
    then this model λ is a soft detector. On the other hand, in a binary classification
    problem, any trained model that produces a decision (i.e., positive or negative)
    instead of a score is called a crisp detector. We can convert a soft detector
    to one or more crisp detectors by setting one or more thresholds θ on the output
    scores produced by a soft detector. A crisp detector always gives a decision whether
    the testing sequence is normal ( score≥θ ) or anomalous ( score<θ ) based on a
    predefined threshold, θ . However, because of the limited amount of representative
    data, complex behavior of a system, and imbalanced distributions of classes, it
    is difficult to determine a threshold on the scores that will always separate
    the normal and anomalous sequences during operation [21]. Therefore, a single
    crisp HMM detector may generate a large number of false alarms. The Boolean combination
    of responses of multiple crisp HMM detectors (crisp-HMMs) in the ROC space have
    been shown to decrease the false alarm rate [21]. The crisp-HMMs are produced
    by setting various thresholds on the scores of the multiple soft HMM detectors
    (soft-HMMs). The following section introduces the two most useful Boolean combination
    techniques BBC2 and IBC for combining crisp-HMMs and also reports on their limitations.
    SECTION IV. ROC-Based Boolean Combination Techniques The ROC curve is a commonly
    used metric for evaluation of detectors’ performance. It plots the performances
    of a binary classifier in a 2-D space [9], where, y-axis represents the true positive
    rate (tpr) , and x-axis represents the false positive rate (fpr) for every possible
    crisp detector. The tpr is the proportion of correctly classified positive responses
    over the total number of positive samples tested by a crisp detector. The fpr
    is the proportion of incorrectly classified negative responses over the total
    number of negative samples tested by a crisp detector. Therefore, a single crisp
    detector plots a single point (fpr, tpr) in an ROC space, whereas a soft detector
    produces an ROC curve by connecting all the possible crisp detector''s points
    at various decision thresholds. A. ROC Convex Hull (ROCCH) All the points in an
    ROC space can be classified into two groups superior and inferior based on their
    tpr and fpr . Suppose a and b are two operating points in the ROC space, a is
    defined as superior to b , if fp r a ≤fp r b and tp r a ≥tp r b . If an ROC curve
    has tpr(∗)>fpr(∗) for all its points (∗) , then it is a proper ROC curve. The
    ROCCH is therefore the piece-wise outer envelope connecting only its superior
    points [6], [9], [52]. The linear interpolation is used to connect the two adjacent
    superior points so that, no points in an ROC space lies out of the final ROCCH
    curve. The accuracy of an ROCCH curve is measured by the AUC. The ROCCH can be
    used for the combination of two or more crisp classifiers in an ROC space [50],
    [51]. However, ROCCH combination rules discard the inferior points without verifying
    their combination in order to improve the system performance. The following section
    introduces the Boolean combination approaches [1] , [21], [54] of multiple ROC
    curves and showed that the new composite ROCCH improves the AUC as compared to
    the original ROCCH. B. Boolean Combination of ROC Curves The very first Boolean
    combination approach, proposed by Daugman [54], used only the conjunction (and)
    and disjunction (or) rules and fused on all the responses in an ROC space. The
    author applied these rules in a biometric test and concluded that the new composite
    ROCCH may increase the AUC of the ROC curve. As a consequence, other researchers
    also applied the and or or combination to combine soft detectors [55], [56]. For
    example, consider a pair of soft detectors ( S a ,  S b ), and the various decision
    thresholds are Ta and Tb , respectively. In a pairwise combination, the and or
    or rules are fused between each pair of converted crisp detectors ( C a i , C
    b j ) . The optimum thresholds are then selected based on the Neyman–Person test
    1 [52]. Finally, the selected optimum thresholds along with the corresponding
    Boolean functions are stored and used during operation. However, the and and or
    combinations cannot provide optimal thresholds when the training and validation
    datasets are limited and imbalanced [21]. The reason for the limited and imbalance
    data may lead to the appearance of large concavities in the resulting ROC curves
    [57]. In particular, the false alarm may be increased, if we fuse the best detector
    and the worst detector. But, the diversity among the combined detectors is an
    important factor in order to improve the performance while reducing the false
    alarm rate [53]. Therefore, further improvement is possible by including the other
    Boolean rules, in addition to the and and or rules. The following sections introduce
    the two most common combination techniques using all Boolean rules: 1) Pairwise
    brute- BBC2 [1]; and 2) IBC [21]. We also report on the limitations and complexities
    of these techniques. C. Pair-Wise BBC2 The pair-wise BBC2 fuses all possible pairs
    of crisp detectors generated from all the available soft detectors using all Boolean
    functions. As BBC2 uses all Boolean functions, it implicitly combines responses
    of both accurate and diverse crisp detectors at both superior and inferior points
    in the ROC space. However, the pair-wise brute-force strategy is computationally
    expensive due to the high number of permutations. For example, if the number of
    crisp detectors is N, there are N2 possible combinations for only one Boolean
    function. Barreno et al. [1] reported that exploiting all Boolean functions using
    an exhaustive brute-force search to determine optimum points leads to an exponential
    number of combinations. D. Iterative Boolean Combination (IBC) IBC avoids the
    impractical exponential explosion associated with the BBC2 by combining the emerging
    responses on a composite ROCCH sequentially. It first combines the first two ROC
    curves of the first two soft detectors. Then, the combined ROCCH, particularly,
    the emerging points are combined with the next ROC curve, and so on until the
    Kth ROC curve is combined. IBC repeats these sequential combinations iteratively
    until there are no further improvements or it reaches to a predefined maximum
    number of iterations. However, in practice, IBC requires a sequence of combinations
    of 11 to 20 crisp detectors to reach a final point on the final composite ROCCH
    [45]. In fact, it grows linearly with the increase of the number of iterations.
    Tracking and analyzing such a long sequence of combination rules during testing
    time increase the complexity of IBC. Moreover, the order of combined crisp detectors
    makes the IBC algorithm more sensitive to finding the best subset. It is evident
    that the computation time and complexity increase exponentially for BBC2 and linearly
    for IBC with the increase of the number of combined soft detectors (K), and thus
    making them inefficient. Our proposed pruning approach select the smallest and
    most diverse subset of detectors (among all available ones), which does not only
    reduce the computation time and complexity for Boolean combinations but also maintains
    or improves the detection accuracy (while reducing the false alarm rate) using
    the smallest number of Boolean combinations. SECTION V. Proposed Weighted Pruning
    Technique The proposed weighted pruning based Boolean combination approach leverages
    both weighted and unweighted kappa measures of (dis)agreement. The main novelty
    of this paper is to ensure the diversity among the scores of all the available
    ensemble of soft detectors by pruning the redundant soft detectors using weighted
    kappa. Then, our approach applies the unweighted kappa based MinMax-Kappa pruning
    technique (one of the pruning techniques of PBC) individually on each selected
    diverse base soft detectors and selects the complementary crisp detectors. At
    the end, we merge all the selected complementary crisp detectors from each selected
    diverse base soft detectors and use them for Boolean combination. A. Kappa Measure
    of (Dis)Agreement Cohen''s kappa or simply called kappa is a statistical tool
    that is widely used for measuring the interrater reliability or (dis)agreement
    between raters [5]. There are two types of kappa coefficients that can be used
    in computing the interrater reliability. The unweighted kappa coefficient is the
    simplest version of kappa [58] that is used only for nominal category. The weighted
    kappa coefficient is an extended version of kappa [46] that is used when the category
    is ordinal [59]. Our pruning techniques leverage both kappa coefficients. The
    weighted kappa coefficient is used to prune the redundant soft detectors when
    the level of scores is ordinal (thresholds). The unweighted kappa coefficient
    is used to prune the trivial and redundant crisp detectors when the decision is
    nominal (anomaly/normal). The contingency matrix for both kappa coefficients of
    (dis)agreement is defined on two detectors. Let the two detectors be D1 and D2
    , and the contingency matrix is C n×n . Here, n is the order of levels. For unweighted
    kappa coefficient, n is fixed to two, i.e., either positive or negative. For weighted
    kappa coefficient, n is equal to the number of levels or thresholds with the assumption
    that both detectors have the same number of constant levels or thresholds. An
    example of a contingency table C 2×2 for n=2 is given in Table I. Where, each
    element a ij represents the number of instances on which detector D1 and detector
    D2 agree at level i and level j . The sum of all elements in Table I is equal
    to the size of the validation set. TABLE I Contingency Matrix For the weighted
    kappa coefficient, we need to define the weighted matrix W in addition to the
    contingency matrix C . Among the many possible weighting schemes, the linear weighting
    scheme is effective when one order is important than the next one [60]. We also
    use linear weight when the order is the number of thresholds, and the distance
    between two thresholds is important to define whether two soft detectors are similar
    or diverse. We can compute the linear weighting matrix W using W = w ij =1− abs(i−j)
    n−1 . (4) View Source When C and W are the same dimensional square matrices, the
    kappa coefficient for both unweighted and weighted kappa can be computed based
    on the Hadamard product ( o ) [46] or element-wise product of matrices according
    to kp= p a − p ε 1− p ε (5) View Source where p a = sum(CoW) is the proportion
    of weighted agreement (for unweighted kappa, W=I means complete agreement). The
    parameter p ε is the proportion of agreement due to chance and computed using
    (6) as p ε =( c n×1  × r 1×n )oW. (6) View Source Here, c n×1 denotes a column
    matrix in which each element is the sum of each row of C . Similarly, r 1×n is
    a row matrix in which each element is the sum of each column of C . The kappa
    coefficient kp computes the interrater reliability based on the proportion of
    agreement ( p a ) and agreement due to chance ( p ε ), where the degrees of disagreement
    are controlled by the weight matrix W ( W=I for unweighted kappa that means no
    degrees of disagreement). Therefore, kp=1 indicates perfect agreement (i.e., both
    detectors agree at the same level for every instances), and kp= 0 indicates that
    any agreement is totally due to chance. The value of kp might also be negative.
    Negative values indicate that both detectors are negatively correlated, and such
    complementary detectors are important in the combination of ensemble techniques
    [27], [53]. In the rest of this paper, we use the running example shown in Fig.
    2 to describe the phases of our approach. In this example, we have selected three
    HMM-based detectors, D 1 , D 2 , and D 3 by varying the number of hidden states.
    Fig. 2(a) shows the scores of each detector. Fig. 2. Simple example of weighted
    and unweighted kappa for pruning redundant soft and crisp detectors. Show All
    Phase1-Pruning using weighted kappa: The first phase of Algorithm 1 describes
    the steps for pruning the redundant soft detectors using weighted kappa coefficient
    kp . Suppose, we have K soft detectors and they produce S k {k=1…K} score vectors
    using a validation set V . In the example of Fig. 2, K = 3 and the scores for
    each detector are shown in Fig. 2(a). Let the number of thresholds of each soft
    detector be n k . In the example of Fig. 2, n k = 4 . Therefore, we have K ROC
    curves ( S k , n k ) with probably K different AUC values. In each iteration (lines
    7–18 in Algorithm 1), we select one out of K available soft detectors for which
    the AUC is maximum and use it as a base soft detector S b . We store S b onto
    B (line 9 in Algorithm 1) for the next Phase2. Now, we compute the weighted kappa
    coefficients kp between S b and each of the rest K←K− S b soft detectors, where
    the thresholds n k of S b are used as an order or levels. Then, the soft detectors
    among the K− S b soft detectors, which perfectly agree (0.8<kp≤1) with S b based
    on the computed weighted kappa kp , are pruned as a redundant copy of S b . Let
    us say, the number of redundant detectors we found in each iteration is 0≤ K ′
    ≤K−1 , and then we remove them from the available K detectors as: K←K− K ′ . We
    repeat this process until K is zero. Algorithm 1: PSCDs( S 1 ,… S K , T 1 ,… T
    K ,lab) : Pruning Soft and Crisp Detectors. input:  scores of K soft detectors
    { S 1 ,… S K } on a validation set along with their thresholds { T 1 ,… T K }
    , and true labels lab of size |lab| . output:  selected L≪K diverse base soft
    detectors { B 1 ,… B L } along with their complementary crisp detectors or thresholds
    { θ 1 ,… θ L } where θ l ≪ T l ( θ l = 12 and T l = 100 on average) 1 // Phase1-pruning
    soft detectors using weighted kappa 2 allocate an array AU C all [1:K] // temporary
    store auc of each Sk 3 for k←1 to K do 4 compute auc of ROC( S k , T k ) 5 push
    auc onto AU C all 6 allocate an empty array B=[] //store selected diverse soft
    detectors 7 while (K) 8 select base soft detector: S b ←ma x k [AU C all (k)]
    9 store S b onto B // store S b as a base soft detector 10 let n b ← number of
    order/levels/thresholds in T b 11 update - K←K− S b // remove S b from K soft
    detectors 12 update AU C all ←AU C all −AU C all ( S b ) - // remove auc for S
    b 13 let n← the size of |K| 14 for k←1 to n do 15 compute linear weighted kappa
    KP between S k and S b using n b 16 if 0.80<KP<=1 17 update - K←K− S k // remove
    S k as a redundant copy of S b 18 update AU C all ←AU C all −AU C all ( S k )
    - // remove auc for S k 19 // —–Phase2- pruning crisp detectors using unweighted
    kappa———– 20 let L ← number of selected diverse base soft detectors in B 21 let
    m ← number of selected complementary crisp detectors from S b ∈B 22 allocate an
    empty array θ=[] //store thresholds of each complementary crisp //detectors 23
    for b←1 to L do 24 let n b ← number of crisp detectors or thresholds in T b ∈
    S b 25 allocate an array U[1: n b ] //store temporary kappa coefficients 26 allocate
    an array V[|lab|: n b ] //store temporary responses 27 for j←1 to n b do 28 r←
    S b ≥ t j //temporary responses at decision threshold t j ∈ T b 29 compute unweighted
    kappa KP between r and lab 30 push KP onto U and r onto V 31 filter U and V by
    removing trivial detectors 32 select m complementary crisp detectors using MinMaxKappa(U,V)
    pruning technique 33 map m selected complementary crisp detectors into θ b thresholds
    34 store θ b thresholds onto θ // store θ b complementary crisp detectors of S
    b 35 return B⟨ S 1 ,… S L ⟩ and θ⟨ θ 1 ,…, θ L ⟩ Using the example shown in Fig.
    2, we have S b = D 1   because the AUC of D 1 is maximum. We then store D 1 in
    B as a base soft detector. Suppose, n k of D1 is equal to four different levels
    ( S≥3; 3>S≥2;2>S≥1; and 1>S≥0 ) of scores S( D 1 ) . First, we have to compute
    the contingency and weighted matrices between base ( S b = D 1  ) and each of
    the rest two ( K←K− S b ) soft detectors D 2 and D 3 . Fig. 2(b) shows the contingency
    tables ( C 4×4 ) for four different levels. Since the dimension of the contingency
    and weighted matrices are the same, we put them together, where, each cell c ij
    (#_#_ w ij ) in Fig. 2(b) represents three values: The first and second values
    represent the number of samples agreed at levels i and j of the two contingency
    tables between D 1 and D 2 and between D 1 and D 3, respectively. The third value
    is the linear weight computed using ( 4). Based on the contingency and weighted
    matrices between two detectors, we can compute the weighted kappa ( kp ) coefficients
    using ( 5). The weighted kappa KP between D 1 and D 2 is 1, meaning that both
    are in perfect agreement (i.e., kp ∈0.8<kp≤1 ) at the same level for every instances,
    and thus D 2 should be pruned (lines 15–18 in Algorithm 1). However, the weighted
    kappa kp between D 1 and D 3 is 45.65 , meaning poor agreement (i.e., kp∉0.8<kp≤1
    ) at the same level for every instances, and therefore D 3 is more likely to diverse
    from D 1 and should be selected for combination. At the end of the first iteration,
    we only keep D 3 (i.e., K=1 ), while D 2 is pruned because it is redundant of
    the base detector D 1 . The final results of this phase consist of two diverse
    base soft detectors D 1 and D 3 . The diversities at the response level for four
    different thresholds are presented in Fig. 2(c). We can see that the responses
    of the two selected base soft detectors D 1 and D 3 diverse at various instances
    [see Fig. 2(c)] for all threshold points, except for S≥0 . In Fig. 3(a), we show
    a more realistic example, using the ADFA-LD dataset with 20 soft HMM detectors.
    In this figure, we have eight base soft diverse detectors (green solid ROC curves)
    and 12 pruned redundant soft detectors (black dotted ROC curves). Similarly, Fig.
    3(b) shows the experiment on CANALI-WD dataset, where we have only three base
    soft diverse detectors and 17 pruned redundant soft detectors. At the end of Phase1,
    all the selected base soft diverse detectors L≪K (stored in B) are then fed into
    Phase2 of Algorithm 1. Fig. 3. Example of selected base soft detectors (green
    solid lines) with pruning redundant soft detectors (doted black lines) under the
    ROC space using weighted kappa ( Phase1 in Algorithm 1) on ADFA-LD dataset (a)
    and CANALI-WD dataset (b). Show All Phase2-Pruning using unweighted kappa: The
    second phase of Algorithm 1 leverages the MinMax−Kappa pruning method [45], one
    of the two pruning methods of PBC using unweighted kappa, to select the complementary
    crisp detectors. Since the base soft detectors selected in Phase1 are diverse,
    we apply the MinMax−Kappa pruning method on each base soft detector individually
    instead of brute-force search like in PBC. We compute the unweighted kappa coefficient
    kp between a base soft detector''s decision vector (or crisp detector) and the
    true decision labels (or ground truth), same as in PBC. If n b is the number of
    decision levels on a base detector''s scores vector S b , then we obtain n b crisp
    detectors. Now, we compute unweighted kappa coefficients of n b crisp detectors
    and sorted them in ascending order. According to MinMax−Kappa , the accurate crisp
    detectors should reside close to kp≈k p max and their complementary crisp detectors
    should reside close to kp≈ kp min . However, we have to set the number of crisp
    detectors and the ratio of them to be selected close to kp max and kp min . We
    set the ratio 50%, same as in MinMax−Kappa . Moreover, before selecting the complementary
    crisp detectors, we have to filter out the trivial crisp detectors (giving always
    either positive or negative responses) whose kp is close to zero. In the running
    example shown in Fig. 2, Phase2 selects two diverse base soft detectors D 1 and
    D 3 with four different thresholds. Therefore, each base soft detector produces
    four crisp detectors at four different levels or thresholds. The responses R(D(S)≥θ)
    of each crisp detector for 25 instances and their corresponding true labels (ground
    truth) are shown in Fig. 2(c). Fig. 2(d) shows the unweighted kappa values sorted
    in ascending order for each crisp detector of two base soft detectors D 1 and
    D 3 . Consider a ratio of 50% and the number of crisp detectors to be selected
    to be two. Therefore, from Fig. 2(d), we obtain, kp max ≈0.62 and kp min ≈0 for
    D 1 . Similarly, for D 3 , kp max ≈0.59 and kp min ≈0 . However, the trivial crisp
    detectors [one for D 1 : R(S≥0) ; and two for D 3 : R(S≥1) and R(S≥0) ] should
    be filtered out first. Fig. 2(d) shows the filtered trivial crisp detectors (large
    diagonal marker with cross sign). Since the ratio is 50%, from each base soft
    detector, one crisp detector should be selected close to kp max , and another
    one should be selected close to kp min . Fig. 2(d) shows the four selected complementary
    crisp detectors (two from each base soft detector, marked with large circle marker).
    In general, if the number of selected complementary crisp detectors from a selected
    base soft detector is m (i.e., m/2 close to kp max and m/2 close to kp min ),
    then the total number of selected crisp detectors will be M=m∗L , where L is number
    of selected base soft detectors (selected from Phase1). We tested m with different
    setting ( l=4,8,12,16 , and 20) and obtained best results for m=12 . In Fig. 4,
    we show a more realistic example using ADFA-LD dataset. In this figure, we have
    M complementary crisp detectors (red bold points) selected from L diverse base
    soft detectors (selected in Phase1) using unweighted kappa-based MinMax-Kappa
    pruning technique. Fig. 4(a) shows the results under the space of kp−fpr , and
    Fig. 4(b) shows the results under the space of kp − tpr. Fig. 5 also shows the
    selected total M=96 complementary crisp detectors from the L=8 diverse base soft
    detectors under the ROC space. Fig. 4. Example of selected complementary crisp
    detectors (red bold points) under the simple kappa versus true positive rate (kp
    − tpr) diagram (a) and kappa versus false positive rate (kp − fpr) diagram (b)
    with pruning trivial and redundant crisp detectors (small black points) from the
    L base soft detectors (selected by Phase1 in Algorithm 1) using MinMax−Kappa pruning
    technique ( Phase2 in Algorithm 1) on ADFA-LD dataset. Show All Fig. 5. Example
    of selected complementary crisp detectors (red bold points) under the ROC space
    with pruning trivial and redundant crisp detectors (small black points) from the
    L base soft detectors (selected by Phase1 in Algorithm 1) using MinMax−Kappa pruning
    technique ( Phase2 in Algorithm 1) on ADFA-LD dataset. Show All Phase3-Boolean
    combination techniques: The third phase combines the selected complementary crisp
    detectors using Boolean functions. The first combination approach called WPBC2,
    shown in Algorithm 2, combines all possible pairs of complementary crisp detectors
    (selected from Phase1 and Phase2) same as in BBC2. In contrast with BBC2, WPBC2
    fuses only the complementary crisp detectors instead of using brute-force (i.e.,
    all available crisp detectors). The second approach called WPIBC, shown in Algorithm
    3, combines the complementary crisp detectors of each diverse base soft detectors
    sequentially same as in IBC. The difference is that WPIBC only combines the most
    diverse base soft detectors after pruning all the redundant soft detectors. As
    we will show in the evaluation section, both WPBC2 and WPIBC Boolean combination
    approaches, using only M≪N complementary crisp detectors of L≪K diverse base soft
    detectors, improved the true positive rate when the false tolerance is almost
    close to zero. Algorithm 2: WPBC2( S 1 ,… S K , T 1 ,… T K ,lab) : Weighted Pruning
    Pair-wise Boolean Combination. input:scores of K soft detectors { S 1 ,… S K }
    on a validation set along with their thresholds { T 1 ,… T K } , and true labels
    lab of size |lab| . output:a new composite ROCCH —constructed by | P e | (size
    of P e ) combination responses or | P e | emerging points. Each point is a combination
    of two crisp detectors using only one Boolean function. 1 prune redundant soft
    and crisp detectors (B⟨ S 1 ,… S L ⟩,θ⟨ θ 1 ,…, θ L ⟩)←PSCDs( S 1 ,… S K , T 1
    ,… T K ,lab) // where L≪K is the number of selected diverse base soft detectors
    2 set BooleanFunctions ←{a∧b,¬a∧b,a∧¬b,¬(a∧b),a∨b,¬a∨b,a∨¬b,¬(a∨b),a⊕b,a≡b} 3
    let F ← number of Boolean functions in BooleanFunctions 4 let m i ← number of
    decision thresholds in θ i 5 let M← ∑ L i=1 m i total number of crisp detectors
    5 allocate an array C[|lab|,M] 6 // convert soft detectors to crisp detectors
    7 for i←1 to L do 8 for j←1 to m i do 9 r← S i ≥ t j //temporary responses at
    decision threshold t j ∈ θ i 10 push r onto C 11 allocate an array P[2, C 2 ×F]
    // temporary store points (fpr,tpr) of fused responses 12 foreach bf∈ BooleanFunctions
    do 13 for i←1 to M do 14 for j←1 to M do 15 r←bf(C[i],C[j]) // combine responses
    16 compute p←(tpr,fpr) using r and lab 17 push p onto P 18 compute composite ROCCH
    of all ROC points in P 19 map each emerging points P e on ROCCH into a 3-tuples:
    P e ← <( S i , t j ),( S i , t j ),bf> // where i={1,…,L} and t j ∈ θ i 20 return
    ROCCH along with all emerging points { P 1 ,…, P e } Algorithm 3: WPIBC( S 1 ,…
    S K , T 1 ,… T K ,lab) : Weighted Pruning Iterative Boolean Combination. input:scores
    of K soft detectors { S 1 ,… S K } on a validation set along with their thresholds
    { T 1 ,… T K } , and true labels lab of size |lab| . output:a new composite ROCCH
    — constructed by | R iter | (size of R iter ) combination responses or | R iter
    | emerging points. Each point is a sequential combination on average of five crisp
    detectors using four Boolean functions. 1 call pruning function // prune redundant
    soft and crisp detectors (B⟨ S 1 ,… S L ⟩,θ⟨ θ 1 ,…, θ L ⟩) ←PSCDs( S 1 ,… S K
    , T 1 ,… T K ,lab) // where L≪K is the number of selected diverse base soft detectors
    2 set BooleanFunctions ←{a∧b,¬a∧b,a∧¬b,¬(a∧b),a∨b,¬a∨b,a∨¬b,¬(a∨b),a⊕b,a≡b} 3
    iter ←1 // combine the first two ROC curves of the first two diverse base soft
    detectors 4 let m 1 ← number of points in first curve ROC( S 1 , θ 1 ) 5 let m
    2 ← number of points in second curve ROC( S 2 , θ 2 ) 6 allocate an array P[2,
    m 1 × m 2 ] // temporary store the points of fused responses 7 foreach bf∈ BooleanFunctions
    do 8 for i←1 to m 1 do 9 r 1 ← S 1 ≥ t i // temporary responses at decision threshold
    t i ∈ θ 1 10 for j←1 to m 2 do 11 r 2 ← S 2 ≥ t j // temporary responses at decision
    threshold t j ∈ θ 2 12 r 12 ←bf( r 1 , r 2 ) // fuse responses 13 compute p←(tpr,fpr)
    using r 12 and lab 14 push p onto P 15 compute ROCC H iter of all combination
    ROC points in P 16 map each emerging points p e on ROCC H iter into a 3-tuples:
    p e ← <( S 1 , t i ),( S 2 , t j ),bf> 17 store all emerging points p e on ROCC
    H iter onto R 1:2 18 // combine rest of the ROC curves of rest of the L-2 diverse
    base soft detectors 19 for b←3 to L do 20 let n e ← number of emerging points
    in R 1:b−1 21 let m b ← number of points in lRO C b ( S b , θ b ) curve 22 allocate
    an array P[2, n e × m b ] // temporary storage of fused responses 23 foreach bf∈
    BooleanFunctions do 24 for i←1 to n e do 25 r 1 ← R 1:b−1 (i) // responses from
    immediate previous combinations 26 for j←1 to m b do 27 r 2 ← S b ≥ t j // temporary
    responses at decision threshold t j ∈ θ b 28 r 12 ←bf( r 1 , r 2 ) // fuse responses
    29 compute p←(tpr,fpr) using r 12 and lab 30 push p onto P 31 update ROCC H iter
    of all combination ROC points in P 32 map each emerging points p e on ROCC H iter
    into a 3-tuples: p e ← < R 1:b−1 (i),( S b , t j ),bf> 33 store all emerging points
    p e on ROCC H iter onto R 1:b 34 store all the emerging points to reach on the
    final ROCC H iter onto R iter ← R 1:L 35 set maxiter and tol // maximum number
    of iterations and tolerance 36 iter ←2 to maxiter 37 repeat steps 2 to 33 with
    L+1 ROC curves: ROC( R iter−1 ) and ROC( S 1 , θ 1 ),…,ROC( S L , θ L ) 38 if
    (AUC H iter ≤AUC H iter−1 +tol) then 39 break // stop further iteration 40 return
    ROCC H iter and R iter B. Complexity Analysis Suppose, we have K soft detectors
    with S k {k=1…K} scores using a validation set V . Let the number of decision
    thresholds on the scores S k of each soft detector be constant, and the size be
    T . Let N=K∗T be the total number of crisp detectors. The brute-force search for
    optimal combination is infeasible in practice due to the doubly exponential combinations.
    In fact, for N crisp detectors there are 2 N possible outcomes that can be combined
    in 2 2 N ways, which makes the brute-force combination impractical even for small
    N values [1], [43]. The worst case time complexities of the proposed and existing
    Boolean combination methods are given in Table II. The pair-wise combination of
    N crisp detectors employed in BBC2, which requires O( N 2 ) Boolean operations,
    may not be feasible in practice for large N values. The sequential combination
    of the IBC algorithm reduces its worst case time complexity to O( T 2 +N) Boolean
    operations. TABLE II Worst Case Time Complexity of Pruning and Without Pruning-Based
    Boolean Combination Methods Our recent pruning approach [43] used the kappa-error
    diagrams or simply called unweighted kappa coefficient to decide which ensemble
    members can be pruned with maintaining a similar overall accuracy. Although PBC
    reduces the impractical exponential computation time for BBC2 to O(N(logN+1))
    , the performance at low false alarm values is also decreased (details in Section
    VI). This is because PBC selects U≪N complementary crisp detectors over the whole
    N converted crisp detectors, it cannot consider the diversity among the individual
    soft detectors. The proposed pruning technique is more general as it ensures the
    diversity among both of the individual soft and crisp detectors instead of using
    N crisp detectors. As shown above, the total number of crisp detectors N depends
    on two important parameters K and T . Phase1 in the proposed weighted pruning
    technique reduces the size of the ensemble from K to L diverse soft detectors,
    by pruning the redundant ones. As shown in Fig. 3(a), out of K=20 soft HMM detectors,
    Phase1 selects only L=8HMMs for ADFA-LD dataset and only L=3HMMs for CANALI-LD
    dataset [see Fig. 3(b)]. Then, Phase2 optimizes the size of T of each selected
    base diverse soft detector (L) to m<<T by pruning all the trivial and redundant
    crisp detectors. Here, m is a user defined parameter and set based on the experimental
    results using validation set (e.g., in this experiment, m=12 gives the best result
    for both datasets). At the end, the proposed pruning methods always select M=L∗m
    complementary crisp detectors. Therefore, the worst case time complexity required
    by the proposed pruning technique to select M complementary crisp detectors is
    O( K 2 +K∗(T(logT+1))) , where, Phase1 requires about K 2 operations for computing
    and sorting the AUC and the weighted kappa of K soft detectors, in order to select
    L diverse base soft detectors. In Phase2, each base diverse soft detector ( L
    ) requires about T(logT+1) operations for computing and sorting the unweighted
    kappa for T crisp detectors, in order to select m≪T complementary crisp detectors.
    Therefore, in the case of worst case, Phase1 selects all K soft detectors (i.e.,
    L=K ). So, the worst case time complexity for Phase2 requires about (K∗(T(logT+1)))
    operations, in order to select a total of M=K∗m complementary crisp detectors.
    At the end of pruning Phases, Phase3 combines the decisions of M complementary
    crisp detectors. In Phase3, the worst case time complexity for the proposed WPBC2
    is about O( M 2 ) Boolean operations, and for the proposed WPIBC is about O( m
    2 +M) Boolean operations, where M≪N and m≪T . SECTION VI. Experiments and Comparison
    We experimented with the proposed pruning approach on two system call datasets:
    ADFA-LD [6] and CANALI-WD [47]. The experimental results are compared with BBC2
    [1] and IBC [21] without pruning. We also compared our approach to PBC that we
    proposed in previous work [43]. ADFA-LD dataset: ADFA-LD consists of normal and
    anomalous sequences of system calls collected from Ubuntu [6]. A normal sequence
    of system calls of a process is collected from the system call traces while it
    is executed under the normal conditions. An anomalous sequence of system calls
    of an attack is collected from the system call traces while it is executed against
    the system. There are in total 5206 normal traces collected from various normal
    Unix-based processes such as web browsing and Latex document preparations. The
    dataset contains 60 attack traces by exercising six different types of attacks:
    web-based exploitation, simulated social engineering, poisoned executable, remotely
    triggered vulnerabilities, remote password brute-force attacks, and system manipulation.
    In training, we use the 833 normal traces same as in [6] to train the 20 discrete-time
    ergodic HMMs (i.e., K = 20 soft detectors) with various values. The rest of the
    4373 normal traces and the 60 anomalous traces are used for evaluation. CANALI-WD
    dataset: CANALI-WD consists of two normal datasets called goodware and anubis-good
    and two malware datasets called malware and malware-test [47]. The goodware dataset
    contains a massive amount of 180 GB execution traces of normal day-to-day operations,
    which are collected from ten different machines. The anubis-good dataset contains
    the traces of 36 benign applications executed under anubis [61]. The malware dataset
    is a collection of execution traces of 6000 malware samples including a mix of
    all the existing categories (botnets, worms, dropper, Trojan horses, etc.), which
    are randomly extracted from anubis [61]. The final malware-test dataset is a collection
    of execution traces of 1200 malware samples, which are collected from a different
    machine than the normal ones used for anubis. In training, we use the anubis-good
    dataset and the traces for nine out of ten machines in the goodware dataset (same
    as in [47]) to train 20 soft HMMs detectors with various values. In contrast to
    [47], however, where the malware dataset was also used to train the models, we
    only use malware for testing. This is because an anomaly detector mainly models
    the normal behavior of a system. Therefore, the rest of the 23 traces of the tenth
    machine in the goodware dataset, 5855 traces from malware dataset, and 1133 traces
    from malware-test dataset are used for evaluation. A. Experimental Setup We use
    a stratified fivefold cross validation (5FCV) technique, same as in [43] , on
    the testing set for the evaluation of the proposed pruning approach. Since the
    ratio between the normal and anomalous traces in both datasets is not balanced,
    we applied stratified 5FCV to partition the normal and anomalous sets separately.
    This is because we want to keep the same ratio (normal to anomalous) to guarantee
    that all folds include the normal and anomalies traces. Therefore, for ADFA-LD
    dataset, each fold contains 874 traces selected randomly from the 4373 normal
    traces and 12 attacks traces selected randomly from the 60 attack traces. Similarly,
    for CANALI-WD dataset, each fold contains four traces selected randomly from the
    23 normal traces and 1397 traces selected randomly from the 6988 anomalous traces.
    However, as we followed the same setting as in PBC [43] instead the way of standard
    cross validation, we also used one fold for validation and the remaining four
    folds for testing on the both ADFA-LD and CANALI-WD datasets. As described in
    Section III, we apply the BW algorithm on the validation set to learn the parameters
    of an HMM with setting the random initialization of A, B, and π , and M=340 distinct
    system call symbols for ADFA-LD dataset and M=89 distinct symbols for CANALI-WD
    dataset. Since a single HMM with a predefined number of states N may have limited
    chances to fit the underlying structure of the data (as noted in Section III),
    20 different discrete-time ergodic HMMs (i.e., 20 soft detectors) are trained
    with various N=10, 20…200 values. For each state value N , we repeated the training
    process ten times with a different random initialization of A, B, and π to avoid
    the local minima, and the HMM that gives the highest AUC value on the validation
    set is selected for Boolean combination. B. Results and Comparison We mainly focus
    on how the proposed pruning-based Boolean combination approaches can reduce the
    computation time (as discussed in Section V) of the BBC2 and IBC techniques while
    maintaining or improving the detection accuracy and reducing the false alarm rate.
    Figs. 6 and 7 show the AUC results in the ROC space for the proposed weighted
    pruning techniques on ADFA-LD and CANALI-WD datasets. We can see that the ROC
    curve of the proposed pruning-based WPIBC shows slightly better AUC than IBC.
    In particularly, WPIBC is able to ensure the diversity among the fused crisp detectors
    (selected using unweighted kappa at Phase2 in Algorithm 1) where each crisp detector
    comes from the selected diverse base soft detectors (selected using weighted kappa
    at Phase1 in Algorithm 1). Therefore, in contrast to IBC, where the order of combination
    responses in each iteration is the order of all the available soft and crisps
    detectors, WPIBC maintains the order of combination responses in each iteration
    among the selected diverse soft and crisp detectors (see details in Algorithms
    1 and 3). For instance, to achieve the final operating points denoted in Fig.
    6 with a large pink circle, WPIBC uses only five selected complementary crisp
    detectors (red bold plus marker points) and four Boolean operations, whereas IBC
    uses 17 crisp detectors (black bold circle marker points) and 16 Boolean operations.
    Fig. 6. Algorithm comparisons on ADFA-LD dataset where one fold is used for validation
    and four folds are used for testing. Show All Fig. 7. Algorithm comparisons on
    CANALI-WD dataset where one fold is used for validation and four folds are used
    for testing. Show All Compared to BBC2, although the AUC of WPBC2 is slightly
    low, WPBC2 maintains the same AUC of PBC shown in Figs. 6 and 7. However, WPBC2
    overcomes the exponential time complexity problem of BBC2 by pruning the redundant
    and trivial crisp detectors, in fact, without pruning, BBC2''s time complexity
    is exponential with respect to the number of detectors (N ^2) [1], [43]. Table
    III shows the maximum detection accuracy (tpr) achieved by each technique for
    a fixed (almost close to zero) fpr value of 0.002, all values are averaged over
    the 5FCV. TABLE III Average (avg), Maximum (max), and Minimum (min) AUC Values
    and True Positive Rate (tpr) With False Positive Rate (fpr)<=0.002 , and Their
    Standard Deviations (std) Over the 5FCV (Train on One Fold and Tested on Four
    Folds) For ADFA-LD dataset, although the AUC values of all pruning methods are
    almost equal, the tpr of PBC with MinMax-Kappa pruning technique is the worst.
    The tpr of WPIBC is almost equal to that of BBC2 method and slightly better than
    that of IBC method. Moreover, the standard deviation of WPIBC is also good as
    compared to the other methods. For the CANALI-WD dataset, the tpr of WPIBC is
    still better than PBC and WPBC2 pruning techniques, and almost equal to BBC2 and
    IBC that do not use pruning techniques. Through this analysis, we observed that
    when the proposed weighted pruning technique combines the selected complementary
    crisp detectors iteratively (i.e., called WPIBC), it achieves similar results
    to that of IBC. Particularly, when we compared the results with the tpr , where
    the maximum fpr is almost equal to zero (0.002), both WPIBC and WPBC2 outperform
    PBC. The results demonstrate that the proposed pruning approach is more general
    and applicable to either pair-wise Boolean combinations (WPBC2) and iterative
    Boolean combinations (WPIBC). Moreover, we tested the proposed pruning approach
    by using the standard way of 5FCV, i.e., four folds are used in validation, and
    one fold is used in testing. With this setting, the results of one fold of 5FCV
    are demonstrated in Fig. 8 for ADFA-LD dataset and in Fig. 9 for CANALI-WD dataset.
    Table IV shows the average results over the 5FCV with this standard setting of
    5FCV. From Figs. 8 and 9, we can see that for both datasets our proposed pruning-based
    Boolean combination approaches are able to achieve the same performance (in terms
    of AUC, fpr , and tpr ), while reducing the time complexity, the number of crisp
    detectors, and the number of Boolean combinations. For CANALI-WD dataset, we got
    almost equal results with the original approaches (which use all crisp detectors)
    and the highest value of tpr=0.91 when the false alarm rate is zero, given in
    Table IV. However, for ADFA-LD dataset, we observed a great difference between
    the proposed pruning approach and the PBC. When the average tpr=0.49 for WPIBC
    (with the limit of maximum fpr is equal to 0.002), it is equal to zero for PBC
    and 0.17 for WPBC2. For example, from Fig. 8, we got tpr=0.51 (when fpr<=0.002
    ) for WPIBC, it is still zero for PBC. Fig. 8. Algorithm comparisons on ADFA-LD
    dataset where four folds are used for validation and one fold is used for testing
    in 5FCV. Show All Fig. 9. Algorithm comparisons on CANALI-WD dataset where four
    folds are used for validation and one fold is used for testing. Show All TABLE
    IV Average (avg), Maximum (max), and Minimum (min) AUC Values and True Positive
    Rate (tpr) With False Positive Rate (fpr)<=0.002 , and Their Standard Deviations
    (std) Over the 5FCV (Train on Four Folds and Tested on One Fold) C. Cost Analysis
    Table V shows the cost, i.e., the combination time and the number of Boolean operations
    that are required by each method during the validation and testing phases. The
    values are averaged over the 5FCV on the ADFA-LD dataset. All 5FCV executions
    are performed on a 3.1 GHz Intel Core i7 CPU machine with 16 GB of RAM and a 17×5400
    r/ min hard disk. TABLE V Cost Analysis (Values are Averaged Over 5 FCV) in Terms
    of Pruning and Combination Time (s), and Number of Boolean Operations Applied
    During Validation Phase, and the Number of Combined Crisp Detectors Required to
    Achieve Each Vertex on ROCCH During Testing Phase We can see that although the
    pruning time of the proposed approach is slightly more than the PBC, WPIBC reduced
    the combination time and the number of Boolean operations to almost half compared
    to IBC. The total computation time, including pruning and combination during validation
    of WPIBC, was 7.9 s, whereas PBC took 16.6 s. Furthermore, in testing, WPIBC also
    reduced the number of combined crisp detectors by almost half than the number
    required by IBC (5 instead of 11). We can see in Fig. 6 that WPIBC requires on
    average five crisp detectors, whereas IBC requires 11 crisp detectors to achieve
    a single point on the final composite ROCCH. Similarly, WPBC2 always requires
    only two crisp detectors similar to BBC2 and PBC to achieve a single point on
    the final ROCCH. Therefore, the proposed pruning approach is more general, and
    it can be applicable to both pair-wise and IBC s. However, based on the computation
    time and the number of combined Boolean operations, WPIBC is more desirable in
    order to obtain better accuracy while reducing the false alarm rates (as shown
    in Tables III and IV). From the worst case time complexity given in Table II,
    we can see that the proposed pruning approach reduces the total number of crisp
    detectors, i.e., N=K∗T by optimizing two important parameters of K and T in Phase1
    and Phase2, respectively. For example, Phase1 of the proposed weighted pruning
    approach selects only L=3 diverse ensembles of HMM soft detectors out of K=20HMM
    soft detectors [shown in Fig. 3(b) ] for CANALI-WD dataset. As a result, Phase2
    computes the unweighted kappa only for about 300 (i.e., L∗T and let say T=100
    ) crisp detectors, in order to select only M=36 (i.e., M=L∗m , where m=12 ) complementary
    crisp detectors. Whereas PBC always computes the unweighted kappa for about N=2000
    (i.e.,  N=K∗T ) crisp detectors, in order to select U=50 complementary crisp detectors.
    Moreover, since PBC cannot ensure the diversity among the ensembles of soft HMM
    detectors, the probability of selecting the redundant complementary crisp detectors
    or rejecting the other diverse crisp detectors is also high. In fact, it is reported
    in Tables III and IV that PBC significantly reduced the tpr with a low false alarm
    as compared to the other approaches due to the rejection of some diverse complementary
    crisp detectors. SECTION VII. Effects of Weighted Pruning-Based Boolean Combination
    For any ensemble-based Boolean combination algorithms, increasing the accuracy
    is highly dependent on the diversity among the fused soft/crisp detectors (i.e.,
    the level of disagreement among the fused soft/crisp detectors should be high).
    Although the existing ensemble based BBC2 and IBC Boolean combination techniques
    implicitly fused such diverse soft/crisp detectors and showed higher accuracy,
    they face the challenges of computation time and complexity because of fusing
    all the possible pair of crisp detectors from all the available soft detectors
    (as discussed in Sections IV and V; and reported in Table III). In addition, the
    accuracy of IBC is also dependent on the order of combinations. In fact, with
    the increase of number of soft detectors, the computation time and complexity
    increase exponentially for BBC2 and linearly for IBC (discussed in Section IV).
    To be clear, we tested the proposed approach using 50 available soft HMM detectors
    (i.e., on average 5000 crisp detectors), trained with various N=5, 10, …,250 values
    on CANALI-WD dataset. The results are shown in Fig. 10 , where the values are
    transformed into a logarithmic scale. It is clear that when we apply the proposed
    weighted pruning approach (top one in Fig. 10), a noticeable improvement can be
    observed in the reduction of the number of Boolean operations. Particularly, WIBC
    significantly reduces the number of Boolean operations as compared to other approaches.
    For example, BBC2 requires 25 million (7.4 in logarithmic scale) Boolean operations
    for 50 soft detectors, whereas, WPBC2 uses only 3600 (3.4) operations. Similarly,
    when IBC requires 15 000 (4.2 in logarithmic scale) Boolean operations, WIBC uses
    only 204 (2.3) operations. As a result, we can state that WPBC2 is 6944 times
    faster than BBC2 and WPIBC is 73 times faster than IBC for 50 soft detectors.
    Moreover, from the 30 soft detectors, WPBC2 and WIBC always select five diverse
    soft detectors with the increase of the number of soft detectors, and thus, reach
    a constant number of Boolean operations. Fig. 10. Algorithm''s computation time
    and complexity analysis on the validation subset of CANALI-WD dataset. Show All
    The bottom part of Fig. 10 compares the computation time (including pruning and
    combination time together for pruning-based approaches). We can see that WPBC2
    and WIBC reported the lowest computation times as compared to other approaches.
    For example, WPBC2 is 10 000 times (seconds) faster than BBC2, and WPIBC is two
    times faster than IBC during validation phase using 50 available soft detectors.
    Moreover, from the 30 soft detectors, although the pruning time for WPBC2 and
    WIBC increases slightly with the increase of number of soft detectors, the combination
    time remains same as both are always using only five selected diverse soft detectors.
    Compared to PBC pruning approach where both the pruning and combination time are
    increasing linearly with the increase of number of soft detectors. In fact, PBC
    shows worst result when the false alarm is almost zero for both ADFA-LD and CANALI-WD
    datasets (given in Tables III and IV). On the other hand, the accuracy with almost
    zero false alarm is the desired expected solution for deploying a ADS in a real
    world application. The reason is that PBC also uses all the available soft detectors
    to select a subset of complementary crisp detectors without ensuring the diversities
    among the use of soft detectors. As a result, the redundant soft detectors produces
    redundant crisp detectors, and thus it increases the probability of selecting
    these redundant copies if anyone is selected as a complementary crisp detector
    by MinMax-Kappa pruning technique of PBC. The proposed WPBC2 and WPIBC weighted
    pruning techniques select the most diverse base soft detectors from the available
    soft detectors using weighted kappa. For instance, from the Fig. 3(a) , eight
    diverse base soft detectors are selected while 12 are pruned as for redundant
    copies for ADFA-LD dataset. Similarly, from the Fig. 3(b), only three diverse
    base soft detectors are selected while 17 are pruned for CANALI-WD dataset. As
    the selected base soft detectors are diverse, the converted crisp detectors from
    them might also be diverse as well. Therefore, when we apply the MinMax-Kappa
    pruning technique on each selected diverse base soft detectors individually, there
    is no chance for the selection of redundant complementary crisp detectors. As
    a result, our proposed pruning technique shows better accuracy when the false
    alarm is close to zero, compared to PBC for both datasets (given in Tables III
    and IV). Moreover, the proposed weighted based pruning approach is more general
    as we can combine the selected diverse soft/crisp detectors either pair-wise or
    iteratively same as in BBC2 or IBC Boolean combination techniques. Although the
    proposed approach is experimentally validated only on HIDS using system call data,
    it can be applied in other application domains particularly, where one model does
    not formulate the complex normal behaviors of a system. In that case, we can train
    ensemble detectors with considering various normal behaviors. Then, the proposed
    method may be a good one for pruning and combining the multiple detector''s decisions.
    For example, detecting programming errors (i.e., software bugs) and root causes
    in a complex computer programming system [64], [65]. Fosdick and Osterweil [66]
    reported that a computer program is strongly related to the computation patterns
    of input data and, thus, useful for detecting the data flow anomalies. The sequences
    of operations, i.e., the flows of data are assumed to be consistent and used to
    model ensembles classifiers. A social or cultural event or road accident can also
    be detected using sensor and user (e.g., users of twitter, Facebook, etc.) generated
    data. For example, Pramod et al. [63] trained several linear Markov models by
    segmenting the nonlinear traffic data and used them to detect the city events.
    SECTION VIII. Limitations and Discussion Our approach is limited to ensemble of
    homogeneous soft anomaly detectors (i.e., multiple HMMs). However, the input can
    be ensemble of heterogeneous soft and crisp anomaly detectors (e.g., STIDE [11]
    , SVM [72], etc.). In fact, having different types of detectors should further
    increase the diversity in the ensemble and allow for improved performance [73].
    Heterogenous detectors use different learning techniques and may commit different
    (and potentially complementary) type of errors, which increases the diversity
    in the ensemble. For example, OC-SVM models the normal behavior of a system using
    fixed-size feature vectors instead of sequential features like HMM; STIDE uses
    the Hamming distance, whereas HMM uses likelihood probability as a matching measure.
    To adapt our approach to support heterogeneous detectors, we need to modify Phase1,
    which assumes the same thresholds of a base soft detector, which are the orders
    or levels for the weighted kappa for computing the diversity score. It may be
    more efficient to group them based on each modeling technique. Then, apply the
    Phase1 pruning technique on each group separately. For example, STIDE with various
    sliding window sizes can be used to produce many homogeneous soft detectors [11],
    which can then be fed as input to Phase1. Although the proposed approach significantly
    reduces the Boolean combination time (see Fig. 10) by pruning the number of combined
    soft (K) and crisp detectors (N), the worst case time complexity, particularly,
    for the pruning phases (given in Table II), will be increased exponentially (
    K 2 ) with the increase of K. Therefore, for large values of K, the pruning approach
    may suffer from scalability problems. To address this limitation, we need resort
    to parallel processing techniques and platforms such as the Hadoop ecosystem [74],
    [75]. Moreover, the proposed approach is dependent on the ROC space for pruning
    and combining the decisions of the selected complementary crisp detectors. However,
    here, the used ROC curves are a binary classification problem. Therefore, to extend
    the approach for multiclass classification problems, we need to work with an ROC
    curve for more than two classes, and then adapt the Boolean combination and pruning
    techniques to accommodate multiple classes. SECTION IX. Conclusion The proposed
    effective pruning-based Boolean combination techniques analyze the diversities
    among the available ensemble soft detectors (HMMs) using weighted kappa (measures
    the agreement/disagreement between two soft detectors). Based on the weighted
    kappa coefficients, it selects a best subset of diverse base soft detectors while
    pruned all the redundant soft detectors. Each selected base soft detector is then
    converted into all the possible crisp detectors (at various decision thresholds),
    and then used for selecting a subset of complementary crisp detectors using an
    unweighted kappa-based MinMax-Kappa pruning technique. At the end, we merge all
    the selected complementary crisp detectors and use them for Boolean combinations.
    The experimental evaluation on the two benchmarking ADFA-LD and CANALI-WD system
    call datasets verified the validation of the proposed method. We achieved much
    better results than the recent PBC pruning technique, particularly, when the false
    alarm is almost close to zero. Our future plan is to investigate the proposed
    pruning approach using different diverse detectors and other datasets. Moreover,
    we also want to leverage big data platforms such as Hadoop and the MapReduce programming
    model in order to further improve the performance of our approach, especially
    when used with multiple heterogeneous ensemble soft detectors such as HMMs, One-class
    SVM, STIDE, and so on. Authors Figures References Citations Keywords Metrics Footnotes
    More Like This Anomaly Detection and Classification in Multispectral Time Series
    Based on Hidden Markov Models IEEE Transactions on Geoscience and Remote Sensing
    Published: 2022 An Unsupervised Anomaly Detection Approach using Subtractive Clustering
    and Hidden Markov Model 2007 Second International Conference on Communications
    and Networking in China Published: 2007 Show More IEEE Personal Account CHANGE
    USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile
    Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS
    Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT
    Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use |
    Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy
    A not-for-profit organization, IEEE is the world''s largest technical professional
    organization dedicated to advancing technology for the benefit of humanity. ©
    Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Transactions on Reliability
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Anomaly Detection Techniques Based on Kappa-Pruned Ensembles
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

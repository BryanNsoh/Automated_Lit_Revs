- DOI: https://doi.org/10.1109/access.2019.2926642
  analysis: '>'
  authors:
  - Basheer Qolomany
  - Ala Al-Fuqaha
  - Ajay Gupta
  - Driss Benhaddou
  - Safaa Alwajidi
  - Junaid Qadir
  - A.C.M. Fong
  citation_count: 128
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy IEEE.org IEEE Xplore IEEE
    SA IEEE Spectrum More Sites Subscribe Donate Cart Create Account Personal Sign
    In Browse My Settings Help Institutional Sign In All Books Conferences Courses
    Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals & Magazines
    >IEEE Access >Volume: 7 Leveraging Machine Learning and Big Data for Smart Buildings:
    A Comprehensive Survey Publisher: IEEE Cite This PDF Basheer Qolomany; Ala Al-Fuqaha;
    Ajay Gupta; Driss Benhaddou; Safaa Alwajidi; Junaid Qadir; Alvis C. Fong All Authors
    116 Cites in Papers 8179 Full Text Views Open Access Comment(s) Under a Creative
    Commons License Abstract Document Sections I. Introduction II. Smart Buildings:
    Concept and Architecture III. Smart Building Components IV. Ml Background for
    SBS: Models, Tasks, and Tools V. Applications of Ml-Based Context-Aware Systems
    for SBs Show Full Outline Authors Figures References Citations Keywords Metrics
    Abstract: Future buildings will offer new convenience, comfort, and efficiency
    possibilities to their residents. Changes will occur to the way people live as
    technology involves people''s lives and information processing is fully integrated
    into their daily living activities and objects. The future expectation of smart
    buildings includes making the residents'' experience as easy and comfortable as
    possible. The massive streaming data generated and captured by smart building
    appliances and devices contain valuable information that needs to be mined to
    facilitate timely actions and better decision making. Machine learning and big
    data analytics will undoubtedly play a critical role to enable the delivery of
    such smart services. In this paper, we survey the area of smart building with
    a special focus on the role of techniques from machine learning and big data analytics.
    This survey also reviews the current trends and challenges faced in the development
    of smart building services. The major machine learning tasks that are relevant
    to smart buildings include: data collection and acquisition, data pre-processing,
    and dimensionality reduction. Published in: IEEE Access ( Volume: 7) Page(s):
    90316 - 90356 Date of Publication: 03 July 2019 Electronic ISSN: 2169-3536 DOI:
    10.1109/ACCESS.2019.2926642 Publisher: IEEE CCBY - IEEE is not the copyright holder
    of this material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/
    to obtain full-text articles and stipulations in the API documentation. SECTION
    I. Introduction Although the term “smart building” (SB) may bring a thought of
    a fictional smart space from science-fiction movies, but the reality is that SBs
    exist today, and their number is getting increased. With recent advances in machine
    learning (ML), big data analytics, sensor technologies and the Internet of Things
    (IoT), regular buildings can be cost-effectively transformed into SBs with bare
    minimum infrastructural modifications. There are smart office, smart library,
    smart home, smart health care facilities, smart hospital and many other types
    of SBs that can provide automated services that can provide many value-added services
    (such as reduction of wasted energy) and also help to ensure the comfort, health,
    and safety of the occupants. The hyperconnectivity that will be brought about
    by the emergence of IoT will increase the promise of SB since now all the basic
    building amenities and commodities ranging from your house electronics to your
    plant vases will be interconnected. But this hyperconnectivity will at the same
    time complicate the process of managing SBs. In particular, SBs and their inhabitants
    are expected to create large volumes of streaming data. ML, sampling, compression,
    learning, and filtering technologies are becoming more significant to manage the
    stream of big data of individuals. In 1981, the term Intelligent Buildings (IBs)
    was initially coined by United Technology Building Systems (UTBS) Corporation
    in the U.S. In July 1983, IBs became a reality with the opening of the City Place
    Building in Hartford, Connecticut [1]. Today, the number of SBs is growing at
    an unprecedented rate including smart office, smart hospitality, smart educational
    facilities etc. [2]. An SB is recognized as an integrated system that takes advantage
    of a range of computational and communications infrastructure and techniques [3].
    Examples of SB services include smart thermostats that allow the temperature to
    be controlled based on the time of the day/year and the users’ preferences with
    minimal or no manual configuration. Using data analytics to “learn” the users’
    preferences before taking the appropriate actions is probably the most important
    enabling technology for IBs [4]. Lately, smart coffee machines appeared in the
    market with the capability to make coffee automatically, according to users’ preferences
    and schedules. Fridges can offer allocated programming interfaces for their control
    [5]. IBs aim to provide their users with safe, energy efficient, environment-friendly,
    and convenient services. In order to maximize comfort, minimize cost, and adapt
    to the needs of their inhabitants, SBs must rely on sophisticated tools to learn,
    predict, and make intelligent decisions. SB algorithms cover a range of technologies,
    including prediction, decision-making, robotics, smart materials, wireless sensor
    networks, multimedia, mobile computing, and cloud computing. With these technologies,
    buildings can cognitively manage many SB services such as security, privacy, energy
    efficiency, lighting, maintenance, elderly care, and multimedia entertainment.
    The massive volume of sensory data collected from sensors and appliances must
    be analyzed by algorithms, transformed into information, and minted to extract
    knowledge so that machines can have a better understanding of humans than their
    environment. Furthermore, and most importantly, such knowledge can lead to new
    products and services that can dramatically transform our lives. For example,
    readings from smart meters can be used to better predict and balancing the usage
    of power. Monitoring and processing sensory data from wearable sensors attached
    to patients can produce new remote healthcare services. The main philosophy behind
    ML is to create the analytical models automatically in order to permit the algorithms
    to learn continuously from available data. The application of ML techniques increased
    over the last two decades due to the availability of massive amounts of complex
    data and the increased usability of current ML tools. Today, ML is already widely
    applied in different applications including recommendation systems offered by
    online services (e.g., Amazon, Netflix) and automatic credit rating services used
    by banks. Alphabet’s Nest thermostat utilizes ML to “learn” the temperature preferences
    of its users and adapt to their work schedule to minimize the energy use. Other
    widely publicized examples of ML applications include Google’s self-driving car,
    sentiment analysis of Amazon and Twitter data, fraud detection, and Facebook’s
    facial-recognition technology that is used to tag the suggested person on images
    uploaded by users. A. SB Trends and Market Impact In this section, we look at
    the statistics related to SBs, to allow us to understand the current trends and
    motivations in industry marketplaces and academic researches toward SBs. According
    to the report by MarketsandMarkets [6], The SB market is estimated to grow from
    7.42 billion dollars in 2017 to 31.74 billion dollars by 2022, at a Compound Annual
    Growth Rate (CAGR) of 33.7% from 2017 to 2022. In yet another report Zion Market
    Research [7], 2016 and it is expected to reach 61,900 million dollars by 2024.
    It is expected to exhibit a CAGR of more than 34% between 2017 and 2024. The market
    is primarily driven by government initiatives globally for SB projects and the
    increasing market for integrated security and safety systems as well as energy
    efficient building systems. Figure 1 shows the Statista [8] forecast market size
    of the global smart home market from 2016 to 2022 (in billion U.S. dollars). FIGURE
    1. Forecast market size of the global smart home market from 2016 to 2022 [8].
    Show All According to the Gartner report [9], it is expected that the number of
    smart connected homes grows to 700 million homes by 2020, supplied by mass consumer
    adoption and an increase in the number of devices and apps available. Figure 2
    shows Gartner’s 2018 Hype Cycle expectation for deep learning, ML, connected homes,
    and smart workspace. FIGURE 2. Hype Cycle for the Connected Home, 2018 [7]. Show
    All According to report by Research and Markets [10], [11], the global IoT SB
    market will reach approximately $51.44B USD globally by 2023. The report also
    forecast that 33% of IoT SB market will be supplied by artificial intelligent
    technologies by 2023, and automation systems of SB will grow at 48.3% CAGR from
    2018–2023. Frost & Sullivan also predict that by 2025, the growth of connected
    home living will reach 3.7 billion smartphones, 700 million tablets, 520 million
    wearable health-related devices and 410 million smart appliances in the connected
    person world. B. Related Survey Papers Although many of survey papers focused
    on SBs have been published, none of them is focused on the role of data analytics
    and ML in the context of SBs. We describe the relevant survey papers next and
    will compare these survey papers to our paper in Table 2. Chan et al. in 2008
    provided an overview of smart home research [12]. It also discusses assistive
    robots, and wearable devices. The article reviews smart home projects arranged
    by country and continent. Alam et al. [13] provided details about sensors, devices,
    algorithms, and communication protocols utilized in smart homes. The paper reviews
    smart home works according to their desired services and research goals; namely,
    security, comfort, and healthcare. Lobaccaro et al. [14] presented the concept
    of smart home and smart grid technologies and discuss some challenges, benefits
    and future trends of smart home technologies. Pan et al. [15] reviewed the works
    on efficient energy consumption in SBs using microgrids. The survey investigates
    research topics and the recent advancements in SBs and the vision of microgrids.
    A few survey papers have reviewed works on facilitating independent living of
    the elderly people in smart homes. Ni et al. [16] conducted a survey on the features
    of sensing infrastructure and activities that can assist the independent living
    of the elderly in smart homes. A survey on ambient assisted living technologies
    for elderly people has been presented Rashidi and Mihailidis [17]. Peetoom et
    al. [18] focused on monitoring technologies to recognize life activities in-home
    such as fall detection and changes in health status. Salih et al. [19] presented
    a review of ambient intelligence assisted healthcare monitoring services and described
    the various application, communication, and wireless sensor network technologies
    that have been employed in the existing research literature. A number of papers
    have focused IoT: (a) Perera et al. [20] discussed IoT applications from the perspective
    of context-awareness and self-learning; (b) Tsai et al. [21] surveyed the applications
    of data mining technologies in IoT; and (c) Mahdavinejad et al. [22] reviewed
    some ML methods that can be applied to IoT data analytics. TABLE 1 List of Important
    Acronyms Used TABLE 2 Comparison of Relevant Survey Papers C. Contributions and
    Organization of This Paper To the best of our knowledge, this is the first survey
    that covers SBs jointly from the perspectives of application, data analytics,
    and ML. The main contributions of our paper are: Exploration of the potential
    of ML-based context-aware systems to provide SB services; Identification of research
    challenges and directions for SBs and how ML models can help in resolving such
    challenges; Identification of SB applications including comfort, security, energy
    efficiency, and convenience and the role of ML in such applications. Our research
    can provide an impetus to ML researchers to investigate new exciting ML-based
    SB services. The rest of the paper is organized as follows: Section II introduces
    the concept of SBs and its underlying architecture. Section III introduces the
    various components of the SB ecosystem and its underlying architecture. Section
    V presents context recognition and activity modeling and the role of ML in SBs.
    Section VI highlights research and development challenges and provides a future
    perspective of SB projects. Finally, Section VII presents a summary of lessons
    learned and concludes the paper. For the convenience of the readers, we have enlisted
    the important acronyms used in Table 1. SECTION II. Smart Buildings: Concept and
    Architecture In 1984, The New York Times published an article that described that
    real estate developers are creating “a new generation of buildings that almost
    think for themselves called intelligent buildings.” Such an intelligent building
    (IB) was defined as “a marriage of two technologies - old-fashioned building management
    and telecommunications.” [23]. Since then, many definitions of SBs have been suggested.
    This is due to the fact that the life-cycle of building planning, design, implementation,
    and operation involves different industry players that have different roles. In
    addition, the rapid changes in technology are affecting this definition. For instance,
    the advent of IoT and smart city concepts is impacting the definition of SB. Therefore,
    it is hard to compose a unique view of IBs with a single definition that is accepted
    worldwide. However, it is vital to have a good understanding of the main standard
    bodies and companies involved in shaping the development of SBs [1]. The Institute
    for Building Efficiency [24] focuses on the operation of buildings to provide
    efficient healthy and comfortable environment [25]. IBM [26] focuses also on the
    operation of SBs to provide integrated physical and digital infrastructures that
    provide reliable, sustainable, and cost-effective occupancy services. According
    to the European Commission’s Information Society [27], SBs means buildings that
    are supplied by information and communication technologies in the context of the
    combining Ubiquitous Computing and the IoT: In general, the buildings that are
    supplied with sensors, actuators, microchips, micro- and nano-embedded systems
    in order to enable collecting, filtering and producing more information locally,
    to be further incorporated and managed globally according to business functions.”
    In SBs, a variety of AI and multi-agent system techniques are employed including
    [28]: Reasoning and knowledge representation including ontologies and rules to
    represent devices and building services. ML for human activity recognition. Multi-agent
    systems for distributed intelligence and semantic interoperability. Intelligent
    approaches such as planning, intelligent control, adaptive interfaces, and optimization
    for efficient management of resources and services. An SB is therefore the integration
    of a wide range of systems and services into a unified environment that involve
    energy management systems, temperature monitoring systems, access security systems,
    fire and life safety, lighting control and reduction, telecommunications services,
    office automation, computer systems, area locating systems, LANs, management information
    systems, cabling and records, maintenance systems, and expert systems [29]. Figure
    3 shows examples of SB appliances including air-conditioning systems, lighting
    systems, solar energy generators, power-supply systems, temperature sensors, humidity
    sensors, power usage sensors, and surveillance cameras. For example, centralized
    control of these elements can promote the efficient use of energy through the
    intelligent control of lights and air conditioning units and the intelligent management
    of multiple green and brown energy sources. In most cases, an SB uses an Ethernet
    backbone with bridges to a Controller Area Network (CAN) [26]. FIGURE 3. Example
    of SB appliances. Show All It is easier to introduce smart services in residential
    buildings compared to commercial buildings since residential buildings have less
    technical equipment and less stringent efficiency requirements. Because the commercial
    buildings usually have more public visitors and therefore building models for
    commercial buildings are usually more challenging than building models for residential
    buildings which usually have a limited number of the occupants most of the time.
    In addition, the costs associated with the purchase and installation of smart
    devices and infrastructure at commercial buildings is more than residential buildings.
    Figure 4 shows an integrated framework in a residential building that employs
    a network of intelligent sensors. These sensors control systems such as energy
    generation, metering, HVAC, lighting, and security. A building automation system
    manages a set of smart appliances, sensors, and actuators, which collectively
    deliver services for the well-being of the inhabitants. Examples of such smart
    appliances, sensors, and actuators include washers and dryers, refrigerators,
    heaters, thermostats, lighting systems, power outlets, energy meters, smoke detectors,
    televisions, game consoles, windows/door controllers and sensors, air conditioners,
    video cameras, and sound detectors. More advanced smart devices are constantly
    being developed like smart floors and smart furniture [28], [30]. FIGURE 4. Smart
    appliances, sensors, and actuators in a smart residential building. Show All The
    IoT will enable the integration and interoperability of heterogeneous devices
    in SBs as well as the real-time processing of the data generated by sensors in
    support of optimal control and operation of the building. In this paper, We propose
    a layered architecture for SBs based on the layered architecture of IoT. Figure
    5 shows the layered architecture of SBs. FIGURE 5. Layers of the base IoT architecture
    that serves as the foundation for SBs. Show All As can be seen from the sensing
    layer (the bottom layer in Figure 5), input data is obtained from different types
    of physical sensors that monitor environmental parameters, collect data about
    residents and detect anomalies (e.g., fire and water pipe bursts). This layer
    also includes actuators that can be controlled to save energy, minimize water
    consumption, etc. The network layer (the second layer in Figure 5), includes access
    and core networks that provide transparent data transmission capability. This
    layer serves as a bridge between the sensing layer and the upper layers which
    are mainly responsible for data processing. An intermediary software layer called
    the middleware layer is needed (the third layer in Figure 5) to provide seamless
    integration of heterogeneous devices and networks covered by the sensing layer
    of the architecture. That layer serves as a bridge between the embedded software
    that runs of smart sensors and back-end software services. This layer provides
    interoperability using standardized programming interfaces and protocols [31].
    Therefore, this layer performs the process of converting the collected data from
    various data formats into a common representation. SB middleware can be based
    on open standards or proprietary, in addition, application-specific or general-purpose.
    Most often, proprietary middleware is application-specific while general-purpose
    middleware is based on open standards [28]. The context and semantic discovery
    layer (the fourth layer in Figure 5) is responsible for managing context and semantic
    discoverers including context and semantics generating, configuring, and storing.
    The processing and reasoning layer (the fifth layer in Figure 5) is responsible
    for processing the extracted information from the middleware then according to
    the application’s type it will make decisions. In this layer, there are various
    techniques of information processing applied to fuse, extract, contextualize.
    massive data into useful actionable knowledge. In this layer, two phases should
    be identified: context consumer and context producer of the middleware. In the
    context consumer phase, the data processing techniques are applied on the data
    produced by the middleware; while in context producer phase the process of decision-making
    is implemented to supply the service layer with valuable knowledge. while in the
    second stage, further context information can be provided to the middleware for
    registration in the ontology context. Specific services and applications are abstracted
    in the application layer (the top-most layer in Figure 5). This layer presents
    a framework with direct access to the underlying functionalities to serve in the
    implementation of various types of applications. Moreover, control panels should
    be installed in the building to control the automated indoor spaces and to support
    a local human-machine interface. For instance, in a multi-story building, each
    floor could have a control panel to automate the operations, such as control opening
    the windows, control of air conditioning to achieve the desired temperature, control
    close/open the blinds according to the preferred light intensity before using
    artificial lighting [32], [33]. Summary: Still there is no single standard definition
    for SBs. In this section, we reviewed many definitions for SBs by many institutes,
    counties, regions and different disciplines; each has their own definition for
    SBs. We presented the layered architectural pattern for adapting services in an
    SB environment. We wanted to provide a general design for adapting actions according
    to the different versions of context in SBs. This architecture may be used in
    different smart environments such as intelligent transport systems, security,
    health assistance, and SBs among others. We layered the architecture into six
    layers starting from the sensing layer, which includes various types of sensors
    that are installed to collect environmental information in SBs. While network
    layer providing data stream support and data flow control and ensuring that messages
    arrive reliably by using data transport protocols such as Wi-Fi, Bluetooth, Ethernet
    etc. Data Acquisition layer to collect the data from the heterogeneous sources
    of data. Context and semantic discovery layer to generate, configure, and store
    context and semantic information. Context processing and reasoning layer to process
    the information and extract the knowledge that making the decisions according
    to the application context. And the last layer which is application layer such
    as health assistance and elderly home care, comfort and entertainment services,
    security, tele-management, smart watering, energy efficiency, etc. After discussing
    the main components of commercial and residential buildings, we have now set the
    stage for a detailed discussion on the components of SBs in the next section.
    SECTION III. Smart Building Components Advances in smart building technology have
    driven to the extensive development of SBs to generate economic and environmental
    benefits for building owners through the convergence of IT and building automation
    systems. Figure 6 shows the key components of SB systems, these include extensive
    sensors and actuators systems, networking and communication systems, software
    platform system, HVAC system, and smart control devices. FIGURE 6. Components
    of smart buildings. Show All Current systems utilize control devices and smart
    sensors that are connected to a central system. These control devices and smart
    sensors are placed throughout the environment. Each particular system has its
    own collection of networking and communication systems that enable it to communicate
    with the central system. SBs are performing connected networks that serve as a
    communication backbone for multiple systems. In many ways, HVAC equipment is the
    most complicated building system, with numerous components arranged to produce
    heating, cooling, and ventilation. The functionality of HVAC system not only makes
    the building healthy and comfortable for its inhabitants, but it also manages
    a big part of the energy consumed, as well as plays a significant role in life
    safety. SBs adopt technology to monitor and control facility systems and perform
    any required modifications. The objective of an SB is to utilize computers and
    software to control lighting, alarm systems, HVAC, and other systems through a
    single computer interface. A. Sensors and Actuators for SBs Sensors and actuators
    are mechanical components that measure and control the environmental values of
    their environment. Sensors collect information from the environment and make it
    ready for the system. For instance, IR sensors can be utilized for human presence
    detection in a room. While actuator is a device to convert an electrical control
    signal to a physical action, such that it takes decisions and then performs proper
    actions according to the environment, which enables automated and remote interaction
    with the environment.For example, a light actuator is capable of switching on/off,
    dimming one or more electric lights [34]. The rapid development of micromechanics,
    microelectronics, integrated optics, and other related technologies has facilitated
    the development of different types of smart sensors integrated into daily objects
    and infrastructure at smart building environment or worn by the users, and are
    connected by network technologies in order to collect contextual information about
    daily living activities more efficiently and faster, with lower energy consumption
    and less processing resources. Environmental sensors are utilized for detecting
    the human activity of a specific object that performed in specific locations in
    the building, while wearable sensors are utilized for controlling and observing
    mobile activities and physiological signals [35]. 1) Environmental Sensors It
    is found that data collected from environmental sensors can form important information
    to monitor human behaviors within an SB. These sensory data are then analyzed
    to identify and observe basic and instrumental daily living activities made by
    occupants such as bathing, dressing, preparing a meal, taking medication etc.
    The environmental sensing is generally based on several simple binary sensors
    in every part of the home, RFID technology, and video cameras. This variety of
    sensing may implement important insight into contexts and actual activities although
    it might come with possible costs such as complexity. Motion sensors are utilized
    for detecting the occupant’s presence and location everywhere in the house. There
    are different types of motion sensors. IR presence sensor is one of the most utilized
    kind of motion sensors in SBs to detect occupants’ presence. Pressure sensors
    can be attached to the objects such as beds, chairs, sofas, and floors in order
    to track the actions and locations of the occupants. While Contact switches are
    usually placed on the doors of fridge, rooms, or cabinets to detect the actions
    that the occupant makes with these objects [36]. Light sensors, humidity sensors,
    temperature sensors, or power sensors are other types of sensors that are deployed
    and utilized in SB to recognize the activities. Light sensors are utilized to
    measure the light intensity in a particular room in the building. Humidity sensors
    are utilized to detect the air humidity of a specific location in the building.
    Temperature sensors are utilized to measure the temperature of the specific environment.
    while the power sensors are utilized to identify the power usage of electric devices.
    2) Wearable Sensors and Biosensors These sensors are attached directly or indirectly
    to the user body. Their small size enables these sensors to be attached to clothes,
    wristwatches, glasses, belts, shoes etc. These sensors can be categorized into
    inertial sensors and vital sign sensors (or biosensors). Wearable inertial sensors
    are highly transportable and no stationary units that can give accurately detailed
    features of occupant’s action and body posture. Those sensors are composed of
    accelerometers, gyroscopes and magnetic sensors. There is a need for receivers
    and cameras in the process of data collection, therefore can be used outside laboratory
    circumstances [37]. Wearable biosensors such as blood pressure, skin temperature,
    and heart rate are significant for collecting vital signs to monitor the health.
    The most commonly utilized inertial sensors for mobile activity monitoring are
    accelerometers and gyroscopes. Accelerometers can be utilized to measure the rate
    of acceleration accompanying a sensitive axis, they are useful to monitor the
    motion’s activities such as doing exercise, standing, sitting, walking, or walking
    upstairs and downstairs. While the gyroscopes can be utilized to measure angular
    velocity and maintain orientation. Some examples of primary vital signs are Electrocardiogram
    (ECG), heart rate, blood pressure, blood glucose, oxygen saturation, and respiratory
    rate. There are various vital sign sensor utilized to measure different vital
    signals such as Electroencephalography sensors (EEG) for observing electrical
    brain activity, Electrooculography sensors (EOG) for observing eye movement in
    ocular activity, Electromyography sensors (EMG) for observing muscle activity.
    Electrocardiography sensors (ECG) for observing cardiac activity, pressure sensors
    for observing blood pressure, CO2 gas sensors for observing respiration, thermal
    sensors for observing body temperature and galvanic skin response for observing
    skin sweating [38], [39]. 3) Heating, Ventilation, and Air Conditioning (HVAC)
    HVAC system plays an essential role in SB services. HVAC system plays a remarkable
    role in efficient energy consumption in SBs, as well as it offers new operating
    options to increase the occupants’ comfort. In addition to meeting the desired
    temperature, HVAC control systems are produced in order to sustain comfort within
    an enclosed space by producing a specific level of humidity, pressure, air motion,
    and air quality in an SB [40]. CO2, humidity and temperature levels in a building
    can affect occupant’s health and comfort; consequently measuring CO2, humidity,
    and temperature in this context can improve personal wellbeing [41]. Heating and
    cooling systems consume a huge amount of energy in the buildings, so it is necessary
    to optimize it utilizing smart controllers and sensors in order to save operational
    costs. Smart HVAC systems can sense and control efficiently different air quality
    parameters inside the building by utilizing distributed sensors and VAV fans throughout
    the building to perform an optimal ventilation [42]. Most of the current HVAC
    actuation systems in smart buildings are based on the data collected about the
    occupants using sensors and cameras, which are utilized specifically for HVAC
    systems. Certainly, There is a specific cost for the design, maintenance, setup
    and hardware of the data collection network [43]. Table 3 shows a summary for
    different types of smart sensors in the SBs. TABLE 3 Various Smart Sensors Useful
    in the Context of SBs B. Smart Control Devices Smart control devices collect data
    from a variety of sensors, process this data, and activate actuators to react
    to the events detected by the sensors. A smart control device can operate independently,
    without control by a central server. But there might be a needed communication
    amongst various control devices or they can connect with each other using the
    smart gateway. WeMo [44] is a Wi-Fi enabled switch utilized to turn electronic
    devices on/off from anywhere. It can control LED motion sensors, light bulbs,
    mart wall switches and plugs, and lighting devices, all from the smartphone app
    or browser. There is no hub needed for WeMo devices, everything can be managed
    through the free cloud service provided by Belkin. You can use the specific channel
    to connect the device to e-services such as Gmail to trigger specific actions.
    WeMo devices also support context-aware feature, it turns on/off automatically
    according to the time of day, whether it is sunrise or sunset etc. The Nest thermostat
    [45], a smart device developed by Nest—which has been acquired by Google—adjusts
    to your life and seasons change automatically. Just use it for a week and it programs
    itself. It learns about the level of temperatures that the occupants prefer and
    creates a context-aware personalized schedule. The smart thermostat turns to an
    energy-efficient mode automatically when the residents leave the building. It
    could start warming up the area when it senses activity, such as an occupant’s
    returning back home from work. The Nest Thermostat is controllable via a smartphone
    and an installed app. If you are away for a while, this device has also a capability
    to sustain a particular temperature in your house. Lockitron [46] is a door lock
    that can control the door remotely over the Internet to open and close it by phone.
    Lockitron app can be installed and used by any iOS or Android smartphone. Homeowners
    can directly grant family and friends the access to open a given door by providing
    authorization over the Internet. Lockitron can also utilize Bluetooth low energy
    technology, which means that it will keep controlling even in the event of Internet
    or power outages. Lockitron can also connect to the Internet with Bridge, through
    which occupants can control the bolt anywhere in the world. The SmartThings [47]
    SB automation system comprised of a communications smart hub, that supports various
    smart appliances and devices; the smart hub supports various technologies and
    protocols such as ZigBee, Z-Wave, as well as IP-accessible devices and lets you
    control appliances using Wi-Fi and Bluetooth connectivity. SmartThings provides
    kits that include smart plugs, in addition, the basic sensors that can be utilized
    to measure temperature, as well as to detect presence, motion, orientation, and
    vibration. SmartThings also includes an open platform that enables smart device
    vendors and third-party software to provide hardware and software that can be
    utilized alongside the platform. Philips Hue [48] is a combination of LED lighting
    with mobile technology. An accompanying mobile app that allows you to control
    lighting systems and changing color sets depending on your mood utilizing Wi-Fi
    technology. The new Philips Hue bridge supports the required authentication to
    enable Apple HomeKit technology to control and enable your Philips Hue to connect
    to other HomeKit enabled accessories and take control of your home. Blufitbottle
    [49] this bottle records the drinking habits of the users and sends them notifications
    about the time and amount of the water that they are supposed to drink to keep
    them healthy and hydrated. The app collects data about users such as their weight
    and age, plus other factors such as the current levels of temperature and humidity
    to estimate the amount of the needed water to keep them hydrated. When the user
    falls behind with hydration, an alert sounds, as well as a simple glance from
    the LEDs, will indicate when it’s time for the next drink. Canary [50] is an all-in-one
    home security system that comprises a set of sensors such as temperature, air
    quality, sound, motion vibration, in addition, an HD video camera in one unit.
    The system utilizes ML algorithms to let the users know what is happening at home
    and take action by sending notifications to your phone if something happens. Those
    ML models learn over time and send the users smarter notifications as it detects
    motion. So that, the longer you have the system, the more effective it becomes.
    Canary is able to decrease the rate of false alarms by learning the user behavior
    and the ambient noise level and the home temperature patterns. Amazon Echo [51]
    is a small cylinder enable the users to control anything in the home via the voice.
    Amazon Echo has a powerful voice recognition capability, the user does not have
    to worry about the complexities of their voice. Amazon Echo is connectable via
    Wi-Fi or Bluetooth, the users can send voice commands to control the speakers
    as well as other compatible devices such as Belkin’s WeMo and Philips Hue. It
    can also use Amazon cloud Lambda service to send commands. To send any command
    It requires to include the name of the program, for instance, “Alexa, turn on
    TV”. It also includes a network to distant servers, which slows down the response
    time. Honeywell Total Connect Remote Services [52] this device merges personal
    smart home automation with security monitoring task. It enables the occupants
    to control and monitor everything in the home from lighting and window shades
    systems to security cameras and smoke alarms. the user can utilize a smartphone
    app or desktop-mounted hardware console for controlling and monitoring. It can
    provide real-time alerts, GPS vehicle and asset tracking, video viewing, and mobile
    control. The system only supports Z-Wave devices, it needs to be installed by
    an authorized Honeywell dealer. It does not work with Wi-Fi enabled smart thermostats.
    In addition, the Honeywell provides security cameras and sensors, it also supports
    other smart devices from third parties, such as Yale locks and Lutron lighting.
    Table 4 shows a comparison among various smart control devices in the SBs. TABLE
    4 Comparison Among Various Smart Control Devices in SB C. Networking and Home
    Gateway An SB combines a communication network in order to control smart devices
    and services within the building. The communication network of a smart building
    can be based on diverse communication media such as twisted pair cable, as the
    traditional computer networks. The networking in building automation system has
    a tendency to utilize a heterogeneous network that is made up of diverse communication
    media and network standards. The building automation network is identified by
    physical technology and communication protocols. There is an internal network
    that connects devices inside the building, as well as the external networks, can
    be integrated separately. Public Internet, ISDN, and mobile phone networks are
    some examples of external networks [28], [53]. A typical SB may comprise a number
    of different components, such as sensors, actuators, communication and processing
    devices. Because of their nature, these components have limited capabilities and
    computational capacity in term of battery capacity and capability of data processing.
    To deal with this issue, most of the SB systems have been utilized as a central
    gateway to collect, process, and analyze context data from different sensors and
    actuators in the building. Several protocols such as Bluetooth, ZigBee, Wi-Fi,
    and Z-wave can be utilized for communicating the gateway. The home gateway can
    also collect and store data for a specific time period. Typically, these gateways
    can connect to the cloud services and perform data processing and reasoning tasks.
    The centralized gateway usually does not have any interface. They can be controlled
    and managed utilizing smartphones, tablets, or computers [54], [55]. In general,
    depending on the communication media used, SB network technology can be classified
    by interconnection method into three main types: Powerline, Busline, and Wireless
    [15], [56], which we describe next. 1) Powerline Communication (PLC) PLC method
    reuses the building electrical network; such that devices, appliances, and services
    are directly connected to the main power supply utilizing the already available
    electrical outlets in a building. The data is sent through the normal cable system
    to activate or deactivate the devices in the building. PLC system is historically
    the oldest technology in SB and is generally cheap but less reliable and scalable
    [3]. Originally, the application of PLC was mainly to secure the typical operation
    of the electric power supply system in case of failures or breakdowns through
    the direct exchange of information between the distribution center, and power
    plant. Therefore, this approach has become a competitive choice for SB networking,
    benefiting from availability, robustness, and ready connectivity of this method.
    Some of the protocols of this method offer a single-way communication, which enables
    the device to only receive information but not to communicate. There are different
    mainstream protocols of PLC method such as X-10, INSTEON, HomePlug, BACnet, and
    Lonworks. 2) Busline Busline systems in SBs networks use a separate physical media,
    usually twisted-pair cabling similar to the physical cables utilized for network
    services for transporting electrical signals. This type of systems is pleasant
    the building’s occupants, albeit the configuration process is complex, and it
    requires some knowledge of networking. Although the configuring complexity and
    installation cost of this system, the use of a separate cable could present a
    positive note about this approach, as it allows this method of networking to provide
    higher bandwidth, and to make it the most reliable of the three approaches. In
    addition, this technology usually supports a completed two-way communication protocol
    that enables the appliances to easily communicate with each other [57]. Some of
    the protocols in Busline technology are Konnex (KNX), CAN (Controller Area Network),
    Modbus, Meter-Bus (M-Bus). 3) Wireless Interconnection Many of the new SB applications
    use wireless technologies such as infrared and radio frequency, which are more
    convenient for users due to their untethered nature and the elimination of cables.
    The devices within the smart building can communicate wirelessly as radio wave
    can penetrate through floors, cabinets, and walls [56]. Because of the complexity
    and cost of potential modifications and of the re-wiring process in a smart building,
    several different wireless technologies are rising to produce flexible networking
    patterns convenient to occupants without taking to consider the physical wiring
    and deployment of such wire in the building. Typically, there are various protocols
    for the wireless system such as Bluetooth, ZigBee, WLAN, Z-wave, RFID etc., which
    essentially work in the industrial scientific medical bands, particularly in the
    2.4GHz frequency range. These wireless technologies are usually related to some
    control network concept in an SB such as low power consumption, high cost-effectiveness,
    low speed, flexibility in networking, deployment as well as building coverage
    [3]. The gateway is the central server of an SB that is commonly used in IoT solutions.
    The services provided by the gateway essentially concern to system management
    functionalities such as monitoring, controlling, and configuring the systems and
    their devices. It also supports some processing and data storage capabilities
    required for complex applications. D. Software Platform For a building to be “smart,”
    it is important that all the appliances and systems in the building communicate
    and exchange data securely with each other as well as with smartphones, tablets,
    and servers in the cloud. Software platforms play a critical role in exchanging,
    archiving and disseminating information through different protocols. These platforms
    use push, pull, publish/subscribe, etc. The goal of the joint commercial enterprises
    is to develop an open source software platform in order to make the process of
    data exchanging easier between the devices of different manufacturers. Therefore,
    the users will not have to worry in the future about the compatibility issues
    when utilizing electric and electronic devices of different manufacturers at home.
    In addition, the new platform can also offer a variety of different building services
    such as entertainment, energy efficiency, and security technology. Hence, this
    will enable creating different apps for these areas of use [58]. ABB, Robert Bosch
    GmbH, and Cisco Systems Inc. established an open-software platform called Mozaiq
    Operations GmbH [59] to unify smart building technology and offer interoperability
    across for all devices and services in the building, to simplify the experience
    for residents. It will enable users to seamlessly and intuitively customize their
    appliances and devices, regardless of manufacturers and brands of these devices,
    in order to improve energy efficiency and achieve a unique level of control and
    comfort. For instance, the user can close the blinds in the home either by a click
    from a smartphone or through a pre-set instruction; and switch off automatically
    all screen devices for the children to go outside to play. In a smart building,
    many devices and appliances can simply and securely share information with one
    another and with smartphones and other smart devices; and the Internet in general.
    Indigo Domotics [60] is to implement the do-it-yourself smart building platform.
    Indigo home automation software controllers available for the Mac OS enables residents
    to combine an array of common INSTEON, Z-Wave and X10 devices for unparalleled
    control of your building lighting, sensors, thermostats, and appliances. With
    Indigo Touch (sold through iTunes app store, iOS only), users will easily achieve
    remote control of their appliances utilizing an iPhone, iPad, or iPod Touch. They
    also can use a web browser on any device to control their appliances virtually
    anywhere in the world. The users can receive texts or emails about specific events
    has been detected for doors opening/closing, power failures etc. Indigo, from
    Perceptive Automation, is the newest home automation software for the Mac. OpenHAB
    [61] is an open-source software platform that follows a middleware approach for
    integrating different technologies in smart building systems into a single solution.
    OpenHAB platform address a variety of network technologies and appliances in the
    area of a smart building. Currently, the dependency on a particular vendor becomes
    a problem due to the lack of a common language that bridges the different devices
    with building automation system. The main goal of the OpenHAB platform is to integrate
    the new devices and technologies in a smart building system through a community-based
    approach. OpenHAB utilizes an OSGi based modular system for communicating between
    different technologies and devices. Bindings can be developed and deployed as
    an OSGi bundle to bridge a particular technology and device. There are different
    supported technologies exist such as EnOcean, KNX, Z-Wave, and others are supported
    through special bindings [62]. SmartThings [47] this platform composed of hardware
    devices, sensors, and software applications. Context information is collected
    from the sensors, this context is contributed to the reasoning and action that
    are performed by the application. For instance, the sprinkler in the garden can
    detect the rain, and switch itself off accordingly to save water. SmartThings
    kit comprises sensors, smart devices, and hub. While the SmartThings application
    is configured to enable users to control and monitor their building environment
    through a smartphone device. The SmartThings Hub works to connect the sensors,
    devices and building’s internet router to one another and to the cloud. It is
    compatible with different communication protocols such as Zigbee, Z-Wave, and
    IP-accessible devices. In addition, the SmartThings is compatible with other sensors
    and devices such as thermostats, moisture sensors, motion sensors, presence sensors,
    locks and garage door openers [63]. HomeOS [64] is Microsoft’s home operating
    system platform, that can be installed on a personal computer. It is an open platform
    that is not limited to Windows-based devices [65], [66]. with HomeOS platform,
    applications can be installed to maintain various context-aware functionalities,
    for example, taking an image by a door camera and sending it to the occupant when
    someone rings the doorbell. HomeOS provides a PC-like abstraction that manages
    and extends the technology of network devices to the users and developers in the
    smart building environment. Its design enables the users to map their protocol-independent
    services to support the applications with simple APIs, a kernel, and protocols
    of specific devices. HomeOS usually runs on an allocated computer such as a home
    gateway, it does not need any adjustments to commodity devices. HomeOS usually
    utilizes (i) Datalog-based access control to facilitate the process of managing
    technology in the smart home (ii) a kernel to incorporate the devices and applications
    and (iii) protocol-independent services to allow the developers manageable access
    to the devices. Lab of Things (LoT) [67], [68] is an experimental research platform
    that utilizes connected devices in the buildings. LoT offers a framework that
    provides deployment capabilities such as remote monitoring and updating of system
    health, and logging data collected from different appliances in cloud storage.
    It enables data sharing and collecting, sharing codes, connect hardware sensors
    to the software platform, and participants using HomeOS. The platform is designed
    to make it simple to design solutions that can be deployed in IoT based smart
    services such as healthcare, energy management services as it works in combination
    with HomeOS. Eclipse Smarthome [69] is a framework that has a focus on heterogeneous
    environments such as smart building and ambient assisted living. This platform
    takes to consider a variety of existing communication mechanisms. Eclipse SmartHome
    works as an abstraction and translation framework that enables communications
    across system and protocol boundaries. It provides many relevant implemented extensions,
    protocols, and standards that are significant for smart building services. Those
    implementations can be of Java library or an OSGi bundle shapes so that they can
    be utilized independently from the rest of the project. The framework can work
    on different embedded devices such as a BeagleBone Black, an Intel Edison, or
    a Raspberry Pi. Extensions of Eclipse SmartHome are compatible with the solutions
    provided by different vendors. This means your code that is written for a specific
    purpose can be extended easily on commercial platforms. Eclipse SmartHome offers
    a variety of characteristics to allow you to design a special Smart Home solution
    for your expectations [70]. Apart from discussing various SB solutions, we will
    also highlight the popular simulator called Cooja is used widely by the research
    community to produce small simulations for relatively large wireless networks
    of embedding sensors and actuators; and connected devices, in order to develop,
    debug and evaluate systems based on the wireless sensor network technology. Cooja
    simulator is a Java-based wireless sensor network simulator. It is distributed
    with Contiki OS project. Cooja enables the emulation of the set of sensor nodes,
    in addition, it can simulate physical and application layers of the system [71].
    There are three basic properties for the simulated node in Cooja: Its hardware
    peripherals, node type, and data memory. The node type can be shared among multiple
    nodes and defines properties that are common to all these nodes [72]. Summary:
    The field of SBs contains a variety of technologies, across commercial, industrial,
    institutional and domestic buildings, including building controls and energy management
    systems. Several organizations and institutions are working to supply buildings
    with technology that enables the residents to adopt a single device to control
    all electronic devices and appliances. In this section, we discussed the various
    components for SBs including sensors and actuators, smart control devices, smart
    gateway, networking and software platforms. SECTION IV. Ml Background for SBS:
    Models, Tasks, and Tools Massive data generated from sensors, wearable devices,
    and other IoT technologies provide rich information about the context of users
    and building status and can be used to design SB management. This context information
    is needed to extract useful and interesting insights for various stakeholders.
    When the data volume is very high, developing predictive models using traditional
    approaches does not provide accurate insight and we require newly developed tools
    from big data. Big data is primed to make a big impact in SBs and is already playing
    a big role in the architecture, engineering, and construction (AEC) industries
    [73], notably for waste analytics [74] and waste minimization [75]. ML is a powerful
    tool that facilitates the process of mining a massive amount of data that have
    been collected from different sources around us and make sense of a complicated
    world. ML algorithms apply a model on new data by learning the model from a set
    of observed data examples called a training set. For example, after being trained
    on a set of sample accelerometer data marked as walking or jogging, an ML algorithm
    can classify the future data points into walking and jogging classes. ML makes
    it relatively easy to develop advanced software systems without much involvement
    from the human side. They are applicable to many real-life problems in SB environments.
    One can also design and develop self-learning and collaborative systems. ML does
    not remove the human element from data science—it draws on computers’ strengths
    in handling big data to complement our understanding of semantics and context.
    It only needs training data to extract better features or parameters required
    to improve a given system. ML algorithms can be used to make predictions based
    on data patterns. It enables the computer to learn from the fed input data without
    being explicitly programmed so that ML algorithms can learn from and make predictions
    on input data [76], [77]. Nest thermostat is an example of a device that applies
    a specific temperature in a specific room and at a certain time of day according
    to the occupants’ preference. There are devices such as Amazon’s Echo that can
    learn from voice patterns, and the others those learn from much more complex behavior
    and activity patterns. A. Ml Models ML techniques have been widely used to develop
    smart systems which can sense and react according to context modifications in
    SBs [78]. There are many different ML algorithms, according to the two well-known
    theorems No Free Lunch theorem and Ugly Duckling theorem. No Free Lunch theorem
    states “there are no algorithms that can be said to be better than any other”,
    without prior information about the problem, any two algorithms may perform equally
    well in solving a problem. While Ugly Duckling theorem states “we cannot say that
    any two different patterns would be more similar to each other than any other
    pairs.” [79]. Mainly, ML is categorized into four categories handling different
    types of learning tasks as follows: Supervised learning, unsupervised learning,
    semi-supervised learning and reinforcement learning (RL) algorithms Figure 7 shows
    ML styles. These categories are described next and a summarized comparison between
    these ML techniques is presented in Table 5. TABLE 5 Comparison of ML Techniques
    FIGURE 7. ML styles. Show All 1) Supervised Learning refers to developing algorithms
    based on a labeled training dataset, from which the learner should generalize
    a representation by building the system model that represents the relations between
    the input, output and system parameters. ML model is developed through a training
    process that continues on the input training data until the model reaches the
    desired level of accuracy [80], [81]. Some examples of common supervised ML algorithms
    are: naive Bayes model, decision tree, linear discriminant functions such as support
    vector machines (SVMs), artificial neural networks (ANNs), hidden Markov models
    (HMMs), instance-based learning (such as k-nearest-neighbor learning), ensembles
    (bagging, boosting, random forest), logistic regression, genetic algorithms, and
    logistic regression [82], [83]. Supervised learning approaches are extensively
    used to solve different problems in smart buildings. Application in SBs: Boger
    et al. [76] proposed a supervised learning system using Markov decision processes
    to help people with dementia the process of hand washing. Altun et al. [84] make
    a comparative study on the supervised human activity classification approaches
    using body-worn miniature inertial and magnetic sensors. Mozer [85] developed
    the occupant comfort control of the home environment system using neural networks
    and reinforcement learning to control air heating, lighting, ventilation, and
    water heating in the smart home environment. Bourobou et al. [86] presented a
    hybrid approach using ANN and K-pattern clustering to identify and predict user
    activities in the smart environments. Hsu et al. [87] proposed a TV recommendation
    system using a neural network model based on user personalized properties such
    as activities, interests, moods, experiences, and demographic information data.
    Fleury et al. [88] proposed a healthcare-focused smart home system using the SVM
    algorithm to classify daily living activities based on the data from the different
    sensors. Supervised learning problems can be further grouped into classification,
    regression, time series, and ensemble method problems. a: Classification The task
    of classification algorithms is to classify an instance into a specific discrete
    set of possible categories. Given two sets of data (labeled and unlabeled datasets),
    the labeled dataset is used for the training process, while the unlabeled dataset
    will be used to evaluate of the classification results. The normal process is
    to count the number of instances that are assigned to the right category, which
    is also known as the accuracy rate (AR) defined by [21]. The classification algorithm
    can mathematically be described as follows: AR= N c N t (1) View Source where
    N c denotes the number of test instances that are correctly assigned to their
    categories to which they belong; N t the number of test instances. The precision
    ( P ) and recall ( R ) are used to measure the details of the classification results.
    The four possible outcomes are true positive ( TP ), false negative ( FN ), false
    positive ( FP ), and true negative ( TN ), the precision ( P ) and recall ( R
    ) are generally defined as: P= TP TP+FP (2) View Source Given P and R , a simple
    method to describe the precision and recall of the overall classification results,
    called F-score or F-measure, is defined as: F= 2PR P+R (3) View Source Commonly
    used classification techniques include decision trees, SVM, rule-based induction,
    neural networks, deep learning, memory-based reasoning, and Bayesian networks
    [89]. b: Decision Tree Algorithms The decision tree method is an important predictive
    ML modeling approach, which constructs a model of decisions presented based on
    the actual values of features in the data. Decision trees can be utilized for
    both classification and regression problems. In tree structures, leaves represent
    class labels and branches represent conjunctions of attributes that drive to those
    labels [90]. The decision trees that the target variable takes continuous values
    called regression trees. Decision trees are often one of the favorites of ML algorithms
    because of its speed and accuracy. The most common algorithms for decision tree
    are [91]: classification and regression tree, ID3, C4.5 and C5.0, Chi-squared,
    M5, and conditional decision trees. Application in SBs: Delgado et al. [92] propose
    an ML technique based on decision trees to extract the most frequent activities
    of human behavior and the temporal relationship of those activities in order to
    produce the human behavior quickly in a smart environment. Viswanathan et al.
    [93] introduce a prototype distributed data mining system for healthcare environment
    using C4.5 classification algorithm that can provide the patient monitoring and
    health services. Decision trees algorithm is a non-parametric algorithm that is
    easy to interpret and explain. The main disadvantage of this algorithm is that
    it can easily overfit. c: Bayesian Algorithms Bayesian methods utilize Bayes’
    theorem for classification and regression problems. The most common Bayesian algorithms
    are [94]: Naive Bayes, Gaussian naive Bayes, Bayesian belief network, Bayesian
    network. Application in SBs: Parnandi et al. [95] propose an indoor localization
    approach based on Naive Bayes classification and dynamic time warping, they exploit
    the embedded sensors of smartphones to determine the building that the user entered
    and the activities that the user is performing inside the building. Verbert et
    al. [96] proposed an ML approach based on Bayesian network to diagnosis the fault
    in HVAC systems. The model has been constructed based expert knowledge concerning
    conservation laws, component interdependencies, and historical data using virtual
    sensors. Naive Bayes classifier approaches have been applied with potential results
    for human activity recognition in [97], [98]. Naive Bayes approach recognizes
    human activities that identify with the highest probability to the set of sensor
    readings that were observed. d: Support Vector Machine (SVM) is a supervised ML
    algorithm which can be applied for both classification and regression problems
    though mostly used in classification challenges [140]. SVM is one of the most
    popularly utilized for many statistical learning problems, such as face and object
    recognition, text classification, spam detections, handwriting analysis etc. [141].
    is maximizing the margin that separating between the hyperplane of two classes’
    closest points. Support vectors are the points lying on the boundaries, and the
    optimal separating hyperplane is the middle of the margin [142]. Application in
    SBs: Fu et al. [105] proposed an SVM method to predict the system level electricity
    loads of public buildings that have electricity sub-metering systems. A real-time
    human tracker system proposed Nguyen et al. [106] using SVM for predicting and
    recognizing human motion based on the input images from a network of four cameras
    in the ubiquitous smart homes. Petersen et al. [107] developed an SVM model to
    predict the times where visitors are present in the home using only the data provided
    by wireless motion sensors in each room. Fleury et al. [88] presented a study
    for automatic recognition of daily living activities in a smart home based on
    SVM. They collected the data from various sensors such as Infra-Red Presence Sensors,
    door contacts, temperature and hygrometry sensor, and microphones. Das et al.
    [108] proposed a one-class classification approach for a real-time activity error
    detection in smart homes using one-class SVM. Zhao et al. [143] proposed an ML
    approach based on SVM and RNN to detect the occupancy behavior of a building through
    the temperature and heating source information for the energy efficiency consumption
    purposes. e: Artificial Neural Network Algorithms (ANNs) ANN models are inspired
    by the process of biological neural networks. ANN models are commonly utilized
    for regression and classification problems. The common ANN algorithms are [94]:
    Perceptron, Back-Propagation, Hopfield Network, and Radial Basis Function Network
    (RBFN). ANNs provide a number of advantages including it requires less statistical
    training, it has the capacity to detect complex nonlinear relationships between
    the predictor and response variables, as well as the ability to detect all possible
    relationships between predictor variables [104]. On the other hand, disadvantages
    include its “black box” nature, heavy computational burden and proneness to overfitting.
    However, due to the inherent features of neural networks, it has the following
    main limitations: challenge in training with no local optima, its accommodation
    to modifications in the behavior, the validation process of the results, and the
    complexity of network performance interpretation. Application in SBs: Badlani
    and Bhanot [99] developed a smart home system for energy efficiency applying pattern
    recognition based on ANNs, the system incorporates an RNN to capture human behavior
    patterns and an ANN for security applications in smart homes. Other researchers
    have applied ANNs to present context-aware services. Campo et al. [100] developed
    a system that calculates the probability of occupation for each section of the
    building and compares the probability with the current situation systematically.
    See [101] for a survey paper focusing on the role of ANNs for smart home services.
    Ermes et al. [102] proposed a hybrid classifier approach using a tree structure
    comprising a priori knowledge and ANN to recognize the activities such as rowing,
    biking, playing football, walking, running, sitting, or hiking. Ciabattoni et
    al. [103] proposed a home energy management system design using the neural network
    algorithm to predict the power production of the photovoltaic plant and the home
    consumptions during the given time. f: Deep Learning Algorithms: Deep learning
    methods represent an evolved form of ANNs in which a deep architecture (many layers
    comprising multiple linear and non-linear transformations [144]) is used. One
    of the promises of DL is replacing the manually selected features with efficient
    unsupervised or semi-supervised feature learning and hierarchical feature extraction
    algorithms. The most common DL algorithms are [145]: Convolutional Neural Network
    (CNN), Recurrent Neural Network (RNN), Deep Boltzmann Machine (DBM), Deep Belief
    Network (DBN), and Stacked Auto-Encoders. Deep learning has been used successfully
    in varieties of big data analytics applications, particularly natural language
    processing (NLP) applications, medical diagnosis, stock market trading, network
    security, and image identification. Deep learning is now ubiquitously used in
    major businesses and companies. Microsoft research on a deep learning system presented
    real-time speech translation system between Mandarin Chinese and English languages
    [146]. Apple’s Siri uses a deep learning trained model, and the voice recognition
    in the Google Android phone also uses a deep learning trained model [147]. DL
    utilizes a number of techniques such as drop-out and convolutions that enables
    the models to learn efficiently from high-dimensional data. However, DL requires
    much more data to train compared to other algorithms because of the magnitudes
    of parameters for estimation required by the models. Application in SBs: Choi
    et al. [114] propose two prediction algorithms deep belief network and restricted
    Boltzmann machines based on the DL framework for predicting different human activities
    in a building. They also presented a hybrid model which combines for predicting
    human behavior. The paper [115] proposes a generic deep learning framework based
    on convolutional and RNNs for human activity recognition that is suitable for
    multimodal wearable sensors, such as accelerometers, gyroscopes or magnetic field
    sensors. Alsheikh et al. [116] proposed a hybrid approach of DL and hidden Markov
    model for human activity recognition using triaxial accelerometers. Baccouche
    et al. [117] propose a two-steps neural-based deep model to classify human activities,
    the first step of the model is automatically learned spatiotemporal features based
    on Convolutional Neural Networks. Then the second step of the model uses an RNN
    to classify the entire sequence of the learned features for each time-step. In
    [118], they propose an acceleration-based human activity recognition method using
    Convolution Neural Network. In [119] a deep convolutional neural network as the
    automatic feature extractor and classifier for recognizing human activities is
    proposed using the accelerometer and gyroscope on a smartphone. Hammerla et al.
    [148] explore the performance of deep, convolutional, and recurrent approaches
    of deep learning for human activity recognition using wearable sensors. For the
    sake of measuring the performance, the authors used three representative datasets
    that comprise motion data collected from wearable sensors. g: Hidden Markov Models
    (Hmm) An HMM is a doubly stochastic process with a hidden underlying stochastic
    process that can be observed through the sequence of observed symbols emitted
    by another stochastic process. Application in SBs: Wu et al. [113] proposed an
    improved HMM to predict user behaviors in order to provide services for people
    with disabilities. They developed a temporal state transition matrix to be utilized
    instead of the fixed state transition matrix. Lv and Nevatia [112] used hidden
    Markov models for both automatic recognition and segmentation of 3-D human activities
    to allow real-time evaluation and feedback for physical rehabilitation. Cheng
    et al. [110] proposed an inference engine based on the HMM that provides a comprehensive
    activity of daily living recognition capability. They integrated both Viterbi
    and Baum-Welch algorithms to enhance the accuracy and learning capability. Chahuara
    et al. [111] proposed sequence-based models for online recognition of daily living
    activities in an SB environment. They presented three of sequence-based models:
    HMM, conditional random fields, and a sequential Markov logic network. h: Time
    Series Analysis A time series is a collection of temporal instances; time series
    data set usually have the following characteristics include the high dimensionality,
    large number of instances, and updating continuously [149]. One of the important
    purposes for time series representation is to reduce the dimension, and it divides
    into three categories: model-based representation, non-data-adaptive representation,
    and data-adaptive representation [150], [151]. Application in SBs: Survadevara
    et al. [125] proposed a wellness model using seasonal autoregression integration
    moving average time series with sleeping activity scenario in a smart home environment
    to forecast the elderly sleeping tendency. Zhou et al. [126] proposed a time series
    analysis framework to explore relationships among non-stationary time series in
    the case of data sensors in SBs. Jakkula and Cook [127] propose a time series
    based framework to determine temporal rules from observed physical and instrumental
    activities of occupants in a smart home. i: Regression The aim in regression problems
    is to estimate a real-valued target function. It is related to representing the
    relationship between variables that are repeatedly processed utilizing a measure
    of error in the predictions made by the model [152]. The most common regression
    algorithms are [153]: linear regression, logistic regression, stepwise regression,
    and ordinary least squares regression. Application in SBs: Chen et al. [120] used
    the regression technique of orthogonal matching pursuit algorithm to identify
    the physical and environmental parameters that providing the energy efficiency
    in an SB. Bouchard et al. [121] presented a gesture recognition system using linear
    regression combined with the correlation coefficient to recognize the gesture
    direction and estimate the segmentation of continuing gestures of daily usage
    activities in a smart environment. j: Ensemble Methods A combination of multiple
    classifiers often referred to as a classifier ensemble, group of classification
    models that are trained separately and the predictions of those models are then
    combined in a way to produce the overall prediction [154]. The most popular ensemble
    learning based classification techniques are [155]: random forest, boosting, gradient
    boosting machines, AdaBoost, bagging, and blending. Application in SBs: Jurek
    et al. [122] proposed a cluster-based ensemble approach solution for activity
    recognition within the application domain of smart homes. With this approach,
    activities are modeled as cluster collections built on different subsets of features.
    Fatima et al. [123] proposed an ensemble classifier method for activity recognition
    in smart homes using genetic algorithm optimization to merge the prediction output
    of multiple classifiers that make up the ensemble. They used the ANN, HMM, conditional
    random field, and SVM [13] as base classifiers for activity recognition. Guan
    and Ploetz [124] proposed a deep LSTM ensemble method for activity recognition
    using wearables: more specifically, the authors developed modified training procedures
    for LSTM networks and proposed the combination of sets of diverse LSTM learners
    into classifier collectives. 2) Unsupervised Learning Unsupervised Learning refers
    to developing algorithms that use data with no labels to analyze the behavior
    or the system being investigated [156]. Thus, the algorithm does not know about
    the truth of the outcome. In other words, the unsupervised learning algorithm
    classifies the sample sets to different clusters by investigating the similarity
    between the input samples. Clustering is done using different parameters taken
    from the data which enable us to identify correlations which are not so obvious.
    The inferring structures existing within the input data is used to prepare the
    model to prepare and extract general rules of the model. A mathematical process
    might be used to systematically reduce redundancy, or organize data by similarity
    [129]. The unsupervised approach has been applied to recognize various activities
    in smart buildings when it is challenging to have labels for input data [130].
    Common unsupervised learning problems are clustering, dimensionality reduction,
    and association rule learning. There are a variety of commonly used unsupervised
    learning algorithms, some of those algorithms are based on supervised-learning
    algorithms: the Apriori algorithm and k-Means. In unsupervised learning, usually
    there is no a measure for the output; we recognize only the features and the target
    is to define the patterns and relationships among a set of input measures [80].
    The major disadvantage of unsupervised learning is the absence of direction for
    the learning algorithm, hence, there might not be any useful detected knowledge
    in the selected set of attributes for the training. Clustering is a method of
    unsupervised learning that involves detecting patterns in the data by placing
    each data element into a group of K-clusters, where each group holds data elements
    most similar to each other [157]. Unsupervised learning problems can be categorized
    into clustering and association problems, which are described next. a: Clustering
    A clustering problem explores the internal groupings in the input data, such as
    grouping customers by their purchasing habits. Clustering techniques are usually
    organized by modeling strategies such as centroid-based and hierarchical. All
    methods are concerned with handling the internal structures in the input data
    to properly organize the data into groups of maximum commonality [158]. The quality
    of the clustering result is evaluated depends on the type of application that
    utilizes a clustering algorithm. For example, the sum of squared errors is generally
    utilized for data clustering while the peak-signal-to-noise ratio is used for
    image clustering [21]. The most common clustering algorithms are [153]: k-Means,
    k-Medians, expectation maximization, and hierarchical clustering. Application
    in SBs: Fahad et al. [128] propose an activity recognition approach that combines
    the classification with the clustering, in their approach the activity instances
    are clustered using Lloyd’s clustering algorithm. Then, they apply evidence theoretic
    K-Nearest neighbors learning method that combines KNN with the Dampster Shafer
    theory of evidence. The paper [86] proposes a hybrid approach to recognize and
    predict user activities in a smart environment. They use the K-pattern clustering
    algorithm to classify so varied and complex user activities, and ANN to recognize
    and predict users’ activities inside their personal rooms. Lapalu et al. [82]
    used an unsupervised learning approach to address the issues of daily living activities’
    learning in smart home. They utilize the Flocking algorithm for clustering analysis
    of a use case in cognitive assistance service that assists the people suffering
    from some type of dementia such as Alzheimer’s disease. Aicha et al. [83] present
    an unsupervised learning approach for detecting abnormal visits of an elderly
    in a smart home environment based on a Markov modulated Poisson process model.
    The model combines multiple data streams, such as in the front-door sensor transitions
    and the general sensor transitions. The other cases of social communication services,
    Rashidi and Cook [129] applied an unsupervised learning approach to detect social
    interaction and monitor activity daily living in a smart space, their approach
    can adapt and update automatically to reflect the changes in discovered patterns
    from implicit and explicit identified feedbacks of the occupant. Rashidi et al.
    [130] introduce an unsupervised method that identifies and tracks the normal activities
    that commonly occur in an individual’s routine in a smart environment. The activity
    discovery method of the system is produced to cluster the sequences based on the
    simple k-means algorithm. Fiorini et al. [159] proposed an unsupervised ML approach
    to identify the behavioral patterns of the occupants using unannotated data collected
    from low-level sensors in an SB. Their approach involves processing and analyzing
    collected data related to the daily living activities of 17 older adults living
    in a community-based home supplied with a variety of sensors. They extract activity
    information from collected data at different times of the day. b: Association
    The association rule learning problem is utilized to identify the rules that define
    large portions of input data, such as people that buy X item also tend to buy
    Y item. Association analysis is performed on rules discovered by analyzing input
    data for frequent if/then statement and using the criteria of support and confidence
    to discover relationships between unrelated data in a relational database or another
    information repository. Here “support” indicates how frequently the items appear
    in the database while “confidence” indicates the number of times the if/then statements
    have been found to be true. Many algorithms for generating association rules have
    been proposed. Apriori algorithm is the most well-known association algorithm
    [160]. Application in SBs: Aztiria et al. [161] proposed system that learns the
    frequent patterns of human behavior using association, workflow mining, clustering,
    and classification techniques. The core part of the system is the learning layer
    which is made up of two modules: the language module, which provides a standard
    conceptualization of the patterns; and the algorithm module, which discovers the
    patterns. Kang et al. [162] proposed a service scenario generation scheme for
    interpreting association rules extracted from the states of all devices in SB
    environments. Typically, These states are collected periodically at a specific
    time interval from the devices. Nazerfard et al. [163] propose a framework to
    discover the temporal features of the activities, including the temporal sequencing
    of activities and their start time and duration using the temporal association
    rule techniques in a smart home. 3) Semi-Supervised Learning Semi-Supervised learning
    lies between supervised and unsupervised methods. Input data is a composite of
    labeled and unlabeled samples. These hybrid algorithms aim to inherit the strengths
    of the main categories while mitigating their weaknesses. The model learns the
    patterns present in the data and also make predictions. Example problems are classification
    and regression [164]. There are some common semi-supervised learning models, including
    generative models, heuristic approaches, semi-supervised SVM, graph-based methods,
    self-training, help-training, mixture models, co-training and multi-view learning
    [94]. Application in SBs: Cook [131] combined fully-supervised and semi-supervised
    learning to recognize and follow activities that support health monitoring and
    assistance context-aware services for people experiencing difficulties living
    individually at smart homes. Liu et al. [132] proposed a vision based semi-supervised
    learning approach for fall detection and recognizing other activity daily living
    in smart environments to overcome the labeling challenges of human activities
    by systematic interpreting the activities with the highest confidence. Fahmi et
    al. [133] proposed a semi-supervised fall detection approach in which a supervised
    algorithm utilizing decision trees in the training process and then profiles are
    used to implement a semi-supervised algorithm based on multiple thresholds. Radu
    et al. [134] present semi-supervised ML method using only the low power sensors
    on a smartphone to consider the problem of determining whether a user is indoors
    or outdoors. Guan et al. [135] propose a semi-supervised learning algorithm for
    activity recognition named En-Co-training to make use of the available unlabeled
    samples to enhance the performance of activity learning with a limited number
    of labeled samples. The proposed algorithm extends the co-training paradigm by
    using an ensemble method. 4) Reinforcement Learning Reinforcement learning is
    a learning approach to control a system in order to maximize performance measure
    that represents a long-term objective [165]. Reinforcement learning, an area of
    ML inspired by behaviorist psychology, is concerned with the way that software
    agents have to take actions in an environment in order to maximize the concept
    of cumulative reward. RL algorithms learn control policies, particularly when
    there is no a priori knowledge and there is a massive amount of training data.
    However, RL algorithms suffer from some drawback such as the high computational
    cost required to find the optimal solution, such that all states need to be visited
    to choose the optimal one. The well-known approaches of RL are Brute force, Monte
    Carlo methods, Temporal difference methods, and Value function [166]. Q-learning
    [167] is a model-free reinforcement learning approach based on learning the required
    utility given a state decision. Application in SBs: Mozer [136] applied Q-learning
    for lighting regulation to predict the time of turning the lights ON/OFF in a
    building. This prediction model can be utilized to schedule the lights’ activations
    in a building for efficient energy consumption proposes. Li and Jayaweera [137]
    proposed a Q-learning based approximate dynamic programming algorithm to provide
    a more efficient, flexible and adaptive method. This approach can enable customers
    to make an optimal on-line decision making in SB environment to maximize the profits
    based on both local fully observable and the estimated hidden information of the
    building. Khalili and Aghajan [138] proposed a temporal differential class of
    RL method for autonomous learning of a user’s preference of music and lighting
    service settings in presence of different states of the user in SB environment.
    The preferences are learned by the model by using the explicit or implicit feedback
    from users when they react to the provided service. Xu et al. [139] give a survey
    of developments in RL algorithms with function approximation. They evaluated and
    compared different RL algorithms using several benchmark learning, prediction,
    and learning control tasks. B. ML Tasks for SBS In this section, we will describe
    the major ML tasks that are relevant to SB. The reader is referred to Figure 8
    for a general depiction of ML tasks in SBs and the steps taken to implement ML
    in an SB environment. FIGURE 8. ML tasks in SB environment. Show All 1) Data Collection
    and Acquisition A variety of data collection approaches are used, each of which
    has different deals in terms of capabilities, energy efficiency, and connectivity.
    Sensors and similar objects in SBs produce raw data simultaneously in an automated
    way and such devices may store the data for a specific period of time or report
    it to controlled components [168]. Data can be collected at gateways; the collected
    data is then filtered and processed, fused into compact forms for efficient transmission.
    A variety of communication technologies such as Zigbee, Wi-Fi, and cellular are
    utilized to transfer data to collection points. Data collected from a global-scale
    deployment of smart things defines the basis for decision making and providing
    services. It is possible that the decisions are unreliable when the quality of
    utilized data is poor [169]. Zhao et al. [170] propose a data acquisition and
    transmission system which could be used for monitoring systems to collect energy
    consumption data (e.g., electricity, water, gas, heating, etc.) from terminal
    meters which are installed in buildings. The system stores the data periodically
    after analyzing and processing it and finally transmits the data to servers through
    the Ethernet. Rowley et al. [171] propose the data acquisition and modeling approaches
    that can support the delivery of building energy infrastructure in both new building
    and renovated real-world contexts. Such methods provide a means to achieve short,
    medium and long-term forecasting of possible scenario pathways to multi-objective
    sustainable outcomes. CLEEN MMEA [172] platform that collects, processes, and
    manages the data and initiates contextual knowledge extraction. The purpose is
    to establish an online marketplace to collect data and provide services for different
    companies. The interfaces are made public so that any company can easily join
    the network to buy or sell services. The analysis results can be given to an energy
    services company in order to allow offering the service to the owners. A typical
    example of open access data collection system is e3Portal [173] developed by VTT
    in collaboration with Finnish municipalities. e3Portal offers information and
    tools when planning savings measures and energy retrofitting in municipal buildings.
    It also involves frequently updated data regarding energy and water consumption
    in thousands of public buildings like schools, kindergartens, offices, hospitals,
    other health care facilities, etc. Decision makers, designers, operation and maintenance
    personnel, as well as buildings users, can utilize it. There are projects that
    provide publicly available SB datasets for researchers to conduct further studies;
    A list of “Home Datasets” [174] includes the datasets collected by projects from
    UC Berkeley, MIT, Washington State University, University of Amsterdam, University
    of Edinburgh, and the University of Tokyo. The WARD [175] project supported by
    NSF TRUST Center at UC Berkeley provides a benchmark dataset for human action
    recognition using a wearable motion sensor network. The dataset was collected
    from 13 repetitive actions by 13 male and 7 female participants between the ages
    of 19 and 75. An MIT project [176] collected daily live activities dataset from
    two single-person apartments within a period of two weeks. Eighty-four sensors
    to record opening-closing events were attached to different appliances and devices
    such as drawers, refrigerators, containers, etc. Banos et al. [177] introduced
    an open benchmark dataset collected from various inertial sensors attached to
    different parts of the body. They considered 33 fitness activities, recorded using
    9 inertial sensor units from 17 participants. The CASAS project [178] at Washington
    State University provides a publicly-available dataset for a three-bedroom apartment
    with one bathroom, a kitchen, and a living room. Different types of motion and
    digital sensors are installed to support temperature readings, in addition, the
    analog sensors are installed to support readings for hot water, cold water, and
    stove burner use [179]. The PlaceLab project [180] of MIT provides a dataset collected
    from a one-bedroom apartment with more than 900 sensors, including those coming
    from motion, switch and RFID sensors. That is being used to monitor activity in
    the environment in the context of a smart home [181]. A collection of smart meters
    data from five houses in the UK [182] That consists of 400 million instances.
    The active power is formed by different appliances and the whole-house power demand
    every 6 seconds. The major challenges that arise for data collection are scalability,
    privacy, security, and heterogeneity of resources [183]. Automated sensor data
    collection process collects a large amount of data that overwhelms the collection
    and analysis centers in comparison to the data collected from other sources such
    as IoT devices and social media. This leads to a huge number of small synchronous
    write operations to the database storage system, consequently, resulting in serious
    performance bottlenecks to the storage system design [184]. Because of the extensive
    use of RFID technology, privacy issues arise in data collection; for example,
    the RFID tags carried by a person may become a unique identifier for that person.
    Also, other security concerns appear, for example, the radio signals of RFID technology
    are easily jammed. Hence, that can disrupt the data collection process [185].
    The heterogeneity of data that is being collected from different resources is
    another major challenge, such that the data are usually very noisy, large-scale,
    and distributed. This makes it very difficult to use the collected data effectively
    without a clear description of existing data processing techniques [184]. 2) Data
    Preprocessing A large amount of data are generated by sensors in SBs; this data
    comes from various sources with diverse formats and structures. Usually, this
    data is not ready for analysis as it might be incomplete or redundant due to low
    battery power, poor calibration, exposure to various malicious elements and interference.
    Therefore, raw data typically needs to be preprocessed to deal with missing data,
    discard noisy and redundant data and integrate data from various sources into
    an integrated schema before being committed to storage. This preprocessing is
    called data cleaning. The quality of data can be improved substantially by applying
    some cleaning techniques to the data before it arrives its end user [168], [186].
    Data cleaning is one of the significant tasks in the data processing phase. Data
    cleaning is not a new process particular for the IoT data processing. It has already
    been applied as a process for database management systems. Presenting a data cleaning
    method would further aid the applications to focus on their core logic without
    worrying about data reliability post-processing overheads [184]. There are many
    different techniques that have been utilized to deal with the problem of cleaning
    noisy data streams such as Kalman filters [187], statistical models [186] and
    outlier detection models [184]. One of the major challenges with data cleaning
    techniques in the SBs is the heterogeneity of data collected from different sources
    particularly WSN- and RFID-enabled data streams. The utilized data cleaning techniques
    should be able to deal with several different variables of interest to satisfy
    IoT applications’ requirements, for example, setting home temperature based on
    observed outer temperature, user habits, energy management, etc. [169] Any type
    of failures such as a failed sensor, network issues, camera failure, or database
    crashes in the process of collecting data would invalidate the data. Consequently,
    this type of impediment will dramatically increase the time required to collect
    data [179]. 3) Dimensionality Reduction There are huge volumes of raw data that
    are captured from heterogeneous and ubiquitous of sensors used in SBs. Most of
    the data collected from those sensors are redundant and they need to be brought
    down to a smaller number of features by applying dimensionality reduction techniques
    without losing significant information [188]. The main idea from the dimensionality
    reduction strategy is to find a new coordinate system in which the input data
    can be represented with much fewer features without losing significant information.
    The dimensionality reduction can be made in two different ways: by extracting
    of the features that represent the significant data characteristics (this technique
    is called feature extraction), or by only selecting the most relevant features
    from the original dataset, this method is called feature selection [189], [190].
    Like clustering methods, the dimensionality reduction approach explores and exploits
    the internal structure of the data, but in this case in an unsupervised manner
    using less information. Most of these techniques can be utilized in classification
    and regression problems. Examples of some salient algorithms are [153]: Principal
    Component Analysis (PCA), Principal Component Regression (PCR), and Linear Discriminant
    Analysis (LDA). Chen et al. [191] propose a framework using the classification
    information of local geometry of data to reduce the dimensionality of a dataset
    on human activity recognition from wearable, object, and ambient sensors. a: Feature
    Extraction The main components of the original data are the features. After extracting
    the features from the raw dataset, such features contain important information
    that is used by the learning algorithms for the activities discrimination. The
    most common methods of feature extraction work in time, frequency, and discrete
    domains [192]. Among time domain method, mean and standard deviation are the key
    approaches for almost all sensor types. While the frequency domain method focuses
    on the periodic structure of the collected data. Wavelet Transformation and Fourier
    Transform are the most common approaches. And discrete domain methods such as
    Euclidean-based distances, dynamic time warping, and Levenshtein edit distance
    are key approaches implemented in several applications such to string similarity,
    classifying human activities and modeling human behavioral patterns [16], [193].
    b: Feature Selection The main role of feature selection is to discriminate the
    most related subset of features within a high dimensional vector of features,
    so that reduces the load of noise and computational expense on the learning models.
    In order to map the high dimensional vector of features into a lower dimensional
    vector, there are several common algorithms used such as Linear Discriminant Analysis
    (LDA), Principal Component Analysis (PCA), and Independent Component Analysis
    (ICA) [194]. Hausmann and Ziekow [195] proposed an approach for automatically
    adapting the feature selection for SBs application ML models from the time-series
    data based on wrapper methods and genetic optimization. Fahad et al. [196] propose
    an activity recognition approach for overlapping activities using K-Nearest neighbors
    approach that distinguishes the most important features from the collected information
    obtained from deployed sensors in multiple locations and objects. Fang et al.
    [197] determine that the different feature sets generate different levels of accuracy
    for recognizing human activities, and selecting inappropriate datasets increases
    the level of computational complexity and decreases the level of prediction accuracy
    in smart home environments. The wrapper and filtering are the two main statistical
    methods of feature selection problem. It is argued that although the wrapper approach
    may obtain better performances, filters are less resource intensive and faster
    [198]. In [199], different feature selection methods are utilized for the process
    of dimensionality reduction of the learning problem to recognize the human activities
    from observed sensors. The authors show that the performance of the learning models
    to recognize the human activity has a strong relationship with the utilized features.
    c: Feature Projection feature projection can be represented as a mapping from
    the original set of features to an appropriate set that optimizes the learning
    criterion, such that the feature projection approach allows the process of visualizing
    and mapping the high-dimensional feature vectors to low dimensional one, in addition,
    it enables analyzing the distribution of the reduced feature vectors [200]. Consequently,
    the feature projection approach reduces the pattern recognition’s processing time
    and enables selecting the best-performed classifier for the reduced feature vectors.
    Hence, it makes real-time implementation possible [198]. Chu et al. [201] proposed
    a linear supervised feature projection that utilizes the LDA algorithm for EMG
    pattern recognition that attempted to recognize nine kinds of hand motion. C.
    ML Tools & Platforms for SBs There are a variety of existing ML platforms and
    tools to support the learning process. With the current increasing number of those
    kinds of toolkits, the task of selecting the right tool for processing big data
    streaming from various sources can still be difficult. Typically, there is no
    single toolkit that truly fits and provides solutions for all different problems.
    Many of the available toolkits might have overlapping uses, and each has advantages
    and disadvantages. Most of those toolkits might require experiences in the domains
    of programming languages and system architecture. In addition, usually many people
    lack a full understanding of the capabilities and how to use those available platforms
    [202]. The important factors that must be considered when selecting a specific
    ML tool are scalability, speed, coverage, usability, extensibility, and programming
    languages support. With respect to the scalability factor, the size and complexity
    of the data should be considered to determine if a specific toolkit will be fit.
    The processing platform that the library is running on and the complexity of the
    algorithm affect the speed factor. Not all the projects prioritize the speed factor;
    if the models require frequent updates, the speed may be a crucial concern; but
    not otherwise. Coverage represents the number of ML algorithms implemented in
    the tool. With the massive amount of data capturing from heterogeneous sources,
    ML community faces the challenges of how the ML model can efficiently process
    and learn from the big data. In general, the available big data tools do not implement
    all varieties of different classes of ML algorithms, and typically their coverage
    ranges from a few algorithms to around two dozen. The usability factor includes
    elements such as initial setup processing; continuous maintenance; the available
    programming languages and user interface available; the amount of documentation,
    or availability of a knowledgeable user. The extensibility factor means that the
    implementations introduced in the tools can be utilized as building blocks towards
    new systems. It is necessary to evaluate tools in terms of how well they are able
    to meet this factor. There are a variety of ML libraries that are available in
    different programming languages. Depending on the task you are trying to accomplish,
    certain languages, libraries, and tools can be more effective than others. The
    following provides a detailed observation of the strengths and weaknesses of the
    top used deep learning and ML tools. The reader is also referred to Table 6 for
    a concise tabulated summary of the described deep learning and ML tools. TABLE
    6 Comparison Between Deep Learning and ML Tools 1) H2O H20 [203] is an open-source
    in-memory, distributed, and scalable ML framework for big-data analysis that supports
    ML libraries, along with tools for parallel processing, analytics, data preprocessing
    and evaluation tools. It is produced by the H2O.ai, which launched in 2011 in
    Silicon Valley. The most notable feature of this product is that it provides numerous
    tools for deep neural networks. The H2O software APIs can be called from Python,
    Java, R, and Scala. Users without programming expertise can still utilize this
    tool via the web-based User Interface. In addition to the processing engine provided
    by H2O framework, it also allows the users to integrate their models with other
    available frameworks such as Spark and Storm. Depending on what is suitable for
    the algorithm, The H2O’s engine uses multiple execution methods to process data
    completely in memory. The general technique used is distributed Fork/Join, which
    is reliable and suitable for massively parallel tasks. The H2O software can be
    run on different operating systems such as Microsoft Windows, Mac OS X, and Linux
    (e.g. Ubuntu 12.04; CentOS), It also runs on Apache Hadoop Distributed File System
    (HDFS) and Spark systems for big-data analysis. In addition, it can operate on
    various cloud computing environments such as Amazon EC2, Google Compute Engine,
    and Microsoft Azure. As of July 2016, the algorithms supported in H2O cover the
    tasks classification, clustering, generalized linear models, statistical analysis,
    ensembles, optimization tools, data preprocessing options and deep neural networks.
    2) MLlib (Spark) MLlib [204] is Apache Spark’s ML library. MLlib aims to provide
    scalable and easy to use ML methods. It includes common ML algorithms for classification,
    regression, clustering, dimensionality reduction, as well as lower-level optimization
    primitives and higher-level pipeline APIs. The classification techniques of SVM,
    random forest, logistic regression, Naïve Bayes, decision trees, and gradient-boosted
    trees are supported whereas for clustering, k-means, Gaussian mixture, and power
    iteration clustering are supported. MLLib supports implementations for linear
    regression and isotonic regression, and incorporates a collaborative filtering
    algorithm using alternating least squares. PCA is supported for dimensionality
    reduction. MLlib includes APIs for development in Scala, Java, Python, and SparkR.
    Generally, MLlib depends on Spark’s iterative batch and streaming approaches,
    as well as its use of in-memory computation. 3) Tensorflow Tensorflow [205] is
    an open source software library for numerical computation and deep ML in a variety
    of perceptual and language understanding tasks utilizing data flow graphs. TensorFlow
    was originally developed by the Google Brain team and was released in November
    2015 under an Apache 2.0 open source license. TensorFlow has tools that support
    deep learning, reinforcement learning, and other algorithms. TensorFlow implements
    data flow graphs, where “tensors” are batches of data that can be processed by
    a set of algorithms defined by a graph. The movements of the data through the
    system are called “flows”—hence, the name. TensorFlow can run on multiple CPUs
    and GPUs. It can run on Linux, Mac OS X desktop, and server systems, and Windows
    support on roadmap, as well as on Android and Apple’s iOS mobile computing platforms.
    TensorFlow is written with a Python API over a C/C++ engine that makes it run
    fast. TensorFlow utilizes a symbolic graph of vector operations method, in order
    to easily define a new network. However, TensorFlow has a weakness that is related
    to modeling flexibility. Such that each computational flow has to be constructed
    as a static graph. That makes some computations such as beam search difficult.
    4) Torch Torch [206] is an open source ML computing framework that supports a
    variety of ML algorithms. Torch was originally developed at NYU. It is efficient
    and easy to use, thanks to a script language based on the Lua programming language
    and a C/CUDA implementation, Torch was intended to be portable, fast, extensible,
    and easy to use in development. Some version of Torch is employed by large companies
    such as Google DeepMind, the Facebook AI Research Group, IBM, Yandex, and the
    Idiap Research Institute. In addition, it has been extended to run on Android
    and iOS platforms. A variety of community-contributed packages for Torch, giving
    it a versatile range of support and functionality. It provides various deep learning
    algorithms that support computer vision; signal, image, video, and audio processing;
    parallel processing and networking [207]. 5) Deeplearning4j Deeplearning4j [221]
    is an open source distributed DL library, primarily developed by Adam Gibson from
    an ML group in San Francisco. Deeplearning4j is written for Java and JVM as well
    as to support a variety of DL algorithms such as restricted Boltzmann machine,
    deep belief networks, convolutional networks, recurrent neural networks, deep
    autoencoder, stacked denoising autoencoder, and recursive neural tensor network.
    All these algorithms can be integrated with Hadoop and Spark for distributed parallel
    processing. Deeplearning4j relies on Java programming language, in addition, it
    is compatible with Clojure and includes a Scala API. Deeplearning4j is designed
    to be utilized in business environments, rather than as a research tool. It is
    applied in a variety of applications such as fraud detection, anomaly detection,
    recommender systems, and image recognition. 6) Massive Online Analysis (Moa) MOA
    [222] is one of the common open source frameworks for data stream mining and possessing.
    MOA is written in Java related to the WEKA project that developed at the University
    of Waikato, New Zealand. It includes a set of learners and stream generators that
    can be used from the GUI, the command-line, and the Java API. MOA supports a variety
    of ML algorithms for classification, regression, clustering, outlier detection,
    as well as some tools for evaluation [223]. 7) Caffe Caffe [224] is a DL framework,
    it is primarily developed with the consideration of expression, speed, and modularity.
    It utilizes the machine-vision library for fast convolutional networks from Matlab,
    which has been ported to C and C++. It is developed by the Berkeley vision and
    learning center and by the community contributors. In Caffe, multimedia scientists
    and practitioners have an organized and state-of-the-art toolkit for DL algorithms.
    Caffe was originally developed for machine-vision, it has been utilized and improved
    by users in other fields such as robotics, neuroscience, speech recognition, and
    astronomy. In addition, it supports Python and MATLAB code bindings. Caffe offers
    image classification with state of the art CNN algorithm. Caffe is mainly utilized
    as a source of pre-trained models hosted on its Model Zoo site. Caffe is useful
    for performing image analysis using CNNs and regional analysis within images using
    RCNNs. The performance and processing speed of Cafee make it as one of the most
    utilized platforms for research experiments and industry deployment. It has the
    capability to process over 60 million images per day with a single NVIDIA K40
    GPU. Caffe has already been applied in many research projects at UC Berkeley and
    other universities, performing very well in many tasks such as object classification,
    object detection, and Learning Semantic Features. It provides a complete and well-documented
    toolkit for training, testing, tuning, and deploying models. Caffe utilizes a
    large repository of pre-trained neural network models called the Model Zoo, which
    is suitable for a variety of common image classification tasks [225]. 8) Azure
    Ml Microsoft first launched Azure ML [226] as a preview in June 2014. Azure ML
    enables users to create and train models, then convert those models into APIs
    that can be applied to other services. Users can get up to 10GB of storage per
    account for model data, although they can also connect their own Azure storage
    to the service for larger models. programmers can use either the R or Python programming
    language for developing with Azure services. Users can purchase ML algorithms
    from Microsoft Azure Marketplace, they can also obtain free algorithms from the
    community gallery that has been created by Microsoft to share ML algorithms with
    each other. They share many of predictive analytics of personal assistant in Windows
    Phone called Cortana. Azure ML also utilizes solutions from Xbox and Bing. Azure
    currently supports different features and capabilities such as run Hadoop over
    Ubuntu Linux on Azure, it also supports hosting Storm for analyzing data streams.
    In addition, it allows developers to connect.NET and Java libraries to Storm.
    Azure ML studio supports a variety of modules for training, scoring, and validation
    processes. Azure ML comes with a large library of algorithms for predictive analytics.
    The popular families of algorithms are regression, anomaly detection, clustering,
    and classification. D. Real-Time Big Data Analytics Tools for SBS Several applications
    need to have real-time data analysis for stream data and waiting for the information
    to be archived and then analyzed is not practical for these type of applications.
    Generally, Stream processing is intended to analyze a massive amount of data and
    act on real-time streaming data utilizing continuous queries such as SQL-type
    queries to handle streaming data in real-time utilizing scalable, available and
    fault-tolerant architecture. Essential to stream processing is Streaming Analytics.
    More and more tools offer the possibility of real-time streaming data. The following
    presents some of the common and widely used options. 1) Apache Storm Storm [227]
    is an open source distributed real-time data processing framework that provides
    massively scalable event collection. The initial release was on 17 September 2011,
    it was created by Nathan Marz and the team at BackType, and is now owned by Twitter.
    Storm can easily process unlimited streams and with any programming language.
    It has the capability to process over one million tuples per second per node with
    a highly scalable, fault-tolerant, and reliable architecture. Storm is written
    in Java and Clojure. Trident is a high-level abstraction layer for Storm, can
    be utilized to accomplish state management persistence. Storm is a system of complex
    event processing. This type of solution allows companies to respond to the arrival
    of sudden and continuous data (information collected in real-time by sensors,
    millions of comments generated on social networks such as Twitter, WhatsApp and
    Facebook, bank transfers etc.). Some of the specific applications of Storm include
    customer service management in real-time, operational dashboards, data monetization,
    cybersecurity analytics, and threat detection. 2) Apache Kafka Kafka [228] is
    a fast, scalable, fault-tolerant and durable open-source message broker project
    that originally developed by LinkedIn, and subsequently open sourced in early
    2011 and released by Apache Software Foundation on 23 October 2012. Kafka is written
    in Scala. It supports a variety of use case scenarios with a focus on high throughput,
    reliability, and scalability characteristics. For example, it can message sensor
    data from heating and cooling equipment in office buildings. 3) Oracle In 2013,
    Oracle started utilizing Oracle Enterprise Manager that includes Oracle Big Data
    Appliance to manage all of its big-data technologies. Oracle has also produced
    multiple low-latency technologies for Oracle Fast Data components includes Oracle
    Event Processing, Coherence, NoSQL, Business Analytics, and Real-Time Decisions.
    Oracle Event Processing provides solutions for building applications to filter,
    correlate and process events in real-time. It supports IoT services by delivering
    actionable insight on data streaming from a variety of data sources in real-time
    [229]. Oracle Stream Explorer (OSX) and Oracle R Enterprise (ORE) aim to support
    equipment monitoring applications for the systems that made of a variety of components
    through sensors, anomaly detection and failure prediction of such systems. ORE
    [230] is utilized to handle low-frequency streams in batch mode, while OSX handles
    the high-frequency streams making real-time predictions and sends the results
    back to user applications that are communicating with the output channels. OSX
    [231] is a middleware platform has the capability to process large amounts of
    streaming data in real-time for a variety of streaming data applications, from
    a multitude of sources like sensors, social media, financial feeds, etc. It streamlines
    real-time data delivery into most popular big data solutions, including Apache
    Hadoop, Apache HBase, Apache Hive, Apache Flume, and Apache Kafka to facilitate
    improved insight and timely action. Oracle Real-Time Decisions [232] is a decision
    management platform with self-learning that determines optimized recommendations
    and actions with messaging, imagery, products, and services within business processes.
    4) Amazon Kinesis Streams Amazon Kinesis [233] is a platform for collecting and
    processing large streams of data on AWS in real-time, AWS launched Kinesis in
    November of 2013, offering powerful services for loading and analyzing streaming
    data, in addition, it provides custom streaming data applications for specialized
    needs. Sometimes Terabytes of data per hour can be generated - that need to be
    collected, stored, and processed continuously from various application services
    such as web applications, mobile devices, wearables, industrial sensors etc. Typically,
    Amazon Kinesis Streams application can use the Amazon Kinesis Client Library and
    reads data from an Amazon Kinesis stream as data records. These applications can
    run on Amazon EC2 instances. 5) Apache Spark Streaming Apache Spark [234] is an
    open-source platform for real-time data processing, it can implement using four
    different languages: Scala, the syntax in which the platform is written; Python;
    R; and Java. Spark Streaming is an extension of core Spark API. It allows building
    fault-tolerant processing of real-time data streams. Spark Streaming allows the
    processing of millions of data among the clusters, and Spark SQL which makes it
    easier to exploit the data through the SQL language. Spark Streaming divides the
    live data stream into a predefined interval of batches, then handles each batch
    of data as Resilient Distributed Datasets (RDDs). Then we can apply operations
    like map, reduce, join, window etc. to process these RDDs. The last results of
    these operations are then returned in batches. Spark Streaming can be utilized
    for a variety of application such as real-time monitoring and analyzing of application
    server logs. These logs messages are considered time series data. Examples of
    such type of data are sensor data, weather information, and clickstream data.
    This data can also be utilized for predicting future states based on historical
    data. Apache assures a computation speed that performs the operations quicker
    by 100 times than what is currently offered by Hadoop MapReduce in memory, and
    10 times better than in disc. Spark can be executed either in independent cluster
    mode or in the cloud on different frameworks such as Hadoop, Apache Mesos, and
    EC2. In addition, Spark can access numerous databases such as HDFS, Cassandra,
    HBase or S3, Amazon’s data warehouse. 6) Apache Flume Flume [242] is a distributed,
    reliable and open-source log data aggregation framework. Apache Flume is applied
    in many applications ranging from log data aggregation, to transport massive quantities
    of event data including network traffic data, social-media-generated data, email
    messages and pretty much any data source possible into the HDFS. The architecture
    of Flume is simple and flexible, it is also robust and fault tolerant with tunable
    reliability mechanisms for failover and recovery. log manufacturing operations
    is an example of Flume’s application. The a massive log file data can stream through
    Flume. The log file data can be stored in HDFS and analyzed by utilizing Apache
    Hive. 7) Apache Samoa SAMOA [243] is a distributed streaming ML framework that
    contains programming abstractions for distributed streaming ML algorithms. Its
    name stands for Scalable Advanced Massive Online Analysis and was originally developed
    at Yahoo! Labs in Barcelona in 2013 and has been part of the Apache incubator
    since late 2014. SAMOA is both a platform and a library. It enables the algorithm
    developer to reuse their code to run on different underlying execution engine.
    In addition, it supports plug-in modules to port SAMOA to different engines. By
    utilizing SAMOA, the ML algorithm developer does not need to worry about the complexity
    of underlying distributed stream processing engines. They can run it locally or
    utilizing one of stream processing engines, such as Storm, S4, or Samza. SAMOA
    provides the ML algorithms for a variety of tasks including classification, regression,
    clustering, along with boosting, and bagging for ensemble learning. Additionally,
    it offers a platform for the implementation of these ML algorithms, as well as
    a framework that enables the user to write their own distributed streaming algorithms.
    For example, there is CluStream for clustering, as well as Vertical Hoeffding
    Tree, which uses vertical parallelism on top of the decision tree, or Hoeffding
    tree for classification. There is also Adaptive Model Rules Regressor, which uses
    both vertical and horizontal parallelism implementations for regression [244].
    A summarized comparison between various real-time data analytics tools is provided
    in Table 7. TABLE 7 Comparison Between Real-Time Data Analytics Tools TABLE 8
    Categorized Applications of SB SECTION V. Applications of Ml-Based Context-Aware
    Systems for SBs The potential uses of ML in an SB environment can be divided into
    four categories: detection, recognition, prediction, and optimization [79]. We
    discuss these categories separately next. In general, detection is the extraction
    of particular information from a larger stream of information. Many detection
    applications in SBs such as fire detection, leak detection, and anomaly detection
    [245]. Many different applications have been studied by researchers in activity
    recognition in SBs; examples include fitness tracking, health monitoring, fall
    detection. [246]. The goal of recognition is to classify an object or an event
    to a predefined category. It focuses on how to make computer programs perform
    intelligent and human-like tasks, such as the recognition of an object from an
    image. The goal of prediction is to determine the temporal relations’ model between
    specific events to predict what will happen in the near future. Prediction can
    be either for classification or regression problems [247]. Event prediction when
    the goal is to predict the most probable event or subsequent activity is an example
    of classification problems, while latency prediction when the output takes on
    continuous values is an example of the regression problem. The general steps of
    applying ML processes to predict an event in an SB environment is shown in Figure
    9. FIGURE 9. Steps involved in applying ML models in an SB environment. Show All
    The goal of optimization, on the other hand, is to maximize the long-term profits
    by making proper decisions in different situations. reinforcement learning can
    be utilized with these problems. Some optimization problems can be managed as
    prediction problems such that the profits for different actions are predicted
    and the action with the highest profit would be selected. Decision making is the
    most common case of the optimization problem. It takes to consider a variety of
    variables and solving deals between the profits of different locations of the
    environment [248]. Smart buildings are becoming increasingly supplied with a variety
    of sensors that measure different parameters, and data from these sensors is analyzed
    by ML algorithms and used for a range of services and applications for the activities
    of the building occupants. SBs go far beyond saving energy and contributing to
    sustainability goals. The application and services provided by the SBs can be
    both residential and commercial ranging from e-health, e-marketing, intelligent
    car parking system, intelligent transportation system, automation, and logistics
    services. Figure 10 shows the taxonomy of basic domains of SB services. Lighting
    services are associated with the well-being of occupants depending on their activities
    in SBs that have sensors to conserve energy when lights are not needed. The power
    and electrical system may have onsite renewable energy sources to provide a percentage
    of power consumption in SBs. Waste management is related to the activities and
    actions required to collect, separate, transport, together with monitoring and
    regulation of waste management system in SBs. The security is related to managing
    automated locks, biometric devices as well as video surveillance systems in SBs.
    The communications center is related to connecting sensors and actuators in the
    building as well as the operations control center. The operations control center
    supports system analytics and decision making for the operations. Visual interfaces
    provide a dashboard that shows the status of SB services and human operators to
    better manage the building resources. These interfaces also allow the occupants
    to set up their optimal parameters for comfort and productivity improvement on
    daily activities. HVAC stands for the humidity, ventilation and air conditioning
    system, intended for the convenience of occupants that have effective interaction
    with the environment. Parking services aim to minimize the area and volume required
    for parking cars. It could support car sharing, electric vehicles and a place
    for bicycles as well. Finally, the water management services aim to increase savings
    and manage water reclamation for flushing, landscaping and air-cooling systems.
    FIGURE 10. SB services taxonomy. Show All Based on our literature survey, we have
    identified that the application areas of SBs can be elderly care, comfort/entertainment,
    security/safety, energy management, and other projects. In the rest of the section,
    we will briefly describe the major domains in providing the following SB services:
    (1) care of the elderly population; (2) enhancing energy efficiency; (3) enhancing
    comfort or providing entertainment; (4) enhancing safety and security; and (5)
    miscellaneous projects. a: Elderly Population’s Home Care SB technology such as
    sensors, voice activation, GPS, Bluetooth, cellular connectivity via mobile phones,
    smartphone monitoring apps and sophisticated computers can be especially useful
    for elderly or disabled individuals who live independently. Elderly persons can
    take the advantages of such technologies (e.g., monitoring system, emergency system,
    dangerous kitchen appliance detection, fall detection), to maintain a safe and
    healthy lifestyle while living independently [56], [249]. Smart technology in
    the SBs aims to collect real-time information on human daily activity and then
    learn of their personal patterns. ML techniques have the potential for a very
    wide array of new innovations in healthcare that will be transformative for both
    providers and their patients. Whenever a deviation from the norm patterns is detected,
    SB systems send the alerts to family members and the caregivers in order for them
    to take urgent response action. By using big data analytics and ML algorithms
    it is possible to analyze large-scale data contained in electronic medical records—e.g.,
    to learn automatically how physicians treat patients including the drugs they
    prescribe [250]. Some prominent projects in this space are described next. Chernbumroong
    et al. [56] proposed an activity recognition and classification approach for detecting
    daily living activities of the elderly people applying SVM. They used wrist-worn
    multi-sensors namely accelerometer, temperature sensor and altimeter for detection
    basic five activities namely feeding, grooming, dressing, mobility, and stairs.
    And other instrumental activities such as washing dishes, ironing, sweeping and
    watching TV. Taleb et al. [251] proposed a middleware-level solution that integrates
    both the sensing and the monitoring services for assisting elders at smart homes
    environment. The appliances used in the proposed framework include RFID readers
    that cover of the whole building, sound sensors, video cameras, smart door lock,
    microphone and speakers for interaction with the system. CAALYX [252] is a European
    Commission-funded project that supports older people’s autonomy and self-confidence.
    The service is formed of three distinct subsystems including elderly monitoring
    subsystem, home monitoring subsystem and the caretaker’s monitoring subsystem.
    The system delivers a high priority message to an emergency service including
    the geographic position and clinical condition of the elder user. EasyLine+ [253]
    project funded by the European Commission to support elderly people with or without
    disabilities in carrying out a longer independent life at home. The system uses
    a neural network, assistive software, and a variety of sensors such as illumination
    sensor, temperature sensor, door sensors, and RFID giving the capacity of controlling
    the white goods. Hossain et al. [254] proposed a cloud-based cyber-physical multi-sensory
    smart home framework for elderly people that supports gesture-based appliance
    control. Suryadevara et al. [255] proposed a model for generating sensor activity
    pattern and predicting the behavior of an elderly person using household appliances.
    b: Energy Efficiency When temperatures rise or fall in various zones of your home,
    heaters, air conditioners, fans, and other devices will turn on or off (or increase
    or decrease in speed or temperature). In order to perform an efficient energy
    consumption of the supply systems, a significant step that is necessary by analyzing
    the way that current energy consuming system is using in buildings [256]. In the
    last decade, analysis of the energy efficiency in the smart spaces has received
    increasing attention. Various approaches for energy efficiency have been proposed
    utilizing predictive modeling based on profile, climate data, and building characteristics
    [32], [257]. For instance, lights throughout your home might turn on and off depending
    on the time of day. In the past, various attempts have been made to improve energy
    efficiency in the SBs through the use of smart metering and sensor networks at
    the residential level facilities. It is a fact that these types of infrastructure
    are becoming more widespread but due to their variety and size, they cannot be
    directly utilized to make conclusions that help to improve the energy efficiency.
    ML approaches will be the key to the handling of energy efficiency problem in
    SBs. Learning about the occupants’ consumption habits is capable of generating
    collaborative consumption predictions that help the occupant to consume better
    [258]. Some prominent projects in this space are described next. Reinisch et al.
    [259] developed an optimized application of AI system for SB environment. The
    system focuses on some capabilities like ubiquity, context awareness, conflict
    resolution, and self-learning features. The system operates on a knowledge base
    that stores all the information needed to fulfill the goals of energy efficiency
    and user comfort. Jahn et al. [260] proposed an energy efficiency features system
    built on top of a Hydra middleware framework [261]. The system provides both,
    stationary and mobile user interfaces for monitoring and controlling a smart environment.
    Pan et al. [262] proposed an IoT framework that uses smartphone platform and cloud-computing
    technologies to improve the energy efficiency in SBs. They built an experimental
    testbed for energy consumption data analysis. Fensel et al. [263] proposed the
    SESAME-S project (SEmantic SmArt Metering - Services for energy efficient houses).
    The project focuses on designing and evaluating the energy efficiency services
    to enable the end-consumers in making the right decisions and controlling their
    energy consumption. The system combines a variety of smart building components,
    such as smart meters, a variety of sensors, actuators, and simulators that can
    integrate virtual appliances such as the washing machine. Vastardis et al. [264]
    proposed a user-centric smart-home gateway system architecture to support home-automation,
    energy usage management, and smart-grid operations. The gateway is supported by
    ML classification algorithms component such as C4.5 and RIPPER that is able to
    extract behavioral patterns of the users and feed them back to the gateway. Irrigation
    systems monitoring and smart watering system that keep track of rain and soil
    conditions and irrigate appropriately are a very cost-effective way to reduce
    outdoor water consumption. Investment in water management software and services,
    water-efficient plumbing, and irrigation management delivers economic and sustainability
    benefits. Water conservation and management is an example of such benefits [265].
    c: Comfort/Entertainment One of the main goals of SB research is to facilitate
    user daily life activities by increasing their satisfaction and comfort level.
    SBs supports automated appliance control and assistive services to offer a better
    quality of life. They utilize context awareness techniques to optimize the occupant’s
    comfort based on predefined constraints of conditions in a building environment.
    Typical examples of comfort services include lighting, background music, automation
    of routine activities, advanced user interfaces based on voice or gestures, etc.
    [30]. Other services related to comfort services in SB environments are Indoor
    Climate Control and Intelligent Thermostat [265]. Indoor Climate Control: Measurement
    and control of temperature, lighting, CO2 fresh air. In the SB environment, HVAC
    systems play an essential role in forming indoor environmental quality. Typically,
    HVAC systems are produced not only to heat and cool the air but also to draw in
    and circulate outdoor air in large buildings [266]. Kabir et al. [267] present
    a context-aware application that provides the service according to a predefined
    preference of a user. They use the KNN classifier to infer the predefined service
    that will maximize the user’s comfort and safety while requiring minimum explicit
    interaction of the user with the environment. Ahn et al. [268] proposed a deep
    learning model that estimates periodically the atmospheric changes and predict
    the indoor air quality of the near future. d: Safety/Security As the SB technology
    progresses, the role of ML and deep learning in security and connected devices
    will increase. Deep learning will continue to help gain insights using big data
    that were previously inaccessible, particularly in image and video. Advanced technologies
    such as behavioral analysis and ML to detect, categorize, and block new threats
    will be beneficial. In a traditional home system, as soon as a fire is detected
    the Fire/smoke detectors are activated and start sending a fire alarm. However,
    SB can perform much better than the traditional system. It not only sends an alarm
    but also turns on the light only in the safest route and guides the occupants
    of the building out, as well as it will unlock the doors and windows for smoke
    ventilation, turn off all the devices and call the nearest fire service station.
    Other than this, it can take video of the areas surrounding the building, provide
    the status of window breakage alarms, and automatically lock all the doors and
    the windows when the last person of the house leaves [30]. The main services for
    security and safety in SBs are: Perimeter Access Control, Liquid Presence, Intelligent
    Fire Alarm, Intrusion Detection, and Motion Detection Systems [265]. Perimeter
    Access Control service provides control to restricted areas and detects non-authorized
    users that access the areas. Access card provides a variety of solutions that
    allow staff members, vendors or contractors to access specific areas at specific
    times you designate. The same access card can also be utilized to check employee
    attendance. In addition, there is widespread use of biometric technology including
    fingerprint, facial recognition, and iris scans [269]. Additionally, liquid presence
    detection technique has been utilized in data centers, warehouses, and sensitive
    building grounds to prevent breakdowns and corrosion in such areas [270]. Intelligent
    Fire Alarm and its corresponding safety systems are crucial parts of an intelligent
    building. It is a system with multi-function sensors (i.e., chemical gas sensors,
    integrated sensor systems, and computer vision systems) These sensors enable measuring
    smoke and carbon monoxide (CO) levels in the building. They also can give warnings,
    howling alarms, and tell with a human voice about the place and level of smoke
    and CO. In addition, they can give a message on a smartphone if the smoke or the
    CO alarm goes off [271]. Examples of intrusion detection systems including window
    and door opening detection and intrusion prevention [265]. An infrared motion
    sensor is utilized to detect the motion in a specific area in the building. This
    sensor can reliably send alerts to the alarm panel, with the system implementing
    algorithms for adaption to environmental disturbances and reducing any false alarms
    [265]. Image recognition solution can be used in security software to identify
    people, places, objects, and more. It can also be used to detect unusual patterns
    and activities. Clarifai [272] specializes in a field of ML known as “computer
    vision” that teaches computers to “see” images and video. Clarifai’s technology
    can play a key role in security surveillance and at present, the company works
    only with home security. Each image is processed on a pixel by pixel basis through
    convoluted neural networks. Bangali and Shaligram [273] proposed a home security
    system that monitors the home when the user is away from the place. The system
    is composed of two methods: one uses a web camera to detect the intruder—whenever
    there is a motion detected in front of the camera, a security alert in terms of
    sound and an email is delivered to the occupant. And the other one is based on
    GSM technology that sends SMS. A home security system that sends alert messages
    to the house owner and police station in case of illegal invasion at home is proposed
    in [274]. The system consists of different sensor nodes as the input components
    while the output components respond to the signal received from the input components.
    The sensor nodes consist of a thief alarm, presence detecting circuit, and the
    break-in camera. Zhao and Ye [275] proposed a wireless home security system that
    utilizes low cost, low power consumption, and GSM/GPRS. The system has a user
    interface and it can respond to alarm incidents. e: Miscellaneous Projects CASAS
    [178] is a project by Washington State University that provides a noninvasive
    assistive environment for dementia patients at SBs. The project focuses on three
    main areas for SBs: medical monitoring, green living, and general comfort. CASAS
    project comprises of three layers: physical layer, middleware layer, and software
    applications layer. Aware Home Research Initiative (AHRI) [276] is a project that
    has constructed by a group at the Georgia Institute of Technology for SB services
    in the fields of health and well-being, digital media and entertainment, and sustainability.
    AHRI utilizes a variety of sensors such as smart floor sensors, it also utilizes
    assistive robots for monitoring and helping the elderly. House_n [277] is a multi-disciplinary
    project leads by a group of researchers at the MIT. The main objective of the
    project is to facilitate the design of the smart home and its associated technologies,
    products, and services. The home is supplied with hundreds of various sensors
    that are installed almost in every part of the home that and being utilized to
    develop user interface applications that enable the users to control and monitor
    their environment, save resources, remain mentally and physically active, and
    stay healthy. The EasyLiving project [278] at Microsoft Research is concerned
    with the development of a prototype architecture and technologies to aggregate
    diverse devices into a coherent user experience for intelligent environments.
    The EasyLiving project was designed to provide context-aware computing services.
    The project utilizes a variety of sensors and cameras to track and recognize the
    human activities in the room by using the geometric model of a room and taking
    readings from sensors installed in the room. The Gator Tech Smart House project
    [279] is a programmable space specifically designed for the elderly and disabled
    developed by The University of Florida’s mobile and pervasive computing laboratory.
    The project’s goal is to create SB environments that can sense themselves and
    their residents. The project provides special cognitive services for the residents
    such as mobility, health, and other age-related impairments. A generic middleware
    is utilized to integrate system components in order to maintain a service definition
    for every sensor and actuator in the building. The components of the middleware
    including separate physical, sensor platform, service, knowledge, context management,
    and application layers [280]. Other well-known smart home projects include DOMUS
    [281] which is a research project, by the University of Sherbrooke in Canada,
    that supports mobile computing and cognitive assistance in smart buildings. The
    project aims to assist people suffering from Alzheimer’s type dementia, schizophrenia,
    cranial trauma, or intellectual deficiencies. Adaptive House project [136] at
    The University of Colorado has constructed a prototype system that is equipped
    with a variety of sensors that provide different environmental information including
    sound, motion, temperature, light levels. In addition, actuators that control
    the space and water heaters; lighting units, and ceiling fans. In Asia, there
    are also some other smart building projects have been developed, such as “Welfare
    Techno House” project, which is equipped with different sensors such as ECG, body
    weight, and other temperature measured indicators [282]. Ubiquitous Home project
    [283] is another smart building project in Japan, which utilizes RFID, PIR, pressure
    sensors, as well as cameras and microphones for monitoring elderly adults. Summary:
    Recently, several different context-aware and ML techniques have been utilized
    to support SB services. ML-based approaches are capable to perform better prediction
    and adaptation than others. The philosophy behind ML is to automate the learning
    process that enables algorithms to create analytical models with the support of
    available data. ML can be applied in different learning styles including supervised
    learning, unsupervised learning, semi-supervised learning, as well as reinforcement
    learning when the learning is the result of the interaction between a model and
    the environment. The general uses of ML for SB services are detection, recognition,
    prediction, and optimization. In the section, we also talked about how to acquire
    the context from multiple distributed and heterogeneous sources and the techniques
    for modeling and processing such context to be used in the application services
    of SBs. We also talked about the most used tools and platforms ML and others for
    real-time data analytics by ML community to efficiently process and learn from
    big data. Without such ML tools, one would have to implement all of the techniques
    from scratch requiring expertise in the techniques and in efficient engineering
    practices. SECTION VI. Open Issues and Future Research Directions Research on
    SBs has made great strides in recent years, but a number of challenges remain.
    We present some major challenges related to SBs in this part of the work. These
    challenges will channelize the research directions for future SBs. A. Security
    and Privacy Wherever there is an interconnection of two systems or networks (wired
    or wireless), there are issues of security and privacy and the same is true in
    the case of SB. Security is an essential role in SB environments. Any SB application
    should ensure the confidentiality and integrity of data. Access control must be
    included in SB systems, for instance, the unauthorized users should not be able
    to disconnect the alarm system by connecting the pervasive system [284]. There
    is a massive amount of streaming that is collected from the various installed
    sensors and appliances, such data needs to be processed and stored. Hence, cloud
    computing services can be utilized for this purpose. However, with all of this
    data that is transmitted, the issue of losing the privacy increases. Therefore,
    different encryption techniques are needed to preserve personal privacy [285].
    There are specific challenges related to the user’s privacy including challenges
    related to the data privacy of personal information and the privacy of the individual’s
    physical location and tracking. That needs for privacy enhancement technologies
    and relevant protection laws and tools for identity management of users and objects
    [286]. The recent trend of ML research has focused on handling security and privacy
    issues in SB environments. There are different security-related services have
    utilized ML techniques, such as determining safe device behavior by detecting
    and blocking activities and potentially harmful behavior [287]. ML techniques
    have the potential to reduce security gap because of their capability to learn,
    identify and detect the users’ habits and behaviors. Consequently, it can detect
    the abnormal behaviors predicting risks and intrusions before they happen. For
    instance, ML models learn the routine of the users, such as the time they get
    home or go to sleep. These models can suggest rules based on those detected behaviors
    from all connected devices [288]. B. SBS and Context-Aware Computing In the SB
    environment, there exists a massive amount of raw data being continuously collected
    about the various human activities and behaviors. It is important to develop techniques
    that convert this raw data into valuable knowledge [289]. Context awareness and
    ML techniques are expected to provide great support to process and store big data
    and create important knowledge from all this data [290]. The process of data interpretation
    and knowledge extraction has the following challenges including addressing noisy
    real-world data and the ability to develop further inference techniques that do
    not have the limitations of traditional algorithms. Usually, It is very complex
    to formalize and model the contextual information related to human behaviors in
    a standard way due to the complex physiological, psychological and behavioral
    aspects of human beings [291]. The humans communicate through rich languages as
    well as gestures and expressions. Modern ubiquitous computer systems lack an automatic
    mechanism of inferring information as the humans do. New research is necessary
    to raise human activities and behaviors recognition to understand the complex
    dependencies between the apps and humans [292], [293]. The context-aware prompting
    systems have essential applications in SBs such as emergency notifications, medication
    prompting, heart rate monitoring, generation of agenda reminders, and weather
    alerts. However, issuing prompts for all detected errors can possibly be false
    positives, and consequently, lead to annoyance and sometimes prove to be unsafe
    for specific activities. ML methods can be used for an accurate and precise prediction
    when a person faces difficulty while doing daily life activities [294]. C. Personal
    Data Stream Management in SBS The data streaming management system is able to
    process and transfer raw data collected from a variety of sensors to information,
    it is also able to fuse this information to a feature and directly process features
    [295]. While the data processing for a single SB is simple, it is more complex
    when processing the data from multiple SBs, because there are different people
    that tend to share less common interests and have opposing interests concerning
    the processed data [296]. The simple sensors in an SB environment can detect different
    events related to temperature, motion, light, or weather. Moreover, other appliances
    like a television and a telephone can also send their status or other data as
    events. All this data from different sensors can be used by SB services to detect
    specific states and send a request to some actuators according to specific predefined
    rules, for instance, turn on the light if the television is used [297]. However,
    this approach is not generalizable in case of a group of people residing in the
    same building. Although it can work well for one certain person when personal
    preferences can be automatically learned for an individual person, therefore each
    of the residents has to define their own set of rules [298]. Because of the increasing
    number of sensors that produce data streams, the traditional analyzing and processing
    techniques of these data streams are mostly impractical now [299]. Despite the
    availability of new tools and systems for handling massive amounts of data continuously
    generating by a variety of sensors in SBs, however, the real promise of advanced
    data analytics to still lies beyond the realm of pure technology [296]. In [300]
    discuses research challenges for data streams of real-world applications. They
    analyze issues concerning privacy, timing, preprocessing, relational and event
    streams, model complexity and evaluation, availability of information, and problems
    related to legacy systems. D. Big Data Challenges in SBS Nowadays, a variety of
    sensing technology in the SBs can be utilized to collect a massive amount of heterogeneous
    data at a reasonable cost. Typically, hundreds of thousands of transactions can
    be generated by a single SB every day. The process of storing this data over the
    long-term is challenging [258]. We can imagine the challenges and opportunities
    that the companies or government will encounter in the future to manage incoming
    data from dozens of SBs. This new data could provide us with more contextual information
    that consequently leads to much better services to the occupants [301]. In the
    world of big data, despite the availability massive amount of data, however, it
    is not necessarily easy to obtain valuable information from this data utilizing
    the traditional approaches like trial and error to extract meaningful information
    from this data. Analyzing these massive amounts of data requires new technologies
    to store, organize, and process big data effectively, it needs high-performance
    processors that enable uncovering the insights in big data. It also requires flexible
    cloud computing services and virtualization techniques, as well as software such
    as Apache Hadoop and Spark [302]. It requires providing appropriate ML techniques
    which differ from the traditional approaches for effective and efficient solution
    of the above issues. For these reasons, researchers have recently started to think
    about the problems and opportunities resulting from the adoption of big data in
    SB environments [303], [304]. The information extracted from this big data has
    significant value and could greatly contribute in the future of SBs as assistive
    tools and for better services delivery. That is why it is necessary that the researchers
    start to analyze and think about the solutions for the current and future challenges
    of big data in SBs [305]. E. Interoperability Interoperability means that two
    (or more) systems work together unchanged even though they were not necessarily
    designed to work together. When equipment, devices or appliances having different
    communication and networking technologies can communicate effectively, interoperability
    is satisfied. It is a challenge to ensure that an SB that has various components
    will be intelligible. Typically, each of these components might have been produced
    by different vendors, each of which may have created under different design constraints
    and considerations [306]. Therefore it becomes essential to satisfy interoperability
    so that a number of heterogeneous communication and networking technologies could
    coexist in various parts of SBs. For example, an energy management system may
    use Wi-Fi and ZigBee for communication purposes. A lot of work can be done in
    this context [307]. F. Reliability We can expect that the reliability is one of
    the main concern of occupants and developers of SB systems. A variety of appliances
    and devices present in SB such as televisions, microwave, washing machines etc.
    are required exceedingly to be reliable. Achieving expected levels of reliability,
    especially when linked with communication technologies utilized with these devices
    that may be expected in SBs, is a great challenge. There are different reasons
    for these challenges differences in technological approaches, regulations, development
    culture, and the expectations of the market [306]. G. Integration The key to a
    successful SB implementation is integration: linking building systems such as
    lighting, power meters, water meters, pumps, heating, and chiller plants together
    using sensors and control systems, and then connecting the building automation
    system to enterprise systems. Integration allows executives to gain smart-building
    benefits, both in new construction and by gradually transforming existing buildings
    into SBs. What these SBs have in common is integration. Generally, the integration
    in SB systems brings a range of benefits from energy savings to productivity gains
    to sustainability. The SB systems can be attached to enterprise business systems
    to add another level of intelligence that enhances decision-making and improves
    building performance [2]. However, integrating multiple systems is very challenging
    as each individual system has its own assumptions, strategies to control the physical
    world, and semantics. As an example of integrating two systems in SB, assume a
    system that is responsible for energy management, and another system for health
    care are running concurrently. In this case, the integrated system should not
    turn off medical appliances to save energy while they are being used as suggested
    by the health care system [292]. As a future perspective for SBs, You will wake
    up to the sound of the alarm, at the same time the available sensors will be aware
    that you are waking up. The other sensors such as light sensors will automatically
    turn on the light in the building, while the thermostat will warm the area that
    you are about to use in the building. Your coffee will start to brew, you will
    also get a notification on your phone about the weather. The other sensors in
    the kitchen and refrigerator will remind you with a list of items that you will
    need to pick up on your way from your workplace to home to make dinner. When you
    leave your house, you can press a button from your phone to self-drive your car
    out of the garage. After that, the security system will start monitoring and controlling
    the home. Such the doors will automatically lock. Appliances will switch to an
    energy-saving mode. When the home sensors sense utilizing geofencing technology
    that you are way back home, it will get ready again for your arrival, the thermostat
    will warm things up, the garage door will open as you pull up, and your favorite
    music will start to play when you walk in [141]. Summary: Although the recent
    researches have been done in the SBs field, there is a need for a lot more efforts;
    however, we believe that SBs are possible for the mass market in the near future.
    The main challenges and future research directions of this eld can be summarized
    as follows: User context in term of behavior and intention should be studied and
    respected whenever possible; Further research is needed into context-aware prompting
    systems, personal data streaming and big data analysis of occupants in SB environment;
    Some of the other challenges like the interoperability, reliability, and integration
    still require more attention. SECTION VII. Conclusions The promise of smart buildings
    (SBs) is a world of appliances that anticipate your needs and do exactly what
    you want them to at the touch of a button. Since SBs and their inhabitants create
    voluminous amounts of streaming data, SB researchers are looking towards techniques
    from ML and big data analytics for managing, processing, and gaining insights
    from this big data. This paper reviewed the most important aspects of SBs with
    particular focus on what is being done and what are the issues that require further
    research in ML and data analytics domains. In this regards, we have presented
    a comprehensive survey of the research works that relate to the use of ML and
    big data particularly for building smart infrastructure and services. Although
    the recent advancements in technologies that make the concept of SBs feasible,
    there are still a variety of challenges that limit large-scale real-world systems
    in SBs field. Addressing these challenges soon will be a powerful driving force
    for advancements in both industrial and academic fields of SB research. ACKNOWLEDGMENT
    The statements made herein are solely the responsibility of the authors. Authors
    Figures References Citations Keywords Metrics More Like This MIS-IoT: Modular
    Intelligent Server Based Internet of Things Framework with Big Data and Machine
    Learning 2018 IEEE International Conference on Big Data (Big Data) Published:
    2018 Framework for Mobile Internet of Things Security Monitoring Based on Big
    Data Processing and Machine Learning IEEE Access Published: 2018 Show More IEEE
    Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW
    PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE Access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/8600701/08754678.pdf
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: 'Leveraging Machine Learning and Big Data for Smart Buildings: A Comprehensive
    Survey'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1007/978-3-030-37177-7
  analysis: '>'
  authors:
  - Sabina Leonelli
  - Niccolò Tempini
  citation_count: 57
  full_citation: '>'
  full_text: '>

    Your privacy, your choice We use essential cookies to make sure the site can function.
    We also use optional cookies for advertising, personalisation of content, usage
    analysis, and social media. By accepting optional cookies, you consent to the
    processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Home Book Data Journeys in the
    Sciences Book Open Access © 2020 You have full access to this open access Book
    Download book PDF Download book EPUB Overview Editors: Sabina Leonelli, Niccolò
    Tempini     Facilitates an in-depth understanding of data-intensive methods Is
    the most advanced survey of data practices across the sciences Presents a ground-breaking
    and comprehensive framework for data studies Contains original contributions by
    world-leading science scholars in the respective fields 129k Accesses 113 Citations
    82 Altmetric Sections Table of contents About this book Keywords Editors and Affiliations
    About the editors Bibliographic Information Publish with us Search within this
    book Search Table of contents (21 chapters) Front Matter Pages i-xvii Download
    chapter PDF Learning from Data Journeys Sabina Leonelli Pages 1-24Open Access
    Download chapter PDF Origins: Data Collection, Preparation and Reporting Front
    Matter Pages 25-25 Download chapter PDF Material Origins of a Data Journey in
    Ocean Science: How Sampling and Scaffolding Shape Data Practices Gregor Halfmann
    Pages 27-44Open Access Download chapter PDF What Data Get to Travel in High Energy
    Physics? The Construction of Data at the Large Hadron Collider Koray Karaca Pages
    45-58Open Access Download chapter PDF Tracing Data Journeys Through Medical Case
    Reports: Conceptualizing Case Reports Not as “Anecdotes” but Productive Epistemic
    Constructs, or Why Zebras Can Be Useful Rachel A. Ankeny Pages 59-76Open Access
    Download chapter PDF Clustering: Data Ordering and Visualization Front Matter
    Pages 77-77 Download chapter PDF From Dirty Data to Tidy Facts: Clustering Practices
    in Plant Phenomics and Business Cycle Analysis Marcel Boumans, Sabina Leonelli
    Pages 79-101Open Access Download chapter PDF The Datum in Context: Measuring Frameworks,
    Data Series and the Journeys of Individual Datums Mary S. Morgan Pages 103-120Open
    Access Download chapter PDF Data Journeys Beyond Databases in Systems Biology:
    Cytoscape and NDEx William Bechtel Pages 121-143Open Access Download chapter PDF
    A Data Journey Through Dataset-Centric Population Genomics James Griesemer Pages
    145-167Open Access Download chapter PDF Sharing: Data access, Dissemination and
    Quality Assessment Front Matter Pages 169-169 Download chapter PDF Sharing Data,
    Repairing Practices: On the Reflexivity of Astronomical Data Journeys Götz Hoeppe
    Pages 171-190Open Access Download chapter PDF Evaluating Data Journeys: Climategate,
    Synthetic Data and the Benchmarking of Methods for Climate Data Processing Wendy
    S. Parker Pages 191-206Open Access Download chapter PDF The Babel of Drugs: On
    the Consequences of Evidential Pluralism in Pharmaceutical Regulation and Regulatory
    Data Journeys Niccolò Tempini, David Teira Pages 207-225Open Access Download chapter
    PDF Interlude Front Matter Pages 227-227 Download chapter PDF Most Often, What
    Is Transmitted Is Transformed Theodore M. Porter Pages 229-236Open Access Download
    chapter PDF Interpreting: Data Transformation, Analysis and Reuse Front Matter
    Pages 237-237 Download chapter PDF The Reuse of Digital Computer Data: Transformation,
    Recombination and Generation of Data Mixes in Big Data Science Niccolò Tempini
    Pages 239-263Open Access Download chapter PDF Data, Meta Data and Pattern Data:
    How Franz Boas Mobilized Anthropometric Data, 1890 and Beyond Staffan Müller-Wille
    Pages 265-283Open Access Download chapter PDF 1 2 Next page Back to top Keywords
    Big Data Data Epistemology Data Ethics Data Science Epistemology of Science Social
    Studies of Data Social Studies of Science Data Collection, Preparation and Reporting
    Data at the Large Hadron Collider Data Journeys in Medical Case Reports Data Ordering
    and Visualization Clustering Practices in Plant Phenomics Databases in Systems
    Biology Data access, Dissemination and Quality Assessment Methods for Climate
    Data Processing Data Journeys in Pharmaceutical Regulation Data Mixes in Big Data
    Linkage Practice Radiocarbon Dating and Robustness Reasoning in Archaeology Data
    from Objects to Assets Open Access About this book This groundbreaking, open access
    volume analyses and compares data practices across several fields through the
    analysis of specific cases of data journeys. It brings together leading scholars
    in the philosophy, history and social studies of science to achieve two goals:
    tracking the travel of data across different spaces, times and domains of research
    practice; and documenting how such journeys affect the use of data as evidence
    and the knowledge being produced.  The volume captures the opportunities, challenges
    and concerns involved in making data move from the sites in which they are originally
    produced to sites where they can be integrated with other data, analysed and re-used
    for a variety of purposes. The in-depth study of data journeys provides the necessary
    ground to examine disciplinary, geographical and historical differences and similarities
    in data management, processing and interpretation, thus identifying the key conditions
    of possibility for the widespread data sharing associated with Big and Open Data.  The
    chapters are ordered in sections that broadly correspond to different stages of
    the journeys of data, from their generation to the legitimisation of their use
    for specific purposes. Additionally, the preface to the volume provides a variety
    of alternative “roadmaps” aimed to serve the different interests and entry points
    of readers; and the introduction provides a substantive overview of what data
    journeys can teach about the methods and epistemology of research. Editors and
    Affiliations Department of Sociology, Philosophy and Anthropology & Exeter Centre
    for the Study of the Life Sciences (Egenis), University of Exeter, Exeter, UK
    Sabina Leonelli, Niccolò Tempini Alan Turing Institute, London, UK Sabina Leonelli,
    Niccolò Tempini About the editors Sabina Leonelli is Professor in Philosophy and
    History of Science at the University of Exeter, where she co-directs the Centre
    for the Study of the Life Sciences and leads the data governance strand of the
    Institute for Data Science and Artificial Intelligence. Her interests include
    the epistemology, history and social studies of data-intensive science, open science
    and biological modelling. She is a Turing Fellow, ERC grantee, Editor-in-Chief
    of History and Philosophy of the Life Sciences, Associate Editor of the Harvard
    Data Science Review.  Niccolò Tempini is Senior Lecturer in Data Studies at the
    University of Exeter and a Turing Fellow at the Alan Turing Institute. He researches
    big data research and digital infrastructures, investigating the specific knowledge
    production economies, organization forms and data management innovations that
    these projects engender with a focus in their social and epistemic consequences.
    His research has been published in international journals across science and technology
    studies, information systems, sociology and philosophy.  Bibliographic Information
    Book Title Data Journeys in the Sciences Editors Sabina Leonelli, Niccolò Tempini
    DOI https://doi.org/10.1007/978-3-030-37177-7 Publisher Springer Cham eBook Packages
    Religion and Philosophy, Philosophy and Religion (R0) Copyright Information The
    Editor(s) (if applicable) and The Author(s) 2020 License CC BY Hardcover ISBN
    978-3-030-37176-0 Published: 30 June 2020 Softcover ISBN 978-3-030-37179-1 Published:
    18 September 2020 eBook ISBN 978-3-030-37177-7 Published: 29 June 2020 Edition
    Number 1 Number of Pages XVII, 412 Number of Illustrations 14 b/w illustrations,
    25 illustrations in colour Topics Philosophy of Science, History of Science, Science,
    Humanities and Social Sciences, multidisciplinary Publish with us Policies and
    ethics Back to top Access this book Softcover Book USD 59.99 Hardcover Book USD
    59.99 MyCopy Softcover USD 39.99 Tax calculation will be finalised at checkout
    Other ways to access Licence this eBook for your library Institutional subscriptions
    Discover content Journals A-Z Books A-Z Publish with us Publish your research
    Open access publishing Products and services Our products Librarians Societies
    Partners and advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan
    Apress Your privacy choices/Manage cookies Your US state privacy rights Accessibility
    statement Terms and conditions Privacy policy Help and support 129.93.161.219
    Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln
    (3000134173) © 2024 Springer Nature'
  inline_citation: '>'
  journal: Springer eBooks
  limitations: '>'
  pdf_link: null
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: Data Journeys in the Sciences
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/app10051803
  analysis: '>'
  authors:
  - Quang-Duy Nguyen
  - Catherine Roussey
  - María Poveda‐Villalón
  - Christophe de Vaulx
  - Jean-Pierre Chanet
  citation_count: 13
  full_citation: '>'
  full_text: ">\napplied  \nsciences\nArticle\nDevelopment Experience of a Context-Aware\
    \ System\nfor Smart Irrigation Using CASO and IRRIG\nOntologies\nQuang-Duy Nguyen\
    \ 1,*,†\n, Catherine Roussey 1,†\n, María Poveda-Villalón 2,†\n,\nChristophe de\
    \ Vaulx 3\nand Jean-Pierre Chanet 1\n1\nUniversité Clermont Auvergne, INRAE, UR\
    \ TSCF, 63178 Aubière, France; catherine.roussey@inrae.fr (C.R.);\njean-pierre.chanet@inrae.fr\
    \ (J.-P.C.)\n2\nOntology Engineering Group, Universidad Politécnica de Madrid,\
    \ 28660 Boadilla del Monte, Madrid, Spain;\nmpoveda@ﬁ.upm.es\n3\nLaboratoire d’Informatique,\
    \ de Modélisation et d’Optimisation des Systèmes (LIMOS), UMR 6158\nUCA-CNRS,\
    \ 63170 Aubière, France; christophe.de_vaulx@uca.fr\n*\nCorrespondence: quang-duy.nguyen@inrae.fr\n\
    †\nThese authors contributed equally to this work.\nReceived: 31 December 2019;\
    \ Accepted: 21 February 2020; Published: 5 March 2020\nFeatured Application: This\
    \ paper presents a smart irrigation context-aware system to be applied\non an\
    \ experimental farm in France.\nThe experimental farm is an ecosystem for agricultural\n\
    machines and digital information systems developed by an alliance of European\
    \ organizations\nand institutes. Moreover, the two ontologies proposed by this\
    \ paper, CASO and IRRIG, are\nopen access and have the potential to be used by\
    \ other applications such as smart buildings\nor smart cities.\nAbstract:\nThe\
    \ rapid development of information and communication technologies and wireless\n\
    sensor networks has transformed agriculture practices. New tools and methods are\
    \ used to support\nfarmers in their activities. This paper presents a context-aware\
    \ system that automates irrigation\ndecisions based on sensor measurements. Automatic\
    \ irrigation overcomes the water shortage\nproblem, and automatic sensor measurements\
    \ reduce the observational work of farmers. This paper\nfocuses on a method for\
    \ developing context-aware systems using ontologies. Ontologies are used\nto solve\
    \ heterogeneity issues in sensor measurements. Their main goal is to propose a\
    \ shared data\nschema that precisely describes measurements to ease their interpretations.\
    \ These descriptions are\nreusable by any machine and understandable by humans.\
    \ The context-aware system also contains\na decision support system based on a\
    \ rules inference engine. We propose two new ontologies:\nThe Context-Aware System\
    \ Ontology addresses the development of the context-aware system\nin general.\
    \ The Irrigation ontology automates a manual irrigation method named IRRINOV®.\n\
    These ontologies reuse well-known ontologies such as the Semantic Sensor Network\
    \ (SSN) and Smart\nAppliance REFerence (SAREF). The decision support system uses\
    \ a set of rules with ontologies to\ninfer daily irrigation decisions for farmers.\
    \ This project uses real experimental data to evaluate the\nimplementation of\
    \ the decision support system.\nKeywords: agriculture; smart irrigation; context-aware\
    \ system; ontology; rules\n1. Introduction\nIn the agricultural domain, farmers\
    \ need to observe natural phenomena to engage in appropriate\nactivities on their\
    \ ﬁelds. For example, in traditional irrigation, farmers go to their ﬁelds to\
    \ examine\nAppl. Sci. 2020, 10, 1803; doi:10.3390/app10051803\nwww.mdpi.com/journal/applsci\n\
    Appl. Sci. 2020, 10, 1803\n2 of 41\nthe crop development stage and measure the\
    \ soil moisture provided by probes in the soil. Then, they\nuse practical experience\
    \ or follow an irrigation method to estimate manually the water needs of their\n\
    crops. Based on their estimations, the farmers decide whether to irrigate the\
    \ ﬁelds. This conventional\napproach has two signiﬁcant drawbacks. First, irrigation\
    \ requires daily observations, often made by\nfarmers. Manual observations are\
    \ inﬂuenced by other factors such as the weather or the situation of\nfarmers.\
    \ For example, a daily observation could be skipped if the farmer is sick. Second,\
    \ the resource\nshortage problem demands that farmers use water sparingly.\nContext-aware\
    \ systems (CASs) can overcome the above-mentioned situations. A CAS uses a\nwireless\
    \ sensor network (WSN) to monitor environmental phenomena and uses those measurements\n\
    for further processes. In a CAS, context refers to “any information that can characterize\
    \ the situation of\nan entity. An entity could be a person, a place or an object\
    \ that is considered relevant to the interaction\nbetween a user and an application,\
    \ including the user and the application themselves” [1]. A CAS\nhas two contexts:\
    \ a low-level context and a high-level context [2]. The low-level context contains\n\
    quantitative data. The high-level context contains qualitative data that synthesize\
    \ a situation and ease\nthe decision. For example, the statement “soil moisture\
    \ is 160 centibar (cbar)” presents a low-level\ncontext; however, the statement\
    \ “soil is dry” presents a high-level context.\nThe CAS has some peculiar characteristics.\
    \ First, sensors in the system are heterogeneous. Each\ntype of phenomenon demands\
    \ a different type of sensor. For example, in agriculture, pluviometers\nmeasure\
    \ rain quantity, and tensiometers measure soil moisture. Thus, the CAS should\
    \ address\nsome data interoperability issues. Second, the system should have the\
    \ capability to process the raw\nmeasurement data and apply reason on them.\n\
    To address the above requirements, ontologies are adequate candidates. Some sensor\
    \ ontologies\nare provided by several institutes of standardization. Their main\
    \ goal is to propose a shared data\nschema that precisely describes measurements\
    \ to ease their interpretations. These descriptions are\nreusable by any machine\
    \ and understandable by humans. They propose a data modeling design pattern\n\
    that is precise enough to answer any informational need. Thus, any sensor measurements\
    \ described\nby these ontologies may be reusable by several decision support systems\
    \ (DSSs). The sensor network\nbecomes a data provider for several applications.\
    \ For example, rain quantity measurements can be\nused by irrigation decision\
    \ systems and crop disease management systems. Reusing existing ontologies\nenables\
    \ the harmonization of sensor measurement descriptions. Moreover, those descriptions\
    \ share\nthe same data model. Thus, they are easy to integrate in a global data\
    \ schema. Furthermore, some\nontologies enable reasoning over data because they\
    \ propose logical descriptions. In short, ontologies\nused in context modeling\
    \ can solve the heterogeneity issues of various sensor measurements and infer\n\
    the high-level context and decisions by applying rules. To the best of our knowledge,\
    \ the proposed\nwork is the ﬁrst to reuse two well-known ontologies: the new version\
    \ of the Semantic Sensor Network\n(SSN) [3] and Smart Appliances REFerence (SAREF)\
    \ [4].\nThis paper presents the development method of a CAS that combines two\
    \ engineering\nmethodologies: ontology and information systems. This method was\
    \ used to build a smart irrigation\nCAS that automates a manual irrigation method.\
    \ This irrigation method, called IRRINOV®, was\ndeveloped by Arvalis (Arvalis\
    \ is an applied agricultural research organization dedicated to arable\ncrops.\
    \ It engages in many activities at 27 different local sites in France.) and its\
    \ partners. The IRRINOV®\nmethod is widely used in many regions in France. The\
    \ development of the system also includes the\ndevelopment of two new ontologies—the\
    \ Context-Aware System Ontology (CASO) and Irrigation\nontology (IRRIG)—and a\
    \ set of rules for reasoning. The two new ontologies reuse well-known\nontologies\
    \ related to sensors and devices—SSN and SAREF. CASO specializes and extends SSN\
    \ to\ndescribe the processing of context. CASO implements a generic context model\
    \ that can be specialized\nto any observation of environmental phenomena. Using\
    \ CASO simpliﬁes the data processing and rule\ngenerating by dividing them in\
    \ several steps. IRRIG specializes CASO by implementing the IRRINOV®\nmethod.\
    \ The two ontologies model the sensor measurements and results of all measurement\
    \ processing\n(cleaning, aggregation, reasoning, etc.). The system uses a set\
    \ of rules for reasoning. Each rule\nAppl. Sci. 2020, 10, 1803\n3 of 41\nimplements\
    \ small inference steps. Thus, they are easy to understand, manage and correct.\
    \ Finally, we\npropose a complete DSS that supports farmers in making daily irrigation\
    \ decisions.\nThe rest of this paper is organized as follows. Section 2 presents\
    \ the state of the art of several smart\nirrigation systems available in the research\
    \ world. Section 3 introduces background information for\nthe cycle of processes\
    \ implemented in a CAS and the IRRINOV® method. The next section describes\nthe\
    \ development process of the complete system and the two ontologies. Section 5\
    \ provides an\nexample of the development presented in Section 4. Section 6 presents\
    \ and compares the results after\nimplementing the system using real experimental\
    \ data provided by Arvalis. Also, this section discusses\nthe limitations of the\
    \ IRRINOV® method, the limitations of the Arvalis dataset and the limitations\
    \ of\nthe DSS system. Finally, a brief conclusion sums up the system and presents\
    \ the perspectives.\n2. State of the Art\nAs mentioned in the introduction, an\
    \ ontology is a shared data schema that provides a common\nunderstanding of data\
    \ descriptions. Data descriptions based on ontologies are reusable by any machine\n\
    and understandable by humans. Thus, we examined ontologies already used in irrigation\
    \ decision\nsystems to reuse them as data modeling patterns to improve the results\
    \ of our data modeling activity.\nSeveral expert systems already exist that can\
    \ determine whether a crop needs water. For example,\none expert system uses the\
    \ common-KADS method to irrigate mango trees, as presented in [5]. Please\nnote\
    \ that this expert system is not connected to any sensors or actuators. Its goal\
    \ is to help farmers\ndecide when to irrigate. However, no information about the\
    \ ontology publication is provided.\nSemantic web technologies are already used\
    \ in CASs dedicated to irrigation. For example, the\nFIWARE platform that links\
    \ Internet of Things (IoT) devices to the cloud has been used in several\ndifferent\
    \ irrigation experiments [6]. The FIWARE cloud platform contains the SEPA SPARQL-based\n\
    engine, which represents information in an RDF format and provides SPARQL queries.\
    \ To the best of\nour knowledge, no information about the ontologies used in these\
    \ experiments is available online.\nThe works of [7,8] present some ontologies\
    \ dedicated to hilly citrus tree cultivation. One ontology\naddresses the irrigation\
    \ decision. The ontology stores the computations of relative soil moisture based\n\
    on the soil type and the crop growth stage. When the soil moisture reaches a given\
    \ threshold, the\nfarmers receive an alert from the system. In this case, the\
    \ ontology is not published; therefore, it is\nimpossible to reuse it.\nTo our\
    \ point of view, the most successful CAS dedicated to irrigation is the one developed\
    \ during\nthe PLANTS project [9]. This system is installed in a greenhouse. It\
    \ uses several types of sensors to\nobserve raspberry plants. This system can\
    \ control watering equipment to control irrigation in the four\nzones of the greenhouse.\
    \ The PLANTS ontology aims to describe e-entities and their interactions [9,10].\n\
    An e-entity is a virtual representation of a physical object that can be either\
    \ a raspberry plant or\nequipment. Every measurement is deﬁned as the parameter\
    \ of an e-entity. Sensor streams are not\naggregated. The last measurements are\
    \ used to update a parameter. The rules are used to derive the\nstates of raspberry\
    \ plants from various parameters. Watering equipment is controlled by the detection\n\
    of “drought stress” in a speciﬁc zone. Thus, the only part of the ontology that\
    \ we want to reuse is the\nplant state hierarchy. Unfortunately, this ontology\
    \ is unavailable on the Web because it is the schema\nof the facts-base implemented\
    \ in the Jess inference engine.\nTo conclude, while several works focus on processing\
    \ sensor streams and computing aggregations,\ntheir results are not directly reusable,\
    \ as our approach should handle the temporal and spatial\naggregation of sensor\
    \ streams for the irrigation use case. Additionally, the ontologies mentioned\n\
    in previous works are either unavailable online or their domain is loosely related\
    \ to our use case.\n3. Background Information\nThis smart irrigation system is\
    \ based on a CAS and the IRRINOV® method. First, the cycle of\nprocesses implemented\
    \ in a CAS provides an overview of the global system: its devices, its phases\
    \ of\nAppl. Sci. 2020, 10, 1803\n4 of 41\nprocesses and the transformation from\
    \ data to context. Second, the IRRINOV® method speciﬁes the\nrequirements of the\
    \ system and the basic algorithm for making decisions.\n3.1. Cycle of Processing\
    \ Dedicated to CAS\nIn irrigation, a CAS has three speciﬁc components. First,\
    \ a WSN plays the role of sensing and\nmonitoring the plot environment. Second,\
    \ a DSS can (1) send notiﬁcations to farmers to support them\nin their decision-making\
    \ process and (2) automatically make decisions and control the watering system.\n\
    Third, watering devices are in charge of watering the soil in the ﬁeld.\nThe CAS\
    \ processes can be grouped and represented as a cycle of processes [11]. This\
    \ cycle is\ncalled the CAS life cycle. It is divided into four phases: (1) acquisition,\
    \ (2) modeling, (3) analysis, and\n(4) exploitation. Please note that this section\
    \ improves our previous work about CAS life cycle [12] by\ndecreasing the number\
    \ of phases. The exchange between two phases can consist of data, the low-level\n\
    context or the high-level context. The CAS life cycle for smart irrigation is\
    \ depicted in Figure 1. The four\nphases of its life cycle are described as follows.\n\
    Exploitation\nphase\nAcquisition\nphase\nModeling\nphase\nAnalysis\nphase\nData\n\
    Low-level\ncontext\nExternal \ndata\nsources\nData\nExternal \nsystems\nInformation\n\
    Data\nHigh-level\ncontext\nWatering\ndevice\nWireless Sensor \nNetwork\nFigure\
    \ 1. Life cycle of a smart irrigation CAS.\n•\nAcquisition phase focuses on how\
    \ the system retrieves and processes measurements from sensor\ndevices and data\
    \ from external data sources. The output of this phase are measurements and\n\
    related data derived after raw data cleaning processes.\n•\nModeling phase focuses\
    \ on the data model and the integration of input data into the system.\nThe system\
    \ is equipped with a storage service. The input data are organized with a common\n\
    data model to become the low-level context. As shown in Figure 1, the input of\
    \ this phase is data\nderived from the acquisition phase. The output of this phase\
    \ is the low-level context. This paper\nconsiders ontologies as a candidate for\
    \ the data modeling process.\n•\nAnalysis phase focuses on the transformation\
    \ from the low-level context into the high-level\ncontext. The high-level context\
    \ is an enrichment of the context with qualitative data. Such\ndata summarize\
    \ the situation of entities and support the decision process. The system uses\
    \ a\nrules-based inference engine for the reasoning process. As shown in Figure\
    \ 1, the input of this\nphase is the low-level context. The output of this phase\
    \ is the high-level context. This paper\nconsiders Drools (https://www.drools.org/)\
    \ as a candidate for the inference engine.\n•\nExploitation phase focuses on the\
    \ use of the high-level context to distribute them to\ncorresponding agents, which\
    \ can be other devices or users. The input of this phase is the\nhigh-level context.\
    \ The output of this phase can be human-readable content, a message to an\nexternal\
    \ system or a reaction of a watering device to the environment.\nAppl. Sci. 2020,\
    \ 10, 1803\n5 of 41\n3.2. IRRINOV® Method\nThis subsection presents the IRRINOV®\
    \ (All versions of the IRRINOV® method are available\nat http://www.irrinov.arvalisinstitutduvegetal.fr/irrinov.asp)\
    \ method. This method, developed by\nArvalis and its partners, proposes a guide\
    \ to make irrigation decisions based on measurements of soil\nmoisture sensors\
    \ and pluviometers oriented to farmers. The method aims at answering the following\n\
    questions: (1) When should irrigation be started, or when should watering devices\
    \ be installed on the\nplot? (2) When should we start each watering cycle (“Watering\
    \ cycle” is the action of an irrigation\nsystem performing a watering activity\
    \ on all the plots engaged in the system. “Watering cycle duration”\nis the number\
    \ of days between two consecutive waterings of the same plot)? (3) When should\
    \ irrigation\nbe stopped, or when should farmers withdraw the watering devices?\n\
    A set of decision tables and recommendations are provided by IRRINOV® method to\
    \ allow\nfarmers to manage their irrigation system on a single plot. Numerous\
    \ variants of the method are\nproposed depending on the soil, plot and crop types.\
    \ This work uses the IRRINOV® method for the\nregion Midi-Pyrénée, which is dedicated\
    \ to maize crop plants on clay-limestone soil [13] and includes\nthe following\
    \ measuring equipment:\n•\nOne IRRINOV® measuring station composed of six Watermark\
    \ (https://www.irrometer.com/\nsensors.html#wm) probes that measure the soil water\
    \ tension (tensiometer). Three Watermark\nprobes should be placed at 30 cm depth\
    \ in the soil, and the other three should be placed at 60 cm\ndepth in the soil.\
    \ Figure 2 illustrates the prototype of the IRRINOV® station.\n•\nOne mobile pluviometer\
    \ that measures the amount of water received by the crop during a\nwatering.\n\
    •\nOne weather station with a pluviometer to measure the quantity of water received\
    \ by the crop\nduring a rainfall.\nPluviometer\nMonitor box \nIRRINOV station\n\
    Soil sensor at 30cm depth\nSoil sensor at 60cm depth\nFigure 2. Prototype of the\
    \ IRRINOV® station.\nMore information about IRRINOV® method is available at [12].\
    \ The goal of this section is to\nillustrate the processing deﬁned un previous\
    \ section. The IRRINOV® method speciﬁes the time needed\nto install the devices\
    \ on the plot. The IRRINOV® station and the mobile pluviometer should be placed\n\
    in the plot when the crop reaches growth stage V2 (V2, V7, R1, and R5 are the\
    \ code names of maize\ngrowth stages deﬁned in [14]. They are respectively named\
    \ “7 leaf”, “10 leaf”, “silking” and “dent\nstage with 50% moisture” in the Arvalis\
    \ growth stage classiﬁcation.). The measurements can start two\nor three days\
    \ after installation. The Watermark probes are typically read once a week, but\
    \ during dry\nweather, farmers can check the probes more frequently, for example,\
    \ one observation per day. Irrigation\nshould stop when the crop reaches the growth\
    \ stage R5hg45. Please note that state R5 is deﬁned in [14];\nhowever, the state\
    \ R5hg45 is deﬁned in this project. This state means that the crops have moisture\
    \ dents\nequivalent to 45%. The IRRINOV® method speciﬁes the constraints to validate\
    \ the measurements\nof Watermark probes. Those treatments are part of the acquisition\
    \ phase. If the difference between\nthe probe measurements is above 30 cbar, then\
    \ one of the probes is malfunctioning, and the farmer\nshould visit the ﬁeld to\
    \ correct the probe installation. The value read on a Watermark probe must\nbe\
    \ multiplied by the correction coefﬁcient, which is speciﬁc for each batch of\
    \ probes. For example,\nAppl. Sci. 2020, 10, 1803\n6 of 41\nprobes from 2013 have\
    \ a correction coefﬁcient equal to 1.0. In this paper, we call the former value\
    \ a\nraw data value. The latter value after this process is the measurement value.\
    \ Please note that when\nthe measurement value is 199 cbar, the IRRINOV® method\
    \ considers that there is a contact problem\nbetween the Watermark probe and the\
    \ soil. The measurement value represents the soil tension and has\nthe cbar unit.\
    \ It is part of the output of the acquisition phase.\nThe IRRINOV® method relies\
    \ on decision tables to determine when to start a watering cycle\ndepending on\
    \ the soil moisture measurements and crop growth stage. An example of table that\n\
    determines when to start a watering cycle for clay-limestone soil is provided\
    \ in Table 1 which is, in fact,\napplied to maize crops when their growth stage\
    \ is between V2 and V7. The decision table indicates that\nthe farmer should start\
    \ the ﬁrst watering cycle when the median value of three probe measurements\n\
    reach a given threshold.\nTable 1. Decision table of the relation of the watering\
    \ cycle duration and the soil moisture for maize at\ngrowth stage V2.\nWatering\
    \ cycle duration\n9 to 10 days\n6 to 8 days\nbelow 5 days\nMedian of 30 cm depth\
    \ probes\n30 cbar\n50 cbar\n60 cbar\nMedian of 60 cm depth probes\n10 cbar\n20\
    \ cbar\n20 cbar\nSum of the median of 30 cm depth probes\nand the median of 60\
    \ cm depth probes\n40 cbar\n70 cbar\n80 cbar\nThe second column of the above decision\
    \ table should be read as “If the plot has a watering cycle\nduration ﬁxed between\
    \ 9 and 10 days”, and one of the two following conditions is satisﬁed:\n(1)\n\
    “When the median value of three probe measurements at 30 cm depth are above the\
    \ 30 cbar\nvalue” and “when the median value of three probe measurements at 60\
    \ cm depth are above the\n10 cbar value”.\n(2)\n“When the total (sum of the median\
    \ of 30 cm depth measurements and the median of 60 cm depth\nmeasurements) is\
    \ above 40 cbar”.\nThen, a watering cycle should start.\nThis project translates\
    \ all the decision tables into rules to transform the manual IRRINOV® method\n\
    into an automatic DSS. Those processing are part of the analysis phase. The exploitation\
    \ phase will\ntranslate the irrigation decision into a command executable by the\
    \ watering device.\n4. CAS Development\nThe development methodology used to develop\
    \ the smart irrigation CAS is the mini-waterfall\nmethodology [15]. Additionally,\
    \ CASO and IRRIG ontologies have been developed following the\nlinked open terms\
    \ (LOT) methodology [16].\nA mini-waterfall is a methodology used for system engineering.\
    \ It is inspired by the well-known\nwaterfall methodology, which develops a system\
    \ in ﬁve activities: (1) speciﬁcation, (2) design, (3)\nimplementation, (4) testing\
    \ and (5) maintenance. The purpose of the mini-waterfall methodology is to\nrepeat\
    \ the sequence of the ﬁve activities multiple times to develop the system progressively.\n\
    LOT is a methodology used for ontology engineering. It was ﬁrst proposed in [16]\
    \ and further\ndeveloped at [17]. LOT is inspired by agile techniques in which\
    \ sprints aim to align ontology\ndevelopment with software development agile practices.\
    \ This methodology focuses on (1) the reuse\nof terms (classes, properties and\
    \ attributes) existing in already published vocabularies or ontologies\nand (2)\
    \ the publication of the ontology following the linked data principles. LOT relies\
    \ on the\nontological engineering activities deﬁned in the NeOn methodology [18]\
    \ when available. LOT deﬁnes\niterations over the following four activities: (1)\
    \ ontological requirements speciﬁcation, (2) ontology\nimplementation, (3) ontology\
    \ publication, and (4) ontology maintenance.\nAppl. Sci. 2020, 10, 1803\n7 of\
    \ 41\nFigure 3 illustrates the smart irrigation CAS development methodology combined\
    \ with the\nontology development methodology. Ontology development has a life\
    \ cycle called the LOT life\ncycle. The LOT life cycle is presented by the dashed\
    \ yellow box. Each activity in this life cycle is\nrepresented by a solid yellow\
    \ box. The solid black arrows between the boxes show the order of the\nactivities;\
    \ for example, the development team must perform the ontological requirements\
    \ speciﬁcation\nactivity before the ontological implementation activity. The CAS\
    \ development life cycle is called a\nmini-waterfall life cycle. It is presented\
    \ by the dashed blue box. Each activity in this life cycle is\nrepresented by\
    \ a solid blue box. The solid yellow arrow between one activity X in the LOT life\
    \ cycle\nand one activity Y in a mini-waterfall life cycle means that the result\
    \ of activity X is necessary to\nimplement activity Y. For example, the design\
    \ activity of the mini-waterfall cycle requires the result of\nthe ontology conceptualization\
    \ activity of the LOT life cycle. Otherwise, the dashed blue arrow from\none activity\
    \ Y of mini-waterfall to one activity X of LOT life cycle means that the result\
    \ of the activity\nY can contribute to activity X. It is necessary to note two\
    \ items in this methodology. First, the LOT life\ncycle is triggered by the mini-waterfall\
    \ life cycle, but it is independent of the mini-waterfall life cycle.\nConsequently,\
    \ the LOT life cycle can be shorter than the mini-waterfall life cycle. Suppose\
    \ that after\neach development life cycle, there is a new version. Therefore,\
    \ there is nothing to prevent the ontology\nfrom having three versions at the\
    \ same time, but the system can only have one version. Second, after\nthe maintenance\
    \ activities of both the LOT life cycle and CAS life cycle, the development team\
    \ renews\nthe sequence, i.e., starts with the ﬁrst activity. However, they can\
    \ skip the current activity if they ﬁnd\nthat the last time result of the same\
    \ activity is sufﬁcient.\nSpecification\nDesign\nImplementation\nTesting\nOntological\n\
    requirements\nspecification\nOntological implementation\nOntology\nConceptualization\n\
    Ontology \nmaintenance\nMini-waterfall\nLOT\nOntology\nEncoding\nOntology\nEvaluation\n\
    Maintenance\nOntology \npublication\nFigure 3. Mini-waterfall combined with LOT\
    \ methodology to develop a system.\nThe speciﬁcation activity analyzes and identiﬁes\
    \ all the requirements for the system and the\nassociated ontology (global data\
    \ schema). In the design activity, the system uses a network of ontologies\nto\
    \ model the results of all data processing. Therefore, ontology implementation\
    \ is part of the system\ndesign. In the CAS implementation activity, the system\
    \ imports the ontologies. The result after a CAS\nimplementation activity contributes\
    \ to the ontology evaluation activity. If the CAS is implemented,\nthen the ontologies\
    \ cover all the requirements. The ontologies should be available in public URIs\n\
    through ontology publication. Ontology evaluation and system testing are necessary\
    \ to guarantee that\nthe system works correctly. Finally, the system and the ontologies\
    \ are maintained.\nAppl. Sci. 2020, 10, 1803\n8 of 41\nDuring the speciﬁcation\
    \ activity, we identify several sensor streams to be processed. The next\nactivities\
    \ of the mini-waterfall methodology (design, implementation and testing) were\
    \ applied on one\nstream at a time to cover all the requirements. Then, a global\
    \ algorithm was implemented that merges\nall the results of the stream processing.\n\
    4.1. CAS Speciﬁcation\nFirst, it is necessary to present the resources for system\
    \ development. All the requirements of the\nsystem are extracted from the following\
    \ resources:\n•\nThe IRRINOV® method version for the region Midi-Pyrénée, France.\n\
    •\nThe Arvalis dataset: real experimental data from Arvalis and INRAE (INRAE (French\
    \ National\nResearch Institute for Agriculture, Food and Environment) was founded\
    \ on 01/01/2020 from the\nfusion between INRA and IRSTEA. It supports the profound\
    \ changes in agriculture, food and the\nenvironment in France, Europe and around\
    \ the world through its research activities.). This is an\nexcel ﬁle that contains\
    \ recorded daily observations and activities of farmers in a maize plot T1 B1\
    \ -\nDKC4814 from 14/06/2013 to 06/10/2013 in Gaillac, France. Please note that\
    \ the observations\nrecorded in the Arvalis dataset are the daily aggregated values\
    \ of the sensor measurements. In\nother words, the data in the dataset are already\
    \ processed from the raw measurements.\n•\nFarming journal (“Carnet de Terrain”\
    \ in French): a document that contains several tables to record\nall the precise\
    \ observations related to the plot. It is a kind of experimentation journal that\
    \ was\nused frequently in research laboratories.\n•\nExperiences and knowledge\
    \ from specialists in the agriculture domain. The specialists are from\nArvalis\
    \ and INRAE.\nThis subsection focuses on two requirements: the data modeling requirement\
    \ and the processing\nrequirement. The data modeling requirement is needed for\
    \ developing ontologies. The processing\nrequirement is used to identify the type\
    \ of processing applied on the sensor streams (cleaning,\naggregation, comparison).\n\
    4.1.1. Ontology Requirement\nFirst, the IRRINOV® documentation [13] was studied\
    \ to identify the following:\n•\nThe type of sensors used and their measurements.\n\
    •\nThe data needed to make the decision: type of soil, type of crop, sowing date,\
    \ sensor localization\nand depth, quantity of rain per day, evolution of crop\
    \ growth stage, and moisture measurements\nat different depths.\n•\nThe different\
    \ processes applied to the sensor measurement streams, such as data cleaning,\
    \ spatial\nand temporal aggregation, and threshold comparison.\n•\nThe different\
    \ decisions produced by the method.\nSecond, it was necessary to communicate with\
    \ specialists of Arvalis and INRAE to clarify the\nIRRINOV® method. Some of the\
    \ questions formulated to the experts were as follows: What is the\ndifference\
    \ between an irrigation period and a watering cycle? What are the possible values\
    \ of maize\ngrowth stages? How are we to observe a growth stage?\nThird, to generalize\
    \ the system, it was necessary to derive standard deﬁnitions and concepts in\n\
    the agriculture domain. This work was carried out by querying a web retrieval\
    \ system. The selected\nresources were articles referenced in publications and\
    \ from well-known organizations. For example,\nthe different maize growth stages\
    \ are deﬁned in a publication from the University of Iowa [14].\nFourth, the analysis\
    \ of the Arvalis dataset provided a better understanding of the computing\nprocesses\
    \ on sensor measurements, as well as the experimental details such as the type\
    \ of soil and the\ncode names of the sensors.\nAppl. Sci. 2020, 10, 1803\n9 of\
    \ 41\nThe ﬁrst analysis enabled this system to deﬁne several process workﬂows\
    \ corresponding to the\ntype of sensor measurement stream. A workﬂow deﬁnes the\
    \ aggregations (or any mathematical\nfunctions) and deductions applied on the\
    \ streams. An example of temporal aggregation is the\ncomputation of the average\
    \ on a 24-h window applied on a soil moisture stream produced by one\nprobe. Then,\
    \ the aggregation results are conceptualized into a property of an observed phenomenon.\n\
    This system considers four main sensor streams described by observed phenomena\
    \ and associated\nproperties: (1) the moisture of the soil, (2) the quantity of\
    \ rain, (3) the growth stage of the crop, and (4)\nthe water need state of the\
    \ crop.\nMoreover, from the ﬁrst analysis, an ontology requirement speciﬁcation\
    \ about the smart\nirrigation CAS was generated. These speciﬁc requirements were\
    \ written as a competency questions\ndocument. An online spreadsheet (The spreadsheet\
    \ is available on the GitLab repository of this project\nhttps://gitlab.irstea.fr/irrig/public/tree/master/CompetencyQuestions)\
    \ was deﬁned to share them.\nIt contains the following ﬁelds:\n•\nThe identiﬁed\
    \ code of requirements.\n•\nThe competency questions written in natural language.\
    \ Various forms of the question were\nwritten to generalize them.\n•\nSome examples\
    \ of answers to identify the domain value.\n•\nThe explanation of the answer.\n\
    •\nThe references of the vocabulary deﬁnitions.\nFigure 4 presents an excerpt\
    \ of the current competency questions.\nPlease note that these\ncompetency questions\
    \ are a large table with many columns and rows; we only show an excerpt\nas an\
    \ illustration. For example, CQ1.1 expresses the need to know the type and brand\
    \ of each sensor.\nCQ1.3 expresses the need to deﬁne the type of sensor streams\
    \ used as inputs in the IRRINOV® method.\nFigure 4. Screenshot of a part of the\
    \ competency questions document containing the questions and\nanswers from CQ1.1\
    \ to CQ1.4.\n4.1.2. Processing Requirement\nIn studying the IRRINOV® method, we\
    \ noticed that the irrigation decisions proposed by this\nmethod are based on\
    \ several aggregation measurements: temporal aggregation and spatial aggregation.\n\
    We notice that the decision workﬂows of processes follow the same pattern: provide\
    \ a stream of sensor\nmeasurements, aggregate certain sensor measurements extracted\
    \ from the stream, and then compare\nthe aggregation results to a threshold. The\
    \ thresholds enable us to deﬁne certain states. A state is\nqualitative data of\
    \ a property that characterizes the observed phenomenon. The goal of the rules\
    \ is\nto determine the state of each property. The design activity goal will be\
    \ to translate each statement\nin decision tables and the associated threshold\
    \ into one or several reasoning rules. The speciﬁcation\nrequirements activity\
    \ identiﬁes each process belonging to one workﬂow dedicated to one stream and\n\
    Appl. Sci. 2020, 10, 1803\n10 of 41\ndetermines its input, its output and its\
    \ parameters (thresholds). For example, the workﬂow dedicated\nto the soil moisture\
    \ stream starts with a measurement process from a soil tensiometer probe. Then,\n\
    those measurements are the input data of a sequence of aggregation processes.\
    \ The last aggregation\nvalue is compared to a threshold to produce a state of\
    \ a soil moisture entity. This example is precisely\noutlined in Section 5.\n\
    Second, the Arvalis dataset provided the parameters to precisely determine the\
    \ aggregation\nprocesses used in the IRRINOV® method. Examples of such information\
    \ are the watering cycle\nduration and the threshold for soil moisture.\n4.2.\
    \ CAS Design\nThis subsection focuses on explaining the conceptualization process\
    \ of the ontologies. Later,\nthe system design describing how to use the ontologies\
    \ for data modeling is presented.\n4.2.1. Ontology Conceptualization\nFirst, the\
    \ ontology requirements speciﬁcation was oriented to the development of one ontology\n\
    to support the smart irrigation CAS. However, it should be noted that a general\
    \ part of the ontology\ncould be reusable for other use cases; therefore, we decided\
    \ to materialize the implementation in\ntwo ontologies, CASO and IRRIG. In the\
    \ following, a typical approach for the conceptualization is\ndetailed, and then\
    \ the decisions about the ontology modularization used to create CASO and IRRIG\
    \ are\ndescribed. Please note that our ontologies have already studied well-known\
    \ ontologies about sensor\nmeasurements [12]. They choose to reuse SSN since this\
    \ ontology provides a precise description of\nmeasurements based on data modeling\
    \ patterns. SSN deﬁnes several patterns that help to understand\nthe data modeling\
    \ issues.\nThe ﬁrst step towards a conceptualization was to identify from the\
    \ competency questions\ndocument those ontology elements that needed to be represented.\
    \ More precisely, this step was\ncarried out in the following order:\n•\nIdentiﬁcation\
    \ of concepts: We want to model all the processes applied to sensor streams. They\n\
    are mainly aggregations and threshold comparisons. The goal of the comparison\
    \ is to derive\nqualitative (symbolic) data. To differentiate quantitative from\
    \ symbolic computation, we need\nto use deduction. A deduction provides qualitative\
    \ data as a result. These results are the entity\nstates that should be deﬁned\
    \ in some referential item. For example, maize growth stages are\nstates deﬁned\
    \ in a certain thesaurus. In most cases, the state of an entity is derived because\
    \ one\nvalue is above or below a threshold. We model thresholds as state boundaries.\n\
    •\nIdentiﬁcation of relations: To characterize a deduction, we need two new relations:\
    \ (1) a relation\nthat links a deduction to its resulting state and (2) a relation\
    \ that links a deduction to the period\nwhen this deduction is valid, i.e., the\
    \ period when the entity is associated with a state.\n•\nIdentiﬁcation of cardinality\
    \ restrictions applied for relations: This step also involves a decision on\n\
    whether the relation at hand should be deﬁned as functional. For example, the\
    \ relation between\na deduction and its result is functional. A deduction has\
    \ only one result: the state of the entity\nderived by the deduction.\n•\nIdentiﬁcation\
    \ of individuals: Following the SSN pattern, these entities are characteristics\
    \ of the\nfeature of interest [3]. They are modeled as an instance of the class\
    \ ssn:Property, which are linked\nto an instance of the class sosa:FeatureOfInterest\
    \ by the object property ssn:hasProperty. To\nspecialize an SSN to the irrigation\
    \ use case, the involved properties in the use case, for example,\nair temperature\
    \ or crop stage, have been deﬁned as instances of properties.\nNext, ontologies\
    \ and particular ontology elements were identiﬁed to be reused. The following\n\
    selected ontologies have been developed and maintained by standardization organizations.\n\
    •\nThe W3C & OGC Semantic Sensor Network (SSN) ontology describes sensors, observations,\n\
    samples and actuators [3].\nAppl. Sci. 2020, 10, 1803\n11 of 41\n•\nSmart Appliances\
    \ REFerence (SAREF) (http://www.w3id.org/saref) is an ontology for smart\nappliances\
    \ that contributes to semantic interoperability in the IoT domain [4].\nThis ETSI\n\
    recommendation focuses on the representation of appliances and devices together\
    \ with their\nfunctions, commands, services, states and proﬁles (It is necessary\
    \ to mention that CASO and\nIRRIG reuse some concepts from SAREF and SAREF4AGRI,\
    \ which are unavailable in the latest\npublished versions of these ontologies,\
    \ but it is known by the authors that they will be available\nin the next versions.\
    \ SAREF4AGRI is an extension of SAREF for agriculture.).\n•\nThe W3C PROV ontology\
    \ represents provenance information [19].\n•\nThe W3C SKOS vocabulary describes\
    \ knowledge organization systems. It will be useful in\ndeﬁning properties and\
    \ their states [20].\n•\nThe W3C OWL-Time (http://www.w3.org/2006/time), an ontology\
    \ of temporal entities,\ndescribes the temporal properties of resources.\nAnother\
    \ well-known ontology reused in this conceptualization is the Ontology of Units\
    \ of Measure\nand Related Concepts (OM) [21].\nIn some cases, the reused ontology\
    \ elements matched the intended use in the developed ontology;\ntherefore, they\
    \ were adopted without modiﬁcation. Some examples of this case are the classes\n\
    sosa:Platform, sosa:FeatureOfInterest or om:Unit.\nHowever, in other cases, some\
    \ additional properties or constraints had to be added to the\nreused elements.\
    \ Then, a new subclass of reused concepts was created to attach the new semantics\n\
    to the subclasses created.\nFor example, the class caso:Observation is a specialization\
    \ of the\nclass sosa:Observation since sosa:Observation represents any computation\
    \ activity in general.\ncaso:Observation uses the object property prov:wasInformedBy\
    \ to identify the inputs of the\ncomputation. The class caso:Deduction is a specialization\
    \ of caso:Observation. A deduction is\nalso a computation or a measurement that\
    \ has a state for a result.\ncaso:hasClosedUpperBoundary\ncaso:hasOpenUpperBoundary\n\
    caso:hasClosedLowerBoundary\ncaso:hasOpenLowerBoundary\nsaref:has\nFunction\n\
    caso:State\n caso:hasResultState\nprov:wasInfluencedBy\ncaso:hasValidTime\ncaso:Deduction\n\
    caso:triggers\nFunction\ncaso:lesserThan\ncaso:lesserThanOrEqualTo\ncaso:greaterThan\n\
    caso:greaterThanOrEqualTo\nskos:Concept\nssn:Property\nsosa:observedProperty\n\
    sosa:FeatureOfInterest\ntime:TemporalEntity\nsosa:phenomenon\nTime\nom:hasUnit\n\
    sosa:Result\ncaso:hasState\n<<owl:subpropertyOf>>\nsosa:hasResult\nprov:used\n\
    caso:Observation\nprov:wasInformedBy\ncaso:Actuation\nsosa:resultTime:: xsd:dateTime\n\
    sosa:hasSimpleResult\nsosa:madeBySensor\nsosa:Observation\ncaso:Property\nssn:hasProperty\n\
    om:hasUnit\ncaso:boundaryValue\ncaso:Boundary\nsaref:Device\nsaref:Function\n\
    saref:Command\nsaref:isCommandOf\nsaref:hasCommand\nsosa:actsOnProperty\nsosa:madeByActuator\n\
    sosa:hasFeature\nOfInterest\nsosa:Actuation\nsosa:ObservableProperty\nsosa:ActuatableProperty\n\
    sosa:Sample\nLegend\nClass\nAttribute whose domain is the\nattached class\nobject\
    \ property applicable\nto attached class\nsubClassOf\nobject property with domain\n\
    and range definitions\n<<stereotype>>\nsosa:Sensor\nsaref:Actuator\nsaref:Sensor\n\
    sosa:Actuator\nsosa:hasFeature\nOfInterest\nsosa:isSampleOf\nUnion class (Anonymous)\n\
    U\nPrefixes\nowl: http://www.w3.org/2002/07/owl#\nsosa:http://www.w3.org/ns/sosa/\n\
    ssn: http://www.w3.org/ns/ssn/\nsaref: http://www.w3id.org/saref#\ntime: http://www.w3.org/2006/time#\n\
    om: http://www.ontology-of-units-of-measure.org/resource/om-2/\nprov: http://www.w3.org/ns/prov\n\
    skos: http://www.w3.org/2008/05/skos\nOntology\ncaso: https://w3id.org/def/caso#\n\
    U\nsosa:resultTime:: xsd:dateTime\nsosa:hasSimpleResult\nssn:System\nsosa:hosts\n\
    sosa:Platform\nom:Unit\nFigure 5. Overview of the CASO.\nAppl. Sci. 2020, 10,\
    \ 1803\n12 of 41\nFinally, the conceptualization was modularized into two ontologies:\
    \ CASO and IRRIG. The IRRIG\nontology imports and extends CASO. The CASO ontology\
    \ is illustrated in Figure 5. This IRRIG\nontology is depicted in Figure 6. The\
    \ entities deﬁned in the CASO and IRRIG ontologies are preceded\nby the preﬁxes\
    \ “caso” (yellow boxes) and “irrig” (blue boxes), respectively.\nThe goal of CASO\
    \ is to model any context processing. IRRIG is a specialization of CASO used to\n\
    describe all the context processing involved in the IRRINOV® method. For this\
    \ reason, it specializes\nsome elements of CASO, as shown in Figure 6. For example,\
    \ IRRIG specializes the class ssn:Property\nin different subclasses related to\
    \ moisture, stress, and growth. Several subclasses of caso:Observation\nspecify\
    \ different types of observations. Each subclass is dedicated to the observations\
    \ of one speciﬁc\ninstance of ssn:Property.\nsaref:has\nFunction\nsosa:madeBy\n\
    Sensor\nsosa:observed\nProperty\nsosa:hasFeatureOf\nInterest\nprov:wasInformedBy\n\
    prov:used\ncaso:Observation\ncaso:hasClosedUpperBoundary\ncaso:hasOpenUpperBoundary\n\
    caso:hasClosedLowerBoundary\ncaso:hasOpenLowerBoundary\ncaso:State\ncaso:hasResultState\n\
    caso:hasValid\nTime\ncaso:Deduction\nsosa:madeBy\nActuator\nsosa:actsOn\nProperty\n\
    sosa:hasFeatureOf\nInterest\nprov:wasInfluencedBy\ncaso:Actuation\ncaso:hasState\n\
    caso:Property\nom:hasUnit\ncaso:Boundary\nirrig:Soil30cmDepthDaily\nAverageMoistureObservation\n\
    irrig:RootZoneDaily\nMoistureObservation\nirrig:Soil60cmDepthDaily\nAverageMoistureObservation\n\
    om:Unit\nirrig:CropGrowth\nDeduction\nirrig:RootZoneMoisture\nLevelDeduction\n\
    irrig:CropWaterNeed\nDeduction\nsosa:hosts\nsosa:hosts\nsosa:Platform\nsosa:Sensor\n\
    ssn:hasProperty\nsosa:FeatureOfInterest\nssn:Property\ntime:TemporalEntity\nirrig:IrrigationActuation\n\
    sosa:hasResult\nom:hasUnit\nsosa:phenomenon\nTime\nsosa:resultTime:: xsd:dateTime\n\
    sosa:hasSimpleResult::\nsosa:Result\nsaref:Device\nsaref4agri:WateringValve\n\
    saref:Actuator\nsaref:Sensor\nsaref4agri:SoilTensiometer\nsaref4agri:Pluviometer\n\
    saref4agri:Thermometer\nsosa:Actuator\nsosa:Observable\nProperty\nsosa:Actuatable\n\
    Property\nirrig:MoistureProperty\nirrig:StressProperty\nirrig:GrowthProperty\n\
    irrig:CropGrowthState\nirrig:CropWaterNeed\nState\nirrig:RootZoneMoisture\nLevelState\n\
    irrig:RainIntensity\nBoundary\nirrig:RootZoneMoisture\nLevelBoundary\nPrefixes\n\
    owl: https//www.w3.org/2002/07/owl#\ncaso: https://w3id.org/def/caso#\nsosa:http://www.w3.org/ns/sosa/\n\
    ssn: http://www.w3.org/ns/ssn/\nsaref: http//www.w3id.org/saref#\nsaref4agri:\
    \ http//www.w3id.org/def/saref4agri#\ntime: http://www.w3.org/2006/time#\nom:\
    \ http://www.ontology-of-units-of-measure.org/resource/om-2/\nskos: http://www.w3.org/2008/05/skos#\n\
    Ontology\nirrig: https://w3id.org/def/irrig#\nLegend\nClass\nAttribute whose domain\
    \ is the\nattached class\nobject property applicable\nto attached class\nsubClassOf\n\
    object property with domain\nand range definitions\nirrig:soil30cmDepth\nMoistureObservation\n\
    irrig:Soil60cmDepth\nMoistureObservation\nom:hasNumericValue\ncaso:boundaryValue::\n\
    sosa:Observation\ncaso:triggers\nFunction\nsosa:Actuation\nsaref:hasCommand\n\
    saref:Function\nsaref:Command\nskos:Concept\nirrig:RainIntensityState\nirrig:RainIntensity\n\
    Deduction\nirrig:IntensityProperty\nirrig:RainQuantity\nObservation\nirrig:RainDailyTotal\n\
    QuantityObservation\nirrig:CropGrowth\nObservation\nssn:System\nsosa:Sample\n\
    sosa:is\nSampleOf\nsaref:hasManufacturer:: xsd:string\nsaref:hasName:: xsd:string\n\
    saref:hasModel:: xsd:string\nirrig:irrigationDelay\nObservation\nFigure 6. Overview\
    \ of the IRRIG ontology.\nDuring the conceptualization phase, several versions\
    \ of the ontology model are produced and\nstored in a private repository of INRAE.\
    \ Figures 5 and 6 are parts of the lastest version (v201912).\n4.2.2. System Design\n\
    Two main steps used to model the smart irrigation CAS are (1) to identify the\
    \ entities needed to\nmodel and (2) to choose the appropriate vocabulary and relation\
    \ from CASO and IRRIG to model the\ndetermined entities.\nFirst, we determined\
    \ the entities needed to model the smart irrigation CAS. The following\nvocabulary\
    \ should be considered entities:\n•\nFeature of interest is the natural phenomenon\
    \ observed by sensors.\n•\nThe property of the feature of interest can be a quantitative\
    \ property (a sensor measurement or\naggregation) or a qualitative property (a\
    \ state that is a result of threshold comparison).\n•\nData processing actions\
    \ and the actor that executes the action. The data processing may be a\nmeasurement,\
    \ an aggregation or an inference.\nAppl. Sci. 2020, 10, 1803\n13 of 41\n•\nResult\
    \ and the time related to the action.\nThe action could be a measurement, aggregation\
    \ or deduction (threshold comparison or inference).\nOn the one hand, the result\
    \ of a deduction should be qualitative data that are a state of the entity. On\n\
    the other hand, the result of the measurement and aggregation is numerical data.\n\
    Table 2 shows a list of entities needed to model. This table contains six columns:\n\
    •\nWorkﬂow: there are four streams deﬁned in this project: (1) crop growth, (2)\
    \ crop water need, (3)\nsoil moisture, and (4) rain quantity. Each stream speciﬁes\
    \ a dedicated workﬂow of processes.\n•\nFeature of interest: the phenomenon that\
    \ needs to be observed: crop, rain, soil, etc.\n•\nProperty: the aspect of the\
    \ phenomenon that needs to be observed.\n•\nType of action: could be a measurement,\
    \ an aggregation or a deduction.\n•\nActor: depending on the type of action, an\
    \ actor could be a sensor, a software component that\nimplements an aggregation,\
    \ or an inference engine for the deduction.\n•\nType of result: could be a state\
    \ or a numeric value.\nTable 2. List of features of interest, properties and actors\
    \ that require modeling.\nWorkﬂow\nFeature of\nInterest\nProperty\nType of\nAction\n\
    Actor\nType\nof\nResult\nCrop growth\nCrop\nGrowth\nMeasurement\nHuman\nState\n\
    Growth\nDeduction\nInference engine\nState\nCrop water\nneed\nWater Need\nDeduction\n\
    Inference engine\nState\nSleeping\nSleeping duration\nAggregation\nComponent that\
    \ gets\nthe sleeping duration\nNumeric\nSoil moisture\nSoil at 30 cm\ndepth\n\
    Moisture at 30 cm\ndepth\nMeasurement\nSoil tensiometer\nNumeric\nDaily\naverage\n\
    moisture at 30 cm\ndepth\nAggregation\nComponent that gets\ndaily\naggregated\n\
    moisture\nNumeric\nSoil at 60 cm\ndepth\nMoisture at 60 cm\ndepth\nMeasurement\n\
    Soil tensiometer\nNumeric\nDaily\naverage\nmoisture at 30 cm\ndepth\nAggregation\n\
    Component that gets\ndaily\naggregated\nmoisture\nNumeric\nRoot zone\nDaily\n\
    average\nmoisture at root\nzone\nAggregation\nComponent that gets\ndaily\naggregated\n\
    moisture\nNumeric\nRoot\nzone\nmoisture level\nDeduction\nInference engine\nState\n\
    Rain quantity\nRain\nRain quantity\nMeasurement\nPluviometer\nNumeric\nDaily total\
    \ rain\nquantity\nAggregation\nComponent\nthat\ngets daily total rain\nquantity\n\
    Numeric\nIntensity\nDeduction\nInference engine\nState\nDelay\nDelay duration\n\
    Aggregation\nComponent that gets\nthe number of delay\ndays\nNumeric\nIn this\
    \ table, in addition to the entities related to the agricultural phenomenon, it\
    \ is essential to\nmention the two other entities: sleeping and delay. Sleeping\
    \ is the period after a watering action of one\nplot. No more watering action\
    \ is applied on this plot during the sleeping period. Delay is the period\nwhen\
    \ a watering action is postponed due to a rain event.\nAppl. Sci. 2020, 10, 1803\n\
    14 of 41\nThe second step of the CAS modeling is to select the vocabulary in CASO\
    \ and IRRIG to model\nthe entities. In CASO and IRRIG, the features of interest,\
    \ properties and state of properties were\npredeﬁned. Thus, the remaining work\
    \ creates the individuals for the appropriate actions, numeric\nresults, actors\
    \ and time that relate to the corresponding feature of interests and properties.\n\
    The list of modeled entities and their associated processes deﬁned from the above\
    \ analysis enabled\nus to design part of the CAS. To design inference processes\
    \ (the rules), we build a state diagram for\neach workﬂow. This diagram presents\
    \ the conditions for a property reaching a state. Moreover, this\nindicates the\
    \ behavior of the system after the property reaches the state. The state diagram\
    \ uses a set\nof information:\n•\nList of the states for the concerned property.\n\
    •\nThe conditions under which that property can reach a state.\n•\nThe actions\
    \ of the system after the property reaches the state.\nTo design the state change\
    \ of certain properties, we selected the UML state diagram. First, we\ndrafted\
    \ the state changes in chronological order. Based on this ﬁrst draft, we designed\
    \ the conditions\nof state changes based on the IRRINOV® decision table. Then,\
    \ we checked each set of conditions to\nmake them independent. The goal was to\
    \ have the same set of conditions always reach the same state\nvalue. In the end,\
    \ the state diagram took into account synchronization issues between the new sensor\n\
    measurements, the aggregation processes and the state changes. For that reason,\
    \ an Init state was\ncreated in each state diagram to represent a synchronization\
    \ point for daily computation. Moreover,\neach state diagram has a clock to manage\
    \ the synchronization between all the processes.\nSection 5.1.4 presents the lastest\
    \ version of the state diagram related to the RootZoneMoistureLevel\nproperty.\
    \ The conditions of the state diagram will be translated into semantic web rule\
    \ language\n(SWRL) rules during the implementation activity.\n4.3. CAS Implementation\n\
    This subsection presents the process used to transform the model of the ontologies\
    \ and the system\ninto software products using encoding languages.\n4.3.1. Ontology\
    \ Encoding\nOnce the models were designed, the two ontologies were encoded in\
    \ OWL [22] using Protégé [23].\nThe implementation of the ontologies included\
    \ the declaration of metadata such as authors, dates,\nand licenses, according\
    \ to [24]. The OWL code of the ontologies is available on two distinct GitHub\n\
    repositories. The current implementation of CASO contains 27 classes, 40 object\
    \ properties and 4\ndatatype properties reusing the SOSA, SSN, SKOS, SAREF, PROV,\
    \ Time, and OM ontologies. The\nIRRIG ontology imports CASO and extends it with\
    \ 31 classes, 4 properties and 71 individuals to model\nthe irrigation use case\
    \ states, properties and features of interest. Among them, four classes and three\n\
    datatype properties are reused from SAREF4AGRI.\n4.3.2. System implementation\n\
    This project developed a program called Ontogen. This program was written in Python\
    \ and Java.\nIn the Arvalis use case, Ontogen takes as input speciﬁc sensor measurements\
    \ provided by Arvalis in\nan Excel ﬁle and produces the output as the state of\
    \ CropWaterNeed property. The program itself can\nbe divided into three modules:\n\
    •\nVirtual sensors: read data from Excel ﬁles.\n•\nAggregators: run functions\
    \ to produce aggregated data.\n•\nInference engine: The core is OWLAPI (https://github.com/owlcs/owlapi)\
    \ and SWRLAPI\n(https://github.com/protegeproject/swrlapi). This module uses a\
    \ set of SWRL rules, and all the\ndata provided from the previous module to infer\
    \ the high-level context.\nAppl. Sci. 2020, 10, 1803\n15 of 41\nThe aggregations\
    \ are encoded in Python as a function. The deductions are executed by the\nSWRLAPI\
    \ Drool inference engine integrated into Ontogen. In detail, the reasoning process\
    \ of the\ninference engine in Ontogen can be explained as follows. First, Ontogen\
    \ generates an OWL ﬁle\nthat contains all the individuals and the IRRIG ontology\
    \ necessary for the rule engine; it creates\nall the individuals that describe\
    \ sensor measurements. It also creates the individuals, instances of\ncaso:Deduction,\
    \ necessary to deﬁne the daily deduction per instance of the class caso:Property.\
    \ The\nﬁle name is the concatenation of the feature of interest name and the beginning\
    \ date. Second, it\nlaunches the Drools rule engine and applies it to the individuals\
    \ previously created. The Drools engine\nupdates the caso:Deduction instance.\
    \ It links an instance of the class caso:State with an instance of\ncaso:Deduction\
    \ via the object property caso:hasResultState. Then, it creates a new OWL ﬁle\
    \ that\ncontains the results of the inference engine. The OWL ﬁle is updated from\
    \ the previous ﬁle. The\nrule for Drools is coded in SWRL. There are a total of\
    \ 25 rules in SWRL and two queries in semantic\nquery-enhanced web rule language\
    \ (SQWRL):\n•\n5 rules for crop growth.\n•\n1 rule for rain intensity.\n•\n1 rule\
    \ for root zone soil moisture level.\n•\n16 rules for crop water need.\n•\n2 SQWRL\
    \ queries for the results after the reasoning.\nEach rule is put in a rule ﬁle\
    \ with a “.rule” extension. The rule ﬁles are available on the GitLab\nrepository\
    \ of INRAE via the following link https://gitlab.irstea.fr/irrig/public/tree/master/Rule.\n\
    The DSS consists of (1) a knowledge base and an inference engine, mostly for high-level\n\
    context inference, and (2) several functions for numeric data calculation.\nExcept\
    \ for the case\nof SleepingDuration, it is a numeric value, but the inference\
    \ engine produces its value.\nThe\nknowledge-base contains a rules-base and a\
    \ facts-base. Technically speaking, the DSS is a part\nof the Ontogen program.\
    \ Each day, the DSS takes phenomenon observations as input and produces an\nirrigation\
    \ decision. Please note that the Arvalis dataset does not provide the sensor measurements\
    \ but\nthe daily aggregated values of those measurements.\nFigure 7 shows the\
    \ algorithm implemented by the DSS. At 06:00:00 on day d, the system triggers\n\
    the DSS to start the computation. First, the DSS retrieves the observations relevant\
    \ to days d-1 and\nd recorded in the Arvalis dataset. Please note that in the\
    \ algorithm of Figure 7, the data retrieved at\nthe instant [d 06:00:00] belong\
    \ to the period [d-1 00:00:00, d 06:00:00]. The DSS checks the\nvalue of the evaluation\
    \ of the CropGrowth property of day d-1. As the IRRINOV® method is valid\nonly\
    \ when the state of CropGrowth is from V7 to R5hg45, then the DSS has three possible\
    \ cases: (1)\nif the state of CropGrowth is less than V7, then the DSS waits until\
    \ the next day to reevaluate the\nCropGrowth, (2) if the state of CropGrowth equals\
    \ R5hg45, then the DSS stops, and (3) if the state of\nCropGrowth is between V7\
    \ and R5hg45, then the DSS continues to retrieve rules to create a fact related\n\
    to CropGrowth. The fact integrates rules as axioms. After determining the fact,\
    \ the DSS can launch the\nDrools inference engine to infer the state of CropGrowth\
    \ for day d-1. Next, the DSS runs the functions\nto obtain the value of the root\
    \ zone average moisture of day d-1 and to obtain the number of delay days.\nThe\
    \ function to obtain the value of root zone average moisture takes the value of\
    \ the average moisture\nof day d-1 corresponding to each soil tensiometer from\
    \ the Arvalis dataset. Additionally, the function\nto obtain the number delay\
    \ days takes the value of the total rain quantity of day d-1 from the Arvalis\n\
    dataset. The DSS collects all calculated results and retrieves the other rules\
    \ related to RainIntensity,\nRootZoneMoistureLevel and CropWaterNeed properties\
    \ and updates them. Later, the Drools inference\nengine infers the state of the\
    \ three mentioned properties and the value of SleepingDuration. Based on\nthe\
    \ state of CropWaterNeed, the DSS offers two solutions: (1) if the state of CropWaterNeed\
    \ is Yes,\nthe DSS suggests that users launch irrigation on day d; otherwise,\
    \ (2) if the state of CropWaterNeed\nis No, NotApplicable or Unavailable, the\
    \ DSS suggests that users do nothing. After producing the\nAppl. Sci. 2020, 10,\
    \ 1803\n16 of 41\nsuggestion, the system saves the results of all computations\
    \ into the knowledge base. Finally, the DSS\ncontinues to wait until 06:00:00\
    \ of the next day (d+1).\nevaluate CropWaterNeed\n[d-1 00:00:00, d 00:00:00[\n\
    read getDailyAggregatedMoisture\n[d-1 06:00:00, d 06:00:00[\nrun getRootZoneDailyAverageMoisture\n\
    [d-1 06:00:00, d 06:00:00[\nwait until 06:00:00\nCropWaterNeed ?\nlaunch Irrigation\
    \ between\n[d 06:00:00, d+1 06:00:00[\nsave all data and context\nof the day d\n\
    retrieve data needed for\nthe day d = today\nKnowledge Base\nArchive\nArvalis\
    \ Dataset\nread getRainDailyTotalQuantity\n[d-1 06:00:00, d 06:00:00[\nretrieve\
    \ relevant rules\nrun getDelay\n[d-1 06:00:00, d 06:00:00[\nevaluate RootZoneMoistureLevel\n\
    [d-1 00:00:00, d 00:00:00[\nevaluate RainIntensity\n[d-1 00:00:00, d 00:00:00[\n\
    Last Crop Stage ?\n Last Crop Stage < V7\nLast Crop Stage = R5hg45\n V7 <= Last\
    \ Crop Stage < R5hg45\nretrieve relevant rules\nevaluate CropGrowth\n[d-1 00:00:00,\
    \ d 00:00:00[\nCropWaterNeed = No OR NotApplicable OR Unavailable\nCropWaterNeed\
    \ = Yes\ncreate relevant facts of \nthe day d\ncreate relevant facts of\nthe day\
    \ d\nTemporal\nKnowledge Base\nLegend\nOntogen inference engine\nOntogen aggregator\n\
    Arvalis function\nevaluate SleepingDuration\n[d 00:00:00, d+1 00:00:00[\nFigure\
    \ 7. Algorithm of the DSS.\nAppl. Sci. 2020, 10, 1803\n17 of 41\n4.4. CAS Testing\n\
    CASO and IRRIG are examined using an ontological testing tool. The project also\
    \ develops a\ngroup of unit tests and sample test scenarios to verify the working\
    \ mechanism of the system.\n4.4.1. Ontology Evaluation\nThe presented ontologies\
    \ have been evaluated following three approaches: checking the absence\nof bad\
    \ practices, coverage and data-oriented validation.\nTo check the absence of bad\
    \ practices or common errors in the ontology, the online pitfall scanner\nOOPS!\
    \ [25] has been applied to IRRIG and CASO. After executing the system, the following\
    \ changes\nwere made: (1) deﬁne some properties as the inverse of corresponding\
    \ properties, (2) add metadata as\nrdfs:label and rdfs:comment for ontology elements,\
    \ and (3) properly enter some ontology elements\nas OWL classes or properties.\n\
    Regarding the competency questions coverage, the IRRIG ontology, which as already\
    \ mentioned\ncontains CASO, has been compared to the CQ previously deﬁned. For\
    \ each CQ, the ontology elements\nneed to answer the questions that have been\
    \ identiﬁed.\nFinally, we checked whether the data from our use case could be\
    \ annotated with the ontologies.\nTo do this, an RDF ﬁle representing one day\
    \ of measurements from the Arvalis dataset in 2013 was\ngenerated. Some examples\
    \ from this ﬁle are outlined in detail in Section 5.\n4.4.2. System Testing\n\
    The project develops multiple unit tests and sample tests to evaluate the rules\
    \ and aggregations.\nThe sample test scenarios contain speciﬁc data from the Arvalis\
    \ dataset.\n•\n20 test scenarios for crop growth workﬂow.\n•\n14 test scenarios\
    \ for rain intensity workﬂow.\n•\n21 test scenarios for soil moisture workﬂow.\n\
    •\n83 test scenarios for crop water need workﬂow.\n4.5. CAS Maintenance\nCASO\
    \ and IRRIG are maintained based on a GitHub repository, and the smart irrigation\
    \ project is\nmaintained using a GitLab repository.\n4.5.1. Ontology Publication\
    \ and Maintenance\nThe key factor in maintaining the two ontologies is the interactions\
    \ between our maintainer\nteam and the community. Then, the CASO and IRRIG ontologies\
    \ must be published online. The\npublication of the CASO and IRRIG ontologies\
    \ relies on the https://w3id.org/ permanent identiﬁers\ninitiative. The ontology\
    \ publication follows the content negotiation mechanism. The URIs https:\n//w3id.org/def/caso#\
    \ and https://w3id.org/def/irrig# identify the two ontologies. The content\nnegotiation\
    \ mechanism deployed to publish the ontologies was transparent to ontology developers,\
    \ as\nit was managed by OnToology [26]. OnToology is a web-based system that builds\
    \ on top of Git-based\nenvironments and integrates a set of tools for documentation,\
    \ evaluation and publication activities.\nThe HTML published was generated by\
    \ OnToology’s integrated version of Widoco [27] and manually\nupdated to include\
    \ information about the ontology using a general description and diagrams.\nThe\
    \ issue tracker provided by GitHub is the tool used to receive feedback and control\
    \ issue lists.\nIn addition to this portal, CASO and IRRIG developers also provide\
    \ maintainer email addresses that\nenable another method for the community to\
    \ contact.\nIn our road map, IRRIG is maintained for ﬁve years. CASO will be maintained\
    \ even longer.\nAppl. Sci. 2020, 10, 1803\n18 of 41\n4.5.2. System Maintenance\n\
    A smart irrigation CAS is still in development by our team. We have implemented\
    \ and tested\nall the processes located on the server. Now, we need to improve\
    \ the development of the sensor and\nactuator network. To maintain the system\
    \ and continue with development, we use a private GitLab\nrepository. This repository\
    \ is open to identiﬁed users. Thus, those users can indicate issues to the\ndevelopment\
    \ team using the issue tracker.\n5. Example of CAS Development\nThe development\
    \ of CAS produces complex design works of many entities related to rain intensity,\n\
    crop growth, root zone moisture level and crop water needs. Figure 8 shows the\
    \ four workﬂows\nin this project. In a limited scope, this paper presents a part\
    \ of the design activity that shows the\ntransformation from soil moisture measurement\
    \ to the state of the RootZoneMoistureLevel property.\nWe select this transformation\
    \ because it contains a temporal aggregation and a spatial aggregation.\nMoreover,\
    \ the data used as the illustration in this part is the date 14/08/2013 in the\
    \ Arvalis data.\nA tensiometer measures the soil tension [28]. The soil tension\
    \ affects the water extraction capability\nof crops:\n•\nWhen the soil tension\
    \ is low, the crops require less energy to extract soil water. In other words,\n\
    when a tensiometer returns a high value, the soil moisture level is low.\n•\n\
    When the soil tension is high, the crops must use a large amount of energy to\
    \ extract soil water.\nThe IRRINOV® method evaluates the water needs of crops\
    \ by estimating the root zone moisture.\nRoot zone moisture is the quantity of\
    \ “water remaining in the depth of soil accessed by a plant” [29].\nIt depends\
    \ on the soil type, root depth and irrigation method. Its goal is to evaluate\
    \ the amount of\nirrigation water required by the plants [30]. The system uses\
    \ six tensiometers to evaluate the root\nzone moisture.\nSoil30cmDeph\nMoistureObservation\n\
    Soil30cmDepthDaily\nAverageMoistureObservation\nRootZoneDailyAverage\nMoistureObservation\n\
    RootZoneMoistureLevel\nDeduction\nCropWaterNeed\nDeduction\nSleepingDuration\n\
    Observation\nRainIntenstiy\nDeduction\nCropGrowth\nDeduction\nRainDailyTotalQuantity\n\
    Observation\nDelayDuration\nObservation\nSoil Moisture workflow\nCrop Water Need\n\
    workflow\nLegend\nPresented in the example\nNot presented in the example\nOntogen\
    \ aggregator\nArvalis function\nOntogen inference engine\nCropGrowth\nObservation\n\
    RainQuantity\nObservation\nRain Quantity workflow\nCrop Growth workflow\nFigure\
    \ 8. Four workﬂows of the CAS.\nRootZoneMoistureLevel is an observational property\
    \ of the root zone feature of interest.\nThe RootZoneMoistureLevel property is\
    \ qualitative data represented by a state. These states are\ndetermined based\
    \ on tensiometer measurements. Each tensiometer is placed at a speciﬁc depth in\
    \ the\nsoil. Thus, the RootZoneMoistureLevel property depends on the following\
    \ quantitative data properties:\n•\nSoil30cmDepthMoisture: the moisture of a new\
    \ feature of interest that represents the soil layer at\na 30 cm depth (Soil30cmDepth).\n\
    Appl. Sci. 2020, 10, 1803\n19 of 41\n•\nSoil60cmDepthMoisture: the moisture of\
    \ a new feature of interest that represents the soil layer at\na 60 cm depth (Soil60cmDepth).\n\
    •\nSoil30cmDepthDailyAverageMoisture: the daily average moisture of the feature\
    \ of interest\nSoil30cmDepth. It equals the daily average of the property Soil30cmDepthMoisture.\n\
    •\nSoil60cmDepthDailyAverageMoisture: the daily average moisture of the feature\
    \ of interest\nSoil60cmDepth. It equals the daily average of the property Soil60cmDepthMoisture.\n\
    •\nRootZoneDailyAverageMoisture:\nthe daily average moisture of the root zone\
    \ feature of\ninterest.\nIt represents a spatial aggregation of Soil30cmDepthDailyAverageMoisture\
    \ and\nSoil60cmDepthDailyAverageMoisture properties.\nThe section aims to present\
    \ some activities of the mini-waterfall methodology. Please note that\nthe speciﬁcation\
    \ activity is already described in Section 4.1. This activity has produced a set\
    \ of\nrequirements. The design activity is divided into two parts: process conceptualization\
    \ and ontology\nconceptualization. The ontology conceptualization activity uses\
    \ ontologies to model the input and\noutput of each process previously deﬁned.\
    \ The implementation activity presents the rule associated\nwith the soil moisture\
    \ stream. Finally, the testing activity shows some typical test cases.\n5.1. Processes\
    \ Conceptualization\nThis subsection presents in detail the processes related\
    \ to the soil moisture stream. A sequence of\nprocesses builds a speciﬁc workﬂow,\
    \ as shown in Figure 8.\n5.1.1. Aggregation Processes of Soil Measurement\nThe\
    \ ﬁrst aggregation process is the computation of the daily aggregated soil moisture\
    \ of the\nsoil tensiometer. In the Arvalis dataset, each observation was stored\
    \ as two datapoints: (1) the\ndaily aggregated soil moisture in cbar and (2) the\
    \ date of observation (year, month, day). Three soil\ntensiometers observe the\
    \ moisture at a 30 cm depth, and three others observe the moisture at a 60 cm\n\
    depth. The soil tensiometers used in the IRRINOV® method are Watermark probes.\
    \ Watermark probe\np measures the soil moisture at time t of day d. The unit of\
    \ the Watermark probe is the cbar. Please note\nthat a measurement value of 199\
    \ cbar indicates an error in the measurement process. Thus, the cleaning\nprocess\
    \ is applied to remove all 199 cbar values. The function getValidMoistureProbe(p,t)\
    \ returns only\nthe valid moisture value measured by probe p at time t. If the\
    \ moisture value is not valid, the function\nreturns nothing. The function getDailyAggregatedMoisture(p,d)\
    \ returns the average value of all the\nvalid moisture values measured by probe\
    \ p during the interval [d 00:00:00, d+1 00:00:00[. Table\n3 presents the calculation\
    \ of getDailyAggregatedMoisture(p,d) for one probe. Please note that the data\n\
    recorded in the Arvalis data are, in fact, the value of the function getDailyAggregatedMoisture(p,d).\n\
    Table 3. The function getDailyAggregatedMoisture(p,d).\ngetDailyAggregatedMoisture(p,\
    \ d) = ∑n\ni=1 getValidMoistureProbe(p, ti)\nn\non the condition that ti ⊂ [d\
    \ 00:00:00, d+1 00:00:00[\nwhere\n•\nd: a speciﬁc day, e.g., 14/08/2013\n•\nti:\
    \ a speciﬁc instant of day d, e.g., 08:00:00 on 14/08/2013\n•\ngetValidMoistureProbe(p,\
    \ ti): the valid moisture value measured by the probe p at the speciﬁc\ntime ti.\n\
    •\nn: the number of valid moisture values measured during day d.\nSuppose that\
    \ p1, p2, and p3 are the three probes at a 30 cm depth, and p4, p5, and p6 are\
    \ the three\nprobes at a 60 cm depth. The function getRootZoneDailyAverageMoisture(d)\
    \ returns the sum of the\nAppl. Sci. 2020, 10, 1803\n20 of 41\ntwo median values:\
    \ (1) the median of the getDailyAggregatedMoisture(p, d) values of three probes\
    \ at\na 30 cm depth, and (2) the median of the getDailyAggregatedMoisture(p, d)\
    \ values of three probes at a\n60 cm depth. Table 4 presents the calculation of\
    \ getRootZoneDailyAverageMoisture(d).\nTable 4. The function getRootZoneDailyAverageMoisture(d).\n\
    getRootZoneDailyAverageMoisture(d) = Median(getDailyAggregatedMoisture(p1, d),\n\
    getDailyAggregatedMoisture(p2, d),\ngetDailyAggregatedMoisture(p3, d))\n+Median(getDailyAggregatedMoisture(p4,\
    \ d),\ngetDailyAggregatedMoisture(p5, d),\ngetDailyAggregatedMoisture(p6, d))\n\
    where\n•\np1, p2, and p3: three watermark probes placed at a 30 cm depth\n•\n\
    p4, p5, and p6: three watermark probes placed at a 60 cm depth\n•\ngetDailyAggregatedMoisture(pi,d):\
    \ returns the average moisture value measured by the probe\npi during the interval\
    \ [d 00:00:00, d+1 00:00:00[ (see Table 3)\n•\nMedian(x, y, z): is the median\
    \ value of x, y and z.\n5.1.2. State of RootZoneMoistureLevel Property\nThe output\
    \ of rules are the daily states of the RootZoneMoistureLevel property. For each\
    \ day, a\nstate should be determined. The list of possible states is as follows:\n\
    •\nRootZoneMoistureLevel.Init:\nThis\nstate\nrepresents\nthe\nfact\nthat\nthe\n\
    function\ngetRootZoneDailyAverageMoisture(d) will be evaluated from new measurements\
    \ of tensiometers.\nThe tensiometers will perform several measurements per day.\
    \ This state is not an output of the\nautomata. It is a transitional state before\
    \ determining the new state of the RootZoneMoistureLevel\nproperty\n•\nRootZoneMoistureLevel.Saturated:\
    \ The root zone is saturated by water. Crops do not need extra\nwater. Moreover,\
    \ any machine is allowed to access the plot.\n•\nRootZoneMoistureLevel.VeryHigh:\
    \ The root zone contains a signiﬁcantly high amount of water.\nCrops do not need\
    \ water regardless of its growth stage.\n•\nRootZoneMoistureLevel.High: The root\
    \ zone contains a high amount of water. Crops need water\nat speciﬁc growth stages.\n\
    •\nRootZoneMoistureLevel.Average: The root zone contains an average amount of\
    \ water. Crops\nneed water at speciﬁc growth stages.\n•\nRootZoneMoistureLevel.Low:\
    \ The root zone contains a low amount of water. Crops need water\nat speciﬁc growth\
    \ stages.\n•\nRootZoneMoistureLevel.VeryLow: The root zone contains an insigniﬁcant\
    \ amount of water.\nCrops need water at speciﬁc growth stages.\n•\nRootZoneMoistureLevel.Dry:\
    \ The root zone is dry. Crops need water regardless of its growth\nstage.\nThe\
    \ states of the RootZoneMoistureLevel property follow the order VeryLow < Low\
    \ < Average\n< High < VeryHigh < Saturated. Those states follow the inverse order\
    \ of the value of the function\ngetRootZoneDailyAverageMoisture(d).\nAppl. Sci.\
    \ 2020, 10, 1803\n21 of 41\n5.1.3. Threshold\nCertain thresholds are used to determine\
    \ the state of the RootZoneMoistureLevel property from\nthe result of the function\
    \ getRootZoneDailyAverageMoisture(d). Please note that these thresholds\ndepend\
    \ on the variety of maize crops and soil types.\n•\nTh_ST_Minimum: The smallest\
    \ value measured by a Watermark probe. In the Watermark’s\nspeciﬁcation, it is\
    \ ﬁxed at 0 cbar.\n•\nTh_ST_Saturation: This threshold value in the Arvalis experimentation\
    \ is 10 cbar.\n•\nTh_ST_VeryHigh: This threshold value in the Arvalis experimentation\
    \ is 70 cbar.\n•\nTh_ST_High: This threshold value in the Arvalis experimentation\
    \ is 120 cbar.\n•\nTh_ST_Average: This threshold value in the Arvalis experimentation\
    \ is 140 cbar.\n•\nTh_ST_Low: This threshold value in the Arvalis experimentation\
    \ is 150 cbar.\n•\nTh_ST_VeryLow: This threshold value in the Arvalis experimentation\
    \ is 160 cbar.\n•\nTh_ST_Maximum: This is set to 301 cbar, which is higher than\
    \ any measurement value provided\nby any Watermark probe. The maximal measurement\
    \ value that a Watermark probe can reach\nranges from 0 to 200. However, to compute\
    \ the soil tension, the manufacturer provides a\ncoefﬁcient. The measurement value\
    \ is multiplied by the coefﬁcient to obtain the soil tension value.\nThe maximum\
    \ coefﬁcient provided by Watermark’s manufacturer is 1.5 (from 2002 until now),\n\
    and the maximal soil tension value is 300 cbar (200 cbar * 1.5).\nThe relations\
    \ between thresholds and states of the RootZoneMoistureLevel property are\npresented\
    \ in Figure 9. The blue squares represent the state of the RootZoneMoistureLevel\
    \ property.\nThe green squares represent the soil tension thresholds.\nThe dashed\
    \ line squares represent a\nRootZoneDailyAverageMoisture(d) value. Each of the\
    \ squares’ positions show the upper threshold\nand the lower threshold. For example,\
    \ if the RootZoneDailyAverageMoisture(d) value is superior or\nequal to Th_ST_Low\
    \ (150) and inferior to the Th_ST_VeryLow (160), then the RootZoneMoistureLevel\n\
    state is VeryLow.\nVeryLow\nLow\nAverage\nHigh\nVeryHigh\nSaturated\n<\n<\n<\n\
    <\n<\n160\nDry\n<\n150\n140\n120\n70\n10\nTh_ST_VeryLow\nTh_ST_Low\nTh_ST_Average\n\
    Th_ST_High\nTh_ST_VeryHigh\nTh_ST_Saturation\n>=\n>\n>=\n>\n>=\n>\n>=\n>=\n>\n\
    >=\n>\n>\n0\nTh_ST_Minimum\n301\nTh_ST_Maximum\n>\n>=\nFigure 9. Relation between\
    \ states and thresholds of root zone moisture level.\n5.1.4. State Diagram\nThe\n\
    state\ndiagram\npresents\nthe\ninference\nconception\nto\ndeduce\nthe\nstate\n\
    of\nthe\nRootZoneMoistureLevel\nproperty\nbased\non\nthe\nresult\nof\nthe\nfunction\n\
    getRootZoneDailyAverageMoisture(d). In the diagram illustrated in Figure 10, there\
    \ are eight states\nand ten transitions. The variable tsoil represents a clock\
    \ dedicated to the RootZoneMoistureLevel\nproperty that has a time step of one\
    \ day.\nAppl. Sci. 2020, 10, 1803\n22 of 41\nwhen(CropGrowth.State >= V7)\nLL\n\
    RootZoneMoistureLevel.Init\n  entry / run getRootZoneDailyAverageMoisture(d)\n\
    RootZoneMoistureLevel.Satured\n entry / tsoil := 0D\nRootZoneMoistureLevel.VeryHigh\n\
    \ entry / tsoil := 0D \nRootZoneMoistureLevel.High\n entry / tsoil := 0D\nwhen(Th_ST_Minimum\
    \ <= \ngetRootZoneDailyAverageMoisture(d) \n< Th_ST_Saturation)\nRootZoneMoistureLevel.Average\n\
    \ entry / tsoil := 0D\nRootZoneMoistureLevel.Low\n entry / tsoil := 0D\nRootZoneMoistureLevel.VeryLow\n\
    \ entry / tsoil := 0D\nwhen(tsoil >= 1D)\nRootZoneMoistureLevel.Dry\n entry /\
    \ tsoil := 0D\nwhen(Th_ST_Saturation <= \ngetRootZoneDailyAverageMoisture(d)\n\
    < Th_ST_VeryHigh)\nwhen(Th_ST_VeryHigh <= \ngetRootZoneDailyAverageMoisture(d)\n\
    < Th_ST_High)\nwhen(Th_ST_High <= \ngetRootZoneDailyAverageMoisture(d)\n< Th_ST_Average)\n\
    when(Th_ST_Average <= \ngetRootZoneDailyAverageMoisture(d)\n< Th_ST_Low)\nwhen(Th_ST_Low\
    \ <= \ngetRootZoneDailyAverageMoisture(d)\n< Th_ST_VeryLow)\nwhen(Th_ST_VeryLow\
    \ <= \ngetRootZoneDailyAverageMoisture(d)\n< Th_ST_Maximum)\nwhen(CropGrowth.State\
    \ = R5hg45)\nFigure 10. Automata of RootZoneMoistureLevel states and their transitions.\n\
    The transition from the initial state towards the state Init indicates when the\
    \ state\nof the CropGrowth property is V7 or any upper state;\nthen, the RootZoneMoistureLevel\n\
    property reaches the state Init.\nAfter reaching this state, a new evaluation\
    \ of the function\ngetRootZoneDailyAverageMoisture(d) is performed based on daily\
    \ tensiometer measurements.\nThe transition from the state Init towards the state\
    \ Saturated indicates that when the value of\nthe function RootZoneDailyAverageMoisture(d)\
    \ is equal or superior to Th_ST_Minimum and inferior\nto Th_ST_Saturation, then\
    \ the RootZoneMoistureLevel property reaches the Saturated state. After\nreaching\
    \ this state, the clock tsoil is reset.\nThe transition from the state Init towards\
    \ the state VeryHigh indicates that when the value of the\nfunction getRootZoneDailyAverageMoisture(d)\
    \ is equal or superior to Th_ST_Saturation and inferior\nAppl. Sci. 2020, 10,\
    \ 1803\n23 of 41\nto Th_ST_VeryHigh, then the RootZoneMoistureLevel property reaches\
    \ the VeryHigh state. After\nreaching this state, the clock tsoil is reset.\n\
    The transition from the state Init towards the state High indicates that when\
    \ the value of the\nfunction getRootZoneDailyAverageMoisture(d) is equal or superior\
    \ to Th_ST_VeryHigh and inferior\nto Th_ST_High, then the RootZoneMoistureLevel\
    \ property reaches the High state. After reaching this\nstate, the clock tsoil\
    \ is reset.\nThe transition from the state Init towards the Average state indicates\
    \ that when the value of the\nfunction getRootZoneDailyAverageMoisture(d) is equal\
    \ or superior to Th_ST_High and inferior to\nTh_ST_Average, then the RootZoneMoistureLevel\
    \ property reaches the Average state. After reaching\nthis state, the clock tsoil\
    \ is reset.\nThe transition from the state Init towards the state Low indicates\
    \ when the value of the\nfunction getRootZoneDailyAverageMoisture(d) is equal\
    \ or superior to Th_ST_Average and inferior\nto Th_ST_Low, then the RootZoneMoistureLevel\
    \ property reaches the Low state. After reaching this\nstate, the clock tsoil\
    \ is reset.\nThe transition from the state Init towards the state VeryLow indicates\
    \ that when the value of the\nfunction getRootZoneDailyAverageMoisture(d) is equal\
    \ or superior to Th_ST_Low and inferior to\nTh_ST_VeryLow, then the RootZoneMoistureLevel\
    \ property reaches the VeryLow state. After reaching\nthis state, the clock tsoil\
    \ is reset.\nThe transition from the state Init towards the state Dry indicates\
    \ that when the value of the\nfunction getRootZoneDailyAverageMoisture(d) is equal\
    \ or superior to Th_ST_VeryLow and inferior to\nTh_ST_Maximum, then the RootZoneMoistureLevel\
    \ property reaches the Dry state. After reaching\nthis state, the clock tsoil\
    \ is reset.\nThe transition from one state among Saturated, VeryHigh, High, Average,\
    \ Low, VeryLow and\nDry towards the state Init indicates that after one day ((tsoil\
    \ >= 1)?), a state change is possible; in other\nwords, a state is reached for\
    \ a whole day.\nThe transition from the state Init towards the ﬁnal state indicates\
    \ that when the CropGrowth\nproperty is at the state R5hg45, then moisture measurements\
    \ are terminated.\n5.2. Ontology Conceptualization\nThe ontology IRRIG is used\
    \ to model the input and output of our DSS. During the decision\nprocess, we need\
    \ to model the following:\n•\nThe measurements of six tensiometers.\n•\nThe average\
    \ of the measurements provided by a tensiometer for a whole day.\n•\nThe computation\
    \ of the root zone moisture per day.\n•\nThe output of the deduction process,\
    \ as the states of the RootZoneMoistureLevel property deduced\nby the rule engine.\n\
    This section uses a data sample on 14/08/2013 from the Arvalis dataset to illustrate\
    \ the\nconceptualization. The sample (https://gitlab.irstea.fr/irrig/public/tree/master/Sample/)\
    \ was\nmodeled in Turtle format.\n5.2.1. Tensiometer Measurement Model\nThe goal\
    \ of this subsection is to model the tensiometer measurements or, more precisely,\
    \ the result\nof the function getValidMoistureProbe(p,t). A tensiometer may be\
    \ placed at a 30 cm or 60 cm depth.\nThis section describes the valid measurement\
    \ of a tensiometer placed at a 30 cm depth. This model\nreuses some elements of\
    \ the IRRIG ontology. IRRIG deﬁned several classes and instances used for\nmodeling\
    \ tensiometer measurements:\n•\nirrig:featureOfInterest_Soil30cmDepth:\nthis\n\
    individual\nrepresents\nthe\nsoil\nlayer\nat\na\n30 cm depth.\nThis individual\
    \ is an instance of the class sosa:FeatureOfInterest.\nThe\nindividual\nirrig:featureOfInterest_soil30cmDepth\n\
    is\nlinked\nto\nthe\nindividual\nAppl. Sci. 2020, 10, 1803\n24 of 41\nirrig:observableProperty_soil30cmDepth_moisture\
    \ by the sosa:hasProperty object property\n(see Figure 11).\n•\nirrig:MoistureProperty:\
    \ this class is a subclass of ssn:Property. It represents the amount of water\n\
    available inside the entity. The moisture aspect of the entity is intrinsic to\
    \ and cannot exist without\nthe entity. The moisture quality value should be expressed\
    \ by a qualitative value such as a state\nor by a quantitative value (see Figure\
    \ 11).\n•\nirrig:observationProperty_soil30cmDepth_moisture: this individual represents\
    \ the moisture\nproperty of the soil layer at a 30 cm depth. It is an instance\
    \ of the class irrig:MoistureProperty\n(see Figure 11).\n•\nirrig:Soil30cmDepthMoistureObservation:\n\
    this class is a subclass of caso:Observation.\nIt is a deﬁned class that represents\
    \ the act of carrying out a procedure (observation)\nto estimate or calculate\
    \ a value of a moisture property related to the soil layer\nat\na\n30\ncm\ndepth.\n\
    This\nmoisture\nproperty\nis\nrepresented\nby\nthe\nindividual\nirrig:observableProperty_soil30cmDepth_moisture.\
    \ Two necessary and sufﬁcient conditions are\ndeﬁned: (1) All instances of the\
    \ class irrig:Soil30cmDepthMoistureObservation are linked to the\nindividual irrig:observableProperty_soil30cmDepth_moisture\
    \ via the sosa:observedProperty\nobject property; (2) All instances of irrig:Soil30cmDepthMoistureObservation\
    \ are linked to the\nindividual irrig:featureOfInterest_soil30cmDepth via the\
    \ sosa:hasFeatureOfInterest object\nproperty. Each instance of irrig:Soil30cmDepthMoistureObservation\
    \ is linked to a sensor to\ndescribe which tensiometer made the observation and\
    \ how.\nFirst, the measurement data are stored in the system under the IRRIG model.\
    \ Figure 11 presents\nan example of one measurement from one soil tensiometer.\n\
    sosa:FeatureOfInterest\n ssn:hasProperty \nirrig:featureOfInterest_\nsoil30cmDepth\n\
    sosa:ObservableProperty\nirrig:observableProperty_\nsoil30cmDepth_moisture\nsaref4agri:SoilTensiometer\n\
    irrig:soilTensiometer_\n1_30cm\nirrig:Soil30cmDepthMoistureObservation\nsosa:madeBy\n\
    Sensor\nsosa:hasFeature\nOfInterest\nsosa:observed\nProperty\nsosa:phenomenonTime\n\
    sosa:hasSimple\nResult\nsosa:hasResult\nsosa:resultTime\narvalis:observation_at_2013-08-14T080000_0200_of_\n\
    soilTensiometer_1_on_soil30cmDepth_moisture\n\"780.0 millibar\"^^rdfs:Literal\n\
    sosa:Result\nom:hasUnit\nom:hasNumericValue\narvalis:result_value_780.0_millibar\n\
    om:Unit\nom:millibar\n\"780.0\"^^xsd:double\ntime:Instant\narvalis:instant_2013-08-14T\n\
    080000_0200\n\"2013-08-14T08:00:00+02:00\"^^xsd:dateTime\ntime:inXSDDateTimeStamp\n\
    irrig:MoistureProperty\nsosa:Sensor\n\"2013-08-14T08:00:00+02:00\"\n^^xsd:dateTime\n\
    Figure 11. Example of an observation of a soil tensiometer.\nAppl. Sci. 2020,\
    \ 10, 1803\n25 of 41\nAn\ninstance\nof\nthe\nclass\nirrig:Soil30cmDepthMoistureObservation\n\
    represents\nthe\ncomputation of the function getValidMoistureProbe(p,t).\nIt is\
    \ an observation of a moisture\nproperty related to the soil layer at a 30 cm\
    \ depth, as shown in Figure 11.\nBy deﬁnition,\nindividuals\nof\nirrig:Soil30cmDepthMoistureObservation\n\
    are\nlinked\nto\nthe\nindividual\nirrig:observedProperty_soil30cmDepth_moisture,\
    \ an instance of the class irrig:MoistureProperty,\nand\nto\nthe\nindividual\n\
    irrig:FeatureOfInterest_Soil30cmDepth,\nan\ninstance\nof\nthe\nclass\nsosa:FeatureOfInterest.\n\
    The observation individual is linked to the sensor that made the observation.\
    \ We assumed\nthat the node, which contains a tensiometer probe, also has the\
    \ capacity to clean the probe\nmeasurements. A node tensiometer is represented\
    \ by an instance of the class sosa:Sensor. It is\nalso an instance of the class\
    \ saref4agri:SoilTensiometer. Arvalis identiﬁes their tensiometers by\na number\
    \ and depth, as presented in Section 4.1.\nWe reuse this information to create\
    \ a name\nfor each instance of saref4agri:SoilTensiometer. For example, Figure\
    \ 11 contains the individual\narvalis:soilTensiometer_1_30cm.\nA tensiometer measurement\
    \ is an instantaneous observation. Please note that the measurements\nof tensiometers\
    \ are unavailable in the Arvalis dataset.\nThus, we can imagine that tensiometer\n\
    measurements may happen at any time of the day. Figure 11 presents a measurement\
    \ that happens\nat 08:00:00 on 14/08/2013. To store the time of the measurement,\
    \ we create an instance of the class\ntime:Instant. The time:inXSDDateTimeStamp\
    \ data property stores the associated date time value. The\nsosa:phenomenonTime\
    \ object property links the observation individual to the instant individual.\n\
    To present the time when the node tensiometer generates the measurement, we use\
    \ the\nsosa:resultTime datatype property to links the observation individual to\
    \ the xsd:dateTime value\ncorresponding to a precise time. In Figure 11, this\
    \ precise time is at 08:00:00 on 14/08/2013.\nThe result of tensiometer measurement\
    \ is presented by an instance of the class sosa:Result. This\nresult is described\
    \ by a value and a unit. The instance of sosa:Result is linked to the data value\
    \ via\nthe om:hasNumericValue datatype property. The instance of sosa:Result is\
    \ linked to the individual\nom:millibar, an instance of the class om:Unit, via\
    \ the om:hasUnit object property. Please note that\nin the Arvalis dataset, the\
    \ unit of tensiometer measurement is the cbar. However, to the best of our\nknowledge,\
    \ this unit has not yet been deﬁned in any ontology. Thus, we prefer to reuse\
    \ the millibar\n(mbar), a unit that is already deﬁned in well-known ontologies\
    \ such as OM. For this reason, this model\nuses the millibar as the unit for moisture,\
    \ as shown in Figure 11.\n5.2.2. Function getDailyAggregatedMoisture Model\nThe\
    \ goal of this subsection is to model the result of the function getDailyAggregatedMoisture(p,d).\n\
    This function computes the daily average of all the measurements provided by one\
    \ tensiometer. IRRIG\ndeﬁnes several classes and instances used for modeling the\
    \ daily average of tensiometer measurements:\n•\nirrig:observationProperty_soil30cmDepth_dailyAverageMoisture:\
    \ this individual represents the\ndaily average of the moisture property related\
    \ to the soil layer at a 30 cm depth.\nIt is\nan instance of the class irrig:MoistureProperty.\
    \ This individual is linked to the individual\nirrig:featureOfInterest_soil30cmDepth\
    \ (see Figure 12).\n•\nirrig:Soil30cmDepthDailyAverageMoistureObservation:\nthis\n\
    class\nis\na\nsubclass\nof\ncaso:Observation. It is a deﬁned class that represents\
    \ the act of carrying out a procedure\n(observation) to calculate the average\
    \ per day of the moisture property. This speciﬁc property is\nrepresented by the\
    \ individual irrig:observableProperty_soil30cmDepth_dailyAverageMoisture.\nTwo\n\
    necessary\nand\nsufﬁcient\nconditions\nare\ndeﬁned:\n(1)\nAll\ninstances\nof\n\
    the\nclass\nirrig:Soil30cmDepthDailyAverageMoistureObservation\nare\nlinked\n\
    to\nthe\nindividual\nirrig:observableProperty_soil30cmDepth_dailyAverageMoisture\n\
    via\nthe\nsosa:observedProperty\nobject\nproperty;\n(2)\nAll\ninstances\nof\n\
    irrig:Soil30cmDepthDailyAverageMoistureObservation\nare\nlinked\nto\nthe\nindividual\n\
    irrig:featureOfInterest_soil30cmDepth via the sosa:hasFeatureOfInterest object\
    \ property.\nAppl. Sci. 2020, 10, 1803\n26 of 41\nEach instance of irrig:Soil30cmDepthDailyAverageMoistureObservation\
    \ is linked to a sensor\nto describe which agent made the observation and how.\n\
    Figure 12 presents an example of the getDailyAggregatedMoisture(p,d) result.\n\
    irrig:Soil30cmDepthMoistureObservation\narvalis:Observation_at_PT24H_2013-07-\n\
    16T000000_0200_of_\nSoilTensiometer_01_Soil30cmDepth_Moisture\nirrig:Soil30cmDepthMoistureObservation\n\
    arvalis:Observation_at_PT24H_2013-07-\n16T000000_0200_of_\nSoilTensiometer_01_Soil30cmDepth_Moisture\n\
    irrig:Soil30cmDepthMoistureObservation\narvalis:Observation_at_PT24H_2013-07-\n\
    16T000000_0200_of_\nSoilTensiometer_01_Soil30cmDepth_Moisture\nsosa:FeatureOfInterest\n\
    ssn:hasProperty\nirrig:featureOfInterest_\nsoil30cmDepth\nsosa:ObservableProperty\n\
    irrig:observableProperty_\nsoil30cmDepth_dailyAverageMoisture\nsosa:Sensor\narvalis:aggregator_\n\
    getDailyAggregatedMoisture_1\nirrig:Soil30cmDepthDailyAverageMoistureObservation\n\
    sosa:madeBy\nSensor\nsosa:hasFeature\nOfInterest\nsosa:observed\nProperty\nsosa:phenomenonTime\n\
    sosa:hasSimple\nResult\nsosa:hasResult\n sosa:resultTime \narvalis:observation_at_PT24H_2013-08-14T060000_0200_of_\n\
    aggregator_getDailyAggregatedMoisture_1_\non_soil30cmDepth_dailyAverageMoisture\n\
    \"780.0 millibar\"^^rdfs:Literal\nsosa:Result\nom:hasUnit\nom:hasNumericValue\n\
    arvalis:result_value_780.0_millibar\nom:Unit\nom:millibar\n\"780.0\"^^xsd:double\n\
    time:Interval\ntime:hasBeginning\ntime:hasEnd\ntime:hasDuration\narvalis:interval_PT24H_2013-08-14T\n\
    060000_0200\ntime:Duration\narvalis:duration_PT24H\narvalis:instant_2013-08-14\n\
    T060000_0200\narvalis:instant_2013-08-15\nT060000_0200\ntime:Instant\nirrig:Soil30cmDepthMoistureObservation\n\
    arvalis:observation_at_2013-08-14T080000_0200_of_\nsoilTensiometer_1_on_soil30cmDepth_moisture\n\
    prov:wasInformedBy\n\"2013-08-14T06:00:00+02:00\"^^xsd:dateTime\ntime:inXSDDateTimeStamp\n\
    \"2013-08-15T06:00:00+02:00\"^^xsd:dateTime\ntime:inXSDDateTimeStamp\nirrig:MoistureProperty\n\
    \"2013-08-15T06:00:00+02:00\"\n^^xsd:dateTime\nFigure 12. Example of the computation\
    \ of getDailyAggregatedMoisture(p,d).\nThe instance of the class irrig:Soil30cmDepthDailyAverageMoistureObservation\
    \ represents\nthe computation of the daily average of all measurements provided\
    \ by one tensiometer, as shown\nin Figure 12. By deﬁnition, individuals of irrig:Soil30cmDepthMoistureObservation\
    \ are linked to\nthe individual irrig:observedProperty_soil30cmDepth_dailyAverageMoisture,\
    \ an instance of the class\nirrig:MoistureProperty, and to the individual irrig:featureOfInterest_soil30cmDepth.\n\
    The observation individual is linked to the sensor that produces the result, i.e.,\
    \ a software program\nthat computes the daily average of several measurements.\
    \ We do not have information on the agent\nthat produces this computation in the\
    \ Arvalis dataset. It is possible that the same software, located\non a server,\
    \ computes the average for all the measurements. Alternatively, the IRRINOV station\
    \ may\ncontain two different processing devices. Each device can compute the average\
    \ for all the tensiometers\nlocated at the same depth. To avoid errors, we create\
    \ a software agent for each tensiometer based\non the tensiometer name: arvalis:aggregator_getDailyAggregatedMoisture_1.\
    \ The individual that\nAppl. Sci. 2020, 10, 1803\n27 of 41\nrepresents the software\
    \ is an instance of the class sosa:Sensor. The observation individual is linked\
    \ to\nthe software agent via the sosa:madeBySensor object property, as shown in\
    \ Figure 12.\nThe software program produces the result once per day at a precise\
    \ time. In the Arvalis dataset,\nthere is no information about the hour, minute\
    \ and second of the computation. For synchronization\npurposes, we ﬁx it to the\
    \ time of the deduction computation [d+1 06:00:00]. At this time, all the\ntensiometer\
    \ measurements were available for the computation of the average. To store the\
    \ time of the\ncomputation, we use the sosa:resultTime datatype property to links\
    \ the observation individual to the\nxsd:dateTime corresponding to the precise\
    \ time [d+1 06:00:00]. This is presented in Figure 12.\nThe computation calculates\
    \ the daily average. Figure 12 presents the average for the 14/08/2013.\nWe represent\
    \ the day as a period of 24 h: [d 00:00:00, d+1 00:00:00[.\nThus, we create an\n\
    instance of the class time:Interval, which is described by two instances of time:Instant.\n\
    The\nsosa:phenomenonTime object property links the observation individual to the\
    \ time:Interval instance.\nA computation of daily average is based on several\
    \ tensiometer measurements. Thus, the instance\nof the class irrig:Soil30cmDepthDailyAverageMoistureObservation\
    \ is linked to several instances of\nthe class irrig:Soil30cmDepthMoistureObservation\
    \ via the prov:wasInformedBy object property, as\nshown in Figure 12.\nThe result\
    \ of the computation is represented by an instance of the class sosa:Result. This\
    \ instance\nis described by a unit and a value, as shown in Figure 12.\n5.2.3.\
    \ Function getRootZoneDailyAverageMoisture Model\nThe\ngoal\nof\nthis\nsubsection\n\
    is\nto\nmodel\nthe\nresult\nof\nthe\nfunction\ngetRootZoneDailyAverageMoisture(d).\n\
    The value represents the evaluation of average daily\nmoisture related to the\
    \ root zone. First, the computation is relative to the daily average moisture\n\
    property, as presented in the previous section. Second, the feature of interest\
    \ is no more a soil layer at\na speciﬁc depth, but a volume of soil named root\
    \ zone, as explained in the introduction paragraph.\nIRRIG deﬁnes several classes\
    \ and instances used for modeling the measurements of the daily average\nmoisture\
    \ of root zone:\n•\nirrig:featureOfInterest_rootZone: this individual represents\
    \ the root zone. This individual is an\ninstance of the class sosa:FeatureOfInterest.\
    \ The individual irrig:featureOfInterest_rootZone\nis linked to the individual\
    \ irrig:observableProperty_rootZone_dailyAverageMoisture by the\nsosa:hasProperty\
    \ object property (see Figure 13).\n•\nirrig:observationProperty_rootZone_dailyAverageMoisture:\
    \ this individual represents the daily\naverage of the moisture property related\
    \ to the root zone.\nIt is an instance of the class\nirrig:MoistureProperty (see\
    \ Figure 13).\n•\nirrig:RootZoneDailyAverageMoistureObservation: this class is\
    \ a subclass of caso:Observation.\nIt is a deﬁned class that represents the act\
    \ of carrying out a procedure (observation) to calculate the\ndaily average of\
    \ the moisture property related to the root zone. The speciﬁc moisture property\
    \ is\nrepresented\nby\nthe\nindividual\nirrig:observableProperty_rootZone_dailyAverageMoisture.\n\
    Two\nnecessary\nand\nsufﬁcient\nconditions\nare\ndeﬁned:\n(1)\nAll\ninstances\n\
    of\nthe\nclass\nirrig:RootZoneDailyAverageMoistureObservation\nare\nlinked\nto\n\
    the\nindividual\nirrig:observableProperty_rootZone_dailyAverageMoisture\nvia\n\
    the\nsosa:observedProperty\nobject property; (2) All instances of irrig:RootZoneDailyAverageMoistureObservation\
    \ are\nlinked to the individual irrig:featureOfInterest_rootZone via the sosa:hasFeatureOfInterest\n\
    object property. Each instance of irrig:RootZoneDailyAverageMoistureObservation\
    \ is linked to\na sensor to describe which agent made the observation and how.\n\
    Figure 13 presents an example of the getRootZoneDailyAggregatedMoisture(d) result.\n\
    Appl. Sci. 2020, 10, 1803\n28 of 41\nirrig:Soil60cmDepthDailyAverageMoistureObservation\n\
    arvalis:Observation_at_PT24H_2013-07-31T060000_0200_of_\nSoftwareAgent_Soil60cmDepth_AverageMoisturePerDay\n\
    irrig:Soil60cmDepthDailyAverageMoistureObservation\narvalis:Observation_at_PT24H_2013-07-31T060000_0200_of_\n\
    SoftwareAgent_Soil60cmDepth_AverageMoisturePerDay\nirrig:Soil30cmDepthDailyAverageMoistureObservation\n\
    arvalis:Observation_at_PT24H_2013-07-31T060000_0200_of_\nSoftwareAgent_Soil30cmDepth_AverageMoisturePerDay\n\
    irrig:Soil30cmDepthDailyAverageMoistureObservation\narvalis:Observation_at_PT24H_2013-07-31T060000_0200_of_\n\
    SoftwareAgent_Soil30cmDepth_AverageMoisturePerDay\nsosa:FeatureOfInterest\nssn:hasProperty\n\
    irrig:featureOfInterest_\nrootZone\nirrig:MoistureProperty\nirrig:observableProperty_\n\
    rootZone_dailyAverageMoisture\nsosa:Sensor\narvalis:aggregator_\ngetRootZoneDailyAverageMoisture\n\
    prov:wasInformedBy\nprov:wasInformedBy\nirrig:RootZoneDailyAverageMoistureObservation\n\
    sosa:madeBy\nSensor\nsosa:hasFeature\nOfInterest\nsosa:observed\nProperty\nsosa:phenomenonTime\n\
    sosa:hasSimple\nResult\nsosa:hasResult\n sosa:resultTime \narvalis:observation_at_PT24H_2013-08-14T060000_0200_\n\
    of_aggregator_getRootZoneDailyAverageMoisture_\non_rootZone_dailyAverageMoisture\n\
    time:Interval\ntime:hasBeginning\ntime:hasEnd\ntime:hasDuration\narvalis:interval_PT24H_\n\
    2013-08-14T060000_0200\n\"2360.0 millibar\"^^rdfs:Literal\nsosa:Result\nom:hasUnit\n\
    om:hasNumericValue\narvalis:result_value_2360.0_millibar\nom:Unit\nom:millibar\n\
    \"2360.0\"^^xsd:double\ntime:Duration\narvalis:duration_PT24H\narvalis:instant_2013-08-14\n\
    T060000_0200\narvalis:instant_2013-08-15\nT060000_0200\ntime:Instant\nirrig:Soil30cmDepthDailyAverageMoistureObservation\n\
    arvalis:observation_at_PT24H_2013-08-14T060000_0200_\nof_aggregator_dailyAggregatedMoisture_1_\n\
    on_soil30cmDepth_dailyAverageMoisture\nirrig:Soil60cmDepthDailyAverageMoistureObservation\n\
    arvalis:observation_at_PT24H_2013-08-14T060000_0200_\nof_aggregator_dailyAggregatedMoisture_4_\n\
    on_soil60cmDepth_dailyAverageMoisture\nsosa:ObservableProperty\n\"2013-08-14T06:00:00+02:00\"\
    ^^xsd:dateTime\ntime:inXSDDateTimeStamp\n\"2013-08-15T06:00:00+02:00\"^^xsd:dateTime\n\
    time:inXSDDateTimeStamp\n\"2013-08-15T06:00:00+02:00\"\n^^xsd:dateTime\nFigure\
    \ 13. Example of the computation of getRootZoneDailyAverageMoisture(d).\nAn\n\
    instance\nof\nthe\nclass\nirrig:RootZoneDailyAverageMoistureObservation\nrepresents\n\
    the\ncomputation\nof\nthe\ndaily\naverage\nmoisture\nfor\nthe\nroot\nzone.\nBy\n\
    deﬁnition,\nindividuals\nof\nirrig:RootZoneDailyAverageMoistureObservation\nare\n\
    linked\nto\nthe\nindividual\nirrig:observedProperty_rootZone_dailyAverageMoisture,\n\
    an\ninstance\nof\nthe\nclass\nirrig:MoistureProperty, and to the individual irrig:featureOfInterest_rootZone,\
    \ an instance of the\nclass sosa:FeatureOfInterest, as shown in Figure 13.\nThe\
    \ observation individual is linked to the sensor that produces the result,\ni.e.,\n\
    a\nsoftware that computes the equation presented in Table 4.\nThe software program\
    \ is named\narvalis:aggregator_getRootZoneDailyAverageMoisture. This individual\
    \ is an instance of the class\nsosa:Sensor. The observation individual is linked\
    \ to the sensor via the sosa:madeBySensor object\nproperty, as shown in Figure\
    \ 13.\nThe software computes at a precise time when all its inputs are available.\
    \ There is no information\nabout the hour, minute and second of the computation.\
    \ For synchronization purposes, we ﬁx it to\nthe time at [d+1 06:00:00]. To store\
    \ the time of the computation, we use the sosa:resultTime datatype\nAppl. Sci.\
    \ 2020, 10, 1803\n29 of 41\nproperty to links the observation individual to the\
    \ xsd:dateTime value corresponding to the precise time\n[d+1 06:00:00]. This is\
    \ presented in Figure 13.\nThe computation calculates the daily average. Figure\
    \ 13 presents the computation for the\n14/08/2013. We represent the day as a period\
    \ of 24 h: [d 00:00:00, d+1 00:00:00[. We reuse\nthe instance of the class time:Interval\
    \ deﬁned for the description of the daily average of tensiometer\nmeasurements\
    \ (see Section 5.2.2). The sosa:phenomenonTime object property links the observation\n\
    individual to the time:Interval instance.\nThe result of the computation is presented\
    \ by an instance of the class sosa:Result, as shown in\nFigure 13.\n5.2.4. RootZoneMoistureLevel\
    \ Deduction Model\nThe goal of the subsection is to model the output of the rule\
    \ engine, which infers\nthe\nstate\nof\nthe\nRootZoneMoistureLevel\nproperty\n\
    based\non\nthe\nresult\nof\nthe\nfunction\ngetRootZoneDailyAverageMoisture(d).\
    \ IRRIG deﬁnes several classes and instances used for modeling\nRootZoneMoistureLevel\
    \ deductions:\n•\nirrig:ObservationProperty_RootZone_MoistureLevel: this individual\
    \ represents the moisture\nproperty of the root zone.\nIt is an instance of the\
    \ class irrig:MoistureProperty.\nIt is\nalso an instance of the class caso:Property\
    \ because its associated values are states,\nrepresented by instances of the class\
    \ irrig:RootZoneMoistureLevelState.\nThis individual\nis linked to the individual\
    \ irrig:featureOfInterest_rootZone (see Figure 14).\nThe individual\nirrig:ObservationProperty_RootZone_MoistureLevel\
    \ is linked to an instance of the class\nirrig:RootZoneMoistureLevelState via\
    \ the object property caso:hasState.\n•\nirrig:RootZoneMoistureLevelState: this\
    \ class is a subclass of caso:State.\nIt represents the\nqualitative value of\
    \ the RootZoneMoistureLevel property which changes over time, summarizing\na set\
    \ of information about that property.\nSeveral instances of this class are presented\
    \ in\nSection 5.1.2.\n•\nirrig:RootZoneMoistureLevelDeduction: this class is a\
    \ subclass of caso:Deduction.\nIt is a\ndeﬁned class that represents the act of\
    \ carrying out a procedure (observation) to estimate the state\nof the moisture\
    \ property for the root zone. The moisture property is represented by the individual\n\
    irrig:observableProperty_rootZone_moistureLevel.\nTwo necessary and sufﬁcient\
    \ conditions\nare deﬁned: (1) All instances of irrig:RootZoneMoistureLevelDeduction\
    \ are linked to the\nindividual irrig:observableProperty_rootZone_moistureLevel\
    \ via the sosa:observedProperty\nobject property; (2) All instances of irrig:RootZoneMoistureLevelDeduction\
    \ are linked to the\nindividual irrig:featureOfInterest_rootZone via the sosa:hasFeatureOfInterest\
    \ object property.\nEach instance of irrig:RootZoneMoistureLevelDeduction is linked\
    \ to an instance of the class\nirrig:RootZoneMoistureLevelState by the caso:hasResultState\
    \ object property, is linked to\nan instance of irrig:RootZoneMoistureObservation\
    \ by the prov:wasInformedBy object property,\nand is linked to a sensor to describe\
    \ the agent that made the deduction.\nFigures 14 and 15 present an example of\
    \ the RootZoneMoistureLevel deduction.\nAppl. Sci. 2020, 10, 1803\n30 of 41\n\
    sosa:FeatureOfInterest\nssn:hasProperty\nirrig:featureOfInterest_\nrootZone\n\
    irrig:MoistureProperty\ncaso:hasState\nirrig:observableProperty_\nrootZone_moistureLevel\n\
    sosa:Sensor\narvalis:ontogen_inferenceEngine_\nSWRLAPI_drools\nirrig:RootZoneMoistureLevelDeduction\n\
    sosa:madeBySensor\nsosa:hasFeature\nOfInterest\nsosa:observed\nProperty\ncaso:hasResultState\n\
    prov:wasInformedBy\nprov:used\narvalis:deduction_at_PT24H_2013-08-14T\n060000_0200_of_ontogen_inferenceEngine_\n\
    SWRLAPI_drools_on_rootZone_moistureLevel\nirrig:RootZoneMoistureLevelState\nirrig:state_rootZone_\n\
    moistureLevel_dry\nirrig: RootZoneDailyAverageMoistureObservation\nsosa:hasResult\n\
    arvalis:observation_at_PT24H_2013-08-14T060000_0200_\nof_aggregator_getRootZoneDailyAverageMoisture_\n\
    on_rootZone_dailyAverageMoisture\ncaso:Property\nsosa:Result\narvalis:result_value_\n\
    2360.0_millibar\nFigure 14. Example of the deduction of root zone moisture level\
    \ (part 1).\ntime:Interval\ntime:hasBeginning\ntime:hasEnd\ntime:hasDuration\n\
    arvalis:interval_PT24H_2013-08-13T\n000000_0200\ntime:Duration\narvalis:duration_PT24H\n\
    arvalis:instant_2013-08-13\nT000000_0200\narvalis:instant_2013-08-14\nT000000_0200\n\
    time:Instant\n\"2013-08-13T00:00:00+02:00\"\n^^xsd:dateTime\n\"2013-08-14T00:00:00+02:00\"\
    \n^^xsd:dateTime\ntime:inXSDDateTimeStamp\ntime:inXSDDateTimeStamp\ntime:Interval\n\
    arvalis:interval_PT24H_2013-08-14T\n060000_0200\ntime:hasDuration\narvalis:instant_2013-08-15\n\
    T060000_0200\n\"2013-08-15T06:00:00+02:00\"\n^^xsd:dateTime\ntime:inXSDDateTimeStamp\n\
    time:hasBeginning\ntime:hasEnd\nirrig:RootZoneMoistureLevelDeduction\n sosa:resultTime\
    \ \narvalis:deduction_at_PT24H_2013-08-14T\n060000_0200_of_ontogen_inferenceEngine_\n\
    SWRLAPI_drools_on_rootZone_moistureLevel\ncaso:hasValidTime\nsosa:phenomenonTime\n\
    arvalis:instant_2013-08-14\nT060000_0200\n\"2013-08-14T06:00:00+02:00\"\n^^xsd:dateTime\n\
    time:inXSDDateTimeStamp\n\"2013-08-15T06:00:00+02:00\"\n^^xsd:dateTime\nFigure\
    \ 15. Example of the deduction of root zone moisture level (part 2).\nAn instance\
    \ of the class irrig:RootZoneMoistureLevelDeduction represents a deduction process\n\
    for the RootZoneMoistureLevel property, as shown in Figure 14. By deﬁnition, this\
    \ individual is\nlinked to the individual irrig:observedProperty_rootZone_moistureLevel,\
    \ an instance of the class\nirrig:MoistureProperty, and to the individual irrig:featureOfInterest_rootZone.\n\
    The\ndeduction\nindividual\nis\nlinked\nto\nan\nactor\nthat\nproduces\nthe\nresult.\n\
    The\nactor\nis\nan\nSWRLAPI\nDrools\nEngine\nthat\nis\nrepresented\nby\nthe\n\
    individual\narvalis:ontogen_inferenceEngine_SWRLAPI_drools,\nan\ninstance\nof\n\
    the\nclass\nsosa:Sensor.\nAppl. Sci. 2020, 10, 1803\n31 of 41\nThe deduction is\
    \ linked to the sensor via the sosa:madeBySensor object property, as shown\nin\
    \ Figure 14.\nA RootZoneMoistureLevel deduction is based on an observation individual\
    \ that represents\na computation of the function getRootZoneDailyAverageMoisture(d).\
    \ The deduction instance of\nFigure 14 is based on the observation individual\
    \ presented in Figure 13.\nThus, the deduction\nindividual is linked to the instance\
    \ of the class irrig:RootZoneDailyAverageMoistureObservation\nvia the prov:wasInformedBy\
    \ object property.\nThe\nresult\nof\na\nRootZoneMoistureLevel\ndeduction\nis\n\
    an\ninstance\nof\nthe\nclass\nirrig:RootZoneMoistureLevelState.\nThe deduction\
    \ individual is linked to its state result by\nthe caso:hasResultState object\
    \ property, as shown in Figure 14. The possible states are shown in\nFigure 16.\n\
    irrig:MoistureProperty\nirrig:observableProperty_\nrootZone_moistureLevel\nirrig:RootZoneMoistureLevelState\n\
    irrig:state_rootZone_\nmoistureLevel_saturated\nsosa:hasState\nirrig:state_rootZone_\n\
    moistureLevel_veryHigh\nirrig:state_rootZone_\nmoistureLevel_high\nirrig:state_rootZone_\n\
    moistureLevel_average\nirrig:state_rootZone_\nmoistureLevel_low\nirrig:state_rootZone_\n\
    moistureLevel_veryLow\nirrig:state_rootZone_\nmoistureLevel_dry\nFigure 16. States\
    \ of root zone moisture level property.\nEach day, our system makes decisions\
    \ about the value of certain properties, such as crop growth,\nrain intensity\
    \ and root zone moisture level. These decisions are based on several sensor observations\n\
    performed during day d. Day d is represented by an interval of 24 h: [d 00:00:00,\
    \ d+1 00:00:00[.\nFor the synchronization of computations, the frequency of such\
    \ decisions should be ﬁxed to one precise\ntime. According to Météo-France, the\
    \ record of rain quantity per day is made between day d at 06:00:00\nto day d+1\
    \ at 06:00:00 [31]. This project considers that all the computations should be\
    \ available at a\nprecise time, ﬁxed at [d+1 06:00:00]. Each decision regarding\
    \ day d will be valid for an interval of\n24 h: [d+1 06:00:00, d+2 06:00:00[.\n\
    Figure 15 illustrates the time period regarding a RootZoneMoistureLevel deduction.\n\
    The\nphenomenon time represents day d. It is represented by a 24-h interval: [d\
    \ 00:00:00, d+1 00:00:00[.\nIn Figure 15, the time when the result of the deduction\
    \ is available is named the result time. It is ﬁxed\nat [d+1 06:00:00]. This result\
    \ is valid during a period of 24 h named valid time: [d+1 06:00:00,\nd+2 06:00:00[.\n\
    To store the time of the deduction, we use the sosa:resultTime datatype property\
    \ to links the\ndeduction individual to the xsd:dateTime corresponding to the\
    \ result time at [d+1 06:00:00]. This is\npresented in Figure 15.\nAppl. Sci.\
    \ 2020, 10, 1803\n32 of 41\nTo represent the fact that a deduction concerns day\
    \ d, we use the object property\nsosa:phenomenonTime. Day d is represented by\
    \ an instance of the class time:Interval, which is\ndescribed by two instances\
    \ of the class time:Instant:\n•\nOne instance represents the beginning of the\
    \ interval: [d 00:00:00]. The object property\ntime:hasBeginning links the instance\
    \ of time:Interval to the beginning time:Instant instance.\n•\nOne instance represents\
    \ the end of the interval: [d+1 00:00:00]. The instance of time:Interval is\n\
    linked to the ending time:Instant by the object property time:hasEnding.\nEach\
    \ instance of time:Instant has a time:inXSDDateTimeStamp data value, which precisely\
    \ indicates\nthe date and time of the instant.\nThe deduction result for day d\
    \ is valid for 24 h: [d+1 06:00:00, d+2 06:00:00[, i.e., no new\ndeduction will\
    \ be performed during this valid time. The valid time is represented by an instance\
    \ of the\nclass time:Interval, which is associated with two instances of the class\
    \ time:Instant as presented above.\nThe caso:hasValidTime object property, as\
    \ illustrated in Figure 15, links the deduction individual to\nthe valid time.\n\
    Figure 17 supports to clarify the synchronization of all the computations.\nd\
    \ 00:00:00\nd+1 00:00:00\nd+3 00:00:00\n06:00:00\n06:00:00\nt\nLegend\nClosed\
    \ boundary\nOpen boundary\nSoil30cmDepthMoistureObservation\nSoil30cmDepthDailyAverageMoistureObservation\n\
    t\nt\nt\n06:00:00\nd+2 00:00:00\nPhenomenon Time\nPhenomenon Time\nPhenomenon\
    \ Time\nValid Time\nResult Time\nPhenomenon Time\nRootZoneDailyAverageMoistureObservation\n\
    RootZoneMoistureLevelDeduction\nFigure 17. Time scales of the soil moisture workﬂow.\n\
    5.3. Implementation of the Reasoning Process in the Soil Moisture Workﬂow\nIn\
    \ this case, only one rule is required to determine the state of the RootZoneMoistureLevel\n\
    property. The reason is that all states of the RootZoneMoistureLevel property\
    \ are associated with\nan open upper boundary and a closed lower boundary, as\
    \ shown in Figure 9. In other words,\nFigure 18 shows that all transitions follow\
    \ the same pattern based on an upper and lower boundary:\n“When ( lowerBoundary\
    \ <= RootZoneMoistureLevelPerDay(d) < upperBoundary)”. The relation\nof a state\
    \ and its boundaries is also modeled in the IRRIG ontology.\nFor example, Figure\
    \ 18\nshows that the individual irrig:state_rootZone_moistureLevel_veryLow, an\
    \ instance of the class\nAppl. Sci. 2020, 10, 1803\n33 of 41\nirrig:RootZoneMoistureLevelState,\
    \ is associated with two instances of the class caso:Boundary titled\nirrig:boundary_rootZone_tension_veryLow\
    \ via the object property caso:hasOpenUpperBoundary,\nand irrig:boundary_rootZone_tension_low\
    \ via the object property caso:hasCloseLowerBoundary.\nThe individual irrig:boundary_rootZone_tension_veryLow\
    \ represents a threshold of 1600.0 mbar.\nThe individual irrig:boundary_rootZone_tension_low\
    \ represents a threshold of 1500.0 mbar. The\nstate corresponding to the individual\
    \ irrig:state_rootZone_moistureLevel_veryLow is reached\nwhen the root zone average\
    \ moisture per day is inferior to the value of the individual\nirrig:boundary_rootZone_tension_veryLow\
    \ and is superior or equal to the value of the individual\nirrig:boundary_rootZone_tension_low.\n\
    caso:hasOpen\nUpperBoundary\nom:hasUnit\ncaso:boundaryValue\nirrig:boundary_rootZone_\n\
    tension_maximum\ncaso:Boundary\nirrig:RootZoneMoistureLevelState\nirrig:state_rootZone_\n\
    moistureLevel_dry\nom:millibar\nom:Unit\n\"3010.0\"^^xsd:double\nirrig:boundary_rootZone_\n\
    tension_veryLow\ncaso:hasClose\nLowerBoundary\nom:hasUnit\ncaso:boundaryValue\n\
    \"1600.0\"^^xsd:double\nFigure 18. Boundaries of the state RootZoneMoistureLevel.Dry.\n\
    Table 5 shows the ﬁelds of the rule for the state of RootZoneMoistureLevel deduction.\
    \ All this\ninformation is stored in a ﬁle of the rules-base managed by Ontogen.\
    \ The “short name” ﬁeld contains\nthe code name of the rule. The “full name” ﬁeld\
    \ contains a full version name of the rule that is easier\nto understand. The\
    \ description of the rule is in the “description” ﬁeld. The content of the rule\
    \ encoded\nin SWRL that is used by the SWRLAPI Drools inference engine is in the\
    \ “Rule in SWRL” ﬁeld.\n5.4. Testing of the Reasoning Process in the Soil Moisture\
    \ Workﬂow\nThis section focuses on the testing results. In each test scenario,\
    \ the system takes an input value\nand produces an output result. It is possible\
    \ to evaluate the system by comparing the inferred output\nresults to the expected\
    \ outputs. There are a total of 21 test scenarios:\n•\n14 unit tests: Input values\
    \ are boundary values given by the testers around the threshold. Expected\noutputs\
    \ are manually calculated by the testers using the IRRINOV® method.\n•\n7 sample\
    \ tests: Input values are samples chosen in the Arvalis dataset. Expected outputs\
    \ are\nmanually calculated by the testers using the IRRINOV® method.\nTable 6\
    \ shows the results of the 14 unit test scenarios.\nThis table includes the four\n\
    following columns.\n•\nID test: the code name of the test scenario.\n•\nObservation:\n\
    the input is the observation value, which is the value of the function\ngetRootZoneDailyAverageMoisture(d).\n\
    •\nExpected deduction result: the state of RootZoneMoistureLevel calculated by\
    \ the testers.\n•\nDeduction result from the DSS: the state of RootZoneMoistureLevel\
    \ inferred by the DSS.\nPlease note that in this kind of test, the time of observation\
    \ has no impact on the result of the\ndeduction. Thus, this testing ignores this\
    \ kind of input.\nAppl. Sci. 2020, 10, 1803\n34 of 41\nTable 5. Rule for RootZoneMoistureLevel\
    \ property.\nShort name:\nADv122019-RM\nFull name:\nArvalisData-IrrigVersion122019-RootZoneMoistureLevel\n\
    Description:\nThe goal of this rule is to determine the state of RootZoneMoistureLevel.\
    \ The rule implements the transition\nfrom the Init state to one of the states\
    \ VeryLow, Low, Average, High, VeryHigh, Saturated (see Figure 10). The\ninput\
    \ of this rule is the root zone daily moisture (?result_observation_rootzone_moisture).\
    \ The output of this\nrule is the Root Zone Moisture Level deduction (?deduction_rootzone_moisturelevel).\
    \ The mechanism of this\nrule checks if the value of the root zone moisture is\
    \ in the value domain of two thresholds; it then concludes\nthe state correspondingly.\n\
    Rule in SWRL:\nirrig:RootZoneMoistureLevelDeduction(?deduction_rootzone_moisturelevel)\
    \ ˆ\nprov:used(?deduction_rootzone_moisturelevel, ?result_observation_rootzone_moisture)\
    \ ˆ\nom:hasNumericalValue(?result_observation_rootzone_moisture,?value_result_observation)\
    \ ˆ\ncaso:hasState(irrig:observableProperty_rootZone_moistureLevell,?state_rootzone_moisturelevel)\
    \ ˆ\ncaso:hasOpenUpperBoundary(?state_rootzone_moisturelevel,?boundary_upper)\
    \ ˆ\ncaso:boundaryValue(?boundary_upper,?value_boundary_upper) ˆ\ncaso:hasClosedLowerBoundary(?state_rootzone_moisturelevel,?boundary_lower)\
    \ ˆ\ncaso:boundaryValue(?boundary_lower,?value_boundary_lower) ˆ\nswrlb:lessThan(?value_result_observation,?value_boundary_upper)\
    \ ˆ\nswrlb:greaterThanOrEqual(?value_result_observation,?value_boundary_lower)\n\
    ->\ncaso:hasResultState(?deduction_rootzone_moisturelevel,?state_rootzone_moisturelevel)\n\
    Table 6. Unit tests of rules for the state of RootZoneMoistureLevel deduction.\n\
    ID Test\nObservation\n(Input)\nExpected\nDeduction Result\nDeduction Result\n\
    from the DSS\nmoistureLevel-Saturated-0\n0 cbar\nSaturated\nSaturated\nmoistureLevel-Saturated-9\n\
    9 cbar\nSaturated\nSaturated\nmoistureLevel-VeryHigh-10\n10 cbar\nVeryHigh\nVeryHigh\n\
    moistureLevel-VeryHigh-69\n69 cbar\nVeryHigh\nVery High\nmoistureLevel-High-70\n\
    70 cbar\nHigh\nHigh\nmoistureLevel-High-119\n119 cbar\nHigh\nHigh\nmoistureLevel-Average-120\n\
    120 cbar\nAverage\nAverage\nmoistureLevel-Average-139\n139 cbar\nAverage\nAverage\n\
    moistureLevel-Low-140\n140 cbar\nLow\nLow\nmoistureLevel-Low-149\n149 cbar\nLow\n\
    Low\nmoistureLevel-VeryLow-150\n150 cbar\nVeryLow\nVeryLow\nmoistureLevel-VeryLow-159\n\
    159 cbar\nVeryLow\nVeryLow\nmoistureLevel-Dry-160\n160 cbar\nDry\nDry\nTable 7\
    \ shows the results of the seven sample test scenarios. This table includes four\
    \ columns\nas follows.\n•\nID test: the code name of the test scenario.\nAppl.\
    \ Sci. 2020, 10, 1803\n35 of 41\n•\nDate:\nthe input value is the date of the\
    \ observation.\nFrom this date,\nthere is\na corresponding observation value.\n\
    The observation is the value of the function\ngetRootZoneDailyAverageMoisture(d).\n\
    •\nExpected deduction result: the state of RootZoneMoistureLevel calculated by\
    \ the testers.\n•\nDeduction result from the DSS: the state of RootZoneMoistureLevel\
    \ inferred by the DSS.\nTable 7. Sample tests of rules for the state of RootZoneMoistureLevel\
    \ deduction\nID Test\nDate (Input)\nExpected\nDeduction Result\nDeduction Result\n\
    from the DSS\nmoistureLevel-Saturated-26062013\n26/06/2013\nSaturated\nSaturated\n\
    moistureLevel-VeryHigh-16072013\n16/07/2013\nVeryHigh\nVeryHigh\nmoistureLevel-Low-21072013\n\
    21/07/2013\nLow\nLow\nmoistureLevel-High-26072013\n26/07/2013\nHigh\nHigh\nmoistureLevel-VeryLow-31072013\n\
    31/07/2013\nVeryLow\nVeryLow\nmoistureLevel-Average-03082013\n03/08/2013\nAverage\n\
    Average\nmoistureLevel-Dry-14082013\n14/08/2013\nDry\nDry\nThe deduction result\
    \ and the data related to each test are coded in Turtle format and stored in\n\
    a ﬁle with a “.owl” extension. The test ﬁles are available on the GitLab repository\
    \ of INRAE via the\nfollowing link https://gitlab.irstea.fr/irrig/public/tree/master/Testing.\n\
    6. Experimentation\nThe DSS or decision support application is an essential part\
    \ of the smart irrigation CAS. Each day,\nthe DSS produces an irrigation decision\
    \ as a suggestion for farmers. Comparing the results of these\nautomated decisions\
    \ with human decisions enable us to evaluate the DSS. The human decisions made\n\
    by irrigation experts are available in the experimental dataset provided by Arvalis\
    \ and INRAE, as\npresented in Section 4.1.\nThis section ﬁrst describes the methodology\
    \ used to evaluate this DSS. Moreover, a discussion on\nthe limitations of the\
    \ evaluation is raised at the end of this section to highlight the advantages\
    \ and\ndrawbacks of the DSS.\n6.1. Evaluation Methodology\nTo evaluate our system,\
    \ we selected several periods from the original dataset. Those periods\nshould\
    \ have different events that imply state changes in the observed properties. The\
    \ selected periods\nwere as follows:\n•\n[14/08/2013, 21/08/2013]: The period\
    \ has one light rain event.\n•\n[21/08/2013, 03/09/2013]: The period has one moderate\
    \ rain event.\n•\n[31/07/2013, 14/08/2013]: The period has two consecutive moderate\
    \ rain events.\n•\n[22/07/2013, 31/07/2013]: The period has a crop state change\
    \ and two rain events.\nEach period contains two consecutive watering days which\
    \ are the ﬁrst day and the last day\nin the period. For example, in the ﬁrst period\
    \ [14/08/2013, 21/08/2013], the watering days are\n14/08/2013 and 21/08/2013.\n\
    Then, we compared the day of the watering decision made by our DSS from the day\
    \ of the\nwatering decision made by the farmer. The comparison relies on the fact\
    \ that when both the farmer\nand the DSS follow the same rules of the IRRINOV®\
    \ method, then the watering decisions on the same\nAppl. Sci. 2020, 10, 1803\n\
    36 of 41\nconditions should be equivalent. Thus, when both the farmer and the\
    \ DSS decide to do a watering on\nthe ﬁrst day of each period, the next watering\
    \ day deduced by the DSS should be the last day of the\nperiod, in line with the\
    \ decision of the farmer.\nPlease note that with each period, the DSS takes the\
    \ human decision of the ﬁrst day as an input.\nIt produces its decision from the\
    \ second day of the period. For example, with the period [14/08/2013,\n21/08/2013],\
    \ the DSS takes the watering decision on day 14/08/2013. It deduces the decisions\
    \ from\nday 15/08/2013 to day 21/08/2013.\n6.2. Result and Analysis\nThe results\
    \ of the experiment over the four mentioned periods are shown in the four data\
    \ tables\nbelow. Each table includes 16 columns and several rows. The ﬁrst row\
    \ of the table contains the labels\nof the type of data in the column. Each one\
    \ from the second row contains the data corresponding to a\nday of the period.\
    \ Details of the ﬁrst row: The ﬁrst 13 cells are ﬁlled in gray to indicate that\
    \ the data in\nthe columns corresponding to these cells are input data; the 14th\
    \ and 15th cells are in red to indicate\nthat the data in the columns corresponding\
    \ to these cells are inferred results. The last cell is in green to\nindicate\
    \ that the data in the 16th column are the decisions of humans in reality. The\
    \ meaning of each\ncolumn is as follows.\n•\nThe ﬁrst three columns show the information\
    \ of the day, month, and year of the date.\n•\nThe fourth column shows the total\
    \ rain quantity of a day. Its unit is mm. When the rain quantity\nis greater than\
    \ 0, the cell is ﬁlled with blue.\n•\nThe ﬁfth column shows the number of delay\
    \ days. These data in this cell are calculated from the\ndata in the fourth column.\
    \ Its unit is the day. When the number of delay days is greater than 0,\nthe cell\
    \ is ﬁlled with blue.\n•\nThe next six cells correspond to six soil tensiometers.\
    \ These indicate the average soil moisture of\na day as measured by a soil tensiometer.\
    \ Its unit is cbar.\n•\nThe 12th cell shows the average root zone moisture of\
    \ a day. The data in this cell are calculated\nbased on the data in the six previous\
    \ cells. Its unit is also cbar.\n•\nThe 13th cell shows the crop state observed\
    \ by a human. If farmers recognize a new crop state\nand put it in the dataset,\
    \ then this state is written by the name code, and the cell is ﬁlled with\nyellow.\
    \ Otherwise, the text entered in the cell is “null”.\n•\nThe 14th cell shows the\
    \ value SleepingDuration inferred by the DSS. Its unit is the day.\n•\nThe 15th\
    \ cell shows the state of the CropWaterNeed. When CropWaterNeed reaches state\
    \ Yes, the\ntext in the cell is in uppercase, and the cell is ﬁlled with red.\n\
    •\nThe 16th cell shows the decision of farmers recorded in the dataset. The day\
    \ that farmers decide\nto water the plot, the corresponding cell is made green,\
    \ and the text inside the cell is “YES”.\nOtherwise, there is no text.\nFigure\
    \ 19 shows the results of the experimental period from 22/07/2013 to 31/07/2013.\
    \ The ﬁrst\nirrigation is performed on 22/07/2013. The farmer decides to schedule\
    \ the second irrigation on\n31/07/2013; however, the DSS suggests that the farmer\
    \ does nothing on the same day. The farmer\ndisobeys the IRRINOV® method in this\
    \ case, and he/she has a good reason. When the value of the\naverage root zone\
    \ moisture is 152 cbar, the root zone moisture level is low. If the root zone\
    \ moisture\nlevel is low and the crop growth is R1, then the crop needs water.\
    \ If following the IRRINOV® methods,\nthe farmer should wait at least two more\
    \ days because a rain event postpones the irrigation by four\ndays. The data of\
    \ SleepingDuration also reﬂect this calculation. The result of this experiment\
    \ proves\nthat the farmer decision may be different from the IRRINOV® method.\n\
    Appl. Sci. 2020, 10, 1803\n37 of 41\nFigure 19. DSS experiment during the period\
    \ from 22/07/2013 to 31/07/2013.\nFigure 20 shows the results of the experimental\
    \ period from 31/07/2013 to 14/08/2013. The ﬁrst\nirrigation is performed on 31/07/2013.\
    \ The second irrigation is scheduled by both the farmer and the\nDSS is on 31/07/2013.\
    \ This example shows that the farmer follows the IRRINOV® method and the\nDSS\
    \ gives a correct result based on this method. The DSS result is correct in this\
    \ case because there are\nrains on two consecutive days. The two rainy days are\
    \ 06/08/2013 and 07/08/2013. These two rainy\ndays produce seven delay days.\n\
    Figure 20. DSS experiment during the period from 31/07/2013 to 14/08/2013.\nFigure\
    \ 21 shows the results of the experimental period from 14/08/2013 to 21/08/2013.\
    \ The ﬁrst\nirrigation is performed on 14/08/2013. The second irrigation is scheduled\
    \ by both the farmer and the\nDSS is on 21/08/2013. This example shows that the\
    \ farmer follows the IRRINOV® method and the\nDSS gives a correct result based\
    \ on this method. The DSS result is correct in this case because of the\nlight\
    \ rain on 19/08/2013. There are no delay days in this period.\nFigure 21. DSS\
    \ experiment during the period from 14/08/2013 to 21/08/2013.\nFigure 22 shows\
    \ the results of the experimental period from 21/08/2013 to 03/09/2013. The\n\
    ﬁrst irrigation is performed on 21/08/2013. The farmer decides to schedule the\
    \ second irrigation\non 21/08/2013. However, the second irrigation is scheduled\
    \ by the DSS is two days sooner. From\nthis experiment, it is possible to conclude\
    \ that the farmer disobeys the IRRINOV® method one more\nAppl. Sci. 2020, 10,\
    \ 1803\n38 of 41\ntime. However, this time, the reason for the farmer is unclear.\
    \ From the data in the column of average\nroot zone moisture, the root zone is\
    \ at a dry state from 29/08/2013. Therefore, the decision following\nIRRINOV®\
    \ method is better than the decision made by the farmer, since the crops in the\
    \ latter case\nneed to wait for water more than those in the former case.\nFigure\
    \ 22. DSS experiment during the period from 21/08/2013 to 03/09/2013.\n6.3. Discussion\n\
    This section discusses the limitations of the IRRINOV® method, the limitations\
    \ of the Arvalis\ndataset and the limitations of the DSS system.\nFirst, the IRRINOV®\
    \ method is not a complete method for irrigation decisions. IRRINOV®\nprovides\
    \ guidelines for irrigation decisions based on crop variety, soil and region in\
    \ metropolitan\nFrance. This method is only dedicated to climate events that have\
    \ a greater chance of occurring in\nmetropolitan France. For example, the IRRINOV®\
    \ method ignores the fact that in summer, some daily\nrain events with high intensity\
    \ may occur for a long period, such as in tropical climates. Moreover, the\nIRRINOV®\
    \ method provides no guide about the amount of water that must be used for irrigation.\
    \ It\ndoes not take into account that a farmer may have some water restriction\
    \ usages. For example, one\nfarm may be allowed to water a plot only each week\
    \ on Monday morning.\nSecond, the irrigation decision in the Arvalis dataset is\
    \ a human decision, and humans can make\nerrors. For example, the ﬁrst watering\
    \ decision in the Arvalis dataset occurs on 08/07/2013. Following\nthe IRRINOV®\
    \ method, farmers should not water the crop on this day since the crop is at the\
    \ V7 state,\nand moisture sensor measurements do not reach the threshold. Maybe\
    \ the farmer has made an error,\nor maybe he has decided to water the plot sooner\
    \ because he knows that he will not be able to water\nthe plot in subsequent days\
    \ due to water restrictions.\nThird, the DSS provides automatic results that seem\
    \ to contain no errors. Unfortunately, the DSS\nis limited. The IRRIG ontology\
    \ and rules decision is dedicated to a maize crop on a speciﬁc type of soil.\n\
    If the irrigation decision concerns another crop or other soil, all the thresholds\
    \ for crop growth, root\nzone moisture level and crop watering property should\
    \ be changed. However, the rain intensity rule is\nthe same for all the IRRINOV®\
    \ guidelines regardless of the observed crop and type of soil. Thus, rain\nmodeling\
    \ and associated rules can be used. Fortunately, CASO contains the threshold deﬁnitions\n\
    associated with the state of the property. This means that a new ontology should\
    \ be deﬁned for each\ntype of crop and soil as long as some threshold values change.\
    \ However, our rules are generic, and\ntheir updates should be easy to implement.\
    \ Please note that in other systems, such as PLANTS, the\nthresholds are declared\
    \ inside the rules. Therefore, it is more difﬁcult to modify them.\n7. Conclusions\n\
    Precision agriculture needs CASs. A CAS that contains a WSN and a DSS can reduce\
    \ the work\nof farmers but also improve precision in farming activities. This\
    \ paper presents our experience in\ndeveloping a smart irrigation CAS. This system\
    \ has three advantages: (1) it automates a manual\nAppl. Sci. 2020, 10, 1803\n\
    39 of 41\nirrigation method based on the support of specialists and a real experimental\
    \ dataset, (2) it uses\ntwo new ontologies called CASO and IRRIG that extend other\
    \ well-known ontologies such as SSN\nand SAREF, and (3) it provides several rules\
    \ that can work for other similar systems. This paper\nﬁrst describes the methodology\
    \ of CAS development based on ontologies and details each step of\nthe proposed\
    \ methodology. Second, this paper also shares an example of development. Finally,\
    \ an\nevaluation of the DSS in this system is also published.\nA smart irrigation\
    \ CAS is a complex system. This system requires different roles to participate\n\
    and contribute to development, such as system developers, ontologists, farmers\
    \ and agronomists.\nIn developing the DSS, we encountered several challenges.\
    \ First, because of the participation of\ndifferent roles from different domains,\
    \ sharing the same vocabulary and understanding the agronomist\nmodel correctly\
    \ is complicated. Thanks to the SSN ontology and its precise modeling pattern,\
    \ the\ndesign activity produced a clear understanding of the output of each aggregation\
    \ process.\nSecond, the development of a DSS requires the development of ontologies.\
    \ There are many\nmethodologies used to develop an information system and other\
    \ methodologies used to develop an\nontology. To the best of our knowledge, this\
    \ work is the ﬁrst to combine the two types of methodologies.\nIn the case of\
    \ CASO and IRRIG, reusing standard and well-known ontologies was a decision made\n\
    to increase interoperability with other systems and datasets. However, in practice,\
    \ this activity was\nactually time-consuming. When reusing ontologies, one truly\
    \ needs to understand the semantics and\nconsequences behind every axiom and deﬁnition.\
    \ It becomes even more complicated when several\nontologies need to be combined,\
    \ such as SSN/SOSA and SAREF. Based on this experience, it can\nbe stated that\
    \ building an ad hoc model from scratch would require less time and consume fewer\n\
    resources; therefore, the decision of reusing ontologies is based completely on\
    \ whether interoperability\nis a requirement. In other words, should the sensor\
    \ streams be reused by several DSSs?\nThird, the dataset provided by Arvalis is\
    \ limited. Thus, to test the correctness and robustness of\nthe DSS, more datasets\
    \ should be used. As soon as the sensor network can be deployed on some maize\n\
    plots, our DSS will be tested on this new dataset. We plan to perform more experiments\
    \ in 2021.\nFinally, the IRRINOV® method itself cannot cover all situations; for\
    \ example, it does not deﬁne\nthe action when there are consecutive multiple rainy\
    \ days. However, the automatic irrigation system\nneeds a mechanism to address\
    \ this issue. One solution is to use machine learning to train the system\nover\
    \ data of different scenarios. If the training is sufﬁcient, the system can learn\
    \ the action based on\nthe scale of the IRRINOV® method.\nThe DSS is a part of\
    \ a smart irrigation CAS that will be deployed at the experimental INRAE farm\n\
    (The experimental farm is a part of the AgrotechnoPôle, an ecosystem for agricultural\
    \ machines and\ndigital information systems developed by an alliance of several\
    \ organizations and institutes in Europe.\nTwo members of the alliance dedicated\
    \ to develop AgrotechnoPôle are INRAE and LIMOS.) located at\nMontoldre in France.\
    \ In the future, the DSS system will be combined with other components, such as\n\
    networks, sensors and actuators, to form a complete smart irrigation system.\n\
    Author Contributions: Conceptualization, Q.-D.N., C.R. and M.P.-V.; Project administration,\
    \ J.-P.C.; Software,\nQ.-D.N.; Validation, Q.-D.N., C.R. and M.P.-V.; Writing—original\
    \ draft, Q.-D.N., C.R. and M.P.-V.; Writing—review\n& editing, C.d.V. and J.-P.C.\
    \ All authors have read and agreed to the published version of the manuscript.\n\
    Funding: The project “ConnecSens” and the project “I-Site Clermont - Programme\
    \ WOW! Wide Open to the World\n- CAP20-25” (16-IDEX-0001) has funded this research.\
    \ The CPER research project “ConnecSens” is co-ﬁnanced by\nthe Auvergne Rhône-Alpes\
    \ region in France via the program n° 1130 and by the European Union via FEDER\
    \ funds.\nAcknowledgments: We would like to thank Sophie Gendre from Arvalis and\
    \ Jacques-Eric Bergez from INRAE\nfor their helpful support of this project. We\
    \ also acknowledge the contributions of the “ETSI Specialist Task Force\n534:\
    \ SAREF extensions” project.\nConﬂicts of Interest: The authors declare no conﬂict\
    \ of interest.\nAppl. Sci. 2020, 10, 1803\n40 of 41\nReferences\n1.\nAbowd, G.D.;\
    \ Dey, A.K.; Brown, P.J.; Davies, N.; Smith, M.; Steggles, P. Towards a Better\
    \ Understanding\nof Context and Context-Awareness. In Handheld and Ubiquitous\
    \ Computing; Springer: Berlin/Heidelberg,\nGermany, 1999; Volume 1707, pp. 304–307.\n\
    2.\nSun, J.; De Sousa, G.; Roussey, C.; Chanet, J.P.; Pinet, F.; Hou, K.M. A new\
    \ formalisation for wireless sensor\nnetwork adaptive context-aware system: Application\
    \ to an environmental use case. In Proceedings of the\nTenth International Conference\
    \ on Sensor Technologies and Applications SENSORCOMM 2016, Nice, France,\n24–28\
    \ July 2016; pp. 49–55.\n3.\nJanowicz, K.; Haller, A.; Cox, S.J.; Le Phuoc, D.;\
    \ Lefrançois, M. SOSA: A lightweight ontology for sensors,\nobservations, samples,\
    \ and actuators. J. Web Semant. 2018, 56, 1. [CrossRef]\n4.\nETSI TS 103 264 -\
    \ v2.1.1. SmartM2M; Smart Appliances; Reference Ontology and oneM2M Mapping; Technical\n\
    report; ETSI: Sophia-Antipolis, France, 2017.\n5.\nNada, A.; Nasr, M.; Hazman,\
    \ M. Irrigation expert system for trees. Int. J. Eng. Innov. Technol. (IJEIT)\
    \ 2014,\n3, 170–175.\n6.\nKamienski, C.; Soininen, J.P.; Taumberger, M.; Dantas,\
    \ R.; Toscano, A.; Salmon Cinotti, T.; Filev Maia, R.;\nTorre Neto, A. Smart Water\
    \ Management Platform: IoT-Based Precision Irrigation for Agriculture. Sensors\n\
    2019, 19, 276. [CrossRef] [PubMed]\n7.\nWang, Y.; Wang, Y.; Wang, J.; Yuan, Y.;\
    \ Zhang, Z. An ontology-based approach to integration of hilly citrus\nproduction\
    \ knowledge. Comput. Electron. Agric. 2015, 113, 24–43. [CrossRef]\n8.\nWang,\
    \ Y.; Wang, Y. Citrus ontology development based on the eight-point charter of\
    \ agriculture. Comput.\nElectron. Agric. 2018, 155, 359–370. [CrossRef]\n9.\n\
    Goumopoulos, C.; Kameas, A.D.; Cassells, A. An Ontology-Driven System Architecture\
    \ for Precision\nAgriculture Applications. Int. J. Metadata Semant. Ontol. 2009,\
    \ 4, 72–84. [CrossRef]\n10.\nGoumopoulos, C.; O’Flynn, B.; Kameas, A. Automated\
    \ zone-speciﬁc irrigation with wireless sensor/actuator\nnetwork and adaptable\
    \ decision support. Comput. Electron. Agric. 2014, 105, 20–33. [CrossRef]\n11.\n\
    Perera, C.; Zaslavsky, A.; Christen, P.; Georgakopoulos, D. Context aware computing\
    \ for the internet of\nthings: A survey. IEEE Commun. Surv. Tutor. 2013, 16, 414–454.\
    \ [CrossRef]\n12.\nPoveda Villalón, M.; Nguyen, Q.D.; Roussey, C.; de Vaulx, C.;\
    \ Chanet, J.P. Ontological Requirement\nSpeciﬁcation for Smart Irrigation Systems:\
    \ A SOSA/SSN and SAREF Comparison. In Proceedings of the\n9th International Semantic\
    \ Sensor Networks Workshop, International Semantic Web Conference , CEUR\nWorkshop\
    \ Proceedings, Monterey, CA, USA, 9 October 2018; Volume 2213, pp. 1–16.\n13.\n\
    Arvalis; INRA; Chambre d’Agriculture. Guide de l’utilisateur, Carnet de terrain:\
    \ Piloter l’irrigation avec la\nméthode IRRINOV; Technical report 07X04; Arvalis:\
    \ Midy-Pyrénées, France, 2007.\n14.\nAbendroth, L.J.; Elmore, R.W.; Boyer, M.J.;\
    \ Marlay, S.K. Corn Growth and Development; Iowa State University:\nAmes, IA,\
    \ USA, 2011.\n15.\nMuller, P.A.; Gaertner, N. Modélisation objet avec UML; Eyrolles:\
    \ Paris, France, 2004.\n16.\nPoveda-Villalón, M. A Reuse-Based Lightweight Method\
    \ for Developing Linked Data Ontologies and\nVocabularies. In The Semantic Web:\
    \ Research and Applications; Simperl, E., Cimiano, P., Polleres, A., Corcho,\n\
    O., Presutti, V., Eds.; Springer: Berlin/Heidelberg, Germany, 2012; pp. 833–837.\n\
    17.\nGarcía-Castro, R.; Fernández-Izquierdo, A.; Heinz, C.; Kostelnik, P.; Poveda-Villalón,\
    \ M.; Serena, F. D2.2\nDetailed Speciﬁcation of the Semantic Model; Technical\
    \ report; Universidad Politécnica de Madrid (UPM):\nMadrid, Spain, 2017.\n18.\n\
    Suárez-Figueroa, M.C.; Gómez-Pérez, A.; Fernandez-Lopez, M. The NeOn Methodology\
    \ framework:\nA scenario-based methodology for ontology development. Appl. Ontol.\
    \ 2015, 10, 107–145. [CrossRef]\n19.\nLebo, T.; Sahoo, S.; McGuinness, D.; Belhajjame,\
    \ K.; Cheney, J.; Corsar, D.; Garijo, D.; Soiland-Reyes, S.;\nZednik, S.; Zhao,\
    \ J. Prov-o: The prov ontology. W3C Recommendation, 30 April 2013.\n20.\nBechhofer,\
    \ S.; Miles, A. Skos simple knowledge organization system reference.\nW3C Recommendation,\n\
    18 August 2009 .\n21.\nRijgersberg, H.; Van Assem, M.; Top, J. Ontology of units\
    \ of measure and related concepts. Semant. Web\n2013, 4, 3–13. [CrossRef]\n22.\n\
    W3C OWL Working Group. OWL 2 Web Ontology Language Document Overview, 2nd ed.;\
    \ W3c Recommendation\nW3C: Cambridge, MA, USA, 2012.\nAppl. Sci. 2020, 10, 1803\n\
    41 of 41\n23.\nMusen, M.A. The protégé project: A look back and a look forward.\
    \ AI Matters 2015, 1, 4–12. [CrossRef]\n[PubMed]\n24.\nGarijo, D.; Poveda Villalon,\
    \ M. A Checklist for Complete Vocabulary Metadata; Technical report; WIDOCO:\n\
    San Francisco, CA, USA, 2017.\n25.\nPoveda-Villalón, M.; Gómez-Pérez, A.; Suárez-Figueroa,\
    \ M.C. OOPS! (OntOlogy Pitfall Scanner!): An On-line\nTool for Ontology Evaluation.\
    \ Int. J. Semant. Web Inf. Syst. (IJSWIS) 2014, 10, 7–34. [CrossRef]\n26.\nAlobaid,\
    \ A.; Garijo, D.; Poveda-Villalón, M.; Santana-Perez, I.; Fernández-Izquierdo,\
    \ A.; Corcho, O.\nAutomating ontology engineering support activities with OnToology.\n\
    J. Web Semant. 2018, 57, 100472.\n[CrossRef]\n27.\nGarijo, D. WIDOCO: A wizard\
    \ for documenting ontologies. In Proceedings of the International Semantic Web\n\
    Conference; Springer: Berlin, Germany, 2017, pp. 94–102.\n28.\nMigliaccio, K.W.;\
    \ Olczyk, T.; Li, Y.; Muñoz-Carpena, R.; Dispenza, T. Using Tensiometers for Vegetable\n\
    Irrigation Scheduling in Miami-Dade County; Technical report ABE326, University\
    \ of Florida: Gainesville, FL,\nUSA, 2002.\n29.\nInternational Atomic Energy Agency\
    \ (IAEA). A Practical Guide To Methods, Instrumentation and Sensor\nTechnology.\
    \ In Field Estimation of Soil Water Content; Training course series 30, IAEA:\
    \ Vienna, Austria,\n2008; p. 141.\n30.\nBrouwer, C.; Prins, K.; Heibloem, M. Irrigation\
    \ water management: irrigation scheduling. Train. Man. 1989,\n4, 66.\n31.\nMétéo\
    \ France. Durées de Retour de Précipitations Journalier; Météo France: Paris,\
    \ France, 2019; pp. 1–10.\n© 2020 by the authors. Licensee MDPI, Basel, Switzerland.\
    \ This article is an open access\narticle distributed under the terms and conditions\
    \ of the Creative Commons Attribution\n(CC BY) license (http://creativecommons.org/licenses/by/4.0/).\n"
  inline_citation: '>'
  journal: Applied sciences (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/2076-3417/10/5/1803/pdf?version=1583938924
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: Development Experience of a Context-Aware System for Smart Irrigation Using
    CASO and IRRIG Ontologies
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/agriengineering4020029
  analysis: '>'
  authors:
  - Sargam Yadav
  - Abhishek Kaushik
  - Mahak Sharma
  - Shubham Sharma
  citation_count: 18
  full_citation: '>'
  full_text: '>

    Citation: Yadav, S.; Kaushik, A.;

    Sharma, M.; Sharma, S. Disruptive

    Technologies in Smart Farming: An

    Expanded View with Sentiment

    Analysis. AgriEngineering 2022, 4,

    424–460. https://doi.org/10.3390/

    agriengineering4020029

    Academic Editor: Lin Wei

    Received: 19 March 2022

    Accepted: 22 April 2022

    Published: 12 May 2022

    Publisher’s Note: MDPI stays neutral

    with regard to jurisdictional claims in

    published maps and institutional afﬁl-

    iations.

    Copyright:

    © 2022 by the authors.

    Licensee MDPI, Basel, Switzerland.

    This article is an open access article

    distributed

    under

    the

    terms

    and

    conditions of the Creative Commons

    Attribution (CC BY) license (https://

    creativecommons.org/licenses/by/

    4.0/).

    AgriEngineering

    Article

    Disruptive Technologies in Smart Farming: An Expanded View

    with Sentiment Analysis

    Sargam Yadav 1,†, Abhishek Kaushik 2,*,†, Mahak Sharma 3 and Shubham Sharma 4

    1

    School of Computing, Dublin Business School, D02 WC04 Dublin, Ireland; sargam.yadav@edhec.com

    2

    Department of Computing Science and Mathematics, Dundalk Institute of Technology,

    A91 K584 Dundalk, Ireland

    3

    Department of Education, VBGI of Educational Studies, Udaipur RJ SH 32, India;
    mahak10sharma@gmail.com

    4

    School of Food Science and Environmental Health, Technological University Dublin,

    D07 EWV4 Dublin, Ireland; shubham.sharma@tudublin.ie

    *

    Correspondence: abhishek.kaushik@dkit.ie

    †

    These authors contributed equally to this work.

    Abstract: Smart Farming (SF) is an emerging technology in the current agricultural
    landscape. The

    aim of Smart Farming is to provide tools for various agricultural and farming
    operations to improve

    yield by reducing cost, waste, and required manpower. SF is a data-driven approach
    that can

    mitigate losses that occur due to extreme weather conditions and calamities. The
    inﬂux of data from

    various sensors, and the introduction of information communication technologies
    (ICTs) in the ﬁeld

    of farming has accelerated the implementation of disruptive technologies (DTs)
    such as machine

    learning and big data. Application of these predictive and innovative tools in
    agriculture is crucial

    for handling unprecedented conditions such as climate change and the increasing
    global population.

    In this study, we review the recent advancements in the ﬁeld of Smart Farming,
    which include novel

    use cases and projects around the globe. An overview of the challenges associated
    with the adoption

    of such technologies in their respective regions is also provided. A brief analysis
    of the general

    sentiment towards Smart Farming technologies is also performed by manually annotating
    YouTube

    comments and making use of the pattern library. Preliminary ﬁndings of our study
    indicate that,

    though there are several barriers to the implementation of SF tools, further research
    and innovation

    can alleviate such risks and ensure sustainability of the food supply. The exploratory
    sentiment

    analysis also suggests that most digital users are not well-informed about such
    technologies.

    Keywords: smart farming; precision farming; unmanned vehicles; wireless sensor
    networks; senti-

    ment analysis; computer vision; Internet of things (IoT)

    1. Introduction

    Agriculture is an indispensable ﬁeld of study, as the continued survival of the
    human

    race depends on it. New and updated technology has been implemented throughout
    the

    ages in order to improve agricultural output and sustainability. The world’s population
    is

    expected to grow to approximately 9.7 billion by the year 2050 [1]. To keep up
    with this

    increase in population, food production needs to go up by 70%. However, the resources

    available to produce the required food output are steadily decreasing due to climate
    change

    and an increase in the number of settlements. Water levels are receding, arable
    lands are

    shrinking, and the environment is being rapidly degraded. The agricultural industry
    is

    also one the biggest contributors of greenhouse gases. The strain on the availability
    of

    food across the world is predicted to increase drastically with the increase in
    the world

    population over the next few decades [2,3]. Agriculture 4.0, or the fourth agricultural

    revolution, was discussed by the World Government Summit in 2018 in the report
    titled

    ‘Agriculture 4.0—The Future of Farming Technology’ [4]. The report highlights
    the need for

    more efﬁcient food production practices that can overcome the increasing food
    demand in

    AgriEngineering 2022, 4, 424–460. https://doi.org/10.3390/agriengineering4020029

    https://www.mdpi.com/journal/agriengineering

    AgriEngineering 2022, 4

    425

    coming years. It would be nearly impossible to keep up with this increase in demand
    with-

    out the integration of information and communication technologies (ICTs) and disruptive

    technologies (DTs) such as remote sensing, Internet of Things (IoT), machine learning,
    big

    data, etc., into the agricultural industry. Smart Farming is of great interest
    to researchers

    and scientists as it has yielded great results in reducing the ecological footprint
    of farm-

    ing [5], improving production efﬁciency [6], reducing human labor through unmanned

    vehicles [7,8], detecting diseases through image processing [9,10], and more.

    Precision farming is an approach that utilizes ICTs to monitor resources such
    as

    crops, ﬁelds, and animals [11]. It aims to maximize resource usage and crop yield
    while

    minimizing associated costs. The agricultural sector consumes a signiﬁcant amount
    of

    resources in the form of water, land, fertilizer, and energy. Precision farming
    is concerned

    with calculating the exact amount of resources required to grow plants and sustain
    livestock.

    Smart Farming (SF), which could be considered an extension of precision farming,
    focuses

    on utilization of data obtained from precision farming in an intelligent way and
    making crop

    production more efﬁcient by predicting crop yield [12,13], reducing wastage of
    resources,

    automating tasks [14], and providing agricultural management support [15]. It
    can also

    be used to perform soil analysis [16], so that crops of optimal quality can be
    grown. There

    have been several calamities in recent years that occurred due to climate change
    [17]. In

    light of these calamities, there is great need for smart farming to help manage
    agricultural

    activities. Due to the various risks and external factors associated with farming,
    such as

    weather extremities and plant diseases, implementation of data-driven predictive
    tools,

    which can be used to provide insights into farming operations such as crop yield,
    feed

    intake, weather conditions, soil conditions, etc., is crucial for mitigation [18].
    Decisions can

    thereby be made based on real-time data rather than heuristic, thumb-rule data.

    The availability of huge amounts of data from Internet of things (IoT) devices
    has

    allowed for application of big-data tools. The development of Artiﬁcial Intelligence
    (AI)

    tools has impacted the efﬁciency of a number of tasks associated with farming,
    suggesting

    that data-driven agriculture is a good approach to ensure agricultural sustainability.
    Cli-

    mate change is predicted to disproportionately impact smallholder farmers [19].
    Even a

    temperature variation of a few degrees will drastically affect smallholder farmers
    who are

    not adequately prepared for the situation. A substantial amount of crop losses
    occur due to

    weather events, which can be greatly mitigated through predictive weather modeling.
    This

    approach can help farmers navigate the agricultural risks that arise from the
    unprecedented

    deterioration of the environment, social and economic changes in the industry,
    and the

    increase in demand for food production. The availability of big data has the potential
    to

    revamp the entire food supply chain [20]. A global connectivity chain in farming
    will allow

    for the use of correctly priced products, better market positioning, and improved
    means of

    production. The use of ICT in farming will provide greater insight and advice
    on agricul-

    tural practices to farmers. The increase in visibility that comes with inter-connectivity
    of

    the supply chain is also likely to improve the productivity and conﬁdence of farmers
    in

    such practices.

    Agricultural tasks such as fertilizer and pesticide spraying, crop monitoring,
    seed

    planting, etc., can be automated through the use of Unmanned Aerial Vehicles (UAVs)

    and Unmanned Ground Vehicles (UGVs) [21]. Robots can be trained to autonomously

    plant saplings and move heavy pots, thus complementing human effort in the agricultural

    industry and reducing the farmer’s workload [22]. Autonomous vehicles never tire
    and can

    work around the clock. They also provide better accuracy and speed to improve
    the size of

    yields. With computer vision, autonomous vehicles can identify if the crops are
    ripe, ready,

    and disease-free. Lightweight sensors can be deployed on aerial vehicles to collect
    detailed

    information about crops and soil parameters through hyper-spectral imaging [23].
    Sensors

    can also be used to map various parameters such as type of land, crop, vegetation
    index,

    chlorophyll index, and water index [24]. Drones can help to create a precision
    map of a ﬁeld

    so that each part can precisely receive the resources it needs [25]. IoT is a
    major enabling

    technology that allows communication between the various sensors installed on
    the farm.

    AgriEngineering 2022, 4

    426

    IoT makes use of Wireless Sensor Networks (WSN), which can collect a large amount
    of

    data about the environment, crop production, cattle monitoring, and more [26].
    Information

    generated by IoT devices allows farmers to track farm operations and performance,
    and

    make informed decisions to improve farm productivity and yield. The massive amounts
    of

    data collected from the WSNs can be analyzed through technologies such as big
    data and

    deep learning. These technologies provide the added advantages of predictive modeling,

    real-time decision making, and adaptability to external factors. With the number
    of smart

    devices increasing steadily, the implementation of IoT in farms will increase
    interoperability,

    decrease losses due to human errors, and provide seamless uniﬁcation of information.

    Vertical farming, which is the practice of growing crops in a vertically stacked
    layer within

    a controlled environment for maximum growth, is one way to grow crops independently

    of local soil and climate conditions [27].

    The widespread implementation of smart farming tools faces several limitations

    and challenges depending on the geographical location of the project. One prominent

    barrier is the lack of internet connectivity, especially in rural areas. Such
    technology is not

    affordable for everyone. Without a stable internet connection agricultural sensors
    cannot

    communicate with each other. The initial cost of installation is high for any
    SF project,

    making it especially difﬁcult for smallholder farms to accept the risks. Further,
    the farmers

    implementing smart farming technologies may not fully understand the operation,
    ﬁnd the

    system too complex to use, or may be skeptical about its beneﬁts. Older farmers
    usually

    prefer traditional farming and are unwilling to learn to operate new technology
    [28]. The

    security and privacy of the data generated by sensors is also a concern, as there
    has to be

    an accountable party in case of mishandling or misuse [6]. This review paper highlights

    the current state-of-the-art ICTs and DTs that are applicable to the agricultural
    sector. The

    practical implementation of these technologies in particular projects across the
    world has

    also been covered, along with the limitations of the approaches and their potential
    to

    alleviate signiﬁcant concerns faced by farmers. Exploratory sentiment analysis
    has also

    been performed on comments collected from YouTube videos relevant to smart farming

    in order to determine public opinion regarding the implementation of these tools.
    This

    work aims to serve as a reference and motivation for further research in the adoption
    of

    technological tools in the agricultural industry.

    2. Motivation

    In this study, an in-depth exploration of recent advancements in the ﬁeld of smart

    farming is performed. It has always been a human endeavor to revolutionize agriculture

    by domesticating animals, planting crops in rotations, using pesticides and fertilizers,
    etc.

    The advent of ICTs has brought about the fourth agricultural revolution, or Agriculture

    4.0, which focuses on the use of limited resources on targeted areas. As discussed
    in

    the previous section, this is achievable with the help of sophisticated technologies
    such

    as unmanned vehicles, satellite imagery, sensors, and more. DTs such as AI have
    also

    greatly impacted the agricultural sector by improving efﬁciency, providing predictive

    analysis of yield, and mitigating production and market risks. Studies have shown
    several

    beneﬁts of using smart solutions in farming practices, such as reduction of necessary

    manpower, increase in yield, effective management of livestock, monitoring of
    crops and

    weather conditions, predictive analysis, and cost reduction. Several initiatives
    have been

    undertaken across the world that support the use of precision farming and smart
    farming

    while also providing insight on the speciﬁc limitations that were encountered.
    It is crucial

    that the ever-increasing global food demand is met, as the survival of the human
    race

    depends on it. Smart farming is capable of providing essential assistance to farmers
    to

    ensure sustainable food production. It can help farmers manage risks by providing
    speciﬁc

    weather forecasts, yield projections, likelihood of diseases, and more. It can
    thereby also

    increase proﬁts for the farmer, as the availability of data on risk assessment
    and external

    conditions can allow for optimal cultivation of crops. The motivation for conducting
    this

    study is to streamline the current state-of-the-art ICTs and DTs applicable to
    the farming

    AgriEngineering 2022, 4

    427

    sector, analyze components of various smart farming projects, discuss potential
    uses of

    such components, and list the common challenges that face the large-scale adoption
    of such

    techniques. The considerations for using smart farming in different geographical
    regions

    also needs to be discussed. The general attitude of people towards the adoption
    of any

    new technology is a great indicator of its perceived beneﬁts. To determine the
    consensus of

    the opinion on smart farming, we have performed a surface-level sentiment analysis
    on

    comments collected from YouTube channels relevant to smart farming. Thus, this
    work can

    serve as a point of reference for future research in the area of smart farming
    and can help

    researchers explore diverse technologies that are relevant to the topic.

    During this exploratory study, we formed the following two hypotheses, each with

    their respective research questions for further investigation:

    Hypothesis 1. ICTs and DTs can be used in the agricultural sector to make signiﬁcant
    improve-

    ments in several farming applications. The following research question was crafted
    to accept or

    reject the hypothesis:

    1.

    What are the state-of-the-art ICTs and DTs currently used in smart farming?

    Hypothesis 2. There are certain signiﬁcant challenges to the widespread adoption
    of smart farming

    tools, such as lack of awareness about the topic amongst the general population.
    The following

    research questions are explored in this context:

    1.

    What are the challenges associated with the widespread adoption of smart farming
    tools?

    2.

    What are the current opinions and expectations of the digital user with regards
    to smart

    farming?

    For this study, Google Scholar was used to perform exploratory analysis. Speciﬁc
    key-

    words, such as ‘plant disease detection’, ‘unmanned ground vehicles’, ‘precision
    livestock’,

    ‘big data’, etc., were selected. The searches were performed in the format [technology][smart

    farming]. For example, in order to search for articles that provided an overview
    of big-

    data applications in farming, the search phrase was ‘big data smart farming’.
    A total of

    30 keywords were grouped into six groups to analyze the number of citations for
    the top

    ﬁve results for each search. We attempted to exclude review papers that covered
    a few or

    all of the keywords. The number of citations for the top ﬁve results for each
    keyword is

    graphed in Figure 1 in six groups. The average number of citations for the top
    ﬁve results

    was calculated. The documents where the number of citations was greater than the
    average

    for that keyword were considered for the study.

    The rest of this paper is structured as follows: Section 3 covers the various
    ICTs and

    DTs, such as big data, IoT, cloud computing, AI, unmanned vehicles, blockchain,
    and

    decision support systems, that enable smart farming initiatives. Research efforts
    and

    projects that utilize such technologies in the agricultural sector are also discussed.
    Section 4

    covers state-of-the-art smart farming projects that have been launched and completed
    in the

    European Union and across the world. A brief overview of user sentiment towards
    smart

    farming technologies is conducted through comments collected from YouTube videos
    about

    smart farming in Section 5, in order to better encapsulate user perception towards
    such

    tools. Section 6 highlights the various challenges present in the widespread adoption
    of

    precision and smart agricultural practices. In Section 7, we discuss the ﬁndings
    of our study

    with respect to the two hypotheses formulated, followed by the conclusion in Section
    8.

    The structure of the paper is displayed in Figure 2.

    AgriEngineering 2022, 4

    428

    Figure 1. Number of citations per keyword for each of the 6 groups (a–f) of 5
    closely related keywords.

    The number of citations are compared for the top 5 search results.

    Figure 2. Structure of the paper.

    AgriEngineering 2022, 4

    429

    3. Technologies

    This section provides a thorough discussion of the key technologies that assist
    in the

    evolution of smart farming. These technologies include sensing systems, wireless
    sensor

    networks, IoT, unmanned vehicles, decision support systems, blockchain, and more.
    One

    or more of these tools has been used in collaboration for smart farming projects
    worldwide.

    The development of new sensors with improved sensitivity has allowed for the collection

    of higher-quality spatial and temporal data, which can be be analyzed for more
    timely and

    efﬁcient decision making. The advancements in remote sensing translate to reducing
    human

    time and effort, as less human intervention is required. Over the past few years,
    UAVs

    and UGVs have drastically improved in precision and have become more lightweight
    and

    cheaper, allowing for their easy adaption on large-scale farms. Wireless sensor
    networks

    can help the seamless functioning of sensors, autonomous vehicles, and decision-support

    systems to impact production at all stages. IoT platforms can allow control of
    daily farm

    activities through remote devices. Figure 3 classiﬁes the technologies implemented
    in smart

    farming, along with their most common applications. Table 1 provides a brief description

    of each technology along with some related works and applications.

    Figure 3. Technologies and applications.

    Table 1. Overview of ICTs in smart farming.

    Technology

    Description

    Applications

    Sensors

    A sensor is a device that detects changes

    in the physical environment and records

    this information for future analysis.

    Smart collars for monitoring cattle well-being [29]; Hyperspectral

    imaging of crop ﬁeld [24]; Greenhouse monitoring [30]

    IoT platforms

    IoT is a network of physical objects which

    share information across the internet.

    Real-time monitoring and management system for wheat diseases,

    pests, and weed [31]; IOT platforms using sensors to measure and

    monitor humidity using the NETPIE protocol [32]; Monitoring

    health status of dairy cows using IoT and wireless body area

    networks (WBANs) using LoRa [33]; AgriTech- framework of

    optimizing resources using IoT [34]; IoT-based system for remote

    monitoring of soil characteristics using DS18B20 sensor [35];

    Agri-IoT framework for IoT-based smart farming [36]; An

    IoT-based greenhouse monitoring system with Micaz motes [37];

    IoT-based agricultural stick integrated with Arduino technology

    and Solar technology for temperature and moisture monitoring [37]

    AgriEngineering 2022, 4

    430

    Table 1. Cont.

    Technology

    Description

    Applications

    Decision

    support

    systems

    DSS is an information system that assists

    in operational decision making by

    providing additional predictive insights.

    DSS for automatic climate control and minimizing diseases for

    greenhouse tomatoes [38]; AgriPrediction-LoRa IoT

    technology-based support system using ARIMA prediction

    model [39]; AgroDSS-cloud-based DSS for farm management [40];

    Web-based decision support system capable of supporting farmers

    in selecting appropriate alternative crops [41]

    Cloud/edge

    computing

    Cloud computing is the online delivery of

    hosted services, such as software, storage,

    and computation power. Fog/edge

    computing is a decentralized computing

    architecture between the cloud and

    connected peripheral devices that allows

    computation and storage closer to the

    edge devices.

    Cloud-computing-based system for early detection of borer insects

    in tomatoes [42]; cloud-computing-enabled spatio–temporal

    cyber–physical infrastructure (CESCI) for soil monitoring [43];

    Cloud-based farm management system (FMS) developed within

    FIWARE [44]; IoT-based smart farming system built upon FIWARE

    for fruit quality control [45]; IoT platform based on edge and cloud

    computing for soil-less culture needs in greenhouses [46];

    Fog-computing-based framework designed to provide a complete

    farming ecosystem [47]

    Blockchain

    A distributed, immutable ledger that

    keeps a record of all transactions of

    digital assets over a network.

    Smart contract-based authentication scheme [48]; model ICT

    e-agriculture system with a blockchain infrastructure and

    evaluation tool [49]; Blockchain-based secure smart greenhouse

    farming [50]; Ecological food traceability system based on

    blockchain and IoT technologies [51]

    3.1. Sensors

    The implementation of ICTs and DTs in farming is dependent on the availability
    of

    wireless connectivity. Remote sensing is crucial for IoT devices to function.
    Sensors serve

    as the basic building block in a wireless sensor network (WSN), which then handles
    the

    seamless communication between IoT devices. The advancements in sensing technology

    translate to the use of additional wavelengths in the light spectrum to remotely
    monitor

    crops, manage weeds, capture imagery, and more. Satellites and UAVs are equipped
    with

    thermal, visual light (RBG), and near infrared (NIR) cameras to capture multi
    or hyper-

    spectral images of the crop ﬁeld [24]. Hyper-spectral imaging divides light into
    thousands

    of smaller bands, which captures a lot of detail. Lightweight, hyper-spectral
    cameras can

    be used to monitor crop health, water and nutrient levels, and symptoms of a disease
    over

    large areas, which can be difﬁcult to access by other means. The availability
    of detailed and

    precise data also allows for spot application of resources and better decision
    making.

    The choice of technology to be used in a project relies heavily on the available
    band-

    width, transmission distance, and energy requirements. Wireless technologies that
    have

    been utilized in smart farming operations over the years include Bluetooth Low
    Energy

    (BLE), ZigBee, WiFi, 3G/4G/5G, LoRa, and more. Cellular networks (3G/4G/5G) serve

    the purpose of aggregating data from various sensors in a smart farming environment.

    Bluetooth Low Energy (BLE) provides coverage of 100 m and consumes less power
    than

    Bluetooth. It can be implemented in systems for livestock positioning [52], greenhouse

    monitoring [30], and more. BLE is not suitable for transferring large amounts
    of data [53].

    ZigBee is a WSN protocol that provides a smaller coverage area and low energy
    con-

    sumption. It can be used for scenarios such as solar power monitoring [54], greenhouse

    monitoring, etc. WiFi is beneﬁcial where high bandwidth and large amounts of data
    trans-

    fer is required. Cellular 3G/4G/5G networks offer wide coverage and low latency,
    but

    they drive up the cost and power consumption. LoRa can cover an area of 20 km
    and

    consumes less energy. Specialized sensors have been introduced for tasks such
    as pest

    identiﬁcation and control, plant health monitoring, resource level monitoring,
    etc. Bug

    detection and classiﬁcation can be performed using acoustic sensing devices and
    cameras,

    which capture factors such ﬂight behavior and humming sound [55]. Similarly, parasite

    detection was performed in study [56] using a spectral sensor that measures light
    waves.

    The difference in the reﬂected light pattern can be an indicator of infestation
    in the plant.

    AgriEngineering 2022, 4

    431

    López et al. [57] propose an autonomous monitoring system that uses a low-cost
    image

    sensor for visually inspecting bug traps deployed across the ﬁeld. Bioacoustic
    sensors

    have also been deployed to detect red palm weevil infestation in palm trees [58].
    Wireless

    sensors can be installed on leaves to monitor parameters such as humidity, water
    content,

    temperature, etc., to estimate the plant’s health and required amount of resources
    [59]. The

    growth rate of the plant stem and trunk can also be used to determine its health.
    Various

    sensors, such as the stem micro variation sensors, sap ﬂow relative rate sensors,
    stem ﬂux

    relative rate sensors, auxanometers, and trunk dendrometer, are used for this
    purpose [60].

    Environmental factors such as atmospheric pressure, solar radiation, wind speed,
    rainfall,

    temperature, and humidity can also be measured by wind speed and direction sensors,

    ambient seismic energy sensors, precipitation sensors, etc. [61]. Global navigation
    satellite

    systems (GNSS) can help increase efﬁciency in smart dairy farming. Smart collars
    can be

    worn by cows and can be used to collect data on the health and well-being of livestock
    [29].

    Farmers can program GPS collar trackers to keep cattle in a certain area. The
    cattle can then

    be sent to autonomous milking robots when their udders are full. The amount and
    quality

    of milk is then analyzed by the robots. Virtual fences can also prevent cattle
    from getting

    hurt on electric fencing and allow for rotational grazing [62].

    3.2. IoT Platforms

    IoT can enable devices and sensors to collect data about physical parameters of
    a

    farm. The functionalities provided by IoT, such as smart processing of data and
    real-time

    communication between devices, enable it to optimize agricultural practices [63].
    IoT

    blends the usage of physical devices such as actuators and sensors with a WSN
    to allow for

    seamless communication [26]. Sensors can serve as the peripheral devices that
    can gather

    information over a WSN which can then be analyzed with an IoT platform. There
    are

    currently several commercially available IoT platforms that aim to greatly reduce
    manual

    labor. They are utilized in various functions of crop monitoring. Zhang et al.
    [31] propose

    a monitoring system for wheat diseases, pests, and weed. The system collects data
    from

    IoT terminals and attempts real-time monitoring and management of crops. Lee et
    al. [64]

    implement a predictive system for effective pest control and proper utilization
    of pesticides

    and fungicides. Correlation is calculated between the pests and weather data relevant
    to

    the control of pests. Chieochan et al. [32] implement IoT sensors to monitor the
    humidity

    of a mushroom farm. The system controls sprinklers and fog pumps and provides
    push

    notiﬁcations to the user. Benaissa et al. [33] implement Wireless Body Area Networks

    (WBANs) in conjunction with IoT to monitor the health of dairy cows. Timely detection
    of

    health issues in the cattle is a costly and challenging task that was automated
    in the study

    through the use of a Long-Range (LoRa) off-body wireless channel and IoT. Garcia
    et al. [65]

    implement WSNs to monitor the presence of pests such as snails. The system is
    also capable

    of predictive analysis based on environmental factors such as temperature and
    humidity.

    Giri et al. [34] introduce an automation framework called AgriTech for adequate
    uti-

    lization of water, fertilizer, and pesticides. AgriTech allows the farmer to monitor
    the ﬁeld

    and perform actions such as spraying through the use of a mobile device. Kodali
    et al. [66]

    present the model of an IoT-based smart greenhouse that automatically carries
    out irri-

    gation, temperature and air humidity control, and water management with the help
    of

    sensors. In the study done by Na et al. [35], an IoT-based remote monitoring system
    is

    implemented to monitor soil characteristics such as pH, temperature, and moisture
    content

    using a DS18B20 sensor. Accurate measurement of such parameters can enable better

    analysis and decisions regarding fertilizer usage and crops sown. Kamilaris et
    al. [36]

    introduce Agri-IoT, a framework for analyzing real-time data streams from heterogeneous

    sensors that also supports decision making. It supports integration for data streams
    from

    multiple domains, data analytics, and interoperability for smart farming applications.

    Akkas et al. [37] implement a prototype of a wireless sensor network made up of
    MicaZ

    motes that monitor environmental variables such as temperature, light, pressure,
    and

    humidity in a greenhouse. The study highlights the advantages of implementing
    a WSN

    AgriEngineering 2022, 4

    432

    over traditional cabling within an IoT platform, such as costs, vulnerability,
    and inability to

    relocate the wiring system. Nayyar and Puri [67] propose the use of an IoT-based
    agricul-

    tural stick integrated with Arduino technology and Solar technology to capture
    live data

    on physical factors such as temperature and soil moisture. The system provided
    accuracy

    of 98% in live feeds when tested on live agricultural ﬁelds.

    3.3. Decision Support Systems (DSS)

    Decision support systems (DSSs) add value to the smooth functioning of farming

    practices by providing support to farmers, guiding them to correct information,
    assist-

    ing in decision making, and laying out the best course of action for a given scenario.

    The farm-wide availability of production rules and expertise can drastically improve
    efﬁ-

    ciency. Canadas et al. [38] propose a real-time decision support system implemented
    for

    greenhouse tomatoes that facilitates better decision making by identifying sensor
    faults,

    maintaining climate variables, and performing disease identiﬁcation on crops.
    The study

    highlights the effectiveness of the DSS in climate control and minimizing crop
    wastage

    due to diseases. Taylor et al. [68] perform a case study on web of things that
    highlights

    other useful applications of support systems such as environmental and livestock
    moni-

    toring. Dos Santons et al. [39] present AgriPrediction, an IoT-based support system
    that

    utilizes LoRa wireless network range system and the ARIMA predictive model to
    better

    manage crop dysfunctions. The system presents promising results, and is also shown
    to

    be applicable in rural areas with sparse connectivity. Kukar et al. [40] present
    AgroDSS,

    a novel cloud-based decision support system that allows farmers to perform predictive

    analysis on their own farm data. The system was implemented to study pest population

    and provide a better understanding of interdependencies of various parameters
    in a sim-

    ulated environment. The study done by Antonopoulou et al. [41] provides an approach

    for continued sustainability by allowing farmers to select alternate crops for
    a region. The

    system can be accessed through mobile devices to increase adoptability amongst
    farmers,

    and supports the farmer throughout the cultivation process. Thakare et al. [69]
    provide

    a DSS for remote monitoring that integrates smart sensing and smart irrigation
    systems

    to monitor parameters such as temperature, moisture content, and efﬁcient water
    use.

    The study emphasizes the importance of smart farming with hydroponics, which allows

    farming in unsuitable soil and water conditions.

    3.4. Unmanned Vehicles

    The advancement in robotics has led to the development of autonomous vehicles,

    which are used extensively in farming for mechanical weeding, fertilizer spraying,
    and

    harvesting. Unmanned vehicles have shown to decrease human labor, improve productiv-

    ity, reduce costs, and increase accuracy of measurements. They could be further
    classiﬁed

    into UAVs and UGVs. UAVs are aircraft embedded with wireless sensors, transmitters,

    and/or cameras that can function autonomously or be controlled remotely. UGVs,
    on

    the other hand, are autonomous machines that operate while in contact with the
    ground.

    The use of lightweight cameras with autonomous aerial vehicles can allow for remote

    monitoring of crops, which can allow for better decision making. Bareth et al.
    [70] per-

    formed a study to examine the usability of UAV-based multi-temporal crop surface
    models

    for estimating plant height, estimating the biomass through height measurement,
    and

    combining vegetation indices for more accurate estimation. The results obtained
    from

    ﬁeld experiments imply that UAV-based RGB imaging can provide accurate modeling
    of

    physical parameters of the plant. The review study done by Roldan et al. [71]
    highlights

    the advancement of robots in smart farming for automation of labor-intensive tasks
    such as

    planting, harvesting, monitoring, inspection, and treating crops. Unmanned vehicles
    are

    able to collect information about the environment and navigate it by using machine
    vision

    systems. They implement Global Navigation Satellite System (GNSS) technologies
    [72] to

    navigate precisely. UAVs provide an added advantage for remote sensing in the
    form of

    timely control and high spatial ground resolution. Remote imaging can capture
    several

    AgriEngineering 2022, 4

    433

    characteristics through different types of cameras, such as multispectral, thermal,
    and high

    spatial resolution RGB camera, as demonstrated in the study done by Matese et
    al. [73] to

    measure intra-vineyard variability and leaf temperature and to perform analysis
    of missing

    plants. UAVs possess the potential to obtain high spatial resolution imagery without
    being

    too affected by weather conditions.

    Lu et al. [74] perform species classiﬁcation in tall grassland with the use of
    high spatial

    resolution imagery obtained from a UAV, and show that the method obtains higher
    accuracy

    than other data from satellites. Tripicchio et al. [75] present a novel implementation
    of an

    RGB-D sensor integrated with UAVs to differentiate between different plowing techniques

    used on a ﬁeld. The system provides the functionality of computer vision, navigation,

    and data analysis and was shown to be a feasible technique for determination of
    soil

    characteristics. Moribe et al. [76] provide an effective and synchronized technique
    for

    measuring leaf temperature. Infrared thermometers attached to drones and sensor
    nodes

    integrate seamlessly with the WSN. Lottes et al. [77] propose a system that utilizes
    a UAV

    to detect vegetation, such as sugar beets, and performs feature extraction and
    maps the

    distribution of weeds and crops. UAVs provide an autonomous solution for monitoring

    large areas of agricultural land covering crops, livestock, and more. Unmanned
    vehicles

    function through the use of technologies such as robotics, IoT, remote sensing,
    and big

    data, and can automate labor-intensive tasks such as spraying, data collection,
    water

    management, weed mapping, irrigation, fertilization, crop monitoring and management,

    and ﬁeld-level phenotyping.

    3.5. Cloud/Edge Computing

    Given the vast amount of incoming data from various sources, a centralized approach

    to storing and managing large amounts of data is essential. A cloud-based architecture

    can allow for the necessary computation power to analyze the plethora of data
    obtained

    from the different types of sensors installed on a farm. Cloud computing facilitates
    ﬂexible

    storage and availability of data and resources, making them suitable for real-time
    implemen-

    tation. Rupanagudi et al. [42] propose a novel solution to pest control in tomatoes
    by crop

    monitoring using video processing, cloud computing, and robotics. Zhou et al.
    [43] present

    a cloud-computing-enabled spatio–temporal cyber–physical infrastructure (CESCI)
    to per-

    form comprehensive surface soil moisture monitoring, which can help reduce costs,
    increase

    agricultural productivity, and boost farmers’ net income. FIWARE is an open-sourced
    cloud

    platform that has shown potential in many smart farming applications. Kaloxylos
    et al. [44]

    present a cloud-based farm management system that utilizes the FIWARE architecture
    and

    was shown to be acceptable by farmers during evaluation. Corista et al. [45] introduce

    an IoT-based smart farming system built upon FIWARE that aims to control fruit
    quality

    during the entire fruit production chain. The system is developed using the vf-OS
    (virtual

    factory Operating System) platform, which integrates various applications and
    allows

    external producers and consumers to interact.

    Another IoT platform based on cloud and edge computing is proposed by

    Zamora et al. [46] and works in three tiers: the local plane collects data on
    crops, the

    edge plane monitors and manages the main precision agriculture (PA) tasks, and
    the cloud

    platform maintains records and performs data analytics. Fog computing, also called
    edge

    computing, is a decentralized computing architecture between the cloud and connected
    pe-

    ripheral devices and aims to enhance speed and performance [78]. Edge computing
    systems

    provide a decentralized approach to automation of tasks by using pre-loaded ﬁeld
    data

    from edge locations [79]. Thus, fog computing is a promising architecture for
    smart farming

    solutions, since it provides low latency and increased reliability for support
    systems [80].

    In case of real-time operational decision making, time is of the essence. Malik
    et al. [47]

    introduce a simulation platform that leverages fog computing to allow users to
    under-

    stand sensor deployment and data collection in a complete farming ecosystem. Thus,

    a cloud platform is essential if real-time analysis is to be performed. Use of
    additional

    data-driven approaches can be invaluable depending on the application. Cloud computing

    AgriEngineering 2022, 4

    434

    architecture can be used to manipulate large amounts of heterogeneous data arising
    from

    several sources. It can provide the necessary storage and computation resources,
    making it

    complementary to big data tools.

    3.6. Blockchain

    Blockchain technology provides new modes of interaction between parties in a supply

    chain. It is a distributed, immutable ledger that keeps a record of all transactions
    of digital

    assets over a network. It also has the capacity to improve food safety by providing
    traceabil-

    ity for purchased food products and monitoring for contamination. In order to
    avoid bias in

    the data collected from ICT and DT devices, it is important that data manipulation
    is made

    difﬁcult or impossible. The addition of a new record in a blockchain requires
    veriﬁcation

    from a peer-to-peer network, ensuring its legitimacy. Similarly, the majority
    should agree

    while making changes to records, making it difﬁcult for unauthorized individuals
    to alter

    the data. Thus, blockchain-based technologies for smart farming ensure that the
    data is

    correct, transparent, and traceable. In conjunction with smart contracts, which
    are protocols

    that are activated without human intervention when the terms of an agreement are
    met,

    blockchain technology can ensure timely payments [81]. Vangala et al. [48] propose
    an

    authenticated key agreement mechanism for smart farming that is based on smart
    contracts.

    The system is shown to provide more security and functionality than other authentication

    protocols. Patil et al. [50] present a security framework that combines blockchain
    technol-

    ogy with IoT devices and allows sharing of a digital ledger of transactions among
    the nodes

    on an IoT network. Lin et al. [51] introduce an ecological food traceability system
    that

    incorporates blockchain technology and IoT and aims to improve food safety while
    also

    establishing trust between the parties involved. The use of smart contracts is
    also consid-

    ered for the timely management of problems in the system. An ICT and DT e-agricultural

    system with blockchain technology that distributes water quality data over a network

    is proposed by Lin et al. [49]. They also present an evaluation tool that can
    be used to

    determine the speciﬁc requirements and suitability of this technology. A simulated
    model

    of blockchain technology is proposed by Widi Widayat et al. [82] and can be implemented

    in a smart farming environment. The parties in a smart farming system, namely
    farmers,

    food suppliers, and customers, are connected to a global blockchain network and
    appear

    as a node account in the smart contract. Another potential application of blockchain
    tech-

    nology is for providing agricultural insurance. Nguyen et al. [83] present a smart
    contract

    developed on NEO to provide drought-based crop insurance. This could be invaluable

    to farmers who work in extreme weather conditions, as it can reduce their damages
    and

    vulnerability while also avoiding excess evaluation costs.

    3.7. Big Data and Artiﬁcial Intelligence

    IoT devices and sensors capture various types of data from all over the ﬁeld that
    can

    then be analyzed through big data tools. Big data refers to larger and more complex
    datasets

    that consist of a greater variety of data from multiple data sources and can also
    be mined

    for opinions and information [84]. Data modeling techniques such as machine learning
    and

    deep learning can help enhance the entire food production cycle by performing
    predictive

    analysis, providing real-time decision making, and reﬁning the business model
    of the farm

    to cut loses. AI is a research sub-ﬁeld of computer science that utilizes robust
    datasets to

    solve problems by performing classiﬁcation or predictions based on the input data
    [85].

    Machine learning is a sub-ﬁeld of AI that allows models to learn from experience
    without

    being explicitly programmed. Deep learning is a sub-ﬁeld of machine learning that
    further

    eliminates some of the human intervention required in training by automating feature

    extraction from larger datasets [86]. Currently, there are also several types
    of state-of-the-

    art conversational systems being used to assist farmers in agricultural operations
    [87].

    Table 2 summarizes some notable research works in smart farming that have performed

    image processing using Convolutional Neural Networks (CNNs). CNNs are a class
    of

    Artiﬁcial Neural Networks (ANNs) that are used to perform classiﬁcation tasks
    on images

    AgriEngineering 2022, 4

    435

    by adjusting learnable weights and biases [88]. Table 3 provides a summary of
    various

    studies that have utilized other AI models in smart farming, along with their
    respective

    outcomes.

    AI can help reduce resource wastage through monitoring and predictive modeling.

    Varghese and Sharma [89] propose a hardware-based system that helps monitor factors

    such as moisture content in soil, humidity, and atmospheric conditions. The system
    also

    determines the appropriate crops for given soil and environmental conditions through
    the

    use of IoT and machine learning. Arvindan et al. [90] introduce an automated irrigation

    system that measures moisture content in the soil and provides remote control
    through

    an Android smart phone. This can help with the sustainable and automatic farming
    of

    certain crops that require different degrees of irrigation depending on their
    growth stage.

    Khaki et al. [91] introduce WheatNet, which is a CNN that collects ﬁeld observational
    data,

    such as wheat head counts. The system achieves a Mean Absolute Error (MAE) and
    Root

    Mean Squared Error (RMSE) of 3.85 and 5.19, respectively, in the wheat head counting
    task

    with fewer parameters, implying that the approach is robust and crucial for observation
    and

    decision making. Deep learning algorithms are used extensively to reduce crop
    wastage

    and optimize crop yield. The development of systems for accurate prediction of
    crop yield

    is essential, especially in developing countries, as it can secure food availability,
    prevent

    famine, and provide further assistance to the sustainable development of agriculture.
    Crop

    yield can depend on several factors, such as genotype, environment, etc. Wang
    et al. [12]

    present a deep-learning-based system for predicting soybean crop yields based
    on data

    collected from remote sensing. Long Short-Term Memory (LSTM) cells were trained
    and

    tested on 4 years of Argentinian soybean harvest data. The model’s transferability
    was

    then tested by using soybean harvest results from Brazil. Khaki et al. [13] implemented

    Deep Neural Networks (DNNs) for yield prediction of maize. The dataset consisted
    of

    the genotype and yield performance of 2267 maize hybrids. The best-performing
    model

    provided an RMSE of 12% of the average yield and 50% of the standard deviation
    for the

    validation dataset in imperfect weather conditions.

    Alfred et al. [92] provide a survey of the implementation of big data and machine
    learn-

    ing on paddy rice production in the Asia–Pacific region. The integration of sensors,
    satellites,

    and drones complements machine learning tools in improving productivity. Machine
    learn-

    ing tools utilize the big data collected from these devices for estimating rice
    yield [93,94],

    monitoring growth [94], and providing a smart irrigation system [95]. Kiruthika
    et al. [96]

    propose a system to detect paddy rice crop diseases such as leaf blast disease,
    brown spot

    disease, and bacterial blight disease. A Gray-Level Co-occurrence Matrix (GLCM)
    is used to

    recognize disease from the input image; two classifiers are used for recognition:
    ANN and

    Support Vector Machine (SVM). ANN performs better than SVM, with a precision of
    90.60%

    and accuracy of an 93.33%. Dahane et al. [97] propose a novel EDGE–fog–IoT–cloud-based

    architecture that utilizes WSNs to support farming activities in three steps:
    data collection

    from sensors (soil moisture, temperature, humidity, water level, etc.), data cleaning
    and

    storage, and predictive analysis through AI tools. Performance of Gated Recurrent
    Unit

    (GRU) and LSTMs on live data from three parameters is compared, with varying results.

    Jhuria et al. [9] propose a tool that utilizes ANNs to identify diseases in grapes
    and apples.

    Image processing is performed on an image dataset, and an accuracy of 90% is obtained
    based

    on color and texture. The study also provides a tool to determine the quality
    of fruit by

    weight. Bhange et al. [98] present a web-based tool for identification of fruit
    diseases trained

    on images of pomegranate fruit. The system processes an image uploaded by the
    user for

    parameters such as color and morphology, and classifies it as infected or non-infected
    using

    SVMs. Accuracy of 82% was recorded using the ‘morphology’ parameter in the experiment.

    Guo et al. [10] propose a system for identification of plant diseases through
    the use of deep

    learning. The model identifies black rot, bacterial plaque and rust diseases by
    implementing

    a Region Proposal Network (RPN) for leaf localization, the Chan–Vese algorithm
    for leaf

    segmentation, and VGG-13 [99] architecture for disease identification. This method
    provides

    an accuracy of 83.57%. In the study by Ferentinos [100], image classification
    through a VGG

    AgriEngineering 2022, 4

    436

    CNN is performed on a database of 87,848 photographs of leaves of healthy and
    infected

    plants in a set of 58 distinct classes of [plant, disease] combinations, and a
    success rate of

    99.53% is achieved. Similarly, smartphone-assisted crop disease diagnosis is performed
    by

    Mohanty et al. [101] on the PlantVillage dataset consisting of 54,306 images of
    plant leaves.

    The GoogleNet architecture performed the best out of all models tested, resulting
    in an

    accuracy of 99.35% on 14 crop species and 26 diseases. The prevention of fruit
    tree diseases

    can also significantly impact overall agricultural production. Li et al. [102]
    conducted a study

    comparing the performance of three ensemble learning classifiers and two deep
    learning

    classifiers. The stacking ensemble learning classifier provides the highest validation
    accuracy

    of 98.05% and test accuracy of 97.34% on a dataset of 10,000 images of pear black
    spot, pear

    rust, apple mosaic, and apple rust. Figure 4 displays a generalized example of
    plant disease

    identification through the use of CNNs. The network takes input in the form of
    segmented

    images and classifies them as ‘Diseased’ and ‘Not Diseased’.

    Figure 4. Disease identiﬁcation through image processing.

    Due to the rapid increase in global meat consumption, technologies such as precision

    livestock farming [103] have become essential to ensure the quality of meat products
    and

    reduction of the environmental impact. AI tools can also prove beneﬁcial in livestock

    management by monitoring cattle health and behavior. Xu et al. [104] propose a
    system for

    individual identiﬁcation of cattle through face detection, performed using the
    RetinaNet

    object detection algorithm. Fine-tuning was performed on seven different CNN models,

    and transfer learning was used for this study. RetinaNet incorporating the ResNet
    50

    provided the highest average accuracy of 99.8% and an average processing time
    of 0.0438 s.

    Gjergji et al. [105] evaluated the following neural networks for the regression
    task of cattle

    weight prediction: CNNs, Recurrent Neural Networks (RNN)/CNN networks, recurrent

    attention models, and recurrent attention models with CNNs. CNNs were shown to

    provide the best performance with MAE of 23.19 kg, signiﬁcantly outperforming
    the top

    linear regression models, which reached an error of 38.46 kg. Jung et al. [106]
    present a

    deep learning-based system for classiﬁcation of cattle vocals and real-time monitoring
    of

    livestock. The voice parameter of cattle can signal valuable information such
    as gender

    of cattle, distress, and disorders in the cattle [107]. The voice was converted
    to Mel-

    frequency cepstral coefﬁcients (MFCCs) and given as input to a CNN for classiﬁcation

    with an accuracy of 91.36%. The accuracy increased to 94.18% when short-time Fourier

    transform-based noise ﬁltering was used to reduce background noise. In the context
    of

    smart farming practices, deep learning has also been shown to be widely beneﬁcial
    in

    the ﬁeld of aquaculture. Fish production contributes to a great portion of the
    food source

    in any area. Zhang et al. [108] propose the use of DNNs for ﬁsh identiﬁcation,
    species

    classiﬁcation, analysis of ﬁsh behavior, feeding decisions, and water quality
    prediction. The

    method provided an accuracy of 96% and recognition rate of 98% when trained on
    the Fish 4

    knowledge dataset, which contains 8487 images of ﬁsh with different conditions.
    The study

    done by Rohani et al. [109] proposes a model consisting of multi-layer perceptron
    (MLP)

    and SVM for classiﬁcation of rainbow trout as dead or alive. Both classiﬁers provided

    an average accuracy of 100% during the training phase and average of 99.45% during

    the testing phase. Zambrano et al. [110] propose the use of machine learning tools
    to

    forecast water quality variables such as dissolved oxygen, pH, and pond temperature.
    A

    AgriEngineering 2022, 4

    437

    comparison is performed between Random Forests (RF), ANNs, and multivariate linear

    regression, out of which RFs performed the best.

    CNNs can also be used to perform object detection and pattern recognition on images

    collected by aerial vehicles to detect anomalies such as weed clusters, standing
    water, etc.

    Chiu et al. [111] introduce ‘Agriculture-Vision’, a large-scale dataset of aerial
    farmland

    images, designed for semantic segmentation of agricultural pattern recognition.
    The dataset

    consists of 94,986 high-quality aerial images consisting of RGB and near-infrared
    (NIR)

    channels. The study proposed a Feature Pyramid Network (FPN)-based model with
    a

    ResNet encoder to classify 9 ﬁeld anomaly patterns. The mean intersection-over-union

    (mIoU) was 43.40% for the validation set and 43.66% for the test set. The ﬁrst
    Agriculture-

    Vision Challenge [112] encouraged further development of novel algorithms for
    pattern

    recognition in agriculture. The challenge dataset consists of 21,061 aerial and
    multi-spectral

    farmland images, and six anomaly patterns were to be recognized in the task. The
    best-

    performing model, Residual DenseNet with Squeeze-and-Excitation (SE) block, introduced

    by Team DSCC, achieved a modiﬁed mIoU of 63.9%. The study by Kussul et al. [113]

    performs classiﬁcation of crops using MLPs, RFs, and CNNs. The dataset consisted
    of

    19 multitemporal scenes acquired by Landsat-8 and Sentinel-1A RS satellites, and
    the

    highest classiﬁcation accuracy of 94.6% was achieved by 2-D CNNs. Another crop
    vision

    dataset for species classiﬁcation and detection is the CropDeep [114] dataset,
    which consists

    of 31,147 images and at least 1500 samples for each of the 30 classes. A baseline
    study

    showed the best performing model was ResNet50, with an accuracy of 99.81%. The
    study

    further suggests the YOLOv3 network with modiﬁcation to achieve higher accuracy
    on

    the dataset. Anand et al. [115] present ‘AgriSegNet’, which is a multi-scale hierarchical

    attention network for semantic segmentation using UAV-acquired aerial images for
    IoT-

    assisted precision agriculture. The mIoU on the test set of the Agriculture-Vision
    dataset

    for the six anomaly classes are: Background: 78.10%; Double Plant: 46.40%; Planter
    Skip:

    8.60%; Standing Water: 61.20%; Waterway: 44.90%; Weed Cluster: 50.20%.

    Table 2. Summary of applications of CNNs in smart farming.

    Applications

    Results

    Plant disease detection through CNN [100]

    99.53% success rate

    Plant disease detection by CNN trained on 14 crop

    species and 26 diseases [101]

    99.35% accuracy

    CNN for identiﬁcation of 6 diseases in tomato

    leaves [116]

    AlexNet accuracy: 97.49%; VGG16

    net accuracy: 97.23%

    Plant disease detection by CNN trained on 13 crop

    species and 26 diseases [117]

    MobileNet accuracy: 99.62%;

    InceptionV3 accuracy: 99.74%

    Cattle face detection through CNN: Object detection

    algorithm RetinaNet incorporating ResNet 50 [104]

    Average precision score: 99.8%;

    Average processing time: 0.0438 s

    Beef cattle body weight prediction through CNN [105]

    Mean absolute error: 21.64 kg

    Holstein Friesian cattle detection and individual

    identiﬁcation through CNN [118]

    99.3% accuracy

    Species classiﬁcation and detection on the CropDeep crop

    vision dataset done by CNNs [114]

    Baseline study: ResNet50 average

    accuracy of 99.81%

    Classiﬁcation of crop types (maize, soybeans, etc.) done

    by MLPs, RFs, and CNNs [113]

    Highest accuracy of 94.6% by

    ensemble of 2-D CNNs

    FPN-based model for semantic segmentation of

    agricultural land on the Agriculture-Vision dataset [111]

    mean intersection-over-union (mIoU)

    was 43.40% for the validation set and

    43.66% for the test set.

    Residual DenseNet with squeeze-and-excitation (SE)

    block on the Agriculture-Vision challenge dataset [112]

    modiﬁed mIoU of 63.9%.

    AgriEngineering 2022, 4

    438

    In this subsection, we emphasize several points regarding the opportunities provided

    by AI in the ﬁeld of smart farming. Image processing is of great importance to
    the agricul-

    tural sector. Images captured by UAVs, UGVs, satellites, and sensors need to be
    analyzed so

    that relevant insight can be extracted from them to assist in farm operations.
    Depending on

    the requirements, different types of cameras, such as visible spectrum, NIR, hyperspectral,

    or multispectral may be used. In conjunction with several ICTs, AI can efﬁciently
    perform

    functions such as crop monitoring, livestock monitoring, disease detection, pest
    detection,

    etc. Predictive modeling can help farmers to prepare for extreme weather conditions
    and

    market ﬂuctuations, thereby lowering their vulnerability. Current state-of-the-art
    models

    have provided promising results, implying that further research in the area with
    more

    advanced AI tools can help to bridge the gap in food production.

    Table 3. Summary of applications of Artiﬁcial Intelligence in Smart Farming.

    Applications

    Results

    K-means for clustering; SVM for classiﬁcation of

    pomegranate diseases [98]

    82% accuracy (morphology)

    ANN for disease detection in grapes and apples [9]

    90% accuracy (morphology)

    RPN for localization of leaves; ChanVese algorithm for

    segmentation; transfer learning model for disease

    identiﬁcation [10]

    83.57% accuracy

    ANN for paddy crop disease detection [96]

    93.33% accuracy

    Fruit disease identiﬁcation by stacking ensemble learning

    classiﬁer trained on apple and pear diseases [102]

    Accuracy of 98.05% on validation

    dataset and 97.34% on test dataset

    UAV-based plant/weed classiﬁcation with Random

    Forests [77]

    Crop vs. weed classiﬁcation accuracy

    of 96% and 90% recall

    Soybean crop yields in Argentina using LSTMs; Transfer

    learning approach for Brazil soybean harvests [12]

    RMSE of 0.54 for Argentina and 0.38

    for Brazil (transfer learning

    from Brazil)

    Deep neural network (DNN) for yield prediction of

    maize hybrids [13]

    Yield prediction: training

    RMSE = 10.55, validation RMSE:

    12.79 for DNN

    Classiﬁcation of ﬁsh in aquatic ﬁsh farms through

    DNN [108]

    Accuracy = 96%, recognition

    rate = 98%

    Random Forests for forecasting water quality variables

    such as dissolved oxygen, pond temperature, etc. [110]

    RMSE for pond temperature = 0.5971,

    RMSE for dissolved oxygen = 1.616.

    Recognition and classiﬁcation of dead and alive rainbow

    trout eggs done by MLP and SVM [109]

    Training accuracy = 100%; average

    testing accuracy = 99.45%

    4. Initiatives Worldwide

    This section includes the various research initiatives that have been undertaken
    in

    smart farming in the European Union [119] and across the world. The initiatives
    usually

    employ several of the ICTs and DTs discussed in Section 3. The European Union
    has

    funded many projects to allow for the integration of ICTs and DTs into the agricultural

    sector. Crop monitoring is one of the major functions performed in farms that
    utilize

    smart farming tools. Table 4 provides an overview of the recent projects concerning
    the

    implementation of SF tools for crop monitoring that have been undertaken in the
    European

    Union. Table 5 lists the projects that perform other functions such as harvesting,
    water

    management, satellite imagery, and more. The corresponding technologies for each
    project

    have also been listed along with their application. The Echord++ [120] project,
    which

    lasted from 1 October 2013 to 30 September 2018, involved various ﬁeld operations
    such as

    monitoring, harvesting, and grafting for crops such as tomatoes, asparagus, and
    peppers.

    Cloud computing is utilized by many projects that require monitoring operations.
    These

    AgriEngineering 2022, 4

    439

    include Vinbot [121] (crop monitoring and yield prediction in a vineyard), Ermes
    [122] (crop

    monitoring for rice), Fractals [123] (monitoring, disease detection, and fertilization
    of olive

    trees), and more. The importance of UAVs and UGVs is apparent, as they have been
    utilized

    in several projects. Implementations of UGVs include Vinerobot [124] for a vineyard,

    Sweeper [125] for harvesting peppers, Flourish [126] for monitoring and spraying
    sugar

    beets and sunﬂowers, PANtHEOn [127] for monitoring hazelnuts and water management,

    and Romi [128] for crop monitoring and weed management. UAVs are utilized for
    crop

    monitoring of rice in Ermes [122], potatoes and vineyard in Mistrale [129], and
    more.

    Seamless communication between different technologies has been executed through
    the use

    of WSNs, such as Water-Bee [130] and Figaro [131], for the purpose of water management.

    Table 4. Smart Farming projects in EU for crop monitoring.

    Project Name

    Technologies

    Operations

    Echord ++ [120]

    Cloud computing; Image processing; Machine

    learning; UAV; UGV

    Crop monitoring; Harvesting; Weed

    management

    Vinerobot [124]

    Image processing; Machine learning ; UGV

    Crop monitoring; Disease detection;

    Water management

    Vinbot [121]

    Cloud computing; Image processing; UGV

    Crop monitoring; Yield prediction

    Flourish [126]

    Image processing; UAV; UGV

    Crop monitoring; Spraying

    PANtHEOn [127]

    Big data; UAV; UGV; WSN

    Crop monitoring; Water management

    Ermes [122]

    Big data; Cloud computing; UAV; WSN

    Crop monitoring

    Fractals [123]

    Cloud Computing; WSN

    Crop monitoring; Disease detection

    Mistrale [129]

    Image processing; UAV

    Crop monitoring; Water management

    Romi [128]

    UAV; UGV

    Crop monitoring; Weed management

    Apollo [132]

    Aerospace sensing

    Crop monitoring

    AgriCloud P2 [133]

    Cloud computing; Edge computing; Information

    systems; Terrestrial sensing

    Crop monitoring

    Sensagri [134]

    UGV; Terrestrial sensing; Aerospace sensing

    Crop monitoring

    IoF2020 [135]

    Cloud computing; UAV; UGV; Big data; Aerospace

    and terrestrial sensing; Information systems

    Crop monitoring; Livestock farming;

    Dairy monitoring

    DataBio [136]

    Machine learning; Big data; Aerospace and

    terrestrial sensing; Cloud computing

    Crop monitoring; Forestry; Fishery

    Apmav [137]

    Big data; Machine learning; UAV; Terrestrial

    sensing; Cloud computing

    Crop monitoring

    AfarCloud [138]

    Big data; Terrestrial sensing; UGV

    Crop monitoring; Livestock farming

    BigDataGrapes [139]

    Machine learning; Big data; UAV; Terrestrial

    sensing; Cloud computing; Information systems

    Crop monitoring

    Dragon [140]

    Machine learning; Big data; UAV; UGV; Aerospace

    and terrestrial sensing; Information systems

    Crop monitoring

    There have been several research projects on smart farming taken up all over the

    world, in part inspired by the positive outcomes of the EU projects. Table 6 provides
    a

    summary of government projects and start-ups that focus on the development of
    innovative

    solutions for smart farming. Some projects, such as the Villages of Excellence
    (VoE),

    have been launched in collaboration between two governments to ensure the sharing
    of

    technology and expertise and provide better outcomes for both. Smart irrigation
    plays

    an important role in ensuring crop sustainability in dry areas. Startups such
    as Madar

    Farms [141] and Responsive drip irrigation [142] aim to provide smart irrigation
    solutions

    to tackle water challenges and food security in the United Arab Emirates and the
    United

    AgriEngineering 2022, 4

    440

    States respectively. SunCulture [143] is a Kenyan AgriTech company that provides
    solar-

    powered irrigation systems for smallholder farms, and also provides the option
    of a drip

    irrigation system. In Morocco, the government introduced the Green Generation
    2020–2030

    strategy [144], which focuses on the digitization of agriculture through initiatives
    such as

    the installation of solar pumps for irrigation. Food security and sustainability
    are of great

    concern worldwide. Startups such as AbyFarm [145] in Singapore aim to implement
    urban

    farming by employing ICT and DT tools such as IoT and blockchain. Lack of resources

    in rural areas could be a hindering factor in crop yield. Ossian Agro Automation
    [146] is

    an Indian company working towards rural automation and the development of wireless

    automation systems. All year round production of crops can be achieved by vertical

    farming, which is the practice of growing crops in many layers in a controlled
    environment.

    Ground vertical farming [147] in Lebanon implements vertical farming and aims
    to reduce

    water wastage by re-circulation. Figure 5 displays the various smart farming projects
    taken

    up across the world, classiﬁed according to their primary function.

    Figure 5. Smart Farming initiatives worldwide

    In several developing countries, there is a lack of government-funded projects.
    The

    initiative is rather taken up by individual startups, with the goal to provide
    assistance to

    farmers, conduct further research, and educate farmers and learners about the
    potential

    of agricultural technology. There is an increased interest amongst consumers,
    who want

    to ensure that the end product they receive is unadulterated. Public opinion in
    Europe

    skews in favor of healthy products grown with minimum pesticides. Consideration
    of the

    socio–economic impact of smart farming projects is also necessary. Certain participating

    farms have reported average cost savings of over €5000 and reduction of climate
    impact by

    10% [148]. Thus, these initiatives have been greatly beneﬁcial to farming operations
    by de-

    creasing costs, reducing greenhouse emissions, and improving soil conditions.
    The projects

    contributed signiﬁcantly to their objectives of reducing resource wastage, environmental

    impact, and energy consumption, and demonstrated measures to mitigate issues resulting

    from climate change and the shortage of skilled labor.

    AgriEngineering 2022, 4

    441

    Table 5. Smart Farming projects in EU.

    Project Name

    Technologies

    Operations

    Sweeper [125]

    Image orocessing; UGV

    Harvesting

    Figaro [131]

    WSN

    Water management

    Enorasis [149]

    WSN

    Water management

    WEAM4i [150]

    Cloud computing; WSN

    Water management

    CHAMPI-ON [151]

    Image processing; Machine learning

    Harvesting

    Auditor [152]

    Aerospace sensing

    Satellite imagery

    RUC-APS [153]

    Cloud computing; Edge computing; Information

    systems

    Management; Optimization

    AfriCultuReS [154]

    Big data; Aerospace and terrestrial sensing;

    Cloud computing; Information systems

    Food security

    SWAMP [155]

    Big data; UAV; Terrestrial sensing; Cloud

    computing; Information systems

    Water Use

    Water4Agri [156]

    Aerospace sensing

    Water Use

    Table 6. Smart Farming initiatives worldwide.

    Project/Company

    Country or Countries

    Objectives

    Villages of Excellence (VoE)

    (2021–2023) [157]

    India and Isreal

    Improve the productivity and quality of

    horticulture; Increase income of farmers

    Nosho Navi 1000

    (2014–2016) [158]

    Japan

    Large-scale smart rice farming

    AbyFarm [145]

    Singapore

    IoT, blockchain and machine learning for urban

    farming to ensure sufﬁciency of crops

    Smart Farming for the

    Future Generation

    (2019–2023) [159]

    Vietnam and Uzbekistan

    Development of policies, enhancement of skills

    and knowledge. Support farmers through

    post-harvest handling and markets

    AgriEdge [160]

    Morocco

    Precision agriculture platform for practices such

    as efﬁcient use of water and fertilizer, monitoring

    weather data, and satellite imaging.

    Generation Green

    2020–2030 [144]

    Morocco

    Introduction of new technologies for sustainable

    agriculture; Installation of over 100,000 solar

    pumps for irrigation

    Baramoda [161]

    Egypt

    Sustainable agriculture; Maximize the efﬁciency

    of agri-waste management

    Ground–Vertical

    farming [147]

    Lebanon

    Improve efﬁciency of agricultural yield; Reduce

    water consumption and costs.

    Robinson Agri [162]

    Lebanon

    Greenhouse technology; Distribution of

    agricultural resources

    Kenya Climate Smart

    Agriculture Project

    (KCSAP) [163]

    Kenya

    Improve productivity in case of climate change

    risks and provide response in emergencies

    MimosaTek [164]

    Vietnam

    IoT platforms for precision farming solutions

    Ossian Agro

    Automation [146]

    India

    Wireless automation systems (Nano Ganesh) for

    irrigation in rural areas

    SunCulture [143]

    Kenya

    Solar-powered irrigation systems (RainMaker2)

    Madar Farm [141]

    United Arab Emirates

    Ensure food and water security

    Responsive Drip

    Irrigation [142]

    United States of America

    Smart irrigation

    Lentera Africa [165]

    Kenya

    Technology enabled farmer advisory services;

    Farm inputs and equipment

    AgriEngineering 2022, 4

    442

    5. Sentiment Analysis

    In order to ensure successful integration of new tools and technologies available
    for

    smart farming, it is necessary to understand how knowledgeable the general public
    is

    about the topics and how the innovations are perceived. Public sentiment can be
    a strong

    determinant of whether or not a project is approved for implementation in an area
    [166].

    It can also be indicative of the various socio–economic, behavioral, and cultural
    issues

    that arise by the advancement and implementation of such technology [28,167].
    In light of

    this, we performed sentiment analysis on the comments of YouTube videos pertaining
    to

    smart farming technologies. This section provides details about the dataset, experimental

    methodology, and the results and analysis of the experiment.

    5.1. Dataset

    The dataset was constructed by scraping YouTube comments left by users on 16 YouTube

    videos that were relevant to our study [168–172]. The videos were selected by
    searching

    the relevant keywords, such as ‘smart farming IoT’, and then ﬁltering the ones
    with most

    views and comments. Table 7 provides a list of the video titles, the channels,
    upload date,

    and the total number of likes and views on each video. For this study, only comments

    in English were considered. A total of 7311 comments were included in the dataset
    from

    videos about smart farming.

    5.2. Experiment

    Two approaches were used for performing sentiment analysis. In the first approach,
    two

    annotators assigned one of the following six labels to the comments: ‘Praising’,
    ‘Queries’,

    ‘Suggestions’, ‘Undefined’, ‘Hybrid’, and ‘Opinion’. Cohen’s kappa coefficient,
    which is a

    measure of inter-rater agreement, was calculated on the ratings of the two annotators.
    The

    value of the kappa statistic ranges from 0 to 1, with 0 implying only a chance
    agreement and 1

    implying perfect agreement between the two annotators. The formula to calculate
    Cohen’s

    kappa for two raters is:

    κ = po − pe

    1 − pe

    = 1 − 1 − po

    1 − pe

    (1)

    where: po = the relative observed agreement among raters, and pe = the hypothetical

    probability of chance agreement.

    A brief description of these labels is given in Table 8, along with the total
    number of

    comments for each label, and an example of the label from the dataset. Table 9
    gives the total

    counts of each of the six labels that were assigned to the comments collected
    from the videos.

    Table 7. Videos selected for sentiment analysis.

    Video

    Serial

    No.

    Video Title

    Channel

    Total Likes

    (Accessed

    on—14 April 2022)

    Uploaded On

    No. of

    Views

    1.

    How Japan Is Reshaping Its Agriculture By

    Harnessing Smart-Farming Technology

    Science Insider

    1100

    8 March 2021

    35,000

    2.

    Europe has the best regenerative farmers in

    the world

    Richard Perkins

    543

    8 October 2020

    16,000

    3.

    The Futuristic Farms That Will Feed the World

    Freethink

    22,000

    19 August 2019

    805,000

    4.

    Vertical farms could take over the world

    Freethink

    26,000

    22 May 2021

    753,000

    5.

    India’s largest Precision Farm—Simply Fresh

    Discover Agriculture

    2500

    12 March 2021

    70,000

    6.

    Solar Panels Plus Farming?

    Agrivoltaics Explained

    Undecided with Matt

    Ferell

    59,000

    5 October 2021

    1.9 million

    7.

    7 Israeli Agriculture Technologies

    Israel

    35,000

    21 January 2019

    2 million

    AgriEngineering 2022, 4

    443

    Table 7. Cont.

    Video

    Serial

    No.

    Video Title

    Channel

    Total Likes

    (Accessed

    on—14 April 2022)

    Uploaded On

    No. of

    Views

    8.

    The CNH Industrial Autonomous Tractor

    Concept (Full Version)

    CNH Industrial

    17,000

    30 August 2016

    2.7 million

    9.

    IoT Smart Plant Monitoring System

    Viral Science—the

    home of creativity

    6800

    20 December 2020

    341,000

    10.

    Singapore’s Bold Plan to Build the Farms of

    the Future

    Tomorrow’s Build

    30,000

    13 July 2021

    1.8 million

    11.

    Smart Vertical Farms in Sharjah

    Episode Up

    1200

    17 September 2020

    59,000

    12.

    Drones, robots, and super sperm—the future

    of farming

    DW Documentary

    6700

    7 February 2019

    919,000

    13.

    Simply Fresh—India’s Largest State Of The Art

    Precision Farm

    Simply Fresh

    7100

    10 October 2020

    314,000

    14.

    RIPPA The Farm Robot Exterminates Pests

    And Weeds

    ABC Science

    8800

    14 May 2018

    813,000

    15.

    Top 10 Agritech Startups Empowering

    Indian Farmers

    Backstage With

    Millionaires

    11,000

    9 June 2020

    325,000

    16.

    This Farm of the Future Uses No Soil and 95%

    Less Water

    Stories

    152,000

    5 July 2016

    152,000

    The second approach was to apply transfer learning to perform surface level sentiment

    analysis using the pre-trained Pattern library for Python. Pattern library can
    be used to

    perform various natural language processing tasks such as parsing, N-gram generation,

    and more. Polarity of a given text ranges from 1 to −1, with 1 representing a
    highly positive

    sentiment and −1 representing a highly negative sentiment. The subjectivity ranges
    from

    0 (Objective) to 1 (Subjective). It provides a measure of factual information
    or personal

    opinion in the comments, with 1 being subjective and 0 being objective. For example,
    for

    the following comment in our dataset: ’Fantastic. We need a lot of that here in
    Australia;

    suffering from drought; really bad water management by those in authority etc.’
    , the

    polarity was calculated as −0.1499 and subjectivity was 0.7833. The negative value
    of

    polarity indicates that the sentiment expressed by the comment was negative, whereas
    the

    value of subjectivity is closer to 1 suggesting that the comment was mostly subjective.

    Table 8. Label description.

    Label Serial No.

    Label

    Description

    Example

    1

    Praising

    Simple positive response

    This is amazing! Everyone is a

    winner when we chose

    sustainability!

    2

    Suggestion

    Any concrete suggestion

    relevant to the topic

    technology is really spectacular,

    now just assess its viability.

    3

    Opinion

    Positive, negative, or

    combined sentiment

    Technology is taking over farming,

    I like having to do it the way they

    do it now

    4

    Undeﬁned

    Could not be determined or

    isn’t relevant

    that would be like playing farming

    simulator in real life!

    5

    Hybrid

    More than one of the

    categories

    best part of farming is driving

    tractor. now get a robot to shovel

    manure, do chores like that would

    be sweet. why does the robot need

    lights at night?

    6

    Queries

    Any concrete queries

    relevant to the topic

    i wonder how much this thing

    costs

    AgriEngineering 2022, 4

    444

    Table 9. Number of comments of each label type.

    Video Serial No.

    Praising

    Suggestion

    Opinion

    Undeﬁned

    Hybrid

    Queries

    1.

    14

    5

    3

    5

    0

    2

    2.

    8

    2

    10

    2

    2

    4

    3.

    33

    7

    83

    14

    20

    21

    4.

    98

    33

    504

    176

    81

    149

    5.

    8

    0

    5

    3

    0

    4

    6.

    31

    15

    70

    25

    47

    11

    7.

    61

    1

    17

    50

    12

    16

    8.

    31

    9

    351

    233

    17

    54

    9.

    39

    4

    5

    29

    15

    110

    10.

    129

    39

    399

    225

    29

    57

    11.

    26

    2

    4

    2

    4

    3

    12.

    36

    4

    113

    36

    9

    9

    13.

    94

    0

    24

    4

    24

    32

    14.

    23

    14

    155

    126

    8

    33

    15.

    54

    14

    45

    23

    13

    15

    16.

    273

    85

    1455

    438

    218

    466

    5.3. Results and Analysis

    In this section, we detail the results of our experiment and analyze our ﬁndings.

    Evaluation has been conducted separately for the two approaches through user-based

    analysis and transfer-learning-based analysis. Table 10 records the number of
    comments

    under a video and the results obtained from sentiment analysis. The value of mean
    polarity,

    mean subjectivity, and Cohen’s kappa coefﬁcient is listed for each corresponding
    video

    serial number.

    5.3.1. User-Based Analysis

    In user-based analysis, the mean Cohen’s kappa was calculated to be 0.9617, which

    shows high inter-rater reliability. Figure 6 displays the Cohen’s kappa coefﬁcient
    for each

    video with respect to the mean value. The value is highest at 1 for videos no.
    5, 9, and 12,

    indicating perfect agreement between the labels assigned by both annotators. The
    value

    is lowest at 0.8141 for video no. 2 titled ‘Europe has the best regenerative farmers
    in the

    world’, implying a slight disagreement between the assigned labels. The high value
    of

    kappa coefﬁcient implies that the categories assigned by the annotators are correct.

    Figure 7 plots the correlation matrix between the frequency of the six labels.
    We can

    see the highest degree of correlation is 0.96 between the following labels: ‘Opinion’
    and

    ‘Suggestion’, and ‘Queries’ and ‘Hybrid’, indicating that the frequency of one
    increases

    with the other. The lowest degree of correlation is 0.81 between ‘Hybrid’ and
    ‘Undeﬁned’,

    suggesting that all labels show a relatively positive correlation amongst each
    other.

    AgriEngineering 2022, 4

    445

    Table 10. Results of Sentiment Analysis

    Video Serial No. No. of Comments Mean Polarity Mean Subjectivity Kappa Coeff.

    1

    29

    0.2143

    0.3124

    0.9061

    2

    28

    0.2546

    0.4956

    0.8141

    3

    178

    0.2262

    0.4809

    0.9609

    4

    1041

    0.1420

    0.4197

    0.9890

    5

    20

    0.3104

    0.4197

    1.0

    6

    199

    0.2140

    0.4942

    0.9220

    7

    157

    0.3404

    0.4710

    0.9467

    8

    695

    0.0919

    0.3838

    0.9526

    9

    202

    0.1743

    0.2915

    1.0

    10

    878

    0.1417

    0.4087

    0.9698

    11

    41

    0.3849

    0.5369

    0.9571

    12

    207

    0.1172

    0.4116

    1.0

    13

    178

    0.4360

    0.5480

    0.9827

    14

    359

    0.1186

    0.3734

    0.9958

    15

    164

    0.2736

    0.4614

    0.9921

    16

    2935

    0.1942

    0.4546

    0.9995

    Average Score

    0.2092

    0.4352

    0.9617

    Figure 6. Cohen’s Kappa Coefﬁcient plotted against mean value of 0.9617.

    AgriEngineering 2022, 4

    446

    Figure 7. Correlation heatmap between assigned labels.

    A word cloud is a data visualization technique used for representing text data
    where

    the frequency or importance of each word is indicated by its size. It can help
    us highlight

    and analyze signiﬁcant textual data points. Pre-processing of the comments was
    performed

    to remove stop words and punctuation from the text. Figure 8 displays the word
    clouds

    for the comments collected from videos of serial number 1–8. We can see that on
    the word

    cloud in Figure 8a, which is for the video titled ‘How Japan Is Reshaping Its
    Agriculture By

    Harnessing Smart- Farming Technology’, ‘Japan’ is one of the most frequent and
    important

    words in the text. Similarly, for Figure 8g for video no. 7 on the bottom left
    titled ‘7 Israeli

    Agriculture Technologies’, the most signiﬁcant word is ‘Israel’. Figure 9 displays
    the word

    clouds for the comments collected from videos of serial number 9–16. The word
    9b on the

    top left for the video titled ‘Singapore’s Bold Plan to Build the Farms of the
    Future’ has

    ‘Singapore’ as the most prominent word. This indicates that several comments for
    these

    videos included some text about the country in which the technology was implemented.
    For

    videos demonstrating a particular technology, such as No. 7: ‘Solar Panels Plus
    Farming?

    Agrivoltaics Explained’; No. 8: ‘The CNH Industrial Autonomous Tractor Concept
    (Full

    Version)’; and No. 14: ‘RIPPA The Farm Robot Exterminates Pests And Weeds’, the
    name of

    the technology (solar, tractor, robot, respectively) is of great prominence. Table
    11 provides

    a list of the top ﬁve most-relevant words in the comments dataset for each video,
    along

    with their respective frequencies.

    5.3.2. Transfer-Learning-Based Analysis

    The results of sentiment analysis using the Pattern library are discussed in this
    sub-

    section. Mean polarity and mean subjectivity are plotted opposite each other in
    Figure 10.

    The overall polarity for all 7311 comments is 0.2092, suggesting that the overall
    sentiment

    is slightly positive. The overall subjectivity of all comments is 0.4352, implying
    that the

    comments were close to being neutral. Subjective statements generally contain
    personal

    opinion, emotion, or judgment, whereas objective comments are factual information.
    Po-

    larity determines the degree of positive or negative sentiment in the text. The
    highest

    mean subjectivity score was 0.5480 for video no. 13 titled ‘Simply Fresh—India’s
    Largest

    State Of The Art Precision Farm’, followed by 0.5369 for video no. 11 titled ‘Smart
    Vertical

    Farms in Sharjah’. This shows that the comments were of a more opinionated nature,
    rather

    than being factual. The lowest mean subjectivity score was 0.2915 for video no.
    9 titled

    ‘IOT Smart Plant Monitoring System’, indicating that mostly facts were discussed
    in the

    comments for this video. The score suggesting higher objectivity could be because
    the video

    is discussing technical details about an IoT platform rather than explaining widespread

    innovative concepts such as precision farms and vertical farms. The comments collected

    from video no. 8 titled ‘The CNH Industrial Autonomous Tractor Concept (Full Version)’

    resulted in the lowest mean polarity of 0.0919, indicating that the user sentiment
    was

    generally neutral. The highest mean polarity of 0.4460 was achieved for video
    no. 13 titled

    AgriEngineering 2022, 4

    447

    ‘Simply Fresh—India’s Largest State Of The Art Precision Farm’, showing that user
    attitude

    was generally positive towards the state-of-the-art precision farm highlighted
    in the video.

    Figure 8. Word clouds for videos serial no. 1–8 corresponding (a–h) respectively.

    AgriEngineering 2022, 4

    448

    Figure 9. Word clouds for videos no. 9–16 corresponding (a–h) respectively.

    In the investigation of user sentiment towards smart farming and precision agriculture,

    the main objective was to analyze user opinion, which is the voice of masses.
    During

    compilation of the dataset, it was observed that videos providing more in-depth
    and

    case-study-based information about smart farming tools did not receive many views
    and

    comments. This could be because the general public is not well-informed about
    novel

    technology in the farming sector, as asserted in Section 6. The majority of the
    comments

    were collected from videos about broader topics. The Cohen’s kappa coefﬁcient
    indicated

    that the labels assigned by the two annotators were mostly in agreement and valid.
    The

    mean values of polarity and subjectivity in the comments was calculated through
    the

    Pattern library, and the results suggest that there is a varying degree of subjectivity
    amongst

    the comments. The polarity suggests that user opinion was mostly positive in the
    comments

    analyzed. Thus, it can be safely inferred that training and education programs
    can increase

    the visibility of innovations in smart farming, allowing the general population
    to form a

    AgriEngineering 2022, 4

    449

    well-informed opinion on the risks and beneﬁts. Positive user sentiment can then
    serve as

    a catalyst towards faster adoption of such tools.

    Table 11. List of ﬁve most frequent words for each video with respective frequencies.

    Video Serial No.

    Most Common

    2nd

    3rd

    4th

    5th

    1.

    technology (6)

    japanese (5)

    japan (5)

    video (4)

    good (4)

    2.

    richard (5)

    regenerative (4)

    love (4)

    farming (3)

    start (3)

    3.

    food (66)

    farming (29)

    sustainable (21)

    energy (21)

    water (20)

    4.

    farming (183)

    food (157)

    vertical (151)

    grow (109)

    people (97)

    5.

    hands (2)

    environment (2)

    farmer (2)

    corporate (2)

    awesome (2)

    6.

    solar (129)

    panels (101)

    energy (56)

    water (51)

    land (41)

    7.

    israel (42)

    love (35)

    india (21)

    agriculture (13)

    technology (13)

    8.

    tractor (109)

    farming (104)

    farm (61)

    farmer (57)

    work (56)

    9.

    project (39)

    code (26)

    software (24)

    sir (24)

    error (22)

    10.

    singapore (201)

    food (145)

    farming (88)

    people (83)

    ﬁrms (70)

    11.

    great (9)

    video (8)

    good (7)

    farm (5)

    food (5)

    12.

    farming (30)

    future (24)

    people (22)

    cow (18)

    nature (18)

    13.

    great (36)

    farming (26)

    work (24)

    sir (24)

    farm (22)

    14.

    robot (42)

    robots (30)

    people (27)

    farm (22)

    good (19)

    15.

    video (36)

    great (25)

    farmers (24)

    india (24)

    good (19)

    16.

    plants (430)

    food (429)

    farming (355)

    water (332)

    soil (319)

    Figure 10. Mean polarity vs. mean subjectivity.

    6. Challenges

    There has been a signiﬁcant increase in the number of smart farming initiatives
    being

    taken up around the world, with promising results. However, with the advent of
    new,

    innovative technologies there are always some unseen risks and associated challenges.

    The agricultural sector has greatly impacted the environment by taking up about
    40% of

    the world’s available land [173] and consuming approximately 70% of the water
    [174].

    Climate change and the growing population further exacerbate food and water scarcity,

    making sustainable food production a challenging task. Thus, it is critical that
    current

    agricultural practices need to evolve to ensure the efﬁcient use of land and water
    resources.

    To elaborate further on Research Question 2, we discuss the various challenges
    that hamper

    the adoption of smart farming in the following bullet points:

    AgriEngineering 2022, 4

    450

    1.

    Training and awareness: Lack of technical expertise by the farmers implementing

    new technology is a major setback to smart farming. Das et al. [28] conducted
    a

    study to understand the views of Irish farmers towards adoption of cloud computing

    and smart farming technologies. Surveys and interviews conducted with 32 farmers

    revealed that the rate of adoption was higher among younger farmers and lower

    amongst older farmers, who were hesitant to use new technology and preferred

    traditional farming. The digital divide has to be reduced by providing guidance

    and training to the farmers [175]. Lack of knowledge about the technology results

    in greater skepticism towards its adoption amongst farmers, who may not realize

    the value of the tool or consider it an unsuitable ﬁt for their farm. In this
    current

    study, we formed a dataset of YouTube comments related to smart farming operations

    and performed surface level sentiment analysis of them. During the data collection

    process, it was observed that very few comments were left under videos that provided

    a technical and detailed framework for a smart farming project. Comments were

    mostly collected from videos explaining broader topics, such as ‘Vertical Farming’.

    This indicates that there is a general lack of awareness about these technologies
    and

    their applicability to farming.

    2.

    Technical considerations: Fixed and moving sensing technologies require further

    improvements to be able to withstand extreme weather conditions in order to remain

    fully functional [176,177]. Edge node devices may be battery dependent and run
    out

    of power during operation [178,179]. Data is collected from various sensors and
    can be

    analyzed through IoT platforms. There is a requirement for data storage, as there
    is a

    huge amount of data being generated from IoT devices. IoT has improved connectivity

    of all operations by leaps and bounds, but it does come with the added concern
    of

    data privacy and security [180]. It also exposes the smart farming environment
    to

    cybersecurity threats, which could result in signiﬁcant loses [181]. Data encrypting

    in the Industrial Internet of Things (IIoT) also presents a signiﬁcant challenge
    for

    farmers [182].

    3.

    Costs: The costs associated with sensors needs to reduced so that they can be
    imple-

    mented in small-scale farms as well. The solution needs to be designed speciﬁcally

    for the project in question, and also needs regular updates and management. Farmers

    may hesitate in implementing such technologies as they could create issues and
    cause

    further losses instead of providing beneﬁts. Research and development costs for
    the

    implementation of such tools are also steep. There is also a signiﬁcant amount
    of cost

    associated with data transmission within a smart farm [183]. Market uncertainty
    adds

    substantial risk to ensuring a sustainable income for farmers, as proﬁt margins
    are

    getting increasingly smaller. Farmers in small-scale agricultural ﬁelds are hesitant

    to use upgraded technology because of the high initial costs, perceived risks,
    and

    complexity of the system.

    4.

    Government support: The laws and regulations in the area where smart farming is

    being considered for implementation play a huge role in its eventual success or
    failure.

    The local governments are responsible for taking initiatives and providing funding

    and support training programs for the adoption of such tools [184]. Several successful

    initiatives taken up in the European Union [119] and across the world [144] have

    highlighted the importance of the effort taken up by regulatory bodies.

    5.

    Ethical considerations: Human safety is also a concern in the operation of unmanned

    vehicles [185]. Collisions with the ground or other objects may also cause damage

    to the vehicle. It is also essential that the UAVs be ﬂown in unrestricted areas.
    Cur-

    rently, it is not clear where the accountability for the actions taken by autonomous

    vehicles lies. Data need to be uploaded to cloud systems in a secure manner, keeping

    regulations in mind. It is necessary for smart farming operations to be transparent
    so

    that they are more trusted and accepted. The ownership of agricultural data is
    a huge

    liability that needs to be kept in mind. There are also legal and ethical considerations

    with the potential mishandling and misuse of these data [186]. Animal welfare
    is

    AgriEngineering 2022, 4

    451

    also a concern while making use of autonomous robots to perform functions such
    as

    milking [187].

    6.

    Regional considerations: Lack of proper infrastructure, such as roads, can be
    a major

    hurdle towards the advancement of smart farms, as the necessary resources and

    technology will not be successfully transported. There is limited availability
    of inter-

    net in rural areas, where smart farming could be of greater signiﬁcance. Standard

    protocols and frameworks for wireless communication cannot be deﬁned, as the

    requirements rely heavily on the speciﬁc use case [188]. Further, communication

    protocols implemented within the smart farm may only provide coverage over small

    areas [189].

    7. Discussion

    This review study was conducted to assess the challenges and opportunities in
    smart

    farming by exploring current state-of-the-art ICTs and DTs, analyzing global projects,
    and

    understanding the perception of the general public towards such innovative practices.
    The

    two hypothesis stated at the beginning of the study have been supported by the
    ﬁndings of

    the research questions, which have been answered as follows:

    Hypothesis 3. ICTs and DTs can be used in the agricultural sector to make signiﬁcant
    improve-

    ments in several farming applications.

    The following research question were crafted to accept or reject the hypothesis:

    1.

    What are the state-of-the-art ICTs and DTs currently used in smart farming?

    Over the last decade, several smart farming projects have been launched across
    the

    world that were powered by technologies such as IoT, wireless sensor networks,

    unmanned vehicles, etc., as detailed in Section 3. The potential use cases for
    each

    technology are discussed in Section 4, although several projects utilize more
    than one.

    Several research projects in the European Union [18] and worldwide have also been

    discussed. The development of precise sensors enables the capture of data with
    higher

    accuracy, thus enabling better quality analysis and decision making [14]. Decision

    support systems can guide the farmer with operational decisions about choice of
    crop,

    frequency of fertilizer use, better utilization of resources, and more [69]. Autonomous

    vehicles take care of labor-intensive tasks, thus freeing up farmers for other
    important

    tasks [77]. Communication between various IoT devices through a WSN can allow

    for effective monitoring of the farm throughout the day, making it easier for
    the

    farmer to make operational decisions [36]. Blockchain technology can ensure that
    the

    supply and raw materials purchased are of good quality and there is no adulteration

    taking place [48]. DTs such as artiﬁcial intelligence also have an array of potential

    applications in smart farming, building upon the availability of massive amounts

    of heterogeneous data from sensors [20]. We have discussed the use of machine

    learning and deep learning for disease identiﬁcation in crops, fruits, and cattle
    in

    Section 3.7. AI has also shown great potential in optimizing resource utilization
    by

    automating timely irrigation, performing preemptive actions if a certain parameter

    crosses a threshold, and predictive analysis of weather and crop conditions [188].
    AI

    can also be used to identify optimal conditions for growing crops and preventing
    crop

    wastage. Image processing is of great relevance in smart farming, as there have
    been

    several studies that implement CNNs [98]. Image processing can be used for livestock

    management, guiding the decision-making processes of harvesting robots and pest

    and weed elimination drones. It can also enable precision farming by collecting
    data

    from sensors and deploying resources accordingly [9].

    Hypothesis 4. There are certain signiﬁcant challenges to the widespread adoption
    of smart farming

    tools, such as lack of awareness about the topic amongst the general population.

    AgriEngineering 2022, 4

    452

    The following research questions are explored in this context:

    1.

    What are the challenges associated with the widespread adoption of smart farming

    tools?

    Despite the increasing number of smart farming projects being launched all over

    the world, there still exist many factors that hinder the widespread implementa-

    tion of such tools [6,188]. As we have discussed in Section 6, the limitations
    can be

    broadly categorized as lack of training and awareness, technical considerations,
    costs,

    government support, ethical considerations, and regional considerations. Technical

    difﬁculties arise due to the inability of current systems to withstand extreme
    weather

    and atmospheric conditions, being too bulky and costly to implement, and not provid-

    ing up-to-the-mark accurate data [176]. Another challenge is the proper infrastructure

    required for storing and processing large amounts of data collected from sensors
    [181].

    The privacy and security of this data is of great importance. Regional limitations

    could be the lack of infrastructure and connectivity. Smaller farms in rural areas
    could

    beneﬁt greatly from the use of smart farming tools. However, most smart farming

    practices require the use of internet connectivity, which is sparse in rural areas.
    Other

    factors that hamper the development of smart farming may include lack of techni-

    cal expertise by farmers, insufﬁcient incentives provided by the government for
    the

    implementation of such practices, and skepticism of farmers towards the beneﬁts
    of

    smart farming [28]. General awareness amongst farmers is generally low and can
    be

    increased through training programs. Although smart farming tools are generally

    black-box techniques, farmers making use of them still need to understand their

    operations so that they can consider the process reliable. Cost considerations
    could

    also make farmers skeptical towards installing new tools, as the upfront expenditure

    may be too much [183].

    2.

    What are the current opinions and expectations of the digital user with regard
    to

    smart farming?

    In order to better understand user perception of smart farming technologies [166],

    we performed sentiment analysis on relevant English comments collected from

    YouTube [168], as detailed in Section 5. The comments were collected from 16 different

    videos that detailed innovative farming solutions. Then, two different approaches

    to observe user sentiment were utilized. In the ﬁrst approach, comments were man-

    ually labeled by two annotators into one of the following six categories: Praising,

    Queries, Suggestions, Undeﬁned, Hybrid and Opinion. Cohen’s Kappa coefﬁcient,

    which is the measure of inter-rater reliability, was calculated as 0.9617. This
    shows a

    high rate of agreement between the labels assigned by both annotators. The labels

    also show high positive correlation with each other, as depicted in Figure 10.
    Word

    clouds created for each video in Figures 8 and 9 highlight signiﬁcant words, such
    as

    ‘technology’, ‘farming’, ‘solar’, etc. In the second approach, polarity and subjectivity

    were calculated for each comment using Pattern library for Python. The polarity

    score ranges from −1 (negative) to 1 (positive) and indicates whether the sentiment

    is positive or negative. The overall polarity was calculated as 0.2092, indicating
    a

    slightly positive sentiment. The subjectivity score ranges from 0 (objective)
    to 1 (sub-

    jective) and indicates the degree of factual information or opinion in the statement.

    The overall subjectivity was calculated as 0.4352, suggesting that the comments
    were

    slightly objective. This implies that the comments discussed were fact-based rather

    than opinionated. However, only a rudimentary study was performed to determine

    user sentiment, and better results can be achieved using state-of-the-art models
    for

    sentiment analysis. In the brief overview of user sentiment conducted in the study,

    we noticed lack of user comments on informative and technical videos about smart

    farming platforms, indicating that a knowledge gap and a digital divide exists
    for

    such technologies [175], which can be detrimental to their widespread adoption.
    The

    general attitude of users towards smart farming technologies is superﬁcial, as
    the

    public is not well-informed about these topics.

    AgriEngineering 2022, 4

    453

    8. Conclusions

    Ensuring a sustainable food supply for the ever-increasing global population has

    become a necessity due to the unprecedented changes in the environment. The agricultural

    sector must update its practices in light of the worsening strain on land and
    water resources,

    and data-driven approaches provide such an opportunity to ensure sustainability.
    This

    study provided an overview of ICTs and DTs in automating and streamlining farming

    operations, and demonstrated how smart farming can improve crop yields by monitoring,

    disease prevention, automation of sowing and harvesting, etc. Examples of primary

    technological tools available for smart farming are IoT, unmanned vehicles, remote
    sensing,

    predictive analysis through big data, and so on. This shift towards data-driven
    approaches

    enables farming facilities to utilize available resources for maximum yield. The
    study also

    presents various challenges that are associated with large-scale implementation
    of smart

    farming practices, such as poor connectivity in rural areas, insufﬁcient funds
    and skilled

    labor, skepticism from farmers, concerns with data privacy, and more. To analyze
    the

    attitude of the public towards implementation of smart farming, we performed sentiment

    analysis on comments from YouTube channels related to smart farming. Preliminary

    ﬁndings in both user-based and transfer-learning based opinion mining suggest
    that a

    better understanding of smart farming tools would help the public in forming an
    informed

    opinion. Further advances are required to improve precision, cost, and efﬁciency
    of robots,

    sensors, and unmanned vehicles before they are readily adopted. Keeping the barriers

    to adoption for smart farming techniques in mind, the future scope of research
    would

    be to develop techniques that provide greater adaptability, ensure food sustainability,

    reduce cost, and counter the harmful affects of climate change on agriculture.
    Greater

    connectivity in rural areas could accelerate the integration of ICTs in smallholder
    farms,

    allowing them to prepare for unprecedented changes in farming conditions. Further

    research and investigation of the possible uses of DTs and ICTs is necessary to
    understand

    the challenges and opportunities in smart farming. A detailed sentiment analysis
    using

    advanced language models and inclusion of non-English comments can also provide
    greater

    insight into the expectations and opinions of digital users towards innovative
    farming

    solutions. Multidisciplinary research also needs to be conducted to elucidate
    other socio–

    economic, environmental, and technical factors that impede development and adoption
    of

    such innovations.

    Author Contributions: Conceptualization, A.K. and S.S.; methodology, S.Y.; Computing,
    S.Y.; vali-

    dation, M.S., S.Y. and A.K.; formal analysis, M.S.; investigation, S.Y.; resources,
    A.K.; data curation,

    S.Y. and M.S.; writing—original draft preparation, S.Y.; writing—review and editing,
    A.K. and S.S.;

    visualization, S.Y.; supervision, A.K. and S.S.; project administration, A.K.
    All authors have read and

    agreed to the published version of the manuscript.

    Funding: This research received no external funding.

    Data Availability Statement: For data, please contact the corresponding author.

    Conﬂicts of Interest: The authors declare no conﬂict of interest.

    References

    1.

    UN Population. Available online: https://www.un.org/development/desa/en/news/population/world-population-prospects-

    2019.html (accessed on 2 March 2022).

    2.

    Hunter, M.C.; Smith, R.G.; Schipanski, M.E.; Atwood, L.W.; Mortensen, D.A. Agriculture
    in 2050: Recalibrating targets for

    sustainable intensiﬁcation. Bioscience 2017, 67, 386–391. [CrossRef]

    3.

    Samir, K.; Lutz, W. The human core of the shared socioeconomic pathways: Population
    scenarios by age, sex and level of

    education for all countries to 2100. Glob. Environ. Chang. 2017, 42, 181–192.

    4.

    De Clercq, M.; Vats, A.; Biel, A. Agriculture 4.0: The future of farming technology.
    In Proceedings of the World Government

    Summit, Dubai, United Arab Emirates, 11–13 February 2018; pp. 11–13.

    5.

    Walter, A.; Finger, R.; Huber, R.; Buchmann, N. Opinion: Smart farming is key
    to developing sustainable agriculture. Proc. Natl.

    Acad. Sci. USA 2017, 114, 6148–6150. [CrossRef] [PubMed]

    AgriEngineering 2022, 4

    454

    6.

    Bacco, M.; Barsocchi, P.; Ferro, E.; Gotta, A.; Ruggeri, M. The digitisation of
    agriculture: A survey of research activities on smart

    farming. Array 2019, 3, 100009. [CrossRef]

    7.

    Ju, C.; Son, H.I. Discrete event systems based modeling for agricultural multiple
    unmanned aerial vehicles: Automata theory

    approach. In Proceedings of the 2018 18th International Conference on Control,
    Automation and Systems (ICCAS), PyeongChang,

    Korea, 17–20 October 2018; pp. 258–260.

    8.

    Muchiri, N.; Kimathi, S. A review of applications and potential applications of
    UAV. In Proceedings of the Sustainable Research

    and Innovation Conference, New York, NY, USA, 21–22 September 2016; pp. 280–283.

    9.

    Jhuria, M.; Kumar, A.; Borse, R. Image processing for smart farming: Detection
    of disease and fruit grading. In Proceedings of the

    2013 IEEE Second International Conference on Image Information Processing (ICIIP-2013),
    Shimla, India, 9–11 December 2013;

    pp. 521–526.

    10.

    Guo, Y.; Zhang, J.; Yin, C.; Hu, X.; Zou, Y.; Xue, Z.; Wang, W. Plant disease
    identiﬁcation based on deep learning algorithm in

    smart farming. Discret. Dyn. Nat. Soc. 2020, 2020, 2479172. [CrossRef]

    11.

    Blackmore, S. Precision farming: An introduction. Outlook Agric. 1994, 23, 275–280.
    [CrossRef]

    12.

    Wang, A.X.; Tran, C.; Desai, N.; Lobell, D.; Ermon, S. Deep transfer learning
    for crop yield prediction with remote sensing data.

    In Proceedings of the 1st ACM SIGCAS Conference on Computing and Sustainable Societies,
    San Jose, CA, USA, 20–22 June 2018;

    pp. 1–5.

    13.

    Khaki, S.; Wang, L. Crop yield prediction using deep neural networks. Front. Plant
    Sci. 2019, 10, 621. [CrossRef]

    14.

    Chetan Dwarkani, M.; Ganesh Ram, R.; Jagannathan, S.; Priyatharshini, R. Smart
    farming system using sensors for agricultural

    task automation. In Proceedings of the 2015 IEEE Technological Innovation in ICT
    for Agriculture and Rural Development

    (TIAR), Chennai, India, 10–12 July 2015; pp. 49–53.

    15.

    Skobelev, P.O.; Simonova, E.V.; Smirnov, S.; Budaev, D.S.; Voshchuk, G.Y.; Morokov,
    A. Development of a knowledge base in the

    “smart farming” system for agricultural enterprise management. Procedia Comput.
    Sci. 2019, 150, 154–161. [CrossRef]

    16.

    Mohamed, E.S.; Belal, A.; Abd-Elmabod, S.K.; El-Shirbeny, M.A.; Gad, A.; Zahran,
    M.B. Smart farming for improving agricultural

    management. Egypt. J. Remote Sens. Space Sci. 2021, 24, 971–981. [CrossRef]

    17.

    2021’s Weather Disasters Brought Home the Reality of Climate Change. Available
    online: https://www.nationalgeographic.com/

    environment/article/this-year-extreme-weather-brought-home-reality-of-climate-change
    (accessed on 7 April 2022).

    18.

    Moysiadis, V.; Sarigiannidis, P.; Vitsas, V.; Kheliﬁ, A. Smart farming in Europe.
    Comput. Sci. Rev. 2021, 39, 100345. [CrossRef]

    19.

    Harvey, C.A.; Rakotobe, Z.L.; Rao, N.S.; Dave, R.; Razaﬁmahatratra, H.; Rabarijohn,
    R.H.; Rajaofara, H.; MacKinnon, J.L. Extreme

    vulnerability of smallholder farmers to agricultural risks and climate change
    in Madagascar. Philos. Trans. R. Soc. B Biol. Sci. 2014,

    369, 20130089. [CrossRef] [PubMed]

    20.

    Wolfert, S.; Ge, L.; Verdouw, C.; Bogaardt, M.J. Big data in smart farming—A review.
    Agric. Syst. 2017, 153, 69–80. [CrossRef]

    21.

    Mogili, U.R.; Deepak, B. Review on application of drone systems in precision agriculture.
    Procedia Comput. Sci. 2018, 133, 502–509.

    [CrossRef]

    22.

    Shamshiri, R.R.; Weltzien, C.; Hameed, I.A.; Yule, I.J.; Grift, T.E.; Balasundram,
    S.K.; Pitonakova, L.; Ahmad, D.; Chowdhary,

    G. Research and development in agricultural robotics: A perspective of digital
    farming. Int. J. Agric. Biol. Eng. 2018, 11, 1–14.

    [CrossRef]

    23.

    Migdall, S.; Klug, P.; Denis, A.; Bach, H. The additional value of hyperspectral
    data for smart farming. In Proceedings of the 2012

    IEEE International Geoscience and Remote Sensing Symposium, Munich, Germany, 22–27
    July 2012; pp. 7329–7332.

    24.

    Uddin, M.A.; Ayaz, M.; Mansour, A.; Le Jeune, D.; Aggoune, E. Wireless senors
    for modern agriculture in KSA: A survey. In

    Proceedings of the 2016 7th International Conference on Computer Science and Information
    Technology (CSIT), Amman, Jordan,

    13–14 July 2016; pp. 1–7.

    25.

    Sona, G.; Passoni, D.; Pinto, L.; Pagliari, D.; Masseroni, D.; Ortuani, B.; Facchi,
    A. UAV multispectral survey to map soil and

    crop for precision farming applications. In Proceedings of the Remote Sensing
    and Spatial Information Sciences Congress:

    International Archives of the Photogrammetry Remote Sensing and Spatial Information
    Sciences Congress, Prague, Czech

    Republic, 12–19 July 2016; International Society for Photogrammetry and Remote
    Sensing (ISPRS): Nice, France, 2016; Volume 41,

    pp. 1023–1029.

    26.

    Boursianis, A.D.; Papadopoulou, M.S.; Diamantoulakis, P.; Liopa-Tsakalidi, A.;
    Barouchas, P.; Salahas, G.; Karagiannidis, G.; Wan,

    S.; Goudos, S.K. Internet of things (IoT) and agricultural unmanned aerial vehicles
    (UAVs) in smart farming: A comprehensive

    review. Internet Things 2020, 18, 100187. [CrossRef]

    27.

    Despommier, D. Farming up the city: The rise of urban vertical farms. Trends Biotechnol.
    2013, 31, 388–389. [CrossRef]

    28.

    Das, V.J.; Sharma, S.; Kaushik, A. Views of Irish farmers on smart farming technologies:
    An observational study. AgriEngineering

    2019, 1, 164–187.

    29.

    Akbar, M.O.; Ali, M.J.; Hussain, A.; Qaiser, G.; Pasha, M.; Pasha, U.; Missen,
    M.S.; Akhtar, N. IoT for development of smart dairy

    farming. J. Food Qual. 2020, 2020, 4242805. [CrossRef]

    30.

    Gang, L.L.L. Design of greenhouse environment monitoring and controlling system
    based on bluetooth technology. Trans. Chin.

    Soc. Agric. Mach. 2006, 10, 97–100.

    31.

    Zhang, S.; Chen, X.; Wang, S. Research on the monitoring system of wheat diseases,
    pests and weeds based on IOT. In Proceed-

    ings of the 2014 9th International Conference on Computer Science & Education,
    Vancouver, BC, Canada, 22–24 August 2014;

    pp. 981–985.

    AgriEngineering 2022, 4

    455

    32.

    Chieochan, O.; Saokaew, A.; Boonchieng, E. IOT for smart farm: A case study of
    the Lingzhi mushroom farm at Maejo

    University. In Proceedings of the 2017 14th International Joint Conference on
    Computer Science and Software Engineering

    (JCSSE), NakhonSiThammarat, Thailand, 12–14 July 2017; pp. 1–6.

    33.

    Benaissa, S.; Plets, D.; Tanghe, E.; Trogh, J.; Martens, L.; Vandaele, L.; Verloock,
    L.; Tuyttens, F.; Sonck, B.; Joseph, W. Internet

    of animals: Characterisation of LoRa sub-GHz off-body wireless channel in dairy
    barns. Electron. Lett. 2017, 53, 1281–1283.

    [CrossRef]

    34.

    Giri, A.; Dutta, S.; Neogy, S. Enabling agricultural automation to optimize utilization
    of water, fertilizer and insecticides

    by implementing Internet of Things (IoT). In Proceedings of the 2016 International
    Conference on Information Technology

    (InCITe)-The Next Generation IT Summit on the Theme-Internet of Things: Connect
    your Worlds, Noida, India, 6–7 October 2016;

    pp. 125–131.

    35.

    Na, A.; Isaac, W.; Varshney, S.; Khan, E. An IoT based system for remote monitoring
    of soil characteristics. In Proceedings of the

    2016 International Conference on Information Technology (InCITe)-The Next Generation
    IT Summit on the Theme-Internet of

    Things: Connect your Worlds, Noida, India, 6–7 October 2016; pp. 316–320.

    36.

    Kamilaris, A.; Gao, F.; Prenafeta-Boldu, F.X.; Ali, M.I. Agri-IoT: A semantic
    framework for Internet of Things-enabled smart

    farming applications. In Proceedings of the 2016 IEEE 3rd World Forum on Internet
    of Things (WF-IoT), Reston, VA, USA,

    12–14 December 2016; pp. 442–447.

    37.

    Akka¸s, M.A.; Sokullu, R. An IoT-based greenhouse monitoring system with Micaz
    motes. Procedia Comput. Sci. 2017, 113, 603–608.

    [CrossRef]

    38.

    Cañadas, J.; Sánchez-Molina, J.A.; Rodríguez, F.; del Águila, I.M. Improving automatic
    climate control with decision support

    techniques to minimize disease effects in greenhouse tomatoes. Inf. Process. Agric.
    2017, 4, 50–63. [CrossRef]

    39.

    dos Santos, U.J.L.; Pessin, G.; da Costa, C.A.; da Rosa Righi, R. AgriPrediction:
    A proactive internet of things model to anticipate

    problems and improve production in agricultural crops. Comput. Electron. Agric.
    2019, 161, 202–213. [CrossRef]

    40.

    Kukar, M.; Vraˇcar, P.; Košir, D.; Pevec, D.; Bosni´c, Z. AgroDSS: A decision
    support system for agriculture and farming. Comput.

    Electron. Agric. 2019, 161, 260–271.

    41.

    Antonopoulou, E.; Karetsos, S.; Maliappis, M.; Sideridis, A. Web and mobile technologies
    in a prototype DSS for major ﬁeld

    crops. Comput. Electron. Agric. 2010, 70, 292–301. [CrossRef]

    42.

    Rupanagudi, S.R.; Ranjani, B.; Nagaraj, P.; Bhat, V.G.; Thippeswamy, G. A novel
    cloud computing based smart farming system for

    early detection of borer insects in tomatoes. In Proceedings of the 2015 International
    Conference on Communication, Information

    & Computing Technology (ICCICT), Mumbai, India, 15–17 January 2015; pp. 1–6.

    43.

    Zhou, L.; Chen, N.; Chen, Z. A cloud computing-enabled spatio-temporal cyber-physical
    information infrastructure for efﬁcient

    soil moisture monitoring. ISPRS Int. J.-Geo-Inf. 2016, 5, 81. [CrossRef]

    44.

    Kaloxylos, A.; Groumas, A.; Sarris, V.; Katsikas, L.; Magdalinos, P.; Antoniou,
    E.; Politopoulou, Z.; Wolfert, S.; Brewster, C.;

    Eigenmann, R.; et al. A cloud-based Farm Management System: Architecture and implementation.
    Comput. Electron. Agric. 2014,

    100, 168–179. [CrossRef]

    45.

    Corista, P.; Ferreira, D.; Gião, J.; Sarraipa, J.; Gonçalves, R.J. An IoT agriculture
    system using FIWARE. In Proceedings of the 2018

    IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC),
    Stuttgart, Germany, 17–20 June 2018;

    pp. 1–6.

    46.

    Zamora-Izquierdo, M.A.; Santa, J.; Martínez, J.A.; Martínez, V.; Skarmeta, A.F.
    Smart farming IoT platform based on edge and

    cloud computing. Biosyst. Eng. 2019, 177, 4–17. [CrossRef]

    47.

    Malik, A.W.; Rahman, A.U.; Qayyum, T.; Ravana, S.D. Leveraging fog computing for
    sustainable smart farming using distributed

    simulation. IEEE Internet Things J. 2020, 7, 3300–3309. [CrossRef]

    48.

    Vangala, A.; Sutrala, A.K.; Das, A.K.; Jo, M. Smart Contract-Based Blockchain-Envisioned
    Authentication Scheme for Smart

    Farming. IEEE Internet Things J. 2021, 8, 10792–10806. [CrossRef]

    49.

    Lin, Y.P.; Petway, J.R.; Anthony, J.; Mukhtar, H.; Liao, S.W.; Chou, C.F.; Ho,
    Y.F. Blockchain: The evolutionary next step for ICT

    e-agriculture. Environments 2017, 4, 50. [CrossRef]

    50.

    Patil, A.S.; Tama, B.A.; Park, Y.; Rhee, K.H. A framework for blockchain based
    secure smart green house farming. In Advances in

    Computer Science and Ubiquitous Computing; Springer: Singapore, 2017; pp. 1162–1167.

    51.

    Lin, J.; Shen, Z.; Zhang, A.; Chai, Y. Blockchain and IoT based food traceability
    for smart agriculture. In Proceedings of the 3rd

    International Conference on Crowd Science and Engineering, Singapore, 28–31 July
    2018; pp. 1–6.

    52.

    Nikodem, M. Bluetooth Low Energy Livestock Positioning for Smart Farming Applications.

    In International Conference on

    Computational Science; Springer: Singapore, 2021; pp. 55–67.

    53.

    Sukhadeve, V.; Roy, S. Advance agro farm design with smart farming, irrigation
    and rain water harvesting using internet of

    things. Int. J. Adv. Eng. Manag. 2016, 1, 33–45. [CrossRef]

    54.

    Chung, W.Y.; Luo, R.H.; Chen, C.L.; Heythem, S.; Chang, C.F.; Po, C.C.; Li, Y.
    Solar powered monitoring system development for

    smart farming and Internet of Thing applications. Meet. Abstr. Electrochem. Soc.
    2019, 28, 1371–1375. [CrossRef]

    55.

    Bedord, L. Sensors Protect Crops from Insect Damage. 2015. Available online: https://www.agriculture.com/technology/crop-

    management/ﬁeldwork/senss-protect-crops-from-insect-damage_590-ar47778 (accessed
    on 7 April2022).

    56.

    Schmidt, F. Agricultural Sensors: Improving Crop Farming to Help Us Feed the World.
    Available online: https://www.dw.com/

    en/agricultural-sensors-improving-crop-farming-to-help-us-feed-the-world/a-17733350
    (accessed on 7 April2022).

    AgriEngineering 2022, 4

    456

    57.

    López, O.; Rach, M.M.; Migallon, H.; Malumbres, M.P.; Bonastre, A.; Serrano, J.J.
    Monitoring pest insect traps by means of

    low-power image sensor technologies. Sensors 2012, 12, 15801–15819. [CrossRef]

    58.

    Rach, M.M.; Gomis, H.M.; Granado, O.L.; Malumbres, M.P.; Campoy, A.M.; Martín,
    J.J.S. On the design of a bioacoustic sensor for

    the early detection of the red palm weevil. Sensors 2013, 13, 1706–1729. [CrossRef]

    59.

    Stoner, R. The Rev 3 Leaf Sensor. 2014. Available online: https://leafsensor.wordpress.com/
    (accessed on 7 April 2022).

    60.

    Hydraulic Conductivity in Plant Stems. Available online: www.ictinternational.com/casestudies/hydraulic-conductivity-in-

    plant-stems/ (accessed on 7 April 2022).

    61.

    Karlen, D.L.; Mausbach, M.; Doran, J.W.; Cline, R.; Harris, R.; Schuman, G. Soil
    quality: A concept, deﬁnition, and framework for

    evaluation (a guest editorial). Soil Sci. Soc. Am. J. 1997, 61, 4–10. [CrossRef]

    62.

    Butler, Z.; Corke, P.; Peterson, R.; Rus, D. Virtual fences for controlling cows.
    In Proceedings of the IEEE International Conference

    on Robotics and Automation, New Orleans, LA, USA, 26 April–1 May 2004; Volume
    5, pp. 4429–4436.

    63.

    Nukala, R.; Panduru, K.; Shields, A.; Riordan, D.; Doody, P.; Walsh, J. Internet
    of Things: A review from ‘Farm to Fork’. In

    Proceedings of the 2016 27th Irish Signals and Systems Conference (ISSC), Londonderry,
    UK, 21–22 June 2016; pp. 1–6.

    64.

    Lee, H.; Moon, A.; Moon, K.; Lee, Y. Disease and pest prediction IoT system in
    orchard: A preliminary study. In Proceedings of

    the 2017 Ninth International Conference on Ubiquitous and Future Networks (ICUFN),
    Milan, Italy, 4–7 July 2017; pp. 525–527.

    65.

    Garcia-Lesta, D.; Cabello, D.; Ferro, E.; Lopez, P.; Brea, V.M. Wireless sensor
    network with perpetual motes for terrestrial snail

    activity monitoring. IEEE Sensors J. 2017, 17, 5008–5015. [CrossRef]

    66.

    Kodali, R.K.; Jain, V.; Karagwal, S. IoT based smart greenhouse. In Proceedings
    of the 2016 IEEE Region 10 Humanitarian

    Technology Conference (R10-HTC), Agra, India, 21–23 December 2016; pp. 1–6.

    67.

    Nayyar, A.; Puri, V. Smart farming: IoT based smart sensors agriculture stick
    for live temperature and moisture monitoring

    using Arduino, cloud computing & solar technology. In Proceedings of the International
    Conference on Communication and

    Computing Systems (ICCCS-2016), Gurgaon, India, 9–11 September 2016; CRC Press:
    London, UK, 2017; ISBN 9781315364094.

    68.

    Taylor, K.; Grifﬁth, C.; Lefort, L.; Gaire, R.; Compton, M.; Wark, T.; Lamb, D.;
    Falzon, G.; Trotter, M. Farming the web of things.

    IEEE Intell. Syst. 2013, 28, 12–19. [CrossRef]

    69.

    Thakare, A.; Belhekar, P.; Budhe, P.; Shinde, U.; Waghmode, V. Decision support
    system for smart farming with hydroponic style.

    Int. J. Adv. Res. Comput. Sci. 2018, 9, 427–431.

    70.

    Bareth, G.; Aasen, H.; Bendig, J.; Gnyp, M.L.; Bolten, A.; Jung, A.; Michels,
    R.; Soukkamäki, J. 7 Low-Weight and UAV-based

    Hyperspectral Full-frame Cameras for Monitor-ing Crops: Spectral Comparison with
    Portable Spectroradiometer Measurements.

    Photogramm. Fernerkund. Geoinf. 2015, 69–80. [CrossRef]

    71.

    Roldán, J.J.; del Cerro, J.; Garzón-Ramos, D.; Garcia-Aunon, P.; Garzón, M.; de
    León, J.; Barrientos, A. Robots in agriculture: State

    of art and practical experiences. In Service Robots; IntechOpen: London, UK, 2018;
    pp. 67–90.

    72.

    Groves, P.D. Principles of GNSS, inertial, and multisensor integrated navigation
    systems, [Book review]. IEEE Aerosp. Electron.

    Syst. Mag. 2015, 30, 26–27. [CrossRef]

    73.

    Matese, A.; Toscano, P.; Di Gennaro, S.F.; Genesio, L.; Vaccari, F.P.; Primicerio,
    J.; Belli, C.; Zaldei, A.; Bianconi, R.; Gioli, B.

    Intercomparison of UAV, aircraft and satellite remote sensing platforms for precision
    viticulture. Remote Sens. 2015, 7, 2971–2990.

    [CrossRef]

    74.

    Lu, B.; He, Y. Species classiﬁcation using Unmanned Aerial Vehicle (UAV)-acquired
    high spatial resolution imagery in a

    heterogeneous grassland. ISPRS J. Photogramm. Remote Sens. 2017, 128, 73–85. [CrossRef]

    75.

    Tripicchio, P.; Satler, M.; Dabisias, G.; Ruffaldi, E.; Avizzano, C.A. Towards
    smart farming and sustainable agriculture with drones.

    In Proceedings of the 2015 International Conference on Intelligent Environments,
    Prague, Czech Republic, 15–17 July 2015;

    pp. 140–143.

    76.

    Moribe, T.; Okada, H.; Kobayashl, K.; Katayama, M. Combination of a wireless sensor
    network and drone using infrared

    thermometers for smart agriculture. In Proceedings of the 2018 15th IEEE Annual
    Consumer Communications & Networking

    Conference (CCNC), Las Vegas, NV, USA, 12–15 January 2018; pp. 1–2.

    77.

    Lottes, P.; Khanna, R.; Pfeifer, J.; Siegwart, R.; Stachniss, C. UAV-based crop
    and weed classiﬁcation for smart farming. In

    Proceedings of the 2017 IEEE International Conference on Robotics and Automation
    (ICRA), Singapore, 29 May–3 June 2017;

    pp. 3024–3031.

    78.

    Yi, S.; Li, C.; Li, Q. A survey of fog computing: Concepts, applications and issues.
    In Proceedings of the 2015 Workshop on

    Mobile Big Data, Hangzhou, China, 21 June 2015; pp. 37–42.

    79.

    Sittón-Candanedo, I.; Alonso, R.S.; Rodríguez-González, S.; Coria, J.A.G.; De
    La Prieta, F. Edge computing architectures in

    industry 4.0: A general survey and comparison. In International Workshop on Soft
    Computing Models in Industrial and Environmental

    Applications; Springer: Cham, Switzerland, 2019; pp. 121–131.

    80.

    Moysiadis, V.; Sarigiannidis, P.; Moscholios, I. Towards distributed data management
    in fog computing. Wirel. Commun. Mob.

    Comput. 2018, 2018, 7597686. [CrossRef]

    81.

    Zheng, Z.; Xie, S.; Dai, H.N.; Chen, W.; Chen, X.; Weng, J.; Imran, M. An overview
    on smart contracts: Challenges, advances and

    platforms. Future Gener. Comput. Syst. 2020, 105, 475–491. [CrossRef]

    82.

    Widi Widayat, I.; Köppen, M. Blockchain Simulation Environment on Multi-image
    Encryption for Smart Farming Application. In

    International Conference on Intelligent Networking and Collaborative Systems;
    Springer: Cham, Switzerland, 2021; pp. 316–326.

    AgriEngineering 2022, 4

    457

    83.

    Nguyen, T.; Das, A.; Tran, L. NEO smart contract for drought-based insurance.
    In Proceedings of the 2019 IEEE Canadian

    Conference of Electrical and Computer Engineering (CCECE), Edmonton, AB, Canada,
    5–8 May 2019; pp. 1–4.

    84.

    Hurwitz, J.; Nugent, A.; Halper, F.; Kaufman, M. Big Data for Dummies; John Wiley
    & Sons: Hoboken, NJ, USA; New York, NY,

    USA, 2013.

    85.

    Dick, S. Artiﬁcial Intelligence. Harv. Data Sci. Rev. 2019, 1. [CrossRef]

    86.

    Goodfellow, I.; Bengio, Y.; Courville, A. Deep Learning; MIT Press: Cambridge,
    MA, USA, 2016.

    87.

    Yadav, S.; Kaushik, A. Do You Ever Get Off Track in a Conversation? The Conversational
    System’s Anatomy and Evaluation

    Metrics. Knowledge 2022, 2, 55–87. [CrossRef]

    88.

    O’Shea, K.; Nash, R. An introduction to convolutional neural networks. arXiv 2015,
    arXiv:1511.08458.

    89.

    Varghese, R.; Sharma, S. Affordable smart farming using IoT and machine learning.

    In Proceedings of the 2018 Second

    International Conference on Intelligent Computing and Control Systems (ICICCS),
    Madurai, India, 14–15 June 2018; pp. 645–650.

    90.

    Arvindan, A.; Keerthika, D. Experimental investigation of remote control via Android
    smart phone of arduino-based automated

    irrigation system using moisture sensor. In Proceedings of the 2016 3rd International
    Conference on Electrical Energy Systems

    (ICEES), Chennai, India, 17–19 March 2016; pp. 168–175.

    91.

    Khaki, S.; Safaei, N.; Pham, H.; Wang, L. Wheatnet: A lightweight convolutional
    neural network for high-throughput image-based

    wheat head detection and counting. arXiv 2021, arXiv:2103.09408.

    92.

    Alfred, R.; Obit, J.H.; Yee, C.C.P.; Haviluddin, H.; Lim, Y. Towards Paddy Rice
    Smart Farming: A Review on Big Data, Machine

    Learning and Rice Production Tasks. IEEE Access 2021, 9, 50358–50380. [CrossRef]

    93.

    Rahmat, R.F.; Lini, T.Z.; Pujiarti; Hizriadi, A. Implementation of Real-Time Monitoring
    on Agricultural Land of Rice Plants

    Using Smart Sensor. In Proceedings of the 2019 3rd International Conference on
    Electrical, Telecommunication and Computer

    Engineering (ELTICOM), Medan, Indonesia, 16–17 September 2019; pp. 40–43. [CrossRef]

    94.

    Alifah, S.; Gunawan, G.; Tauﬁk, M. Smart Monitoring of Rice Logistic Employing
    Internet of Things Network. In Proceedings

    of the 2018 2nd Borneo International Conference on Applied Mathematics and Engineering
    (BICAME), Balikpapan, Indonesia,

    10–11 December 2018; pp. 199–202. [CrossRef]

    95.

    Tiglao, N.M.; Alipio, M.; Balanay, J.V.; Saldivar, E.; Tiston, J.L. Agrinex: A
    low-cost wireless mesh-based smart irrigation system.

    Measurement 2020, 161, 107874. [CrossRef]

    96.

    Kiruthika, S.U.; Raja, S.K.S.; Jaichandran, R.; Priyadharshini, C. Detection and
    Classiﬁcation of Paddy Crop Disease using Deep

    Learning Techniques. Int. J. Recent Technol. Eng. 2019, 8, 2277–3878. [CrossRef]

    97.

    Dahane, A.; Benameur, R.; Kechar, B.; Benyamina, A. An IoT Based Smart Farming
    System Using Machine Learning.

    In

    Proceedings of the 2020 International Symposium on Networks, Computers and Communications
    (ISNCC), Montreal, QC,

    Canada, 20–22 October 2020; pp. 1–6.

    98.

    Bhange, M.; Hingoliwala, H. Smart farming: Pomegranate disease detection using
    image processing. Procedia Comput. Sci. 2015,

    58, 280–288. [CrossRef]

    99.

    Sengupta, A.; Ye, Y.; Wang, R.; Liu, C.; Roy, K. Going deeper in spiking neural
    networks: VGG and residual architectures. Front.

    Neurosci. 2019, 13, 95. [CrossRef] [PubMed]

    100. Ferentinos, K.P. Deep learning models for plant disease detection and diagnosis.
    Comput. Electron. Agric. 2018, 145, 311–318.

    [CrossRef]

    101. Mohanty, S.P.; Hughes, D.P.; Salathé, M. Using deep learning for image-based
    plant disease detection. Front. Plant Sci. 2016,

    7, 1419. [CrossRef] [PubMed]

    102. Li, H.; Jin, Y.; Zhong, J.; Zhao, R. A Fruit Tree Disease Diagnosis Model
    Based on Stacking Ensemble Learning. Complexity 2021,

    2021, 6868592. [CrossRef]

    103. Banhazi, T.M.; Lehr, H.; Black, J.; Crabtree, H.; Schoﬁeld, P.; Tscharke,
    M.; Berckmans, D. Precision livestock farming: An

    international review of scientiﬁc and commercial aspects. Int. J. Agric. Biol.
    Eng. 2012, 5, 1–9.

    104. Xu, B.; Wang, W.; Guo, L.; Chen, G.; Wang, Y.; Zhang, W.; Li, Y. Evaluation
    of Deep Learning for Automatic Multi-View Face

    Detection in Cattle. Agriculture 2021, 11, 1062. [CrossRef]

    105. Gjergji, M.; de Moraes Weber, V.; Silva, L.O.C.; da Costa Gomes, R.; De Araújo,
    T.L.A.C.; Pistori, H.; Alvarez, M. Deep learning

    techniques for beef cattle body weight prediction. In Proceedings of the 2020
    International Joint Conference on Neural Networks

    (IJCNN), Glasgow, UK, 19–24 July 2020; pp. 1–8.

    106. Jung, D.H.; Kim, N.Y.; Moon, S.H.; Jhin, C.; Kim, H.J.; Yang, J.S.; Kim,
    H.S.; Lee, T.S.; Lee, J.Y.; Park, S.H. Deep Learning-Based

    Cattle Vocal Classiﬁcation Model and Real-Time Livestock Monitoring System with
    Noise Filtering.

    Animals 2021, 11, 357.

    [CrossRef]

    107. Riede, T.; Tembrock, G.; Herzel, H.; Brunnberg, L. Vocalization as an Indicator
    for Disorders in Mammals. Ph.D. Thesis, Acoustical

    Society of America, Melville, NY, USA, 1997.

    108. Zhang, Y.; Zhang, F.; Cheng, J.; Zhao, H. Classiﬁcation and Recognition of
    Fish Farming by Extraction New Features to Control

    the Economic Aquatic Product. Complexity 2021, 2021, 5530453. [CrossRef]

    109. Rohani, A.; Taki, M.; Bahrami, G. Application of artiﬁcial intelligence for
    separation of live and dead rainbow trout ﬁsh eggs.

    Artif. Intell. Agric. 2019, 1, 27–34. [CrossRef]

    110. Zambrano, A.F.; Giraldo, L.F.; Quimbayo, J.; Medina, B.; Castillo, E. Machine
    learning for manually-measured water quality

    prediction in ﬁsh farming. PLoS ONE 2021, 16, e0256380. [CrossRef] [PubMed]

    AgriEngineering 2022, 4

    458

    111. Chiu, M.T.; Xu, X.; Wei, Y.; Huang, Z.; Schwing, A.G.; Brunner, R.; Khachatrian,
    H.; Karapetyan, H.; Dozier, I.; Rose, G.; et al.

    Agriculture-vision: A large aerial image database for agricultural pattern analysis.
    In Proceedings of the IEEE/CVF Conference

    on Computer Vision and Pattern Recognition, Seattle, WA, USA, 13–19 June 2020;
    pp. 2828–2838.

    112. Chiu, M.T.; Xu, X.; Wang, K.; Hobbs, J.; Hovakimyan, N.; Huang, T.S.; Shi,
    H. The 1st agriculture-vision challenge: Methods and

    results. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
    Recognition Workshops, Seattle, WA, USA,

    13–19 June 2020; pp. 48–49.

    113. Kussul, N.; Lavreniuk, M.; Skakun, S.; Shelestov, A. Deep learning classiﬁcation
    of land cover and crop types using remote

    sensing data. IEEE Geosci. Remote Sens. Lett. 2017, 14, 778–782. [CrossRef]

    114. Zheng, Y.Y.; Kong, J.L.; Jin, X.B.; Wang, X.Y.; Su, T.L.; Zuo, M. CropDeep:
    The crop vision dataset for deep-learning-based

    classiﬁcation and detection in precision agriculture. Sensors 2019, 19, 1058.
    [CrossRef]

    115. Anand, T.; Sinha, S.; Mandal, M.; Chamola, V.; Yu, F.R. AgriSegNet: Deep
    aerial semantic segmentation framework for IoT-assisted

    precision agriculture. IEEE Sensors J. 2021, 21, 17581–17590. [CrossRef]

    116. Rangarajan, A.K.; Purushothaman, R.; Ramesh, A. Tomato crop disease classiﬁcation
    using pre-trained deep learning algorithm.

    Procedia Comput. Sci. 2018, 133, 1040–1047. [CrossRef]

    117. Kulkarni, O. Crop disease detection using deep learning.

    In Proceedings of the 2018 Fourth International Conference on

    Computing Communication Control and Automation (ICCUBEA), Pune, India, 16–18 August
    2018; pp. 1–4.

    118. Andrew, W.; Greatwood, C.; Burghardt, T. Visual localisation and individual
    identiﬁcation of holstein friesian cattle via deep

    learning. In Proceedings of the IEEE International Conference on Computer Vision
    Workshops, Venice, Italy, 22–29 October 2017;

    pp. 2850–2859.

    119. Smart Farming European Union. Available online: https://cordis.europa.eu/
    (accessed on 11 April 2022).

    120. Project ECHORD Plus Plus (European Clearing House for Open Robotics Development
    Plus Plus). 2018. Available online:

    https://cordis.europa.eu/project/id/601116 (accessed on 13 December 2021).

    121. Project VINBOT (Autonomous Cloud-Computing Vineyard Robot to Optimize Yield
    Management and Wine Quality). 2017.

    Available online: http://vinbot.eu (accessed on 13 December 2021).

    122. Project ERMES (An Earth obseRvation Model Based RicE Information Service).
    2017. Available online: http://www.ermes-fp7

    space.eu/en. (accessed on 14 December 2021).

    123. Project FRACTALS (Future Internet Enabled Agricultural Applications). 2016.
    Available online: https://www.fractals-fp7.com

    (accessed on 14 December 2021).

    124. Project VINEROBOT (VINEyardROBOT). 2017. Available online: http://www.vinerobot.eu
    (accessed on 13 December 2021).

    125. Project SWEEPER (Sweet Pepper Harvesting Robot). 2018. Available online:
    http://www.sweeper-robot.eu (accessed on

    13 December 2021).

    126. Project Flourish (Aerial Data Collection and Analysis, and Automated Ground
    Intervention for Precision Farming). 2018.

    Available online: http://ﬂourish-project.eu (accessed on 13 December 2021).

    127. Project PANtHEOn (Precision Farming of Hazelnut Orchards). 2020. Available
    online:

    http://www.project-pantheon.eu

    (accessed on 13 December 2021).

    128. Project ROMI (RObotics for MIcrofarms). 2020. Available online: https://romi-project.eu
    (accessed on 14 December 2021).

    129. Project MISTRALE (Monitoring of SoIl moiSture and wateR-Flooded Areas for
    agricuLture and Environment). 2017. Available

    online: http://www.mistrale.eu (accessed on 14 December 2021).

    130. Project WaterBee Smart Irrigation Systems Demonstration Action. Available
    online: https://cordis.europa.eu/project/id/283638

    (accessed on 14 December 2021).

    131. Project FIGARO (Flexible and PrecIse IrriGation PlAtform to Improve FaRm
    Scale Water PrOductivity). 2016. Available online:

    http://www.ﬁgaro-irrigation.net (accessed on 13 December 2021).

    132. Project Apollo (Advisory Platform for Small Farms Based on Earth Observation).
    2016. Available online: https://cordis.europa.

    eu/project/id/687412 (accessed on 14 December 2021).

    133. Project AgriCloud P2 (Demonstration of a Cloud-Based Precision Farming Management
    System). 2016. Available online:

    https://cordis.europa.eu/project/id/720176 (accessed on 14 December 2021).

    134. Project Sensagri (Sentinels Synergy for Agriculture). 2016. Available online:
    https://cordis.europa.eu/project/id/730074

    (accessed on 14 December 2021).

    135. Project IoF2020 (Internet of Food and Farm 2020). 2017. Available online:
    https://cordis.europa.eu/project/id/731884 (accessed

    on 14 December 2021).

    136. Project DataBio (Data-Driven Bioeconomy). 2017. Available online: https://cordis.europa.eu/project/id/732064
    (accessed on

    14 December 2021).

    137. Project Apmav (Innovative Drone-Based Solution for Agriculture). 2017. Available
    online: https://cordis.europa.eu/project/id/

    763132 (accessed on 14 December 2021).

    138. Project AfarCloud (Aggregate Farming in the Cloud). 2018. Available online:
    https://cordis.europa.eu/project/id/783221

    (accessed on 14 December 2021).

    139. Project BigDataGrapes (Big Data to Enable Global Disruption of the Grapevine-Powered
    Industries). 2018. Available online:

    https://cordis.europa.eu/project/id/780751 (accessed on 14 December 2021).

    AgriEngineering 2022, 4

    459

    140. Project Dragon (Data Driven Precision Agriculture Services and Skill Acquisition).
    2018. Available online: https://cordis.europa.

    eu/project/id/810775 (accessed on 14 December 2021).

    141. Madar Farms (United Arab Emirates). Available online: https://www.madarfarms.co/
    (accessed on 25 December 2021).

    142. Responsive Drip Irrigation (United States of America). Available online:
    https://www.responsivedrip.com/ (accessed on

    26 December 2021).

    143. SunCulture (Kenya). Available online: https://sunculture.com/ (accessed on
    25 December 2021).

    144. Generation Green 2020–2030. Available online: https://www.ada.gov.ma/en/news/his-majesty-king-mohammed-vi-launches-

    new-agricultural-strategy-generation-green-2020-2030 (accessed on 15 December
    2021).

    145. AbyFarm (Urban Farming in Singapore). Available online: https://www.abyfarm.com/
    (accessed on 15 December 2021).

    146. Ossian Agro Automation (India). Available online: http://nanoganesh.com/
    (accessed on 25 December 2021).

    147. GROUND-Vertical Farming (Lebanon). Available online: https://berytech.org/proﬁles/ground-vertical-farming/
    (accessed on

    17 December 2021).

    148. Smart Farming Identiﬁes €5600 Average Cost Savings on Participating Farms.
    Available online: https://smartfarming.ie/

    (accessed on 12 April 2022).

    149. Project ENORASIS (ENvironmental Optimization of IRrigAtion Management with
    the Combined uSe and Integration of High

    PrecisIon Satellite Data). 2014. Available online: http://www.enorasis.eu (accessed
    on 14 December 2021).

    150. Project WEAM4i (Water and Energy Advanced Management for Irrigation). 2017.
    Available online: http://weam4i.eu (accessed

    on 14 December 2021).

    151. Project CHAMPI-ON (Fully Automatic System for Picking and Handling Mushrooms
    for the Fresh Market). 2013. Available

    online: http://www.champi-on.eu (accessed on 14 December 2021).

    152. Project Auditor (Advanced Multi-Constellation EGNSS Augmentation and Monitoring
    Network). 2016. Available online:

    https://auditor-project.accorde.com (accessed on 14 December 2021).

    153. Project RUC-APS (Enhancing and Implementing Knowledge Based ICT Solutions
    within High Risk and Uncertain Conditions

    for Agriculture Production Systems). 2016. Available online:

    https://cordis.europa.eu/project/id/691249 (accessed on

    14 December 2021).

    154. Project AfriCultuReS (Enhancing Food Security in AFRIcan AgriCULTUral Systems
    with the Support of REmote Sensing). 2017.

    Available online: https://cordis.europa.eu/project/id/774652 (accessed on 14 December
    2021).

    155. Project SWAMP (Smart Water Management Platform). 2017. Available online:
    https://cordis.europa.eu/project/id/777112

    (accessed on 14 December 2021).

    156. Project Water4Agri (Securing Water for Food and Safety with the World’s Most
    Advanced Soil Moisture Information Derived

    from Satellites). 2017. Available online: https://cordis.europa.eu/project/id/783989
    (accessed on 14 December 2021).

    157. VoE (Village of Excellence). 2021. Available online: https://www.business-standard.com/article/economy-policy/india-israel-

    sign-3-year-work-programme-for-cooperation-in-agri-tomar-121052401072_1.html (accessed
    on 14 December 2021).

    158. Nosho Navi (Smart Paddy Agriculture Mode Implemented by Agricultural Production
    Corporation). 2014. Available online:

    http://www.agr.kyushu-u.ac.jp/lab/keiei/NoshoNavi/NoshoNavi1000/eng/index.html
    (accessed on 14 December 2021).

    159. Smart farming for the Future Generations (Vietnam and Uzbekistan). Available
    online:

    https://www.fao.org/vietnam/

    programmes-and-projects/project-list/en/ (accessed on 15 December 2021).

    160. AgriEdge (Moroccan-Based Precision Agriculture Services Platform and Digital
    Marketplace for Agro-Products). Available online:

    https://agriedge.um6p.ma/ (accessed on 15 December 2021).

    161. Baramoda (Egypt). Available online: https://baramoda.org/ (accessed on 15
    December 2021).

    162. Robinson Agri (Lebanon). Available online: https://www.robinsons-lb.com/
    (accessed on 17 December 2021).

    163. Kenya Climate Smart Agriculture Project (Kenya). Available online: https://www.kcsap.go.ke/
    (accessed on 25 December 2021).

    164. MimosaTek (Vietnam). Available online: https://mimosatek.com/ (accessed on
    25 December 2021).

    165. Lentera Africa. Available online: https://lenterafrica.com/ (accessed on
    11 March 2022).

    166. Salim, J.N.; Trisnawarman, D.; Imam, M.C. Twitter users opinion classiﬁcation
    of smart farming in Indonesia. IOP Conf. Ser.

    Mater. Sci. Eng. 2020, 852, 012165. [CrossRef]

    167. Regan, Á. ‘Smart farming’ in Ireland: A risk perception study with key governance
    actors. NJAS-Wagening. J. Life Sci. 2019,

    90, 100292. [CrossRef]

    168. Kaur, G.; Kaushik, A.; Sharma, S. Cooking is creating emotion: A study on
    hinglish sentiments of youtube cookery channels

    using semi-supervised approach. Big Data Cogn. Comput. 2019, 3, 37. [CrossRef]

    169. Shah, S.R.; Kaushik, A. Sentiment analysis on indian indigenous languages:
    A review on multilingual opinion mining. arXiv

    2019, arXiv:1911.12848.

    170. Shah, S.R.; Kaushik, A.; Sharma, S.; Shah, J. Opinion-mining on marglish
    and devanagari comments of youtube cookery channels

    using parametric and non-parametric learning models. Big Data Cogn. Comput. 2020,
    4, 3. [CrossRef]

    171. Venkatakrishnan, S.; Kaushik, A.; Verma, J.K. Sentiment analysis on google
    play store data using deep learning. In Applications of

    Machine Learning; Springer: Singapore, 2020; pp. 15–30.

    172. Kazhuparambil, S.; Kaushik, A. Classiﬁcation of Malayalam-English Mix-Code
    Comments using Current State of Art. In Proceed-

    ings of the 2020 IEEE International Conference for Innovation in Technology (INOCON),
    Bangluru, India, 6–8 November 2020;

    pp. 1–6.

    AgriEngineering 2022, 4

    460

    173. Goldewijk, K.; Beusen, A.; Doelman, J.; Stehfest, E. New anthropogenic land
    use estimates for the Holocene. J. Earth Syst.Sci.

    Data Discuss. 2016, 10.

    174. FAO. AQUASTAT Database. 2016. Available online: http://www.fao.org/nr/water/aquastat/data/query/index.html?lang=en

    (accessed on 6 April 2022).

    175. O’Shaughnessy, S.A.; Kim, M.; Lee, S.; Kim, Y.; Kim, H.; Shekailo, J. Towards
    Smart Farming Solutions in the US and South Korea:

    A Comparison of the Current Status. Geogr. Sustain. 2021, 2, 312–327.

    176. Ojha, T.; Misra, S.; Raghuwanshi, N.S. Wireless sensor networks for agriculture:
    The state-of-the-art in practice and future

    challenges. Comput. Electron. Agric. 2015, 118, 66–84. [CrossRef]

    177. Yue, Y.G.; He, P. A comprehensive survey on the reliability of mobile wireless
    sensor networks: Taxonomy, challenges, and future

    directions. Inf. Fusion 2018, 44, 188–204. [CrossRef]

    178. Føre, M.; Frank, K.; Norton, T.; Svendsen, E.; Alfredsen, J.A.; Dempster,
    T.; Eguiraun, H.; Watson, W.; Stahl, A.; Sunde, L.M.; et al.

    Precision ﬁsh farming: A new framework to improve production in aquaculture. Biosyst.
    Eng. 2018, 173, 176–193. [CrossRef]

    179. Berckmans, D. Precision livestock farming technologies for welfare management
    in intensive livestock systems. Rev. Sci. Tech.

    2014, 33, 189–196. [CrossRef]

    180. Tzounis, A.; Katsoulas, N.; Bartzanas, T.; Kittas, C. Internet of Things
    in agriculture, recent advances and future challenges.

    Biosyst. Eng. 2017, 164, 31–48. [CrossRef]

    181. Gupta, M.; Abdelsalam, M.; Khorsandroo, S.; Mittal, S. Security and privacy
    in smart farming: Challenges and opportunities.

    IEEE Access 2020, 8, 34564–34584. [CrossRef]

    182. Choo, K.K.R.; Gritzalis, S.; Park, J.H. Cryptographic solutions for industrial
    Internet-of-Things: Research challenges and

    opportunities. IEEE Trans. Ind. Inform. 2018, 14, 3567–3569. [CrossRef]

    183. Alzubi, J.; Nayyar, A.; Kumar, A. Machine learning from theory to algorithms:
    An overview. J. Phys. Conf. Ser.

    2018, 1142,

    012012. [CrossRef]

    184. Soto, I.; Barnes, A.; Eory, V.; Beck, B.; Balafoutis, A.; Sanchez, B.; Vangeyte,
    J.; Fountas, S.; Van Der Wall, T.; Gomez-Barbero, M.

    Which factors and incentives inﬂuence the intention to adopt precision agricultural
    technologies? In Proceedings of the 2018

    Conference, Vancouver, BC, Canada, 28 July–2 August 2018.

    185. Yinka-Banjo, C.; Ajayi, O. Sky-farmers: Applications of unmanned aerial vehicles
    (UAV) in agriculture. In Autonomous Vehicles;

    IntechOpen: London, UK, 2019; pp. 107–128.

    186. Charo, R.A. Yellow lights for emerging technologies. Science 2015, 349, 384–385.
    [CrossRef] [PubMed]

    187. Eastwood, C.; Klerkx, L.; Ayre, M.; Dela Rue, B. Managing socio-ethical challenges
    in the development of smart farming: From a

    fragmented to a comprehensive approach for responsible research and innovation.
    J. Agric. Environ. Ethics 2019, 32, 741–768.

    [CrossRef]

    188. Bacco, M.; Berton, A.; Ferro, E.; Gennaro, C.; Gotta, A.; Matteoli, S.; Paonessa,
    F.; Ruggeri, M.; Virone, G.; Zanella, A. Smart

    farming: Opportunities, challenges and technology enablers. In Proceedings of
    the 2018 IoT Vertical and Topical Summit on

    Agriculture-Tuscany (IOT Tuscany), Tuscany, Italy, 8–9 May 2018; pp. 1–6.

    189. Santamaria-Artigas, A.E.; Franch, B.; Guillevic, P.; Roger, J.C.; Vermote,
    E.F.; Skakun, S. Evaluation of Near-Surface Air

    Temperature From Reanalysis Over the United States and Ukraine: Application to
    Winter Wheat Yield Forecasting. IEEE J. Sel.

    Top. Appl. Earth Obs. Remote Sens. 2019, 12, 2260–2269. [CrossRef]

    '
  inline_citation: '>'
  journal: AgriEngineering
  limitations: '>'
  pdf_link: https://www.mdpi.com/2624-7402/4/2/29/pdf?version=1652354689
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'Disruptive Technologies in Smart Farming: An Expanded View with Sentiment
    Analysis'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/s21175949
  analysis: '>'
  authors:
  - Jordi Mateo
  - Adela Pagès‐Bernaus
  - Lluís M. Plà-Aragonés
  - Joan Pau Castells-Gasia
  - D. Babot
  citation_count: 7
  full_citation: '>'
  full_text: ">\nsensors\nArticle\nAn Internet of Things Platform Based on Microservices\
    \ and\nCloud Paradigms for Livestock\nJordi Mateo-Fornés 1,*\n, Adela Pagès-Bernaus\
    \ 2,3\n, Lluís Miquel Plà-Aragonés 3,4\n, Joan Pau Castells-Gasia 1\nand Daniel\
    \ Babot-Gaspa 3,5\n\x01\x02\x03\x01\x04\x05\x06\a\b\x01\n\x01\x02\x03\x04\x05\x06\
    \a\nCitation: Mateo-Fornés, J.;\nPagès-Bernaus, A.; Plà-Aragonés,\nL.M.; Castells-Gasia,\
    \ J.P.;\nBabot-Gaspa, D. An Internet of\nThings Platform Based on\nMicroservices\
    \ and Cloud Paradigms\nfor Livestock. Sensors 2021, 21, 5949.\nhttps://doi.org/10.3390/s21175949\n\
    Academic Editor: Asim Biswas\nReceived: 30 July 2021\nAccepted: 1 September 2021\n\
    Published: 4 September 2021\nPublisher’s Note: MDPI stays neutral\nwith regard\
    \ to jurisdictional claims in\npublished maps and institutional afﬁl-\niations.\n\
    Copyright: © 2021 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article\
    \ is an open access article\ndistributed\nunder\nthe\nterms\nand\nconditions of\
    \ the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n\
    4.0/).\n1\nDepartment of Computer Science and Industrial Engineering, University\
    \ of Lleida, 25001 Lleida, Spain;\njcg23@alumnes.udl.cat\n2\nDepartment of Business\
    \ Administration, University of Lleida, 25001 Lleida, Spain; adela.pages@udl.cat\n\
    3\nDepartment of Mathematics, University of Lleida, 25001 Lleida, Spain; lluismiquel.pla@udl.cat\
    \ (L.M.P.-A.);\ndaniel.babot@udl.cat (D.B.-G.)\n4\nDepartment of Animal Science,\
    \ University of Lleida, 25198 Lleida, Spain\n5\nAGROTECNIO-CERCA Center, 25198\
    \ Lleida, Spain\n*\nCorrespondence: jordi.mateo@udl.cat\nAbstract: With the growing\
    \ adoption of the Internet of Things (IoT) technology in the agricultural\nsector,\
    \ smart devices are becoming more prevalent. The availability of new, timely,\
    \ and precise\ndata offers a great opportunity to develop advanced analytical\
    \ models. Therefore, the platform\nused to deliver new developments to the ﬁnal\
    \ user is a key enabler for adopting IoT technology.\nThis work presents a generic\
    \ design of a software platform based on the cloud and implemented\nusing microservices\
    \ to facilitate the use of predictive or prescriptive analytics under different\
    \ IoT\nscenarios. Several technologies are combined to comply with the essential\
    \ features—scalability,\nportability, interoperability, and usability—that the\
    \ platform must consider to assist decision-making\nin agricultural 4.0 contexts.\
    \ The platform is prepared to integrate new sensor devices, perform\ndata operations,\
    \ integrate several data sources, transfer complex statistical model developments\n\
    seamlessly, and provide a user-friendly graphical interface. The proposed software\
    \ architecture is\nimplemented with open-source technologies and validated in\
    \ a smart farming scenario. The growth\nof a batch of pigs at the fattening stage\
    \ is estimated from the data provided by a level sensor installed\nin the silo\
    \ that stores the feed from which the animals are fed. With this application,\
    \ we demonstrate\nhow farmers can monitor the weight distribution and receive\
    \ alarms when high deviations happen.\nKeywords: sensors; Internet of Things;\
    \ microservices architecture; cloud computing; precision\nlivestock farming; smart\
    \ farm; pig farming\n1. Introduction\nDevelopments in the digital era are transforming\
    \ the agricultural industry by making\nits processes more efﬁcient, automated,\
    \ and competitive. The line that separates the virtual\nand the physical world\
    \ is getting closer, and this approximation brings in new paradigms\nand challenges\
    \ to become a full-ﬂedged 4.0 industry. From the Internet of Things (IoT)\nperspective,\
    \ the core idea is that each physical object in the real world is equipped with\n\
    sensors that connect it to the virtual world. Predictive models, prescriptive\
    \ models, or\nArtiﬁcial Intelligence (AI) algorithms can be fed with these data\
    \ enriched with other context\ninformation to generate new insights to assist\
    \ the decision making process. Several inno-\nvations, like sensor technology\
    \ [1,2], positioning systems [3], digital image processing [4],\ncloud [5], and\
    \ fog computing [6], among others, make this transformation possible.\nNowadays,\
    \ the automatic acquisition of data, which is part of the dataﬁcation and\ndigitization\
    \ process, is undertaken in many sectors given that sensors are becoming cheaper\n\
    and more energy-efﬁcient [7]. The value of such data is directly related to the\
    \ use given.\nThe simplest use of the sensor data leads to descriptive analytics,\
    \ and using the information\nSensors 2021, 21, 5949. https://doi.org/10.3390/s21175949\n\
    https://www.mdpi.com/journal/sensors\nSensors 2021, 21, 5949\n2 of 21\nonly in\
    \ this way may not exploit its full potential [8]. Therefore, given that the number\n\
    of devices that can transmit data is increasing, there is a need to improve the\
    \ systems for\ngathering, crossing, and processing the data provided by the different\
    \ sources in order to\nsupport smart decisions.\nTo start with, several challenges\
    \ arise on the data collection process: (a) raw data\ncoming from the sensor may\
    \ be inaccurate or even erroneous due to systematic and random\nerrors; (b) some\
    \ information may be partially lost due to network congestion, continuous\nenvironmental\
    \ interference [9], or long distances in remote places [10]; (c) fraudulent ma-\n\
    nipulation of data by attackers affecting their veracity [11]; (d) some technical\
    \ speciﬁcations\nfrom sensors manufacturers can vary the structure of their data\
    \ and/or their communi-\ncation interface may change [12]; or (e) huge volumes\
    \ of real-time data that traditional\nsystems cannot handle [13] may overload\
    \ the systems, among others. The presence of any\nof these factors requires speciﬁc\
    \ data operations to avoid an inadequate representation [14].\nAnother challenge\
    \ to address is how the multiple types of sources, devices, and other\ninformation\
    \ sources are connected in order to obtain a global vision. Data come from\ndifferent\
    \ installations, places, databases, business information systems and more, each\
    \ with\ntheir own format. Computing platforms and services need to be ﬂexible\
    \ to allow diverse\ndata exchange among internal and external tools.\nWith the\
    \ aim to increase the value of the data collected, data scientists in the ﬁelds\n\
    of Operational Research, Artiﬁcial Intelligence, or Statistics are developing\
    \ advanced\nmodeling techniques. These techniques may rely at some points in solving\
    \ intensive\ncomputational processes regarding CPU (central processing unit) and\
    \ memory, such as\nwhen solving optimization models or training neural networks.\
    \ The management of these\nresources requires platforms where services can scale\
    \ with resource needs.\nMoreover, the human interaction with these complex techniques\
    \ and smart data\ngenerated need to be presented with a user-friendly perspective,\
    \ smoothing the learning\ncurve and providing targeted information. Decision-makers\
    \ need to use these tools with a\nnatural ﬂow to access different information\
    \ levels depending on their roles and decisions.\nTo overcome the challenges exposed\
    \ until now, in this work we propose a generic\nsoftware architecture together\
    \ with guidelines on how to adapt the architecture to different\nIoT scenarios.\
    \ Therefore, the main contributions of this work is the design of a software\n\
    architecture with the following properties:\n•\nSupport the integration of several\
    \ type of sensors, in order to automatically collect\nreal-time data and keep\
    \ historical records, independently of their original format.\n•\nAssist in the\
    \ adoption of methodologies and mechanisms to detect and correct possible\nerrors\
    \ in order to provide the most accurate information.\n•\nThe capability to obtain\
    \ data from other data sources such as databases or web services\namong others\
    \ to complement the sensor data.\n•\nInteroperability between internal and external\
    \ systems.\n•\nThe provision of the needed resources to ensure the correct use\
    \ of the different tools\nand methodologies of the digital platform.\n•\nThe incorporation\
    \ of tools that facilitate the interaction with different complex pro-\ncesses\
    \ and provide new insights to the users.\n•\nSecurity mechanisms to provide the\
    \ needed information and access to the different\nprocesses for the different\
    \ user roles.\n•\nEasy of use, implementation, management, and deployment of the\
    \ architecture into\ndifferent scenarios.\nIn order to validate this architecture\
    \ design, this work presents a case study for the pig\nsector. A platform using\
    \ this software architecture has been implemented. Data collected\nfrom feed silos\
    \ equipped with a level sensor are used to predict the growth of a batch\nof fattening\
    \ pigs. Procedures for data cleaning are integrated in order to provide data\n\
    of quality to proceed with the analysis. To increase the data value, statistical\
    \ models\nare integrated in order to estimate the feed intake and the growth of\
    \ a batch of pigs.\nThe average growth model is based on a sigmoid function from\
    \ the Gompertz family which\nSensors 2021, 21, 5949\n3 of 21\nuses the accumulated\
    \ feed intake. The distribution is complemented with the estimation\nof the variance\
    \ of the weight of the animals, by using a cubic polynomial function. This\ninformation\
    \ allows the farmer to infer whether the pigs are gaining weight as expected.\n\
    This application also incorporates an alert system to warn the farmer if some\
    \ anomaly\nis detected.\nThe rest of this paper is organized as follows. Section\
    \ 2 performs a literature review of\nsimilar works. Section 3 presents the design\
    \ of the cloud architecture, the technologies that\nhave been chosen to implement\
    \ it, and how it has been distributed and deployed.\nSection 5 applies this cloud\
    \ platform to a livestock scenario. Finally, Section 6 high-\nlights the main\
    \ conclusions of this work and future research lines.\n2. Bibliography Review\n\
    In this section, we review the state-of-the-art of proposals found in the literature\
    \ that\naddress the design of cloud platform architectures. We limit the scope\
    \ to works in the\nagricultural sector, which is related to our case study. We\
    \ analyze if these works present\nIoT platforms that accomplish a set of characteristics\
    \ that in our opinion are essential for\nIoT scenarios. These characteristics\
    \ are the following:\n1.\nDecision-making assistance: To analyze the type of tools\
    \ included in each work,\nsuch as visualization proposals, the use of predictive\
    \ or prescriptive analysis or the\ngeneration of alarms among others.\n2.\nScalability:\
    \ To analyze if the platform is able to integrate new IoT devices and services\n\
    to meet potentially growing demand.\n3.\nInteroperability: To explore whether\
    \ the architecture is prepared to easily communi-\ncate between different systems\
    \ independently of their technology.\n4.\nPortability: To check whether the architecture\
    \ provides some mechanisms that facili-\ntate the system to be run in different\
    \ environments.\nWe ﬁrst present a brief introduction of the works analyzed. It\
    \ follows a comparison of\nthe characteristics included.\nFerrández-Pastor et\
    \ al. [15] present a platform that can acquire, process, store, and\nmonitor data\
    \ from growing cropping systems with the purpose to automate the mainte-\nnance\
    \ of croplands and control the conditions that determine the proper development\
    \ of\na crop such as soil moisture, water pH level, or luminance. Trilles et al.\
    \ [16] present the\ndesign of an architecture for IoT that manages devices, acquires\
    \ data from such devices, and\nanalyzes and generates events/alerts from these\
    \ data devices. They validate the solution in\nvineyards to monitor environmental\
    \ variables, such as the temperature, air/soil humidity,\nand to help the farmer\
    \ predict the mildew disease.\nTaneja et al. [17] present an IoT platform for\
    \ animal behaviour analysis and health\nmonitoring. Their focus is on different\
    \ parameters of dairy farms to monitor the health of\nthe cows and to detect possible\
    \ anomalies.\nThe work presented by Cambra et al. [18] proposes an innovative\
    \ IoT communication\nsystem used as a low controller irrigation system. It collects\
    \ real-time data such as temper-\nature, humidity, air, rain to monitor it, controls\
    \ the actuators (components that perform\nmechanical actions), and detects dangers\
    \ in the ﬁeld. Codeluppi et al. [19] propose a\nlow-cost, modular IoT platform\
    \ to improve the management of generic farms. Authors\nvalidate the platform in\
    \ a real farm to collect environmental variables related to the growth\nof grapes\
    \ and greenhouse vegetables.\nA cloud-based framework called WALLeSMART is presented\
    \ in [20] which proposes\nan architecture to address the challenges of acquisition,\
    \ processing, and visualization of a\nmassive amount of data to assist decision-making.\
    \ They focus on collecting parameters\nrelated to the dairy farms and the weather.\
    \ Stevens et al. [21] present MICROCEA,\nan architecture developed to automate\
    \ the growth of plants in urban indoor residential\nareas. The purpose is to monitor\
    \ sensor data, such as light, temperature, and humidity, and\nlet users program\
    \ events to automate the process.\nSensors 2021, 21, 5949\n4 of 21\nTable 1 summarizes\
    \ the comparison of these works and our proposal with the main\nkeywords of the\
    \ architecture presented from a technological point of view and how they\nuse\
    \ data from sensors to assist decision-making.\nTable 1. Comparison between related\
    \ studies.\nProposal\nPlatform keywords\nDecision Making\nScalability\nPortability\n\
    Interoperability\nSector\n[15]\nCloud Computing\nEdge Computing\nDescriptive Analytics\n\
    -\nAgriculture\n[16]\nCloud Computing\nDocker\nMicroservices\nTime Series DB\n\
    Descriptive Analytic\nPredictive Analytic\nAgriculture\n[17]\nCloud Computing\n\
    Docker\nFog Computing\nMicroservices\nNo SQL databases\nDescriptive Analytic\n\
    Predictive Analytic\nLivestock\n[18]\nCloud Computing\nRelational Databases\n\
    Descriptive Analytic\nPredictive Analytic\nPrescriptive Analytic\n-\n-\n-\nAgriculture\n\
    [19]\nCloud Computing\nRelational Databases\nDescriptive Analytics\n-\n-\n-\n\
    Agriculture\n[20]\nCloud Computing\nDocker\nNo SQL and relational\ndatabases\n\
    Descriptive Analytics\n-\nLivestock\n[21]\nCloud Computing\nNo SQL databases\n\
    Descriptive Analysis\n-\n-\nAgriculture\nOur proposal\nCloud Computing\nDocker\n\
    Microservices\nNoSQL databases\nDescriptive Analytic\nPredictive Analytic\nLivestock\n\
    All the analyzed works provide some tools to visualize data (either historical\
    \ sensor\ndata, real-time sensor data, or external services data) and perform\
    \ some management tasks.\nOnly three works present the required tools for IoT\
    \ scenarios so that the data collected can\nprovide extra information: the work\
    \ in [16], where they provide models to detect diseases\nin the crop and generate\
    \ alarms since the farmers can deal with the problem at early stages.\nThe system\
    \ developed by the authors of [18] generates alarms and create actions to deal\n\
    with the adequate growth of the crops, and the solution implemented in [17] provides\n\
    analysis to predict heat detection or anomalies of the cows and generate alarms\
    \ to warn\nthe farmer. Such solutions are mostly self-created platforms. However,\
    \ the method in [15]\nuses the Ubidots IoT platform in order to provide with generic\
    \ and basic visualization and\nanalysis tools.\nFrom a scalability point of view,\
    \ all these works use the cloud computing technology\nin order to obtain the needed\
    \ resources to integrate new services and IoT devices. However,\nthe type of database\
    \ used and how these applications are distributed must be also taken in\nto consideration\
    \ in order for the platform to cope with the new needs of the environment.\nSome\
    \ solutions use relational databases [18,19]. These kinds of databases are not\
    \ change-\ntolerant as they require that the structure of the data is deﬁned before\
    \ storing it, and a small\nupdate in the schema can cause a great deal of modiﬁcations\
    \ in the system that must be\ncarefully controlled. Using NoSQL [17,20] or Time\
    \ series databases [16] is a better choice for\nIoT scenarios due to the heterogeneous\
    \ data of the sensors. For example, NoSQL databases\nprovide ﬂexible schemes that\
    \ allow storing unstructured data without having to predeﬁne\na structure.\nAnother\
    \ important feature is how the different applications of the architecture are\n\
    distributed to ensure that it is able to support potentially growing demands.\
    \ Different\nSensors 2021, 21, 5949\n5 of 21\napproaches are found: the authors\
    \ of [19] propose a platform that is able to integrate new\nIoT devices and application\
    \ modules according to the demands of farmers. The works\nin [15,17] take some\
    \ responsibilities from the cloud such as computing and analytics in order\nto\
    \ be performed at the edge of the network and provide better time responses. In\
    \ addition,\nin [16,17] the authors present a microservice-based approach in order\
    \ to distribute the IoT\nplatform in a set of services that are responsible for\
    \ performing speciﬁc functionalities and\nare independent from each other.\nWith\
    \ regards to the interoperability, most of the studies take into consideration\
    \ pro-\nviding HTTP (Hyper Text Transfer Protocol) APIs (Application Programming\
    \ Interfaces) to\nthe services in order to be able to interact with the consumer\
    \ applications. An HTTP API is\nan interface that allows the interaction of two\
    \ applications by using the HTTP protocol. In\naddition, the most used message\
    \ protocol in these works that allows a connection of the\nIoT devices and the\
    \ cloud platform is the MQTT (Message Queueing Telemetry Transport).\nHowever,\
    \ in order to integrate heterogeneous IoT devices, they might require other kinds\n\
    of network protocols. In [16], the authors use RabbitMQ in order to also be able\
    \ to operate\nwith AMQP (Advanced Message Queuing Protocol) and STOMP (Streaming\
    \ Text Oriented\nMessaging Protocol) clients.\nFinally, there is also the need\
    \ to provide mechanisms that facilitate the use of the\narchitecture into different\
    \ environments and scenarios. The works in [16,17,20] are the\nonly studies that\
    \ provide these facilities. In fact, they use Docker in order to package\nthe\
    \ architecture and its dependencies in order to be deployed in any environment\
    \ with\nthe advantage to select which component might need in order to adapt it\
    \ to a speciﬁc\nIoT scenario.\nAfter analyzing the reviewed works, we ﬁnd that\
    \ there is a gap in solutions that\nprovide generic scalable, portable, and interoperable\
    \ architectures that let integrate models\nin order to take advantage from the\
    \ data collected by the sensors. It is of special importance\nto provide evidence\
    \ in practical applications of the added value that the integration of\nseveral\
    \ sources can provide in the agricultural sector, in general, and the livestock\
    \ sector,\nin particular.\nIn our work, the purpose is to provide guidelines and\
    \ a proof of concept to design ar-\nchitectures that can be reused in different\
    \ IoT scenarios with the adoption of a Microservice\napproach, Docker, and the\
    \ integration of models with a focus in Agricultural contexts.\n3. Architecture\n\
    Basically, in an IoT scenario there are sensors that can share their data through\
    \ the\nInternet and interoperate with cloud platforms, see Figure 1.\nThese sensors\
    \ can give access to their data through APIs or Edge computing nodes.\nUsually,\
    \ in most of the IoT scenarios, sensors provide APIs that allow obtaining their\n\
    last reads (they are updated periodically) in semi-real-time by using the HTTP\
    \ protocol.\nHowever, there are other scenarios where it is required that the\
    \ response time is the lowest\npossible. In order to provide quicker responses,\
    \ there is the need that the processing and\nstorage capabilities of the cloud\
    \ are moved near to these IoT devices, but also to use more\nlightweight protocols\
    \ than HTTP such as MQTT for data transmission to provide real-time\ninteraction.\
    \ Edge computing nodes offer these capabilities. Nevertheless, the resources of\n\
    these computing nodes are limited and in order to store historical data or perform\
    \ complex\ntasks they must also transmit the preprocessed sensor data to the cloud.\
    \ The cloud platform\nis the key to manage the different requirements of IoT scenarios\
    \ such as huge volumes of\nheterogeneous data, security, interoperability, and\
    \ scalability by providing the on-demand\ncomputing resources such as networks,\
    \ databases, servers, storage, and others through the\nInternet thanks to its\
    \ cloud computing infrastructure.\nSensors 2021, 21, 5949\n6 of 21\nFigure 1.\
    \ General Internet of Things (IoT) scenario.\nThis generic cloud architecture\
    \ (Figure 2) has been designed by taking into account the\nrequirements presented\
    \ in Section 1 but with the condition that the cloud platform must be\nconnected\
    \ with third-party APIs or Edge nodes to give response to these input data.\n\
    This cloud architecture comprises three layers (the presentation layer, the logic\
    \ layer,\nand the data layer) and a gateway. The gateway opens the door to the\
    \ cloud platform.\nThus, it sits between the users and a collection of user services.\
    \ The primary purpose of\nthe presentation layer is to provide a user interface\
    \ to collect the user data and display\nthe relevant information to the user.\
    \ The logic layer represents the processes to obtain the\nsensor data, the treatment\
    \ of this heterogeneous data such as data cleaning methodologies,\nthe generation\
    \ of alarms, the execution of different algorithms to obtain valuable data for\n\
    the users, and the interoperability mechanisms to interact with external systems.\
    \ Finally,\nthe data layer is in charge of storing the data that come from different\
    \ sources.\nThese layers are implemented following a microservices architecture\
    \ approach. These\ncollections of services provide the full functionality of the\
    \ cloud platform. As observed\nabove, each service uses its technology stack and\
    \ interoperates between them by using\nlightweight protocols and APIs. Observe\
    \ that if a service needs to be updated, then only\nthis service becomes non-operational\
    \ without affecting the others. Another highlighting\nfeature is that these decoupling\
    \ limits were building the overall platform by using a unique\ntechnology. Instead,\
    \ it can use the adequate technology in order to build a speciﬁc func-\ntionality.\n\
    3.1. Gateway\nThe gateway sits between the users and a collection of user services.\
    \ It decouples\nthe services and allows routing each user request to the right\
    \ place, keeping track of\neverything, and allowing role-based access to the platform\
    \ services. Finally, it adds a\nspeciﬁc component that controls all trafﬁc, and\
    \ external interaction must pass through this\ncomponent. This way reduces the\
    \ complexity to add new services and components and\nreuse these functionalities.\n\
    Sensors 2021, 21, 5949\n7 of 21\nFigure 2. Cloud architecture design.\nThe main\
    \ functionality of the gateway is providing authentication and authorization\n\
    mechanisms. This functionality is provided by the combination of the Shinyproxy\
    \ [22] and\nLDAP services. Shinyproxy is an open-source software that provides\
    \ the authentication\nand authorization mechanisms to deploy Shiny apps in a production\
    \ context.\nThe Shinyproxy service offers a login page that sends the credentials\
    \ to the LDAP\ndirectory service to check if an user exists and the roles that\
    \ the user has assigned to provide\nthe web application that it might require.\
    \ This way, it provides an isolated workspace for\nevery user session by launching\
    \ a Docker container with the web application accessed by\nthe user.\n3.2. Presentation\
    \ Layer\nThe presentation layer is the visible part of the cloud architecture.\
    \ It represents the\ntool that users use to interact with the complex functionalities\
    \ and models they might\nrequire. It is a user-friendly web application that can\
    \ be accessed from any user device\nconnected to the Internet. It hides the complexity\
    \ of the functionalities and operations\nperformed to obtain the desired information.\n\
    The main functionalities of this layer are gathering user input using forms and\
    \ wizards,\nand displaying output data using dashboards and data visualization\
    \ tools. This work\nproposes R Shiny to present the data collected by the sensors\
    \ and the analysis provided by\nSensors 2021, 21, 5949\n8 of 21\nthe cloud in\
    \ a user-friendly manner. The data are obtained by the REST API offered by the\n\
    Node js web service.\nR Shiny is a package for the R language that facilitates\
    \ the building of interactive web\napps by providing the required components to\
    \ integrate the different analysis developed in\nR in the web without knowing\
    \ Javascript, HTML (HyperText Markup Language), and CSS\n(Cascading Style Sheets).\
    \ It also provides the mechanisms to interoperate with external\nsystems such\
    \ as APIs to obtain and transmit the required information. Therefore, it permits\n\
    agile deployment and maintenance for technical and non-technical users.\n3.3.\
    \ Logic Layer\nThis layer aims to process the data from the presentation layer,\
    \ the sensors, and\nexternal services through deﬁned business operations and query\
    \ the data layer. It acts\nas the bridge that allows communication between the\
    \ presentation layer, the IoT devices,\nthe external services, and the data layer.\
    \ APIs allow interoperating between the different\ncomponents of the architecture\
    \ independently of the technology stack that has been used.\nIt also lets the\
    \ integration of new components to provide more data, such as more sensors,\n\
    external services, and others. Most of the time, these APIs use the REST (Representational\n\
    State Transfer) principles to operate respecting the HTTP protocol and transfer\
    \ the required\nresources by using data formats such as JSON (JavaScript Object\
    \ Notation) and XML\n(Extensible Markup Language). Finally, different scripts\
    \ have been developed to perform\ndata collection and data analysis to extract\
    \ the value of this data and generate alarms. Thus,\nthe main functionalities\
    \ of this layer are as follows:\n•\nData Collection: Collect data periodically\
    \ and store them into the MongoDB database.\n•\nData Cleaning: Detect and correct\
    \ data errors, outliers, or erroneous input data.\n•\nData processing and Analysis:\
    \ Execute predictive and prescriptive models. Trans-\nforming raw data into valuable\
    \ data.\n•\nAlert Notiﬁcation: Inform the users via email about possible problems.\n\
    Most of these actions and functions must be executed periodically, such as data\
    \ collec-\ntion, data cleaning, and data processing. Thus, CRON jobs are implemented\
    \ to automate\nthese executions periodically and make the platform act autonomous.\
    \ The technologies\nthat have been applied to implement these functionalities\
    \ are:\n•\nNode js [23]. Node js is an application runtime environment that allows\
    \ writing\nJavaScript for web applications. It comes with many adequate libraries\
    \ for back-end\ndevelopment, such as ﬁle system management, HTTP streams, or database\
    \ man-\nagement. It has been chosen to develop the web service and implement an\
    \ alert\nnotiﬁcation system since it facilitates dealing with multiple client\
    \ requests and pro-\nvides mechanisms that help scale the applications. The authors\
    \ propose using Node js\nto implement the APIs because they have previous know-how\
    \ and successful projects\nimplemented on it. However, it is possible to choose\
    \ similar technologies such as\nFalcon, Asp.Net, or Spring to develop these APIs.\
    \ The web service is in charge of\nretrieving the data from the database and receiving\
    \ the client’s data to process the\ndata and store it. These data are transmitted\
    \ and received using the JSON format.\nThe communication between the client and\
    \ the web service is made via the REST\nAPI with the HTTP protocol that deﬁnes\
    \ the different CRUD (Create, Read, Update,\nDelete) operations that different\
    \ controllers deﬁne. These controllers can operate with\nthe NoSQL database by\
    \ using a library called mongoose that permits mapping the\nmodels deﬁned by Schemas\
    \ into collections of the database. The alert notiﬁcation\nsystem uses the nodemailer\
    \ library to send emails to the user when the system detects\nan alert.\n•\nPython.\
    \ In order to perform the data collection process, Python has been chosen. It\n\
    provides the mechanisms to perform HTTP calls, MQTT protocol, and query NoSQL\n\
    databases. A Python script has been implemented to collect the sensor data provided\n\
    by an External API and uses a package called pymongo to store the data into the\n\
    Sensors 2021, 21, 5949\n9 of 21\nNoSQL database. In order to integrate new sensors,\
    \ it would be necessary to develop\nthe corresponding script using the protocol\
    \ that would be required for that sensor.\nNote that Python is one of the most\
    \ powerful scripting languages, but other languages\ncan be used to implement\
    \ these services. The authors suggest using Python because it\nhas a large community\
    \ and several data mining, automation, and big data platforms\nrely on it. Moreover,\
    \ it is versatile, ﬂexible, easy to manage and maintain, and it has a\nvast range\
    \ of libraries available.\n•\nR. In order to perform the data cleaning and analysis,\
    \ R scripts have been developed.\nThese scripts interact with the Web service\
    \ to store the cleaned data and store the\noutputs of the analysis methods. It\
    \ is also possible to implement these services\nwith other programming technologies.\
    \ Nevertheless, the authors suggest using R to\nsimplify the integration with\
    \ the presentation layer and to allow operations research\nexperts to develop\
    \ models and analytics, as R is a language broadly used in this\nresearch ﬁeld.\n\
    The methodology presented relies on sensors with data transmission capabilities\
    \ such\nas HTTP or MQTT. Therefore, the only requirement to add a new sensor to\
    \ the platform is\ndeﬁning the rules to transmit the data using the APIs. Nevertheless,\
    \ this is not a limitation,\nand if the sensors are old-fashioned and do not support\
    \ these protocols or they do not have\ndirect access to the net, a simple solution\
    \ is to add a ﬁle submission microservice to the\nplatform. Then, the manager\
    \ of the sensor can manually submit the readings periodically\nto the platform.\n\
    3.4. Data Layer\nThe data layer is in charge of storing data from the sensors,\
    \ user proﬁles, user roles,\nand data coming from external services, among others.\
    \ This layer needs to be write-\noptimized to handle all the data arriving from\
    \ the devices. Another important feature is\nthat data are alive and can change\
    \ in the future, so the database technology must permit\nthe addition of new data\
    \ types or change the current structure. Therefore, NoSQL is most\nproper for\
    \ this purpose than relational databases.\nMongoDB [24] is an open-source NoSQL\
    \ database oriented to documents and is write-\noptimized. It allows storing unstructured\
    \ data as a document in a representation called\nBSON (Binary JSON) in a collection\
    \ of documents. It provides a dynamic schema that lets\nus build ﬂexible models\
    \ by updating the schema without affecting the other documents.\nThese features\
    \ allow adapting quickly to changes that can be vital when the system starts to\n\
    store huge volumes of data. This database is also designed to support horizontal\
    \ scalability\nachieved by adding new machines and is managed by the cloud computing\
    \ technology\nand provides high-performance to perform simple operations. Finally,\
    \ it also saves costs\nand complexity in comparison to relational databases. These\
    \ features make this database\nideal for IoT scenarios.\nOn the other hand, OpenLDAP\
    \ [25] is an open-source implementation of LDAP that\nallows access to directory\
    \ services. These directories are specialized databases optimized\nfor reading,\
    \ browsing, searching, and simple update operations. These features make these\n\
    databases ideal for providing centralized user administration to store sensitive\
    \ information\nand other users’ account details. Furthermore, to make more accessible\
    \ the management\nof this LDAP directory, an administration user interface is\
    \ provided. LAM provides a\nuser-friendly interface to manage an LDAP directory\
    \ without the need for the administrator\nto manage LDAP entries.\n4. Deployment\n\
    This section explains how the software architecture has been deployed by leveraging\n\
    the advantages of Virtual Machines and container virtualization using Docker.\n\
    Virtual Machines are digital representations of physical computers with their\
    \ Opera-\ntive System and assigned resources (Memory, CPU, storage, and networks)\
    \ created from a\nsoftware component called a hypervisor. This virtualization\
    \ allows the cloud infrastructure\nSensors 2021, 21, 5949\n10 of 21\nto be split\
    \ up by independent Virtual Machines that can act as different servers by sharing\n\
    the resources managed by the hypervisor. Moreover, Docker can be installed in\
    \ these\nVirtual Machines [26]. Docker is an open platform that allows splitting\
    \ up the applications\nfrom the infrastructure into Docker containers and dealing\
    \ with process isolation. Docker\ncontainers allow separating service and dependencies\
    \ from the underlying operating\nsystem and other containers to avoid dependency\
    \ conﬂicts. All these containerized appli-\ncations share a unique operating system,\
    \ so it permits saving resources and it is also faster\nto be started and stopped\
    \ than Virtual Machines that need each one an Operative System.\nThe cloud platform\
    \ chosen to develop this work is OpenNebula. This is an enterprise-\nready platform\
    \ that helps build an Elastic Private Cloud. It avoids risks and vendor lock-in\n\
    by choosing a powerful but easy-to-use, open-source solution. OpenNebula is based\
    \ on\nvirtual machines but also allows containerized applications from Docker\
    \ to be run.\nOpenNebula offers an open and transparent means to build private\
    \ clouds. The Stormy\nserver [27] is a legacy private cloud platform supported\
    \ by public funding, developed and\nmaintained by the authors’ research group\
    \ aimed at assisting researchers and deployed\nwith OpenNebula and KVM. There\
    \ are several manuscripts, such as that in [28] or in [29],\nthat use the Stormy\
    \ service as a support platform to achieve their goals. Nevertheless,\nthis architecture\
    \ is not limited to this cloud provider as it has been given the needed\nmechanisms\
    \ to be reused in different environments such as Amazon Web Services (AWS)\nor\
    \ Google Cloud.\nConcretely, we have instantiated different virtual machines using\
    \ a Centos7 OS image\nto host the different microservices. Each virtual machine\
    \ is protected with a ﬁrewall. All the\nmicroservices are deployed and managed\
    \ using container-based virtualization (Docker).\nThis containerization allows\
    \ this architecture to be scaled and reused so it can replace\nthe services used\
    \ in this architecture for the speciﬁc services and its suitable technologies\n\
    to implement the speciﬁc IoT scenario and also the environment where these services\n\
    are deployed but also duplicate the services that require more availability. Therefore,\
    \ it\nfacilitates that this cloud architecture can be reused in any environment\
    \ and is prepared to\ntake advantage of autoscaling policies provided by Kubernetes\
    \ or other cloud orchestrators.\nFigure 3 depicts a general-purpose deployment\
    \ into a cloud provider (OpenNebula,\nAmazon Web Services or Google Cloud). First,\
    \ it is conﬁgured the virtual resources into the\ncloud provider (CPU, Memory\
    \ and Networks). Then, the operating system (Centos7 in our\ndeployment) is installed\
    \ to each virtual machine deployed together with all the required\ntools (Docker\
    \ and Git). Next, an orchestrator is installed and conﬁgured. Our deployment\n\
    uses docker-compose, but other alternatives that can be used are Kubernetes, docker-\n\
    swarm, among others. In parallel, the development environment can be conﬁgured\
    \ in a\nlocal machine to implement and test the services and the applications.\
    \ Then, to integrate\nthe development and production environments, GitHub is used\
    \ (push and pull actions).\nFinally, the docker build commands are employed to\
    \ create the images, and to run and\nexecute all the services the docker-compose\
    \ up commands are used.\nSensors 2021, 21, 5949\n11 of 21\nVersion September 1,\
    \ 2021 submitted to Sensors\n11 of 21\nDeployment\nCloud Provider\nInstantiate\n\
    Virtual Machine\nin the cloud\nprovider\nLaunch Virtual\nMachine in the\ncloud\
    \ provider\nOrchestrator\nInstall and\nconfigure\nOrchestrator \n(Kubernetes)\n\
    Out of scope of\nthis paper\ncompose\nothers\nVirtual Machine\nInstall docker\n\
    and \ndocker-compose\nin each VM\nInstall git\nProduction Environment\nGit pull\n\
    Launch services \nand apps\ndocker-compose up\nNo\nEnd -\nArchitecture \nis running\n\
    Prod\nDevelopment Environment\nWrite dockerfile\nTest\nMicroservices\nand Apps\n\
    Code\nMicroservices\nand Apps\nInstall docker\nCreate images\nfrom services\n\
    docker build\nstart?\nYes\nRelaunch services \nand apps\ndocker-compose down\n\
    docker-compose up\nTest \npassed?\nNo\nYes\nGit push\nenvironment?\nDev\nFigure\
    \ 3. Block diagram of the deployment of the architecture.\nThe application we\
    \ have developed leverages the information provided by a low-cost sensor installed\n\
    394\nin a silo to infer the feed consumption and from this information compute\
    \ the expected growth.\n395\nThe primary use of a sensor installed in a silo is\
    \ to provide information on the amount of feed\n396\navailable to guide the farmer\
    \ on the replenishment order. However, this information can provide\n397\nextra\
    \ value if it is combined with other information. For example, feed manufacturers\
    \ may plan better\n398\ntheir operations if they know the inventory levels of\
    \ their clients [36]. From a farmer perspective, the\n399\nenrichment of statistical\
    \ growth models with sensor data that estimates the feed intake may provide\n\
    400\nvaluable estimates of the expected growth evolution of a batch of pigs. Monitoring\
    \ the animals’ growth\n401\nis relevant to support the optimal moment for delivering\
    \ the pigs to the abattoir and to detect abnormal\n402\ndeviations between the\
    \ theoretical expected growth curve and the estimated growth based on sensor\n\
    403\ndata. Such deviations may reveal the occurrence of some (sanitary, feed quality,\
    \ ...) problem if the\n404\nestimated curve is slower or reﬂect the result of\
    \ a good practice if the growth is faster.\n405\nFigure 3. Block diagram of the\
    \ deployment of the architecture.\n5. Case Study\nThe rate of adoption of sensor\
    \ technologies varies among sectors, and it is related\nto the trade-off between\
    \ the costs and potential beneﬁts. In particular, the agricultural\nsector uses\
    \ different sensors to measure and track the evolution of several environmental\n\
    characteristics such as soil humidity, air temperature or CO2 concentrations,\
    \ among others.\nThis type of information is relevant to guide the decisions on\
    \ the best actuation at each\nmoment. The data analysis that stems from this information\
    \ usually falls in the descriptive\narea. With the IoT platform presented, we\
    \ aim to facilitate the development, usage and\nadoption of applications involving\
    \ advanced modeling techniques for the agricultural\nSensors 2021, 21, 5949\n\
    12 of 21\nsector. In this way, new developments from the Operations Research or\
    \ the Artiﬁcial Intel-\nligence communities such as prescriptive optimization\
    \ models [30], predictive statistical\nmodels [31] or classiﬁcation models [32],\
    \ among others may be easily transferred to the\nﬁnal users.\nThe current case\
    \ study applies the described cloud architecture to build a smart\napplication\
    \ that estimates the growth of pigs based on the amount of feed discharged from\n\
    the silo, where a sensor is installed. Pork is one of the most consumed meats\
    \ in the world\ntogether with poultry [33]. It is estimated that between 60% and\
    \ 70% of the total production\ncost per kilogram of pork corresponds to feed consumption\
    \ [34], being the information\nrelated to the feed a key characteristic to monitor\
    \ and control. This application has been\ndeveloped within a demonstration project\
    \ with the participation of three farmers and a\ntotal of eight silos monitored\
    \ and sixteen batches analyzed (composed of 500–900 animals\nper batch). The capacity\
    \ of the silos monitored ranged from 11,000 kg to 16,000 kg.\nThe interest in\
    \ estimating (and better understanding) the growth of a batch of pigs is\none\
    \ of the key breakthroughs that the pig sector is working on. Some approaches\
    \ go in the\nline of precision feeding where individual data on feed intake and\
    \ weight is monitored\neach time an animal visits the feeding station [35]. While\
    \ this system offers accurate and\ncomprehensive information, it is still an expensive\
    \ option. At the other end, traditional pig\nmanagement software offers estimates\
    \ on the expected growth based on estimates from\nprevious batches. An estimation\
    \ of the feed consumed is built from these parameters and\nthen compared with\
    \ the loads performed during the growth. However, the interest of\nmonitoring\
    \ the feed dynamics is increasing and other solutions are being implemented.\n\
    The application we have developed leverages the information provided by a low-cost\n\
    sensor installed in a silo to infer the feed consumption and from this information\
    \ compute\nthe expected growth.\nThe primary use of a sensor installed in a silo\
    \ is to provide information on the amount\nof feed available to guide the farmer\
    \ on the replenishment order. However, this information\ncan provide extra value\
    \ if it is combined with other information. For example, feed\nmanufacturers may\
    \ better plan their operations if they know the inventory levels of their\nclients\
    \ [36]. From a farmer’s perspective, the enrichment of statistical growth models\n\
    with sensor data that estimate the feed intake may provide valuable estimates\
    \ of the\nexpected growth evolution of a batch of pigs. Monitoring the animals’\
    \ growth is relevant to\nsupport the optimal moment for delivering the pigs to\
    \ the abattoir and to detect abnormal\ndeviations between the theoretical expected\
    \ growth curve and the estimated growth based\non sensor data. Such deviations\
    \ may reveal the occurrence of some (sanitary, feed quality,\netc.) problem if\
    \ the estimated curve is slower or reﬂect the result of a good practice if the\n\
    growth is faster.\nIn the following sections, the application that estimates the\
    \ weight evolution of the\npigs in a fattening farm based on the estimate of the\
    \ feed consumption is presented. We\nﬁrst explain the process to integrate several\
    \ sources of data with the predictive models,\nthe characteristics of the farm,\
    \ the sensor technology used, the growth models, and the user-\nfriendly interface\
    \ that allows to easily obtain the information. The resulting application\ncan\
    \ be accessed from https://gcd007.udl.cat/login (version 31 August 2021) and the\n\
    functionalities can be explored with a demonstration test set for a user (username:\
    \ demo)\nwith password (demo@alba25.udl.cat). Note that some functionalities are\
    \ disabled for this\ndemonstration user.\n5.1. Process Description\nIn a three-site\
    \ system, pig production is divided in three stages: (a) maternity, where\nthe\
    \ piglets are born and stay there for 4–5 weeks; (b) rearing, where young pigs\
    \ are grown\nup to the age of 8–10 weeks; and (c) fattening, where the pigs are\
    \ grown for 17–20 weeks\nuntil they reach a target marketing weight and then are\
    \ sent to the abattoir. In this\napplication, our target is to estimate the growth\
    \ at the fattening stage. Figure 4 shows the\nmain steps of the data ﬂow process,\
    \ from the data acquisition to the ﬁnal growth estimate.\nSensors 2021, 21, 5949\n\
    13 of 21\nThe data sources are the sensor measures and some technical parameters\
    \ of the batch of\npigs which are combined to provide an estimate of the average\
    \ feed consumption per\nanimal. The literature provides functions that relate\
    \ the average consumption of pigs\nwith the expected growth. The expected average\
    \ weight is ﬁnally modeled as a weight\ndistribution, so the farmer has a week\
    \ by week estimation of the number of animals that\nare expected to be in each\
    \ weight range.\nSILO CONTENTS\nBATCH\nINFORMATION\nFEED\nCONSUMPTION\nGROWTH\n\
    ESTIMATION\nFigure 4. General data ﬂow process.\nDue to sanitary reasons, the\
    \ animals at the fattening stage are grown in batches where\nno new animals can\
    \ enter the farm before the last animal from the previous batch has left\nand\
    \ the farm is sanitized. However, the entrance and removal of animals can happen\
    \ on\ndifferent days. The application shows information for a particular batch,\
    \ which is deﬁned\nwith the earliest entrance of animals. For each entrance, the\
    \ date, number of piglets, and\nthe average weight needs to be speciﬁed by the\
    \ farmer in an input form. This is the basic\ninformation the farmer obtains for\
    \ each truck of piglets received.\nAt the entrance, piglets may not have a homogeneous\
    \ weight nor age. Furthermore,\nthe growth rate of each animal will be different\
    \ and therefore some animals will reach the\ntarget weight earlier than others.\
    \ When a sufﬁcient number of animals (which is related to\nthe truck capacity)\
    \ reach the marketing weight, those animals are sent to the abattoir. It\nis customary\
    \ that the marketing window comprises four or ﬁve weeks. When a group of\nanimals\
    \ is sent to the abattoir, the farmer is expected to inform of the number of animals\n\
    removed and the weight reported by the abattoir. Having the information on the\
    \ number\nof animals present in the farm is very relevant so the application can\
    \ compute the average\nindividual feed intake more accurately.\n5.1.1. Feed Consumption\
    \ Estimation\nThe driver information for estimating the amount (in kg) of feed\
    \ consumption of the\nbatch is provided by the sensor. By monitoring the silo\
    \ level, we can infer the amount of\nfeed that the batch is consuming. We assume\
    \ that the amount of feed discharged from the\nsilo is consumed by the animals\
    \ disregarding any lost it may happen due to rejection or\nwaste. There exists\
    \ several solutions in the market for remotely monitoring a silo contents.\nA\
    \ direct approach to know the silo’s content weight is to install load cells in\
    \ the silo support\nstructure [37]. This is the most precise approach but for\
    \ already installed silos, it demands a\ncostly installation. An indirect approach\
    \ is to use level or surface sensors, which are based\non radar, laser or other\
    \ type of guided wave technology which provides information on the\nvolume of\
    \ the silo that is occupied. Therefore, the weight of the feed in a silo needs\
    \ to be\napproximated by combining the measure of the sensor with the feed density.\
    \ These type of\nsensors are usually placed at the top of the silo and require\
    \ minimal installation. They are\nusually powered by a solar cell which removes\
    \ the need to be connected to a power grid.\nIn this work, the sensor used is\
    \ a wireless one-point level sensor developed by Mon-\nitoring Control Systems\
    \ [38] based on laser technology. In order to compute the level,\nSensors 2021,\
    \ 21, 5949\n14 of 21\nit takes into account the height of the silo and it uses\
    \ a time-of-ﬂight computation to a\nspeciﬁc point, usually the center of the silo.\
    \ Then, it measures the time that the laser beam\n(Class II laser, <1 mW, 635\
    \ nm) uses to go to this speciﬁc point and to come back (see\nFigure 5). This\
    \ type of sensor is appropriate for small and medium bins with up to a range\n\
    of 40 m, such as those used to store feed for animals; otherwise, it may suffer\
    \ from lack\nof accuracy. The reading is done periodically; in this work, an automated\
    \ CRON job is\nexecuted every two hours. This reading is sent through a radio\
    \ network of wide coverage\nand low electricity consumption (Sigfox network [39])\
    \ to the company platform called\nDigitplan. We access this information through\
    \ a REST API in order obtain the silo data via\nHTTP protocol.\n5.1.1. Feed consumption\
    \ estimation\n439\nThe driver information for estimating the amount (in kg) of\
    \ feed consumption of the batch is\n440\nprovided by the sensor. By monitoring\
    \ the silo level we can infer the amount of feed that the batch is\n441\nconsuming.\
    \ We assume that the amount of feed discharged from the silo is consumed by the\
    \ animals\n442\ndisregarding any lost it may happen due to rejection or waste.\
    \ There exists several solutions in the\n443\nmarket for remotely monitoring a\
    \ silo contents. A direct approach to know the silo’s content weight is\n444\n\
    to install load cells in the silo support structure [37]. This is the most precise\
    \ approach but for already\n445\ninstalled silos, it demands a costly installation.\
    \ An indirect approach is to use level or surface sensors\n446\nwhich are based\
    \ on radar, laser or other type of guided wave technology which provides information\n\
    447\non the volume of the silo that is occupied. Therefore, the weight of the\
    \ feed in a silo needs to be\n448\napproximated by combining the measure of the\
    \ sensor with the feed density. These type of sensors are\n449\nusually placed\
    \ at the top of the silo and require minimal installation. They are usually powered\
    \ by a\n450\nsolar cell which removes the need to be connected to a power grid.\n\
    451\nFeed level\nLaser \nSilometric\nsensor\nFigure 5. Diagram of the spatial\
    \ distribution of the sensor in the silo. Technical details can be found on\n\
    the manufacturer web page [38].\nIn this work, the sensor used is a wireless one-point\
    \ level sensor developed by Monitoring Control\n452\nSystems [38] based on laser\
    \ technology. In order to compute the level, it takes into account the height\n\
    453\nof the silo and it uses a time-of-ﬂight computation to a speciﬁc point, usually\
    \ the center of the silo\n454\nThen it measures the time that the laser beam (Class\
    \ II laser, <1mW, 635 nm.) uses to go to this speciﬁc\n455\npoint and to come\
    \ back (see Figure 5). This type of sensor is appropriate for small and medium\
    \ bins\n456\nwith up to a range of 40 meters, such as those used to store feed\
    \ for animals, otherwise it may suffer\n457\nfrom lack of accuracy. The reading\
    \ is done periodically, in this work an automated CRON job is\n458\nexecuted every\
    \ two hours. This reading is sent through a radio network of wide coverage and\
    \ low\n459\nelectricity consumption (Sigfox network [39]) to the company platform\
    \ called Digitplan. We access this\n460\ninformation through a REST API in order\
    \ obtain the silo data via HTTP protocol.\n461\nThe information provided by the\
    \ sensor is therefore a measure of volume which needs to be\n462\ntransformed\
    \ to weight (see Figure 6). For doing so, we need to know the density of the feed\
    \ which is\n463\ndifferent for each truckload that reﬁlls the silo. This characteristic\
    \ demands to control for the points in\n464\nwhich the reading increases due to\
    \ the feed reﬁlling operation. To reduce inaccuracies, it is expected\n465\nthat\
    \ the farmer introduces the real weight of the added quantity. The system assumes\
    \ a default density\n466\nand by comparing the estimation of the amount introduced\
    \ according to the default value and the real\n467\nvalue provided, a more precise\
    \ estimation of the density can be done. The weight of the contents of the\n468\n\
    silo is estimated by multiplying the occupied volume of the silo times the density\
    \ of the feed.\n469\nTo approximate the amount of feed supplied to the batch would\
    \ sufﬁce to subtract two consecutive\n470\nreadings expressed as weight. However,\
    \ the process of discharging the feed from the silo leaves\n471\nFigure 5. Diagram\
    \ of the spatial distribution of the sensor in the silo. Technical details can\
    \ be found\non the manufacturer web page [38].\nThe information provided by the\
    \ sensor is therefore a measure of volume which needs\nto be transformed to weight\
    \ (see Figure 6). For doing so, we need to know the density of the\nfeed which\
    \ is different for each truckload that reﬁlls the silo. This characteristic demands\n\
    to control for the points in which the reading increases due to the feed reﬁlling\
    \ operation.\nTo reduce inaccuracies, it is expected that the farmer introduces\
    \ the real weight of the\nadded quantity. The system assumes a default density,\
    \ and by comparing the estimation of\nthe amount introduced according to the default\
    \ value and the real value provided, a more\nprecise estimation of the density\
    \ can be done. The weight of the contents of the silo is\nestimated by multiplying\
    \ the occupied volume of the silo times the density of the feed.\nSensor Reading\
    \ \n(volume)\nEstimated weight \nof the silo contents\nFeed refill?\nGet truckload\
    \ weight\nYes\nGet feed density\nNo\nUpdate feed density\nFigure 6. Estimation\
    \ of the weight of the feed from the readings of the sensor.\nTo approximate the\
    \ amount of feed supplied to the batch would sufﬁce to subtract two\nconsecutive\
    \ readings expressed as weight. However, the process of discharging the feed\n\
    from the silo leaves the surface uneven making the readings ﬂuctuate among consecutive\n\
    Sensors 2021, 21, 5949\n15 of 21\nperiods (instead of being monotonically decreasing\
    \ within any two reﬁlling operations).\nDue to this reason, data cleaning is done\
    \ by means of a centered moving average. Punctual\nmissing data are also interpolated\
    \ using this procedure. Figure 7 illustrates some of the data\ncleaning procedures\
    \ that the application automatically performs. The dots show the days\nand the\
    \ amount in which the silo was reﬁlled. By default, the application assumes a\
    \ feed\ndensity, but the density is re-estimated with the information about the\
    \ real weight of the\nreﬁlling load. Then, the series of the weight with the reﬁlling-based\
    \ density is computed\nand is cleaned in order to remove sensor noise or missing\
    \ values.\nOscillations due to refill operations\nG\nG\nG\nG\nG\ndefault density\n\
    \ overestimate\ndefault density\n underestimate\n0\n 5000\n10,000\n15,000\nApr\
    \ 15\nMay 01\nMay 15\nFeed contents in the silo (kg)\nG\nFeed refill\nRaw sensor\
    \ data (default density)\nRaw sensor data (estimated density)\nSmoothed series\n\
    Figure 7. Time series of the silo contents estimated from the sensor readings.\n\
    There exists other sensors on the market that could be used instead of the sensor\n\
    presented [40,41]. Each sensor can use different technologies (radar, 3D level\
    \ sensor, etc.)\nto provide information on the ﬁlled volume and each manufacturer\
    \ provide access to the\ncollected data in a speciﬁc way. The platform allows\
    \ to include different scripts to import\ndata such that the different sensors\
    \ can easily be included. Other solutions directly weight\nthe feed unloaded [42]\
    \ which eliminates the need to perform the transformation from\nvolume to weight,\
    \ and only the data cleaning step should be performed.\nOnce the point reading\
    \ is cleaned, the accumulated weekly consumption is estimated\n(see Figure 8).\
    \ This estimated consumption based on the sensor readings is compared with\na\
    \ theoretical accumulated feed consumption which is computed according to technical\n\
    parameters that reﬂects usual patterns of the farm and the breed of animals that\
    \ hosts. These\nparameters are provided by the user and are the average daily\
    \ gain (ADG), the expected\nfeed conversion rate (FCR), and the age (in weeks).\
    \ Among the alternatives to estimate\nthe expected accumulated feed intake (AFI)\
    \ for a batch of N animals at week t [43],\nthe exponential function is used:\n\
    AFIt = N\nA\n1 + exp −(b · aget)\n(1)\nwhere A is the expected amount of feed\
    \ taken at adult age and b is a ﬁtted constant.\nSensors 2021, 21, 5949\n16 of\
    \ 21\nFigure 8. Cumulative feed intake of the animals in the batch.\n5.1.2. Growth\
    \ Estimation\nSeveral empirical models exist to estimate the growth curve for\
    \ the average population\nby estimating the average weight along the time. However,\
    \ the average weight of a group\nof pigs is comprised of individuals with differing\
    \ performance levels and individual growth\ncurves. Empirically is observed that\
    \ as live weight increases, weight variation between the\npigs also increases.\
    \ Therefore, from a farmer’s point of view, the distribution of the weight\nconveys\
    \ better information. In this work, a growth curve from the Gompertz family [44]\n\
    has been used to estimate the average weight (AW) of the population at a particular\
    \ week t:\nAWt = A exp− exp(b−k·AFIt)\n(2)\nwhere AWt is the average body weight\
    \ (kg) at week t, A is the asymptotic adult body\nweight (kg), b is an empirically\
    \ ﬁtted parameter that makes the starting point ﬂexible, k is\nan empirically\
    \ ﬁtted parameter related to the rate of growth, and AFIt is the average accu-\n\
    mulated feed intake (kg) up to week t. Given that a batch may be composed by subgroups\n\
    of animals, one for each entry, Equation (2) is applied to each subgroup. Figure\
    \ 9 shows\nthe expected weight for each entry of the batch at a speciﬁc point\
    \ in time, computed with\nthe average feed intake according to the theoretical\
    \ function and also with the estimated\ndata from the sensor. This information\
    \ has commercial signiﬁcance, as deviations between\nthose curves alert the farmer\
    \ to review the animals in order to ﬁnd the cause of the de-\nviance. However,\
    \ before diving into the causes, data accuracy has to be veriﬁed. When\na signiﬁcant\
    \ deviation between the theoretical and sensor-based estimations is detected,\n\
    an alert message is sent to the farmer to verify that the data corresponding to\
    \ the weight of\nthe silo’s reﬁlling information have been provided.\nThe distribution\
    \ of the weight at a particular point in time is represented by a Normal\ndistribution\
    \ with the mean according to Equation (2) and variance computed from a cubic\n\
    polynomial function. To provide a better picture of the weight of the animals\
    \ in the batch, all\nthe subgroups distributions are merged to compose the ﬁnal\
    \ weight distribution. Figure 10\nshows the weight distribution at a particular\
    \ week with the expected number of animals\nwithin a 5 kg range. This information\
    \ is especially relevant to plan the delivery of animals\nto the abattoir based\
    \ on a target weight.\nSensors 2021, 21, 5949\n17 of 21\nFigure 9. Animal average\
    \ weight.\nFigure 10. Animal weight distribution in a speciﬁc week.\n5.1.3. Data\
    \ Input Process\nThe reading and data processing of the sensor data are automated\
    \ within the appli-\ncation. Other information related to the batch is required\
    \ to be provided by the farmer.\nIn its current state of development, the user\
    \ must perform a manual entry. This is gen-\neral information to set up a batch,\
    \ inventory information about the number of animals\npresent in the farm either\
    \ entrances or departures, and the information on the reﬁlling\ntruck loads. The\
    \ reader is invited to explore this information with the demo user provided\n\
    in the application.\nThe application also includes a descriptive (and simpliﬁed)\
    \ view to monitor the\navailable feed in the silo. It shows an already processed\
    \ range of historical data corrected\nby the density estimates and it is compared\
    \ with the cleaned series.\n5.2. Deployment\nFigure 11 shows the deployment of\
    \ the architecture explained in Section 4 applied to\nthe case study. This proof\
    \ of concept is deployed using two virtual machines (VM1 and\nVM2) under OpenNebula\
    \ cloud provider. VM1 contains the gateway and is the open-door\nSensors 2021,\
    \ 21, 5949\n18 of 21\nto the internet. VM2 is only accessible from VM1. As we\
    \ commented, we use Centos7\nas operating system in both virtual machines. This\
    \ ﬁgure also highlights all the services\nthat are started using Docker compose\
    \ orchestrator (green and yellow boxes). The yellow\nboxes represent the services\
    \ related to the data layer, and the green ones represent the APIs,\nscripts,\
    \ and other services discussed. Note that the data collection service is gathering\
    \ data\nfrom the sensor every to 2 h and stores it into the database using HTTP\
    \ communication\nprotocol. Next, the data cleaning service processes incoming\
    \ data and checks for errors and\nnon-consistent data. In parallel, the alarm\
    \ service checks information from the database to\ninform the user, if needed.\
    \ Finally, the RShinny Application uses farm service (API) and\nthe growth model\
    \ to interact using HTTP and HTTPS communication protocols to display\ninformation\
    \ to the ﬁnal user (client). This communication is controlled (authenticated and\n\
    authorized) through the gateway.\nit is compared with the cleaned series.\n529\n\
    5.2. Deployment\n530\nFigure 11 shows the deployment of the architecture explained\
    \ in Section 4 applied to the case study.\n531\nThis proof of concept is deployed\
    \ using two virtual machines (VM1 and VM2) under OpenNebula cloud\n532\nprovider.\
    \ VM1 contains the gateway and is the open-door to the internet. VM2 is only accessible\
    \ from\n533\nVM1. As we commented we use Centos7 as Operating System in both virtual\
    \ machines. This ﬁgure\n534\nalso highlights all the services that are started\
    \ using Docker compose orchestrator (green and yellow\n535\nboxes). The yellow\
    \ boxes represent the services related to the data layer and the green ones represent\n\
    536\nthe APIs, scripts and other services discussed. Note, that the data collection\
    \ service is gathering data\n537\nfrom the sensor every to 2 hours and stores\
    \ it into the database using HTTP communication protocol.\n538\nNext, the data\
    \ cleaning service processes incoming data and checks for errors and non-consistent\n\
    539\ndata. In parallel, the alarm service checks information from the database\
    \ to inform the user, if needed.\n540\nFinally, the RShinny Application uses farm\
    \ service (API) and the growth model to interact using\n541\nHTTP and HTTPS communication\
    \ protocols to display information to the ﬁnal user (client). This\n542\ncommunication\
    \ is controlled (authenticated and authorized) through the gateway.\n543\nDocker\
    \ Host\nGateway\nLDAP\nMONGO DB\nData collection\nservice\nsensor\nHTTP\n2 hours\
    \ / read\nwrite\nData cleaning\n service\nread / write\nauthentication /\nauthoritzation\n\
    R Shinny \napplication\nFarm service\nGrowth Model\nDocker Host\nClient\nVM 1\n\
    VM 2\nPrivate virtual network\nInternet\nHTTP / HTTPS\nAlarm Service\nFigure 11.\
    \ General scheme of the deployment of the case study.\nFigure 11. General scheme\
    \ of the deployment of the case study.\n6. Conclusions and Future Work\nThe paper\
    \ concludes by arguing the current need for designing architectures that\nsupport\
    \ evolving and emerging sensors and devices to facilitate digital transformation\
    \ in\nagricultural contexts. The ﬁndings of this study can be understood as general\
    \ guidelines\nof features to be taken into account when designing Information\
    \ Technology solutions to\nassist agriculture. These guidelines are more consistent\
    \ with current research showing that\nmost features and requirements are standard\
    \ in other industrial sectors.\nNevertheless, in this study, we shed light on\
    \ the challenges and issues of applying\nthese methodologies and Fog, Edge, and\
    \ Cloud paradigms to agricultural scenarios.\nOne of these requirements is to\
    \ deal with the heterogeneous data of sensors and\nexternal services to connect\
    \ the physical and virtual worlds. Broadly translated, the state-\nof-the-art\
    \ ﬁndings indicate that this requirement can be solved by using Fog and Edge\n\
    paradigms or developing scripts in the cloud side (as we propose) that can be\
    \ worth\noperating with these devices by using the corresponding protocol such\
    \ as HTTP and MQTT\nand storing the data into NoSQL databases such as MongoDB.\n\
    Furthermore, another important characteristic that must provide the cloud platform\
    \ is\nscalability. We have shown how a modular design using a microservice approach\
    \ helps\nin adjusting the computational resources on demand. Therefore, we show\
    \ how container\ntechnologies such as Docker can integrate more sensors, analysis\
    \ methods, and services,\nand provide horizontal scaling.\nSensors 2021, 21, 5949\n\
    19 of 21\nTogether, the present study conﬁrms that Docker technology also facilitates\
    \ the porta-\nbility and interoperability of the platform to other IoT scenarios\
    \ and Cloud providers by\nonly installing this technology into the cloud. Moreover,\
    \ there is also the need to provide\nsecurity mechanisms such as roles and authentication\
    \ to provide access to the needed tools\nand prevent undesired access to the platform.\n\
    The case study shows a practical implementation of the ideas presented in this\
    \ work\nwhere all the architecture and the application is developed with open-source\
    \ initiatives.\nThe application shows a way to enhance the value of the data gathered\
    \ by a sensor level\nin a silo from where a batch of pigs are fattened. While\
    \ special care has been taken in the\ndesign of a general and ﬂexible architecture\
    \ so that it can receive data from other sensor\nmanufacturers, much attention\
    \ has also been paid to the integration of advanced modeling\ntools, such as the\
    \ growth model. Note that the code developed at the modeling stage\nwith the R\
    \ statistical software was easily transferred to the platform development team,\n\
    allowing a ﬂuid ﬂow of work. Although the application is focused to the livestock\
    \ sector,\nthe conceptual architecture presented is general and applicable to\
    \ other agro-industrial\nprocesses. We leave as a future work, performing a proof\
    \ of concept of the methodologies\nin other settings.\nFinally, regarding future\
    \ work, we are interested in integrating new kinds of sensors\nto analyze critical\
    \ tasks for the case study that can be assigned to Edge Nodes and provide\nnew\
    \ analysis to provide valuable output. Functionality that would be interesting\
    \ to\nintegrate would be registering IoT devices to the platform by using, for\
    \ example, QR\n(Quick Response) codes and the conﬁguration/management of these\
    \ devices to control\nproprietary devices. From a user perspective, having a push\
    \ notiﬁcation complement would\nenhance the reception of alarms. This and other\
    \ characteristics may be included in future\ndevelopments. Another exciting characteristic\
    \ for IoT scenarios is product traceability that\ncan be implemented by leveraging\
    \ Blockchain technologies. Furthermore, to improve the\nanalysis performance,\
    \ a processing distributed framework such as Apache Spark could be\nintegrated\
    \ to provide support for R and Python programming to provide complex analysis\n\
    with huge amounts of data.\nAuthor Contributions: J.M.-F., A.P.-B. and L.M.P.-A.\
    \ project administration, J.M.-F. and A.P.-B.\nsupervision, design, methodology\
    \ and writing, J.M.-F. and J.P.C.-G. software, A.P.-B. and J.P.C.-G.\nvisualization,\
    \ D.B.-G., A.P.-B. and L.M.P.-A. data and validation. All authors have read and\
    \ agreed to\nthe published version of the manuscript.\nFunding: This research\
    \ was partially supported by the Intelligent Energy Europe (IEE) program\nand\
    \ the Ministerio de Economía y Competitividad under contract TIN2017-84553-C2-2-R,\
    \ by the\nEuropean Union FEDER (CAPAP-H6 network TIN2016-81840-REDT) and the demonstration\
    \ activity\nﬁnanced by the Operation 01.02.01 of Technological Transfer from the\
    \ Program of Rural Development\nin Catalunya 2014–2020 coﬁnanced by DARP and FEDER.\n\
    Acknowledgments: Jordi Mateo-Fornés is member of the research group 2017-SGR363,\
    \ and Adela\nPagès-Bernaus and Lluís Miquel Plà-Aragonés are members of the research\
    \ group 2017-SGR01193,\nboth funded by Generalitat de Catalunya.\nConﬂicts of\
    \ Interest: The authors declare no conﬂict of interest.\nReferences\n1.\nShaﬁque,\
    \ K.; Khawaja, B.A.; Sabir, F.; Qazi, S.; Mustaqim, M. Internet of Things (IoT)\
    \ for Next-Generation Smart Systems: A\nReview of Current Challenges, Future Trends\
    \ and Prospects for Emerging 5G-IoT Scenarios. IEEE Access 2020, 8, 23022–23040.\n\
    [CrossRef]\n2.\nBinti Mohamad Noor, M.; Hassan, W.H. Current research on Internet\
    \ of Things (IoT) security: A survey. Comput. Netw. 2019,\n148, 283–294. [CrossRef]\n\
    3.\nWaadt, A.; Bruck, G.; Jung, P. Positioning Systems and Technologies. In Mobile\
    \ Positioning and Tracking, 2nd ed.; Frattasi, S., Della\nRosa, F., Eds.; Wiley-IEEE\
    \ Press: Chichester, UK, 2017; Chapter 8, pp. 189–223. [CrossRef]\n4.\nSharma,\
    \ A.; Singh, P.K.; Kumar, Y. An integrated ﬁre detection system using IoT and\
    \ image processing technique for smart cities.\nSustain. Cities Soc. 2020, 61,\
    \ 102332. [CrossRef]\nSensors 2021, 21, 5949\n20 of 21\n5.\nVarghese, B.; Buyya,\
    \ R. Next generation cloud computing: New trends and research directions. Future\
    \ Gener. Comput. Syst. 2018,\n79, 849–861. [CrossRef]\n6.\nHu, P.; Dhelim, S.;\
    \ Ning, H.; Qiu, T. Survey on fog computing: Architecture, key technologies, applications\
    \ and open issues. J.\nNetw. Comput. Appl. 2017, 98, 27–42. [CrossRef]\n7.\nKaranassios,\
    \ V. Sensors trends: Smaller, cheaper, smarter, faster and under wireless control.\
    \ In Proceedings of the FLEPS\n2019—IEEE International Conference on Flexible\
    \ and Printable Sensors and Systems, Proceedings, Glasgow, UK, 7–10 July 2019;\n\
    pp. 2019–2022. [CrossRef]\n8.\nBerckmans, D. General introduction to precision\
    \ livestock farming. Anim. Front. 2017, 7, 6–11. [CrossRef]\n9.\nJesus, G.; Casimiro,\
    \ A.; Oliveira, A. A survey on data quality for dependable monitoring in wireless\
    \ sensor networks. Sensors\n2017, 17, 2010. [CrossRef]\n10.\nYawut, C.; Kilaso,\
    \ S. A Wireless Sensor Network for Weather and Disaster Alarm Systems. Int. Conf.\
    \ Inf. Electron. Eng. 2011,\n6, 155–159.\n11.\nBelfkih, A.; Duvallet, C.; Sadeg,\
    \ B. A survey on wireless sensor network databases. Wirel. Netw. 2019, 25, 4921–4946.\
    \ [CrossRef]\n12.\nJirkovsky, V.; Obitko, M.; Marik, V. Understanding data heterogeneity\
    \ in the context of cyber-physical systems integration. IEEE\nTrans. Ind. Inform.\
    \ 2017, 13, 660–667. [CrossRef]\n13.\nTaleb, I.; Serhani, M.A.; Dssouli, R. Big\
    \ Data Quality: A Survey. In Proceedings of the 2018 IEEE International Congress\
    \ on Big\nData, BigData Congress 2018—Part of the 2018 IEEE World Congress on\
    \ Services, Seattle, WA, USA 2–7 July 2018; pp. 166–173.\n[CrossRef]\n14.\nChu,\
    \ X.; Ilyas, I.F.; Krishnan, S.; Wang, J. Data cleaning: Overview and emerging\
    \ challenges. In Proceedings of the ACM SIGMOD\nInternational Conference on Management\
    \ of Data, Portland, OR, USA, 14–19 June 2016; pp. 2201–2206. [CrossRef]\n15.\n\
    Ferrández-Pastor, F.J.; García-Chamizo, J.M.; Nieto-Hidalgo, M.; Mora-Pascual,\
    \ J.; Mora-Martínez, J. Developing ubiquitous\nsensor network platform using internet\
    \ of things: Application in precision agriculture. Sensors 2016, 16, 1141. [CrossRef]\n\
    16.\nTrilles, S.; González-Pérez, A.; Huerta, J. An IoT platform based on microservices\
    \ and serverless paradigms for smart farming\npurposes. Sensors 2020, 20, 2418.\
    \ [CrossRef] [PubMed]\n17.\nTaneja, M.; Byabazaire, J.; Davy, A.; Olariu, C. Fog\
    \ assisted application support for animal behaviour analysis and health\nmonitoring\
    \ in dairy farming. In Proceedings of the IEEE World Forum on Internet of Things,\
    \ Singapore, 5–8 February 2018;\npp. 819–824. [CrossRef]\n18.\nCambra, C.; Sendra,\
    \ S.; Lloret, J.; Garcia, L. An IoT service-oriented system for agriculture monitoring.\
    \ In Proceedings of the 2017\nIEEE International Conference on Communications\
    \ (ICC), Paris, France, 21–25 May 2017; pp. 1–6. [CrossRef]\n19.\nCodeluppi, G.;\
    \ Cilfone, A.; Davoli, L.; Ferrari, G. LoraFarM: A LoRaWAN-based smart farming\
    \ modular IoT architecture. Sensors\n2020, 20, 2028. [CrossRef]\n20.\nRoukh, A.;\
    \ Fote, F.N.; Mahmoudi, S.A.; Mahmoudi, S. WALLeSMART: Cloud Platform for Smart\
    \ Farming. In Proceedings of the\nSSDBM 2020: 32nd International Conference on\
    \ Scientiﬁc and Statistical Database Management, Vienna, Austria, 7–9 July 2020;\n\
    pp. 1–4. [CrossRef]\n21.\nStevens, J.D.; Shaikh, T. MicroCEA: Developing a Personal\
    \ Urban Smart Farming Device. In Proceedings of the 2nd International\nConference\
    \ on Smart Grid and Smart Cities, ICSGSC 2018, Kuala Lumpur, Malaysia, 12–14 August\
    \ 2018; pp. 49–56. [CrossRef]\n22.\nShinyProxy v2.3.0. Available online: https://shinyproxy.io/\
    \ (accessed on 21 April 2021).\n23.\nNode.js v8.16.1. Available online: https://nodejs.org/es/\
    \ (accessed on 21 April 2021).\n24.\nMongoDB v4.0.14. Available online: https://www.mongodb.com/\
    \ (accessed on 21 April 2021).\n25.\nOpenLDAP v1.2.5. Available online: https://www.openldap.org/\
    \ (accessed on 21 April 2021).\n26.\nDocker v19.03.8. Available online: https://www.docker.com/\
    \ (accessed on 21 April 2021).\n27.\nStormy. Available online: https://stormy.udl.cat/\
    \ (accessed on 21 April 2021).\n28.\nMateo-Fornes, J.; Solsona-Tehas, F.; Vilaplana-Mayoral,\
    \ J.; Teixido-Torrelles, I.; Rius-Torrento, J. CART, a Decision SLA Model for\n\
    SaaS Providers to Keep QoS Regarding Availability and Performance. IEEE Access\
    \ 2019, 7, 38195–38204. [CrossRef]\n29.\nMateo, J.; Pla, L.M.; Solsona, F.; Pagès,\
    \ A. A production planning model considering uncertain demand using two-stage\
    \ stochastic\nprogramming in a fresh vegetable supply chain context. SpringerPlus\
    \ 2016, 5, 1–16. [CrossRef] [PubMed]\n30.\nNadal-Roig, E.; Pagès-Bernaus, A.;\
    \ Plà-Aragonès, L.M. Bi-objective optimization model based on proﬁt and CO2 emissions\
    \ for\npig deliveries to the abattoir. Sustainability 2018, 10, 1782. [CrossRef]\n\
    31.\nDominiak, K.N.; Hindsborg, J.; Pedersen, L.J.; Kristensen, A.R. Spatial modeling\
    \ of pigs’ drinking patterns as an alarm reducing\nmethod II. Application of a\
    \ multivariate dynamic linear model. Comput. Electron. Agric. 2019, 161, 92–103.\
    \ [CrossRef]\n32.\nRiekert, M.; Opderbeck, S.; Wild, A.; Gallmann, E. Model selection\
    \ for 24/7 pig position and posture detection by 2D camera\nimaging and deep learning.\
    \ Comput. Electron. Agric. 2021, 187, 106213. [CrossRef]\n33.\nFood and of the\
    \ United Nations (FAO). Meat Production by Livestock Type. 2020. Available online:\
    \ http://www.fao.org/faostat/\nen/?#data/ (accessed on 23 July 2021).\n34.\nAHDB.\
    \ Cost of Production in Selected Countries (InterPIG). Available online: https://ahdb.org.uk/cost-of-production-in-selected-\n\
    countries (accessed on 23 July 2021).\n35.\nNedap—ProSense. Available online:\
    \ https://www.nedap-livestockmanagement.com/pigfarming/ (accessed on 21 August\
    \ 2021).\n36.\nRaba, D.; Estrada-Moreno, A.; Panadero, J.; Juan, A.A. A reactive\
    \ simheuristic using online data for a real-life inventory routing\nproblem with\
    \ stochastic demands. Int. Trans. Oper. Res. 2020, 27, 2785–2816. [CrossRef]\n\
    Sensors 2021, 21, 5949\n21 of 21\n37.\nExafan—Weighting Silo. Available online:\
    \ https://exafan.com/en/farm-equipment/exafans-equipment/fodder-storage/silo-\n\
    weighing-systems/ (accessed on 21 August 2021).\n38.\nMCSystems. Available online:\
    \ https://mcsystems.es/en/ (accessed on 28 July 2021).\n39.\nSigfox. Available\
    \ online: https://www.sigfox.com/en/what-sigfox/technology (accessed on 21 August\
    \ 2021).\n40.\nBinMaster. Available online: https://www.binmaster.com/ (accessed\
    \ on 21 August 2021).\n41.\nSchauer. Available online: https://en.schauer-agrotronic.com/pig/pig-feeding-systems\
    \ (accessed on 21 August 2021).\n42.\nSilows. Available online: https://www.cticontrol.com/en/market-pigs/pigs-fattening/pigs-fattening-weighing/\
    \ (accessed on\n21 August 2021).\n43.\nSchinckel, A.; Einstein, M.; Jungst, S.;\
    \ Booher, C.; Newman, S. Evaluation of Different Mixed Model Nonlinear Functions\
    \ to\nDescribe the Feed Intakes of Pigs of Different Sire and Dam Lines1. Prof.\
    \ Anim. Sci. 2009, 25, 345–359. [CrossRef]\n44.\nTjørve, K.M.; Tjørve, E. The\
    \ use of Gompertz models in growth analyses, and new Gompertz-model approach:\
    \ An addition to\nthe Uniﬁed-Richards family. PLoS ONE 2017, 12, 1–17. [CrossRef]\
    \ [PubMed]\n"
  inline_citation: '>'
  journal: Sensors (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/1424-8220/21/17/5949/pdf?version=1630918317
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: An Internet of Things Platform Based on Microservices and Cloud Paradigms
    for Livestock
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1007/978-1-0716-2205-6_21
  analysis: '>'
  authors:
  - Jérôme Bartholomé
  - Parthiban Thathapalli Prakash
  - Joshua N. Cobb
  citation_count: 11
  full_citation: '>'
  full_text: '>

    Your privacy, your choice We use essential cookies to make sure the site can function.
    We also use optional cookies for advertising, personalisation of content, usage
    analysis, and social media. By accepting optional cookies, you consent to the
    processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Home Genomic Prediction of Complex
    Traits Protocol Genomic Prediction: Progress and Perspectives for Rice Improvement
    Protocol Open Access First Online: 22 April 2022 pp 569–617 Cite this protocol
    You have full access to this open access protocol Download protocol PDF Download
    protocol EPUB Genomic Prediction of Complex Traits Jérôme Bartholomé, Parthiban
    Thathapalli Prakash & Joshua N. Cobb  Part of the book series: Methods in Molecular
    Biology ((MIMB,volume 2467)) 5432 Accesses 7 Citations 8 Altmetric Abstract Genomic
    prediction can be a powerful tool to achieve greater rates of genetic gain for
    quantitative traits if thoroughly integrated into a breeding strategy. In rice
    as in other crops, the interest in genomic prediction is very strong with a number
    of studies addressing multiple aspects of its use, ranging from the more conceptual
    to the more practical. In this chapter, we review the literature on rice (Oryza
    sativa) and summarize important considerations for the integration of genomic
    prediction in breeding programs. The irrigated breeding program at the International
    Rice Research Institute is used as a concrete example on which we provide data
    and R scripts to reproduce the analysis but also to highlight practical challenges
    regarding the use of predictions. The adage “To someone with a hammer, everything
    looks like a nail” describes a common psychological pitfall that sometimes plagues
    the integration and application of new technologies to a discipline. We have designed
    this chapter to help rice breeders avoid that pitfall and appreciate the benefits
    and limitations of applying genomic prediction, as it is not always the best approach
    nor the first step to increasing the rate of genetic gain in every context. Key
    words Rice Breeding program Genomic prediction Genomic selection Oryza sativa
    You have full access to this open access chapter,  Download protocol PDF Similar
    content being viewed by others Genomic Selection in Rice Breeding Chapter © 2018
    Genome-wide prediction models that incorporate de novo GWAS are a powerful new
    tool for tropical rice improvement Article Open access 10 February 2016 Understanding
    the genomic selection for crop improvement: current progress and future prospects
    Article 10 May 2023 1 Introduction The objective of every plant breeding program
    is to provide improved varieties that meet the needs of key stakeholders (value
    chain participants from farmers up to consumers). A clear understanding of the
    biology and the genetics of the species combined with a targeted product concept
    is a key element to achieve this objective [1]. However, the genetic landscape
    that a breeder needs to explore to identify superior products is very large and
    materially exceeds the capacity of breeding programs [2]. Indeed, plant breeding
    can be considered as a numbers game where breeding schemes are designed to increase
    the probability of finding genotypes with desirable combinations of characteristics
    using a limited amount of resources [3]. The breeding scheme is the conceptual
    framework that captures all the activities that a breeder does during a breeding
    cycle. A single breeding cycle can be summarized in four major parts: creation,
    evaluation, selection, and recombination [4] and is designed to create new variation,
    accurately assess the performance of the breeding germplasm, and to recombine
    selected individuals to form an improved cohort. Evaluation is a central part
    of a breeding scheme which involves multiple phenotyping steps designed to estimate
    the heritable genetic value (or breeding value) of the selection candidates [5].
    In the case of yield, usually a set of genotypes preselected for highly heritable
    traits are evaluated in multi-environment trials (MET) intended to represent the
    target population of environments (TPE) in which the product is expected to perform
    [6, 7]. These final steps of the evaluation process require significant resources
    and span over multiple years in a majority of plant breeding programs [3]. To
    overcome this limitation and increase the efficiency of breeding programs, several
    methodologies and tools have emerged over the last three decades due in large
    part to improvements in the characterization of DNA polymorphisms and computing
    power [8]. Among them, methods that use molecular information to infer phenotypic
    performance (such as marker-assisted selection [9, 10] and genomic selection [11])
    are important tools that allow modern breeding programs to maximize the use of
    their limited resources. Contrary to classical marker-assisted selection, genomic
    prediction accounts for quantitative trait loci of both large and small effect,
    thus capturing a higher proportion of the genetic variance of a trait [12, 13].
    The concept of genomic selection was first proposed by Meuwissen et al. [11] for
    animal breeding. In this simulation study, the authors predicted the genetic value
    based on molecular markers of juveniles without phenotypic records using the animals
    of the two previous generations to estimate the marker effects. They obtained
    high accuracies for the predicted breeding values (genomic estimated breeding
    values—GEBV) and concluded that this approach to increase the rate of genetic
    gain has potential when coupled with techniques to reduce generation intervals.
    Genomic selection commonly refers to the process where selection candidates, which
    are only genotyped, are selected based on their GEBV (genomic predictions). To
    achieve this, marker-phenotype relationship is first modeled using a training
    set (a smaller representative set of individuals that reflects as closely as possible
    the genetics of the individuals intended for prediction) on which phenotypic and
    genome-wide marker data are both generated [12, 14]. To evaluate the performance
    of the models, most of the time, the correlation between the predicted and observed
    values is calculated using a validation population whose composition depends on
    the validation strategy [15]. This metric is usually referred to as accuracy or
    predictive ability depending on which observed values predictions are compared
    to: breeding values or phenotypic performances, respectively. The accelerated
    development of mid- and high-density genotyping technology during the 2010s led
    to the first report of the practical use of genomic prediction in dairy cattle
    [16] followed by important contributions by breeders working in agriculturally
    important plant species [17, 18]. Indeed, genomic prediction is now an intense
    field of research seeking to optimize its use and integration into both plant
    and animal breeding programs globally. Important advancements have been made regarding
    our understanding of the major factors affecting the accuracy of the GEBVs including
    the effective population size of the breeding program, the heritability and genetic
    architecture of the target traits, the size and the composition of the training
    population, as well as the number, distribution, and informativeness of the markers
    [19]. Genomic prediction models and their implementation in software tools have
    also received special attention in order to efficiently leverage all information
    contained not only in genomic and phenotypic datasets, but also in other sources
    of “omics” data [20]. While the drivers of prediction accuracy are increasingly
    well understood, the question of how genomic prediction best integrates into an
    existing plant breeding strategy remains a challenge since breeding programs operate
    in a wide variety of contexts (target traits, species, resources, scale, etc.).
    Rice (Oryza sativa ) is a model species for molecular biology [21] and a staple
    food for a large part of humanity. Important gains in productivity were obtained
    thanks to the breeding efforts during and immediately following the green revolution
    [22, 23]. These improvements were realized mostly through phenotypic selection
    in large segregating pedigree nurseries [22, 24, 25]. The use of molecular markers
    was also key for the introgression of major alleles conferring resistance to biotic
    [26] or abiotic stress [27, 28]. The success of this strategy depended heavily
    on the high heritability and simple genetic architectures of the traits under
    selection (plant height, maturity, disease resistance, grain type) and the very
    large and well-characterized genetic diversity of O. sativa [29, 30] and closely
    related species such as O. glaberrima (African rice), O. rufipogon, or O. nivara
    [31, 32]. This may explain why the interest for implementing genomic prediction
    in the global rice breeding community has been delayed relative to animal breeding
    or breeding traditionally cross-pollinated crops like corn. During this time,
    it bears mentioning that some key advancements were made through population improvement
    via a recurrent selection strategy in Latin America [25, 33]. However, more recently,
    the acceleration in genetic gain for yield in other species, the decreasing costs
    of genotyping, and the growing importance of sustainability in rice production
    have contributed to an increased interest in deploying genomic prediction in rice
    breeding. In this chapter, we first give an overview of the research on genomic
    prediction in rice with a focus on studies that make use of the strategy in a
    breeding program. Then we highlight important considerations for the integration
    of genomic prediction into a rice breeding scheme. In this second part, aspects
    such as identifying the entry points for genomic selection in a breeding scheme,
    the effective design of training populations, strategies to reduce the generation
    interval, and the importance of data management systems are presented. In the
    third part, we take the International Rice Research Institute (IRRI) breeding
    program for irrigated systems as an example for the integration of genomic prediction
    into a product development program and provide the associated data and R scripts
    to run and interpret the analysis (available in Data 1, 2, and 3). In the last
    part, we present interesting progress in genomic prediction that can further help
    rice breeding programs to increase their efficiency. Our objective for this chapter
    is to provide rice breeders with a solid foundation for understanding the advantages
    and limitations of using genomic prediction in their breeding strategy to maximize
    the rate of genetic gain for relevant traits. Due to the heavy presence of inbred
    rice in Asia, we chose to focus the scope of this chapter to inbred Asian rice
    (O. sativa) though the specificities of applying genomic prediction to hybrid
    rice are addressed to a lesser extent. For another viewpoint on the importance
    of genomic prediction for rice breeding, we refer the reader to the book chapters
    from Spindel and Iwata [34] and Ahmadi et al. [35]. 2 Genomic Prediction Works
    in Rice The literature on genomic prediction for crop species is very rich. With
    over 50 studies published since 2014 (Table 1 [36, 38, 40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91]),
    genomic prediction in rice is not an exception. We report on most of the studies
    published in rice (either exclusively or in concert with other species) in order
    to highlight the volume and diversity of the work conducted to date and their
    relevance for improving breeding strategies. To achieve the latter, we intentionally
    emphasize studies focused on integration with breeding programs, which tend to
    report the more practical challenges of the implementation. Table 1 Studies on
    genomic prediction in rice. When multiple data sets were used in a study, the
    information is reported only for the rice dataset Full size table 2.1 General
    Overview The first studies reporting the use of genomic prediction on rice were
    published in 2014 (Table 1). Despite the wealth of genomic and marker resources
    available in rice, these studies came, surprisingly, 5 years after the first studies
    on genomic prediction (using real data) that were published in maize [92], wheat
    [93], or barley [94]. The breadth of genomic resources available to rice and the
    depth of genetic diversity that has been characterized so far have led to the
    discovery of many major QTL with reasonable effect sizes. While a unique and valuable
    resource for the rice breeding community, the heavy focus on discovery, characterization,
    and introgression of large-effect QTL from exotic germplasm may have served to
    delay the transition toward genomic prediction [95]. The type of populations evaluated
    in these early genomic prediction studies in rice tends to reinforce that impression
    (Fig. 1a). Indeed, among the first three studies published in 2014, two were based
    on the same diversity panel [37] and one on hybrids derived from a mapping population
    (an immortalized F2 [39]). Overall, diversity panels which were, in many cases,
    designed for association studies [37] represented a large proportion of the studies
    published so far (Fig. 1a). For most of these studies, the objective was methodological:
    understanding the impacts of population structure, integration of prior knowledge
    on trait genetic architecture, training set optimization , model comparison or
    integration of crop models without direct implication in a breeding program. Given
    the extent of ancestral subpopulation structure in rice, the use of diversity
    panels to assess genomic prediction models is likely to induce bias in the estimation
    of the predictive ability. Indeed if the population structure is not taken into
    account, most of the predictive ability can arise from the ability to predict
    between subpopulations and not within subpopulations [36]. Apart from studies
    based on diversity panels, 16 studies used breeding lines, nine studies focused
    on hybrids, six used a mapping population, four studies were based on synthetic
    populations, and three used cultivars (Fig. 1a). Fig. 1 Summary of the literature
    on genomic prediction of rice. It represents the information detailed in Table
    1. (a) Treemap of the types of populations used to train genomic prediction models
    and the associated references for studies which were based on already published
    datasets. (b) Histograms of the important characteristics of the datasets: the
    size of the population, the number of phenotypic traits, the number of environments
    in which the traits were measured (year, season, or location), and the number
    of molecular markers used for genomic predictions. (c) Circle diagram of the ten
    most used prediction models over the 54 studies. (d) Circle diagram of the validation
    strategy used to assess the accuracy of prediction models : cross-validation (CV),
    HAT method, interset validation, and progeny validation Full size image In addition
    to the wide variety of populations encountered in these studies, the size of the
    population, the number of markers, the number of phenotypes, or the number of
    environments used to characterize the populations was highly variable (Fig. 1b).
    The largest population size (2265) was achieved using publicly available data
    from the 3000 rice genome project [87]. Given the limitations and difficulties
    surrounding the collection of high-quality phenotype data, understandably most
    studies employed population sizes around 300 (Table 1). In cases where large populations
    of 1000 or 2000 individuals were used, the phenotyping was done in a very limited
    number of environments (usually 1 or 2). In fact, less than half of the studies
    used more than three environments for phenotypic evaluations (Fig. 1b). Among
    the three studies having phenotypic information in 10 or more environments (year,
    season, or location), two are based on germplasm from breeding programs [51, 66]
    but the datasets were unbalanced (not all individuals phenotyped in all environments
    or genotyped). The third study from Jarquin et al. [88] used the information from
    51 environments in combination with days length to predict days to heading for
    untested genotypes. Among the wide variety of traits considered, flowering time
    (or maturity), plant height, and grain yield were the most common. The number
    of markers ranged from 162 [50] to four million [89], with the majority of the
    studies using a few thousand markers (Table 1). Genotyping by sequencing and fixed
    SNP (single nucleotide polymorphism) arrays were the most commonly used technologies.
    In some cases, very high marker densities were obtained through whole-genome re-sequencing
    at generally low coverage (1× or 2×) followed by imputation [75, 87]. Statistical
    methods for genomic prediction have been a central focus of many studies across
    all species where it has been applied. Across the 54 rice studies, 33 different
    methods were evaluated with the genomic best linear unbiased prediction (GBLUP)
    method being the most used (Fig. 1c). Since this method was proposed [96], its
    flexibility and robustness have enabled it to quickly become a reference method
    for both animal and plant breeding. Similar to the traditional pedigree BLUP [97],
    GBLUP uses an additive relationship matrix that is based on markers instead of
    pedigree information. Several extensions or variations of this additive model
    have been proposed to account for dominance and/or epistasis [38, 55] or to use
    other “omics” data (transcriptome or metabolome) to estimate relatedness among
    individuals [82, 91]. In addition to GBLUP , RKHS (reproducing kernel Hilbert
    space), frequentist and Bayesian LASSO (least absolute shrinkage and selection
    operator), RR-BLUP (ridge regression BLUP), RF (random forest), SVM (support vector
    machine), PLSR (partial least squares regression), BayesB, and BayesC were the
    most used methods in these studies on rice (Fig. 1c). Other methods from the large
    family of machine learning approaches, such as gradient boosting machine (GBM)
    or artificial neural network (ANN), were also evaluated in the context of genomic
    prediction with mixed results [70, 87]. The composition of the validation set,
    which can play an important role in determining the accuracy of predictions, was
    highly dependent on the validation strategy used in each study (Table 1). Sallam
    et al. [15] defined three main types of validation methods: cross-validation (subset
    validation), interset validation, and progeny validation depending on the composition
    of the training and validation sets. The cross-validation or subset validation
    (k-fold, leave-one-out, random, or stratified sampling) was by far the most used
    strategy among all of the studies that we have compiled (Fig. 1d). This validation
    method is very convenient because you just need to partition your data into training
    and validation sets to be able to estimate accuracies without an “independent”
    dataset (as is needed for interset or progeny validation). Due to its nature,
    cross-validation tends to overestimate the accuracy of prediction compared to
    more realistic validation scenarios [59, 98]. The situation becomes even more
    complex when multivariate models are used [99]. Another approach close to cross-validation,
    the HAT method [57, 100], was used in four studies. This method, based on the
    hat matrix of the random effects, uses the predicted residual sum of squares to
    estimate accuracy of prediction and works in the context of GBLUP , RKHS, and
    Bayesian models. This method is considerably faster than cross-validation as no
    additional model retraining is necessary [100]. The interset and the progeny validation
    methods were only used in three studies each (Fig. 1d). Considering the context
    of breeding programs where the integration of genomic prediction is primarily
    targeted to reduce cycle time, progeny validation represents a more meaningful
    assessment of the performance of prediction models. Indeed, in the initial concept
    of genomic selection, Meuwissen et al. [11] used progeny validation: models were
    built with data from generations 1001 and 1002 and the accuracies were calculated
    using the predicted values and the true breeding values from the generation 1003.
    Moreover, the decay of linkage disequilibrium occurring between markers and QTL
    due to the recombination in progeny generations tends to decrease the accuracy
    of predictions [101], but makes them more realistically interpretable in terms
    of applications to practical breeding scenarios. For example, Ben Hassen et al.
    [59] used progeny validation of inbred lines with a limited number of individuals
    and found lower predictive ability compared to cross-validation for the same traits.
    2.2 Important Findings and Current Limitations for Genomic Prediction in Rice
    2.2.1 Important Findings Table 1 provides a short summary of the main objective
    of each study in this review. The reader can thus be directed toward the publications
    that are most relevant to his or her questions. Hereafter, we summarize important
    results focusing mainly on those most related to the implementation in breeding
    programs. 1. Genomic prediction works in different contexts. The most important
    results that arise from all studies is that the prediction of the performances
    based on molecular markers works. Indeed, the accuracy of GEBVs are relatively
    high even for traits like grain yield. Many rice breeders are concerned by the
    efficiency of genomic prediction but it is clearly not justified looking at the
    literature on rice and more specifically studies using breeding germplasm [43,
    47, 55, 56, 59, 64]. 2. Prediction accuracy can be increased. The breeders can
    play on different factors to increase the accuracy of predictions or to reduce
    the cost of implementation. Indeed, by optimizing the training set composition
    and evaluation, by targeting informative molecular markers (polymorphic with a
    medium to high minor allele frequency and spread along the genome), or by integrating
    additional data (historical, environmental covariates, crop model, …) better accuracies
    can be obtained. The size and the composition of the training set defines the
    strength of genetic relationship with the selection candidates which is one of
    the most important factors driving the accuracy. Therefore, algorithms have been
    developed to select the training set [41, 44, 48, 75, 80]. Concerning molecular
    markers, different studies show that marker density can, to some extent, be reduced
    without affecting the prediction accuracy. For example, Arbelaez et al. [69] designed
    a cost-effective SNP assay with only 1000 markers selected to be informative in
    elite breeding material and obtained good accuracies. 3. Models can predict offspring
    performance. The initial concept of genomic selection was based on the prediction
    of breeding values of offspring with the objective to decrease the duration of
    breeding cycles [11]. The very few studies on rice that performed progeny validation
    [58, 59, 91] show promising results when parental information is used to predict
    progeny performances. However, more remains to be done in that direction since
    most of the increase in genetic gain related to the integration of genomic prediction
    is related to the reduction of breeding cycle time. 4. Genomic prediction is efficient
    in the context of hybrids: Much of the lessons learned regarding marker densities,
    training set identification, and model selection apply equally to hybrid and inbred
    breeding schemes. Hybrid programs do present unique challenges where predictions
    could be applied that are not applicable to other breeding schemes. Of note is
    the prediction of how males and females might be combined to create superior hybrid
    combinations. In hybrid rice there is some evidence that hybrid performance is
    driven by a convergence of additive genetics from the male and female lines. Incorporating
    nonadditive parameters into the prediction does not seem to help [38]. While this
    seems reasonable, other crops have shown a significant nonadditive component to
    hybrid performance (e.g., in corn [102, 103]). This particular conclusion was
    likely biased by a very narrow genetic base and very low accuracy for interset
    prediction of grain yield. There is also evidence that multi-trait models can
    improve prediction accuracy for low heritability traits in hybrid rice [56, 83].
    This is of particular importance in the hybrid context as many traits (especially
    cost of goods traits like hybrid seed production yield) are particularly difficult
    to measure early in a breeding program. A particularly unique set of correlated
    phenotypes associated with hybrid programs is the opportunity to measure per se
    performance of the inbred parents as well as hybrid performance of the same material.
    Using parental phenotype data combined with data on hybrid performance can improve
    the prediction accuracy of hybrid rice yield by about 13% [91]. 5. Modeling GxE
    increases prediction accuracy . Whether it is through multi-environment genomic
    prediction models [58, 64] or by combining crop growth models and genomic prediction
    models [50, 88], several studies demonstrated the better accuracy of these approaches
    to predict environment-specific performances. A key advantage of genomic selection
    over traditional phenotypic selection in the case of multi-environment models
    is the ability of models to assess marker effects and marker effects by environment
    interactions and ultimately increase the prediction accuracy [18, 104]. With the
    integration of crop growth models in the genomic prediction framework, the response
    of the genotype to the environmental variations is modeled which allows the prediction
    of the performance of selection candidates for untested environments [105]. This
    approach is very promising for rice improvement because it takes better account
    of GxE. However, the routine use of crop growth models in breeding programs requires
    a substantial investment in terms of data acquisition and analysis and thus will
    be interesting for specific rice systems prone to environmental constraints. 6.
    Differences between genomic prediction models are marginal. Most of the studies
    comparing statistical models for genomic prediction found small or no differences
    between them in terms of accuracy [20]. In general, none of the models is consistently
    better for all the traits or validation methods. GBLUP is usually used as a reference
    due to its simplicity, versatility to include different types of information,
    and robustness to different trait architecture. Bayesian models (such as B-LASSO,
    BayesB or BayesC) or RKHS can perform better when dealing with traits influenced
    by large-effect genes (such as flowering time or blast resistance). The few studies
    that used machine learning methods (such as ANN or SVM) reported disappointing
    results with very variable performances even with an optimization of the parameters
    [70, 87]. Further work in this direction is probably needed to conclude on the
    interest of these methods for routine genomic prediction. 2.2.2 Current Limitations
    In spite of the number and diversity of studies, there are still some points that
    are not well covered in the literature on rice. Depending on the context, they
    can be limiting for harnessing the full potential of genomic selection. 1. Accuracy
    alone is not enough to assess the effectiveness of genomic prediction . Almost
    all the studies based their evaluation of genomic selection on the accuracy of
    the predictions. Although accuracy is an important factor to assess prediction
    model efficiency, it does not inform on which individuals are selected in fine
    by the different methods. The realized selection differential would probably be
    a better metric to compare different genomic prediction approaches as breeders
    jointly consider several traits to advance material, which makes the evaluation
    on traits separately less relevant. Finally, as rightly pointed out by Bassi et
    al. [106], the phenotype is also only a predictor of the true breeding value and
    has an error variance just like a GEBV. 2. Within-family prediction accuracy is
    not sufficiently taken into account. No study on rice has looked in detail into
    within-family prediction accuracy using multiple biparental families or parental
    information as the training set. Indeed, except for the specific case of studies
    using one biparental family, reports on within-family accuracy are scarce. This
    is manifest as well in the hybrid literature where most papers focus on predicting
    specific hybrid combinations and do not attempt to estimate general combining
    ability among a cohort of new males or females. This is however a key point when
    it comes to the implementation of genomic prediction since greater within-family
    accuracy can help to increase the rate of genetic gain while balancing the level
    of inbreeding in the population. Differences between crosses are better predicted
    as both within and between family variations are captured by the model [107, 108].
    3. Grain quality or disease resistance traits were neglected. No study related
    to the nutritional value of the polished grain (zinc content, glycemic index,
    …) was published to date. Only one study assessed the potential of genomic prediction
    to help decrease the level of arsenic in the grain using breeding [74]. Regarding
    disease resistance, the only study from Huang et al. [77] reported accuracies
    ranging from 0.15 to 0.72 for the prediction of resistance to several isolates
    of Magnaporthe oryzae (blast). For disease resistance, rice geneticists focus
    mainly on major genes, but targeting quantitative variation is also important
    to address concerns like bypassing resistances. For grain nutritional value, negative
    correlations between traits can be better addressed using multi-trait genomic
    prediction. 4. Implementation in breeding programs is secondary. While it is clear
    that the underlying goal of all studies is to improve our knowledge of genomic
    prediction to optimize breeding strategies, few of them place their findings in
    a concrete case of a breeding program. For example, Spindel et al. [47] proposed
    to integrate genomic prediction into an irrigated rice breeding pipeline and discussed
    the advantages and constraints of such a scheme. However, for most of the studies
    working on breeding germplasm (see Table 1) this is not the case. The results
    therefore remain more theoretical than practical, as such analyses are important
    to justify investments in genomic selection and to understand potential barriers
    to its implementation. 3 Integration of Genomic Prediction into Rice Breeding
    Programs: Key Aspects Entry points for genomic selection in a rice breeding program
    will vary depending on the objectives of the program, the breeding strategy in
    place, the genetic and/or environmental constraints the breeder has to account
    for, and the cost of genotyping and of phenotyping the traits under selection.
    However, there are key prerequisites to assess before integrating a breeding program’s
    readiness to implement genomic prediction. In the absence of essential components
    such as (a) clear objectives, (b) meticulous data management, (c) effective operations,
    (d) effective phenotyping and (e) selection based on BLUP, the application of
    genomic predictions is extremely limited [4]. Executing genomic prediction using
    breeding data or specially designed training sets is useful for establishing baseline
    capacity to do prediction, but integrating the technology into an existing breeding
    program can be a challenge. Breeding programs represent multi-year pipelines that
    manage overlapping cohorts of germplasm, so changing the strategy often is done
    stepwise so as not to disrupt the product development process. The purpose of
    this section is to provide guidelines regarding important elements to consider
    before implementing a genomic selection strategy in a rice breeding program. 3.1
    Map the Breeding Strategy The main value of genomic prediction lies in its use
    in decision making to efficiently select breeding material at one or several stages
    of the breeding scheme. Therefore, a clear understanding of the breeding strategy
    and its different components is the basis for an efficient integration of genomic
    prediction. Oftentimes, the breeding scheme resides in the head of the breeder,
    and translating this knowledge into a structured framework is a mandatory step
    to carefully design alternative schemes [109]. Genomic prediction is a long-term
    investment for the breeding program and the direct transition to an optimal genomic
    selection strategy is not always possible. Therefore, a transition plan needs
    to be elaborated by the breeding team and experts in order to define clear steps
    to achieve the objectives. This aspect is usually not reported in the literature
    on genomic prediction as it comes down to more technical information regarding
    the breeding scheme. In rice, only one study placed the results in the framework
    of a breeding program and detailed the use of genomic prediction and its potential
    impacts [47]. However, as shown in wheat, this step of breeding scheme characterization
    is essential for the integration or the optimization of genomic selection based
    on the knowledge acquired during the last years [106, 110]. Optimal genomic selection
    schemes are usually not simple evolutions of the current breeding scheme. The
    majority of conventional breeding schemes in rice, and self-pollinated crops in
    general, rely on pedigree breeding [25] but genomic selection is best suited to
    recurrent selection schemes based on elite by elite crosses to improve complex
    traits. Indeed, a well-structured breeding program where the elite germplasm has
    been clearly identified and with a small effective population size (Ne ≈ 40) is
    more likely to benefit from the use of genomic prediction due to higher linkage
    disequilibrium between markers and QTL, low or absence of population structure,
    and higher relatedness among genotypes. In addition, several major changes are
    needed to fully leverage genomic predictions: reduce cycle time, build a training
    set, store/use phenotypic and genotypic data, reallocate budget and staff [106,
    111]. Understanding the interconnections between these changes and how they will
    impact the sequence of current operations allow to anticipate potential obstacles.
    Key recommendations: 1. Define clearly the current breeding strategy and its objectives.
    2. Plan the integration of genomic prediction as a long-term investment with a
    clear roadmap. 3. Use recurrent selection in elite population to maximize the
    potential of genomic prediction. 3.2 Reduce the Cycle Time An interesting aspect
    of genomic selection is that it has led to a greater focus on the fundamentals
    of breeding in the plant breeding community [112]. The concept of response to
    selection captured in the Breeder’s equation is perhaps the best example [4, 109].
    Among the parameters of the equation, the generation interval (or cycle time)
    is the easiest to understand and to play with. As highlighted by Meuwissen et
    al. [11] in their seminal paper, the use of genomic predictions can greatly increase
    the rate of genetic gain by reducing cycle time: “It was concluded that selection
    on genetic values predicted from markers could substantially increase the rate
    of genetic gain in animals and plants, especially if combined with reproductive
    techniques to shorten the generation interval.” This conclusion was confirmed
    15 years later by the first report of the impact of genomic selection on the rate
    of genetic gain in dairy cattle [113]. The authors found a dramatic reduction
    in the generation interval related to a sharp increase in the rate of genetic
    gain from yield traits (50–100%). In plant breeding, methods to reduce cycle time
    (independently from the use of genomic selection) have been studied for several
    decades now [114, 115] . Rapid generation advance (RGA) or double haploids are
    probably the most common in crop species, even if more modern approaches have
    been proposed lately [116, 117]. In rice, RGA has regained interest recently as
    it is a cost-efficient way to quickly fix material (typically from F2 to F6 in
    1 year) for its evaluation in replicated trials [118]. This can be realized in
    greenhouses, screenhouses or in the field depending on the resources available.
    For breeders working on a classical pedigree breeding scheme, the use of RGA could
    be a first step toward the implementation of genomic selection [119]. For breeding
    programs already implementing RGA or similar methods to reduce cycle time, genomic
    selection can further help to shorten the breeding cycle. However, this requires
    a genomic prediction model that can efficiently predict the genetic value of the
    next generation (progeny). Therefore, a training set based on material from one
    or several previous cycles has to be constituted before implementing this type
    of scheme. This is also the case for more aggressive strategies based on recurrent
    selection that aim at recombining non-fixed material (S0) selected based on predicted
    values only. In that type of scheme, the population improvement part is partially
    decoupled from the product development part, which allows a 1-year or even shorter
    breeding cycle [120, 121]. For the moment, only simulation studies have reported
    this type of scheme since several technical challenges have to be solved before
    implementation. Indeed, a drastic reduction of breeding cycle time can lead to
    overlapping activities between different cycles during the transition period that
    may disrupt ongoing cycles or increase substantially the workload. Key recommendations:
    1. Use genomic prediction in conjunction with robust methods to produce inbred
    lines (e.g., rapid generation advance) to effectively reduce cycle time. 2. Take
    into account technical constraint associated with cycle time reduction into the
    genomic prediction roadmap. 3.3 Design the Training Set Once the entry point of
    genomic prediction in the breeding scheme has been defined, the design of the
    training set is the first step toward the implementation of genomic selection.
    Three major choices have to be made regarding the training set: its composition
    and size, its phenotyping, and its genotyping. The breeder must find a balance
    between these three aspects in order to optimize the training set according to
    available resources. A simple way for most breeding programs to get started is
    to begin genotyping every line that enters the yield trial. From there, those
    datasets can be empirically optimized to increase prediction accuracy. It is well
    known that the accuracy increases with the size of the training set. Theoretical
    [122,123,124] and empirical studies [67, 125, 126] suggest that the training set
    size should be maximized when dealing with complex traits. However, large training
    sets are not always feasible mainly due to genotyping and phenotyping costs. Several
    methods were developed to optimize the training set composition in order to achieve
    high accuracies while maintaining the size to a manageable number [41, 44, 48,
    71, 75, 80, 127,128,129]. All of these methods use the additive genetic relationships
    (usually based on marker data) to optimally sample a set of representative genotypes.
    A key aspect of the optimization of the training set is the definition of the
    predicted set (selection candidates). Indeed, close genetic relationships between
    the training set and the selection candidates are key to maximize prediction accuracy
    [130, 131]. Therefore, most of the optimization methods are jointly considering
    the genotypes that will compose the training and the predicted sets to either
    directly compute criteria based on relatedness (the average of the relationship
    coefficients between the training set and the predicted set [128, 132]) or to
    estimate criteria based on mixed model theory (the prediction error variance,
    the coefficient of determination, or the expected accuracy [41, 80, 127]). In
    the cases where the training and the predicted sets come from the same population
    (e.g., selection candidates from the same cohort) or the information on the predicted
    individuals is not yet available (e.g., offspring), optimization methods have
    been developed to minimize the genetic relationships between individuals of the
    training set [48, 75]. Depending on the availability of data and the prediction
    objectives, the breeder can choose among these optimization methods to shape the
    training set and update it when selection candidates from a new cycle need to
    be predicted. The optimization of the composition of the training set has to be
    done in conjunction with the phenotyping strategy. In most cases, the selection
    candidates that will be used to update the prediction model are evaluated for
    key traits in MET to estimate G × E. Since the total number of plots available
    for the evaluation is almost fixed, the breeder needs to balance the population
    size with the level of replication (within and across environments). Classically,
    the level of replication increases during the breeding cycle to dedicate more
    resources to a smaller number of more promising lines in the final stages. In
    the context of genomic selection where the evaluation unit being the alleles instead
    of the individuals, increasing the size of the training set while decreasing the
    level of replication tends to increase the accuracy of prediction [133, 134].
    The typical size of a training population (150–300) to be phenotyped in a classical
    fully replicated experiment can therefore be multiplied by 1.5–3 with sparse testing.
    However, it is advisable to have a sufficient level of replication within and
    across environments to: (1) maintain repeatability, especially for low heritability
    traits, (2) assess the level of G × E, and (3) avoid model convergence issues
    with too few replicates. The limitation of replication using sparse testing approaches
    can also be a good opportunity when the seed availability is a constraint. Finally,
    the technology used to genotype the training and predicted sets needs to be carefully
    considered in order to efficiently capture distinct QTL alleles as well as general
    relatedness in the population. Several factors come into play when choosing or
    developing the appropriate genotyping technology: cost, type of markers, density,
    informativeness in the target population, reproducibility rate, etc. In the case
    of applying genomic prediction, a good characterization of the genetic diversity
    managed by the breeding program is essential to determine the marker density needed
    to achieve an optimal prediction accuracy. It has been shown using both deterministic
    [13, 135] and stochastic [136] simulations that the marker density has to increase
    when the effective population size increases to maintain the accuracy [135,136,137].
    However most empirical studies in rice found that the accuracy reaches a plateau
    when the marker density goes beyond 2–5 markers per centiMorgan for breeding programs
    with an effective population size lower than 50. Key recommendations: 1. Maximize
    the relatedness between the training and the predicted sets where possible. 2.
    Use sparse testing for phenotyping in order to balance the size of the training
    set and the level of available resources. 3. Avoid using a training set from one
    breeding pipeline in order to predict the candidates from another breeding pipeline.
    3.4 Generate and Integrate Good Quality Data As highlighted before, data acquisition
    and management are essential components of a breeding program. All advancement
    decisions are made based on recorded data from multiple sources (field, laboratory,
    service provider, etc.). Careful data management from the seed to the phenotype
    and/or to the genotype has to be in place to ensure accuracy. The use of digital
    data collection tools is a key way to reduce as much as possible errors that can
    be perpetuated during the data collection process. Concerningly, it has been demonstrated
    with simulated data that even a small percentage of severe errors (0.1% or 1%)
    in phenotypic records can severely reduce the response to selection [138]. Similar
    conclusions were also found when errors are present in the pedigree records [139].
    Besides accurate data, robust and appropriately designed analysis pipelines are
    needed to curate the data and turn it into interpretable intelligence. Genomic
    prediction adds an additional layer of complexity compared to traditional marker-assisted
    selection in that it can require the integration of different types of data (phenotypes,
    genotypes, pedigree, and/or weather data) collected over several years to be useful.
    Consistency of data type and format and the stability of data structures over
    time are key aspects to leveraging the full power of historical breeding data
    to train and continuously update genomic prediction models [140]. To help the
    breeders with data management, software solutions such as the Breeding Management
    System (https://bmspro.io), Breeding4Results (B4R) (https://riceinfo.atlassian.net/wiki/spaces/ABOUT/pages/326172737/Breeding4Results+B4R),
    Breedbase (https://breedbase.org), or GOBii Genomic Data Management (https://gobiiproject.atlassian.net/wiki/spaces/GD/overview)
    are available and used in different public organizations. Despite the significant
    efforts to develop analysis pipelines (like the RiceGalaxy, https://galaxy.irri.org,
    [141]) and the Breeding API project (https://brapi.org) designed to enable interoperability
    among plant breeding databases, no efficient end to end solution is publicly available
    to perform genomic prediction in the context of an applied breeding program. Indeed,
    several limitations are present among available software for implementing genomic
    prediction, including a lack of direct linkages between genotypic and phenotypic
    data, limited multi-environment or multi-trait analytical capability, no possibility
    to integrate dominance or epistasis effects into a prediction model, and no meaningful
    integration of weather data into an analytical pipeline. The majority of public
    breeding programs therefore extract the phenotypic and genotypic data from their
    respective data management software and use ad hoc analysis pipelines to run genomic
    prediction models . Hopefully, projects such as the Breeding API or the Enterprise
    Breeding System (https://ebs.excellenceinbreeding.org) will offer these possibilities
    in the near future within a coherent framework designed to enable applied breeding
    programs. Key recommendations: 1. Use digital data collection systems where possible.
    2. Work with data management systems and efficient analysis routines for genomic
    prediction (GBLUP , RR-BLUP). 3. Use consistent genotypic and phenotypic data
    structures over years to facilitate data integration. 3.5 Take into Account the
    Costs The integration of genomic selection in a breeding program is a long-term
    investment that must translate into a better rate of genetic gain to be worth
    implementing. Even if the advantages of using genomic selection are clear, the
    optimal breeding scheme relative to genetic, operational, and cost constraints
    is not easy to identify. After setting a vision for what’s optimal, the need to
    convert to this new strategy in a budget friendly way is probably the most important
    limitation for the strengthening of modern breeding programs. Nevertheless, there
    are several levers that can be used to liberate resources in a program aiming
    to fully deploy genomic selection. The first levers are related to phenotyping.
    Thanks to genomic prediction, some phenotyping steps can be reduced or even eliminated
    saving the related costs de facto. Indeed, this is one of the main advantages
    of genomic prediction which, with the right data structures in place, allows for
    both a reduction of cycle time and phenotyping costs [111]. The costs of phenotyping
    and the potential to replace a phenotyping activity with a prediction should be
    carefully evaluated when planning the integration of genomic prediction as it
    may sometimes require a modification of the breeding scheme. One key example of
    this is the cost savings incurred when transitioning from traditional pedigree
    breeding program where the selection that occurs during the fixation steps (F2–F5)
    can be delayed until after inbred lines have been extracted by substituting a
    field-based pedigree nursery with a much cheaper and faster SSD-based RGA method.
    The cost savings made at this level can easily cover the cost of genotyping since
    advancing material through RGA is much less expensive (around 1 US dollar per
    F5/F6 lines) [119]. Organizations must however look to multi-year budgeting strategies
    to accommodate the fixed costs that may be incurred if existing greenhouse facilities
    cannot be leveraged for this activity. Initial capital investments can often be
    paid for by reduced operational costs over several years. Furthermore, organizations
    must factor in the additional funding that could be generated due to the increase
    in genetic gain that will accompany a shortening of the breeding cycle and an
    improvement in selection accuracy. Another direct way to recover costs is by using
    genomic prediction to reduce the volume of an expensive phenotyping exercise [75,
    142]. This can be done either by selectively phenotyping a carefully chosen subset
    of a trial for expensive traits like grain biochemistry or other post-harvest
    traits and using the cost savings to pay for DNA fingerprinting. Additionally,
    developing an index of high-throughput correlated traits that may be less expensive
    to measure or offer higher throughput compared to the target trait can decrease
    the cost of phenotyping and offer similar accuracy. In that context, multi-trait
    genomic prediction offers an ideal framework to integrate correlated traits to
    maximize prediction accuracy [143]. The second levers are related to genotyping.
    In a crop breeding program, the choice of the genotyping technology to characterize
    the breeding germplasm (training and prediction sets) is mostly driven by the
    cost of genotyping per sample (and not really well captured by the cost per data
    point) [144]. Indeed, the cost per sample with available tools (genotyping-by-sequencing
    or fixed SNP arrays) is often too high to be used routinely in a public breeding
    program. In small to medium size breeding programs, the cost per sample has to
    be around 10 US dollars or less in order to assess a sufficient number of individuals.
    In that price bracket, the number of loci that can be currently targeted is around
    1000–5000 SNPs. One option to keep costs down in the long term is to design a
    custom genotyping assay with SNPs selected to be specifically informative in the
    target breeding population. This would be a cheaper option than GBS or public
    fixed arrays and allow for higher density of information content in the genotype
    dataset. A custom SNP panel has the additional benefit of potentially surveying
    specific trait markers of relevance to a breeding program in addition to the genome-wide
    markers included in the set, thus allowing for more extensive QTL profiling of
    lines for known alleles that are not necessarily prioritized for MAS . In fact,
    depending on the capability of the genotyping service provider, it is not unreasonable
    to save sampling and DNA extraction costs by combining MAS and fingerprinting
    such that the cohort is screened with a few markers intended for MAS , then to
    have the DNA from selected lines re-arrayed into a new plate for genome-wide fingerprinting.
    It is also possible to achieve low genotyping cost by using low-coverage genotyping-by-sequencing
    [145]. Given the limitation of genotyping-by-sequencing when the sequencing depth
    is lowered (high rate of missing data, high error rate for heterozygous loci),
    this approach won’t capture heterozygous loci efficiently and must be used for
    genotyping fixed lines, coupled with an efficient imputation framework based on
    high-quality sequence data of ancestral lines in the pedigree. This therefore
    requires expertise in bioinformatics and access to high-performance computing
    resources. Key recommendations: 1. Consider reducing the number of phenotyping
    steps, only phenotyping a subset of a trial, or using cheaper or higher throughput
    correlated traits. 2. Design a genotyping platform with a set of markers selected
    specifically for the germplasm managed in the breeding program and deploy it at
    a service provider. 4 An Example on IRRI Breeding Program for Irrigated Systems
    Here, we give a practical example of the integration and use of genomic predictions
    in an active rice breeding program. The recently redesigned breeding program for
    irrigated systems at IRRI offers an ideal context to understand the key elements
    of an applied breeding program using genomic predictions [146, 147]. Indeed, with
    its global mandate of Southeast Asia, South Asia, and Eastern Africa as the main
    areas of intervention, it represents the direct derivation of the early breeding
    efforts that resulted in the Green Revolution in Asia. As such, it is the best
    representation possible of an effort to produce materials that combine high yield
    potential and adaptation to diverse environmental conditions. 4.1 The Transition
    from Pedigree Breeding to Recurrent Genomic Selection The applications of genomic
    selection to the IRRI breeding program came in two broad categories: within cohort
    predictions (full and half sibs predicting other full and half sibs) to optimize
    our testing strategy and across cohort predictions (grandmothers and mothers predicting
    daughters and granddaughters) to accelerate our breeding cycles, both of which
    required changes to the breeding strategy. First and foremost, both applications
    required the cost-effective deployment of a genotyping technology that allowed
    for the routine fingerprinting of the breeding material. This marker set (known
    as the 1k-RiCA amplicon panel [69]) had recently been developed and populated
    with markers that were specifically informative in our germplasm. Publicly available
    fixed array genotyping technology would not have served this purpose well as many
    of the markers on these arrays are chosen to differentiate germplasm globally
    [148] and were often very expensive with relatively few (or worse, biased) polymorphisms.
    With the marker panel in place and deployed at a service provider, in the immediate
    term, the most useful application of genomic selection was to allow for selections
    to be made based on performance in the target environments rather than depending
    on a correlated response to selection with Philippine environments (where IRRI’s
    headquarters are located). The program as it is currently resourced generates
    a stage 1 yield trial of approximately 2000 new lines each year. As all of IRRI’s
    yield trials are conducted by national agricultural research partners, the ability
    to test 2000 lines in multilocation yield trials in Africa, South Asia, and Southeast
    Asia was extremely limited. Up to this point, the early generation breeding material
    was selected based on performance in the Philippines and a small number of advanced
    lines were sent to the regional locations for testing and evaluation (Fig. 2).
    Genomic selection using full and half sibs was employed to enable direct selection
    based on the target environment and avoid needing to rely on indirect selection.
    By selecting an optimized subset of the cohort and sending it to be tested in
    the region of interest, phenotype data from the specific region of interest could
    be used to predict the performance of the remaining cohort in that region. In
    this way, the entire cohort is tested somewhere, but no individual is tested everywhere,
    and thus an advancement of superior lines can be sent to partners that is tailored
    to their unique conditions. To do this, however, required that funds be identified
    to fingerprint the full cohort of about 2000 new lines every year. In order to
    make this form of genomic selection cost neutral, it was noted that the testing
    strategy in the Philippines was testing lines for 3 years (Fig. 2, former scheme).
    By eliminating the middle testing phase and selecting a region-specific set of
    lines for advance testing, sufficient funds were recovered to cover the cost of
    fingerprinting. Fig. 2 Former, current, and future breeding schemes at IRRI for
    irrigated systems. The evolution between the schemes is characterized by the integration
    of genomic prediction (GP) and a reduction of the breeding cycle length. The genomic
    prediction is indicated in red with the associated number of individuals being
    phenotyped in the regions to update the model. The color of the steps corresponds
    to the location of the activities: green in the Philippines and yellow in the
    regions with the partners. The years and the seasons (WS: wet season, DS: dry
    season) are indicated on the left side. The numbers on the right indicate the
    population size of each step. The black thick arrows indicate the recycling of
    the best lines as parents. MAS : marker-assisted selection using 10–20 trait markers
    mostly related to disease resistance. INGER: International network for genetic
    evaluation of rice led by IRRI Full size image The genomic prediction application
    with more long-term value to the program was to enable across cohort predictions
    so that superior lines in each region could be recycled back into the breeding
    pipeline prior to regional testing, and thus accelerating the breeding cycle (Fig.
    2, future scheme). This kind of prediction however requires a more robust, multi-year
    dataset consisting of regional phenotype data on ancestral lines, as phenotype
    data from full and half sibs of the emergent candidates would be unavailable at
    the time the prediction needs to be made. With the first application of genomic
    prediction in place, the program is now well positioned to begin generating multi-year
    datasets with region-specific phenotypic observations needed to predict new parents.
    However, to make this kind of prediction possible, a more directed manipulation
    of the crossing strategy needed to be implemented. The most important decision
    a breeder makes is selecting and crossing parents on the basis of breeding values
    for relevant traits. As this metric was not routinely calculated at IRRI, our
    first step was to gather our historical data together into a single model and
    generate the best estimates possible for breeding values and reliabilities for
    yield, maturity, and plant height. Breeding values for other important traits
    such as grain quality, disease resistance, and other agronomic traits were not
    collected routinely enough or at enough locations to provide meaningful estimates
    of breeding value. This process was substantially accelerated due to the efforts
    made to migrate data into the B4R data management system. As DNA fingerprint data
    was not available on the vast majority of our historical lines, pedigree data
    stored in the genealogy management system was used to estimate relatedness coefficients.
    This multi-year evaluation of our historical data permitted the identification
    of a unique core set of lines with high and reliable breeding values for yield,
    which would form the basis of further breeding and germplasm characterization
    efforts. Once identified, this set of high breeding value lines were fingerprinted
    and that data was then used to estimate the effective population size and used
    to estimate the frequencies of major genes for other traits (such as amylose content
    or resistance to blast). These metrics would be used to guide selection strategies
    among the progeny and evaluate the risk/benefit of introducing new genetics into
    the program. This step, while not specifically motivated by genomic selection,
    was critically important because along with the development and characterization
    of the core germplasm came a commitment from the program to primarily cross within
    this new gene pool to drive genetic gain. This relatedness across generations
    (and aversion to frequent introduction of new germplasm into the program) creates
    genetic continuity over multigenerational cohorts that enables the ability to
    use phenotype data from ancestors to predict the performance of newly created
    descendants. Corresponding with that relatedness was the development of business
    rules for crossing and population development. These rules ensure that new crosses
    generated by the breeding program maximized genetic variation in the next generation
    to the extent possible. They also allowed for sufficient numbers of full and half-siblings
    in each cohort to be generated, from which predictive power could be obtained.
    Among these, business rules included a commitment to cross with lines from the
    most recent cohorts whenever possible (rather than older released lines), preventing
    the use of any one line in more than 10% of the crosses to avoid bottleneck the
    variability, the complete avoidance of sub-lining so that each F2 plant generates
    a unique F6 line, and ensuring that sufficient new fixed lines from each cross
    were entered into the stage 1 yield trial such that there was a reasonable probability
    of identifying a new line that was at least one standard deviation better than
    the average yield of the cross. With these two applications of genomic prediction
    underway, the program went from a long-cycle pedigree nursery to a rapid-cycle
    genomics enabled breeding strategy. This strategy involved making crosses and
    setting population size targets according to predefined business rules, generating
    new lines through RGA approaches, employing MAS after line fixation, and using
    bulk harvests of the selected head rows to create seed for shipping to regional
    locations for testing. Predictions of the entire cohort across all regions would
    ensure that every line had either an observation or a prediction in every region,
    from which a core set of superior region-specific lines were identified and shipped
    to partners for stage 2 yield trial evaluation and testing. As data accumulated
    in the regions on cohorts of lines, and as the progeny and grand progeny of the
    original core set of lines begin to fill the pipeline, the capacity for predicting
    regional performance across cohorts will grow until sufficient data becomes available
    to allow for the identification of new parents prior to stage 1 yield testing.
    4.2 Description of the Breeding Schemes and Integrating Genomic Prediction The
    mapping of the breeding scheme is a key component for the optimal use of breeding
    program resources and to understand where the entry points for genomic selection
    could be placed. The current breeding strategy summarized in Fig. 2 was initiated
    in 2017 at IRRI in order to reduce cycle time and optimize multi-environment evaluations
    thanks to the introduction of genomic prediction. In this strategy, most of the
    activities take place at IRRI headquarters in the Philippines. In the first year,
    the crosses (80–100) are made and the F1 plants are validated using dedicated
    SNP markers. In the second year the segregating families go through SSD from F2
    to F6 via RGA. At that stage, 7500 to 10,000 lines are advanced: this corresponds
    to 200–400 lines per cross. Population sizes for each cross are determined based
    on the anticipated segregation of major genes. In the third year, the lines are
    evaluated in the field in panicle rows for seed increase and for the evaluation
    of uniformity, plant architecture, and maturity. At the same time, the lines are
    genotyped for marker-assisted selection for major loci prioritized for each breeding
    pipeline. These include the waxy gene for amylose content and a number of disease
    resistance genes for major pests and disease (blast, bacterial leaf blight, ...)
    [10]. The second season of the third year is dedicated to the preparation of the
    seeds to be shipped in the regions. In the fourth year, the lines advanced based
    on MAS and head row selection (1500–2000) are genotyped using a low-density platform
    with less than 1000 SNP markers [69]. The same lines are also evaluated in the
    first stage yield trial at IRRI headquarters in the Philippines. In parallel,
    a subset of the cohort (250–300 lines) is sent to the regional partners in South
    Asia and Eastern Africa for multi-environment evaluation of key agronomic traits
    (plant height, time to flowering, grain yield). This subset (training set) is
    used to build the genomic prediction model that is later used to select an advanced
    class of superior lines among the entire cohort. Since no historical data were
    available for building reliable genomic prediction models , the integration of
    genomic prediction in this scheme relies on the use of half sibs or full sib-sibs
    to maximize the accuracy with highly related training and predicted sets [142,
    149]. The genomic prediction models are used to select parental lines for the
    following cycle and to select promising lines (30–40) for the second stage yield
    trial that are conducted in the fifth year of the breeding scheme. The best performing
    lines at the end of this stage can then go through advance testing in the national
    variety release system or can be used by partners in the regions in their breeding
    program to enrich their gene pools. In this strategy, the breeding cycle spans
    over 5 years with the recycling of advanced lines as parents occurring during
    the fourth year (Fig. 2). Compared to previous breeding schemes that were in place
    at IRRI, the cycle time is shortened by 2 years [147]. Reduction of cycle time
    is a key factor to increase the rate of genetic gain [109]. In this scheme, one
    of the major tools for cycle reduction is RGA. This approach, known for a long
    time [150, 151], was optimized in 2013 and implemented at large scale at IRRI
    in 2014 [118]. Currently, genomic prediction is not used to decrease cycle time
    and is mainly used to increase the intensity and accuracy of selection in regional
    environments, especially for yield. The main reason for this is the lack of historical
    data in the breeding program suitable for genomic prediction. Indeed, very few
    breeding lines have been consistently genotyped and phenotyped to build a reliable
    database. Therefore, the current phase is a transition phase where the data currently
    generated feeds a database that will be used to predict the performance of future
    progeny (across cohort predictions). This is highlighted in Fig. 2 as the future
    scheme. This ability to directly predict the performance of selection candidates
    before evaluating them in the field will enable us to decrease the cycle time
    by 2 additional years resulting in a 2-year breeding cycle. However, this comes
    with operational challenges such as ensuring four generations per year in a stable
    manner during RGA, production of enough seed at the end of the RGA to enable multi-environment
    trials, and navigating the import/export process quickly enough to ensure the
    seed arrives to the partners in time for planting in the main season. 4.3 A Practical
    Example of the Analytical Pipeline In this section, we present the analysis pipeline
    that we currently use at IRRI to perform genomic selection. This corresponds to
    the activities mapped to the fourth year of the current breeding strategy (first
    stage yield trial, Fig. 2). The analysis pipeline is divided into three main steps
    (Fig. 3): 1. The selection of the training set. This step is based on SNP markers
    specifically chosen to be informative in the elite germplasm used in the breeding
    program [69] and the optimization method of Akdemir et al. [41] that minimizes
    the prediction error variance (PEV) in the predicted set. 2. The single trial
    analysis. In this step, phenotypic data (plant height, days to flowering, and
    grain yield) are measured on the training set in several regional locations, which
    are analyzed separately to assess the quality of the data at each location and
    estimate spatial adjustments to genotypic values with a mixed model, taking the
    experimental design into consideration. 3. The genomic prediction analysis. In
    this last step, a GBLUP model trained with the genotypic and phenotypic data from
    the training set is used to predict genomic estimated breeding values (GEBVs)
    for all the untested lines. Fig. 3 The data analysis flowchart represents the
    routine steps that are performed for every breeding cycle at IRRI’s breeding program.
    The whole cohort (first stage yield trial) is first genotyped with a SNP panel
    and the data is used to select a training population (subset of the whole cohort).
    The training population is then evaluated in multi-environment trials (MET). The
    single trials are analyzed with a mixed model that takes into account the experimental
    design. The single trial BLUPs combined with the marker information of the whole
    cohort are then used to compute the genomic estimated breeding values (GEBV) of
    the lines Full size image To illustrate the analysis pipeline, real data from
    the IRRI breeding program for irrigated systems is used as an example. The analyses
    were conducted within the R environment and utilized the R packages asreml (under
    license) or sommer (freely available) for mixed model analyses and functions developed
    specifically for the analysis pipeline and from the literature. We have opted
    to give the user the possibility to choose between asreml and sommer according
    to his preferences. All the R scripts and the data are provided in the supplementary
    material (Data 1, 2, and 3). 4.3.1 Selection of the Training Set In the current
    breeding scheme the genomic prediction is used for within-cohort predictions.
    In order to identify the best subset (training set) to be phenotyped in regional
    MET, we use an optimization method based on mixed model theory that minimizes
    the prediction error variance [41]. This method available in the R package STPGA
    (for Selection of Training Populations by Genetic Algorithm) requires the genomic
    relationship matrix (G matrix) as an input. In the example, the entire cohort
    of 1722 lines is genotyped with 1079 SNP markers. We use the rrBLUP package to
    compute the G matrix based on the genotypic matrix (geno_data) containing marker
    information coded as [−1, 0, 1]. The G matrix is then used as a parameter for
    the OptiTS function along with the desired size of the training set (sTS = 300)
    and the number of replicates (rep = 5). The number of replicates allows the selection
    of the individuals most represented in the different runs to be included in the
    training set in order to avoid suboptimal solutions from the genetic algorithm
    [41]. To evaluate the representativeness of the training set compared to the entire
    cohort, the individuals are plotted using the two first principal components from
    the G matrix (Fig. 4). Fig. 4 Principal component analysis using the molecular
    marker data on all breeding lines used for genomic prediction. The orange triangles
    represent the lines selected to form the training set using the optimization method
    of Akdemir et al. [41]. The remaining lines (in grey circles) compose the predicted
    set Full size image 4.3.2 Single Trial Analysis Once the training set is identified,
    it is sent to regional partners to be evaluated in MET. For this case study, actual
    trial data from five different locations in Bangladesh were used. These trials
    were conducted in the 2020 dry season (Jan–May). Each trial comprises 362 breeding
    lines of which 299 are training set lines, and the rest are advanced lines from
    the previous cohort and check varieties. All the trials used a partially replicated
    design with 20% of lines replicated. Three traits are used in this example: plant
    height (cm), days to flowering, and grain yield (t/ha). The trial data is uploaded
    into the B4R database, which has been adopted by IRRI for managing all breeding
    trial data. The exported data from the B4R database for each location is used
    to perform individual single trial analyses (pheno_data object). The objective
    of this step is to remove potential error in the dataset and to adjust from spatial
    variation using the experimental design. The following mixed model (asreml or
    sommer) is used to obtain the BLUP and deregressed BLUP for each line: model <-
    asreml( fixed = trait ~ 1 ,  random = ~ DESIGN_X + DESIGN_Y + GID,  na.action
    = na.method(x = "include"),  data = dataset) model <- sommer::mmer(fixed = trait
    ~ 1,  random = ~ DESIGN_X + DESIGN_Y + GID,  rcov = ~ units,  data = dataset,  verbose
    = FALSE) The variable DESIGN_X and DESIGN_Y represent the coordinates of the plots
    within the field. The variable GID represents the ID of the genotypes. The BLUP
    and deregressed BLUP values are then calculated. The single trial analysis is
    embedded in a function called single_trial_asreml or single_trial_sommer that
    takes the formatted phenotypic raw data as an input and returns a data frame with
    several variables including location, trait, genotype ID, BLUP, deregressed BLUP,
    and repeatability (H2). The function is then used for all locations and traits
    to run the model and retrieve the BLUPs (Fig. 5a). Fig. 5 Results from the single
    trial analysis and genomic prediction analysis. Panel a shows the boxplot of BLUP
    values for grain yield, days to 50% flowering, and plant height from the five
    partner trial locations. Panel b presents the distribution of grain yield GEBV
    of the predicted and training set lines. The results were obtained using asreml
    Full size image 4.3.3 Genomic Predictions The deregressed BLUP value of the training
    set lines from the single trial analysis and the genome-wide marker genotype data
    of the entire cohort (training set and predicted set) consisting of 1722 lines
    are used in the genomic prediction model . The genome-wide marker data is used
    to construct the additive relationship matrix with the sommer package. The inverse
    of the additive relation matrix is then constructed in the case where asreml is
    used the GBLUP analysis. The GEBV for each line is computed using the GBLUP model
    where the regressed BLUP from each location is the response variable, location
    as fixed effect, the breeding line (gid) and inverse of the G matrix (invG) are
    used as the random effects. model <- asreml(fixed = trait ~ 1 + location,  random
    = ~ vm(gid, invG),  data = dataset) model <- sommer::mmer( fixed = trait ~ 1 +
    location,  random = ~ vs(gid, Gu = G),  rcov = ~ vs(units),  data = dataset,  verbose
    = FALSE) Similarly to the single location analysis, this model is embedded in
    a function (gblup _asreml or gblup _sommer) with two parameters: the first is
    the output from the single location analysis and the second is the inverse of
    the G matrix. The output of the function is a table containing the GEBV on the
    entire cohort (Fig. 5b). The GEBV values are then combined with trait marker information
    and used by the breeder for selecting lines for advanced testing and, also, selecting
    parents for the next breeding cycle. 5 Other Applications of Genomic Prediction
    for Rice Improvement In the previous parts of the chapter, we saw that genomic
    selection requires both methodological research and a carefully designed breeding
    program to be implemented efficiently. In this last part, we present ongoing developments
    regarding the use of genomic predictions for rice improvement. We think it is
    important for breeders to be aware of upcoming approaches and tools to be ready
    when they are mature enough to be integrated in breeding programs when appropriate.
    5.1 Characterization of Genetic Diversity for Pre-breeding The characterization
    and the use of genetic diversity is important to meet long-term breeding objectives
    and maintain the adaptive potential of the breeding populations [152]. In the
    case of recurrent selection in elite germplasm, the addition of new material threatens
    the genetic gain in the short term by diluting the impact of high value alleles
    carefully accumulated through successive cycles of selection. However, in the
    long term, the loss of genetic diversity due to selection but also to negative
    or neutral linkage drag or genetic drift can be compensated by careful introduction
    of genetic variation into the elite pool [153]. The identification of the best
    accessions for particular breeding objectives is laborious, as it requires an
    accurate phenotyping of a large number of diverse lines that often mask valuable
    haplotypes in low breeding value backgrounds. In this context, genomic prediction
    can be used to identify superior accessions in germplasm collections and be applied
    to pre-breeding, which aims to identify high-potential genotypes among a large
    number of accessions [154,155,156]. In rice, the availability of large genomic
    resources such as the 3000 rice genomes [30] or the high-density rice array panel
    [157] offers a unique opportunity to use genomic prediction to target valuable
    genotypes relative to the breeding objectives. 5.2 Definition of Heterotic Groups
    for Hybrid Breeding In hybrid breeding, heterotic groups are usually needed to
    optimally use the heterosis within a species [158]. To this end, hybrid selection
    causes the germplasm to become structured into genetically distinct groups that
    display superior hybrid performance when individuals from complementary groups
    are crossed. Contrary to other major crops (e.g., corn [159]), heterotic groups
    in rice are defined largely according to complementarity with a particular sterility
    system and not according to gene pools defined by complimentary heterotic potential.
    This is further complicated in rice due to the strong population structure that
    characterizes rice diversity being confused as heterotic differentiation of complementary
    gene pools [29, 30]. Efforts to coerce ancestral subpopulations into heterotic
    groups, as in the case of the two major types (indica and japonica), have limitations
    due to sterility, contrasting adaptations, and very different distributions of
    major grain quality parameters [160]. Further research is required to identify
    natural patterns of heterosis [161], and in some cases genomic prediction can
    assist this exploration. Recently, the use of predictions to define heterotic
    pools based on complementary yield performance has been proposed in rice [162].
    In this study based on real data, the authors applied the approach developed by
    Zhao et al. [163] to detect heterotic patterns for yield by combining the predicted
    performances of all unique single-cross hybrids with a simulated annealing algorithm
    with different group sizes. 5.3 Integration of High-Throughput Phenotyping and
    Environmental Information The significant progress made with genomics in breeding
    programs has reinforced the idea that phenotyping is still a bottleneck for genetic
    improvement [164]. This may seem paradoxical since one of the advantages of genomic
    selection lies in the reduction of some phenotyping steps. However, accurate field
    phenotyping for important traits (e.g., grain yield) in METs is even more important
    to efficiently train the prediction model and capture G × E. In addition, selection
    for more expensive or difficult traits (drought resistance, lodging tolerance,
    grain quality, etc.) can be integrated earlier in the breeding scheme thanks to
    genomic prediction and therefore increase the selection intensity. These observations
    have led to an ever-increasing interest in high-throughput phenotyping methods
    [165, 166]. Several tools (RGB and multispectral cameras, thermal sensor, etc.)
    and platforms (phenomobiles, unmanned aerial vehicles, etc.) are available for
    field and laboratory phenotyping with a wide range of applications. When integrated
    in a genomic prediction model , high-throughput phenotypic data can substantially
    increase the prediction accuracy [167, 168]. In the case of phenomic selection,
    high-throughput near-infrared spectroscopy data can even replace genotypic data
    and offer similar accuracy [169, 170]. However, to be useful in a breeding context,
    the large quantity of data generated by the high-throughput phenotyping techniques
    needs to be stored in a data management system, properly vetted relative to the
    costs and selection accuracies available from manual phenotypes, and associated
    with correct genotype data if it is to improve the decision-making process. Although
    tools and analysis pipelines have evolved in recent years, there are still important
    constraints to the routine use of these approaches: the acquisition of multi-environment
    field data and not just data from a central research station, the availability
    of data management systems that can handle large time-series datasets, and the
    initial cost of related equipment. It is expected as the technologies and regulations
    mature that dedicated companies offering high-throughput phenotyping services
    will emerge, much like has been the case with genotyping. In addition to high-throughput
    phenotyping, a better characterization of environmental factors affecting the
    performance crop plants will enhance our ability to explain nongenetic sources
    of variation. Such “envirotyping” is an area of active research that shows great
    promise [171]. To become truly useful technologies that permit the high-throughput
    collection of envirotype data in real time need to continue to mature as well
    as data management and analytical strategies for extracting intelligence from
    these datasets. 6 Conclusion: A Point of View of a Rice Breeder Based on the literature
    in rice and in other species, the ability to do genomic prediction and the value
    of applying genomic selection to rice breeding programs are beyond question. The
    capacity to estimate the prediction values and the key datasets and models that
    underlie the estimation of GEBVs is also very well understood. The marker resources
    and phenotyping capacity in rice are present and available at this point to even
    the most remote breeding organizations. Furthermore, the rules that describe how
    quantitative trait variation is inherited in populations are well understood,
    and it would seem the infinitesimal model applies to quantitative traits in rice
    in most cases. What remains to capture the full value of this technology is the
    reorientation of rice breeding programs around a short-cycle recurrent selection
    strategy within a defined gene pool. During that transition, genomic prediction
    can additionally be helpful for improving selection within cohorts and save money
    on field evaluation. As a result, generating genotype data or building an analytical
    pipeline is often not the starting point for implementation of genomic selection
    in most programs. Clear business rules for data collection and management, clearly
    defined best practices for parental selection, and a commitment to work within
    elite gene pools must come first. Second to these foundational activities, breeding
    programs must standardize and systematize their operations in such a way that
    resources are optimized, workflows are clear, and breeders are not spending inordinate
    amounts of time managing logistics. Field work needs to focus more on data quality
    and data collection, reserving selection decisions for after data has been collected,
    analyzed, and interpreted. Marker systems for routine genotyping are also necessary
    but must be developed such that the genotype data is specifically informative
    to the breeding germplasm of interest. The public rice literature to date has
    largely focused on questions related to if predictions work in rice or how to
    optimize prediction accuracy. Very few rice publications address how predictions
    can be practically applied to enhanced rates of genetic gain. As a result, in
    an attempt to modernize many breeders get stuck in “proof of concept purgatory”
    by trying to replicate analyses done by others. Breeders seeking to improve their
    strategy would instead be benefited from considering whether the appropriate foundations
    are laid in their programs and then considering carefully what the entry points
    for prediction are in their stated breeding strategy. Commercial breeding programs
    may have the advantage of having the freedom to invest resources in additional
    capital or operational expenditures up front in order to capture value in the
    long term. However as budgets are often tight, fixed, or subject to congressional
    approval for publicly funded programs, cost saving adjustments to the breeding
    strategy (such as applying a sparse testing design or implementing rapid generation
    advance for line fixation) may liberate resources in the short term which can
    be applied to laying the proper foundations for a fully genomic prediction-enabled
    breeding strategy. References Ragot M, Bonierbale M, Weltzien E (2018) From market
    demand to breeding decisions: a framework Google Scholar   Gallais A (2011) Méthodes
    de création de variétés en amélioration des plantes. Quae Google Scholar   Brown
    J, Caligari P (2011) An introduction to plant breeding. Wiley Google Scholar   Rutkoski
    JE (2019) Chapter four—a practical guide to genetic gain. In: Sparks DL (ed) Advances
    in agronomy. Academic, pp 217–249 Google Scholar   Lynch M, Walsh B (1998) Genetics
    and analysis of quantitative traits. Sunderland, MA, Sinauer Google Scholar   Cooper
    M, Hammer GL (1996) Plant adaptation and crop improvement. CAB International,
    Wallingford Book   Google Scholar   Chenu K (2015) Chapter 13—characterizing the
    crop environment—nature, significance and applications. In: Sadras VO, Calderini
    DF (eds) Crop physiology, 2nd edn. Academic, San Diego, pp 321–348 Chapter   Google
    Scholar   Xu Y, Li P, Zou C et al (2017) Enhancing genetic gain in the era of
    molecular breeding. J Exp Bot 68:2641–2666. https://doi.org/10.1093/jxb/erx135
    Article   CAS   PubMed   Google Scholar   Lande R, Thompson R (1990) Efficiency
    of marker-assisted selection in the improvement of quantitative traits. Genetics
    124:743–756 Article   CAS   PubMed   PubMed Central   Google Scholar   Cobb JN,
    Biswas PS, Platten JD (2018) Back to the future: revisiting MAS as a tool for
    modern plant breeding. Theor Appl Genet 132(3):647–667. https://doi.org/10.1007/s00122-018-3266-4
    Article   CAS   PubMed   PubMed Central   Google Scholar   Meuwissen TH, Hayes
    BJ, Goddard ME (2001) Prediction of total genetic value using genome-wide dense
    marker maps. Genetics 157:1819–1829 Article   CAS   PubMed   PubMed Central   Google
    Scholar   Goddard ME, Hayes BJ (2007) Genomic selection. J Anim Breed Genet 124:323–330.
    https://doi.org/10.1111/j.1439-0388.2007.00702.x Article   CAS   PubMed   Google
    Scholar   Goddard M (2008) Genomic selection: prediction of accuracy and maximisation
    of long term response. Genetica 136:245–257. https://doi.org/10.1007/s10709-008-9308-0
    Article   PubMed   Google Scholar   Heffner EL, Sorrells ME, Jannink J-L (2009)
    Genomic selection for crop improvement. Crop Sci 49:1–12. https://doi.org/10.2135/cropsci2008.08.0512
    Article   CAS   Google Scholar   Sallam AH, Endelman JB, Jannink J-L, Smith KP
    (2015) Assessing genomic selection prediction accuracy in a dynamic barley breeding
    population. Plant Genome 8:20. https://doi.org/10.3835/plantgenome2014.05.0020
    Article   CAS   Google Scholar   VanRaden PM, Van Tassell CP, Wiggans GR et al
    (2009) Invited review: reliability of genomic predictions for North American Holstein
    bulls. J Dairy Sci 92:16–24. https://doi.org/10.3168/jds.2008-1514 Article   CAS   PubMed   Google
    Scholar   Hickey JM, Chiurugwi T, Mackay I et al (2017) Genomic prediction unifies
    animal and plant breeding programs to form platforms for biological discovery.
    Nat Genet 49:1297–1303. https://doi.org/10.1038/ng.3920 Article   CAS   PubMed   Google
    Scholar   Crossa J, Pérez-Rodríguez P, Cuevas J et al (2017) Genomic selection
    in plant breeding: methods, models, and perspectives. Trends Plant Sci 22:961–975.
    https://doi.org/10.1016/j.tplants.2017.08.011 Article   CAS   PubMed   Google
    Scholar   Hayes BJ, Bowman PJ, Chamberlain AJ, Goddard ME (2009) Invited review:
    genomic selection in dairy cattle: progress and challenges. J Dairy Sci 92:433–443.
    https://doi.org/10.3168/jds.2008-1646 Article   CAS   PubMed   Google Scholar   de
    los Campos G, Hickey JM, Pong-Wong R et al (2013) Whole-genome regression and
    prediction methods applied to plant and animal breeding. Genetics 193:327–345.
    https://doi.org/10.1534/genetics.112.143313 Article   PubMed Central   Google
    Scholar   Izawa T, Shimamoto K (1996) Becoming a model plant: the importance of
    rice to plant science. Trends Plant Sci 1:95–99. https://doi.org/10.1016/S1360-1385(96)80041-0
    Article   Google Scholar   Peng S, Khushg G (2003) Four decades of breeding for
    varietal improvement of irrigated lowland rice in the International Rice Research
    Institute. Plant Prod Sci 6:157–164. https://doi.org/10.1626/pps.6.157 Article   Google
    Scholar   Chandler RF (1982) An adventure in applied science: a history of the
    International Rice Research Institute. IRRI Google Scholar   Breth S (1985) International
    rice research: 25 years of partnership. IRRI Google Scholar   Guimaraes EP (2009)
    Rice breeding. In: Cereals. Springer, pp 99–126 Chapter   Google Scholar   Jena
    KK, Mackill DJ (2008) Molecular markers and their use in marker-assisted selection
    in rice. Crop Sci 48:1266–1276. https://doi.org/10.2135/cropsci2008.02.0082 Article   Google
    Scholar   Ismail AM, Singh US, Singh S et al (2013) The contribution of submergence-tolerant
    (Sub1) rice varieties to food security in flood-prone rainfed lowland areas in
    Asia. Field Crops Res 152:83–93. https://doi.org/10.1016/j.fcr.2013.01.007 Article   Google
    Scholar   Steele KA, Price AH, Shashidhar HE, Witcombe JR (2006) Marker-assisted
    selection to introgress rice QTLs controlling root traits into an Indian upland
    rice variety. Theor Appl Genet 112:208–221. https://doi.org/10.1007/s00122-005-0110-4
    Article   CAS   PubMed   Google Scholar   Glaszmann JC (1987) Isozymes and classification
    of Asian rice varieties. Theor Appl Genet 74:21–30. https://doi.org/10.1007/BF00290078
    Article   CAS   PubMed   Google Scholar   Wang W, Mauleon R, Hu Z et al (2018)
    Genomic variation in 3,010 diverse accessions of Asian cultivated rice. Nature
    557:43–49. https://doi.org/10.1038/s41586-018-0063-9 Article   CAS   PubMed   PubMed
    Central   Google Scholar   Brar D, Khush G (2002) Transferring genes from wild
    species into rice. In: Kang MS (ed) Quantitative genetics, genomics, and plant
    breeding. CABI, Wallingford, p 197 Chapter   Google Scholar   Brar DS, Khush GS
    (2018) Wild relatives of rice: a valuable genetic resource for genomics and breeding
    research. In: Mondal TK, Henry RJ (eds) The wild oryza genomes. Springer, Cham,
    pp 1–25 Google Scholar   Breseghello F, de Morais OP, Pinheiro PV et al (2011)
    Results of 25 years of upland rice breeding in Brazil. Crop Sci 51:914–923. https://doi.org/10.2135/cropsci2010.06.0325
    Article   Google Scholar   Spindel J, Iwata H (2018) Genomic selection in rice
    breeding. In: Sasaki T, Ashikari M (eds) Rice genomics, genetics and breeding.
    Springer, Singapore, pp 473–496 Chapter   Google Scholar   Ahmadi N, Bartholomé
    J, Tuong-Vi C, Grenier C (2020) Genomic selection in rice: empirical results and
    implications for breeding. In: Quantitative genetics, genomics and plant breeding.
    CABI, Wallingford, pp 243–258 Chapter   Google Scholar   Guo Z, Tucker DM, Basten
    CJ et al (2014) The impact of population structure on genomic prediction in stratified
    populations. Theor Appl Genet 127:749–762. https://doi.org/10.1007/s00122-013-2255-x
    Article   PubMed   Google Scholar   Zhao K, Tung C-W, Eizenga GC et al (2011)
    Genome-wide association mapping reveals a rich genetic architecture of complex
    traits in Oryza sativa. Nat Commun 2:467. https://doi.org/10.1038/ncomms1467 Article   CAS   PubMed   Google
    Scholar   Xu SH, Zhu D, Zhang QF (2014) Predicting hybrid performance in rice
    using genomic best linear unbiased prediction. Proc Natl Acad Sci U S A 111:12456–12461.
    https://doi.org/10.1073/pnas.1413750111 Article   CAS   PubMed   PubMed Central   Google
    Scholar   Hua JP, Xing YZ, Xu CG et al (2002) Genetic dissection of an elite rice
    hybrid revealed that heterozygotes are not always advantageous for performance.
    Genetics 162:1885–1895 Article   CAS   PubMed   PubMed Central   Google Scholar   Zhang
    Z, Ober U, Erbe M et al (2014) Improving the accuracy of whole genome prediction
    for complex traits using the results of genome wide association studies. PLoS
    One 9:e93017. https://doi.org/10.1371/journal.pone.0093017 Article   CAS   PubMed   PubMed
    Central   Google Scholar   Akdemir D, Sanchez JI, Jannink J-L (2015) Optimization
    of genomic selection training populations with a genetic algorithm. Genet Sel
    Evol 47:38. https://doi.org/10.1186/s12711-015-0116-6 Article   PubMed   PubMed
    Central   Google Scholar   Blondel M, Onogi A, Iwata H, Ueda N (2015) A ranking
    approach to genomic selection. PLoS One 10:e0128570. https://doi.org/10.1371/journal.pone.0128570
    Article   CAS   PubMed   PubMed Central   Google Scholar   Grenier C, Cao T-V,
    Ospina Y et al (2015) Accuracy of genomic selection in a rice synthetic population
    developed for recurrent selection breeding. PLoS One 10:e0136594. https://doi.org/10.1371/journal.pone.0136594
    Article   CAS   PubMed   PubMed Central   Google Scholar   Isidro J, Jannink J-L,
    Akdemir D et al (2015) Training set optimization under population structure in
    genomic selection. Theor Appl Genet Theor Angew Genet 128:145–158. https://doi.org/10.1007/s00122-014-2418-4
    Article   Google Scholar   Iwata H, Ebana K, Uga Y, Hayashi T (2015) Genomic prediction
    of biological shape: elliptic fourier analysis and kernel partial least squares
    (PLS) regression applied to grain shape prediction in rice (Oryza sativa L.).
    PLoS One 10:e0120610. https://doi.org/10.1371/journal.pone.0120610 Article   CAS   PubMed   PubMed
    Central   Google Scholar   Onogi A, Ideta O, Inoshita Y et al (2015) Exploring
    the areas of applicability of whole-genome prediction methods for Asian rice (Oryza
    sativa L.). Theor Appl Genet 128:41–53. https://doi.org/10.1007/s00122-014-2411-y
    Article   PubMed   Google Scholar   Spindel J, Begum H, Akdemir D et al (2015)
    Genomic selection and association mapping in rice (Oryza sativa): effect of trait
    genetic architecture, training population composition, marker number and statistical
    model on accuracy of rice genomic selection in elite, tropical rice breeding lines.
    PLoS Genet 11:e1004982. https://doi.org/10.1371/journal.pgen.1004982 Article   CAS   PubMed   PubMed
    Central   Google Scholar   Bustos-Korts D, Malosetti M, Chapman S et al (2016)
    Improvement of predictive ability by uniform coverage of the target genetic space.
    G3 6:3733–3747. https://doi.org/10.1534/g3.116.035410 Article   PubMed   PubMed
    Central   Google Scholar   Jacquin L, Cao T-V, Ahmadi N (2016) A unified and comprehensible
    view of parametric and kernel methods for genomic prediction with application
    to rice. Front Genet 7:145. https://doi.org/10.3389/fgene.2016.00145 Article   PubMed   PubMed
    Central   Google Scholar   Onogi A, Watanabe M, Mochizuki T et al (2016) Toward
    integration of genomic selection with crop modelling: the development of an integrated
    approach to predicting rice heading dates. Theor Appl Genet 129:805–817. https://doi.org/10.1007/s00122-016-2667-5
    Article   PubMed   Google Scholar   Spindel JE, Begum H, Akdemir D et al (2016)
    Genome-wide prediction models that incorporate de novo GWAS are a powerful new
    tool for tropical rice improvement. Heredity 116:395–408. https://doi.org/10.1038/hdy.2015.113
    Article   CAS   PubMed   PubMed Central   Google Scholar   Campbell MT, Du Q,
    Liu K et al (2017) A comprehensive image-based phenomic analysis reveals the complex
    genetic architecture of shoot growth dynamics in rice (Oryza sativa). Plant Genome
    10. https://doi.org/10.3835/plantgenome2016.07.0064 Gao N, Martini JWR, Zhang
    Z et al (2017) Incorporating gene annotation into genomic prediction of complex
    phenotypes. Genetics 207:489–501. https://doi.org/10.1534/genetics.117.300198
    Article   CAS   PubMed   PubMed Central   Google Scholar   Matias FI, Galli G,
    Granato ISC, Fritsche-Neto R (2017) Genomic prediction of autogamous and allogamous
    plants by SNPs and haplotypes. Crop Sci 57:2951–2958. https://doi.org/10.2135/cropsci2017.01.0022
    Article   Google Scholar   Morais OP, Duarte JB, Breseghello F et al (2017) Relevance
    of additive and non-additive genetic relatedness for genomic prediction in rice
    population under recurrent selection breeding. Genet Mol Res 16. https://doi.org/10.4238/gmr16039849
    Wang X, Li L, Yang Z et al (2017) Predicting rice hybrid performance using univariate
    and multivariate GBLUP models based on North Carolina mating design II. Heredity
    118:302–310. https://doi.org/10.1038/hdy.2016.87 Article   CAS   PubMed   Google
    Scholar   Xu S (2017) Predicted residual error sum of squares of mixed models:
    an application for genomic prediction. G3 7:895–909. https://doi.org/10.1534/g3.116.038059
    Article   PubMed   PubMed Central   Google Scholar   Ben Hassen M, Bartholome
    J, Vale G et al (2018) Genomic prediction accounting for genotype by environment
    interaction offers an effective framework for breeding simultaneously for adaptation
    to an abiotic stress and performance under normal cropping conditions in rice.
    G3 8:2319–2332. https://doi.org/10.1534/g3.118.200098 Article   PubMed   PubMed
    Central   Google Scholar   Ben Hassen M, Cao TV, Bartholome J et al (2018) Rice
    diversity panel provides accurate genomic predictions for complex traits in the
    progenies of biparental crosses involving members of the panel. Theor Appl Genet
    131:417–435. https://doi.org/10.1007/s00122-017-3011-4 Article   CAS   PubMed   Google
    Scholar   Campbell M, Walia H, Morota G (2018) Utilizing random regression models
    for genomic prediction of a longitudinal trait derived from high-throughput phenotyping.
    Plant Direct 2:e00080. https://doi.org/10.1002/pld3.80 Article   PubMed   PubMed
    Central   Google Scholar   Du C, Wei JL, Wang SB, Jia ZY (2018) Genomic selection
    using principal component regression. Heredity 121:12–23. https://doi.org/10.1038/s41437-018-0078-x
    Article   CAS   PubMed   PubMed Central   Google Scholar   Gao N, Teng J, Ye S
    et al (2018) Genomic prediction of complex phenotypes using genic similarity based
    relatedness matrix. Front Genet 9:364. https://doi.org/10.3389/fgene.2018.00364
    Article   CAS   PubMed   PubMed Central   Google Scholar   Mathew B, Léon J, Sillanpää
    MJ (2018) Impact of residual covariance structures on genomic prediction ability
    in multienvironment trials. PLoS One 13:e0201181. https://doi.org/10.1371/journal.pone.0201181
    Article   CAS   PubMed   PubMed Central   Google Scholar   Monteverde E, Rosas
    JE, Blanco P et al (2018) Multienvironment models increase prediction accuracy
    of complex traits in advanced breeding lines of rice. Crop Sci 58:1519–1530. https://doi.org/10.2135/cropsci2017.09.0564
    Article   Google Scholar   Morais Júnior OP, Breseghello F, Duarte JB et al (2018)
    Assessing prediction models for different traits in a rice population derived
    from a recurrent selection program. Crop Sci 58:2347–2359. https://doi.org/10.2135/cropsci2018.02.0087
    Article   CAS   Google Scholar   Morais Júnior OP, Duarte JB, Breseghello F et
    al (2018) Single-step reaction norm models for genomic prediction in multienvironment
    recurrent selection trials. Crop Sci 58:592–607. https://doi.org/10.2135/cropsci2017.06.0366
    Article   Google Scholar   Xu Y, Wang X, Ding XW et al (2018) Genomic selection
    of agronomic traits in hybrid rice using an NCII population. Rice 11:32. https://doi.org/10.1186/s12284-018-0223-4
    Article   PubMed   PubMed Central   Google Scholar   Yabe S, Yoshida H, Kajiya-Kanegae
    H et al (2018) Description of grain weight distribution leading to genomic selection
    for grain-filling characteristics in rice. PLoS One 13:e0207627. https://doi.org/10.1371/journal.pone.0207627
    Article   CAS   PubMed   PubMed Central   Google Scholar   Arbelaez JD, Dwiyanti
    MS, Tandayu E et al (2019) 1k-RiCA (1K-Rice Custom Amplicon) a novel genotyping
    amplicon-based SNP assay for genetics and breeding applications in rice. Rice
    12:55. https://doi.org/10.1186/s12284-019-0311-0 Article   PubMed   PubMed Central   Google
    Scholar   Azodi CB, Bolger E, McCarren A et al (2019) Benchmarking parametric
    and machine learning models for genomic prediction of complex traits. G3 9:3691–3702.
    https://doi.org/10.1534/g3.119.400498 Article   PubMed   PubMed Central   Google
    Scholar   Berro I, Lado B, Nalin RS et al (2019) Training population optimization
    for genomic selection. Plant Genome 12:1–14. https://doi.org/10.3835/plantgenome2019.04.0028
    Article   PubMed   Google Scholar   Bhandari A, Bartholomé J, Cao-Hamadoun T-V
    et al (2019) Selection of trait-specific markers and multi-environment models
    improve genomic predictive ability in rice. PLoS One 14:e0208871. https://doi.org/10.1371/journal.pone.0208871
    Article   PubMed   PubMed Central   Google Scholar   e Sousa MB, Galli G, Lyra
    DH et al (2019) Increasing accuracy and reducing costs of genomic prediction by
    marker selection. Euphytica 215:18. https://doi.org/10.1007/s10681-019-2339-z
    Article   CAS   Google Scholar   Frouin J, Labeyrie A, Boisnard A et al (2019)
    Genomic prediction offers the most effective marker assisted breeding approach
    for ability to prevent arsenic accumulation in rice grains. PLoS One 14:e0217516.
    https://doi.org/10.1371/journal.pone.0217516 Article   CAS   PubMed   PubMed Central   Google
    Scholar   Guo T, Yu X, Li X et al (2019) Optimal designs for genomic selection
    in hybrid crops. Mol Plant 12:390–401. https://doi.org/10.1016/j.molp.2018.12.022
    Article   CAS   PubMed   Google Scholar   Hu X, Xie W, Wu C, Xu S (2019) A directed
    learning strategy integrating multiple omic data improves genomic prediction.
    Plant Biotechnol J 17:2011–2020. https://doi.org/10.1111/pbi.13117 Article   CAS   PubMed   PubMed
    Central   Google Scholar   Huang M, Balimponya EG, Mgonja EM et al (2019) Use
    of genomic selection in breeding rice (Oryza sativa L.) for resistance to rice
    blast (Magnaporthe oryzae). Mol Breed 39:114. https://doi.org/10.1007/s11032-019-1023-2
    Article   CAS   Google Scholar   Lima LP, Azevedo CF, De Resende MDV et al (2019)
    New insights into genomic selection through population-based non-parametric prediction
    methods. Sci Agric 76:290–298. https://doi.org/10.1590/1678-992X-2017-0351 Article   Google
    Scholar   Monteverde E, Gutierrez L, Blanco P et al (2019) Integrating molecular
    markers and environmental covariates to interpret genotype by environment interaction
    in rice (Oryza sativa L.) grown in subtropical areas. G3 9:1519–1531. https://doi.org/10.1534/g3.119.400064
    Article   PubMed   PubMed Central   Google Scholar   Ou JH, Liao CT (2019) Training
    set determination for genomic selection. Theor Appl Genet 132:2781–2792. https://doi.org/10.1007/s00122-019-03387-0
    Article   PubMed   Google Scholar   Suela MM, Lima LP, Azevedo CF et al (2019)
    Combined index of genomic prediction methods applied to productivity traits in
    rice. Cienc Rural 49. https://doi.org/10.1590/0103-8478cr20181008 Wang S, Wei
    J, Li R et al (2019) Identification of optimal prediction models using multi-omic
    data for selecting hybrid rice. Heredity 123(3):395–406. https://doi.org/10.1038/s41437-019-0210-6
    Article   PubMed   PubMed Central   Google Scholar   Wang X, Xu Y, Li PC et al
    (2019) Efficiency of linear selection index in predicting rice hybrid performance.
    Mol Breed 39:1–13. https://doi.org/10.1007/s11032-019-0986-3 Article   Google
    Scholar   Baba T, Momen M, Campbell MT et al (2020) Multi-trait random regression
    models increase genomic prediction accuracy for a temporal physiological trait
    derived from high-throughput phenotyping. PLoS One 15:e0228118. https://doi.org/10.1371/journal.pone.0228118
    Article   CAS   PubMed   PubMed Central   Google Scholar   Banerjee R, Marathi
    B, Singh M (2020) Efficient genomic selection using ensemble learning and ensemble
    feature reduction. J Crop Sci Biotechnol 23:311–323. https://doi.org/10.1007/s12892-020-00039-4
    Article   Google Scholar   Cui YR, Li RD, Li GW et al (2020) Hybrid breeding of
    rice via genomic selection. Plant Biotechnol J 18:57–67. https://doi.org/10.1111/pbi.13170
    Article   CAS   PubMed   Google Scholar   Grinberg NF, Orhobor OI, King RD (2020)
    An evaluation of machine-learning for predicting phenotype: studies in yeast,
    rice, and wheat. Mach Learn 109:251–277. https://doi.org/10.1007/s10994-019-05848-5
    Article   PubMed   Google Scholar   Jarquin D, Kajiya-Kanegae H, Taishen C et
    al (2020) Coupling day length data and genomic prediction tools for predicting
    time-related traits under complex scenarios. Sci Rep 10:13382. https://doi.org/10.1038/s41598-020-70267-9
    Article   CAS   PubMed   PubMed Central   Google Scholar   Schrauf MF, Martini
    JWR, Simianer H et al (2020) Phantom epistasis in genomic selection: on the predictive
    ability of epistatic models. G3 10:3137–3145. https://doi.org/10.1534/g3.120.401300
    Article   CAS   PubMed   PubMed Central   Google Scholar   Toda Y, Wakatsuki H,
    Aoike T et al (2020) Predicting biomass of rice with intermediate traits: modeling
    method combining crop growth models and genomic prediction models. PLoS One 15:e0233951.
    https://doi.org/10.1371/journal.pone.0233951 Article   CAS   PubMed   PubMed Central   Google
    Scholar   Xu Y, Zhao Y, Wang X et al (2020) Incorporation of parental phenotypic
    data into multi-omic models improves prediction of yield-related traits in hybrid
    rice. Plant Biotechnol J 19(2):261–272. https://doi.org/10.1111/pbi.13458 Article   CAS   PubMed   PubMed
    Central   Google Scholar   Piepho HP (2009) Ridge regression and extensions for
    genomewide selection in maize. Crop Sci 49:1165–1176. https://doi.org/10.2135/cropsci2008.10.0595
    Article   Google Scholar   de los Campos G, Naya H, Gianola D et al (2009) Predicting
    quantitative traits with regression models for dense molecular markers and pedigree.
    Genetics 182:375–385. https://doi.org/10.1534/genetics.109.101501 Article   CAS   PubMed   PubMed
    Central   Google Scholar   Zhong S, Dekkers JCM, Fernando RL, Jannink J-L (2009)
    Factors affecting accuracy from genomic selection in populations derived from
    multiple inbred lines: a barley case study. Genetics 182:355–364. https://doi.org/10.1534/genetics.108.098277
    Article   CAS   PubMed   PubMed Central   Google Scholar   Fukuoka S, Ebana K,
    Yamamoto T, Yano M (2010) Integration of genomics into rice breeding. Rice 3:131–137.
    https://doi.org/10.1007/s12284-010-9044-9 Article   Google Scholar   VanRaden
    PM (2008) Efficient methods to compute genomic predictions. J Dairy Sci 91:4414–4423.
    https://doi.org/10.3168/jds.2007-0980 Article   CAS   PubMed   Google Scholar   Henderson
    CR (1975) Best linear unbiased estimation and prediction under a selection model.
    Biometrics 31:423–447. https://doi.org/10.2307/2529430 Article   CAS   PubMed   Google
    Scholar   Michel S, Ametz C, Gungor H et al (2016) Genomic selection across multiple
    breeding cycles in applied bread wheat breeding. Theor Appl Genet 129:1179–1189.
    https://doi.org/10.1007/s00122-016-2694-2 Article   PubMed   PubMed Central   Google
    Scholar   Runcie D, Cheng H (2019) Pitfalls and remedies for cross validation
    with multi-trait genomic prediction methods. G3 9:3727–3741. https://doi.org/10.1534/g3.119.400598
    Article   PubMed   PubMed Central   Google Scholar   Gianola D, Schön C-C (2016)
    Cross-validation without doing cross-validation in genome-enabled prediction.
    G3 6:3107–3128. https://doi.org/10.1534/g3.116.033381 Article   PubMed   PubMed
    Central   Google Scholar   Habier D, Fernando RL, Dekkers JCM (2007) The impact
    of genetic relationship information on genome-assisted breeding values. Genetics
    177:2389–2397. https://doi.org/10.1534/genetics.107.081190 Article   CAS   PubMed   PubMed
    Central   Google Scholar   Technow F, Schrag TA, Schipprack W et al (2014) Genome
    properties and prospects of genomic prediction of hybrid performance in a breeding
    program of maize. Genetics 197:1343–1355. https://doi.org/10.1534/genetics.114.165860
    Article   PubMed   PubMed Central   Google Scholar   González-Diéguez D, Legarra
    A, Charcosset A et al (2021) Genomic prediction of hybrid crops allows disentangling
    dominance and epistasis. Genetics 218:iyab026. https://doi.org/10.1093/genetics/iyab026
    Article   PubMed   PubMed Central   Google Scholar   Crossa J (2012) From genotype
    × environment interaction to gene × environment interaction. Curr Genomics 13:225–244.
    https://doi.org/10.2174/138920212800543066 Article   CAS   PubMed   PubMed Central   Google
    Scholar   Voss-Fels KP, Cooper M, Hayes BJ (2019) Accelerating crop genetic gains
    with genomic selection. Theor Appl Genet 132:669–686. https://doi.org/10.1007/s00122-018-3270-8
    Article   PubMed   Google Scholar   Bassi FM, Bentley AR, Charmet G et al (2016)
    Breeding schemes for the implementation of genomic selection in wheat (Triticum
    spp.). Plant Sci 242:23–36. https://doi.org/10.1016/j.plantsci.2015.08.021 Article   CAS   PubMed   Google
    Scholar   Würschum T, Maurer HP, Weissmann S et al (2017) Accuracy of within-
    and among-family genomic prediction in triticale. Plant Breed 136:230–236. https://doi.org/10.1111/pbr.12465
    Article   CAS   Google Scholar   Edwards SM, Buntjer JB, Jackson R et al (2019)
    The effects of training population design on genomic prediction accuracy in wheat.
    Theor Appl Genet 132:1943–1952. https://doi.org/10.1007/s00122-019-03327-y Article   CAS   PubMed   PubMed
    Central   Google Scholar   Cobb JN, Juma RU, Biswas PS et al (2019) Enhancing
    the rate of genetic gain in public-sector plant breeding programs: lessons from
    the breeder’s equation. Theor Appl Genet 132:627–645. https://doi.org/10.1007/s00122-019-03317-0
    Article   PubMed   PubMed Central   Google Scholar   Dreisigacker S, Crossa J,
    Pérez-Rodríguez P et al (2021) Implementation of genomic selection in the cimmyt
    global wheat program, findings from the past 10 years. Crop Breed Genet Genomics
    3:e210005. https://doi.org/10.20900/cbgg20210005 Article   Google Scholar   Heffner
    EL, Lorenz AJ, Jannink J-L, Sorrells ME (2010) Plant breeding with genomic selection:
    gain per unit time and cost. Crop Sci 50:1681–1690. https://doi.org/10.2135/cropsci2009.11.0662
    Article   Google Scholar   Bernardo R (2020) Reinventing quantitative genetics
    for plant breeding: something old, something new, something borrowed, something
    BLUE. Heredity 125(6):375–385. https://doi.org/10.1038/s41437-020-0312-1 Article   PubMed   PubMed
    Central   Google Scholar   García-Ruiz A, Cole JB, VanRaden PM et al (2016) Changes
    in genetic selection differentials and generation intervals in US Holstein dairy
    cattle as a result of genomic selection. Proc Natl Acad Sci 113:E3995–E4004. https://doi.org/10.1073/pnas.1519061113
    Article   CAS   PubMed   PubMed Central   Google Scholar   Bardhan Roy SK, Pateña
    GF, Vergara BS (1982) Feasibility of selection for traits associated with cold
    tolerance in rice under rapid generation advance method. Euphytica 31:25–31. https://doi.org/10.1007/BF00028303
    Article   Google Scholar   Niizeki H, Oono K (1968) Induction of haploid rice
    plant from anther culture. Proc Jpn Acad 44:554–557. https://doi.org/10.2183/pjab1945.44.554
    Article   Google Scholar   Watson A, Ghosh S, Williams MJ et al (2018) Speed breeding
    is a powerful tool to accelerate crop research and breeding. Nat Plants 4:23–29.
    https://doi.org/10.1038/s41477-017-0083-8 Article   PubMed   Google Scholar   Yan
    G, Liu H, Wang H et al (2017) Accelerated generation of selfed pure line plants
    for gene identification and crop breeding. Front Plant Sci 8:1786. https://doi.org/10.3389/fpls.2017.01786
    Article   PubMed   PubMed Central   Google Scholar   Collard BCY, Beredo JC, Lenaerts
    B et al (2017) Revisiting rice breeding methods—evaluating the use of rapid generation
    advance (RGA) for routine rice breeding. Plant Prod Sci 20:337–352. https://doi.org/10.1080/1343943X.2017.1391705
    Article   Google Scholar   Bonnecarrere V, Rosas J, Ferraro B (2019) Economic
    impact of marker-assisted selection and rapid generation advance on breeding programs.
    Euphytica 215:197. https://doi.org/10.1007/s10681-019-2529-8 Article   Google
    Scholar   Gaynor RC, Gorjanc G, Bentley AR et al (2017) A two-part strategy for
    using genomic selection to develop inbred lines. Crop Sci 57:2372–2386. https://doi.org/10.2135/cropsci2016.09.0742
    Article   Google Scholar   Muleta KT, Pressoir G, Morris GP (2019) Optimizing
    genomic selection for a sorghum breeding program in Haiti: a simulation study.
    G3 9:391–401. https://doi.org/10.1534/g3.118.200932 Article   PubMed   Google
    Scholar   Daetwyler HD, Pong-Wong R, Villanueva B, Woolliams JA (2010) The impact
    of genetic architecture on genome-wide evaluation methods. Genetics 185:1021–1031.
    https://doi.org/10.1534/genetics.110.116855 Article   CAS   PubMed   PubMed Central   Google
    Scholar   Goddard ME, Hayes BJ, Meuwissen THE (2011) Using the genomic relationship
    matrix to predict the accuracy of genomic selection. J Anim Breed Genet 128:409–421.
    https://doi.org/10.1111/j.1439-0388.2011.00964.x Article   CAS   PubMed   Google
    Scholar   Elsen J-M (2017) An analytical framework to derive the expected precision
    of genomic selection. Genet Sel Evol 49:95. https://doi.org/10.1186/s12711-017-0366-6
    Article   PubMed   PubMed Central   Google Scholar   Norman A, Taylor J, Edwards
    J, Kuchel H (2018) Optimising genomic selection in wheat: effect of marker density,
    population size and population structure on prediction accuracy. G3 8:2889. https://doi.org/10.1534/g3.118.200311
    Article   PubMed   PubMed Central   Google Scholar   Tayeh N, Klein A, Le Paslier
    M-C et al (2015) Genomic prediction in pea: effect of marker density and training
    population size and composition on prediction accuracy. Front Plant Sci 6:941.
    https://doi.org/10.3389/fpls.2015.00941 Article   PubMed   PubMed Central   Google
    Scholar   Rincent R, Laloë D, Nicolas S et al (2012) Maximizing the reliability
    of genomic selection by optimizing the calibration set of reference individuals:
    comparison of methods in two diverse groups of maize inbreds (Zea mays L.). Genetics
    192:715–728. https://doi.org/10.1534/genetics.112.141473 Article   CAS   PubMed   PubMed
    Central   Google Scholar   Rincent R, Charcosset A, Moreau L (2017) Predicting
    genomic selection efficiency to optimize calibration set and to assess prediction
    accuracy in highly structured populations. Theor Appl Genet 130:2231–2247. https://doi.org/10.1007/s00122-017-2956-7
    Article   CAS   PubMed   PubMed Central   Google Scholar   Mangin B, Rincent R,
    Rabier C-E et al (2019) Training set optimization of genomic prediction by means
    of EthAcc. PLoS One 14:e0205629. https://doi.org/10.1371/journal.pone.0205629
    Article   CAS   PubMed   PubMed Central   Google Scholar   Pszczola M, Strabel
    T, Mulder HA, Calus MPL (2012) Reliability of direct genomic values for animals
    with different relationships within and to the reference population. J Dairy Sci
    95:389–400. https://doi.org/10.3168/jds.2011-4338 Article   CAS   PubMed   Google
    Scholar   Habier D, Tetens J, Seefried F-R et al (2010) The impact of genetic
    relationship information on genomic breeding values in German Holstein cattle.
    Genet Sel Evol 42:5. https://doi.org/10.1186/1297-9686-42-5 Article   CAS   PubMed   PubMed
    Central   Google Scholar   Lorenz AJ, Smith KP (2015) Adding genetically distant
    individuals to training populations reduces genomic prediction accuracy in barley.
    Crop Sci 55:2657–2667. https://doi.org/10.2135/cropsci2014.12.0827 Article   CAS   Google
    Scholar   Lorenz AJ (2013) Resource allocation for maximizing prediction accuracy
    and genetic gain of genomic selection in plant breeding: a simulation experiment.
    G3 3:481–491. https://doi.org/10.1534/g3.112.004911 Article   PubMed   PubMed
    Central   Google Scholar   Jarquin D, Howard R, Crossa J et al (2020) Genomic
    prediction enhanced sparse testing for multi-environment trials. G3 10:2725. https://doi.org/10.1534/g3.120.401349
    Article   CAS   PubMed   PubMed Central   Google Scholar   Grattapaglia D, Resende
    MV (2011) Genomic selection in forest tree breeding. Tree Genet Genomes 7:241–255.
    https://doi.org/10.1007/s11295-010-0328-4 Article   Google Scholar   Hickey JM,
    Dreisigacker S, Crossa J et al (2014) Evaluation of genomic selection training
    population designs and genotyping strategies in plant breeding programs using
    simulation. Crop Sci 54:1476–1488. https://doi.org/10.2135/cropsci2013.03.0195
    Article   Google Scholar   Meuwissen TH (2009) Accuracy of breeding values of
    “unrelated” individuals predicted by dense SNP genotyping. Genet Sel Evol 41:35.
    https://doi.org/10.1186/1297-9686-41-35 Article   CAS   PubMed   PubMed Central   Google
    Scholar   Mackay IJ, Caligari PDS (1999) Major errors in data and their effect
    on response to selection. Crop Sci 39:cropsci1999.0011183X003900020016x. https://doi.org/10.2135/cropsci1999.0011183X003900020016x
    Article   Google Scholar   Israel C, Weller JI (2000) Effect of misidentification
    on genetic gain and estimation of breeding value in dairy cattle populations.
    J Dairy Sci 83:181–187. https://doi.org/10.3168/jds.S0022-0302(00)74869-7 Article   CAS   PubMed   Google
    Scholar   Breseghello F, de Mello RN, Pinheiro PV et al (2021) Building the Embrapa
    rice breeding dataset for efficient data reuse. Crop Sci 61:3445–3457. https://doi.org/10.1002/csc2.20550
    Juanillas V, Dereeper A, Beaume N et al (2019) Rice galaxy: an open resource for
    plant science. GigaScience 8:giz028. https://doi.org/10.1093/gigascience/giz028
    Article   PubMed   PubMed Central   Google Scholar   Akdemir D, Isidro-Sánchez
    J (2019) Design of training populations for selective phenotyping in genomic prediction.
    Sci Rep 9:1446. https://doi.org/10.1038/s41598-018-38081-6 Article   CAS   PubMed   PubMed
    Central   Google Scholar   Ben-Sadoun S, Rincent R, Auzanneau J et al (2020) Economical
    optimization of a breeding scheme by selective phenotyping of the calibration
    set in a multi-trait context: application to bread making quality. Theor Appl
    Genet 133:2197–2212. https://doi.org/10.1007/s00122-020-03590-4 Article   CAS   PubMed   Google
    Scholar   Rasheed A, Hao Y, Xia X et al (2017) Crop breeding chips and genotyping
    platforms: progress, challenges, and perspectives. Mol Plant 10:1047–1064. https://doi.org/10.1016/j.molp.2017.06.008
    Article   CAS   PubMed   Google Scholar   Gorjanc G, Dumasy J-F, Gonen S et al
    (2017) Potential of low-coverage genotyping-by-sequencing and imputation for cost-effective
    genomic selection in biparental segregating populations. Crop Sci 57:1404–1420.
    https://doi.org/10.2135/cropsci2016.08.0675 Article   CAS   Google Scholar   Cobb
    J, Rafiqul M, Kumar Katiyar S et al (2020) The evolution of a revolution: re-designing
    green revolution breeding programs in Asia and Africa to increase rates of genetic
    gain. [W020]. PAG, public, p 9 Google Scholar   Collard BCY, Gregorio GB, Thomson
    MJ et al (2019) Transforming rice breeding: re-designing the irrigated breeding
    pipeline at the international rice research institute (IRRI). Crop Breed Genet
    Genomics 1:e190008. https://doi.org/10.20900/cbgg20190008 Article   Google Scholar   Thomson
    MJ, Singh N, Dwiyanti MS et al (2017) Large-scale deployment of a rice 6K SNP
    array for genetics and breeding applications. Rice 10:40. https://doi.org/10.1186/s12284-017-0181-2
    Article   PubMed   PubMed Central   Google Scholar   Habier D, Fernando RL, Garrick
    DJ (2013) Genomic BLUP decoded: a look into the black box of genomic prediction.
    Genetics 194:597–607. https://doi.org/10.1534/genetics.113.152207 Article   CAS   PubMed   PubMed
    Central   Google Scholar   Maruyama K (1989) Using rapid generation advance with
    single seed descent in rice breeding. International Rice Research Institute, pp
    253–259 Google Scholar   De Pauw RM, Clarke JM (1976) Acceleration of generation
    advancement in spring wheat. Euphytica 25:415–418. https://doi.org/10.1007/BF00041574
    Article   Google Scholar   McCouch S, Baute GJ, Bradeen J et al (2013) Feeding
    the future. Nature 499:23. https://doi.org/10.1038/499023a Article   CAS   PubMed   Google
    Scholar   Cowling WA (2013) Sustainable plant breeding. Plant Breed 132:1–9. https://doi.org/10.1111/pbr.12026
    Article   Google Scholar   Gorjanc G, Jenko J, Hearne SJ, Hickey JM (2016) Initiating
    maize pre-breeding programs using genomic selection to harness polygenic variation
    from landrace populations. BMC Genomics 17:30. https://doi.org/10.1186/s12864-015-2345-z
    Article   CAS   PubMed   PubMed Central   Google Scholar   Yu X, Li X, Guo T et
    al (2016) Genomic prediction contributing to a promising global strategy to turbocharge
    gene banks. Nat Plants 2:16150. https://doi.org/10.1038/nplants.2016.150 Article   CAS   PubMed   Google
    Scholar   Tanaka R, Iwata H (2018) Bayesian optimization for genomic selection:
    a method for discovering the best genotype among a large number of candidates.
    Theor Appl Genet 131:93–105. https://doi.org/10.1007/s00122-017-2988-z Article   PubMed   Google
    Scholar   Wang DR, Agosto-Pérez FJ, Chebotarov D et al (2018) An imputation platform
    to enhance integration of rice genetic resources. Nat Commun 9:3519. https://doi.org/10.1038/s41467-018-05538-1
    Article   CAS   PubMed   PubMed Central   Google Scholar   Melchinger AE, Gumber
    RK (1998) Overview of heterosis and heterotic groups in agronomic crops. In: Lamkey
    KR, Staub JE (eds) Concepts and breeding of heterosis in crop plants, vol 24.
    CSSA, Madison, WI, pp 29–44 Google Scholar   Reif JC, Melchinger AE, Xia XC et
    al (2003) Use of SSRs for establishing heterotic groups in subtropical maize.
    Theor Appl Genet 107:947–957. https://doi.org/10.1007/s00122-003-1333-x Article   CAS   PubMed   Google
    Scholar   Ouyang Y, Liu Y-G, Zhang Q (2010) Hybrid sterility in plant: stories
    from rice. Curr Opin Plant Biol 13:186–192. https://doi.org/10.1016/j.pbi.2010.01.002
    Article   PubMed   Google Scholar   Xie F, He Z, Esguerra MQ et al (2014) Determination
    of heterotic groups for tropical Indica hybrid rice germplasm. Theor Appl Genet
    127:407–417. https://doi.org/10.1007/s00122-013-2227-1 Article   Google Scholar   Beukert
    U, Li Z, Liu G et al (2017) Genome-based identification of heterotic patterns
    in rice. Rice 10:22. https://doi.org/10.1186/s12284-017-0163-4 Article   PubMed   PubMed
    Central   Google Scholar   Zhao Y, Li Z, Liu G et al (2015) Genome-based establishment
    of a high-yielding heterotic pattern for hybrid wheat breeding. Proc Natl Acad
    Sci 112:15624–15629. https://doi.org/10.1073/pnas.1514547112 Article   CAS   PubMed   PubMed
    Central   Google Scholar   Araus JL, Kefauver SC, Zaman-Allah M et al (2018) Translating
    high-throughput phenotyping into genetic gain. Trends Plant Sci 23:451–466. https://doi.org/10.1016/j.tplants.2018.02.001
    Article   CAS   PubMed   PubMed Central   Google Scholar   Araus JL, Cairns JE
    (2014) Field high-throughput phenotyping: the new crop breeding frontier. Trends
    Plant Sci 19:52–61. https://doi.org/10.1016/j.tplants.2013.09.008 Article   CAS   PubMed   Google
    Scholar   Pauli D, Chapman SC, Bart R et al (2016) The quest for understanding
    phenotypic variation via integrated approaches in the field environment. Plant
    Physiol 172:622–634. https://doi.org/10.1104/pp.16.00592 Article   CAS   PubMed   PubMed
    Central   Google Scholar   Rutkoski J, Poland J, Mondal S et al (2016) Canopy
    temperature and vegetation indices from high-throughput phenotyping improve accuracy
    of pedigree and genomic selection for grain yield in wheat. G3 6:2799–2808. https://doi.org/10.1534/g3.116.032888
    Article   PubMed   PubMed Central   Google Scholar   Juliana P, Montesinos-López
    OA, Crossa J et al (2019) Integrating genomic-enabled prediction and high-throughput
    phenotyping in breeding for climate-resilient bread wheat. Theor Appl Genet 132:177–194.
    https://doi.org/10.1007/s00122-018-3206-3 Article   CAS   PubMed   Google Scholar   Rincent
    R, Charpentier J-P, Faivre-Rampant P et al (2018) Phenomic selection is a low-cost
    and high-throughput method based on indirect predictions: proof of concept on
    wheat and poplar. G3 8(12):3961–3972. https://doi.org/10.1534/g3.118.200760 Article   CAS   PubMed   PubMed
    Central   Google Scholar   Lane HM, Murray SC, Montesinos-López OA et al (2020)
    Phenomic selection and prediction of maize grain yield from near-infrared reflectance
    spectroscopy of kernels. Plant Phenome J 3:e20002. https://doi.org/10.1002/ppj2.20002
    Article   Google Scholar   Xu Y (2016) Envirotyping for deciphering environmental
    impacts on crop plants. Theor Appl Genet 129:653–673. https://doi.org/10.1007/s00122-016-2691-5
    Article   CAS   PubMed   PubMed Central   Google Scholar   Download references
    Acknowledgments The authors are grateful to Adam Famoso and Flavio Breseghello
    for their valuable comments and comprehensive review of the chapter. We would
    also like to thank the irrigated rice team at IRRI: Rose Imee Zhella Morantte,
    Vitaliano Lopena, Holden Verdeprado, and Juan David Arbelaez for their help with
    data acquisition and management regarding the example provided on IRRI breeding
    program. We thank the IRRI Bangladesh team and, in particular, Rafiqul M. Islam
    as well as our partners in Bangladesh for their support in obtaining phenotypic
    data for the training set presented in the example. Funding The Bill and Melinda
    Gates Foundation through the Accelerated Genetic Gain in Rice (AGGRi) Alliance
    project sponsored and funded this work. Author information Authors and Affiliations
    CIRAD, UMR AGAP Institut, Montpellier, France Jérôme Bartholomé AGAP Institut,
    Univ Montpellier, CIRAD, INRAE, Montpellier SupAgro, Montpellier, France Jérôme
    Bartholomé Rice Breeding Platform, International Rice Research Institute, Manila,
    Philippines Jérôme Bartholomé & Parthiban Thathapalli Prakash RiceTec Inc, Alvin,
    TX, USA Joshua N. Cobb Corresponding author Correspondence to Jérôme Bartholomé
    . Editor information Editors and Affiliations CIRAD, UMR AGAP Institut, Montpellier,
    France Nourollah Ahmadi UMR AGAP Institut, CIRAD, Montpellier, France Jérôme Bartholomé
    1 Electronic Supplementary Material Data 1 Data from the irrigated breeding program
    provided as a real case example. IRRI_GS_data (ZIP 495 kb) Data 2 R functions
    for the genomic prediction analysis pipeline currently used at IRRI. IRRI_GS_functions
    (ZIP 10 kb) Data 3 R scripts for the genomic prediction analysis pipeline currently
    used at IRRI. IRRI_GS_script (ZIP 11 kb) Rights and permissions Open Access This
    chapter is licensed under the terms of the Creative Commons Attribution 4.0 International
    License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing,
    adaptation, distribution and reproduction in any medium or format, as long as
    you give appropriate credit to the original author(s) and the source, provide
    a link to the Creative Commons license and indicate if changes were made. The
    images or other third party material in this chapter are included in the chapter''s
    Creative Commons license, unless indicated otherwise in a credit line to the material.
    If material is not included in the chapter''s Creative Commons license and your
    intended use is not permitted by statutory regulation or exceeds the permitted
    use, you will need to obtain permission directly from the copyright holder. Reprints
    and permissions Copyright information © 2022 The Author(s) About this protocol
    Cite this protocol Bartholomé, J., Prakash, P.T., Cobb, J.N. (2022). Genomic Prediction:
    Progress and Perspectives for Rice Improvement. In: Ahmadi, N., Bartholomé, J.
    (eds) Genomic Prediction of Complex Traits. Methods in Molecular Biology, vol
    2467. Humana, New York, NY. https://doi.org/10.1007/978-1-0716-2205-6_21 Download
    citation .RIS.ENW.BIB DOI https://doi.org/10.1007/978-1-0716-2205-6_21 Published
    22 April 2022 Publisher Name Humana, New York, NY Print ISBN 978-1-0716-2204-9
    Online ISBN 978-1-0716-2205-6 eBook Packages Springer Protocols Publish with us
    Policies and ethics Sections Figures References Abstract Introduction Genomic
    Prediction Works in Rice Integration of Genomic Prediction into Rice Breeding
    Programs: Key Aspects An Example on IRRI Breeding Program for Irrigated Systems
    Other Applications of Genomic Prediction for Rice Improvement Conclusion: A Point
    of View of a Rice Breeder References Acknowledgments Author information Editor
    information Electronic Supplementary Material Rights and permissions Copyright
    information About this protocol Publish with us Discover content Journals A-Z
    Books A-Z Publish with us Publish your research Open access publishing Products
    and services Our products Librarians Societies Partners and advertisers Our imprints
    Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage
    cookies Your US state privacy rights Accessibility statement Terms and conditions
    Privacy policy Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA)
    (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature'
  inline_citation: '>'
  journal: Methods in molecular biology (Clifton, N.J.)
  limitations: '>'
  pdf_link: https://link.springer.com/content/pdf/10.1007/978-1-0716-2205-6_21.pdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'Genomic Prediction: Progress and Perspectives for Rice Improvement'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1007/978-3-030-37177-7_5
  analysis: '>'
  authors:
  - Marcel Boumans
  - Sabina Leonelli
  citation_count: 7
  full_citation: '>'
  full_text: ">\n79\nFrom Dirty Data to Tidy Facts: Clustering \nPractices in Plant\
    \ Phenomics and Business \nCycle Analysis\nMarcel Boumans and Sabina Leonelli\n\
    Abstract This chapter considers and compares the ways in which two types of data,\
    \ \neconomic observations and phenotypic data in plant science, are prepared for\
    \ use as \nevidence for claims about phenomena such as business cycles and gene-\
    \ environment \ninteractions. We focus on what we call “cleaning by clustering”\
    \ procedures, and \ninvestigate the principles underpinning this kind of cleaning.\
    \ These cases illustrate the \nepistemic significance of preparing data for use\
    \ as evidence in both the social and \nnatural sciences. At the same time, the\
    \ comparison points to differences and similarities \nbetween data cleaning practices,\
    \ which are grounded in the characteristics of the objects \nof interests as well\
    \ as the conceptual commitments, community standards and research \ntools used\
    \ by economics and plant science towards producing and validating claims.\n1 \
    \ Introduction: Preparing Big Data for Analysis\nBig data cannot be interpreted\
    \ without extensive and laborious preparation, includ-\ning various stages of\
    \ processing and ordering to make it possible for data to be dis-\nseminated and\
    \ subjected to analysis. Several chapters in this volume – including \nHalfmann’s\
    \ on sampling in oceanography, Karaca on data acquisition in particle \nphysics\
    \ and Hoeppe on sharing observations in astronomy  - stress the decisive \nimpact\
    \ that such preparation practices have on the subsequent journeys of data and\
    \ \nthe use of data as evidence for claims about phenomena. In this chapter we\
    \ discuss \nthe epistemological significance of yet another practice of data preparation:\
    \ data \ncleaning, that is the efforts involved in formatting, manipulating and\
    \ visualising \ndata so that they are sufficiently tractable to be amenable for\
    \ analysis.\nM. Boumans (*) \nUtrecht University School of Economics, Utrecht\
    \ University, Utrecht, The Netherlands\ne-mail: m.j.boumans@uu.nl \nS. Leonelli\
    \ \nDepartment of Sociology, Philosophy and Anthropology & Exeter Centre for the\
    \  \nStudy of the Life Sciences (Egenis), University of Exeter, Exeter, UK\nAlan\
    \ Turing Institute, London, UK\ne-mail: s.leonelli@exeter.ac.uk\n© The Author(s)\
    \ 2020\nS. Leonelli, N. Tempini (eds.), Data Journeys in the Sciences, \nhttps://doi.org/10.1007/978-3-030-37177-7_5\n\
    80\nThe cleaning strategies that we aim to discuss are not focused on scrubbing\
    \ and \nscraping dirt away, but rather on tidying up, sorting and ordering. In\
    \ everyday life as \nin data practices, tidying up can be done in a variety of\
    \ different ways depending on \nexisting habits and future requirements. In what\
    \ follows, we focus on two strategies \nfor tidying up data which both rely, in\
    \ different ways, on the clustering of objects \ninto groups. The first strategy\
    \ is to get rid of smudges and flecks by arranging \nobjects so that unruly bits\
    \ are less visible, and the eye is drawn to the more orderly – \ncleaner - parts\
    \ of the ensemble. We exemplify this strategy through the analysis of \ndata cleaning\
    \ practices in economics, and specifically in relation to business cycle \nanalysis,\
    \ where data consist of observations of journalists, business annals, and \nsocial\
    \ and economic statistical time-series. The second strategy is to put everything\
    \ \nin boxes and store them some place out of sight, placing labels on each box\
    \ to be \nable to retrieve its contents when needed (the more boxes and objects\
    \ one has, of \ncourse, the more complex the labels will need to be).1 We exemplify\
    \ this strategy \nthrough the analysis of data cleaning practices in biology,\
    \ and specifically the han-\ndling of phenomic data about plants, where data include\
    \ images and measurements \ndocumenting the morphology, physiology and behaviour\
    \ of organisms and their \nenvironments.\nWe compare a case from the natural sciences\
    \ (biology) with one from social sci-\nences (economics) in some detail to exemplify\
    \ the complexity of the research prac-\ntices involved, which mirrors the complexity\
    \ of the phenomena under study in both \nareas. While the conceptual commitments,\
    \ community standards and research tools \nused by economics and biology are starkly\
    \ different, in both cases data cleaning and \nsubsequent analysis involve bringing\
    \ together voluminous datasets of diverse types \nand formats, generated by a\
    \ broad range of heterogeneous sources. The projected \nvalue of these data as\
    \ evidence for scientific claims grows with aggregation: the \nmore data analysts\
    \ are able to link together and consider as a single body of evi-\ndence, the\
    \ more sophisticated and reliable the resulting insights are expected to be.\n\
    The chapter is organised as follows. In the first section, we examine the work\
    \ \nrequired to create meaningful clusters from these forms of big data, and the\
    \ extent \nto which data cleaning transforms datasets. In section two we draw\
    \ on Mary \nDouglas’s seminal analysis of dirt and impurity, in which she argued\
    \ that cleaning \nis not about removal but about ordering, to identify a common\
    \ strategy used by \nresearchers in both cases, which we call cleaning by clustering.\
    \ After discussing \nthis general approach, we note how the specific mechanisms\
    \ and tools used to enact \nthis strategy differ considerably in the two domains\
    \ of practice. In economics, \ncleaning by clustering is largely a question of\
    \ exercising visual judgement grounded \non principles similar to the Gestalt\
    \ principles, thus arranging data in ways that are \naesthetically appealing and\
    \ intuitively intelligible to the analyst. This strategy goes \na long way towards\
    \ facilitating data mining, for instance through the construction of \n1 This\
    \ approach to cleaning is heavily built on the strategies of packaging, curating\
    \ and labelling \nexplored by Leonelli (2011, 2016). Contrary to data packaging\
    \ in her previous studies, however, \ntidying up is not primarily aimed at making\
    \ data portable across contexts, but rather at making it \npossible for data to\
    \ be analysed and interpreted.\nM. Boumans and S. Leonelli\n81\ndata models that\
    \ highlight meaningful correlations and direct analysts towards spe-\ncific interpretations.\
    \ By the same token, this form of clustering is difficult to undo, \nleading to\
    \ a situation where the aesthetic criteria employed to arrange the data are \n\
    traded off with the ways in which the data could be used as evidence. In plant\
    \ phe-\nnomics, cleaning by clustering is instead guided by the attempt to define\
    \ a “land-\nscape” for the re-purposing of data: a set of conditions, in other\
    \ words, through \nwhich researchers may be able to re-use data for new goals.2\
    \ The priority in this case \nis not achieving visual intelligibility alone, but\
    \ rather the creation of data visualisa-\ntion and retrieval tools that enable\
    \ users to disaggregate data clusters when needed \nto confront new research questions.\
    \ This enables researchers to trace the origin of \nthe relevant data journeys,\
    \ and evaluate the reliability and appropriateness of every \nstep of “cleaning”\
    \ in light of novel situations of inquiry within which data may be \nre-purposed.\
    \ We are particularly interested in identifying the principles that guide \ndata\
    \ cleaning activities in these cases, and the conceptual, material and social\
    \ cir-\ncumstances within which these principles are grounded and through which\
    \ they \noriginate. To this aim, in section three we explore the relation between\
    \ data cleaning \npractices and how data are subsequently moved and used. Comparing\
    \ our two cases \npoints to significant differences between data practices, which\
    \ are grounded in the \nnature of the objects of interest as well as in the conceptual\
    \ commitments, commu-\nnity standards and research tools used by economics and\
    \ plant science towards pro-\nducing and validating claims. It also points to\
    \ the difficulties experienced by data \nanalysts in providing general principles\
    \ of cleanliness with regard to research data, \nas exemplified by the recent\
    \ debate around “tidy data” in computational data sci-\nence, which we discuss\
    \ in our closing section.\n2  Cleaning Data: Empirical Cases from Plant Science\
    \ \nand Economics\nOur starting point is a close look at two cases of “data cleaning”\
    \ taken from eco-\nnomics and plant science, respectively. The cases exemplify\
    \ some of the most \nsophisticated forms of data processing in each field, aiming\
    \ to encompass very dif-\nferent types and formats of data coming from a wide\
    \ variety of sources, which can \nonly be considered as a single body of evidence\
    \ thanks to laborious processing. The \neconomic case, concerning the generation\
    \ of quantitative facts about the business \ncycle at the National Bureau of Economic\
    \ Research in the 1940s, was selected for \ntwo reasons. On the one hand, this\
    \ post-war research at the NBER is exemplary for \nmany current practices of data\
    \ preparation in economics, and on the other hand this \npractice was described\
    \ so explicitly and in such great detail in a publication, \nMeasuring Business\
    \ Cycle (1946), that it enables and ensures insight and under-\n2 The landscape\
    \ may include data collection strategies, repositories and visualisation tools\
    \ enabling \nresearchers to retrieve, compare and analyse data coming from a variety\
    \ of sources.\nFrom Dirty Data to Tidy Facts: Clustering Practices in Plant Phenomics\
    \ and Business…\n82\nstanding of this specific clustering practice. The plant\
    \ science case, concerning the \nprocessing of phenotypic data in plant phenomics,\
    \ constitutes one of the most dis-\ncussed examples of complex data processing\
    \ in contemporary biology, with several \nongoing debates documenting the rationale\
    \ and strategies used to make data usable \nfor further analysis. Below, we focus\
    \ on the discussions surrounding the identifica-\ntion of essential data and related\
    \ standards (“minimal information”) for this kind of \nresearch.\n2.1  Empirical\
    \ Case: Measuring Business Cycles\nFounded in 1920, the National Bureau of Economic\
    \ Research (NBER) is a private, \nnon-profit, non-partisan organization dedicated\
    \ to conducting economic research \nand to disseminating research findings among\
    \ academics, public policy makers, and \nbusiness professionals.3 The object of\
    \ the NBER is “to ascertain and to present to \nthe public important economic\
    \ facts and their interpretation in a scientific and \nimpartial manner” (Burns\
    \ and Mitchell 1946, p. v). Wesley C. Mitchell, the first \ndirector of the NBER\
    \ till 1945, was well-known for his contributions to the empiri-\ncal analysis\
    \ of business cycles.4 The NBER is not a statistical office or bureau that \n\
    aims at collecting economic and social data, but instead aims to analyse existing\
    \ \neconomic and social statistics, in this case to “measure business conditions.”\
    \ These \nstatistics were data of various aspects of economic and business life\
    \ and came from \nvarious different sources. An 11 page long appendix of Measuring\
    \ Business Cycle \n(1946) list these statistics such as of industrial production,\
    \ freight, sales, milk used \nin factory production, transit rides, railway passengers\
    \ miles, wholesale prices, total \nincome payments, employment, bank debits, electric\
    \ power production, payrolls, \nbusiness failures, from organisations such as\
    \ Federal Reserve, Interstate Commerce \nCommission, Bureau of Foreign and Domestic\
    \ Commerce, Railroad Companies, \nBureau of Labor Statistics, Chicago Board of\
    \ Trade, and Bureau of Foreign and \nDomestic Commerce.\nThe book Measuring Business\
    \ Cycles (1946) was the result of 20 years of empir-\nical business studies at\
    \ the Bureau under the supervision of Mitchell. The aim was \nto identify and\
    \ establish facts about the business cycles, which could be used to test \nexisting\
    \ business cycle theories. Burns and Mitchell stated that theoretical work on\
    \ \nbusiness cycles was “often highly suggestive; yet rest so much upon simplifying\
    \ \nassumptions and is so imperfectly tested for conformity to experience that,\
    \ for our \npurposes, the conclusions must serve mainly as hypotheses” (p. 4).\
    \ At the same \ntime, they observed that “satisfactory tests cannot be made unless\
    \ hypotheses have \nbeen framed with an eye to testing, and unless, observations\
    \ upon many economic \n3 See the NBER website, http://www.nber.org\n4 See Morgan\
    \ 1990, pp.  44–56, for a more detailed background of the NBER and Mitchell’s\
    \ \napproach.\nM. Boumans and S. Leonelli\n83\nactivities have been made in a\
    \ uniform manner” (p. 4). Although theories were seen \nas “incomplete in coverage”\
    \ and “highly suggestive,” they were not “put aside” but \nused “as hypotheses\
    \ concerning what activities and what relations among them are \nworth studying.\
    \ In that way they will be of inestimable value in his factual inqui-\nries” (p. 10).\
    \ Hence the point of departure for data analysis was not a theory of the \nbusiness\
    \ cycle but a very general definition covering commonly accepted character-\n\
    istics of the business cycles:\nBusiness cycles are a type of fluctuation found\
    \ in the aggregate economic activity of nations \nthat organize their work mainly\
    \ in business enterprises: a cycle consists of expansions \noccurring at about\
    \ the same time in many economic activities, followed by similarly general \n\
    recessions, contractions, and revivals which merge into the expansion phase of\
    \ the next \ncycle; this sequence of changes is recurrent but not periodic; in\
    \ duration business cycles \nvary from more than one year to ten or twelve years;\
    \ they are not divisible into shorter \ncycles of similar character with amplitudes\
    \ approximating their own. (Burns and Mitchell \n1946, p. 3)\nThis working definition\
    \ was supposed to list the observable characteristics of a \n“distinct species\
    \ of economic phenomena” (p. 3), that is the business cycle. This \ndefinition\
    \ focused on what should be measured, such as the average duration of the \ncycle.\
    \ To achieve this aim, all kinds of questions raised by this definition had first\
    \ to \nbe answered.5\nTo understand which principles of clustering were used in\
    \ this case of business \ncycle measurement, we need to have a closer look at\
    \ the four implicit assumptions \nmade within this definition. The first assumption\
    \ is that the cyclical turns of differ-\nent processes are concentrated around\
    \ certain points in time. The second assump-\ntion is that the business cycle\
    \ is not a periodic but a recurrent process, a “regularity” \nthat is different\
    \ from “seasonal variations, random change, and secular trends” \n(p. 6). Another\
    \ assumption of the definition is that business cycles run in a continu-\nous\
    \ round, “no intervals are admitted between one phase and its successor, or \n\
    between the end of one cycle and the beginning of the next” (p. 7). And the last\
    \ \nassumption is the duration of the cycle, somewhere between 1  year and 10\
    \ or \n12 years.\nThe main problem for analysts is that business indexes and time\
    \ series do not \nshow “cyclical patterns” that are “sweeping smoothly upward\
    \ from depressions to a \nsingle peak of prosperity and the declining steadily\
    \ to a new trough” (p. 7), and so \na business cycle has to be identified from\
    \ an irregular process, where the movements \nare interrupted by others in the\
    \ opposite direction, and where one may see double or \ntriple peaks and troughs.\
    \ What therefore is needed are criteria to identify the char-\nacteristics of\
    \ the business cycles, such as “what reversals in direction mark the end \nof\
    \ a cyclical phase” (p. 8). Crucial to our analysis is the fact that such criteria\
    \ cannot \nbe derived from any (business cycle) theory,6 but rather they relate\
    \ to aesthetic \n5 Such as, for instance: How large or small does a nation have\
    \ to be to have a business cycle, or is \nit an international phenomenon? How\
    \ far back in time can business cycles be traced? What is the \nmost appropriate\
    \ level of aggregation? Which economic activities should be included?\n6 See Bogen\
    \ and Woodward (1988) for a similar, more general claim about the incompleteness\
    \ of \ntheories in this respect.\nFrom Dirty Data to Tidy Facts: Clustering Practices\
    \ in Plant Phenomics and Business…\n84\njudgements based on visual displays of\
    \ the data. In other words, certain smooth and \nsimple shapes turn out to be\
    \ used as tools to process and visualise the data. The \napproach is based on\
    \ pattern recognition, described by Burns and Mitchell (1946, \np. 8n) as “the\
    \ source of all true knowledge”, but nevertheless it is required to be as \nobjective\
    \ as possible. Indeed, these criteria are presented as “a ‘brake’ on an inves-\n\
    tigator’s pattern sense which […] may lead to mischievous fictions” (p. 8n).\n\
    Burns and Mitchell emphasized that the cyclical pattern can be seen “only by the\
    \ \neye of the mind” (p. 12). “What we literally observe is not a congeries of\
    \ economic \nactivities rising and falling in unison, but changes in readings\
    \ taken from many \nrecording instruments of varying reliability” (p. 14). To\
    \ “see” the business cycle “in \nthe mind’s eye,” these recordings have “to be\
    \ decomposed for our purposes; then \none set of components must be put together\
    \ in a new fashion” (p. 14).\nWe conceive business cycles to consist of roughly\
    \ synchronous movements in many activi-\nties. To determine whether this thought\
    \ symbol represents experience or fantasy, our mea-\nsures of the cyclical behavior\
    \ characteristics of many activities must be assembled into the \nend products\
    \ of which our definition is the blueprint. In statistical jargon, time-series\
    \ analy-\nsis must be followed by a time-series synthesis. (Burns and Mitchell\
    \ 1946, p. 17)\nThe idea is the decomposition of the time series into cyclical,\
    \ secular, seasonal \nand random movements, but the “isolation of cyclical fluctuations”\
    \ was considered \nto be a “highly uncertain operation” (p. 37), particularly\
    \ if it is done in a “mechani-\ncal manner”. The components cannot be segregated\
    \ without considerable testing \nand experimenting by skilled technicians. “There\
    \ is always danger that the statisti-\ncal operations performed on the original\
    \ data may lead an investigator to bury real \nproblems and worry about false\
    \ ones” (p. 38).7\nMost of the analysis was in the determination of cyclical timing.\
    \ It had become \nclear that the data needed to be adjusted for – i.e., cleaned\
    \ from – seasonal variations \n“to be more useful in explaining business cycles\
    \ than would measures made from \nhighly fabricated data” (p. 43). We therefore\
    \ briefly focus on this aspect of the busi-\nness cycle analysis, to show how\
    \ much it was a combination of “hunch and judg-\nment” (p. 44) and mechanical\
    \ methods, which results were evaluated based on their \nvisual displays.\nTwo\
    \ methods were used, one consisted in taking averages of the original figures\
    \ \nfor each months, which were adjusted for secular trend; and the other entailed\
    \ tak-\ning a 12-month moving average of the original figures, placing each average\
    \ in the \nseventh month of shifting 12-month intervals. The rationale for both\
    \ methods are \nthe assumptions that “random components of a series [will] cancel\
    \ one another” and \nthat “the process of averaging will tend also to make the\
    \ cyclical component of a \nseries sum to zero” (p. 47).\nWhen the data was adjusted\
    \ for seasonal variations, the next problem was the \ndating of cyclical fluctuations.\
    \ Therefore the data was plotted upon a semi-logarith-\n7 See Boumans 2015 for\
    \ a more detailed account of measurement, which sees measurement as a \nconsidered\
    \ balance between mechanical objectivity and expert judgement.\nM. Boumans and\
    \ S. Leonelli\n85\nmic chart (typically about 7 feet long) such that the whole\
    \ record was studied in this \ngraphic form. As far as possible the scales were\
    \ kept uniform.\nThe basic criterion for distinguishing the three types of movements,\
    \ that is the \ncyclical, secular and erratic movements, was their duration. Secular\
    \ trends were \nconceived as drifts that persist in a given direction for a few\
    \ decades. Erratic move-\nments, the “saw-tooth contour” (p. 57) were supposed\
    \ to cover no longer than a few \nmonths. But even with this basic criterion,\
    \ the judgments were often difficult:\nWhen specific cycles are made doubtful\
    \ by random movements, we smooth the data by \nmoving averages and base judgments\
    \ upon the curve of moving averages. When the secular \ntrend rises sharply, we\
    \ allow brief and mild declines to count as contractions of specific \ncycles.\
    \ Similarly, when the secular trend falls sharply, brief and mild rises are counted\
    \ a \nspecific-cycle expansions. (Burns and Mitchell 1946, p. 57)\nOnce the cycles\
    \ had been distinguished the NBER researchers proceeded with \nthe dating of the\
    \ turning points. The idea is to take the highest and lowest points of \nthe plotted\
    \ curves as the dates of the cyclical turns. But often it is not clear to decide\
    \ \nwhich points these are, for example when erratic movements are prominent in\
    \ the \nvicinity of a cyclical turn. Then all kinds of checks or averages have\
    \ to be consid-\nered to arrive at a determination.\nOur methods of determining\
    \ specific cycles make no pretensions to elegance. Since no fast \nline separates\
    \ erratic or episodic movements from specific cycles, or erratic turns from \n\
    cyclical turns, there is ample opportunity for vagaries of judgment. At times\
    \ our rules fail to \nyield a clear-cut decision. At times the members of our\
    \ statistical staff disagree in their \nefforts to apply the rules to a given\
    \ series. Our experience indicates that this difficulty can-\nnot be removed by\
    \ multiplying rules. (Burns and Mitchell 1946, p. 64)\nThe judgment is instead\
    \ based on a consensus of three persons who have worked \nindependently on marking\
    \ off the cycle. Once arrived at this consensus, the whole \nprocess is audited\
    \ by an “experienced member of the staff” (p. 64) (Fig. 1).\n2.2  Empirical Case:\
    \ Processing and Interoperability \nRequirements for Imaging Data in Plant Phenomics\n\
    Plant phenotyping involves analysing plant trait data with the aim to study develop-\n\
    ment and gene-environment interactions. It emerged in the 1960s with an initial\
    \ \nemphasis on quantitative analysis, which was later broadened to imaging data\
    \ \nobtained via high-throughput experiments performed in fields, glasshouses,\
    \ and/or \nlaboratories. Such imaging data, and the accompanying observations\
    \ about the con-\nditions under which the images were obtained, now constitute\
    \ the most coveted type \nof data in this field, with increasingly sophisticated\
    \ tools being developed for their \nvisualisation and automated analysis. This\
    \ shift of emphasis on complex data for-\nmats proceeded in parallel to the broadening\
    \ of the term “phenotyping” to include \nany type of morphological variability\
    \ within organisms, thus encompassing not \nonly the immediately visible features\
    \ of organisms, but also (1) features of tissues, \nFrom Dirty Data to Tidy Facts:\
    \ Clustering Practices in Plant Phenomics and Business…\n86\nFig. 1 Example chart\
    \ of a time series in its original shape and after it has been adjusted for sea-\n\
    sonal variation. The adjustment is supposed to facilitate dating of turning points,\
    \ indicated by the \nasterisks. (Source: Burns and Mitchell 1946, p. 60, Chart\
    \ 4)\nproteins, metabolic pathways and other aspects only accessible through intervention\
    \ \nand specialised imaging techniques; and (2) the ways in which such features\
    \ vary \nacross environments that range from laboratories to glasshouses, field\
    \ trials and the \n“wild” – which involves collecting data on the soil, climate,\
    \ other organisms and \nmicrobiome with which plants interact. In the words of\
    \ prominent contributors to \nthe field, phenotyping – also called “phenomics” –\
    \ “broadened its focus from the \ninitial characterization of single-plant traits\
    \ in controlled conditions towards ‘real-\nlife’ applications of robust field\
    \ techniques in plant plots and canopies” (Walter \net al. 2015). Importantly\
    \ for our analysis, this shift in the conceptualisation of phe-\nnotypic traits\
    \ made them much less obviously identifiable as concrete descriptors. \nCollecting\
    \ data about the size of a leaf or the structure of a metabolic pathway is not\
    \ \nsimply a matter of observation, but rather is informed by a rich conceptual\
    \ apparatus \ndefining what counts as leaf surface and metabolism. Thus, just\
    \ as much as business \ncycles are no pure theoretical constructs, phenotypes\
    \ are no ‘brute facts’ about the \nworld: in both cases, empirical and theoretical\
    \ considerations remain firmly inter-\ntwined, and affect researchers’ approach\
    \ to data processing and interpretation.\nA key component of contemporary phenomics,\
    \ and the reason why it is regarded \nas generating knowledge that can underpin\
    \ and guide agricultural production, is a \nholistic characterisation of plant\
    \ performance, which involves the employment of \nseveral investigative methods\
    \ and the generation and analysis of a wide variety of \ndata types. These include,\
    \ for instance, multispectral and thermographic imaging of \nplant growth, which\
    \ is often carried out within so-called “smart glasshouses” in an \nautomated\
    \ fashion (by robots or conveyor belts that transport the plants to various \n\
    imaging chambers, multiple times per day, over an extended period of time). \n\
    M. Boumans and S. Leonelli\n87\nPhotographs and measurements are produced that\
    \ document how plants develop, \nhow their leaves and roots change, and how they\
    \ respond to external stimuli.\nCleaning such images for analysis involves judgements\
    \ around the quality and \nresolution of the photograph, the lighting and background\
    \ conditions, the position \nin which plants have been captured and the extent\
    \ and clarity to which relevant \nleaves and roots show in the picture. The quantity\
    \ of images generated through any \none experiment makes it hard for researchers\
    \ to do such work manually, and yet it \nis hard to fully automate due to the\
    \ large amount of know-how and theoretical com-\nmitments involved in judging\
    \ image quality – encompassing familiarity with the \nplants and their full life-cycle,\
    \ expectations around how plants may respond to envi-\nronmental conditions, existing\
    \ conceptualisations of plant development and growth, \nand assumptions around\
    \ which environmental and morphological elements need to \nbe valued and prioritised\
    \ over others.\nAnother popular type of phenomic data is acquired through top-view\
    \ imaging of \nthe plant canopy in the field, which can be performed by humans\
    \ in helicopters, \nrobots or remote-controlled drones. These photographs can\
    \ be analysed to measure \nleaf greenness, via tools such as the Normalised Difference\
    \ Vegetation Index, or \nplant biomass and growth in the area under scrutiny.\
    \ Again, while some basic \nparameters can be established for what counts as a\
    \ “bad image” and which elements \nof each image may be classified as “noise”,\
    \ cleaning such images involves expert \nassessment based on detailed knowledge\
    \ of the characteristics and patterns of \ngrowth of the plants at hand. An example\
    \ (Fig. 2) is an imaging study of soy-bean \nfields to determine patterns of growth,\
    \ in which researchers prepare images for fur-\nther analysis (in their own words,\
    \ “classify” the images) through models that are \nmanually trained at every step\
    \ to respond to the traits of interest in the beans (Xavier \net al. 2017).\n\
    Given the sensitivity of phenomic studies to local conditions and the conceptual\
    \ \npreferences and know-how of specific researchers, consensus around how to\
    \ clean \ndata is hard to achieve. Nevertheless, such consensus is highly valued\
    \ and sought \nfor, as it enables researchers to compare results obtained across\
    \ species, field types \nand environmental conditions. One attempt towards establishing\
    \ general standards \nfor data collection and processing is the Minimal Information\
    \ About Plant \nPhenotypic Experiments, or MIAPPE. MIAPPE is part of a broader\
    \ set of “minimal \ninformation about data” movement now recognized and coordinated\
    \ by the FAIR \nsharing international initiative for reusable data curation.8\
    \ This is an attempt to stan-\ndardize the practices and variables required to\
    \ tidy up data formatting and analysis \nenough to make data searchable, visualisable\
    \ and retrievable through digital means. \nThe idea of “minimal” information is\
    \ meant to foster an evaluation of which contex-\ntual information is most important\
    \ to data interpretation, resulting in as small a set \n8 See https://fairsharing.org/collection/MIBBI.\
    \ Among the first incarnations of the movement, and \nnow highly successful standards\
    \ in their own right, were the Minimal Information About a \nMicroarray Experiment,\
    \ or MIAME (Rogers and Cambrosio 2007) and the Minimal Information \nfor Biological\
    \ and Biomedical Investigations, or MIBBI (http://www.nature.com/nbt/journal/v26/\n\
    n8/full/nbt.1411.html)\nFrom Dirty Data to Tidy Facts: Clustering Practices in Plant\
    \ Phenomics and Business…\n88\nFig. 2 Example imagery of a single plot of soy-bean\
    \ canopy, used to calculate a percentage can-\nopy coverage on a given sampling\
    \ date. (a, b) From aerial (above; a) or ground (below; b) plat-\nforms, with\
    \ raw (left) and classified (right) imagery. (Source: http://www.genetics.org/\n\
    content/206/2/1081)\nas possible of metadata that researchers view as essential\
    \ to phenotypic data reuse. \nSomewhat paradoxically, within MIAPPE this aspiration\
    \ towards minimal informa-\ntion is accompanied by the wish to lose as little\
    \ information as possible about the \noriginal format of the data, the circumstances\
    \ under which they were generated, and \nthe ways in which they were processed\
    \ since. This is because the specificity of the \nprovenance and formatting of\
    \ data in each case is regarded as highly valuable by the \nplant scientists using\
    \ such data for their own research, a requirement that research-\ners and engineers\
    \ involved in the development of MIAPPE take seriously: “We had \nto allow for\
    \ differences that occur between particular types of plant experiments, \ne.g.\
    \ performed in different growth facilities. This is reflected in a varying set\
    \ of \nattributes recommended in MIAPPE” (Ćwiek-Kupczyńska et al. 2016). Indeed,\
    \ the \nM. Boumans and S. Leonelli\n89\nlist of attributes to be reported to MIAPPE\
    \ involves over 80 items, which can extend \nto over a hundred depending on the\
    \ field conditions. The basic categories are them-\nselves relatively broad, encompassing\
    \ general metadata, timing and location, bio-\nsources, environment, treatments,\
    \ experimental design, observed variables and as \nmuch information as possible\
    \ on sample collection, processing and management – a \nfar cry from the minimalism\
    \ that the MIAPPE criteria were expected to exemplify.\nIt is useful to consider\
    \ a couple of the simplest examples from this list. Take for \ninstance the item\
    \ “location and timing of an experiment”. Here MIAPPE developers \nnote that “depending\
    \ on the nature of the study and scientific objectives, different \ninitial time\
    \ points might be crucial—sowing date or transfer date, treatment applica-\ntion\
    \ time, etc. The duration of particular stages is also important.” (Ćwiek-\nKupczyńska\
    \ et al. 2016, p. 3). Thus, even a relatively straightforward measure such \n\
    as the time of the experiment turns out to be a complex and context-dependent\
    \ issue, \nfor which it is hard to establish any hard and fast boundaries to ensure\
    \ comparability \nacross different experiments.9 Another example is item “biosource” –\
    \ that is, the \nidentification of the plant material at hand. Here MIAPPE recommends\
    \ using at \nleast two attributes, one consisting of the species name as in standard\
    \ taxonomic \nclassifications, and the other consisting of the “infraspecific”\
    \ name, pointing to the \nspecific variant, accession or line in question. Complications\
    \ arise due to the types \nand history of the plant materials at hand. While the\
    \ taxonomy of plant species is, \nthough controversial, subject to international\
    \ standards, the identification and clas-\nsification of sub-species variants\
    \ is highly decentralised and context-dependent, \nwith no overarching agreement\
    \ around classification and often not even a clear \nawareness of the differences\
    \ between local systems. For example the varieties of the \nplant Manihot esculenta,\
    \ whose root cassava is a key crop in West Africa and South \nAmerica, are often\
    \ defined by the different ways in which local breeders value spe-\ncific traits\
    \ (like the humidity and colour of the root) when processing the plant for \n\
    food production. Aware of this fact, the authors point to the importance of referenc-\n\
    ing any “public collection of names”, and/or a specific experimental station or\
    \ gene-\nbank in which the variant may be stored and or the seeds may have been\
    \ sourced, \nand to which they can be physically traced. There are international\
    \ identification \nsystems for crops of commercial interest, such as the FAO/Bioversity\
    \ Multi-Crop \nPassport Descriptors, but these do not cover all possible variants.\
    \ The ways in which \ndata about specific attributes are structured in MIAPPE\
    \ conform to the ISA-Tab \nstandards for data ordering, which is widely adopted\
    \ in biology and looks as follows \n(Table 1).\nThis table aims to impose a clear\
    \ conceptual ordering of the data, resulting in \ntheir presentation in a format\
    \ and structure that is amenable to computational analy-\nsis. At the same time,\
    \ the application of the ISA-Tab standard to the specific case of \nphenotyping\
    \ is complex, as demonstrated by challenges encountered in developing \nthe so-called\
    \ “ISA-Tab Phenotyping Configuration”. This consists of a standard \nInvestigation\
    \ file, a Phenotyping Assay file describing phenotypic procedures and \nobserved\
    \ variables (according to the dozens of attributes identified by MIAPPE, \n9 See\
    \ Leonelli (2018) for an analysis of data time and its significance particularly\
    \ within \nexperiments.\nFrom Dirty Data to Tidy Facts: Clustering Practices in Plant\
    \ Phenomics and Business…\n90\nTable 1 The structure of an ISA-Tab dataset\nSource:\
    \ Ćwiek-Kupczyńska et al. (2016)\nsuch as location and biosources), and three\
    \ versions of a Study file: one called \n“basic study” and consisting of a default\
    \ general description of all plant experi-\nments, which needs to be extended\
    \ by added recommended MIAPPE attributes as \napplicable to the specific case10;\
    \ and two extensions called “field” and “greenhouse” \nstudies, featuring specific\
    \ attributes for growth facilities and environmental infor-\nmation (Ćwiek-Kupczyńska\
    \ et al. 2016, p. 8) (Table 2).\nNotably, despite the drive towards comparability,\
    \ MIAPPE emphasizes the need \nto capture any data format in use within the relevant\
    \ scientific communities, rather \nthan attempting to impose overarching standards\
    \ on the ways in which data are \nproduced: “in our implementation of MIAPPE,\
    \ we do not restrict the format of the \nraw data in any way; it can be any custom,\
    \ platform- or device- specific format, \nincluding texts, images, binary data,\
    \ etc.” (Ćwiek-Kupczyńska et al. 2016, p. 11). At \nthe same time, MIAPPE requires\
    \ that information about data provenance (metadata) \nis reported in ways that\
    \ are comprehensive and retrievable by later data users. The \nmost stringent\
    \ MIAPPE instructions concern how to organize and display such \nmetadata:\nIf\
    \ there is no description, the Derived Data File should be a standard, plain tab-separated\
    \ \nsample-by-variable matrix. Its first column should contain (in the simplest\
    \ situation) values \nfrom the Assay Name column in the Assay file, and the rest\
    \ of the columns provide values \nfor all variables. The names of those columns\
    \ should correspond to the values in the Variable \n10 In practice, it can be\
    \ also used when very little is known about the origin of observations, e.g. for\
    \ \nsimple, external or legacy phenotypic datasets that should be formatted as\
    \ ISA-Tab, without the \nambition to satisfy the MIAPPE recommendations.\nM. Boumans\
    \ and S. Leonelli\n91\nTable 2 Illustration of what the basic ISA-TAB fields correspond\
    \ to when implemented by plant \nscientists in the field and in the greenhouse,\
    \ respectively\nBasic\nField\nGreenhouse\nSource name\nSource name\nSource name\n\
    Characteristics[organism]\nCharacteristics[organism]\nCharacteristics[organism]\n\
    Characteristics[Infraspecific \nname]\nCharacteristics[Infraspecific \nname]\n\
    Characteristics[Infraspecific name]\nCharacteristics[seed origin]\nCharacteristics[seed\
    \ origin]\nCharacteristics[seed origin]\nCharacteristics[study start]\nCharacteristics[study\
    \ start]\nCharacteristics[study start]\nCharacteristics[study \nduration]\nCharacteristics[study\
    \ \nduration\nCharacteristics[study duration\nCharacteristics[growth \nfacility]\n\
    Characteristics[growth \nfacility]\nCharacteristics[growth facility]\nCharacteristics[geographic\
    \ \nlocation]\nCharacteristics[geographic \nlocation]\nCharacteristics[geographic\
    \ location]\nProtocol REF[rooting]\nProtocol REF[rooting]\n Parameter value[rooting\
    \ \nmedium]\n Parameter value[rooting medium]\n Parameter value[container type]\n\
    \ Parameter value[container \nvolume]\n Parameter value[plot size]\n Parameter\
    \ value[container \ndimension]\n Unit\n Unit\n Parameter value[sowing \ndensity]\n\
    \ Parameter value[number of plants \nper container]\n Parameter value[pH]\n Parameter\
    \ value[pH]\nProtocol REF[aerial \nconditions]\nProtocol REF[aerial conditions]\n\
    \ Parameter value[air \nhumidity]\n Parameter value[air humidity]\n Parameter\
    \ value[daily \nphoton flux]\n Parameter value[daily photon flux]\n Parameter\
    \ value[length of \nlight period]\n Parameter value[length of light \nperiod]\n\
    \ Parameter value[day \ntemperature]\n Parameter value[day temperature]\n Parameter\
    \ value[night \ntemperature]\n Parameter value[night \ntemperature]\nProtocol\
    \ REF[nutrition]\nProtocol REF[nutrition]\n Parameter value[N before \nfertilisation]\n\
    \ Parameter value[N before \nfertilisation]\n Parameter value[type of \nfertiliser]\n\
    \ Parameter value[type of fertiliser]\n Parameter value[amount of \nfertiliser]\n\
    \ Parameter value[amount of \nfertiliser]\n(continued)\nFrom Dirty Data to Tidy\
    \ Facts: Clustering Practices in Plant Phenomics and Business…\n \n \n \n \n \n\
    \ \n \n \n92 \nM. Boumans and S. Leonelli \nTable 2 (continued) \nBasic \nField\
    \ \nGreenhouse \nProtocol REF[watering] \nProtocol REF[watering] \nParameter value[irrigation\
    \ \ntype] \nParameter value[irrigation type] \nParameter value[volume] \nParameter\
    \ value[volume] \nParameter \nvalue[frequency] \nParameter value[frequency] \n\
    Protocol REF[sampling] \nProtocol REF[sampling] \nParameter \nvalue[experimental\
    \ unit] \nParameter value[experimental \nunit] \nSample name \nSample name \n\
    Sample name \nSource: Ćwiek-Kupczyńska et al. (2016) \nID column in the Trait\
    \ Defnition File […]. So, a default derived data format is an “Assay \nName ×\
    \ Variable” matrix of observations, that can be quantitative or qualitative. An\
    \ exten-\nsion of the above rule governing the format of the Derived Data File\
    \ is possible by using \nvalues from another “data node” column (e.g. Source Name,\
    \ Sample Name, Extract Name, \netc.) as unique identifers of the rows in the table\
    \ with the associated observations. (Ćwiek-\nKupczyńska et al. 2016, p. 12) \n\
    This is because such ordering is what enables researchers to initiate \ncomparisons:\
    \ \nwe can provide separate data fles with measurements taken for different observational\
    \ \nunits, e.g., morphological traits like “height” and “number of leaves” can\
    \ be assigned to the \nwhole plant, whereas physiological traits can be restricted\
    \ to samples taken from particular \nleaf of a plant. Also conveying data aggregated\
    \ over “data nodes” is possible in this way. \n(Ćwiek-Kupczyńska et al. 2016,\
    \ p. 12) \nDespite the attention placed by MIAPPE developers on the variability\
    \ and con-\ntextuality of data and related preparation procedures, applying MIAPPE\
    \ criteria to \nthe processing of data in the feld remains a big challenge. As\
    \ a concrete example, \nwe take the data processing performed at a leading station\
    \ for the collection of phe-\nnomics data in the UK. The North Wyke Farm Platform\
    \ is a research facility built \naround a working farm in Devon, in which researchers\
    \ can study the interactions \nbetween climate, soil, animals, plants and microbiota\
    \ in as close a setting as possi-\nble to real farming. The whole area is full\
    \ of sensors and measurement devices, \nwhich collect data at regular intervals\
    \ (15 minutes) about a variety of aspects of the \nfarm: temperature, soil composition,\
    \ humidity and rainfall, etc. The sensors are cali-\nbrated and checked in 15\
    \ huts (“monitoring cabins”) positioned around the felds, \nand the data produced\
    \ is sent wirelessly to the central computing facility based in \nthe manor house,\
    \ where researchers proceed to prepare the data, cluster them and \nstore/disseminate\
    \ them through a database. There are also three meteorological sta-\ntions that\
    \ move around the felds. An important activity besides collecting numeri-\ncal\
    \ measurements is the collection of samples (of soil, air, water, insects and\
    \ plants), \n93\nwhich are acquired manually (e.g. manual sampling device for\
    \ soil), prepared and \nstored in fridges at various temperatures).11\nResearchers\
    \ interviewed12 in North Wyke have stressed that the data collected by \nthe Farm\
    \ Platform are not yet being interpreted: this will only be possible when \nenough\
    \ longitudinal data are collected over the course of the next few years.13 This\
    \ \nmakes the task of data cleaning ever more important, since the researchers’\
    \ main \ntask at the moment is to make sure that the data collected is reliable\
    \ and clustered \nand displayed in ways that will facilitate further analysis,\
    \ and prove informative for \ninterested farmers. Cleaning the data means first\
    \ of all making them comparable and \nconsistent with other datasets generated\
    \ within the Farm, an arduous task given the \nvariety of measurements taken and\
    \ images collected. Equally important is to make \nsure that such data would be\
    \ comparable and consistent with other phenomics data \nfrom outside North Wyke.\
    \ While researchers attempt to follow criteria similar to \nthose formulated by\
    \ MIAPPE, the variability in the interpretation of the attributes \nand values\
    \ is a serious threat to automated mining and comparison among the data. \nResearchers\
    \ aim to enable analysis in the future, but caution against any automated \nsearch.\
    \ They also emphasize how the power of this evidence is in the meta-data, the\
    \ \ninformation that enables researchers to contextualize the findings and evaluate\
    \ their \nsignificance in relation to findings from other locations enacting different\
    \ epistemic \ncultures and methods.\n3  Cleaning by Clustering: The Principles\
    \ Underpinning \nData Cleaning Practices\nRenowned anthropologist Mary Douglas\
    \ provided an important argument for under-\nstanding the process of cleaning\
    \ as being not about removal, but about ordering. \nAccording to Douglas (2002),\
    \ dirt is essentially disorder: “There is no such thing as \nabsolute dirt: it\
    \ exists in the eye of the beholder. […] Dirt offends against order. \nEliminating\
    \ it is not a negative movement, but a positive effort to organize the envi-\n\
    11 The facility attracts researchers from different communities and disciplines\
    \ seeking to develop \nsustainable agriculture and ruminant production systems\
    \ http://www.nature.com/news/agriculture-\nsteps-to-sustainable-livestock-1.14796.\
    \ It is the only currently functioning facility of its kind \nworld-wide, and\
    \ the Global Farm Platform http://www.globalfarmplatform.org/ was born to \nattempt\
    \ to export this model and initiate similar sites elsewhere.\n12 Interviews were\
    \ carried out by Leonelli in January 2016. A subset of the interviews, which inter-\n\
    viewees consented to release in an open access format, is available here: https://zenodo.org/com-\n\
    munities/datastudies/?page=1&size=20\n13 North Wyke researchers are also conducting\
    \ short-term studies in which the data are used as \nevidence for claims about\
    \ phenomena. Examples include research on replacing nitrogen as fertil-\nizer,\
    \ the use of plants to manage soil and water during floods, shifts in soil biota\
    \ as land use \nchanges, and the modelling of grassland production systems. At\
    \ the same time, researchers only \ntake up research that will not “distort” on-going,\
    \ long-term data collection by forcing them to \n“clean” data with too narrow\
    \ a set of epistemic goals in mind.\nFrom Dirty Data to Tidy Facts: Clustering\
    \ Practices in Plant Phenomics and Business…\n94\nronment” (p. 2). In chasing\
    \ dirt when tidying we are “positively re-ordering our \nenvironment, making it\
    \ conform to an idea […] it is a creative moment, an attempt \nto relate form\
    \ to function, to make unity of experience” (p. 3). Douglas emphasizes \nthat\
    \ the identification of dirt should not be considered as a unique, isolated event.\
    \ \n“Where there is dirt there is system. Dirt is the by-product of a systematic\
    \ ordering \nand classification of matter, in so far as ordering involves rejecting\
    \ inappropriate \nelements” (p. 44). Cleaning is the reaction which condemns any\
    \ object or idea likely \nto confuse or contradict cherished classifications,\
    \ thus “reducing dissonance” \n(Douglas 2002, p. 340). Thus cleaning is part of\
    \ the epistemological activity of \nsystematization, such as ordering and classification.\
    \ Douglas distinguishes two \nphases to such systematization practices:\nIn the\
    \ course of any imposing of order, the attitude to rejecting bits and pieces of\
    \ dirt goes \nthrough two stages. First they are recognisably out of place, a\
    \ threat to good order, and so \nare regarded as objectionable and vigorously\
    \ brushed away. At this stage they have some \nidentity: they can be seen to be\
    \ unwanted bits of whatever it was they came from, hair or \nfood or wrappings.\
    \ This is the stage at which they are dangerous; their half-identity still \n\
    clings to them and the clarity of the scene in which they obtrude is impaired\
    \ by their pres-\nence. But a long process of pulverizing, dissolving and rotting\
    \ awaits any physical things \nthat have been recognized as dirt. In the end,\
    \ all identity is gone. The origin of the various \nbits and pieces is lost and\
    \ they have entered into the mass of common rubbish. It is unpleas-\nant to poke\
    \ about in the refuse to try to recover anything, for this revives identity. So\
    \ long \nas identity is absent, rubbish is not dangerous. It does not even create\
    \ ambiguous percep-\ntions since it clearly belongs in a defined place, a rubbish\
    \ heap of one kind or another. \n(Douglas 2002, pp. 197-8)\nThe stage of total\
    \ disintegration is the stage in which dirt has become undifferen-\ntiated. Then\
    \ a cycle has been completed, resulting in an order that is either continu-\n\
    ous with what was there before the cleaning or created by the process of cleaning\
    \ itself.\nDrawing on Douglas’s analysis, we argue that in both of our cases researchers\
    \ \nadopt the same broad strategy for data cleaning: they clean by clustering.\
    \ Cleaning \nis a way to impose order and intelligibility on a dataset, by identifying\
    \ categories \nand typologies for classification, models and algorithms through\
    \ which data can be \nfiltered and selected, and/or tools through which data can\
    \ be displayed and organ-\nised so as to enable further analysis and interpretation.\n\
    The specific mechanisms and tools used to enact this strategy, however, differ\
    \ \nconsiderably across our cases, revealing a divergence in the heuristic principles\
    \ \nused to guide and motivate the cleaning strategies, and the extent to which\
    \ whatever \nis neutralized from a given stage of data cleaning is regarded as\
    \ “unwanted bits” \nwith “some half-identity clinging to them”, or as dirt where\
    \ “identity is absent”.\nIn our economics case, clustering involves looking for\
    \ cyclical patterns through \nvisual judgement. To understand the heuristic behind\
    \ this cleaning procedure, it is \nuseful to discuss briefly Gestalt theory first.\
    \ Gestalt psychologists study perceptual \norganization: “how all the bits and\
    \ pieces of visual information are structured into \nlarger units of perceived\
    \ objects and their interrelations” (Palmer 1999, p. 255). A \n“naïve realist”\
    \ explanation of this organization could be that this organization simply \nreflects\
    \ the structure of the external world. A problem with this explanation is that\
    \ the \nvisual system does not have direct access to how the environment is structured,\
    \ it has \nonly access to the image projected onto the retina, the “array of light\
    \ that falls on the \nM. Boumans and S. Leonelli\n95\nretinal mosaic” (p. 257).\
    \ This optic array allows for an infinite variety of possible \norganizations.\
    \ The question therefore is how the visual system picks out one of them. \nTo\
    \ answer this question Max Wertheimer, one of the founders of Gestalt psychology,\
    \ \nstudied the stimulus factors that affect perceptual grouping: “how various\
    \ elements \nin a complex display are perceived as ‘going together’ in one’s perceptual\
    \ experi-\nence” (Palmer 1999, p. 257). The theoretical approach of the Gestalt\
    \ psychologists is \nthat perceptual organization is grounded in the wish to maximize\
    \ simplicity, or \nequivalently, minimize complexity. They called this hypothesis\
    \ the principle of \nPrägnanz, today also called the minimum principle. It states\
    \ that the percept will be \nas good as the prevailing conditions allow. The term\
    \ “good” refer to the degree of \nfigural simplicity or regularity, and the prevailing\
    \ conditions refer to the structure of \nthe current stimulus image (Palmer 1999,\
    \ p. 289). The Gestalt psychologists saw \nsymmetry as a global property with\
    \ which figural goodness could be analysed.\nThe organising Gestalt in the case\
    \ of the NBER business cycle analysis was a \ncyclical pattern, such as the Fig. 3.\
    \ By taking averages, whether weighted or not \n(which is an act of clustering),\
    \ one aimed at reducing the noise in the observations \nas much as possible. Because\
    \ it is not possible to tidy up by a kind of physical inter-\nvention on some\
    \ physical material, the tidying up is not done by removal but by \nclustering\
    \ in such a way that the cluster itself is “cleaner” than the individual data.\
    \ \nThe principle of Prägnanz that was implicitly applied and was the underlying\
    \ goal \nof the procedures is an as simple as possible shaped cycle with clear\
    \ peaks and \ntroughs.\nIn the economic case, the original data end up as what\
    \ Douglas classified as \nundifferentiated dirt – that is, as objects that are\
    \ forever disconnected from their \noriginal source.\n[T]hese symbols are derived\
    \ by extensive technical operations from symbolic records kept \nfor practical\
    \ ends, or combinations of such records. We are, in truth, transmuting actual\
    \ \nexperience in the workaday world into something new and strange […]. (Burns\
    \ and Mitchell \n1946, p. 17)\nFig. 3 Example of a “typical” business cycle pattern\
    \ (Source: https://seekingalpha.com/\narticle/2716385-investing-in-business-cycles)\n\
    From Dirty Data to Tidy Facts: Clustering Practices in Plant Phenomics and Business…\n\
    96\nIn other words, the process of cleaning by clustering in this case transforms\
    \ a \nlarge quantity of objects that were previously identified as data into objects\
    \ that \nhave new evidential value, but are no longer available or retrievable\
    \ as sources of \ninformation about the contexts from which they were inferred.14\
    \ At the same time, \nit is important to note that the resulting records do not\
    \ completely fail to provide an \nidentity to the discarded objects. Keeping some\
    \ traces of the original time series is \nrelevant if only to verify that results\
    \ are not artificial products of spurious cyclical \npatterns. The visualisations\
    \ of original times and the adjusted one should show suf-\nficient similarity.\
    \ “A common method of judging the goodness of [an] adjustment is \nto see whether\
    \ the adjusted figures show similar movements in successive years” \n(Burns and\
    \ Mitchell 1946, p. 54).\nIn plant phenomics, clustering instead involves defining\
    \ a “landscape” for the \npotential re-contextualisation of data. The starting\
    \ assumption is that phenomics data, \nin all their richness, variability and\
    \ multiplicity of features, may be used for all sorts \nof research goals, ranging\
    \ from studies of irrigation systems to investigations of plant \ngrowth and nutrition\
    \ (as in the case of North Wyke data). Therefore the priority for \nresearchers\
    \ is not the visual intelligibility of a particular way of arranging data, but\
    \ \nrather the creation of categorisations that facilitate the disaggregation\
    \ of data clusters \nwhen needed by the inquiry at hand. In other words, researchers\
    \ want to retain the \nability to trace the origin of the relevant data journeys,\
    \ and evaluate the adequacy of \nevery step of data cleaning towards producing\
    \ reliable evidence for new research \nquestions. Key heuristic principles here\
    \ are: accuracy, in the sense of being as faithful \nas possible to the specific\
    \ characteristics of the research objects at hand; and trace-\nability of data\
    \ sources, in the sense of making sure that prospective data analysts have \n\
    what they need to assess the quality of the data and, if needed, process them\
    \ differ-\nently (which typically includes as extensive an access as possible\
    \ to metadata).\nThis approach is hard to compare to the application of Gestalt\
    \ principles, because \nthose are focusing on visual appearance and presentation,\
    \ while phenomics prac-\ntices of cleaning by clustering focus on interpretability\
    \ and the potential to disag-\ngregate existing data clusters. Nevertheless, like\
    \ the economics case, this is in \nstriking opposition to common sense interpretations\
    \ of the metaphors of “cleaning” \nand “dirt” that focus on the removal of blatantly\
    \ unwanted items. Both in biology \nand economics “dirt” may (and often does)\
    \ contain useful information, which needs \nto be ordered so as to be retrievable\
    \ depending on the interests of the prospective \nanalyst. The original datasets\
    \ and related metadata never fully become undifferenti-\nated dirt as in Douglas’s\
    \ analysis. Rather, researchers attempt to “cling on to their \nhalf-identity”,\
    \ in Douglas’s terms, thus leaving open the option for these objects to \nbe re-identified\
    \ as data and fully reinstated as significant sources of evidence for a \nclaim.\
    \ The main difference between the two fields is that economic data have lost \n\
    more of the identity of their original data than is the case in phenomics. While\
    \ in \nplant phenomics accuracy and traceability are leading, in economics accuracy\
    \ has \nto be balanced with Prägnanz, and traceability is not required.\n14 This\
    \ interpretation assumes a relational account of data epistemology, as outlined\
    \ in Leonelli \n(2016) and in the introduction to this volume.\nM. Boumans and\
    \ S. Leonelli\n97\n4  Comparing Heuristics across Research Communities \nin Natural\
    \ and Social Sciences\nEconomic data are processed in ways that make them much\
    \ more computationally \ntractable than phenomics data due to their numerical\
    \ format. Economic data are thus \nbetter amenable to aggregation and analysis\
    \ in comparison to many other data types, \nwhich potentially expands their scope\
    \ for linkage and aggregation with other datasets \nbut also limits the power\
    \ of investigators to contextualise and situate the data in rela-\ntion to their\
    \ origin. In this case, cleaning by clustering is a cumulative process, in \n\
    which the bulk of “raw” data is replaced by a smaller set of business-cycle “facts”\
    \ \nthrough the exercise of visual principles.15 As a result, analysts working\
    \ at later stages \nof these data journeys are left mostly with data models that\
    \ conform to specific criteria \nand are best used to address a narrow set of\
    \ questions, in conformity with the princi-\nples and assumptions made while preparing\
    \ them for analysis. The original “raw” data \nare no longer accessible, having\
    \ been “cleaned out” in the data visualisations.\nBy contrast, phenomics data\
    \ remain more difficult to analyse through computa-\ntional tools, and can only\
    \ be compared and linked with other datasets by employing \ncase-by-case adjustments.\
    \ They are so heterogeneous, and their ordering into clus-\nters so pluralistic\
    \ and open to multiple interpretations, that additional processing is \nneeded\
    \ every time researchers re-use them for a specific project. When considering\
    \ \ndata on biosource as discussed in section two, for instance, researchers need\
    \ to \ndouble-check what assumptions have been made about the taxonomy of plant\
    \ vari-\neties when ordering plant traits into groups. At the same time, the richness\
    \ of data \nformats and of the information that they carry make them useful evidence\
    \ for a large \nvariety of inquiries, and makes it easier to interrogate their\
    \ reliability and quality in \nrelation to different research conditions and aims.\
    \ Phenomics data can potentially \nbe used to answer many research questions.\
    \ Cleaning by clustering in this case is \nnot a cumulative process: it is crucial\
    \ for researchers to lose as few data and meta-\ndata as possible, as one never\
    \ knows what will turn out to be important later.\nIt has been frequently observed\
    \ that big data aggregation is often accompanied \nby loss of contextual information\
    \ (metadata).16 While in both of our cases the role \nand ordering of contextual\
    \ information plays a key role in the process of cleaning by \nclustering, the\
    \ principles associated to handling such contextual information are \nconsiderably\
    \ different. In economics, metadata become increasingly less relevant: \nthe principles\
    \ guiding data ordering and clustering are those of Prägnanz. In plant \nphenomics,\
    \ metadata never cease to be relevant, as the principles guiding ordering \nand\
    \ clustering are those of accuracy and traceability.\n15 Facts about phenomena,\
    \ in the sense of Bogen and Woodward 1988.\n16 Lawrence Busch (2014, also discussed\
    \ in Mittlestand and Floridi 2016) lists several reasons for \nthis, including:\
    \ Lossiness (lose aspects of the phenomena studied); Drift (phenomena change over\
    \ \ntime, but data representing them do not); Distancing (distance from phenomenon\
    \ facilitates iden-\ntification of patterns); Layering (reducing phenomena to\
    \ set of variables, e.g. in Tidy data); Errors; \nStandards; Disproportionality;\
    \ Amplification/reduction; Narratives.\nFrom Dirty Data to Tidy Facts: Clustering\
    \ Practices in Plant Phenomics and Business…\n98\nAssumptions made about the nature\
    \ of the phenomena at hand (respectively, \nplant morphology and business cycles)\
    \ may seem to have a significant impact on the \ntype of techniques and principles\
    \ enacted by researchers. For instance, the propo-\nnents of MIAPPE explicitly\
    \ note that\nwe are fully aware that MIAPPE suggests a description of the experiment\
    \ that is rather \nextended in comparison to current practices. Hence, although\
    \ we think that all of the attri-\nbutes in Table 1 are needed to adequately describe\
    \ each dataset, we accept that, in practice, \nthe full complement of information\
    \ may not be possible to collect, or might be unavailable \nto the person building\
    \ the dataset. Therefore, we have selected and marked those descriptors \ndeemed\
    \ absolutely essential. (Ćwiek-Kupczyńska et al. 2016, 7)\nRemarkably, their “absolutely\
    \ essential” list of traits still comprises 35 attributes, \na skinnier list than\
    \ the original list of over 80 attributes (ranging from 70 to over a \nhundred\
    \ depending on growth conditions and type of environment/soil), but still \ndaunting\
    \ in its richness.\nWe do not think that these differences should be viewed simply\
    \ as a measure of \nthe difference between studying plants and studying economic\
    \ conditions. Both \ntypes of phenomena are highly complex in their own ways,\
    \ and arguably economic \nbehaviour is even more difficult to reduce to a simple\
    \ set of variables. A more plau-\nsible explanation lies in the methods and commitments\
    \ characterizing the two fields \nof inquiry. Economics, business cycle analysis\
    \ in particular, is a highly generalist \nfield but it is not holistic: research\
    \ focuses on analysing the business cycle as an \nisolated phenomenon. By contrast,\
    \ plant phenomics favours a holistic approach, \nemphasising the complexity of\
    \ the interrelated processes through which plant mor-\nphology is constituted\
    \ (see Fig. 4 and also Leonelli 2016, ch. 6).\nFurthermore, plant phenomics has\
    \ no pretension to achieve a “complete repre-\nsentation” (or complete knowledge)\
    \ of the plant systems it analyses, precisely \nbecause of their daunting complexity\
    \ and the fact that so little is as yet known about \nthem. Thus, any model proposed\
    \ in plant science to analyse a phenomenon will be \nlimited in scope, and need\
    \ to be complemented by several others to provide a more \ncomprehensive picture\
    \ of the phenomena for specific investigative goals. Related to \nthis, mathematical\
    \ and statistical modelling – while of course strongly present in \nthis work –\
    \ are not always the primary or main tool of analysis; and their role is not \n\
    always one of data validation, they are also employed as tools to order and display\
    \ \nthe data at hand in ways that may help analysis (Leonelli 2019).\n5  Conclusions\n\
    Our analysis points to the difficulties experienced by analysts in providing general\
    \ \nprinciples of cleanliness with regard to research data. This is nicely exemplified\
    \ \nwhen considering the ongoing debate around the identification and application\
    \ of \noverarching “tidy data principles” in contemporary data science, which\
    \ seeks to \noutline criteria for “cleaning” and structuring data so as to make\
    \ them amenable to \ncomputational analysis (Wickham 2014). Within this framework,\
    \ data processing is \nM. Boumans and S. Leonelli\n99\nFig. 4 Representation of\
    \ the conceptual landscape for phenomics, taken from a seminal review \npaper\
    \ from Walter et al. (2015)\nconceptualised as consisting of four stages: (1)\
    \ import data; (2) tidy data; (3) trans-\nform/visualise/model data; (4) communicate\
    \ data. Tidy datasets are defined as pro-\nviding “a standardized way to link\
    \ the structure of a dataset (its physical layout) with \nits semantics (its meaning)”\
    \ (Wickham 2014, 2), thus helping to prepare data for \nvisualisation and modelling.\
    \ This literature does not shy away from data diversity, \nand recognises that\
    \ data “tidiness” comes in a variety of different flavours depending \non the\
    \ field and goals of inquiry, the statistical and computational tools available\
    \ \n(which are referred to as “tidy tools”, p. 20), and the cognitive preferences\
    \ of inves-\ntigators. The starting point for this work is to acknowledge that\
    \ determining what are \nobservations and what are variables is relatively easy\
    \ in the case of specific datasets, \nbut that such a distinction is hard to define\
    \ in general terms, also because of the \ndiversity often characterising data\
    \ sources and levels of abstraction. At the same \ntime, an attempt is made to\
    \ discuss tools through which “messy data” can be “tidied \nup”, so as to be ready\
    \ for computational analysis. An example is the activity of \n“melting”, which\
    \ consists of stacking datasets by turning columns of numbers into \nrows. Another\
    \ is “string splitting”, which involves splitting the columns of any given \n\
    data table into different variables. Furthermore, a series of “tidy tools” are\
    \ presented, \nsuch as data aggregation, filtering, visualisation and statistical\
    \ modelling, whose \ncommon aim is to “take untidy datasets as input and return\
    \ tidy datasets as outputs” \n(p. 12). All these strategies for cleanliness are\
    \ meant to “make analysis easier by \neasing the transitions between manipulation,\
    \ visualisation and modelling” (p. 15).\nThis approach to data cleaning aligns\
    \ nicely with the strategy that we have called \n“cleaning by clustering”. At\
    \ the same time, our reading of Douglas’s work on dirt \nprovides a conceptual\
    \ framework and rationale for this approach. It makes it clear \nthat cleanliness\
    \ is not a matter of removing unnecessary items, “noise” or “mess” \nFrom Dirty\
    \ Data to Tidy Facts: Clustering Practices in Plant Phenomics and Business…\n\
    100\nfrom somehow predefined “meaningful datasets”, thus assuming that (1) there\
    \ is a \n“best way” to order data regardless of the research aims of specific\
    \ investigations; \nand (2) what researchers should consider as reliable and veritable\
    \ data need to be \nuncovered and separated from “meaningless noise”. By contrast,\
    \ we propose to view \ndata cleanliness as a process of ordering data into clusters,\
    \ which runs in parallel with \nsituated attempts to assign meaning to data in\
    \ relation to specific research questions \nand goals. Thus cleaning can take\
    \ a variety of different forms – and result in very \ndifferent ideas of “what\
    \ counts as data” – depending on the assumptions, commit-\nments and circumstances\
    \ of the research projects at hand. Moreover, our cases have \nshown that the\
    \ above mentioned four stages of data analysis are actually four aspects \nof\
    \ one process of data interpretation which cannot be separated from each other.\n\
    References\nBogen, James, and James Woodward. 1988. Saving the Phenomena. Philosophical\
    \ Review 97 (3): \n303–352.\nBoumans, Marcel. 2015. Science Outside the Laboratory.\
    \ Oxford: Oxford University Press.\nBurns, Arthur F., and Wesley C. Mitchell.\
    \ 1946. Measuring Business Cycles. New York: National \nBureau of Economic Research.\n\
    Busch, Lawrence. 2014. Big Data, Big Questions | A Dozen Ways to Get Lost in Translation:\
    \ \nInherent Challenges in Large Scale Data Sets. International Journal of Communication\
    \ 8 (0): \n18. https://doi.org/10.1007/SpringerReference_22340.\nĆwiek-Kupczyńska,\
    \ Hanna, Thomas Altmann, Daniel Arend, Elizabeth Arnaud, Dijun Chen, \nGuillaume\
    \ Cornut, Fabio Fiorani, et  al. 2016. Measures for Interoperability of Phenotypic\
    \ \nData: Minimum Information Requirements and Formatting. Plant Methods 12 (1):\
    \ Bio Med \nCentral: 44. https://doi.org/10.1186/s13007-016-0144-4.\nDouglas,\
    \ Mary. 2002[1966]. Purity and Danger. An Analysis of the Concept of Pollution\
    \ and \nTaboo. London/New York: Routledge.\nHalfmann, Gregor. this volume. Material\
    \ Origins of a Data Journey in Ocean Science: How \nSampling and Scaffolding Shape\
    \ Data Practices. In Data Journeys in the Sciences, ed. Sabina \nLeonelli and\
    \ Niccolò Tempini. Cham: Springer.\nHoeppe, Götz. this volume. Sharing Data, Repairing\
    \ Practices: On the Reflexivity of Astronomical \nData Journeys. In Data Journeys\
    \ in the Sciences, ed. Sabina Leonelli and Niccolò Tempini. \nCham: Springer.\n\
    Karaca, Koray. this volume. What Data Get to Travel in High Energy Physics? The\
    \ Construction of \nData at the Large Hadron Collider. In Data Journeys in the\
    \ Sciences, ed. Sabina Leonelli and \nNiccolò Tempini. Cham: Springer.\nLeonelli,\
    \ Sabina. 2011. Packaging Small Facts for Re-Use: Databases in Model Organism\
    \ \nBiology. In How Well Do Facts Travel? ed. P. Howlett and M.S. Morgan, 325–348.\
    \ Cambridge: \nCambridge University Press.\n———. 2016. Data-Centric Biology: A\
    \ Philosophical Study. Chicago: University of Chicago \nPress.\n———. 2018. The\
    \ Time of Data: Time-Scales of Data Use in the Life Sciences. Philosophy of \n\
    Science 85 (5): 741–754.\n———. 2019. What Distinguishes Data from Models? European\
    \ Journal for the Philosophy of \nScience 9: 22.\n———. this volume. Learning from\
    \ Data Journeys. In Data Journeys in the Sciences, ed. Sabina \nLeonelli and Niccolò\
    \ Tempini. Cham: Springer.\nMorgan, Mary S. 1990. The History of Econometric Ideas.\
    \ Cambridge, MA: Cambridge University \nPress.\nM. Boumans and S. Leonelli\n101\n\
    Palmer, Stephen E. 1999. Vision Science. Cambridge, MA: MIT Press.\nRogers, Susan,\
    \ and Alberto Cambrosio. 2007. Making a New Technology Work: The Standardization\
    \ \nand Regulation of Microarrays. Journal of Biology 80: 165–178.\nWalter, Achim,\
    \ Frank Liebisch, and Andreas Hund. 2015. Plant Phenotyping: From Bean Weighing\
    \ \nto Image Analysis. Plant Methods 11 (1): 14. https://doi.org/10.1186/s13007-015-0056-8.\n\
    Wickham, Hadley. 2014. Tidy Data. Journal of Statistical Software 59 (10). https://doi.\n\
    org/10.18637/jss.v059.i10.\nXavier, Alencar, Benjamin Hall, Anthony A. Hearst,\
    \ Keith A. Cherkauer, and Katy M. Rainey. \n2017. Genetic Architecture of Phenomic-Enabled\
    \ Canopy Coverage in Glycine Max. Genetics \n206 (2): 1081–1089. https://doi.org/10.1534/genetics.116.198713.\n\
    Marcel Boumans is Pierson Professor of History of Economics at Utrecht University.\
    \ His main \nresearch focus is on understanding empirical research practices in\
    \ social science from a combined \nhistorical and philosophy perspective. He is\
    \ particularly interested in the practices of measurement \nand modelling and\
    \ the role of mathematics in social science. Because models are not complete as\
    \ \nsources of knowledge for sciences outside the laboratory, additional expert\
    \ judgements are needed. \nThis is the topic of his most recent monograph Science\
    \ Outside the Laboratory (OUP, 2015). His \ncurrent research project “Vision and\
    \ Visualisation” focuses on exploring how expert judgments \n(views) are made\
    \ and how they could be validated, particularly in those research practices where\
    \ \nvisualizations are made or used. The first outcome of this project is “Graph-Based\
    \ Inductive \nReasoning” published in Studies in History and Philosophy of Science\
    \ (2016).\nSabina Leonelli is Professor of Philosophy and History of Science at\
    \ the University of Exeter, \nwhere she codirects the Exeter Centre for the Study\
    \ of the Life Sciences (Egenis) and leads the \n“Data Governance, Algorithms and\
    \ Values” strand of the Institute for Data Science and Artificial \nIntelligence.\
    \ Her research concerns the epistemology and governance of data-intensive science,\
    \ the \nphilosophy and history of organisms as scientific models and the role\
    \ of open science in the global \nresearch landscape. She has an interest in science\
    \ policy and served as expert for national and \ninternational bodies including\
    \ the European Commission. She is a Turing Fellow, Editor-in-Chief \nof History\
    \ and Philosophy of the Life Sciences and Associate Editor of the Harvard Data\
    \ Science \nReview. Her publications span philosophy, social science, biology,\
    \ history, data science and science \npolicy and include the monographs Data-Centric\
    \ Biology: A Philosophical Study (2016) and La \nRecherche Scientifique à l’Ère\
    \ des Big Data (2019). Between 2014 and 2019, she led the European \nResearch\
    \ Council Starting Grant “The Epistemology of Data-Intensive Science” which supported\
    \ \nthe development of this volume.\nOpen Access This chapter is licensed under\
    \ the terms of the Creative Commons Attribution 4.0 \nInternational License (http://creativecommons.org/licenses/by/4.0/),\
    \ which permits use, sharing, \nadaptation, distribution and reproduction in any\
    \ medium or format, as long as you give appropriate \ncredit to the original author(s)\
    \ and the source, provide a link to the Creative Commons license and \nindicate\
    \ if changes were made.\nThe images or other third party material in this chapter\
    \ are included in the chapter’s Creative \nCommons license, unless indicated otherwise\
    \ in a credit line to the material. If material is not \nincluded in the chapter’s\
    \ Creative Commons license and your intended use is not permitted by \nstatutory\
    \ regulation or exceeds the permitted use, you will need to obtain permission\
    \ directly from \nthe copyright holder.\nFrom Dirty Data to Tidy Facts: Clustering\
    \ Practices in Plant Phenomics and Business…\n"
  inline_citation: '>'
  journal: Springer eBooks
  limitations: '>'
  pdf_link: https://link.springer.com/content/pdf/10.1007%2F978-3-030-37177-7_5.pdf
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: 'From Dirty Data to Tidy Facts: Clustering Practices in Plant Phenomics and
    Business Cycle Analysis'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/access.2023.3294985
  analysis: '>'
  authors:
  - Devika Menon
  - B. Anand
  - Chiranji Lal Chowdhary
  citation_count: 3
  full_citation: '>'
  full_text: '>

    IEEE.org IEEE Xplore IEEE-SA IEEE Spectrum More Sites 404: Page Not Found The
    page you were looking for could not be found. Browse or search IEEE Xplore to
    continue. Email us at onlinesupport@ieee.org for further assistance. © Copyright
    2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE Access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/6514899/10182252.pdf
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: 'Digital Twin: Exploring the Intersection of Virtual and Physical Worlds'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.apenergy.2023.120907
  analysis: '>'
  authors:
  - Zhihan Lv
  - Chen Cheng
  - Haibin Lv
  citation_count: 7
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Related work 3. DTs-based
    thermal energy storage system for smart buildings and its scheduling strategy
    security 4. Results and discussion 5. Discussion 6. Conclusion Declaration of
    Competing Interest Data availability References Show full outline Cited by (7)
    Figures (8) Show 2 more figures Applied Energy Volume 338, 15 May 2023, 120907
    Digital twins for secure thermal energy storage in building Author links open
    overlay panel Zhihan Lv a, Chen Cheng b, Haibin Lv c Show more Add to Mendeley
    Share Cite https://doi.org/10.1016/j.apenergy.2023.120907 Get rights and content
    Under a Creative Commons license open access Highlights • Places the Phase Change
    Material in the indoor building structure. • The DTs model of the Phase Change
    Wall (PCW) structure is constructed. • The PCW structure is used to build a thermal
    energy storage. Abstract The purpose of this work is to explore the role of the
    safe and optimal scheduling of thermal energy storage systems in intelligent buildings
    in promoting sustainable economic development under Digital Twins (DTs) technology.
    Phase Change Material (PCM) has high energy density, constant temperature storage,
    small footprint, and long service life. Here, PCM is first placed in the indoor
    building structure, and the DTs technology is introduced. In the development of
    intelligent buildings, the data generated by the energy storage system of intelligent
    buildings in the real space can be mapped to the virtual space in real time for
    simultaneous analysis. In addition, the PCM wall structure and thermal network
    DTs model are designed for the intelligent building. In addition, the PCW structure
    is used to build a thermal energy storage and dispatch model of the smart thermoelectric
    building based on DTs. Finally, the model is evaluated and analyzed experimentally.
    The analysis of system optimization power under different schemes indicates that
    the scheduling operation strategy of thermal energy storage of building walls
    can avoid overcharging or over-discharging batteries in the microgrid and reduce
    battery power consumption. Besides, the building wall energy storage capacity
    is always in the range of 0.2 ∼ 0.8 on the all-weather scale. Moreover, the model
    constructed here achieves significantly lower economic costs, environmental costs,
    and energy costs and a better energy-saving effect than the existing model. The
    model built here can serve as experimental reference for further digital energy
    storage in intelligent buildings and comprehensive energy utilization because
    of its superior safety performance and lower consumption. Previous article in
    issue Next article in issue Keywords Thermal energy storageDigital twinsPhase
    change materialIntelligent buildingMicrogrid 1. Introduction With the rapid development
    of information technology, various advanced are even more broadly applied, such
    as the Internet of Things (IoT), Cloud Computing, Digital Twins (DTs), and Artificial
    Intelligence (AI). For example, Cheng et al. (2022) proposed an energy-efficient
    multilayer virtual traffic scheduling algorithm regarding smart city construction
    that can effectively provide directions for smart city development and construction
    [1]. These techniques have also promoted the transformation of the construction
    industry from traditional construction and management methods to digital and intelligent
    transformation, which is one of the pillar industries of China''s real economy
    [2]. The building provides housing and keeps the cold out. Therefore, the design
    of the wall''s heat preservation performance is extremely essential. The heat
    insulation and thermal energy storage function of the building makes the whole
    indoor environment warm in winter and cool in summer, reflecting the energy saving,
    improving the living environment, and functions of using the construction [3].
    Therefore, the application of IoT, Cloud Computing, AI, and other technologies
    to building insulation and thermal energy storage security has become the focus
    of scholars in related fields. Currently, the building industry is in the process
    of intelligent development. Its overall design usually adopts the integrated design-manufacturing-construction
    method for bidding to ensure the integrity and integration of the overall building
    [4]. In the traditional building construction process, high requirements are put
    forward for information sharing, interaction, and collaboration among the design
    unit, manufacturer, and construction unit. However, there are still cases of conflicting
    nodes of building components in the construction process of actual engineering
    projects, such as nodes of columns and beams or nodes of wall panels and concealed
    columns. The problem of heat insulation and thermal energy storage during the
    construction of buildings is prominently important [5]. Jiang et al. (2021) formulated
    and fabricated a new self-reinforced composite phase change material for thermal
    energy storage using continuous hot-melt extrusion. They aimed to address the
    mismatch between energy production and demand under deep renewable energy penetration
    scenarios and address climate change challenges [6]. Wang et al. (2022) designed
    and constructed a novel medium to high temperature packed-bed latent heat storage
    material for thermal energy storage studies in buildings [7]. After understanding
    the performance of thermal energy storage materials designed in the above-mentioned
    traditional building construction, AI technology is introduced to analyze the
    digital construction of intelligent buildings. The construction of buildings develops
    intellectually with the application of various technologies, such as IoT, Cloud
    Computing, DTs, and AI. Spiking neural networks in machine learning are thought
    to boost the precision and durability of spike-based meta-learning by Yang & Tan
    et al. (2022) [8] and Yang & Linares-Barranco (2022) [9]. The self-adaptive multicompartment
    algorithm has been presented by Yang and Gao et al. (2022) as a means to create
    efficient adaptive neuromorphic computing systems for use in domains ranging from
    robotics to edge computing [10]. For example, the high-efficiency collaboration
    of the integration of project design, construction production, and operation and
    maintenance services of building insulation and thermal energy storage engineering
    driven by digital chain can be realized through digital modeling, visual cognition
    and interaction, high performance computing of relevant data, and intelligent
    decision making [11], [12]. DTs technology can simulate and describe the state
    and behavior of entities in physical space through high-fidelity dynamic virtual
    models and preview or simulate all activities of physical entities in virtual
    space in advance or in real-time [13]. For instance, Lv et al. (2022) combined
    DTs and AI to predict traffic accidents. The result showed that the prediction
    accuracy is high, which can provide a reference for the prevention of traffic
    congestion [14]. Introducing DTs technology into the construction process of intelligent
    building insulation and thermal energy storage systems can effectively improve
    the efficiency of construction projects and reduces the incidence of errors, and
    improve construction quality. It also improves the informatization and intelligence
    of the construction process of building insulation and thermal energy storage
    projects, promoting the digital development of thermal insulation and thermal
    energy storage systems in smart buildings. Of course, the operation of thermal
    insulation and thermal energy storage systems in smart buildings is inseparable
    from the support of the power system. Microgrids utilize decentralized local energy
    sources for distributed generation and apply them to the distributed thermal energy
    storage systems in buildings [15]. Swaminathan et al. (2020) developed an optimal
    sizing and scheduling model for microgrids with model predictive control. They
    found that building-level microgrids for medium-sized commercial buildings can
    save initial and operational costs [16]. Ramli & Jabbar (2022) proposed a solar-powered
    portable water pump for IoT-enabled smart irrigation system. Tests of the developed
    solar water pump confirmed its effectiveness. It has successfully conserved energy
    and cut down on running expenses [17]. The heat pump is connected to the microgrid
    when the building is constructed. The thermal energy storage system and heat pump
    can flexibly adjust the power according to the real-time electricity price and
    renewable energy generation under the premise of ensuring the appropriate indoor
    temperature of the building [18]. If the electricity meets the customer''s electricity
    demand, the surplus electricity will be converted into heat energy by the heat
    pump and stored in the intelligent building heat storage system. Suppose the local
    decentralized energy generation is insufficient. In that case, the intelligent
    building thermal storage system can release thermal energy into the microgrid,
    and users only need a small amount of purchased electricity to meet their power
    needs. In summary, exploring the safe dispatch and sustainable development of
    thermal energy storage systems in intelligent buildings is of theoretical significance
    to the green development of the social economy and the improvement of social and
    economic benefits. Therefore, this work innovatively introduces DTs technology
    into intelligent buildings and places the Phase Change Material (PCM) in the interior
    building structure. Additionally, a DTs-based thermal energy storage and safety
    scheduling model for thermoelectric smart buildings is constructed using the PCM
    wall. Measurements of its effectiveness obtained through experimentation. This
    work provides experimental support for the rational modernization of the construction
    industry and contributes to the long-term health of the economy. The structure
    of this work is as follows. Section 1 introduces the research background, motivation,
    purpose, innovation, and contribution. Section 2 expounds on the research of scholars
    in related fields and analyzes its advantages and disadvantages, which makes the
    value of this research prominent. Section 3 introduces the DTs technology and
    designs the PCW structure of the intelligent building. On this basis, a DTs-based
    thermal energy storage and scheduling model is constructed for thermoelectric
    smart buildings. Finally, the model performance is experimentally evaluated. Section
    4 comparatively compares the model constructed here with different schemes proposed
    by scholars in related fields. Section 5 briefly outlines the research results
    and explains the limitations and prospects. 2. Related work 2.1. Analysis of the
    application status of DTs in the field of construction DTs technology is the digital
    representation of a physical process, person, place, system, or device. It can
    promote the intelligent building to realize the information fusion and interaction
    between virtual space and physical space. Many scholars have conducted research
    on the application of DTs in architecture. Li et al. (2020) proposed a DTs-driven
    sustainability evaluation information architecture for the dynamic evolution of
    the entire life cycle in intelligent manufacturing, aimed at the challenges faced
    by the conventional manufacturing industry. Finally, they verified the effectiveness
    of the DTs dynamic information architecture and sustainability evaluation method
    [19]. White et al. (2021) found that the combination of increasingly large and
    accurate Building Information Models (BIMs) in smart cities and big data generated
    by IoT sensors makes a large amount of data in smart cities even more accurate
    and transparent. Meanwhile, a public and open DTs model makes the planning of
    the smart city industrialization process increasingly accurate [20]. Chen et al.
    (2021) proposed an embodied carbon estimation method in buildings based on DTs
    technology and life cycle assessment. They applied the model to automatic data
    communication between BIM databases. The comparative analysis result suggested
    that this embodied carbon estimation method outperformed others [21]. 2.2. Analysis
    on the current situation of research on optimal scheduling of Cooling, Heating,
    and power in intelligent buildings When modeling smart buildings, many scholars
    have studied the performance related to the optimal operation and dispatch of
    combined cooling, heating, and power (CCHP) microgrids and energy storage systems
    of a smart building. Cybersecurity concerns with running Virtual Power Plants
    and microgrids powered by renewable energy sources were highlighted in a study
    by Ravi et al. (2022). Security and operational scenarios for the new ecosystem
    are also outlined [22], with an emphasis on the interoperability, security, and
    integration of Distributed Energy Resources. Antoniadou-Plytaria et al. (2020)
    proposed an energy management system model for smart building microgrids based
    on battery energy storage. They proved that the framework could accurately estimate
    building operating costs and improve the overall performance of batteries as flexible
    resources in building microgrids through simulation [23]. Cui et al. (2020) constructed
    a nonlinear partial load ratio model for gas turbines, boilers, and coolers and
    proposed a piecewise least squares linearization method. The results showed that
    the optimal operation effect of optimal scheduling for different objectives is
    significantly better than the constant efficiency model. Besides, the choice of
    gas turbine, heat recovery steam generator, and electric chiller models for both
    models greatly impact the system operation results [24]. Ren et al. (2021) evaluated
    two different systems using solar energy. In system A, solar energy was converted
    into heat and electricity by solar thermal collectors and photovoltaic (PV) panels,
    respectively. Solar energy was converted into heat and electricity through PV
    thermal collectors in system B. It was found that when system A operates under
    the following electric load strategy, it can bring many benefits to the three
    buildings and construct a system with a configuration and component size that
    are closely related to the building type [25]. Dong et al. (2022) presented an
    optimization strategy based on robust model predictive control to deal with multiple
    uncertainties in source loads. Under uncertain scenarios of renewable energy generation
    and load consumption, the optimization model was transformed into a tractable
    form for robust dispatch that minimizes operating costs. The authors confirmed
    that under uncertain scenarios, the optimal dispatching model of their intelligent
    building CCHP system reduces the operating cost by 11.5% compared with the traditional
    model predictive control strategy [26]. Lin et al. (2022) proposed a new thermoelectric
    powered wireless sensor network platform for low-cost environmental sensing in
    building envelopes through thermoelectric energy harvesting and ultra-low power
    management. The result suggested that the system can offer unique and innovative
    advantages in terms of self-powered system architecture, thermally optimized internals,
    and milliwatt power management [27]. 2.3. Summarization Based on an analysis of
    the relevant research conducted by the aforementioned experts, it has been determined
    that the digital twin technology was initially applied to intelligent buildings.
    The research on the modeling of the medium thermal energy storage system is overly
    simplistic, and the thermal network''s construction is not refined. In practical
    operation, the thermal side of the structure may pose a safety risk if it is out
    of control. In order to improve the building''s intelligence and the stability
    and safety of its thermal system, this study implements digital twin technology
    so that the data generated by the smart building''s energy storage system in the
    real world can be mapped to the virtual space in real time and analyzed in synchrony.
    More research is needed to develop and test the fine thermal network DTs model
    of phase-change thermal storage wall structure and thermal energy storage in intelligent
    buildings. This model is useful for building smart buildings and keeping the economy
    growing in a sustainable way. 3. DTs-based thermal energy storage system for smart
    buildings and its scheduling strategy security 3.1. Application of DTs technology
    in intelligent buildings The first task is to create a DTs model of the construction
    application to integrate the DTs technology with the practical construction field.
    This work expands the 3D model, adds two dimensions of DTs Data (DTD) and Connection
    (CN), and constructs a five-dimensional DTs model [28], as shown in Fig. 1. Download
    : Download high-res image (221KB) Download : Download full-size image Fig. 1.
    Energy conversion diagram for Scheme 1. The model developed during this study
    is referred to as scheme 1. It transfers the heat energy from the building''s
    walls into electrical energy for power generation using a generator. The spinning
    reserve capacity of the wind/solar/storage grids is provided by the battery system''s
    comprehensive utilization. Fig. 1 displays the energy conversion diagram for Scheme
    1. The five-dimensional DTs model in Fig. 1 mainly includes five parts: the Physical
    Entity (PE), Virtual Entity (VE), Service System (SS), DTD, and CN between each
    part. The five elements complement each other and form the DTs of the intelligent
    building [29]. Ma et al. (2022) designed a DTs-driven operational mechanism and
    a general framework for big data cleaning and integration to explain and illustrate
    sustainable smart manufacturing in smart buildings [30]. In the intelligent building
    DTs, the PE is a physical product that the user can operate. In addition to completing
    the normal function output, it is necessary to collect the parameters required
    by the environment and the building''s own operating system to drive the VE model
    of the information domain.; VE is the mapping of the PE and the basis for building
    a five-dimensional DTs model. It can characterize and describe the PE of intelligent
    buildings from multiple dimensions, multiple spatial scales, and multiple time
    scales. SS is a newly added dimension and is the main driver of the DTs model.
    It relies on the virtual space algorithm library, model library, database, and
    expert knowledge base to make decisions on the operation scenario and status of
    the intelligent building energy storage system to realize the scheduling of thermal
    network clusters [31]. DTD is the data that exists and operates according to the
    rules defined by the system in the DTs model. It mainly studies and analyzes the
    operation and data flow processing of the DTs system of intelligent buildings.
    CN can complete the interconnection and intercommunication between the various
    components. PE, VE, and SS are regarded as structural points. The topology of
    the DTs model of the intelligent building can be formed through the connection
    between the structural issues. Fig. 2 reveals the DTs model of an intelligent
    building based on the five-dimensional DTs system. Download : Download high-res
    image (268KB) Download : Download full-size image Fig. 2. Energy conversion diagram
    for Scheme 2. Scheme 2 combines the energy storage effect of the wall with other
    equipment such as wind turbines, photovoltaic panels, and battery energy storage
    systems and only uses the battery energy storage system as a spinning backup.
    Fig. 2 shows the energy conversion diagram for Scheme 2. Fig. 2 depicts the evolution
    of the DTs intelligent building model. First, identify the physical entity, i.e.,
    the component of the intelligent building, and provide the pertinent physical
    entity specification. Second, develop a virtual entity, abstract the spatial structure
    of the intelligent building, and evaluate simulations using the relevant model.
    Third, design data; determine the data that must be collected when the smart building
    is in operation, as well as the equipment required for data collection. Fourth,
    establish a connection; clarify the connection between the physical entity and
    the virtual entity of the smart building, as well as the connection protocol used.
    Fifth, test the smart building. Sixth, validate the smart building. Fifth, realize
    the service aimed at the intelligent building''s practical issues, enhance the
    traditional scheduling process, and develop a platform to present the intelligent
    building''s DTs data. The user tests and evaluates the developed intelligent building
    model, makes specific improvement suggestions, and enriches and refines software
    requirements, such as adding vision and physical entity models, making suggestions
    for improving traditional scheduling algorithms, and adding other new requirements.
    Naturally, the developer will use this information to enhance the software until
    the user''s approval and satisfaction are obtained, after which the software will
    be fully implemented, tested, and maintained. 3.2. Analysis of PCW structure material
    and the thermal network DTs model of intelligent buildings During the construction
    of the building, the materials used in the PCW structure are the basis of the
    thermal energy storage system. A PCM transforms its physical properties and absorbs
    or releases a large amount of heat as the temperature changes [32]. At present,
    PCMs commonly used in building materials usually exist in the form of solid–liquid
    mixed storage. They have the advantages of low price, high energy density, constant
    temperature storage, small occupied volume, and long service life and have been
    widely concerned by scholars in related fields. If the PCM is filled in the building,
    the PCM wall can be formed [33]. Liu et al. (2020) designed shape-stabilized PCMs
    with desirable latent enthalpies and found that these materials had satisfactory
    shape stability as well as excellent thermal energy management [34]. Here, the
    PCM is placed in the indoor building structure. The DTs technology is introduced
    to establish a DTs model of the PCW material and its thermal network in an intelligent
    building, as presented in Fig. 3. Download : Download high-res image (198KB) Download
    : Download full-size image Fig. 3. Energy conversion diagram for Scheme 3. In
    Scheme 3, the cooling or heating used by the user end adopts the conventional
    power grid''s maximum output operation mode and only uses the microgrid battery
    energy storage system as a rotating backup. Fig. 3 presents the energy conversion
    diagram for Scheme 3. As shown in Fig. 3, the PE data of the intelligent building
    wall is mapped into the virtual space through DTs technology after collection.
    It is assumed that the three sides of the virtual wall of the intelligent building
    (including the PCW) face the shade, and the other side is subject to solar radiation
    (named wall No. 1). Besides, the convective heat exchange between the air gap
    of the PCM wall and the room air is enhanced by installing a forced air circulation
    system in the phase change wall. At the same time, the thermodynamic model takes
    into account the heat leakage of the PCM to the indoor and outdoor environments,
    which contributes to the thermal balance between the nodes of the intelligent
    building. In this thermal network model, solar radiation is expressed as ; the
    input variables include the ambient temperature and the temperature of the PCM;
    the controllable variable is the circulating air velocity ; the state variables
    include the indoor air temperature , the PCM wall air gap air temperature , and
    the internal and external surface temperature of the structure , where N = 4 represents
    the number of walls. Take the cooling mode of the intelligent building thermal
    network in summer and the heating mode in winter as an example. According to the
    law of thermodynamics, the uncontrollable heat leakage of PCM at time t includes
    indicators such as , , , , and [35]. refers to the total amount of uncontrollable
    heat leakage from PCM to the inside and outside of the building; and represent
    the heat leaked from PCM to the outer wall of the building phase change wall through
    conduction and radiation; and indicate the heat leaked from PCM to the building
    phase change wall through conduction and radiation of the inner wall. The details
    are shown in Equations (1)∼(5): (1) (2) (3) (4) (5) In Equations (1) ∼ (5), ,
    , , and represent the heat conduction and heat radiation coefficients of the PCM
    and the outer wall and inner wall; and refer to the contact area between the outer
    and inner layers of the wall and the air gap of the phase change layer, respectively;
    and denote the nodal temperature of the outer and inner walls of the PCW. The
    controllable heat transfer of the forced air circulation at time t is calculated
    as the enthalpy change difference between the air inlet and outlet of the PCW,
    as shown in Equation (6). (6) In Equation (6), indicates the specific heat capacity
    of air; denotes the indoor air temperature; refers to the circulating air flow
    rate, which at any moment t is bounded by the maximum air flow rate , expressed
    as . Equation (6) is a bilinear expression multiplying the controllable variable
    circulating air flow rate and the state variable room air temperature . The transformation
    of Equation (6) is briefly discussed. If the circulating air flow rate , the optimization
    of indoor air temperature should be kept at the upper limit of human comfort temperature
    under the summer cooling release mode working condition. Otherwise, the circulating
    air flow rate in the indoor circulation air can be further reduced to reduce the
    energy loss of the thermal energy storage system. If the circulating air flow
    rate mt = 0, the controlled heat transfer in Equation (6) is always 0 under any
    [36], [37]. Therefore, the constant human comfort temperature upper limit can
    be replaced by the variable indoor air temperature . Equation (6) can be transformed
    into the linear formula shown in Equation (7). (7) Therefore, after the comprehensive
    analysis of Equations (1) ∼ (7), the total heat load of the building is expressed
    as the total energy of controllable heat transfer and uncontrollable heat leakage,
    as presented in Equation (8). (8) In addition, the thermal balance correlation
    of intelligent buildings can be further analyzed according to the above equations.
    Equation (9) indicates the PCM heat balance. (9) In Equation (9), refers to the
    heat flow from the air gap of PCW to PCM at time t. The heat flow from the external
    environment to the outer PCW is equal to the heat transfer between the outer PCW
    and the air gap or between PCM and other building walls. Thus, the heat balance
    of the outer PCW can be expressed as Equation (10). (10) In Equation (10), and
    refer to the heat loss of the outer PCW and the heat flow from the external environment
    to the outer PCW at time t, respectively; represents the heat flow from the remaining
    walls of the building to the outer PCW at time t. The heat exchange between the
    room air and the inner surface of the other walls to the phase change interior
    wall is equal to the heat exchange between the phase change interior wall and
    the air gap, PCM, and the inner surface of the other walls. Hence, the heat balance
    of the inner PCW can be written as Equation (11). (11) In Equation (11), signifies
    the heat flow from the rest of the building walls to the inner PCW at time t;
    refers to the heat flow of the envelope j to the inner PCW at time t, denotes
    the heat flow from the room air to the inner PCW at time t. Equations (12) ∼ (14)
    express the heat balance of each wall of the building [38]. (12) (13) (14) Equations
    (12), (13) represent the thermal balance relationship between each building wall
    and the outside world. Equation (14) indicates the thermal balance relationship
    between each building wall and indoor air and other walls. refers to the heat
    loss of the enclosure structure k at time t; represents the heat flow from the
    remaining walls of the building to the enclosure structure k at time t; denotes
    the radiation heat transfer from the external environment to the enclosure structure
    k at time t; signifies the heat flow from the enclosure structure k to the room
    at time t; stands for the heat flow from the envelope structure k to the envelope
    structure j at time t. The heat exchange of the solar radiation wall (Wall 1)
    of the building is marked as , as shown in Equation (15). (15) In Equation (15),
    refers to the radiation heat transfer coefficient. The heat exchange from room
    air to the PCM and the inner PCW is equal to the heat exchange between the other
    walls except for the PCW and the room air. That is, the heat balance can be expressed
    as Equation (16). (16) This work investigates the pertinent theories of phase
    change materials and explains the thermodynamic content of phase change materials
    when applied to intelligent buildings. The findings provide the foundation for
    the following thermodynamic energy storage and dispatching models for intelligent
    buildings. 3.3. Analysis of the thermal energy storage and dispatch model based
    on DTs of intelligent buildings Because the building has a certain heat capacity,
    when the thermal power changes, the indoor temperature changes relatively lag,
    but the human body has a certain range of comfortable temperatures. The energy
    storage characteristics of PCMs can meet the indoor cooling/heating needs of buildings.
    Fig. 4 displays the thermal energy storage and scheduling model for smart buildings
    based on DTs technology. Download : Download high-res image (296KB) Download :
    Download full-size image Fig. 4. Thermal energy storage and dispatching model
    based on DTs for intelligent buildings. In Fig. 4, the physical space is a complex,
    dynamic architectural environment consisting of the data collection layer, the
    data analysis layer, and the network perception layer. The five major elements
    of the data collection layer are construction personnel, mechanical equipment,
    materials, work methods, and the environment. It collects the most original data
    sources related to intelligent buildings. Then, the data analysis layer processes
    the acquired data sources to form economic cost data, environmental cost data,
    energy cost data, and construction safety data, respectively. The model transmits
    the multi-source heterogeneous data obtained from the analysis and processing
    layers to the virtual space and simultaneously receives instructions from the
    virtual space, and reacts accordingly. The network perception layer is responsible
    for the perception and collection of data and the transmission of data to the
    virtual space. The model uploads real-time data of construction activities into
    the virtual space by establishing a set of standard data interfaces and communication
    protocols in the network module to achieve uniform conversion and transmission
    of data from different sources. The thermal energy storage and distribution of
    intelligent buildings in this model rely heavily on PCM phase change walls. There
    is no need to transform light energy and local scattered energy into heat energy
    for building walls when generating electricity. The thermal energy of the building
    wall is converted into electrical energy for the user end by the generator, and
    the battery system provides the rotating reserve capacity for the wind/solar/storage
    grid. Following is a description of the relevant thermal energy scheduling mechanism
    involved. Here, refers to the heat dissipation power of the building (kW); represents
    the outdoor temperature (℃); signifies the indoor temperature (℃); refers to the
    specific heat capacity of the air, and the unit is kJ/(kg·K). From the two working
    conditions of heating in winter and cooling in summer, the relationship between
    the heat inside and outside the building and the temperature is expressed as Equations
    (17), (18). (17) (18) Equations (17), (18) represent the two working conditions
    of heating in winter and cooling in summer, respectively. stands for the air density
    (kg/m 3); refers to the heating power in winter (kW); signifies the cooling power
    (kW) in summer; refers to the volume capacity of the building. Assume that the
    heat dissipation power of the building is unchanged during the heat release and
    heat storage process. Then, the maximum charge and discharge energy (kW) provided
    by the building energy storage can be expressed as Equation (19). (19) The indoor
    temperature of a building is a response to a combination of factors, such as outdoor
    temperature, solar radiation, and indoor heat sources. To simplify the calculation,
    the external wall of the building is conducted as one-dimensional heat output
    according to the relevant thermodynamic knowledge. According to the law of energy
    conservation, the heat balance of the indoor temperature node is established as
    Equation (20). (20) In Equation (20), refers to the convective heat transfer coefficient
    of the interior wall surface; denotes the surface area of the external wall; stands
    for the thermal conductivity of the window; refers to the area of the window;
    stands for the interval time period; represents the convective heat transfer of
    the indoor heat source; refers to the number of air changes; indicates the solar
    heat gained through windows; refers to the indoor heat source radiating heat.
    Further, the multiobjective operation optimization modeling is carried out on
    the thermal energy storage and scheduling model of intelligent buildings. Its
    objective function is analyzed in terms of economic cost, environmental cost,
    and energy cost, respectively. The financial cost mainly includes the fuel cost
    of power generation by the system, the power purchase cost of the system from
    the grid, and the cost of equipment maintenance. The fuel cost generated by the
    consumption of natural gas by the micro gas turbine is calculated according to
    Equation (21). (21) In Equation (21), refers to the unit price of natural gas,
    and represents the unit volume of natural gas. The power purchase cost of the
    system is expressed as Equation (22). (22) In Equation (22), T refers to a dispatch
    cycle; represents the power purchased from the microgrid to the grid in the t
    period; stands for the power sold by the microgrid to the grid in the t period
    (kW); refers to the electricity purchase price in the t period; signifies the
    point-of-sale electricity price from the microgrid to the larger grid in period
    t. The maintenance cost of the system can be expressed as Equation (23). (23)
    In Equation (23), , , and refer to the fan output, PV output, and battery charge
    and discharge power, respectively (positive when charging and negative when discharging);
    , , , , and represent the maintenance costs of fans, PVs, batteries, micro gas
    turbines, waste heat boilers, and absorption chillers, respectively. Therefore,
    the minimum objective function of economic cost is written as Equation (24). (24)
    Environmental costs mainly consider carbon dioxide emissions. The system uses
    natural gas as fuel. The combustion of natural gas produces carbon dioxide and
    water. The power purchased by the system from the grid is also derived from the
    electricity generated by thermal power plants, which also produce carbon dioxide.
    Thus, the environmental cost is represented by the carbon dioxide conversion coefficient
    [39]. The objective function for the minimum carbon dioxide emission of the system
    is: (25) where and refer to the carbon dioxide conversion coefficient of natural
    gas and electric energy, respectively. Energy cost is the amount of energy consumed.
    As primary energy, natural gas belongs to non-renewable energy. Now, fossil energy
    has been exhausted day by day [40], [41]. The objective function for minimizing
    energy consumption and energy waste is written as Equation (26). (26) In Equation
    (26), refers to the daily cooling capacity of the microgrid in the smart building
    thermal energy storage and dispatch model; represents the daily heat supply produced
    by the microgrid in the model; denotes the daily power generation of the microgrid
    in the system. 3.4. Experimental performance evaluation A case study is performed
    to verify the feasibility and effectiveness of the proposed thermal energy storage
    and scheduling model based on DTs of smart buildings. This section selects a typical
    photovoltaic-integrated smart building group as the research object. The specific
    environment and parameter settings are as follows. The total installed capacity
    of rooftop photovoltaics in the smart building group is 1500 kW, and the total
    number of rooms equipped with phase-change material energy storage systems is
    400. The size of the room is 4500 × 4500 × 3400 mm, and the mass of phase change
    material configured on the wall of each room is 600 kg. A 3 kW heat pump and a
    circulation fan with a maximum air velocity of 5 kg/s are installed. In this experiment,
    the hardware and software configurations are as follows. In the software, the
    operating system is Linux 64bit, the Python version is Python 3.6.1, and the development
    platform is PyCharm; in the hardware, the CPU is an Intel core i7-7700@4. 2 GHz
    8-core, the memory is Kingston ddr4 2400 MHz 16G, and the GPU is an Nvidia GeForce
    1060 8G. For the sake of focus and hypothesis analysis, this work assumes that
    all rooms have the same comfort temperature interval and uses a centralized control
    strategy of the energy management system. The energy dispatch center sends dispatching
    commands to the building thermal energy storage system in each house to control
    the heat pump power and circulating air flow rate of the building thermal energy
    storage system in each house. The model developed during this study is referred
    to as scheme 1. It transfers the heat energy from the building''s walls into electrical
    energy for power generation using a generator. The spinning reserve capacity of
    the wind/solar/storage grids is provided by the battery system''s comprehensive
    utilization. As evidence of the superiority of the proposed technique, the following
    two plans are presented for comparison. Scheme 2 combines the energy storage effect
    of the wall with other equipment such as wind turbines, photovoltaic panels, and
    battery energy storage systems and only uses the battery energy storage system
    as a spinning backup. In Scheme 3, the cooling or heating used by the user end
    adopts the conventional power grid''s maximum output operation mode and only uses
    the microgrid battery energy storage system as a rotating backup. 4. Results and
    discussion 4.1. System optimization power under different schemes Fig. 5 compares
    the three schemes mentioned above to explore the optimal power of the system.
    In Fig. 5, the power station output represents the electric energy generated by
    the microgrid power station; the battery output represents the electric energy
    generated by the microgrid battery energy storage system; the net load power is
    the sum of the power station output and the battery output power. Download : Download
    high-res image (325KB) Download : Download full-size image Fig. 5. Optimized power
    distribution of the system under different schemes (a. Scheme 1; b. Scheme 2;
    c. Scheme 3). It can be seen from Fig. 5 that under the three schemes, the net
    load is negative from 1:00 to 4:00; the output of wind power and PVs is greater
    than the conventional grid load. Scheme 3 adopts the maximum output operation
    mode to maintain a high output; Scheme 1 and Scheme 2 consider the dynamic energy
    storage characteristics of the building wall energy storage, avoiding battery
    overcharge to dissipate a large amount of surplus renewable energy and consuming
    less. At 21:00, when the net load is in the peak period, the wind power and PV
    output cannot meet the normal load demand. Users of Scheme 1 and Scheme 2 need
    to purchase electricity from the power station to run at close to full power generation
    power, avoiding the need for the battery to meet a large number of loads. It can
    effectively reduce the peak-to-valley difference of the equivalent load of the
    microgrid and play the role of shifting peaks and filling valleys. The above analysis
    demonstrates that the scheduling and operation strategy of the building wall energy
    storage with dynamic energy storage characteristics is considered in this scheme
    with a great degree of flexibility. It can avoid the overcharge or over-discharge
    of the battery in the microgrid, reduce the power consumption of the battery,
    and extend the service life of the battery to a certain extent. Fig. 6 reveals
    the deterministic dispatch under the conditions of electricity-thermal uncertainty
    under the three scenarios, deterministic dispatch power consumption and day-ahead
    sale and purchase power of sea island microgrid PV power, heat pump power of the
    building energy storage system, and energy storage capacity of PCW. Download :
    Download high-res image (264KB) Download : Download full-size image Fig. 6. Deterministic
    dispatching power consumption and day-ahead power consumption under different
    schemes (a. Scheme 2; b. Scheme 3; c. Scheme 1). According to Fig. 6, under different
    schemes, the PV power generation is not enough to meet the user''s electricity
    demand during the period of 1:00–6:00, 13:00–14:00, and 19:00–24:00 every day.
    Therefore, smart building micro-grid users meet the demand for conventional electrical
    loads by purchasing the right amount of electricity from the grid. Then, the remaining
    electricity is converted into thermal energy by the heat pump and delivered to
    the building phase change energy storage system to meet the heat demand of island
    residents. During the hours of 7:00–13:00 and 15:00–18:00 when the PV power is
    generated, the island intelligent building micro-grid does not purchase electricity
    from outside or sell electricity in small amounts at a fixed price. Moreover,
    the surplus electricity of the island micro-grid is converted into thermal energy
    of the building phase change energy storage system for storage. Besides, the energy
    is released through the phase change material and forced air circulation system
    in the intelligent building to directly meet the thermal demand of the island
    residents. Scheme 1 can convert the thermal energy of the building wall into electric
    energy for the user end through the generator and comprehensively utilize the
    battery system to provide the rotating reserve capacity of the wind/solar/storage
    grid. Therefore, the power purchase required in Scheme 1 is significantly less
    than that in Scheme 2 and Scheme 3, while the electricity sold is obviously larger
    than that in Scheme 2 and Scheme 3. In addition, the analysis of the PCW energy
    storage system for intelligent buildings in the three schemes indicates that the
    capacity of Scheme 1 is always in the range of 0.2 ∼ 0.8 on the all-weather scale;
    the capacities of Scheme 2 and Scheme 3 are smaller than Scheme 1. The result
    suggests that the DTs-based intelligent building thermal energy storage and dispatching
    model constructed here has no thermal energy loss exhaustion or inflow overflow
    and realizes long-term peak-shaving and valley-filling of large power grid loads.
    The PV-integrated buildings reported here are compared with traditional residential
    buildings and office buildings in terms of electrical load and indoor heat source
    values, as shown in Fig. 7. Download : Download high-res image (233KB) Download
    : Download full-size image Fig. 7. Comparison results of electrical load and indoor
    heat source value of different types of buildings (a. electric load; b. indoor
    heat source value). Fig. 7 compares the electrical load and indoor heat source
    values for different types of buildings. It can be seen from the Fig. 7 that the
    electric load value consumed by office buildings is the largest and the indoor
    heat source value is higher. The photovoltaic integrated buildings constructed
    in this study can have a higher indoor heat source while maintaining a lower electrical
    load value. Therefore, the PV-integrated buildings constructed here have a better
    wall energy storage effect and lower power consumption compared with residential
    and office buildings. 4.2. Cost consumption under different schemes The thermal
    energy storage and dispatch model of smart buildings based on DTs reported here
    is compared with the models proposed by Antoniadou-Plytaria et al. (2020), Cui
    et al. (2020), Ren et al. (2021), and Dong et al. (2022) The algorithm under different
    risk indicators (0, 0.05, 0.1, 0.15, 0.2) from the perspectives of economic cost,
    environmental cost, and energy cost. Fig. 8 provides the results. Download : Download
    high-res image (582KB) Download : Download full-size image Fig. 8. Results of
    economic cost, environmental cost, and energy cost with the increase of risk indicators
    under different models (a. economic cost; b. environmental cost; c. energy cost).
    Fig. 8a shows that with the increase of risk indicators, the economic cost required
    by each model algorithm increases sequentially, and the cost required by the model
    reported here is significantly lower than that of other model algorithms. In Fig.
    8b, as the risk index increases, the environmental cost required by each model
    algorithm increases sequentially. The cost of the research model is significantly
    lower than other model algorithms. In Fig. 8c, as the risk index increases, the
    energy cost required by each model algorithm increases sequentially. The cost
    of the research model is significantly lower than other model algorithms. The
    model reported here achieves functional regulation and reduces the consumption
    of economic costs, environmental costs, and energy costs. Therefore, the thermal
    energy storage and dispatching model of intelligent buildings based on DTs constructed
    here can enhance the energy storage effects of buildings, cut down economic costs,
    environmental costs, and energy costs, and enhance safety performance. 5. Discussion
    The comparability and verification of the smart building thermal energy storage
    and dispatching model based on DTs'' viability and efficiency. First, three schemes
    were used to conduct a system-optimized power analysis. It was discovered that
    the thermal energy dispatching mechanism described in this study can extend the
    battery''s service life to some degree. Simultaneously, analyses of the deterministic
    scheduling power consumption and day-ahead trading power under distinct strategies.
    The DTs-based intelligent building thermal energy storage and scheduling model
    developed here lacks both thermal energy loss exhaustion and inflow overflow.
    This may be because this research model avoids over-discharge of the battery to
    meet a large number of load demands, which can effectively reduce the peak-to-valley
    difference of the equivalent load of the microgrid and play the role of shifting
    peaks and filling valleys to realize long-term maintenance of large power grid
    loads. This is consistent with the views put forward by Pekárová et al. (2022)
    [42] and Zhao et al. (2022) [43]. This work is compared with the research of scholars
    in related fields in terms of economic cost, environmental cost, and energy cost.
    It can be found that with the increase of risk indicators, the economic cost,
    environmental cost, and energy cost required by each model algorithm increase
    in turn. And, the cost of the model reported here is significantly lower than
    other model algorithms. This may be because DTs technology can digitally interact
    with the construction status and information of the building complex when building
    photovoltaic integrated buildings, make quick decisions about problems that come
    up during construction and the operating status of equipment and components, and
    then control functions. This is consistent with the view put forward by Odukomaiya
    et al. (2021) [44]. Finally, it shows that the thermal energy storage and scheduling
    model of intelligent building based on DTs built here can provide experimental
    basis and development direction for the intelligent development and sustainable
    economic development in the follow-up construction field. 6. Conclusion In the
    era of rapid development of information technology, the construction sector is
    also developing in the intellectual direction. The innovation and contribution
    of this work lie in the incorporation of DTs technology into the design of intelligent
    buildings so that the data generated by the energy storage systems of intelligent
    buildings in the real world can be mapped to the virtual world for simultaneous
    analysis in real time. Simultaneously, the PCM wall construction and thermal energy
    storage and distribution model of the thermoelectric intelligent building are
    built. When power generation is required, the thermal energy scheduling mode used
    here transfers building wall thermal energy through a generator into electrical
    energy for user-end usage. Experimental evaluations show that the energy storage
    capacity of building walls consistently remains in the range of 0.2 ∼ 0.8 on an
    all-weather scale. From the perspective of cost consumption, the economic cost,
    environmental cost, and energy cost of the model reported are significantly lower
    than the existing model. This work contributes to the subsequent intelligent development
    of the building field and sustainable economic development. However, there are
    some deficiencies in this work. For the convenience of modeling and calculation,
    this work did not consider the impact of numerous other secondary factors, such
    as temperature fluctuations in the environment, PV cell temperature variations,
    and wind speed, on building wall energy storage scheduling. Therefore, follow-up
    research will improve the environmental factors and uncertainties in the building
    construction process to explore the effect of the robust dispatching strategy
    of the building microgrid. In addition, different residents'' preferences for
    temperature were not taken into account. It is also an added factor in the improvement
    of the energy storage system of the subsequent intelligent building to put the
    system into practice against time. CRediT authorship contribution statement Zhihan
    Lv: Conceptualization, Methodology, Writing – original draft, Writing – review
    & editing. Chen Cheng: Methodology, Software, Investigation, Writing – original
    draft. Haibin Lv: Writing – original draft, Writing – review & editing, Supervision.
    Declaration of Competing Interest The authors declare that they have no known
    competing financial interests or personal relationships that could have appeared
    to influence the work reported in this paper. Data availability The authors do
    not have permission to share data. References [1] C. Cheng, J. Dou, Z. Zheng Energy-efficient
    SDN for Internet of Things in smart city Internet of Things and Cyber-Physical
    Systems, 2 (2022), pp. 145-158 View PDFView articleView in ScopusGoogle Scholar
    [2] S.I. Hussain, S. Kalaiselvam Nanoencapsulation of oleic acid phase change
    material with Ag2O nanoparticles-based urea formaldehyde shell for building thermal
    energy storage J Therm Anal Calorim, 140 (1) (2020), pp. 133-147 CrossRefView
    in ScopusGoogle Scholar [3] B. Maleki, A. Khadang, H. Maddah, M. Alizadeh, A.
    Kazemian, H.M. Ali Development and thermal performance of nanoencapsulated PCM/plaster
    wallboard for thermal energy storage in buildings J Build Eng, 32 (2020), Article
    101727 View PDFView articleView in ScopusGoogle Scholar [4] S.O. Abioye, L.O.
    Oyedele, L. Akanbi, A. Ajayi, J.M.D. Delgado, M. Bilal, et al. Artificial intelligence
    in the construction industry: A review of present status, opportunities and future
    challenges J Build Eng, 44 (2021), Article 103299 View PDFView articleView in
    ScopusGoogle Scholar [5] Xiong Y, Song C, Ren J, Jin Y, Nie B, Xu Q, et al., Sludge-incinerated
    ash based shape-stable phase change composites for heavy metal fixation and building
    thermal energy storage. Process Safety Environ Protect; 2022, 162, 346-356. Google
    Scholar [6] Z. Jiang, M.E.N. Rivero, X. Liu, X. She, Y. Xuan, Y. Ding A novel
    composite phase change material for medium temperature thermal energy storage
    manufactured with a scalable continuous hot-melt extrusion method Appl Energy,
    303 (2021), Article 117591 View PDFView articleView in ScopusGoogle Scholar [7]
    W. Wang, X. He, Y. Shuai, J. Qiu, Y. Hou, Q. Pan Experimental study on thermal
    performance of a novel medium-high temperature packed-bed latent heat storage
    system containing binary nitrate Appl Energy, 309 (2022), Article 118433 View
    PDFView articleView in ScopusGoogle Scholar [8] S. Yang, J. Tan, B. Chen Robust
    spike-based continual meta-learning improved by restricted minimum error entropy
    criterion Entropy, 24 (4) (2022), p. 455 Google Scholar [9] S. Yang, B. Linares-Barranco,
    B. Chen Heterogeneous ensemble-based spike-driven few-shot online learning Front
    Neurosci, 16 (2022), Article 850932 View in ScopusGoogle Scholar [10] S. Yang,
    T. Gao, J. Wang, B. Deng, M.R. Azghadi, T. Lei, et al. SAM: a unified self-adaptive
    multicompartmental spiking neuron model for learning with working memory Front
    Neurosci, 16 (2022), Article 850945 View in ScopusGoogle Scholar [11] G. Krishna,
    R. Singh, A. Gehlot, S.V. Akram, N. Priyadarshi, B. Twala Digital Technology Implementation
    in Battery-Management Systems for Sustainable Energy Storage: Review, Challenges,
    and Recommendations Electronics, 11 (17) (2022), p. 2695 CrossRefView in ScopusGoogle
    Scholar [12] J. Henzel, Ł. Wróbel, M. Fice, M. Sikora Energy consumption forecasting
    for the digital-twin model of the building Energies, 15 (12) (2022), p. 4318 CrossRefView
    in ScopusGoogle Scholar [13] S. Agostinelli, F. Cumo, G. Guidi, C. Tomazzoli Cyber-physical
    systems improving building energy management: Digital twin and artificial intelligence
    Energies, 14 (8) (2021), p. 2338 CrossRefView in ScopusGoogle Scholar [14] Z.
    Lv, J. Guo, A.K. Singh, H. Lv Digital Twins Based VR Simulation for Accident Prevention
    of Intelligent Vehicle IEEE Trans Veh Technol, 71 (4) (2022), pp. 3414-3428 CrossRefView
    in ScopusGoogle Scholar [15] Coelho L, Koukou MK, Dogkas G, Konstantaras J, Vrachopoulos
    MG, Rebola A, et al., Latent thermal energy storage application in a residential
    building at a mediterranean climate. Energies; 2022. 15(3), 1008. Google Scholar
    [16] S. Swaminathan, G.S. Pavlak, J. Freihaut Sizing and dispatch of an islanded
    microgrid with energy flexible buildings Appl Energy, 276 (2020), Article 115355
    View PDFView articleView in ScopusGoogle Scholar [17] R.M. Ramli, W.A. Jabbar
    Design and implementation of solar-powered with IoT-Enabled portable irrigation
    system Internet of Things and Cyber-Physical Systems, 2 (2022), pp. 212-225 View
    PDFView articleView in ScopusGoogle Scholar [18] B. Yang, Z. Lv, F. Wang Digital
    Twins for Intelligent Green Buildings Buildings, 12 (6) (2022), p. 856 CrossRefView
    in ScopusGoogle Scholar [19] L. Li, T. Qu, Y. Liu, R.Y. Zhong, G. Xu, H. Sun,
    et al. Sustainability Assessment of Intelligent Manufacturing Supported by Digital
    Twin IEEE Access, 8 (2020), pp. 174988-175008 CrossRefView in ScopusGoogle Scholar
    [20] G. White, A. Zink, L. Codecá, S. Clarke A digital twin smart city for citizen
    feedback Cities, 110 (2021), Article 103064 View PDFView articleView in ScopusGoogle
    Scholar [21] C. Chen, Z. Zhao, J. Xiao, R. Tiong A conceptual framework for estimating
    building embodied carbon based on digital twin technology and life cycle assessment
    Sustainability, 13 (24) (2021), p. 13875 CrossRefView in ScopusGoogle Scholar
    [22] R.S. Ravi, A. Jolfaei, D. Tripathy, M. Ali Secured energy ecosystems under
    Distributed Energy Resources penetration Internet of Things and Cyber-Physical
    Systems, 2 (2022), pp. 194-202 View PDFView articleView in ScopusGoogle Scholar
    [23] K. Antoniadou-Plytaria, D. Steen, O. Carlson, M.A.F. Ghazvini Market-Based
    Energy Management Model of a Building Microgrid Considering Battery Degradation
    IEEE Trans Smart Grid, 12 (2) (2020), pp. 1794-1804 Google Scholar [24] Q. Cui,
    P. Ma, L. Huang, J. Shu, J. Luv, L. Lu Effect of device models on the multiobjective
    optimal operation of CCHP microgrids considering shiftable loads Appl Energy,
    275 (2020), Article 115369 View PDFView articleView in ScopusGoogle Scholar [25]
    F. Ren, Z. Wei, X. Zhai Multiobjective optimization and evaluation of hybrid CCHP
    systems for different building types Energy, 215 (2021), Article 119096 View PDFView
    articleView in ScopusGoogle Scholar [26] X. Dong, C. Zhang, B. Sun Optimization
    strategy based on robust model predictive control for RES-CCHP system under multiple
    uncertainties Appl Energy, 325 (2022), Article 119707 View PDFView articleView
    in ScopusGoogle Scholar [27] Q. Lin, Y.C. Chen, F. Chen, T. DeGanyar, H. Yin Design
    and experiments of a thermoelectric-powered wireless sensor network platform for
    smart building envelope Appl Energy, 305 (2022), Article 117791 View PDFView articleView
    in ScopusGoogle Scholar [28] Y. Zou, R. Li, X. Zhang, J. Song Five-dimensional
    model research of complex product assembly driven by digital twin Int J Wirel
    Mob Comput, 21 (3) (2021), pp. 198-206 CrossRefView in ScopusGoogle Scholar [29]
    K. Shen, L. Ding, C.C. Wang Development of a Framework to Support Whole-Life-Cycle
    Net-Zero-Carbon Buildings through Integration of Building Information Modelling
    and Digital Twins Buildings, 12 (10) (2022), p. 1747 CrossRefView in ScopusGoogle
    Scholar [30] S. Ma, W. Ding, Y. Liu, S. Ren, H. Yang Digital twin and big data-driven
    sustainable smart manufacturing based on information management systems for energy-intensive
    industries Appl Energy, 326 (2022), Article 119986 View PDFView articleView in
    ScopusGoogle Scholar [31] B. Teisserenc, S. Sepasgozar Adoption of blockchain
    technology through digital twins in the construction industry 4.0: A pestels approach
    Buildings, 11 (12) (2021), p. 670 CrossRefView in ScopusGoogle Scholar [32] M.
    Nazari Sam, A. Caggiano, C. Mankel, E. Koenders A comparative study on the thermal
    energy storage performance of bio-based and paraffin-based PCMs using DSC procedures
    Materials, 13 (7) (2020), p. 1705 CrossRefGoogle Scholar [33] A. Abderrahmane,
    N.A. Qasem, A. Mourad, M. Al-Khaleel, Z. Said, K. Guedri, et al. Enhancing the
    melting process of shell-and-tube PCM thermal energy storage unit using modified
    tube design Nanomaterials, 12 (17) (2022), p. 3078 CrossRefView in ScopusGoogle
    Scholar [34] L. Liu, X. Fan, Y. Zhang, S. Zhang, W. Wang, X. Jin, et al. Novel
    bio-based phase change materials with high enthalpy for thermal energy storage
    Appl Energy, 268 (2020), Article 114979 View PDFView articleView in ScopusGoogle
    Scholar [35] D. Vérez, E. Borri, A. Crespo, B.D. Mselle, Á. de Gracia, G. Zsembinszki,
    et al. Experimental Study on Two PCM Macro-Encapsulation Designs in a Thermal
    Energy Storage Tank Appl Sci, 11 (13) (2021), p. 6171 CrossRefView in ScopusGoogle
    Scholar [36] S. Zhang, D. Feng, L. Shi, L. Wang, Y. Jin, L. Tian, et al. A review
    of phase change heat transfer in shape-stabilized phase change materials (ss-PCMs)
    based on porous supports for thermal energy storage Renew Sustain Energy Rev,
    135 (2021), Article 110127 View PDFView articleView in ScopusGoogle Scholar [37]
    A. Abderrahmane, O. Younis, M. Al-Khaleel, H. Laidoudi, N. Akkurt, K. Guedri,
    et al. 2D MHD mixed convection in a zigzag trapezoidal thermal energy storage
    system using NEPCM Nanomaterials, 12 (19) (2022), p. 3270 CrossRefView in ScopusGoogle
    Scholar [38] G. Chiriac, D.D. Lucache, C. Nițucă, A. Dragomir, S. Ramakrishna
    Electric bus indoor heat balance in cold weather Appl Sci, 11 (24) (2021), p.
    11761 CrossRefView in ScopusGoogle Scholar [39] C. Kim, M.C. Dinh, H.J. Sung,
    K.H. Kim, J.H. Choi, L. Graber, et al. Design, implementation, and evaluation
    of an output prediction model of the 10 MW floating offshore wind turbine for
    a digital twin Energies, 15 (17) (2022), p. 6329 CrossRefView in ScopusGoogle
    Scholar [40] D. Popescu, M. Dragomir, S. Popescu, D. Dragomir Building Better
    digital twins for production systems by incorporating environmental related functions—literature
    analysis and determining alternatives Appl Sci, 12 (17) (2022), p. 8657 CrossRefView
    in ScopusGoogle Scholar [41] F.J. Folgado, I. González, A.J. Calderón PEM electrolyser
    digital twin embedded within MATLAB-based graphical user interface Eng Proc, 19
    (1) (2022), p. 21 CrossRefView in ScopusGoogle Scholar [42] P. Pekárová, A. Tall,
    J. Pekár, J. Vitková, P. Miklánek Groundwater temperature modelling at the water
    table with a simple heat conduction model Hydrology, 9 (10) (2022), p. 185 CrossRefView
    in ScopusGoogle Scholar [43] Z. Zhao, J. Nan, M. Li Thermal management of serpentine
    flexible heater based on the orthotropic heat conduction model Micromachines,
    13 (4) (2022), p. 622 CrossRefView in ScopusGoogle Scholar [44] A. Odukomaiya,
    J. Woods, N. James, S. Kaur, K.R. Gluesenkamp, N. Kumar, et al. Addressing energy
    storage needs at lower cost via on-site thermal energy storage in buildings Energ
    Environ Sci, 14 (10) (2021), pp. 5315-5329 CrossRefView in ScopusGoogle Scholar
    Cited by (7) Disodium hydrogen phosphate dodecahydrate/fumed silica composites
    with high latent heat and suitable phase change temperature for use in building
    roof 2024, Journal of Energy Storage Show abstract Digitalization in response
    to carbon neutrality: Mechanisms, effects and prospects 2024, Renewable and Sustainable
    Energy Reviews Show abstract Developing an integrative framework for digital twin
    applications in the building construction industry: A systematic literature review
    2024, Advanced Engineering Informatics Show abstract Enabling coordination in
    energy communities: A Digital Twin model 2024, Energy Policy Show abstract A super-real-time
    three-dimension computing method of digital twins in space nuclear power 2023,
    Computer Methods in Applied Mechanics and Engineering Show abstract Literature
    review of digital twin technologies for civil infrastructure 2023, Journal of
    Infrastructure Intelligence and Resilience Show abstract View all citing articles
    on Scopus © 2023 The Author(s). Published by Elsevier Ltd. Part of special issue
    Utilization of energy storage in buildings Edited by Xiaohu Yang, Kamel Hooman,
    Sandra Boetcher, Jinyue Yan, Zhibin Yu View special issue Recommended articles
    A fuzzy-set-based joint distribution adaptation method for regression and its
    application to online damage quantification for structural digital twin Mechanical
    Systems and Signal Processing, Volume 191, 2023, Article 110164 Xuan Zhou, …,
    Leiting Dong View PDF A novel predictive control based management strategy considering
    smart PHEV in digital twin simulation Solar Energy, Volume 252, 2023, pp. 291-308
    Jinsong Zhan, …, Wei Hu View PDF Underactuated digital twin''s robotic hands with
    tactile sensing capabilities for well-being Digital Twin for Healthcare, 2023,
    pp. 15-38 Mohd Faisal, …, Abdulmotaleb El Saddik Show 3 more articles Article
    Metrics Citations Citation Indexes: 6 Captures Readers: 66 View details About
    ScienceDirect Remote access Shopping cart Advertise Contact and support Terms
    and conditions Privacy policy Cookies are used by this site. Cookie settings |
    Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V.,
    its licensors, and contributors. All rights are reserved, including those for
    text and data mining, AI training, and similar technologies. For all open access
    content, the Creative Commons licensing terms apply.'
  inline_citation: '>'
  journal: Applied energy
  limitations: '>'
  pdf_link: null
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: Digital twins for secure thermal energy storage in building
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.34133/icomputing.0006
  analysis: '>'
  authors:
  - Shiqiang Zhu
  - Tong Yu
  - Tao Xu
  - Hongyang Chen
  - Schahram Dustdar
  - Sylvain Gigan
  - Deniz Gündüz
  - Ekram Hossain
  - Yaochu Jin
  - Feng Huei Lin
  - Bo Liu
  - Zhiguo Wan
  - Ji Zhang
  - Zhifeng Zhao
  - Wentao Zhu
  - Zuoning Chen
  - T.S. Durrani
  - Huaimin Wang
  - Jiangxing Wu
  - Tong‐Yi Zhang
  - Yunhe Pan
  citation_count: 27
  full_citation: '>'
  full_text: '>

    Web Store Add shortcut Name URL Customize Chrome'
  inline_citation: '>'
  journal: Intelligent computing
  limitations: '>'
  pdf_link: https://spj.science.org/doi/pdf/10.34133/icomputing.0006?download=true
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: 'Intelligent Computing: The Latest Advances, Challenges, and Future'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.20944/preprints202010.0429.v1
  analysis: '>'
  authors:
  - Rodrigo Filev Maia
  - Carlos Ballester
  - Arbind Agrahari Baniya
  - John Hornbuckle
  citation_count: 1
  full_citation: '>'
  full_text: '>

    This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details             Deny Allow selection
    Allow all Instructions for Authors Awards About FAQ Submit Log in/Register preprints.org
    > computer science and mathematics > algebra and number theory > doi: 10.20944/preprints202010.0429.v1
    Preprint Article Version 1 Preserved in Portico This version is not peer-reviewed
    IRRISENS: An IoT Platform Based on Microservices Applied in Commercial-Scale Crops
    Working in a Multi-Cloud Environment Rodrigo Filev Maia * , Carlos Ballester Lurbe
    , Arbind Agrahari Baniya , John Hornbuckle Version 1 : Received: 20 October 2020
    / Approved: 21 October 2020 / Online: 21 October 2020 (10:40:16 CEST) A peer-reviewed
    article of this Preprint also exists. Filev Maia, R.; Ballester Lurbe, C.; Agrahari
    Baniya, A.; Hornbuckle, J. IRRISENS: An IoT Platform Based on Microservices Applied
    in Commercial-Scale Crops Working in a Multi-Cloud Environment. Sensors 2020,
    20, 7163. Copy Abstract Research has shown the multitude of applications that
    IoT, cloud computing and forecast technologies present in every sector. In agriculture,
    one application is the monitoring of factors that influence crop development to
    assist in making crop management decisions. Research on the application of such
    technologies in agriculture has been mainly conducted at small experimental sites
    or under controlled conditions. This research has provided relevant insights and
    guidelines for the use of different types of sensors, application of a multitude
    of algorithms to forecast relevant parameters as well as architectural approaches
    of IoT platforms. However, research on the implementation of IoT platforms at
    the commercial scale is needed to identify platform requirements to properly function
    under such conditions. This article evaluates an IoT platform (IRRISENS) based
    on fully replicable microservices used to sense soil, crop and atmosphere parameters,
    interact with third party cloud services, planning and scheduling irrigation as
    well as control of irrigation water control devices. The proposed IoT platform
    was evaluated during one growing season at four commercial scale farms on two
    different broadacre irrigated crops with very different water management requirements
    (rice and cotton). Five main requirements for IoT platforms to be used in agriculture
    at commercial scale were identified from implementing IRRISENS in rice and cotton
    production: scalability, flexibility, heterogeneity, robustness to failure and
    security. The platform addressed all these requirements. The results showed that
    the microservice approach followed in the platform is robust against both intermittent
    and critical failures in the field that could occur in any of the monitored sites.
    Further, processing or storage overload caused for any reason at one farm did
    not affect the performance of the platform regarding the other monitored farms.
    This paper also discusses how the microservice approach can address the data heterogeneity
    issue when crops with different management requirements are monitored. Since there
    are no shared microservices among farms, the IoT platform proposed here also provides
    data isolation maintaining data confidentiality for each user, which is relevant
    in a commercial farm scenario. Keywords IoT platform; microservice; smart agriculture;
    irrigated crops; Agriculture 4.0 Subject Computer Science and Mathematics, Algebra
    and Number Theory Copyright: This is an open access article distributed under
    the Creative Commons Attribution License which permits unrestricted use, distribution,
    and reproduction in any medium, provided the original work is properly cited.
    Download PDF Comments (0) We encourage comments and feedback from a broad range
    of readers. See criteria for comments and our Diversity statement. Leave a public
    comment Send a private comment to the author(s) * All users must log in before
    leaving a comment Related Articles Peer-review Articles Latency-Adjustable Cloud/Fog
    Computing Architecture for Time-Sensitive Environmental Monitoring in Olive Groves
    Athanasios Tsipis et al. AgriEngineering, 2020 A Context-Aware Middleware Cloud
    Approach for Integrating Precision Farming Facilities into the IoT toward Agriculture
    4.0 Eleni Symeonaki et al. Applied Sciences, 2020 Precision Agriculture Design
    Method Using a Distributed Computing Architecture on Internet of Things Context
    Francisco Ferrández-Pastor et al. Sensors, 2018 An IoT Platform Based on Microservices
    and Serverless Paradigms for Smart Farming Purposes Sergio Trilles et al. Sensors,
    2020 Irriman Platform: Enhancing Farming Sustainability through Cloud Computing
    Techniques for Irrigation Management Manuel Forcén-Muñoz et al. Sensors, 2021
    Smart Farming Techniques for Climate Change Adaptation in Cyprus George Adamides
    et al. Atmosphere, 2020 Extending ONTAgri with Service-Oriented Architecture towards
    Precision Farming Application Muhammad Fahad et al. Sustainability, 2021 CultivData:
    Application of IoT to the Cultivation of Agricultural Data Felipe Lemus-Prieto
    et al. IoT, 2021 A Cloud-Based IoT Platform for Precision Control of Soilless
    Greenhouse Cultivation Alaa Sagheer et al. Sensors, 2020 Development of a Low-Cost
    Open-Source Platform for Smart Irrigation Systems Francisco Puig et al. Agronomy,
    2022 Views 189 Downloads 281 Comments 0 Get PDF Cite Share 0 Bookmark BibSonomy
    Mendeley Reddit Delicious Alerts Notify me about updates to this article or when
    a peer-reviewed version is published. Preprints.org is a free preprint server
    subsidized by MDPI in Basel, Switzerland. Contact us RSS MDPI Initiatives SciProfiles
    Sciforum Encyclopedia MDPI Books Scilit Proceedings JAMS Important links How it
    Works Advisory Board FAQ Friendly Journals Instructions for Authors About Statistics
    Subscribe Choose the area that interest you and we will send you notifications
    of new preprints at your preferred frequency. Subscribe © 2024 MDPI (Basel, Switzerland)
    unless otherwise stated Disclaimer Privacy Policy Terms of Use  Feedback'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: 'IRRISENS: An IoT Platform Based on Microservices Applied in Commercial-Scale
    Crops Working in a Multi-Cloud Environment'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.15760/etd.3567
  analysis: '>'
  authors:
  - Asunción Santamaría
  citation_count: 1
  full_citation: '>'
  full_text: ">\nPortland State University \nPortland State University \nPDXScholar\
    \ \nPDXScholar \nDissertations and Theses \nDissertations and Theses \n6-2-2023\
    \ \nA Policy Proposal for Agricultural Data Governance \nA Policy Proposal for\
    \ Agricultural Data Governance \nAna Sofía Castellanos Santamaría \nPortland State\
    \ University \nFollow this and additional works at: https://pdxscholar.library.pdx.edu/open_access_etds\
    \ \n Part of the Agriculture Commons, Public Administration Commons, and the Public\
    \ Policy Commons \nLet us know how access to this document benefits you. \nRecommended\
    \ Citation \nRecommended Citation \nCastellanos Santamaría, Ana Sofía, \"A Policy\
    \ Proposal for Agricultural Data Governance\" (2023). \nDissertations and Theses.\
    \ Paper 6422. \nhttps://doi.org/10.15760/etd.3567 \nThis Dissertation is brought\
    \ to you for free and open access. It has been accepted for inclusion in Dissertations\
    \ \nand Theses by an authorized administrator of PDXScholar. Please contact us\
    \ if we can make this document more \naccessible: pdxscholar@pdx.edu. \n \nA Policy\
    \ Proposal for Agricultural Data Governance \n \n \n \nby \n \nAna Sofía Castellanos\
    \ Santamaría \n \n \n \n \n \n \nA dissertation submitted in partial fulfillment\
    \ of the \nrequirements for the degree of \n \n \n \n \n \nDoctor of Philosophy\
    \ \nin \nPublic Affairs and Policy \n \n \n \n \nDissertation Committee: \nBruce\
    \ Gilley, Chair \nJennifer Allen \nMellie Pullman \nBirol Yesilada \nPortland\
    \ State University \n2023 \n \ni \nAbstract \nAs the digital economy continues\
    \ to grow and data becomes increasingly important, \neffective data governance\
    \ is essential. A data governance framework enables the efficient \nmanagement,\
    \ sharing, and integration of data, resulting in better decision-making, \nincreased\
    \ productivity, and enhanced innovation across industries, including agriculture.\
    \ \nHowever, the agricultural sector in the United States is lagging behind other\
    \ industries in \nthe adoption of effective data governance practices. Agricultural\
    \ data governance presents \na unique set of challenges due to the wide range\
    \ of stakeholders involved and the ever-\nincreasing volume of data generated\
    \ by digital technologies in farming. One key challenge \nto achieving the benefits\
    \ of effective agricultural data governance is the lack of a robust \npolicy framework.\
    \ \nTo address this issue, this doctoral dissertation utilizes a rigorous policy\
    \ analysis \nmethodology to examine the current data governance policy frameworks,\
    \ identify gaps and \nareas for improvement, and propose a comprehensive policy\
    \ framework for agricultural \ndata governance. The proposed policy framework\
    \ is informed by the policy analysis and \ndesigned to be adaptable and scalable\
    \ to meet the changing needs of the digital economy \nand the agriculture sector.\
    \ It addresses the challenges posed by the ever-increasing volume \nof agricultural\
    \ data and aims to enhance the digital transformation of the agriculture sector.\
    \ \n \nii \nTable of Contents \nAbstract ...............................................................................................................................\
    \ i \nList of Tables ....................................................................................................................\
    \ iv \nList of Figures ....................................................................................................................\
    \ v \nIntroduction .......................................................................................................................\
    \ 1 \nChapter 1: Research Question and Methods..................................................................\
    \ 8 \nResearch Gap ..................................................................................................................\
    \ 9 \nOntology .......................................................................................................................\
    \ 12 \nPolicy Science versus Social Science ...........................................................................\
    \ 14 \nResearch Design and Methods ......................................................................................\
    \ 15 \nChapter 2: The Policy Problem .....................................................................................\
    \ 19 \nAgricultural Data and Data Governance .......................................................................\
    \ 19 \n▪ \nAgricultural Data ..............................................................................................\
    \ 19 \n▪ \nData Governance ..............................................................................................\
    \ 37 \n▪ \nData Governance Policy Framework ...............................................................\
    \ 38 \nThe Sense of Problem ...................................................................................................\
    \ 45 \nProblem Structuring Methods .......................................................................................\
    \ 50 \n▪ \nContent Analysis ...............................................................................................\
    \ 54 \n▪ \nVOS-Viewer Software Analysis .........................................................................\
    \ 59 \n▪ \nBoundary Analysis ............................................................................................\
    \ 62 \nStatement of Policy Problem ........................................................................................\
    \ 65 \nChapter 3: Policy Options ..............................................................................................\
    \ 69 \nGeneric Standards .........................................................................................................\
    \ 69 \nCodes of Practice ..........................................................................................................\
    \ 73 \n▪ \nNew Zealand Farm Data Code of Practice ......................................................\
    \ 76 \n▪ \nEuropean Union Code of Conduct on Agricultural Data Sharing by \nContractual\
    \ Agreement .............................................................................................\
    \ 77 \n▪ \nAustralia Agricultural Data Rules: Enabling Best Practices ...........................\
    \ 80 \n▪ \nThe U.S. Privacy and Security Principles for Farm Data ................................\
    \ 82 \nU.S. Data Cooperatives .................................................................................................\
    \ 87 \nU.S. National and State-Level Laws and Regulations ..................................................\
    \ 90 \nLesson Drawing and Benchmarking .............................................................................\
    \ 97 \nPolicy Options Design ................................................................................................\
    \ 101 \n▪ \nOption 1: Minimalist .......................................................................................\
    \ 108 \n▪ \nOption 2: Moderate.........................................................................................\
    \ 113 \n▪ \nOption 3: Maximalist ......................................................................................\
    \ 118 \nChapter 4: Policy Proposal ..........................................................................................\
    \ 126 \nProjection ....................................................................................................................\
    \ 128 \nPrediction ....................................................................................................................\
    \ 131 \n \niii \nExpert judgment or Conjecture ...................................................................................\
    \ 135 \nA Two-Stage Model for Agricultural Data Governance Policy Framework ..............\
    \ 137 \n▪ \nPrescription: The Final Step in Agricultural Data Governance Policy\
    \ Analysis\n \n148 \nCost Effective Analysis...............................................................................................\
    \ 150 \nCosts and Benefits.......................................................................................................\
    \ 153 \nFindings.......................................................................................................................\
    \ 163 \nConclusion .....................................................................................................................\
    \ 165 \nBibliography ..................................................................................................................\
    \ 168 \nAppendix: Tables for the Application of Forecasting Policy Analysis Methods\
    \ ..... 174 \n \n \n \n \niv \nList of Tables \nTable 1 Methods of Policy Analysis\
    \ .................................................................................\
    \ 16 \nTable 2 Agricultural Data Taxonomy ...............................................................................\
    \ 22 \nTable 3 The U.S. Agriculture Agencies ............................................................................\
    \ 24 \nTable 4 Other U.S Agencies in the Agriculture Sector .....................................................\
    \ 26 \nTable 5 Players in the agriculture industry in the United States .......................................\
    \ 30 \nTable 6 Data Practices and Providers ...............................................................................\
    \ 31 \nTable 7 Users of Agricultural Data ...................................................................................\
    \ 32 \nTable 8 Data Governance Safeguards and Enablers, and the 7 Dimensions and\
    \ Regulatory \nIssues .................................................................................................................................\
    \ 41 \nTable 9 Characteristics of Three Methods of Problem Structuring ..................................\
    \ 51 \nTable 10 Key Agricultural Data Problems........................................................................\
    \ 57 \nTable 11 Comparison of the criteria to classify structured policy problems\
    \ .................... 67 \nTable 12 Agricultural Data Cooperatives in the U.S\
    \ ........................................................ 88 \nTable 13 Minnesota\
    \ Agricultural Data Types Regulation ................................................\
    \ 93 \nTable 14 Government role and what they should do ......................................................\
    \ 103 \nTable 15 Three Policy Options for an Agricultural Data Governance ...........................\
    \ 107 \nTable 16 Comparison of the three policy options ...........................................................\
    \ 123 \nTable 17 Forecasting Methods ........................................................................................\
    \ 126 \nTable 18 Questions to be answered by the agricultural data governance\
    \ policy options for \na policy problem feasibility analysis...............................................................................\
    \ 139 \nTable 19 Prediction of a Policy Option for Agricultural Data Governance\
    \ ................... 140 \nTable 20 Six dimensions for policy prescription analysis\
    \ for agricultural data governance\n.........................................................................................................................................\
    \ 141 \nTable 21 Questions to be answered by the agricultural data governance\
    \ policy options for \na policy process feasibility analysis ................................................................................\
    \ 143 \nTable 22 Prediction of a policy option for agricultural data governance\
    \ in the policy \nprocess adoption..............................................................................................................\
    \ 144 \nTable 23 Cost Effectiveness Analysis.............................................................................\
    \ 153 \nTable 24 Estimated direct and indirect benefits from a policy framework\
    \ to govern \nagricultural data ..............................................................................................................\
    \ 154 \nTable 25 Estimated direct, indirect and risk costs in this study ......................................\
    \ 159 \n \n \n \n \nv \nList of Figures \nFigure 1 Evolving Agricultural Methods\
    \ and Technologies ............................................... 5 \nFigure\
    \ 2 The Explanatory Cycle .......................................................................................\
    \ 13 \nFigure 3 Policy Analysis Process for Agriculture Data Governance Policy\
    \ Framework . 17 \nFigure 4 Cycle of Agricultural Data .................................................................................\
    \ 24 \nFigure 5 A visual representation of the information that one farmer reports\
    \ to various \nUSDA agencies .................................................................................................................\
    \ 27 \nFigure 6 Technology companies digitally transforming farming .....................................\
    \ 28 \nFigure 7 Main-actors in public and private ag data in the U.S. ........................................\
    \ 35 \nFigure 8 A Data Value Chain............................................................................................\
    \ 36 \nFigure 9 Data Governance Policy Framework..................................................................\
    \ 39 \nFigure 10 Data Governance Safeguards and Enablers Regulatory Dimensions\
    \ ............... 40 \nFigure 11 Keywords co-occurrence network-based map of agricultural\
    \ data problem .... 61 \nFigure 12 Explanation of the boundary analysis three-step\
    \ process ................................. 64 \nFigure 13 Boundary estimation\
    \ of agricultural data key problem factors ........................ 65 \nFigure\
    \ 14 Diagram of most relevant dimensions in the agricultural data governance \n\
    policy problem ..................................................................................................................\
    \ 66 \nFigure 15 Data Governance Policy Framework Components considered for Agricultural\
    \ \nData ...................................................................................................................................\
    \ 71 \nFigure 16 Comparison of existing COPs ..........................................................................\
    \ 85 \nFigure 17 Four Models to Modernize the USDA Agricultural Data Infrastructure\
    \ ......... 95 \nFigure 18 Agricultural Data Governance Policy Framework: regulatory\
    \ dimensions and \nattributes to design the policy options ..............................................................................\
    \ 99 \nFigure 19 Components of Policy Design ........................................................................\
    \ 101 \nFigure 20 Components of policy design for agricultural data governance\
    \ policy options\n.........................................................................................................................................\
    \ 105 \nFigure 21 Forecasting process structure .........................................................................\
    \ 128 \nFigure 22 Data Governance Collective Action Problem in Public Organizations..........\
    \ 133 \nFigure 23 Two-step Step Forecasting Prediction Process ..............................................\
    \ 138 \nFigure 24 Rate of each policy option addressing the agricultural data\
    \ governance policy \nproblem dimensions ........................................................................................................\
    \ 140 \nFigure 25 Rate of Policy Process Feasibility For each Policy Option ............................\
    \ 144 \n \n1 \nIntroduction \nIn today's digital economy, data governance plays\
    \ an increasingly vital role. A well-\ndesigned data governance framework facilitates\
    \ efficient data management, sharing, and \nintegration, leading to improved decision-making,\
    \ increased productivity, and enhanced \ninnovation across industries, including\
    \ agriculture. However, compared to other industries, \nthe agricultural sector\
    \ in the United States has been slow to adopt effective data governance \npractices.\
    \ This is due to the unique challenges presented by agricultural data governance,\
    \ \nincluding a diverse range of stakeholders and the growing volume of data generated\
    \ by \ndigital farming technologies. \nOne of the primary barriers to realizing\
    \ the benefits of effective data governance in \nagriculture is the lack of a\
    \ robust policy framework. To address this issue, this doctoral \nresearch provides\
    \ a policy analysis aimed at creating a comprehensive policy framework \nto enhance\
    \ agricultural data governance in the United States. The goal of this study is\
    \ to \nidentify opportunities to improve agricultural policies for the digital\
    \ transformation era. \nCurrently, digital technologies in farming range from\
    \ satellite-guided tractors to seed-\nselecting algorithms and crops developed\
    \ with gene-editing techniques (Bunge, 2021, p. \n3). These new technologies are\
    \ anticipated to increase productivity and drive a more \nsustainable and efficient\
    \ agriculture industry. While digital technologies are an important \ncomponent\
    \ of the agricultural sector's digital transformation, relying solely on them\
    \ is not \nsufficient for complete digitalization. \n \n2 \nEvery nozzle, pump,\
    \ valve, tank, and motor are equipped with sensors that can collect \nlarge amounts\
    \ of data as part of their regular operations (Featherstone, 2021, p. 1). For\
    \ \nexample, “…the amount of data generated per day by average farm exceeded 250\
    \ 000 data \npoints in 2015.” (Kosior, 2019a, p. 4) and an increase in agricultural\
    \ data generation is \nexpected “to exceed 2 million data points per day by 2030.”\
    \ (Kosior, 2019, p. 5). Data can \nbe combined from satellite maps, drone images,\
    \ routine soil samples, and weather and \nclimate reports. \nData generated from\
    \ all these technologies play a crucial role. Effective governance of \nthe large\
    \ amounts of agricultural data and recognizing its value, is essential to enhance\
    \ \nagriculture outcomes and maximize the sector's economic benefits. The digital\
    \ \ntransformation of agriculture involves boosting the sector's ability to not\
    \ only produce and \ngather data, but also to exchange and utilize data in new\
    \ and innovative ways. (Jouanjean \net al., 2020, p. 6). Therefore, farmers and\
    \ producers must view data as a potential strategic \nasset for their farms and\
    \ the industry as a whole.  \nIn the United States, there are various challenges\
    \ to the digital transform the agriculture \nsector, and use agricultural data\
    \ in smart agriculture1. For instance, Mr. Creighton’s corn \nfarm in Eleroy,\
    \ Illinois (Bunge, 2021, p, 1) is representative of farms that faces challenges\
    \ \ndue to the rise of digital technologies and the vast amount of data they collect.\
    \ As reported \nin the Wall Street Journal on August 22, 2021, one of the significant\
    \ difficulties that U.S. \n \n1 “The digitalization of agriculture involves the\
    \ development, adoption, and iteration of digital \ntechnologies in the agricultural\
    \ sector; what has been referred to as both digital agriculture (preferred in\
    \ \nAustralia and New Zealand) or smart farming (preferred in the European Union)\
    \ in different spatial \ncontexts.” (Fielke et al. 2020, p.3) \n \n3 \nfarms currently\
    \ face is working with agricultural technology providers (ATPs)2 to govern \n\
    data. \nIn this case, Mr. Creighton signed a contract with provider Indigo Agriculture\
    \ Inc. \nIndigo’s original concept was to “reshape the agriculture industry” (Bunge,\
    \ 2021, p.2) \nusing cutting-edge technology and a data platform to connect farmers\
    \ with buyers and get \nthe best prices in the market. They also marketed special\
    \ microbes to enhance seed \nproductivity, and farmers had the option to sell\
    \ their products at guaranteed premium prices \nthrough their program. Indigo’s\
    \ business strategy was to create a cluster of digital \nagricultural data platforms,\
    \ from seeds, to an online marketplace, and transport logistics. \nHowever, Mr.\
    \ Creighton faced difficulties, such as a large amount of paperwork, short \n\
    response times to his requests and concerns, and payment delays. This led to growing\
    \ \nmistrust of Indigo Inc. by Mr. Creighton.  \nSimilar to Mr. Creighton, many\
    \ farmers in the U.S. are encountering challenges with \nATPs entering the business\
    \ market and focusing on collecting agricultural data. One such \ncompany is Agrian\
    \ Inc., based in California. Agrian Inc. provides farmers with the tools to \n\
    comply with federal and state pesticide and chemical regulations and offers platforms\
    \ for \nharvest, application, and planting maps. Growers utilize these services\
    \ to create fertility \nrecommendations or to aggregate data to address agronomic\
    \ needs based on the maps. \n(Featherstone, 2021, p. 1) However, the ability to\
    \ aggregate agricultural data has raised \n \n2 Agricultural Technology Providers\
    \ (ATPs) could be categorized into nine main categories: farm \nmanagement software,\
    \ precision agriculture and predictive data analytics, sensors, animal data, robotics\
    \ \nand drones, smart irrigation, next gen farms, marketplaces, plant data/analysis.\
    \ Source of information \nCBInsights (2017) “The Ag tech market map: 100+ startups\
    \ powering the future of farming and \nagribusiness” Research Briefs. Available\
    \ at:  https://www.cbinsights.com/research/agriculture-tech-market-\nmap-company-list/\
    \ \n \n4 \nconcerns among farmers about data ownership, privacy and security as\
    \ well as the flows \nof data sharing. \nAnother challenge faced by U.S. farmers\
    \ is the lack of accessible digital tools for \nrepairing digital farming equipment.\
    \ As noted at a small cattle farm in Cape Girardeau, \nMissouri, (O’Reilly, 2021),\
    \ the farmer, Mr. Hovis struggled to find software tools needed \nto sync a new\
    \ part to his tractor. The cost of acquiring the necessary technology for repairs\
    \ \nwas just as high as the farm itself. To address this issue, Mr. Hovis filed\
    \ a right-to-repair \nbill in January 2021, and many other farmers across the\
    \ United States are also pushing for \n“right to repair” laws that would require\
    \ manufacturers to provide easy access to tools, \nsoftware parts, and documentation.\
    \ This effort is gaining support from state farm bureaus, \nfarmers unions3, and\
    \ lawmakers from both parties in states like Florida, Montana, and \nNebraska\
    \ (O’Reilly, 2021). \nThe challenges faced by farmers like Mr. Creighton and Mr.\
    \ Hovis, highlight the \ndifficulties that U.S. farmers encounter with technology\
    \ and data in the modern agriculture \nindustry. Despite the benefits of technology\
    \ and data in improving farming efficiency, \ngoverning agricultural data remains\
    \ a critical issue that needs to be addressed. The situation \nof Mr. Creighton\
    \ with ATPs and Mr. Hovis with software tools demonstrate the need for \n \n3\
    \ On January 2023, the American Farm Bureau Federation (AFBF) and John Deere signed\
    \ a \nmemorandum of understanding that guarantees farmers' right to repair their\
    \ own farm equipment (AFBF, \n2023). This agreement was the result of years of\
    \ discussions between the two organizations. The MOU \noutlines a plan to address\
    \ farmers' concerns and John Deere promises to work with farmers and dealers to\
    \ \nresolve any issues that arise, while also committing to bi-annual evaluations\
    \ with the AFBF. The MOU \ngrants farmers access to repair codes, manuals, product\
    \ guides, and the ability to purchase diagnostic tools \ndirectly from John Deere.\
    \ The manufacturer also offers assistance with ordering parts and products. This\
    \ \nagreement could serve as a blueprint for other manufacturers, and AFBF has\
    \ already initiated talks for the \nsame. However, the John Deere - AFBF MOU is\
    \ a non-binding agreement between one equipment \nmanufacturer and one group representing\
    \ farmers in the U.S. (National Farmers Union, 2023). \n \n5 \nfarmers to have\
    \ more control over the technology they use and access to necessary \ninformation\
    \ to repair their equipment. This reflects the ongoing tensions in the agriculture\
    \ \nindustry between the benefits of technology and the challenges of data governance\
    \ and \nmaintenance. \nFigure 1 highlights the history of innovation in the agricultural\
    \ sector and showcases \nthe challenges faced by U.S. farms in adapting to the\
    \ changing methods and technologies \nduring the process of digital transformation.\
    \ \nFigure 1 Evolving Agricultural Methods and Technologies \n \nSource:4 Ayushee\
    \ Sharma (2020). Industry 4.0 Driving Agricultural Revolution. \nThe Figure 1\
    \ demonstrates the ongoing trend of farmers embracing new technologies \nand techniques\
    \ in an effort to improve their operations. From early innovations such as \n\
    plows and irrigation systems to the most recent advances in precision agriculture,\
    \ the \n \n4 Information and graphic available at: https://iot.electronicsforu.com/content/tech-trends/industry-4-\n\
    driving-agricultural-revolution/ \n \n6 \nagricultural industry has always sought\
    \ ways to make farming more efficient, sustainable, \nand profitable (OECD, 2019a,\
    \ p. 21). The incorporation of digital technologies and data \ncollection in the\
    \ form of smart agriculture allows the sector to advance these efforts and \n\
    overcome some of the challenges faced by farmers and producers. By embracing digital\
    \ \ntransformation, the industry can use data to make better decisions, increase\
    \ productivity, \nreduce waste, and reduce negative environmental impacts. The\
    \ key is to ensure that the \ndata generated is effectively managed and that farmers\
    \ and producers can access and use it \nin ways that benefit both themselves and\
    \ the larger sector. \nThe FAO's Status Report on Digital Technologies in Agriculture\
    \ and Rural Areas states \nthat the growth of the market will be driven by the\
    \ gradual integration of advanced and \ninterconnected digital solutions, along\
    \ with the rise of big data analytics (Trendov, et al. \n2019, p.80). This highlights\
    \ the fact that the implementation of smart or digital agriculture \nnot only\
    \ requires a significant investment in digital tools and technology but also a\
    \ shift in \nthinking5 to address the new challenges brought about by data and\
    \ its usage. \nAdditionally, farmers are concerned about data ownership, privacy,\
    \ and security, which \nhighlights the need for clear and concise policies on\
    \ data sharing and use in the agricultural \nsector. This is especially important\
    \ in the context of the U.S., where there is a growing \nmarket of ATPs that aim\
    \ to aggregate and use farm data. Farmers need to understand the \n \n5 The shift\
    \ to digital agriculture requires not just the use of new technology such as drones,\
    \ sensors, or \nmobile apps, but also an increase in farmers' data literacy. Farmers\
    \ must learn to manage and govern their \ndata to fully realize its potential\
    \ benefits, including reducing risk and improving production efficiency. \nThey\
    \ must go beyond simply following technology recommendations and understand how\
    \ the data \ncollected can benefit their farming practices and the entire agricultural\
    \ value chain. This shift involves a \nchange in traditional farming methods and\
    \ requires an investment in learning and understanding data and \nits use in agriculture.\
    \ \n \n7 \nflow of data and be confident that their data will not be misused or\
    \ exploited. A well-\ndesigned policy framework will help to mitigate these concerns\
    \ and ensure that the benefits \nof smart agriculture and digital technologies\
    \ are effectively leveraged for the benefit of \nfarmers and the overall agricultural\
    \ sector. \n \n \n8 \nChapter 1: Research Question and Methods  \nThe aim of this\
    \ chapter is to identify the existing gaps in research and to investigate the\
    \ \nrole that a policy framework could play in enhancing the digitalization process\
    \ of \nagriculture in the United States. The focus is on how a well-designed policy\
    \ framework \ncould contribute to the sustainable development of modernized farming\
    \ practices through \nthe use of digital technologies. The primary research question\
    \ addressed in this study is:  \nWhat is the most effective policy framework for\
    \ governing agricultural \ndata to promote sustainable farm modernization through\
    \ digital \ntransformation? \nIn this context, the term \"sustainability\" refers\
    \ to not only the economic sustainability \nof farms (i.e., their ability to remain\
    \ profitable and sustainable operations), but also the \nenvironmental and social\
    \ sustainability of the agricultural sector as a whole. Although these \nvarious\
    \ aspects of sustainability require different types of agricultural data, this\
    \ research \nproject assumes that high-quality data is required for each aspect's\
    \ policy-making and \nsocial action. Because this project addresses the primary\
    \ question of how to establish a data \ngovernance system, the question of how\
    \ data can be applied to different aspects of \nsustainability is left to future\
    \ research. Sustainability represents the long-term impact that \nagricultural\
    \ data governance aims to achieve. However, this research focuses on the \npreceding\
    \ outputs of interest, which are the production and sharing of high-quality data\
    \ \nand the subsequent outcome of interest, which is the cost-effective digitization\
    \ of the \nagricultural sector. \nThe primary research focus of this study is\
    \ to examine the general issues related to data \npractices and contractual complexities\
    \ in the agriculture sector at the national level in the \n \n9 \nUnited States.\
    \ The study also looks at cross-sector data governance practices and compares\
    \ \nthem with international approaches. Additionally, the research addresses the\
    \ sub-question \nof what type of policy framework can effectively balance the\
    \ interests of various \nstakeholders while addressing the benefits and risks\
    \ of increased data access in the U.S. \nagricultural sector. \nResearch Gap \n\
    In recent years, there has been an exponential growth in the amount of data generated\
    \ \nby agricultural activities in the United States. According to a report by\
    \ the United States \nDepartment of Agriculture (USDA), the amount of data generated\
    \ by precision agriculture \ntechnologies in the country is expected to grow by\
    \ 20% per year, reaching a total of 4.1 \nmillion terabytes by 2050 (USDA, 2019).\
    \ This represents a massive opportunity for the \nagriculture sector to improve\
    \ its efficiency, productivity, and sustainability, as well as to \ncreate new\
    \ business models and revenue streams. However, to fully realize the potential\
    \ of \nthis data, it is necessary to establish a governance framework that promotes\
    \ data sharing, \nprotects data privacy and security, and addresses the technical\
    \ and legal challenges \nassociated with the use of agricultural data.  \nThis\
    \ study recognizes that there is a lack of consensus in the U.S. regarding the\
    \ \nmechanisms that can ensure the reliability and trustworthiness of the flow\
    \ of agricultural \ndata. Currently, there are no legally binding frameworks in\
    \ place to govern the use and \nmanagement of agricultural data, leading to a\
    \ need for a comprehensive policy framework \nto address these issues.  \n \n\
    10 \nResearchers such as Sanderson et al. (2018) and Wiseman (2019) have explored\
    \ the use \nof codes of practice (COPs) as a means of addressing the legislative\
    \ gaps in the regulation \nof agricultural data practices (Sanderson et al., 2018)\
    \ in the U.S. and other countries where \nthey are considered enforceable. However,\
    \ despite the efforts of COPs to promote \nresponsible data practices in the agriculture\
    \ sector, there is a lack of evaluation of \ncompliance with the core principles\
    \ of these codes, which presents a significant challenge. \nNot all agriculture\
    \ service and technology providers, as well as farmers and producers, \nparticipate\
    \ in the collective efforts to implement the codes of agricultural data practices.\
    \ \nAs a result, it is unclear whether these codes have been successful in promoting\
    \ accountable \ndata practices and trust between technology providers, farmers,\
    \ and producers. The \nparticipation rate in these codes and its impact on the\
    \ trust relationships between \nstakeholders is not well understood.  \nAdditionally,\
    \ the United States Department of Agriculture (USDA) is in the process of \nupdating\
    \ its agricultural data infrastructure systems (Ristino & Hart, 2022). Discussions\
    \ \nare ongoing about the need for the USDA and its agencies to undergo institutional\
    \ changes \nto support the digital transformation of agriculture. Implementing\
    \ such changes would \nrequire a comprehensive understanding of data sharing,\
    \ use, and reuse at a macro-level, \nand would necessitate collaboration from\
    \ all stakeholders involved. \nThe situation presented above highlights the potential\
    \ risks and benefits of policy \ndecisions that could impact the digital transformation\
    \ of the agriculture sector, and the lack \nof comprehensive analysis or proposals\
    \ for a data governance framework specific to this \nsector. While COPs have been\
    \ explored as a means of promoting responsible data practices \n \n11 \nin agriculture,\
    \ the lack of evaluation of compliance and participation rates of stakeholders\
    \ \npose significant challenges. \nAs there is limited literature available on\
    \ a public policy, legal, or regulatory framework \nfor governing agricultural\
    \ data practices, particularly in the United States, this research \naims to fill\
    \ this gap in the literature and in the fields of policy analysis and public policy.\
    \ \nThe goal is to facilitate meaningful changes that encourage and support efficient,\
    \ secure, \nand accurate data sharing across stakeholders in the agriculture sector.\
    \  \nThis research aims to provide a comprehensive policy framework for governing\
    \ \nagricultural data practices by conducting a policy analysis and proposing\
    \ policy \nalternatives that have the potential to significantly improve agricultural\
    \ data practices. The \nfocus is on establishing standards for data usage at the\
    \ macro, meso, and micro levels to \nencourage efficient, secure, and accurate\
    \ data sharing among agriculture sector \nstakeholders. \nA comprehensive policy\
    \ framework for governing agricultural data practices could lead \nto improved\
    \ efficiency, reduced costs and a lower environmental impact in the agriculture\
    \ \nsector. It can serve as a valuable resource for policymakers and stakeholders\
    \ in considering \noptions for improving the governance of agricultural data.\
    \ However, it is important to note \nthat the implementation of a prescriptive\
    \ policy framework (Sanderson et al., 2018, p. 7) \nmay face challenges such high\
    \ costs, and difficulty in reaching agreement among all \ninterested stakeholders,\
    \ including government agencies, agriculture service and technology \nproviders,\
    \ farmers, and producers. Despite these limitations, this research aims to \n\
    contribute to the sector and to public affairs by offering a valuable policy framework\
    \ for \n \n12 \ngoverning agricultural data practices that would be acceptable\
    \ and implementable by all \ninterested parties in the agriculture sector.  \n\
    The complexity of the task is compounded by the need to balance the competing\
    \ \nconcerns of different stakeholders and address the benefits and risks of enhanced\
    \ access to \ndata. The challenge of reaching agreement and implementing a comprehensive\
    \ policy \nframework highlights the need for a collaborative and inclusive process\
    \ that takes into \naccount the perspectives and interests of all stakeholders.\
    \  \nOntology \nAdopting a structuralist analysis approach to govern agricultural\
    \ data means \nacknowledging the power structures that shape incentives and constraints\
    \ for different \nactors within the agricultural sector. This involves recognizing\
    \ that the role of structures \n“[is to] exercise causal powers by providing an\
    \ environment of incentives and prohibitions \nfor various agents within a social\
    \ system.” (Little, 1991, p. 104). This approach seeks to \nensure that the control,\
    \ access, sharing, and use of agricultural data by all stakeholders \nleads to\
    \ a fair and equitable outcome. By examining the various elements and components\
    \ \nof the agricultural data governance process, the goal is to promote a system\
    \ that is \nbeneficial to all parties involved. \nAs stated by Little (1991, p.\
    \ 105) the “incentives and constraints imposed by the social \nstructure will\
    \ have predictable consequences for the choices that individuals will make.” It\
    \ \nis therefore necessary for the state and its institutions to step in and implement\
    \ trustworthy \nsystems to govern agricultural data in the U.S. \n \n13 \nFigure\
    \ 2 illustrates Coleman's Boat (Coleman, 1986, p.1310) and provides a visual \n\
    representation of the relationship between macro and micro foundational connections.\
    \ It \nserves as a structural explanation and provides insight into the intention\
    \ driving this \nresearch6.  \nFigure 2 The Explanatory Cycle \n \nDiagram elaborated\
    \ by the author \nThe social system of agricultural data governance (Ag-DG) is\
    \ institutionalized as a \npolicy framework, with norms for sector participation\
    \ playing a crucial role at the meso \nlevel. Individual decisions to participate\
    \ and share data within the framework are driven by \ntrust, transparency, and\
    \ legitimacy. This leads to a more stable and effective agricultural \nsector,\
    \ resulting in improved products and services. \n \n6 In this research, the epistemological\
    \ approach adopts inductive reasoning to create knowledge by \nobserving, from\
    \ a comparative perspective, particular case studies. Creating knowledge by induction\
    \ might \nbe open-ended and the appearance of new evidence can modify the initial\
    \ conclusion. However, this could \nbe also positive since it gives the possibility\
    \ to feedback policy frameworks to adapt and incorporate \nchanges and new knowledge.\
    \ \n \n14 \nPolicy Science versus Social Science \nPolicy science, as elucidated\
    \ by Goodin et al. (2006), endeavors to supply policy actors \nwith useful information\
    \ for the purpose of providing policy advice. The objective of policy \nstudies\
    \ is action-oriented and aimed at contributing to the improvement of life by offering\
    \ \npolitical actors something that they can put into use (Goodin et al. 2006,\
    \ p. 5). Policy \nscience seeks to address questions regarding what ought to be\
    \ done, as opposed to what it \nis. On the other hand, social science seeks to\
    \ uncover laws and generalizations and provides \npolitical-institutional designs\
    \ as instruments of collective values (Goodin et al. 2006). In \ncontrast, policy\
    \ science focuses on what can be achieved collectively through and within \ninstitutional\
    \ frameworks. \nIn this research, the findings of policy analysis are not intended\
    \ to be general statements \nabout the theme under research, but specific prescriptions\
    \ intended to assist policymakers. \nTherefore, the policy science approach does\
    \ not take a deductive approach but rather an \ninductive one. Policy studies\
    \ stress an aspiration toward relevance7 along with the role of \nvalue premises8\
    \ in policy choice (Goodin et al. 2006)9. This research design does not \n \n\
    7 Policy studies is a multidisciplinary field that investigates the decision-making\
    \ processes involved in \npublic policy. In this context, \"relevance\" refers\
    \ to the importance of ensuring that policy decisions are \nbased on evidence\
    \ and are responsive to the needs and values of society. The idea is that policies\
    \ should be \ngrounded in the best available knowledge and research, and should\
    \ be tailored to the specific needs of the \npeople and communities affected by\
    \ them. \n8 Value premises, on the other hand, refer to the underlying moral and\
    \ ethical principles that shape policy \ndecisions. These may include ideas about\
    \ social justice, individual rights, environmental sustainability, and \nother\
    \ ethical considerations that are important to policymakers and society as a whole.\
    \ \n9 Goodin et al. (2006) argue that policy studies should take both relevance\
    \ and value premises into \naccount when analyzing policy choices. By doing so,\
    \ policymakers can make more informed decisions that \nare grounded in evidence\
    \ and aligned with the values and priorities of society. This approach recognizes\
    \ \nthat policy choices are not purely technical or objective, but are influenced\
    \ by a range of social, cultural, \nand political factors, and by the values and\
    \ beliefs of the people involved in making those choices. \n \n15 \naddress the\
    \ general question of what kind of policy framework will tend to cause \nimprovements\
    \ in agricultural data governance and thus of agricultural outcomes but only \n\
    the context-specific question of what kind of policy framework should be implemented\
    \ as \noptimal for agricultural data governance in the United States. \nIn addition,\
    \ this research seeks to gain an understanding of not only farmers' \nperspectives\
    \ on the value and use of agricultural data, but also the perspectives of other\
    \ \nstakeholders involved in the sector. The objective of conducting policy analysis\
    \ is to assist \ndecision-makers in determining the desired outcomes and the most\
    \ feasible means of \nachieving those goals (Schneider, 1997, p. 9) through the\
    \ implementation of public policy. \nPolicy plays a mediating role in resolving\
    \ conflicts and fostering compromise among \nconflicting interests. It endeavors\
    \ to establish an optimal structure that would provide \nsuitable incentives to\
    \ stakeholders, thus overcoming challenges such as mistrust, lack of \ntransparency,\
    \ and information asymmetry risks.  \nThis study specifically examines the relationship\
    \ between stakeholders such as farmers, \nas data primary contributors, and third-party\
    \ agriculture technology providers, with a focus \non resolving the conflicts\
    \ arising from agricultural data usage. The aim is to create a \nstructure that\
    \ facilitates collaboration and establishes a long-lasting and trustworthy \n\
    relationship between farmers, producers, tech and service providers.  \nResearch\
    \ Design and Methods \nAs stated by Dunn (2018, p. 3), policy analysis is a comprehensive\
    \ and interdisciplinary \nprocess aimed at the production, critical evaluation,\
    \ and dissemination of policy-relevant \nknowledge. The methods of policy analysis\
    \ are designed to address the intricate nature of \n \n16 \nthe policy-making\
    \ process. This study proposes a multi-method strategy (Peters & \nFontaine, 2020,\
    \ p. 14) that aims to understand the problem at hand through the examination \n\
    of tangible and verifiable facts and information. \nThis research utilizes policy\
    \ analysis methods to structure the problem, design policy \noptions, and forecast\
    \ policy proposals. These methods are considered as tools for creating \nand transforming\
    \ knowledge (Dunn, 2018, p. 8). Table 1 presents an overview of the policy \n\
    analysis methods selected for this research. \nTable 1 Methods of Policy Analysis\
    \ \nPolicy Stage \nDescription \nApplication \nProblem \nStructuring \nDeveloping\
    \ a definition of the key \nelements of the problem; structuring the \nright problem\
    \ to propose the right \nsolution. \nWhat are the key \nelements of the problem\
    \ \nof creating an agricultural \ndata governance \nframework in the U.S.? \n\
    Policy \nOptions  \nDeveloping policy alternatives and \nforecasting their effects;\
    \ discussion of \ndifferent approaches taken in other \ncountries (lesson drawing,\
    \ benchmarking, \nbest practices, policy diffusion).  \nWhat are the main options\
    \ \nfor creating an \nagricultural data \ngovernance framework in \nthe U.S.?\
    \ \nPolicy \nProposal \nChoosing a preferred policy option using \ncriteria of\
    \ effectiveness (productivity, \ninnovation, sustainability) cost-\neffectiveness,\
    \ political feasibility, \ntechnical feasibility, legitimacy, security, \ncost-benefit\
    \ analysis. \nWhat agricultural data \ngovernance framework \nwould work best\
    \ for the \nU.S.? \nAdapted from Dunn, 2018. \n \n17 \nA roadmap is presented\
    \ in this doctoral dissertation to guide the progression of the \nanalysis, providing\
    \ a clear and structured approach for conducting the policy analysis and \ndeveloping\
    \ a policy framework. This roadmap outlines the steps involved in the policy \n\
    analysis process, from problem structuring and option design to policy proposal.\
    \ By \nfollowing this roadmap, the resulting policy framework will be well-informed,\
    \ evidence-\nbased, and effective in improving agricultural data practices. The\
    \ research content is \npresented in a roadmap format in Figure 3, outlining the\
    \ sequence of the study. \nFigure 3 Policy Analysis Process for Agriculture Data\
    \ Governance Policy Framework \n \nThe steps illustrated in Figure 3 are as follows:\
    \ \nChapter 2: The Data Governance Policy Problem: This chapter provides an in-depth\
    \ \nanalysis of the current data governance landscape in the U.S. agricultural\
    \ sector. It \nexamines existing data governance frameworks, with a particular\
    \ focus on identifying the \nsafeguards and enabling mechanisms that ensure the\
    \ secure flow of data among \nThe Data Governance \nPolicy Problem\n- Agricultural\
    \ Data\n- Data Governance\n- Data Governance \nFramework\n- Problem Structuring\
    \ \nMethods\nPolicy Options\n- COPs\n- U.S. data governance \nregulations\n- Lessons\
    \ Drawing\n- Policy Options Design\nPolicy Proposal \n- Projection\n- Prediction\n\
    - Conjecture\n- A Two-Stage Model for \nAgricultural Data \nGovernance Policy\
    \ \nFramework\n \n18 \nstakeholders. The objective is to gain a better understanding\
    \ of the key elements of the \nproblem and structure it in a way that facilitates\
    \ proposing the right solution. \nChapter 3: Policy Options: The goal of this\
    \ chapter is to analyze publicly available \npolicy documents related to data\
    \ governance from a comparative perspective in order to \nidentify valuable lessons\
    \ and best practices. This chapter discusses the different approaches \ntaken\
    \ in the U.S. and other countries to solve the agricultural data governance problem.\
    \ \nThese existing data governance policies serve as the basis for developing\
    \ three policy \nalternatives. This step includes consolidating the gathered information\
    \ to provide a \ncomprehensive analysis and designing policy options to solve\
    \ the agricultural data \ngovernance problem in the U.S. \nChapter 4: Policy Proposal:\
    \ In this chapter, this research then proceeds to project the \nfeasibility and\
    \ effectiveness of these three policy options in the context of the U.S., and\
    \ \npropose a two-stage solution, that moves from minimal to moderate models.\
    \ The chapter \nthen evaluates the policy options using criteria such as cost-effectiveness,\
    \ political \nfeasibility, and costs and benefits analysis to choose a preferred\
    \ policy option.  \nIn conclusion, policy analysis methods serve as effective\
    \ means of evaluating and \nproposing \"potential solutions to practical problems\"\
    \ (Dunn, 2018, p. 3), including those \nrelated to agricultural data governance.\
    \ These methods aid in accurately defining the policy \nproblem. This research\
    \ draws on a comparative policy lesson-drawing approach to identify \nviable options\
    \ for designing the three most appropriate policy alternatives. The evidence \n\
    from comparative cases is used to project the feasibility and effectiveness of\
    \ each model \nin the U.S. context while balancing the competing demands of various\
    \ stakeholders. \n \n19 \nChapter 2: The Policy Problem \nThis chapter will address\
    \ the nature and scope of the agricultural data governance policy \nproblem. It\
    \ will build on the previous chapter by presenting a detailed and well-structured\
    \ \nmodel of the policy problem. To achieve this, this research uses three methods\
    \ of problem \nstructuring. The chapter concludes with a preferred model of the\
    \ policy problem. This \nmodel will serve as the basis for formulating policy\
    \ options in Chapter 3. This chapter also \nincludes the description of the context\
    \ covering agricultural data and the data governance \nframework, which serves\
    \ as background information to structure the problem in the \nagriculture sector\
    \ in the U.S. \nAgricultural Data and Data Governance \n▪ \nAgricultural Data\
    \ \nData can be understood as a representation of factual information in various\
    \ formats, \nincluding numerical, textual, visual, or audio forms (Abraham et\
    \ al. 2019). On many \noccasions, data has been described as a valuable commodity,\
    \ similar to oil, that can \ncontribute to economic growth and development (Benfeldt\
    \ Nielsen, 2017, p. 120). Unlike \noil, however, data is a renewable resource\
    \ that can be continuously used and leveraged for \nmultiple purposes.  \nTo realize\
    \ the full potential of data, it is crucial to understand the contextual information\
    \ \nthat provides value to the data. According to DAMA-DMBOK (2015), context refers\
    \ to \nthe data's representational system. For instance, in the agricultural sector,\
    \ data has the \npotential to drive better decision making, increase farm profitability,\
    \ and promote \n \n20 \nsustainability by aggregating and analyzing various data\
    \ sources, such as seed yields, input \nrates, and product pricing (Séronie, 2020).\
    \ \nAgricultural data classification encompasses a wide range of categories, including\
    \ \nlivestock data, land data, agronomic data, climate data, and equipment data,\
    \ among others. \nIn some cases, this type of data may be linked to personal information\
    \ about farmers. Land \ndata, for example, may include information such as the\
    \ farmer's name, address, and \nfinancial information such as bank loans (Wiseman\
    \ & Sanderson, 2019). It is critical to \ndistinguish between data streams in\
    \ the agri-food chain10, depending on whether they are \nrelated to pre-planting\
    \ or consumption activities. \nOne of the difficulties in determining the origin\
    \ of agricultural data is determining \nwhether it is generated on-farm or off-farm,\
    \ especially when it is generated on-farm \nthrough a third party, such as an\
    \ agriculture technology provider (ATP). This lack of clear \ndistinction may\
    \ lead to confusion regarding the ownership and control of this type of data.\
    \ \nThe classification criteria for agricultural data also include how and why\
    \ the data is \ngenerated (Jouanjean et al., 2020). In this regard, Jouanjean\
    \ et al. (2020) classified how \nagricultural data is generated into three categories:\
    \ process-mediated, machine-generated, \nand human-sourced. Traditional business\
    \ data generated as a result of processes that \nmonitor and record business events\
    \ of interest falls under the purview of process-mediated \n \n10 This distinction\
    \ is important because different types of data may require different levels of\
    \ protection or \nregulation. For example, data related to pre-planting activities,\
    \ such as land data, may be more sensitive \nand require more protection because\
    \ they can be linked to personal information about farmers. On the other \nhand,\
    \ data related to consumption activities, such as nutritional information, may\
    \ require more transparency \nand regulation to ensure food safety and consumer\
    \ protection. Therefore, understanding the different types \nof data in the agri-food\
    \ chain and their associated risks and benefits is crucial for developing effective\
    \ \npolicies and regulations for agricultural data governance. \n \n21 \ndata\
    \ (Jouanjean et al. 2020). Machine-generated data, on the other hand, is generated\
    \ \nautomatically by computer-based digital devices, tools, and applications that\
    \ have grown \nin importance with the rise of precision farming11. Finally, human-sourced\
    \ data refers to \nhuman-created records, such as those found in books, photographs,\
    \ audio, and video \n(Jouanjean et al. 2020). \nThe second criterion for classifying\
    \ agricultural data is based on its primary reason why \n(purpose), which is to\
    \ assist farmers in making informed decisions. For instance, \nagriculture data\
    \ is used by the private sector to develop and support new services and \nactivities,\
    \ while agricultural data is used by public institutions to inform their innovation\
    \ \npolicies and activities (Jouanjean et al. 2020). \nIn the agriculture sector\
    \ of the U.S., data is used in two contexts: public and private big \ndata. On\
    \ the one hand, public-level big data, according to Stubbs (2016), refers to records\
    \ \ncollected, maintained, and analyzed through publicly funded sources and federal\
    \ agencies, \nsuch as farm program participant records and weather data. Private\
    \ big data, on the other \nhand, includes records generated at the production\
    \ level by farmers and agriculture \ntechnology providers, such as yield data,\
    \ soil analysis, irrigation levels, livestock \nmovement, and grazing rates. Both\
    \ public and private big data are useful in agriculture. \nThey provide a more\
    \ accurate picture of agricultural operations, making them a better \ndecision-making\
    \ tool. \n \n11 The increased in data generation that could provide insights for\
    \ making informed-farming decisions, \nneed specialized regulation considerations.\
    \ \n \n22 \nThis study uses the agricultural data taxonomy proposed by Jouanjean\
    \ et al. (2020), \nwhich focuses on what data is generated and how it is collected.\
    \ Jouanjean et al. (2020) \nclassify and categorize agricultural data, dividing\
    \ it into three broad typologies: farm \nbusiness operations and management data,\
    \ farm production process tracking data, and data \ncollected to provide general\
    \ agricultural services. \nThis research incorporates Stubbs' (2016) distinction\
    \ between private and public data, \nwhich relates to the why of data generation.\
    \ This analysis identifies key agricultural data \nthat farmers and other stakeholders\
    \ should be aware of. Table 2 summarizes the various \ntypes of agricultural data,\
    \ and Figure 4 shows how they interact.  \nTable 2 Agricultural Data Taxonomy\
    \ \n \nDescription of the type of data \nFarm business operations and \nmanagement\
    \ data \n• Financial \n• Tax \n• Human resource \n• Contracts \n• Supply chain\
    \ (partnerships, customer, \nand supplier information) \n• Rolling and fixed assets\
    \ data \n• Machine operations data (fuel \nconsumption, equipment function, \n\
    reference) \n• Reporting and compliance data \n(government policies, certification\
    \ \nschemes) \n \n23 \n \nDescription of the type of data \nFarm production process:\
    \ \nmachine-generated data, tracking \ndata (applied processes data) \n• Crop\
    \ seed \n• Dates of operations \n• Water management \n• Disease and pest management\
    \ (type of \nherbicides, insecticide, fungicide used, \nand dates and location\
    \ applied) \n• Yield data \n• Land data (Soil and fertility data, \nwatershed,\
    \ drainage, tillage practice) \n• GIS, GPS, and field boundary data \n• Livestock\
    \ data (breed, genetics, feed, \nproduction) \nGeneral services to agriculture\
    \ \ndata \n• Climate and weather data \n• Environmental and ecological data \n\
    • Commodity prices and market \ninformation \nAdapted from Jouanjean et al. (2020,\
    \ p.30) \n \n24 \nFigure 4 Cycle of Agricultural Data \n \nAdapted from Jouanjean,\
    \ M. et al (2020) and Stubbs (2016) \nAccording to Stubbs (2016), there are two\
    \ types of public agricultural data sets in the \nUnited States: traditional data\
    \ and administrative data. Traditional data includes \ninformation gathered, managed,\
    \ and analyzed using traditional methods such as surveys. \nThese data sets are\
    \ generated in the agriculture industry, particularly the United States \nDepartment\
    \ of Agriculture (USDA) to fulfill the mandates of this agency (Stubbs, 2016,\
    \ \npp. 3-5). Table 3 displays the most important agriculture sector agencies\
    \ in the United \nStates, as well as their involvement in agricultural data. \
    \ \nTable 3 The U.S. Agriculture Agencies \nU.S Agency in the Agriculture \nSector\
    \ \nData Activities \nNational Agricultural Statistics \nService (NASS) \nCollects,\
    \ manages, and analyzes survey data \nthrough the Census of Agriculture; \n \n\
    25 \nEconomic Research Service (ERS) \n \nCollects, manages, and uses resource,\
    \ \nproduction, and financial data through the \nAgricultural Resource Management\
    \ (ARM) \nsurvey;  \nAgricultural Research Service (ARS) Collects, manages, and\
    \ uses scientific data \nrelated to agriculture through its mission of \nresearch\
    \ and information access; \nNatural Resources Conservation \nService (NRCS) \n\
    Collects, manages, and uses soil, water, and \ngeospatial data through the Soil\
    \ Survey \nprogram;  \nAgricultural Marketing Service \n(AMS) \nCollects, manages,\
    \ and uses price and sales \ninformation through its market news \nprograms; \n\
    World Agricultural Outlook Board \n(WAOB) \nAnalyzes commodity and market data\
    \ to \ndevelop the World Agricultural Supply and \nDemand Estimates (WASDE) report.\
    \  \nAdapted from Stubbs (2016) \nAdministrative data, on the other hand, is a\
    \ less commonly used source of agricultural \ninformation derived from the administration\
    \ of agriculture programs mandated by law and \nbased on the goals of an agriculture\
    \ sector agency. These organizations are not typically \nthought of as big data\
    \ collectors, and this type of data is not made public. Administrative \ndata\
    \ is subject to statutory restrictions that limit its availability to the public.\
    \ Despite these \nconstraints, these data can still be used to improve the efficiency\
    \ and quality of federal \nfarm program and activity decision-making (Stubbs,\
    \ 2016, p. 4), as well as to investigate \nother aspects of the agriculture sector.\
    \ Table 4 lists the relevant agriculture sector agencies \nin the U.S. \n \n26\
    \ \nTable 4 Other U.S Agencies in the Agriculture Sector \nOther U.S Agency in\
    \ the Agriculture \nSector \nData Activities \nRisk Management Agency (RMA) \n\
    Collects, manages, and uses individual yield \nand loss information to administer\
    \ the \nFederal Crop Insurance program; \nFarm Service Agency (FSA) \nCollects\
    \ and manages individual producers’ \nfarm record data, federal payments, and\
    \ loan \ninformation used in administering various \nfarm programs; \nNatural\
    \ Resources Conservation \nService (NRCS) \nCollects and manages conservation\
    \ plans, \ngeospatial data, and conservation program \nactivities and payments;\
    \ \nAdapted from Stubbs (2016) \nIn the United States, the collection and use\
    \ of public agricultural data is governed by a \nnumber of statutes and guidance\
    \ documents that establish not only data quality standards \nbut also privacy\
    \ protection requirements. When collecting data, the USDA and its affiliated \n\
    agencies generally prioritize confidentiality, transparency, and public access.\
    \ However, as \nStubbs (2016, p. 5) points out, one of the major challenges for\
    \ public agricultural big data \nis a constrained federal budget, reduced staffing\
    \ levels, and a lag in the adoption of new \ntechnologies. These factors have\
    \ all had an impact on federal agriculture agencies’ ability \nto collect, govern\
    \ and manage data effectively. \nThe collection, sharing, and use of agricultural\
    \ data present various challenges for the \nUSDA, as noted by Ristino and Hart\
    \ (2022, p. 3). These challenges include the absence of \nopen data standards,\
    \ inconsistent system interoperability, misaligned incentives for farmers \nto\
    \ provide data, leadership and governance gaps, and inconsistent legal authority\
    \ and \n \n27 \ninterpretation within the agency. Figure 5 depicts the various\
    \ USDA agencies12 that require \nfarmers to report their data in order to participate\
    \ in programs like soil conservation. \nHowever, the current reporting requirements\
    \ impose a burden on farmers, as they are \nrequired to report their data to multiple\
    \ USDA agencies (Sanderson et al., 2018), and this \nissue has yet to be resolved.\
    \ \nFigure 5 A visual representation of the information that one farmer reports\
    \ to various \nUSDA agencies \n \nAdapted from (Ristino & Hart, 2022) \nPrivate\
    \ data, as defined in this study, refers to data sets generated by the agricultural\
    \ \nproducer on the farm13 and used to improve farm or agriculture sector operations\
    \ (Stubbs, \n2016, p. 7). The participation of various key stakeholders in the\
    \ agricultural industry is \n \n12 USDA agencies such as the Farm Service Agency\
    \ (FSA), Natural Resources Conservation Services \n(NRCS), Risk Management Agency\
    \ (RMA), and the National Agricultural Statistics Service (NASS). \n13 The author\
    \ explains that for the purposes of her report, private agricultural data sets\
    \ are farm-level data \nwithout aggregating with other farms because it is an\
    \ issue frequently discuss in the agriculture community. \n \n28 \ncritical in\
    \ facilitating private agricultural data collection, management (which includes\
    \ \nprocessing, sharing, integration, and analysis), and use. Farmers and agricultural\
    \ producers \nare among the most experienced in utilizing private data effectively.\
    \ Privately analyzed \ndata can be used to develop recommendations for a variety\
    \ of farming practices, including \nseed and fertilizer application rates, soil\
    \ analysis, and weather forecasts, among others. \nFigure 6 depicts more than\
    \ 100 technology firms that are digitally transforming farming \npractices. \n\
    Figure 6 Technology companies digitally transforming farming \n \nSource14 CBInsights\
    \ (2017) \nThe use of private data in agriculture is increasing, and its benefits\
    \ are becoming more \napparent. The improved outcomes in production, such as higher\
    \ yields, lower costs, and \n \n14 More information is available at CBInsights\
    \ (2017) “The Ag Tech Market Map: 100+ Startups \nPowering the future of Farming\
    \ and Agribusiness” Agriculture. Retrieved from: \nhttps://www.cbinsights.com/research/agriculture-tech-market-map-company-list/\
    \ \n \n29 \nreduced farming risks, are just a few examples. There are also environmental\
    \ benefits \nassociated with this, including improved soil quality and more efficient\
    \ use of water \nresources. The ability to collect, process, and analyze agricultural\
    \ data in real time provides \nadditional benefits as well as new business opportunities.\
    \ \nAccording to Stubbs (2016), the use of these advanced technologies has created\
    \ an ever-\nchanging landscape of information sources and stakeholders. However,\
    \ the complexity of \nthe data collection process, as well as the involvement\
    \ of numerous private players, pose \nsignificant challenges in the private agricultural\
    \ data sector.  \nData standardization, interoperability, accuracy, and privacy\
    \ concerns are just a few of \nthe key challenges. According to Stubbs (2016,\
    \ p. 11), one of the most pressing challenges \nconfronting the private agricultural\
    \ data sector is data privacy, and producers must ensure \nthat their data is\
    \ secure and protected from unauthorized access. Furthermore, data \nstandardization\
    \ is an important issue because it ensures that the data gathered can be \naccurately\
    \ compared and analyzed across multiple sources and stakeholders. \nThe network\
    \ that facilitates communication among the technologies involved is another \n\
    critical aspect of data collection. This network is commonly referred to as the\
    \ \"Internet of \nThings\" (IoT), which refers to a network of interconnected\
    \ objects that communicate with \none another and with computers via the Internet\
    \ (Stubbs, 2016, p.8). This area is subject to \ncontinuous development and evolution\
    \ due to the dynamic nature of the technologies \ninvolved in the data collection\
    \ stage. \nFurthermore, the use of cloud computing to store and process data has\
    \ grown in \npopularity because it provides a cost-effective solution for data\
    \ storage and management \n \n30 \n(Stubbs (2016, p. 8). With the rise of cloud\
    \ computing, producers have gained greater \ncontrol over their data collection,\
    \ management, and analysis. They can also share their data \nwith other farmers\
    \ and agricultural industry stakeholders. However, this presents \nchallenges,\
    \ such as ensuring data security, privacy, and data ownership. The rapidly \n\
    changing landscape of the data collection stage in private agriculture big data\
    \ highlights \nthe importance of a comprehensive and adaptable policy framework\
    \ that ensures \nresponsible data collection and use in the agriculture sector.\
    \ The table 5 lists data collection \nimportant players in the agriculture industry\
    \ in the U.S. \nTable 5 Players in the agriculture industry in the United States\
    \ \nImportant stakeholders \nTechnologies for Data Collection  \nEquipment \n\
    Manufacturers \nManufacturers of traditional farm equipment (e.g., \ntractors)\
    \ are well positioned to expand into data \ncollection technologies. In many cases,\
    \ technology is an \nextension of the equipment already in use. \nChemical Companies\
    \ and \nApplicators \nChemical companies are playing an increasing role in the\
    \ \nresearch and development of data collection tools and \nmethods to improve\
    \ application use of nutrients and \npesticides. \nMulti-Use Technologies \nTechnologies\
    \ used by other industries. For example, \nsome farmers in the dairy industry\
    \ are exploring the use \nof radio frequency identification (RFID), commonly \n\
    used in the shipping and transportation industries, to \ntrack movement, production,\
    \ feed, and disease outbreaks \nin herds.  \nAdapted from Stubbs (2016, p.8) \n\
    \ \n31 \nPrivate agricultural big data management encompasses the processes of\
    \ organizing, \nadministering, and governing large amounts of data (Stubbs, 2016,\
    \ p. 9). The goal of data \nmanagement is to ensure high-quality data that is\
    \ easily accessible to end users. This stage \nof the agriculture industry is\
    \ rapidly growing, with an increasing number of actors \nproviding flexible solutions\
    \ for mid-sized and small-scale farmers/producers. These actors \neither collect\
    \ and organize data for a fee or serve as data brokers, trading and selling data\
    \ \n(Stubbs, 2016, p. 9). Table 6 summarizes some of the most common data management\
    \ \npractices and providers. \nTable 6 Data Practices and Providers \nImportant\
    \ stakeholders \nData management practices \nProducers \nProducers are the primary\
    \ data generators in the \nagricultural sector. They have traditionally stored\
    \ their \ndata locally, either on their own computers or on physical \ndata storage\
    \ devices. However, some are now beginning \nto explore cloud-based storage options\
    \ that offer greater \nconvenience and accessibility. Producers are also \nincreasingly\
    \ interested in data analytics and using data to \nimprove their farming practices.\
    \ \nData Collectors \nData collection and management companies offer a \nvariety\
    \ of services to producers, including data collection, \nstorage, and analysis.\
    \ Many of these companies are \naffiliated with other agricultural products such\
    \ as \nequipment, seed, or chemicals. Data collectors often \nprovide value-added\
    \ services such as benchmarking and \npredictive analytics. \n \n32 \nIndependent\
    \ \nAgricultural Data Banks \nThese are private companies that specialize in data\
    \ \nmanagement and analysis for the agricultural sector. They \noffer a range\
    \ of services, including data storage, analysis, \nand reporting. Data banks generally\
    \ operate on a \nsubscription or fee-for-service basis, and their clients \ninclude\
    \ both producers and other agricultural \nstakeholders. \nData Cooperatives \n\
    These are producer-owned organizations that pool \nmembers’ data to create economies\
    \ of scale and generate \nadditional value and negotiating power. Data cooperatives\
    \ \noffer a variety of services, including data storage, \nmanagement, and analysis.\
    \ They also provide members \nwith access to benchmarking data and other industry\
    \ \ninsights. Many data cooperatives anonymize data before \nselling it to interested\
    \ parties in order to protect members’ \nprivacy. \nAdapted from Stubbs (2016,\
    \ p.9) \nThe final stage of the process is the use of private agricultural data.\
    \ In this stage, the \nvalue of the data for producers is realized. Typically,\
    \ data sets are analyzed and packaged \nin a usable and understandable format.\
    \ Stubbs (2016, p.10) distinguishes three types of \nanalytical products: descriptive,\
    \ prescriptive, and predictive data products. Table 7 lists the \nprimary users\
    \ of these data products. \nTable 7 Users of Agricultural Data \nImportant stakeholders\
    \ \nUses/users of private ag data \nFarmers and Ranchers \nProducers who own the\
    \ data can benefit from big data \nproducts that offer improved production such\
    \ as lower \ncosts, increased yields, or reduced inputs. \n \n33 \nRetailers \n\
    Retailers create big data products by analyzing data, \npackaging it into a usable\
    \ and timely product, and selling \nit to the producer. \nIndustry Groups \nNational\
    \ commodity and agricultural industry groups \nprovide guidance on licensing language\
    \ and data \ncontracts, especially related to producer concerns \nregarding privacy,\
    \ security, and ownership. \nEnvironmental Interests \nThe use of private agricultural\
    \ big data can result in \npositive environmental effects such as reduced inputs\
    \ \n(e.g., fertilizer, pesticides, and water) and increased \nefficiencies (e.g.,\
    \ reduced air emissions through reduced \ntillage overlap). \nAdapted from Stubbs\
    \ (2016, p.10) \nConsequently, private corporations are leveraging the use of\
    \ meteorological, soil, and \nfield-based information to assist farmers in determining\
    \ crop yield-limiting conditions and \nmaking production-related decisions. Furthermore,\
    \ certain entities are using cutting-edge \nmicrobiology and technology to improve\
    \ crop robustness and accelerate the growth of \ncarbon markets (Ristino & Hart,\
    \ 2022). Moreover, agricultural machinery manufacturers \nhave embraced new technologies\
    \ and integrated the most recent tractors and harvesters into \ncloud systems,\
    \ allowing for the collection of real-time data from the field for future use.\
    \ \nHowever, it has been noted that the USDA's efforts to collect, integrate,\
    \ and use data to \nimprove farmer outcomes and agricultural program performance\
    \ have been hampered \n \n34 \n(Ristino & Hart, 2022), and that much of the large\
    \ amounts of data collected to address \nvarious agriculture-related missions\
    \ remains unused15 (Ristino & Hart, 2022). \nTo summarize, the use of private\
    \ agricultural data is becoming more common, and the \nbenefits are becoming more\
    \ apparent. Private agricultural data has the potential to \nrevolutionize the\
    \ way farmers make production decisions, from increased yields and lower \ncosts\
    \ to improved soil quality and water availability. However, challenges remain,\
    \ such as \ndata ownership and privacy concerns, high costs of precision tools\
    \ and equipment, and \nmarket competition. Despite these obstacles, private companies\
    \ are using cutting-edge \ntechnologies such as IoT, drones, and sensors to collect,\
    \ manage, and analyze data in order \nto provide solutions to farmers. Furthermore,\
    \ while the USDA's data collection efforts have \nbeen limited, private companies\
    \ are stepping up to fill the void, providing innovative \nsolutions that can\
    \ improve farmer outcomes and performance. Figure 7 shows the \ndistribution of\
    \ agricultural data in the United States and highlights the key players \ninvolved.\
    \ The figure illustrates the absence of governance data infrastructures tools\
    \ or \n \n15 There is no single source of data that provides a comprehensive view\
    \ of how much agricultural data in \nthe U.S. is being used. However, there have\
    \ been various studies and reports that suggest that while there is \na significant\
    \ amount of agricultural data being collected, much of it is not being fully utilized\
    \ or shared. For \nexample, a 2018 report by the USDA found that while the majority\
    \ of farmers were collecting data on their \noperations, many were not using it\
    \ to make management decisions. Similarly, a 2019 survey by the \nAmerican Farm\
    \ Bureau Federation found that while most farmers were using some type of precision\
    \ \nagriculture technology, many were not fully utilizing the data collected by\
    \ these technologies. Overall, \nthese studies suggest that while there is a significant\
    \ amount of agricultural data being collected, there may \nbe untapped potential\
    \ for its use in improving agricultural productivity and sustainability. USDA\
    \ Economic \nResearch Service. (2018). Agricultural Resources and Environmental\
    \ Indicators, 2018. Retrieved from \nhttps://www.ers.usda.gov/webdocs/publications/93026/eib-208.pdf.\
    \ American Farm Bureau \nFederation. (2019). Farmers and Ranchers’ Views on the\
    \ Adoption of Ag Tech. Retrieved from \nhttps://www.fb.org/market-intel/farmers-growing-reliance-on-technology-highlights-\n\
    need-for-robust-digital-toolbox  \n \n35 \naggregate platforms in the country's\
    \ public sector and highlights the importance of \nconsidering the reuse of public\
    \ agricultural administrative data. \nFigure 7 Main-actors in public and private\
    \ ag data in the U.S. \n \nDiagram elaborated by the author \nIn the context of\
    \ analyzing agricultural data in the United States, it is necessary to \ndescribe\
    \ the data value chain. The term \"value chain\" refers to the steps taken to\
    \ \nincrementally add value and produce a final product or outcome (Brown, 2020,\
    \ p. 4). A \ndata value chain describes the information flow from raw data to\
    \ valuable insights in the \ncontext of big data systems (Cavanillas et al., 2021,\
    \ p. 29). This concept can be used to \norganize data activities and transform\
    \ processes into a series of steps that add value to data. \nThe definition of\
    \ an agricultural data value chain will aid in addressing challenges in \nagricultural\
    \ data governance in the context of agriculture's digital transformation. It entails\
    \ \n \n36 \nmanaging and coordinating data in a continuous flow from data generators\
    \ to decision-\nmakers16, which will aid in agricultural data governance (Miller\
    \ & Mork, 2013, p. 57). \nFigure 8 presents a data value chain adapted for the\
    \ purposes of this research, which \nencompasses six stages that can be grouped\
    \ into phases and potentially divided into sub-\nphases. \nFigure 8 A Data Value\
    \ Chain \n \nAdapted from Kosior (2019) \nThe utilization of a data value chain\
    \ in agriculture plays a crucial role in optimizing the \ntransformation of raw\
    \ data into valuable information. This process of transforming data \ninto smart\
    \ data involves the incremental addition of value at various stages of data input\
    \ \nactivities, data processing and transformation, and finally the generation\
    \ of high-quality \nand accurate data products (Brown, 2020, p.4). Currently,\
    \ the governance of agricultural \ndata value chains in the United States is primarily\
    \ governed by private contracts and \nagreements (Fisher & Streinz, 2021, p. 73),\
    \ which are complex in nature and provide data \nproducers or farmers with limited\
    \ negotiation power. \n \n16 Given this data cycle conceptual framework, in the\
    \ current digital and technological global context, the \neconomic dynamic is\
    \ becoming more data-driven when it comes to make decisions. This is what known\
    \ as \ndata economy. One of the main challenges “the data economy faces today\
    \ is the insufficient level of data \nsharing between public and private actors.”\
    \ (Carballa, 2019, p. 222) \ndata collection\ndata \nprocessing\ndata \nsharing\n\
    data \nanalysis\ndata use\ndata \nproducts and \nservices\n \n37 \n▪ \nData Governance\
    \ \nData governance is defined by DAMA International (2015, p. 67) as the “exercise\
    \ of \nauthority and control (planning, monitoring, and enforcement) over the\
    \ management of \ndata assets.” The concept of governing data refers to the decision-making\
    \ processes \ninvolved in data management, as well as the expected data-related\
    \ behaviors and responses \nof individuals and processes (DAMA 2015, p. 68). Data\
    \ governance thus entails the \ncreation of a systematic decision-making framework\
    \ that outlines the various roles and \nresponsibilities associated with data\
    \ access. The goal is achieving organizational or sectoral \nobjectives such as\
    \ improving operational efficiency, mitigating risks, and gaining market \nadvantages\
    \ (Benfeldt et al., 2020, p. 301). \nFurthermore, data governance is frequently\
    \ described as a comprehensive system that \nincludes fundamental attributes or\
    \ characteristics. According to the Data Governance \nInstitute (DGI), as cited\
    \ in Al-Ruithe et al. (2019, p. 840), data governance is defined by \ndecision\
    \ rights and responsibilities regarding information-related procedures that are\
    \ \ncarried out in accordance with established models that specify who is authorized\
    \ to execute \nspecific actions with specific data, when, under what conditions,\
    \ and using what methods. \nFor the purposes of this doctoral dissertation, data\
    \ governance is defined as a \ncomprehensive system that includes decision-making\
    \ authority and accountability for \nmanaging data assets, with a focus on controlling\
    \ the flow of data by regulating its access, \nusability, quality, and security.\
    \ This definition includes the roles and responsibilities of \nnetwork members,\
    \ rules and processes, principles or standards that facilitate data practice \n\
    \ \n38 \ncoordination, and common goals. In this dissertation, the overarching\
    \ goal of data \ngovernance is to ensure that data is managed effectively as a\
    \ valuable asset. \n▪ \nData Governance Policy Framework \nThe World Bank's World\
    \ Development Report 2021: Data for Better Lives (WDR21) \n(World Bank, 2021)\
    \ presents a data governance framework that outlines the legal and \nnormative\
    \ safeguards and enablers required to promote trust and foster the growth of a\
    \ \ndata-driven economy. WDR21 and Chen (2021) define safeguards as “norms and\
    \ legal \nframeworks that aim to protect the rights of individuals and entities\
    \ participating in the data \neconomy by addressing misuse of data or data breaches”\
    \ (Chen, 2021, p. 4). And enablers \nare defined as “norms and laws that facilitate\
    \ the use and reuse of data, such as data \nportability mechanisms and open data\
    \ legislation, (Chen, 2021, p. 4). Figure 9 illustrates \nthese two pillars as\
    \ critical components in creating an efficient data governance \nenvironment and\
    \ regulatory framework, as well as describing the overall data governance \nobjectives.\
    \ \n \n39 \nFigure 9 Data Governance Policy Framework  \n \nAdapted from Chen\
    \ (2021) \nThe two pillars of the data governance framework proposed by WDR21\
    \ and Chen \n(2021) include multiple dimensions that address various issues related\
    \ to data governance \nand necessarily require corresponding regulations. Figure\
    \ 10 of the report illustrates these \ndimensions. This study will adapt these\
    \ dimensions to specifically address agricultural data \ngovernance. \n \n40 \n\
    Figure 10 Data Governance Safeguards and Enablers Regulatory Dimensions \n \n\
    Adapted from Chen (2021) \nThese dimensions allow the Global Data Regulation Diagnostic\
    \ report (Chen, 2021) to \nidentify data components from other data governance\
    \ regulations. Personal data includes \nnot only \"data directly provided by an\
    \ individual, but also personally identifiable \ninformation and machine-generated\
    \ information that can readily be linked to an individual \n(such as mobile phone\
    \ data)\" (World Bank, 2021, p. 190). Non-personal data recognizes \n\"intellectual\
    \ property rights (IPRs) over non-personal data.\" Regarding enabler \ndimensions,\
    \ e-commerce/e-transactions refer to electronic communications (or e-\ncommunications)\
    \ and digital ID systems (e.g., e-signatures) for accessing services (e.g., e-\n\
    government services) (Chen, 2021, p. 19). Public intent data \"refers to data\
    \ collected for \npublic purposes, regardless of the collection instrument or\
    \ the entity that manages the data\" \n(e.g., censuses and home surveys) (Chen,\
    \ 2021, p. 21). Private intent data \"refers to data \ncollected with the original\
    \ intent of pursuing commercial purposes\" (e.g., consumer data) \n \n41 \n(Chen,\
    \ 2021, p. 22). Table 8 organizes the safeguards and enablers, as well as the\
    \ seven \ndimensions of data governance, each with its own set of regulatory concerns\
    \ that must be \ncarefully considered when developing a legally binding instrument.\
    \ The table will be used \nas a tool to guide the analysis and evaluation of regulatory\
    \ frameworks and policies related \nto agricultural data governance in this study.\
    \ \nTable 8 Data Governance Safeguards and Enablers, and the 7 Dimensions and\
    \ \nRegulatory Issues \nData \nGovernance \nPillars \nDimensions \nRegulatory\
    \ issues to be addressed \nSafeguards \nPersonal data \n• Personal data protection\
    \ (e.g., an \nindividual's health or financial \ninformation)  \n• Data rights,\
    \ such as the right to \nobject to data usage, file complaints, \nand seek redress\
    \ \n• Implementation \nof \ndata \nsubject \nrights, such as redress. \n• Use\
    \ of personal data, as well as \nrestrictions on sharing with third \nparties.\
    \ \n• Requirements for data minimization, \npurpose limitation, and data storage\
    \ \nlimitation. \nNon-personal data \n• Intellectual property rights protection\
    \ \n• Protection of third-party rights in \nnonpersonal government data, such\
    \ \n \n42 \nData \nGovernance \nPillars \nDimensions \nRegulatory issues to be\
    \ addressed \nas company registers or business \ndata underlying official statistics.\
    \ \nCybersecurity and \ncybercrime \n• Adoption of provisions prohibiting \nthe\
    \ criminalization of unauthorized \nor illegal access to or use of \ninfrastructure,\
    \ systems, and data. \nCross-border data \ntransfer \n• Conditions under which\
    \ personal \ndata can be transferred abroad. \n• Adequacy and accountability \n\
    approaches, including \ndocumentation of the specific \nconditions that allow\
    \ data transfer. \n• Mutual agreements with foreign \ncountries or multinational\
    \ entities, as \nwell as schemes to require, permit, \nor limit cross-border transfers\
    \ of \npersonal data. \nEnablers \nPublic intent data \n• Open data laws,  \n\
    • Interoperability of government data \nexchange platforms,  \n• Data classification\
    \ policy and its \nmandatory use for government data,  \n• Access to information\
    \ (ATI)  \n• Adoption by governments of an \nopen licensing regime. \nPrivate\
    \ intent data \n• Creating incentives and removing \nbarriers to facilitate voluntary\
    \ data \n \n43 \nData \nGovernance \nPillars \nDimensions \nRegulatory issues\
    \ to be addressed \nsharing involving private sector \nactors  \n• Granting data\
    \ portability rights to \nindividuals to legally obtain and \nreuse their personal\
    \ data across \nservices \nE-commerce/e-\ntransactions \n• Adaptable e-commerce\
    \ law to fast-\nevolving technologies.  \n• Legal recognition of e-signatures.\
    \ \n• Adoption of principles of \ntechnological neutrality of e-\ncommunications.\
    \  \n• Implementation of a digital ID \nsystem so users can access e-\ngovernment\
    \ services. \nAdapted from Abraham et al. 2019; DAMA – DMBOK 2017, and from Chen,\
    \ 2021 \nIt is important to recognize that data governance is a continuous process\
    \ that involves \npeople17, processes, and technology. The primary goal of data\
    \ governance is to enhance \nthe value of data while minimizing the associated\
    \ costs and risks (Abraham et al., 2019, p. \n424). This highlights the ongoing\
    \ effort required to effectively manage data, as well as the \nimportance of effective\
    \ data governance practices. \n \n17 People is involved in generating, governing,\
    \ and using data. These are data generators, users, policy \nmakers. Retrieved\
    \ from: Laney (2001), UN Global Pulse (2018), Oracle, UN Women. \nhttps://cgspace.cgiar.org/bitstream/handle/10568/108205/Fairfood_Infosheet_SmallFarmer_BigData.pdf?se\n\
    quence=1 \n \n44 \nIntroducing data governance into the agricultural sector can\
    \ help to ensure data quality \nwhile also ensuring its secure and open use. As\
    \ the agricultural sector continues to \ndigitalize its farming practices, agricultural\
    \ data governance becomes more important as it \npromotes desirable and responsible\
    \ agricultural data practices. The sector can ensure that \ndata is managed responsibly\
    \ and that its value is maximized while potential risks are \nminimized by implementing\
    \ effective data governance practices. \nUntil now, contractual agreements have\
    \ primarily governed the management of \nagricultural data. Contractual agreements\
    \ define the conditions under which data can be \ncollected, shared, and used\
    \ by farmers, producers, and digital technology providers. These \nagreements\
    \ define the parameters for data use and the extent to which data can be shared\
    \ \nwith third-party service providers, as well as the consequences of data misuse\
    \ or \nunauthorized access. These contracts, according to Casalini and Gray (2020),\
    \ determine \ndata sharing permissions and data ownership following contract termination.\
    \ According to \nMicheli et al. (2019), power imbalances and power relations can\
    \ have an impact on \ngovernance processes and value creation.  \nThese scholars\
    \ argue that civic society and public bodies play an important role in \ndemocratizing\
    \ data governance and redistributing value through data. This implies that, in\
    \ \naddition to addressing technical aspects of data governance, it is also necessary\
    \ to consider \nthe roles and responsibilities of various stakeholders, as well\
    \ as how power dynamics and \ninformation asymmetries between them can affect\
    \ data governance in agriculture. \nAccording to Micheli et al. (2019), agricultural\
    \ data governance requires an examination \nof stakeholders' roles and responsibilities,\
    \ as well as the processes and mechanisms used \n \n45 \nas data strategies to\
    \ access, share, and use data. Thus, effective data governance in \nagriculture\
    \ needs not only addressing software, digital applications, or data platforms,\
    \ but \nalso power dynamics and information asymmetries between farmers and agricultural\
    \ \ntechnology service providers. \nThe Sense of Problem \nIn the United States,\
    \ the governance of agricultural data is currently an unstructured \nproblem,\
    \ meaning that it is a recently explored and discussed issue with various key\
    \ actors \nstill deliberating ideas. The issue of contractual agreements is a\
    \ particular challenge, \nresulting in low trust and tensions between farmers,\
    \ industry professionals, and \nagribusiness (Cue et al., 2021). Furthermore,\
    \ challenges associated with the transition from \nanalog to digital and smart\
    \ farming, as well as the generation of large amounts of \nagricultural data,\
    \ present additional difficulties. \nThe problem situation at hand is the digitalization\
    \ of agriculture18, which involves the \nadoption of innovative digital technologies\
    \ like artificial intelligence (AI), sensors, drones, \nand robotics to optimize\
    \ agricultural production systems, value chains, and food systems. \nHowever,\
    \ the growing reliance on digital tools in agriculture has resulted in disagreements\
    \ \nand tensions between farmers and agriculture technology providers, particularly\
    \ regarding \nagricultural data monetization (Cue et al., 2021, p. 11). This issue\
    \ has yet to be fully \nstructured, as agricultural data governance is a relatively\
    \ new concept being explored and \ndebated by key actors in this field. \n \n\
    18 The adoption, use, and adaptation of digital farming technologies in agriculture\
    \ daily practices.  \n \n46 \nIn the United States, the Code of Practice (COP)\
    \ and its fundamental principles \nrepresent an initial move towards establishing\
    \ reliable systems for the flow of agricultural \ndata that safeguard privacy\
    \ and security. Nonetheless, due to its voluntary and non-binding \nregulatory\
    \ nature, as well as the lack of evidence demonstrating its impact and outcomes\
    \ \nin promoting beneficial data practices for all stakeholders in this sector,\
    \ the it proves \ninsufficient to govern data in the agricultural industry. \n\
    There is a growing concern among farmers regarding the ambiguous use of data that\
    \ \narises from the implementation of digital farming technologies. The various\
    \ stakeholders \ninvolved, including farmers, agriculture tech providers, and\
    \ other agribusinesses, hold \ndifferent perspectives on the value of data and\
    \ its potential benefits. \nFarmers’ associations in the United States, for example,\
    \ have created data cooperative \nplatforms, while agribusinesses provide mobile\
    \ application services for data analysis. The \nAgriculture Network Information\
    \ Collaborative (AgNIC)19 is an example of an institution \ncooperating voluntarily\
    \ in the field of agricultural information and data management. \nAdditionally,\
    \ there are private business companies that deal with the storage and analysis\
    \ \nof agricultural data, including but not limited20 to the Agriculture Data\
    \ Coalition (ADC), \nFarmers Business Network (FBN), Growers Information Services\
    \ Coop. (GiSC), Open Ag \n \n19 AgNIC webpage: agnic.org \n20 Others, such as\
    \ the National Coalition for Food and Agricultural Research (NCFAR) (www.ncfar.org),\
    \ \na nonpartisan, consensus-based, and customer-led coalition or the Agricultural\
    \ Research Data Network \n(ARDN) (https://agmip.github.io/ARDN/). The goal of\
    \ ARDN is to build a distributed network for \nharmonized crop system research\
    \ data and make it available through existing data portals like the USDA's \n\
    Ag Data Commons. It provides researchers with tools and protocols that allow them\
    \ to not only share their \ndata, but also make it interoperable and reusable.\
    \ \n \n47 \nData Alliance, the National Agricultural Producers Data Cooperative\
    \ (NAPDC), and Ag \nTransparent. \nAgricultural data issues have been recognized\
    \ as a public concern in the United States \nand have been incorporated into legislative\
    \ policy-making agendas. Senators Amy \nKlobuchar and John Thune introduced the\
    \ Agricultural Data Act (Ag-Data Act) (115th \nCongress, 2017-2018) as an example\
    \ of how senators began to address agricultural data in \n2018. Senator Klobuchar\
    \ proposed that by using appropriate data collection, review, and \nanalysis methods,\
    \ knowledge of how conservation practices impact farm and ranch \nprofitability,\
    \ such as crop yields, soil health, and other risk-reducing factors, could be\
    \ \nexpanded (Thune et al., 2017). Nonetheless, the Agricultural Data Act Bill\
    \ makes no \nmention of the different types of data practices that exist in agricultural\
    \ data contracts \n(Janzen, 2018b). It is difficult to evaluate or \"determine\
    \ the precise information that will \nbe collected, how the USDA will obtain it,\
    \ and who will have access to, use, or share it\" \n(Janzen, 2018a). \nThe absence\
    \ of legal regulations to govern data sharing and usage in the U.S. \nagricultural\
    \ sector has raised concerns among farmers from specific agricultural industries\
    \ \n(Cue et al., 2021). For example, in response, farmers from the dairy industry,\
    \ are calling \nfor the introduction of legislation, proposing a \"Farmers Bill\
    \ of Rights\" to ensure fair and \ntransparent dairy data governance within an\
    \ ecosystem comprising farmers and industry \ncompanies (Cue et al., 2021, p.\
    \ 6). To support this legislative proposal, Cue et al. (2021) \nconducted a survey\
    \ as part of the Dairy Brain project at the University of Wisconsin-\nMadison\
    \ in 2021. The findings showed that 59% of farmers reported not having signed\
    \ a \ndata sharing agreement in the past five years, while 22% were unsure if\
    \ they had signed \n \n48 \none (unpublished data). Despite this, all farmers\
    \ eventually share their data in some way. \nHence, these concerns are considered\
    \ significant worldwide (Cue et al., 2021, p. 4). \nAccording to Jouanjean et\
    \ al. (2020), farmers are uncertain whether the data collected \nbelongs to them\
    \ or to third parties who provide technological tools. Additionally, Kosior \n\
    (2019a, p. 6) notes that the current network of organizations managing and utilizing\
    \ \nagricultural data operates under an outdated and fragmented regulatory framework.\
    \ The \nabsence of specific legal and regulatory frameworks for smart farming\
    \ data leads to \nmistrust in the farming community and inhibits farmers' willingness\
    \ to share their data. \nPolitical economic factors, such as a lack of a data-sharing\
    \ culture in government and \ninadequate coordination among government entities\
    \ (Cue et al., 2021, p. 11), can further \nhinder the exchange of public sector\
    \ agricultural data. The value of agricultural data that \nhas not been used to\
    \ its full potential is nil. \nIn the World Development Report 2021: Data for\
    \ Better Lives, the World Bank (World \nBank, 2021, p. 190) states that several\
    \ factors have the potential to undermine trust in the \nflow and use of data.\
    \ These include the lack of a legal framework, an inadequate \nimplementation\
    \ of laws, institutions and law enforcement that are weak, or the absence of \n\
    effective ways for parties to enforce their rights (World Bank, 2021, p. 190).\
    \ Additionally, \npractices that provide unfair advantages to certain actors,\
    \ incentives that are skewed or \nunbalanced, and poor or insecure infrastructure\
    \ are also contributing factors. \nIn addition to distrust in agreements with\
    \ ATPs, the OECD (2019a, p. 25) report entitled \n“Digital Opportunities for Better\
    \ Agricultural Policies” notes that farmers frequently lack \nthe necessary tools\
    \ and skills to effectively utilize data for decision-making. This includes \n\
    \ \n49 \ntools for data management and governance, which enable data sharing,\
    \ integration, and \nlinkage across various intelligent systems (OECD, 2019a,\
    \ p. 25). Intelligent systems rely \non big data analytics, cloud computing, machine-to-machine\
    \ communication, and the \nInternet of Things (IoT) (OECD, 2019b, p. 27) to generate\
    \ new and valuable information. \nWithout context, trends, or causal references,\
    \ individual data points are meaningless. The \nOECD report argues that combining\
    \ different types and sources of data can provide \nactionable insights not only\
    \ for farmers but also for regulators and policymakers, \nsignificantly increasing\
    \ the value of the data (OECD, 2019a, p. 26). \nGlobally, several organizations\
    \ are working towards advocating policy solutions for \nenhancing equitable agricultural\
    \ data practices. Some of these key organizations include \nthe Organization for\
    \ Economic Cooperation and Development (OECD), the World Bank, \nGlobal Open Data\
    \ for Agriculture and Nutrition (GODAN), Global Forum on Agricultural \nResearch\
    \ and Innovation (GFAR), and the Centre for Agriculture and Bioscience \nInternational\
    \ (CABI), among others. While these organizations emphasize different but \ninterconnected\
    \ facets of agricultural data governance, they promote varied and disjointed \n\
    solutions to the issue. \nWhile digital technologies like drones have shown promise\
    \ in providing efficient \nsolutions for farmers, the potential of the data they\
    \ generate is often underutilized. In an \narticle by Smith Thomas (2022), John\
    \ Church, an associate professor at Thompson Rivers \nUniversity in British Columbia\
    \ and the Regional Innovation Chair in cattle industry \nsustainability, describes\
    \ how drones are useful in monitoring cattle, from checking calving \npastures\
    \ to determining if an animal is sick or has an elevated body temperature. Despite\
    \ \nthese specific uses, it is unclear how the data generated by drones can be\
    \ effectively \n \n50 \ngoverned and utilized to contribute to the sustainability\
    \ of the agricultural sector and its \nsubsectors. \nCABI's Director of Data Policy\
    \ and Practice highlights the importance of addressing the \ninstitutional context\
    \ and the roles of various actors involved in agricultural data \ngovernance,\
    \ including farmers, industry and government statistical organizations, \ntechnology\
    \ businesses, and research institutions. According to the Director, achieving\
    \ real \nchange in agricultural data practices requires an improved data culture\
    \ where trust in data \nis earned and built over time, and where sustainable data\
    \ access is integrated into platforms \nfrom the outset. The Director emphasizes\
    \ the need to address data sharing and mitigate \nrisks during the development\
    \ of interventions, rather than treating them as an afterthought. \nThis approach\
    \ presents an opportunity to promote responsible data practices and to enhance\
    \ \nthe sustainability of the agricultural sector and subsectors. (GFAR Blog,\
    \ 2022, p.3) \nProblem Structuring Methods \nIn the realm of public policy, problem\
    \ structuring is an approach that aims to integrate \nmultiple alternative perspectives\
    \ or views regarding a particular problem situation \n(Rosenhead, 1996). From\
    \ a social stage perspective, structuring a policy problem requires \ntwo distinct\
    \ actions. The first is identifying the problem situation, while the second is\
    \ \nidentifying multiple representations or interpretations of the situation (Hoppe,\
    \ 2018, p. 14) \nfrom the diverse perspectives of various stakeholders. These\
    \ representations must highlight \nthe elements and factors that are contributing\
    \ to the policy problem.  \nThese methods help to identify the characteristics\
    \ of the problem, its type, and the stages \nrequired to structure it. The focus\
    \ is on understanding the problem situation within the \n \n51 \nconditions that\
    \ lead to conflicts or dissatisfaction. According to Dunn (2018, p.69), the \n\
    nature of a policy problem should be defined in terms of needs, values, or opportunities\
    \ for \nimproving or optimizing outcomes. For example, the need to govern agricultural\
    \ data, the \nvalues that underpin the agricultural sector, and the opportunities\
    \ that can be seized to do \nso must be clearly defined as a first step before\
    \ proposing any public policy alternatives. \nIn the case of agricultural data\
    \ governance, farmers are concerned about their contracts \nwith ATPs, lack of\
    \ trust and transparency in accessing, sharing, and using agricultural data, \n\
    as well as doubts about the benefits of using this data (Casalini & Gray, 2020).\
    \ \nAdditionally, the external conditions that contribute to the problem, such\
    \ as power \nasymmetries and data politics among agri-businesses, ATPs, and farmers,\
    \ need to be \ndefined, classified, and evaluated (Dunn, 2018, p.72). Understanding\
    \ the context is \nessential to comprehend the dynamics involved in current agricultural\
    \ data practices. \nWhen approaching the problem of structuring agricultural data\
    \ governance, it is \nessential to assess how stakeholders define the problem.\
    \ The goal is to accurately define \nthe problem in order to identify the appropriate\
    \ solution and avoid what Dunn (2018, p. \n80) refers to as the error of the third\
    \ type21. To this end, there are several methods that can \nbe employed, including\
    \ the problem structuring methods summarized in Table 9. \nTable 9 Characteristics\
    \ of Three Methods of Problem Structuring \nMethod \nAim \nProcedure \nSource\
    \ of \nKnowledge \nContent \nAnalysis \nCritical and \nanalytical \nthinking \
    \ \nStakeholder \nidentification, \nassumption \nAgriculture sector \nstakeholders:\
    \ \nscholars, farmers, \n \n21 An error of the third type is formulating and solving\
    \ the wrong problem. \n \n52 \nMethod \nAim \nProcedure \nSource of \nKnowledge\
    \ \nsurfacing, \nchallenging, and \nsynthesis \nfarmer-led \nassociations, public,\
    \ \nand non-profit \nsector organizations \nKey Item \nMapping \nCreative \nsynthesis\
    \ of \nassumptions \nand key items \nusing a \nsoftware tool \nMapping analysis\
    \ \nof key items  \nAgriculture sector \nstakeholders: \nscholars, farmers, \n\
    farmer-led \nassociations, public, \nand non-profit \nsector organizations \n\
    Boundary \nAnalysis \nEnsuring that \nthe problem \nestimation is as \naccurate\
    \ as \npossible \nBoundary \nestimation \n(Pareto chart) \nAgriculture sector\
    \ \nstakeholders: \nscholars, farmers, \nfarmer-led \nassociations, public, \n\
    and non-profit \nsector organizations \nAdapted from Dunn, 2018 \nThese three\
    \ problem-structuring methods aim to identify the essential elements that \nconstitute\
    \ a problem, including the conditions that lead to stakeholder concerns, mistrust,\
    \ \ndissatisfactions, conflicts, or tensions, as well as external factors. The\
    \ selected problem \nstructuring methods aim to capture diverse perspectives on\
    \ the problem situation to \nfacilitate consensus building on the problem definition.\
    \ Taken together, these methods \noffer a rigorous and comprehensive approach\
    \ to structuring the policy problem of \nagricultural data governance, providing\
    \ valuable insights that enhance the credibility, \ntransferability, and reliability\
    \ of this qualitative research. \nIn order to avoid the error of formulating and\
    \ solving the wrong policy problem (Dunn, \n2018, p.80), this research has selected\
    \ a total of 57 documents for analysis. These \n \n53 \ndocuments include a range\
    \ of sources such as scholarly papers, policy papers, discussion \npapers, industry\
    \ newspapers, research reports from international organizations, and \nwebinars’\
    \ content, all of which are focused on agricultural data practices. By using multiple\
    \ \ntext-data points22, the research benefits from a large number of sources,\
    \ which reduces the \nreliability problem that may arise from a heavy dependence\
    \ on a smaller set of sources. \nMoreover, the larger sample size of 57 text-data\
    \ sources used in this research reduces the \nlikelihood of random error. As a\
    \ result, the possibility of Type III error, which refers to \ndefining the wrong\
    \ problem, is significantly minimized. \nAdditionally, the probability of Type\
    \ II error, which results from structuring the problem \ntoo narrowly, is also\
    \ reduced because the high number of sampled text-data sources tends \nto bring\
    \ forth a greater number of problem elements during analysis. However, the \n\
    possibility of defining the problem too broadly, Type I error, is increased by\
    \ these problem \nstructuring methods. This outcome is due to the only stopping\
    \ rule being the accumulation \nof new problem elements. As such, it is important\
    \ to reassess the scope of the structured \nproblem at the policy formulation\
    \ stage to identify whether any elements are marginal or \nunnecessary. Such elements\
    \ may not contribute to the target problem that solutions seek to \nresolve. \
    \ \n \n22 \"Text-data points\" refer to individual pieces of text-based information\
    \ that are used in research or \nanalysis. By incorporating multiple text-data\
    \ points from a variety of sources, this research is better able to \naccount\
    \ for a range of perspectives and reduce the risk of bias or inaccuracies. \n\
    \ \n54 \n▪ \nContent Analysis \nContent analysis is a widely used method in qualitative\
    \ research for studying various \nphenomena. Its main objective is to uncover\
    \ the implicit meaning of textual data by \nquantifying the significance of written\
    \ language. It examines data present in messages and \ncommunication as opposed\
    \ to observable events or individual characteristics. In this study, \ncontent\
    \ analysis is defined as a “method for investigating social reality, which involves\
    \ \ndeducing the attributes of a non-apparent context [or phenomenon] from the\
    \ characteristics \nof an apparent text” (Krippendorff, 2004, p. 25). \nKrippendorff's\
    \ (2004) definition of content analysis emphasizes the importance of \ncontext\
    \ in analyzing text. By using content analysis to uncover the underlying meaning\
    \ of \ntext, this research can gain a more nuanced understanding of the complex\
    \ policy problem \nof agricultural data governance in the U.S. context. Furthermore,\
    \ this approach allows for \nthe identification of the key elements of the problem,\
    \ which can inform the subsequent use \nof network-based maps and boundary analysis\
    \ to structure the problem and identify \npotential solutions. \nThe process consists\
    \ of several steps to ensure the scientific rigor of the content analysis \nmethod\
    \ in this research. The first step involves defining the research question and\
    \ the scope \nof the analysis. This is followed by selecting the documents that\
    \ will be analyzed from \nvarious sources, including academic literature, policy\
    \ papers, reports, newsletters and \nnewspaper, and webinars’ content. The next\
    \ step involves pre-processing the data to ensure \nthat it was suitable for analysis.\
    \ \n \n55 \nPre-processing the data for this qualitative content analysis involves\
    \ data cleaning23, \ncoding, and categorization based on relevant themes, concepts,\
    \ or categories, which are \ndesigned to organize and analyze the text-data effectively.\
    \ In this research, the qualitative \ncontent analysis involves manual coding,\
    \ which is a widely used method for analyzing \ntextual data. Manual coding entails\
    \ identifying and labeling relevant text segments using \npredetermined categories\
    \ to identify patterns and themes within the selected qualitative \ndata. This\
    \ process helps to uncover key insights and themes and provides a more in-depth\
    \ \nunderstanding of stakeholders’ perspectives. \nFinally, the next step in the\
    \ process involves analyzing the coded data to generate \ninsights and develop\
    \ a problem structure that accurately captured the underlying issues and \nchallenges\
    \ related to agricultural data governance. This process ensures the validity,\
    \ \nreliability, and replicability of the content analysis method and provides\
    \ a clear and \ntransparent framework for conducting the analysis. \nFindings\
    \ from Content Analysis \nThe content analysis conducted in this research was\
    \ delimited to 57 text documents \npublished between October 2020 and May 2022.\
    \ The selection of this time frame was based \non pertinent events related to\
    \ text publications. Specifically, the report titled “Issues around \ndata governance\
    \ in the digital transformation of agriculture: The farmers’ perspective” by \n\
    Jouanjean et al. (2020) published by the Organisation for Economic Cooperation\
    \ and \nDevelopment, and the report by Ristino and Hart (2022) titled “Modernizing\
    \ Agriculture \n \n23 Data cleaning involves removing irrelevant or extraneous\
    \ information and ensuring that the data is \nconsistent and accurate. This may\
    \ involve checking for inconsistencies, correcting errors, and removing \nduplicates\
    \ \n \n56 \nData Infrastructure to Improve Economic and Ecological Outcomes” published\
    \ by the Data \nFoundation. The literature search query was crafted as follows:\
    \ “agricultural data” or “farm \ndata” or “agricultural data and data governance”\
    \ or “digital technology and agricultural \ndata” or “agricultural data and regulations\
    \ or legal.” Nonetheless, a few documents dated \nfrom 2017, 2018, and 2019 were\
    \ included in the analysis due to their relevance to the \nresearch theme and\
    \ the scarcity of documents addressing the governance of agricultural \ndata.\
    \ The search was conducted based on the criterion that each document addresses\
    \ the \nuse of digital technologies and agricultural data. \nAn initial inventory\
    \ of themes was developed through an inductive thematic analysis of \nthe text\
    \ data set, with the aim of openly codifying text data into interrelated information\
    \ \ncategories (Creswell, 2007). To group codes into a category set, Dey (1993:\
    \ 100) suggests \ninterpreting the data to analyze it. This step requires a comprehensive\
    \ understanding of the \ntext to isolate features that may lead to the identification\
    \ of policy problems related to \nagricultural data. \nMoreover, creating categories\
    \ involves grouping related data. The process of grouping \ndata or establishing\
    \ relationships creates categories that are conceptually and empirically \ngrounded.\
    \ That is, categories must be grounded in “relevant empirical [text] material\
    \ and \nrelate to an appropriate analytic context” (Dey, 1993: 102). Table 10\
    \ presents the key \nthemes identified in the text data set, including subthemes,\
    \ keywords, and descriptions. \n \n57 \nTable 10 Key Agricultural Data Problems\
    \ \nKey Problem \nThemes \nSubthemes \nKeywords \nDescription \nData Sharing \n\
    (Data \nGovernance) \nAgricultural Data \nFarm data, Code of \nconduct, big data,\
    \ \nOpen data, \nManagement, Law \nThe use and sharing of \ndata generated and\
    \ \ncollected in farms, and \nthe issues related to \nsecondary use and \naccess\
    \ to such data. This \ntheme is related to \nquestions of governance \nand control\
    \ of \nagricultural data. \nData Privacy \nand Security \nRisks, \nCybersecurity\
    \ \nAccess, Control, Law \nand Regulations, Data \nStorage, Data \nCollection\
    \ \nThe risks related to the \ndisclosure or exposure \nof data without farmers'\
    \ \nconsent, and concerns \nabout cybersecurity and \ndata privacy. \nData \n\
    Ownership \nOwnership \nRights \nDigital farming, \nDigital farming \ntechnologies,\
    \ \nAgriculture 4.0, \nAgribusiness, Tech \ncompanies, \nAgriculture industry\
    \ \nFarmers' concerns about \nwho owns the data \ngenerated or collected in \n\
    farms through digital \nfarming technologies. \nSmart \nFarming or \nSmart \n\
    Agriculture \nDigital \nagriculture, \nDigital farming, \nAgriculture 4.0 \nDigitalization,\
    \ Digital \nfarming technologies, \nAgricultural \ntechnology providers, \nAgribusiness,\
    \ Tech \ncompanies, \nAgriculture industry \nThe adoption of digital \ntechnologies,\
    \ and the \nbenefits and challenges \nof implementing \"smart\" \nfarming systems.\
    \ \nTrust \nInformed \nConsent, \nBenefits, Open \nAccess, \nStandards \nContractual\
    \ \nagreements, \nAgricultural tech and \nservice providers \nThe lack of trust\
    \ in \ninformed consent and \nconcerns about \nmaintaining principles \nvia contractual\
    \ \nagreements with \n \n58 \nKey Problem \nThemes \nSubthemes \nKeywords \nDescription\
    \ \nagricultural tech and \nservice providers. \nTransparency Terms and \nConditions,\
    \ \nContract \nAgreements, \nThird Parties \nAgribusiness, \nFarmers/producers\
    \ \nThe lack of transparency \nin contractual \nagreements between \nagribusiness\
    \ and \nfarmers/producers, and \nthe difficulties in \nunderstanding terms and\
    \ \nconditions. \nOthers \nEthics, \nAsymmetries, \nInequality, \nInclusion, \n\
    Voluntary \nStandards, \nBenefits, Data \nMonetization, \nData Economy, \nData\
    \ Literacy, Ag \ntech services \nOther concerns of \nfarmers around \nagricultural\
    \ data \npractices, including \nethical considerations, \nasymmetries in power,\
    \ \nand the potential for \ninequality or \nexclusion. \n \nElaborated by the\
    \ author \nIn this study, the selected texts were classified based on their sources,\
    \ representing \ndifferent stakeholders in U.S. agriculture. The first classification\
    \ type includes scholars and \ntheir peer-reviewed articles. The second stakeholder\
    \ is the media that covers agriculture \nand digital technologies. The third stakeholder\
    \ is farm association publications and news, \nand the final stakeholder is represented\
    \ by reports and publications from international \norganizations. \n \n59 \n▪\
    \ \nVOS-Viewer Software Analysis  \nThe second method used in this study was the\
    \ VOSviewer software24, which was used \nas a tool to create and visualize maps\
    \ based on network25 data (van Eck & Waltman, 2021, \np. 3). This software utilizes\
    \ text data from reference manager files to create the maps (van \nEck & Waltman,\
    \ 2021, pp. 26–27). The input data for VOSviewer was imported from the \nreference\
    \ repository created in Zotero. The \"network visualization\" option was selected\
    \ \nfrom among the visualization options provided by the software to visualize\
    \ the problem of \nagricultural data. \nTo refine the settings and create the\
    \ map, this research used the objects of interest or \nitems26 (van Eck & Waltman,\
    \ 2021, p. 5) that were identified from the key themes and \nkeywords in the text\
    \ data set. The map includes only the items and links between them, \nrepresenting\
    \ the connections or relations between two or more items. For example, co-\noccurrence\
    \ links were used to represent the number of publications in which certain terms\
    \ \noccur together, based on the keywords identified in each text selected as\
    \ a data source. \nThe software's useful contribution to the policy problem structuring\
    \ process is its ability \nto group each item or keyword into clusters, based\
    \ on their characteristics such as weight \n \n24 VOSviewer “can be used to construct\
    \ networks of scientific publications, scientific journals, \nresearchers, research\
    \ organizations, countries, keywords, or terms. Items in these networks can be\
    \ \nconnected by co-authorship, co-occurrence, citation, bibliographic coupling,\
    \ or co-citation links.” (van Eck \nand Waltman, 2021, p. 3) \n25 A “network is\
    \ a set of items together with the links between the items.” (van Eck and Waltman,\
    \ 2021, \np. 5) \n26 Other types of items to create maps in VOSviewer could be\
    \ for example publications, researchers, or \nterms (tags or key terms). \n \n\
    60 \nand score attributes27. In this case, the weight attributes are the links\
    \ and total link strength \nbetween items based on their co-occurrence28. The\
    \ software then labels the clusters using \ncluster numbers and different colors\
    \ to represent their connections. Figure 11 shows the \ngraphic created by VOSviewer,\
    \ which visualizes the networks constructed based on the \ninput data extracted\
    \ from the text sources reviewed. This serves as a complementary tool \nto the\
    \ categories reflected in the content analysis. \nRelevant factors related to\
    \ agricultural data governance were clearly revealed by \nvisualizing and exploring\
    \ the map created by VOSviewer. As a tool for addressing policy \nproblems, VOSviewer\
    \ effectively identified key themes and keywords related to \nagricultural data\
    \ governance. Through the analysis of the literature sources examined, the \n\
    software discovered a total of 35 co-occurring items or keywords. \n \n27 Both\
    \ attributes are represented by numerical values. For example, “A weight of an\
    \ item should in some \nway indicate the importance of the item. An item with\
    \ a higher weight is regarded as more important than \nan item with a lower weight…\
    \ A score attribute may indicate any numerical property of items.” (van Eck \n\
    and Waltman, 2021, p. 6) \n28 For any item this is “the number of links of an\
    \ item with other items and the total strength of the links \nof an item with\
    \ other items.” (van Eck and Waltman, 2021, p. 6) \n \n61 \nFigure 11 Keywords\
    \ co-occurrence network-based map of agricultural data problem \n \nFigure 11\
    \ displays a co-occurrence network based on high-frequency agricultural data \n\
    keywords found in the selected text data sources. VOSviewer's default colors were\
    \ used to \nindicate the five clusters of agricultural keywords, with lines showing\
    \ the distance between \nthe keywords. The red color represents the smart farming\
    \ cluster, with main connection \nlines to trust and data ownership. The blue\
    \ lines connect the transparency cluster, yellow \nlines present the code of conduct\
    \ cluster, green lines represent the data sharing cluster, and \npurple lines\
    \ depict the agricultural policy cluster. The distance between the keywords on\
    \ \nthe network indicates the level of co-occurrence and their relationship. The\
    \ closer the \ndistance, the higher the co-occurrence and stronger the relationship\
    \ between the keywords. \n \n62 \nIn addition to complementing the content analysis,\
    \ this map provides further insight into \nthe key policy problem factors related\
    \ to agricultural data governance. By clustering related \nkeywords according\
    \ to their co-occurrence and highlighting their connections, the map \nilluminates\
    \ the interrelationships between various themes and sheds light on their relevance\
    \ \nto the overarching policy problem. Thus, the map enhances our understanding\
    \ of the \ncomplex and multifaceted issues involved in governing agricultural\
    \ data. \nOne limitation of using VOSviewer is that it relies solely on text data\
    \ from reference \nmanager files, which may not capture all relevant sources on\
    \ a particular topic. To address \nthis, future studies could consider using multiple\
    \ sources of data, such as social media, \ngovernment reports, or interviews with\
    \ stakeholders, to provide a more comprehensive \nunderstanding of the policy\
    \ problem.  \n▪ \nBoundary Analysis \nBoundary analysis is a method used to define\
    \ the key elements of a policy problem by \nincorporating input from stakeholders\
    \ who have explicit knowledge or experience with the \ntopic (Dunn, 2018). The\
    \ aim of the boundary analysis method in this study is to specify \nand conclude\
    \ the structuring of the policy problem for governing agricultural data based\
    \ \non the key themes identified in the previous content analysis and software\
    \ analysis. The \npurpose of this approach is to estimate \"whether the system\
    \ of individual problem \nformulations … is relatively complete\" (Dunn, 2018,\
    \ p. 89). In other words, the goal is to \nidentify multiple problems that are\
    \ defined in different ways by key stakeholders in the \nagriculture sector. Overall,\
    \ this analysis seeks to establish the boundaries necessary to \nformulate the\
    \ policy problem of governing agricultural data in a comprehensive manner. \n\
    \ \n63 \nDunn's (2018) three-step process for boundary analysis includes saturation\
    \ sampling, \nelicitation of problem representation, and boundary estimation.\
    \ The first step, saturation \nsampling, involves an exhaustive review of biographic\
    \ references in selected documents to \nidentify additional actors or stakeholders\
    \ who discuss agricultural data issues. This process \ncontinues until no new\
    \ references are found, ensuring that a comprehensive list of \nstakeholders is\
    \ identified. The next step, elicitation of problem representation, involves a\
    \ \nsystematic analysis of stakeholder descriptions of the problem. This analysis\
    \ may include \ninterviews, surveys, or other means of gathering information from\
    \ stakeholders. The final \nstep, boundary estimation, involves identifying the\
    \ key elements or boundaries of the \nproblem by analyzing the stakeholder descriptions\
    \ and identifying areas of agreement or \ndisagreement. By following this three-step\
    \ process, boundary analysis can provide a \ncomprehensive and structured approach\
    \ to understanding the policy problem of governing \nagricultural data. \nThe\
    \ content analysis method was used to obtain \"problem representations from \n\
    stakeholders\" (Dunn, 2018, p. 91). Each text data set was revisited to select\
    \ text units that \nexplained how each actor or stakeholder described the issues\
    \ of data governance for farm \ndata. The context for the content under analysis\
    \ was provided by scholars, farm \nassociations, news sites in agriculture, and\
    \ publications from international organizations. \nFinally, the boundary estimation\
    \ process involved summing the cumulative frequency of \nkey agricultural data\
    \ problems from all text-data sources. A brief explanation of the three-\nstep\
    \ process is shown in Figure 12 and boundary estimations is displayed in a pareto\
    \ chart \nin Figure 13. \n \n64 \nFigure 12 Explanation of the boundary analysis\
    \ three-step process \n \nAdapted from Dunn 2018 \nThe first step involved accessing\
    \ written descriptions of the problem by stakeholders in \nthe agricultural sector\
    \ using text data sets collection. From the available documents, the \nsecond\
    \ step involved identifying problem representations within the bounded system\
    \ of \nstakeholders. These are \"ideas, basic paradigms, dominant metaphors, standard\
    \ operating \nprocedures, ... by which [stakeholders] attach meaning to events\"\
    \ (Dunn, 2018, p. 91). The \nthird step, represented by the Pareto chart in Figure\
    \ 12, shows the estimated boundary of \nthe key agricultural data problems that\
    \ were identified through content analysis. The Pareto \nchart primarily organizes\
    \ the count of themes, subthemes, and keywords obtained from the \ncontent analysis.\
    \ The revision of these themes was also compared with the keywords \nvisualized\
    \ in the VOSviewer map. \n• Thorough \nexamination of \nbiographic      \nreferences\
    \ to select \ndocuments \nSaturation Sampling \n• Stakeholder \ninformation to\
    \ \nidentify key themes \nand issues \nElicitation of Problem \nRepresentation\
    \ \n• Structuring of the \npolicy problem \nbased on identified \nthemes and issues\
    \ \nBoundary Estimation \nRelevant \ndocuments found \nKey themes and \nissues\
    \ identified \n \n65 \nFigure 13 Boundary estimation of agricultural data key\
    \ problem factors \n \nStatement of Policy Problem \nThe three methods presented\
    \ above provided the basis for defining a set of problem \ndimensions. The key\
    \ agricultural data items were classified into four dimensions: data \nsharing,\
    \ data production cycle, data rights and norms, and smart farming. Figure 14 \n\
    provides an overview of the most important dimensions of the policy problem, based\
    \ on \nthe results of the content analysis, VOSviewer software, and boundary analysis.\
    \ \nShare of cumulative Ag-\nData Elements \n \n66 \nFigure 14 Diagram of most\
    \ relevant dimensions in the agricultural data governance \npolicy problem \n\
    \ \nThe identified dimensions of the agricultural data governance problem emphasize\
    \ the \nimportance of a data governance policy framework that establishes guidelines,\
    \ standards, \nand roles to facilitate data sharing across the agriculture sectors\
    \ in the United States. This \nframework should focus on developing trustworthy\
    \ data-sharing systems and environments \nthrough mechanisms and measures that\
    \ enable agricultural data access and use. To achieve \nthis, the agricultural\
    \ data governance framework should prioritize trust and transparency \nin data\
    \ sharing, enhance mechanisms to increase data availability, and overcome technical\
    \ \nbarriers to data reuse within the sector. Such measures will enhance the value\
    \ and benefits \nthat the agriculture sector can derive from agricultural data,\
    \ transforming it into a smart \nand digitally transformed industry. \nThe use\
    \ of the three methods aimed to identify and map different perspectives on \n\
    agricultural data governance, and structure it as a policy problem through a multi-\n\
    Data Sharing\nData Rights and Norms\nData Production Cycle \nSmart Farming\n•Trust\
    \ and Transparency\n•Ethics\n•Risks\n•Cybersecurity\n•Data ownership\n•Data privacy\
    \ and \nsecurity \n• Digitization \n• Data use and re-use\n• Big and Open data\n\
    • Digitalization (improve \nprocesses by leveraging digital \ntechnologies)\n\
    • Digital farming technologies \naccess and challenges\n \n67 \nstakeholder approach.\
    \ However, it is important to note that these methods have a moderate \nlevel\
    \ of replicability, as they rely on general guidelines and specific descriptions\
    \ that may \nbe subject to researcher subjectivity and research context. \nThe\
    \ policy problem of agricultural data governance, as currently structured and\
    \ \nassuming its proper structuring, appears to be a broad but relatively well-organized\
    \ and \nmoderately complex policy problem. To further evaluate the agricultural\
    \ data policy \nproblem, ten wicked problem characteristics developed by Rittel\
    \ and Weber (1973) were \nused to demonstrate the moderately structured nature\
    \ of this problem. These characteristics \nare presented in Table 11. \nTable\
    \ 11 Comparison of the criteria to classify structured policy problems \nCharacteristics\
    \ \nAgricultural Data Governance Problem \nDecision-makers \nUSDA agencies, such\
    \ as the National \nAgricultural Library (NAL), or the \nNational Agricultural\
    \ Statistics Service \n(NASS) \nStakeholders \nBroad but relatively well-defined\
    \ (farmers, \nagriculture tech providers, tech companies, \nagribusiness) \nValue\
    \ Consensus \nModerate/Bargaining \nPreference Rankings \nRelatively stable and\
    \ transitive \nStop collection information rule \nRelevant knowledge/information\
    \ is large \nbut limited \nAbility to Forecast \nChallenging/Uncertain \nPolicy\
    \ Alternatives \nLimited \nAdministrative and Political Obstacles \nSome \nRole\
    \ of policy analysis in problem \nstructuring \nSome \nNature of policy problem\
    \ \nSecondary/Functional \nAdapted from Rittel and Weber 1973 \n \n68 \nAccording\
    \ to Mitroff (1974, p. 224 in Dunn, 2018), well-structured problems are those\
    \ \nfor which enough information is available to understand their sources and\
    \ develop feasible \npolicy solutions. While the agricultural data governance\
    \ problem is complex, it is \nmoderately well-defined, with evidence available\
    \ to help settle differences between \nstakeholders. Unlike a value-based problem,\
    \ this policy problem is not solely based on \nconflicting values or preferences,\
    \ but rather on practical challenges related to data sharing \nand management.\
    \ The policy solutions developed in the agriculture sector could be applied \n\
    to other sectors facing similar challenges. \nThe policy problem of agricultural\
    \ data governance is a complex and evolving issue, \nwith multiple stakeholders\
    \ involved in the governance of agricultural data, including \nfarmers, agricultural\
    \ technology providers, tech companies, and agribusiness. As data \nbecomes increasingly\
    \ central to agricultural production, there is a growing need to establish \n\
    guidelines, standards, and roles to facilitate data sharing and use across the\
    \ sector.  \nAdditionally, as the volume of agricultural data continues to increase,\
    \ there is a need for \nmechanisms to ensure data privacy and security, as well\
    \ as to address cybersecurity risks. \nFurthermore, there is a need to overcome\
    \ technical barriers to data reuse and establish \ntrustworthy data-sharing environments\
    \ to increase trust and transparency in the sector. \nOverall, a governance framework\
    \ for agricultural data is essential to maximize the sector's \nbenefits and value,\
    \ transforming it into a smart and digitally transformed industry. \n \n69 \n\
    Chapter 3: Policy Options \nThis chapter employs a comparative case analysis approach\
    \ to propose three distinct \npolicy options for agricultural data governance,\
    \ aimed at addressing the policy problem \nidentified in Chapter 2. The methods\
    \ used for the comparative case analysis include bench-\nmarking and lesson-drawing.\
    \ \nThe policy options, labeled as minimal, moderate, and maximal, are designed\
    \ to offer \ndistinctive solutions to the policy problem. To develop these options,\
    \ this research maps \nthe existing policy frameworks in other jurisdictions and\
    \ explore the potential \ntransferability of legal provisions to the agricultural\
    \ data governance context in the U.S. \nThis approach aims to fill the legal void\
    \ that currently exists in the U.S. agriculture sector \nregarding the governance\
    \ of agricultural data.  \nGeneric Standards \nMost legal regulations and policy\
    \ provisions that govern data are structured around two \nmain components: safeguards\
    \ and enablers. These components include standards for \nprotecting personal and\
    \ non-personal data, as well as ensuring secure mechanisms and \nprocesses for\
    \ the flow of private and public intent data sharing. Examples of these \nregulations\
    \ and policies include the \"Gramm-Leach Bliley\" Act (GLBA) for the financial\
    \ \nservice industry, the Health Insurance and Portability and Accountability\
    \ Act (HIPAA) for \nthe healthcare industry, and the California Consumer Privacy\
    \ Act (CCPA). However, in \nthe United States, agricultural data is currently\
    \ governed by contracts and licensing \nagreements controlled by private agricultural\
    \ corporations. This practice creates an \n \n70 \nenvironment where farmers and\
    \ primary producers have limited bargaining power and little \nincentive to share\
    \ their data.  \nThe Global Data Regulation Diagnostic publication from the World\
    \ Bank (Chen, 2021) \npresents a detailed assessment of laws and regulations on\
    \ data governance. Its content \ncovers both safeguards and enablers for data\
    \ governance across 80 countries ranging from \nlow to high-income groups (Chen,\
    \ 2021, p. 1). Figure 15 provides a useful overview of the \ndifferent components\
    \ of a data governance framework29 that can be used to guide the \nanalysis of\
    \ policy options for agricultural data governance in the U.S. \n \n29 A framework\
    \ understood as a structured and well-defined description of the data activities\
    \ upon which \na policy should be built. A policy framework in this research establishes\
    \ a set of criteria for selecting \nfeatures, elements, components, or mechanisms\
    \ from each existing data governance regulation that could \nsolve the agricultural\
    \ data problem in the United States. \n \n71 \nFigure 15 Data Governance Policy\
    \ Framework Components considered for Agricultural \nData \n \nAdapted from Chen,\
    \ 2021 \nSafeguards refer to norms or legal regulations that aim to protect the\
    \ data-related rights \nof market players, while enablers are norms or laws that\
    \ aim to facilitate the use and re-use \nof data (Chen, 2021). Both pillars, safeguards\
    \ and enablers, contain components that foster \ntrust and transparency among\
    \ stakeholders in governing data.  \nBy drawing on the best practices and lessons\
    \ learned from other jurisdictions, this \nresearch aims to develop a set of policy\
    \ options for agricultural data governance in the \nUnited States. These policy\
    \ options will be based on a comparative case analysis of existing \n \n72 \n\
    data governance frameworks30, with a particular focus on the regulatory components\
    \ of the \nCodes of Practice, the Gramm-Leach-Bliley Act (GLBA), the Health Insurance\
    \ and \nPortability and Accountability Act (HIPAA), the California Consumer Privacy\
    \ Act \n(CCPA), and the EU Data Governance Act. The selection of these laws and\
    \ regulations \nwas based on their relevance to the data governance dimensions,\
    \ which include both \nsafeguards and enablers, and their potential to address\
    \ some of the challenges in the \nagricultural sector.  \nThe Codes of Practice\
    \ provide principles and guidelines to promote responsible data \npractices. The\
    \ GLBA and HIPAA have frameworks for safeguarding personal data, which \nare important\
    \ considerations in the agricultural sector where personal data such as financial\
    \ \ninformation, bank loans and credit scores, and land ownership information\
    \ may be \ncollected from farmers. The CCPA has provisions for regulating the\
    \ use of non-personal \ndata, which are relevant for the agricultural sector where\
    \ both types of data (personal and \nnon-personal31) are generated and shared.\
    \ \nOne of the key challenges in agricultural data governance is balancing the\
    \ need for \nprivacy and data protection with the benefits of data sharing and\
    \ collaboration. On the one \nhand, farmers and other primary producers need to\
    \ be able to trust that their data will be \nkept confidential and used only for\
    \ agreed-upon purposes. On the other hand, data sharing \ncan lead to important\
    \ insights and innovations that can benefit the entire agricultural sector. \n\
    \ \n30 These frameworks include a mix of safeguards and enablers, such as data\
    \ protection regulations, data \nsharing agreements, and technical standards for\
    \ data interoperability. However, there is no one-size-fits-all \nsolution to\
    \ data governance, and policymakers must carefully consider the unique context\
    \ of their own \njurisdiction when developing data governance policies. \n31 Non-personal\
    \ data in the agriculture sector are agronomic data, such as soil type, crop type,\
    \ planting \ndensity, fertilization, and pesticide usage. \n \n73 \nFinding a\
    \ good balance between these competing interests is a difficult but necessary\
    \ task \nfor this study. \nCodes of Practice \nThis section analyzes four Codes\
    \ of Practice (COPs), also known as Codes of Conduct. \nCOPs are industry-led\
    \ self-regulatory frameworks for agricultural data practices. These \nCOPs aim\
    \ to promote good agricultural data practices among farmers, producers, and \n\
    agribusiness companies or ATPs. They comprise voluntary sets of rules based on\
    \ principles \n(Sanderson et al., 2018) and are intended to shape the behavior\
    \ of business or community \norganizations, and are enforced by the industry or\
    \ sector itself (Sanderson, 2019, p.6). \nThese codes address issues such as data\
    \ ownership providing definitions and best practices \nfor the management of agricultural\
    \ data. While adherence to these COPs is voluntary, they \noffer a framework for\
    \ stakeholders in the agriculture sector to work together and promote \nresponsible,\
    \ responsive, and transparent data contracting practices. \nCurrently, there are\
    \ only four codes available: the U.S. Farm Bureau Privacy and \nSecurity Principles\
    \ for Farm Data, the EU Code of Conduct on Agricultural Data Sharing \nby Contractual\
    \ Agreement, the New Zealand Farm Data Code of Practice, and the \nAustralian\
    \ Farm Data Code. These codes are relatively new, with the U.S. and New \nZealand\
    \ pioneering the launch of their codes of agricultural data practices in 2014,\
    \ \nsupported by private agriculture industry associations and businesses, and\
    \ in some cases, \nwith governmental assistance. \n \n74 \nWhile COPs represent\
    \ an initial collaborative effort to promote awareness about the \nvalue of agricultural\
    \ data among farmers, producers, and ATPs, they are relatively new32, \nnon-binding,\
    \ and their impact, effects, and consequences in terms of effectively governing\
    \ \nagricultural data between farmers and ATPs, as well as agribusiness companies,\
    \ remain \nunknown. According to Sanderson et al. (2018, p. 15), given the voluntary\
    \ nature of the \nfour existing COPs, there are additional challenges at the macro\
    \ structural-institutional \nlevel. These include the appropriation of an agile\
    \ agricultural data normative framework33, \nthe extension and implementation\
    \ of COPs, issues around trademark-based logos created \nfrom these codes, and\
    \ the assessment of the effects or consequences of existing COPs.  \nThe question\
    \ of whether self-policing by farm associations and agribusiness groups is \n\
    sufficient or whether additional oversight is necessary is complex. On the one\
    \ hand, \nallowing industry stakeholders to regulate themselves can be more efficient\
    \ and responsive \nto sector-specific issues, but on the other hand, it can also\
    \ lead to conflicts of interest and \na lack of accountability. \nIn this scenario,\
    \ the COPs are not mandatory and lack legal enforceability, thus the \nparties\
    \ engaged in data contracts have complete discretion over their adherence. Therefore,\
    \ \nthere is a possibility that certain parties may not adhere to the principles\
    \ outlined in the \ncodes, or that various stakeholders may interpret and implement\
    \ them inconsistently. \nThese four COPs have three general goals. First, to raise\
    \ awareness among farmers and \nproducers about the importance of agricultural\
    \ data. Second, to empower them to use data \n \n32 Most of them have been in\
    \ force since 2014. \n33 Sanders et al (2018) understand as an agile ag-data normative\
    \ framework as the set of rules, norms or \nprinciples regulating or norming the\
    \ agricultural data practices. \n \n75 \nto build a profitable future. And third,\
    \ to encourage agribusiness companies and ATPs to \nadopt more responsible, responsive,\
    \ and transparent data contracting practices. These \ncodes serve as the foundation\
    \ for resolving sector concerns related to agricultural data \ngovernance, including\
    \ issues around data ownership. \nThese COPs propose a collective action approach\
    \ to empower farmers and primary \nproducers to pursue transparent transactions\
    \ or practices of agricultural data through \ncontractual agreements. They are\
    \ based on definition of core principles and best practices \nfor agricultural\
    \ data, involving all stakeholders willing to comply, from farmers and \nproducers\
    \ to agribusiness and technology providers. According to Sanderson et al. (2018,\
    \ \np. 2), the purpose of agricultural codes of practice is \"inextricably linked\
    \ to consent, \ndisclosure, transparency, and ultimately, the building of trust.\"\
    \  \nOther contributions from all of these COPs include the specification of terms\
    \ and \ndefinitions. For example, the EU-COD defines what a data originator34\
    \ is, what their rights \nare, and data pseudonymization35. In the case of the\
    \ Australian Agricultural Data Rules, it \ncovers the concepts of data governance,\
    \ management, and implementation. It includes a \ncapacity and capability-building\
    \ component to educate farmers, as well as a risk, \nregulation, and compliance\
    \ component to ensure cybersecurity. \nAll of the principles embodied in these\
    \ codes for agricultural data practices are the result \nof collective action\
    \ by stakeholders in the agriculture sector. Efforts to develop and publish \n\
    \ \n34 Data originator is defined as the “person or entity that can claim the\
    \ exclusive right to license access to \nthe data and control its downstream to\
    \ use or re-use” (EU-CoD, 2018) \n35 Data pseudonymization is the “procedure in\
    \ which the most revealing fields within a data record are \nreplaced by one or\
    \ more artificial identifiers or pseudonyms.” (EU-CoD, 2018). Its main purpose\
    \ is to \n“render the data record less identifiable and therefore lower the risks\
    \ involved in its use” \n \n76 \ncodes of practice are based on consensus and\
    \ agreements among interested farm \nassociations, agribusiness companies, and\
    \ other agricultural industry organizations. The \nrole of the government in promoting\
    \ credibility and legitimacy in the principles promoted \nby COPs, as well as\
    \ monitoring compliance with them, is important. Governments can \nserve as a\
    \ third-party enforcer of compliance with the principles and act as a mediator\
    \ in \ncases of disputes. \n▪ \nNew Zealand Farm Data Code of Practice \nThe Farm\
    \ Data Code of Practice Version 1.1 was launched in New Zealand in 201436 \nafter\
    \ extensive consultation and planning across the agriculture sector. This code\
    \ provides \nguidelines for effective data sharing in the country's agriculture\
    \ industry and is adhered to \nby organizations such as Dairy NZ, the Red Meat\
    \ Profit Partnership, and the Ministry of \nPrimary Industries to ensure that\
    \ farmers' information is handled appropriately. The code \noffers recommended\
    \ standards and requirements for collecting, storing, and sharing \nagricultural\
    \ data and is owned and operated by Farm Data Accreditation Ltd (FDAL), an \n\
    independent company whose shareholders include the industry representative \n\
    organizations that created and mandated the code. \nThe Farm Data Code of Practice\
    \ in New Zealand regulates organizations that collect, \nstore, and share primary\
    \ agriculture data, with a focus on implementing practices that \nprovide primary\
    \ producers37  with confidence regarding their data security. Registered \n \n\
    36 According to the New Zealand Code of Practice, in “April 2015, ownership of\
    \ the Farm Data Code of \nPractice was transferred to an independent company,\
    \ Farm Data Accreditation Limited.” More information \navailable at:   \n37 “Primary\
    \ producers” is the term used to refer to farmers in the New Zealand COP. \n \n\
    77 \norganizations have agreed to disclose their practices and policies related\
    \ to data rights, \nprocessing, sharing, storage, and security (FDAL, 2016) to\
    \ increase data sharing securely \nwithin the sector and promote innovation in\
    \ services and products.  \nFDAL, an independent company, oversees the Code and\
    \ provides administrative and \noperation services to agriculture companies with\
    \ an annual license, certificate, and \npermission to use the trademark. FDAL\
    \ also has an executive board that receives \ncomplaints about noncompliance with\
    \ the principles, and determines whether agricultural \ncompanies' logos should\
    \ be renewed on an annual basis, making it a safeguard for farmers \nand agribusiness.\
    \ The distinctive roles and responsibilities of FDAL are what distinguish \nthis\
    \ code from the others, and will be considered for the purposes of this research.\
    \ \n▪ \nEuropean Union Code of Conduct on Agricultural Data Sharing \nby Contractual\
    \ Agreement \nIn the European Union38, a coalition of European farm associations39\
    \ from the EU agri-\nfood chain launched the Code of Conduct on Agricultural Data\
    \ Sharing by Contractual \nAgreement in 2018. Prior to these Code, agricultural\
    \ data was collected, stored, and used \n \n38 See Kosior, K. 2019 “From Analogue\
    \ to Digital Agriculture. Policy and Regulatory Framework for \nAgricultural Data\
    \ Governance in the EU” ISEG Research Seminar „Governance, regulation and economic\
    \ \nintegration”, Lisbon School of Economics and Management, University of Lisbon,\
    \ 8 May 2019 \n39 European farmers, and European agri-cooperatives (Copa and Cogeca),\
    \ European Agricultural \nMachinery (CEMA), European Organisation of Agricultural,\
    \ Rural and Forestry Contractors (CEETTAR), \nEuropean Council of Young Farmers\
    \ (CEJA), European Crop Protection Association (ECPA), European \nForum of Farm\
    \ Animal Breeders (EFFAB), European Compound Feed Manufactures’ Federation \n\
    (FEFAC), and European Seed Association (ESA).  \n \n \n78 \nby public institutions\
    \ (Kosior, 2019b), but the rapid development and implementation of \nfarming technologies\
    \ that generate large amounts of data highlighted the need for the Code \nof Conduct.\
    \ \nThis COP was developed with the input of various stakeholders from the agri-food\
    \ value \nchain, including farmers, agri-businesses, and public institutions.\
    \ This collaborative \napproach helped ensure that the guidelines are practical,\
    \ effective, and widely accepted. \nInitially, nine agro-associations40 developed\
    \ the guidelines for processing and sharing \nagricultural data in the EU Code.\
    \ The Code of Conduct was created to promote access to \naccurate agricultural\
    \ data, which is a crucial step \"to develop digital farming enabling \nfarmers\
    \ to produce more using fewer resources\" (Koerhuis, 2018, p.1). It provides guidance\
    \ \non the use of agricultural data, particularly on the rights to access and\
    \ use the data. It \nincludes a checklist as well as key guidelines for operators\
    \ to follow. Janzen (2018) and \nKoerhuis (2018) suggest that granting access\
    \ to agricultural data will facilitate and \naccelerate data-driven business models\
    \ in this sector. \nThis COP fosters a dialogue among all stakeholders in the\
    \ agri-food value chain \n(Wiseman et al., 2019, p. 7) to encourage fair and transparent\
    \ contractual agreement rules \nfor data sharing. Unlike the codes in the United\
    \ States and New Zealand, the European \nUnion's Code of Conduct provides specific\
    \ definitions to govern contracts between farmers \nand agri-business, preventing\
    \ contractual agreements from being misinterpreted.  \n \n40 Since 2018, the government\
    \ has partnered with industry associations such as Copa-Cogeca40, European \n\
    Agricultural Machinery (CEMA), Fertilizers Europe, the European Confederation\
    \ of Agricultural, Rural \nand Forestry Contractors (CEETTAR), European Council\
    \ of Young Farmers (CEJA), European Crop \nProtection Association (ECPA), European\
    \ Forum of Farm Animal Breeders (EFFAB), European Feed \nManufacturers' Federation\
    \ (FEFAC), and European Space Agency (ESA). \n \n79 \nThe Code of Conduct establishes\
    \ guidelines focusing on the rights and obligations \nassociated with the use\
    \ and sharing of agricultural data. It uses a \"compliance tool\" \n(Wiseman et\
    \ al. 2019, p.9) which is a contract checklist for agricultural data, to ensure\
    \ a \ntrustworthy environment to construct data-driven business models that benefit\
    \ all \nstakeholders involved in using a product or service that collects or uses\
    \ agricultural data. \nAccording to van der Burg et al. (2021, p. 6), the EU COP's\
    \ key features are its five \nprinciples: data ownership, data access, control\
    \ and portability, data protection and \ntransparency, privacy and security, and\
    \ intellectual property rights. \nOne additional point to consider regarding the\
    \ EU Code of Conduct on Agricultural \nData Sharing is the important role that\
    \ data standardization plays in its implementation. \nStandardization is critical\
    \ for ensuring data compatibility and interoperability between \ndifferent stakeholders\
    \ in the agricultural sector, as well as for improving the quality of the \ndata\
    \ itself. The EU Code of Conduct specifically encourages the use of existing standards\
    \ \nfor data exchange and storage, such as the ISO 1178341 standard for agricultural\
    \ technology \nand the AgGateway ADAPT framework42. This emphasis on standardization\
    \ helps to \n \n41 ISO 11783, also known as the Tractor Implement Management System\
    \ (TIMS), is an international \nstandard developed to enable interoperability\
    \ between tractors and implements used in agriculture. It \nprovides a communication\
    \ protocol for electronic control units (ECUs) used in agricultural machinery,\
    \ \nallowing them to exchange data and communicate with one another. The standard\
    \ covers a wide range of \nfunctions, including the exchange of data between tractors\
    \ and implements, the management of diagnostic \nand software updates, and the\
    \ control of functions such as steering, transmission, and hydraulics. The use\
    \ \nof ISO 11783 can improve the efficiency and productivity of agricultural operations\
    \ by enabling different \nmachinery components to work together seamlessly. Information\
    \ available at: International Organization \nfor Standardization (ISO). (2020).\
    \ ISO 11783-1:2017. Tractors and machinery for agriculture and forestry \n— Serial\
    \ control and communications data network — Part 1: General standard for mobile\
    \ data \ncommunication. https://www.iso.org/standard/57556.html \n42 The AGGateway\
    \ ADAPT (Agricultural Data Application Programming Toolkit) framework is an open-\n\
    source platform developed by the AGGateway organization to enable interoperability\
    \ between different \n \n \n80 \novercome the challenge of data fragmentation\
    \ and siloed information, allowing for more \neffective collaboration and data-driven\
    \ decision-making across the agri-food value chain. \n▪ \nAustralia Agricultural\
    \ Data Rules: Enabling Best Practices  \nThe Agricultural Data Rules were developed\
    \ in Australia and published in February \n2020 with the support of the National\
    \ Farmers’ Federation and the Australian Government \nDepartment of Agriculture,\
    \ Water and the Environment. This code was developed as part \nof the \"Growing\
    \ a digital future for Australian Agriculture\" program, and originated from \n\
    the ‘Accelerating precision agriculture to decision agriculture: Enabling digital\
    \ agriculture \nin Australia’ (P2D) project which evaluated the desired state\
    \ of digital agriculture in the \ncountry (Wiseman, 2019). \nThe National Farmers'\
    \ Federation partnered with a range of stakeholders, including \nfarmers, industry\
    \ bodies, government agencies, and technology providers. These \npartnerships\
    \ were critical in ensuring that the code was tailored to the needs of Australian\
    \ \nfarmers and industry participants, while also providing a framework for collaboration\
    \ and \ninnovation in the sector. \n \nsoftware applications used in agriculture.\
    \ The ADAPT framework provides a set of standard application \nprogramming interfaces\
    \ (APIs) that can be used to integrate different agricultural software systems,\
    \ such as \nfarm management systems, precision agriculture tools, and machinery\
    \ control systems. The framework is \ndesigned to be flexible and scalable, allowing\
    \ it to adapt to different types of data and workflows used in \nagriculture.\
    \ The ADAPT framework enables users to access data from different sources and\
    \ use it to inform \ndecision-making, improving the efficiency and profitability\
    \ of agricultural operations. Information \navailable at: AGGateway. (2021). AGGateway\
    \ ADAPT. \nhttps://www.aggateway.org/GetConnected/ADAPT(inter-operability).aspx\
    \ \n \n81 \nThe main objective of the Agricultural Data Rules is to not only develop\
    \ a data rules \nframework, but also to include an action plan that will create\
    \ an enabling environment for \ndigital innovation in Australian agricultural\
    \ industries (Wiseman & Sanderson, 2020, p. 3). \nThis code incorporates definitions\
    \ and principles from both the EU and New Zealand \nCOPs, making it a more robust\
    \ and comprehensive code for addressing the agricultural \ndata problem in Australia.\
    \ \nTo facilitate agricultural innovation through data-driven decision-making\
    \ and a reliable \nflow of agricultural data, the Australian Agricultural Data\
    \ Rules are structured around three \nkey pillars: people, responsibilities, and\
    \ structures. The roles of individuals handling \nagricultural data are essential\
    \ to the success of the code, and the \"capacity and capability\" \nand \"risk,\
    \ regulation, and compliance\" components address this issue. The former covers\
    \ \ncommunication, education, and training, while the latter addresses risk assessment,\
    \ \ncybersecurity, complaints, breach, and reporting (Wiseman & Sanderson, 2020,\
    \ p. 6).  \nThe code outlines six key principles for agricultural data management,\
    \ including \ngovernance, transparency, privacy, security, accessibility, and\
    \ usability. It provides \nguidelines for responsible data sharing, such as obtaining\
    \ consent from data owners, \nensuring data quality and accuracy, and protecting\
    \ sensitive information. By including \nthese principles and guidelines, the code\
    \ provides a comprehensive framework for the \nmanagement and sharing of agricultural\
    \ data in Australia.  \nWhile the code provides a valuable framework for data\
    \ governance and responsible data \nsharing, it may require significant resources\
    \ and investment to implement effectively. \nAdditionally, there may be challenges\
    \ in ensuring compliance with the code's guidelines, \n \n82 \nparticularly for\
    \ small-scale farmers and other stakeholders who may have limited resources \n\
    or technical capabilities. \n▪ \nThe U.S. Privacy and Security Principles for\
    \ Farm Data \nIn 2014, the American Farm Bureau Federation (AFBF), commodity groups,\
    \ farm \norganizations, and ATPs jointly formulated the \"Privacy and Security\
    \ Principles for Farm \nData\"43, also known as the Core Principles, which is\
    \ the most extensive code in the U.S. \nTwo years later, in 2016, AFBF, along\
    \ with other organizations and agribusiness \ncompanies, established the Ag-Data\
    \ Transparency Evaluator Inc44, a non-profit \norganization that developed the\
    \ Ag-Data Transparent logo or seal of approval45. This logo \nrecognizes compliance\
    \ with the Core Principles for agricultural data. However, no \nscholarly literature\
    \ or other documents are available that demonstrate or describe the \nverification\
    \ processes for Core Principles compliance. \nThe goal of the U.S. Core Principles\
    \ is to encourage as many agribusiness and \nagricultural tech companies46 as\
    \ possible to commit47 to including them in their contracts \nand agreements with\
    \ farmers. According to the information available on Ag-Data \n \n43 The Core\
    \ Principles are available at: https://www.agdatatransparent.com/principles \n\
    44 It is a non-profit organization providing the certification process based on\
    \ the Core Principles at a cost \ndepending on the size of the organization, whether\
    \ it is a startup, standard or large. More information \navailable at: https://www.agdatatransparent.com/about\
    \ and at: \nhttps://www.agdatatransparent.com/principles. \n45 An official logo\
    \ acting as a certificate of voluntary commitment to comply with the core principles\
    \ of \nagricultural data practices. \n46 According to the AFBF web page information,\
    \ over 37 organizations –agribusiness technology \nproviders (ATP) contracting\
    \ with farmers– have agreed to follow these Core Principles. \n47 Guarantee to\
    \ incorporate the Core Principles into ag-data contracts mainly based on a sign\
    \ of good \nfaith, since the ag data principles are non-binding guidelines. \n\
    \ \n83 \nTransparent, over 37 organizations (Certified Companies Ag Data Transparent,\
    \ 2022) in \nthe United States have agreed to follow the Core Principles and have\
    \ obtained the Ag Data \nTransparent certification as proof of compliance. This\
    \ certification process is based on the \n13 \"core principles,\" (Core Principles\
    \ Ag Data Transparent, 2022)48 and companies or \nATPs must answer 11 questions49\
    \ about how they collect, use, share, and protect farmers' \nagricultural data.\
    \ These answers are reviewed and approved by an independent third-party \nadministrator\
    \ (Certified Companies Ag Data Transparent, 2022), and when approved, \nADT issues\
    \ the certification seal. \nThe ADT seal or logo serves as an assurance to farmers\
    \ that organizations can be trusted \nto handle their agricultural data in contracts.\
    \ According to Todd Janzen, the ADT \nadministrator, the seal \"is helping provide\
    \ transparency, simplicity, and trust for farmers \nand their tech providers.\"\
    \ While the \"core principles\" for agricultural data are essential, the \ncertification\
    \ process demonstrates how they can be put into practice.  \nThe Core Principles\
    \ require agribusinesses to be open and transparent about their data \ncollection\
    \ and usage practices. Companies are expected to disclose the types of data they\
    \ \ncollect, how it is collected, and how it is used. They are also required to\
    \ be transparent \nabout the third parties with whom they share data and the purposes\
    \ for which they share it. \nIn addition to transparency, the U.S. Core Principles\
    \ emphasize the importance of \nsecurity in agricultural data practices. The principles\
    \ recognize that agricultural data is \nsensitive and valuable information that\
    \ requires protection. The Core Principles require \n \n48 Information available\
    \ at : https://www.agdatatransparent.com/principles \n49 11 Questions Ag Data\
    \ Transparent, 2022. Information available at \nhttps://www.agdatatransparent.com/11-questions\
    \ \n \n84 \nagribusinesses to implement reasonable security measures to protect\
    \ agricultural data from \nunauthorized access, use, or disclosure. The principles\
    \ also require companies to provide \nfarmers with information about their security\
    \ practices, including how they secure data, \nwhat security measures they have\
    \ in place, and how they respond to security incidents. \nOverall, the U.S. Core\
    \ Principles for Farm Data represent an important step towards \nestablishing\
    \ responsible data practices in the agriculture sector. By emphasizing the \n\
    importance of data control, transparency, and security, the Core Principles provide\
    \ a \nframework for agribusinesses and farmers to work together in a more responsible\
    \ and \ntrustworthy manner. The principles are not legally binding, but they provide\
    \ a valuable set \nof guidelines that can help ensure that agricultural data is\
    \ managed in a responsible and \nethical manner. \nIn summary, the common objective\
    \ of these codes is to create trusting environments and \nrelationships for sharing\
    \ and using agricultural data between farmers, producers, and \nservice, machinery,\
    \ and digital tech agribusiness providers based on contract agreements. \nNonetheless,\
    \ adherence to all agricultural data practices codes is entirely voluntary, as\
    \ they \nare non-binding guidelines for parties who agree to work together based\
    \ on data contracts. \nFigure 16 provides a visual comparison of these codes,\
    \ illustrating the gradual contribution \nof each code to the agricultural data\
    \ practices of the four countries. \n \n85 \nFigure 16 Comparison of existing\
    \ COPs \n \nAdapted from GODAN50 (2022) \nFigure 16 shows an incremental comparison\
    \ of the four COPs analyzed in this section. \nEach of these COPs includes comparable\
    \ guidelines and principles to enhance agricultural \ndata practices in their\
    \ respective countries. The Australian COP, released in 2020, \nintegrates numerous\
    \ definitions and principles from the preceding codes, while also \nemphasizing\
    \ the significance of enhancing capacity and capabilities within the agricultural\
    \ \nsector to effectively collect, manage, and utilize agricultural data. This\
    \ includes providing \ntraining and education to farmers and other stakeholders\
    \ on data collection and analysis \n \n50 GODAN toolkit: “Code of Conduct Constructor”\
    \ Available at: \nhttps://www.godan.info/codes/list/definitions  \n \n86 \nmethods,\
    \ as well as investing in the necessary infrastructure and technology to enable\
    \ \neffective data sharing and collaboration. \nCOPs are voluntary and principle-based\
    \ guidelines for the self-regulation of agricultural \ndata practices. While they\
    \ are not legally enforceable, they have the potential to drive \nsignificant\
    \ industry-wide shifts in data practices. These COPs provide foundational \ncomponents\
    \ for governing agricultural data, engaging stakeholders, fostering trust and\
    \ \ntransparency, and creating innovative pathways to extract value from agricultural\
    \ data. \nHowever, there is currently no conclusive evidence that these COPs are\
    \ effective tools for \nsupporting agricultural data practices in any of the countries\
    \ where they are in force.  \nCOPs can be a starting point for policy frameworks,\
    \ as they encourage discussions and \ncollaboration to find solutions that meet\
    \ the needs and interests of all involved parties. The \nGlobal Open Data for\
    \ Agriculture and Nutrition (GODAN), the Technical Centre for \nAgriculture and\
    \ Rural Cooperation (CTA), and the Global Forum on Agricultural Research \nand\
    \ Innovation (GFAR) have jointly launched a toolkit that enables stakeholders\
    \ to develop \nand simulate their own agricultural codes of conduct.  \nThe Agricultural\
    \ Codes of Conduct Toolkit is the result of a consultative process \ninvolving\
    \ the GODAN/CTA Sub-Group on Data Codes of Conduct, as part of a planned \nglobal\
    \ collective action on Empowering Farmers through Equitable Data Sharing. The\
    \ \ntoolkit aims to enable stakeholders to better understand the needs and concerns\
    \ of all actors \ninvolved in the agricultural data value chain, thus strengthening\
    \ trust across the industry. \nIt features 17 clauses that users can access and\
    \ select from depending on their relevance. \nWhile these clauses are not exhaustive\
    \ and do not replace a robust institutional framework, \n \n87 \nthey can be useful\
    \ in guiding decision-making and operationalizing ethical practices for \nthe\
    \ flow of agricultural data.  \nThe online platform can play a critical role in\
    \ creating a dialogue among stakeholders \nand finding solutions that address\
    \ the needs and interests of all parties involved. In the \nwords of Andre Laperriere,\
    \ Executive Director of GODAN, “Codes of conduct help \ninclude smallholder farmers\
    \ in decision making, policy design, and enhancement of \nprivacy protection and\
    \ trust, as well as providing considerable economic and health \nbenefits.” \n\
    U.S. Data Cooperatives  \nThere are several companies in the U.S. that offer data\
    \ services and solutions to the \nagriculture sector, including collaborative\
    \ agribusiness models such as data cooperatives51 \nand data pools. Six major\
    \ organizations in the United States serve as intermediaries in \nagricultural\
    \ data management. These organizations include the Ag Data Coalition (ADC), \n\
    the Grower Information Services Cooperative (GiSC), the Farmers Business Network\
    \ \n(FBN), and the most recent federally funded initiative of the United States\
    \ Department of \nAgriculture, the National Agricultural Producers Data Cooperative\
    \ (NAPDC). Other \norganizations such as the Open Ag Data Alliance (OADA), AgGateway,\
    \ and others have \n \n51 Data cooperatives are “entities established to facilitate\
    \ the collaborative pooling of data by individuals \nor organizations for their\
    \ mutual economic, social, or cultural benefit. From an economic perspective,\
    \ data \ncooperatives aim to rebalance the asymmetric relationship between data\
    \ subjects and those who use data to \ndevelop services and products” (Baloup\
    \ et al., 2021, p. 29) \n \n88 \nalso been discovered52. Table 12 summarizes information\
    \ from the four major agricultural \ndata companies. \nThese collaborative agribusiness\
    \ models, play a key role in ensuring buy-in from all \nstakeholders, particularly\
    \ farmers, in data-driven solutions, and highlighting the benefits \nthat come\
    \ with effective data governance. They provide oversight and transparency over\
    \ \nthe use of data entrusted to them, and ensure that data-driven strategies\
    \ add value to the \nagri-food chain in the United States. \nTable 12 Agricultural\
    \ Data Cooperatives in the U.S \nOrganization Description \nADC \nIt is a non-profit\
    \ organization created in 2016. Its organizational \npurpose is to educate the\
    \ agriculture sector about the value of ag-data –\nas an agriculture sector asset–\
    \ and its potential for data sharing \nbetween farmers, universities, and other\
    \ companies.  \nGiSC \nIt has been a farmer-owned national data cooperative since\
    \ 2014. Its \nmain objective is to provide farmers with a network of technology\
    \ \npartners. Also, it is an independent platform that gives agriculture \ntechnology\
    \ and data information and storage to improve farm \ndecisions and promote the\
    \ industrial agriculture revolution. \nFBN \nIt is a business network of independent\
    \ farmers that have shared \nagriculture data since 2014. It claims that its mission\
    \ is “by \ndemocratizing information, providing unbiased analytics, and creating\
    \ \ncompetition for farmers’ business.” (FBN, 2020) As a driven \n \n52 Others\
    \ are: AgMatix company for linking field research type data; AgNIC (A collaboration\
    \ among \nlibraries and organizations that promotes access to authoritative agricultural\
    \ information and data.); United \nStates Agricultural Information Network (USAIN);\
    \ the Agricultural Research Data Network (ARDN); and \nData Commons. \n \n89 \n\
    Organization Description \ninformation source, this network guarantees transparency\
    \ and fairness \nas values when dealing with ag data. \nNAPDC \nIt is defined\
    \ as a project. The overall goal of this project is to develop a \nblueprint for\
    \ a national data framework and cooperative where \nproducers, universities, and\
    \ not-for-profit entities can store and share \ndata and develop powerful tools\
    \ that enable producers to maximize \ntheir production and profitability. The\
    \ NAPDC will develop a \nblueprint for a national agricultural producers’ data\
    \ framework; engage \nand support diverse participation including all types of\
    \ agricultural \nresearch institutions, producers, and representatives of a relevant\
    \ data \nproducer and end-user organizations; and communicate and \ndisseminate\
    \ findings of all activities through publications, peer-\nreviewed articles, and\
    \ presentations to scientific and producer groups. \nThese companies function\
    \ as independent data aggregation platforms that share \nagronomic precision data\
    \ with a common goal of creating a secure system for processing \nagricultural\
    \ data efficiently. They offer centralized locations for managing all agricultural\
    \ \ndata. For instance, GiSC offers the AgHub tool, which collects and securely\
    \ stores all \nagricultural data from digital technologies such as tractors, sprayers,\
    \ sensors, and drones.  \nThese cooperatives emphasize a farmer-first approach\
    \ and claim to be an \"independent, \nunbiased, and objective farmer-driven information\
    \ source,\" as stated on the FBN53 website. \nOthers, like Open Ag Data Alliance,\
    \ create \"a secure data ecosystem that enables data \nsecurity, privacy, and\
    \ interoperability for the entire agriculture industry\"54 through open \nsoftware\
    \ available to farmers. These six data cooperatives mentioned are only examples\
    \ of \n \n53 More information available at: https://www.fbn.com/about \n54 Information\
    \ available at: http://openag.io/principles/ \n \n90 \npotential opportunities\
    \ to create new entities that address the ever-increasing volume of \nagricultural\
    \ data challenges for farmers.  \nIn conclusion, data cooperatives and other data\
    \ intermediaries are emerging as key \nplayers in the agriculture sector. These\
    \ organizations offer secure and centralized platforms \nto manage agricultural\
    \ data, provide oversight and transparency over the use of data \nentrusted to\
    \ them. Moving forward, the continued growth and success of these data \ncooperatives\
    \ will depend on their ability to maintain trust among all stakeholders, \nparticularly\
    \ farmers, and to keep pace with the rapidly evolving technological landscape\
    \ in \nthe agriculture sector. \nU.S. National and State-Level Laws and Regulations\
    \ \nThe policy landscape and legal framework regulating agricultural data governance\
    \ in \nthe United States reveals challenges and uncertainties. Although there\
    \ are regulatory bill \ninitiatives, none of them aim to set industry-specific\
    \ norms for data flow, sharing, privacy, \nand security. Modernization and innovation\
    \ of agricultural data infrastructure at the public \ninstitutional level, such\
    \ as the U.S. Department of Agriculture (USDA), is still pending. \nThe Agriculture\
    \ Improvement Act (P.L. 115-334), also known as the “2018 Farm bill,” \nwas signed\
    \ into law in December 2018 and will remain in effect until 2023 (McMinimy et\
    \ \nal., 2019). This Act was part of the U.S. Congress's periodic agricultural\
    \ policy revisions \nthat largely extended “agricultural commodity support programs\
    \ along existing lines while \nmodifying them in various ways” (McMinimy et al.,\
    \ 2019, p.1). The major changes focused \non reallocating funding across agriculture\
    \ and food programs. \n \n91 \nThe farm Bill 2018 responds to a periodic regulatory\
    \ revision that addresses a wide \nrange of agricultural and food-related issues;\
    \ for instance, issues related to “agricultural \nconservation, credit, rural\
    \ development, domestic nutrition assistance, trade and \ninternational food aid,\
    \ organic agriculture, forestry…” (McMinimy et al.,2019, p. 1) among \nothers.\
    \ One of the new Farm Bill 2018 provisions is the extension of support for urban\
    \ \nagricultural programs as well as the creation of new and specific authorities\
    \ (Janzen, 2018). \nHowever, the modifications in the law did not address the\
    \ issue of agricultural data \ngovernance, including standards, safeguards and\
    \ enabler mechanisms, or processes to \nmanage it in a way that farmers could\
    \ easily access information they reported themselves \nvia a single platform.\
    \ \nDespite these challenges, the USDA has made progress in recent years. For\
    \ example, \nthe 2014 Farm Bill mandated the Acreage Crop Reporting Streamlining\
    \ Initiative (ACRSI), \naimed at reducing the burden of data submission for farmers\
    \ and preventing duplication of \ndata received in various department programs\
    \ (Ristino & Hart, 2022, p. 7). ACRSI has \nestablished a standardized framework\
    \ for farmers to report acreage data to the USDA. The \ninstitutional role of\
    \ USDA is to develop and publish reporting standards for the framework \nas part\
    \ of the initiative. \nAccording to Ristino & Hart (2022, p.7), ACRSI data is\
    \ shared electronically and \nsecurely between farmers and relevant program areas.\
    \ ACRSI demonstrates the benefits \nand value of creating data standards that\
    \ facilitate more efficient, secure, and accurate data \nsharing across the USDA\
    \ (Ristino & Hart, 2022, p. 7). However, the disconnect between \nUSDA agencies\
    \ promotes institutional silos, making the integration, sharing, and use of \n\
    agricultural data even more difficult. \n \n92 \nIn 2018, the USDA established\
    \ a Chief Data Officer (CDO) and assistant Data Officers \nin each mission to\
    \ improve data governance practices within the agency. This institutional \nmodification\
    \ resulted in the creation of the Enterprise Data Analytics Platform and Toolset\
    \ \n(EDAPT). EDAPT connects data from 150 sources, both internal and external,\
    \ to provide \na comprehensive collection of administrative data and a standardized\
    \ set of centrally \navailable data analytics tools. The department-wide dashboard\
    \ created a more data-focused \nculture, building technical and leadership capacity\
    \ and inspiring other CDOs to develop \nsimilar platforms within their agencies\
    \ (Ristino & Hart, 2022, p. 7). \nThe USDA's development of the Data Strategy\
    \ for 2021-2023 represents a recent effort \nto tackle the challenges of governing\
    \ agricultural data within the agency. The Strategy's \nfirst goal is focused\
    \ on Data Governance and Leadership. In line with this, the USDA \nreleased the\
    \ USDA Data Act Governance and POC Charter in 2019. The Act seeks to \nenhance\
    \ data quality within the agency by establishing governance processes, protocols,\
    \ \nroles and responsibilities, and rules for accessing, controlling, and sharing\
    \ data within the \nagency's structural organization. The USDA's growing awareness\
    \ of data issues and its \ncritical institutional role in promoting the benefits\
    \ of effective use of agricultural data \nhighlights the importance of continuing\
    \ efforts to modernize and enhance data governance \nin the agriculture sector.\
    \ \nIn 2018, Senators Amy Klobuchar and John Thune introduced the Agricultural\
    \ Data Act \n(Ag-Data Act, 115th Congress, 2017-2018), a bipartisan bill aimed\
    \ at streamlining the \ncollection and sharing of agricultural data for the benefit\
    \ of U.S. agriculture producers. The \nprimary goal of the bill was to increase\
    \ knowledge about how conservation practices \nimpact farm and ranch profitability\
    \ and soil health by collecting, reviewing, and analyzing \n \n93 \ndata. The\
    \ bill intended to make USDA data available to researchers and land grant \nuniversities\
    \ to encourage the study of conservation practices and their effects on farm \n\
    profitability and soil health (Janzen, 2018a). \nAccording to Janzen (2018a),\
    \ the purpose of this bill is to streamline agricultural data \ncollection within\
    \ the USDA and make it available for research purposes to land grant \nuniversities\
    \ and other organizations. \nAt the state level, Minnesota's legal regulations\
    \ identify the various types of agricultural \ndata in the public sector. However,\
    \ they do not provide a description of the rules, norms, \nor processes to access,\
    \ share, and use such public data. In 2020, Chapter 13 outlined the \nGovernment\
    \ Data practices, and Section 13.643 and 13.6435 specifically deal with \nAgricultural\
    \ Data types. Table 13 below provides a detailed description of the content of\
    \ \nboth sections of the Minnesota legislation. \nTable 13 Minnesota Agricultural\
    \ Data Types Regulation \nSection \nTitle \nSubdivisions \n13.643 \nAgricultural\
    \ Data \n1. Department of \nAgriculture Data \n(a) Loan and grant \napplicant\
    \ data \n(b) Farm advocate data \n2. Farm assistance data \n \n3. Aquaculture\
    \ permit \ndata \n \n4. [Repealed, 2001, \nc202s21] \n \n5.Data received from\
    \ \nfederal government  \n \n6. Animal premises data \n \n7.Research, monitoring,\
    \ \nor assessment data \n \n13.6435 Agricultural data \ncoded elsewhere \n1. Scope\
    \ \n \n2. Department of \nAgriculture \n(a) Agriculture best \npractices loan\
    \ program \n \n94 \n(b) Aquaculture data \n(c) Aquatic farm license \n(d) Agricultural\
    \ \nCommodities Promotion \nCouncil. \n(e) Agricultural producer \nassociation\
    \ and commodity \nhandlers \n3. Pesticide control \n(a) Registration. \n(b) Dealer\
    \ and applicator \nrecords \n4. Agricultural \napplications; protection \nof trade\
    \ secrets. \n(a) Industrial hemp \nlicensing data. \n5. MS 2018 [Repealed, \n\
    2020 c 89 art 1 s 21] \n \n6. Meat inspection data \n \n7. [Repealed, 1Sp2001\
    \ c \n2 s 162] \n \n8. Dairy products \n \n9. [Repealed, 2010 c 382 \ns 87] \n\
    \ \n10. Rural Finance \nAuthority \n \n11. Farm products; grain \nbuyer licensee\
    \ data. \n \n12. Farmer-lender \nmediation. \n \n13. Ethanol producer \npayments.\
    \ \n \n14. Agricultural water \nquality certification \nprogram \n \nAdapted from\
    \ Minnesota, Status 2020. CHAPTER 13 GOVERNMENT DATA PRACTICES \nThe subdivision\
    \ 4 of Section 13.6435, \"agricultural applications; protection of trade \nsecrets,\"\
    \ is a significant step towards addressing legal issues and disputes related to\
    \ ag data. \nHowever, Ellixson & Griffin (2016, p.2) point out that as of 2016,\
    \ there were no laws \ncovering the ownership of agricultural data or the consequences\
    \ of misusing that data. \n \n95 \nThe agricultural sector's national and public\
    \ data infrastructure is essential for providing \ncritical agricultural insights,\
    \ improving the effectiveness of farm bill programs, and \noffering better value\
    \ to farmers and taxpayers (Ristino & Hart, 2022). To address these \nissues,\
    \ the AGree Initiative, Three Canyon Farms, Data Foundation, University of Missouri\
    \ \nCenter for Regenerative Agriculture, and the Meridian Institute collaborated\
    \ on the \nwebinar, \"Models for Modernizing Agriculture Data Infrastructure:\
    \ Lessons Learned from \nData Innovation in Other Sectors\" on June 9, 2022. They\
    \ discussed the recently published \nreport, \"Modernizing Agriculture Data Infrastructure\
    \ to Improve Economic and Ecological \nOutcomes,\" which outlines four practical\
    \ options for modernizing the USDA's data \ninfrastructure to adapt, innovate,\
    \ and ensure food security in the future (Ristino & Hart, \n2022). Figure 17 illustrates\
    \ these four models. \nFigure 17 Four Models to Modernize the USDA Agricultural\
    \ Data Infrastructure \nAdapted from (Ristino & Hart, 2022, p. 3) \nThe current\
    \ USDA data infrastructure is struggling to assist farmers in addressing \nchallenges,\
    \ such as the extreme weather events that caused the Midwest floods in 2019, \n\
    disruptions in global supply chains like those experienced in 2021, and the rising\
    \ prices of \nfertilizers (Ristino & Hart, 2022). Adopting one of the four proposed\
    \ models could help \n \n96 \nimprove the low institutional performance of the\
    \ USDA in assisting agriculture digital \ntransformation.  \nA centralized model\
    \ for data infrastructure, operated within the USDA, could provide \nreliable\
    \ data standards and build trustworthy systems for farmers and other stakeholders.\
    \ \nHowever, Ristino and Hart (2022, p. 3) argue that due to the USDA’s limited\
    \ infrastructure \ncapacity and heavy inter-institutional regulations, this model\
    \ may be impractical.  \nThe second model proposes centralizing the data infrastructure\
    \ under a public-private \npartnership. This model combines the appeal of enabling\
    \ government authorities for data \nprotection and resources with the flexibility\
    \ of the private sector, including its ability to \nprotect proprietary information.\
    \  \nA third model involves designing a data linkage hub. Ristino & Hart (2022)\
    \ state that \nongoing discussions are underway to determine the benefits of this\
    \ model. It would provide \na highly secure environment for integrating data with\
    \ some usage restrictions. \nThe final model proposes a contractual approach,\
    \ which is sensitive and requires \ncoordination and negotiations with farmers\
    \ regarding the economic contractual rates \n(Ristino & Hart, 2022, p. 14). This\
    \ approach requires clear incentives to compensate \npartners or data providers\
    \ for data exchange and transactions. \nWhile not prescriptive, these four models\
    \ offer potential solutions to the challenges \nfacing the USDA agency's data\
    \ practices. In a webinar featuring speakers such as Robert \nBlair, president\
    \ of Three Canyon Farms, it was noted that farmers have a distrust of data \n\
    reporting and that the USDA is falling behind in terms of data practices in the\
    \ information \nage (Atwood et al., 2022). Blair emphasized the need for the USDA\
    \ to modernize its \n \n97 \ninfrastructure to collect and promote data flow among\
    \ farmers and other USDA agencies. \nAgriculture stakeholders recognize the importance\
    \ of using data to improve food safety \nand security at a macro level. \nThe\
    \ four proposed models for modernizing the USDA's data infrastructure system offer\
    \ \nan opportunity to build trust and collaboration between farmers and other\
    \ stakeholders in \nthe agriculture sector, as well as unlock economic opportunities\
    \ by leveraging data value. \nFor example, better information about farms' productivity\
    \ and risk can help address \ndynamic weather and economic challenges (Ristino\
    \ & Hart, 2022, p. 4) and researchers \ncould use data to understand how different\
    \ farming practices affect productivity and \nenvironmental outcomes, which can\
    \ enable ecosystem markets. \nHowever, while these models address the issue at\
    \ the meso-institutional level, governing \nagricultural data at the macro sector\
    \ level remains a challenge. Private agribusiness firms \nare already using data\
    \ to make production decisions and promote carbon markets, and \nagricultural\
    \ machinery manufacturers are connecting equipment to the cloud for real-time\
    \ \ndata collection. Meanwhile, the USDA's data infrastructure has stalled, hindering\
    \ its ability \nto support farmers and enhance program performance. \nLesson Drawing\
    \ and Benchmarking \nThis section summarizes the main lessons, best practices,\
    \ and benchmarks drawn from \nthe examination of existing regulatory frameworks\
    \ for data governance in the U.S., other \ncountries, other sectors, and Europe.\
    \ Lesson-drawing is a process that requires more than \njust highlighting successful\
    \ examples of current programs or processes addressing similar \n \n98 \nproblems\
    \ elsewhere. As Rose (1991, p. 19) notes, it also requires examination of under\
    \ \nwhat conditions and to what extent a current program or process would work\
    \ elsewhere. \nOne lesson to draw from the codes of practice is the importance\
    \ of agricultural data \ndefinitions. While the U.S. code of practice does not\
    \ explicitly describe the types of data \ncovered by the set of principles, the\
    \ codes from New Zealand and the European Union do \nso to varying degrees. The\
    \ EU COP provides a comprehensive list of definitions that \naccurately describe\
    \ the scope of all three codes55 (van der Burg et al., 2021), including the \n\
    importance of data originators56 having control over their data. \nOne of the\
    \ strengths of codes of practice (COPs) is that they are principle-based and \n\
    reflect what the industry considers good practice in agricultural data management\
    \ \n(Wiseman et al., 2019, p. 11). Instead of prescribing specific processes or\
    \ actions, COPs \nfocus on the desired outcomes of data practices. This approach\
    \ emphasizes consent, \ndisclosure, and transparency in data practices through\
    \ contractual agreements rather than \ndictating how agribusinesses should manage\
    \ their data. \nAnother lesson learned from examining the COPs, is the importance\
    \ of the Australian \nData Rules, which provide an action-oriented program for\
    \ capacity building, training, and \nrisk management. Figure 18 summarizes these\
    \ regulatory lessons drawn from the COPs, \nwhich are concise and relevant to\
    \ the proposed data governance framework. \n \n55 EU code definition of agricultural\
    \ data: “data related to agricultural production, including farm data and \nall\
    \ types of data generated within the farming processes”  \n56 Data originator:\
    \ “the person or entity with the exclusive right to license data access and control\
    \ its \ndownstream use and re-use.” Definition from the EU Code of Conduct (p.6).\
    \ \n \n99 \nFigure 18 Agricultural Data Governance Policy Framework: regulatory\
    \ dimensions and \nattributes to design the policy options \n \nAdapted from Chen,\
    \ 2021 \nFurthermore, benchmarking allows for the comparison and measurement of\
    \ standards \nand strategies that can foster trust and transparency. The Gramm-Leach-Bliley\
    \ Act \n(GLBA)57 is a significant example not only because it established data\
    \ handling standards, \nbut also because it expanded consumer rights. Customers\
    \ now have the right to access their \n“nonpublic personal information (NPI)58”\
    \ at any time, increasing transparency between \nconsumers and financial institutions.\
    \ This increase in transparency has given consumers \n \n57 Gramm-Leach-Bliley\
    \ Act, Pub. L. No. 106-102, 113 Stat. 1338 (1999). \n58 Nonpublic personal information\
    \ refers to any information that can be used to identify an individual and \n\
    is not available to the public. Examples of NPI include a person's name, address,\
    \ social security number, \ncredit card number, and financial account information.\
    \ GLBA requires financial institutions to disclose \ntheir policies for collecting,\
    \ sharing, and protecting NPI, and to give customers the right to opt out of \n\
    having their NPI shared with third parties. \n \n100 \nthe ability to control\
    \ how their data is handled and to opt out of sharing information with \nthird\
    \ parties. \nSimilarly, the U.S. HIPAA59 regulation sets rules and standards governing\
    \ the privacy \nand security of personal health data in the country. By establishing\
    \ compliance and security \nrules, HIPAA ensures a reliable flow of health and\
    \ personal data. For instance, it defines \nthe roles and responsibilities of\
    \ institutions providing healthcare and health insurance \ncompanies to protect\
    \ patients' personal information. \nTo encourage innovation, best practices for\
    \ agricultural data management should \nprioritize implementing data governance\
    \ strategies such as defining roles and \nresponsibilities for decisions involving\
    \ agricultural data, promoting data sharing, building \ntrust in data collection,\
    \ use, and sharing, and ensuring adequate safeguards against the risks \nassociated\
    \ with data misuse. \nIn the US, data cooperatives have emerged to address the\
    \ lack of proper management \nand utilization of the data collected, as well as\
    \ the absence of a standardized comprehensive \nsecurity system for the flow of\
    \ agricultural data. While these cooperatives offer a variety \nof digital solutions,\
    \ an agricultural data governance framework should aim to simplify data \nexchange\
    \ between companies, farmers, and the public sector. It should provide a \ncomprehensive\
    \ solution to the vulnerability of agricultural data to breaches and cyber-\n\
    attacks. \n \n59 Health Insurance Portability and Accountability Act of 1996,\
    \ Pub. L. No. 104-191, 110 Stat. 1936 \n(1996). \n \n101 \nPolicy Options Design\
    \ \nThis research proposes three policy alternatives or options60 as potential\
    \ solutions to \naddress the policy problem of agricultural data governance in\
    \ the U.S. A well-designed \npolicy should have clear, specific, and consistent\
    \ goals, with links to the targeted behavior \nof the population, and ultimately\
    \ the desired outcomes (Schneider, 1997, p. 35). The policy \nalternatives proposed\
    \ in this research are tailored to the data governance pillars, which \ninclude\
    \ safeguards and enablers, as per the legal data governance framework presented\
    \ by \nWDR21 (World Bank, 2021), that encompass various types of data and stakeholders.\
    \ \nFigure 19 illustrates the policy design components considered in the formulation\
    \ of the \npolicy alternatives. \nFigure 19 Components of Policy Design \n \n\
    Adapted from (Schneider, 1997) \nTools and rules are procedural aspects of policy\
    \ design that specify who is responsible \nfor what, where, and when (Schneider,\
    \ 1997, p. 97) in order to achieve certain benefits, \nsuch as capacity-building\
    \ or providing incentives for action. Rationales and assumptions \nare explanations\
    \ or reasons for the design decisions made, such as the choice of target \npopulation,\
    \ tools, rules, and goals (Schneider, 1997, p. 99). The rationale connects the\
    \ \n \n60 In policy-making, a policy alternative or option refers to an action\
    \ that produces specific consequences \nor effects (Stone, 2012, p. 225). The\
    \ policy alternatives were developed based on a comparative analysis of \nexisting\
    \ data governance frameworks described in this chapter. \n \n102 \npolicy elements\
    \ to the context, making explicit claims that the design is responsive to the\
    \ \nproblem and will have a positive impact. Assumptions are the underlying logic\
    \ that \nconnects the selected elements together. Policy goals and problems to\
    \ be solved are \nintentional aspects of policy design. These are expressed in\
    \ objective and technical terms, \nbut they represent desired outcomes. They can\
    \ be broadly defined and framed in terms of \npublic interest or narrowly defined\
    \ and framed to affect only specific groups (Schneider, \n1997). \nDesigning a\
    \ data governance policy framework involves establishing guidance norms \nand\
    \ rules, data quality standards, defining roles and responsibilities for compliance\
    \ and \nsecurity, and promoting capacity building, particularly among farmers.\
    \ The overall \nobjective is to develop a policy that governs the flow of agricultural\
    \ data while promoting \ntrust and transparency among all stakeholders. \nAn agricultural\
    \ data policy should be drafted as \"principle-based and technologically \nneutral\
    \ laws and regulations... [to] help them remain relevant as technologies evolve\
    \ and \nreduce compliance burdens” (World Bank, 2021, p. 191), which means creating\
    \ an \nadaptable policy. A data governance policy framework requires government\
    \ agencies in \nthe agriculture sector to act not only as regulators but also\
    \ as investors in good data \npractices that can generate value from agricultural\
    \ data. \nAn expert judgement from the international institution, OECD, and its\
    \ report \"Digital \nOpportunities for Better Agricultural Policies\" (OECD, 2019),\
    \ states that governments \nshould take the lead in improving access to agricultural\
    \ data. One key role of the \ngovernment in micro/farm level agricultural data\
    \ is to enable the ability to link datasets \n \n103 \nwhile preserving confidentiality\
    \ as necessary (Sanderson et al., 2018). The \nrecommendations of OECD (2019)\
    \ have been synthesized in Table 14. \nTable 14 Government role and what they\
    \ should do \nPublic \norganizations/institutions \nFunctions/roles (what needs\
    \ to be done…) \nGovernment agencies: \nstatistical agencies, \nadministrative\
    \ agencies (e.g., \npaying agencies for voluntary \nprograms) and regulatory \n\
    agencies (e.g., environmental \nregulators) \nTo increase their interaction and\
    \ explore ways to pool \ndata. They should also work together with data \nproviders\
    \ and data users to establish a clear \nframework governing data access. \nGovernments\
    \ \nTo formulate clear policies for access and use of \nadministrative data which\
    \ consider both the benefits \nand risks. \nTo investigate how administrative\
    \ data can be re-used \nto support: 1) agricultural and agri-environmental \n\
    policy implementation; 2) policy-relevant research; \nand 3) services to farmers.\
    \ \nTo create a coherent, tiered data dissemination \nstrategy to improve access\
    \ to agricultural micro data. \nTo explore ways to incentivize provision of private\
    \ \nsector data for public use and for agricultural \nresearch; options include\
    \ monetary incentives (i.e., \npayments for data provision) and non-monetary \n\
    incentives such as provision of regulatory safe \nharbors for data providers.\
    \ \n \n104 \nData-collection agencies  \nTo explore how the burden of existing\
    \ data collection \nby government organizations can be lessened while \nmaintaining\
    \ or strengthening data collection using \ndigital technologies. \nTo put in place\
    \ data management frameworks which \ninclude methodologies for the evaluation\
    \ of data \nquality for data from alternative sources and \nplanning. \nAdapted\
    \ from OECD (2019) “Digital Opportunities for Better Agricultural Policies” \n\
    The data governance framework includes safeguards to protect personal data and\
    \ \nbalance the interests of data reuse and non-personal data. Enablers promote\
    \ mechanisms \nfor data sharing and incentivize both the public and private sector\
    \ to use and reuse data. \nThe framework also defines roles and responsibilities\
    \ for creating an environment that \nfosters education on digital technologies\
    \ and their implementation. The intended outcome \nis to create robust and adaptable\
    \ data governance regulations that include safeguards to \nprevent the misuse\
    \ of data, as well as enablers that facilitate access to and use of data. \nFigure\
    \ 20 captures the components of the data governance framework for each policy\
    \ \noption in this research. In order to integrate the role of institutions, the\
    \ \"roles and \nresponsibilities\" pillar is an additional component of each policy\
    \ option data governance \nframework. Outcomes are added to the policy options\
    \ design to serve as an analysis \ncriterion for each of them. \n \n105 \nFigure\
    \ 20 Components of policy design for agricultural data governance policy options\
    \ \n \nSafeguards are an essential component of a data governance policy framework,\
    \ as they \nprovide mechanisms and processes to create a secure environment for\
    \ accessing and using \npersonal and non-personal data. They support individuals'\
    \ agency to control their data, \nensuring their data rights to give consent to\
    \ the use of personal data (World Bank, 2021, p. \n191), such as farmers' addresses\
    \ and identification numbers, or third-party access to non-\npersonal data, such\
    \ as crop production. The goal of these norms is to ensure data security \nand\
    \ promote trustworthiness. \nThe inclusion of safeguards in the policy options\
    \ design is crucial due to the concern of \npower asymmetries arising from a data\
    \ control approach, rather than a data ownership \nperspective. Therefore, safeguards\
    \ are established in the form of substantive rights, such \nas preventing unauthorized\
    \ disclosure or unfair use of personal and non-personal data, and \nprocedural\
    \ rights that promote transparency and accountability, such as the right to receive\
    \ \nnotice, object to data usage, and access, correct, or erase data (World Bank,\
    \ 2021, p. 194). \n \n106 \nEnabling norms and rules for the good practice of\
    \ data use and reuse are a fundamental \npillar of a data governance framework.\
    \ Enablers are primarily analyzed based on the \ndomain of the data, i.e., whether\
    \ the data are generated or controlled by the public or private \nsector, or both\
    \ (World Bank, 2021, p. 199). \nInstitutions play a critical role in implementing\
    \ regulations. They have distinct values, \nnorms, and operating procedures that\
    \ define their culture (Schneider, 1997, p. 76). The \nUSDA is the federal agency\
    \ responsible for the agriculture sector, and it has the potential \nto modernize\
    \ its structure to support sector data governance and promote a data-driven \n\
    culture within the sector. \nIncorporating justice as a central standard in policy\
    \ design can create an institutional \ndata-driven and digital technology culture\
    \ that serves the interests and principles of \ndistributive justice (Schneider,\
    \ 1997, p. 64). To achieve desired outcomes, policy design \nshould target specific\
    \ populations (Schneider, 1997, p. 35). The goal of an agricultural data \ngovernance\
    \ policy framework is to create strong and resilient policy options that can adapt\
    \ \nto the rapid and ongoing evolution of IR 4.0 technologies such as AI, IoT,\
    \ and ICTs. Such \na framework should also be able to deal with multi-stakeholder\
    \ conflicts over the medium-\nto-long term (Howlett, 2019, p. 28). \nTo achieve\
    \ both robustness and resilience in policy design, Howlett (2019, p. 30) \nsuggests\
    \ the need to design and adopt policies that feature agility and flexibility in\
    \ their \ncomponents and processes. Therefore, institutions' role in policy design\
    \ is to determine the \nnecessary robustness and resilience to respond to the\
    \ need for a mutually influencing co-\nevolution of technology and regulatory\
    \ frameworks. \n \n107 \nAfter considering all these factors in proposing an agricultural\
    \ data governance \nframework, this research presents three policy options: minimalist,\
    \ moderate, and \nmaximalist. Table 15 summarizes these three policy alternatives,\
    \ including the rules, \nnorms, degree of intervention by institutions, goals,\
    \ the expected problems to be solved, \nand desired outcomes. \nTable 15 Three\
    \ Policy Options for an Agricultural Data Governance \n \n \nMinimal \nModerate\
    \ \nMaximal \nFrom the least \nto the most \nvisible/tangible \nrole of \ngovernment\
    \ \nGovernment level \nFormal record \nof standard \noperating \nprocedures \n\
    Regulatory–\nFederal level \nStatutory–\nState level \nRegulation visibility \n\
    Low visibility \ninternally \npublished \n(agencies \ninternal rules) \nModerately\
    \ \nvisible \nthrough \nfederal states \nregulations \n(regulatory \nagencies)\
    \ \nHighly \nvisible \nthrough \ncodification \nin statute law \npublication \n\
    (Congress \npublic \nlegislation) \nPolicy Goals \nEquity–equal \nopportunities\
    \ \nfor all \nstakeholders \nto benefit \nfrom the value \nof data \nEquality–\n\
    efficiency \ntrade-offs \nEquality–\nefficiency, \nand security \n \n108 \n \n\
    \ \nMinimal \nModerate \nMaximal \nPolicy Outcomes \nState and local \nagencies\
    \ \ninternal values \nthat have \nimplications \nfor policy \noutputs, \nbenefits.\
    \ \n(Everyone \ngains) \nProtective \nregulatory \n(bargaining, \ncompromise)\
    \ \nRedistributive \n(ideological \nand class \nconflict) \nAdapted from Stone\
    \ (2012) and Birkland (2011) \nThese three policy options represent three policy\
    \ levels. The first level, the minimalist \npolicy option, it is a data governance\
    \ solution that emerge from the COPs created by the \nagriculture sector farm-led\
    \ associations. A second level, the moderate policy option, it is a \ndata governance\
    \ solution that sets out rules for all private and public parties to follow \n\
    regarding data use. And finally, a third level, a maximalist policy option, it\
    \ is a data \ngovernance solution integrating data governance level 1 and 2 and\
    \ considering the rights \non and of data at the national level, i.e., a data\
    \ governance act for agricultural data. \n▪ \nOption 1: Minimalist \nThe purpose\
    \ of the minimalist policy approach is to address the issue of mistrust in \n\
    current agricultural data practices through contractual agreements between farmers\
    \ and \nproviders. This option is minimal in its scope as it aims to transform\
    \ the voluntary nature \nof the U.S. Code of Practice (COP) and involve agriculture\
    \ institutions and agencies in \n \n109 \nimplementing processes and mechanisms\
    \ to oversee and evaluate Agriculture Tech \nProviders (ATPs) and other agribusinesses\
    \ that carry a data transparent logo. The goal is \nto ensure that ATPs adhere\
    \ to ethical data practices and provide transparency in their data \nsharing agreements\
    \ with farmers. \nIntended goal: to shift the agricultural sector's mindset towards\
    \ agricultural data \ngovernance, grounded in the U.S. core principles for data\
    \ practices. \nThe goal of the minimalist policy approach is to shift the agricultural\
    \ sector's mindset \ntowards agricultural data governance by transforming the\
    \ voluntary self-regulated set of \nguidelines and principles in the U.S. COP\
    \ into a legal normative data framework that \ngoverns decision-making on agricultural\
    \ data sharing. Government agriculture agencies \nwould play an intervening role\
    \ in supervising the process for obtaining a data transparent \nlogo, seal, or\
    \ trademark and establishing a standardized agreement model specific to the \n\
    agricultural sector in the U.S. In essence, the goal is to achieve a more meaningful\
    \ model \nof consent for using and reusing agricultural data between the private\
    \ and public sectors \nand farmers in the modern digital age. \nEnabling trustworthy\
    \ data operations is crucial for promoting transparent agricultural \ndata practices\
    \ based on the U.S. Code of Practice and the Core Principles. \nThis requires\
    \ implementing technical and organizational measures to ensure data \nintegrity,\
    \ security, and privacy, such as data encryption, access controls, and audit trails.\
    \ \nMoreover, it involves fostering a culture of transparency and accountability\
    \ in data \noperations, which includes informing data subjects about data collection\
    \ and processing \nactivities, obtaining their consent when necessary, and providing\
    \ them with access to their \ndata and the means to correct or delete it. By enabling\
    \ such data operations, the agricultural \n \n110 \nsector can enhance trust among\
    \ stakeholders and promote the responsible use and reuse of \nagricultural data.\
    \ \nA good starting point is to make the U.S. COP's \"core principles\" legally\
    \ binding, as \nthey have been defined and agreed upon by farmers61 to improve\
    \ agricultural data \ngovernance practices. These core principles set rules and\
    \ standards for data sharing, use, \nand reuse, and can help determine the roles\
    \ and responsibilities of the USDA and its \nsubagencies, as well as establish\
    \ a standardized classification of agricultural data types for \nuse in contractual\
    \ agreements. To encourage compliance, the USDA can supervise the \nprocess of\
    \ obtaining a trademark or logo from ATPs and agri-businesses committed to \n\
    promoting transparent data practices. Regulations and institutional interventions\
    \ can also \nhelp foster trust and encourage compliance behaviors, as unified\
    \ data classification is a key \nenabler of data reuse (World Bank, 2021, p. 202).\
    \ \nEnablers to data interoperability & integration for making attractive incentives\
    \ for \npublic and private intent data sharing  \nData interoperability and integration\
    \ can enable the seamless exchange of data between \ndifferent systems, applications,\
    \ and stakeholders in the agricultural sector. This can be \nachieved by adopting\
    \ standard data formats, APIs, and protocols for data sharing, use, and \nreuse.\
    \ Several enablers can promote data interoperability and integration: \n- \nOpen\
    \ data standards: Open data standards can enable data to be shared and \nintegrated\
    \ across different platforms, applications, and stakeholders. Standards \n \n\
    61 Farmers who are part of or participate through the American Farm Bureau Federation\
    \ (AFBF) \n \n111 \nsuch as the AgGateway ADAPT framework can facilitate interoperability\
    \ among \nprecision agriculture devices and software systems. \n- \nIncentives\
    \ for data sharing: Public and private sector actors can be incentivized to \n\
    share and integrate data through financial, social, and technical means. For \n\
    instance, government subsidies, tax credits, or grants can encourage data sharing\
    \ \namong farmers, while social recognition, reputation, or peer pressure can\
    \ motivate \nprivate sector actors to share data. \n- \nData intermediaries: Data\
    \ intermediaries can act as trusted third parties to \nfacilitate data sharing\
    \ and integration among different stakeholders. \nIntermediaries such as farm\
    \ management software providers or agricultural \ncooperatives can aggregate and\
    \ harmonize data from different sources, ensuring \ndata quality, security, and\
    \ privacy. \n- \nData analytics: Advanced analytics tools such as AI, machine\
    \ learning, and \npredictive modeling can help integrate and derive insights from\
    \ disparate data \nsources, enabling better decision-making and value creation\
    \ for all stakeholders \ninvolved. \nThe overall goal of a data governance framework\
    \ in the agriculture sector is to \nincentivize trustworthy mechanisms for data\
    \ sharing, both public and private. In addition \nto legally recognizing core\
    \ principles, agriculture agencies need to modernize and create \ngovernment data\
    \ exchange platforms to ensure data interoperability. This will create \nopportunities\
    \ to open certain types of public intent data for exchange and create incentives\
    \ \nwhile removing barriers to voluntary data sharing involving private sector\
    \ actors such as \nATPs and data cooperatives. The value of agricultural data\
    \ can benefit multiple \n \n112 \nstakeholders, and guidelines or standard contractual\
    \ provisions should be formulated to \ngovern the fairness of terms of use. \n\
    Roles and responsibilities for data quality and compliance for shaping the agriculture\
    \ \ndata economy to continue in the path of the digital transformation \nTo ensure\
    \ the development of a thriving agricultural data economy, roles and \nresponsibilities\
    \ for data quality and compliance must be clearly defined and implemented. \n\
    This requires a concerted effort from both the public and private sectors. Government\
    \ \nagencies, such as the USDA, can play a key role in developing and enforcing\
    \ data \nstandards. This includes establishing mechanisms to monitor and ensure\
    \ compliance with \nthe current U.S. COP62 principles and guidelines. \nPrivate\
    \ sector entities, such as ATPs and data cooperatives, have a responsibility to\
    \ \nuphold these standards and ensure that the data they collect and share is\
    \ of high quality and \nmeets established guidelines. This includes implementing\
    \ data quality control measures, \nsuch as data validation and verification processes,\
    \ to ensure that the data is accurate and \nreliable. \nTo increase transparency\
    \ and trust between farmers, ATPs, and other third parties, a \nmodel of adaptable\
    \ contractual agreements overseen by agriculture agencies should be \ndeveloped.\
    \ Rules are necessary to enforce compliance with contractual agreements, and \n\
    public agencies can assist in policing and enforcing them effectively. One of\
    \ the specific \nroles of these institutions could be to monitor and evaluate\
    \ trademark usage and provide \n \n62 The goal of legally and bindingly regulating\
    \ the current U.S. COP is to reduce the \"digital divide\" \nbetween those who\
    \ have knowledge (i.e., ag. tech service providers) and those who do not, through\
    \ the \nimplementation of transparent and fair data sharing practices. \n \n113\
    \ \ncontinuous feedback loops to promote sector engagement, learning, and improvement.\
    \ It is \nessential to set roles and responsibilities within agriculture agencies\
    \ at the federal and state \nlevels to govern data governance in the U.S. effectively.\
    \ Overall, clear roles and \nresponsibilities are essential for shaping the agriculture\
    \ data economy in a way that fosters \ninnovation, growth, and sustainability.\
    \ \n▪ \nOption 2: Moderate \nA moderate policy option aims to address the agricultural\
    \ data governance problem in \nthe U.S. by proposing the development of trustworthy\
    \ systems. This involves not only \noverseeing the COP and evaluating ATPs and\
    \ agri-businesses carrying a data transparent \nlogo but also creating public\
    \ institutional capacity to introduce safeguards and enablers that \nensure data\
    \ rights and facilitate cross-border sector data sharing, while also ensuring\
    \ \ncompliance with regulatory requirements. \nIntended goal: To create a data\
    \ governance trustworthy and transparent environment \nby regulating agricultural\
    \ data rights and obligations of parties involved in data \npractices and transactions\
    \ \nThe intended goal of a moderate policy option is to establish a transparent\
    \ and \ntrustworthy data governance system for the agricultural sector by defining\
    \ the data security \nresponsibilities of parties involved in transactions through\
    \ contractual agreements. The \nUSDA should have an effective and independent\
    \ role in ensuring data security, including \nregistering data intermediary companies.\
    \ Data intermediaries can facilitate safe data \nsharing and use, promoting equitable\
    \ access to data and its value (World Bank, 2021, p. \n265). The agency can monitor\
    \ the implementation of data rights, including privacy and \n \n114 \nsecurity,\
    \ and handle complaints about legal violations. This role could increase trust\
    \ in data \npractices among agricultural stakeholders.  \nSafeguards for appropriated\
    \ data security conditions for cross-sector border exchange \nof agricultural\
    \ data  \nAppropriate data security conditions are essential for promoting cross-border\
    \ exchange \nof agricultural data. One of the safeguards that can be established\
    \ are agricultural-specific \ndata privacy and security rules and regulations.\
    \ The USDA could work with stakeholders \nto develop such rules and regulations\
    \ that take into account the unique aspects of \nagricultural data, such as farm\
    \ location and practices, and ensure that data is handled \nappropriately. \n\
    Furthermore, the USDA could require data intermediaries and ATPs to undergo regular\
    \ \nsecurity audits and assessments to ensure that they are complying with data\
    \ security \nregulations and standards. The agency could also establish penalties\
    \ for non-compliance to \ndeter ATPs and intermediaries from engaging in risky\
    \ data practices. \nIn addition, the USDA could promote the use of data encryption\
    \ and other security \nmeasures to protect data during transmission and storage.\
    \ This could be accomplished \nthrough the creation of guidelines and recommendations\
    \ for farmers and other stakeholders \non how to securely transmit and store agricultural\
    \ data. \nTo promote cross-border data exchange, it is important to consider the\
    \ impact on the \ncountry's competitiveness and international trade opportunities.\
    \ In order to ensure \nappropriate data security conditions for cross-sector data\
    \ flows, it may be necessary to \nadopt provisions criminalizing unauthorized\
    \ or illegal access to infrastructure, systems, and \n \n115 \ndata. Government\
    \ agencies in the agriculture sector should also consider implementing \nregulatory\
    \ approaches that ensure adequacy and accountability, including specific \nconditions\
    \ that permit data transfer, mutual agreements, and schemes to require, permit,\
    \ or \nlimit cross-border data transfers. \nATPs and other third parties providing\
    \ services cannot engage in data exchange without \na trustworthy system or environment.\
    \ Trust in the data sharing system depends on people's \nconfidence that others\
    \ will follow the rules and agreements, and that there is an authority \nenforcing\
    \ those rules and agreements. In the agriculture sector, in order to build trust\
    \ in the \ndata sharing system, privacy and security should be guaranteed, as\
    \ well as benefits for all \nparties involved. \nEnabling data operations for\
    \ data cooperatives and data integration for an \nAgricultural Data Governance\
    \ and Accreditation Board (a data governance body) \nTo enable data operations\
    \ for data cooperatives, it is necessary to establish data \ngovernance and accreditation\
    \ boards that can provide guidance on data management \npractices, promote interoperability,\
    \ and foster data sharing within the agricultural sector. \nSuch boards can also\
    \ provide technical and policy support to data cooperatives, helping \nthem to\
    \ develop and maintain data management systems that are consistent with industry\
    \ \nstandards and best practices. \nThe integration of data from various sources\
    \ is essential for achieving the full potential \nof data cooperatives. Data integration\
    \ involves the process of combining data from \ndifferent sources to create a\
    \ unified view of the data. This can be done using a variety of \ntools and techniques,\
    \ including data warehousing, data mining, and data modeling. \n \n116 \nAn Agricultural\
    \ Data Governance and Accreditation Board can help facilitate data \nintegration\
    \ by establishing data standards, providing guidance on data quality, and \npromoting\
    \ best practices for data management. The board can also serve as a central point\
    \ \nof contact for data sharing and collaboration among stakeholders in the agricultural\
    \ sector. \nA data governance board could be created or organized within the USDA\
    \ federal \nagency. This board would function as a steering committee, responsible\
    \ for overseeing the \ncollection, transfer, storage, and analysis of agricultural\
    \ data. ATPs, data intermediary \ncompanies, and data cooperatives would be required\
    \ to register with the board and \ncontribute to generating knowledge and advice,\
    \ as well as providing a feedback loop to \nfarmers and policymakers. This would\
    \ ensure that the board has a broad perspective on the \nindustry and can make\
    \ informed decisions about data governance. Additionally, the board \nwould be\
    \ responsible for establishing and enforcing standards for data quality, security,\
    \ \nand privacy. It would also be tasked with developing guidelines for data sharing\
    \ \nagreements and monitoring compliance with those agreements. This would create\
    \ a more \ncohesive and trustworthy data ecosystem for the agriculture sector,\
    \ increasing transparency \nand promoting collaboration between stakeholders.\
    \  \nTo ensure that private sector stakeholders act in the best interests of data\
    \ originators \nsuch as farmers and producers, the USDA Data Governance and Accreditation\
    \ Board could \nprovide guidance and oversight. These stakeholders could advise\
    \ data originators on the \npossible uses of their data and the terms and conditions\
    \ for such uses. Additionally, USDA \nagencies and data intermediary organizations\
    \ could collaborate to build capacity on data \ngovernance issues and provide\
    \ training on the importance of agricultural data and its \n \n117 \npotential\
    \ economic impact. An open-share data platform could also be developed to \nfacilitate\
    \ data sharing and collaboration between stakeholders in the agriculture sector.\
    \ \nOverall, the establishment of data governance and accreditation boards can\
    \ help ensure \nthat data cooperatives operate in a trustworthy and transparent\
    \ environment, with clear \nrules and responsibilities for data management and\
    \ sharing. This, in turn, can promote \ninnovation, facilitate data-driven decision-making,\
    \ and drive growth in the agricultural \nsector. \nRoles and responsibilities\
    \ of government agencies in strengthening technical data \ncapacity, communications,\
    \ and compliance as well as data literacy, to enable e-\ncommunication and e-transactions\
    \ \nThe government agencies have a critical role in strengthening technical data\
    \ capacity \nand data literacy to facilitate e-communication and e-transactions\
    \ in the agriculture sector. \nThis includes providing technical assistance to\
    \ farmers, ATPs, and other stakeholders in \nimplementing data governance best\
    \ practices, such as secure data sharing and compliance \nwith data privacy regulations.\
    \ \nThe government agencies also need to strengthen their own technical capacity\
    \ to oversee \nand enforce data governance policies and regulations. This can\
    \ involve the development of \nnew technologies or systems for monitoring and\
    \ auditing data practices, as well as the \nrecruitment of skilled personnel to\
    \ oversee data governance operations. \nIn addition, the government agencies should\
    \ play a role in promoting communication \nand collaboration among stakeholders\
    \ in the agriculture sector. This includes facilitating \n \n118 \nthe exchange\
    \ of best practices and promoting the adoption of data governance standards \n\
    across different sectors and regions. \nThe role of an agricultural data governance\
    \ and accreditation board is to evaluate and \naccredit ATPs and companies based\
    \ on their compliance with the core principles of the \nU.S. COP. In addition,\
    \ the board will establish a fee schedule for accreditations and \nrenewals and\
    \ will receive a complete checklist from organizations seeking accreditation.\
    \ \nFurthermore, the board will receive and address complaints from farmers and\
    \ primary \nproducers, as well as complying organizations, and will review all\
    \ cases of noncompliance \nand recommend corrective action. To sum up, the roles\
    \ and responsibilities of government \nagencies in improving technical data capacity,\
    \ communications, and compliance are \ncritical for ensuring the safe, secure,\
    \ and responsible use of agricultural data. \nThis moderate policy option aims\
    \ to promote a multi-stakeholder, purpose-driven \napproach to data management\
    \ and governance. The goal is to enable institutions to adapt \nto the rapidly\
    \ evolving digital data ecosystem while enhancing their legitimacy, \ntransparency,\
    \ and accountability. \n▪ \nOption 3: Maximalist \nThe maximalist policy option\
    \ seeks to fully embrace digitization in agriculture by \nestablishing a comprehensive\
    \ regulatory framework for data security, integration, and \ninteroperability.\
    \ This would involve developing national data governance standards, \nestablishing\
    \ clear rules and guidelines for data sharing, and incentivizing compliance with\
    \ \nthese rules through various means, such as tax breaks and subsidies. The goal\
    \ of this policy \n \n119 \noption is to create a secure and dynamic digital economy\
    \ that facilitates agricultural data \naccess, sharing, use, and re-use while\
    \ protecting data privacy and security. \nIntended goal: Integrate agricultural\
    \ data rights governing sharing and ownership, as \nwell as privacy and security\
    \ rights, while regulating data intermediaries and creating \nincentives for reusing\
    \ public administrative agricultural data. \nA comprehensive data governance framework\
    \ must be established to integrate \nagricultural data rights governing sharing\
    \ and ownership, as well as privacy and security \nrights, while regulating data\
    \ intermediaries and creating incentives for reusing public \nadministrative agricultural\
    \ data. This framework should include the following components: \n- \nClear definitions\
    \ of data rights, including ownership, control, and sharing rights, \nas well\
    \ as privacy and security rights. \n- \nRegulations for data intermediaries, including\
    \ data cooperatives and ATPs, that \nensure compliance with data privacy and security\
    \ regulations and that protect \nfarmers' and producers' data rights. \n- \nIncentives\
    \ for reusing public administrative agricultural data to increase the \nefficiency\
    \ and effectiveness of agricultural practices. \n- \nA mechanism for resolving\
    \ disputes related to data ownership and access, \nincluding the creation of a\
    \ data governance body that oversees the implementation \nof data governance policies\
    \ and ensures compliance. \n \n120 \nCreating an institutional environment as\
    \ a foundation for an ecosystem hub63 for \nagricultural data sharing involves\
    \ bringing together all relevant stakeholders and \nestablishing clear rules and\
    \ regulations governing agricultural data practices. This may \ninclude creating\
    \ incentives for data sharing, establishing data privacy and security \nprotocols,\
    \ and setting up a governance framework for data intermediaries. The ecosystem\
    \ \nhub can serve as a central point for sharing data and knowledge, facilitating\
    \ collaboration, \nand fostering innovation in the agricultural sector. By promoting\
    \ greater transparency and \naccountability, the ecosystem hub can help build\
    \ trust among stakeholders and encourage \ngreater participation in data sharing\
    \ efforts. \nAgricultural data governance framework based on data rights could\
    \ indeed provide a \nlegal framework that protects data originators' rights and\
    \ promotes trust in data sharing. \nThis can increase the amount of data made\
    \ available for re-use and encourage data altruism \nacross the agriculture sector\
    \ in the U.S. A robust data governance framework can also \nfoster institutional\
    \ intermediation services, promoting sustainable data-based economic \ntransactions\
    \ benefiting the agriculture sector.  \nIn general, the goal of this approach\
    \ is to ensure that all stakeholders in the agricultural \nsector are protected\
    \ by a robust data governance framework that promotes transparency, \naccountability,\
    \ and trust in the data sharing process. \nSafeguards for data security for agricultural\
    \ data as non-personal data and data \noriginators' data rights protection \n\
    \ \n63 Ecosystem Hub is defined as a network of institutions or organizations\
    \ providing services, and more \nimportantly, maintaining overall connectivity\
    \ as hubs to improve elder care services. \n \n121 \nTo ensure data security and\
    \ protect data originators' data rights in the agriculture sector, \nthe following\
    \ safeguards can be put in place: \n- \nData anonymization and aggregation: non-personal\
    \ data in agriculture can be \nmade anonymous by aggregating data into statistical\
    \ models. This ensures that \ndata is not associated with any individual, and\
    \ thus, privacy is protected. \n- \nData access controls: Access to sensitive\
    \ data should be restricted to only \nauthorized individuals, organizations, and\
    \ data intermediaries. This can be done \nthrough password protection, data encryption,\
    \ or other access control \nmechanisms. \n- \nRegular security audits: Regular\
    \ security audits can be conducted to ensure that \ndata is secure and that data\
    \ originators' data rights are being protected. This can \nhelp identify any potential\
    \ vulnerabilities or breaches in the data system and allow \nfor prompt action\
    \ to be taken to address them. \nThe regulatory environment should strike a balance\
    \ between protecting data originators' \nrights and incentivizing innovation and\
    \ data sharing in the agriculture sector. By providing \nnecessary protections\
    \ for data security and privacy, and establishing backup and recovery \nsystems,\
    \ farmers and primary producers can feel more confident in participating in data\
    \ \nsharing and economic activities without fear of exploitation. \nEnablers to\
    \ increase data integration, interoperability, and operations to access \ninformation\
    \ and to create incentives by removing barriers to voluntary data sharing \nand\
    \ facilitate a smart digital agriculture in the U.S. \n \n122 \nEnabling data\
    \ integration, interoperability, and operations, and creating incentives \nrequires\
    \ the removal of barriers to voluntary data sharing and the facilitation of a\
    \ smart \ndigital agriculture ecosystem in the U.S. This can be achieved by investing\
    \ in modern \ninfrastructure, promoting the adoption of common data standards\
    \ and protocols, fostering \nthe development of data intermediaries and data cooperatives,\
    \ and promoting transparency \nand trust in data sharing among stakeholders. In\
    \ addition, creating incentives, such as \nproviding tax credits or funding opportunities,\
    \ can encourage voluntary data sharing and \nthe adoption of digital technologies,\
    \ which can lead to more efficient and sustainable \nagriculture practices. \n\
    Rights to/on Data as a force for public good \nData is a non-rivalrous good, meaning\
    \ its use by one party does not diminish its use by \nanother. To ensure fair\
    \ use of agricultural data, organizations holding the ADT logo \naccreditation\
    \ and following the U.S. COP \"core principles\" should inform farmers and \n\
    primary producers about the rights they assert in relation to the data, as well\
    \ as the rights \nthe producers have regarding the data. It is also essential\
    \ to disclose the terms under which \nagricultural data is made available to authorized\
    \ third parties or those acting on behalf of \nthe primary producers. \nThe concept\
    \ of data rights as a force for public good refers to the idea that data, \nespecially\
    \ agricultural data, should be viewed as a valuable resource that can benefit\
    \ \nsociety as a whole. This means that data originators (i.e., farmers and primary\
    \ producers) \nshould have the right to control how their data is collected, used,\
    \ and shared, and that the \npublic should have access to certain categories of\
    \ data that can be used to improve \nagricultural practices, support research,\
    \ and inform public policy. By recognizing data as a \n \n123 \npublic good, institutions\
    \ and agencies in the agriculture sector can create a regulatory \nenvironment\
    \ that encourages data sharing and innovation while also protecting data privacy\
    \ \nand security. Ultimately, this approach can help to promote sustainable agriculture\
    \ and \neconomic growth while ensuring that data is used for the greater good\
    \ of society. \nCreating a data governance framework entail putting regulations,\
    \ procedures, and norms \nin place at the macro institutional level. According\
    \ to Séronie, encouraging adherence to \nestablished rules, processes, and standards\
    \ for data usage can result in increased efficiency, \nbetter technical performance,\
    \ lower costs, and lower environmental impact at the macro \nlevel (2020, p.4).\
    \ Furthermore, it can pave the way for a cultural shift toward understanding \n\
    how to manage and govern data. Table 16 compares the three policy options proposed\
    \ for \naddressing the agricultural data policy challenge in the United States.\
    \ \nTable 16 Comparison of the three policy options \nRegulatory \nData \nGovernance\
    \ \nAttributes \nOption 1: \nMinimalist. \nOption 2: \nModerate.  \nOption 3:\
    \ Maximalist. \nSafeguards \nNo specific \nsafeguards for data \nprotection and\
    \ \nsharing. \nEstablishing \nappropriate safety \nconditions for \ncross-border\
    \ \nexchange of \nagricultural data in \nthe agriculture \nsector. \nSafeguards\
    \ for \nagricultural data as \nnon-personal data and \nprotection of data \noriginators'\
    \ data rights. \n \n124 \nRegulatory \nData \nGovernance \nAttributes \nOption\
    \ 1: \nMinimalist. \nOption 2: \nModerate.  \nOption 3: Maximalist. \nEnablers\
    \ \nEnabling a \ntrustworthy system \nto foster \ntransparent \nagricultural data\
    \ \npractices through \nthe U.S. Code of \nPractice and the \nCore Principles\
    \ \nIncentivizing \npublic and private \nintent data sharing \nby removing \n\
    barriers and \nincreasing access \nto information for \nsmart digital \nagriculture\
    \ in the \nU.S. \nStrengthening technical \ndata capacity and \ncommunications,\
    \ as \nwell as data literacy, to \nenable e-transactions. \nInstitutional \nRoles\
    \ and \nResponsibilities \nRoles and \nresponsibilities for \nshaping trust in\
    \ \nagricultural data \nand the agriculture \ndata economy to \ncontinue in the\
    \ path \nof digital \ntransformation. \nEstablishing Data \nCooperatives and \n\
    an Agricultural \nData Governance \nand Accreditation \nBoard (a data \ngovernance\
    \ body) \nRights to/on Data as a \nforce for public good. \nRegulating agricultural\
    \ \ndata rights and \nobligations of parties \ninvolved in data \npractices and\
    \ \ntransactions. \nIntended \noutcomes \nChanging the \nagricultural \nsector’s\
    \ mindset \ntoward agricultural \ndata governance \nbased on the U.S. \ncore principles\
    \ for \ndata practices. \nCreating a \ntrustworthy and \ntransparent data \ngovernance\
    \ \nenvironment for \nregulating \nagricultural data \nrights and \nobligations\
    \ of \nparties involved in \ndata practices and \ntransactions. \nIntegrating\
    \ agricultural \ndata rights governing \nsharing and ownership, \nas well as privacy\
    \ and \nsecurity rights, while \nregulating data \nintermediaries and \ncreating\
    \ incentives for \nreusing public \nadministrative \nagricultural data. \nIn the\
    \ agricultural sector, it is important to establish rules for access as well as\
    \ to \nfacilitate and ensure data use and reuse. Therefore, in light of the agricultural\
    \ data \ngovernance policy problem, it is necessary to control data access and\
    \ sharing by defining \nthe roles and responsibilities of agencies and institutions.\
    \ These are additional components \nincluded in this research's data governance\
    \ framework. Additionally, institutions in the \n \n125 \nagriculture sector should\
    \ specify and define the types of data, such as public and private \nintent agricultural\
    \ data, that can be shared, used, and reused. \n \n \n126 \nChapter 4: Policy\
    \ Proposal \nThe objective of this chapter is to use methods of policy forecasting\
    \ to generate a policy \nproposal from the three options presented in Chapter\
    \ 3. These methods will be used to \ndetermine which of the three policy models,\
    \ either individually or in combination, is most \nlikely to advance the goals\
    \ of agricultural data governance, and whether any of them should \nbe rejected\
    \ based on their predicted effects. The results will be used in the Conclusion\
    \ to \nsuggest next steps and further research needs. \nForecasting in policy\
    \ analysis refers to a “set of procedures for creating information \nabout future\
    \ states of society based on present or prior information” (Dunn, 2018, p. 119)\
    \ \nrelated to a particular policy issue or problem. The goal is to generate information\
    \ about \nfuture societal states regarding a specific policy issue based on present\
    \ information. Table \n17 presents a description of the forecasting methods that\
    \ will be used to forecast the policy \nframework for governing data in agriculture\
    \ in this research.  \nTable 17 Forecasting Methods \nForecasting Form \nWhat\
    \ it is? \nHow to apply? \nProjection \nIt involves identifying the \nrelevant\
    \ actors, assessing \ntheir goals and strategies, \nand analyzing the potential\
    \ \nimpact of policy options on \nthese factors. It helps \npolicymakers to anticipate\
    \ \nand evaluate the potential \nconsequences of different \nIt involves analyzing\
    \ \nhistorical data to identify \npatterns and trends that can \nbe used to predict\
    \ future \noutcomes. \n \n127 \npolicy options before \nmaking decisions. \nPrediction\
    \  \nIt is based on theoretical \nexplanations of why some \ntrends should be\
    \ \nimplemented in the future. \nPrediction based mapping \ndata governance legal\
    \ \nframeworks across sectors \nto analyze the alternatives \navailable that can\
    \ be \nadaptable to design data \nregulations in the \nagriculture sector. \n\
    Expert judgment \nIt is based on the \nprofessional experience \nand authority\
    \ of persons \n(scholars) who are \npresumed to have special \ncapabilities to\
    \ foresee \nfuture states of society.  \nExpert judgments will \ncome from webinar\
    \ \npresentations, or the work \nof other scholars. \n(Experienced based, \nconjecture)\
    \ \nAdapted from Dunn, 2018 \nThis research uses projection, prediction, and expert\
    \ judgment (or conjecture) as \nforecasting methods to estimate the potential\
    \ outcomes of the three policy options for \nagricultural data governance. These\
    \ methods aim to provide insight into the expected or \nestimated policy outcomes\
    \ of a framework for agricultural data governance. \nAs stated in the beginning\
    \ of this project, the policy output of agricultural data \ngovernance is the\
    \ production and sharing of high-quality data, and the resulting outcome \nis\
    \ a cost-effective digitization of the agricultural sector. The ultimate objective\
    \ is to \nestablish a socially, economically, and environmentally sustainable\
    \ agricultural sector. As \n \n128 \nthis research assumes a direct connection\
    \ from outputs to outcome to impact, the policy \nforecasting here is limited\
    \ to outputs. \nIn the case of the agricultural data problem in the U.S., forecasting\
    \ policy options can \nlead to the development of an agricultural data governance\
    \ framework that meets the \nexpectations of all stakeholders while improving\
    \ efficiency and sustainability in \nagriculture. By forecasting the contents\
    \ of the three new policy options, this research aims \nto determine the most\
    \ plausible option for the future of the agriculture sector in the U.S. \nFigure\
    \ 21 illustrates the structure of the forecasting process. \nFigure 21 Forecasting\
    \ process structure \n \nProjection \nDue to the lack of a comprehensive national\
    \ inventory of data governance regulatory \npractices in the U.S., early projections\
    \ of the three policy options proposed in this study \nare challenging. However,\
    \ the current and rapid development of what scholars refer to as \n \n129 \nthe\
    \ \"data economy\" (Chen, 2021, p. 29) justifies the need for flexible policies\
    \ that can \nfacilitate the growth of various data-driven products, services,\
    \ and business models. \nCOPs represent an initial sector-specific effort to address\
    \ emerging concerns \nsurrounding agricultural data practices. In the U.S., the\
    \ COPs, also known as \"core \nprinciples,\" have been adopted by large farmer-led\
    \ organizations and associations such as \nthe American Farm Bureau Federation\
    \ (AFBF). However, only 37 agriculture tech \nproviders64 have undergone the certification\
    \ process of the Ag Data Transparent Evaluator \n(ADT) and agreed to incorporate\
    \ the \"core principles\" into their contracts and agreements \nwith farmers (Janzen,\
    \ 202165). \nThis COP or \"core principles\" in the U.S. represent a mid-stream,\
    \ non-binding form of \nagricultural data regulation due to the voluntary commitment\
    \ of agriculture tech providers \nto data transparency with farmers and the lack\
    \ of an assessment or evaluation process for \ntheir compliance.  \nA minimal\
    \ policy option for agricultural data governance provides the minimal enablers\
    \ \nfor data sharing, compelling agriculture tech providers to adhere to the \"\
    core principles\" \nwhen collecting, storing, and transferring farmers' agricultural\
    \ data. In this minimalist \npolicy option, state agriculture public entities\
    \ such as the U.S. Department of Agriculture \nhave a minimal role contribution.\
    \ This agency serves as an enabler in verifying compliance \nwith the \"core principles\"\
    \ and auditing companies with the ADT seal and their agricultural \ndata contracts\
    \ and agreements. \n \n64 Figure 6 depicts more than 100 technology firms that\
    \ are digitally transforming farming practices. \n65 Information available at:\
    \ https://www.agdatatransparent.com/about \n \n130 \nMany U.S. companies that\
    \ collect agricultural data have yet to commit to the \nagricultural data \"core\
    \ principles\" (Janzen, 202166). However, adopting a minimal policy \noption based\
    \ on the existing COP could be rapidly embraced and effectively implemented, \n\
    given the established principles and certification process recognized by large\
    \ farmer-led \nassociations. With clear role definitions and public institution\
    \ support, the number of \ncompanies participating and signing on to the \"core\
    \ principles\" and achieving Ag Data \nTransparent certification could significantly\
    \ increase in the short term. \nMoving forward, a moderate data governance policy\
    \ option could include not only \nintroducing safeguards for agricultural data\
    \ sharing but also enabling the flow and reuse of \nnon-personal public administrative\
    \ agricultural data. While this represents a new policy \ncontext and content,\
    \ forecasting its success is difficult. \nA maximalist data governance policy\
    \ would include both safeguards and enablers, \nprotecting data rights and facilitating\
    \ the use and re-use of public administrative \nagricultural data while ensuring\
    \ its safe flow among stakeholders. This policy would \npromote a trustworthy\
    \ agricultural data system by increasing awareness of the value of \nagricultural\
    \ data and encouraging participation in the ag sector data economy. However, \n\
    like the moderate policy alternative, projecting the effectiveness of this policy\
    \ prediction \nis challenging. \nThese three policy options are currently conceptual\
    \ and projecting their effectiveness is \ndifficult and insufficient. However,\
    \ based on a comparative macro analysis of the literature \nand the Global Data\
    \ Regulation diagnostic, which assesses data governance laws and \n \n66 Information\
    \ available at: https://www.agdatatransparent.com/about \n \n131 \nregulations\
    \ across 80 countries, it is accurate to project that a normative legal framework\
    \ \nfor agricultural data governance would be an important addition to the future\
    \ of the \nagricultural data economy in the U.S. \nPrediction \nForeseeing the\
    \ future impact of a data governance policy framework for the agriculture \nsector\
    \ in the United States involves considering the potential positive and negative\
    \ \nfeedback loops. These will be evaluated by institutions and stakeholders who\
    \ are subject \nto the enforcement of these regulations and norms. The predictive\
    \ approach relies on a set \nof causal assumptions about how a particular policy\
    \ may be implemented and what its \noutcomes will be. As a result, forecasting\
    \ the three policy options involves predicting not \nonly their feasibility but\
    \ also their impact on the agriculture sector. \nTo theorize and predict the feasibility\
    \ of the three agricultural data governance policy \noptions, this research section\
    \ draws on the notion of a collective action problem. This \napproach presents\
    \ a theoretical perspective that compares existing literature on collective \n\
    action to explain data governance as a current issue within the data economy.\
    \ The aim is \nto attempt a prediction that explains the reasons for adopting\
    \ a minimalist, moderate, or \nmaximalist policy alternative. \nThe Coleman Boat\
    \ model provides a predictive framework that outlines how certain \nfactors can\
    \ lead to specific outcomes through various mechanisms. In the context of \nagricultural\
    \ data governance, the Coleman Boat model represents the relationship between\
    \ \nthe macro and micro aspects of the social system. At the macro level, agricultural\
    \ data \ngovernance is institutionalized as a policy framework that sets the norms\
    \ for sector \n \n132 \nparticipation. The meso level is crucial in determining\
    \ whether individuals participate in \nand share data within the framework, as\
    \ their decisions are influenced by factors such as \ntrust, transparency, and\
    \ legitimacy. \nIntegrating Benfeldt et al.'s (2020) collective action theory\
    \ approach to data governance \ninto the model can offer a more comprehensive\
    \ insight into the meso and micro processes \nthat influence participation in\
    \ Ag-DG. This perspective highlights the challenges of \nmobilizing an organization\
    \ to adopt a data governance framework. It emphasizes the \nimportance of understanding\
    \ the internal dynamics of the system or organization, which \nincludes comprehending\
    \ the motivations and behaviors of individual actors. \nBenfeldt et al.'s (2020)\
    \ approach identifies six constituent challenges that must be \naddressed to successfully\
    \ adopt data governance within public organizations, including \nperceiving value,\
    \ enabling collaboration, fostering capabilities, data overview, local \npractices,\
    \ and political ambience (Benfeldt et al., 2020, 308). These challenges are \n\
    interrelated and form a \"problem triangle,\" as illustrated in Figure 22, which\
    \ is adapted to \nthe agricultural data governance policy problem. \n \n133 \n\
    Figure 22 Data Governance Collective Action Problem in Public Organizations \n\
    \ \nThe problem triangle describes the difficulties faced by actors with diverse\
    \ and possibly \nconflicting interests, who struggle to find common ground and\
    \ collaborate towards a shared \nobjective. By integrating Benfeldt's ideas into\
    \ the Coleman Boat model, we can gain a \nbetter understanding of how these challenges\
    \ affect individual and organizational \nparticipation in agricultural data governance.\
    \ \nAt the micro level, the challenge of recognizing the value of sharing data\
    \ may influence \nthe decisions of individual stakeholders to participate in Ag-DG.\
    \ Additionally, the \nchallenge of enabling collaboration may impact the effectiveness\
    \ of the framework as a \nwhole, as it influences how well stakeholders work together.\
    \ \nTo overcome these challenges, it is necessary to foster capabilities, provide\
    \ an overview \nof the available data, align local practices, and create a conducive\
    \ political environment. \nThis integrated framework provides a more comprehensive\
    \ explanation of the mechanisms \nthat lead to successful agricultural data governance.\
    \ \n \n134 \nBenfeldt et al. (2020, p.309) explain: \nPerceiving value of data\
    \ governance is challenging because actors in a \ncollective tend to ascribe different\
    \ meanings to the purpose or outcome \nof the collective action. Enabling collaboration\
    \ between functions on \ndata governance is complicated because actors tend to\
    \ take actions that \nprotect their individual interests at the expense of achieving\
    \ a greater \njoint outcome. Fostering capabilities for governing data is difficult\
    \ \nbecause doing so requires effectively managing heterogeneous resources \n\
    contributed by different actors to the common \"good\" produced in a \ncollective.\
    \ (Benfeldt et al., 2020, p. 309) \nAdopting a data governance framework is assumed\
    \ to be beneficial because it involves \nimplementing processes and principles\
    \ that are supposed to be enterprise-wide.” (Benfeldt \net al., 2020, p. 306).\
    \ Therefore, from a collective action theoretical perspective, agricultural \n\
    data has the potential to become a collective good based on the willingness and\
    \ capabilities \nof users to take advantage of it. \nIn addition, within the context\
    \ of the digital data economy, Kerber & Frank (2017) \npropose a framework that\
    \ identifies the main causes of potential market failure problems \nin data trading\
    \ within the Internet of Things (IoT) applications. These market failure \nproblems\
    \ include information asymmetries about data quality and source, a lack of demand\
    \ \nfor data due to a lack of awareness of its value, a lack of interoperability\
    \ and \nstandardization, pricing problems, and strategic reasons for data holders\
    \ not to share, trade, \nor give access to data. \nIn the current agricultural\
    \ data landscape, private companies have demonstrated the \nvalue of collecting\
    \ and utilizing agricultural data. However, the U.S. Department of \n \n135 \n\
    Agriculture (USDA) has lagged behind in terms of data collection, integration,\
    \ and \nutilization. For instance, the USDA collects vast amounts of data to support\
    \ a diverse range \nof agricultural programs. Nevertheless, the lack of clear\
    \ collaboration across agencies has \nhindered data utilization. As a result,\
    \ there are numerous disconnected data silos within the \nUSDA that, at times,\
    \ require employees to make manual data calls to gather essential \ninformation\
    \ for analysis (Ristino & Hart, 2022, p. 5). Consequently, data-driven decision-\n\
    making practices are challenging to implement. \nExpert judgment or Conjecture\
    \ \nThe conjecture approach relies on expert judgments, which are valuable because\
    \ they \nconcentrate on predictions of future trends and implicit knowledge of\
    \ the probable \ntriumphs or failures of various policy options, instead of past\
    \ data or formal models. One \ncritical aspect of this approach is making conjectures\
    \ about the future state of technology \nand data. Moreover, it is important to\
    \ note that expert judgment or conjecture can be a \nvaluable tool in policy analysis\
    \ and the development of agricultural data governance \npolicies. While past data\
    \ and formal models are useful, expert judgment can provide \ninsights into future\
    \ trends and the potential success or failure of policy options. However, \nit\
    \ is essential to ensure that expert judgments are based on sound reasoning and\
    \ evidence, \nrather than personal bias or unsupported assumptions. \nFor instance,\
    \ the \"Data for Better Lives\" World Bank report argues that to use data for\
    \ \ndevelopment purposes, a legal framework for data governance is necessary,\
    \ which should \ninclude both safeguards and enablers (World Bank, 2021, p. 190).\
    \ Safeguards are legal \nframeworks and norms that ensure trust in data governance\
    \ and management by limiting \n \n136 \nharm from data misuse and breaches affecting\
    \ data security and integrity. Enablers refer to \npolicies, laws, regulations,\
    \ and standards that enable the use, reuse, and sharing of data \nwithin and between\
    \ stakeholder groups by promoting openness, interoperability, and \nportability.\
    \ \nIn Industry Revolution 4.0, a data governance framework approach is necessary\
    \ to \ntransform data into a strategic asset for organizations and sectors. In\
    \ the agriculture sector, \nscholars such as Jouanjean et al. (2020) and Wiseman\
    \ et al. (2019) agree that starting with \nsector-specific solutions is key to\
    \ solving data governance problems. \nFor example, Wiseman et al. (2019) examined\
    \ three of the four existing codes of \nconduct (COPs) on agricultural data, except\
    \ for the most recent one from Australia, and \nmade recommendations. The authors\
    \ suggested a farmer-centered COP on agricultural data \nas it would facilitate\
    \ broad adoption and have a greater impact. However, it is crucial to \nensure\
    \ the legitimacy of the code and those who administer and accredit compliance.\
    \ \nAdopting minimal normative regulation where farmers’ associations and agriculture\
    \ public \norganizations play a role could ensure proper implementation and enforcement\
    \ of an \nagricultural data governance policy. \nSanderson and Wiseman (2018)\
    \ stress the importance of developing a tailored data \ngovernance framework specific\
    \ to the agriculture sector, due to the distinct categories of \nagricultural\
    \ data. The use of voluntary-private membership contractual models, such as \n\
    COPs, is recommended by Wiseman et al. (2019) to ensure data sharing and gain\
    \ farmers' \ntrust. However, since COPs are governed through private data contractual\
    \ agreements, they \nmay be more suitable for agribusinesses and companies working\
    \ with farmers and using \n \n137 \ntheir data, rather than farmers-led organizations/associations.\
    \ Nevertheless, to ensure \nproper implementation and enforcement of COPs and\
    \ the credibility of farmers in their \nself-regulation, scholars argue that governments\
    \ must also play a role in agricultural data \nmanagement and practice (Wiseman\
    \ et al. 2019, p.13). This highlights the need for \nnormative regulation for\
    \ agricultural data governance that represents smallholder farmers, \nnot just\
    \ through associations but also directly. \nThe rapidly evolving IoT technology\
    \ requires regulatory efforts to be open to new \ninnovations in order to solve\
    \ data governance problems. Therefore, a legal framework for \ndata governance,\
    \ whether minimalist, moderate, or maximalist, should limit private parties' \n\
    freedom to produce, create, and use data in new ways only as necessary to address\
    \ market \nfailure problems, such as lack of rights on data, competition problems,\
    \ information \nproblems, and transaction cost problems (Kerber & Frank, 2017,\
    \ p. 17) and achieve other \nnormative societal objectives. \nA Two-Stage Model\
    \ for Agricultural Data Governance Policy Framework \nThis section also includes\
    \ a two-step feasibility analysis. In the first step, each policy \noption is\
    \ analyzed based on the identified policy problem components to determine the\
    \ \nfactors that could define the effects or consequences of the chosen policy's\
    \ success or \nfailure. The second step attempts to predict which policy option\
    \ would be feasible from a \npolicy process selection perspective. This step addresses\
    \ major issues influencing the \npolicy process, including incidents, ideas, interests,\
    \ institutions, inter-unit diffusion, and \nindustrialization. These elements\
    \ are crucial in the policy history process and require \nanswering a set of minimum\
    \ questions as part of the feasibility analysis to identify any \n \n138 \noutstanding\
    \ issues or concerns with each policy alternative. Figure 23 illustrates the two-\n\
    step process used to analyze each policy option and predict which one could be\
    \ feasibly \nadvocated for not only in terms of solving the agricultural data\
    \ governance policy problem \nbut also in terms of feasibility for adoption. \
    \ \nFigure 23 Two-step Step Forecasting Prediction Process \n \nThe three proposed\
    \ options will be analyzed considering this theoretical-explanatory \nscenario\
    \ and the dimensions of the policy problem to which an alternative public policy\
    \ \nmust respond. Table 18 describes the questions to be answered when analyzing\
    \ each policy \noption. \n \n139 \nTable 18 Questions to be answered by the agricultural\
    \ data governance policy options \nfor a policy problem feasibility analysis \n\
    Dimensions of the \nagricultural data \ngovernance policy \nproblem \nQuestions\
    \ to find the policy option with best outcomes \nTrust between farmers \nand agricultural\
    \ \ntechnology providers in \ndata sharing  \nDoes the policy option address the\
    \ development of trust \nbetween farmers and technology providers through \ncontractual\
    \ agreements to govern agricultural data \nsharing? \nData privacy and \nconfidentiality\
    \ norms and \nrights \nDoes the policy option provide mechanisms for ensuring\
    \ \ndata privacy, security, and sharing rights for agricultural \ndata use and\
    \ reuse? \nOversight, accountability, \nand transparency in data \nproduction\
    \ cycle \nDoes the policy option effectively encourage oversight, \naccountability,\
    \ and transparency from government \nagencies, private companies, and other data\
    \ \nintermediaries? \nDigital transformation in \nthe smart farming sector \n\
    Does the policy option enable the agriculture sector to \nadvance in digital transformation\
    \ by utilizing agricultural \ndata and deriving benefits from its value? \nEach\
    \ policy option will be analyzed using this set of questions to determine if their\
    \ data \ngovernance components address each dimension of the agricultural data\
    \ governance \nproblem. The analysis will generate results presented in Table\
    \ 19 and Figure 24, assuming \ndichotomous values for all cases of predictive\
    \ analysis of the policy options created \nspecifically for this research. \n\
    \ \n140 \nTable 19 Prediction of a Policy Option for Agricultural Data Governance\
    \ \n  \nAddressing the policy problem dimensions  \n  \n  \nPolicy \noptions \
    \ \nData \nsharing \nData rights \nprivacy  \nData \nproduction  \nSmart \nFarming\
    \ \nPolicy \nadoption \ntime \nPolicy \nadoption \nbudget \n% \nproblem \nresponse\
    \ \nOption \n1 \nHigh \nMedium \nMedium \nUnder \nserved \nHigh \nHigh \n72% \n\
    Option \n2  \nHigh \nHigh \nHigh \nHigh \nLow \nMedium \n83% \nOption \n3  \n\
    High \nHigh \nHigh \nHigh \nUnder \nserved \nUnder \nserved \n67% \nFigure 24\
    \ Rate of each policy option addressing the agricultural data governance policy\
    \ \nproblem dimensions \n \n \nTable 19 presents the results of assigning dichotomous\
    \ values to each data governance \ncomponent in each policy option. The values\
    \ of 1 or 0 are assigned based on the answers \nto the questions presented earlier.\
    \ If a policy option addresses all dimensions of the problem \n72%\n83%\n67%\n\
    Option 1: Minimalist.\nOption 2: Moderate.\nOption 3: Maximalist.\nAddressing\
    \ the policy problem dimensions \n \n141 \nthrough its data governance components,\
    \ a value of 1 is assigned. On the other hand, if a \npolicy option does not fully\
    \ address the dimensions of the problem, a value of 0 is assigned. \nEach dimension\
    \ of each data governance component for each problem dimension equals \nthree.\
    \ In this study, a score of 3 for each dimension of a problem dimension for each\
    \ policy \noption is defined as \"high,\" a score of 2 is defined as \"medium,\"\
    \ a score of 1 is defined as \n\"low,\" and a score of 0 is defined as \"underserved.\"\
    \ \nThe last columns of Table 19 assign dichotomous values to the time and budget\
    \ criteria \nrequired for implementing each policy option. The analysis concludes\
    \ by adding up the \nvalues assigned to the data governance components for each\
    \ dimension of the problem. If \nthe total value is greater than 6, it indicates\
    \ that all the values have been met. Based on \nthese findings, the percentage\
    \ of each policy option's response to the corresponding \ndimensions of the problem\
    \ was calculated, as shown in Figure 24. \nTo explore the potential outcomes of\
    \ the three-policy options proposed in this research \nand determine an optimal\
    \ policy for governing agricultural data, Table 20 outlines six \ndimensions that\
    \ must be considered during the policy analysis process. Each of the \ndimensions\
    \ is associated with specific issues that should be addressed by each policy \n\
    option. By examining how well each policy option addresses these dimensions and\
    \ issues, \nwe can determine which option is most feasible to advocate for within\
    \ the policy process.  \nTable 20 Six dimensions for policy prescription analysis\
    \ for agricultural data governance \nPolicy \nDimension \nIssues to be addressed\
    \ \nInterests and \nIdeas \n- \nCollective action problems \n \n142 \n- \nAdvocates\
    \ of change or stasis \n- \nPowerful ideas to mobilize, frame, and determine policy\
    \ change \nIncidents \n- \nIncidents that create windows for new ideas  \n- \n\
    Incidents of non-technical communication (e.g., in the \nagriculture food insecurity;\
    \ food supply chain issues such as \nfarming labor issues and shortages)  \nInstitutions\
    \ \n- \nInstitutions that allow policy responses to occur  \n- \nInstitutional\
    \ strategies to optimize the use of institutions for \npolicy response \nInter-unit\
    \ \n- \nPolitical economy/fiscal incentives  \n- \nGlobalization (“global supply\
    \ chains effect”) \nIndustrialization \n- \nDigital transformation in the agriculture\
    \ sector: integration of \nnew digital technologies (e.g., IoT, Cloud, Mobile,\
    \ AI) changing \nthe delivery of services. \nA prediction model that combines\
    \ the 6 ‘I's from policy advocacy to policy outcomes is \neffective when it follows\
    \ a pathway that leads to positive outcomes. This involves carefully \nexamining\
    \ the factors involved in the policy process. The first step is to ask questions\
    \ to \ndetermine if each policy option adequately addresses the dimensions of\
    \ the agricultural \ndata governance problem. The second step is to ask questions\
    \ to determine which options \nare more feasible for adoption as a public policy.\
    \ \n \n143 \nTable 21 Questions to be answered by the agricultural data governance\
    \ policy options \nfor a policy process feasibility analysis \nPolicy Dimensions\
    \  \nQuestions to Determine Optimal Policy Option \nIncidents  \nWhat social,\
    \ cultural, or economic incidents may influence or \naffect the policy process\
    \ of the policy option? \nInterests and Ideas  \n- Will the policy option shape\
    \ and raise the perceived value of \ndata governance through collective action\
    \ by key stakeholders? \n- Will the policy option facilitate collaboration of\
    \ data \ngovernance ideas and development of capabilities for governing \nagricultural\
    \ data? \nInstitutions  \nAre implementing agencies capable of carrying out the\
    \ policy \nalternative? \nCan necessary agreements be reached among government,\
    \ \nprivate sector, and other partners, including those that are \nlegally binding?\
    \ \nInter-Unit diffusion  \nCan this policy option transfer specific parts of\
    \ policy from other \nsectors' data governance policies? \nOr can this policy\
    \ use or selectively copy policy mechanisms \nfrom other sectors (e.g., HIPAA\
    \ or CCPA)? \nIndustrialization  \nIs this policy option the most beneficial for\
    \ the sector's \nadvancement in the digital transformation era? \nBased on the\
    \ evidence previously gathered in this research, and considering the existing\
    \ \nlegal regulations on data governance, this study proposes to select among\
    \ three high-\npotential policy options for addressing the problem of agricultural\
    \ data governance in the \nUnited States. Similar to the previous analysis of\
    \ the three policy options, this analysis \nassumes dichotomous values for all\
    \ cases of predictive analysis of the policy options \ncreated specifically for\
    \ this research. The results are shown in Table 22 and Figure 25. The \ndetailed\
    \ values assigned to each dimension can be found in the annexes. \n \n144 \nTable\
    \ 22 Prediction of a policy option for agricultural data governance in the policy\
    \ \nprocess adoption \nPolicy options \nfor Ag Data \ngovernance  \nPolicy Process\
    \ Feasibility Dimension \n  \nIncidents  \nInterests \nand Ideas \nInstitutions\
    \ \nInter-Unit \ndiffusion  \nIndustrialization  \n% Policy \nFeasibility \nOption\
    \ 1: \nminimalist  \nHigh \nMedium \nHigh \nMedium \nUnder served \n70% \nOption\
    \ 2: \nModerate \nHigh \nLow \nHigh \nHigh \nHigh \n80% \nOption 3: \nMaximalist\
    \ \nMedium \nHigh \nUnder \nserved \nMedium \nHigh \n50% \nFigure 25 Rate of Policy\
    \ Process Feasibility For each Policy Option \n \nTable 22 provided the criteria\
    \ for analyzing each of the policy options based on the \npublic policy adoption\
    \ process. A value of either 1 or 0 was assigned to each policy option \nfor each\
    \ dimension. These values were classified as \"high,\" \"medium,\" \"low,\" or\
    \ \n\"underserved.\" The \"high\" rating was calculated by summing the values\
    \ assigned to each \ndimension for each policy option. The specific values assigned\
    \ to each factor in each \ndimension for each policy option are detailed in the\
    \ annexes. Using the total sum of each \npolicy option for each dimension in the\
    \ public policy process, we calculated the percentage \n70%\n80%\n50%\nOption\
    \ 1: Minimalist.\nOption 2: Moderate.\nOption 3: Maximalist.\nPolicy Process Feasibility\n\
    \ \n145 \nof feasibility for implementing each policy option. The total sum was\
    \ a value of 10, \nrepresenting the sum of each dimension's possible value. \n\
    Tables 19 and 22 show that the Minimalist policy option receives high ratings\
    \ in the \nincidents and institutions dimensions but low ratings in the interests\
    \ and ideas, inter-unit \ndiffusion, and industrialization dimensions. The Minimalist\
    \ policy option appears to \nprioritize addressing the dimension of trust between\
    \ farmers and agricultural technology \nproviders in data sharing, with a high\
    \ level of feasibility in terms of incidents, institutions, \nand policy adoption\
    \ time and budget. However, it shows low feasibility in addressing the \ndimension\
    \ of data privacy and confidentiality norms and rights, and only moderate \nfeasibility\
    \ in the dimension of oversight, accountability, and transparency in data \nproduction\
    \ cycle. Concerning policy process feasibility, the Minimalist option has a \n\
    moderate percentage of policy feasibility, indicating that it may encounter some\
    \ challenges \nin terms of interest and ideas and inter-unit diffusion. \nBased\
    \ on the information provided in the two tables, it is important to note that\
    \ policy \noptions for agricultural data governance should be carefully considered\
    \ in terms of their \nfeasibility and ability to address the dimensions of the\
    \ problem. The Minimalist policy \noption may be effective in addressing the issue\
    \ of trust between farmers and agricultural \ntechnology providers in data sharing,\
    \ but may face challenges in terms of data privacy and \nconfidentiality norms\
    \ and rights, as well as oversight, accountability, and transparency in \nthe\
    \ data production cycle. It is also important to consider the level of policy\
    \ process \nfeasibility, which includes incidents, interests and ideas, institutions,\
    \ inter-unit diffusion, \nand industrialization. By carefully examining and selecting\
    \ the appropriate policy option, \n \n146 \npolicymakers can ensure that the agricultural\
    \ sector benefits from the use of data while also \nprotecting the rights and\
    \ interests of farmers and other stakeholders involved in the process. \nThe Moderate\
    \ policy option outperformed both the Minimalist and Maximalist options \nin both\
    \ dimensions. It achieved an 80% feasibility rate in the Policy Process Feasibility\
    \ \nDimension and an 83% problem response rate in the agricultural data governance\
    \ problem \ndimensions, making it the most viable option for addressing the issue.\
    \ \nThe Moderate option excelled in all four dimensions of the agricultural data\
    \ governance \nproblem, including trust between farmers and agricultural technology\
    \ providers in data \nsharing, data privacy and confidentiality norms and rights,\
    \ oversight, accountability, and \ntransparency in the data production cycle,\
    \ and digital transformation in the smart farming \nsector. It also received a\
    \ high score in the industrialization dimension of the Policy Process \nFeasibility\
    \ table, indicating that it is the most advantageous option for the sector's \n\
    advancement in the digital transformation era. \nThe Moderate policy option is\
    \ expected to have a significant impact on the agricultural \ndata governance\
    \ problem while remaining feasible for implementation. Therefore, it is the \n\
    most practical policy option for addressing the agricultural data governance problem.\
    \ \nDespite scoring high in all four dimensions of the agricultural data governance\
    \ problem, \nthe Moderate option may face obstacles in terms of adoption time\
    \ and budget, as rated as \nmedium in the Policy Options table. Furthermore, traditional\
    \ farmers may resist or pose \nbarriers to the option's implementation, despite\
    \ its high score in the industrialization \ndimension. It is therefore essential\
    \ to discuss these potential challenges to gain a more \n \n147 \ncomprehensive\
    \ understanding of the feasibility and potential impact of the Moderate policy\
    \ \noption. \nBased on the analysis so far, we can rule out the Maximalist option\
    \ because it received \nthe lowest score in all dimensions of the public policy\
    \ adoption process. The Maximalist \noption scored poorly in the effectiveness\
    \ dimension because it would likely face significant \nopposition from key stakeholders,\
    \ such as farmers, who may be unwilling to share their \ndata. In addition, the\
    \ Maximalist option's approach to data governance may not effectively \naddress\
    \ the problems associated with agricultural data governance. The Maximalist option\
    \ \nalso received a low score in the feasibility dimension because it would be\
    \ difficult to \nimplement given the current resource and capacity constraints.\
    \ It would require significant \nfunding and coordination between various institutions\
    \ and stakeholders, which may not be \nfeasible in the short term. Furthermore,\
    \ the Maximalist option may not be sustainable over \nthe long term as it may\
    \ face challenges in maintaining political and stakeholder support. \nTherefore,\
    \ based on the evidence gathered, it is unlikely that the Maximalist option would\
    \ \nbe the optimal policy for governing agricultural data. \nIn this research,\
    \ the policy problem of agricultural data governance has been analyzed, \nand\
    \ four main dimensions have been identified: data sharing, the data production\
    \ cycle, \ndata rights and norms, and smart farming. Based on these dimensions,\
    \ three policy options \nhave been developed to propose a policy framework that\
    \ addresses each dimension of the \nagricultural data policy problem. The proposed\
    \ policy options range from minimal to \nmaximalist government approaches, with\
    \ each option providing data safeguards, enablers, \nroles, and responsibilities\
    \ for governing agricultural data. After forecasting the outcomes \nof these three\
    \ policy options, it has been concluded that the minimalist and moderate \n \n\
    148 \napproaches are the most feasible options within the policy process, as they\
    \ not only solve \nthe agricultural data governance problem but also account for\
    \ new innovations and \ntechnological developments. In contrast, the maximalist\
    \ option fails to provide a realistic \nand feasible policy solution. Therefore,\
    \ the proposed two-stage model for agricultural data \ngovernance policy recommends\
    \ the adoption of the minimalist or moderate approach, \ndepending on the specific\
    \ needs and characteristics of each agricultural sector in the US. \n▪ \nPrescription:\
    \ The Final Step in Agricultural Data Governance \nPolicy Analysis  \nThe final\
    \ step in the policy analysis process is to propose a policy option that is most\
    \ \nlikely to resolve the governance issues of agricultural data in the United\
    \ States. This step \nis called prescription, and it focuses on policy choice\
    \ by considering the reasons for \nselecting a particular option. In other words,\
    \ it provides a means of selecting one policy \noption from among several possible\
    \ outcomes (Dunn, 2018, p. 190). In the remainder of \nthis chapter, this research\
    \ will examine which of the two feasible policy options, minimalist \nor moderate,\
    \ should be recommended based on the outcomes previously determined in the \n\
    agriculture sector. \nConsidering the trade-offs associated with collective action,\
    \ both the minimalist and \nmoderate policy alternatives are likely to achieve\
    \ the policy goal67 of balancing equity and \n \n67 Policy goal: “A desired outcome\
    \ of a policy; these goals can be explicitly stated or implicit in the \npolicy\
    \ and other factors found in its legislative history” (Birkland, 2016, p. 236)\
    \ \n \n149 \nefficiency68 among the proposed agricultural data governance policy\
    \ options. These policy \nalternatives aim to address the lack of data standardization,\
    \ access, sharing, and use, not \nonly to enhance agricultural practices and productivity,\
    \ but also to improve crop yields, \nnutritional quality, and promote sustainable\
    \ agriculture overall. \nThe minimalist policy option aims to implement and practice\
    \ data governance principles \nbased on the United States COP Core Principles\
    \ effectively. Its purpose is to monitor \ncompliance with the Core Principles\
    \ in contractual agreements to enable a trusted data-\nsharing system across the\
    \ U.S. agriculture sector. On the other hand, the moderate policy \nalternative\
    \ for agricultural data governance not only aims to implement and practice data\
    \ \ngovernance Core Principles but also assigns roles and responsibilities for\
    \ data access and \nsharing. It also emphasizes the use of data value and promotes\
    \ sector collaboration. \nHowever, achieving a well-balanced solution between\
    \ the interests of various \nstakeholders can be a complex task. Therefore, proposing\
    \ a specific policy option requires \nan evaluation to determine the best approach.\
    \ In governing agricultural data, the aim is to \nmaximize the benefits of sharing\
    \ and using such data in relation to the costs of not currently \nutilizing large\
    \ amounts of unshared agricultural data due to stakeholders' distrust. \nSharing\
    \ and using agricultural data can significantly improve agricultural productivity\
    \ \nand risk management, including adaptation or mitigation of the effects of\
    \ climate change \n(OECD, 2019). Data-driven decisions could also enhance international\
    \ market access and \nopen up new digital trade opportunities, which would benefit\
    \ agricultural productivity, \n \n68 Efficiency: “Gaining the most output for\
    \ a given level of input… [it] is often thought of as getting the \nsame output\
    \ for less of a particular input, or getting more of something for a constant\
    \ input.” (Birkland, \n2016, p. 233). \n \n150 \nprofitability, food security,\
    \ and the overall digitalization of the agricultural sector, leading \nto data-ization.\
    \ \nTo summarize, proposing a policy option for governing agricultural data in\
    \ the United \nStates necessitates careful consideration of the trade-offs associated\
    \ with collective action, \nas well as an in-depth assessment of the costs and\
    \ benefits of the available policy \nalternatives. Prescription, the final step\
    \ in the policy analysis process, focuses on selecting \nthe best policy option\
    \ based on its potential outcomes.  \nIn this case, the minimalist and moderate\
    \ policy alternatives are the most feasible \nalternatives for achieving the policy\
    \ goal of balancing equity and efficiency in agricultural \ndata governance. The\
    \ minimalist policy option seeks to monitor compliance with COP \nprinciples,\
    \ whereas the moderate policy option assigns roles and responsibilities for data\
    \ \naccess and sharing while emphasizing data value and encouraging sector collaboration.\
    \ \nCost-effective analysis and costs and benefits analysis will be used to determine\
    \ the best \napproach for governing agricultural data and maximizing the benefits\
    \ of sharing and using \nsuch data in relation to the costs for the agriculture\
    \ sector in the U.S. \nCost Effective Analysis  \nCost-effectiveness analysis\
    \ (CEA) is a useful method that enables a comparison of \npolicy options not only\
    \ based on their effectiveness (benefits) measured in units of public \ngoods\
    \ or services but also on the costs associated with achieving different levels\
    \ of benefits \nthat may be more effective at a lower cost (Dunn, 2018, p. 217).\
    \ Therefore, the CEA \nmethod can be employed to examine and compare the benefits\
    \ that the minimalist policy \noption for agricultural data governance offers\
    \ in comparison to the moderate policy option \n \n151 \nand the status quo, which\
    \ is doing nothing at all. Through this evaluation process, it will \nbe possible\
    \ to determine the most cost-effective and beneficial policy option for the \n\
    agricultural sector. \nThree criteria are commonly used in CEA. The first is the\
    \ adequacy analysis, which \nexamines whether a policy option can meet minimal\
    \ standards of benefit at some maximal \ncost level. The second criterion, cost\
    \ minimization, evaluates whether a policy option has \nthe lowest costs for some\
    \ minimally acceptable level of benefits. Finally, the third criterion, \nbenefit\
    \ maximization, assesses whether a policy option provides the greatest benefits\
    \ for \nsome maximally acceptable level of costs. Applying these criteria will\
    \ enable us to identify \nthe most cost-effective policy option for governing\
    \ agricultural data in the U.S. \nThe cost effectiveness of agricultural data\
    \ governance policy framework will depend on \nseveral factors: \n- \nThe volume\
    \ and complexity of the data: The more data that needs to be collected, \nstored,\
    \ and managed, the more costly it may be to implement effective \ngovernance policy.\
    \ \n- \nThe level of risk associated with the data: If the data is sensitive or\
    \ valuable, more \nstringent security measures may be required, which may increase\
    \ the cost. \n- \nThe level of collaboration required: If multiple stakeholders\
    \ are involved in the \ndata collection and use, it may be more costly to coordinate\
    \ their efforts and \nensure that everyone is following the same data governance\
    \ guidelines and \nstandards. \n \n152 \n- \nThe availability of funding: The\
    \ availability of funding can play a significant role \nin the cost effectiveness\
    \ of agricultural data governance policy framework. If \nsufficient resources\
    \ are available, more robust governance measures may be \nimplemented. \nAn effective\
    \ agricultural data governance policy should ultimately balance the costs of \n\
    implementing governance measures with the benefits of ensuring that data is collected,\
    \ \nstored, and used in a way that benefits all stakeholders. This balance is\
    \ crucial to ensure \nthat the policy is sustainable and provides value to the\
    \ agricultural sector. \nThe comparison between the two policy options (minimalist\
    \ and moderate) showed that \nwhile policy option II (moderate) may achieve higher\
    \ overall benefit maximization by \nallocating more funds, policy option I (minimalist)\
    \ achieves the minimum standard of \nbenefits of data governance at the lowest\
    \ cost, making it the most effective choice. The \nCEA method did not identify\
    \ any potential problems or unintended consequences of either \npolicy implementation.\
    \ Implementing a design and strategy to improve data governance \nand its consumption\
    \ is a challenging task. Therefore, Policy Option I will be pursued as it \nwill\
    \ serve as the foundation for Policy Option II. This approach provides a significant\
    \ \nbenefit and is the most efficient way to implement an agricultural data governance\
    \ policy \nsolution. Table 23 presents a comparison of the results of the cost-effectiveness\
    \ analysis. \n \n153 \nTable 23 Cost Effectiveness Analysis \nPolicy \nBenefit\
    \ \nMaximization \nCost \nMinimization \nOverall Max Benefit and Less \nCost \n\
    Policy I \nIneffective \nEffective \nEffective \nPolicy II \nEffective \nIneffective\
    \ \nEffective \nNo \nPolicy \nIneffective \nIneffective \nIneffective \nCosts\
    \ and Benefits  \nIn this section, the forecasted effects of the minimal and moderate\
    \ policies are compared \nto a \"status quo\" situation, which represents the\
    \ measures or values of benefits and costs if \nthe policy vacuum scenario for\
    \ agricultural data governance persists. Maintaining the status \nquo of agricultural\
    \ data practices is also considered as one of the possible options. \nTo begin\
    \ this process of evaluating policy options for agricultural data governance,\
    \ it is \nnecessary to identify and categorize the costs and benefits associated\
    \ with each option. This \nanalysis should consider both direct and indirect costs\
    \ and benefits that are relevant to the \npolicy options being considered. Additionally,\
    \ the importance of each factor should be \nranked to help determine the relative\
    \ weight of each element in selecting among the \noptions. \nTo clarify, estimated\
    \ direct benefits are primary outcomes of a policy option that directly \naddress\
    \ the structured policy problem dimensions for the targeted population. On the\
    \ other \nhand, estimated indirect benefits are secondary outcomes that are associated\
    \ with less \nvalued benefits than the flow (access, sharing, and using) of agricultural\
    \ data governance, \nbut still contribute to solving the agricultural data governance\
    \ problem on a smaller scale. \n \n154 \nDirect estimated benefits refer to the\
    \ benefits that can be directly attributed to the \nimplementation of a policy\
    \ option. In the case of agricultural data governance, these \nbenefits would\
    \ focus on improving access, sharing, and the use of agricultural data. \nExamples\
    \ of these benefits could include the development of data-sharing standards, \n\
    incentivizing farmers, producers to share data, and building a data-sharing infrastructure\
    \ \nwithin agricultural research. The literature review was an effective source\
    \ for projecting \nthese direct estimated benefits. \nPotential indirect benefits\
    \ of facilitating data-sharing standards, safeguards, and \nenablers in agriculture\
    \ include increased collaboration between domain researchers and \ndata scientists,\
    \ as well as the development of a data-sharing infrastructure within \nagricultural\
    \ research. This can lead to increased research investment, and the recovery of\
    \ \nunpublished data, which can further support innovation and knowledge creation\
    \ in the \nfield. These indirect benefits may not be immediately apparent, but\
    \ can have a significant \nimpact on the overall success of agricultural research\
    \ and development efforts (Brouder et \nal., 2019, p. 2). \nTable 24 Estimated\
    \ direct and indirect benefits from a policy framework to govern \nagricultural\
    \ data \nBenefits \nDirect  \nIndirect \nIncreased involvement of USDA agencies\
    \ \nin developing an effective oversight \ntrustworthy system of COP principles\
    \ in \ncontractual agreements between farmers \nand ATPs. \nIncrease public involvement\
    \ and strategic \nabilities on improving IoT-enabled \nAgricultural (IoTAg) monitoring.\
    \ \n \n155 \nBenefits \nDirect  \nIndirect \nIncreased level of collaboration\
    \ for a \nreliable and trustworthy agricultural data \nflow, such as farmer-to-ATP\
    \ coordination \nmechanisms. \nIncrease the promotion of a data-literacy \nculture\
    \ in agriculture: the ability to read, \nunderstand, create, and communicate data\
    \ \nfor best farming practices using digital \ntechnologies. \nIncrease USDA capacity\
    \ and procedures \nfor data sharing to trusted academic \norganizations and researchers\
    \ with \nanonymized and aggregated data via the \nsecure data center for research,\
    \ analysis, \nand evaluation.  \nIncrease in data-driven public agricultural \n\
    research approaches based on the \navailability of public data. \nIncrease incentives\
    \ for instituting a data-\ndriven approach for agriculture future \ndecision-making\
    \ where data can be found, \nintegrated, and used. \nImprove agriculture government\
    \ agencies' \nstrategic abilities to provide technical \nassistance to farmers,\
    \ to allocate federal \nfunds, and improve farm program \nimplementation. \nIncreased\
    \ USDA involvement and \nintervention capacity in COP principles \nviolations\
    \ in contract agreements between \nfarmers and ATPs and appropriate action. \n\
    \ \nImproved management agencies' ability to \nstore agricultural-related information\
    \ on \nthe cloud and make it accessible from \nanywhere, allowing for fast data\
    \ access \nand real-time information availability. \nImproved USDA capacity to\
    \ implement \nregistration requirements for private \ncompanies acting as data\
    \ intermediaries. \nReduce waste and inefficiencies in post-\nproduction processing\
    \ and handling in the \nagriculture sector. \nImproved management of USDA \norganizational\
    \ capacity to oversee the \ngranting of ATPs' data-transparent \nLowering the\
    \ risk of climate change and \nextreme weather events due to the sharing \nand\
    \ using of larger amounts of \nagricultural data. \n \n156 \nBenefits \nDirect\
    \  \nIndirect \ntrademark or logo and evaluate its renewal \non an annual basis.\
    \ \nIncrease agricultural stakeholders' \nawareness of the importance of protecting\
    \ \npersonal farmer information (address, \nbank, and credit information). \n\
    Increasing the resilience and sustainability \nof food systems to ensure food\
    \ and \nnutrition security. \nIncentives for promoting a data-driven \ninternational\
    \ trade environment. \n \nIncentives to form partnerships and \nalliances with\
    \ international collaborators \nand subject experts to create open data \nplatforms\
    \ in order to make it easier for \nprimary producers, practitioners, and \nresearchers\
    \ to find agricultural data in \ntheir field of interest (collaborative \nagricultural\
    \ open databases). \n \nThe digital economy has emerged alongside the flow of\
    \ data, creating the potential for \nsignificant innovation and benefits for users\
    \ (Howell, 2022, p.1). Data has two distinct \ncharacteristics that set it apart\
    \ from other goods: it is non-competing and displays network \neffects. This means\
    \ that a single piece of data has the capacity to provide multiple benefits \n\
    to multiple applications, and when combined with additional information, its value\
    \ \nincreases. To fully realize the potential of data, reliable data-sharing solutions\
    \ must be \ndeveloped, and this is where data governance comes into play. By ensuring\
    \ proper data \ngovernance, we can unlock the benefits of data while mitigating\
    \ risks and promoting ethical \npractices. \n \n157 \nThese potential benefits\
    \ can be observed in the wine industry, where having a \ntrustworthy system for\
    \ contractual agreements in place to access, share, and use data can \nplay a\
    \ significant role in sustaining a vibrant transatlantic trade relationship between\
    \ the \nEU and US wine sectors. This sector is a vital driving force in many rural\
    \ economies and \na significant number of medium and small businesses. Implementing\
    \ a data governance \nframework will incentivize government agencies to intervene\
    \ by collecting, linking, and \nanalyzing data to support the economic vitality\
    \ and diversity of the wine sectors. For \ninstance, this can involve working\
    \ on tariffs on wine to achieve a 'zero for zero' wine trade \nenvironment (Featherstone,\
    \ 2021). However, the US wine industry has recently faced \nchallenges due to\
    \ President Donald J. Trump's administration's imposition of a 25% tariff \non\
    \ French, Spanish, German, and English wines in October 2019, which led to a drop\
    \ of \nnearly $500 million in the value of French wine exports to the US in 202069.\
    \ \nDirect estimated benefits are essential in evaluating the significance of\
    \ collaborating \nwith provider users who have access to data and information\
    \ on pests and diseases to \ndevelop research on a single platform. An example\
    \ to consider is the PlantwisePlus \nKnowledge Bank70 and the CABI Digital Library\
    \ (CDL) platform, which provides access \nto diagnostic and decision support tools,\
    \ as well as data sheets, detailed images, and \ndistribution maps71. Knowledge\
    \ Bank users can benefit from improved search capabilities, \n \n69 Information\
    \ available at: https://www.decanter.com/wine-news/us-suspends-wine-tariffs-eu-454550/\
    \ \n70 PlantWise Knowledge Plus is a free online resource that gathers plant health\
    \ information from across \nthe world. More information available at: https://blog.plantwise.org/2021/08/12/what-is-the-plantwise-\n\
    knowledge-bank/ \n71 Detailed information available at the Plantwise Blog: \n\
    https://blog.plantwise.org/2022/11/29/plantwiseplus-knowledge-bank-joins-the-cabi-digital-library/\
    \ \n \n158 \nan enhanced mobile experience, and access to key decision-making\
    \ tools, among other \nadvantages. \nAnother example of how data governance solutions\
    \ can incentivize partnerships \nbetween public agencies and private companies\
    \ is the Agmatix initiative72. Agmatix is a \nstartup ag-tech company that has\
    \ developed a single engine to digitize research data, \nenabling agro-professionals\
    \ to increase crop yields and quality while minimizing \nenvironmental impact.\
    \ By employing machine learning and artificial intelligence, Agmatix \ncreates\
    \ statistically and scientifically stronger models and decision support systems,\
    \ which \ncan aid in the mainstream adoption of big data in agronomy to increase\
    \ global yields. The \nAgmatix platform facilitates the development of statistical\
    \ agricultural models, which can \nhelp reduce food waste and support global food\
    \ security in light of population growth. \nAgriculture science can be better\
    \ translated into practice through the implementation of \na data governance framework\
    \ for the sector. Such a framework can help provide policy \nmakers with access\
    \ to less fragmented, partial, and biased evidence, allowing for more \ninformed\
    \ decision-making. Additionally, according to PwC, IoT-enabled Agricultural \n\
    (IoTAg) monitoring is the fastest-growing technology segment in smart, connected\
    \ \nagriculture, with an expected market value of $4.5 billion by 2025 (Columbus,\
    \ 2021). \nThe estimated benefits highlighted above illustrate the value of implementing\
    \ an \nagricultural data governance policy. Establishing data safeguards and enablers\
    \ through \npolicy measures will facilitate the advancement of data sharing. Incorporating\
    \ data \ngovernance practices such as workflows and usage guidelines in all federally\
    \ funded \n \n72 Agmatix information available at: https://www.agmatix.com/ag-field-trial-management/\
    \ \n \n159 \nprojects, along with coordinating existing and emerging data initiatives,\
    \ networks, and \nrepositories, and building long-term infrastructure comprising\
    \ hardware, software, and \nhuman resources, will help to curate, preserve, and\
    \ add value to agricultural data beyond \nits primary use. \nThe estimated costs\
    \ encompass all the expenses that would be necessary to implement \neither of\
    \ the two public policy options. Estimated direct costs represent the minimum\
    \ \namount required for each policy option to achieve the desired benefits and\
    \ outcomes. \nAlthough these costs are typically expressed in monetary terms to\
    \ gauge the advantages \nand disadvantages of a given policy option, it is impractical\
    \ to provide precise monetary \nestimates for each cost category in this research\
    \ on solving agricultural data governance \nissues in the U.S. This is due to\
    \ the fact that agricultural costs are constantly fluctuating, \nand data accuracy\
    \ can be inconsistent. Nevertheless, the estimated costs provided are \nsupported\
    \ by specific examples in the literature. Attempting to determine costs through\
    \ \nsurvey methods or market behavior inferences is a challenging task. \nTable\
    \ 25 Estimated direct, indirect and risk costs in this study  \nCosts  \nDirect\
    \  \nIndirect  \nRisk \nCapacity building and \nmodernization of \norganizational\
    \ digital \ninfrastructure for USAID \nagencies. \nChallenges with ATPs in \n\
    regulatory compliance with \nCOP principles in \ncontractual agreements and \n\
    lawsuits, \nThe fragmentation of the \nagriculture industry has \nnegative impact\
    \ on data \ngovernance practices \nFarmers automation \ntechnology subsidies \n\
    Poor data quality, data \ninaccuracy and data \nThe Department of \nAgriculture\
    \ delays \n \n160 \ninconsistency \nadopting a modernizing \nmodel to implement\
    \ \nagricultural data policy \nchanges \nImproving the \ninfrastructure, \nmaintenance,\
    \ and storage \ncapacity for data sharing \namong USDA agencies. \nLengthy adoption\
    \ of \nagricultural digital \ntechnology process, lack of \nexpertise, privacy\
    \ and \nsecurity issues \nFarmers' access to \naggregated agricultural \ndata\
    \ is constrained or \nlimited. \nFunding for projects \nrelated to data cooperatives\
    \ \nor data intermediaries, \nannual membership, \ncollaborative agriculture \n\
    organizations, and ATPs \nbusinesses. \nChallenges in reaching out \nto small\
    \ farmers \n(information distribution \nabout policy changes) \nReduced central\
    \ location \nfor all agricultural data \nmanagement offered by ag \ntech providers\
    \ \nAnnual memberships to \naccess and maintain the \nADT Trademark or logo. \n\
    Negative effects on supply \nchain coordination \nOpen-source software has \n\
    limited accessibility for \nfarmers and other \nagriculture stakeholders. \nLarge\
    \ amounts of unused \nagricultural data. \n \n \nIncrease the adoption of AI \n\
    in the agriculture industry. \n \n \nInvestment in cloud \nconnectivity technologies\
    \ \nfor the agriculture sector \n \n \nGlobally, it is expected that the amount\
    \ of data generated each day will reach 463 \nexabytes (Bonner, 2022), highlighting\
    \ the growing importance of developing sustainable \n \n161 \ndata management\
    \ processes. Some studies have attempted to quantify the cost of poor data \n\
    quality. For example, according to a 2016 report by IBM (Redman, 2016), poor-quality\
    \ \ndata73 costs businesses $3.1 trillion annually in the United States alone.\
    \ Sakpal (2021) \nestimated that poor data quality costs organizations an average\
    \ of $15 million per year. \nMoreover, a study by Experian in 2020 found that\
    \ inaccurate data cost businesses an \naverage of 12% of their annual revenue.\
    \ These numbers are only estimates and may not be \napplicable to all organizations,\
    \ but they give a general sense of the significant financial \nimpact of poor\
    \ data quality. In addition to revenue impacts, poor-quality data or a lack of\
    \ \ndata can lead to flawed decision-making and assessments over time (Bonner,\
    \ 2022). Access \nand shareability are crucial for data to be useful. \nEvaluating\
    \ risk costs is important when determining which policy option has a lower \n\
    risk of harm. However, estimating potential consequences and external factors\
    \ that may \naffect outcomes is challenging (Aven, 2014, p. 20). Probabilities\
    \ are conditional (if...then) \nand based on prior knowledge about the event,\
    \ such as scientific knowledge, data, \nassumptions, perceptions, and beliefs\
    \ (Aven, 2014, p.23). Therefore, probability-based risk \nassessment costs for\
    \ an agricultural data policy framework are primarily informed by \nprevious knowledge\
    \ of agricultural data issues. For instance, in the US agriculture sector, \n\
    data access and use by others continue to be dependent on individual contractual\
    \ \nagreements, aided by one-time trial-and-error data transfer solutions (Cragin\
    \ et al. 2010). \nA significant barrier remains the lack of funding for synthesis\
    \ research using aggregated \n \n73 Poor quality data can include inaccurate information,\
    \ incomplete data, non-formatted information, \nirrelevant content, or even duplicate\
    \ data. \n \n162 \ndata. Concerns about data privacy, security, and intellectual\
    \ property also prevent emerging \ndata-sharing efforts, particularly those involving\
    \ public-private partnerships. \nTo assess risk, it's important to measure or\
    \ calculate expected values or costs, which are \nknown as risk metrics. These\
    \ can provide valuable information about the level of risk in a \nspecific situation.\
    \ For example, in the United States, the infrastructure deficit poses a risk \n\
    to agriculture's ability to comply with \"open access\" policies. When assessing\
    \ risk at the \nmacro policy and governance levels, it's important to consider\
    \ not only the likelihood of a \nrisky event occurring and causing harm, but also\
    \ the unknown consequences and the \npotential human reactions, behaviors, and\
    \ attitudes towards it. \nThe public's expectations for accessing and using agricultural\
    \ science to make informed \ndecisions span a wide range of land management, from\
    \ understanding food's nutritional \nvalue for diet modification to vastly improving\
    \ precision technology application for \nprofitable crop and animal production\
    \ and environmental protection (Brouder et al., 2019, \np. 3). As such, risk is\
    \ a function of the implementation of public policy. It is important to \nevaluate\
    \ the likelihood of potential risks and their associated costs if policy option\
    \ one or \ntwo is implemented. \nUncertainties around funding could raise concerns\
    \ about the feasibility of functional, \nhybrid business data models that could\
    \ complement existing public financing data models \nthrough short-term research\
    \ grants or national funding (Brouder et al., 2019, p. 13). The \ncost of the\
    \ envisioned data infrastructure is largely unknown, but undoubtedly, significant\
    \ \ninvestment will be required. Data stewardship, as opposed to simple storage,\
    \ involves \n \n163 \nadditional workflows and human resources (Bourne, Lorsch,\
    \ and Green 2015), which \nfurther exacerbates cost concerns and uncertainty.\
    \ \nThe costs of modernizing agriculture data infrastructure (Ristino & Hart,\
    \ 2022) and \nrestructuring the USDA to oversee COP principles in contractual\
    \ agreements are estimated \nto be directly associated with the minimalist policy\
    \ option I. Modernizing the USDA will \nprovide a foundation for the moderate\
    \ policy option II, which aims to oversee agriculture \ndata intermediaries and\
    \ their processing, storage, analysis, and provision of other data \nservices\
    \ to farmers and producers. Estimated remaining costs in USDA modernization, \n\
    such as the formation of an agricultural data governance board for policy option\
    \ II to \npromote secure and safe agricultural data flow between data intermediaries,\
    \ farmers, and \nproducers, are lower. By modernizing USDA agencies, the agricultural\
    \ sector will witness \nincreased innovation, implementation of digital technologies\
    \ and tools, food security, \nsustainability, and a digitally transformed sector.\
    \ \nFindings \nThe analysis presented dismisses the status quo as an unrealistic\
    \ alternative, as it fails \nto provide any benefits while increasing costs and\
    \ risks associated with the loss of data \nliteracy and informed decision-making.\
    \ Policy option I is the best scenario, given the \ngovernment's allocation of\
    \ funds in the agricultural sector, as it offers the greatest benefit \nfor cost.\
    \ The cost and benefits analysis supports its implementation, as it will enhance\
    \ the \nstewardship and ownership of agricultural data, providing stakeholders\
    \ with a better \nunderstanding of the implications of ongoing technological innovations\
    \ in the sector. \nHowever, budget constraints may limit the scope of this option.\
    \ \n \n164 \nPolicy option II builds upon the foundation of policy option I and\
    \ can potentially provide \nadditional benefits. However, it may not necessarily\
    \ result in reduced costs compared to \npolicy option I. A more comprehensive\
    \ analysis that takes into account potential entry \nbarriers and the potential\
    \ for diminishing returns on investment may be necessary to fully \nunderstand\
    \ the economic impact of policy option II. Currently, both Cost-Effective \nAnalysis\
    \ and Costs and Benefits do not provide a clear picture of this impact. Policy\
    \ option \nI appears to be the most viable scenario in terms of costs and benefits.\
    \  \nThe CBA further supports this conclusion, as it confirms that maximizing\
    \ efficiency \nand minimizing costs will be critical to the successful implementation\
    \ of data governance \nin the agricultural sector. By adopting a comprehensive\
    \ approach to data stewardship and \nownership, farmers and producers can minimize\
    \ risks while maximizing outputs, all while \nmaintaining accurate records for\
    \ regulatory compliance. \nIn summary, the evidence suggests that policy option\
    \ I provides the best balance of \nbenefits and costs for the agricultural sector,\
    \ with policy option II serving as a logical \nextension of policy option I. By\
    \ adopting a forward-thinking approach to data governance \nand management, the\
    \ government can lay the groundwork for a sustainable and secure \nagricultural\
    \ future, while farmers and producers can enjoy the benefits of increased data\
    \ \nliteracy and informed decision-making. \n \n \n165 \nConclusion \nIn the era\
    \ of the Fourth Industrial Revolution, data is no longer just a byproduct of \n\
    agricultural activities; it has become a valuable commodity in its own right.\
    \ As the \nagriculture sector undergoes digital transformation, there is a growing\
    \ need for a \ncomprehensive data governance policy framework that can facilitate\
    \ the secure and \nefficient management of agricultural data.  \nThe analysis\
    \ of the agricultural data governance policy problem and the three policy \noptions\
    \ presented in this dissertation highlight the need for modernizing the agricultural\
    \ \ndata infrastructure in the U.S. agriculture sector. The core of this research\
    \ lies in identifying \na significant policy problem, specifically the lack of\
    \ a comprehensive agricultural data \ngovernance policy. Through this research,\
    \ the aim was to ask the appropriate questions to \naddress this issue from a\
    \ policy perspective, and propose potential solutions that can be \neffective\
    \ in facilitating the digital transformation of the agriculture sector.  \nThe\
    \ objective of an agricultural data governance policy framework is to promote\
    \ data \nsharing and reuse in the sector while protecting personal data and privacy.\
    \ A policy \nframework for cross-sector data sharing can establish clear rules,\
    \ such as obtaining consent \nand safeguarding personal data, promoting responsible\
    \ data sharing. This framework \nencourages innovation and competition while ensuring\
    \ that data is used for the greater good \nof agriculture in the U.S.  \nThis\
    \ research recommends implementing policy options to establish a secure and safe\
    \ \nflow of agricultural data between data intermediaries, farmers, and producers.\
    \ This \ninitiative will serve as a foundation for sector innovation, increase\
    \ the implementation of \n \n166 \ndigital technologies and tools, and promote\
    \ food security, sustainability, and a digitally \ntransformed sector. \nIn addition,\
    \ providing guidelines and objectives for agricultural data governance and \n\
    management will empower farmers and producers to make informed decisions based\
    \ on \ndata analysis, resulting in increased productivity and economic growth.\
    \ In summary, \nmodernizing agricultural data infrastructure and potentially implementing\
    \ policy options I \nand II are crucial for sustaining and growing the agricultural\
    \ sector. These policies will \nimprove data stewardship and ownership, enhance\
    \ sector innovation and efficiency, and \nadvance food security, sustainability,\
    \ and the digital transformation of the sector. \nOne of the key contributions\
    \ of this doctoral research is the proposal of a two-step \npolicy, which represents\
    \ an innovative approach to addressing the challenges posed by the \nFourth Industrial\
    \ Revolution and the digital transformation of the economy in the \nagriculture\
    \ policy subsystem. This policy recommendation represents an attempt at policy\
    \ \ninnovation that has the potential to facilitate the adoption of new technologies\
    \ and promote \nsustainable agriculture practices. By proposing this new approach,\
    \ this research is offering \nvaluable insights into how policymakers can adapt\
    \ to the changing technological landscape \nand ensure that the agricultural sector\
    \ is well-positioned to thrive in the future. \nMoving forward, the next recommended\
    \ step would be to conduct a stakeholder \nassessment in the agricultural sector\
    \ to identify opportunities and challenges related to \nimplementing an agricultural\
    \ data governance policy. This assessment will allow for a \nbetter understanding\
    \ of the needs and concerns of stakeholders, including farmers, \nproducers, and\
    \ data intermediaries. Based on the findings of the assessment, a collaborative\
    \ \n \n167 \nprocess can be initiated to engage stakeholders in discussions and\
    \ agreements of \ncooperation to facilitate the implementation of an agricultural\
    \ data governance policy. This \nwill require a multidisciplinary approach, involving\
    \ policymakers, industry leaders, and \nacademia to ensure that the policy is\
    \ effective, beneficial, and aligned with the digital \ntransformation of the\
    \ agriculture sector. \nBy highlighting the importance of a data-driven approach\
    \ to agriculture and the potential \nbenefits of using data as an additional product\
    \ in this sector, this study hopes to contribute \nto the ongoing conversation\
    \ surrounding agricultural data governance and encourage \nfurther research and\
    \ policy development in this area. This research underscores the need \nfor policymakers\
    \ and stakeholders to prioritize modernizing the agricultural sector and \ndeveloping\
    \ a robust data governance policy framework to ensure the future of food security\
    \ \nand economic development. \nIn conclusion, it is necessary to implement an\
    \ agricultural data governance policy that \npromote responsible data use, foster\
    \ transparency and trust, and facilitate innovation and \ngrowth in the sector.\
    \ \n \n \n168 \nBibliography \nAFBF. (2023). AFBF Signs Right to Repair Memorandum\
    \ of Understanding with John \nDeere. AFBF Newsroom. https://www.fb.org/newsroom/afbf-signs-right-to-\n\
    repair-memorandum-of-understanding-with-john-deere \nAtwood, D., Blair, R., Howell,\
    \ K., Myers, R., & Ristino, L. (2022, June 9). Models for \nModernizing Agriculture\
    \ Data Infrastructure: Lessons Learned from Data \nInnovation in Other Sectors\
    \ [Webinar]. https://www.datafoundation.org/events-\nlist/models-for-modernizing-agriculture-data-infrastructure-lessons-learned-from-\n\
    data-innovation-in-other-sectors/2022 \nBaloup, J., Bayamlıoğlu, E., Benmayor,\
    \ A., Ducuing, C., Dutkiewicz, L., Lalova, T., \nMiadzvetskaya, Y., & Peeters,\
    \ B. (2021). White Paper on the Data Governance \nAct. SSRN Electronic Journal.\
    \ https://doi.org/10.2139/ssrn.3872703 \nBenfeldt Nielsen, O. (2017). A Comprehensive\
    \ Review of Data Governance Literature. \nAssociation for Information Systems\
    \ AIS Electronic Library (AISeL), Selected \nPapers of the IRIS(8), 15. \nBenfeldt,\
    \ O., Persson, J. S., & Madsen, S. (2020). Data Governance as a Collective \n\
    Action Problem. Information Systems Frontiers, 22(2), 299–313. \nhttps://doi.org/10.1007/s10796-019-09923-z\
    \ \nBonner, A. (2022, April 14). Bad data: A $3T-per-year problem with a solution.\
    \ \nVentureBeat. https://venturebeat.com/datadecisionmakers/bad-data-a-3t-per-year-\n\
    problem-with-a-solution/ \nBrouder, S., Eagle, A., Fukagawa, N., McNamara, J.,\
    \ Murray, S., Parr, C., & Tremblay, \nN. (2019). Enabling Open-source Data Networks\
    \ in Public Agricultural \n \n169 \nResearch. https://www.cast-science.org/wp-content/uploads/2019/05/QTA2019-\n\
    1-Data-Sharing.pdf \nBrown, D. (2020). Health Data Governance Framework [Report].\
    \ Monash University. \nhttps://doi.org/10.26180/5f3335c306a3b \nBunge, J. (2021,\
    \ August 22). How a Billion-Dollar Farm-Tech StartupStumbled, Then \nRevamped.\
    \ https://www.wsj.com/articles/how-a-billion-dollar-farm-tech-startup-\nindigo-stumbled-then-revamped-11629656437\
    \ \nCertified Companies Ag Data Transparent. (2022). Ag Data Transparent. \nhttps://www.agdatatransparent.com/certified2\
    \ \nChen, R. (2021). Mapping Data Governance Legal Frameworks around the World:\
    \ \nFindings from the Global Data Regulation Diagnostic. The World Bank. \nhttps://doi.org/10.1596/1813-9450-9615\
    \ \nColumbus, L. (2021, February 17). 10 Ways AI Has The Potential To Improve\
    \ \nAgriculture In 2021. Forbes. \nhttps://www.forbes.com/sites/louiscolumbus/2021/02/17/10-ways-ai-has-the-\n\
    potential-to-improve-agriculture-in-2021/ \nCore Principles Ag Data Transparent.\
    \ (2022). Ag Data Transparent. \nhttps://www.agdatatransparent.com/principles\
    \ \nCue, R., Doornink, M., George, R., Griffiths, B., Jorgensen, M. W., Rogers,\
    \ R., Saha, A., \nTaysom, K., Cabrera, V. E., Wangen, S. R., & Fadul-Pacheco,\
    \ L. (2021). Data \nGovernance in the Dairy Industry. Animals, 11(10), 2981. \n\
    https://doi.org/10.3390/ani11102981 \n \n170 \nFeatherstone, C. (2021, March 12).\
    \ Software helps farmers make sense of their fields. \nhttps://basinbusinessjournal.com/news/2021/mar/12/software-help-farmers-make-\n\
    sense-their-fields/ \nFisher, A., & Streinz, T. (2021). Confronting Data Inequality.\
    \ SSRN Electronic Journal. \nhttps://doi.org/10.2139/ssrn.3825724 \nHoppe, R.\
    \ (2018). Rules-of-thumb for problem-structuring policy design. Policy Design\
    \ \nand Practice, 1(1), 12–29. https://doi.org/10.1080/25741292.2018.1427419 \n\
    Johnson, R. (2019). 2018 Farm Bill Primer: Support for Urban Agriculture. \nCongressional\
    \ Research Service (CRS), 3. \nJouanjean, M.-A., Cassalini, Grey, & Wiseman. (2020).\
    \ Issues around data governance \nin the digital transformation of agriculture:\
    \ The farmers’ perspective (OECD \nFood, Agriculture and Fisheries Papers No.\
    \ 146; OECD Food, Agriculture and \nFisheries Papers, Vol. 146). https://doi.org/10.1787/53ecf2ab-en\
    \ \nKerber, W., & Frank, J. S. (2017). Data Governance Regimes in the Digital\
    \ Economy: \nThe Example of Connected Cars. SSRN Electronic Journal. \nhttps://doi.org/10.2139/ssrn.3064794\
    \ \nKosior. (2019a, May). From Analogue to Digital Agriculture. Policy and Regulatory\
    \ \nFramework for Agricultural Data Governance in the EU. ISEG Research Seminar\
    \ \n„Governance, regulation and economic integration”, Lisbon School of Economics\
    \ \nand Management, University of Lisbon, 8 May 2019. \nhttps://ssrn.com/abstract=2839811.\
    \ \n \n171 \nKosior, K. (2019b). Towards a New Data Economy for EU Agriculture.\
    \ Studia \nEuropejskie -Studies in European Affairs, 23(4), 91–107. \nhttps://doi.org/10.33067/SE.4.2019.6\
    \ \nKrippendorff, K. (2004). Content analysis: An introduction to its methodology\
    \ (2nd \nedition.). Sage. \nNational Farmers Union. (2023). Right to Repair [Farmers\
    \ union]. https://nfu.org/wp-\ncontent/uploads/2023/02/FFF_R2R_02252023.pdf \n\
    OECD. (2019a). Digital Opportunities for Better Agricultural Policies. OECD. \n\
    https://doi.org/10.1787/571a0812-en \nOECD. (2019b). Enhancing Access to and Sharing\
    \ of Data: Reconciling Risks and \nBenefits for Data Re-use across Societies.\
    \ OECD. \nhttps://doi.org/10.1787/276aaca8-en \nO’Reilly, K. (2021, March 23).\
    \ It Shouldn’t Cost the Farm to Fix a Tractor. WSJ. \nhttps://www.wsj.com/articles/it-shouldnt-cost-the-farm-to-\
    \ ix-a-tractor-\n11616537863 \nPeters, B. G., & Fontaine, G. (2020). Handbook\
    \ of research methods and applications in \ncomparative policy analysis. Edward\
    \ Elgar Publishing. \nRedman, T. C. (2016, September 22). Bad Data Costs the U.S.\
    \ $3 Trillion Per Year. \nHarvard Business Review. https://hbr.org/2016/09/bad-data-costs-the-u-s-3-\n\
    trillion-per-year \nRistino, L., & Hart, N. (2022). Modernizing Agriculture Data\
    \ Infrastructure to Improve \nEconomic and Ecological Outcomes. Data Foundation\
    \ and the AGree Initiative. \n \n172 \nhttps://www.datafoundation.org/modernizing-agriculture-data-infrastructure-to-\n\
    improve-economic-and-ecological-outcomes-2022 \nSakpal, M. (2021, July 14). 12\
    \ Actions to Improve Your Data Quality. Gartner. \nhttps://www.gartner.com/smarterwithgartner/how-to-improve-your-data-quality\
    \ \nSanderson, J., Wiseman, L., & Poncini, S. (2018). What’s behind the ag-data\
    \ logo? An \nexamination of voluntary agricultural-data codes of practice. International\
    \ \nJournal of Rural Law and Policy, 1. https://doi.org/10.5130/ijrlp.1.2018.6043\
    \ \nSchneider, A. L. (1997). Policy design for democracy. University Press of\
    \ Kansas. \nStone, D. A. (2012). Policy paradox: The art of political decision\
    \ making (Third \nedition.). W.W. Norton & Company. \nvan der Burg, S., Wiseman,\
    \ L., & Krkeljas, J. (2021). Trust in farm data sharing: \nReflections on the\
    \ EU code of conduct for agricultural data sharing. Ethics and \nInformation Technology,\
    \ 23(3), 185–198. https://doi.org/10.1007/s10676-020-\n09543-1 \nvan Eck, N. J.,\
    \ & Waltman, L. (2021). VOSviewer Manual. 51. \nWiseman, L., & Sanderson, J. (2020).\
    \ Agricultural data rules: Enabling best practices. \nGriffin University & USC\
    \ Australia. \nhttp://www.acipa.edu.au/pdfs/Agricultural_Data_Rules_Report.pdf\
    \ \nWiseman, L., Sanderson, J., Zhang, A., & Jakku, E. (2019). Farmers and their\
    \ data: An \nexamination of farmers’ reluctance to share their data through the\
    \ lens of the laws \nimpacting smart farming. NJAS - Wageningen Journal of Life\
    \ Sciences, 90–91, \n100301. https://doi.org/10.1016/j.njas.2019.04.007 \n173\
    \ \nWorld Bank. (2021). World Development Report 2021: Data for Better Lives.\
    \ The World \nBank. https://doi.org/10.1596/978-1-4648-1600-0 \n174 \nAppendix:\
    \ Tables for the Application of Forecasting Policy Analysis Methods \nAttached\
    \ below are the Excel tables that were used in our forecasting analysis work.\
    \ \nForecasting–Prediction Policy Analysis: Policy options addressing the dimensions\
    \ of the policy problem \nAddressing the policy problem dimensions \nPolicy \n\
    Options \nfor Ag-DG  \nData governance \nlegal dimensions \n(Chen, 2021) \nFarmer\
    \ \nand \npublic \ntrust in \ndata \nsharing \n(0.4) \nData rights and \nnorms\
    \ for \nprivacy and \nconfidentiality \n(0.2) \nData production \ncycle, Oversight,\
    \ \naccountability \n(0.2) \nSmart Farming-\nSector digital \ntransformation \n\
    (0.2) \nPolicy adoption time \nPolicy adoption \nbudget \nSum \nTotal \n% \nproblem\
    \ \nresponse \nOption 1: \nMinimalist \nSafeguards \n1 \n0 \n1 \n0 \n1 \n1 \n\
    4 \n6 \nEnablers \n1 \n1 \n0 \n0 \n1 \n1 \n4 \n6 \nInstitutional \nroles and \n\
    responsibilities \n1 \n1 \n1 \n0 \n1 \n1 \n5 \n6 \nOption 1 consolidated \nHIGH\
    \ \nMEDIUM \nMEDIUM \nUNDER SERVED \nHIGH \nHIGH \n13 \n18 \n72% \nOption 2: \n\
    Moderate \nSafeguards \n1 \n1 \n1 \n1 \n0 \n1 \n5 \n6 \nEnablers \n1 \n1 \n1 \n\
    1 \n1 \n1 \n6 \n6 \nInstitutional \nroles and \nresponsibilities \n1 \n1 \n1 \n\
    1 \n0 \n0 \n4 \n6 \n175 \nOption 2 consolidated \nHIGH \nHIGH \nHIGH \nHIGH \n\
    LOW \nMEDIUM \n15 \n18 \n83% \nOption 3: \nMaximalist \nSafeguards \n1 \n1 \n\
    1 \n1 \n0 \n0 \n4 \n6 \nEnablers \n1 \n1 \n1 \n1 \n0 \n0 \n4 \n6 \nInstitutional\
    \ \nroles and \nresponsibilities \n1 \n1 \n1 \n1 \n0 \n0 \n4 \n6 \nOption 3 consolidated\
    \ \nHIGH \nHIGH \nHIGH \nHIGH \nUNDER SERVED \nUNDER SERVED \n12 \n18 \n67% \n\
    Policy Process Feasibility Analysis \nPolicy Process Feasibility Dimension \n\
    Policy \nOptions for \nAg-DG \nIncidents  \nInterests and Ideas \nInstitutions\
    \ \nInter-Unit diffusion  \nIndustrialization  \nOption 1: \nMinimalist \nIncidents\
    \ that \ncreate windows \nfor new ideas \nHIGH \nCollective \naction \nproblems\
    \ \nMEDIUM \nInstitutions \nthat allow \npolicy \nresponses to \noccur \nHIGH\
    \ \nPolitical \neconomy/fiscal \nincentives \nMEDIUM \nAgriculture \nSector Digital\
    \ \ntransformation \nUNDER SERVED \nIncidents of non-\ntechnical \ncommunication\
    \ \nAdvocates of \nchange or \nstasis \nInstitutional \nstrategies to \noptimize\
    \ the \nuse of \ninstitutions for \npolicy \nresponse \nGlobalization \n(“global\
    \ supply \nchains effect”) \nPowerful \nideas to \nmobilize, \nframe, and \ndetermine\
    \ \npolicy \nchange \n176 \nPolicy Process Feasibility Dimension \nPolicy \nOptions\
    \ for \nAg-DG \nIncidents  \nInterests and Ideas \nInstitutions \nInter-Unit diffusion\
    \  \nIndustrialization  \nOption 2: \nModerate  \nIncidents that \ncreate windows\
    \ \nfor new ideas \nHIGH \nCollective \naction \nproblems \nLOW \nInstitutions\
    \ \nthat allow \npolicy \nresponses to \noccur \nHIGH \nPolitical \neconomy/fiscal\
    \ \nincentives \nHIGH \nAgriculture \nSector Digital \ntransformation \nHIGH \n\
    Incidents of non-\ntechnical \ncommunication \nAdvocates of \nchange or \nstasis\
    \ \nInstitutional \nstrategies to \noptimize the \nuse of \ninstitutions for \n\
    policy \nresponse \nGlobalization \n(“global supply \nchains effect”) \nPowerful\
    \ \nideas to \nmobilize, \nframe, and \ndetermine \npolicy \nchange \nOption 3:\
    \ \nMaximalist \nIncidents that \ncreate windows \nfor new ideas \nMEDIUM \nCollective\
    \ \naction \nproblems \nHIGH \nInstitutions \nthat allow \npolicy \nresponses\
    \ to \noccur \nUNDER SERVED \nPolitical \neconomy/fiscal \nincentives \nMEDIUM\
    \ \nAgriculture \nSector Digital \ntransformation \nHIGH \nIncidents of non-\n\
    technical \ncommunication \nAdvocates of \nchange or \nstasis \nInstitutional\
    \ \nstrategies to \noptimize the \nuse of \ninstitutions for \npolicy \nresponse\
    \ \nGlobalization \n(“global supply \nchains effect”) \nPowerful \nideas to \n\
    mobilize, \nframe, and \ndetermine \npolicy \nchange \n177 \nCoding of Benefits\
    \ and Costs \nQualitative Y \nNumeric Y \nWeighted Numeric \nBENEFITS I \n(DIRECT)\
    \ \nImportance \nRank \nRank \nWeight \nOption \n1 \nOption \n2 \nStatus \nQuo\
    \ \nWeighte\nd Rank \nOption \n1 \nOption \n2 \nNo \npolicy \nOption \n1 \nOption\
    \ \n2 \nNo \npolicy \nIncreased involvement \nof USDA agencies in \ndeveloping\
    \ an \nEFFECTIVE \nOVERSIGHT \ntrustworthy system of \nCOP principles in \ncontractual\
    \ agreements \nbetween farmers and \nATPs \n1 \n1.25 \nhigh \nmedium \nnone \n\
    22.5 \n3 \n2 \n0 \n67.5 \n45 \n0 \nIncreased level of \ncollaboration for a \n\
    reliable and trustworthy \nagricultural data flow, \nsuch as farmer-to-ATP \n\
    coordination \nmechanisms \n2 \n1.25 \nmedium \nhigh \nnone \n21.3 \n2 \n3 \n\
    0 \n42.5 \n63.8 \n0 \nIncrease incentives for \nsharing public data \n3 \n1.25\
    \ \nmedium \nhigh \nnone \n20 \n2 \n3 \n0 \n40 \n60 \n0 \nIncrease incentives\
    \ for \ninstituting a data-driven \nfuture decision-making \napproach where data\
    \ \ncan be found, \nintegrated, and used \n4 \n1.25 \nmedium \nhigh \nlow \n18.8\
    \ \n2 \n3 \n1 \n37.5 \n56.3 \n18.8 \nIncreased USDA \ninvolvement and \nintervention\
    \ capacity in \nCOP principles \nviolations in contract \nagreements between \n\
    farmers and ATPs and \nappropriate action \n5 \n1.25 \nhigh \nhigh \nnone \n17.5\
    \ \n3 \n3 \n0 \n52.5 \n52.5 \n0 \n178 \nImproved USDA \ncapacity to implement\
    \ \nregistration \nrequirements for private \ncompanies acting as \ndata intermediaries.\
    \ \n6 \n1.25 \nlow \nmedium \nnone \n16.3 \n1 \n2 \n0 \n16.3 \n32.5 \n0 \nImproved\
    \ management \nof USDA organizational \ncapacity to oversee the \ngranting of\
    \ ATPs' data-\ntransparent trademark \nor logo and evaluate its \nrenewal on an\
    \ annual \nbasis \n7 \n1.25 \nlow \nlow \nnone \n15 \n1 \n1 \n0 \n15 \n15 \n0\
    \ \nIncrease agricultural \nstakeholders' awareness \nof the importance of \n\
    protecting personal \nfarmer information \n(address, bank, and \ncredit information).\
    \ \n8 \n1.25 \nhigh \nhigh \nnone \n13.8 \n3 \n3 \n0 \n41.3 \n41.3 \n0 \nIncentives\
    \ for \nsupporting a data-driven \ninternational trade \nenvironment \n9 \n1.25\
    \ \nmedium \nmedium \nnone \n12.5 \n2 \n2 \n0 \n25 \n25 \n0 \nIncentives to form\
    \ \npartnerships and \nalliances with \ninternational \ncollaborators and \nsubject\
    \ experts in order \nto make it easier for \nprimary producers, \npractitioners,\
    \ and \nresearchers to find \nagricultural data in their \nfield of interest.\
    \ \n10 \n1.25 \nmedium \nhigh \nnone \n11.3 \n2 \n3 \n0 \n22.5 \n33.8 \n0 \nBENEFITS\
    \ II \n(INDIRECT) \n179 \nIncrease public \ninvolvement and \nstrategic abilities\
    \ on \nimproving IoT-enabled \nAgricultural (IoTAg) \nmonitoring \n11 \n1 \nmedium\
    \ \nhigh \nlow \n8 \n2 \n3 \n1 \n16 \n24 \n8 \nIncrease farmer \nparticipation\
    \ in best \nfarming practices for \nusing digital \ntechnologies (data \nliteracy)\
    \ \n12 \n1 \nmedium \nhigh \nlow \n7 \n2 \n3 \n1 \n14 \n21 \n7 \nIncrease in data-driven\
    \ \nin public agricultural \nresearch approaches \nbased on the availability \n\
    of public intent data \n13 \n1 \nmedium \nhigh \nlow \n6 \n2 \n3 \n1 \n12 \n18\
    \ \n6 \nImprove agencies' \nstrategic abilities to \nallocate federal funds to\
    \ \nspecific agriculture \nprograms \n14 \n1 \nlow \nmedium \nnone \n5 \n1 \n\
    2 \n0 \n5 \n10 \n0 \nImproved management \nagencies' ability to store \nagricultural-related\
    \ \ninformation on the \ncloud and make it \naccessible from \nanywhere, allowing\
    \ for \nfast data access and \nreal-time information \navailability \n15 \n1 \n\
    medium \nhigh \nlow \n4 \n2 \n3 \n1 \n8 \n12 \n4 \nReduce waste and \ninefficiencies\
    \ in post-\nproduction processing \nand handling \n16 \n1 \nmedium \nhigh \nlow\
    \ \n3 \n2 \n3 \n1 \n6 \n9 \n3 \nLowering the risk of \nclimate change and \nextreme\
    \ weather events \n17 \n1 \nmedium \nhigh \nnone \n2 \n2 \n3 \n0 \n4 \n6 \n0 \n\
    180 \nIncreasing the resilience \nand sustainability of \nfood systems to ensure\
    \ \nfood and nutrition \nsecurity \n18 \n1 \nmedium \nmedium \nlow \n1 \n2 \n\
    2 \n1 \n2 \n2 \n1 \nMAX \n18 \n1 \nMIN \nCOSTS I (DIRECT) (Policy Option Implementation\
    \ - 1 the most \nimportant) \nCapacity building \ntrainings and \nmodernization\
    \ of \norganizational digital \ninfrastructure for \nDepartment of \nAgriculture\
    \ agencies. \n1 \n1.25 \nmedium \nhigh \nnone \n22.5 \n2 \n3 \n0 \n45 \n67.5 \n\
    0 \nFarmers automation \ntechnology subsidies \n2 \n1.25 \nmedium \nhigh \nnone\
    \ \n21.25 \n2 \n3 \n0 \n42.5 \n63.8 \n0 \nData storage \ninfrastructure and \n\
    maintenance \n3 \n1.25 \nmedium \nmedium \nlow \n20 \n2 \n2 \n1 \n40 \n40 \n20\
    \ \nData Cooperatives or \nIntermediaries annual \nmembership \n4 \n1.25 \nmedium\
    \ \nlow \nhigh \n18.75 \n2 \n1 \n3 \n37.5 \n18.8 \n56.3 \nADT Trademark or logo\
    \ \nfor one-year \n5 \n1.25 \nmedium \nlow \nhigh \n17.5 \n2 \n1 \n3 \n35 \n17.5\
    \ \n52.5 \nLarge amounts of \nunused agricultural data \n6 \n1.25 \nlow \nlow\
    \ \nhigh \n16.25 \n1 \n1 \n3 \n16.3 \n16.3 \n48.8 \nAI investment in \nagriculture\
    \ \n7 \n1.25 \nlow \nhigh \nnone \n15 \n1 \n3 \n0 \n15 \n45 \n0 \nInterconnectivity\
    \ (IOT - \nCentral Servers) \n8 \n1.25 \nmedium \nhigh \nlow \n13.75 \n2 \n3 \n\
    1 \n27.5 \n41.3 \n13.8 \nCOSTS II \n(INDIRECT) \nChallenges with ATPs \nin regulatory\
    \ \ncompliance with COP \nprinciples in contractual \nagreements and lawsuits\
    \ \n9 \n1 \nlow \nmedium \nmediu\nm \n10 \n1 \n2 \n2 \n10 \n20 \n20 \n181 \nPoor\
    \ data quality, data \ninaccuracy and data \ninconsistency \n10 \n1 \nlow \nmedium\
    \ \nmediu\nm \n9 \n1 \n2 \n2 \n9 \n18 \n18 \nLengthy adoption of \nagricultural\
    \ digital \ntechnology process, \nlack of expertise, \nprivacy and security \n\
    issues \n11 \n1 \nmedium \nhigh \nlow \n8 \n2 \n3 \n1 \n16 \n24 \n8 \nChallenges\
    \ in reaching \nout to small farmers \n(information \ndistribution about \npolicy\
    \ changes) \n12 \n1 \nmedium \nhigh \nnone \n7 \n2 \n3 \n0 \n14 \n21 \n0 \nNegative\
    \ effects on \nsupply chain \ncoordination \n13 \n1 \nmedium \nlow \nhigh \n6\
    \ \n2 \n1 \n3 \n12 \n6 \n18 \nCOSTS III (RISK) \nThe fragmentation of \nthe agriculture\
    \ industry \nhas negative impact on \ndata governance \npractices \n14 \n1 \n\
    medium \nmedium \nlow \n5 \n2 \n2 \n1 \n10 \n10 \n5 \nThe Department of \nAgriculture\
    \ delays \nadopting a modernizing \nmodel to implement \nagricultural data policy\
    \ \nchanges \n15 \n1 \nmedium \nmedium \nlow \n4 \n2 \n2 \n1 \n8 \n8 \n4 \nFarmers\
    \ have restricted \nor limited access to \naggregated agricultural \ndata \n16\
    \ \n1 \nmedium \nmedium \nlow \n3 \n2 \n2 \n1 \n6 \n6 \n3 \nAg Tech providers\
    \ \nreduce the offer of a \ncentralized location for \nall agricultural data \n\
    management \n17 \n1 \nmedium \nmedium \nlow \n2 \n2 \n2 \n1 \n4 \n4 \n2 \n182\
    \ \nFarmers have restricted \naccess to open-source \nsoftware \n18 \n1 \nmedium\
    \ \nmedium \nlow \n1 \n2 \n2 \n1 \n2 \n2 \n1 \nMAX \n18 \n1 \nMIN \n91 \n119 \n\
    79 \n"
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: https://pdxscholar.library.pdx.edu/cgi/viewcontent.cgi?article=7504&context=open_access_etds
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: A Policy Proposal for Agricultural Data Governance
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.20868/upm.thesis.69244
  analysis: '>'
  authors:
  - José Andrés Muñoz Arcentales
  citation_count: 0
  full_citation: '>'
  full_text: '>

    LoginCreate Account Advanced Search Contribution to the advancement of data engineering
    for smart spaces through data usage control and context-aware systems Muñoz Arcentales,
    José Andrés (2021). Contribution to the advancement of data engineering for smart
    spaces through data usage control and context-aware systems. Thesis (Doctoral),
    E.T.S.I. Telecomunicación (UPM). https://doi.org/10.20868/UPM.thesis.69244. Description
    Title Contribution to the advancement of data engineering for smart spaces through
    data usage control and context-aware systems Author/s Muñoz Arcentales, José Andrés
    Contributor/s Salvachúa Rodríguez, Joaquín (jsalvachua@dit.upm.es) https://orcid.org/0000-0002-7269-8079
    Alonso González, Álvaro https://orcid.org/0000-0002-8456-8351 Item Type Thesis
    (Doctoral) Read date 2021 Subjects Telecommunications Faculty E.T.S.I. Telecomunicación
    (UPM) Department Ingeniería de Sistemas Telemáticos Creative Commons Licenses
    Recognition - No derivative works - Non commercial Full text PDF - Requires a
    PDF viewer, such as GSview, Xpdf or Adobe Acrobat Reader Download (5MB) | Preview
    Abstract Currently, one of the most promising application fields of context-aware
    systems is that of IoT-based (Internet of Things) smart spaces. A smart space
    is a physical space that relies on technology to connect "things" to the virtual
    world, increasing the level of awareness of what is occurring in physical environments.
    Besides IoT devices, IoT-based smart spaces include software platforms and services,
    artificial intelligence (AI), machine learning (ML), big data, cloud computing,
    heterogeneous connectivity, virtual/mixed realities, and a huge range of technologies
    to improve people’s quality of life, to decrease environmental impact, and to
    optimize the use of physical resources. Most previous works provide a generic
    high-level structure of how a context-aware system can be operationalized, but
    do not offer clues on how to implement it. On the other hand, there are many implementations
    of context-aware systems applied to specific IoT-based smart environments that
    are context-specific: it is not clear how they can be extended to other use cases.
    Additionally, in recent years, a new business paradigm has emerged which revolves
    around effectively extracting value from data. In this scope, providing a secure
    ecosystem for data sharing that ensures data governance and traceability is of
    paramount importance as it holds the potential to create new applications and
    services. Protecting data goes beyond restricting who can access what resource
    (covered by identity and Access Control): it becomes necessary to control how
    data are treated once accessed, which is known as data usage control. Data usage
    control provides a common and trustful security framework to guarantee the compliance
    with data governance rules and responsible use of organizations’ data by third-party
    entities, easing and ensuring secure data sharing in ecosystems such as Smart
    Cities and Industry 4.0. This thesis encompasses the design, implementation, and
    validation of two architectures for enabling context-aware data analytics and
    data usage control in smart spaces. Both architectures have been implemented relying
    on the building blocks of the FIWARE ecosystem, presenting agnostic end-to-end
    solutions that take into consideration the complete data lifecycle, filling the
    existing gap in the literature. On the one hand, on the topic of context-aware
    systems, I provide an architecture and a reference implementation that can be
    readily operationalized in any IoT-based smart environment regardless of its field
    of application, providing a context-aware data analytics solution that is not
    context-specific. I provide two sample application scenarios that showcase how
    the reference implementation can be used in a variety of fields, covering from
    data acquisition and modeling, to data reasoning and dissemination. On the other
    hand, regarding data usage control, I present an architecture proposal and its
    subsequent implementation that achieves access and usage control in shared data
    ecosystems among multiple organizations. The proposed architecture is based on
    the UCON (Usage Control) model and an extended XACML (eXtensible Access Control
    Markup Language) Reference Architecture, relying on key aspects of the IDS (International
    Data Spaces) Reference Architecture Model. The implementation presented has been
    validated with a use case in the food industry, presenting a series of metrics
    of the response time of policy compliance verification and punishment enforcement.
    Finally, the results reported in this thesis contributes to the advancement of
    data engineering not only by enabling data analytics capabilities in context-aware
    systems but also by providing a trustworthy mechanism to ensure that the data
    generated by those systems can be continuously controlled and monitored using
    the proposed data usage control framework. ----------RESUMEN---------- Actualmente,
    uno de los campos de aplicación más prometedores de los sistemas conscientes del
    contexto es el de los espacios inteligentes basados en el IoT (Internet de las
    cosas). Un espacio inteligente es un espacio físico que se apoya en la tecnología
    para conectar las "cosas" con el mundo virtual, aumentando el nivel de conciencia
    de lo que ocurre en los entornos físicos. Además de los propios dispositivos IoT,
    los espacios inteligentes basados en IoT incluyen plataformas y servicios de software,
    inteligencia artificial (IA), aprendizaje automático (ML), big data, computación
    en la nube, conectividad heterogénea, realidades virtuales/mixtas y una enorme
    gama de tecnologías para mejorar la calidad de vida de las personas, disminuir
    el impacto medioambiental y optimizar el uso de los recursos físicos. La mayoría
    de los trabajos anteriores proporcionan una estructura genérica de alto nivel
    sobre cómo puede funcionar un sistema consciente del contexto, pero no ofrecen
    pistas sobre cómo implementarlo. Por otra parte, hay muchas implementaciones de
    sistemas conscientes del contexto aplicadas a entornos inteligentes específicos
    basados en IoT que son específicos del campo de aplicación: no está claro cómo
    pueden extenderse a otros casos de uso. Además, en los últimos años ha surgido
    un nuevo paradigma empresarial que gira en torno a la extracción efectiva de valor
    de los datos. En este ámbito, proporcionar un ecosistema seguro para el intercambio
    de datos que garantice la gobernanza y la trazabilidad de los mismos es de vital
    importancia, ya que encierra el potencial de crear nuevas aplicaciones y servicios.
    La protección de los datos va más allá de la restricción de quién puede acceder
    a qué recurso (cubierta por el control de identidad y acceso): se hace necesario
    controlar cómo se tratan los datos una vez que se accede a ellos, lo que se conoce
    como control de uso de los datos. El control de uso de los datos proporciona un
    marco de seguridad común y de confianza para garantizar el cumplimiento de las
    normas de gobernanza de datos y el uso responsable de los datos de las organizaciones
    por parte de terceras entidades, facilitando y garantizando el intercambio seguro
    de datos en ecosistemas como las Ciudades Inteligentes y la Industria 4.0. Esta
    tesis abarca el diseño, la implementación y la validación de dos arquitecturas
    para permitir el análisis de datos conscientes del contexto y el control del uso
    de datos en espacios inteligentes. Ambas arquitecturas se han implementado basándose
    en los bloques del ecosistema FIWARE, presentando soluciones agnósticas de extremo
    a extremo que tienen en cuenta el ciclo de vida completo de los datos, llenando
    el vacío existente en la literatura. Por un lado, en lo relacionado con el tema
    de los sistemas conscientes del contexto, proporciono una arquitectura y una implementación
    de referencia que puede ser fácilmente operacionalizada en cualquier entorno inteligente
    basado en IoT, independientemente de su campo de aplicación, proporcionando una
    solución de análisis de datos consciente del contexto que no es específica del
    mismo. Proporciono dos escenarios de aplicación de ejemplo que muestran cómo la
    implementación de referencia puede ser utilizada en una variedad de campos, cubriendo
    desde la adquisición de datos y el modelado, hasta el razonamiento de datos y
    la difusión. Por otro lado, en lo que respecta al control del uso de los datos,
    presento una propuesta de arquitectura y su posterior implementación que logra
    el control de acceso y uso de datos en ecosistemas de datos compartidos entre
    múltiples organizaciones. La arquitectura propuesta se basa en el modelo UCON
    (Usage Control) y en una arquitectura de referencia XACML (eXtensible Access Control
    Markup Language) ampliada, apoyándose en aspectos clave del modelo de arquitectura
    de referencia IDS (International Data Spaces). La implementación presentada ha
    sido validada con un caso de uso en la industria alimentaria, presentando una
    serie de métricas del tiempo de respuesta de la verificación del cumplimiento
    de las políticas y de la aplicación de las sanciones. Finalmente, los resultados
    reportados en esta tesis contribuyen al avance de la ingeniería de datos, no sólo
    al habilitar las capacidades de análisis de datos en los sistemas conscientes
    del contexto, sino también al proporcionar un mecanismo confiable para asegurar
    que los datos generados por esos sistemas puedan ser controlados y monitoreados
    continuamente usando el marco de control de uso de datos propuesto en esta tesis.
    More information Item ID 69244 DC Identifier https://oa.upm.es/69244/ OAI Identifier
    oai:oa.upm.es:69244 DOI 10.20868/UPM.thesis.69244 Deposited by Archivo Digital
    UPM 2 Deposited on 12 Jan 2022 08:45 Last Modified 11 Jul 2022 22:30 Statistics
    Export citation Edit (repository staff only) Grouped by ... Date Subject Document
    Institution Department Degree Masters Author Editor Director Datos Investigación
    Plan Gestión Datos PGDonline EcienciaDatos Funders Unión Europea Gobierno de España
    Comunidad de Madrid Funders'' policies Especial Collections Cream Of Science TFG/TFM
    Cooperación Last deposited Other Formats Atom RSS 2.0 RSS 1.0 OAI 2.0 This repository
    Contact Help Software Tweets por el @archivoupm  Check whether the anglo-saxon
    journal in which you have published an article allows you to also publish it under
    open access.  Check whether the spanish journal in which you have published an
    article allows you to also publish it under open access. Archivo Digital UPM is
    the institutional digital repository maintained by the Library at the Universidad
    Politécnica de Madrid. Developed and maintained in EPrints. Syndication: Atom,
    RSS 2.0 and RSS 1.0 (HTML) Harvesting: OAI 2.0'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: https://oa.upm.es/69244/1/JOSE_ANDRES_MUNOZ_ARCENTALES.pdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: Contribution to the advancement of data engineering for smart spaces through
    data usage control and context-aware systems
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

[
  {
    "DOI": "https://doi.org/10.3390/agriengineering5030081",
    "authors": [
      "Giuliana Bilotta",
      "Emanuela Genovese",
      "Rocco Citroni",
      "F. Cotroneo",
      "Giuseppe M. Meduri",
      "Vincenzo Barrile"
    ],
    "citation_count": 1,
    "full_citation": "",
    "full_text": "Citation: Bilotta, G.; Genovese, E.;\nCitroni, R.; Cotroneo, F.; Meduri,\nG.M.; Barrile, V. Integration of an\nInnovative Atmospheric Forecasting\nSimulator and Remote Sensing Data\ninto a Geographical Information\nSystem in the Frame of Agriculture\n4.0 Concept. AgriEngineering 2023, 5,\n1280\u20131301. https://doi.org/10.3390/\nagriengineering5030081\nAcademic Editors: Muhammad\nJehanzeb Masud Cheema,\nMuhammad Aqib, Ahmed Elbeltagi,\nSaddam Hussain and Shoaib Rashid\nSaleem\nReceived: 9 May 2023\nRevised: 18 June 2023\nAccepted: 30 June 2023\nPublished: 17 July 2023\nCopyright:\n\u00a9 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed\nunder\nthe\nterms\nand\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nAgriEngineering\nArticle\nIntegration of an Innovative Atmospheric Forecasting\nSimulator and Remote Sensing Data into a Geographical\nInformation System in the Frame of Agriculture 4.0 Concept\nGiuliana Bilotta 1\n, Emanuela Genovese 1, Rocco Citroni 2, Francesco Cotroneo 1, Giuseppe Maria Meduri 1\nand Vincenzo Barrile 1,*\n1\nDICEAM Department, Mediterranea University of Reggio Calabria, 89124 Reggio Calabria, Italy;\ngiuliana.bilotta@unirc.it (G.B.); emanuela.genovese@unirc.it (E.G.); francesco.cotroneo@unirc.it (F.C.);\ning.giuseppemariameduri@gmail.com (G.M.M.)\n2\nDepartment of Engineering, University of Palermo, 90128 Palermo, Italy; rocco.citroni@unipa.it\n*\nCorrespondence: vincenzo.barrile@unirc.it\nAbstract: In a world in continuous evolution and in which human needs grow exponentially ac-\ncording to the increasing world population, the advent of new technologies plays a fundamental\nrole in all \ufb01elds of industry, especially in agriculture. Optimizing times, automating machines, and\nguaranteeing product quality are key objectives in the \ufb01eld of Agriculture 4.0, which integrates\nvarious innovative technologies to meet the needs of producers and consumers while guaranteeing\nrespect for the environment and the planet\u2019s resources. In this context, our research aims to propose\nan integrated system using data coming from an innovative experimental atmospheric and forecast-\ning simulator (capable of predicting some characteristic climate variables subsequently validated\nwith local sensors), combined with indices deriving from Remote Sensing and UAV images (treated\nwith the data fusion method), that can give fundamental information related to Agriculture 4.0 with\nparticular reference to the subsequent phases of system automation. These data, in fact, can be\ncollected in an open-source GIS capable of displaying areas that need irrigation and fertilization and,\nmoreover, establishing the path of an automated drone for the monitoring of the crops and the route\nof a self-driving tractor for the irrigation of the areas of interest.\nKeywords: atmospheric simulator; unmanned aerial vehicles; satellite imagery; remote sensing;\ngeomatic techniques\n1. Introduction\nAgriculture 4.0 consists of an upgrade of the usual farming techniques and has the\nscope to create a more sustainable and ef\ufb01cient agriculture system that can produce higher\nyields while minimizing the impact on the environment. By using advanced technolo-\ngies, farmers can make more informed decisions, reduce waste, and optimize resource\nutilization, leading to a more sustainable and pro\ufb01table agriculture industry. Agriculture\n4.0 encompasses the advancement of precision farming and refers to all agricultural actions\nthat are based on a precise and accurate analysis of data and information acquired and\ntransferred using advanced tools and technology. This refers to the tools and techniques\nthat allow for the synergistic use of a variety of digital 4.0 technologies, allowing for the\nautomatic collection, integration, and analysis of data collected from the \ufb01eld, sensors, or\nother third-party sources. Agriculture 4.0 refers to the application of the Internet of Things\n(IoT), Big Data, arti\ufb01cial intelligence, and robotics to extend, accelerate, and improve the\nef\ufb01ciency of operations affecting the entire production chain [1].\nSome innovations are:\n\u2022\nProcess automation: thanks to the use of drones and sensors, it is possible to monitor\ncrops throughout their growth phase, as well as check the state of well-being or the\nAgriEngineering 2023, 5, 1280\u20131301. https://doi.org/10.3390/agriengineering5030081\nhttps://www.mdpi.com/journal/agriengineering\nAgriEngineering 2023, 5\n1281\nneed to irrigate and fertilize the soil. There are countless bene\ufb01ts associated with\ndrones in the context of the agricultural industry. In fact, they can be of help to farmers\nin acquiring data on the state of stress of plants and observing the movements of\nlivestock, but they can also allow the identi\ufb01cation of diseases in plants and animals,\nallowing timely interventions.\n\u2022\nThe use of GIS: thanks to this software that can integrate data of different natures,\nit is possible to ef\ufb01ciently determine (according to different parameters such as soil\npH, temperature, and humidity) the position of the crops, the land use, and the need\nfor fertilization and irrigation. It is also possible to carry out an analysis of historical\ndata to provide farmers with tools that allow them to choose the best conditions for\ntheir crops.\nOf fundamental importance is the sustainable management of the environment and\nthe planet\u2019s resources, including water. As is known, intelligent consumption of this\nresource is essential in the \ufb01eld of agriculture, [2]. Moreover, there are many studies\ncarried out on the automation of agricultural vehicles and the monitoring of crops and\nlivestock. The advent of robotics in agriculture has allowed numerous bene\ufb01ts, including\nan increase in productivity, the acceleration of operations in the procedures related to the\nmaintenance of cultivation, as well as safety during production processes and precision in\nthe analysis of the possible interventions to be carried out to optimize the harvest [3,4]. The\nGIS (Geographic Information System) is a crucial tool frequently utilized in the realm of\nAgriculture 4.0. It has numerous applications, particularly in precision agriculture, such as\nassessing the potential of agricultural waste to generate bioenergy [5]. Particularly useful\nare open-source GISs that allow for the implementation of internal functions (including\nforecasting ones) useful in various application \ufb01elds, also allowing interaction with external\ntechnologies in real time. As it is known, diverse data types can be incorporated into the\nGIS, including free satellite data, although many of these data are limited due to their\nlow resolution. As a result, higher spatial and temporal resolution multispectral UAV\nimages must be combined with this data to resolve this limitation. To address the issue of\nintegrating non-uniform data, data fusion techniques are frequently employed [6,7]. So,\nin the literature, extensive studies could be found regarding the technologies, materials,\nalgorithms, and protocols involved in this research, but less could be found regarding their\nintegration. The present research \ufb01ts into this context by proposing as the main novelty\nthe use of an atmospheric experimental simulator capable of providing punctual variables,\nwhich, together with local sensor data and the data fusion of satellite and drone images, are\nall managed by an open-source GIS capable of estimating fundamental parameters related\nto the cultivation and automation of agricultural vehicles. This estimation is in the frame\nof a strategic management of crops through the identi\ufb01cation of local optimal cultivation\ntypologies and the automation of optimal \ufb01eld route planning for both self-driving tractors\nand UAVs, which is further useful for tactical in-season crop monitoring to guide crop\nirrigation and fertilization management.\n2. Materials and Methods\nDuring experimentations, in order to identify areas that best \ufb01t the different possible\ntypologies of cultivation and to plan the routes of both self-driving tractors and UAVs, we\nhave used different systems, algorithms, and methodologies structured and integrated\nwith each other as schematically shown in the \ufb02ow diagram in Figure 1. Referred to in\nmore detail:\n\u2022\nAn open-source GIS, in particular the open-source QGIS;\n\u2022\nan innovative and experimental atmospheric simulator;\n\u2022\nsatellite and UAV images,\n\u2022\nlocal sensors;\n\u2022\nalgorithms and protocols for data transmission.\nAgriEngineering 2023, 5\n1282\nFigure 1. Flow diagram developed in the frame of Agriculture 4.0 concept illustrating the method-\nological scheme and the different integrated systems, algorithms, and methodologies aiming to\nidentify areas that best \ufb01t the different possible typologies of cultivation and to plan the optimal\nroutes of both self-driving tractors and UAVs as \ufb01nal products of the built strategic management\nsystem for crop irrigation and fertilization.\nFirstly, the atmospheric simulator (using as inputs the Digital Elevation Model (DEM)\nof the territory, weather sensor data, radar data, and very large-scale weather models) was\nused to obtain, as outputs, the punctual values of some characteristic weather variables:\nprecipitation, wind, pressure, and temperature, which were subsequently reprocessed to\nobtain DEM layers of these variables. (Weather variables such as precipitation, wind, pres-\nsure, and temperature are important for Agriculture 4.0 because they directly in\ufb02uence the\nenvironmental conditions that can have an impact on crops. Precipitation is crucial for the\nwater supply of plants; wind can affect growth and disease spread; atmospheric pressure\nprovides information about imminent climatic changes; and temperature in\ufb02uences plant\ngrowth and maturation). The validation of the results obtained was performed through\nthe combination of different ground truth devices: local sensors (soil moisture sensor, leaf\nwetness sensor, pH sensor, temperature and humidity sensor, and barometric pressure\nsensor), using wireless sensor network nodes (WSNn). This WSN was supported with the\nZigBee protocol (Texas Instruments, Dallas, TX, USA), an ATmega128L microcontroller\n(Microchip Technology Inc., Chandler, AZ, USA), and a solar cell module (Canadian Solar,\nGuelph, ON, Canada) with the aim of collecting information from various sensors and\npassing the information to a cloud server. Through the data fusion technique [8], we have\ncombined satellite data and UAV images to establish important indices used as an indica-\ntion of vegetation richness and to capture soil differences: NDVI (normalized difference\nvegetation index), LST (land surface temperature), NDMI (normalized difference moisture\nindex), and BSI (bare soil index). In particular, the satellite images used are:\n\u2022\nSentinel-2, Level 2A: Level 2A of Sentinel-2 processing includes a scene classi\ufb01cation\nand an atmospheric correction applied to Top-Of-Atmosphere (TOA) Level-1C or-\nthoimage products. Level-2A\u2019s main output is an orthoimage bottom-of-atmosphere\n(BOA) corrected re\ufb02ectance product.\n\u2022\nWorldView-3: capable of acquiring images at 31 cm panchromatic, 1.24 m multispec-\ntral, 3.7 m shortwave infrared, and 30 m CAVIS (clouds, aerosols, vapors, ice, and\nsnow) resolution.\nAs regards UAV images, a Micasense Altum Camera was used to capture multispectral\nphotos with a DJI Matrice 600 Pro. This camera is ideal for agricultural use since it can\ncollect photos of crops in both visible and infrared wavelengths at the same time. The drone\n\ufb02ew around 30 m above the ground, producing aerial GSD photos with a resolution of 5 cm.\nAll this information was processed by the GIS, which estimates the optimal automation\nAgriEngineering 2023, 5\n1283\nparameters and those relating to the cultivable areas. In particular, the algorithms used to\nidentify the cultivable areas are as follows:\n1.\nSpatial data analysis algorithms, in particular buffering, intersection, overlay, and\nclustering analysis, are useful for identifying areas of interest, evaluating the proximity\nof climatic data, sensor data, and DEM data, and carrying out comparative analyses\nbetween different areas.\n2.\nRaster analysis algorithms to extract information from raster data such as DEM and\nNDVI by calculating terrain statistics and identifying speci\ufb01c slope or elevation areas\nthat are best suited for certain crops.\n3.\nSupervised classi\ufb01cation algorithms such as random forest, support vector machine\n(SVM), and neural networks to classify image data to determine crop typology and\nto build a predictive model. These algorithms are available as plugins or additional\nextensions that can be installed and used within the QGIS environment.\nIn relation to the algorithms used for tractor automation, QGIS includes a number of\ntools and algorithms that can be used to perform routing analysis and route planning and\nalso supports the use of additional plugins and integration with other tools and libraries\nthat offer advanced routing and route optimization features. Speci\ufb01cally, the \u201cNetwork\nAnalysis Library (NAl)\u201d and \u201cpgRouting\u201d plugins were used to perform advanced routing\nanalysis within QGIS. These plugins offer optimized routing algorithms that take into\naccount factors such as obstacles, speed constraints, and speci\ufb01c preferences to calculate\noptimal routes, always keeping in mind the necessary use of GPS for positioning and\nreferenced cartography for displaying the position.\nAs regards the parameters, the output parameters for identifying the cultivable areas\nare as follows:\n1.\nCrop classi\ufb01cation map: Using the supervised or unsupervised classi\ufb01cation algo-\nrithms, it was possible to generate a crop classi\ufb01cation map that assigns the estimated\ncrop type to each area of the study area.\n2.\nCrop suitability assessment: Based on the analysis of climate data, local sensor data,\nDEM, and NDVI, it was possible to generate a crop suitability assessment for the\nstudy area.\n3.\nAnalysis of environmental characteristics: The analysis of climate data, local sensor\ndata, DEM, and NDVI provided information on the environmental characteristics of\nthe study area, including maps of temperature, precipitation, soil moisture, and soil\npH, which have been used to evaluate the adaptability of crops to local environmen-\ntal conditions.\n4.\nAnalysis report: They included statistics on the prevailing crops, indicators of crop\nsuitability, analyses of environmental characteristics, and other relevant information\nfor determining the type of cultivation in the study area.\n5.\nTabular output data: In addition to the maps and reports, tabular output data have\nbeen produced, which reports detailed information on the study area.\nIn relation to the automation of the tractor, the output parameters are GPS coordinates\n(in real time), driving routes (to maximize operation ef\ufb01ciency), speed control (to ensure\nsafe and ef\ufb01cient driving), sensor monitoring (to detect any obstacles, avoid collisions\nand ef\ufb01ciently manage the resources of the tractor), actuator control (to ensure precise\nand smooth driving according to the routes and instructions provided), ground condition\nmonitoring (to adapt the driving of the tractor, make decisions in real time and to optimize\nthe use of resources), alarms and warnings (to alert the operator or user in case of emergency\nsituations, unforeseen obstacles or technical problems during automated driving), and\nperformance monitoring (for operations management).\nThen, through Cannelloni software (written in C++11 and capable of transferring CAN\nframes between two machines using UDP) and a series of protocols (datagram protocol\n(UDP) or stream control transmission protocol (SCTP), which are supported by Cannelloni\nsoftware. In some cases, it is necessary to convert SCTP to the transmission control protocol\nAgriEngineering 2023, 5\n1284\n(TCP)). The data are transmitted to the agricultural vehicle, which will have the task of\nirrigating and fertilizing the area according to the vegetation\u2019s needs, and to the drone,\nwhich will have the task of monitoring the existing cultivation. As a result, it is possible to\nvisualize the different typologies on the GIS of areas suitable for cultivation related to land,\nwater, and climate parameters.\n2.1. Geogra\ufb01c Information System\nGeographic Information System (GIS) technology is increasingly being used in agri-\nculture to help farmers make better decisions and optimize their farming practices. GIS is a\nsystem that allows for the capture, storage, analysis, and visualization of geographic data,\nsuch as crop yields, soil characteristics, weather patterns, and other relevant information.\nBy integrating this information with other data sources, farmers can gain insights into their\noperations and make more informed decisions.\nGIS can help farmers in various ways, such as:\n\u2022\nLand use planning: GIS can help farmers make informed decisions about the best\nuse of their land. It can be used to analyze factors such as soil type, topography, and\nclimate to determine the best species to crop in a particular area.\n\u2022\nMarket analysis: it can be used to analyze market trends and demand for certain crops.\n\u2022\nDisaster management: GIS can be used to monitor and respond to natural disasters\nsuch as \ufb02oods, droughts, and wild\ufb01res. By quickly identifying affected areas, farmers\ncan take appropriate action to protect their crops and minimize losses.\nIn our research, GIS plays a central role in the management of the information collected\nfrom different sources and in the return of important information related to Agriculture\n4.0. In fact, the choice of the optimal areas for cultivation depends on several factors that\ncan affect the yield and quality of the crop, which include climate, type of soil, irrigation,\ntopography, and market needs. In the following study, QGIS (an open-source GIS) was\nused, which consists of software that allows one to process, display, and analyze geographic\ndata such as maps, satellite images, sensor data, etc., using the Python language. This\ntype of software, which is entirely updatable, has therefore allowed the automation of the\nmanagement of geographical data, the creation of customized scripts for data analysis, and\nthe creation of customized tools for data visualization.\n2.2. Atmospheric Simulator\nThe main novelty of this research is the use of an atmospheric simulator [9] that,\nthrough a DEM and radar/sensor data, can provide important climate information in rela-\ntion to the orographic characteristics of the land. This article outlines the functioning of an\natmospheric simulator that has the ability to generate highly detailed weather \ufb01eld outputs\nwithin a restricted domain. With minimal input, this software can produce outputs related\nto wind, temperature, humidity, cloud cover, rain, and other atmospheric parameters for\ncubic cells as small as 50 m. Unlike NWP (numerical weather prediction), the simulator\u2019s\natmosphere microphysics is based on laws that regulate the interaction of a number of\nparticles with which the atmosphere has been discretized. The latter, in fact, consists of\na set of particles contained in the center of a cube (cells). Each of these particles contains\nwithin it a speci\ufb01c quantity of gas, water, and humidity from which its mass exchanges and\ninteractions with other particles and the external environment are de\ufb01ned. The particles\nwill be subjected to a force derived from their energy state, from interaction with other\nparticles, or from the surface.\nEssentially, the simulator emulates the behavior of the Earth\u2019s atmosphere as it relates\nto weather patterns and represents the state of variation of the particles with which the\natmosphere has been discretized and how they interact with each other. The simulation\nmodel incorporates two solvers, L1 and L2, which work in tandem and process tasks at\na higher level. These solvers translate the phenomena of the troposphere and vertical\nexchange into a particle representation of the atmosphere.\nAgriEngineering 2023, 5\n1285\n2.2.1. Solver 1\nSolver L1 is responsible for several tasks, including assigning physical and chemical\nproperties to particles, applying forces to particles based on their energy state from interac-\ntions with radiation and heat sinks, assigning initial states to particles and environmental\nelements, dividing the 3D domain into macro-clusters, and providing atomically referable\nforecast \ufb01elds for each. Real-time data or hypothetical values can be used as input.\n2.2.2. Solver 2\nOn the other hand, Solver L2 is a Newtonian Simulator that utilizes the values of force,\nmass, viscosity, and local density assigned by Solver L1 to individual particles. It employs\na software library for \ufb02uid modeling called SPH (smoothed particle hydrodynamics) [10]\nthat specializes in realistic simulations of \ufb02uids or gases within a few hundred meters.\nThe library is developed by Nvidia, and the technology is called Nvidia PhysX. Solver\nL2 introduces the forces attributed to the particles by L1 and initiates dynamic evolution\nthrough PhysX using SPH Fluids rules. For instance, if there is local interpenetration of cells\nat time t, repulsion forces come into play according to the represented parameters, such\nas partial compressibility, friction, viscosity, and mass. This mechanism represents winds,\nincluding complex turbulence characterizations and localized pressure variations, such\nas convective or ascending situations, in the 3D domain. The mechanism is particularly\neffective in complex orographic regions, such as the Apennines, where sudden altitude\nvariations are challenging to manage with classic NWP (numerical weather prediction).\n2.2.3. General Diagram of the Simulator\nThe initialization of Solver L2 involves reading an ASCII DEM that will serve as the\norographic domain of the simulation. The particles are positioned uniformly on the scene\nand evolve until a point of stability is reached. Solver L1 processes the initial conditions\nobtained from measurements, such as sensors or radar, and provides directives for assigning\nforces, velocities, and positions to particles in speci\ufb01c spatial volumes (clusters) to Solver\nL2. L2 evolves by applying these directives for a speci\ufb01ed time interval, and Solver L1 is\ninformed of the new state of particles at the end of the evolution, including their position,\nvelocity, density, and changes compared to the previous state. Solver L1 then associates\nthe attributes provided by L2 with particle and atmospheric state-related characteristics\nsuch as humidity and temperature. The pattern detector (part of L1) creates clusters with\nhomogeneous atmospheric characteristics such as cloud cover, rain, humidity, average\ntemperature, and pressure from the states provided by Solver L2. The values referred to as\nclusters are the output provided by the simulator.\nThe L1 now has the following inputs, which are no longer initial conditions: Pattern\ndetector clusters, internal phenomenological conditions such as the position of the sun\nor the orography as seen from the point of view of atmospheric heat absorption, and\ncoarse-scale boundary conditions, which are only required at the boundaries of the domain.\nThe processed output then becomes directives for the new evolutionary step for L2, thus\nclosing the feedback loop.\nFor this research, we have used a workstation with 3 GPUs con\ufb01gured in SLI mode\nwith 17280 CUDA CORE and 36 GB of video memory, in addition to 12 CORE Intel CPUs,\na dedicated CPU Intel I7-10810U, and 16 GB RAM. This workstation was built to operate\nand cover an area of 60 km \u00d7 60 km.\nThe advantages of this simulator are obvious:\n\u2022\nallows you to have a general view of how some weather variables can evolve in a small\narea and with high resolution, providing valid outputs in the selected area of interest;\n\u2022\nanalyzes inhomogeneous data of different nature, therefore different in quality\nand quantity;\n\u2022\nuse hardware components that are affordable and do not limit their use to specialized\npersonnel only;\n\u2022\noperates at the microscale.\nAgriEngineering 2023, 5\n1286\nFigure 2 shows the architecture of the experimental software.\n2.3. Sensors and Communication Protocols\nResources such as fertilizers, seeds, and water, the latter of which has become in-\ncreasingly precious for a farmer, are indispensable but unfortunately not in\ufb01nite resources.\nToday, with the development of new technologies, the concept of intelligent or precision\nagriculture has been introduced, which makes it possible to maximize crops while mini-\nmizing the resources indicated above. The introduction of increasingly performing sensors\ninstalled on the ground allows small-scale information to be provided to the farmer on\ncrops, minimizing resources and reducing the impact on the environment [11\u201315]. The\nconcept of modern agriculture is based on numerous physical and chemical measurements.\nThis is possible considering sensors and Internet of Things (IoT) networks. Based on this\nconcept, sensors in agriculture are primarily used to measure properties in soil, plants,\nair, and water. A sensor is a transducer designed to convert one physical quantity into\nanother, usually an electrical signal. The latter will have to meet requirements such as the\ntransmission, processing, storage, display, recording, and control of information. A real\nscenario is shown in Figure 3, which shows the real functioning of smart farming.\nAgriEngineering 2023, 5, FOR PEER REVIEW  \n7 \n \n \ndetector clusters, internal phenomenological conditions such as the position of the sun or \nthe orography as seen from the point of view of atmospheric heat absorption, and coarse-\nscale boundary conditions, which are only required at the boundaries of the domain. The \nprocessed output then becomes directives for the new evolutionary step for L2, thus clos-\ning the feedback loop. \nFor this research, we have used a workstation with 3 GPUs con\ufb01gured in SLI mode \nwith 17280 CUDA CORE and 36 GB of video memory, in addition to 12 CORE Intel CPUs, \na dedicated CPU Intel I7-10810U, and 16 GB RAM. This workstation was built to operate \nand cover an area of 60 km \u00d7 60 km. \nThe advantages of this simulator are obvious: \n\u2022 \nallows you to have a general view of how some weather variables can evolve in a \nsmall area and with high resolution, providing valid outputs in the selected area of \ninterest; \n\u2022 \nanalyzes inhomogeneous data of di\ufb00erent nature, therefore di\ufb00erent in quality and \nquantity; \n\u2022 \nuse hardware components that are a\ufb00ordable and do not limit their use to specialized \npersonnel only; \n\u2022 \noperates at the microscale. \nFigure 2 shows the architecture of the experimental software. \n \nFigure 2. Architecture of the experimental software illustrating the connection of the two solvers \naiming to determine the variables useful to identify the di\ufb00erent possible typologies of cultivation. \n2.3. Sensors and Communication Protocols \nResources such as fertilizers, seeds, and water, the latter of which has become increas-\ningly precious for a farmer, are indispensable but unfortunately not in\ufb01nite resources. \nToday, with the development of new technologies, the concept of intelligent or precision \nagriculture has been introduced, which makes it possible to maximize crops while mini-\nmizing the resources indicated above. The introduction of increasingly performing sen-\nsors installed on the ground allows small-scale information to be provided to the farmer \non crops, minimizing resources and reducing the impact on the environment [11\u201315]. The \nFigure 2. Architecture of the experimental software illustrating the connection of the two solvers\naiming to determine the variables useful to identify the different possible typologies of cultivation.\nAs regards local sensor communication, wireless sensor nodes (WSNs) [16\u201323] com-\nmunicate via their radio modules. If two or more nodes can send and receive data from\neach other, they are directly connected. The result is a network able to transmit/receive\ndata to/from each other, collecting large amounts of data. The bene\ufb01t for WSNs is due to\ntheir connection without wiring infrastructure. Today, WSNs represent a robust, simple,\nand complete wireless solution for agriculture, improving quality and productivity.\nThe elements that constitute a sensor node are mainly sensing, storage, processing,\nand communication capabilities, as shown in Figure 4. Part A is composed of several\nsensors, such as a temperature sensor, humidity sensor, rain sensor, leaf wetness sensor,\nZigBee protocol [24\u201326], ATmega128L microcontroller, and solar cell module, that support\nthis WSN. Communication protocols play a major role in intelligent IoT-based agriculture\nand cover short or long distances for smart farming. Wireless protocols/technologies\nAgriEngineering 2023, 5\n1287\nthat are used in agricultural applications are, for short distances, ZigBee and Wi-Fi, and\nfor long distances, mobile communication networks, long-range wireless area networks\n(LoRaWAN), Bluetooth, and LPWAN protocols. Among microcontrollers, the most used\nin agriculture are ATmega128L nodes because this microcontroller supports multi-level\ndata aggregation, decision making, storage capabilities, \ufb02ash memory, low complexity,\nand energy management. Traditionally, batteries limited in size and capacity in\ufb02uence\nthe lifetime of WSNs. Today, solutions such as the combination of ultra-low-power nodes\nwith energy-harvesting techniques make WSNs perpetually operational. Part B indicates\ntwo components\u2014special nodes usually called sinks, hubs, or gateways in the literature,\ndepending on their function\u2014are added when the network needs to coordinate or commu-\nnicate with an external network. Actuators allow for indirect intervention in the operation\nor control of mechanisms. The sink node passes all information to the cloud platform. All\nsensor, sink, and actuator nodes adopted the low-power ZigBee wireless protocol. This\ninformation obtained from sensors and governed by actuators is then transmitted via a\ngateway to cloud computing for data processing and storage, as shown in Part C. The task\nof the gateway is to collect information from various sensors and pass the information to\nthe cloud server [27\u201333].\nAgriEngineering 2023, 5, FOR PEER REVIEW  \n8 \n \nconcept of modern agriculture is based on numerous physical and chemical measure-\nments. This is possible considering sensors and Internet of Things (IoT) networks. Based \non this concept, sensors in agriculture are primarily used to measure properties in soil, \nplants, air, and water. A sensor is a transducer designed to convert one physical quantity \ninto another, usually an electrical signal. The latter will have to meet requirements such \nas the transmission, processing, storage, display, recording, and control of information. A \nreal scenario is shown in Figure 3, which shows the real functioning of smart farming. \n \nFigure 3. Smart farming-based Internet of Things (IoT): (A) agricultural sensor nodes with associ-\nated sensors and solar cells; (B) sink and actuator nodes; and (C) gateway nodes and cloud compu-\nting. \nAs regards local sensor communication, wireless sensor nodes (WSNs) [16\u201323] com-\nmunicate via their radio modules. If two or more nodes can send and receive data from \neach other, they are directly connected. The result is a network able to transmit/receive \ndata to/from each other, collecting large amounts of data. The bene\ufb01t for WSNs is due to \ntheir connection without wiring infrastructure. Today, WSNs represent a robust, simple, \nand complete wireless solution for agriculture, improving quality and productivity. \nThe elements that constitute a sensor node are mainly sensing, storage, processing, \nand communication capabilities, as shown in Figure 4. Part A is composed of several sen-\nsors, such as a temperature sensor, humidity sensor, rain sensor, leaf wetness sensor, \nZigBee protocol [24\u201326], ATmega128L microcontroller, and solar cell module, that support \nthis WSN. Communication protocols play a major role in intelligent IoT-based agriculture \nand cover short or long distances for smart farming. Wireless protocols/technologies that \nare used in agricultural applications are, for short distances, ZigBee and Wi-Fi, and for \nlong distances, mobile communication networks, long-range wireless area networks (Lo-\nRaWAN), Bluetooth, and LPWAN protocols. Among microcontrollers, the most used in \nagriculture are ATmega128L nodes because this microcontroller supports multi-level data \naggregation, decision making, storage capabilities, \ufb02ash memory, low complexity, and \nenergy management. Traditionally, batteries limited in size and capacity in\ufb02uence the life-\ntime of WSNs. Today, solutions such as the combination of ultra-low-power nodes with \nenergy-harvesting techniques make WSNs perpetually operational. Part B indicates two \ncomponents\u2014special nodes usually called sinks, hubs, or gateways in the literature, de-\nFigure 3. Smart farming-based Internet of Things (IoT): (A) agricultural sensor nodes with associated\nsensors and solar cells; (B) sink and actuator nodes; and (C) gateway nodes and cloud computing.\nFigure 3 represents the area where the deployment of a mobile network is bene\ufb01cial\nin the agricultural sector for IoT devices such as sensors and terrestrial and aerial drones\nknown as UAVs, which require constant, reliable, wide coverage, low energy consumption,\nlow-cost devices, high spectrum ef\ufb01ciency, and high-speed Internet connections to exchange\nlarge amounts of data. Data transmitted by sensors on the ground and captured by sensors\non board the drone are processed, analyzed, and then stored in a cloud data repository\nthrough a communication link. This swift transfer of data to the cloud is possible in\nreal time thanks to common communications protocols between sensors/vehicles and\noperators. Typically, agricultural drones are used for low-altitude \ufb02ights below 120 m and\nuse Wi-Fi, with a limited range of 3\u20137 km if on board the drone is a large transmitting\nantenna. Alternatively, for wireless control, the use of a 4G network link seems to alleviate\nthe distance problem, allowing the drone to \ufb02y several kilometers away from the controller.\nTo increase the range of UAVs, the 5G mobile network is suitable to promote low-\ufb02ying\ndrone communications and enhance the safety and security of drone operations. Moreover,\n5G cellular networks allow farmers to receive real-time data, such as high-resolution\nvideo streams and other critical sensory and telemetry data from drones, faster and more\nAgriEngineering 2023, 5\n1288\nseamlessly than with previous-generation mobile networks. Drones do not need to be\nequipped with large amounts of processing power, and 5G technology allows all data to\nbe transmitted to the cloud for faster processing. Today, cellular technologies are playing\na crucial role in IoT devices. Narrow-band IoT (NB-IoT) is a new IoT system protocol\nderived from the current long-term evolution (LTE) capabilities that can share the LTE\nfrequency band without coexistence problems, use the same devices, and seamlessly\nconnect to the LTE main network. NB-IoT design shows high coverage area, extended\nbattery life (i.e., 10 years), high network size (52,000 devices/channel/cell), and low-cost\ndevices. In the near future, NB-IoT technologies such as long-range radio (LoRa) will be\npreferred for transmitting agricultural information over long distances due to their low\npower consumption. In a point-to-point Zigbee network, the communication range can\nreach 100 m in an outdoor environment. ZigBee\u2019s range can be extended by employing ad\nhoc distributed and mesh network topologies. In addition, drones and UAVs can be used\nas mobile router nodes to extend the communication range within smart farming. Drones\ncan pass data collected from sensor nodes to master nodes through multi-hop [34,35].\nAgriEngineering 2023, 5, FOR PEER REVIEW  \n9 \n \noperation or control of mechanisms. The sink node passes all information to the cloud \nplatform. All sensor, sink, and actuator nodes adopted the low-power ZigBee wireless \nprotocol. This information obtained from sensors and governed by actuators is then trans-\nmitted via a gateway to cloud computing for data processing and storage, as shown in \nPart C. The task of the gateway is to collect information from various sensors and pass the \ninformation to the cloud server [27\u201333].  \n \nFigure 4. Study area referring to the experimentation of the atmospheric simulator. The area in ques-\ntion, located in the province of Reggio Calabria, south of Italy, is highlighted with a red line. (Image \nextrapolated from QGIS, Google Satellite base map). \nFigure 3 represents the area where the deployment of a mobile network is bene\ufb01cial \nin the agricultural sector for IoT devices such as sensors and terrestrial and aerial drones \nknown as UAVs, which require constant, reliable, wide coverage, low energy consump-\ntion, low-cost devices, high spectrum e\ufb03ciency, and high-speed Internet connections to \nexchange large amounts of data. Data transmitted by sensors on the ground and captured \nby sensors on board the drone are processed, analyzed, and then stored in a cloud data \nrepository through a communication link. This swift transfer of data to the cloud is possi-\nble in real time thanks to common communications protocols between sensors/vehicles \nand operators. Typically, agricultural drones are used for low-altitude \ufb02ights below 120 \nm and use Wi-Fi, with a limited range of 3\u20137 km if on board the drone is a large transmit-\nting antenna. Alternatively, for wireless control, the use of a 4G network link seems to \nalleviate the distance problem, allowing the drone to \ufb02y several kilometers away from the \ncontroller. To increase the range of UAVs, the 5G mobile network is suitable to promote \nlow-\ufb02ying drone communications and enhance the safety and security of drone opera-\ntions. Moreover, 5G cellular networks allow farmers to receive real-time data, such as \nhigh-resolution video streams and other critical sensory and telemetry data from drones, \nfaster and more seamlessly than with previous-generation mobile networks. Drones do \nnot need to be equipped with large amounts of processing power, and 5G technology al-\nlows all data to be transmitted to the cloud for faster processing. Today, cellular technol-\nogies are playing a crucial role in IoT devices. Narrow-band IoT (NB-IoT) is a new IoT \nsystem protocol derived from the current long-term evolution (LTE) capabilities that can \nshare the LTE frequency band without coexistence problems, use the same devices, and \nseamlessly connect to the LTE main network. NB-IoT design shows high coverage area, \nextended battery life (i.e., 10 years), high network size (52,000 devices/channel/cell), and \nFigure 4. Study area referring to the experimentation of the atmospheric simulator. The area in\nquestion, located in the province of Reggio Calabria, south of Italy, is highlighted with a red line.\n(Image extrapolated from QGIS, Google Satellite base map).\nSensors Used in the Study\nIn the study, \ufb01ve types of sensors that measure important soil characteristics were\nmainly used: Soil moisture sensor, leaf wetness sensor, pH sensor, temperature and hu-\nmidity sensor, and barometric sensor. As is known, one of the limitations of using point\nmeasurement sensors is their representativeness of soil or vegetation parameter variability\nwithin a \ufb01eld. In fact, point measurements provide information at a speci\ufb01c location, but\nthey may not fully capture the spatial variability of the parameters of interest. While\naware of the limitations, we have used these local sensors because they have been useful to\nvalidate the reliability of the model given by the atmospheric simulator.\nSoil moisture sensors are commonly used in agriculture to help farmers determine\nwhen to irrigate their crops, as overwatering can be costly and damaging to the crops, and\nunderwatering can also be detrimental. They can also be used in landscaping to ensure that\nplants are receiving the appropriate amount of water. Information given by the soil Moisture\nSensor (we have used the TEROS 12 soil moisture sensor (Meter Environment, Washington,\nDC, USA) is of fundamental importance in agriculture; in fact, thanks to this instrument,\nfarmers can measure the volumetric water content in the soil\u2014which is the amount of water\npresent in the soil as a percentage of the total volume of the soil\u2014and manage the irrigation\nsystem in a productive way. This type of sensor uses different technologies with which the\nAgriEngineering 2023, 5\n1289\ncontent of water is measured indirectly through speci\ufb01c parameters such as the dielectric\nconstant. As is known, there are two categories of soil moisture sensors depending on the\ntechnology they use: sensors that measure volumetric water content (VWC) and sensors\nthat measure soil tension when placed in the soil pro\ufb01le. Volumetric content is the volume\nof liquid water in the soil, usually expressed as a percentage. Soil water tension indicates,\ninstead, the energy required by plant roots to extract water from soil particles. As soil\nwater is removed from the soil, soil tension increases. The three most common types of soil\nmoisture sensors are:\n1.\nElectromagnetic sensors: The most common electromagnetic sensors are capacitance\nsensors or frequency domain re\ufb02ectometry (FDR) sensors and time domain re\ufb02ectom-\netry (TDR) sensors. These sensors indirectly measure VWC based on the dielectric and\nelectric properties of the soil medium (soil bulk permittivity or soil dielectric constant).\nThe dielectric constant is a measure of the substance\u2019s ability to store electrical energy.\nSince soil particles, water, and air all have different dielectric constants, their ability to\nstore or dissipate electrical energy is different.\n2.\nCapacitance or frequency domain sensors: Typically, these sensors are in the form of\ntwo parallel rods (two electrodes) or a pair of metal rings (two electrodes) mounted\nalong the length of a PVC pipe. The capacitor along the length of the PVC pipe allows\nsimultaneous measurements of soil moisture at different depths. Portable capacitance\nprobes also allow measurements at several locations through access tubes. When\nelectric current passes through these electrodes, they form an electromagnetic \ufb01eld\nin the soil. The probe measures the permittivity of a soil medium by measuring the\ncharge time of a capacitor made with that medium and thus the soil water content.\n3.\nTime domain re\ufb02ectometry (TDR) sensors: Time domain re\ufb02ectometry (TDR) sensors\nconsist of two or three parallel rods inserted into the soil, acting as waveguides.\nWhen a de\ufb01ned voltage pulse is sent to the sensor, it travels along the waveguide.\nWhen this pulse reaches the end of the waveguide, it re\ufb02ects back. The oscilloscope\nconnected to the sensor measures this re\ufb02ection. As the soil\u2019s water content increases,\nthe dielectric constant of the soil also increases. Consequently, the travel time of\nthe pulse decreases, and thus, the soil moisture content can be estimated using the\ncalibration equation [36].\nA leaf wetness sensor is a device used to measure the amount of moisture present on\nthe surface of leaves. It is often used in agriculture to help farmers determine the optimal\ntime for irrigation or to prevent fungal diseases that may occur due to prolonged leaf\nwetness. The sensor works by measuring the electrical resistance between two conductive\nplates, or probes, that are placed on the surface of the leaf. By monitoring the changes in\nresistance over time, the sensor can detect when the leaf becomes wet and when it dries\nout. Leaf wetness sensors may also include temperature and humidity sensors to provide\nadditional environmental data that can help farmers make more informed decisions about\nirrigation and disease management. In particular, in this study, we have used the AccuPAR\nLP-80 Leaf Wetness Sensor: The LP-80 Leaf Wetness Sensor consists of a \ufb02at surface that\nis placed in contact with the leaves. It utilizes electrical resistance or capacitive sensing\ntechnology to detect the presence or absence of moisture on the leaf surface. By measuring\nthe wetness level, the sensor can provide valuable information for various applications,\nsuch as determining optimal irrigation schedules, assessing plant health, and monitoring\ndisease conditions [37].\nA pH sensor is a device used to measure the acidity or alkalinity of a liquid or\nsoil. A pH sensor works by using a probe or electrode that is sensitive to changes in\nhydrogen ion concentration. Modern pH sensors may also include temperature sensors\nand microprocessors to automatically compensate for changes in temperature and provide\nmore accurate readings. pH sensors are widely used in agriculture for monitoring and\nmaintaining the pH levels of soil, water, and nutrient solutions used for crop growth. pH\nsensors are essential in agriculture because pH levels directly affect the plant\u2019s ability to\ntake up nutrients from the soil or water. They are also used in hydroponic farming to\nAgriEngineering 2023, 5\n1290\nmonitor the nutrient solutions used to grow plants that grow in water. In particular, for\nthe experimentation, we have used the HALO wireless Soil pH meter (Hanna Instruments,\nInc., Padova, Italy) [38].\nA temperature and humidity sensor is a device used to measure the temperature and\nrelative humidity of the surrounding air. It is commonly used in environmental monitoring\nsystems, greenhouses, and HVAC (heating, ventilation, and air conditioning) systems.\nTemperature and humidity sensors are widely used in agriculture to monitor environmental\nconditions in crop production areas. These sensors are essential in agriculture because\ntemperature and humidity levels directly affect plant growth and health. The applications\nof these sensors also include the monitoring of environmental conditions in greenhouses\nand the control of pest infestations. Pests thrive in speci\ufb01c conditions, and thanks to this\ntype of sensor, farmers can identify conditions that favor pest populations. For the study,\nwe have used BI-SENSOR (Maher Smart Agrocontrollers, Almeria, Spain) [39].\nA barometric pressure sensor is an instrument used to measure atmospheric pressure.\nIt is commonly used in weather monitoring systems, aviation, and altimeters.\nThe sensor works by using a thin, \ufb02exible membrane, typically made of silicon, that\nis exposed to the atmosphere. As atmospheric pressure changes, the membrane expands\nor contracts, causing a corresponding change in the electrical resistance of the sensor.\nModern barometric pressure sensors may also include temperature sensors to compensate\nfor temperature-related changes in atmospheric pressure. This compensation is necessary\nbecause temperature affects the density of air, which in turn affects atmospheric pressure.\nAtmospheric pressure is an essential factor in determining weather patterns and can affect\ncrop growth and yield. Barometric sensors are used in several ways in agriculture, including\nweather forecasting and livestock management. In the study, we used the Digital Barometer\nPS-0060-AD (Netsens Sensing the Environment, Firenze, Italy) [40].\n2.4. Self-Driving Remote Controlled Tractor in Smart Agriculture\nSelf-driving tractors are autonomous vehicles that use advanced technologies such\nas sensors, cameras, GPS, and machine learning algorithms. Autonomous tractors are\nbecoming increasingly popular in the agriculture industry as they offer numerous bene\ufb01ts\nto farmers. One of the main advantages of self-driving tractors is their ability to operate\naround the clock, which increases the ef\ufb01ciency of farming operations. They can work\ncontinuously without the need for rest breaks or sleep, which can be particularly useful\nduring critical periods such as planting and harvesting seasons. Self-driving tractors also\noffer greater precision and accuracy in farming operations. They can operate with high\nlevels of accuracy and repeatability, which can help reduce the use of fertilizers, pesticides,\nand other inputs, leading to improved crop yields and reduced costs. Moreover, self-\ndriving tractors can be programmed to work in various weather conditions and terrains,\nwhich helps reduce soil erosion and improve overall soil health. They can also operate in\nhazardous conditions or environments that may be dangerous for human operators.\nThanks to improvements in several \ufb01elds of engineering, autonomous and remote-\ncontrol studies today allow increased productivity in agriculture [41\u201344]. With a remote\ncontrol, the tractor is operated by a person from a remote area, considering data from\ntractor cameras and sensors. TX/RX of data is possible if requirements such as latency\nand bandwidth for video and control data transfer are veri\ufb01ed. A remote-control system\nincludes cameras, sensors, collision avoidance sensors, and control devices. ISO 11783,\ncommonly known as ISOBUS, is a communication standard that allows a link between\ntractors. ISOBUS is based on the SAE J1939 protocol, which includes the controller area\nnetwork (CAN) and allows electronic control units (ECUs) to communicate through the\nCAN bus. Autonomous control algorithms for agricultural tractors use communication\nbased on the ISOBUS standard. The Cannelloni software allows the connection of area\nnetwork controllers on a local area network. However, data transmission over the Internet\nor a mobile network using this software is not secure. Control of the tractor is based on\nthe CAN bus, whose protocol allows a bit rate of up to 1 Mbps. The components inside\nAgriEngineering 2023, 5\n1291\nthe tractor to remotely drive the tractor are a remote-controlled cabin, a remote-controlled\ntractor, and a computer for CAN tunneling on a mobile network [45].\nAll network traf\ufb01c is over a virtual private network (VPN) connection, and commu-\nnication data among devices occurs on the same local area network. A router connects\nthe tractor to the tactical network using various mobile networks. By default, the router\nuses all these connections simultaneously and switches between them to provide the best\npossible service. The target of the remote control is to verify the possibility of remote\ncontrol of the tractor through various trial networks. This is possible by sending CAN\nmessages over the network. SocketCAN [46,47] allows the CAN interface to be controlled\nand programmed as a standard network interface. The Cannelloni tool allows CAN data\nto be transferred over an Ethernet tunnel. Cannelloni supports tunneling over UDP (user\ndatagram protocol) or SCTP (stream control transmission protocol). The two protocols\nshow substantial differences. In fact, SCTP is fast but unreliable in receiving data, while\nSCTP provides reliable transport but is slower. The secure shell protocol (SSH) is used to\ntransfer the CAN traf\ufb01c over the network and encrypt it. However, the SSH port is not\ncompatible with SCTP. It is needed to convert SCTP to the transmission control protocol\n(TCP). This step is possible using the Socat utility. On board the tractor and remote-control\ncabin is a Raspberry Pi 4 computer connected to the local CAN using a Kvaser USB adapter.\nThe Raspberry Pi onboard the tractor represents a client, allowing a connection to the server\nRaspberry Pi computer on the remote-control cabin. The remote-control cab server has a\nknown address on the Internet, while the tractor may be behind the network address trans-\nlation (NAT) and/or \ufb01rewall of the mobile operator. The tractor software will constantly\ntry to establish a connection to the server. If the connection to the server is lost, the client\nwill keep trying to establish a new connection. The devices on the tractor generate a lot of\nCAN traf\ufb01c, but much of it is not relevant to remote control. The same also applies to the\nremote-control cabin. So, a \ufb01lter has been inserted so that only the requested messages pass\nthrough. Filtering is achieved by modifying the Cannelloni software to regulate outgoing\nand incoming traf\ufb01c [48].\n2.5. Data Fusion Method for Remote Sensing and UAV Images\nData fusion involves merging data from different sensors, platforms, or domains to\ncreate a single, integrated data set. The purpose of data fusion is to enhance the accuracy,\nreliability, and completeness of data and to improve the performance of decision-making\nsystems. By integrating information from different sources, data fusion can help identify\npatterns, trends, and relationships that may not be apparent from individual sources alone.\nData fusion has numerous applications in various \ufb01elds, including defense, aerospace,\nmedicine, transportation, and environmental monitoring. For example, in military op-\nerations, data fusion can be used to combine data from multiple sensors, such as radar,\ninfrared, and acoustic sensors, to provide a more complete picture of the battle\ufb01eld. In\nhealthcare, data fusion can be used to combine data from various medical devices and\nsensors to monitor patient health and provide better care. In this case study, we have\ncombined remote sensing and UAV data.\nToday, real-time information in several application \ufb01elds can be obtained thanks to\na variety of sensors on board UAVs. These \ufb02ight objects receive large amounts of data\n(e.g., large amounts of images), and for this reason, it is needed to introduce intelligent\nalgorithms capable of receiving different types of data and converting them into valuable\nand concise information. To overcome this problem, the trend today is to use multiple\nsensor data fusions capable of handling not only data from UAVs but also data from regular\nrevisit times in high-resolution satellite imagery. So, the use of UAVs allows for obtaining\nperiodic data, while the combination of satellites maintains a \ufb01ne spatial resolution in the\nlarge area of observation [49\u201352]. However, the data obtained from UAVs and satellites\nare used separately; the goal is to merge them through data fusion techniques to obtain\nimages useful for determining the indices useful for agriculture, bearing in mind all the\nadvantages and disadvantages deriving from UAVs and satellite data sources, which differ\nAgriEngineering 2023, 5\n1292\nin \ufb02exibility, cloud dependence, direct meteorological constraint, operator requirements,\ndata management, and payload [53\u201357].\nThe \u201cdata fusion\u201d strategy (spatial-spectral) aims to create datasets with advanced\nfeatures by combining one or more resolutions from each source. This strategy, designed to\nextract the biophysical properties of land cover and vegetation cover at high resolution,\nis currently little used in \ufb01elds such as agriculture. The fusion of satellite and UAV data\noffers a range of advantages, including improved spatial and temporal resolution, greater\ncustomization, and more detailed and comprehensive information. However, there are\nalso some disadvantages, such as the limited coverage of drones compared to satellites,\nhigher costs and more complex logistics, restrictions related to weather conditions, and the\nmanagement of collected data. In particular, the fusion spatial-spectral method is useful to\nimprove the spectral resolution of low-cost UAV sensor imagery and the accuracy of land\ncover classi\ufb01cation [58,59]. Spatiotemporal is used in data analysis when data are collected\nover both space and time. It describes a phenomenon at a particular place and time. The\nfusion spatial-temporal method is useful to obtain biophysical parameters (leaf area index\nand chlorophyll content) of crops and make consistent predictions with \ufb01ne spatial patterns.\nThe spectral resolution of an image describes the frequency of the electromagnetic spectrum\ncollected by the satellite. This spectral characteristic allows different features to be seen\nas separate entities. The temporal resolution of an image is de\ufb01ned as the amount of time\nneeded to revisit and acquire data for the exact same location. The fusion spatial-temporal\nmethod is used to obtain information in multispectral satellite data with hyperspectral data\nfrom a UAV [60,61]. The obtained results allow for obtaining biophysical variables (e.g.,\nleaf area index and chlorophyll content). Finally, the satellite/UAV data fusion improved\nthe performance of the model compared to data obtained individually from satellite or\nUAV due to satellite-based spectral characteristics and structural characteristics obtained\nfrom UAVs [62,63].\nAs is known, remote sensing techniques could be an important tool to ground infor-\nmation on the characteristics of vegetation through the production of significant vegetation\nindices. This information can be collected by multispectral and hyperspectral systems using\noptical sensors, and thanks to these, it is possible to analyze some fundamental indices in\nagriculture, such as the NDVI (normalized difference vegetation index), NDMI (normalized\ndifference moisture index), and BSI (bare soil index). In this research, Sentinel-2 satellite\nimages were used that have a spatial resolution of a decameter and a revisit time of six days,\ntogether with images captured by UAVs, which have a higher resolution and the possibility\nto catch details within the canopies with no difficulty thanks to their flexibility. The data\nutilized for this analysis included a Sentile-2 Level 2A image obtained on four different dates\n(17 May, 14 July, 30 August, and 25 September 2022) at 10:00 UTC, as well as a WorldView-3\nsatellite image taken on 17 November 2022. The WorldView-3 images are considered to be\none of the most detailed and precise commercial satellite images accessible to the public,\nwith a spatial resolution of approximately 30 cm per pixel, allowing for the detection of\nsmall objects on the Earth\u2019s surface, including cars, buildings, vegetation, and other features.\nIn addition, the multispectral images acquired by the DJI Matrice 600 Pro drone (SZ\nDJI Technology Co. Ltd., Shenzhen, China), which was equipped with a Micasense Altum\nCamera (AgEagle Aerial System Inc., Kansas, USA), were also utilized. This camera is well\nsuited for agricultural purposes and has the capability to capture images of crops in both\nvisible and infrared spectra simultaneously. The drone \ufb02ew at a height of approximately\n30 m above the ground, resulting in aerial GSD images with a resolution of 5 cm.\n3. Case Study\nThe study area chosen for the research is in Calabria (South Italy), in particular, in the\nmunicipality of Reggio Calabria, as shown in Figure 4.\nThe red line shows the application area of the simulator, while the application of the\nentire methodology was focused in a zone near the Castle of San Niceto, always in the\nMunicipality of Reggio Calabria, with an extent of 35 hectares.\nAgriEngineering 2023, 5\n1293\nThis area was chosen for different reasons:\n1.\nIt is a virgin area that has not been cultivated yet, so the GIS was able to show us the\nmost suitable area for cultivation.\n2.\nIt has a morphology suitable for using the simulator. In a few kilometers, there is\na sudden change in the orography of the land: one passes from a coastal area to an\nApennine area, and this allows the simulator to function properly as it takes the DEM\nof the area of interest as its initial input. The dimensioning described in Section 2 was\ndesigned to cover an area of 60 km \u00d7 60 km.\n3.\nIt is a small area, and therefore it is possible to apply the entire proposed system and\nhave detailed results.\n4. Results\nAll the data collected during the research were imported into a GIS that, using the\nmethodology in paragraph 2, displayed the main results of the activities we conducted.\nAs regards the atmospheric simulator software, Figure 5 shows a single frame extracted\nfrom the animation offered by the software, highlighting the positions of the particles of\nthe atmosphere in the domain of interest. In Figure 5, orography (derived from the DEM)\nis represented with the red color, while with blue dots, the positions of particles in the\natmosphere are shown according to the SPH model that rules the interactions between\nthem and their evolution over time.\nAgriEngineering 2023, 5, FOR PEER REVIEW  \n15 \n \n \nFigure 5. Frame extracted from the software showing the positions of the particles. The orographic \ntrend of the study area is highlighted in red, and the atmospheric particles are highlighted in blue. \nOnce the software is running, the Pattern Detector (part of Solver L1) creates clusters \nwith similar atmospheric characteristics, identifying rain, humidity, wind, pressure, etc. \nEach punctual value, referred to as Clusters, is the output provided by the simulator, \nwhich is then imported into the GIS. Below, it shows an example of the extrapolation of \nthe precipitation and wind values represented in Figure 6 with dots within the area of the \ncase study. One hundred dots with the respective values of these climatic variables were \nproduced by the simulator and reported to the GIS. In the speci\ufb01c case, the values ob-\ntained (also validated with the local sensors considering a tolerance of 10%) varied in a \nrange between 0 and 4 mm for the precipitation and in a range from 0 to 55 km/h for the \ngusts of wind. \nFigure 5. Frame extracted from the software showing the positions of the particles. The orographic\ntrend of the study area is highlighted in red, and the atmospheric particles are highlighted in blue.\nOnce the software is running, the Pattern Detector (part of Solver L1) creates clusters\nwith similar atmospheric characteristics, identifying rain, humidity, wind, pressure, etc.\nEach punctual value, referred to as Clusters, is the output provided by the simulator, which\nis then imported into the GIS. Below, it shows an example of the extrapolation of the\nprecipitation and wind values represented in Figure 6 with dots within the area of the\ncase study. One hundred dots with the respective values of these climatic variables were\nproduced by the simulator and reported to the GIS. In the speci\ufb01c case, the values obtained\n(also validated with the local sensors considering a tolerance of 10%) varied in a range\nbetween 0 and 4 mm for the precipitation and in a range from 0 to 55 km/h for the gusts\nof wind.\nAgriEngineering 2023, 5\n1294\n \nwhich is then imported into the GIS. Below, it shows an example of the extrapolation of \nthe precipitation and wind values represented in Figure 6 with dots within the area of the \ncase study. One hundred dots with the respective values of these climatic variables were \nproduced by the simulator and reported to the GIS. In the speci\ufb01c case, the values ob-\ntained (also validated with the local sensors considering a tolerance of 10%) varied in a \nrange between 0 and 4 mm for the precipitation and in a range from 0 to 55 km/h for the \ngusts of wind. \n \nFigure 6. Example of values extrapolated from the atmospheric simulator. The orange dots show \nthe precipitation and wind values (derived from the atmospheric simulator) imported into QGIS for \nprocessing and analysis. (Image extrapolated from QGIS, Google Satellite base map). \nFigure 6. Example of values extrapolated from the atmospheric simulator. The orange dots show\nthe precipitation and wind values (derived from the atmospheric simulator) imported into QGIS for\nprocessing and analysis. (Image extrapolated from QGIS, Google Satellite base map).\nIn order to identify the area more susceptible to adverse climatic events, we have\ninterpolated these values, creating the tridimensional map shown in Figures 7 and 8. The\ndistribution of climatic events can be variable according to the seasons and speci\ufb01c weather\nconditions. For an accurate prediction of adverse climatic events, it is necessary to use local\nmeteorological data. For this reason, an analysis of the data from the local weather stations\nin Calabria (which were used in the initialization phase of the simulator) was carried out.\nFrom this analysis, it emerged that, in principle, the areas most affected in Calabria are the\ncoastal areas and the mountainous areas.\nAgriEngineering 2023, 5, FOR PEER REVIEW  \n16 \n \nIn order to identify the area more susceptible to adverse climatic events, we have \ninterpolated these values, creating the tridimensional map shown in Figures 7 and 8. The \ndistribution of climatic events can be variable according to the seasons and speci\ufb01c \nweather conditions. For an accurate prediction of adverse climatic events, it is necessary \nto use local meteorological data. For this reason, an analysis of the data from the local \nweather stations in Calabria (which were used in the initialization phase of the simulator) \nwas carried out. From this analysis, it emerged that, in principle, the areas most a\ufb00ected \nin Calabria are the coastal areas and the mountainous areas. \n \nFigure 7. Tridimensional map derived from the interpolation of points (yellow dots) representing \nthe precipitation punctual values that have been determined by the atmospheric simulator. These \nvalues have been interpolated in the GIS to obtain a continuous representation of precipitation data \nrepresentative of the expected precipitation trend, reported in the \ufb01gure with di\ufb00erent shades of \nblue. \nFigure 7. Tridimensional map derived from the interpolation of points (yellow dots) representing\nthe precipitation punctual values that have been determined by the atmospheric simulator. These\nvalues have been interpolated in the GIS to obtain a continuous representation of precipitation data\nrepresentative of the expected precipitation trend, reported in the \ufb01gure with different shades of blue.\nAgriEngineering 2023, 5\n1295\n \n \nFigure 7. Tridimensional map derived from the interpolation of points (yellow dots) representing \nthe precipitation punctual values that have been determined by the atmospheric simulator. These \nvalues have been interpolated in the GIS to obtain a continuous representation of precipitation data \nrepresentative of the expected precipitation trend, reported in the \ufb01gure with di\ufb00erent shades of \nblue. \n \nFigure 8. Tridimensional map derived from the interpolation of points (yellow dots) representing \nthe wind punctual values that have been determined by the atmospheric simulator. These values \nFigure 8. Tridimensional map derived from the interpolation of points (yellow dots) representing the\nwind punctual values that have been determined by the atmospheric simulator. These values have\nbeen interpolated in the GIS to obtain a continuous representation of wind data representative of the\nexpected wind trend, reported in the \ufb01gure with different shades of red.\nAfter having evaluated Sentinel-2 and WorldView-3 images and UAV multispectral\nimages, a data fusion technique (which also leverages different sensors, such as soil mois-\nture sensors, to further enhance the overall understanding) [7] was performed in the area of\ninterest, determining the different interest indices such as the NDVI (normalized difference\nvegetation index), LST (land surface temperature), NDMI (normalized difference moisture\nindex), and BSI (bare soil index) useful for the planning and management of agricultural\nactivities. The choice fell into these indices because they are very relevant in the context of\nAgriculture 4.0 in order to have an indication of vegetation richness and to capture soil dif-\nferences [64]. As is known, to quantify the link between land surface temperature (LST) and\nvegetation, the normalized difference vegetation index (NDVI) is usually employed as an\nindication of vegetation richness. But the normalized difference moisture index (NDMI) is\nan alternative indicator. By studying the correlations between the land surface temperature\n(LST), the NDMI, and the NDVI, some studies show that the linear association between\nLST and NDMI is stronger, whereas the relationship between LST and NDVI is signi\ufb01cantly\nless and varies by month. The linear association between LST and NDMI steadily decreases\nas the seasons change from summer to fall. This \ufb01nding implies that NDMI, in addition to\nthe previously used NDVI, can be used to analyze LST. NDVI values range from \u22121.0 to\n1.0 in general, with negative values suggesting clouds and water, positive values near zero\nindicating bare soil, and higher positive values indicating sparse vegetation (0.1\u20130.5) to\nthick green vegetation (0.6 and above). The bare soil index (BSI) is a numerical indicator that\ncaptures soil differences by combining blue, red, near-infrared, and short-wave infrared\nspectral bands. These spectral bands are employed in a normalized fashion. The blue and\nnear-infrared spectral bands are utilized to highlight the presence of plants, whereas the\nshort-wave infrared and red spectral bands are employed to measure soil mineral content.\nBSI can be utilized in a variety of remote sensing applications, including soil mapping,\ncrop identi\ufb01cation (in conjunction with NDVI), and so on. In particular, Figure 9 shows an\napplication of the data fusion technique [7] used to calculate the NDVI in the study area.\nAgriEngineering 2023, 5\n1296\nin a normalized fashion. The blue and near-infrared spectral bands are utilized to high-\nlight the presence of plants, whereas the short-wave infrared and red spectral bands are \nemployed to measure soil mineral content. BSI can be utilized in a variety of remote sens-\ning applications, including soil mapping, crop identi\ufb01cation (in conjunction with NDVI), \nand so on. In particular, Figure 9 shows an application of the data fusion technique [7] \nused to calculate the NDVI in the study area. \n \nFigure 9. Example of data fusion technique applied, highlighting (VHR image) the calculation of an \nimportant index (NDVI) useful for determining vegetation richness. Data fusion techniques enable \nFigure 9. Example of data fusion technique applied, highlighting (VHR image) the calculation of\nan important index (NDVI) useful for determining vegetation richness. Data fusion techniques\nenable the acquisition of comprehensive information about an area and the associated cultivation\nrequirements by merging various data sources, including satellite data and UAV images. In particular,\nVHR (very high resolution) image: green = NDVI (normalized difference vegetation index) high;\nyellow = NDVI medium; red = NDVI low.\nOnce the data were collected from the multiple sources, we were enabled to identify using\nthe open-source GIS, in relation to climate parameters, sensor values, and indices deriving\nfrom satellite and UAV images (wind, soil type, soil moisture, NDVI . . . ), different types of\nareas suitable for the cultivation indicated with different capital letters (A, B, C, D . . . ) and\ngrouped for simplicity of treatment according to the parameters useful for the particular\ntypes of crops. Speci\ufb01cally, the available data have made it possible to identify in the study\narea exclusively three types of classes (A, B, and C) reported with different colors. Typology\nA (orange color): cultivation areas suitable for crops that do not need continuous irrigation.\nTypology B (green color): cultivation areas suitable for crops that need continuous irrigation.\nTypology C (yellow color): cultivation areas suitable for trees. Figure 10 shows the three\ndifferent typologies of cultivation.\nFinally, using the methodology and algorithms illustrated in paragraph 2, the GIS\nallowed us to establish the path of a drone used for monitoring existing crops and the path\nof an automatic tractor used for fertilization and irrigation. In Figure 11, the path of the\ndrone in an existing crop is shown with a blue line, the path of the tractor with a red line,\nand the points at which greater fertilization and irrigation interventions are required with\ngreen dots. Figure 10 shows the application of the methodology concerning the choice of\nthe different typologies of cultivation in a small portion of the study area. Figures 9 and 11,\nrepresenting the calculation of the NDVI and the optimal path of the drone and the tractor,\nrespectively, refer to a small area included within the larger area represented in Figure 10.\nAgriEngineering 2023, 5\n1297\n \nD\u2026) and grouped for simplicity of treatment according to the parameters useful for the \nparticular types of crops. Speci\ufb01cally, the available data have made it possible to identify \nin the study area exclusively three types of classes (A, B, and C) reported with di\ufb00erent \ncolors. Typology A (orange color): cultivation areas suitable for crops that do not need \ncontinuous irrigation. Typology B (green color): cultivation areas suitable for crops that \nneed continuous irrigation. Typology C (yellow color): cultivation areas suitable for trees. \nFigure 10 shows the three di\ufb00erent typologies of cultivation. \n  \nFigure 10. GIS showing the three di\ufb00erent typologies of cultivation, A, B, and C, reported in three \ndi\ufb00erent colors (letters and arrows are superimposed on the original image to better visualize the \ndi\ufb00erent typologies highlighted: typology A (orange color) represents cultivation areas suitable for \ncrops that do not need continuous irrigation; typology B (green color) represents cultivation areas \nsuitable for crops that need continuous irrigation; typology C (yellow color) represents cultivation \nareas suitable for trees. \nFinally, using the methodology and algorithms illustrated in paragraph 2, the GIS \nallowed us to establish the path of a drone used for monitoring existing crops and the path \nof an automatic tractor used for fertilization and irrigation. In Figure 11, the path of the \ndrone in an existing crop is shown with a blue line, the path of the tractor with a red line, \nand the points at which greater fertilization and irrigation interventions are required with \ngreen dots. Figure 10 shows the application of the methodology concerning the choice of \nthe di\ufb00erent typologies of cultivation in a small portion of the study area. Figures 9 and \n11, representing the calculation of the NDVI and the optimal path of the drone and the \ntractor, respectively, refer to a small area included within the larger area represented in \nFigure 10. \nFigure 10. GIS showing the three different typologies of cultivation, A, B, and C, reported in three\ndifferent colors (letters and arrows are superimposed on the original image to better visualize the\ndifferent typologies highlighted: typology A (orange color) represents cultivation areas suitable for\ncrops that do not need continuous irrigation; typology B (green color) represents cultivation areas\nsuitable for crops that need continuous irrigation; typology C (yellow color) represents cultivation\nareas suitable for trees.\nAgriEngineering 2023, 5, FOR PEER REVIEW  \n19 \n \n \nFigure 11. GIS, the optimal path of the tractor is shown with a red line, calculated within a cultivated \nportion of land. Within this cultivation, points requiring more irrigation and fertilization interven-\ntions have also been identi\ufb01ed and highlighted in green. The optimal path of the drone for monitor-\ning an existing cultivation is shown with a blue line. \n5. Discussion \nThe research conducted in this work aimed to experiment with and test an automatic \nintegration system for crop optimization and control. The methodology involves the inte-\ngration of an experimental atmospheric simulator, satellite and UAV images, local sensor \nFigure 11. GIS, the optimal path of the tractor is shown with a red line, calculated within a cultivated\nportion of land. Within this cultivation, points requiring more irrigation and fertilization interventions\nhave also been identi\ufb01ed and highlighted in green. The optimal path of the drone for monitoring an\nexisting cultivation is shown with a blue line.\nAgriEngineering 2023, 5\n1298\n5. Discussion\nThe research conducted in this work aimed to experiment with and test an automatic\nintegration system for crop optimization and control. The methodology involves the\nintegration of an experimental atmospheric simulator, satellite and UAV images, local\nsensor data, and data transmission protocols, all managed in an open-source GIS. The study\nfocused on identifying different types of cultivation and establishing optimal routes for\nan automated tractor and a drone to monitor crop growth and health. The research was\nconducted in a speci\ufb01c area in the province of Reggio Calabria, chosen for its suitability\nfor applying the various technologies described. Compared to similar approaches, this\nresearch demonstrates several strengths and weaknesses. One notable strength is the\ncomprehensive integration of multiple technologies, allowing for a holistic approach to\nAgriculture 4.0. Our experimentation enables a detailed understanding of crop conditions\nand facilitates precise fertilization/irrigation optimization. The tested method is part of\nAgriculture 4.0, which still has a number of weaknesses. In fact, the success of Agriculture\n4.0, and therefore also of the methodology proposed by us, relies on the availability of\naccurate and up-to-date data as well as the expertise required to interpret and utilize the\ncollected information effectively. Additionally, the initial setup costs and the need for\nskilled personnel to operate and maintain the system may pose challenges for widespread\nadoption. Despite these weaknesses (however intrinsic to Agriculture 4.0), this research\ncontributes valuable insights into the potential of Agriculture 4.0. The integration of\nvarious technologies and data sources offers a signi\ufb01cant advantage in optimizing irrigation\npractices and monitoring crop health. Clearly, the authors have given importance to the\nmethodology and not so much to the results, reserving the right to analyze them in more\ndetail through different skills for the subdivision of the areas suitable for cultivation. The\ntechnologies to be integrated within drones may be particularly promising, including\nincreasingly sophisticated sensors for the performance of different functions such as the\nvaporization of fertilizers or natural pesticides. In fact, evaporation and crystallization\nprocesses are currently prevalent in commercial fertilizer production facilities. As fertilizer\ndemand continues to rise and the availability of low-cost raw materials decreases, new\nfertilizer production technologies are being developed. Evaporation and crystallization\ntechniques have many applications in the fertilizer industry.\nThis research contributes to the advancement of Agriculture 4.0 by showing the\nintegration of different tools and techniques. While there are weaknesses to address, the\nbene\ufb01ts of adopting such integrated systems for precision agriculture are signi\ufb01cant. The\nresults of this work demonstrate the value of employing advanced technologies to optimize\nagricultural processes and pave the way for more ef\ufb01cient and sustainable agricultural\npractices in the future.\n6. Conclusions\nThe advantages of the proposed innovative system are evident in terms of time con-\nsumption, human resources, and productivity. In fact, the automation of some fundamental\nagricultural activities normally carried out by people saves time and costs. Furthermore,\nthe possibility of analyzing different types of data on soil conditions and the well-being\nof crops can increase productivity and quality and save a highly precious resource, water,\nwhich is instead managed according to what emerges from the weather variables provided\nby the simulator. The main novelty reported in this article lies precisely in the use of this\nsoftware, which, through a few input data, allows you to have an assessment of the weather\nconditions. Furthermore, although self-driving tractors are still relatively new, they are\nalready having a signi\ufb01cant impact on the agriculture industry. With the rapid advances in\ntechnology, it is likely that self-driving tractors will become more common in the future\nand will continue to transform the way farming is conducted.\nThis research focused on a speci\ufb01c area in the province of Reggio Calabria, leverag-\ning the morphological and orographic characteristics of the region for the application of\nvarious technologies. This demonstrates that, with proper planning and implementation,\nAgriEngineering 2023, 5\n1299\nsuch approaches can be adapted to speci\ufb01c agricultural contexts, thus maximizing the\nbene\ufb01ts obtained. The future developments of this research should focus \ufb01rst of all on\nspeeding up and optimizing data processing and data transmission protocols, possibly\nexperimenting with more ef\ufb01cient algorithms in terms of productivity and processing, and\nmoreover, on the validation and large-scale implementation of these integrated systems.\nCollaboration between research institutions, agricultural organizations, and farmers will\nbe crucial to promoting the adoption of these innovative solutions. The ultimate goal is\nto create a sustainable agricultural approach that ef\ufb01ciently utilizes available resources,\nreduces environmental impact, and is bene\ufb01cial for farmers. This requires the continuous\ndevelopment and adaptation of technologies and methods, taking into account the speci\ufb01c\nneeds of different crops, environmental conditions, and the farmers\u2019 requirements.\nAuthor Contributions: Conceptualization, V.B.; methodology, V.B. and E.G.; software, V.B., F.C. and\nR.C.; validation, F.C. and R.C.; formal analysis, V.B. and E.G.; investigation, G.M.M.; resources, V.B.,\nE.G., R.C., F.C., G.M.M. and G.B.; data curation, G.M.M., R.C. and G.B.; writing\u2014original draft\npreparation, V.B. and E.G.; writing\u2014review and editing, E.G. and G.B.; visualization, E.G. and G.B.;\nsupervision, V.B. and E.G.; project administration, V.B. and G.B. All authors have read and agreed to\nthe published version of the manuscript.\nFunding: This research received no external funding.\nData Availability Statement: Not applicable.\nCon\ufb02icts of Interest: The authors declare no con\ufb02ict of interest.\nReferences\n1.\nDe Clercq, M.; Vats, A.; Biel, A. Agriculture 4.0: The Future of Farming Technology; The World Government Summit: Dubai, United\nArab Emirates, 2018; pp. 11\u201313.\n2.\nMarkland, S.M.; Ingram, D.; Kniel, K.E.; Sharma, M. Water for agriculture: The convergence of sustainability and safety. Microbiol.\nSpectr. 2009, 5, PFS-0014-2016. [CrossRef]\n3.\nEdan, Y.; Han, S.; Kondo, N. Automation in agricolture. In Springer Handbook of Automation; Springer: Berlin/Heidelberg,\nGermany, 2009; pp. 1095\u20131128. [CrossRef]\n4.\nLi, M.; Imou, K.; Wakabayashi, K.; Yokoyama, S. Review of research on agricultural vehicle autonomous guidance. Int. J. Agric.\nBiol. Eng. 2009, 2, 1. [CrossRef]\n5.\nBharti, A.; Paritosh, K.; Mandla, V.R.; Chawade, A.; Vivekanand, V. GIS Application for the Estimation of Bioenergy Potential\nfrom Agriculture Residues: An Overview. Energies 2021, 14, 898. [CrossRef]\n6.\nAlvarez-Vanhard, E.; Corpetti, T.; Houet, T. UAV & satellite synergies for optical remote sensing applications: A literature review.\nSci. Remote Sens. 2021, 3, 100019. [CrossRef]\n7.\nBarrile, V.; Simonetti, S.; Citroni, R.; Fotia, A.; Bilotta, G. Experimenting Agriculture 4.0 with Sensors: A Data Fusion Approach\nbetween Remote Sensing, UAVs and Self-Driving Tractors. Sensors 2022, 22, 7910. [CrossRef] [PubMed]\n8.\nMaimaitijiang, M.; Sagan, V.; Sidike, P.; Daloye, A.M.; Erkbol, H.; Fritschi, F.B. Crop monitoring using satellite/UAV data fusion\nand machine learning. Remote Sens. 2020, 12, 1357. [CrossRef]\n9.\nVacondio, R.; Altomare, C.; De Leffe, M.; Hu, X.; Le Touz\u00e9, D.; Lind, S.; Marongiu, J.-C.; Marrone, S.; Rogers, B.D.; Souto-Iglesias,\nA. Grand challenges for smoothed particle hydrodynamics numerical schemes. Comput. Part. Mech 2020, 8, 575\u2013588. [CrossRef]\n10.\nSai, Z.; Fan, Y.; Yuliang, T.; Lei, X.; Yifong, Z. Optimized algorithm of sensor node deployment for intelligent agricultural\nmonitoring. Comput. Electron. Agric. 2016, 127, 76\u201386. [CrossRef]\n11.\nSrbinovska, M.; Gavrovski, C.; Dimcev, V.; Krkoleva, A.; Borozan, V. Environmental parameters monitoring in precision\nagriculture using wireless sensor networks. J. Clean. Prod. 2015, 88, 297\u2013307. [CrossRef]\n12.\nGang, L.L.L. Design of greenhouse environment monitoring and controlling system based on Bluetooth technology. Trans. Chin.\nSoc. Agric. Mach. 2006, 10, 97\u2013100.\n13.\nZhang, R.; Chen, L.; Guo, J.; Meng, Z.; Xu, G. An energy-ef\ufb01cient wireless sensor network used for farmland soil moisture\nmonitoring. In Proceedings of the IET Conference on Wireless Sensor Network, Beijing, China, 15\u201317 November 2010; pp. 2\u20136.\n[CrossRef]\n14.\nNavarro-Hell\u00edn, H.; Torres-S\u00e1nchez, R.; Soto-Valles, F.; Albaladejo-P\u00e9rez, C.; L\u00f3pez-Riquelme, J.; Domingo-Miguel, R. A wireless\nsensors architecture for ef\ufb01cient irrigation water management. Agric. Water Manag. 2015, 151, 64\u201374. [CrossRef]\n15.\nJawad, H.M.; Nordin, R.; Gharghan, S.K.; Jawad, A.M.; Ismail, M. Energy-Ef\ufb01cient Wireless Sensor Networks for Precision\nAgriculture: A Review. Sensors 2017, 17, 1781. [CrossRef] [PubMed]\n16.\nAzaza, M.; Tanougast, C.; Fabrizio, E.; Mami, A. Smart greenhouse fuzzy logic based control system enhanced with wireless data\nmonitoring. ISA Trans. 2016, 61, 297\u2013307. [CrossRef] [PubMed]\nAgriEngineering 2023, 5\n1300\n17.\nAiello, G.; Giovino, I.; Vallone, M.; Catania, P.; Argento, A. A decision support system based on multisensory data fusion for\nsustainable greenhouse management. J. Clean. Prod. 2017, in press. [CrossRef]\n18.\nKim, Y.; Evans, R. Software design for wireless sensor-based site-speci\ufb01c irrigation. Comput. Electron. Agric. 2009, 66, 159\u2013165.\n[CrossRef]\n19.\nOjha, T.; Misra, S.; Raghuwanshi, N.S. Wireless sensor networks for agriculture: The state-of-the-art in practice and future\nchallenges. Comput. Electron. Agric. 2015, 118, 66\u201384. [CrossRef]\n20.\nHaase, J. Wireless network standards for building automation. In Embedded Systems for Smart Appliances and Energy Management;\nSpringer: New York, NY, USA, 2013; pp. 53\u201365.\n21.\nSales, N.; Rem\u00e9dios, O.; Arsenio, A. Wireless sensor and actuator system for smart irrigation on the cloud. In Proceedings of the\nIEEE 2nd World Forum on Internet of Things (WF-IoT), Milan, Italy, 14\u201316 December 2015; pp. 693\u2013698.\n22.\nGuti\u00e9rrez, J.; Villa-Medina, J.F.; Nieto-Garibay, A.; Porta-G\u00e1ndara, M.\u00c1. Automated irrigation system using a wireless sensor\nnetwork and gprs module. IEEE Trans. Instrum. Meas. 2014, 63, 166\u2013176. [CrossRef]\n23.\nCancela, J.; Fandi\u00f1o, M.; Rey, B.; Mart\u00ednez, E. Automatic irrigation system based on dual crop coef\ufb01cient, soil and plant water\nstatus for Vitis vinifera (cv Godello and cv Menc\u00eda). Agric. Water Manag. 2015, 151, 52\u201363. [CrossRef]\n24.\nGeorgakakis, E.; Nikolidakis, S.A.; Vergados, D.D.; Douligeris, C. An analysis of bluetooth, Zigbee and bluetooth low energy and\ntheir use in Wbans. In Proceedings of the International Conference on Wireless Mobile Communication and Healthcare, Ayia Napa, Cyprus,\n18\u201320 October 2010; Springer: Berlin/Heidelberg, Germany; pp. 168\u2013175.\n25.\nHuirc\u00e1n, J.I.; Mu\u00f1oz, C.; Young, H.; Von Dossow, L.; Bustos, J.; Vivallo, G.; Toneatti, M. Zigbee-based wireless sensor network\nlocalization for cattle monitoring in grazing \ufb01elds. Comput. Electron. Agric. 2010, 74, 258\u2013264. [CrossRef]\n26.\nNadimi, E.S.; J\u00f8rgensen, R.N.; Blanes-Vidal, V.; Christensen, S. Monitoring and classifying animal behavior using zigbee-based\nmobile ad hoc wireless sensor networks and arti\ufb01cial neural networks. Comput. Electron. Agric. 2012, 82, 44\u201354. [CrossRef]\n27.\nRani, M.U.; Kamalesh, S. Energy ef\ufb01cient fault tolerant topology scheme for precision agriculture using wireless sensor network.\nIn Proceedings of the International Conference on Advanced Communication Control and Computing Technologies (ICACCCT),\nRamanathapuram, India, 8\u201310 May 2014; pp. 1208\u20131211. [CrossRef]\n28.\nRao, Y.; Jiang, Z.-H.; Lazarovitch, N. Investigating signal propagation and strength distribution characteristics of wireless sensor\nnetworks in date palm orchards. Comput. Electron. Agric. 2016, 124, 107\u2013120. [CrossRef]\n29.\nHarun, A.N.; Kassim, M.R.M.; Mat, I.; Ramli, S.S. Precision irrigation using wireless sensor network. In Proceedings of the\nInternational Conference on Smart Sensors and Application (ICSSA), Kuala Lumpur, Malaysia, 26\u201328 May 2015; pp. 71\u201375.\n[CrossRef]\n30.\nYeo, T.L.; Sun, T.; Grattan, K.T.V. Fibre-optic sensor technologies for humidity and moisture measurement. Sens. Actuators A Phys.\n2008, 144, 280\u2013295. [CrossRef]\n31.\nCao-Hoang, T.; Duy, C.N. Environment monitoring system for agricultural application based on wireless sensor network. In\nProceedings of the 2017 Seventh International Conference on Information Science and Technology (ICIST), Da Nang, Vietnam, 16\u201319 April\n2017; IEEE: Piscataway, NJ, USA, 2017; pp. 99\u2013102. [CrossRef]\n32.\nAli, A.; Shah, G.A.; Farooq, M.O.; Ghani, U. Technologies and challenges in developing machine-tomachine applications: A\nsurvey. J. Netw. Comput. Appl. 2017, 83, 124\u2013139. [CrossRef]\n33.\nSabri, N.; Aljunid, S.A.; Ahmad, R.; Malek, M.; Yahya, A.; Kamaruddin, R.; Salim, M. Smart prolong fuzzy wireless sensor-actor\nnetwork for agricultural application. J. Inf. Sci. Eng. 2012, 28, 295\u2013316.\n34.\nEdwards-Murphy, F.; Magno, M.; Whelan, P.M.; O\u2019Halloran, J.; Popovici, E.M. b+ WSN: Smart beehive with preliminary decision\ntree analysis for agriculture and honey bee health monitoring. Comput. Electron. Agric. 2016, 124, 211\u2013219. [CrossRef]\n35.\nFern\u00e1ndez-Pacheco, D.; Ferr\u00e1ndez-Villena, M.; Molina-Mart\u00ednez, J.; Ruiz-Canales, A. Performance indicators to assess the\nimplementation of automation in water user associations: A case study in southeast spain. Agric. Water Manag. 2015, 151, 87\u201392.\n[CrossRef]\n36.\nKumar, M.S.; Chandra, T.R.; Kumar, D.P.; Manikandan, M.S. Monitoring moisture of soil using low cost homemade Soil moisture\nsensor and Arduino UNO. In Proceedings of the 2016 3rd International Conference on Advanced Computing and Communication\nSystems (ICACCS), Coimbatore, India, 22\u201323 January 2016; IEEE: Piscataway, NJ, USA, 2016; Volume 1, pp. 1\u20134. [CrossRef]\n37.\nHornero, G.; Gait\u00e1n-Pitre, J.E.; Serrano-Finetti, E.; Casas, O.; Pallas-Areny, R. A novel low-cost smart leaf wetness sensor. Comput.\nElectron. Agric. 2017, 143, 286\u2013292. [CrossRef]\n38.\nYin, H.; Cao, Y.; Marelli, B.; Zeng, X.; Mason, A.J.; Cao, C. Soil sensors and plant wearables for smart and precision agriculture.\nAdv. Mater. 2021, 33, 2007764. [CrossRef] [PubMed]\n39.\nZhang, C.; Zhang, W.; Webb, D.J.; Peng, G.D. Optical \ufb01bre temperature and humidity sensor. Electron. Lett. 2020, 46, 643\u2013644.\n[CrossRef]\n40.\nGray, J.; Banhazi, T.M.; Kist, A.A. Wireless data management system for environmental monitoring in livestock buildings. Inf.\nProcess. Agric. 2017, 4, 1\u201317. [CrossRef]\n41.\nNoguchi, N.; Zhang, Q.; Han, S.; Reid, J.F. Autonomous Agricultural Tractor with an Intelligent Navigation System. IFAC Proc.\nVol. 2001, 34, 197\u2013202. [CrossRef]\n42.\nS\u00e1nchez-\u00c1lvarez, D.; Linaje, M.; Rodr\u00edguez-P\u00e9rez, F.-J. A Framework to Design the Computational Load Distribution of Wireless\nSensor Networks in Power Consumption Constrained Environments. Sensors 2018, 18, 954. [CrossRef] [PubMed]\nAgriEngineering 2023, 5\n1301\n43.\nKim, Y.; Evans, R.G.; Iversen, W.M. Remote sensing and control of an irrigation system using a distributed wireless sensor\nnetwork. IEEE Trans. Instrum. Meas. 2008, 57, 1379\u20131387. [CrossRef]\n44.\nNesa Sudha, M.; Valarmathi, M.L.; Babu, A.S. Energy ef\ufb01cient data transmission in automatic irrigation system using wireless\nsensor networks. Comput. Electron. Agric. 2011, 78, 215\u2013221. [CrossRef]\n45.\nCitroni, R.; Di Paolo, F.; Livrieri, P. Evaluation of an Optical Energy Harvester for SHM Applications. AEU-Int. J. Electron.\nCommun. 2019, 111, 152918. [CrossRef]\n46.\nGoodmill Systems.\nGoodmill Systems w24h-S Managed Multichannel Router.\nData Sheet.\nAvailable online:\nhttps:\n//goodmillsystems.com/application/\ufb01les/2615/8860/4850/Goodmill_w24h-S_Datasheet.pdf (accessed on 4 June 2023).\n47.\nSocketCAN\u2014Controller Area Network. Available online: https://www.kernel.org/doc/html/latest/networking/can.html\n(accessed on 4 June 2023).\n48.\nHeikkil\u00e4, M.; Suomalainen, J.; Saukko, O.; Kippola, T.; L\u00e4hetkangas, K.; Koskela, P.; Kalliovaara, J.; Haapala, H.; Pirttiniemi, J.;\nYastrebova, A.; et al. Unmanned Agricultural Tractors in Private Mobile Networks. Network 2022, 2, 1\u201320. [CrossRef]\n49.\nRen, H.; Zhao, Y.; Xiao, W.; Hu, Z. A review of UAV monitoring in mining areas: Current status and future perspectives. Int. J.\nCoal Sci. Technol. 2019, 6, 320\u2013333. [CrossRef]\n50.\nTorres, A.B.; da Rocha, A.R.; da Silva, T.L.C.; de Souza, J.N.; Gondim, R.S. Multilevel data fusion for the internet of things in\nsmart agriculture. Comput. Electron. Agric. 2020, 171, 105309. [CrossRef]\n51.\nRiefolo, C.; Belmonte, A.; Quarto, R.; Quarto, F.; Ruggieri, S.; Castrignan\u00f2, A. Potential of GPR data fusion with hyperspectral\ndata for precision agriculture of the future. Comput. Electron. Agric. 2022, 199, 107109. [CrossRef]\n52.\nSheng, H.; Chen, X.; Su, J.; Rajagopal, R.; Ng, A. Effective data fusion with generalized vegetation index: Evidence from land\ncover segmentation in agriculture. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition\nWorkshops, Seattle, WA, USA, 14\u201319 June 2020; pp. 60\u201366.\n53.\nCastrignan\u00f2, A.; Buttafuoco, G.; Quarto, R.; Parisi, D.; Rossel, R.V.; Terribile, F.; Langella, G.; Venezia, A. A geostatistical sensor\ndata fusion approach for delineating homogeneous management zones in Precision Agriculture. Catena 2018, 167, 293\u2013304.\n[CrossRef]\n54.\nOuhami, M.; Ha\ufb01ane, A.; Es-Saady, Y.; El Hajji, M.; Canals, R. Computer vision, IoT and data fusion for crop disease detection\nusing machine learning: A survey and ongoing research. Remote Sens. 2021, 13, 2486. [CrossRef]\n55.\nComba, L.; Biglia, A.; Aimonino, D.R.; Gay, P. Unsupervised detection of vineyards by 3D point-cloud UAV photogrammetry for\nprecision agriculture. Comput. Electron. Agric. 2018, 155, 84\u201395. [CrossRef]\n56.\nSentinel-2A Handbook Overview. Available online: https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/overview\n(accessed on 13 February 2023).\n57.\nCopernicus Open Access Hub. Available online: https://scihub.copernicus.eu/dhus/#/home (accessed on 13 February 2023).\n58.\nBarrile, V.; Bilotta, G. Self-localization by laser scanner and GPS in automated surveys. Lect. Notes Electr. Eng. 2014, 307, 293\u2013311.\n[CrossRef]\n59.\nAngiulli, G.; Barrile, V.; Cacciola, M. SAR imagery classi\ufb01cation using Multi-class Support Vector Machines. J. Electromagn. Waves\nAppl. 2005, 19, 1865\u20131872. [CrossRef]\n60.\nDeng, L.; Mao, Z.; Li, X.; Hu, Z.; Duan, F.; Yan, Y. UAV-based multispectral remote sensing for precision agriculture: A comparison\nbetween different cameras. ISPRS J. Photogramm. Remote Sens. 2018, 146, 124\u2013136. [CrossRef]\n61.\nFurukawa, F.; Laneng, L.A.; Ando, H.; Yoshimura, N.; Kaneko, M.; Morimoto, J. Comparison of RGB and Multispectral Unmanned\nAerial Vehicle for Monitoring Vegetation Coverage Changes on a Landslide Area. Drones 2021, 5, 97. [CrossRef]\n62.\nBarbedo, J.G.A. Data Fusion in Agriculture: Resolving Ambiguities and Closing Data Gaps. Sensors 2022, 22, 2285. [CrossRef]\n63.\nAyg\u00fcn, S.; G\u00fcne\u00b8s, E.O.; Suba\u00b8s\u0131, M.A.; Alkan, S. Sensor Fusion for IoT-based Intelligent Agriculture System. In Proceedings of\nthe 8th International Conference on Agro-Geoinformatics (Agro-Geoinformatics), Istanbul, Turkey, 16\u201319 July 2019; pp. 1\u20135.\n[CrossRef]\n64.\nQian, L.-X.; Cui, H.-S. Relationship between normalized difference moisture index and land surface temperature. Geogr. Res.\n2008, 27, 1358\u20131367.\nDisclaimer/Publisher\u2019s Note: The statements, opinions and data contained in all publications are solely those of the individual\nauthor(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to\npeople or property resulting from any ideas, methods, instructions or products referred to in the content.\n",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "journal": "AgriEngineering",
    "pdf_link": "https://www.mdpi.com/2624-7402/5/3/81/pdf?version=1689644405",
    "publication_year": 2023,
    "title": "Integration of an Innovative Atmospheric Forecasting Simulator and Remote Sensing Data into a Geographical Information System in the Frame of Agriculture 4.0 Concept"
  }
]
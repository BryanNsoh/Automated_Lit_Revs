[
  {
    "title": "Perspectives on label-free microscopy of heterogeneous and dynamic biological systems",
    "doi": "10.1117/1.JBO.29.S2.S22702",
    "description": "Significance: Advancements in label-free microscopy could provide real-time, non-invasive imaging with unique sources of contrast and automated standardized analysis to characterize heterogeneous and dynamic biological processes. These tools would overcome challenges with widely used methods that are destructive (e.g., histology, flow cytometry) or lack cellular resolution (e.g., plate-based assays, whole animal bioluminescence imaging). Aim: This perspective aims to (1)\u00a0justify the need for label-free microscopy to track heterogeneous cellular functions over time and space within unperturbed systems and (2)\u00a0recommend improvements regarding instrumentation, image analysis, and image interpretation to address these needs. Approach: Three key research areas (cancer research, autoimmune disease, and tissue and cell engineering) are considered to support the need for label-free microscopy to characterize heterogeneity and dynamics within biological systems. Based on the strengths (e.g., multiple sources of molecular contrast, non-invasive monitoring) and weaknesses (e.g., imaging depth, image interpretation) of several label-free microscopy modalities, improvements for future imaging systems are recommended. Conclusion: Improvements in instrumentation including strategies that increase resolution and imaging speed, standardization and centralization of image analysis tools, and robust data validation and interpretation will expand the applications of label-free microscopy to study heterogeneous and dynamic biological systems.",
    "journal": "Journal of biomedical optics",
    "authors": [
      "Pham D.L.",
      "Gillette A.A.",
      "Riendeau J.",
      "Wiech K.",
      "Guzman E.C.",
      "Datta R.",
      "Skala M.C."
    ],
    "citation_count": "0",
    "full_text": "",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "Spatial differentiation of carbon emissions from energy consumption based on machine learning algorithm: A case study during 2015\u20132020 in Shaanxi, China",
    "doi": "10.1016/j.jes.2023.08.007",
    "description": "Carbon emissions resulting from energy consumption have become a pressing issue for governments worldwide. Accurate estimation of carbon emissions using satellite remote sensing data has become a crucial research problem. Previous studies relied on statistical regression models that failed to capture the complex nonlinear relationships between carbon emissions and characteristic variables. In this study, we propose a machine learning algorithm for carbon emissions, a Bayesian optimized XGboost regression model, using multi-year energy carbon emission data and nighttime lights (NTL) remote sensing data from Shaanxi Province, China. Our results demonstrate that the XGboost algorithm outperforms linear regression and four other machine learning models, with an R2 of 0.906 and RMSE of 5.687. We observe an annual increase in carbon emissions, with high-emission counties primarily concentrated in northern and central Shaanxi Province, displaying a shift from discrete, sporadic points to contiguous, extended spatial distribution. Spatial autocorrelation clustering reveals predominantly high-high and low-low clustering patterns, with economically developed counties showing high-emission clustering and economically relatively backward counties displaying low-emission clustering. Our findings show that the use of NTL data and the XGboost algorithm can estimate and predict carbon emissions more accurately and provide a complementary reference for satellite remote sensing image data to serve carbon emission monitoring and assessment. This research provides an important theoretical basis for formulating practical carbon emission reduction policies and contributes to the development of techniques for accurate carbon emission estimation using remote sensing data.",
    "journal": "Journal of Environmental Sciences (China)",
    "authors": [
      "Cao H.",
      "Han L.",
      "Liu M.",
      "Li L."
    ],
    "citation_count": "2",
    "full_text": "Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Highlights Abstract Graphical Abstract Keywords Introduction 1. Materials and methods 2. Results and discussion 3. Conclusion and prospect Declaration of Competing Interest Acknowledgments Appendix. Supplementary materials References Show full outline Cited by (2) Figures (9) Show 3 more figures Tables (2) Table 1 Table 2 Extras (1) Document Journal of Environmental Sciences Volume 149, March 2025, Pages 358-373 Research Article Spatial differentiation of carbon emissions from energy consumption based on machine learning algorithm: A case study during 2015\u20132020 in Shaanxi, China Author links open overlay panel Hongye Cao 1 2, Ling Han 3 4, Ming Liu 3 4, Liangzhi Li 2 5 Show more Share Cite https://doi.org/10.1016/j.jes.2023.08.007 Get rights and content Highlights \u2022 We developed six machine learning models for predicting energy carbon emissions. \u2022 Estimating multi-level carbon combined nighttime light data with socioeconomic data. \u2022 Energy carbon emissions in Shaanxi Province have obvious spatial spillover effects. \u2022 Nighttime light data has great potential for energy carbon emissions. Abstract Carbon emissions resulting from energy consumption have become a pressing issue for governments worldwide. Accurate estimation of carbon emissions using satellite remote sensing data has become a crucial research problem. Previous studies relied on statistical regression models that failed to capture the complex nonlinear relationships between carbon emissions and characteristic variables. In this study, we propose a machine learning algorithm for carbon emissions, a Bayesian optimized XGboost regression model, using multi-year energy carbon emission data and nighttime lights (NTL) remote sensing data from Shaanxi Province, China. Our results demonstrate that the XGboost algorithm outperforms linear regression and four other machine learning models, with an R2 of 0.906 and RMSE of 5.687. We observe an annual increase in carbon emissions, with high-emission counties primarily concentrated in northern and central Shaanxi Province, displaying a shift from discrete, sporadic points to contiguous, extended spatial distribution. Spatial autocorrelation clustering reveals predominantly high-high and low-low clustering patterns, with economically developed counties showing high-emission clustering and economically relatively backward counties displaying low-emission clustering. Our findings show that the use of NTL data and the XGboost algorithm can estimate and predict carbon emissions more accurately and provide a complementary reference for satellite remote sensing image data to serve carbon emission monitoring and assessment. This research provides an important theoretical basis for formulating practical carbon emission reduction policies and contributes to the development of techniques for accurate carbon emission estimation using remote sensing data. Graphical Abstract Download : Download high-res image (328KB) Download : Download full-size image Previous article in issue Next article in issue Keywords Machine learningEnergy carbon emissionsNighttime lightSpatial distribution Introduction Since the industrialization era began in the 1860s, the rapid development of the industrial and electrical industries has driven the consumption of fossil fuels such as coal, oil, and natural gas, making them the most important energy sources globally (Zheng et al., 2021). Fossil energy not only serves as a vital material basis for human survival and development but also plays a crucial role in global and regional economic growth (Li et al., 2022). However, fossil energy is a non-renewable resource, and its extensive consumption has caused depletion, as well as the generation of greenhouse gasses and pollutants, resulting in a series of problems such as global energy reserve shortages, environmental pollution, and climate change. These issues pose serious obstacles to sustainable development of the world economy (Abbasi et al., 2022). Countries worldwide have come to realize that carbon emissions from fossil energy are the leading cause of global warming (Hansen et al., 2000). As a result, they have reached a consensus on the importance of global efforts to reduce emissions, opening up a path for global cooperation in combating climate change. A rational modeling of the spatial distribution of carbon emissions within a region serves as a crucial basis for formulating a clear and explicit carbon reduction strategy (Deng et al., 2018). To achieve this, scholars have mainly utilized two approaches, namely the \u201cbottom-up\u201d and \u201ctop-down\u201d approaches, to spatialize regional energy carbon emissions. The \u201cbottom-up\u201d approach aims to improve the accuracy of carbon emission spatialization by integrating a vast amount of fine-grained carbon emission source survey statistics and other means (Basu et al., 2020; Gurney et al., 2020). For instance, Cai and Wang (2013) established a 1-km spatial grid of carbon emissions in Tianjin, China, based on the carbon emission statistics of primary, secondary, and tertiary industries and spatial grid calculations in the GIS platform. Similarly, Gurney et al. (2020) collected and processed carbon dioxide emissions from fossil fuel (FF) combustion in 10 sectors, including residential, commercial, industrial, power production, highway, off-road, commercial vessel, airport, railroad, and cement, to develop a raster dataset of estimated FFCO2 for the continental United States and Alaska. However, obtaining data for the \u201cbottom-up\u201d approach, especially carbon emission source data for areas below the city and county level, is typically challenging. Additionally, compiling and organizing the data requires a considerable amount of time and effort, which may not align with the current demand for the spatial distribution simulation of carbon emissions, making it challenging to apply this approach to other regions on a large scale (Cai et al., 2020). With the rapid development of remote sensing technology, the Operational Linescan System (OLS) sensor carried by the Defense Meteorological Satellite Program (DMSP) of the U.S. military weather satellite has acquired global nighttime lights (NTL) data (Li et al., 2018). The NTL data can effectively detect low-intensity nighttime lights generated by urban NTL or even small-scale residential land and vehicle traffic and is a good data source for monitoring the intensity of human activities (Chen et al., 2021; Guo et al., 2016; Li et al., 2018). Many scholars have started to use NTL data to conduct a series of studies on human activity intensity and have achieved certain research results, for example, spatialization of GDP (Wu et al., 2013), spatial expansion of cities (Zheng et al., 2022), simulation of electricity consumption (Sun et al., 2021), and spatial and temporal changes in the population (Li and Zhou, 2018; Wang et al., 2020). As NTL data has the ability to effectively monitor human activities, it serves as a reliable data source for characterizing the intensity of human activities. Since production and living activities, primarily human activities, are the main drivers of carbon emissions, NTL data can be utilized to simulate carbon emissions (Shi et al., 2016; Zhang and Pan, 2019). The \u201ctop-down\u201d approach has gained significant attention due to the advantages of NTL data. This approach involves spatializing carbon emissions by integrating easily accessible NTL data and statistical data of energy consumption carbon emissions. The approach enables the conversion of carbon emissions spatial distribution information from administrative boundaries to image elements to clearly and objectively demonstrate the spatial and temporal distribution pattern of carbon emissions. The simulation of carbon emission values based on NTL data is a useful approach to compensate for incomplete statistical data, differing statistical calibers, and the unavailability of relevant energy consumption data below the municipal level. Based on the DMSP/OLS global NTL data, Elvidge et al. (1997) conducted a correlation analysis between NTL and GDP, electricity consumption, and carbon emissions for 21 countries worldwide, and were the first to find a correlation between NTL and carbon emissions. Chen et al. (2018) used NTL data to correct the GDP of the Yangtze River Economic Zone from 2014 to 2050 and predicted the peak of carbon emissions. Guo et al. (2016) simulated carbon emissions in Jiangsu Province in Chinaby administrative regions using DMSP/OLS and NDVI data. Doll et al. (2000) showed for the first time a strong linear regression model of NTL area and carbon emissions for 46 countries worldwide. Zhao et al. (2015) found a linear and exponential relationship between the DN values of NTL images and carbon emissions. Su et al. (2013) used DMSP/OLS NTL data to complete the simulation of China's carbon emissions at the municipal level from 1992 to 2010. Using the correlation analysis between NTL brightness and fossil fuel carbon emissions in China, Japan, Canada, Russia, India, and the United States, Ghosh et al. (2010) found a linear correlation between the two with a correlation coefficient of 076, indicating that the carbon emissions of major countries can be decomposed to the global network more accurately with the help of NTL images. The studies discussed above highlight the potential of using NTL data to estimate carbon emissions at multiple scales. However, further research is needed to expand and deepen our understanding of this approach. Specifically, there is a need for more studies at the city and county scales, as current research is mainly focused on global, national, and provincial scales. Additionally, while linear regression models have been commonly used in current research, there is room for improvement in terms of the goodness of fit and simulation effects of these models. Machine learning algorithms, which have been successfully applied in many fields, could be a promising approach to predicting nonlinear variables in carbon emission estimation. Machine learning algorithms have been widely used in many fields (Bessa and Pellegrino, 2018; Dai et al., 2022; Gupta et al., 2022; Han et al., 2019; He et al., 2022; Herrero-Huerta et al., 2020; Liu et al., 2023).For example, Geng et al. (2022) proposed a food safety risk prediction model based on an improved random forest prediction method with integrated Monte Carlo algorithm to protect and reduce food safety risks. Han et al. (2022) proposed a new dendritic network based on adaptive mean square gradient to predict and analyze the energy consumption of buildings. Wu et al. (2022) used radial basis function (RBF) neural network integrated with multidimensional scaling (MDS) (MDS-RBF) to propose a new modeling technique for industrial process capacity assessment and carbon reduction. This study focuses on Shaanxi Province, which is a significant energy-consuming region in China. The aim is to construct energy carbon emission prediction models using machine learning algorithms that integrate NTL data, basic geographic information data, and socioeconomic statistics. The study employs trend analysis and spatial autocorrelation models to analyze the evolution of carbon emissions at the city, county, and raster scales, as well as the dynamic spatial and temporal patterns. The results of this study can contribute to the formulation of targeted and effective regional carbon emission policies, and provide a scientific basis for the optimal distribution of energy resources in the region. Overall, this study has important implications for promoting sustainable development and reducing carbon emissions in Shaanxi Province. 1. Materials and methods The study was carried out in four stages (Fig. 1). Initially, data collection and processing were performed, which involved the integration of two types of NTL data (DMSP/OLS and NPP/VIIRS) to obtain time-series NTL data for Shaanxi Province from 2000 to 2017. The municipal-level energy consumption carbon emissions for the study area were determined using the energy consumption method. The NTL data and energy consumption carbon emissions data were combined to form a dataset that was divided into a training set and a test set in a 3:1 ratio. Next, six machine learning algorithms (KNN, MLP, RFR, SVR, XGboost, and LR) were applied to the training set, and the optimal parameters for each model were obtained through hyperparameter optimization. Subsequently, the accuracy of the algorithms was verified using the training set, and the optimal model was applied to the NTL data to obtain the spatial distribution of carbon emissions at the city and county levels in Shaanxi Province. Finally, the spatial distribution of carbon emissions was analyzed using trend analysis and spatial autocorrelation analysis, and policy recommendations were provided. This approach lays a foundation for providing region-specific carbon emission policies and the optimal layout of energy resources. Download : Download high-res image (686KB) Download : Download full-size image Fig. 1. Flowchart of energy carbon emission technology based on machine learning approach. KNN: K-Nearest Neighbor; SVR: support vector regression; MLP: Multi-Layer Perceptron; RFR: Random Forest Regression; LR: Linear Regression; XGboost: an extreme gradient boosting decision tree. 1.1. Study area The study area of this research is Shaanxi Province, which is located in China and covers an area of 205,600 km2 between 105\u00b029\u2032\u2212111\u00b015\u2032E and 31\u00b042\u2032\u221239\u00b035\u2032N (Fig. 2a). With the implementation of national development strategies such as \u201cWestern Development\u201d and \u201cOne Belt, One Road,\u201d the population in Shaanxi Province is increasing annually and the level of urbanization is gradually rising (Ahmad et al., 2018). Shaanxi Province is strategically important to China's modernization and all-around opening, with the third-largest reserves of petroleum and natural gas and the fourth-largest reserves of coal in China. As one of China's major mineral resource provinces, Shaanxi Province relies heavily on energy production to support stable economic growth, with an average total energy production of 145,925.96 tons of standard coal per 10,000 people by 2018 (Won et al., 2020). In recent years, energy demand and usage in Shaanxi Province have been on the rise, with industrial energy consumption expanding under the influence of increased large-scale production by energy-intensive enterprises. Energy consumption in 2020 has increased sixfold compared to 2000, with coal consumption accounting for the largest share, remaining at around 80% year-round (Fig. 2b and c). Download : Download high-res image (735KB) Download : Download full-size image Fig. 2. Study area (a), energy consumption (b), and percentage (c). 1.2. Data and processing 1.2.1. DMSP/OLS and NPP/VIIRS NTL data Currently, two satellite sensors, namely the Defense Meteorological Satellite Program Operational Line Scan System (DMSP/OLS) and the Suomi National Polar-orbiting Partnership-Visible Infrared Imaging Radiometer Suite (NPP/VIIRS), are used to acquire global-scale nighttime light (NTL) data (Chen et al., 2021; Yong et al., 2022).The DMSP/OLS NTL dataset provides a continuous time series for the period 1992\u20132013, while the NPP VIIRS NTL product is available from 2012 to the present. The National Oceanic and Atmospheric Administration's (NOAA) National Geographic Data Center (NGDC) was the source of the DMSP/OLS (2000\u20132013) and NPP/VIIRS (2012\u20132017) NTL data. The spatial resolution of the two datasets is 30 arc seconds (about 900 m) and 15 arc seconds (about 500 m), respectively, while the image DN (digital number) value ranges from 0 to 63 (Zhang and Pan, 2019). A larger DN value indicates a higher regional light intensity value (Yong et al., 2022). The DMSP/OLS data suffer from a lack of continuity and comparability between images of long time series as they are obtained from different sensors, and the DN values of single images are affected by oversaturation (Li et al., 2018; Li and Zhou, 2018; Lv et al., 2019). The NPP/VIIRS data mainly available as monthly nighttime light data, and annual light data require synthesis. Additionally, some DN values of NPP/VIIRS data have problems such as negative values, very high values, and unstable light sources (Zheng et al., 2019). Hence, to obtain stable NTL data for estimating carbon emissions over a long period, the aforementioned NTL data types need to be corrected. The processing procedure involved several steps: (i) reprojecting the DMSP/OLS and NPP/VIIRS data into the Albers equal area projection coordinate system, resampling the image resolution to 1 km, and using the research boundary vector data to crop the NTL data of the study area; (ii) correcting the DMSP/OLS images for each period using the invariant target area method to solve the problems of saturation, inter-image discontinuity, and incomparability (Lv et al., 2019; Yong et al., 2022); (iii) synthesizing the NPP/VIIRS monthly data into annual data and eliminating negative and extremely high values in the NTL data (Shi, 2017; Shi et al., 2016; Zhang and Pan, 2019); (iv) recorrecting the NPP/VIIRS data using the corrected DMSP/OLS NTL images as a reference. Specifically, the bright value region of DMSP/OLS images of the same years was used as a mask to extract the valid region in the NPP/VIIRS images assuming that the corrected DMSP/OLS images of 2012 and 2013 have the same bright value region as the NPP/VIIRS images of the same years. The overlapping data in time and space were used to fit and correct the NPP/VIIRS data for each period, and finally, the stable NTL data from 2000 to 2017 were obtained. As shown in Appendix A Fig. S1, the total corrected image DN values are continuous and comparable. This processing procedure enabled the production of long-time series stable NTL data for accurate carbon emission estimation. 1.2.2. Energy consumption and socioeconomic data The data used in this study comprised of consumption data for 12 major fossil energy sources, including raw coal, coke, crude oil, gasoline, kerosene, diesel, and natural gas, obtained from the Shaanxi Energy Statistical Yearbook and the Intergovernmental Panel on Climate Change (IPCC) Guidelines for National Greenhouse Gas Inventory Development, for the period 2000\u20132017. Additionally, socioeconomic data, such as population, economic development level, industrial structure, and built-up area, were obtained from the statistical yearbooks of Shaanxi Province and municipalities, also covering the period 2000\u20132017. Administrative boundary vector data were obtained from the National Basic Geographic Information Center in China. 1.3. Methods 1.3.1. Carbon emission statistics based on energy data In this study, we adopted the energy consumption method (Lv et al., 2019) to measure carbon emissions at the city level in Shaanxi province. Specifically, we utilized the carbon emission calculation coefficients from the IPCC Greenhouse Gas Emissions Inventory Guidelines, along with the end-use consumption of 12 major fossil energy sources (including raw coal, coke, crude oil, gasoline, kerosene, diesel, fuel oil, natural gas, heat, and electricity) from the Energy Consumption Balance Sheets (2000\u20132017) of municipalities in Shaanxi Province. This approach allowed us to accurately estimate carbon emissions associated with energy consumption in the study area. The calculation principle of the energy consumption method is as follows (Meng et al., 2017). (1) where, C (million tons) is the carbon emission; Ei is the i th energy consumption in terms of standard coal, in million tons. The 12 major fossil energy sources, including raw coal, crude oil, gasoline, washed coal, coke, kerosene, diesel, fuel oil, liquefied petroleum gas, natural gas, coke oven gas, and refinery dry gas, are selected in this paper; ki is the carbon emission coefficient of the ith energy source in (million tons of carbon emission)/(10,000 tons of standard coal); the energy conversion standard coal coefficient and carbon emission coefficient are shown in Appendix A Table S1. 1.3.2. Machine learning algorithms In the construction process of each model, the initial values of parameters are set according to the algorithmic characteristics and tuning experience of different models, and the Bayesian method is used for hyperparameter search (Bessa and Pellegrino, 2018; Wu et al., 2019). The best parameters (Table 1) of each model are obtained according to the evaluation index, the best parameters and training set are used for the construction of each machine learning model, and finally, the trained models are used for prediction. (1) KNN Table 1. Hyperparameters, search range, and optimal values of the machine learning methods. Method Hyperparameter Search range Optimal value KNN distance [\u2018Euclidean\u2019, \u2018Manhattan\u2019] Euclidean n_neighbors [1, 3, 5, 8, 10, 40] 5 weights [\u2018Uniform\u2019, \u2018Distance\u2019] Distance MLP hidden layer size [1, 3, 5, 10, 15, 20, 25, 30] 3 activation function [\u2018softmax\u2019, \u2018relu\u2019, \u2018tanh\u2019, \u2018sigmoid\u2019, \u2018linear\u2019] \u2018relu\u2019 learning rate [10\u22124, 10\u22123, 10\u22122, 10\u22121] 10\u22123 batch size [10, 20, 30, 40, 50, 60, 70, 80, 90] 30 RFR n_estimators [50, 100, 150, 200, 250, 300, 350, 400, 450, 500] 200 maximum features [\u2018auto\u2019, \u2018sqrt\u2019, \u2018log2\u2019] \u2018sqrt\u2019 max_depth [2, 4, 6, 8, 10, 12, 14, 16, 18, 20] 8 min_samples_leaf [1, 2, 4, 8, 10] 2 min_samples_split [1, 5, 10, 15, 20] 5 SVR C value [10\u22123, 10\u22122, 10\u22121, 1, 101, 102, 103] 10 kernel [\u2018linear\u2019, \u2018poly\u2019, \u2018rbf\u2019, \u2018sigmod\u2019] \u2018rbf\u2019 gamma [10\u22123, 10\u22122,10\u22121, 1] 10\u22121 XGboost learning_rate [10\u22124, 10\u22123, 10\u22122, 10\u22121] 10\u22121 n_estimators [10, 20, 30, 40, 50, 60] 40 max_depth [2, 4, 6, 8, 10, 12, 14, 16, 18, 20] 10 min_child_weight [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 5 gamma [0.10, 0.12, 0.14, 0.16, 0.18, 0.20] 0.12 The KNN regression model was first proposed by Cover and Hart (1967), and the model is considered to be one of the simplest algorithms in data mining classification and regression techniques. The so-called K nearest neighbors, take the average of the first K samples with the closest distance to the unknown sample to predict that unknown sample. Its core consists of three main elements: the selection of k-values, distance calculation, and weight determination (Modaresi et al., 2018). Although the model is simple in terms of hyperparameters, it can become computationally expensive as the number of samples becomes larger. The model is constructed with parameters and ranges: distance [\u2018Euclidean\u2019, \u2018Manhattan\u2019], n_neighbors [1, 3, 5, 8, 10, 40] and weights [\u2018uniform\u2019, \u2018distance\u2019]. By Bayesian hyperparameter optimization, the optimal parameters are distance = \u2018Euclidean\u2019, n_neighbors = 5, and weights = \u2018distance\u2019. (2) MLP MLP is a typical algorithm in machine learning, a well-known class of artificial neural networks (ANN) (Cheshmberah et al., 2020; Doreswamy et al., 2020). The network consists of an input layer, an implicit layer, and an output layer. The implicit layer of MLP can contain multiple layers, while the input and output layers have only one layer, and each layer is fully connected (fully connected: any neuron in the previous layer is connected to all neurons in the next layer). The model is constructed with parameters and ranges: hidden layer size [1, 3, 5, 10, 15, 20, 25, 30], activation function [\u2018softmax\u2019, \u2018relu\u2019, \u2018tanh\u2019, \u2018sigmoid\u2019, \u2018linear\u2019], learning rate [10\u22124, 10\u22123, 10\u22122, 10\u22121] and batch size [10, 20, 30, 40, 50, 60, 70, 80, 90]. By Bayesian hyperparameter optimization, the optimal parameters are hidden layer size = 3, activation function = \u2018relu\u2019, learning rate = 10\u22123and batch size = 30. (3) RF Random Forest is a decision tree-based machine learning method that can handle classification (RFC) and regression (RFR) problems (Breiman, 2001). RFR generates multiple mutually independent decision trees randomly based on the number of features, while training samples are randomly and replay fully drawn from the original dataset using bootstrap resampling as the training set for each decision tree (Yuan et al., 2017). The RFR model can handle high-dimensional data and evaluate the feature order, thus influencing the sample classification and limiting the interaction between features. An advantage of RFR modeling is that it is not subject to overfitting (Petukhova et al., 2018). The most important parameter of RFR is the number of trees; the more trees there are, the higher the accuracy of RFR predictions. The model is constructed with parameters and ranges: n_estimators [50, 100, 150, 200, 250, 300, 350, 400, 450, 500], maximum features [\u2018auto\u2019, \u2018sqrt\u2019, \u2018log2\u2019], max_depth [2, 4, 6, 8, 10, 12, 14, 16, 18, 20], min_samples_leaf [1, 2, 4, 8, 10] and min_samples_split [1, 5, 10, 15, 20]. By Bayesian hyperparameter optimization, the optimal parameters are n_estimators = 200, maximum features = \u2018sqrt\u2019, max_depth = 8, min_samples_leaf = 2 and min_samples_split = 5. (4) SVR Support vector regression (SVR) is an implementation of the support vector machine algorithm used to handle regression problems. This algorithm was proposed earlier in the field of machine learning, and its basic principle is to find a regression hyperplane between data labels and features so that all the data in the training samples are as close to this plane as possible (Liang et al., 2014). SVR uses the kernel function mapping method to map points in low-dimensional space to high-dimensional space through nonlinear transformation, making them linearly separable and building a linear model to solve nonlinear problems, which largely overcomes the problems of \u201cmany discrete values\u201d and \u201coverfitting\u201d (Liang et al., 2015). The three parameters that have the greatest influence on the modeling are the type of kernel function, the penalty parameter C, and the kernel parameter g. The SVR principle and calculation process are detailed in Liang et al. (2015) and Wang et al. (2009). The model is constructed with parameters and ranges: C-value [10\u22123, 10\u22122, 10\u22121, 1, 101, 102, 103], kernal [\u2018linear\u2019, \u2018poly\u2019, \u2018rbf\u2019, \u2018sigmod\u2019] and gamma [10\u22123, 10\u22122,10\u22121, 1]. By Bayesian hyperparameter optimization, the optimal parameters are C-value = 10, kernel = \u2018rbf\u2019 and gamma = 10\u22121. (5) XGboost The extreme gradient boosting (XGboost) tree algorithm is an integrated learning method based on gradient boosting decision tree (GBDT) implementation (Abedi et al., 2021). The base learner of GBDT uses regression trees, and each of its trees fits the negative gradient of the loss function on the previous tree, and finally, the results of all regression trees are linearly weighted and summed as the resultant output model (Li et al., 2020a). XGBoost is an efficient implementation of GBDT, and its base learners include classification trees and regression trees. The carbon emission estimation problem in this study is a regression problem, so the base learners used in the study are regression trees. Compared with the GBDT algorithm, XGBoost explicitly adds a regularization term to the objective function, and when updating the base learner, GBDT iteratively generates the base learner based on the first-order derivative, while XGBoost not only updates the base learner based on the first-order derivative but also based on the second-order derivative, in addition to a large number of optimizations in the implementation of the XGBoost algorithm (Liu et al., 2021; Yang et al., 2021). An XGBoost model with n trees can be represented as (Wang et al., 2021b): (2) where, is the estimated carbon emission value of the ith sample., xi is the input variable of the ith sample, fn is the prediction function of the nth decision tree, N is the number of decision trees. The XGBoost model update uses a gradient boosting strategy to update the model by updating the negative gradient direction of the loss function, and its optimization model can be expressed as: (3) (4) where, is the loss function, is the regularization term, is model complexity, is the quantized weight vector of the leaf nodes. The XGBoost model, based on retaining the trained tree model, continuously derives the prediction function according to the loss function, updates the prediction function by substituting the prediction function in the previous round, and finally obtains the prediction result through iterative calculation. The model is constructed with parameters and ranges: learning rate [10\u22124, 10\u22123, 10\u22122, 10\u22121], n_estimators [10, 20, 30, 40, 50, 60], max_depth [2, 4, 6, 8, 10, 12, 14, 16, 18, 20], min_child_weight [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] and gamma [0.10, 0.12, 0.14, 0.16, 0.18, 0.20]. By Bayesian hyperparameter optimization, the optimal parameters are learning rate = 10\u22121, n_estimators = 40, max_depth = 10, min_child_weight = 5, and gamma = 0.12. (6) LR Linear regression (LR) models are the simplest and most basic class of supervised learning models in machine learning. The main goal of LR is to consider a given number of data points and draw a best-fit line to fit the model in the best possible way. In this paper, we use the training set to construct a linear regression model (Fig. 3). (5) Download : Download high-res image (179KB) Download : Download full-size image Fig. 3. Scatterplot of the linear regression model. where, y is energy carbon emissions, and x is the DN of NTL. This paper builds KNN, MLP, RFR, SVM, and XGboost algorithms based on the scikit-learn package (sklearn for short, which provides a large number of machine learning algorithms) for python. These algorithms use the KNeighborsRegressor, MLPRegression, RandomForestRegressor, SVR, and XGBRegressor modules to build the models, respectively. The bayesian-optimization package of python for hyperparameter optimization was used in the study. 1.3.3. Statistical metrics The following evaluation metrics were used to compare the carbon emission from the estimated and statistical data: root-mean-square error (RMSE), and coefficient of determination (R2) between the carbon emission extracted from the estimated and statistical data. RMSE and R2 were calculated by the following formulas (Ma et al., 2020): (8) (9) where, xe is the estimated energy carbon emissions, is the mean value of estimated energy carbon emissions, xs is the statistical energy carbon emissions, is the mean value of statistical energy carbon emissions. Taylor diagrams were utilized in this study to assess the accuracy of the model. These diagrams provide a visual representation of correlation coefficients, standard deviations, and root mean square errors. The scatter points on the diagram represent the model, while the radial line depicts the correlation coefficient. The standard deviation is represented by the horizontal and vertical axes, and the root mean square error is illustrated by a dashed line. The utilization of Taylor diagrams is an advancement from traditional scatter plots, which only present two metrics for evaluating model accuracy. 1.3.4. Trend analysis The linear propensity estimation method was used for carbon emission temporal trend analysis. The linear tendency values are estimated by the least squares method as shown below (Lv et al., 2019). (10) where, n is the total number of years, i is the i th year, xi is energy consumption carbon emissions in i year. 1.3.5. Spatial autocorrelation statistics for carbon emissions Conventional research on economic variables has typically relied on non-spatial data, potentially overlooking the spatial effects of geographic data and the spatial correlation and heterogeneity among research subjects. Due to the spatial spillover effects of carbon emissions, emissions generated in one region can have consequences on neighboring regions, thereby influencing the development and execution of emission reduction policies (Chuai et al., 2012). Thus, the spatial correlation of carbon emissions within the study area bears critical theoretical and practical implications. Spatial autocorrelation refers to the statistical correlation among geographic units with different locations and attribute values in space (Wang et al., 2021a). It can be classified into global spatial autocorrelation and local spatial autocorrelation (Yan et al., 2017). In this study, we used the Global Moran's I tool in ArcGIS to analyze global spatial autocorrelation, and the Anselin Local Moran's I tool to analyze local spatial autocorrelation. Global spatial autocorrelation coefficient (I) values were computed to analyze the overall spatial correlation and the degree of spatial dispersion of the region. To determine the local spatial autocorrelation in Shaanxi Province, the local indicators map (LISA) was employed. The LISA map was utilized for visual display, and the spatial clustering units with significance were classified into high-high (H-H) clustering areas, low-low (L-L) clustering areas, high-low (H-L) clustering areas, low-high (L-H) clustering areas, and non-significant areas (Wang et al., 2016). 2. Results and discussion 2.1. Validation of carbon emission estimation model Six machine learning models were developed using the training set, and their optimal parameters were determined. The accuracy of each model was then assessed using the test set, and the results are shown in Fig. 4. The Taylor diagram was used to evaluate the accuracy of each model, with closer distances between the model points (red points) and observation points (blue points) indicating higher accuracy. Download : Download high-res image (592KB) Download : Download full-size image Fig. 4. Taylor diagram of training and testing sets for different machine learning algorithms. The training set accuracy ranking of each machine learning model is as follows: XGboost>RFR>MLP>SVR>KNN>LR, while the test set accuracy ranking is XGboost>RFR>KNN>SVR>LR (Fig. 4). The R2 values of the test set for all six models range from 0.69 to 0.90, indicating a satisfactory performance. The R2 values for XGboost, RFR, and SVR exceed 0.8, with the XGboost model achieving a remarkably high R2 of 0.906. The RMSE values for each model range from 5.69 to 9.07 Mt, with the XGboost model demonstrating the lowest RMSE (5.687 Mt) and the LR model exhibiting the highest (9.066 Mt). Overall, the XGboost model exhibits the best predictive performance among the six machine learning models, followed by RFR, while the LR model has the poorest prediction performance. Apart from the accuracy validation, this paper also quantifies the training time and memory consumption of each model (Appendix A Table S2). The KNN model has the shortest training time, followed by the XGboost model, while the RFR model has the longest training time. Among the models, the RFR model has the highest memory consumption (7852 kb), whereas the SVR model has the lowest (96 kb). Machine learning algorithms have gained popularity in remote sensing modeling due to their ability to improve estimation accuracy (Lin et al., 2022; Tan et al., 2021). In the context of carbon emission modeling, machine learning-based models have been shown to outperform traditional linear regression models. This is because linear regression models struggle to effectively capture the complex relationship between NTL and carbon emissions, and are limited in their ability to perform deep data mining and learning (Jia et al., 2019). In contrast, machine learning algorithms offer higher accuracy and robustness in modeling remote sensing data. Among the five machine learning algorithms investigated in this study, XGboost exhibited the best performance. Li et al. (2020c) demonstrated that XGboost corrects residuals and generates a new tree based on the previous tree, providing better performance than the Random Forest (RF) model, which employs independent trees and is comparatively less flexible (Herrero-Huerta et al., 2020). Previous research has indicated that the RF model can handle high-dimensional data and resist overfitting (Kayad et al., 2019; Zhu et al., 2019), with the RFR model exhibiting the second-best performance in this study. However, the SVR, MLP, and KNN models demonstrated lower performance, with the SVR and MLP models requiring multiple training iterations to obtain the optimal neural network. One possible factor contributing to the lower accuracy of these models is the limited number of observed data points (Han et al., 2019). The KNN model relies heavily on the limited number of neighboring samples and is less tolerant of errors in the training data, leading to lower prediction accuracy (Li et al., 2020b). It is worth noting that there are some limitations in the model comparison in this study. The strengths and weaknesses of the five machine learning models have not been fully demonstrated due to the limited number of observations. However, this study focuses on the accuracy of model estimation, and XGboost is a convenient and effective model for estimating carbon emissions. 2.2. Spatial and temporal dynamics of carbon emissions The spatial and temporal distributions of carbon emissions at three spatial scales, pixel (Fig. 5), county (Appendix A Fig. S2), and city (Appendix A Fig. S3), were obtained for Shaanxi Province with the XGboost model. Download : Download high-res image (2MB) Download : Download full-size image Fig. 5. Spatial and temporal distribution of energy carbon emissions at the pixel scale. As shown in Fig. 5, the energy carbon emissions continued to grow in Shaanxi Province from 2000 to 2017, and the high carbon emission areas showed a trend of gradual expansion. The spatial distribution shows a shift from discrete and sporadic dotted distribution to contiguous and extended distribution. In terms of the annual change trend, the carbon emissions of cities in Shaanxi Province show a gradually increasing trend, which is consistent with the overall characteristics of carbon emissions in Shaanxi Province (Fig. 6 and Appendix A Fig. S3). In terms of spatial changes, the largest increasing trends are in Yulin (Increased by 45.00 Mt in 18 years) and Yan'an (Increased by 46.34 Mt) in the north of Shaanxi Province, and Xi'an (Increased by 30.88 Mt), the provincial capital, in the center, followed by Weinan (Increased by 22.73 Mt), and Xianyang (Increased by 21.00 Mt), Baoji (Increased by 13.13 Mt) in the Guanzhong Plain, and finally Hanzhong (Increased by 8.99Mt), Shangluo (Increased by 5.40 Mt) and Ankang (Increased by 4.70 Mt) in the south of Shaanxi Province (Fig. 6 and Appendix A Fig. S3). Download : Download high-res image (263KB) Download : Download full-size image Fig. 6. Annual Change in carbon emissions at the city level in Shaanxi Province from 2000 to 2017. County-scale energy consumption carbon emissions of high-carbon counties (such as Shenmu, Zhidan, Wuqi, Fugu, and Dingbian counties located in northern Shaanxi Province) show a continuous growth trend from 2000 to 2017, with the highest value being Shenmu County, which increased from 4.65 Mt in 2000 to 14.58 Mt in 2017, which is consistent with the overall characteristics of carbon emissions in China, indicating that the overall economic level of China's counties, the urbanization level has been improved, and the total energy consumption demand has increased leading to a rising trend of county-level carbon emissions (Appendix A Fig. S2). From the perspective of spatial and temporal characteristics, high carbon emission counties are mainly concentrated in northern and central Shaanxi Province. The spatial and temporal distribution characteristics of carbon emissions at the county scale indicate that there is also a regional imbalance in carbon emissions from energy consumption in each county within the municipal scale. To further clarify the temporal trends of carbon emissions from energy consumption, this paper uses linear propensity estimation for the temporal trend analysis of energy carbon emissions (Fig. 7). From the trend of carbon emission changes at the pixel scale, the regions with the fastest growing trend are central and northern Shaanxi Province. In terms of carbon emission change trends at the county scale, seven counties in Shaanxi province belong to the fast-growing type, namely Yuyang and Dingbian counties in Yulin, Wuqi, Zhidan, Ansai, and Baota districts in Yan'an, and Chang'an districts in Xi'an, central Shaanxi, respectively; six counties belong to the relatively fast-growing type, namely Shenmu and Jingbian counties in Yulin, northern Shaanxi, Baqiao district in Xi'an, central The number of counties in the medium, relatively low and low growth categories is 20, 22 and 52, respectively, evenly distributed throughout Shaanxi Province. In terms of carbon emission trends at the city level, two cities belong to the fast-growth type, namely, Yulin and Yan'an; one city belongs to the relatively fast-growth type, namely, Xi'an, the capital of Shaanxi Province; two cities belong to the medium-growth type, namely, Xianyang and Weinan; two cities belong to the relatively low-growth type, namely, Baoji and Hanzhong; three cities belong to the low-growth type, namely, Tongchuan, Ankang, and Shangluo. Ankang City and Shangluo City. Download : Download high-res image (960KB) Download : Download full-size image Fig. 7. Trends in carbon emissions at pixel (a), county (b), and city (c) scale in Shaanxi Province. The fast-growing areas of carbon emissions in Shaanxi Province are mainly located in the coal-rich Yulin City, the oil-rich Yan'an City, and the economically developed Xi'an City; the slow-growing areas of carbon emissions from energy consumption are mainly concentrated in Ankang, Hanzhong and Shangluo City in the south of Shaanxi Province, which have beautiful scenery and a small share of energy consumption. 2.3. Spatial autocorrelation analysis of carbon emissions The results of the global spatial autocorrelation analysis for county-level carbon emissions in Shaanxi Province are presented in Table 2. The analysis reveals a highly significant spatial clustering distribution pattern for county-scale carbon emissions in the study area (Z > 2.58). Furthermore, the I value displays an increasing trend over the 18-year period, which is consistent with the long-term series of changes in carbon emissions, suggesting that the spatial agglomeration of carbon emissions is on the rise. It should be noted that these findings are based on limited spatial data and may not fully represent the strengths and weaknesses of the spatial analysis methods employed. Table 2. Results of global spatial autocorrelation analysis of county-level carbon emissions in Shaanxi Province. Year Moran's index z-score p-value 2000 0.3824 6.3552 0.0000 2001 0.2451 4.0547 0.0001 2002 0.2483 4.1150 0.0000 2003 0.2193 3.6530 0.0003 2004 0.2844 4.6927 0.0000 2005 0.2787 4.6105 0.0000 2006 0.3251 5.3265 0.0000 2007 0.3897 6.3763 0.0000 2008 0.3951 6.5217 0.0000 2009 0.3918 6.5192 0.0000 2010 0.4261 7.0335 0.0000 2011 0.4177 6.8764 0.0000 2012 0.4346 7.1397 0.0000 2013 0.4139 6.8209 0.0000 2014 0.4069 6.6790 0.0000 2015 0.4237 7.1235 0.0000 2016 0.4359 6.5978 0.0000 2017 0.4465 7.0333 0.0000 By examining the outcomes of the global spatial autocorrelation analysis at the county level in Shaanxi Province, we can gain insight into the overall spatial variation of carbon emissions in each region. However, it does not reveal the spatial clustering distribution of carbon emissions within the region. Therefore, this study proceeds to perform a detailed investigation of the local spatial correlation for annualized carbon emissions from 2000 to 2017. The LISA map of county-level carbon emissions reveals that the spatial distribution pattern of carbon emissions in Shaanxi Province remained relatively stable between 2000 and 2017 (Fig. 8). In 2000, the high-value carbon emission clustering areas were concentrated in Shenmu and Fugu counties in Yulin, as well as Yanta, Weiyang, and Beilin districts in Xi'an, while Lueyang, Ningqiang, Foping, and Zhenba counties in Hanzhong, Hanyin, Ziyang, Langao, Pingli, Zhenping, and Baihe counties in Ankang, Zhenan and Shanyang counties in Shangluo, and Yijun County in Tongchuan formed the low-value carbon emission clustering areas. From 2004, several new districts and counties were added to the high-value carbon emission clustering area, such as Dingbian County and Jingbian County in Yulin, Wuqi County, Zhidan County, and Ansai District in Yan'an, and Chang'an District in Xi'an. Between 2004 and 2017, the high-value carbon emission clustering areas in Shaanxi Province were mainly concentrated in Yulin and Yan'an in the northern part of the province, while the low-value clustering areas were mainly located in Hanzhong, Ankang, and Shangluo in the southern part of the province (Appendix A Fig. S4). Download : Download high-res image (2MB) Download : Download full-size image Fig. 8. Local spatial correlation of carbon emissions at the county scale in Shaanxi province during 2000\u20132017. The LISA maps of Shaanxi Province from 2000 to 2017 demonstrate that the observed high values are surrounded by the region of observed high values (H-H) and the observed low values are surrounded by the region of observed low values (L-L), mainly distributed in the first and third quadrants (Jung et al., 2019). The positive spatial correlation in both quadrants indicates that carbon emissions in Shaanxi Province have a significant positive spatial spillover effect. Overall, the analysis reveals those districts and counties with relatively lower economic development exhibit lower carbon emissions. Additionally, the H-H clustering area displays an expanding trend while the L-L clustering area demonstrates a stable trend. H-L and L-H clustering areas in Shaanxi Province occur only in certain years, indicating a highly significant spatial clustering pattern in the spatial distribution of carbon emissions. 2.4. Policy recommendations As global remote sensing technology continues to advance and remote sensing data becomes more accessible, combined with the effectiveness of the model constructed in this study, it is recommended that government departments proactively develop a multi-scale carbon emission estimation model based on the integration of remote sensing data and statistical data at the provincial-city-county-grid level. This will enable the establishment of a mechanism for regional information sharing and work linkage, providing reference and guidance for determining precise emission reduction areas from a more refined scale. The results of our study show that energy carbon emissions in Shaanxi Province are significantly affected by spatial spillover effects, which can lead to the inefficiency of carbon emission reduction efforts (Fig. 8). To address this issue, we recommend promoting the implementation of joint prevention and control mechanisms across Shaanxi Province, with a focus on reducing the spillover effects of high-emission cities. Relevant authorities should take strict measures to control the phenomenon of \u201cpollution transfer\u201d and prioritize the development of green industries that are suitable for local conditions, rather than taking over high-pollution industries from neighboring municipalities. These efforts can help to promote more effective carbon emission reduction strategies and contribute to the sustainable development of Shaanxi Province. From the perspective of spatial distribution and agglomeration of carbon emissions, cities will continue to be the fundamental unit for implementing carbon emission reduction measures in the future. Shaanxi Province, as a major energy resource province in central and western China, faces challenges in reducing carbon emissions due to the high energy carbon emissions in Yulin, the main producer of coal and natural gas, and Yan'an, the main producer of oil and natural gas (Fig. 6 and Appendix A Fig. S3). To address this challenge, energy structure adjustment and energy utilization efficiency improvement are critical measures that need to be taken (Wang et al., 2018; Zhang et al., 2020). It is necessary to optimize the industrial structure, which should strongly support the development of green industries related to emission reduction, such as clean production technology, renewable energy products, system manufacturing industries, and key environmental protection-related industries (Yan and Hua, 2011). Currently, the secondary industry is a significant driving force for Shaanxi Province's economic development, but it is also the industry with the highest impact on carbon emissions and the most CO2 emissions, indicating the urgent need to upgrade and update the industrial structure. On the one hand, it is necessary to promote the elimination of backward production capacity, equipment, and technology while restricting the development of high energy consumption and high carbon emission industries and strongly encourage independent innovation and technological progress. On the other hand, priority should be given to the development of low energy consumption and high-value-added industries and transform the traditional high energy consumption and low-value-added industries into information technology, new energy development, tourism, and other industries, to increase the proportion of the tertiary industry in the national economy. 3. Conclusion and prospect Overall, our study demonstrates the efficacy of integrating DMSP/OLS and NPP/VIIRS global nighttime light data with carbon emission statistics to construct accurate machine learning models for estimating energy carbon emissions at the city and county levels in Shaanxi Province, China. Among the six models tested, the XGboost model with Bayesian optimization yielded the best results, with an R2 value of 0.906 and an RMSE of 5.687 Mt. From 2000 to 2017, high carbon emission counties were mainly concentrated in northern and central Shaanxi Province, with a shift from a discrete and sporadic point-like distribution to a contiguous and extended distribution. Our analysis also revealed strong spatial autocorrelation of carbon emissions in Shaanxi Province, with increasing spatial agglomeration over time. High-high (H-H) and low-low (L-L) clustering were the predominant spatial autocorrelation patterns observed, with the economically developed districts and counties in northern and central Shaanxi exhibiting high-emissions clustering and the economically relatively backward districts and counties in southern Shaanxi exhibiting low-emissions clustering. The high-emissions clustering area showed an expanding trend, while the low-emissions clustering area remained stable. In summary, our findings highlight the importance of the XGboost model with Bayesian optimization in estimating carbon emissions from energy consumption and provide valuable support and data reference for future research on carbon emissions of administrative units at the local, municipal, and district and county levels, where statistical information on energy consumption is lacking. While this study has made progress in the field of carbon emissions research, there are still several issues that require attention in future investigations. Specifically, this study only considers the total carbon emissions resulting from energy consumption and does not differentiate between various sectors, such as construction, transportation, industry, electricity, cement, steel, etc. Given that different human energy activities have varying spatial and temporal evolution characteristics, analysis of the influencing factors, peak attainment paths, and emission reduction strategies for both the total carbon emissions resulting from complex energy consumption and the carbon emissions of subdivided industries is necessary. Therefore, while this study provides a useful starting point for simulating carbon emission data from remote sensing data, future research should build upon this approach and investigate specific sub-sectors in greater detail. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgments This work was supported by the Key Research and Development Program in Shaanxi Province, China (No. 2022ZDLSF07-05) and the Fundamental Research Funds for the Central Universities, CHD (No. 300102352901). The authors also wish to thank the several anonymous reviewers and the special academic editor for their suggestions, which helped improve the manuscript. Appendix. Supplementary materials Download : Download Word document (21MB) References Abbasi et al., 2022 K.R. Abbasi, M. Shahbaz, J. Zhang, M. Irfan, R. Alvarado Analyze the environmental sustainability factors of China: the role of fossil fuel energy and renewable energy Renew. Energ., 187 (2022), pp. 390-402 View PDFView articleView in ScopusGoogle Scholar Abedi et al., 2021 R. Abedi, R. Costache, H. Shafizadeh-Moghadam, Q.B. Pham Flash-flood susceptibility mapping based on XGBoost, random forest and boosted regression trees Geocarto. Int., 37 (19) (2021), pp. 5479-5496 Google Scholar Ahmad et al., 2018 F. Ahmad, M.U. Draz, L.J. Su, I. Ozturk, A. Rauf Tourism and environmental pollution: evidence from the one belt one road provinces of Western China Sustainability, 10 (10) (2018), p. 3520 CrossRefView in ScopusGoogle Scholar Basu et al., 2020 S. Basu, S. Lehman, J. Miller, A. Andrews, C. Sweeney, K. Gurney, et al. Estimating US fossil fuel CO2 emissions from measurements of 14 C in atmospheric CO 2 Proc. Natl. Acad. Sci., 117 (2020), Article 201919032 Google Scholar Bessa and Pellegrino, 2018 M.A. Bessa, S. Pellegrino Design of ultra-thin shell structures in the stochastic post-buckling range using Bayesian machine learning and optimization Int. J. Solids Struct., 139-140 (2018), pp. 174-188 View PDFView articleView in ScopusGoogle Scholar Breiman, 2001 L. Breiman Random forests Mach. Learn., 45 (1) (2001), pp. 5-32 Google Scholar Cai and Wang, 2013 B.F. Cai, J.N. Wang CO2 emissions of Tianjin based on 1 km grid dataset Acta Sci. Circumst., 33 (06) (2013), pp. 1655-1664 View in ScopusGoogle Scholar Cai et al., 2020 M. Cai, Y. Shi, C. Ren Developing a high-resolution emission inventory tool for low-carbon city management using hybrid method \u2013 A pilot test in high-density Hong Kong Energ. Build., 226 (2020), Article 110376 View PDFView articleView in ScopusGoogle Scholar Chen et al., 2021 Z. Chen, B. Yu, C. Yang, Y. Zhou, S. Yao, X. Qian, et al. An extended time series (2000\u20132018) of global NPP-VIIRS-like nighttime light data from a cross-sensor calibration Earth Syst. Sci. Data, 13 (3) (2021), pp. 889-906 CrossRefView in ScopusGoogle Scholar Chen et al., 2018 Z.J. Chen, Y.M. Liu, X. Liu, F.B. Kong Research on carbon emission peak in Yangtze river economic zone with steady economic growth: based on data of global night-time light J. Nat. Reso., 33 (12) (2018), pp. 2213-2222 CrossRefGoogle Scholar Cheshmberah et al., 2020 F. Cheshmberah, H. Fathizad, G.A. Parad, S. Shojaeifar Comparison of RBF and MLP neural network performance and regression analysis to estimate carbon sequestration Int. J. Environ. Sci. Technol., 17 (9) (2020), pp. 3891-3900 CrossRefView in ScopusGoogle Scholar Chuai et al., 2012 X.W. Chuai, X.J. Huang, W.J. Wang, J.Q. Wen, Q. Chen, J.W. Peng Spatial econometric analysis of carbon emissions from energy consumption in China J. Geogr. Sci., 22 (4) (2012), pp. 630-642 CrossRefView in ScopusGoogle Scholar Cover and Hart, 1967 T. Cover, P. Hart Nearest neighbor pattern classification IEEE. T. Inform. Theory, 13 (1) (1967), pp. 21-27 Google Scholar Dai et al., 2022 Y.M. Dai, Y.X. Wang, M.M. Leng, X.Y. Yang, Q. Zhou LOWESS smoothing and Random Forest based GRU model: a short-term photovoltaic power generation forecasting method Energy, 256 (2022), Article 124661 View PDFView articleView in ScopusGoogle Scholar Deng et al., 2018 X.Z. Deng, L. Dan, Q. Ye, Z.H. Wang, Y. Liu, X.Y. Zhang, et al. Methodological framework and research progress on the social and economic costs of carbon emission and reduction J. Geo-Inf. Sci., 20 (2018), pp. 405-413 View in ScopusGoogle Scholar Doll et al., 2000 C. Doll, J.P. Muller, C. Elvidge Night-time imagery as a tool for global mapping of socioeconomic parameters and greenhouse gas emissions Ambio, 29 (03) (2000), pp. 157-162 View in ScopusGoogle Scholar Doreswamy et al., 2020 K.S. Doreswamy, Harishkumar, K.M. Yogesh, G. Ibrahim Forecasting air pollution particulate matter (PM2.5) using machine learning regression models Procedia Comput. Sci., 171 (2020), pp. 2057-2066 Google Scholar Elvidge et al., 1997 C.D. Elvidge, K.E. Baugh, E.A. Kihn, H.W. Kroehl, E.R. Davis, C.W. Davis Relation between satellite observed visible-near infrared emissions, population, economic activity and electric power consumption Int. J. Remote Sens., 18 (6) (1997), pp. 1373-1379 View in ScopusGoogle Scholar Geng et al., 2022 Z.Q. Geng, X.Y. Duan, J.T. Li, C. Chu, Y.M. Han Risk prediction model for food safety based on improved random forest integrating virtual sample Eng. Appl. Artif. Intel., 116 (2022), Article 105352 View PDFView articleView in ScopusGoogle Scholar Ghosh et al., 2010 T. Ghosh, C. Elvidge, P. Sutton, K. Baugh, D. Ziskin, B. Tuttle Creating a global grid of distributed fossil fuel CO2 emissions from nighttime satellite imagery Energies, 3 (12) (2010), pp. 1895-1913 CrossRefView in ScopusGoogle Scholar Guo et al., 2016 X.Y. Guo, Q.W. Yan, X.Y. Tan, S.J. Liu Spatial distribution of carbon emissions based on DMSP/OLS nighttime light data and NDVI in Jiangsu province World Reg. Stud., 25 (04) (2016), pp. 102-110 Google Scholar Gupta et al., 2022 R. Gupta, C. Pierdzioch, A.A. Salisu Oil-price uncertainty and the U.K. unemployment rate: a forecasting experiment with random forests using 150 years of data Resourc. Policy, 77 (2022), Article 102662 View PDFView articleView in ScopusGoogle Scholar Gurney et al., 2020 K.R. Gurney, J. Liang, R. Patarasuk, Y. Song, J. Huang, G. Roest The Vulcan version 3.0 high-resolution fossil fuel CO2 emissions for the United States J. Geophys. Res. Atmos., 125 (2020), Article e2020JD032974 View in ScopusGoogle Scholar Han et al., 2019 L. Han, G.J. Yang, H.Y. Dai, B. Xu, H. Yang, H.K. Feng, et al. Modeling maize above-ground biomass based on machine learning approaches using UAV remote-sensing data Plant Methods, 15 (1) (2019), p. 10 Google Scholar Han et al., 2022 Y.M. Han, J.Z. Li, X.Y. Lou, C.Y. Fan, Z.Q. Geng Energy saving of buildings for reducing carbon dioxide emissions using novel dendrite net integrated adaptive mean square gradient Appl. Energ., 309 (2022), Article 118409 View PDFView articleView in ScopusGoogle Scholar Hansen et al., 2000 J. Hansen, M. Sato, R. Ruedy, A. Lacis, V. Oinas Global warming in the twenty-first century: an alternative scenario Proc. Natl. Acad. Sci., 97 (18) (2000), pp. 9875-9880 View in ScopusGoogle Scholar He et al., 2022 S. He, J.H. Wu, D. Wang, X.D. He Predictive modeling of groundwater nitrate pollution and evaluating its main impact factors using random forest Chemosphere, 290 (2022), Article 133388 View PDFView articleView in ScopusGoogle Scholar Herrero-Huerta et al., 2020 M. Herrero-Huerta, P. Rodriguez-Gonzalvez, K.M. Rainey Yield prediction by machine learning from UAS-based multi-sensor data fusion in soybean Plant Methods, 16 (1) (2020), p. 78 View in ScopusGoogle Scholar Jia et al., 2019 Y. Jia, S.G. Jin, P. Savi, Y. Gao, J. Tang, Y.X. Chen, et al. GNSS-R soil moisture retrieval based on a XGboost machine learning aided method: performance and validation Remote Sens., 11 (14) (2019), p. 1655 CrossRefView in ScopusGoogle Scholar Jung et al., 2019 P.H. Jung, J.-C. Thill, M. Issel Spatial autocorrelation statistics of areal prevalence rates under high uncertainty in denominator data Geogr. Anal., 51 (3) (2019), pp. 354-380 CrossRefView in ScopusGoogle Scholar Kayad et al., 2019 A. Kayad, M. Sozzi, S. Gatto, F. Marinello, F. Pirotti Monitoring within-field variability of corn yield using sentinel-2 and machine learning techniques Remote Sens., 11 (23) (2019), p. 2873 CrossRefView in ScopusGoogle Scholar Li et al., 2018 H.P. Li, M. Long, G.Y. Li Spatial-temporal dynamics of carbon dioxide emissions in China based on DMSP/OLS nighttime stable light data China Environ. Sci., 38 (2018), pp. 2777-2784 View in ScopusGoogle Scholar Li et al., 2020a R. Li, L.L. Cui, H.B. Fu, Y. Meng, J.L. Li, J.P. Guo Estimating high-resolution PM1 concentration from Himawari-8 combining extreme gradient boosting-geographically and temporally weighted regression (XGBoost-GTWR) Atmos. Environ., 229 (2020), Article 117434 View PDFView articleView in ScopusGoogle Scholar Li et al., 2022 W.J. Li, X.Z. Yu, N. Hu, F. Huang, J. Wang, Q.N. Peng Study on the relationship between fossil energy consumption and carbon emission in Sichuan Province Energy Rep., 8 (2022), pp. 53-62 View PDFView articleGoogle Scholar Li and Zhou, 2018 X.M. Li, W.Q. Zhou Dasymetric mapping of urban population in China based on radiance corrected DMSP-OLS nighttime light and land cover data Sci. Total Environ., 643 (2018), pp. 1248-1256 View PDFView articleView in ScopusGoogle Scholar Li et al., 2020b X.Y. Li, Z.H. Liu, H. Lin, G.X. Wang, H. Sun, J.P. Long, et al. Estimating the growing stem volume of chinese pine and larch plantations based on fused optical data using an improved variable screening method and stacking algorithm Remote Sens., 12 (5) (2020), p. 871 View PDFView articleCrossRefGoogle Scholar Li et al., 2020c Y.C. Li, M.Y. Li, C. Li, Z.Z. Liu Forest aboveground biomass estimation using Landsat 8 and Sentinel-1A data with machine learning algorithms Sci. Rep.-UK., 10 (1) (2020), p. 9952 View in ScopusGoogle Scholar Liang et al., 2014 D. Liang, Q.Y. Xie, W.J. Huang, D.L. Peng, X.H. Yang, L.S. Huang, et al. Using least squares support vector machines to estimate time series leaf area index Infrared Laser Eng., 43 (01) (2014), pp. 243-248 View in ScopusGoogle Scholar Liang et al., 2015 D. Liang, Q.Y. Yang, W.J. Huang, D.L. Peng, J.L. Zhao, L.S. Huang, et al. Estimation of leaf area index based on wavelet transform and support vector machine regression in winter wheat Infrared Laser Eng., 44 (01) (2015), pp. 335-340 View in ScopusGoogle Scholar Lin et al., 2022 L.J. Lin, Y.C. Liang, L. Liu, Y. Zhang, D.N. Xie, F. Yin, et al. Estimating PM2.5 concentrations using the machine learning RF-XGBoost model in guanzhong urban agglomeration, China Remote Sens., 14 (20) (2022), p. 5239 CrossRefView in ScopusGoogle Scholar Liu et al., 2021 B. Liu, X.H. Tan, Y.Q. Jin, W.W. Yu, C.Y. Li Application of RR-XGBoost combined model in data calibration of micro air quality detector Sci. Rep-UK., 11 (1) (2021), p. 15662 View in ScopusGoogle Scholar Liu et al., 2023 M. Liu, R.H. Hao, L. Han, G.X. Zhou, L.Z. Li, Y. Wang An integrated economic-ecological index based on satellite-derived carbon sequestration and carbon price: a case study during 2015\u20132020 in Shaanxi, China Ecol. Indic., 153 (2023), Article 110458 View PDFView articleView in ScopusGoogle Scholar Lv et al., 2019 Q. Lv, H.B. Liu, J.T. Wang, H. Liu, Y. Shang Multiscale analysis on spatiotemporal dynamics of energy consumption CO2 emissions in China: utilizing the integrated of DMSP-OLS and NPP-VIIRS nighttime light datasets Sci. Total Environ., 703 (2019), Article 134394 Google Scholar Ma et al., 2020 J.G. Ma, H.T. Duan, L.Y. He, M. Tiffany, Z.G. Cao, T.C. Qi, et al. Spatiotemporal pattern of gypsum blooms in the Salton Sea, California, during 2000-2018 Int. J. Appl. Earth Obs. Geoinf., 89 (2020), Article 102090 View PDFView articleView in ScopusGoogle Scholar Meng et al., 2017 X. Meng, J. Han, C. Huang An improved vegetation adjusted nighttime light urban index and its application in quantifying spatiotemporal dynamics of carbon emissions in China Remote Sens., 9 (8) (2017), p. 829 CrossRefView in ScopusGoogle Scholar Modaresi et al., 2018 F. Modaresi, S. Araghinejad, K. Ebrahimi A comparative assessment of artificial neural network, generalized regression neural network, least-square support vector regression, and K-nearest neighbor regression for monthly streamflow forecasting in linear and nonlinear conditions Water Resour. Manage., 32 (1) (2018), pp. 243-258 CrossRefView in ScopusGoogle Scholar Petukhova et al., 2018 T. Petukhova, D. Ojkic, B. McEwen, R. Deardon, Z. Poljak Assessment of autoregressive integrated moving average (ARIMA), generalized linear autoregressive moving average (GLARMA), and random forest (RF) time series regression models for predicting influenza A virus frequency in swine in Ontario, Canada Plos One, 13 (6) (2018), Article e0198313 CrossRefView in ScopusGoogle Scholar Shi, 2017 K.F. Shi A Study On the Dynamics of Spatial and Temporal Patterns of Carbon Emissions in China from a Multi-Scale Perspective and the Influencing Factors East China Normal University, Shanghai (2017) Google Scholar Shi et al., 2016 K.F. Shi, Y. Chen, B.L. Yu, T.B. Xu, Z.Q. Chen, R. Liu, et al. Modeling spatiotemporal CO2 (carbon dioxide) emission dynamics in China from DMSP-OLS nighttime stable light data using panel data analysis Appl. Energ., 168 (2016), pp. 523-533 View PDFView articleView in ScopusGoogle Scholar Su et al., 2013 Y.X. Su, X.Z. Chen, Y.Y. Ye, Q. Wu, H.O. Zhang, N.S. Huang The characteristics and mechanisms of carbon emissions from energy consumption in China using DMSP/OLS night light imageries Acta Geogr. Sin., 68 (11) (2013), pp. 1513-1526 View in ScopusGoogle Scholar Sun et al., 2021 Y.R. Sun, S.H. Wang, X.C. Zhang, T.O. Chan, W.J. Wu Estimating local-scale domestic electricity energy consumption using demographic, nighttime light imagery and Twitter data Energy, 226 (2021), Article 120351 View PDFView articleView in ScopusGoogle Scholar Tan et al., 2021 W.W. Tan, C.Z. Wei, Y. Lu, D.S. Xue Reconstruction of all-weather daytime and nighttime MODIS aqua-terra land surface temperature products using an XGBoost approach Remote Sens., 13 (22) (2021), p. 4723 CrossRefView in ScopusGoogle Scholar Wang et al., 2021a B. Wang, M.X. Yu, Y.C. Zhu, P.J. Bao Unveiling the driving factors of carbon emissions from industrial resource allocation in China: a spatial econometric perspective Energ. Policy, 158 (2021), Article 112557 View PDFView articleView in ScopusGoogle Scholar Wang et al., 2018 C.P. Wang, Y. Xiao, Q.W. Li, J. Deng, K. Wang Free radicals, apparent activation energy, and functional groups during low-temperature oxidation of Jurassic coal in Northern Shaanxi Int. J. Min. Sci. Techno., 28 (3) (2018), pp. 469-475 View PDFView articleView in ScopusGoogle Scholar Wang et al., 2016 H. Wang, J.F. Zhang, F.B. Zhu, W.W. Zhang Analysis of spatial pattern of aerosol optical depth and affecting factors using spatial autocorrelation and spatial autoregressive model Environ. Earth. Sci., 75 (9) (2016), p. 822 Google Scholar Wang et al., 2020 L.Y. Wang, H. Fan, Y.K. Wang Improving population mapping using Luojia 1-01 nighttime light image and location-based social media data Sci. Total Environ., 730 (2020), Article 139148 View PDFView articleView in ScopusGoogle Scholar Wang et al., 2021b S.B. Wang, J.Q. Zhuang, J. Zheng, H.Y. Fan, J.X. Kong, J.W. Zhan Application of Bayesian hyperparameter optimized random forest and XGBoost model for landslide susceptibility mapping Front. Earth Sci., 9 (2021), Article 712240 View in ScopusGoogle Scholar Wang et al., 2009 X.L. Wang, Z.Y. Zhou, J.P. Yan Apply GA-SVM to retrieve water quality parameters of Weihe River from multispectral remote sensing data J. Remote Sens., 13 (2009), pp. 735-744 CrossRefView in ScopusGoogle Scholar Won et al., 2020 C.D. Won, H.L. Hong, K.R. Pak Origin of clay minerals on section of Luochuan loesspalaeosol in Shaanxi Province, northwest China Front. Earth. Sc-Switz., 14 (4) (2020), pp. 684-694 CrossRefView in ScopusGoogle Scholar Wu et al., 2022 H. Wu, Y.M. Han, Z.Q. Geng, J.Z. Fan, W. Xu Production capacity assessment and carbon reduction of industrial processes based on novel radial basis function integrating multi-dimensional scaling Sustain. Energy. Techn., 49 (2022), Article 101734 View PDFView articleView in ScopusGoogle Scholar Wu et al., 2019 J. Wu, X.Y. Chen, H. Zhang, L.D. Xiong, H. Lei, S.H. Deng Hyperparameter optimization for machine learning models based on Bayesian optimization J. Electron. Sci. Technol., 17 (1) (2019), pp. 26-40 View PDFView articleView in ScopusGoogle Scholar Wu et al., 2013 J.S. Wu, Z. Wang, W.F. Li, J. Peng Exploring factors affecting the relationship between light consumption and GDP based on DMSP/OLS nighttime satellite imagery Remote Sens. Environ., 134 (2013), pp. 111-119 View PDFView articleView in ScopusGoogle Scholar Yan et al., 2017 D. Yan, Y.L. Lei, L. Li, W. Song Carbon emission efficiency and spatial clustering analyses in China's thermal power industry: evidence from the provincial level J. Clean. Prod., 156 (2017), pp. 518-527 View PDFView articleView in ScopusGoogle Scholar Yan and Hua, 2011 W.Z. Yan, S. Hua A strategy study on the environmental protection of the energy and chemical industry Base in Northern Shaanxi Energy Proc., 5 (2011), pp. 969-973 View in ScopusGoogle Scholar Yang et al., 2021 X. Yang, R. Yang, Y. Ye, Z.R. Yuan, D.Z. Wang, K.K. Hua Winter wheat SPAD estimation from UAV hyperspectral data using cluster-regression methods Int. J. Appl. Earth Obs. Geoinf., 105 (2021), Article 102618 View PDFView articleView in ScopusGoogle Scholar Yong et al., 2022 Z.W. Yong, K. Li, J.N. Xiong, W.M. Cheng, Z.G. Wang, H.Z. Sun, et al. Integrating DMSP-OLS and NPP-VIIRS nighttime light data to evaluate poverty in Southwestern China Remote Sens., 14 (3) (2022), p. 600 CrossRefView in ScopusGoogle Scholar Yuan et al., 2017 H.H. Yuan, G.J. Yang, C.C. Li, Y.J. Wang, J.G. Liu, H.Y. Yu, et al. Retrieving soybean leaf area index from unmanned aerial vehicle hyperspectral remote sensing: analysis of RF, ANN, and SVM regression models Remote Sens., 9 (4) (2017), p. 309 CrossRefView in ScopusGoogle Scholar Zhang et al., 2020 H.L. Zhang, L. Shen, S. Zhong, A. Elshkaki Coal resource and industrial structure nexus in energy-rich area: the case of the contiguous area of Shanxi and Shaanxi Provinces, and Inner Mongolia Autonomous Region of China Resourc. Policy, 66 (2020), Article 101646 View PDFView articleView in ScopusGoogle Scholar Zhang and Pan, 2019 Y.N. Zhang, J.H. Pan Spatio-temporal simulation and differentiation pattern of carbon emissions in China based on DMSP/OLS nighttime light China Environ. Sci., 39 (04) (2019), pp. 1436-1446 View in ScopusGoogle Scholar Zhao et al., 2015 N.Z. Zhao, E.L. Samson, N.A. Currit Nighttime-lights-derived fossil fuel carbon dioxide emission maps and their limitations Photogramm. Eng. Rem. S., 81 (12) (2015), pp. 935-943 View PDFView articleView in ScopusGoogle Scholar Zheng et al., 2019 Q.M. Zheng, Q.H. Weng, K. Wang Developing a new cross-sensor calibration model for DMSP-OLS and Suomi-NPP VIIRS night-light imageries ISPRS J. Photogramm. Remote Sens., 153 (2019), pp. 36-47 View PDFView articleView in ScopusGoogle Scholar Zheng et al., 2021 S. Zheng, R. Wang, T.M.W. Mak, S.-C. Hsu, D.C.W. Tsang How energy service companies moderate the impact of industrialization and urbanization on carbon emissions in China? Sci. Total Environ., 751 (2021), Article 141610 View PDFView articleView in ScopusGoogle Scholar Zheng et al., 2022 Y.M. Zheng, Y.R. He, Q. Zhou, H.W. Wang Quantitative evaluation of urban expansion using NPP-VIIRS nighttime light and landsat spectral data Sustain. Cities Soc., 76 (2022), Article 103338 View PDFView articleView in ScopusGoogle Scholar Zhu et al., 2019 W.X. Zhu, Z.G. Sun, J.B. Peng, Y.H. Huang, J. Li, J.Q. Zhang, et al. Estimating maize above-ground biomass using 3D point clouds of multi-source unmanned aerial vehicle data at multi-spatial scales Remote Sens, 11 (22) (2019), p. 2678 CrossRefView in ScopusGoogle Scholar Cited by (2) Integrated energy system model with multi-time scale optimal dispatch method based on a demand response mechanism 2024, Journal of Cleaner Production Show abstract Forecasting China\u2019s CO2 emissions and identifying key drivers: an application of the improved RFAGM model and LMDI decomposition methods 2024, International Journal of Sustainable Development and World Ecology View Abstract \u00a9 2024 The Research Center for Eco-Environmental Sciences, Chinese Academy of Sciences. Published by Elsevier B.V. Recommended articles Improving benzene catalytic oxidation on Ag/Co3O4 by regulating the chemical states of Co and Ag Journal of Environmental Sciences, Volume 143, 2024, pp. 201-212 Hao Guo, \u2026, Yinnian Liao View PDF Source apportionment and specific-source-site risk of quinolone antibiotics for effluent-receiving urban rivers and groundwater in a city, China Journal of Environmental Sciences, Volume 144, 2024, pp. 185-198 Yu Zhao, \u2026, Wenzhong Tang View PDF Evaluation of laboratory and environmental exposure systems for protein modification upon gas pollutants and environmental factors Journal of Environmental Sciences, Volume 143, 2024, pp. 213-223 Zhiwei Pan, \u2026, Senchao Lai View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 1 Captures Readers: 8 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright \u00a9 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply.",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "Predicting the efficiency of arsenic immobilization in soils by biochar using machine learning",
    "doi": "10.1016/j.jes.2023.11.016",
    "description": "Arsenic (As) pollution in soils is a pervasive environmental issue. Biochar immobilization offers a promising solution for addressing soil As contamination. The efficiency of biochar in immobilizing As in soils primarily hinges on the characteristics of both the soil and the biochar. However, the influence of a specific property on As immobilization varies among different studies, and the development and application of arsenic passivation materials based on biochar often rely on empirical knowledge. To enhance immobilization efficiency and reduce labor and time costs, a machine learning (ML) model was employed to predict As immobilization efficiency before biochar application. In this study, we collected a dataset comprising 182 data points on As immobilization efficiency from 17 publications to construct three ML models. The results demonstrated that the random forest (RF) model outperformed gradient boost regression tree and support vector regression models in predictive performance. Relative importance analysis and partial dependence plots based on the RF model were conducted to identify the most crucial factors influencing As immobilization. These findings highlighted the significant roles of biochar application time and biochar pH in As immobilization efficiency in soils. Furthermore, the study revealed that Fe-modified biochar exhibited a substantial improvement in As immobilization. These insights can facilitate targeted biochar property design and optimization of biochar application conditions to enhance As immobilization efficiency.",
    "journal": "Journal of Environmental Sciences (China)",
    "authors": [
      "Cao J.M.",
      "Liu Y.Q.",
      "Liu Y.Q.",
      "Xue S.D.",
      "Xiong H.H.",
      "Xu C.L.",
      "Xu Q.",
      "Duan G.L."
    ],
    "citation_count": "0",
    "full_text": "Typesetting math: 100% Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Abstract Graphical abstract Keywords Introduction 1. Materials and methods 2. Results and discussion 3. Conclusions Declaration of Competing Interest Acknowledgments Appendix. Supplementary materials References Show full outline Figures (5) Tables (2) Table 1 Table 2 Extras (1) Document Journal of Environmental Sciences Volume 147, January 2025, Pages 259-267 Predicting the efficiency of arsenic immobilization in soils by biochar using machine learning Author links open overlay panel Jin-Man Cao 1 3 \u204e\u204e, Yu-Qian Liu 1 2 \u204e\u204e, Yan-Qing Liu 1 3, Shu-Dan Xue 1 3, Hai-Hong Xiong 1, Chong-Lin Xu 1, Qi Xu 1 2, Gui-Lan Duan 1 3 Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.jes.2023.11.016 Get rights and content Abstract Arsenic (As) pollution in soils is a pervasive environmental issue. Biochar immobilization offers a promising solution for addressing soil As contamination. The efficiency of biochar in immobilizing As in soils primarily hinges on the characteristics of both the soil and the biochar. However, the influence of a specific property on As immobilization varies among different studies, and the development and application of arsenic passivation materials based on biochar often rely on empirical knowledge. To enhance immobilization efficiency and reduce labor and time costs, a machine learning (ML) model was employed to predict As immobilization efficiency before biochar application. In this study, we collected a dataset comprising 182 data points on As immobilization efficiency from 17 publications to construct three ML models. The results demonstrated that the random forest (RF) model outperformed gradient boost regression tree and support vector regression models in predictive performance. Relative importance analysis and partial dependence plots based on the RF model were conducted to identify the most crucial factors influencing As immobilization. These findings highlighted the significant roles of biochar application time and biochar pH in As immobilization efficiency in soils. Furthermore, the study revealed that Fe-modified biochar exhibited a substantial improvement in As immobilization. These insights can facilitate targeted biochar property design and optimization of biochar application conditions to enhance As immobilization efficiency. Graphical abstract Download : Download high-res image (171KB) Download : Download full-size image Previous article in issue Next article in issue Keywords BiocharArsenic immobilizationSoilMachine learning Introduction Soils are frequently contaminated with arsenic (As) due to geological processes and human activities (Sharma et al., 2022). Elevated levels of As in soils are detrimental to plant growth and pose significant health risks to humans through the food chain (Li et al., 2011). Consequently, As pollution in soils has gained considerable attention in recent years (Wang et al., 2023). Various physical, chemical, and biological technologies have been employed to reduce the bioavailability of As in contaminated soils (Wan et al., 2020a). Among these technologies, chemical adsorption is the most widely used method for soil remediation due to its cost-effectiveness and simplicity (Zhang et al., 2022). Various adsorbents, including biochar (Wu et al., 2020), activated carbon (Mondal and Garg, 2017), metal-organic frameworks (MOFs) (Wang et al., 2019), and minerals (Aredes et al., 2013), have been utilized for As remediation in soils. Biochar, in particular, has gained increasing attention due to its abundant sources, cost-effectiveness, and eco-friendly properties (Xiao et al., 2018). Biochar is a carbon-rich product with a high surface area and no cellular structure through pyrolysis at high temperatures (usually \u2265 500\u00b0C) (Xiao et al., 2018). Various biomass sources, such as wood, bamboo, fruit peels, and even animal manure, can serve as raw materials for biochar production (Bao et al., 2022). The efficiency of As immobilization in biochar-amended soils varies depending on biochar properties (e.g., feedstock and pyrolysis temperature) and application conditions (e.g., soil properties, biochar application rate, and timing) (Palansooriya et al., 2022). Additionally, the significance of these factors in influencing As immobilization efficiency varies (Palansooriya et al., 2022). Hence, the optimization of biochar properties to adapt to specific soil conditions is essential for enhancing the efficiency of As immobilization by biochar. Nevertheless, conducting scientific experiments to explore the optimal properties and conditions for improving As immobilization efficiency proved to be time-consuming, labor-intensive, and costly. Consequently, identifying optimal parameters through model prediction can mitigate time and cost requirements, ultimately achieving maximum As immobilization efficiency. Machine learning (ML) can process and learn from large, complex, multidimensional datasets to develop accurate prediction models (Palansooriya et al., 2022; Zhu et al., 2022). So far, numerous studies have reported the forecasting the adsorption of pollutants utilizing ML. For instance, Parveen et al. (2019) have found that the support vector regression (SVR) technique has been employed to predict the removal efficiency of Ni (II) ions, yielding more favorable predictive outcomes when compared with the multiple linear regression (MLR) model. In the investigation conducted by Yan et al. (2022), a comparative analysis of performance for three ML algorithms, namely random forest (RF), gradient boost regression tree (GBRT), and extreme gradient boosting (XGB), was undertaken in terms of their ability to predict the characteristics of MOF materials. It was founded that the XGB method evinced a superior predictive capacity in comparison to the other two methodologies. Other predictive models have also been employed to characterize heavy metal adsorption by biochar, unraveling the complex relationships among biochar properties, adsorption conditions, and adsorption behaviors (Zhu et al., 2019b, 2022). With regard to the prediction of heavy metal immobilization by biochar in soil, the modeling procedure closely parallels the prediction of adsorption efficiency (Sun et al., 2022). Presently, research endeavors centered on ML models for forecasting heavy metal immobilization efficiency predominantly include general studies spanning a variety of heavy metals, including As (Guo et al., 2023; Palansooriya et al., 2022; Zhang et al., 2022). However, specialized models tailored to As adsorption onto biochar have not been established up to now. It is worth noting that As, being an anionic metal, exhibits active biogeochemical cycling and manifests markedly distinct behavior in comparison to other heavy metals in soil matrices. For instance, Zhang et al. (2022) determined that biochar was unable to appreciably reduce the bioavailability of As in contrast to Cr, Sb, and V. This result may be attributed to the limited presence of oxidizing functional groups in biochar, thereby restraining the effective oxidation of As (III) and restraining As immobilization efficiency consequently. Additionally, it has been reported that the modification of metals into biochar can enhance heavy metal immobilization efficiency. For instance, iron-modified biochar exhibits increased As adsorption capacity and is widely employed as a remediation material for As-contaminated soils (Yan et al., 2023). Nevertheless, it is noteworthy that the iron content in biochar has rarely been considered as an input feature in previous ML models for prediction. Therefore, the imperative task entails the predictive models by optimal ML techniques for arsenic immobilization efficiency in soils. This study addresses this knowledge gap by utilizing three ML models to predict As immobilization efficiency by biochar in As-contaminated soils. We collected 182 data records on As immobilization efficiency from 17 publications to construct ML models. The objectives of this study are (i) to construct three ML models and determine the optimal algorithm for predicting As immobilization efficiency in biochar-amended soils; (ii) based on the optimal model, assess the importance of input features (biochar properties, soil properties, and environmental conditions) on output features (As immobilization efficiency) and elucidate the impact of Fe content on As immobilization efficiency; (iii) investigate the interactions among the three empirical categories related to As immobilization efficiency. This study fills the knowledge gaps regarding the establishment of As immobilization models and provides a comprehensive examination of the effects of various features on As immobilization efficiency in biochar-amended soils. Furthermore, the proposed framework offers new strategies for guiding biochar preparation to enhance As immobilization in soils. 1. Materials and methods 1.1. Data collection and pre-processing Studies published from 2009 to 2023 were retrieved from Web of Science using the keywords \"biochar\" AND \"soil arsenic.\" Based on prevailing knowledge, 14 parameters were chosen as input features: (i) Biochar properties, including carbon content (C, %), nitrogen content (N, %), oxygen content (O, %), hydrogen content (H, %), molar ratio of hydrogen to nitrogen (C/H), molar ratio of oxygen and nitrogen to carbon ((O + N)/C), molar ratio of oxygen to carbon (O/C), pyrolysis temperatures (T, \u00b0C), pH of biochar (pH_BC), and surface area of biochar (SA, m2/g). (ii) Soil properties, specifically the pH of soil (pH_soil). (iii) Environmental conditions, including biochar application rate (Rate_BC, %), time (Time, d), and initial concentration of As in soil (As_initinal, mg/kg). As immobilization efficiency was defined as the output variable. The As immobilization efficiency of biochar-amended soils, relative to untreated soils, was either directly obtained from the articles or calculated using Eq. (1). The experimental data were directly extracted from figures and tables with software GetData. (1) where, E (%) represents As immobilization efficiency; Xcontrol (mg/kg) represents As concentration in soil of the control group (without biochar application); Xtreat (mg/kg) represents As concentration in soil of the treatment group (with biochar application). The detailed process of machine learning for soil As fixation by biochar is depicted in Appendix A Fig. S1. We designated 14 parameters as input features and As immobilization efficiency as the output variable. As indicated in Table 1, a small number of missing values were observed for H content, O content, N content of biochar, pH_BC, specific surface area of biochar, and soil_pH. To address this, as illustrated in Appendix A Fig. S2, we utilized the Iterative Imputer method to complete the dataset (Mostafa, 2021). Ultimately, a total of 182 data points pertaining to As immobilization efficiency in biochar-amended soils were compiled from 17 research publications (Awad et al., 2019; Dias et al., 2022; Gu et al., 2023; Hong et al., 2022; Islam et al., 2021; Kumar et al., 2022; Kumar and Bhattacharya, 2022; Lebrun et al., 2019, 2022; Lin et al., 2017, 2020; Sun et al., 2021; Yang et al., 2018, 2022, 2023; Zhang et al., 2020; Zhu et al., 2020). Table 1. Empirical categories and input features used to predict heavy metal immobilization efficiency in biochar-amended soils Empirical categories Input features Unit Abbreviation Data range Number of datapoints 1. Biochar Properties 1 pyrolysis temperature \u00b0C Pyrolysis temperature 400\u2013700 182 2 pH - pH_BC 3.10\u201310.60 170 3 Surface area m2/g SA 0.23\u2013333.97 156 4 H/C - H/C 0.01\u20130.40 168 5 O/C - O/C 0.05\u201315.17 177 6 (O+N)/C - (O+N)/C 0.06\u201315.27 167 7 C content % C 6.00\u201391.00 182 8 H content % H 0.80\u20134.49 168 9 N content % N 0.08\u20135.60 172 10 O content % O 4.60\u201391.03 178 2. Experimental conditions 11 Biochar application rate % Rate_BC 0.1\u201315 182 12 Initial arsenic concentration mg/kg As_initinal 21.72\u20133000 182 13 Experiment duration day Time 0\u2013365 182 3. Soil properties 14 pH - pH_soil 4.70\u20138.33 175 To ensure uniform units for selected variables, both input and output parameters underwent Z-score standardization as per Eq. (2): (2) where, xi\u2217 and xi is the normalized and original values of input variables, respectively, while \u03bc and \u03c3 signify the mean value and standard deviation of each variable. 1.2. Model design and evaluation Before constructing the ML models, the entire As dataset was randomly split into an 85% training dataset and a 15% test dataset. The 85% of data points in the dataset were designated as the training data, while the remaining 15% constituted the test data for ML model validation. Three ML models (RF, GBRT, and SVR) were chosen for exploration and comparison of prediction performance. Subsequently, the GridSearchCV function in Python was employed to identify optimal hyperparameters through automated grid searches with 5-fold cross-validation to prevent overfitting (Zhu et al., 2019a). Key hyperparameters for RF, SVR, and GBRT models included: RF: number of trees (n_estimators), maximum depth of the trees (max_depth) and maximum number of features to consider for the best split (max_features), SVR: penalty coefficient (C), degree of the polynomial kernel function (degree) and parameter of the radial basis function (Gamma), GBRT: learning rate (learning_rate), maximum depth of the individual regression estimators (max_depth) and number of trees (n_estimators). These hyperparameters could be adjusted to fine-tune model performance and generalization ability. Subsequently, the model was retrained using the optimal parameters and assessed using the remaining 15% of the data. In the final model evaluation, 10-fold cross-validation was employed to ascertain the accuracy of the evaluation data (Nguyen and Bui, 2019). To determine the optimal model for predicting As immobilization efficiency, the three ML models were constructed based on various material characteristics. Model performance was evaluated using the regression coefficient (R2) and root mean square error (RMSE) for validation metrics, as Eqs. (3) and (4): (3) (4) where is the true value collected from the research literature, is the predicted value of the model output, signifies the average of all collected experimental data output values, and N denotes the total number of data samples. The hyperparameters that were fine-tuned included max_depth (1, 3, 5, 7), learning_rate (0.01, 0.05, 0.1, 0.5, 1), and n_estimators (100, 110, 120, 130, 140, 150, 200, 300) for the GBRT model; max_depth (7, 8, 9, 10, 11, 12), max_features ('auto', 'sqrt'), and n_estimators (60, 68, 71, 73, 75, 77, 79, 81, 83) for the RF model; and Gamma (0.05, 0.1, 0.2, 0.5, 0.7, 1, 2), degree (1, 2, 3, 5), and C (0.001, 0.01, 0.05, 0.1, 0.5, 1, 10) for SVR model. The optimal hyperparameters for the ML models are summarized in Table 2. Table 2. The optimal hyperparameters of three ML models. Target ML model Hyper-parameter Optimal value As immobilization efficiency RF n_estimators 71 max_depth 9 max_features auto SVR C 10 degree 3 gamma 1 GBRT learning_rate 0.01 max_depth 3 n_estimators 150 ML: machine learning; RF: random forest; SVR: support vector regression; GBRT: gradient boost regression tree. 1.3. Analyses of relative importance and partial dependence of features The model with the best prediction performance was further employed to elucidate the importance and impact of each feature on As immobilization. The importance of each input feature was assessed by calculating the weighted impurity decrease of all nodes during the decision tree-building process and then averaging them. Subsequently, the obtained importance data for input variables were analyzed to determine their contribution to the predicted target variable, i.e., the As immobilization efficiency. Two feature analysis methods were employed to evaluate feature importance: RF models directly conducted an importance analysis of model features to elucidate the contribution of input features to the output variable (Zhu et al., 2019a). The random forest feature importance measure was the average collected from all trees in the forest, providing insights into the impact of features on the output results across multiple cases. Another feature analysis utilized the Shapley additive interpretation (SHAP) method, introducing global and local analyses. Global interpretability assessed whether each element contributed positively or negatively to the output variables. Local analysis generated unique SHAP values for individual cases, offering insight into why specific outputs were derived for particular cases. This approach allowed for a more comprehensive evaluation of feature impact (Kim and Kim, 2022; Zhang et al., 2023). Furthermore, the correlations between input variables and the target variable were visualized using partial dependence plots (PDP), which were derived from the weighted average of all visited leaves in a tree-based model. All calculations and plotting were conducted using Python 3.7 with packages from Matplotlib, Numpy, and Pandas. 2. Results and discussion 2.1. Dataset analysis In the ML analysis, it has been recognized that missing data can be imputed to prevent the exclusion of records with missing values (Yuan et al., 2021). To ensure a robust and reliable database, 182 datasets consisting of 14 input features and one output variable (As immobilization efficiency) were collected from various studies and the gaps were filled in using the Iterative Imputer method (Appendix A Fig. S2). As detailed in Table 2, the 14 input variables were categorized into three empirical categories after data collection from publications. For biochar properties, the ranges of T, pH_BC, SA, H/C, O/C, (O+N)/C, C, H, N, and O were 400\u2013700\u00b0C, 3.10\u201310.60, 0.23\u2013333.97 m2/g, 0.01\u20130.40, 0.05\u201315.17, 0.06\u201315.27, 6.00%\u201391.0%, 0.80%\u20134.49%, 0.08%\u20135.60%, and 4.60%\u201391.03%, respectively. For experimental conditions, the ranges of Rate_BC, As_initinal and time were 0.1%\u201315%, 21.72\u20133000 mg/kg, and 0\u2013365 days, respectively. The pH_soil ranged from 4.70 to 8.33. 2.2. ML model development and comparison of model performances After addressing missing data in input features, RF, GBRT, and SVR models were employed to predict As immobilization efficiency in soils based on the 14 input features. As illustrated in Fig. 1, optimal hyperparameters for each model were fine-tuned during the training phase to minimize prediction errors using 5-fold CV. Rainbow plots were utilized to depict how different parameter combinations influenced model performance. Various shades of colors in the rainbow chart indicated varying levels of model effectiveness, with darker shades denoting higher performance. From the three plots in Fig. 1, optimal parameters for GBRT, RF, and SVR were identified based on the color shading. Download : Download high-res image (299KB) Download : Download full-size image Fig. 1. Results of hyperparameter tuning for (a) GBRT, (b) RF, and (c) SVR models. (Key hyperparameters are: GBRT: learning rate (learning_rate) and number of trees (n_estimators); RF: number of trees (n_estimators) and maximum depth of the trees (max_depth); SVR: penalty coefficient (C) and degree of the polynomial kernel function (degree)). A comparison of prediction performance of three ML models on the training and testing data is presented in Fig. 2. Evaluation of prediction performance is based on the values of R2 and RMSE, where higher R2 and lower RMSE indicate superior prediction performance. For the RF model, the R2 values for the training and testing databases were 0.91 and 0.86, respectively. In contrast, the training R2 values for the GBRT and SVR models were 0.37 and 0.78, respectively, and their testing R2 values were 0.67 and 0.64, respectively. These results demonstrate that the RF model exhibited the highest R2 values for both the training and testing databases. In terms of RMSE values, the RF model displayed a significantly lower RMSE value (14.10) for the training database compared to the GBRT and SVR models (36.18 and 21.25, respectively), while the testing RMSE values were relatively similar across all three models (44.60\u201345.23). These findings establish that the RF model, with optimally tuned hyperparameters, outperformed other algorithms in predicting As immobilization efficiency by biochar. This observation aligns with previous research, such as the study by Guo et al. (2023), which reported that the RF model yielded the best performance for soil HM immobilization prediction (training R2 = 0.90, testing R2 = 0.85, RMSE = 4.4) compared to SVR, GBDT, and LR models. Additionally, Hu et al. (2020) found that the RF model exhibited the most accurate prediction ability for bioaccumulation factors of HMs in soil-crop ecosystems, followed by GBM and GLM models. The reason for this result may be due to its ensemble learning approach, easy implementation and tuning, and better ability in handling both numerical and categorical data. Building on the optimal RF predictive model, we have developed a user-friendly graphical interface for predicting As immobilization efficiency by biochar in soils. Access to the web-based software can be obtained at http://rfpreas.rcees.ac.cn/. Download : Download high-res image (296KB) Download : Download full-size image Fig. 2. Predictive performance of (a) GBRT, (b) RF, and (c) SVR to predict arsenic (As) immobilization efficiency in biochar-amended soils. 2.3. Feature importance and partial dependence analyses Using the RF model as a basis, we conducted feature importance analysis using both the RF explainer and SHAP methods (Fig. 3). The RF explainer relies on the average of individual tree predictions within the ensemble of trees (Liu and Aldrich, 2023). In contrast, SHAP employs the Shapley value as an additive feature attribution method, interpreting model predicted values as the sum of attributed values from each input feature (He et al., 2023). While the two methods differ slightly due to their algorithms, their ranking of important features yielded similar results. Notably, the two most crucial features for predicting As immobilization efficiency were consistent: biochar application time and biochar pH. These features explained 38.76%, 42.09%, and 13.11%, 16.77% of the variance, respectively (Fig. 3). Download : Download high-res image (293KB) Download : Download full-size image Fig. 3. Input feature analysis: (a) RF algorithm and (b) SHAP method from the random forest model. To delve deeper into the influence of input features on As immobilization efficiency, one-factor PDP analysis was applied. This analysis visualizes the dependent relationship between arsenic immobilization capability and various features in conjunction with relative importance rankings. As depicted in Appendix A Fig. S3, biochar application time exhibited a positive correlation with As immobilization within the 24\u201350 day range, while prolonged incubation time did not enhance As immobilization. This observation is attributed to the short-term increase in soil pH due to biochar amendment, which subsequently elevated the bioavailability of As. In contrast, the buffering capacity of soil could mitigate the increase of soil pH in the long term, subsequently resulting in As immobilized again. The pH values of biochar ranked second in terms of feature importance (Fig. 3), a key factor affecting As immobilization following biochar application (Zhang et al., 2022). As demonstrated in Appendix A Fig. S3, biochar pH exhibited a negative correlation with As immobilization under alkaline conditions. Previous reports have indicated that biochar typically possesses a pH range of 6.52\u201312.64, and the application of biochar can elevate soil pH (Hossain et al., 2020). Under alkaline conditions, competitive adsorption between negatively charged oxyanion As and \u2013OH groups occurred, resulting in reduced As immobilization efficiency on soil particle surfaces (Sun et al., 2022). Additionally, soil pH, N content, and the rate of biochar application were crucial in predicting As immobilization efficiency (Fig. 3). Research has highlighted that soil pH serves as a pivotal factor influencing the uptake of soil anions by plants. As shown in Appendix A Fig. S3 elevated soil pH (>6.4) could diminish As immobilization efficiency. This can be attributed to the fact that a higher soil pH stimulates the increased release of anionic As, making it more available in soils (Feng et al., 2021; Wan et al., 2019). Regarding the significance of N content, Palansooriya et al. (2022) observed that N content emerged as the most crucial feature for predicting heavy metal immobilization efficiency in their machine learning analysis. The differing rankings between these two studies could be linked to variations in the collected data points. Higher N content was associated with an increased presence of N-containing functional groups, such as \u2013NH2, N\u2013C=O, and C=N, which offer active sites for As immobilization through strong covalent bonding, H bonding, chelation, and electrostatic attraction (Leng et al., 2020). The mobilization of As in soils increased with higher application rates (6%\u20138%) of biochar, whereas lower application rates (<5%) did not significantly impact As mobilization. It is possible that the presence of biochar provided more functional groups for As immobilization. Arabi et al. (2021) also reported that As immobilization efficiency improved with the addition of more than 3% biochar, whereas biochar rates of 3% did not significantly affect As immobilization efficiency. In addition to the factors mentioned above, the Fe content also played a significant role in the immobilization of As in soils. The results for the limited dataset of Fe-modified biochar's impact on As immobilization efficiency (n = 61) are presented in Appendix A Fig. S4. It is evident that pristine biochar had both negative and positive effects on As immobilization, resulting in significant fluctuations, with most cases showing As immobilization efficiency lower than 0. In contrast, the As immobilization efficiency induced by Fe-modified biochar consistently exceeded 0 with minor fluctuations, indicating a notable enhancement in As immobilization in soils when Fe-modified biochar was applied. The increased bioavailability of As observed with the use of pristine biochar in soils can be attributed to the elevated pH following biochar application. This higher pH condition allows dissolved organic matter to compete for sorption sites with As on soil particles (Li et al., 2018). Multiple studies have also investigated As immobilization in soils through the utilization of Fe-modified biochar (Aredes et al., 2013; Wan et al., 2020b; Zhang et al., 2022). These investigations primarily involve mechanisms such as anion exchange, inner-sphere complexation, robust electrostatic attraction, co-precipitation, and diffusion of particles involving Fe and As (Zhang et al., 2022). Consequently, it is plausible to assert that the efficiency of As immobilization within soil matrices can be increased via the utilization of iron-modified biochar. 2.4. Interactions of important features on the impact of As immobilization efficiency The soil pH was an important influencing factor in the predictive model in this work (Fig. 3). It has been reported that the increase in soil pH often results in mobilization of arsenic in the soil (Moreno-Jim\u00e9nez et al., 2012). Considering the pivotal role of soil pH in arsenic immobilization, we conducted an analysis to examine the relationships between soil pH and the three most crucial factors: biochar pH, N content, and biochar application duration. Fig. 4a illustrates the interaction between soil pH and biochar pH. It is evident that the highest As immobilization efficiency was achieved when the biochar pH was below 10, and the soil pH ranged from 6.0 to 7.5. Download : Download high-res image (308KB) Download : Download full-size image Fig. 4. Interactions among four features (N%, biochar application time, pH_biochar and pH_soil) on the impact of As immobilization efficiency. Furthermore, Fig. 4b demonstrates that As immobilization efficiency tended to decrease when the biochar N content exceeded 2%. Additionally, higher levels of As immobilization were observed when the soil pH value fell between 6.8 and 8, coupled with a biochar application duration shorter than 25 days. This effectiveness declined as the application time increased. The results of this study provided some guidance for biochar application. For example, under acidic conditions (pH<6.0), biochar amendment might not improve the immobilization efficiency of As. Generally, As may be effectively immobilized using biochar with N content of 0.5%-1% and pH<10 in soils having a pH ranging from 6 to 7.5. 3. Conclusions This study endeavors to construct three distinct machine learning models, namely GBRT, RF, and SVR, for the purpose of predicting As immobilization efficiency within biochar-amended soils. The RF method emerges as the most adept in terms of predictive capability. Moreover, predicated on the optimal RF predictive model, two key factors are identified, namely biochar application duration and biochar pH. The incorporation of Fe modifications serves to amplify As immobilization efficiency. This reliable predictive framework for As immobilization efficiency through biochar application offers a scientifically grounded guide for the targeted production and application of biochar in As-contaminated soil. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this article. Acknowledgments This work was supported by the National Key Research and Development Program of China (No. 2020YFC1808701). We thank Dr. Shuang Zhang from Research Center for Eco-Environmental Sciences, Chinese Academy of Sciences for his critical reading of the manuscript. Appendix. Supplementary materials Download : Download Word document (9MB) References Arabi et al., 2021 Z. Arabi, J. Rinklebe, A. El-Naggar, D.Y. Hou, A.K. Sarmah, E. Moreno-Jim\u00e9nez (Im)mobilization of arsenic, chromium, and nickel in soils via biochar: a meta-analysis Enviro. Pollut., 286 (2021), Article 117199 View PDFView articleView in ScopusGoogle Scholar Aredes et al., 2013 S. Aredes, B. Klein, M. Pawlik The removal of arsenic from water using natural iron oxide minerals J. Clean. Prod., 60 (2013), pp. 71-76 View PDFView articleView in ScopusGoogle Scholar Awad et al., 2019 Y.M. Awad, M. Vithanage, N.K. Niazi, M. Rizwan, J. Rinklebe, J.E. Yang, et al. Potential toxicity of trace elements and nanomaterials to Chinese cabbage in arsenic- and lead-contaminated soil amended with biochars Environ. Geochem. Health, 41 (2019), pp. 1777-1791 CrossRefView in ScopusGoogle Scholar Bao et al., 2022 Z.J. Bao, C.Z. Shi, W.Y. Tu, L.J. Li, Q. Li Recent developments in modification of biochar and its application in soil pollution control and ecoregulation Environ. Pollut., 313 (2022), Article 120184 View PDFView articleView in ScopusGoogle Scholar Dias et al., 2022 Y.N. Dias, W.V. da Silveira Pereira, M.V. da Costa, E.S. de Souza, S.J. Ramos, C.B. do Amarante, et al. Biochar mitigates bioavailability and environmental risks of arsenic in gold mining tailings from the eastern Amazon J. Environ. Manage., 311 (2022), Article 114840 View PDFView articleView in ScopusGoogle Scholar Feng et al., 2021 R.W. Feng, L.Z. Wang, J.G. Yang, P.P. Zhao, Y.M. Zhu, Y.P. Li, et al. Underlying mechanisms responsible for restriction of uptake and translocation of heavy metals (metalloids) by selenium via root application in plants J. Hazard. Mater., 402 (2021), Article 123570 View PDFView articleView in ScopusGoogle Scholar Gu et al., 2023 S.R. Gu, X. Yang, H.B. Chen, P. Jeyakumar, J.H. Chen, H.L. Wang Crawfish shell- and Chinese banyan branch-derived biochars reduced phytoavailability of As and Pb and altered community composition of bacteria in a contaminated arable soil Sci. Total Environ., 865 (2023), Article 161284 View PDFView articleView in ScopusGoogle Scholar Guo et al., 2023 G.M. Guo, L.Y. Lin, F.M. Jin, O. Ma\u0161ek, Q. Huang Application of heavy metal immobilization in soil by biochar using machine learning Environ. Res., 231 (2023), Article 116098 View PDFView articleView in ScopusGoogle Scholar He et al., 2023 Z.Y. He, Y.J. Yang, R.Z. Fang, S.H. Zhou, W.C. Zhao, Y.J. Bai, et al. Integration of shapley additive explanations with random forest model for quantitative precipitation estimation of mesoscale convective systems Front. Environ. Sci., 10 (2023), Article 1057081 View in ScopusGoogle Scholar Hong et al., 2022 C.Y. Hong, Z.Q. Dong, J.C. Zhang, L. Zhu, L. Che, F.Z. Mao, et al. Effectiveness and mechanism for the simultaneous adsorption of Pb(II), Cd(II) and As(III) by animal-derived biochar/ferrihydrite composite Chemosphere, 293 (2022), Article 133583 View PDFView articleView in ScopusGoogle Scholar Hossain et al., 2020 M.Z. Hossain, M.M. Bahar, B. Sarkar, S.W. Donne, Y.S. Ok, K.N. Palansooriya, et al. Biochar and its importance on nutrient dynamics in soil and plant Biochar, 2 (2020), pp. 379-420 CrossRefView in ScopusGoogle Scholar Hu et al., 2020 B.F. Hu, J. Xue, Y. Zhou, S. Shao, Z.Y. Fu, Y. Li, et al. Modelling bioaccumulation of heavy metals in soil-crop ecosystems and identifying its controlling factors using machine learning Environ. Pollut., 262 (2020), Article 114308 View PDFView articleView in ScopusGoogle Scholar Islam et al., 2021 Md.S. Islam, A.S.I.A. Magid, Y.L. Chen, L.P. Weng, M.Y. Arafat, Z.H. Khan, et al. Arsenic and cadmium load in rice tissues cultivated in calcium enriched biochar amended paddy soil Chemosphere, 283 (2021), Article 131102 View PDFView articleView in ScopusGoogle Scholar Kim and Kim, 2022 Y. Kim, Y. Kim Explainable heat-related mortality with random forest and SHapley Additive exPlanations (SHAP) models Sus. Cities Soc., 79 (2022), Article 103677 View PDFView articleView in ScopusGoogle Scholar Kumar and Bhattacharya, 2022 A. Kumar, T. Bhattacharya Removal of arsenic by wheat straw biochar from soil Bull. Environ. Contam. Toxicol., 108 (2022), pp. 415-422 CrossRefView in ScopusGoogle Scholar Kumar et al., 2022 A. Kumar, T. Bhattacharya, W.A. Shaikh, S. Chakraborty, G. Owens, M. Naushad Valorization of fruit waste-based biochar for arsenic removal in soils Environ. Res., 213 (2022), Article 113710 View PDFView articleView in ScopusGoogle Scholar Lebrun et al., 2019 M. Lebrun, F. Miard, R. Nandillon, G.S. Scippa, S. Bourgerie, D. Morabito Biochar effect associated with compost and iron to promote Pb and As soil stabilization and Salix viminalis L. growth Chemosphere, 222 (2019), pp. 810-822 View PDFView articleView in ScopusGoogle Scholar Lebrun et al., 2022 M. Lebrun, F. Miard, L. Trakal, S. Bourgerie, D. Morabito The reduction of the As and Pb phytotoxicity of a former mine technosol depends on the amendment type and properties Chemosphere, 300 (2022), Article 134592 View PDFView articleView in ScopusGoogle Scholar Leng et al., 2020 L.J. Leng, S.Y. Xu, R.F. Liu, T. Yu, X.M. Zhuo, S.Q. Leng, et al. Nitrogen containing functional groups of biochar: an overview Bioresour. Technol., 298 (2020), Article 122286 View PDFView articleView in ScopusGoogle Scholar Li et al., 2018 G. Li, S. Khan, M. Ibrahim, T.R. Sun, J.F. Tang, J.B. Cotner, et al. Biochars induced modification of dissolved organic matter (DOM) in soil and its impact on mobility and bioaccumulation of arsenic and cadmium J. Hazard. Mater., 348 (2018), pp. 100-108 View PDFView articleGoogle Scholar Li et al., 2011 G. Li, G.X. Sun, P.N. Williams, L. Nunes, Y.G. Zhu Inorganic arsenic in Chinese food and its cancer risk Environ. Int., 37 (2011), pp. 1219-1225 View PDFView articleView in ScopusGoogle Scholar Lin et al., 2017 L. Lin, M.L. Gao, W.W. Qiu, D. Wang, Q. Huang, Z.G. Song Reduced arsenic accumulation in indica rice (Oryza sativa L.) cultivar with ferromanganese oxide impregnated biochar composites amendments Environ. Pollut., 231 (2017), pp. 479-486 View PDFView articleView in ScopusGoogle Scholar Lin et al., 2020 L. Lin, M.L. Gao, Z.G. Song, H.Y. Mu Mitigating arsenic accumulation in rice (Oryza sativa L.) using Fe-Mn-La-impregnated biochar composites in arsenic-contaminated paddy soil Environ. Sci. Pollut. Res., 27 (2020), pp. 41446-41457 CrossRefView in ScopusGoogle Scholar Liu and Aldrich, 2023 X. Liu, C. Aldrich Explaining anomalies in coal proximity and coal processing data with Shapley and tree-based models Fuel, 335 (2023), Article 126891 View PDFView articleView in ScopusGoogle Scholar Mondal and Garg, 2017 M.K. Mondal, R. Garg A comprehensive review on removal of arsenic using activated carbon prepared from easily available waste materials Environ. Sci. Pollut. Res., 24 (2017), pp. 13295-13306 CrossRefView in ScopusGoogle Scholar Moreno-Jim\u00e9nez et al., 2012 E. Moreno-Jim\u00e9nez, E. Esteban, J.M. Pe\u00f1alosa The fate of arsenic in soil-plant systems Rev. Environ. Contam. Toxicol., 215 (2012), pp. 1-37 CrossRefView in ScopusGoogle Scholar Mostafa, 2021 S.M. Mostafa Towards improving machine learning algorithms accuracy by benefiting from similarities between cases J. Intell., 40 (2021), pp. 947-972 CrossRefView in ScopusGoogle Scholar Nguyen and Bui, 2019 H. Nguyen, X.N. Bui Predicting blast-Induced air Overpressure: a robust artificial intelligence system based on artificial neural networks and random forest Nat. Resour. Res., 28 (2019), pp. 893-907 CrossRefView in ScopusGoogle Scholar Palansooriya et al., 2022 K.N. Palansooriya, J. Li, P.D. Dissanayake, M. Suvarna, L.Y. Li, X.Z. Yuan, et al. Prediction of soil heavy metal immobilization by biochar using machine learning Environ. Sci. Technol., 56 (2022), pp. 4187-4198 CrossRefView in ScopusGoogle Scholar Parveen et al., 2019 N. Parveen, S. Zaidi, M. Danish Support vector regression (SVR)-based adsorption model for Ni (II) ions removal Groundw. Sustain. Dev., 9 (2019), Article 100232 View PDFView articleView in ScopusGoogle Scholar Sharma et al., 2022 P.K. Sharma, R. Kumar, R.K. Singh, P. Sharma, A. Ghosh Review on arsenic removal using biochar-based materials Groundw. Sustain. Dev., 17 (2022), Article 100740 View PDFView articleView in ScopusGoogle Scholar Sun et al., 2021 R.Z. Sun, J. Wang, Y.T. Peng, H.M. Wang, Q. Chen Mitigation of arsenic accumulation in arugula (Eruca sativa Mill.) using Fe/Al/Zn impregnated biochar composites Environ. Sci. Pollut. Res., 28 (2021), pp. 4136-4146 CrossRefView in ScopusGoogle Scholar Sun et al., 2022 Y.C. Sun, T.T. Wang, L. Bai, C.H. Han, X.Y. Sun Application of biochar-based materials for remediation of arsenic contaminated soil and water: preparation, modification, and mechanisms J. Environ. Chem. Eng., 10 (2022), Article 108292 View PDFView articleView in ScopusGoogle Scholar Wan et al., 2020a X.M. Wan, M. Lei, T.B. Chen Review on remediation technologies for arsenic-contaminated soil Front. Environ. Sci. Eng., 14 (2020), p. 24 View in ScopusGoogle Scholar Wan et al., 2020b X.M. Wan, C.Y. Li, S.J. Parikh Simultaneous removal of arsenic, cadmium, and lead from soil by iron-modified magnetic biochar Environ. Pollut., 261 (2020), Article 114157 View PDFView articleView in ScopusGoogle Scholar Wan et al., 2019 Y.N. Wan, Q.Q. Huang, A.Y. Camara, Q. Wang, H.F. Li Water management impacts on the solubility of Cd, Pb, As, and Cr and their uptake by rice in two contaminated paddy soils Chemosphere, 228 (2019), pp. 360-369 View PDFView articleView in ScopusGoogle Scholar Wang et al., 2019 C. Wang, J. Luan, C. Wu Metal-organic frameworks for aquatic arsenic removal Water Res., 158 (2019), pp. 370-382 View PDFView articleView in ScopusGoogle Scholar Wang et al., 2023 J.G. Wang, Z.H. Li, Q. Zhu, C.P. Wang, X.J. Tang Review on arsenic environment behaviors in aqueous solution and soil Chemosphere, 333 (2023), Article 138869 View PDFView articleView in ScopusGoogle Scholar Wu et al., 2020 J.Z. Wu, Z.T. Li, D. Huang, X.M. Liu, C.X. Tang, S.J. Parikh, et al. A novel calcium-based magnetic biochar is effective in stabilization of arsenic and cadmium co-contamination in aerobic soils J. Hazard. Mater., 387 (2020), Article 122010 View PDFView articleView in ScopusGoogle Scholar Xiao et al., 2018 X. Xiao, B.L. Chen, Z.M. Chen, L.Z. Zhu, J.L. Schnoor Insight into multiple and multilevel structures of biochars and their potential environmental applications: a critical review Environ. Sci. Technol., 52 (2018), pp. 5027-5047 CrossRefView in ScopusGoogle Scholar Yan et al., 2023 C.C. Yan, X.J. Wang, S.Q. Xia, J.F. Zhao Mechanistic insights into the removal of As(III) and As(V) by iron modified carbon based materials with the aid of machine learning Chemosphere, 321 (2023), Article 138125 View PDFView articleView in ScopusGoogle Scholar Yan et al., 2022 Y.L. Yan, Z.N. Shi, H.L. Li, L.F. Li, X. Yang, S.H. Li, et al. Machine learning and in-silico screening of metal\u2013organic frameworks for O2/N2 dynamic adsorption and separation Chem. Eng. J., 427 (2022), Article 131604 View PDFView articleView in ScopusGoogle Scholar Yang et al., 2022 X. Yang, M. Hinzmann, H. Pan, J.X. Wang, N. Bolan, D.C.W. Tsang, et al. Pig carcass-derived biochar caused contradictory effects on arsenic mobilization in a contaminated paddy soil under fluctuating controlled redox conditions J. Hazard. Mater., 421 (2022), Article 126647 View PDFView articleView in ScopusGoogle Scholar Yang et al., 2018 X. Yang, A.D. Igalavithana, S.-E. Oh, H. Nam, M. Zhang, C.-H. Wang, et al. Characterization of bioenergy biochar and its utilization for metal/metalloid immobilization in contaminated soil Sci. Total Environ., 640\u2013641 (2018), pp. 704-713 View PDFView articleView in ScopusGoogle Scholar Yang et al., 2023 X. Yang, E. Wen, C.J. Ge, A. El-Naggar, H.M. Yu, S.S. Wang, et al. Iron-modified phosphorus- and silicon-based biochars exhibited various influences on arsenic, cadmium, and lead accumulation in rice and enzyme activities in a paddy soil J. Hazard. Mater., 443 (2023), Article 130203 View PDFView articleView in ScopusGoogle Scholar Yuan et al., 2021 X.Z. Yuan, M. Suvarna, S. Low, P.D. Dissanayake, K.B. Lee, J. Li, et al. Applied machine learning for prediction of CO2 adsorption on biomass waste-derived porous carbons Environ. Sci. Technol., 55 (2021), pp. 11925-11936 CrossRefView in ScopusGoogle Scholar Zhang et al., 2023 S.J. Zhang, H.G. Lei, Z.C. Zhou, G.Q. Wang, B. Qiu Fatigue life analysis of high-strength bolts based on machine learning method and SHapley Additive exPlanations (SHAP) approach Structures, 51 (2023), pp. 275-287 View PDFView articleCrossRefGoogle Scholar Zhang et al., 2022 W. Zhang, Y. Cho, M. Vithanage, S.M. Shaheen, J. Rinklebe, D.S. Alessi, et al. Arsenic removal from water and soils using pristine and modified biochars Biochar, 4 (2022), p. 55 View PDFView articleCrossRefGoogle Scholar Zhang et al., 2020 W. Zhang, X.F. Tan, Y.L. Gu, S.B. Liu, Y.G. Liu, X.J. Hu, et al. Rice waste biochars produced at different pyrolysis temperatures for arsenic and cadmium abatement and detoxification in sediment Chemosphere, 250 (2020), Article 126268 View PDFView articleView in ScopusGoogle Scholar Zhu et al., 2020 S.H. Zhu, J.J. Zhao, N. Zhao, X. Yang, C. Chen, J.Y. Shang Goethite modified biochar as a multifunctional amendment for cationic Cd(II), anionic As(III), roxarsone, and phosphorus in soil and water J. Clean. Prod., 247 (2020), Article 119579 View PDFView articleView in ScopusGoogle Scholar Zhu et al., 2019a X.Z. Zhu, Y.N. Li, X.N Wang Machine learning prediction of biochar yield and carbon contents in biochar based on biomass characteristics and pyrolysis conditions Bioresour. Technol., 288 (2019), Article 121527 View PDFView articleView in ScopusGoogle Scholar Zhu et al., 2019b X.Z. Zhu, X.N. Wang, Y.S. Ok The application of machine learning methods for prediction of metal sorption onto biochars J. Hazard. Mater., 378 (2019), Article 120727 View PDFView articleView in ScopusGoogle Scholar Zhu et al., 2022 X.Z. Zhu, Z.B. Xu, S. You, M. Kom\u00e1rek, D.S. Alessi, X.Z. Yuan, et al. Machine learning exploration of the direct and indirect roles of Fe impregnation on Cr(VI) removal by engineered biochar Chem. Eng. J., 428 (2022), Article 131967 View PDFView articleGoogle Scholar Cited by (0) \u204e\u204e These authors contributed equally to this work. View Abstract \u00a9 2024 The Research Center for Eco-Environmental Sciences, Chinese Academy of Sciences. Published by Elsevier B.V. Recommended articles Simultaneous immobilization of multiple heavy metal(loid)s in contaminated water and alkaline soil inoculated Fe/Mn oxidizing bacterium Journal of Environmental Sciences, Volume 147, 2025, pp. 370-381 Yi Wu, \u2026, Zhongren Nan View PDF The impact of endocrine-disrupting chemicals on stem cells: Mechanisms and implications for human health Journal of Environmental Sciences, Volume 147, 2025, pp. 294-309 Juan P. Mu\u00f1oz View PDF Disentangling microbial coupled fillers mechanisms for the permeable layer optimization process in multi-soil-layering systems Journal of Environmental Sciences, Volume 147, 2025, pp. 538-549 Daxin Sun, \u2026, Weiwu Hu View PDF Show 3 more articles Article Metrics Captures Readers: 5 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright \u00a9 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply.",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "Ultrasound-based deep learning radiomics nomogram for risk stratification of testicular masses: a two-center study",
    "doi": "10.1007/s00432-023-05549-6",
    "description": "Objective: To develop an ultrasound-driven clinical deep learning radiomics (CDLR) model for stratifying the risk of testicular masses, aiming to guide individualized treatment and minimize unnecessary procedures. Methods: We retrospectively analyzed 275 patients with confirmed testicular lesions (January 2018 to April 2023) from two hospitals, split into training (158 cases), validation (68 cases), and external test cohorts (49 cases). Radiomics and deep learning (DL) features were extracted from preoperative ultrasound images. Following feature selection, we utilized logistic regression (LR) to establish a deep learning radiomics (DLR) model and subsequently derived its signature. Clinical data underwent univariate and multivariate LR analyses, forming the \"clinic signature.\" By integrating the DLR and clinic signatures using multivariable LR, we formulated the CDLR nomogram for testicular mass risk stratification. The model\u2019s efficacy was gauged using the area under the receiver operating characteristic curve (AUC), while its clinical utility was appraised with decision curve analysis(DCA). Additionally, we compared these models with two radiologists' assessments (5\u20138\u00a0years of practice). Results: The CDLR nomogram showcased exceptional precision in distinguishing testicular tumors from non-tumorous lesions, registering AUCs of 0.909 (internal validation) and 0.835 (external validation). It also excelled in discerning malignant from benign testicular masses, posting AUCs of 0.851 (internal validation) and 0.834 (external validation). Notably, CDLR surpassed the clinical model, standalone DLR, and the evaluations of the two radiologists. Conclusion: The CDLR nomogram offers a reliable tool for differentiating risks associated with testicular masses. It augments radiological diagnoses, facilitates personalized treatment approaches, and curtails unwarranted medical procedures.",
    "journal": "Journal of Cancer Research and Clinical Oncology",
    "authors": [
      "Fang F.",
      "Sun Y.",
      "Huang H.",
      "Huang Y.",
      "Luo X.",
      "Yao W.",
      "Wei L.",
      "Xie G.",
      "Wu Y.",
      "Lu Z.",
      "Zhao J.",
      "Li C."
    ],
    "citation_count": "0",
    "full_text": "Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Advertisement Log in Find a journal Publish with us Track your research Search Cart Home Journal of Cancer Research and Clinical Oncology Article Ultrasound-based deep learning radiomics nomogram for risk stratification of testicular masses: a two-center study Research Open access Published: 19 January 2024 Volume 150, article number 18, (2024) Cite this article Download PDF You have full access to this open access article Journal of Cancer Research and Clinical Oncology Aims and scope Submit manuscript Fuxiang Fang, Yan Sun, Hualin Huang, Yueting Huang, Xing Luo, Wei Yao, Liyan Wei, Guiwu Xie, Yongxian Wu, Zheng Lu, Jiawen Zhao & Chengyang Li  755 Accesses Explore all metrics Abstract Objective To develop an ultrasound-driven clinical deep learning radiomics (CDLR) model for stratifying the risk of testicular masses, aiming to guide individualized treatment and minimize unnecessary procedures. Methods We retrospectively analyzed 275 patients with confirmed testicular lesions (January 2018 to April 2023) from two hospitals, split into training (158 cases), validation (68 cases), and external test cohorts (49 cases). Radiomics and deep learning (DL) features were extracted from preoperative ultrasound images. Following feature selection, we utilized logistic regression (LR) to establish a deep learning radiomics (DLR) model and subsequently derived its signature. Clinical data underwent univariate and multivariate LR analyses, forming the \"clinic signature.\" By integrating the DLR and clinic signatures using multivariable LR, we formulated the CDLR nomogram for testicular mass risk stratification. The model\u2019s efficacy was gauged using the area under the receiver operating characteristic curve (AUC), while its clinical utility was appraised with decision curve analysis(DCA). Additionally, we compared these models with two radiologists' assessments (5\u20138 years of practice). Results The CDLR nomogram showcased exceptional precision in distinguishing testicular tumors from non-tumorous lesions, registering AUCs of 0.909 (internal validation) and 0.835 (external validation). It also excelled in discerning malignant from benign testicular masses, posting AUCs of 0.851 (internal validation) and 0.834 (external validation). Notably, CDLR surpassed the clinical model, standalone DLR, and the evaluations of the two radiologists. Conclusion The CDLR nomogram offers a reliable tool for differentiating risks associated with testicular masses. It augments radiological diagnoses, facilitates personalized treatment approaches, and curtails unwarranted medical procedures. Similar content being viewed by others CT-based deep learning radiomics nomogram for the prediction of pathological grade in bladder cancer: a multicenter study Article Open access 18 September 2023 Radiomics allows for detection of benign and malignant histopathology in patients with metastatic testicular germ cell tumors prior to post-chemotherapy retroperitoneal lymph node dissection Article 11 December 2019 The potential role of MR based radiomic biomarkers in the characterization of focal testicular lesions Article Open access 10 February 2021 Introduction The incidence rate of testicular tumors, which account for approximately 1% of all male tumors and 5% of urinary system tumors, has increased in recent decades, particularly among young and middle-aged men (Park et al. 2018; Znaor et al. 2020; Gurney et al. 2019). The primary symptom is painless testicular enlargement. However, sometimes, they present with symptoms or imaging resembling orchitis, tuberculosis, or other tumor-like conditions, complicating clinical differential diagnosis (Belfield and Findlay-Line 2022; Tandstad et al. 2016). For non-neoplastic testicular lesions, conservative treatment is typically the first approach. However, testicular malignancies often require radical orchiectomy. Studies have shown that unilateral orchiectomy can result in infertility, sexual dysfunction, and reduced sexual function (Henriques et al. 2022; Kerie et al. 2021). Recently, some studies suggest that benign testicular tumors smaller than 2\u20133 cm in diameter can have a favorable prognosis with partial orchiectomy and adjuvant radiotherapy (Fankhauser et al. 2021; Paffenholz et al. 2018; Gentile et al. 2020; Sm et al. 2023). Thus, preoperative risk assessment of testicular masses is crucial. Accurately differentiating between malignant tumors, benign tumors, and non-neoplastic lesions before treatment ensures the best treatment plan for patients. This strategy prevents over-treatment and unnecessary complete resection, prioritizing the preservation of organ function. Ultrasound is essential in evaluating testicular lesions because of its cost-effectiveness, convenience, high reproducibility, and lack of radiation exposure (Minhas et al. 2021). It offers detailed information about a tumor\u2019s location, size, shape, and blood supply (Lai et al. 2023). However, the varied ultrasound characteristics of testicular masses can challenge diagnosis (Marko et al. 2017). Radiomics technology, a recent advancement in clinical methods, is proving invaluable for diagnosing, selecting treatments, and assessing the prognosis of patients with tumors (Zhang et al. 2023). It utilizes quantitative analysis techniques to extract extensive lesion information from conventional medical images, conducting in-depth exploration and analysis of medical images to reveal hidden, intricate details within the images (Lafata et al. 2022). Earlier studies have investigated its use in predicting testicular and other urinary system diseases (Santi et al. 2022; Fan et al. 2022; Xue et al. 2023; Baessler et al. 2020). Lately, deep learning (DL) algorithms have gained widespread recognition and adoption in the field of medical image analysis (Beuque et al. 2023; Tong et al. 2022). DL employs neural networks for feature extraction, enabling automated image analysis post-training\u2014a significant advantage over radiomics. Scholars propose merging DL network output with radiomics features, potentially enhancing image-based radiomics' accuracy and reliability, especially with limited training datasets (Zhang et al. 2022). Among the DL algorithms, convolutional neural networks, with their inherent data-driven modeling capabilities, can directly extract task-related features from medical images, thereby significantly enhancing model accuracy and diagnostic efficiency (Yu et al. 2023; Dominique et al. 2022). Yet, there is a current gap in research that merges DL with ultrasound radiomics to predict the risk stratification of testicular masses. Hence, we introduced two clinical deep learning radiomics (CDLR) nomograms to evaluate their capability in distinguishing between tumors and non-neoplastic lesions, and in differentiating malignant tumors from benign lesions. Materials and methods Research subjects Having received approval from the Ethics Review Committee and a waiver for patient informed consent, we undertook a retrospective study of 275 patients (275 lesions) diagnosed with testicular space-occupying lesions from January 2018 to April 2023. These patients, representing 275 lesions, were treated at both the First Affiliated Hospital of Guangxi Medical University (Center 1) and Baise People\u2019s Hospital (Center 2). To qualify for the study, patients needed to meet certain inclusion criteria. They must have undergone ultrasound examinations within 1 week before surgery, had full ultrasound images and clinical records pre-surgery, and received definitive postoperative pathological diagnoses. Exclusions involved cases with inferior ultrasound image clarity, no evident lesions, concurrent primary tumors elsewhere, or those who underwent neoadjuvant treatment before their ultrasound. Of the participants, 226 from Center 1 were randomly divided into the training (n\u2009=\u2009158 patients) and validation (n\u2009=\u200968 patients) cohorts at a 7:3 ratio. The remaining 49 patients from Center 2 formed an external test cohort. The distribution of lesion pathology types is presented in Supplementary Table 1. An overview of our research process is depicted in Fig. 1. Fig. 1 Patient selection process for this study depicted in a flowchart Full size image Clinical data The collated clinical information included demographics and health metrics such as age, body mass index (BMI), symptom (scrotal pain), existing medical conditions (e.g., hypertension, diabetes, coronary heart disease), complete blood count, serum alpha-fetoprotein (AFP) levels, serum beta-human chorionic gonadotropin (\u03b2-HCG) levels, and more. Radiological evaluations were conducted by experienced radiologists (with 5\u20138 years under their belts). They meticulously analyzed the ultrasound imagery, gauging lesion blood flow distribution through the Adler grading system. The blood flow was then categorized as either sparse (grades 0\u20131) or abundant (grades 2\u20133) based on color Doppler ultrasound readings (Adler et al. 1990; Ma et al. 2015). All clinical data was retrospectively retrieved from the hospital's HIS system. Image acquisition The equipment differed between the two centers. Center 1 utilized the ESAOTE-PLUS color Doppler ultrasound diagnostic equipment from Parkson Medical Company, boasting a high-frequency linear array probe with a 12-MHz frequency. By contrast, Center 2 implemented the Siemens Acuson Sequoia 512 color Doppler ultrasound diagnostic device, outfitted with a 10L4 linear array probe that covered frequencies in the range of 2.9\u20139.9 MHz. Skilled radiologists, each with more than 5 years of experience, captured the ultrasound images in both institutions. For uniformity, the most expansive cross-sectional lesion view was chosen and saved in the digital imaging and communications in medicine format, accumulating 275 images in total. All images were obtained from the hospital's picture archiving and communication system (PACS) and stored in digital imaging and communications in medicine (DICOM) format. Image segmentation and feature extraction We imported all images into ITK-SNAP software (version 3.8; http://www.itksnap.org). The region of interest (ROI) for each lesion was manually outlined along the edge of the lesion within the software by a radiologist with 5 years of experience. To ensure reliability, we evaluated the reproducibility of the outlined features using both intraclass and interclass correlation coefficients (ICCs). To do this, 30 images were selected at random. A radiologist with 8 years of experience outlined the ROI on these images and, after a week, repeated the process for intra-observer consistency assessment. The both radiologists were blinded to the patients\u2019 clinical information and pathology results. We extracted radiomics features from these ROIs using the python pyradiomics (https://pyradiomics.readthedocs.io/en/latest/) package. This included (1) fourteen 2D shape-based features, (2) 306 first-order features, (3) texture features, including features from gray level co-occurrence matrix (GLCM) (n\u2009=\u2009374), gray-level dependence matrix (GLDM) (n\u2009=\u2009238), gray-level run length matrix (GLRLM) (n\u2009=\u2009272), gray-level size zone matrix (GLSZM) (n\u2009=\u2009272), and neighboring gray tone difference matrix (NGTDM) (n\u2009=\u200985), yielding a total of 1,561 radiomics features (Supplementary material Fig. 1). For the extraction of DL features, we utilized a pre-trained ResNet 50 network on the ImageNet database (https://image-net.org/). The training and validation sets remained consistent before training. We fine-tuned model parameters using a 0.01 initial learning rate, 50 epochs, and a batch size of 32, all processed with a stochastic gradient descent optimizer. The output of the ResNet 50 average pooling layer, with adjusted parameters, helped us obtain 2,048 DL features from the ROI of each patient\u2019s ultrasound image. Figure 2 illustrates our research workflow. Fig. 2 Study workflow of the clinical, DLR, and CDLR models for the risk stratification of testicular masses. DLR deep learning radiomics; CDLR clinical deep learning radiomics Full size image Feature selection For the training cohort, we employed a sequential approach to feature screening and dimensionality reduction: First, we retained radiomics features with an ICC exceeding 0.75 and integrated them with the DL features. Then, all selected features were regularized. Second, we applied the minimum redundancy maximum correlation algorithm to further refine feature selection. Finally, using the Least Absolute Shrinkage and Selection Operator (LASSO) regression model along with a tenfold cross-validation process, we identified and retained features with non-zero values. LASSO\u2019s inherent ability for powerful shrinkage and addressing multicollinearity significantly bolstered the accuracy of the model (Liu et al. 2023). Establishment of DLR and clinical models We used LR to construct our models. After the steps of feature screening and dimensionality reduction, we utilized the remaining features to create a DLR model, leading to the generation of a DLR signature. Additionally, single-factor LR analysis was conducted on the clinical characteristics of the training cohort for each variable. If a variable met the significance threshold of p\u2009<\u20090.05, it was chosen for multi-factor LR analysis. This process enabled us to pinpoint critical predictive variables, facilitating the construction of a clinical model. From this, we derived the odds ratio (OR) and their 95% confidence intervals, resulting in a clinical signature. Establishment of CDLR Aiming to fuse clinical and imaging data to develop a precise, objective, and reliable decision-support model, we combined both the clinical and DLR signatures. Using multivariable LR analysis, a combined dimensional CDLR was formulated. For validation, two seasoned radiologists\u2014with 5 and 8 years of ultrasound diagnostic experience\u2014reviewed patient ultrasound images from the validation and test cohorts without knowledge of the pathology. They developed two separate ultrasound feature models, termed Model A and Model B. To gauge the efficacy of these models, receiver operating characteristic (ROC) curves were generated for the training, validation, and test cohorts. From these curves, we determined metrics including AUC, accuracy, sensitivity, specificity, positive predictive value, and negative predictive value. The Delong test was used to discern differences in AUC between models, with a significance level set at p\u2009<\u20090.05. This meticulous evaluation ensures the robustness of our CDLR as a decision-support tool. Statistical analysis For our statistical assessments, we leveraged several software tools, including SPSS software (version 26.0), R software (version 3.6.3; https://www.r-project.org), and Python software (version 3.5.6; http://www.python.org). Descriptive statistics were conveyed as mean\u2009\u00b1\u2009standard deviation. Differences between cohorts were identified using independent sample t-tests. When data displayed a skewed distribution (Q1, Q3), the Mann\u2013Whitney U test was applied. Ratios for categorical variables were derived from the chi-square or Fisher\u2019s exact test, while skewed count data were subjected to rank sum tests. Both univariate and multivariate LR analyses were performed, with a statistical significance threshold of p\u2009<\u20090.05. Results Clinical characteristics Our results can be found in Supplementary Table 2. The results indicated no significant differences among the training, validation, and external test cohorts (p\u2009<\u20090.05). In our study, the training, validation, and test cohorts consisted of 158, 68, and 49 patients, respectively. In Supplementary Table 3, within the training cohort, significant differences were observed in several parameters such as age, lymphocyte count (LYMPH), neutrophil-to-lymphocyte ratio (NLR), platelet-to-lymphocyte ratio (PLR), symptom, serum \u03b2-HCG, and AFP when comparing patients with testicular neoplastic lesions to those with non-neoplastic lesions (p\u2009<\u20090.05). Additionally, in Supplementary Table 4, there were distinct differences between benign and malignant testicular lesions in terms of symptom, serum AFP, \u03b2-HCG levels, and color Doppler blood flow signals (p\u2009<\u20090.05). Construction and validation of DLR To differentiate testicular tumors from non-tumor lesions, we used 7 radiomics features and 19 DL features to construct the DLR model, from which we derived the DLR signature (Fig. 3a and c, Fig. 4a, Supplementary Table 5). The DLR model\u2019s AUC values for the training, validation, and test cohorts were 0.954, 0.850, and 0.803, respectively (Fig. 5a, b and c). To distinguish between benign and malignant testicular lesions, we employed the same feature selection method, identifying 4 radiomics features and 20 DL features (Fig. 3b and d, Fig. 4b, Supplementary Table 5). This DLR model yielded AUCs of 0.894, 0.823, and 0.799 for the training, validation, and test cohorts, respectively (Fig. 5d, e and f). Fig. 3 LASSO, paired with ten-fold cross-validation, was employed to screen both radiomics features and DL features for predicting testicular tumors and malignancies. a, b Show the coefficients of radiomics and DL features obtained from LASSO with ten-fold cross-validation, while c, d depict the mean squared error (MSE) from the tenfold cross-validation. LASSO Least Absolute Shrinkage and Selection Operator; DL deep learning; MSE mean squared error Full size image Fig. 4 a, b Coefficients of the filtered radiomics features and DL features. DL deep learning Full size image Fig. 5 ROC curves comparing different models. a\u2013c ROC curves comparing the clinical, DLR, and CDLR models for predicting testicular tumors across the training, validation, and test cohorts. d\u2013f ROC curves comparing the clinical, DLR, and CDLR models for predicting testicular carcinoma in the training, validation, and test cohorts. ROC receiver operating characteristic; DLR deep learning radiomics; CDLR clinical deep learning radiomics Full size image Development and validation of clinical model and CDLR Within the training cohort, three independent predictors for testicular neoplastic lesions were identified: the absence of symptom, serum AFP levels\u2009\u2265\u200910 ng/mL, and \u03b2-HCG levels\u2009\u2265\u20095 mIU/mL (Supplementary Table 6). From this data, we developed a clinical model, leading to the creation of the clinic signature. By integrating the clinic signature with the DLR signature using multivariable LR, the CDLR showcased enhanced diagnostic prowess (Fig. 5a, b and c, Fig. 6a, Table 1). Specifically, its performance was notably superior to the clinical model (AUC: 0.909 vs. 0.831, p\u2009=\u20090.045), DLR (AUC: 0.909 vs. 0.850, p\u2009=\u20090.211), radiologist A (AUC: 0.909 vs. 0.735, p\u2009=\u20090.041), and radiologist B (AUC: 0.909 vs. 0.775, p\u2009=\u20090.065) in the validation cohort. In the test cohort, CDLR achieved an AUC of 0.835, which exceeded the performances of the clinical model (AUC\u2009=\u20090.768), DLR (AUC\u2009=\u20090.803), and both radiologists (AUC\u2009=\u20090.738 and 0.777, respectively). The absence of symptom, serum AFP\u2009\u2265\u200910 ng/mL, \u03b2-HCG\u2009\u2265\u20095 mIU/mL, and color Doppler flow signals (categorized as Adler classification: 2\u20133) were determined to be independent indicators of testicular malignancy (Supplementary Table 7). In the realm of predicting testicular malignancy (Fig. 5d, e and f, Fig. 6b, Table 2), the CDLR outperformed the clinical model (AUC: 0.851 vs. 0.735, p\u2009=\u20090.014), DLR (AUC: 0.851 vs. 0.823, p\u2009=\u20090.372), radiologist A (AUC: 0.851 vs. 0.744, p\u2009=\u20090.122), and radiologist B (AUC: 0.851 vs. 0.755, p\u2009=\u20090.182) in the validation cohort. Additionally, in the test cohort, CDLR achieved an AUC of 0.834, which outperformed the clinical model (AUC\u2009=\u20090.720), DLR (AUC\u2009=\u20090.799), and radiologist A (AUC\u2009=\u20090.730) and radiologist B (AUC\u2009=\u20090.754). Furthermore, the DCA further indicated that the CDLR delivered more net benefits than the clinical model and DLR in predictions concerning testicular tumors and malignancies (Fig. 6b and d). This superiority in prediction accuracy was further corroborated by the results from the confusion matrix (Fig. 7). Figure 8 displays the activation maps of a convolutional neural network utilized for the identification of testicular non-neoplastic lesions, benign tumors, and malignant tumors. Fig. 6 Nomograms and DCA curves; a CDLR nomogram for predicting testicular tumors; b DCA curve comparison between the clinical, DLR, and CDLR models for predicting testicular tumors. c CDLR nomogram for predicting testicular carcinoma; d DCA curves comparing clinical, DLR, and CDLR models for predicting testicular carcinoma. DCA decision curve analysis; DLR deep learning radiomics; CDLR clinical deep learning radiomics Full size image Table 1 Comparison of diagnostic performances of different models for discriminating testicular neoplasm from non-neoplasm in the training, validation, and test cohorts Full size table Table 2 Comparison of diagnostic performances of different models or discriminating testicular malignant tumor from benign lesions in the training, validation, and test cohorts Full size table Fig. 7 Confusion matrix of different models; a\u2013c confusion matrix of the clinical, DLR, and CDLR models in the validation cohort for predicting testicular tumors; d\u2013f confusion matrix of the clinical, DLR, and CDLR models in the validation cohort for predicting testicular carcinoma. DLR deep learning radiomics; CDLR clinical deep learning radiomics Full size image Fig. 8 Convolutional neural network activation maps used for identifying testicular non-neoplastic lesions, benign tumors, and malignant tumors. The red regions on these maps highlight areas that correlate with the nature of the mass Full size image Discussion Our study indicates that the CDLR surpasses the clinical model, DLR, and radiologists with 5\u20138 years of experience in diagnosing testicular tumors and malignancies. CDLR can be a pivotal tool to support radiologists in imaging diagnosis and help clinicians in making tailored decisions, ultimately cutting down on unnecessary medical procedures. Correctly diagnosing testicular masses is vital, as treatments range from conservative measures to radical surgery. Overlooking a testicular malignancy diagnosis can cause treatment delays and poorer outcomes. For patients with benign testicular tumors, partial orchiectomy can conserve testicular function (Fankhauser et al. 2021; Paffenholz et al. 2018; Gentile et al. 2020; Sm et al. 2023). Conversely, unneeded surgical resections for those with non-neoplastic testicular lesions can adversely affect androgen levels, sexual function, fertility, among others (Henriques et al. 2022; Kerie et al. 2021). Hence, it\u2019s paramount to study and ascertain the nature of testicular masses to minimize unnecessary surgeries and reduce missed diagnoses of malignancies. To our understanding, we are the first research team to devise and authenticate CDLR nomograms to predict testicular mass risk stratification, targeting the identification of neoplastic lesions and malignancies. Radiomics is a burgeoning non-invasive diagnostic method in medical imaging, which focuses on extracting a plethora of quantitative traits from comprehensive medical image data and leveraging this for diagnosis and forecasting. This approach is renowned for its objectivity, non-invasiveness, and data-mining capabilities, marking its potential in tumor diagnosis and treatment (Lambin et al. 2012; Guiot et al. 2022). DL is a formidable method in image analysis, facilitating the derivation of profound insights from image datasets. In our research, we employed deep transfer learning to draw DL attributes and merged them with radiomics traits to determine the nature of the masses. When predicting neoplastic lesions and malignant tumors, DL features stood out in terms of volume and significance among the chosen attributes. This observation underscores that DL technology can adeptly pinpoint key quantitative data mirroring the nature of the masses, thus becoming an indispensable tool for precise diagnoses. Prior research has identified a link between pain and non-neoplastic lesions, with angiogenesis detected via color Doppler ultrasound emerging as a vital independent risk factor for malignancy (Liu et al. 2023). Tumor markers like AFP and \u03b2-HCG are instrumental in pinpointing testicular tumors (Esen et al. 2018). Our results concur with these findings; we recognized asymptomatic scrotal conditions and elevated serum AFP or \u03b2-HCG levels as standalone predictors of testicular tumors. Moreover, we identified asymptomatic scrotal conditions, increased serum AFP or \u03b2-HCG levels, and distinct blood flow signals via color Doppler ultrasound as independent predictors of testicular malignancy. Nevertheless, the accuracy of conventional ultrasound diagnosis for testicular tumors needs enhancement, currently hovering around 76.9% (Lung et al. 2020; Andipa et al. 2004). While contrast-enhanced ultrasound (CEUS) is a newer imaging modality, standard ultrasonography remains the go-to for diagnosing testicular masses (Schr\u00f6der et al. 2016). The constraints of CEUS\u2014such as the need for specialized expertise, higher costs, limited access, and potential contraindications linked to ultrasound contrast agents\u2014have curbed its broad clinical adoption (Liu et al. 2017). In our research, the CDLR attained a commendable accuracy of 88.2%. Past studies emphasized the difficulty in differentiating benign from malignant testicular masses using only conventional ultrasound (Andiap et al. 2004). Fan et al. leveraged magnetic resonance imaging (MRI) volumetric apparent diffusion coefficient histogram analysis, attaining an AUC of 0.822 (Fan et al. 2020). They then integrated MRI imaging with machine learning, producing a prediction model for testicular masses with an AUC of 0.868 (Fan et al. 2022). The enhanced performance in these studies might stem from the extraction of richer features in the radiomics model. Yet, MRI comes with challenges: it\u2019s less sensitive to calcifications, has patient contraindications, is costlier, and has extended examination durations. Our CDLR, showcasing an AUC of 0.851 and an accuracy rate of 79.4%, underlines its significant advantages and potential in this arena. In this study, the standalone DLR showcased superior performance compared to the clinical model, highlighting the importance of using deep image information from radiomics and DL to discern the features of testicular masses. When combined with clinical data, the CDLR displayed better predictive capabilities, surpassing even radiologists with 5\u20138 years of experience. This breakthrough can assist radiologists in precisely identifying testicular tumors and malignancies. However, this study has some limitations. Firstly, as a retrospective study, selection bias and errors are unavoidable. For instance, if ultrasound examinations are conducted by different doctors, subjective errors might arise when selecting the maximum diameter section of the tumor. Secondly, while our study combines clinical characteristics, imaging, and modeling of radiomics and DL features, it doesn\u2019t include other imaging techniques such as contrast-enhanced ultrasound and elastography for comparison or multi-modal fusion. Lastly, defining the ROI boundary might introduce researcher subjectivity. We anticipate using DL technology for automatic identification and delineation of ROI in the future, and we plan on conducting prospective, multicenter studies to further validate our proposed model. Conclusion The clinical-deep learning ultrasound radiomics nomogram introduced in this study produced encouraging results in predicting testicular tumors and malignancies. It even outperformed radiologists with between 3 and 8 years of professional experience. This is crucial for early patient diagnosis, treatment planning, and surgical method decision-making. It can help prevent unnecessary testicle removal or damage to testicular function from excessive medical intervention, providing solid backing for achieving precise tumor treatment goals. Data availability The original contributions presented in the study are included in the article/supplementary material, further inquiries can be directed to the corresponding authors. Abbreviations AUC: Area under the receiver operating characteristic curve AFP: Alpha-fetoprotein BMI: Body mass index \u03b2-HCG: Beta-human chorionic gonadotropin CDLR: Clinical deep learning radiomics CEUS: Contrast-enhanced ultrasound CI: Confidence interval DLR: Deep learning radiomics DCA: Decision curve analysis DICOM: Digital imaging and communications in medicine GLCM: Gray level co-occurrence matrix GLDM: Gray-level dependence matrix GLRLM: Gray-level run length matrix GLSZM: Gray-level size zone matrix ICC: Interclass correlation coefficient LR: Logistic regression LASSO: Least Absolute Shrinkage and Selection Operator LYMPH: Lymphocyte count MRI: Magnetic resonance imaging NGTDM: Neighboring gray tone difference matrix NLR: Neutrophil-to-lymphocyte ratio NPV: Negative predictive value OR: Odds ratio PAS: Picture archiving and communication system PLR: Platelet-to-lymphocyte ratio PPV: Positive predictive value ROI: Region of interest ROC: Receiver operating characteristic References Adler DD, Carson PL, Rubin JM, Quinn-Reid D (1990) Doppler ultrasound color flow imaging in the study of breast cancer: preliminary findings. Ultrasound Med Biol 16:553\u2013559. https://doi.org/10.1016/0301-5629(90)90020-d Article   CAS   PubMed   Google Scholar   Andipa E, Liberopoulos K, Asvestis C (2004) Magnetic resonance imaging and ultrasound evaluation of penile and testicular masses. World J Urol 22:382\u2013391. https://doi.org/10.1007/s00345-004-0425-9 Article   CAS   PubMed   Google Scholar   Baessler B, Nestler T, Pinto Dos Santos D et al (2020) Radiomics allows for detection of benign and malignant histopathology in patients with metastatic testicular germ cell tumors prior to post-chemotherapy retroperitoneal lymph node dissection. Eur Radiol 30:2334\u20132345. https://doi.org/10.1007/s00330-019-06495-z Article   PubMed   Google Scholar   Belfield J, Findlay-Line C (2022) Testicular germ cell tumours-the role of conventional ultrasound. Cancers (basel) 14:3882. https://doi.org/10.3390/cancers14163882 Article   PubMed   Google Scholar   Beuque MPL, Lobbes MBI, van Wijk Y et al (2023) Combining deep learning and handcrafted radiomics for classification of suspicious lesions on contrast-enhanced mammograms. Radiology 307:e221843. https://doi.org/10.1148/radiol.221843 Article   PubMed   Google Scholar   De Santi B, Spaggiari G, Granata AR et al (2022) From subjective to objective: a pilot study on testicular radiomics analysis as a measure of gonadal function. Andrology 10:505\u2013517. https://doi.org/10.1111/andr.13131 Article   CAS   PubMed   Google Scholar   Dominique C, Callonnec F, Berghian A et al (2022) Deep learning analysis of contrast-enhanced spectral mammography to determine histoprognostic factors of malignant breast tumours. Eur Radiol 32:4834\u20134844. https://doi.org/10.1007/s00330-022-08538-4 Article   CAS   PubMed   PubMed Central   Google Scholar   Esen B, Yaman M\u00d6, Baltac\u0131 S (2018) Should we rely on Doppler ultrasound for evaluation of testicular solid lesions? World J Urol 36:1263\u20131266. https://doi.org/10.1007/s00345-018-2273-z Article   CAS   PubMed   Google Scholar   Fan C, Min X, Feng Z et al (2020) Discrimination between benign and malignant testicular lesions using volumetric apparent diffusion coefficient histogram analysis. Eur J Radiol 126:108939. https://doi.org/10.1016/j.ejrad.2020.108939 Article   PubMed   Google Scholar   Fan C, Sun K, Min X et al (2022) Discriminating malignant from benign testicular masses using machine-learning based radiomics signature of appearance diffusion coefficient maps: Comparing with conventional mean and minimum ADC values. Eur J Radiol 148:110158. https://doi.org/10.1016/j.ejrad.2022.110158 Article   PubMed   Google Scholar   Fankhauser CD, Roth L, Kranzb\u00fchler B et al (2021) The role of frozen section examination during inguinal exploration in men with inconclusive testicular tumors: a systematic review and meta-analysis. Eur Urol Focus 7:1400\u20131402. https://doi.org/10.1016/j.euf.2020.06.019 Article   PubMed   Google Scholar   Gentile G, Rizzo M, Bianchi L et al (2020) Testis sparing surgery of small testicular masses: retrospective analysis of a multicenter cohort. J Urol 203:760\u2013766. https://doi.org/10.1097/JU.0000000000000579 Article   PubMed   Google Scholar   Guiot J, Vaidyanathan A, Deprez L et al (2022) A review in radiomics: making personalized medicine a reality via routine imaging. Med Res Rev 42:426\u2013440. https://doi.org/10.1002/med.21846 Article   PubMed   Google Scholar   Gurney JK, Florio AA, Znaor A et al (2019) International trends in the incidence of testicular cancer: lessons from 35 years and 41 countries. Eur Urol 76:615\u2013623. https://doi.org/10.1016/j.eururo.2019.07.002 Article   PubMed   PubMed Central   Google Scholar   Henriques D, Mota Pinto A, Donato H, Le\u00e3o R (2022) Prevalence and management of incidental testicular masses-a systematic review. J Clin Med 11:5770. https://doi.org/10.3390/jcm11195770 Article   PubMed   PubMed Central   Google Scholar   Kerie S, Workineh Y, Kasa AS et al (2021) Erectile dysfunction among testicular cancer survivors: a systematic review and meta-analysis. Heliyon 7:e07479. https://doi.org/10.1016/j.heliyon.2021.e07479 Article   CAS   PubMed   PubMed Central   Google Scholar   Lafata KJ, Wang Y, Konkel B, Yin FF, Bashir MR (2022) Radiomics: a primer on high-throughput image phenotyping. Abdom Radiol 47(9):2986\u20133002. https://doi.org/10.1007/s00261-021-03254-x Article   Google Scholar   Lai DK-H, Cheng ES-W, Mao Y-J et al (2023) Sonoelastography for testicular tumor identification: a systematic review and meta-analysis of diagnostic test accuracy. Cancers (basel) 15:3770. https://doi.org/10.3390/cancers15153770 Article   CAS   PubMed   Google Scholar   Lambin P, Rios-Velazquez E, Leijenaar R et al (2012) Radiomics: extracting more information from medical images using advanced feature analysis. Eur J Cancer 48:441\u2013446. https://doi.org/10.1016/j.ejca.2011.11.036 Article   PubMed   PubMed Central   Google Scholar   Liu Z, Zhang X-Y, Shi Y-J et al (2017) Radiomics analysis for evaluation of pathological complete response to neoadjuvant chemoradiotherapy in locally advanced rectal cancer. Clin Cancer Res 23:7253\u20137262. https://doi.org/10.1158/1078-0432.CCR-17-1038 Article   CAS   PubMed   Google Scholar   Liu J, Ma Y, Xie W et al (2023) Lasso-based machine learning algorithm for predicting postoperative lung complications in elderly: a single-center retrospective study from China. Clin Interv Aging 18:597\u2013606. https://doi.org/10.2147/CIA.S406735 Article   PubMed   PubMed Central   Google Scholar   Liu H, Dong L, Xiang LH, Xu G, Wan J, Fang Y, Ding SS, Jin Y, Sun LP, Xu HX (2023) Multiparametric ultrasound for the assessment of testicular lesions with negative tumoral markers. Asian J Androl 25(1):50 Article   PubMed   Google Scholar   Lung PFC, Fang C, Jaffer OS et al (2020) Vascularity of intra-testicular lesions: inter-observer variation in the assessment of non-neoplastic versus neoplastic abnormalities after vascular enhancement with contrast-enhanced ultrasound. Ultrasound Med Biol 46:2956\u20132964. https://doi.org/10.1016/j.ultrasmedbio.2020.07.028 Article   PubMed   Google Scholar   Ma Y, Li G, Li J, Ren W-D (2015) The diagnostic value of superb microvascular imaging (SMI) in detecting blood flow signals of breast lesions: a preliminary study comparing SMI to color Doppler flow imaging. Medicine (baltimore) 94:e1502. https://doi.org/10.1097/MD.0000000000001502 Article   PubMed   Google Scholar   Marko J, Wolfman DJ, Aubin AL, Sesterhenn IA (2017) Testicular seminoma and its mimics: from the radiologic pathology archives. Radiographics 37:1085\u20131098. https://doi.org/10.1148/rg.2017160164 Article   PubMed   Google Scholar   Minhas S, Bettocchi C, Boeri L et al (2021) European Association of Urology guidelines on male sexual and reproductive health: 2021 update on male infertility. Eur Urol 80:603\u2013620. https://doi.org/10.1016/j.eururo.2021.08.014 Article   PubMed   Google Scholar   Paffenholz P, Held L, Loosen SH et al (2018) Testis sparing surgery for benign testicular masses: diagnostics and therapeutic approaches. J Urol 200:353\u2013360. https://doi.org/10.1016/j.juro.2018.03.007 Article   PubMed   Google Scholar   Park JS, Kim J, Elghiaty A, Ham WS (2018) Recent global trends in testicular cancer incidence and mortality. Medicine (baltimore) 97:e12390. https://doi.org/10.1097/MD.0000000000012390 Article   PubMed   Google Scholar   Schr\u00f6der C, Lock G, Schmidt C et al (2016) Real-time elastography and contrast-enhanced ultrasonography in the evaluation of testicular masses: a comparative prospective study. Ultrasound Med Biol 42:1807\u20131815. https://doi.org/10.1016/j.ultrasmedbio.2016.03.026 Article   PubMed   Google Scholar   Sm C, Jw M et al (2023) Diagnosis and management of indeterminate testicular lesions. Nat Rev Urol. https://doi.org/10.1038/s41585-023-00786-3 Article   Google Scholar   Tandstad T, Stahl O, Dahl O, Haugnes HS, H\u00e5kansson U, Karlsdottir \u00c5, Kjellman A, Langberg CW, Laurell A, Oldenburg J, Solberg A (2016) Treatment of stage I seminoma, with one course of adjuvant carboplatin or surveillance, risk-adapted recommendations implementing patient autonomy: a report from the Swedish and Norwegian Testicular Cancer Group (SWENOTECA). Ann Oncol 27(7):1299\u20131304. https://doi.org/10.1093/annonc/mdw164 Article   CAS   PubMed   Google Scholar   Tong T, Gu J, Xu D, Song L, Zhao Q, Cheng F, Yuan Z, Tian S, Yang X, Tian J, Wang K (2022) Deep learning radiomics based on contrast-enhanced ultrasound images for assisted diagnosis of pancreatic ductal adenocarcinoma and chronic pancreatitis. BMC Med 20(1):74. https://doi.org/10.1186/s12916-022-02258-8 Article   PubMed   PubMed Central   Google Scholar   Xue N, Wang G, Zhang S, Lu Y (2023) The value of contrast-enhanced ultrasonography in differential diagnosis of primary testicular germ cell tumors and non-germ cell tumors over 50 years old. Front Oncol 13:1090823. https://doi.org/10.3389/fonc.2023.1090823 Article   PubMed   PubMed Central   Google Scholar   Yu F-H, Miao S-M, Li C-Y et al (2023) Pretreatment ultrasound-based deep learning radiomics model for the early prediction of pathologic response to neoadjuvant chemotherapy in breast cancer. Eur Radiol 33:5634\u20135644. https://doi.org/10.1007/s00330-023-09555-7 Article   PubMed   Google Scholar   Zhang X, Zhang Y, Zhang G, Qiu X, Tan W, Yin X, Liao L (2022) Deep learning with radiomics for disease diagnosis and treatment: challenges and potential. Front Oncol 17(12):773840. https://doi.org/10.3389/fonc.2022.773840 Article   Google Scholar   Zhang Y-P, Zhang X-Y, Cheng Y-T et al (2023) Artificial intelligence-driven radiomics study in cancer: the role of feature engineering and modeling. Mil Med Res 10:22. https://doi.org/10.1186/s40779-023-00458-8 Article   PubMed   PubMed Central   Google Scholar   Znaor A, Skakkebaek NE, Rajpert-De Meyts E et al (2020) Testicular cancer incidence predictions in Europe 2010\u20132035: a rising burden despite population ageing. Int J Cancer 147:820\u2013828. https://doi.org/10.1002/ijc.32810 Article   CAS   PubMed   Google Scholar   Download references Acknowledgements We are extremely grateful to Dr. Chengyang Li (Department of Urology, The First Affiliated Hospital of Guangxi Medical University) for his selfless assistance throughout the present study. Funding This work was supported by grants from the National Natural Science Foundation of China (81660125). Author information Author notes Fuxiang Fang and Yan Sun contributed equally to this work and therefore share first authorship. Chengyang Li and Jiawen Zhao contributed equally to this work. Authors and Affiliations Department of Urology, The First Affiliated Hospital of Guangxi Medical University, 6 Shuangyong Road, Nanning, 530021, China Fuxiang Fang, Yan Sun, Wei Yao, Guiwu Xie, Yongxian Wu, Zheng Lu, Jiawen Zhao & Chengyang Li Department of Emergency, The First Affiliated Hospital of Guangxi Medical University, Nanning, 530021, China Hualin Huang Department of Epidemiology and Health Statistics, School of Public Health of Guangxi Medical University, Nanning, 530021, China Yueting Huang Department of Ultrasound, The First Affiliated Hospital of Guangxi Medical University, Nanning, 530021, China Liyan Wei Department of Urology, Baise People\u2019s Hospital, Baise, 533099, China Xing Luo Contributions CL and JZ: Conceptualization, funding acquisition and methodology. FF and YS: formal analysis, software, and writing\u2013original draft. XL, HH, YH, WY, LW and GX: Data curation. YW, ZL: Review and editing. Corresponding authors Correspondence to Jiawen Zhao or Chengyang Li. Ethics declarations Conflict of interest The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. Ethical statement The study protocol was approved by the Institutional Review Board. Because the study was retrospective, the institutional review board waived the patient's informed consent. Additional information Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Supplementary Information Below is the link to the electronic supplementary material. Supplementary file1 (DOCX 162 KB) Rights and permissions Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. Reprints and permissions About this article Cite this article Fang, F., Sun, Y., Huang, H. et al. Ultrasound-based deep learning radiomics nomogram for risk stratification of testicular masses: a two-center study. J Cancer Res Clin Oncol 150, 18 (2024). https://doi.org/10.1007/s00432-023-05549-6 Download citation Received 16 October 2023 Accepted 22 November 2023 Published 19 January 2024 DOI https://doi.org/10.1007/s00432-023-05549-6 Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Keywords Ultrasound Testicular lesions Radiomics Deep learning Use our pre-submission checklist Avoid common mistakes on your manuscript. Associated Content Part of a collection: Nomograms in Oncology Sections Figures References Abstract Introduction Materials and methods Results Discussion Conclusion Data availability Abbreviations References Acknowledgements Funding Author information Ethics declarations Additional information Supplementary Information Rights and permissions About this article Advertisement Discover content Journals A-Z Books A-Z Publish with us Publish your research Open access publishing Products and services Our products Librarians Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy rights Accessibility statement Terms and conditions Privacy policy Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln (3000134173) \u00a9 2024 Springer Nature",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "A semi-supervised ensemble clustering algorithm for discovering relationships between different diseases by extracting cell-to-cell biological communications",
    "doi": "10.1007/s00432-023-05559-4",
    "description": "Introduction: In recent decades, many theories have been proposed about the cause of hereditary diseases such as cancer. However, most studies state genetic and environmental factors as the most important parameters. It has been shown that gene expression data are valuable information about hereditary diseases and their analysis can identify the relationships between these diseases. Objective: Identification of damaged genes from various diseases can be done through the discovery of cell-to-cell biological communications. Also, extraction of intercellular communications can identify relationships between different diseases. For example, gene disorders that cause damage to the same cells in both breast and blood cancers. Hence, the purpose is to discover cell-to-cell biological communications in gene expression data. Methodology: The identification of cell-to-cell biological communications for various cancer diseases has been widely performed by clustering algorithms. However, this field remains open due to the abundance of unprocessed gene expression data. Accordingly, this paper focuses on the development of a semi-supervised ensemble clustering algorithm that can discover relationships between different diseases through the extraction of cell-to-cell biological communications. The proposed clustering framework includes a stratified feature sampling mechanism and a novel similarity metric to deal with high-dimensional data and improve the diversity of primary partitions. Results: The performance of the proposed clustering algorithm is verified with several datasets from the UCI machine learning repository and then applied to the FANTOM5 dataset to extract cell-to-cell biological communications. The used version of this dataset contains 108 cells and 86,427 promoters from 702 samples. The strength of communication between two similar cells from different diseases indicates the relationship of those diseases. Here, the strength of communication is determined by promoter, so we found the highest cell-to-cell biological communication between \u201cbasophils\u201d and \u201cciliary.epithelial.cells\u201d with 62,809 promoters. Conclusion: The maximum cell-to-cell biological similarity in each cluster can be used to detect the relationship between different diseases such as cancer.",
    "journal": "Journal of Cancer Research and Clinical Oncology",
    "authors": [
      "Shi X.",
      "Yue C.",
      "Quan M.",
      "Li Y.",
      "Nashwan Sam H."
    ],
    "citation_count": "0",
    "full_text": "Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Advertisement Log in Find a journal Publish with us Track your research Search Cart Home Journal of Cancer Research and Clinical Oncology Article A semi-supervised ensemble clustering algorithm for discovering relationships between different diseases by extracting cell-to-cell biological communications Research Published: 02 January 2024 Volume 150, article number 3, (2024) Cite this article Download PDF Journal of Cancer Research and Clinical Oncology Aims and scope Submit manuscript Xiuchao Shi, Chunxiao Yue, Meiping Quan, Yalin Li & Hiba Nashwan Sam  623 Accesses Explore all metrics Abstract Introduction In recent decades, many theories have been proposed about the cause of hereditary diseases such as cancer. However, most studies state genetic and environmental factors as the most important parameters. It has been shown that gene expression data are valuable information about hereditary diseases and their analysis can identify the relationships between these diseases. Objective Identification of damaged genes from various diseases can be done through the discovery of cell-to-cell biological communications. Also, extraction of intercellular communications can identify relationships between different diseases. For example, gene disorders that cause damage to the same cells in both breast and blood cancers. Hence, the purpose is to discover cell-to-cell biological communications in gene expression data. Methodology The identification of cell-to-cell biological communications for various cancer diseases has been widely performed by clustering algorithms. However, this field remains open due to the abundance of unprocessed gene expression data. Accordingly, this paper focuses on the development of a semi-supervised ensemble clustering algorithm that can discover relationships between different diseases through the extraction of cell-to-cell biological communications. The proposed clustering framework includes a stratified feature sampling mechanism and a novel similarity metric to deal with high-dimensional data and improve the diversity of primary partitions. Results The performance of the proposed clustering algorithm is verified with several datasets from the UCI machine learning repository and then applied to the FANTOM5 dataset to extract cell-to-cell biological communications. The used version of this dataset contains 108 cells and 86,427 promoters from 702 samples. The strength of communication between two similar cells from different diseases indicates the relationship of those diseases. Here, the strength of communication is determined by promoter, so we found the highest cell-to-cell biological communication between \u201cbasophils\u201d and \u201cciliary.epithelial.cells\u201d with 62,809 promoters. Conclusion The maximum cell-to-cell biological similarity in each cluster can be used to detect the relationship between different diseases such as cancer. Similar content being viewed by others SCEC: A Novel Single-Cell Classification Method Based on Cell-Pair Ensemble Learning Chapter \u00a9 2021 A Discussion on the Biological Relevance of Clustering Results Chapter \u00a9 2014 Identification of cancer subtypes from single-cell RNA-seq data using a consensus clustering method Article Open access 31 December 2018 Introduction The human body consists of hundreds of types of cells (Kayal et al. 2019; Peng et al. 2022). These cells are directly or indirectly dependent on each other and have the ability to communicate and influence each other. Therefore, an effective mechanism is needed to find the relationship between this astronomical number of cells. Finding these communications will help identify relationships between different diseases. The nucleus of each cell has the coded instructions necessary to direct the cell's activities and make the necessary proteins. A whole group of these instructions is called a genome (Sivadas et al. 2022). Human genome is the genetic set and genes inside the nucleus of human cells (de Souza et al. 2016). There are millions of genes on each of the chromosomes, each of which has a specific role in the cell. Let the gene expression associated with a cell be represented by promoters (Shahraki et al. 2023). To date, many diagnostic models have been presented for different diseases such as cancer. Each model uses different tools based on a specific dataset for prediction work (Zhang et al. 2022a). In recent years, datasets have been created that include a wide range of diseases. Datasets based on gene expression such as FANTOM5 include 1836 different samples from 201,803 regions of different genes that simultaneously cover several diseases (Rezaeipanah and Ahmadi 2022). Each sample contains the information of one patient from one cell or tissue. Here, sampling has been done in the form of gene expression, which shows how many times a gene has produced itself (de Souza et al. 2016). In general, damaged cells from the body due to a disease can also be observed for other diseases (Li et al. 2023). If the promoters of a cell from two or more diseases are high enough, then it can be said that these diseases have a similar effect on this cell. Since there is information related to cells/tissues for each person, this dataset can be used to detect the communications between cells and tissues in the expression of different genes (Forouzandeh et al. 2023). In general, the analysis of gene expression information in order to identify intercellular communications requires mapping the problem to a clustering problem. Clustering algorithms can find relationships between different diseases by finding the most similar damaged cells. Clustering algorithms are one of the most important techniques in data mining, machine learning and pattern recognition and are known as an effective method in data visualization and analysis (Rezaeipanah et al. 2021). These algorithms have wide applications in image processing, image segmentation, document analysis, market research, etc. Data clustering is data analysis without any prior information to assign each sample of the dataset to a group as a cluster (Zhang et al. 2022b; Zhao et al. 2023a). Each clustering algorithm seeks to create groups of data with maximum similarity between samples in the same clusters and minimum similarity between samples in different clusters. These algorithms are known as unsupervised learning methods, because the class labels are not available in the data analysis process (Cao et al. 2022; Tang et al. 2023). In general, the types of clustering algorithms include hierarchical and partitional (Zhang et al. 2018). Hierarchical algorithms use a similarity metric for the clustering task. In each step of these algorithms, the data are divided into two categories to finally create a tree structure as a dendrogram (Wang et al. 2022). Dendrogram is a tree-structured graph that visualizes the result of a clustering algorithm at different levels of partitions (Forouzandeh et al. 2023). Meanwhile, partitional algorithms directly put data into multiple clusters based on distance or similarity. Hard and soft are common types of partitional clustering algorithms (Cheng et al. 2023). In hard clustering, a sample belongs to only one cluster; while in soft clustering, the degree of belonging of a sample to each cluster is determined by a number between 0 and 1. In many real-world applications, the number of features in a dataset is too large for clustering. In most cases, there are a large number of unrelated features for clustering (Hou et al. 2020). Also, some features may be less important than others. Therefore, applying clustering with a subset of features can lead to an increase in the quality of the final partition. Meanwhile, not all clustering algorithms perform best for all data (Mojarad et al. 2021). Ensemble clustering is very popular to improve the performance of individual clustering algorithms. In an ensemble clustering algorithm, several individual clustering algorithms are combined to cover each other's weaknesses (Zhang et al. 2018). According to this, it is expected that the use of ensemble clustering algorithms will perform better than individual clustering algorithms. Combining individual clustering algorithms with fixed weight is a common approach in ensemble technique. However, using fixed weights in the whole clustering process leads to a decrease in efficiency. In recent years, approaches based on adaptive weights during the clustering process have been developed to solve this shortcoming (Hou et al. 2020). In general, the use of traditional clustering algorithms does not perform well in dealing with high-dimensional data due to the correlation of features, noise, and dispersion. On the other hand, applying the information of paired constraints can increase the effectiveness of individual clustering algorithms (Wang et al. 2020; Zhang et al. 2022c). This information includes must-link and cannot-link constraints. The must-link constraint indicates that a pair of samples belong to the same cluster, and the cannot-link constraint indicates that a pair of samples belongs to two different clusters. Since effective clustering is challenging due to the lack of prior knowledge, using the constraints information as limited prior knowledge can improve the clustering performance. The use of constraint information in the clustering process has led to the emergence of clustering with semi-supervised learning (Mojarad et al. 2021; Bridges and Miller-Jensen 2022). This paper proposes a semi-supervised ensemble clustering framework to discover relationships between diseases based on the extraction of cell-to-cell biological communications. The proposed semi-supervised framework uses prior knowledge in both parts of the ensemble, including the creation of primary partitions and the consensus function. Also, we present a stratified feature sampling mechanism to deal with high-dimensional data, which can reduce the risk of not selecting features to create primary partitions. In addition, the proposed clustering framework uses a new similarity metric developed based on the information of all primary partitions. Our method has medical applications for the treatment and prevention of cancer. In fact, we are looking to identify cells that may be destroyed in the same way in two different cancers. The main contribution of this study is as follows: A clustering framework is proposed by joining \u201csemi-supervised learning\u201d and \u201censemble technique\u201d, which is configured based on stratified feature sampling mechanism and a novel similarity metric Identification of cells with the highest promoters in order to discover relationships between different diseases on the FANTOM5 dataset Validation of the effectiveness of the proposed clustering framework on a wide range of UCI datasets The remainder of this paper is organized as follows: The related work is summarized in \u201cRelated works\u201d. The fundamental concepts related to the problem are given in \u201cBackground\u201d. \u201cProposed clustering framework\u201d explains the proposed clustering framework. The effectiveness of the proposed framework is discussed through numerical simulations in \u201cExperiments\u201d. Finally, the paper ends with conclusions in \u201cConclusions\u201d. Related works Identification of intercellular communication from gene expression data with clustering algorithms is very common (Mojarad et al. 2021). Clustering is one of the data analysis techniques and so far, various solutions have been provided for it (Tan et al. 2022; Chang et al. 2022). For example, k-means, density-based spatial clustering of applications with noise (DBSCAN), multi-view spectral clustering, non-negative matrix factorization-based clustering, unsupervised deep embedding clustering, mean shift clustering, hierarchical clustering, etc. (Zhang et al. 2020; Lei et al. 2022). Compared to partitional clustering algorithms, many efforts have been reported for the improvements of hierarchical clustering algorithms in the last few decades. Compared to classification, prior knowledge such as class labels is not available for clustering. Some studies use limited prior knowledge as constraint information in clustering (Hou et al. 2020). Zhang et al. (2018) used the pairwise constraints information to improve clustering performance and obtained some successes. Other semi-supervised clustering algorithms include constraints k-means, Constraint-based DBSCAN (C-DBSCAN), Pairwise Constrained k-means (PCKmeans), semi-supervised deep fuzzy c-mean clustering, semi-supervised denpeak clustering with pairwise constraints, semi-supervised deep embedded clustering, exhaustive and efficient constraint propagation, and semi-supervised maximum margin clustering (Mojarad et al. 2021). Prades et al. (2020) proposed an agglomerative clustering approach to detect the number of endmembers in hyperspectral images. The authors follow this hypothesis in clustering that there is a cluster for each material different from image. Here, an approach based on principal component analysis applied to the centered image is used to reduce the dimensions. With reducing the dimensions of the image, the authors use a k-means algorithm to create primary clusters. Here, symmetric Kullback\u2013Leibler (SKL) divergence is used as the distance calculation metric. SKL, also known as relative entropy, is a statistical metric from information theory to quantify the difference. This study uses principal component analysis to calculate the density of clusters. After that, a model-based agglomerative clustering approach is applied to provide a hierarchy of partitions. Eventually, the final partition of the hierarchy is determined by a validation algorithm. The number of clusters in the results of this model is considered as the number of materials. Rezaeipanah and Ahmadi (2022) introduced multi-stage weights adjustment in the multi-layer perceptron (MWAMLP) for breast cancer detection. MWAMLP is an ensemble approach that uses three homogeneous multi-layer perceptron (MLP) neural networks for the classification task. The consensus function used in MWAMLP is developed based on the meta-classifier technique. The accuracy of this method on the WBCD dataset is 98.76% on average. Mojarad et al. (2021) used an ensemble clustering algorithm to model inherited disease behavior (ECIDB). Here, cell-to-cell and tissue-to-tissue communications are extracted from the FANTOM5 dataset to identify cells with the highest disruption in each disease pair. The proposed algorithm uses the graph topological structure to represent the FANTOM5 dataset and uses an innovative similarity metric to calculate the cell-to-cell similarity matrix. An ensemble clustering is then applied to identify primary intercellular or intertissue communications. Finally, a friend recommender-based system considering clustering information and topological similarities is used to identify related cells. Sangeetha and Prakash (2021) proposed using deep learning to improve breast cancer disease prediction. A stacked sparse auto encoder network (SSAE) is constructed to learn features effectively. The network consists of a softmax classifier and several sparse autoencoders. In addition to adjusting the parameters of the algorithm, deep learning models are required. The parameters of the stacked sparse autoencoder can, therefore, be adjusted using particle swarm optimization (PSO). Regarding feature learning and classification, the PSO improves the performance of the SSAE. Kayal et al. (2019) conducted a study to provide a new advanced classification method using a deep neural network (DNN) to predict the survival of patients with hepatic cancer. In the proposed method, the authors selected 15 risk factors out of 49 risk factors which are significantly responsible for hepatocellular carcinoma and then applied their method. According to the results, the proposed method is more accurate than other methods. Sivadas et al. (2022) attempted to investigate the impact of racial information and natural factors on the incidence and progression of cancer by employing a multi-omics data fusion breast cancer survival cycle marker detection prediction model. The primary objective of this research is to enhance the prediction of breast cancer survival cycles through the development of a multi-omics fusion prediction model based on ensemble learning. This model incorporates clinical data, transcriptomics data, and methylomics data derived from The Cancer Genome Atlas (TCGA) datasets. The experimental results demonstrate that the three-omics fusion approach (with an accuracy rate of 97.43%) outperforms single-omics experiments and other race-based multi-omics and single-omics experiments in the context of the three-omics experiments, considering racial disparities. This research offers technical support for the classification of breast cancer patient survival cycle predictions and introduces novel concepts for the study of breast cancer survival prognostics. Talatian Azad et al. (2021) proposed an intelligent ensemble classification method based on multi-layer perceptron (IEC-MLP) for breast cancer detection. IEC-MLP uses genetic algorithm for feature selection and parameter settings of MLP neural network. Here, MLP is developed based on an ensemble classification approach with three classifiers. This method detects breast cancer with high accuracy on the WBCD dataset, where the average accuracy is reported to be 98.74%. Background In this section, some basic concepts about the research method are explained. These concepts include system model, hierarchical clustering, semi-supervised clustering, ensemble clustering, and feature sampling. System model An individual clustering algorithm is denoted by \\(\\pi\\). Ensemble clustering consists of several individual clustering algorithms. We assume that \\(\\Pi =\\left\\{{\\pi }_{1},{\\pi }_{2},\\dots ,{\\pi }_{k},\\dots ,{\\pi }_{Z}\\right\\}\\) is the set of \\(Z\\) individual clustering algorithms, where \\({\\pi }_{k}\\) represents the \\(k\\)-th clustering algorithm. Each \\({\\pi }_{k}\\in \\Pi\\) can be applied to a dataset. We assume that \\(X=\\left\\{{x}_{1},{x}_{2},\\dots ,{x}_{i},\\dots ,{x}_{N}\\right\\}\\) is a dataset with \\(N\\) samples, where \\({x}_{i}=\\langle {x}_{i,1},{x}_{i,2},\\dots ,{x}_{i,j},\\dots ,{x}_{i,M}\\rangle\\) represents the \\(i\\)-th sample with \\(M\\) features. Applying each \\({\\pi }_{k}\\) to \\(X\\) results in a partition with multiple clusters. We assume that \\({p}_{k}=\\left[{c}_{k,1},{c}_{k,2},\\dots ,{c}_{k,l},\\dots ,{c}_{k,\\left|{p}_{k}\\right|}\\right]\\) is the partition obtained by applying \\({\\pi }_{k}\\) on \\(X\\) with \\(\\left|{p}_{k}\\right|\\) clusters. Here, \\({c}_{k,l}\\) represents the \\(l\\)-th cluster of the \\(k\\)-th partition. Considering ensemble clustering, applying set \\(\\Pi\\) on \\(X\\) results in \\(P=\\left\\{{p}_{1},{p}_{2},\\dots ,{p}_{Z}\\right\\}\\). We assume that \\({p}_{*}=\\Gamma \\langle {p}_{1},{p}_{2},\\dots ,{p}_{Z}\\rangle\\) is the final partition obtained by consensus of set \\(P\\). Here, \\(\\Gamma\\) represents a consensus function such as majority vote. Let \\({p}_{*}=\\left[{c}_{1},{c}_{2},\\dots ,{c}_{K}\\right]\\) be the details of the final partition, where \\(K\\) represents the total number of clusters. Hierarchical clustering Clustering is an unsupervised learning mechanism for grouping data, where samples belonging to each group have the highest similarity to each other and samples from different groups have the lowest similarity to each other. Partitional clustering and hierarchical clustering are two common types of clustering (Rostami et al. 2023). Partitional clustering clusters samples based on an objective function, where each sample belongs to only one cluster and the total number of clusters is known in advance. The k-means is one of the most common partitional clustering algorithms that performs clustering with the objective of minimizing the average distance to the center of each cluster (Torabi et al. 2022; Cao et al. 2023a). Meanwhile, hierarchical clustering can show a hierarchy of samples by dendrogram. There are two general types of hierarchical clustering: (1) Divisive hierarchical clustering (DHC) or top-down approach where all samples belong to the same cluster at first. After that, each cluster is divided into smaller clusters so that finally each sample has its own cluster. (2) Agglomerative hierarchical clustering (AHC) or bottom-up approach where each sample represents a cluster at first. After that, each pair of clusters with the highest similarity are merged until finally all samples belong to the same cluster (Farahbakhsh et al. 2021). As shown in Fig. 1, the final result for both DHC and AHC is in the form of a dendrogram. Each level in the dendrogram represents a partition as the result of clustering. Fig. 1 An example of hierarchical clustering Full size image Linkage-based metrics are one of the most common AHC methods, which are defined by inter-cluster distance metrics (Rostami et al. 2023). Single linkage, average linkage, centroid linkage, and complete linkage are examples of linkage-based AHC clustering. A summary of these methods is presented in Table 1. In this table, \\(x\\in {c}_{i}\\) represents sample \\(x\\) from cluster \\({c}_{i}\\), \\(\\left|{c}_{i}\\right|\\) indicates the number of cluster members \\({c}_{i}\\) and \\({d}_{x,y}\\) indicates the distance between \\(x\\) and \\(y\\) based on a distance measure such as Euclidean (Sivadas et al. 2022). Basically, the difference between these methods is in the distance calculation metric. Table 1 AHC clustering methods based on linkage Full size table Semi-supervised clustering In unsupervised clustering, the learning algorithm has no knowledge about the labels of the samples. However, semi-supervised clustering can use prior knowledge such as labels of samples for clustering (Wang et al. 2023; Yue et al. 2023). Usually, the prior knowledge used by semi-supervised learning is known as constraint information (Sangeetha and Prakash 2021). Constraint information can include dependencies between samples or an additional set of labeled samples. Pairwise constraints information is the most common prior knowledge used for semi-supervised learning. Pairwise constraints include pairs of samples that are labeled as belonging to the same or different clusters. Therefore, the quality of the partition created by semi-supervised clustering should be improved compared to unsupervised clustering, because semi-supervised clustering uses prior knowledge. Basically, the constraint information can be based on metrics, clusters, and samples (Rostami et al. 2023). Metric-based constraint information allows the use of different distance/similarity measures in the learning process. Cluster-based constraint information provides the possibility of using cluster characteristics such as shape, size, and diameter. Also, sample-based constraint information includes must-link and cannot-link parameters (Jannesari et al. 2023). Here, must-link indicates the possibility of assigning two samples to one cluster, while cannot-link indicates the impossibility of assigning two samples to one cluster. Selecting the most potential sample for semi-supervised clustering is an important challenge for using information constraints (Shahidinejad et al. 2021). Since the labels of samples are not available in clustering, dense groups should be identified in order to find samples that definitely belong to the same cluster. According to the above, semi-supervised clustering simultaneously uses both labeled and unlabeled samples, as shown in Fig. 2. Typically, semi-supervised clustering is configured based on a small number of labeled samples compared to a large number of unlabeled samples. Constraint-based semi-supervised clustering and distance-based semi-supervised clustering are two common categories of semi-supervised clustering (Hayashi et al. 2018). The former uses constraint information to support the algorithm and improve clustering, while the latter includes adaptive distance metrics to extract constraints in supervised learning. Fig. 2 Example of clustering with unsupervised and semi-supervised learning Full size image Ensemble clustering It has been proven that no individual clustering method can provide the best performance for all contexts (Sivadas et al. 2022). Since each individual clustering method has its own advantages and disadvantages, combining several methods can provide more stable, scalable and accurate results compared to each of the individual methods. Ensemble clustering-based methods combine the results of several clustering methods to avoid the disadvantages of each of them and enable effective clustering for more datasets. As shown in Fig. 3, ensemble clustering consists of a number of individual homogeneous or heterogeneous clustering algorithms. These algorithms are considered as members of ensemble clustering. Selecting suitable members that can achieve quality and diversity in the final consensus is an important challenge in ensemble clustering. Fig. 3 Ensemble clustering architecture Full size image Each individual clustering algorithm \\({\\pi }_{k}\\) is applied as a weak method on the dataset and outputs a partition \\({p}_{k}\\). The partitions created in this step are merged by a consensus function \\(\\Gamma\\) to create the final partition \\({p}_{*}\\). Although all partitions can participate in the consensus process, a subset of primary partitions or part of their associated clusters can be candidates for the consensus function. This is a major challenge to address in ensemble clustering. Therefore, ensemble clustering has two main phases: creating primary partitions and merging them by a consensus function (Forouzandeh et al. 2023). The consensus function is an important issue in ensemble clustering, for which various methods have been introduced so far. The most common consensus functions include simple voting, iterative voting, weighted similarity, mixture model, correlation matrix, meta-clustering, etc. In various studies, the superiority of semi-supervised clustering algorithms against unsupervised clustering has been proven (Sangeetha and Prakash 2021). Meanwhile, ensemble clustering provides better performance than individual clustering. With this motivation, we focus on SSEC-based approaches. The use of constraint information in SSEC is a hot research topic in machine learning. Here, prior knowledge such as pairwise constraints and labels of samples are incorporated into ensemble clustering in order to improve efficiency. Most of the existing SSEC approaches use constraint information only to create primary partitions, while the use of this information is ignored in the consensus function (Rezaeipanah and Ahmadi 2022). Figure 4 shows a schematic framework of SSEC-based approaches considering prior knowledge. Fig. 4 SSEC framework considering prior knowledge Full size image Feature sampling Today, the number of large-scale datasets has increased significantly due to the growth of data collection devices (Zhao et al. 2023b; Cao et al. 2023b). Machine learning algorithms for effective analysis of these datasets face serious challenges. Meanwhile, clustering algorithms face issues such as feature correlation, noise, sparseness, and computational complexity when processing big data, which may lead to their failure. Reducing the dimensions of the data by selecting a subset of the original features is one of the most common solutions to address this problem (Rezaeipanah and Ahmadi 2022). Techniques based on randomization such as random projection (Rostami et al. 2023) and random feature sampling (Sangeetha and Prakash 2021) are among the most common methods for selecting the subset of suitable features. However, randomization-based techniques do not consider correlations between features and cannot select effective features for clustering. Stratified feature sampling mechanism was introduced by Jing et al. (2015) to address this issue. This mechanism uses the k-means algorithm to cluster features into a specified number of groups. After that, a number of features are randomly selected from each cluster with the same proportion to obtain several subsets of features. The ensemble clustering architecture considering feature sampling is shown in Fig. 5. Fig. 5 Ensemble clustering architecture considering feature sampling Full size image Proposed clustering framework The proposed clustering framework has four general phases. In the first phase, stratified feature sampling mechanism is applied. This mechanism clusters the features of the dataset using the K-means algorithm to create an independent subset of features for each individual clustering algorithm. Here, feature selection probabilities are adjusted with the aim of reducing the risk of not selecting some features for the clustering task. The second phase is related to the generation of primary partitions by \\(Z\\) individual clustering algorithms. We use AHC-based algorithms for the clustering task, where each algorithm creates its own partition based on a subset of specified features. The output partition in each AHC-based algorithm is determined from the dendrogram by Bayesian PAC theory (Abddallah and Yousef 2018). The third phase consists of presenting a new similarity metric that uses a wide range of information to calculate the similarity between each sample pair, cluster pair and meta-cluster pair. The consensus function is configured in the fourth phase. Since not all primary clusters and not all primary partitions have the same strength, we develop a weighting policy in which the merits of clusters and the strength of partitions are considered to contribute to the final consensus. Finally, the meta-clustering technique is applied as a consensus function to create the final partition. We configure each AHC-based clustering algorithm with semi-supervised learning and use the information of pairwise constraints to improve the clustering performance in both parts of creating primary partitions and the consensus function. An overview of the proposed clustering framework is shown in Fig. 6. Fig. 6 An overview of the proposed clustering framework Full size image The proposed algorithm for large-scale data clustering uses the stratified feature sampling mechanism. In this mechanism, each \\({\\pi }_{k}\\in \\Pi\\) performs clustering based on a subset of the main features. Let \\({\\pi }_{k}\\) form an primary partition based on \\({\\mathcalligra{s}}_{k}\\), where \\({\\mathcalligra{s}}_{k}\\in \\mathcal{S}\\) represents the subset of the \\(k\\)-th selected feature. The mechanism of stratified feature sampling can provide the most suitable set \\(\\mathcal{S}\\) for ensemble clustering. Here, the features of the dataset \\(X\\) are clustered by K-means, and then a number of features are sampled from each cluster to form \\({\\mathcalligra{s}}_{k}\\). This process is applied to all \\({\\mathcalligra{s}}_{k}\\in \\mathcal{S}, \\forall k=1, 2,\\dots ,Z\\). To reduce the risk of not selecting some features, we calculate the probability of selecting the features by considering the sampling history. Let \\({\\mathcalligra{r}}_{j}\\) refer to the sampling rate of the \\(j\\)th feature from the dataset \\(X\\). Here, the sampling rate for selecting the first subset is the same for all features, for example, \\({\\mathcalligra{r}}_{j}=1/M\\). The sampling rate is updated to select the second subset, where the sampling rate of unselected features is halved. This process is repeated for other subsets to reduce the risk of not selecting features. Let \\({s}_{i,j}\\in S\\) be the similarity between samples \\({x}_{i}\\) and \\({x}_{j}\\). We use a new similarity metric considering a wide range of information to calculate the similarity matrix \\(S\\). The Eq. (1) defines the similarity for \\({s}_{i,j}\\). $${s}_{i,j}=\\frac{1}{Z}\\times \\sum_{{p}_{k}\\in P}\\left[\\frac{1}{\\left|{p}_{k}\\right|}\\times \\sum_{{c}_{k,l}\\in {p}_{k}}\\left\\{\\begin{array}{cc}\\frac{{M}_{{c}_{k,l}}+{W}_{{p}_{k}}}{{d}_{i,j}}\\times {\\beta }^{\\left|{c}_{k,l}\\right|}& ({x}_{i},{x}_{j})\\in {c}_{k,l}\\\\ \\frac{1}{{d}_{i,j}}\\times {\\beta }^{\\left|{c}_{k,l}\\right|}& {\\text{otherwise}}\\end{array}\\right.\\right],$$ (1) where \\(Z\\) is the total number of partitions, \\({p}_{k}\\) is the detail of the kth partition, \\(P\\) is the set of all partitions, \\(\\left|{p}_{k}\\right|\\) is the number of clusters in \\({p}_{k}\\), \\({c}_{k,l}\\) is the detail of the \\(l\\)th cluster in \\({p}_{k}\\), \\(\\left|{c}_{k,l}\\right|\\) is the number of samples of \\({c}_{k,l}\\), \\({d}_{i,j}\\) is the Euclidean distance between \\({x}_{i}\\) and \\({x}_{j}\\), \\({M}_{{c}_{k,l}}\\) is the merit associated with \\({c}_{k,l}\\), \\({W}_{{p}_{k}}\\) is the strength/weight associated with \\({p}_{k}\\), and \\(\\beta\\) is a damping factor to reduce the effect of large cluster sizes. In addition to the similarity between each pair of samples, we calculate the similarity between each pair of clusters and each pair of meta-clusters. Let each meta-cluster be a set of several clusters. Equation (2) formulates the similarity between two clusters \\({c}_{k,1}\\) and \\({c}_{k,2}\\) as \\({{\\text{CS}}}_{{c}_{k,1},{c}_{k,2}}\\). Also, Eq. (3) formulates the similarity between two meta-clusters \\({\\psi }_{1}=\\left\\{{c}_{\\mathrm{1,1}},{c}_{\\mathrm{1,2}},\\dots ,{c}_{1,u},\\dots ,{c}_{1,\\left|{\\psi }_{1}\\right|}\\right\\}\\) and \\({\\psi }_{2}=\\left\\{{c}_{\\mathrm{2,1}},{c}_{\\mathrm{2,2}},\\dots ,{c}_{2,v},\\dots ,{c}_{2,\\left|{\\psi }_{2}\\right|}\\right\\}\\) as \\({{\\text{MS}}}_{{\\psi }_{1},{\\psi }_{2}}\\). $${{\\text{CS}}}_{{c}_{k,1},{c}_{k,2}}=\\frac{{\\sum }_{i=1}^{\\left|{c}_{k,1}\\right|}{\\sum }_{j=1}^{\\left|{c}_{k,2}\\right|}{s}_{i,j}}{\\left|{c}_{k,1}\\right|.\\left|{c}_{k,2}\\right|},$$ (2) $${{\\text{MS}}}_{{\\psi }_{1},{\\psi }_{2}}=\\frac{{\\sum }_{u=1}^{\\left|{\\psi }_{1}\\right|}{\\sum }_{v=1}^{\\left|{\\psi }_{2}\\right|}{CS}_{{c}_{1,u},{c}_{2,v}}}{\\left|{\\psi }_{1}\\right|\\times \\left|{\\psi }_{2}\\right|}.$$ (3) Finally, we use a consensus function based on the meta-clustering technique to create the final partition. According to this technique, candidate clusters are considered from all partitions in a set and then re-clustered by average linkage to create meta-clusters. Here, the number of meta-clusters represents the number of final clusters. Eventually, the final partition is created by assigning each sample of the dataset \\(X\\) to a meta-cluster with the highest similarity. In this paper, candidate clusters are selected to participate in the final consensus based on the merit of the primary clusters and the strength of the primary partitions. In extensive studies, normalized mutual information (NMI) is used to evaluate the partition generated from a clustering algorithm (Rezaeipanah and Ahmadi 2022). NMI can calculate the similarity between two partitions such as \\({p}_{u}\\) and \\({p}_{v}\\) by Eq. (4). $${\\text{NMI}}\\left({p}_{u},{p}_{v}\\right)=\\frac{2\\sum_{i=1}^{\\left|{p}_{u}\\right|}\\sum_{j=1}^{\\left|{p}_{v}\\right|}{N}_{ij}{\\text{log}}\\left(\\frac{N.{N}_{ij}}{{N}_{i1}.{N}_{2j}}\\right)}{\\sum_{i=1}^{\\left|{p}_{u}\\right|}{N}_{i1}\\mathrm{ log}\\left(\\frac{{N}_{i1}}{N}\\right)+\\sum_{j=1}^{\\left|{p}_{v}\\right|}{N}_{2j}\\mathrm{ log}\\left(\\frac{{N}_{2j}}{N}\\right)},$$ (4) where \\({N}_{ij}\\) is the number of identical samples in \\({c}_{u,i}\\in {p}_{u}\\) and \\({c}_{v,j}\\in {p}_{v}\\) and \\({N}_{iu}\\) is the number of samples in \\({c}_{u,i}\\). If \\({p}_{v}\\) is assumed as the reference partition, then \\({\\text{NMI}}\\left({p}_{u},{p}_{v}\\right)\\) represents the strength of the partition \\({p}_{u}\\). Let the strength of partition \\({p}_{u}\\) be formulated as the weight of partition \\({p}_{u}\\) by \\({W}_{{p}_{u}}\\). In addition to robustness, we use the merit of the clusters to determine the candidate clusters in the final consensus. Law et al. (2004) developed the NMI criterion and used it to calculate the merit of clusters. The authors converted a cluster into a partition in order to use NMI for evaluation work. Let \\({\\overline{c} }_{k}\\) be a cluster with all samples not in \\({c}_{k}\\). \\({c}_{k}\\) is considered a positive cluster if at least half of its samples are found in another cluster. According to these definitions, the cluster \\({c}_{k}\\) is considered as a partition \\({\\widehat{p}}_{k}=\\left\\{{c}_{k},{\\overline{c} }_{k}\\right\\}\\) with the union of all positive clusters. With converting \\({c}_{k}\\) to \\({\\widehat{p}}_{k}\\), cluster merit of \\({c}_{k}\\) is formulated by Eq. (5). According to the aforementioned concepts, each \\({c}_{k,l}\\in {p}_{k}\\) with a predefined threshold can participate in the final consensus. The Eq. (6) defines the condition for \\({c}_{k,l}\\) to be a candidate for participating in the final consensus. $${M}_{{c}_{k}}={\\text{NMI}}\\left({p}_{0},{\\widehat{p}}_{k}\\right),$$ (5) $$\\left(\\xi \\times {W}_{{p}_{k}}+\\left(1-\\xi \\right)\\times {M}_{{c}_{k,l}}\\right)\\ge \\theta ,$$ (6) where \\({p}_{0}\\) is defined as the reference partition. Also, \\(\\xi\\) is the influence coefficient of the cluster level with respect to the partition level and \\(\\theta\\) is a threshold for determining the consensus candidates. Each \\({\\pi }_{k}\\in \\Pi\\) is an individual clustering algorithm based on AHC such as average linkage. Here, all \\({\\pi }_{k}\\in \\Pi\\) are configured using average linkage and based on semi-supervised learning. Also, the algorithm used in the consensus function is applied using average linkage and based on semi-supervised learning. Let \\({d}_{i,j}\\) be the distance between samples \\({x}_{i}\\) and \\({x}_{j}\\). We use the information of pairwise constraints such as must-link and cannot-link to define \\({d}_{i,j}\\) in semi-supervised learning. If the sample pair \\(({x}_{i},{x}_{j})\\) is covered by the must-link, then it belongs to the set \\({\\Delta }_{M}\\). Meanwhile, if the sample pair \\(({x}_{i},{x}_{j})\\) is covered by cannot-link, then it belongs to the set \\({\\Delta }_{C}\\). Let all members of sets \\({\\Delta }_{M}\\) and \\({\\Delta }_{C}\\) have symmetry and transitivity properties. The symmetry property is formulated by Eq. (7) and the transitivity property is formulated by Eq. (8). Considering semi-supervised learning in the average linkage algorithm, \\({d}_{i,j}\\) is formulated by pairwise constraints information with Eq. (9). $$\\left\\{\\begin{array}{c}({x}_{i},{x}_{j})\\in {\\Delta }_{M} \\to ({x}_{j},{x}_{i})\\in {\\Delta }_{M}\\\\ ({x}_{i},{x}_{j})\\in {\\Delta }_{C} \\to ({x}_{j},{x}_{i})\\in {\\Delta }_{C,}\\end{array}\\right.$$ (7) $$\\left\\{\\begin{array}{c}({x}_{i},{x}_{k}) \\& ({x}_{k},{x}_{j})\\in {\\Delta }_{M} \\to ({x}_{i},{x}_{j})\\in {\\Delta }_{M}\\\\ ({x}_{i},{x}_{k}) \\& ({x}_{k},{x}_{j})\\in {\\Delta }_{C} \\to ({x}_{i},{x}_{j})\\in {\\Delta }_{C},\\end{array}\\right.$$ (8) $${d}_{i,j}=\\left\\{\\begin{array}{cc}0& ({x}_{i},{x}_{j})\\in {\\Delta }_{M}\\\\ \\infty & \\left({x}_{i},{x}_{j}\\right)\\in {\\Delta }_{C}.\\end{array}\\right.$$ (9) Experiments We validate the performance of the proposed framework with several numerical experiments considering the UCI dataset and then use it to extract intercellular communication on the FANTOM5 dataset. The proposed clustering algorithm has been implemented using the MATLAB 2021a simulator on a personal computer with Intel\u00ae Core\u2122 i7 Processor up to 3.4.00 GHz and 16 GB DDR3 Memory. Datasets The evaluations are based on 10 datasets from the UCI machine learning repository, as shown in Table 2. We use a mean replacement policy when dealing with missing values. All datasets used have class labels, which are used as reference partitions in clustering. Since the proposed clustering framework is based on semi-supervised learning, we consider 5% of the supervised samples as the constraint information. Table 2 Details of the datasets used in the simulations Full size table In addition, we use the FANTOM5 dataset to analyze gene expression data and extract intercellular communication. FANTOM5 was compiled in collaboration with the University of Sydney, Australia. In addition to cell information, this dataset also contains tissue information, which is not considered in the current study. Details of this dataset are available at http://fantom.gsc.riken.jp/5. The full version of the FANTOM5 dataset contains 1836 samples per column, where each sample contains information related to a cell or tissue from a single patient. For each sample, 201,802 promoters from different regions of a gene from a specific cell are available. With filtering data related to tissues, we found 108 unique cells. Here, there are 702 examples related to cells. Meanwhile, the rows in this dataset represent the numbers of promoters, which are identified using \u201centrezgene_id\u201d. Some promoter values are not specified and specifically have the value \u201cNA\u201d. Unavailable promoter information is removed. After that, 86,428 promoters are available for each sample. The columns related to cells are taken from different samples of the human body and there may be several samples of the same cell. In general, the first 7 columns related to the promoter information have been sampled and the 8th columns are samples. In addition, the ID of each sample includes details such as disease type, time point, cell name and patient ID. For example, the ID of a sample from the FANTOM5 dataset is: \u201c239SLAM rinderpest infection, 00hr, biol_rep1.CNhs14406.13541-145H4\u201d. Here, \u201cSLAM\u201d represents a family of cell surface receptors and other coding are related to the patient. An overview of the FANTOM5 dataset for cells is shown in Table 3. Table 3 Overview of the FANTOM5 dataset Full size table Evaluation metrics A partition generated by a clustering algorithm is ideal if it has a maximum inter-cluster distance and a minimum intra-cluster distance. We use criteria such as NMI, Adjusted Rand Index (ARI) and silhouette coefficient to evaluate the clustering results (Talatian Azad et al. 2021). NMI is a common criterion for evaluating the performance of clustering algorithms that can measure the similarity between two independent partitions. NMI is defined according to Eq. (4). ARI is another criterion for evaluating the performance of clustering algorithms. ARI uses the Rand Index (RI) to calculate the similarity between two independent partitions. ARI can calculate the similarity between two partitions such as \\({p}_{u}\\) and \\({p}_{v}\\) by Eq. (10). $${\\text{ARI}}\\left({p}_{u},{p}_{v}\\right)=\\frac{\\sum_{i=1}^{\\left|{p}_{u}\\right|}\\sum_{j=1}^{\\left|{p}_{v}\\right|}\\left(\\begin{array}{c}{N}_{ij}\\\\ 2\\end{array}\\right)-\\frac{\\left[\\sum_{i=1}^{\\left|{p}_{u}\\right|}\\left(\\frac{{N}_{iu}}{2}\\right)\\sum_{j=1}^{\\left|{p}_{v}\\right|}\\left(\\frac{{N}_{vj}}{2}\\right)\\right]}{\\left(\\frac{N}{2}\\right)}}{\\frac{1}{2}\\left[\\sum_{i=1}^{\\left|{p}_{u}\\right|}\\left(\\frac{{N}_{iu}}{2}\\right)+\\sum_{j=1}^{\\left|{p}_{v}\\right|}\\left(\\frac{{N}_{vj}}{2}\\right)\\right]-\\frac{\\left[\\sum_{i=1}^{\\left|{p}_{u}\\right|}\\left(\\frac{{N}_{iu}}{2}\\right)\\sum_{j=1}^{\\left|{p}_{v}\\right|}\\left(\\frac{{N}_{vj}}{2}\\right)\\right]}{\\left(\\frac{N}{2}\\right)}}.$$ (10) The silhouette coefficient is an internal index to calculate the performance of clustering algorithms, which performs the evaluation process based on density and separation characteristics. In silhouette, the validity of a partition is calculated based on the combination of intra-cluster and inter-cluster similarity for each pair of independent clusters. The obtained value of the silhouette coefficient is between \u2212\u20091 and +\u20091, and a silhouette with a value of +\u20091 represents an ideal clustering. The silhouette coefficient for \\({x}_{i}\\in {c}_{l}\\) from the \\({p}_{k}\\) partition is calculated by Eq. (11). $${Sil}_{i}=\\frac{{a}_{i}-{b}_{i}}{{\\text{max}}({a}_{i},{b}_{i})},$$ (11) where \\({a}_{i}\\) and \\({b}_{i}\\) are calculated by Eqs. (12) and (13), respectively. $${a}_{i}=\\frac{1}{\\left|{c}_{l}\\right|}\\sum_{{x}_{j}\\in X|{x}_{j}\\in {c}_{l}}{d}_{i,j},$$ (12) $${b}_{i}=\\underset{{c}_{q}\\in {p}_{k}|{c}_{q}\\ne {c}_{l}}{{\\text{min}}}\\left(\\frac{1}{\\left|{c}_{q}\\right|}\\sum_{{x}_{j}\\in X|{x}_{j}\\in {c}_{q}}{d}_{i,j}\\right).$$ (13) Analysis of results The proposed clustering algorithm is compared with several equivalent algorithms such as MWAMLP (Rezaeipanah and Ahmadi 2022), ECIDB (Mojarad et al. 2021), SSAE (Sangeetha and Prakash 2021), and TCGA (Sivadas et al. 2022). Before the comparisons, we prove that the proposed clustering algorithm using the average linkage algorithm provides the best performance in both the creation of primary partitions and the consensus function. We compare the average linkage algorithm with other AHC-based algorithms such as single linkage, centroid linkage and complete linkage. Table 4 shows the results of this comparison. The results of this comparison are presented based on accuracy and the best results are bolded. Also, each row presents the results associated with a dataset, while the last row is the average of the results. The results clearly prove the superiority of the average linkage algorithm and its use in the proposed clustering framework. Table 4 Comparison of average linkage algorithm compared to other AHC-based algorithms Full size table The comparison of the proposed algorithm based on NMI and ARI criteria compared to MWAMLP, ECIDB, SSAE and TCGA is presented in Tables 5 and 6, respectively. The best results of these tables are highlighted in bold. The proposed algorithm performs better than all existing algorithms in many datasets. However, the simulation results show that ECIDB produces quite competitive results with the proposed algorithm. Among the 10 existing ECIDB datasets, the proposed algorithm outperforms the proposed algorithm considering the NMI criterion in the Iris and Colon datasets. Also, ECIDB performs best considering the ARI criterion on the Titanic, Banana and Splice datasets. On average, in the NMI criterion, the proposed algorithm is 8.8%, 1.7%, 12.9%, and 16.5% superior compared to MWAMLP, ECIDB, SSAE, and TCGA, respectively. This superiority for the ARI criterion is 4.6%, 1.8%, 11.5%, and 8.1%, respectively. Table 5 Comparison of different algorithms in terms of NMI criterion Full size table Table 6 Comparison of different algorithms in terms of ARI criterion Full size table Although the proposed clustering algorithm performs better in terms of accuracy, NMI and ARI compared to equivalent algorithms, runtime analysis is also important. High-complexity clustering algorithms are not capable of processing large-scale datasets. The proposed clustering algorithm is equipped with a stratified feature sampling mechanism to deal with big data. This mechanism leads to the reduction of computational complexity and it is expected that the runtime in the proposed algorithm is lower than other algorithms. Figure 7 shows the runtime results of different clustering algorithms. The results clearly show that our algorithm has lower runtime in all datasets. On average, the proposed clustering algorithm provides 6.1%, 34.6%, 43.5%, and 30.8% less runtime compared to MWAMLP, ECIDB, SSAE, and TCGA algorithms, respectively. Fig. 7 Comparison of different algorithms in terms of running time Full size image We proved that the proposed clustering framework has ideal performance for clustering real-world datasets. Hence, we apply it to clustering the FANTOM5 dataset and extracting cell-to-cell biological communications. The FANTOM5 dataset is multifaceted, where multiple samples from the same cell with multiple patients are available. Also, there are different samples of the same cell in different diseases. Therefore, each cell may be related to other cells through various diseases. The concept of communication in FANTOM5 is expressed with promoters. A high value of a promoter indicates the reproduction or disruption of a part of gene expression related to a cell. The activation threshold of promoters has a significant effect on the discovery of intercellular communication. Here, we cluster with different thresholds from 500 to 4000 samples of the FANTOM5 dataset and report the results in terms of the silhouette coefficient. We compare the presented results with ECIDB (Mojarad et al. 2021), as this algorithm was also applied to the FANTOM5 dataset. The results of this comparison are presented in Table 7. The results show the superiority of the proposed algorithm in most thresholds. Meanwhile, the best results are obtained for the silhouette factor with a threshold of 1000. Here, the proposed algorithm with a silhouette coefficient of 0.952 and 19 clusters of samples related to cells have been clustered. These results were obtained for ECIDB with silhouette coefficient equal to 0.809 and 20 clusters. Table 7 Comparison of FANTOM5 dataset clustering results in terms of silhouette coefficient with different thresholds Full size table We analyzed the clustering of the FANTOM5 dataset with different thresholds. A suitable threshold is equal to 1000, considering it leads to the identification of strong communications between cells. In each cluster, the pair of cells with the strongest correlation may indicate a relationship between different diseases. We extracted pairs of cells from different clusters with the highest correlation, whose samples belong to different diseases. Table 8 shows some of the strongest cell-to-cell communications, along with disease names and genes sampled. It shows the hereditary behavior between which diseases, based on which genes and in which cells. Table 8 Number of the strongest cell-to-cell communications identified Full size table Conclusions Gene expression data contain important information of various diseases. The gene expression data of some diseases may be similar. Indeed, some cells in different diseases may contain similar gene expression data. Therefore, discovering the relationships between diseases through the extraction of cell-to-cell biological communications is challenging and can change our understanding of how diseases such as cancer develop. The communication between two cells occurs when the number of promoters is significantly expressed in a number of cells. It is obvious that designing a method to discover cell-to-cell biological communications and identify the real communication between diseases is important for the medical society. A clustering algorithm based on semi-supervised learning and ensemble technique was proposed in the paper to identify intercellular communication. This framework is equipped with a stratified feature sampling mechanism to deal with high-dimensional data. Also, in this framework, a new similarity metric is developed that uses a wide range of primary partition information to estimate similarity. Our proposed framework uses the constraints information in both the phases of creating the primary partitions and the consensus function. The performance of the proposed framework has been validated through clustering of the UCI dataset. Therefore, the proposed framework for extracting intercellular communication was successfully applied to the FANTOM5 dataset. The results of the simulations show that the most promoters between cancer and diseases such as inflammation, monocytosis and aortic aneurysm occur on the \u201cABLIM1\u201d gene. Data availability Data sharing not applicable to this manuscript as no datasets were generated or analyzed during the current study. Code availability There is no free code for this study. References Abddallah L, Yousef M (2018) Ensemble clustering based dimensional reduction. In: Database and expert systems applications: DEXA 2018 international workshops, BDMICS, BIOKDD, and TIR, Regensburg, Germany, September 3\u20136, 2018, Proceedings 29. Springer International Publishing, pp 115\u2013125 Bridges K, Miller-Jensen K (2022) Mapping and validation of scRNA-Seq-derived cell-cell communication networks in the tumor microenvironment. Front Immunol 13:885267 Article   CAS   PubMed   PubMed Central   Google Scholar   Cao C, Wang J, Kwok D, Cui F, Zhang Z, Zhao D et al (2022) webTWAS: a resource for disease candidate susceptibility genes identified by transcriptome-wide association study. Nucleic Acids Res 50(D1):D1123\u2013D1130 Article   CAS   PubMed   Google Scholar   Cao Z, Niu B, Zong G, Xu N (2023a) Small-gain technique-based adaptive output constrained control design of switched networked nonlinear systems via event-triggered communications. Nonlinear Anal Hybrid Syst 47:101299 Article   MathSciNet   Google Scholar   Cao Y, Xu N, Wang H, Zhao X, Ahmad AM (2023b) Neural networks-based adaptive tracking control for full-state constrained switched nonlinear systems with periodic disturbances and actuator saturation. Int J Syst Sci 54(14):2689\u20132704 Article   ADS   MathSciNet   Google Scholar   Chang Y, Niu B, Wang H, Zhang L, Ahmad AM, Alassafi MO (2022) Adaptive tracking control for nonlinear system in pure-feedback form with prescribed performance and unknown hysteresis. IMA J Math Control Inf 39(3):892\u2013911 Article   MathSciNet   Google Scholar   Cheng F, Liang H, Niu B, Zhao N, Zhao X (2023) Adaptive neural self-triggered bipartite secure control for nonlinear MASs subject to DoS attacks. Inf Sci 631:256\u2013270 Article   Google Scholar   de Souza PS, Faccion RS, Bernardo PS, Maia RC (2016) Membrane microparticles: shedding new light into cancer cell communication. J Cancer Res Clin Oncol 142:1395\u20131406 Article   PubMed   Google Scholar   Farahbakhsh F, Shahidinejad A, Ghobaei-Arani M (2021) Multiuser context-aware computation offloading in mobile edge computing based on Bayesian learning automata. Trans Emerg Telecommun Technol 32(1):e4127 Article   Google Scholar   Forouzandeh S, Berahmand K, Sheikhpour R, Li Y (2023) A new method for recommendation based on embedding spectral clustering in heterogeneous networks (RESCHet). Expert Syst Appl 231:120699 Article   Google Scholar   Hayashi T, Ozaki H, Sasagawa Y, Umeda M, Danno H, Nikaido I (2018) Single-cell full-length total RNA sequencing uncovers dynamics of recursive splicing and enhancer RNAs. Nat Commun 9(1):619 Article   ADS   PubMed   PubMed Central   Google Scholar   Hou R, Denisenko E, Ong HT, Ramilowski JA, Forrest AR (2020) Predicting cell-to-cell communication networks using NATMI. Nat Commun 11(1):5011 Article   ADS   CAS   PubMed   PubMed Central   Google Scholar   Jannesari V, Keshvari M, Berahmand K (2023) A novel nonnegative matrix factorization-based model for attributed graph clustering by incorporating complementary information. Expert Syst Appl 242:122799 Google Scholar   Jing L, Tian K, Huang JZ (2015) Stratified feature sampling method for ensemble clustering of high dimensional data. Pattern Recogn 48(11):3688\u20133702 Article   ADS   Google Scholar   Kayal CK, Bagchi S, Dhar D, Maitra T, Chatterjee S (2019) Hepatocellular carcinoma survival prediction using deep neural network. In: Proceedings of international ethical hacking conference 2018: eHaCON 2018, Kolkata, India. Springer, Singapore, pp 349\u2013358 Law MH, Topchy AP, Jain AK (2004) Multiobjective data clustering. In: Proceedings of the 2004 IEEE computer society conference on computer vision and pattern recognition, 2004. CVPR 2004, vol 2. IEEE, pp II-II Lei X, Li Z, Zhong Y, Li S, Chen J, Ke Y et al (2022) Gli1 promotes epithelial\u2013mesenchymal transition and metastasis of non-small cell lung carcinoma by regulating snail transcriptional activity and stability. Acta Pharm Sin B 12(10):3877\u20133890 Article   CAS   PubMed   PubMed Central   Google Scholar   Li X, Chen X, Rezaeipanah A (2023) Automatic breast cancer diagnosis based on hybrid dimensionality reduction technique and ensemble classification. J Cancer Res Clin Oncol 149:7609\u20137627 Article   PubMed   Google Scholar   Mojarad M, Sarhangnia F, Rezaeipanah A, Parvin H, Nejatian S (2021) Modeling hereditary disease behavior using an innovative similarity criterion and ensemble clustering. Curr Bioinform 16(5):749\u2013764 Article   CAS   Google Scholar   Peng L, Wang F, Wang Z, Tan J, Huang L, Tian X et al (2022) Cell\u2013cell communication inference and analysis in the tumour microenvironments from single-cell transcriptomics: data resources and computational strategies. Brief Bioinform 23(4):bbac234 Article   PubMed   Google Scholar   Prades J, Safont G, Salazar A, Vergara L (2020) Estimation of the number of endmembers in hyperspectral images using agglomerative clustering. Remote Sens 12(21):3585 Article   ADS   Google Scholar   Rezaeipanah A, Ahmadi G (2022) Breast cancer diagnosis using multi-stage weight adjustment in the MLP neural network. Comput J 65(4):788\u2013804 Article   Google Scholar   Rezaeipanah A, Syah R, Wulandari S, Arbansyah A (2021) Design of ensemble classifier model based on MLP neural network for breast cancer diagnosis. Intel Artif 24(67):147\u2013156 Article   Google Scholar   Rostami M, Oussalah M, Berahmand K, Farrahi V (2023) Community detection algorithms in healthcare applications: a systematic review. IEEE Access 11:30247\u201330272 Article   Google Scholar   Sangeetha K, Prakash S (2021) An early breast cancer detection system using stacked auto encoder deep neural network with particle swarm optimization based classification method. J Med Imaging Health Inform 11(12):2897\u20132906 Article   Google Scholar   Shahidinejad A, Ghobaei-Arani M, Masdari M (2021) Resource provisioning using workload clustering in cloud computing environment: a hybrid approach. Clust Comput 24(1):319\u2013342 Article   Google Scholar   Shahraki K, Boroumand PG, Lotfi H, Radnia F, Shahriari H, Sargazi S et al (2023) An update in the applications of exosomes in cancer theranostics: from research to clinical trials. J Cancer Res Clin Oncol 149:8087\u20138116 Article   PubMed   Google Scholar   Sivadas A, Kok VC, Ng KL (2022) Multi-omics analyses provide novel biological insights to distinguish lobular ductal types of invasive breast cancers. Breast Cancer Res Treat 193(2):361\u2013379 Article   CAS   PubMed   Google Scholar   Talatian Azad S, Ahmadi G, Rezaeipanah A (2021) An intelligent ensemble classification method based on multi-layer perceptron neural network and evolutionary algorithms for breast cancer diagnosis. J Exp Theor Artif Intell 34(6):949\u2013969 Article   Google Scholar   Tan J, Liu L, Li F, Chen Z, Chen GY, Fang F et al (2022) Screening of endocrine disrupting potential of surface waters via an affinity-based biosensor in a rural community in the Yellow River Basin, China. Environ Sci Technol 56(20):14350\u201314360 Article   ADS   CAS   PubMed   Google Scholar   Tang F, Wang H, Chang XH, Zhang L, Alharbi KH (2023) Dynamic event-triggered control for discrete-time nonlinear Markov jump systems using policy iteration-based adaptive dynamic programming. Nonlinear Anal Hybrid Syst 49:101338 Article   MathSciNet   Google Scholar   Torabi E, Ghobaei-Arani M, Shahidinejad A (2022) Data replica placement approaches in fog computing: a review. Clust Comput 25(5):3561\u20133589 Article   Google Scholar   Wang J, Jiang X, Zhao L, Zuo S, Chen X, Zhang L et al (2020) Lineage reprogramming of fibroblasts into induced cardiac progenitor cells by CRISPR/Cas9-based transcriptional activators. Acta Pharm Sin B 10(2):313\u2013326 Article   PubMed   Google Scholar   Wang H, Sha Y, Wang D, Nazari H (2022) A gene expression clustering method to extraction of cell-to-cell biological communication. Intel Artif 25(69):1\u201312 Article   Google Scholar   Wang T, Zhang L, Xu N, Alharbi KH (2023) Adaptive critic learning for approximate optimal event-triggered tracking control of nonlinear systems with prescribed performances. Int J Control. https://doi.org/10.1080/00207179.2023.2250880 Article   Google Scholar   Yue S, Niu B, Wang H, Zhang L, Ahmad AM (2023) Hierarchical sliding mode-based adaptive fuzzy control for uncertain switched under-actuated nonlinear systems with input saturation and dead-zone. Robot Intell Autom 43(5):523\u2013536 Google Scholar   Zhang D, Jiao L, Bai X, Wang S, Hou B (2018) A robust semi-supervised SVM via ensemble learning. Appl Soft Comput 65:632\u2013643 Article   Google Scholar   Zhang L, Deng S, Zhang Y, Peng Q, Li H, Wang P et al (2020) Homotypic targeting delivery of siRNA with artificial cancer cells. Adv Healthc Mater 9(9):1900772 Article   CAS   Google Scholar   Zhang H, Zhao X, Wang H, Zong G, Xu N (2022a) Hierarchical sliding-mode surface-based adaptive actor\u2013critic optimal control for switched nonlinear systems with unknown perturbation. IEEE Trans Neural Netw Learn Syst. https://doi.org/10.1109/TNNLS.2022.3183991 Article   PubMed   Google Scholar   Zhang H, Zhao X, Zhang L, Niu B, Zong G, Xu N (2022b) Observer-based adaptive fuzzy hierarchical sliding mode control of uncertain under-actuated switched nonlinear systems with input quantization. Int J Robust Nonlinear Control 32(14):8163\u20138185 Article   MathSciNet   Google Scholar   Zhang H, Zou Q, Ju Y, Song C, Chen D (2022c) Distance-based support vector machine to predict DNA N6-methyladenine modification. Curr Bioinform 17(5):473\u2013482 Article   CAS   Google Scholar   Zhao Y, Niu B, Zong G, Xu N, Ahmad AM (2023a) Event-triggered optimal decentralized control for stochastic interconnected nonlinear systems via adaptive dynamic programming. Neurocomputing 539:126163 Article   Google Scholar   Zhao H, Wang H, Xu N, Zhao X, Sharaf S (2023b) Fuzzy approximation-based optimal consensus control for nonlinear multiagent systems via adaptive dynamic programming. Neurocomputing 553:126529 Article   Google Scholar   Download references Funding This work was supported by the talent project of Weinan Normal University. No.18ZRRC07. Author information Authors and Affiliations College of Environment and Life Sciences, Weinan Normal University, Weinan, 714099, Shaanxi, China Xiuchao Shi, Meiping Quan & Yalin Li Weinan Junior Middle School, Weinan, 714000, Shaanxi, China Chunxiao Yue Department of Radiology and Sonar Techniques, Al-Noor University College, Nineveh, Iraq Hiba Nashwan Sam Contributions All authors contributed to the design and implementation of the research, to the analysis of the results and to the writing of the manuscript. Corresponding author Correspondence to Xiuchao Shi. Ethics declarations Conflict of interest The authors declare no competing interests. Ethical approval Not applicable. Additional information Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Rights and permissions Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law. Reprints and permissions About this article Cite this article Shi, X., Yue, C., Quan, M. et al. A semi-supervised ensemble clustering algorithm for discovering relationships between different diseases by extracting cell-to-cell biological communications. J Cancer Res Clin Oncol 150, 3 (2024). https://doi.org/10.1007/s00432-023-05559-4 Download citation Received 14 July 2023 Accepted 01 November 2023 Published 02 January 2024 DOI https://doi.org/10.1007/s00432-023-05559-4 Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Keywords Cell-to-cell communication Ensemble clustering Semi-supervised clustering Gene expression FANTOM5 dataset Use our pre-submission checklist Avoid common mistakes on your manuscript. Sections Figures References Abstract Introduction Related works Background Proposed clustering framework Experiments Conclusions Data availability Code availability References Funding Author information Ethics declarations Additional information Rights and permissions About this article Advertisement Discover content Journals A-Z Books A-Z Publish with us Publish your research Open access publishing Products and services Our products Librarians Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy rights Accessibility statement Terms and conditions Privacy policy Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln (3000134173) \u00a9 2024 Springer Nature",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "Study on the Impact of Remote Working on the Satisfaction and Experience of IT Workers in Poland",
    "doi": "10.23762/FSO_VOL11_NO4_1",
    "description": "The purpose of this study is to determine the level of employee satisfaction with the performance of tasks assigned by the employer in remote form, to explore the discrepancy between employee expectations and the experience of remote working and to identify the characteristics shaping employee preferences, together with an attempt to identify and classify the requirements of IT staff carrying out their professional duties remotely. Employee job satisfaction is a source of benefits both for the employees themselves and for companies operating in a dynamically changing environment. The issue of remote working is the subject of public debate and is a particularly current and important research topic. Satisfaction with remote working is a multidimensional phenomenon encompassing different aspects of the work experience, as well as a subjective experience that varies from person to person, considered in relation to a variety of factors. The paper is theoretical and methodological in nature, using a variety of research methods and techniques, such as a survey questionnaire, the Kano model and the Servqual approach. These methods were supported by a classical literature review, which served as a supporting tool and starting point for further analysis and critique of the literature, as well as structural and causal analysis. The primary data collected through the survey questionnaire were analysed and inferred, and the results showed that IT employees' expectations of remote working are not fully met, especially in the areas of career development and adaptation. Significant differences relate to bonuses, recognition and job stability. The largest unfulfilled expectations are related to job stability, bonuses, allowances to cover the costs of remote working and workplace flexibility. Remote working has positive aspects such as less environmental stress, higher productivity, reduced costs and commuting- related stress. Most of the identified features of remote working (20 out of 24) directly influence job satisfaction. Access to global projects attracts potential employees the most. Three features - subsidised equipment, coverage of remote working costs, and the environmental impact of remote working - are irrelevant to employee satisfaction. This study addresses a topical and relevant contemporary issue in the field of remote working and job satisfaction. It is a pioneering study focusing on the links between remote working and IT employee satisfaction. To date, research has considered the issue from the perspective of remote working, the IT sector or job satisfaction in relation to various factors. However, there is a lack of research combining these three issues. Furthermore, analysis based on the Servqual method and the Kano model has so far been used to measure service quality in various industries and to analyse and categorise customer needs in relation to satisfaction. The application of this tool to the study of employee satisfaction with remote working in the IT industry is a new and unique approach. The findings may be relevant to employers, IT employees, HR professionals and regulators alike.",
    "journal": "Forum Scientiae Oeconomia",
    "authors": [
      "Bielinska-Dusza E.",
      "da Costa R.L.",
      "Hamerska M.",
      "Zak A."
    ],
    "citation_count": "0",
    "full_text": "Study on the Impact of Remote Working on the Satisfaction and Experience of IT Workers in Poland Download",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "Beyond playing 20 questions with nature: Integrative experiment design in the social and behavioral sciences",
    "doi": "10.1017/S0140525X22002874",
    "description": "The dominant paradigm of experiments in the social and behavioral sciences views an experiment as a test of a theory, where the theory is assumed to generalize beyond the experiment's specific conditions. According to this view, which Alan Newell once characterized as playing twenty questions with nature, theory is advanced one experiment at a time, and the integration of disparate findings is assumed to happen via the scientific publishing process. In this article, we argue that the process of integration is at best inefficient, and at worst it does not, in fact, occur. We further show that the challenge of integration cannot be adequately addressed by recently proposed reforms that focus on the reliability and replicability of individual findings, nor simply by conducting more or larger experiments. Rather, the problem arises from the imprecise nature of social and behavioral theories and, consequently, a lack of commensurability across experiments conducted under different conditions. Therefore, researchers must fundamentally rethink how they design experiments and how the experiments relate to theory. We specifically describe an alternative framework, integrative experiment design, which intrinsically promotes commensurability and continuous integration of knowledge. In this paradigm, researchers explicitly map the design space of possible experiments associated with a given research question, embracing many potentially relevant theories rather than focusing on just one. Researchers then iteratively generate theories and test them with experiments explicitly sampled from the design space, allowing results to be integrated across experiments. Given recent methodological and technological developments, we conclude that this approach is feasible and would generate more-reliable, more-cumulative empirical and theoretical knowledge than the current paradigm - and with far greater efficiency.",
    "journal": "Behavioral and Brain Sciences",
    "authors": [
      "Almaatouq A.",
      "Griffiths T.L.",
      "Suchow J.W.",
      "Whiting M.E.",
      "Evans J.",
      "Watts D.J."
    ],
    "citation_count": "12",
    "full_text": "Due to site maintenance, online purchases on Cambridge Core would be temporarily unavailable on Sunday 24th March from 08:00 until 18:00 GMT. Apologies for the inconvenience. We use cookies to distinguish you from other users and to provide you with a better experience on our websites. Close this message to accept cookies or find out how to manage your cookie settings. Discover Content Products and Services Home Home Browse subjects Publications Open research Services About Cambridge Core Access provided by Register Log in Cart ( 0 ) Home >Journals >Behavioral and Brain Sciences >Volume 47 >Beyond playing 20 questions with nature: Integrative... English Fran\u00e7ais Behavioral and Brain Sciences Article contents Abstract Introduction The \u201cone-at-a-time\u201d paradigm From one-at-a-time to integrative by design Existing steps toward integrative experiments Critiques and concerns Conclusion Financial support Competing interest Footnotes References Beyond playing 20 questions with nature: Integrative experiment design in the social and behavioral sciences Published online by Cambridge University Press:  21 December 2022 Abdullah Almaatouq [Opens in a new window] , Thomas L. Griffiths , Jordan W. Suchow , Mark E. Whiting [Opens in a new window] , James Evans  and Duncan J. Watts Show author details Article Figures Related commentaries Metrics Save PDF Share Cite Rights & Permissions [Opens in a new window] Abstract The dominant paradigm of experiments in the social and behavioral sciences views an experiment as a test of a theory, where the theory is assumed to generalize beyond the experiment's specific conditions. According to this view, which Alan Newell once characterized as \u201cplaying twenty questions with nature,\u201d theory is advanced one experiment at a time, and the integration of disparate findings is assumed to happen via the scientific publishing process. In this article, we argue that the process of integration is at best inefficient, and at worst it does not, in fact, occur. We further show that the challenge of integration cannot be adequately addressed by recently proposed reforms that focus on the reliability and replicability of individual findings, nor simply by conducting more or larger experiments. Rather, the problem arises from the imprecise nature of social and behavioral theories and, consequently, a lack of commensurability across experiments conducted under different conditions. Therefore, researchers must fundamentally rethink how they design experiments and how the experiments relate to theory. We specifically describe an alternative framework, integrative experiment design, which intrinsically promotes commensurability and continuous integration of knowledge. In this paradigm, researchers explicitly map the design space of possible experiments associated with a given research question, embracing many potentially relevant theories rather than focusing on just one. Researchers then iteratively generate theories and test them with experiments explicitly sampled from the design space, allowing results to be integrated across experiments. Given recent methodological and technological developments, we conclude that this approach is feasible and would generate more-reliable, more-cumulative empirical and theoretical knowledge than the current paradigm \u2013 and with far greater efficiency. Keywords cumulative knowledge experiments generalizability (in)commensurability Type Target Article Information Behavioral and Brain Sciences , Volume 47 , 2024 , e33 DOI: https://doi.org/10.1017/S0140525X22002874 [Opens in a new window] Copyright Copyright \u00a9 The Author(s), 2022. Published by Cambridge University Press 1. Introduction You can't play 20 questions with Nature and win. (Newell, Reference Newell 1973) Fifty years ago, Allen Newell summed up the state of contemporary experimental psychology as follows: \u201cScience advances by playing twenty questions with nature. The proper tactic is to frame a general question, hopefully binary, that can be attacked experimentally. Having settled that bits-worth, one can proceed to the next \u2026 Unfortunately, the questions never seem to be really answered, the strategy does not seem to work\u201d (italics added for emphasis). The problem, Newell noted, was a lack of coherence among experimental findings. \u201cWe never seem in the experimental literature to put the results of all the experiments together,\u201d he wrote, \u201cInnumerable aspects of the situations are permitted to be suppressed. Thus, no way exists of knowing whether the earlier studies are in fact commensurate with whatever ones are under present scrutiny, or are in fact contradictory.\u201d Referring to a collection of papers by prominent experimentalists, Newell concluded that although it was \u201cexceedingly clear that each paper made a contribution \u2026 I couldn't convince myself that it would add up, even in thirty more years of trying, even if one had another 300 papers of similar, excellent ilk.\u201d More than 20 years after Newell's imagined future date, his outlook seems, if anything, optimistic. To illustrate the problem, consider the phenomenon of group \u201csynergy,\u201d defined as the performance of an interacting group exceeding that of an equivalently sized \u201cnominal group\u201d of individuals working independently (Hill, Reference Hill 1982; Larson, Reference Larson 2013). A century of experimental research in social psychology, organizational psychology, and organizational behavior has tested the performance implications of working in groups relative to working individually (Allen & Hecht, Reference Allen and Hecht 2004; Richard Hackman & Morris, Reference Richard Hackman, Morris and Berkowitz 1975; Husband, Reference Husband 1940; Schulz-Hardt & Mojzisch, Reference Schulz-Hardt and Mojzisch 2012; Tasca, Reference Tasca 2021; Watson, Reference Watson 1928), but substantial contributions can also be found in cognitive science, communications, sociology, education, computer science, and complexity science (Allport, Reference Allport 1924; Arrow, McGrath, & Berdahl, Reference Arrow, McGrath and Berdahl 2000; Barron, Reference Barron 2003; Devine, Clayton, Dunford, Seying, & Pryce, Reference Devine, Clayton, Dunford, Seying and Pryce 2001). In spite of this attention across time and disciplines \u2013 or maybe because of it \u2013 this body of research often reaches inconsistent or conflicting conclusions. For example, some studies find that interacting groups outperform individuals because they are able to distribute effort (Laughlin, Bonner, & Miner, Reference Laughlin, Bonner and Miner 2002), share information about high-quality solutions (Mason & Watts, Reference Mason and Watts 2012), or correct errors (Mao, Mason, Suri, & Watts, Reference Mao, Mason, Suri and Watts 2016), whereas other studies find that \u201cprocess losses\u201d \u2013 including social loafing (Harkins, Reference Harkins 1987; Karau & Williams, Reference Karau and Williams 1993), groupthink (Janis, Reference Janis 1972), and interpersonal conflict (Steiner, Reference Steiner 1972) \u2013 cause groups to underperform their members. As we will argue, the problem is not that researchers lack theoretically informed hypotheses about the causes and predictors of group synergy; to the contrary, the literature contains dozens, or possibly even hundreds, of such hypotheses. Rather, the problem is that because each of these experiments was designed with the goal of testing a hypothesis but, critically, not with the goal of explicitly comparing the results with other experiments of the same general class, researchers in this space have no way to articulate how similar or different their experiment is from anyone else's. As a result, it is impossible to determine \u2013 via systematic review, meta-analysis, or any other ex-post method of synthesis \u2013 how all of the potentially relevant factors jointly determine group synergy or how their relative importance and interactions change over contexts and populations. Nor is group synergy the only topic in the social and behavioral sciences for which one can find a proliferation of irreconcilable theories and empirical results. For any substantive area of the social and behavioral sciences on which we have undertaken a significant amount of reading, we see hundreds of experiments that each tests the effects of some independent variables on other dependent variables while suppressing innumerable \u201caspects of the situation.\u201d Footnote 1 Setting aside the much-discussed problems of replicability and reproducibility, many of these papers are interesting when read in isolation, but it is no more possible to \u201cput them all together\u201d today than it was in Newell's time (Almaatouq, Reference Almaatouq 2019; Muthukrishna & Henrich, Reference Muthukrishna and Henrich 2019; Watts, Reference Watts 2017). Naturally, our subjective experience of reading across several domains of interest does not constitute proof that successful integration of many independently designed and conducted experiments cannot occur in principle, or even that it has not occurred in practice. Indeed it is possible to think of isolated examples, such as mechanism design applied to auctions (Myerson, Reference Myerson 1981; Vickrey, Reference Vickrey 1961) and matching markets (Aumann & Hart, Reference Aumann and Hart 1992; Gale & Shapley, Reference Gale and Shapley 1962), in which theory and experiment appear to have accumulated into a reasonably self-consistent, empirically validated, and practically useful body of knowledge. We believe, however, that these examples represent rare exceptions and that examples such as group synergy are far more typical. We propose two explanations for why not much has changed since Newell's time. The first is that not everyone agrees with the premise of Newell's critique \u2013 that \u201cputting things together\u201d is a pressing concern for the scientific enterprise. In effect, this view holds that the approach Newell critiqued (and that remains predominant in the social and behavioral sciences) is sufficient for accumulating knowledge. Such accumulation manifests itself indirectly through the scientific publishing process, with each new paper building upon earlier work, and directly through literature reviews and meta-analyses. The second explanation for the lack of change since Newell's time is that even if one accepts Newell's premise, neither Newell nor anyone else has proposed a workable alternative; hence, the current paradigm persists by default in spite of its flaws. Footnote 2 In the remainder of this paper, we offer our responses to the two explanations just proposed. Section 2 addresses the first explanation, describing what we call the \u201cone-at-a-time\u201d paradigm and arguing that it is poorly suited to the purpose of integrating knowledge over many studies in large part because it was not designed for that purpose. We also argue that existing mechanisms for integrating knowledge, such as systematic reviews and meta-analyses, are insufficient on the grounds that they, in effect, assume commensurability. If the studies that these methods are attempting to integrate cannot be compared with one another, because they were not designed to be commensurable, then there is little that ex-post methods can do. Footnote 3 Rather, an alternative approach to designing experiments and evaluating theories is needed. Section 3 addresses the second explanation by describing such an alternative, which we call the \u201cintegrative\u201d approach, that is explicitly designed to integrate knowledge about a particular problem domain. Although integrative experiments of the sort we describe may not have been possible in Newell's day, we argue that they can now be productively pursued in parts of the social and behavioral sciences thanks to increasing theoretical maturity and methodological developments. To illustrate this point, section 4 illustrates the potential of the integrative approach by describing three experiments that are first steps in its direction. Finally, section 5 outlines questions and concerns we have encountered and offers our response. 2. The \u201cone-at-a-time\u201d paradigm In the simplest version of what we call the \u201cone-at-a-time\u201d approach to experimentation, a researcher poses a question about the relation between one independent and one dependent variable and then offers a theory-motivated hypothesis that the relation is positive or negative. Next, the researcher devises an experiment to test this hypothesis by introducing variability in the independent variable, aiming to reject the \u201cnull hypothesis\u201d that the proposed dependency does not exist on the basis of the evidence, quantified by a p-value. If the null hypothesis is successfully rejected, the researcher concludes that the experiment corroborates the theory and then elaborates on potential implications, both for other experiments and for phenomena outside the lab. In practice, one-at-a-time experiments can be considerably more complex. The researcher may articulate hypotheses about more than one independent variable, more than one dependent variable, or both. The test itself may focus on effect sizes or confidence intervals rather than statistical significance, or it may compare two or more competing hypotheses. Alternatively, both the hypothesis and the test may be qualitative in nature. Regardless, each experiment tests at most a small number of theoretically informed hypotheses in isolation by varying at most a small number of parameters. By design, all other factors are held constant. For example, a study of the effect of reward or punishment on levels of cooperation typically focuses on the manipulation of theoretical interest (e.g., introducing a punishment stage between contribution rounds in a repeated game) while holding fixed other parameters, such as the numerical values of the payoffs or the game's length (Fehr & Gachter, Reference Fehr and Gachter 2000). Similarly, a study of the effect of network structure on group performance typically focuses on some manipulation of the underlying network while holding fixed the group size or the time allotted to perform the task (Almaatouq et al., Reference Almaatouq, Noriega-Campero, Alotaibi, Krafft, Moussaid and Pentland 2020; Becker, Brackbill, & Centola, Reference Becker, Brackbill and Centola 2017). 2.1. The problem with the one-at-a-time paradigm As Newell himself noted, this approach to experimentation seems reasonable. After all, the sequence of question \u2192 theory \u2192 hypothesis \u2192 experiment \u2192 analysis \u2192 revision to theory \u2192 repeat appears to be almost interchangeable with the scientific method itself. Nonetheless, the one-at-a-time paradigm rests on an important but rarely articulated assumption: That because the researcher's purpose in designing an experiment is to test a theory of interest, the only constructs of interest are those that the theory itself explicitly articulates as relevant. Conversely, where the theory is silent, the corresponding parameters are deemed to be irrelevant. According to this logic, articulating a precise theory leads naturally to a well-specified experiment with only one, or at most a few, constructs in need of consideration. Correspondingly, theory can aid the interpretation of the experiment's results \u2013 and can be generalized to other cases (Mook, Reference Mook 1983; Zelditch, Reference Zelditch 1969). Unfortunately, while such an assumption may be reasonable in fields such as physics, it is rarely justified in the social and behavioral sciences (Debrouwere & Rosseel, Reference Debrouwere and Rosseel 2022; Meehl, Reference Meehl 1967). Social and behavioral phenomena exhibit higher \u201ccausal density\u201d (or what Meehl called the \u201ccrud factor\u201d) than physical phenomena, such that the number of potential causes of variation in any outcome is much larger than in physics and the interactions among these causes are often consequential (Manzi, Reference Manzi 2012; Meehl, Reference Meehl 1990b). In other words, the human world is vastly more complex than the physical one, and researchers should be neither surprised nor embarrassed that their theories about it are correspondingly less precise and predictive (Watts, Reference Watts 2011). The result is that theories in the social and behavioral sciences are rarely articulated with enough precision or supported by enough evidence for researchers to be sure which parameters are relevant and which can be safely ignored (Berkman & Wilson, Reference Berkman and Wilson 2021; Meehl, Reference Meehl 1990b; Turner & Smaldino, Reference Turner and Smaldino 2022; Yarkoni, Reference Yarkoni 2022). Researchers working independently in the same domain of inquiry will therefore invariably make design choices (e.g., parameter settings, subject pools) differently (Breznau et al., Reference Breznau, Rinke, Wuttke, Nguyen, Adem, Adriaans and \u017b\u00f3\u0142tak 2022; Gelman & Loken, Reference Gelman and Loken 2014). Moreover, because the one-at-a-time paradigm is premised on the (typically unstated) assumption that theories dictate the design of experiments, the process of making design decisions about constructs that are not specified under the theory being tested is often arbitrary, vague, undocumented, or (as Newell puts it) \u201csuppressed.\u201d 2.2. The universe of possible experiments To express the problem more precisely, it is useful to think of a one-at-a-time experiment as a sample from an implicit universe of possible experiments in a domain of inquiry. Before proceeding, we emphasize that neither the sample nor the universe is typically acknowledged in the one-at-a-time paradigm. Indeed, it is precisely the transition from implicit to explicit construction of the sampling universe that forms the basis of the solution we describe in the next section. In imagining such a universe, it is useful to distinguish the independent variables needed to define the effect of interest \u2013 the experimental manipulation \u2013 from the experiment's context. We define this context as the set of independent variables that are hypothesized to moderate the effect in question as well as the nuisance parameters (which, strictly speaking, are also independent variables) over which the effect is expected to generalize and that correspond to the design choices the researcher makes about the specific experiment that will be conducted. For example, an experiment comparing the performance of teams to that of individuals not only will randomize participants into a set of experimental conditions (e.g., individuals vs. teams of varying sizes), but will also reflect decisions about other contextual features, including, for example, the specific tasks on which to compare performance, where each task could then be parameterized along multiple dimensions (Almaatouq, Alsobay, Yin, & Watts, Reference Almaatouq, Alsobay, Yin and Watts 2021a; Larson, Reference Larson 2013). Other contextual choices include the incentives provided to participants, time allotted to perform the task, modality of response, and so on. Similarly, we define the population of the experiment as a set of measurable attributes that characterize the sample of participants (e.g., undergraduate women in the United States aged 18\u201323 with a certain distribution of cognitive reflection test scores). Putting all these choices together, we can now define an abstract space of possible experiments, the dimensions of which are the union of the context and population. We call this space the design space on the grounds that every conceivable design of the experiment is describable by some choice of parameters that maps to a unique point in the space. Footnote 4 (Although this is an abstract way of defining what we mean by the experiment design space, we will suggest concrete and practical ways of defining it later in the article.) Figure 1 shows a simplified rendering of a design space and illustrates several important properties of the one-at-a-time paradigm. Figure 1A shows a single experiment conducted in a particular context with a particular sample population. The color of the point represents the \u201cresult\u201d of the experiment: The effect of one or more independent variables on some dependent variable. In the absence of a theory, nothing can be concluded from the experiment alone, other than that the observed result holds for one particular sample of participants under one particular context. From this observation, the appeal of strong theory becomes clear: By framing an experiment as a test of a theory, rather than as a measurement of the relationship between dependent and independent variables (Koyr\u00e9, Reference Koyr\u00e9 1953), the observed results can be generalized well beyond the point in question, as shown in Figure 1B. For example, while a methods section of an experimental paper might note that the participants were recruited from the subject pool at a particular university, it is not uncommon for research articles to report findings as if they apply to all of humanity (Henrich, Heine, & Norenzayan, Reference Henrich, Heine and Norenzayan 2010). According to this view, theories (and in fields such as experimental economics, formal models) are what help us understand the world, whereas experiments are merely instruments that enable researchers to test theories (Lakens, Uygun Tun\u00e7, & Necip Tun\u00e7, Reference Lakens, Uygun Tun\u00e7 and Necip Tun\u00e7 2022; Levitt & List, Reference Levitt and List 2007; Mook, Reference Mook 1983; Zelditch, Reference Zelditch 1969). Figure 1. Implicit design space. Panel A depicts a single experiment (a single point) that generates a result in a particular sample population and context; the point's color represents a relationship between variables. Panel B depicts the expectation that results will generalize over broader regions of conditions. Panel C shows a result that applies to a bounded range of conditions. Panel D illustrates how isolated studies about specific hypotheses can reach inconsistent conclusions, as represented by different-colored points. As noted above, however, we rarely expect theories in the social and behavioral sciences to be universally valid. The ability of the theory in question to generalize the result is therefore almost always limited to some region of the design space that includes the sampled point but not the entire space, as shown in Figure 1C. While we expect that most researchers would acknowledge that they lack evidence for unconstrained generality over the population, it is important to note that there is nothing special about the subjects. In principle, what goes for subjects also holds for contexts (Simons, Shoda, & Lindsay, Reference Simons, Shoda and Lindsay 2017; Yarkoni, Reference Yarkoni 2022). Indeed, as Brunswik long ago observed, \u201c\u2026proper sampling of situations and problems may in the end be more important than proper sampling of subjects, considering the fact that individuals are probably on the whole much more alike than are situations among one another\u201d (Brunswik, Reference Brunswik 1947). Unfortunately, because the design space is never explicitly constructed, and hence the sampled point has no well-defined location in the space, the one-at-a-time paradigm cannot specify a proposed domain of generalizability. Instead, any statements regarding \u201cscope\u201d or \u201cboundary\u201d conditions for a finding are often implicit and qualitative in nature, leaving readers to assume the broadest possible generalizations. These scope conditions may appear in an article's discussion section but typically not in its title, abstract, or introduction. Rarely, if ever, is it possible to precisely identify, based on the theory alone, over what domain of the design space one should expect an empirical result to hold (Cesario, Reference Cesario 2014, Reference Cesario 2022). 2.3. Incommensurability leads to irreconcilability Given that the choices about the design of experiments are not systematically documented, it becomes impossible to establish how similar or different two experiments are. This form of incommensurability, whereby experiments about the same effect of interest are incomparable, generates a pattern like that shown in Figure 1D, where inconsistent and contradictory findings appear in no particular order or pattern (Levinthal & Rosenkopf, Reference Levinthal and Rosenkopf 2021). If one had a metatheory that specified precisely under what conditions (i.e., over what region of parameter values in the design space) each theory should apply, it might be possible to reconcile the results under that metatheory's umbrella, but rarely do such metatheories exist (Muthukrishna & Henrich, Reference Muthukrishna and Henrich 2019). As a result, the one-at-a-time paradigm provides no mechanism by which to determine whether the observed differences (a) are to be expected on the grounds that they lie in distinct subdomains governed by different theories, (b) represent a true disagreement between competing theories that make different claims on the same subdomain, or (c) indicate that one or both results are likely to be wrong and therefore require further replication and scrutiny. In other words, inconsistent findings arising in the research literature are essentially irreconcilable (Almaatouq, Reference Almaatouq 2019; Muthukrishna & Henrich, Reference Muthukrishna and Henrich 2019; Van Bavel, Mende-Siedlecki, Brady, & Reinero, Reference Van Bavel, Mende-Siedlecki, Brady and Reinero 2016; Watts, Reference Watts 2017; Yarkoni, Reference Yarkoni 2022). Critically, the absence of commensurability also creates serious problems for existing methods of synthesizing knowledge such as systematic reviews and meta-analyses. As all these methods are post-hoc, meaning that they are applied after the studies in question have been completed, they are necessarily reliant on the designs of the experiments they are attempting to integrate. If those designs do not satisfy the property of commensurability (again, because they were never intended to), then ex-post methods are intrinsically limited in how much they can say about observed differences. A concrete illustration of this problem has emerged recently in the context of \u201cnudging\u201d due to the publication of a large meta-analysis of over 400 studies spanning a wide range of contexts and interventions (Mertens, Herberz, Hahnel, & Brosch, Reference Mertens, Herberz, Hahnel and Brosch 2022). The paper was subsequently criticized for failing to account adequately for publication bias (Maier et al., Reference Maier, Barto\u0161, Stanley, Shanks, Harris and Wagenmakers 2022), the quality of the included studies (Simonsohn, Simmons, & Nelson, Reference Simonsohn, Simmons and Nelson 2022), and their heterogeneity (Szaszi et al., Reference Szaszi, Higney, Charlton, Gelman, Ziano, Aczel and Tipton 2022). While the first two of these problems can be addressed by proposed reforms in science, such as universal registries of study designs (which are designed to mitigate publication bias) and adoption of preanalysis plans (which are specified to improve study quality), the problem of heterogeneity requires a framework for expressing study characteristics in a way that is commensurate. If two studies are different, that is, a meta-analysis is left with no means to incorporate information from both of them that properly accounts for their differences. Thus, while meta-analyses (and reviews more generally) can acknowledge the importance of moderating variables, they are inherently limited in their ability to do so by the commensurability of the underlying studies. Finally, we note that the lack of commensurability is also unaddressed by existing proposals to improve the reliability of science by, for example, increasing sample sizes, calculating effect sizes rather than measures of statistical significance, replicating findings, or requiring preregistered designs. Although these practices can indeed improve the reliability of individual findings, they are not concerned directly with the issue of how many such findings \u201cfit together\u201d and hence do not address our fundamental concern with the one-at-a-time framework. In other words, just as Newell claimed 50 years ago, improving the commensurability of experiments \u2013 and the theories they seek to test \u2013 will require a paradigmatic shift in how we think about experimental design. 3. From one-at-a-time to integrative by design We earlier noted that a second explanation for the persistence of the one-at-a-time approach is the lack of any realistic alternative. Even if one sees the need for a \u201cparadigmatic shift in how we think about experimental design,\u201d it remains unclear what that shift would look like and how to implement it. To address this issue, we now describe an alternative approach, which we call \u201cintegrative\u201d experimentation, that can resolve some of the difficulties described previously. In general terms, the one-at-a-time approach starts with a single, often very specific, theoretically informed hypothesis. In contrast, the integrative approach starts from the position of embracing many potentially relevant theories: All sources of measurable experimental-design variation are potentially relevant, and decisions about which parameters are relatively more or less important are to be answered empirically. The integrative approach proceeds in three phases: (1) Constructing a design space, (2) sampling from the design space, and (3) building theories from the resulting data. The rest of this section elucidates these three main conceptual components of the integrative approach. 3.1. Constructing the design space The integrative approach starts by explicitly constructing the design space. Experiments that have already been conducted can then be assigned well-defined coordinates, whereas those not yet conducted can be identified as as-yet-unsampled points. Critically, the differences between any pair of experiments that share the same effect of interest \u2013 whether past or future \u2013 can be determined; thus, it is possible to precisely identify the similarities and differences between two designs. In other words, commensurability is \u201cbaked in\u201d by design. How should the design space be constructed in practice? The method will depend on the domain of interest but is likely to entail a discovery stage that identifies candidate dimensions from the literature. Best practices for constructing the design space will emerge with experience, giving birth to a new field of what we tentatively label \u201cresearch cartography\u201d: The systematic process of mapping out research fields in design spaces. Efforts in research cartography are likely to benefit from and contribute to ongoing endeavors to produce formal ontologies in social and behavioral science research and other disciplines, in support of a more integrative science (Larson & Martone, Reference Larson and Martone 2009; Rubin et al., Reference Rubin, Lewis, Mungall, Misra, Westerfield, Ashburner and Musen 2006; Turner & Laird, Reference Turner and Laird 2012). To illustrate this process, consider the phenomenon of group synergy discussed earlier. Given existing theory and decades of experiments, one might expect the existence and strength of group synergy to depend on the task: For some tasks, interacting groups might outperform nominal groups, whereas for others, the reverse might hold. In addition, synergy might (or might not) be expected depending on the specific composition of the group: Some combinations of skills and other individual attributes might lead to synergistic performance; other combinations might not. Finally, group synergy might depend on \u201cgroup processes,\u201d defined as variables such as the communications technology or incentive structure that affect how group members interact with one another, but which are distinct both from the individuals themselves and their collective task. Given these three broad sources of variation, an integrative approach would start by identifying the dimensions associated with each, as suggested either by prior research or some other source of insight such as practical experience. In this respect, research cartography resembles the process of identifying the nodes of a nomological network (Cronbach & Meehl, Reference Cronbach and Meehl 1955; Preckel & Brunner, Reference Preckel and Brunner 2017) or the dimensions of methodological diversity for a meta-analysis (Higgins, Thompson, Deeks, & Altman, Reference Higgins, Thompson, Deeks and Altman 2003); however, it will typically involve many more dimensions and require the \u201ccartographer\u201d to assign numerical coordinates to each \u201clocation\u201d in the space. For example, the literature on group performance has produced several well-known task taxonomies, such as those by Shaw ( Reference Shaw 1963), Hackman ( Reference Hackman 1968), Steiner ( Reference Steiner 1972), McGrath ( Reference McGrath 1984), and Wood ( Reference Wood 1986). Task-related dimensions of variation (e.g., divisibility, complexity, solution demonstrability, and solution multiplicity) would be extracted from these taxonomies and used to label tasks that have appeared in experimental studies of group performance. Similarly, prior work has variously suggested that group performance depends on the composition of the group with respect to individual-level traits as captured by, say, average skill (Bell, Reference Bell 2007; Devine & Philips, Reference Devine and Philips 2001; LePine, Reference LePine 2003; Stewart, Reference Stewart 2006), skill diversity (Hong & Page, Reference Hong and Page 2004; Page, Reference Page 2008), gender diversity (Schneid, Isidor, Li, & Kabst, Reference Schneid, Isidor, Li and Kabst 2015), social perceptiveness (Engel, Woolley, Jing, Chabris, & Malone, Reference Engel, Woolley, Jing, Chabris and Malone 2014; Kim et al., Reference Kim, Engel, Woolley, Lin, McArthur and Malone 2017; Woolley, Chabris, Pentland, Hashmi, & Malone, Reference Woolley, Chabris, Pentland, Hashmi and Malone 2010), and cognitive-style diversity (Aggarwal & Woolley, Reference Aggarwal and Woolley 2018; Ellemers & Rink, Reference Ellemers and Rink 2016), all of which could be represented as dimensions of the design space. Finally, group-process variables might include group size (Mao et al., Reference Mao, Mason, Suri and Watts 2016), properties of the communication network (Almaatouq, Rahimian, Burton, & Alhajri, Reference Almaatouq, Rahimian, Burton and Alhajri 2022; Becker et al., Reference Becker, Brackbill and Centola 2017; Mason & Watts, Reference Mason and Watts 2012), and the ability of groups to reorganize themselves (Almaatouq et al., Reference Almaatouq, Noriega-Campero, Alotaibi, Krafft, Moussaid and Pentland 2020). Together, these variables might identify upward of 50 dimensions that define a design space of possible experiments for studying group synergy through integrative experiment design, where any given study should, in principle, be assignable to one unique point in the space. Footnote 5 As this example illustrates, the list of possibly relevant variables can be long, and the dimensionality of the design space can therefore be large. Complicating matters, we do not necessarily know up front which of the many variables are in fact relevant to the effects of interest. In the example of group synergy, for instance, even an exhaustive reading of the relevant literature is not guaranteed to reveal all the ways in which tasks, groups, and group processes can vary in ways that meaningfully affect synergy. Conversely, there is no guarantee that all, or even most, of the dimensions chosen to represent the design space will play any important role in generating synergy. As a result, experiments that map to the same point in the design space could yield different results (because some important dimension is missing from the representation of the space), while in other cases, experiments that map to very different points yield indistinguishable behavior (because the dimensions along which they differ are irrelevant). Factors such as these complicate matters in practice but do not present a fundamental problem to the approach described here. The integrative approach does not require the initial configuration of the space to be correct or its dimensionality to be fixed. Rather, the dimensionality of the space can be learned in parallel with theory construction and testing. Really, the only critical requirement for constructing the design space is to do it explicitly and systematically by identifying potentially relevant dimensions (either from the literature or from experience, including any known experiments that have already been performed) and by assigning coordinates to individual experiments along all identified dimensions. Using this process of explicit, systematic mapping of research designs to points in the design space (research cartography), the integrative approach ensures commensurability. We next will describe how the approach leverages commensurability to produce integrated knowledge in two steps: Via sampling, and via theory construction and testing. 3.2. Sampling from the design space An important practical challenge to integrative experiment design is that the size of the design space (i.e., the number of possible experiments) increases exponentially with the number of identified dimensions D. To illustrate, assume that each dimension can be represented as a binary variable (0, 1), such that a given experiment either exhibits the property encoded in the dimension or does not. The number of possible experiments is then 2D. When D is reasonably small and experiments are inexpensive to run, it may be possible to exhaustively explore the space by conducting every experiment in a full factorial design. For example, when D = 8, there are 256 experiments in the design space, a number that is beyond the scale of most studies in the social and behavioral sciences but is potentially achievable with recent innovations in crowdsourcing and other \u201chigh-throughput\u201d methods, especially if distributed among a consortium of labs (Byers-Heinlein et al., Reference Byers-Heinlein, Bergmann, Davies, Frank, Kiley Hamlin, Kline and Soderstrom 2020; Jones et al., Reference Jones, DeBruine, Flake, Liuzza, Antfolk, Arinze and Coles 2021). Moreover, running all possible experiments may not be necessary: If the goal is to estimate the impact that each variable has, together with their interactions, a random (or more efficient) sample of the experiments can be run (Auspurg & Hinz, Reference Auspurg and Hinz 2014). This sample could also favor areas where prior work suggests meaningful variation will be observed. Using these methods, together with large samples, it is possible to run studies for higher values of D (e.g., 20). Section 4 describes examples of such studies. Exhaustive and random sampling are both desirable because they allow unbiased evaluation of hypotheses that are not tethered to the experimental design \u2013 there is no risk of looking only at regions of the space that current hypotheses favor (Dubova, Moskvichev, & Zollman, Reference Dubova, Moskvichev and Zollman 2022), and no need to collect more data from the design space because the hypotheses under consideration change. But as the dimensionality increases, exhaustive and random sampling quickly becomes infeasible. When D is greater than 20, the number of experiment designs grows to over 1 million, and when D = 30, it is over 1 billion. Given that the dimensionality of design spaces for even moderately complex problems could easily exceed these numbers, and that many dimensions will be not binary but ternary or greater, integrative experiments will require using different sampling methods. Fortunately, there already exist a number of methods that enable researchers to efficiently sample high-dimensional design spaces (Atkinson & Donev, Reference Atkinson and Donev 1992; McClelland, Reference McClelland 1997; Smucker, Krzywinski, & Altman, Reference Smucker, Krzywinski and Altman 2018; Thompson, Reference Thompson 1933). For example, one contemporary class of methods is \u201cactive learning,\u201d an umbrella term for sequential optimal experimental-design strategies that iteratively select the most informative design points to sample. Footnote 6 Active learning has become an important tool in the design of A/B tests in industry (Letham, Karrer, Ottoni, & Bakshy, Reference Letham, Karrer, Ottoni and Bakshy 2019) and, more recently, of behavioral experiments in the lab (Balietti, Klein, & Riedl, Reference Balietti, Klein and Riedl 2021). Footnote 7 Most commonly, an active learning process begins by conducting a small number of randomly selected experiments (i.e., points in the design space) and fitting a surrogate model to the outcome of these experiments. As we later elucidate, one can think of the surrogate model as a \u201ctheory\u201d that predicts the outcome of all experiments in the design space, including those that have not been conducted. Then, a sampling strategy (also called an \u201cacquisition function,\u201d \u201cquery algorithm,\u201d or \u201cutility measure\u201d) selects a new batch of experiments to be conducted according to the value of potential experiments. Notably, the choice of a surrogate model and sampling strategy is flexible, and the best alternative to choose will depend on the problem (Eyke, Koscher, & Jensen, Reference Eyke, Koscher and Jensen 2021). Footnote 8 We will not explore the details of these methods or their implementation, Footnote 9 as this large topic has been \u2013 and continues to be \u2013 extensively developed in the machine-learning and statistics communities. Footnote 10 For the purpose of our argument, it is necessary only to convey that systematic sampling from the design space allows for unbiased evaluation of hypotheses (see Fig. 2A) and can leverage a relatively small number of sampled points in the design space to make predictions about every point in the space, the vast majority of which are never sampled (see Fig. 2B). Even so, by iteratively evaluating the model against newly sampled points and updating it accordingly, the model can learn about the entire space, including which dimensions are informative. As we explain next, this iterative process will also form the basis of theory construction and evaluation. Figure 2. Explicit design space. Panel A shows that systematically sampling the space of possible experiments can reveal contingencies, thereby increasing the integrativeness of theories (as shown in panel B). Panel C depicts that what matters most is the overlap between the most practically useful conditions and domains defined by theoretical boundaries. The elephants in panels B and C represent the bigger picture that findings from a large number of experiments allow researchers to discern, but which is invisible to those from situated theoretical and empirical positions. 3.3. Building and testing theories Much like in the one-at-a-time paradigm, the ultimate goal of integrative experiment design is to develop a reliable, cohesive, and cumulative theoretical understanding. However, because the integrative approach constructs and tests theories differently, the theories that tend to emerge from it depart from the traditional notion of theory in two regards. First, the shift to integrative experiments will change our expectations about what theories look like (Watts, Reference Watts 2014, Reference Watts 2017), requiring researchers to focus less on proposing novel theories that seek to differentiate themselves from existing theories by identifying new variables and their effects, and more on identifying theory boundaries, which may involve many known variables working together in complex ways. Second, although traditional theory development distinguishes sharply between basic and applied research, integrative theories will lend themselves to a \u201cuse-inspired\u201d approach in which basic and applied science are treated as complements rather than as substitutes where one necessarily drives out the other (Stokes, Reference Stokes 1997; Watts, Reference Watts 2017). We now describe each of these adaptations in more detail. 3.3.1. Integrating and reconciling existing theories As researchers sample experiments that cover more of the design space, simple theories and models that explain behavior with singular factors will no longer be adequate because they will fail to generalize. From a statistical perspective, the \u201cbias-variance trade-off\u201d principle identifies two ways a model (or theory) can fail to generalize: It can be too simple and thus unable to capture trends in the observed data, or too complex, overfitting the observed data and manifesting great variance across datasets (Geman, Bienenstock, & Doursat, Reference Geman, Bienenstock and Doursat 1992). However, this variance decreases as the datasets increase in size and breadth, making oversimplification and reliance on personal intuitions more-likely causes of poor generalization. As a consequence, we must develop new kinds of theories \u2013 or metatheories \u2013 that capture the complexity of human behaviors while retaining the interpretability of simpler theories. Footnote 11 In particular, such theories must account for variation in behavior across the entire design space and will be subject to different evaluation criteria than those traditionally used in the social and behavioral sciences. One such criterion is the requirement that theories generate \u201crisky\u201d predictions, defined roughly as quantitative predictions about as-yet unseen outcomes (Meehl, Reference Meehl 1990b; Yarkoni, Reference Yarkoni 2022). For example, in the \u201cactive sampling\u201d approach outlined above, the surrogate model encodes prior theory and experimental results into a formal representation that (a) can be viewed as an explanation of all previously sampled experimental results and (b) can be queried for predictions treated as hypotheses. This dual status of the surrogate model as both explanation and prediction (Hofman et al., Reference Hofman, Watts, Athey, Garip, Griffiths, Kleinberg and Yarkoni 2021; Nemesure, Heinz, Huang, & Jacobson, Reference Nemesure, Heinz, Huang and Jacobson 2021; Yarkoni & Westfall, Reference Yarkoni and Westfall 2017) distinguishes it from the traditional notion of hypothesis testing. Rather than evaluating a theory based on how well it fits existing (i.e., in-sample) experimental data, the surrogate model is continually evaluated on its ability to predict new (i.e., out-of-sample) experimental data. Moreover, once the new data have been observed, the model is updated to reflect the new information, and new predictions are generated. We emphasize that the surrogate model from the active learning approach is just one way to generate, test, and learn from risky predictions. Many other approaches also satisfy this criterion. For example, one might train a machine-learning model other than the surrogate model to estimate heterogeneity of treatment effects and to discover complex structures that were not specified in advance (Wager & Athey, Reference Wager and Athey 2018). Alternatively, one could use an interpretable, mechanistic, model. The only essential requirements for an integrative model are that it leverages the commensurability of the design space to in some way (a) accurately explain data that researchers have already observed, (b) make predictions about as-yet-unseen experiments, and then, having run those experiments, and (c) integrate the newly learned information to improve the model. If accurate predictions are achievable across some broad domain of the design space, the model can then be interpreted as supporting or rejecting various theoretical claims in a context-population-dependent way, as illustrated schematically in Figure 2B. Reflecting Merton's ( Reference Merton 1968) call for \u201ctheories of the middle range,\u201d a successful metatheory could identify the boundaries between empirically distinct regions of the design space (i.e., regions where different observed answers to the same research question pertain), making it possible to precisely state under what conditions (i.e., for which ranges of parameter values) one should expect different theoretically informed results to apply. If accurate predictions are unachievable even after an arduous search, the result is not a failure of the integrative framework. Rather, it would be an example of the framework's revealing a fundamental limit to prediction and, hence, explanation (Hofman, Sharma, & Watts, Reference Hofman, Sharma and Watts 2017; Martin, Hofman, Sharma, Anderson, & Watts, Reference Martin, Hofman, Sharma, Anderson and Watts 2016; Watts et al., Reference Watts, Beck, Bienenstock, Bowers, Frank, Grubesic and Salganik 2018). Footnote 12 In the extreme, when no point in the space is informative of any other point, generalizations of any sort are unwarranted. In such a scenario, applied research might still be possible, for example, by sampling the precise point of interest (Manzi, Reference Manzi 2012), but the researcher's drive to attain a generalizable theoretical understanding of a domain of inquiry would be exposed as fruitless. Such an outcome would be disappointing, but from a larger scientific perspective, it is better to know what cannot be known than to believe in false promises. Naturally, whether such outcomes arise \u2013 and if so, how frequently \u2013 is itself an empirical question that the proposed framework could inform. With sufficient integrative experiments over many domains, the framework might yield a \u201cmeta-metatheory\u201d that clarifies under which conditions one should (or should not) expect to find predictively accurate metatheories. 3.3.2. Bridging scientific and pragmatic knowledge Another feature of integrative theories is that they will lend themselves to a \u201cuse-inspired\u201d approach. Practitioners and researchers alike generally acknowledge that no single intervention, however evidence-based, benefits all individuals in all circumstances (i.e., across populations and contexts) and that overgeneralization from lab experiments in many areas of behavioral science can (and routinely does) lead practitioners and policymakers to deploy suboptimal and even dangerous real-world interventions (Brewin, Reference Brewin 2022; de Leeuw, Motz, Fyfe, Carvalho, & Goldstone, Reference de Leeuw, Motz, Fyfe, Carvalho and Goldstone 2022; Grubbs, Reference Grubbs 2022; Wiernik, Raghavan, Allan, & Denison, Reference Wiernik, Raghavan, Allan and Denison 2022). Therefore, social scientists should precisely identify the most effective intervention under each arising set of circumstances. The integrative approach naturally emphasizes contingencies and enables practitioners to distinguish between the most general result and the result that is most useful in practice. For example, in Figure 2B, the experiments depicted with a gray point correspond to the most general claim, occupying the largest region in the design space. However, this view ignores relevance, defined as points that represent the \u201ctarget\u201d conditions or the particular real-world context to which the practitioner hopes to generalize the results (Berkman & Wilson, Reference Berkman and Wilson 2021; Brunswik, Reference Brunswik 1955), as shown in Figure 2C. By concretely emphasizing these theoretical contingencies, the integrative approach supports \u201cuse-inspired\u201d research (Stokes, Reference Stokes 1997; Watts, Reference Watts 2017). 4. Existing steps toward integrative experiments Integrative experiment design is not yet an established framework. However, some recent experimental work has begun to move in the direction we endorse \u2013 for example, by explicitly constructing a design space, sampling conditions more broadly and densely than the one-at-a-time approach would have, and constructing new kinds of theories that reflect the complexity of human behavior. In this section, we describe three examples of such experiments in the domains of (1) moral judgments, (2) risky choices, and (3) subliminal priming effects. Note that these examples are not an exhaustive accounting of relevant work, nor fully fleshed out exemplars of the integrative framework. Rather, we find them to be helpful illustrations of work that is closely adjacent to what we describe and evidence that the approach is realizable and can yield useful insights. 4.1. Factors influencing moral judgments Inspired by the trolley problem, the seminal \u201cMoral Machine\u201d experiment used crowdsourcing to study human perspectives on moral decisions made by autonomous vehicles (Awad et al., Reference Awad, Dsouza, Kim, Schulz, Henrich, Shariff and Rahwan 2018, Reference Awad, Dsouza, Bonnefon, Shariff and Rahwan 2020). The experiment was supported by an algorithm that sampled a nine-dimensional space of over 9 million distinct moral dilemmas. In the first 18 months after deployment, the researchers collected more than 40 million decisions in 10 languages from over 4 million unique participants in 233 countries and territories (Fig. 3A). Figure 3. Examples of integrative experiments. The top row illustrates the experimental tasks used in the Moral Machine, decisions under risk, and subliminal priming effects experiments, respectively, followed by the parameters varied across each experiment (bottom row). Each experiment instance (i.e., a scenario in the Moral Machine experiment, a pair of gambles in the risky-choice experiment, and a selection of facet values in the subliminal priming effects experiment) can be described by a vector of parameter values. Reducing the resulting space to two dimensions (2D) visualizes coverage by different experiments. This 2D embedding results from applying principal component analysis (PCA) to the parameters of these experimental conditions. The study offers numerous findings that were neither obvious nor deducible from prior research or traditional experimental designs. For example, they show that once a moral dilemma is made sufficiently complex, few people will hold to the principle of treating all lives equally. Instead, they appear to treat demographic groups quite differently \u2013 for example, a willingness to sacrifice the elderly in service of the young, and a preference for sparing the wealthy over the poor at about the same level as the preference for preserving people following the law over those breaking it (Awad et al., Reference Awad, Dsouza, Kim, Schulz, Henrich, Shariff and Rahwan 2018). A second surprising finding by Awad et al. ( Reference Awad, Dsouza, Kim, Schulz, Henrich, Shariff and Rahwan 2018) was that the differences between omission and commission (a staple of discussions of Western moral philosophy) ranks surprisingly low relative to other variables affecting judgments of morality and that this ethical preference for inaction is primarily concentrated in Western cultures (e.g., North America and many European countries of Protestant, Catholic, and Orthodox Christian cultural groups). Indeed, the observation that clustering between countries is not just based on one or two ethical dimensions, but on a full profile of the multiplicity of ethical dimensions is something that would have been impossible to detect using studies that lacked the breadth of experimental conditions sampled in this study. Moreover, such an approach to experimentation yields datasets that are more useful to other researchers as they evaluate their hypotheses, develop new theories, and address long-standing concerns such as which variables matter most to producing a behavior and what their relative contributions might be. For instance, Agrawal and colleagues used the dataset generated by the Moral Machine experiment to build a model with a black-box machine-learning method (specifically, an artificial neural network) for predicting people's decisions (Agrawal, Peterson, & Griffiths, Reference Agrawal, Peterson and Griffiths 2020). This predictive model was used to critique a traditional cognitive model and identify potentially causal variables influencing people's decisions. The cognitive model was then evaluated in a new round of experiments that tested its predictions about the consequences of manipulating the causal variables. This approach of \u201cscientific regret minimization\u201d combined machine learning with rational choice models to jointly maximize the theoretical model's predictive accuracy and interpretability in the context of moral judgments. It also yielded a more-complex theory than psychologists might be accustomed to: The final model had over 100 meaningful predictors, each of which could have been the subject of a distinct experiment and theoretical insight about human moral reasoning. By considering the influence of these variables in a single study by Awad et al. ( Reference Awad, Dsouza, Kim, Schulz, Henrich, Shariff and Rahwan 2018), the researchers could ask what contribution each made to explaining the results. Investigation at this scale becomes possible when machine-learning methods augment the efforts of human theorists (Agrawal et al., Reference Agrawal, Peterson and Griffiths 2020). 4.2. The space of risky decisions The choice prediction competitions studied human decisions under risk (i.e., where outcomes are uncertain) by automating selection of more than 100 pairs of gambles from a 12-dimensional space with an algorithm (Erev, Ert, Plonsky, Cohen, & Cohen, Reference Erev, Ert, Plonsky, Cohen and Cohen 2017; Plonsky et al., Reference Plonsky, Apel, Ert, Tennenholtz, Bourgin, Peterson and Erev 2019). Recent work scaled this approach by taking advantage of the larger sample sizes made possible by virtual labs, collecting human decisions for over 10,000 pairs of gambles (Bourgin, Peterson, Reichman, Russell, & Griffiths, Reference Bourgin, Peterson, Reichman, Russell, Griffiths, Chaudhuri and Salakhutdinov 2019; Peterson, Bourgin, Agrawal, Reichman, & Griffiths, Reference Peterson, Bourgin, Agrawal, Reichman and Griffiths 2021). By sampling the space of possible experiments (in this case, gambles) much more densely (Fig. 3B), Peterson et al. ( Reference Peterson, Bourgin, Agrawal, Reichman and Griffiths 2021) found that two of the classic phenomena of risky choice \u2013 loss aversion and overweighting of small probabilities \u2013 did not manifest uniformly across the entire space of possible gambles. These two phenomena originally prompted the development of prospect theory (Kahneman & Tversky, Reference Kahneman and Tversky 1979), representing significant deviations from the predictions of classic expected utility theory. By identifying regions of the space of possible gambles where loss aversion and overweighting of small probabilities occur, Kahneman and Tversky showed that expected utility theory does not capture some aspects of human decision making. However, in analyzing predictive performance across the entire space of gambles, Peterson et al. found that prospect theory was outperformed by a model in which the degree of loss aversion and overweighting of small probabilities varied smoothly over the space. The work of Peterson et al. ( Reference Peterson, Bourgin, Agrawal, Reichman and Griffiths 2021) illustrates how the content of theories might be expected to change with a shift to the integrative approach. Prospect theory makes a simple assertion about human decision making: People exhibit loss aversion and overweight small probabilities. Densely sampling a larger region of the design space yields a more nuanced theory: While the functional form of prospect theory is well suited for characterizing human decisions, the extent to which people show loss aversion and overweight small probabilities depends on the context of the choice problem. That dependency is complicated. Even so, Peterson et al. identified several relevant variables such as the variability of the outcomes of the underlying gambles and whether the gamble was entirely in the domain of losses. Machine-learning methods were useful in developing this theory, initially to optimize the parameters of the functions assumed by prospect theory and other classic theories of decision making so as to ensure evaluation of the best possible instances of those theories, and then to demonstrate that these models did not capture variation in people's choices that could be predicted by more-complex models. 4.3. A metastudy of subliminal priming effects A recent cognitive psychology paper described an experiment in which a subliminal cue influences how participants balance speed and accuracy in a response-time task (Reuss, Kiesel, & Kunde, Reference Reuss, Kiesel and Kunde 2015). In particular, participants were instructed to rapidly select a target according to a cue that signaled whether to prioritize response accuracy over speed, or vice versa. Reuss et al. reported typical speed\u2013accuracy tradeoffs: When cued to prioritize speed, participants were faster and gave less accurate responses, whereas when cued to prioritize accuracy, participants were slower and more accurate. Crucially, this relationship was also found with cues that were rendered undetectable via a mask, an image presented directly before or after the cue that can suppress conscious perception of it. The study design of the original experiment included several nuisance variables (e.g., the color of the cue), the values of which were not thought to affect the finding of subliminal effects. If the claimed effects were general, it would appear for all plausible values of the nuisance variables, whereas its appearance in some (contiguous) ranges of values but not in others would indicate contingency. And if spurious, the effect would appear only for the original values, if at all. Baribault et al. ( Reference Baribault, Donkin, Little, Trueblood, Oravecz, van Ravenzwaaij and Vandekerckhove 2018) took a \u201cradical randomization\u201d approach (also called a \u201cmetastudy\u201d approach) in examining the generalizability and robustness of the original finding by randomizing 16 independent variables that could moderate the subliminal priming effect (Fig. 3C). By sampling nearly 5,000 \u201cmicroexperiments\u201d from the 16-dimensional design space, Baribault et al. revealed that masked cues had an effect on participant behavior only in the subregion of the design space where the cue is consciously visible, thus providing much stronger evidence about the lack of the subliminal priming effect than any single traditional experiment evaluating this effect could have. For a recent, thorough discussion of the metastudy approach and its advantages, along with a demonstration using the risky-choice framing effect, see DeKay, Rubinchik, Li, and De Boeck ( Reference DeKay, Rubinchik, Li and De Boeck 2022). 5. Critiques and concerns We have argued that adopting what we have called \u201cintegrative designs\u201d in experimental social and behavioral science will lead to more-consistent, more-cumulative, and more-useful science. As should be clear from our discussion, however, our proposal is preliminary and therefore subject to several questions and concerns. Here we outline some of the critiques we have encountered and offer our responses. 5.1. Isn't the critique of the one-at-a-time approach unfair? One possible response is that our critique of the one-at-a-time approach is unduly critical and does not recognize its proper role in the future of social and behavioral sciences. To be clear, we are neither arguing that scientists should discard the \u201cone-at-a-time\u201d paradigm entirely nor denigrating studies (including our own!) that have employed it. The approach has generated a substantial amount of valuable work and continues to be useful for understanding individual causal effects, shaping theoretical models, and guiding policy. For example, it can be a sufficient and effective means to provide evidence for the existence of a phenomenon (but not the conditions under which it exists), as in field experiments that show that job applicants with characteristically \u201cBlack\u201d names are less likely to be interviewed than those with \u201cWhite\u201d names, revealing the presence of structural racism and informing public debates about discrimination (Bertrand & Mullainathan, Reference Bertrand and Mullainathan 2004). Moreover, one-at-a-time experimentation can precede the integrative approach when exploring a new topic and identifying the variables that make up the design space. Rather, our point is that the one-at-a-time approach cannot do all the work that is being asked of it, in large part because theories in the social and behavioral sciences cannot do all the work that is being asked of them. Once we recognize the inherent imprecision and ambiguity of social and behavioral theories, the lack of commensurability across independently designed and executed experiments is revealed as inevitable. Similarly, the solution we describe here can be understood simply as baking commensurability into the design process, by explicitly recognizing potential dimensions of variability and mapping experiments such that they can be compared with one another. In this way, the integrative approach can complement one-at-a-time experiments by incorporating them within design spaces (analogous to how articles already contextualize their contribution in terms of the prior literature), through which the research field might quickly recognize creative and pathbreaking contributions from one-at-a-time research. 5.2. Can't we solve the problem with meta-analysis? As discussed earlier, meta-analyses offer the attractive proposition that accumulation of knowledge can be achieved through a procedure that compares and combines results across experiments. But the integrative approach is different in at least three important ways. First, meta-analyses \u2013 as well as systematic reviews and integrative conceptual reviews \u2013 are by nature post hoc mechanisms for performing integration: The synthesis and integration steps occur after the data are collected and the results are published. Therefore, it can take years of waiting for studies to accumulate \u201cnaturally\u201d before one can attempt to \u201cput them together\u201d via meta-analyses (if at all, as the vast majority of published effects are never meta-analyzed). More importantly, because commensurability is not a first-order consideration of one-at-a-time studies, attempts to synthesize collections of such studies after the fact are intrinsically challenging. The integrative approach is distinct in that it treats commensurability as a first-order consideration that is baked into the research design at the outset (i.e., ex ante). As we have argued, the main benefit of ex ante over ex post integration is that the explicit focus on commensurability greatly eases the difficulty of comparing different studies and hence integrating their findings (whether similar or different). In this respect, our approach can be viewed as a \u201cplanned meta-analysis\u201d that is explicitly designed to sample conditions more broadly, minimize sampling bias, and efficiently reveal how effects vary across conditions. Although it may take more time and effort (and thus money) to run an integrative experiment than a single traditional experiment, when considering the accumulated effort of all the original research, this effort is much less than that of typical meta-analyses (see sect. 5.6 for a discussion about costs). Second, although a meta-analysis typically aims to estimate the size of an effect by aggregating (e.g., averaging) over design variations across experiments, our emphasis is on trying to map the variation in an effect across an entire design space. While some meta-analyses with sufficient data attempt to determine the heterogeneity of the effect of interest, these efforts are typically hindered by the absence of systematic data on the variations in design choices (as well as in methods). Third, publication bias induced by selective reporting of conditions and results \u2013 known as the file drawer problem (Carter, Sch\u00f6nbrodt, Gervais, & Hilgard, Reference Carter, Sch\u00f6nbrodt, Gervais and Hilgard 2019; Rosenthal, Reference Rosenthal 1979) \u2013 can lead to biased effect-size estimates in meta-analyses. While there are methods for identifying and correcting such biases, one cannot be sure of their effectiveness in any particular case because of their sensitivity to untestable assumptions (Carter et al., Reference Carter, Sch\u00f6nbrodt, Gervais and Hilgard 2019; Cooper, Hedges, & Valentine, Reference Cooper, Hedges and Valentine 2019). Another advantage of the integrative approach is that it is largely immune to such problems because all sampled experiments are treated as informative, regardless of the novelty or surprise value of the individual findings, thereby greatly reducing the potential for bias. 5.3. How do integrative experiments differ from other recent innovations in psychology? There have been several efforts to innovate on traditional experiments in the behavioral and social sciences. One key innovation is collaboration by multiple research labs to conduct systematic replications or to run larger-scale experiments than had previously been possible. For instance, the Many Labs initiative coordinated numerous research labs to conduct a series of replications of significant psychological results (Ebersole et al., Reference Ebersole, Atherton, Belanger, Skulborstad, Allen, Banks and Nosek 2016; Klein et al., Reference Klein, Ratliff, Vianello, Adams, Bahn\u00edk, Bernstein and Nosek 2014, Reference Klein, Vianello, Hasselman, Adams, Adams, Alper and Nosek 2018). This effort has itself been replicated in enterprises such as the ManyBabies Consortium (ManyBabies Consortium, 2020), ManyClasses (Fyfe et al., Reference Fyfe, de Leeuw, Carvalho, Goldstone, Sherman, Admiraal and Motz 2021), and ManyPrimates (Many Primates et al., Reference Altschul, Beran, Bohn, Call, DeTroy, Duguid and Watzek 2019), which pursue the same goal with more-specialized populations, and in the DARPA SCORE program, which did so over a representative sample of experimental research in the behavioral and social sciences (Witkop, Reference Witkop n.d.). Footnote 13 The Psychological Science Accelerator brings together multiple labs with a different goal: To evaluate key findings in a broader range of participant populations and at a global scale (Moshontz et al., Reference Moshontz, Campbell, Ebersole, IJzerman, Urry, Forscher and Chartier 2018). Then, there is the Crowdsourcing Hypothesis Tests collaboration, which assigned 15 research teams to each design a study targeting the same hypothesis, varying in methods (Landy et al., Reference Landy, Jia, Ding, Viganola, Tierney, Dreber and Uhlmann 2020). Moreover, there is a recent trend in behavioral science to run \u201cmegastudies,\u201d in which researchers test a large number of treatments in a single study in order to increase the pace and comparability of experimental results (Milkman et al., Reference Milkman, Patel, Gandhi, Graci, Gromet, Ho and Duckworth 2021, Reference Milkman, Gandhi, Patel, Graci, Gromet, Ho and Duckworth 2022; Voelkel et al., Reference Voelkel, Stagnaro, Chu, Pink, Mernyk, Redekopp and Willer 2022). All of these efforts are laudable and represent substantial methodological advances that we view as complements to, not substitutes for, integrative designs. What is core to the integrative approach is the explicit construction of, sampling from, and building theories upon a design space of experiments. Each ongoing innovation can contribute to the design of integrative experiments in its own way. For example, large-scale collaborative networks such as Many Labs can run integrative experiments together by assigning points in the design space to participating labs. Or in the megastudy research design, the interventions selected by researchers can be explicitly mapped into design spaces and then analyzed in a way that aims to reveal contingencies and generate metatheories of the sort discussed in section 3.3. 5.4. What about unknown unknowns? There will always be systematic nontrivial variables that should be represented in the design space but are missing \u2013 these are the unknown unknowns. We believe our responses to this challenge are worth expanding upon. First, we acknowledge the challenge inherent in the first step of integrative experiment design: Constructing the design space. This construction requires identifying the subset of variables to include from an infinite set of possible variables that could define the design space of experiments within a domain. To illustrate such a process, we discussed the example domain of group synergy (see sect. 3.1). But, of course, we think that the field is wide open, with many options to explore; that the methodological details will depend on the domain of interest; and that best practices will emerge with experience. Second, although we do not yet know which of the many potentially relevant dimensions should be selected to represent the space, and there are no guarantees that all (or even most) of the selected dimensions will play a role in determining the outcome, the integrative approach can shed light on both issues. On the one hand, experiments that map to the same point in the design space but yield different results indicate that some important dimension is missing from the representation of the space. On the other, experiments that systematically vary in the design space but yield similar results could indicate that the dimensions where they differ are irrelevant to the effect of interest and should be collapsed. 5.5. This sounds great in principle but it is impossible to do in practice Even with an efficient sampling scheme, integrative designs are likely to require a much larger number of experiments than is typical in the one-at-a-time paradigm; therefore, practical implementation is a real concern. However, given recent innovations in virtual lab environments, participant sourcing, mass collaboration mechanisms, and machine-learning methods, the approach is now feasible to some. 5.5.1. Virtual lab environments Software packages such as jsPsych (de Leeuw, Reference de Leeuw 2015) nodeGame (Balietti, Reference Balietti 2017), Dallinger (https://dallinger.readthedocs.io/), Pushkin (Hartshorne, de Leeuw, Goodman, Jennings, & O'Donnell, Reference Hartshorne, de Leeuw, Goodman, Jennings and O'Donnell 2019), Hemlock (Bowen, Reference Bowen n.d.), and Empirica (Almaatouq et al., Reference Almaatouq, Becker, Houghton, Paton, Watts and Whiting 2021b) support development of integrative experiments that can systematically cover an experimental design's parameter space with automatically executed conditions. Even with these promising tools, for which development is ongoing, we still believe that one of the most promising, cost-effective ways to accelerate and improve progress in social science is to increase investment in automation (Yarkoni et al., Reference Yarkoni, Eckles, Heathers, Levenstein, Smaldino and Lane 2019). 5.5.2. Recruiting participants Another logistical challenge to integrative designs is that adequately sampling the space of experiments will typically require a large participant pool from which the experimenter can draw, often repeatedly. As it stands, the most common means of recruiting participants online involves crowdsourcing platforms (Horton, Rand, & Zeckhauser, Reference Horton, Rand and Zeckhauser 2011; Mason & Suri, Reference Mason and Suri 2012). The large-scale risky-choice dataset described above, for example, used this approach to collect its 10,000 pairs of gambles (Bourgin et al., Reference Bourgin, Peterson, Reichman, Russell, Griffiths, Chaudhuri and Salakhutdinov 2019). However, popular crowdsourcing platforms such as Amazon Mechanical Turk (Litman, Robinson, & Abberbock, Reference Litman, Robinson and Abberbock 2017) were designed for basic labeling tasks, which can be performed by a single person and require low levels of effort. And the crowdworkers performing the tasks may have widely varying levels of commitment and produce work of varying quality (Goodman, Cryder, & Cheema, Reference Goodman, Cryder and Cheema 2013). Researchers are prevented by Amazon's terms of use from knowing whether crowdworkers have participated in similar experiments in the past, possibly as professional study participants (Chandler, Mueller, & Paolacci, Reference Chandler, Mueller and Paolacci 2014). To accommodate behavioral research's special requirements, Prolific and other services (Palan & Schitter, Reference Palan and Schitter 2018) have made changes to the crowdsourcing model, such as by giving researchers greater control over how participants are sampled and over the quality of their work. Larger, more diverse volunteer populations are also possible to recruit, as the Moral Machine experiment exemplifies. In the first 18 months after deployment, that team gathered more than 40 million moral judgments from over 4 million unique participants in 233 countries and territories (Awad, Dsouza, Bonnefon, Shariff, & Rahwan, Reference Awad, Dsouza, Bonnefon, Shariff and Rahwan 2020). Recruiting such large sample sizes from volunteers is appealing; however, success with such recruitment requires participant-reward strategies like gamification or personalized feedback (Hartshorne et al., Reference Hartshorne, de Leeuw, Goodman, Jennings and O'Donnell 2019; Li, Germine, Mehr, Srinivasan, & Hartshorne, Reference Li, Germine, Mehr, Srinivasan and Hartshorne 2022). Thus, it has been hard to generalize the model to other important research questions and experiments, particularly when taking part in the experiment does not appear to be fun or interesting. Moreover, such large-scale data collection using viral platforms such as the Moral Machine may require some flexibility from Institutional Review Boards (IRBs), as they resemble software products that are open to consumers more than they do closed experiments that recruit from well-organized, intentional participant pools. In the Moral Machine experiment, for example, the MIT IRB approved pushing the consent to an \u201copt-out\u201d option at the end, rather than obtaining consent prior to participation in the experiment, as the latter would have significantly increased participant attrition (Awad et al., Reference Awad, Dsouza, Kim, Schulz, Henrich, Shariff and Rahwan 2018). 5.5.3. Mass collaboration Obtaining a sufficiently large sample may require leveraging emerging forms of organizing research in the behavioral and social sciences, such as distributed collaborative networks of laboratories (Moshontz et al., Reference Moshontz, Campbell, Ebersole, IJzerman, Urry, Forscher and Chartier 2018). As we discussed earlier, in principle, large-scale collaborative networks can cooperatively run integrative experiments by assigning points in the design space to participating labs. 5.5.4. Machine learning The physical and life sciences have benefited greatly from machine learning. Astrophysicists use image-classification systems to interpret the massive amounts of data recorded by their telescopes (Shallue & Vanderburg, Reference Shallue and Vanderburg 2018). Life scientists use statistical methods to reconstruct phylogeny from DNA sequences and use neural networks to predict the folded structure of proteins (Jumper et al., Reference Jumper, Evans, Pritzel, Green, Figurnov, Ronneberger and Hassabis 2021). Experiments in the social and behavioral sciences, in contrast, have had relatively few new methodological breakthroughs related to these technologies. While social and behavioral scientists in general have embraced \u201cbig data\u201d and machine learning, their focus to date has largely been on nonexperimental data. Footnote 14 In contrast, the current scale of experiments in the experimental social and behavioral sciences does not typically produce data at the volumes necessary for machine-learning models to yield substantial benefits over traditional methods. Integrative experiments offer several new opportunities for machine-learning methods to be used to facilitate social and behavioral science. First, by producing larger datasets \u2013 either within a single experiment or across multiple integrated experiments in the same design space \u2013 the approach makes it possible to use a wider range of machine-learning methods, particularly ones less constrained by existing theories. This advantage is illustrated by the work of Peterson et al. ( Reference Peterson, Bourgin, Agrawal, Reichman and Griffiths 2021), whose neural network models were trained on human choice data to explore the implications of different theoretical assumptions for predicting decisions. Second, these methods can play a valuable role in helping scientists make sense of the many factors that potentially influence behavior in these larger datasets, as in Agrawal et al.'s ( Reference Agrawal, Peterson and Griffiths 2020) analysis of the Moral Machine data. Finally, machine-learning techniques are a key part of designing experiments that efficiently explore large design spaces, as they are used to define surrogate models that are the basis for active sampling methods. 5.6. Even if such experiments are possible, costs will be prohibitive It is true that integrative experiments are more expensive to run than individual one-at-a-time experiments, which may partly explain why the former have not yet become more popular. However, this comparison is misleading because it ignores the cost of human capital in generating scientific insight. Assume that a typical experimental paper in the social and behavioral sciences reflects on the order of $100,000 of labor costs in the form of graduate students or postdocs designing and running the experiment, analyzing the data, and writing up the results. Under the one-at-a-time approach, such a paper typically contains just one or at most a handful of experiments. The next paper builds upon the previous results and the process repeats. With hundreds of articles published over a few decades, the cumulative cost of a research program that explores roughly 100 points in the implicit design space easily reaches tens of millions of dollars. Of those tens of millions of dollars, a tiny fraction \u2013 on the order of $1,000 per paper, or $100,000 per research program (<1%) \u2013 is spent on data collection. If instead researchers conducted a single-integrative experiment that covered the entire design space, they could collect all the data produced by the entire research program and then some. Even if this effort explored the design space significantly less efficiently than the traditional research program, requiring 10 times more data, data collection would cost about $1,000,000 (<10%). This is a big financial commitment, but the labor costs for interpreting these data do not scale with the amount of data. So, even if researchers needed to commit 10 times as much labor as for a typical research paper, they would have discovered everything an entire multidecade research program would uncover in a single study costing only $2,000,000. The cost\u2013benefit ratio of integrative experiments is hence at least an order of magnitude better than that of one-at-a-time experiments. Footnote 15 Pinching pennies on data collection results in losing dollars (and time and effort) in labor. If anything, when considered in aggregate, the efficiency gains of the integrative approach will be substantially greater than this back of the envelope calculation suggests. As an institution, the social and behavioral sciences have spent tens of billions of dollars during the past half-century. Footnote 16 With integrative designs, a larger up-front investment can save decades of unfruitful investigation and instead realize grounded, systematic results. 5.7. Does this mean that small labs can't participate? Although the high up-front costs of designing and running an integrative experiment may seem to exclude small labs as well as Principal investigators (PIs) from low-resource institutions, we anticipate that the integrative approach will actually broaden the range of people involved in behavioral research. The key insight here is that the methods and infrastructure needed to run integrative experiments are inherently shareable. Thus, while the development costs are indeed high, once the infrastructure has been built, the marginal costs of using it are low \u2013 potentially even lower than running a single, one-at-a-time experiment. As long as funding for the necessary technical infrastructure is tied to a requirement for sustaining collaborative research (as discussed in previous sections), it will create opportunities for a wider range of scientists to be involved in integrative projects and for researchers at smaller or undergraduate-focused institutions to participate in ambitious research efforts. Moreover, research efforts in other fields illustrate how labs of different sizes can make different kinds of contributions. In biology and physics, some groups of scientists form consortia that work together to define a large-scale research agenda and seek the necessary funding (as described earlier, several thriving experimental consortia in the behavioral sciences illustrate this possibility). Other groups develop theory by digging deeper into the data produced by these large-scale efforts to make discoveries they may not have imagined when the data were first collected; some scientists focus on answering questions that do not require large-scale studies, such as the properties of specific organisms or materials that can be easily studied in a small lab; still other researchers conduct exploratory work to identify the variables or theoretical principles that may be considered in future large-scale studies. We envision a similar ecosystem for the future of the behavioral sciences. 5.8. Shouldn't the replication crisis be resolved first? The replication crisis in the behavioral sciences has led to much reflection about research methods and substantial efforts to conduct more-applicable research (Freese & Peterson, Reference Freese and Peterson 2017). We view our proposal as being consistent with these goals, but with a different emphasis than replication. To some extent, this difference is complementary to replication and can be pursued in parallel with it, but may suggest a different allocation of resources than a \u201creplication first\u201d approach. Discussing the complementary role first, integrative experiments naturally support replicable science. Because choices about nuisance variables are rarely documented systematically in the one-at-a-time paradigm, it is not generally possible to establish how similar or different two experiments are. This observation may account for some recently documented replication failures (Camerer et al., Reference Camerer, Dreber, Holzmeister, Ho, Huber, Johannesson and Wu 2018; Levinthal & Rosenkopf, Reference Levinthal and Rosenkopf 2021). While the replication debate has focused on shoddy research practices (e.g., p-hacking) and bad incentives (e.g., journals rewarding \u201cpositive, novel, and exciting\u201d results), another possible cause of nonreplication is that the replicating experiment is in fact sufficiently dissimilar to the original (usually as a result of different choices of nuisance parameters) that one should not expect the result to replicate (Muthukrishna & Henrich, Reference Muthukrishna and Henrich 2019; Yarkoni, Reference Yarkoni 2022). In other words, without operating within a space that makes experiments commensurate, failures to replicate previous findings are never conclusive, because doubt remains as to whether one of the many possible moderator variables explains the lack of replication (Cesario, Reference Cesario 2014). Regardless of whether an experimental finding's fragility to (supposedly) theoretically irrelevant parameters should be considered a legitimate defense of the finding, the difficulty of resolving such arguments further illustrates the need for a more explicit articulation of theoretical scope conditions. The integrative approach, accepting that treatment effects vary across conditions, would also recommend that directing massive resources to replicating existing effects may not be the best way to help our fields advance. Given that those historical effects were discovered under the one-at-a-time approach, they evaluate only specific points in the design space. Consistent with the argument above, rather than trying to perfectly reproduce those points in the design space (via \u201cdirect\u201d replications), a better use of resources would be to sample the design space more extensively and use continuous measures to compare different studies (Gelman, Reference Gelman 2018). In this way, researchers can not only discover whether historical effects replicate, but also draw stronger conclusions about whether (and to what extent) they generalize. 5.9. This proposal is incompatible with incentives in the social and behavioral sciences Science does not occur in a vacuum. Scientists are constantly evaluated by their peers as they submit papers for publication, seek funding, apply for jobs, and pursue promotions. For the integrative approach to become widespread, it must be compatible with the incentives of individual behavioral scientists, including early career researchers. Given the current priority that hiring, tenure & promotion, and awards committees in the social and behavioral sciences place on identifiable individual contributions (e.g., lead authorship of scholarly works, perceived \u201cownership\u201d of distinct programs of research, leadership positions, etc.), a key pragmatic concern is that the large-scale collaborative nature of integrative research designs might make them less rewarding than the one-at-a-time paradigm for anyone other than the project leaders. Although a shift to large-scale, collaborative science does indeed present an adoption challenge, it is encouraging to note that even more dramatic shifts have taken place in other fields. In physics, for example, some of the most important results in recent decades \u2013 the discovery of the Higgs Boson (Aad et al., Reference Aad, Abajyan, Abbott, Abdallah, Abdel Khalek, Abdelalim and Zwalinski 2012), gravitational waves (Abbott et al., Reference Abbott, Abbott, Abbott, Abernathy, Acernese and Ackley 2016), and so on \u2013 have been obtained via collaborations of thousands of researchers. Footnote 17 To ensure that junior team members are rewarded for their contributions, many collaborations maintain \u201cspeaker lists\u201d that prominently feature early career researchers, offering them a chance to appear as the face of the collaboration. When these researchers apply for jobs or are considered for promotion, the leader of the collaboration writes a letter of recommendation that describes the scientists' role in the collaboration and why their work is significant. A description of such roles can also be included directly in manuscripts through the Contributor Roles Taxonomy (Allen, Scott, Brand, Hlava, & Altman, Reference Allen, Scott, Brand, Hlava and Altman 2014), a high-level taxonomy with 14 roles that describe typical contributions to scholarly output; the taxonomy has been adopted as an American National Standards Institute (ANSI)/National Information Standards Organization (NISO) standard and is beginning to see uptake (National Information Standards Organization, 2022). Researchers who participate substantially in creating the infrastructure used by a collaborative effort can receive \u201cbuilder\u201d status, appearing as coauthors on subsequent publications that use that infrastructure. Many collaborations also have mentoring plans designed to support early career researchers. Together, these mechanisms are intended to make participation in large collaborations attractive to a wide range of researchers at various career stages. While acknowledging that physics differs in many ways from the social and behavioral sciences, we nonetheless believe that the model of large collaborative research efforts can take root in the latter. Indeed, we have already noted the existence of several large collaborations in the behavioral sciences that appear to have been successful in attracting participation from small labs and early career researchers. 6. Conclusion The widespread approach of designing experiments one-at-a-time \u2013 under different conditions with different participant pools, and with nonstandardized methods and reporting \u2013 is problematic because it is at best an inefficient way to accumulate knowledge, and at worst it fails to produce consistent, cumulative knowledge. The problem clearly will not be solved by increasing sample sizes, focusing on effect sizes rather than statistical significance, or replicating findings with preregistered designs. We instead need a fundamental shift in how to think about theory construction and testing. We describe one possible approach, one that promotes commensurability and continuous integration of knowledge by design. In this \u201cintegrative\u201d approach, experiments would not just evaluate a few hypotheses but would explore and integrate over a wide range of conditions that deserve explanation by all pertinent theories. Although this kind of experiment may strike many as atheoretical, we believe the one-at-a-time approach owes its dominance not to any particular virtues of theory construction and evaluation but rather to the historical emergence of experimental methods under a particular set of physical and logistical constraints. Over time, generations of researchers have internalized these features to such an extent that they are thought to be inseparable from sound scientific practice. Therefore, the key to realizing our proposed type of reform \u2013 and to making it productive and useful \u2013 is not only technical, but also cultural and institutional. Acknowledgments We owe an important debt to Saul Perlmutter, Serguei Saavedra, Matthew J. Salganik, Gary King, Todd Gureckis, Alex \u201cSandy\u201d Pentland, Thomas W. Malone, David G. Rand, Iyad Rahwan, Ray E. Reagans, and the members of the MIT Behavioral Lab and the UPenn Computational Social Science Lab for valuable discussions and comments. This article also benefited from conversations with dozens of people at two workshops: (1) \u201cScaling Cognitive Science\u201d at Princeton University in December 2019, and (2) \u201cScaling up Experimental Social, Behavioral, and Economic Science\u201d at the University of Pennsylvania in January 2020. Financial support This work was supported in part by the Alfred P. Sloan Foundation (2020-13924) and the NOMIS Foundation. Competing interest None. Footnotes 1. Although we restrict the focus of our discussion to lab experiments in the social and behavioral sciences, with which we are most familiar, we expect that our core arguments generalize well to other modes of inquiry and adjacent disciplines. 2. By analogy, we note that for almost as long as p-values have been used as a standard of evidence in the social and behavioral sciences, critics have argued that they are somewhere between insufficient and meaningless (Cohen, 1994; Dienes, 2008; Gelman & Carlin, 2017; Meehl, 1990a). Yet, in the absence of an equally formulaic alternative, p-value analysis remains pervasive (Benjamin et al., 2018). 3. Nor do recent proposals to improve the replicability and reproducibility of scientific results (Gelman & Loken, 2014; Ioannidis, 2005; Munaf\u00f2 et al., 2017; Open Science Collaboration, 2015; Simmons, Nelson, & Simonsohn, 2011) address the problem. While these proposals are worthy, their focus is on individual results, not on how collections of results fit together. 4. We also note that in an alternative formulation of the design space, all variables (including what one would think of as experimental manipulations) are included as dimensions of the design space and the focal experimental manipulation is represented as a comparison across two or more points in the space. Some of the examples described in section 4 are more readily expressed in one formulation, whereas others are more readily expressed in the other. They are equivalent: It is possible to convert from one to the other without any loss of information. 5. To illustrate with another example, cultural psychologists such as Hofstede (2016), Inglehart and Welzel (2005), and Schwartz (2006) identified cultural dimensions along which groups differ, which then can be used to define distance measures between populations and to guide researchers in deciding where to target their data-collection efforts (Muthukrishna et al., 2020). Another example of this exercise is the extensive breakdown of the \u201cauction design space\u201d by Wurman, Wellman, and Walsh (2001), which captures the essential similarities and differences of many auction mechanisms in a format more descriptive and useful than simple taxonomies and serves as an organizational framework for classifying work within the field. 6. Active learning is also called \u201cquery learning\u201d or sometimes \u201csequential optimal experimental design\u201d in the statistics literature. 7. Active learning has recently become an important tool for optimizing experiments in other fields, such as machine-learning hyperparameters (Snoek, Larochelle, & Adams, 2012), materials and mechanical designs (Burger et al., 2020; Gongora et al., 2020; Lei et al., 2021), and chemical reaction screening (Eyke, Green, & Jensen, 2020, 2021; Shields et al., 2021) \u2013 just to mention a few. 8. For example, surrogate models can be probabilistic models (e.g., a Gaussian process) as well as nonprobabilistic (e.g., neural networks, tree-based methods), while sampling strategies can include uncertainty sampling, greedy sampling, and distance-based sampling. 9. Popular active learning libraries for experiments include Ax (Bakshy et al., 2018), BoTorch (Balandat et al., 2020), and GPflowOpt (Knudde, van der Herten, Dhaene, & Couckuyt, 2017). 10. See Settles (2011), Greenhill, Rana, Gupta, Vellanki, and Venkatesh (2020), and Ren et al. (2021) for surveys on active learning. 11. Given that the data from the integrative approach are generated independent of the current set of theories in the field, the resulting data are potentially informative not just about those theories, but about theories that are yet to be proposed. As a consequence, data generated by this integrative approach are intended to have greater longevity than data generated by \u201cone-at-a-time\u201d experiments. 12. Another explanation for the inability to make accurate predictions is that the majority of dimensions defining the design space are uninformative and need to be reconsidered. 13. For a more comprehensive list, see Uhlmann et al. (2019). 14. For example, the CHILDES dataset of child-directed speech (MacWhinney, 2014) has had a significant impact on studies of language development, and census data, macroeconomic data, and other large datasets (e.g., from social media and e-commerce platforms) are increasingly prevalent in political science, sociology, and economics. 15. This shift has already occurred in some areas. For example, the cognitive neuroscience field has been transformed in the past few decades by the availability of increasingly effective methods for brain imaging. Researchers now take for granted that data collection costs tens or hundreds of thousands of dollars and that the newly required equipment and other infrastructure for this kind of research costs millions of dollars \u2013 that is, they now budget more for data collection than for hiring staff. Unlocking the full potential of our envisioned integrative approach will require similarly new, imaginative ways of allocating resources and a willingness to spend money on generating more-definitive, reusable datasets (Griffiths, 2015). 16. The budget associated with the NSF Directorate for Social, Behavioral, and Economic Sciences alone is roughly 5 billion dollars over the past two decades and, by its 2022 estimate, accounts for \u201capproximately 65 percent of the federal funding for basic research at academic institutions in the social, behavioral, and economic sciences\u201d (National Science Foundation, 2022). Extending the time range to 50 years and accounting for sources of funding beyond the US federal government, including all other governments, private foundations, corporations, and direct funding from universities, brings our estimate to tens of billions of dollars. 17. We thank Saul Perlmutter for sharing his perspective on how issues of incentives are addressed in physics, drawing on his experience in particle physics and cosmology. References Aad, G., Abajyan, T., Abbott, B., Abdallah, J., Abdel Khalek, S., Abdelalim, A. A., \u2026 Zwalinski, L. (2012). Observation of a new particle in the search for the Standard Model Higgs Boson with the ATLAS detector at the LHC. Physics Letters, Part B, 716(1), 1\u201329.CrossRefGoogle Scholar Abbott, B. P., Abbott, R., Abbott, T. D., Abernathy, M. R., Acernese, F., Ackley, K., \u2026 LIGO Scientific Collaboration and Virgo Collaboration. (2016). Observation of gravitational waves from a binary black hole merger. Physical Review Letters, 116(6), 061102.CrossRefGoogle ScholarPubMed Aggarwal, I., & Woolley, A. W. (2018). Team creativity, cognition, and cognitive style diversity. Management Science, 65(4), 1586\u20131599. https://doi.org/10.1287/mnsc.2017.3001CrossRefGoogle Scholar Agrawal, M., Peterson, J. C., & Griffiths, T. L. (2020). Scaling up psychology via scientific regret minimization. Proceedings of the National Academy of Sciences of the United States of America, 117(16), 8825\u20138835.CrossRefGoogle ScholarPubMed Allen, L., Scott, J., Brand, A., Hlava, M., & Altman, M. (2014). Publishing: Credit where credit is due. Nature, 508(7496), 312\u2013313.CrossRefGoogle ScholarPubMed Allen, N. J., & Hecht, T. D. (2004). The \u201cromance of teams\u201d: Toward an understanding of its psychological underpinnings and implications. Journal of Occupational and Organizational Psychology, 77(4), 439\u2013461.CrossRefGoogle Scholar Allport, F. H. (1924). The group fallacy in relation to social science. The American Journal of Sociology, 29(6), 688\u2013706.CrossRefGoogle Scholar Almaatouq, A. (2019). Towards stable principles of collective intelligence under an environment-dependent framework. Massachusetts Institute of Technology. https://dspace.mit.edu/handle/1721.1/123223?show=full?show=fullGoogle Scholar Almaatouq, A., Alsobay, M., Yin, M., & Watts, D. J. (2021a). Task complexity moderates group synergy. Proceedings of the National Academy of Sciences of the United States of America, 118(36), e2101062118. https://doi.org/10.1073/pnas.2101062118CrossRefGoogle ScholarPubMed Almaatouq, A., Becker, J., Houghton, J. P., Paton, N., Watts, D. J., & Whiting, M. E. (2021b). Empirica: A virtual lab for high-throughput macro-level experiments. Behavior Research Methods, 53, 2158\u20132171. https://doi.org/10.3758/s13428-020-01535-9CrossRefGoogle ScholarPubMed Almaatouq, A., Noriega-Campero, A., Alotaibi, A., Krafft, P. M., Moussaid, M., & Pentland, A. (2020). Adaptive social networks promote the wisdom of crowds. Proceedings of the National Academy of Sciences of the United States of America, 117(21), 11379\u201311386.CrossRefGoogle ScholarPubMed Almaatouq, A., Rahimian, M. A., Burton, J. W., & Alhajri, A. (2022). The distribution of initial estimates moderates the effect of social influence on the wisdom of the crowd. Scientific Reports, 12(1), 16546.CrossRefGoogle ScholarPubMed Many Primates, Altschul, D. M., Beran, M. J., Bohn, M., Call, J., DeTroy, S., Duguid, S. J., \u2026 Watzek, J. (2019). Establishing an infrastructure for collaboration in primate cognition research. PLoS ONE, 14(10), e0223675.Google ScholarPubMed Arrow, H., McGrath, J. E., & Berdahl, J. L. (2000). Small groups as complex systems: Formation, coordination, development, and adaptation. Sage.CrossRefGoogle Scholar Atkinson, A. C., & Donev, A. N. (1992). Optimum experimental designs (Oxford statistical science series, 8) (1st ed.). Clarendon Press.Google Scholar Aumann, R. J., & Hart, S. (1992). Handbook of game theory with economic applications. Elsevier.Google Scholar Auspurg, K., & Hinz, T. (2014). Factorial survey experiments. Sage.Google Scholar Awad, E., Dsouza, S., Bonnefon, J.-F., Shariff, A., & Rahwan, I. (2020). Crowdsourcing moral machines. Communications of the ACM, 63(3), 48\u201355.CrossRefGoogle Scholar Awad, E., Dsouza, S., Kim, R., Schulz, J., Henrich, J., Shariff, A., \u2026 Rahwan, I. (2018). The Moral Machine experiment. Nature, 563(7729), 59\u201364.CrossRefGoogle ScholarPubMed Bakshy, E., Dworkin, L., Karrer, B., Kashin, K., Letham, B., Murthy, A., & Singh, S. (2018). AE: A domain-agnostic platform for adaptive experimentation. Workshop on System for ML. http://learningsys.org/nips18/assets/papers/87CameraReadySubmissionAE%20-%20NeurIPS%202018.pdfGoogle Scholar Balandat, M., Karrer, B., Jiang, D. R., Daulton, S., Letham, B., Wilson, A. G., & Bakshy, E. (2020). BoTorch: A framework for efficient Monte-Carlo Bayesian optimization. In Proceedings of the 34th International Conference on Neural Information Processing Systems (NIPS'20) (pp. 21524\u201321538). Curran Associates Inc.Google Scholar Balietti, S. (2017). NodeGame: Real-time, synchronous, online experiments in the browser. Behavior Research Methods, 49(5), 1696\u20131715.CrossRefGoogle ScholarPubMed Balietti, S., Klein, B., & Riedl, C. (2021). Optimal design of experiments to identify latent behavioral types. Experimental Economics, 24, 772\u2013799. https://doi.org/10.1007/s10683-020-09680-wCrossRefGoogle Scholar Baribault, B., Donkin, C., Little, D. R., Trueblood, J. S., Oravecz, Z., van Ravenzwaaij, D., \u2026 Vandekerckhove, J. (2018). Metastudies for robust tests of theory. Proceedings of the National Academy of Sciences of the United States of America, 115(11), 2607\u20132612.CrossRefGoogle ScholarPubMed Barron, B. (2003). When smart groups fail. Journal of the Learning Sciences, 12(3), 307\u2013359.CrossRefGoogle Scholar Becker, J., Brackbill, D., & Centola, D. (2017). Network dynamics of social influence in the wisdom of crowds. Proceedings of the National Academy of Sciences of the United States of America, 114(26), E5070\u2013E5076.Google ScholarPubMed Bell, S. T. (2007). Deep-level composition variables as predictors of team performance: A meta-analysis. The Journal of Applied Psychology, 92(3), 595\u2013615.CrossRefGoogle ScholarPubMed Benjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., \u2026 Camerer, C. (2018). Redefine statistical significance. Nature Human Behaviour, 2, 6\u201310. https://doi.org/10.1038/s41562-017-0189-zCrossRefGoogle ScholarPubMed Berkman, E. T., & Wilson, S. M. (2021). So useful as a good theory? The practicality crisis in (social) psychological theory. Perspectives on Psychological Science, 16(4), 864\u2013874. https://doi.org/10.1177/1745691620969650CrossRefGoogle ScholarPubMed Bertrand, M., & Mullainathan, S. (2004). Are Emily and Greg more employable than Lakisha and Jamal? A field experiment on labor market discrimination. The American Economic Review, 94(4), 991\u20131013.CrossRefGoogle Scholar Bourgin, D. D., Peterson, J. C., Reichman, D., Russell, S. J., & Griffiths, T. L. (2019). Cognitive model priors for predicting human decisions. In Chaudhuri, K. & Salakhutdinov, R. (Eds.), Proceedings of the 36th international conference on machine learning (Vol. 97, pp. 5133\u20135141). PMLR.Google Scholar Bowen, D. (n.d.). Hemlock. Retrieved April 22, 2022, from https://dsbowen.gitlab.io/hemlockGoogle Scholar Brewin, C. R. (2022). Impact on the legal system of the generalizability crisis in psychology. The Behavioral and Brain Sciences, 45, e7.CrossRefGoogle ScholarPubMed Breznau, N., Rinke, E. M., Wuttke, A., Nguyen, H. H. V., Adem, M., Adriaans, J., \u2026 \u017b\u00f3\u0142tak, T. (2022). Observing many researchers using the same data and hypothesis reveals a hidden universe of uncertainty. Proceedings of the National Academy of Sciences of the United States of America, 119(44), e2203150119.CrossRefGoogle ScholarPubMed Brunswik, E.. (1947). Systematic and representative design of psychological experiments. In Proceedings of the Berkeley symposium on mathematical statistics and probability (pp. 143\u2013202). University of California Press.Google Scholar Brunswik, E. (1955). Representative design and probabilistic theory in a functional psychology. Psychological Review, 62(3), 193\u2013217.CrossRefGoogle Scholar Burger, B., Maffettone, P. M., Gusev, V. V., Aitchison, C. M., Bai, Y., Wang, X., \u2026 Cooper, A. I. (2020). A mobile robotic chemist. Nature, 583(7815), 237\u2013241.CrossRefGoogle ScholarPubMed Byers-Heinlein, K., Bergmann, C., Davies, C., Frank, M. C., Kiley Hamlin, J., Kline, M., \u2026 Soderstrom, M. (2020). Building a collaborative psychological science: Lessons learned from ManyBabies 1. Canadian Psychology/Psychologie Canadienne, 61(4), 349\u2013363. https://doi.org/10.1037/cap0000216CrossRefGoogle ScholarPubMed Camerer, C. F., Dreber, A., Holzmeister, F., Ho, T.-H., Huber, J., Johannesson, M., \u2026 Wu, H. (2018). Evaluating the replicability of social science experiments in nature and science between 2010 and 2015. Nature Human Behaviour, 2(9), 637\u2013644.CrossRefGoogle Scholar Carter, E. C., Sch\u00f6nbrodt, F. D., Gervais, W. M., & Hilgard, J. (2019). Correcting for bias in psychology: A comparison of meta-analytic methods. Advances in Methods and Practices in Psychological Science, 2(2), 115\u2013144.CrossRefGoogle Scholar Cesario, J. (2014). Priming, replication, and the hardest science. Perspectives on Psychological Science, 9(1), 40\u201348. https://doi.org/10.1177/1745691613513470CrossRefGoogle ScholarPubMed Cesario, J. (2022). What can experimental studies of bias tell us about real-world group disparities?. Behavioral and Brain Sciences, 45, E66. https://doi.org/10.1017/S0140525X21000017CrossRefGoogle Scholar Chandler, J., Mueller, P., & Paolacci, G. (2014). Nonna\u00efvet\u00e9 among Amazon Mechanical Turk workers: Consequences and solutions for behavioral researchers. Behavior Research Methods, 46(1), 112\u2013130.CrossRefGoogle ScholarPubMed Cohen, J. (1994). The earth is round (p<.05). The American Psychologist, 49(12), 997.CrossRefGoogle Scholar Cooper, H., Hedges, L. V., & Valentine, J. C. (Eds.) (2019). The handbook of research synthesis and meta-analysis. Russell Sage Foundation.CrossRefGoogle Scholar Cronbach, L. J., & Meehl, P. E. (1955). Construct validity in psychological tests. Psychological Bulletin, 52(4), 281\u2013302.CrossRefGoogle ScholarPubMed Debrouwere, S., & Rosseel, Y. (2022). The conceptual, cunning and conclusive experiment in psychology. Perspectives on Psychological Science, 17(3), 852\u2013862. https://doi.org/10.1177/17456916211026947CrossRefGoogle ScholarPubMed DeKay, M. L., Rubinchik, N., Li, Z., & De Boeck, P. (2022). Accelerating psychological science with metastudies: A demonstration using the risky-choice framing effect. Perspectives on Psychological Science, 17(6), 1704\u20131736. https://doi.org/10.1177/17456916221079611CrossRefGoogle ScholarPubMed de Leeuw, J. R. (2015). JsPsych: A JavaScript library for creating behavioral experiments in a web browser. Behavior Research Methods, 47(1), 1\u201312.CrossRefGoogle Scholar de Leeuw, J. R., Motz, B. A., Fyfe, E. R., Carvalho, P. F., & Goldstone, R. L. (2022). Generalizability, transferability, and the practice-to-practice gap [Review of Generalizability, transferability, and the practice-to-practice gap]. The Behavioral and Brain Sciences, 45, e11.CrossRefGoogle ScholarPubMed Devine, D. J., Clayton, L. D., Dunford, B. B., Seying, R., & Pryce, J. (2001). Jury decision making: 45 years of empirical research on deliberating groups. Psychology, Public Policy, and Law, 7(3), 622\u2013727.CrossRefGoogle Scholar Devine, D. J., & Philips, J. L. (2001). Do smarter teams o better: A meta-analysis of cognitive ability and team performance. Small Group Research, 32(5), 507\u2013532.CrossRefGoogle Scholar Dienes, Z. (2008). Understanding psychology as a science: An introduction to scientific and statistical inference. Macmillan.Google Scholar Dubova, M., Moskvichev, A., & Zollman, K. (2022). Against theory-motivated experimentation in science. MetaArXiv. June 24. https://doi.org/10.31222/osf.io/ysv2uGoogle Scholar Ebersole, C. R., Atherton, O. E., Belanger, A. L., Skulborstad, H. M., Allen, J. M., Banks, J. B., \u2026 Nosek, B. A. (2016). Many Labs 3: Evaluating participant pool quality across the academic semester via replication. Journal of Experimental Social Psychology, 67, 68\u201382.CrossRefGoogle Scholar Ellemers, N., & Rink, F. (2016). Diversity in work groups. Current Opinion in Psychology, 11, 49\u201353.CrossRefGoogle Scholar Engel, D., Woolley, A. W., Jing, L. X., Chabris, C. F., & Malone, T. W. (2014). Reading the mind in the eyes or reading between the lines? Theory of mind predicts collective intelligence equally well online and face-to-face. PLoS ONE, 9(12), e115212.CrossRefGoogle ScholarPubMed Erev, I., Ert, E., Plonsky, O., Cohen, D., & Cohen, O. (2017). From anomalies to forecasts: Toward a descriptive model of decisions under risk, under ambiguity, and from experience. Psychological Review, 124(4), 369\u2013409.CrossRefGoogle Scholar Eyke, N. S., Green, W. H., & Jensen, K. F. (2020). Iterative experimental design based on active machine learning reduces the experimental burden associated with reaction screening. Reaction Chemistry & Engineering, 5(10), 1963\u20131972.CrossRefGoogle Scholar Eyke, N. S., Koscher, B. A., & Jensen, K. F. (2021). Toward machine learning-enhanced high-throughput experimentation. Trends in Chemistry, 3(2), 120\u2013132.CrossRefGoogle Scholar Fehr, E., & Gachter, S. (2000). Cooperation and punishment in public goods experiments. The American Economic Review, 90(4), 980\u2013994.CrossRefGoogle Scholar Freese, J., & Peterson, D. (2017). Replication in social science. Annual Review of Sociology, 43, 147\u2013165. https://doi.org/10.1146/annurev-soc-060116-053450CrossRefGoogle Scholar Fyfe, E. R., de Leeuw, J. R., Carvalho, P. F., Goldstone, R. L., Sherman, J., Admiraal, D., \u2026 Motz, B. A. (2021). ManyClasses 1: Assessing the generalizable effect of immediate feedback versus delayed feedback across many college classes. Advances in Methods and Practices in Psychological Science, 4(3), 25152459211027575.CrossRefGoogle Scholar Gale, D., & Shapley, L. S. (1962). College admissions and the stability of marriage. The American Mathematical Monthly, 69(1), 9\u201315.CrossRefGoogle Scholar Gelman, A. (2018). Don't characterize replications as successes or failures [Review of Don't characterize replications as successes or failures]. The Behavioral and Brain Sciences, 41, e128.CrossRefGoogle ScholarPubMed Gelman, A., & Carlin, J. (2017). Some natural solutions to the p-value communication problem \u2013 and why they won't work. Journal of the American Statistical Association, 112(519), 899\u2013901.CrossRefGoogle Scholar Gelman, A., & Loken, E. (2014). The statistical crisis in science data-dependent analysis \u2013 a \u201cgarden of forking paths\u201d \u2013 explains why many statistically significant comparisons don't hold up. American Scientist, 102(6), 460.CrossRefGoogle Scholar Geman, S., Bienenstock, E., & Doursat, R. (1992). Neural networks and the bias/variance dilemma. Neural Computation, 4(1), 1\u201358.CrossRefGoogle Scholar Gongora, A. E., Xu, B., Perry, W., Okoye, C., Riley, P., Reyes, K. G., \u2026 Brown, K. A. (2020). A Bayesian experimental autonomous researcher for mechanical design. Science Advances, 6(15), eaaz1708.CrossRefGoogle ScholarPubMed Goodman, J. K., Cryder, C. E., & Cheema, A. (2013). Data collection in a flat world: The strengths and weaknesses of Mechanical Turk samples: Data collection in a flat world. Journal of Behavioral Decision Making, 26(3), 213\u2013224.CrossRefGoogle Scholar Greenhill, S., Rana, S., Gupta, S., Vellanki, P., & Venkatesh, S. (2020). Bayesian optimization for adaptive experimental design: A review. IEEE Access, 8, 13937\u201313948.CrossRefGoogle Scholar Griffiths, T. L. (2015). Manifesto for a new (computational) cognitive revolution. Cognition, 135, 21\u201323.CrossRefGoogle ScholarPubMed Grubbs, J. B. (2022). The cost of crisis in clinical psychological science [Review of The cost of crisis in clinical psychological science]. The Behavioral and Brain Sciences, 45, e18.CrossRefGoogle ScholarPubMed Hackman, J. R. (1968). Effects of task characteristics on group products. Journal of Experimental Social Psychology, 4(2), 162\u2013187.CrossRefGoogle Scholar Harkins, S. G. (1987). Social loafing and social facilitation. Journal of Experimental Social Psychology, 23(1), 1\u201318.CrossRefGoogle Scholar Hartshorne, J. K., de Leeuw, J. R., Goodman, N. D., Jennings, M., & O'Donnell, T. J. (2019). A thousand studies for the price of one: Accelerating psychological science with Pushkin. Behavior Research Methods, 51(4), 1782\u20131803. https://doi.org/10.3758/s13428-018-1155-zCrossRefGoogle Scholar Henrich, J., Heine, S., & Norenzayan, A. (2010). The weirdest people in the world?. Behavioral and Brain Sciences, 33(2-3), 61\u201383. https://doi.org/10.1017/S0140525X0999152XCrossRefGoogle ScholarPubMed Higgins, J. P. T., Thompson, S. G., Deeks, J. J., & Altman, D. G. (2003). Measuring inconsistency in meta-analyses. BMJ, 327(7414), 557\u2013560.CrossRefGoogle ScholarPubMed Hill, G. W. (1982). Group versus individual performance: Are N + 1 heads better than one? Psychological Bulletin, 91(3), 517\u2013539.CrossRefGoogle Scholar Hofman, J. M., Sharma, A., & Watts, D. J. (2017). Prediction and explanation in social systems. Science (New York, N.Y.), 355(6324), 486\u2013488.CrossRefGoogle ScholarPubMed Hofman, J. M., Watts, D. J., Athey, S., Garip, F., Griffiths, T. L., Kleinberg, J., \u2026 Yarkoni, T. (2021). Integrating explanation and prediction in computational social science. Nature, 595(7866), 181\u2013188.CrossRefGoogle ScholarPubMed Hofstede, G. (2016). Culture's consequences: Comparing values, behaviors, institutions, and organizations across nations (2nd ed.). Collegiate Aviation Review, 34(2), 108\u2013109. Retrieved from https://www.proquest.com/scholarly-journals/cultures-consequences-comparing-values-behaviors/docview/1841323332/se-2Google Scholar Hong, L., & Page, S. E. (2004). Groups of diverse problem solvers can outperform groups of high-ability problem solvers. Proceedings of the National Academy of Sciences of the United States of America, 101(46), 16385\u201316389.CrossRefGoogle ScholarPubMed Horton, J. J., Rand, D. G., & Zeckhauser, R. J. (2011). The online laboratory: Conducting experiments in a real labor market. Experimental Economics, 14(3), 399\u2013425.CrossRefGoogle Scholar Husband, R. W. (1940). Cooperative versus solitary problem solution. The Journal of Social Psychology, 11(2), 405\u2013409.CrossRefGoogle Scholar Inglehart, R., & Welzel, C. (2005). Modernization, cultural change, and democracy: The human development sequence. Cambridge University Press.Google Scholar Ioannidis, J. P. A. (2005). Why most published research findings are false. PLoS Medicine, 2(8), e124.CrossRefGoogle ScholarPubMed Janis, I. L. (1972). Victims of groupthink: A psychological study of foreign-policy decisions and fiascoes (p. 277). Houghton Mifflin Company. https://psycnet.apa.org/fulltext/1975-29417-000.pdfGoogle Scholar Jones, B. C., DeBruine, L. M., Flake, J. K., Liuzza, M. T., Antfolk, J., Arinze, N. C., \u2026 Coles, N. A. (2021). To which world regions does the valence-dominance model of social perception apply? Nature Human Behaviour, 5(1), 159\u2013169.CrossRefGoogle ScholarPubMed Jumper, J., Evans, R., Pritzel, A., Green, T., Figurnov, M., Ronneberger, O., \u2026 Hassabis, D. (2021). Highly accurate protein structure prediction with AlphaFold. Nature, 596(7873), 583\u2013589.CrossRefGoogle ScholarPubMed Kahneman, D., & Tversky, A. (1979). Prospect theory: An analysis of decision under risk. Econometrica: Journal of the Econometric Society, 47(2), 263\u2013291.CrossRefGoogle Scholar Karau, S. J., & Williams, K. D. (1993). Social loafing: A meta-analytic review and theoretical integration. Journal of Personality and Social Psychology, 65(4), 681\u2013706.CrossRefGoogle Scholar Kim, Y. J., Engel, D., Woolley, A. W., Lin, J. Y.-T., McArthur, N., & Malone, T. W. (2017). What makes a strong team?: Using collective intelligence to predict team performance in league of legends. Proceedings of the 2017 ACM conference on computer supported cooperative work and social computing \u2013 CSCW \u201917 (pp. 2316\u20132329). New York, NY, USA.CrossRefGoogle Scholar Klein, R. A., Ratliff, K. A., Vianello, M., Adams, R. B., Bahn\u00edk, \u0160., Bernstein, M. J., \u2026 Nosek, B. A. (2014). Investigating variation in replicability. Social Psychology, 45(3), 142\u2013152.CrossRefGoogle Scholar Klein, R. A., Vianello, M., Hasselman, F., Adams, B. G., Adams, R. B., Alper, S., \u2026 Nosek, B. A. (2018). Many Labs 2: Investigating variation in replicability across samples and settings. Advances in Methods and Practices in Psychological Science, 1(4), 443\u2013490.CrossRefGoogle Scholar Knudde, N., van der Herten, J., Dhaene, T., & Couckuyt, I. (2017). GPflowOpt: A Bayesian optimization library using TensorFlow. arXiv [stat.ML]. arXiv. http://arxiv.org/abs/1711.03845Google Scholar Koyr\u00e9, A. (1953). An experiment in measurement. Proceedings of the American Philosophical Society, 97(2), 222\u2013237.Google Scholar Lakens, D., Uygun Tun\u00e7, D., & Necip Tun\u00e7, M. (2022). There is no generalizability crisis [Review of There is no generalizability crisis]. The Behavioral and Brain Sciences, 45, e25.CrossRefGoogle ScholarPubMed Landy, J. F., Jia, M. L., Ding, I. L., Viganola, D., Tierney, W., Dreber, A., \u2026 Uhlmann, E. L. (2020). Crowdsourcing hypothesis tests: Making transparent how design choices shape research results. Psychological Bulletin, 146(5), 451\u2013479.CrossRefGoogle ScholarPubMed Larson, J. R. (2013). In search of synergy in small group performance. Psychology Press.CrossRefGoogle Scholar Larson, S. D., & Martone, M. E. (2009). Ontologies for neuroscience: What are they and what are they good for? Frontiers in Neuroscience, 3(1), 60\u201367. https://doi.org/10.3389/neuro.01.007.2009CrossRefGoogle ScholarPubMed Laughlin, P. R., Bonner, B. L., & Miner, A. G. (2002). Groups perform better than the best individuals on letters-to-numbers problems. Organizational Behavior and Human Decision Processes, 88(2), 605\u2013620.CrossRefGoogle Scholar Lei, B., Kirk, T. Q., Bhattacharya, A., Pati, D., Qian, X., Arroyave, R., & Mallick, B. K. (2021). Bayesian optimization with adaptive surrogate models for automated experimental design. NPJ Computational Materials, 7(1), 1\u201312.CrossRefGoogle Scholar LePine, J. A. (2003). Team adaptation and postchange performance: Effects of team composition in terms of members\u2019 cognitive ability and personality. The Journal of Applied Psychology, 88(1), 27\u201339.CrossRefGoogle ScholarPubMed Letham, B., Karrer, B., Ottoni, G., & Bakshy, E. (2019). Constrained Bayesian optimization with noisy experiments. Bayesian Analysis, 14(2), 495\u2013519. https://doi.org/10.1214/18-ba1110CrossRefGoogle Scholar Levinthal, D. A., & Rosenkopf, L. (2021). Commensurability and collective impact in strategic management research: When non-replicability is a feature, not a bug. Working-paper (unpublished preprint). https://mackinstitute.wharton.upenn.edu/2020/commensurability-and-collective-impact-in-strategic-management-research/Google Scholar Levitt, S. D., & List, J. A. (2007). What do laboratory experiments measuring social preferences reveal about the real world? The Journal of Economic Perspectives: A Journal of the American Economic Association, 21(2), 153\u2013174.CrossRefGoogle Scholar Li, W., Germine, L. T., Mehr, S. A., Srinivasan, M., & Hartshorne, J. (2022). Developmental psychologists should adopt citizen science to improve generalization and reproducibility. Infant and Child Development, e2348. https://doi.org/10.1002/icd.2348CrossRefGoogle Scholar Litman, L., Robinson, J., & Abberbock, T. (2017). TurkPrime.com: A versatile crowdsourcing data acquisition platform for the behavioral sciences. Behavior Research Methods, 49(2), 433\u2013442.CrossRefGoogle ScholarPubMed MacWhinney, B. (2014). The childes project: Tools for analyzing talk, volume II: The database (3rd ed.). Psychology Press. https://doi.org/10.4324/9781315805641CrossRefGoogle Scholar Maier, M., Barto\u0161, F., Stanley, T. D., Shanks, D. R., Harris, A. J. L., & Wagenmakers, E.-J. (2022). No evidence for nudging after adjusting for publication bias. Proceedings of the National Academy of Sciences of the United States of America, 119(31), e2200300119.CrossRefGoogle ScholarPubMed ManyBabies Consortium. (2020). Quantifying sources of variability in infancy research using the infant-directed-speech preference. Advances in Methods and Practices in Psychological Science, 3(1), 24\u201352.CrossRefGoogle Scholar Manzi, J. (2012). Uncontrolled: The surprising payoff of trial-and-error for business, politics, and society (pp. 1\u2013320). Basic Books.Google Scholar Mao, A., Mason, W., Suri, S., & Watts, D. J. (2016). An experimental study of team size and performance on a complex task. PLoS ONE, 11(4), e0153048.CrossRefGoogle ScholarPubMed Martin, T., Hofman, J. M., Sharma, A., Anderson, A., & Watts, D. J. (2016). Exploring limits to prediction in complex social systems. In Proceedings of the 25th international conference on world wide web no. 978-1-4503-4143-1 (pp. 683\u2013694). Republic and Canton of Geneva, CHE. International World Wide Web Conferences Steering Committee.CrossRefGoogle Scholar Mason, W., & Suri, S. (2012). Conducting behavioral research on Amazon's Mechanical Turk. Behavior Research Methods, 44(1), 1\u201323.CrossRefGoogle ScholarPubMed Mason, W., & Watts, D. J. (2012). Collaborative learning in networks. Proceedings of the National Academy of Sciences of the United States of America, 109(3), 764\u2013769.CrossRefGoogle ScholarPubMed McClelland, G. H. (1997). Optimal design in psychological research. Psychological Methods, 2(1), 3\u201319.CrossRefGoogle Scholar McGrath, J. E. (1984). Groups: Interaction and performance. Prentice Hall.Google Scholar Meehl, P. E. (1967). Theory-testing in psychology and physics: A methodological paradox. Philosophy of Science, 34(2), 103\u2013115.CrossRefGoogle Scholar Meehl, P. E. (1990a). Why summaries of research on psychological theories are often uninterpretable. Psychological Reports, 66(1), 195\u2013244.CrossRefGoogle Scholar Meehl, P. E. (1990b). Appraising and amending theories: The strategy of Lakatosian defense and two principles that warrant it. Psychological Inquiry, 1(2), 108\u2013141.CrossRefGoogle Scholar Mertens, S., Herberz, M., Hahnel, U. J. J., & Brosch, T. (2022). The effectiveness of nudging: A meta-analysis of choice architecture interventions across behavioral domains. Proceedings of the National Academy of Sciences of the United States of America, 119(1). https://doi.org/10.1073/pnas.2107346118Google ScholarPubMed Merton, R. K. (1968). On sociological theories of the middle range. Social Theory and Social Structure, 39\u201372.Google Scholar Milkman, K. L., Gandhi, L., Patel, M. S., Graci, H. N., Gromet, D. M., Ho, H., \u2026 Duckworth, A. L. (2022). A 680,000-person megastudy of nudges to encourage vaccination in pharmacies. Proceedings of the National Academy of Sciences of the United States of America, 119(6). https://doi.org/10.1073/pnas.2115126119Google ScholarPubMed Milkman, K. L., Patel, M. S., Gandhi, L., Graci, H. N., Gromet, D. M., Ho, H., \u2026 Duckworth, A. L. (2021). A megastudy of text-based nudges encouraging patients to get vaccinated at an upcoming doctor's appointment. Proceedings of the National Academy of Sciences of the United States of America, 118(20), e2101165118.CrossRefGoogle ScholarPubMed Mook, D. G. (1983). In defense of external invalidity. The American Psychologist, 38(4), 379\u2013387.CrossRefGoogle Scholar Moshontz, H., Campbell, L., Ebersole, C. R., IJzerman, H., Urry, H. L., Forscher, P. S., \u2026 Chartier, C. R. (2018). The psychological science accelerator: Advancing psychology through a distributed collaborative network. Advances in Methods and Practices in Psychological Science, 1(4), 501\u2013515.CrossRefGoogle ScholarPubMed Munaf\u00f2, M. R., Nosek, B. A., Bishop, D. V. M., Button, K. S., Chambers, C. D., du Sert, N. P., \u2026 Ioannidis, J. P. A. (2017). A manifesto for reproducible science. Nature Human Behaviour, 1, 21.CrossRefGoogle ScholarPubMed Muthukrishna, M., Bell, A. V., Henrich, J., Curtin, C. M., Gedranovich, A., McInerney, J., & Thue, B. (2020). Beyond western, educated, industrial, rich, and democratic (WEIRD) psychology: Measuring and mapping scales of cultural and psychological distance. Psychological Science, 31(6), 678\u2013701.CrossRefGoogle ScholarPubMed Muthukrishna, M., & Henrich, J. A. (2019). A problem in theory. Nature Human Behaviour, 3, 221\u2013229. https://doi.org/10.1038/s41562-018-0522-1CrossRefGoogle ScholarPubMed Myerson, R. B. (1981). Optimal auction design. Mathematics of Operations Research, 6(1), 58\u201373.CrossRefGoogle Scholar National Information Standards Organization. (2022). ANSI/NISO Z39. 104-2022, CRediT, contributor roles taxonomy. [S. L.]. National Information Standards Organization. https://www.niso.org/publications/z39104-2022-creditGoogle Scholar National Science Foundation. (2022). NSF budget requests to congress and annual appropriations. National Science Foundation. https://www.nsf.gov/about/budget/Google Scholar Nemesure, M. D., Heinz, M. V., Huang, R., & Jacobson, N. C. (2021). Predictive modeling of depression and anxiety using electronic health records and a novel machine learning approach with artificial intelligence. Scientific Reports, 11(1), 1980.CrossRefGoogle Scholar Newell, A. (1973). You can't play 20 questions with nature and win: Projective comments on the papers of this symposium. http://shelf2.library.cmu.edu/Tech/240474311.pdfGoogle Scholar Open Science Collaboration. (2015). PSYCHOLOGY. Estimating the reproducibility of psychological science. Science (New York, N.Y.), 349(6251), aac4716.CrossRefGoogle Scholar Page, S. E. (2008). The difference: How the power of diversity creates better groups, firms, schools, and societies \u2013 New edition. Princeton University Press.CrossRefGoogle Scholar Palan, S., & Schitter, C. (2018). Prolific.ac \u2013 A subject pool for online experiments. Journal of Behavioral and Experimental Finance, 17, 22\u201327.CrossRefGoogle Scholar Peterson, J. C., Bourgin, D. D., Agrawal, M., Reichman, D., & Griffiths, T. L. (2021). Using large-scale experiments and machine learning to discover theories of human decision-making. Science (New York, N.Y.), 372(6547), 1209\u20131214.CrossRefGoogle ScholarPubMed Plonsky, O., Apel, R., Ert, E., Tennenholtz, M., Bourgin, D., Peterson, J. C., \u2026 Erev, I. (2019). Predicting human decisions with behavioral theories and machine learning. arXiv [cs.AI]. arXiv. http://arxiv.org/abs/1904.06866Google Scholar Preckel, F., & Brunner, M. (2017). Nomological nets. Encyclopedia of Personality and Individual Differences, 1\u20134. https://doi.org/10.1007/978-3-319-28099-8_1334-1CrossRefGoogle Scholar Ren, P., Xiao, Y., Chang, X., Huang, P.-Y., Li, Z., Gupta, B. B., \u2026 Wang, X. (2021). A survey of deep active learning. ACM Computing Surveys, 54(9), 1\u201340.Google Scholar Reuss, H., Kiesel, A., & Kunde, W. (2015). Adjustments of response speed and accuracy to unconscious cues. Cognition, 134, 57\u201362.CrossRefGoogle ScholarPubMed Richard Hackman, J., & Morris, C. G. (1975). Group tasks, group interaction process, and group performance effectiveness: A review and proposed integration. In Berkowitz, L. (Ed.), Advances in Experimental Social Psychology (Vol. 8, pp. 45\u201399). Academic Press. https://doi.org/10.1016/s0065-2601(08)60248-8Google Scholar Rosenthal, R. (1979). The file drawer problem and tolerance for null results. Psychological Bulletin, 86(3), 638\u2013641.CrossRefGoogle Scholar Rubin, D. L., Lewis, S. E., Mungall, C. J., Misra, S., Westerfield, M., Ashburner, M., \u2026 Musen, M. A. (2006). National center for biomedical ontology: Advancing biomedicine through structured organization of scientific knowledge. OMICS: A Journal of Integrative Biology, 10(2), 185\u2013198. https://doi.org/10.1089/omi.2006.10.185CrossRefGoogle ScholarPubMed Schneid, M., Isidor, R., Li, C., & Kabst, R. (2015). The influence of cultural context on the relationship between gender diversity and team performance: A meta-analysis. The International Journal of Human Resource Management, 26(6), 733\u2013756.CrossRefGoogle Scholar Schulz-Hardt, S., & Mojzisch, A. (2012). How to achieve synergy in group decision making: Lessons to be learned from the hidden profile paradigm. European Review of Social Psychology, 23(1), 305\u2013343.CrossRefGoogle Scholar Schwartz, S. (2006). A theory of cultural value orientations: Explication and applications. Comparative Sociology, 5(2\u20133), 137\u2013182.CrossRefGoogle Scholar Settles, B. (2011). From theories to queries: Active learning in practice. In Guyon, I., Cawley, G., Dror, G., Lemaire, V., & Statnikov, A. (Eds.), Active learning and experimental design workshop in conjunction with AISTATS 2010 (Vol. 16, pp. 1\u201318). PMLR.Google Scholar Shallue, C. J., & Vanderburg, A. (2018). Identifying exoplanets with deep learning: A five-planet resonant chain around Kepler-80 and an eighth planet around Kepler-90. AJS; American Journal of Sociology, 155(2), 94.Google Scholar Shaw, M. E. (1963). Scaling group tasks: A method for dimensional analysis. https://apps.dtic.mil/sti/pdfs/AD0415033.pdfGoogle Scholar Shields, B. J., Stevens, J., Li, J., Parasram, M., Damani, F., Alvarado, J. I. M., \u2026 Doyle, A. G. (2021). Bayesian reaction optimization as a tool for chemical synthesis. Nature, 590(7844), 89\u201396.CrossRefGoogle ScholarPubMed Simmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological Science, 22(11), 1359\u20131366.CrossRefGoogle ScholarPubMed Simons, D. J., Shoda, Y., & Lindsay, D. S. (2017). Constraints on generality (COG): A proposed addition to all empirical papers. Perspectives on Psychological Science: A Journal of the Association for Psychological Science, 12(6), 1123\u20131128.CrossRefGoogle ScholarPubMed Simonsohn, U., Simmons, J., & Nelson, L. D. (2022). Above averaging in literature reviews. Nature Reviews Psychology, 1(10), 551\u2013552.CrossRefGoogle Scholar Smucker, B., Krzywinski, M., & Altman, N. (2018). Optimal experimental design. Nature Methods, 15(8), 559\u2013560.CrossRefGoogle ScholarPubMed Snoek, J., Larochelle, H., & Adams, R. P. (2012). Practical Bayesian optimization of machine learning algorithms. arXiv [stat.ML]. arXiv. http://arxiv.org/abs/1206.2944Google Scholar Steiner, I. D. (1972). Group process and productivity. Academic Press.Google Scholar Stewart, G. L. (2006). A meta-analytic review of relationships between team design features and team performance. Journal of Management, 32(1), 29\u201355.CrossRefGoogle Scholar Stokes, D. E. (1997). Pasteur's quadrant: Basic science and technological innovation. Brookings Institution Press.Google Scholar Szaszi, B., Higney, A., Charlton, A., Gelman, A., Ziano, I., Aczel, B., \u2026 Tipton, E. (2022). No reason to expect large and consistent effects of nudge interventions [Review of No reason to expect large and consistent effects of nudge interventions]. Proceedings of the National Academy of Sciences of the United States of America, 119(31), e2200732119.CrossRefGoogle ScholarPubMed Tasca, G. A. (2021). Team cognition and reflective functioning: A review and search for synergy. Group Dynamics: Theory, Research, and Practice, 25(3), 258\u2013270.CrossRefGoogle Scholar Thompson, W. R. (1933). On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. Biometrika, 25(3\u20134), 285\u2013294.CrossRefGoogle Scholar Turner, J. A., & Laird, A. R. (2012). The cognitive paradigm ontology: Design and application. Neuroinformatics, 10(1), 57\u201366.CrossRefGoogle ScholarPubMed Turner, M. A., & Smaldino, P. E. (2022). Mechanistic modeling for the masses [Review of Mechanistic modeling for the masses]. The Behavioral and Brain Sciences, 45, e33.CrossRefGoogle ScholarPubMed Uhlmann, E. L., Ebersole, C. R., Chartier, C. R., Errington, T. M., Kidwell, M. C., Lai, C. K., \u2026 Nosek, B. A. (2019). Scientific utopia III: Crowdsourcing science. Perspectives on Psychological Science: A Journal of the Association for Psychological Science, 14(5), 711\u2013733.CrossRefGoogle ScholarPubMed Van Bavel, J. J., Mende-Siedlecki, P., Brady, W. J., & Reinero, D. A. (2016). Contextual sensitivity in scientific reproducibility. Proceedings of the National Academy of Sciences of the United States of America, 113(23), 6454\u20136459.CrossRefGoogle ScholarPubMed Vickrey, W. (1961). Counterspeculation, auctions, and competitive sealed tenders. The Journal of Finance, 16(1), 8\u201337.CrossRefGoogle Scholar Voelkel, J. G., Stagnaro, M. N., Chu, J., Pink, S. L., Mernyk, J. S., Redekopp, C., \u2026 Willer, R. (2022). Megastudy identifying successful interventions to strengthen Americans\u2019 democratic attitudes. Preprint. https://doi.org/10.31219/osf.io/y79u5CrossRefGoogle Scholar Wager, S., & Athey, S. (2018). Estimation and inference of heterogeneous treatment effects using random forests. Journal of the American Statistical Association, 113(523), 1228\u20131242.CrossRefGoogle Scholar Watson, G. B. (1928). Do groups think more efficiently than individuals? Journal of Abnormal and Social Psychology, 23(3), 328.CrossRefGoogle Scholar Watts, D. (2017). Response to Turco and Zuckerman's \u201cVerstehen for sociology.\u201d The American Journal of Sociology, 122(4), 1292\u20131299.CrossRefGoogle Scholar Watts, D. J. (2011). Everything is obvious*: Once you know the answer. Crown Business.Google Scholar Watts, D. J. (2014). Common sense and sociological explanations. The American Journal of Sociology, 120(2), 313\u2013351.CrossRefGoogle ScholarPubMed Watts, D. J. (2017). Should social science be more solution-oriented? Nature Human Behaviour, 1, 15.CrossRefGoogle Scholar Watts, D. J., Beck, E. D., Bienenstock, E. J., Bowers, J., Frank, A., Grubesic, A., \u2026 Salganik, M. (2018). Explanation, prediction, and causality: Three sides of the same coin? https://doi.org/10.31219/osf.io/u6vz5CrossRefGoogle Scholar Wiernik, B. M., Raghavan, M., Allan, T., & Denison, A. J. (2022). Generalizability challenges in applied psychological and organizational research and practice [Review of Generalizability challenges in applied psychological and organizational research and practice]. The Behavioral and Brain Sciences, 45, e38.CrossRefGoogle ScholarPubMed Witkop, G. (n.d.). Systematizing confidence in open research and evidence (SCORE). DARPA. Retrieved June 22, 2022, from https://www.darpa.mil/program/systematizing-confidence-in-open-research-and-evidenceGoogle Scholar Wood, R. E. (1986). Task complexity: Definition of the construct. Organizational Behavior and Human Decision Processes, 37(1), 60\u201382.CrossRefGoogle Scholar Woolley, A. W., Chabris, C. F., Pentland, A., Hashmi, N., & Malone, T. W. (2010). Evidence for a collective intelligence factor in the performance of human groups. Science (New York, N.Y.), 330(6004), 686\u2013688.CrossRefGoogle ScholarPubMed Wurman, P. R., Wellman, M. P., & Walsh, W. E. (2001). A parametrization of the auction design space. Games and Economic Behavior, 35(1), 304\u2013338.CrossRefGoogle Scholar Yarkoni, T. (2022). The generalizability crisis. Behavioral and Brain Sciences, 45, E1. https://doi.org/10.1017/S0140525X20001685CrossRefGoogle Scholar Yarkoni, T., Eckles, D., Heathers, J., Levenstein, M., Smaldino, P. E., & Lane, J. I. (2019). Enhancing and accelerating social science via automation: Challenges and opportunities. https://doi.org/10.31235/osf.io/vncweCrossRefGoogle Scholar Yarkoni, T., & Westfall, J. (2017). Choosing prediction over explanation in psychology: Lessons from machine learning. Perspectives on Psychological Science: A Journal of the Association for Psychological Science, 12(6), 1100\u20131122.CrossRefGoogle ScholarPubMed Zelditch, M. Jr. (1969). Can you really study an army in the laboratory. A Sociological Reader on Complex Organizations, 528\u2013539.Google Scholar You have Access 13 Cited by Linked content Related commentaries (31) Author response Related content AI-generated results: by UNSILO [Opens in a new window] Automated Exploration of Design Solution Space Applying the Generative Design Approach Type Article Title Automated Exploration of Design Solution Space Applying the Generative Design Approach Authors Haibing Li  and Roland Lachmayer   Journal Proceedings of the Design Society: International Conference on Engineering Design Published online: 26 July 2019 Design space optimisation of an unmanned aerial vehicle submerged inlet through the formulation of a data-fusion-based hybrid model Type Article Title Design space optimisation of an unmanned aerial vehicle submerged inlet through the formulation of a data-fusion-based hybrid model Authors F. Akram , H. A. Khan , T. A. Shams  and D. Mavris   Journal The Aeronautical Journal Published online: 12 May 2021 A study of argumentation-based negotiation in collaborative design Type Article Title A study of argumentation-based negotiation in collaborative design Authors Yan Jin  and Mathieu Geslin   Journal AI EDAM Published online: 29 January 2010 Set-based design: a review and new directions Type Article Title Set-based design: a review and new directions Authors Boris Toche , Robert Pellerin  and Clement Fortin   Journal Design Science Published online: 3 July 2020 Exploring the Application of Network Analytics in Characterizing a Conceptual Design Space Type Article Title Exploring the Application of Network Analytics in Characterizing a Conceptual Design Space Authors Joshua T. Gyory , Kosa Goucher-Lambert , Kenneth Kotovsky  and Jonathan Cagan   Journal Proceedings of the Design Society: International Conference on Engineering Design Published online: 26 July 2019 Toward a visual approach in the exploration of shape grammars Type Article Title Toward a visual approach in the exploration of shape grammars Authors Journal AI EDAM Published online: 7 October 2015 Robust design using multiobjective optimisation and artificial neural networks with application to a heat pump radial compressor Type Article Title Robust design using multiobjective optimisation and artificial neural networks with application to a heat pump radial compressor Authors Soheyl Massoudi , Cyril Picard  and J\u00fcrg Schiffmann   Journal Design Science Published online: 6 January 2022 Advantages of surrogate models for architectural design optimization Type Article Title Advantages of surrogate models for architectural design optimization Authors Journal AI EDAM Published online: 7 October 2015 Enhanced function-means modeling supporting design space exploration Type Article Title Enhanced function-means modeling supporting design space exploration Authors Pradipta Biswas , Pilar Orero , Metin Sezgin , Jakob R. M\u00fcller , Ola Isaksson , Jonas Landahl , Visakha Raja , Massimo Panarotto , Christoffer Levandowski  and Dag Raudberget   Journal AI EDAM Published online: 11 October 2019 Evolutionary theory and the social sciences Type Article Title Evolutionary theory and the social sciences Authors Robert L. Burgess  and Peter C. M. Molenaar   Journal Behavioral and Brain Sciences Published online: 27 April 2007 Librarians Authors Publishing partners Agents Corporates Accessibility Our blog News Contact and help Cambridge Core legal notices Feedback Sitemap Select your country preference Afghanistan Aland Islands Albania Algeria American Samoa Andorra Angola Anguilla Antarctica Antigua and Barbuda Argentina Armenia Aruba Australia Austria Azerbaijan Bahamas Bahrain Bangladesh Barbados Belarus Belgium Belize Benin Bermuda Bhutan Bolivia Bosnia and Herzegovina Botswana Bouvet Island Brazil British Indian Ocean Territory Brunei Darussalam Bulgaria Burkina Faso Burundi Cambodia Cameroon Canada Cape Verde Cayman Islands Central African Republic Chad Channel Islands, Isle of Man Chile China Christmas Island Cocos (Keeling) Islands Colombia Comoros Congo Congo, The Democratic Republic of the Cook Islands Costa Rica Cote D'Ivoire Croatia Cuba Cyprus Czech Republic Denmark Djibouti Dominica Dominican Republic East Timor Ecuador Egypt El Salvador Equatorial Guinea Eritrea Estonia Ethiopia Falkland Islands (Malvinas) Faroe Islands Fiji Finland France French Guiana French Polynesia French Southern Territories Gabon Gambia Georgia Germany Ghana Gibraltar Greece Greenland Grenada Guadeloupe Guam Guatemala Guernsey Guinea Guinea-bissau Guyana Haiti Heard and Mc Donald Islands Honduras Hong Kong Hungary Iceland India Indonesia Iran, Islamic Republic of Iraq Ireland Israel Italy Jamaica Japan Jersey Jordan Kazakhstan Kenya Kiribati Korea, Democratic People's Republic of Korea, Republic of Kuwait Kyrgyzstan Lao People's Democratic Republic Latvia Lebanon Lesotho Liberia Libyan Arab Jamahiriya Liechtenstein Lithuania Luxembourg Macau Macedonia Madagascar Malawi Malaysia Maldives Mali Malta Marshall Islands Martinique Mauritania Mauritius Mayotte Mexico Micronesia, Federated States of Moldova, Republic of Monaco Mongolia Montenegro Montserrat Morocco Mozambique Myanmar Namibia Nauru Nepal Netherlands Netherlands Antilles New Caledonia New Zealand Nicaragua Niger Nigeria Niue Norfolk Island Northern Mariana Islands Norway Oman Pakistan Palau Palestinian Territory, Occupied Panama Papua New Guinea Paraguay Peru Philippines Pitcairn Poland Portugal Puerto Rico Qatar Reunion Romania Russian Federation Rwanda Saint Kitts and Nevis Saint Lucia Saint Vincent and the Grenadines Samoa San Marino Sao Tome and Principe Saudi Arabia Senegal Serbia Seychelles Sierra Leone Singapore Slovakia Slovenia Solomon Islands Somalia South Africa South Georgia and the South Sandwich Islands Spain Sri Lanka St. Helena St. Pierre and Miquelon Sudan Suriname Svalbard and Jan Mayen Islands Swaziland Sweden Switzerland Syrian Arab Republic Taiwan Tajikistan Tanzania, United Republic of Thailand Togo Tokelau Tonga Trinidad and Tobago Tunisia Turkey Turkmenistan Turks and Caicos Islands Tuvalu Uganda Ukraine United Arab Emirates United Kingdom United States United States Minor Outlying Islands United States Virgin Islands Uruguay Uzbekistan Vanuatu Vatican City Venezuela Vietnam Virgin Islands (British) Wallis and Futuna Islands Western Sahara Yemen Zambia Zimbabwe Join us online Rights & Permissions Copyright Privacy Notice Terms of use Cookies Policy \u00a9 Cambridge University Press 2024",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "RadioGalaxyNET: Dataset and novel computer vision algorithms for the detection of extended radio galaxies and infrared hosts",
    "doi": "10.1017/pasa.2023.64",
    "description": "Creating radio galaxy catalogues from next-generation deep surveys requires automated identification of associated components of extended sources and their corresponding infrared hosts. In this paper, we introduce RadioGalaxyNET, a multimodal dataset, and a suite of novel computer vision algorithms designed to automate the detection and localization of multi-component extended radio galaxies and their corresponding infrared hosts. The dataset comprises 4 155 instances of galaxies in 2 800 images with both radio and infrared channels. Each instance provides information about the extended radio galaxy class, its corresponding bounding box encompassing all components, the pixel-level segmentation mask, and the keypoint position of its corresponding infrared host galaxy. RadioGalaxyNET is the first dataset to include images from the highly sensitive Australian Square Kilometre Array Pathfinder (ASKAP) radio telescope, corresponding infrared images, and instance-level annotations for galaxy detection. We benchmark several object detection algorithms on the dataset and propose a novel multimodal approach to simultaneously detect radio galaxies and the positions of infrared hosts.",
    "journal": "Publications of the Astronomical Society of Australia",
    "authors": [
      "Gupta N.",
      "Hayder Z.",
      "Norris R.P.",
      "Huynh M.",
      "Petersson L."
    ],
    "citation_count": "0",
    "full_text": "Loading [MathJax]/jax/output/SVG/config.js Due to site maintenance, online purchases on Cambridge Core would be temporarily unavailable on Sunday 24th March from 08:00 until 18:00 GMT. Apologies for the inconvenience. We use cookies to distinguish you from other users and to provide you with a better experience on our websites. Close this message to accept cookies or find out how to manage your cookie settings. Discover Content Products and Services Home Home Browse subjects Publications Open research Services About Cambridge Core Access provided by Register Log in Cart ( 0 ) Home >Journals >Publications of the Astronomical Society of Australia >Volume 41 >RadioGalaxyNET: Dataset and novel computer vision algorithms... English Fran\u00e7ais Publications of the Astronomical Society of Australia Article contents Abstract Introduction RadioGalaxyNET: Dataset RadioGalaxyNET: Novel computer vision methods Training and evaluation Results Conclusions Data availability Footnotes References RadioGalaxyNET: Dataset and novel computer vision algorithms for the detection of extended radio galaxies and infrared hosts Published online by Cambridge University Press:  11 December 2023 Nikhel Gupta [Opens in a new window] , Zeeshan Hayder , Ray P. Norris [Opens in a new window] , Minh Huynh  and Lars Petersson Show author details Article Figures Metrics Save PDF Share Cite Rights & Permissions [Opens in a new window] Abstract Creating radio galaxy catalogues from next-generation deep surveys requires automated identification of associated components of extended sources and their corresponding infrared hosts. In this paper, we introduce RadioGalaxyNET, a multimodal dataset, and a suite of novel computer vision algorithms designed to automate the detection and localization of multi-component extended radio galaxies and their corresponding infrared hosts. The dataset comprises 4 155 instances of galaxies in 2 800 images with both radio and infrared channels. Each instance provides information about the extended radio galaxy class, its corresponding bounding box encompassing all components, the pixel-level segmentation mask, and the keypoint position of its corresponding infrared host galaxy. RadioGalaxyNET is the first dataset to include images from the highly sensitive Australian Square Kilometre Array Pathfinder (ASKAP) radio telescope, corresponding infrared images, and instance-level annotations for galaxy detection. We benchmark several object detection algorithms on the dataset and propose a novel multimodal approach to simultaneously detect radio galaxies and the positions of infrared hosts. Keywords Galaxies: active galaxies: peculiar radio continuum: galaxies Galaxy: evolution methods: data analysis Type Research Article Information Publications of the Astronomical Society of Australia , Volume 41 , 2024 , e001 DOI: https://doi.org/10.1017/pasa.2023.64 [Opens in a new window] NASA ADS Abstract Service [Opens in a new window] Creative Commons This is an Open Access article, distributed under the terms of the Creative Commons Attribution licence (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted re-use, distribution and reproduction, provided the original article is properly cited. Copyright \u00a9 The Author(s), 2023. Published by Cambridge University Press on behalf of the Astronomical Society of Australia 1. Introduction Recent advancements in radio astronomy have enabled us to scan large areas of the sky in a short timescale while generating incredibly sensitive continuum images of the Universe. This has created new possibilities for detecting millions of galaxies at radio wavelengths. For example, the ongoing Evolutionary Map of the Universe (EMU; Norris et al. Reference Norris 2021b) survey, conducted using the Australian Square Kilometre Array Pathfinder (ASKAP; Johnston et al. Reference Johnston 2007; De-Boer et al. Reference DeBoer 2009; Hotan et al. Reference Hotan 2021) telescope, is projected to discover more than 40 million compact and extended galaxies in the next five years (Norris et al. Reference Norris 2021b). Similarly, the Low-Frequency Array (LOFAR; van Haarlem et al. Reference van Haarlem 2013) survey of the entire northern sky is expected to detect more than 10 million galaxies. Other advanced radio telescopes include Murchison Widefield Array (MWA;Wayth et al. Reference Wayth 2018), MeerKAT (Jonas & MeerKAT Team Reference Jonas 2016) and the Karl G. Jansky Very Large Array (JVLA Perley et al. Reference Perley, Chandler, Butler and Wrobel 2011). With the advent of the Square Kilometre Array (SKA Footnote 1) radio telescope, which is expected to become operational in the coming years, the number of galaxy detections is expected to increase further, potentially reaching hundreds of millions. Such an enormous dataset will significantly impact our understanding of the physics of galaxy evolution. This is set to significantly impact our understanding of the evolution of the universe. However, to optimize the outcomes of these surveys, there is a need to innovate and develop new technologies for handling large datasets. Radio galaxies are characterized by giant radio emission regions that extend well beyond their host galaxy structure at visible and infrared wavelengths. While most radio galaxies typically appear as simple, compact circular sources, increasing the sensitivity of radio telescopes results in the detection of more radio galaxies with complex extended structures. These structures typically consist of multiple components with distinct peak radio emissions. Based on the Fanaroff-Riley classifications (Fanaroff & Riley Reference Fanaroff and Riley 1974), radio galaxies exhibit two distinct morphologies, namely, Fanaroff-Riley Class I (FR-I) and Class II (FR-II) Active Galactic Nuclei (AGN) sources. FR-I sources have dark edges, causing the collimated jets from the central black holes at the centre of the host galaxy to exhibit lower luminosity at the edges. FR-II sources, on the other hand, have brighter edges compared to the central host galaxies and sometimes lack a visible connection to the host galaxy. Constructing catalogues of radio galaxies necessitates the grouping of associated components within extended radio galaxies and the identification of their corresponding infrared host galaxies. Grouping these components is essential for estimating the real number density and overall integrated flux of radio galaxies. This process is crucial for modelling galaxy evolution and the expansion of the Universe. Failure to properly group associated components can lead to the misestimation of number density and total flux, resulting in inaccurate models. This highlights the critical need for developing computer vision methods, to reduce the dependency on visual inspections to group associated radio source components and identify their infrared host galaxies. Computer vision tasks are typically dependent on the available data. In supervised learning tasks, the model undergoes training by utilizing pairs of images and labels, where these labels provide precise and comprehensive information necessary for the model to make specific predictions. Recently, these machine learning (ML) methods have been applied in the morphological classification and identification of radio sources, as demonstrated in studies such as (e.g. Lukic et al. Reference Lukic 2018; Alger et al. Reference Alger 2018; Wu et al. Reference Wu 2019; Bowles et al. Reference Bowles, Scaife, Porter, Tang and Bastien 2020; Maslej-Kre\u0161\u0148\u00e1kov\u00e1, El Bouchefry, & Butka 2021; Becker et al. Reference Becker, Vaccari, Prescott and Grobler 2021; Brand et al. Reference Brand 2023). Self-supervised learning utilizes unsupervised techniques to train models based on the inherent data structure, removing the need for explicit annotations. This approach has proven effective in uncovering novel galaxy types in radio surveys, as demonstrated in studies such as (e.g. Galvin et al. Reference Galvin 2020; Mostert et al. Reference Mostert 2021; Gupta et al. Reference Gupta 2022). In contrast, semi-supervised learning integrates both labelled and unlabelled data throughout the training process, as exemplified in Slijepcevic et al. ( Reference Slijepcevic 2022). In the realm of weakly supervised learning, indirect labels are utilized for the entire training dataset, serving as a supervisory signal. This particular approach has found utility in the classification and detection of extended radio galaxies (Gupta et al. Reference Gupta 2023). As supervised learning relies on exact ground truth labels for training, this yields results that are more reliable in contrast to approaches that lack or possess limited supervisory signals during training. However, to train and test such supervised algorithms, a large and diverse dataset of labelled radio galaxy images is necessary. Unfortunately, such a dataset is not currently available for next-generation radio surveys, which poses a significant challenge to developing automated methods for grouping multiple components of radio galaxies and identifying host galaxies. Therefore, there is a dire need for the development of a comprehensive dataset of radio galaxy images, along with accurate and consistent labels, to enable the development of effective machine learning algorithms for the automated grouping and identification of associated components of extended radio galaxies and their hosts. This paper introduces RadioGalaxyNET, which includes a novel dataset and computer vision algorithms designed to tackle the challenge of associating radio galaxy components and identifying their hosts. Notably, our dataset is the first to be entirely curated by professional astronomers through multiple visual inspections and includes multimodal images of radio and infrared sky, as well as pixel-level labels on associated components of extended radio galaxies and their infrared hosts. RadioGalaxyNET dataset has been structured in the COCO dataset format (Lin et al. Reference Lin, Fleet, Pajdla, Schiele and Tuytelaars 2014), allowing for straightforward comparison studies of various object detection strategies for the machine learning community. It includes 2 800 images with three channels each, incorporating two radio sky channels, one corresponding to the infrared sky, and a total of 4 155 annotated instances. The annotations encompass galaxy class information, bounding box details for capturing associated components of each radio galaxy, radio galaxy segmentation masks, and the host galaxy positions in infrared images. To summarize, our work contributes to the following aspects: We introduce the first dataset entirely curated by professional astronomers that includes state-of-the-art images from the highly sensitive ASKAP telescope and instance-level annotations for extended radio galaxies. As a novel addition, our dataset also includes corresponding images of the infrared sky, along with the positional information of the host galaxies. We train and evaluate our dataset on seven cutting-edge object detection algorithms to demonstrate the challenge of detecting and grouping components of radio galaxies. Additionally, we propose a novel method to detect the positions of infrared host galaxies simultaneously. The paper is organized as follows. In Section 2, we provide details on the radio and infrared images, as well as the annotations utilized for training and evaluation. This section also offers a summary of the related work in this domain. Section 3 is dedicated to explaining the novel computer vision algorithms employed. Section 4 provides comprehensive information about the network training process and the evaluation metric. In Section 5, we present the outcomes derived from the trained networks. Our findings are summarized in Section 6, where we also outline directions for future research. 2. RadioGalaxyNET: Dataset 2.1. Radio and infrared images The RadioGalaxyNET dataset contains radio images derived from observations with the ASKAP radio telescope. ASKAP is located at Inyarrimanha Ilgari Bundara, the Murchison Radio-astronomy Observatory (MRO). Utilizing advanced technologies like the phased array feed (PAF) (PAF Hay et al. Reference Hay, O\u2019Sullivan, Kot, Granet, Lacoste and Ouwehand 2006), ASKAP can efficiently scan vast sections of the sky, significantly enhancing survey capabilities. Comprising 36 antennas, ASKAP has baselines reaching up to 6.4 km, with 30 antennas concentrated within a 2.3 km radius (Hotan et al. Reference Hotan 2021). ASKAP is currently involved in various surveys, each designed for specific scientific objectives. One notable survey is the EMU survey, which aims to identify approximately 40 million galaxies over its five-year operational period. In 2019, the EMU pilot survey was conducted to develop technologies in preparation for the main survey. The EMU-PS survey encompasses a sky area of 270 deg $^2$ , ranging from $301^{\\circ}$ to $336^{\\circ}$ in Right Ascension and from $-63^{\\circ}$ to $-48^{\\circ}$ in Declination. Comprising ten overlapping tiles, each tile underwent a total integration time of approximately 10 h, resulting in an RMS noise of 25\u201335 $\\mu$ Jy beam $^{-1}$ . The survey operated within a frequency range of 800\u20131 088 MHz, centred at 944 MHz (with a wavelength of 0.37\u20130.28 m, centred at 0.32 m). The telescope\u2019s visibility data, recording electric fields as a function of time and frequency, was processed through the ASKAPsoft pipeline (Whiting et al. Reference Whiting, Voronkov, Mitchell, Lorente, Shortridge and Wayth 2017) to generate images for the EMU-PS. The identification of the 2 800 extended radio galaxies in the EMU-PS image involved a meticulous manual process conducted in three distinct stages, as detailed by Yew et al. in prep. While a comprehensive overview of the source identification methodology is available in their work, we provide a brief summary here. Initially, a quick assessment of the EMU-PS radio image was conducted to identify clearly visible extended sources. Subsequently, a thorough visual scan covered the entire radio image systematically, involving the classification of sources and marking the extent of diffuse radio emission for each. In the third and final stage, an exhaustive scan aimed to uncover additional sources possibly overlooked in previous stages. Upon completion of the identification process, the centroid position and approximate size of each source were documented. It is important to note that, despite the three rounds of manual identification, locating all extended sources remains challenging, particularly for faint ones, given the substantial scientific resources required for such an exhaustive search. Following this, cut-outs of size $0.25^{\\circ}\\times 0.25^{\\circ}$ were generated at the centroid positions of these galaxies, resulting in $450\\times 450$ pixel images with a pixel size of 2 arcsec. The left column of Fig. 1 presents examples of noisy raw images. Following the procedure outlined by Gupta et al. ( Reference Gupta 2023), we preprocess the raw images. Examples of processed radio images are illustrated in the middle column of Fig. 1. At the same sky locations of radio images, we obtain AllWISE (Cutri et al. Reference Cutri 2021) infrared images from the Wide-field Infrared Survey Explorer\u2019s (WISE; Wright et al. Reference Wright 2010) W1 band that correspond to 3.4 $\\mu$ m wavelength. Similar to radio images, infrared images are processed to reduce noise in the same way. However, the noise in the infrared images is estimated as Median $+3\\times$ MAD due to the non-Gaussian nature of the noise and the saturation of sources in the images. The right column of Fig. 1 presents examples of processed infrared images, while raw infrared images are not displayed for brevity. Finally, we create 3-channel RGB images by combining the processed radio and infrared images. In this process, the B and G channels represent radio channels. The original 32-bit FITS image is initially converted to 16-bit, and its 8\u201316 bit and 0\u20138 bit information are assigned to the B and G channels, respectively. Similarly, the infrared FITS image undergoes a conversion to 16-bit, and its 8\u201316 bit information is incorporated into the R channel. 2.2. Annotations The RadioGalaxyNET dataset has the following four sets of labels the infrared host galaxy positions. the extended radio galaxy classes, the bounding boxes enclosing all components of each radio galaxy, and the segmentation masks for radio galaxies. The labelling process details are discussed in Yew et al. (in preparation) and Gupta et al. ( Reference Gupta 2023). In summary, we visually identified host galaxies in the infrared images, with the most likely hosts situated near or over the central peaks of radio emission. Only sources with identified host galaxies in the infrared image were included in the dataset. Radio sources were classified based on criteria from Fanaroff & Riley ( Reference Fanaroff and Riley 1974), distinguishing between FR-I and FR-II sources by considering the distance between the peak radio emission of all components and the total extent of the source. Additionally, some sources were classified as FR-x due to uncertainties in determining peak flux positions and total extent, as explained in Gupta et al. ( Reference Gupta 2023). Another category, denoted as R, includes resolved sources exhibiting extended emissions without clear peaks other than in the central part. The bounding boxes for each radio source, measured with the CARTA visualization package (Comrie et al. Reference Comrie 2021), served as the basis for obtaining segmentation masks. These masks were then created for all pixels within the bounding box, where the flux exceeded 3 $\\sigma$ . Annotations in the RadioGalaxyNET dataset adhere to the COCO dataset format (Lin et al. Reference Lin, Fleet, Pajdla, Schiele and Tuytelaars 2014), facilitating straightforward comparisons of object detection methods. Radio annotations for each galaxy are stored as \u2018categories\u2019, \u2018box\u2019, and \u2018segmentation\u2019, while the positions of the infrared hosts are stored as \u2018keypoints\u2019. 2.3. Data statistics and possible tasks The RadioGalaxyNET dataset encompasses 2 800 3-channel images featuring two radio sky channels and one corresponding infrared sky channel. Both noisy and processed radio images are included in the dataset. It comprises 2 800 extended radio galaxies, resulting in a total of 4 155 instances of these galaxies due to their proximity in the sky and their appearance in multiple images. The radio galaxies in the dataset are categorized as 13% FR-I, 48% FR-II, 14% FR-x, and 25% R sources. The dataset is divided into three sets: training, validation, and test sets, with a split ratio of $0.7\\;:\\;0.15\\;:\\;0.15$ , respectively. This split ratio is widely used in machine learning and represents a balanced approach that achieves a reasonable trade-off between having sufficient data for training and fine-tuning the model, while also ensuring that the model is evaluated on a suitably large, independent test set. The statistics for the number of objects in one frame, categories of extended radio galaxies, and the occupied area of labelled objects are shown in Fig. 2. The distribution of target galaxies is approximately matched between the training, validation, and test sets. Small extended radio galaxies (area $< 48^2$ in pixels) make up the largest proportion of the dataset. Figure 1. Raw radio (left column), processed radio (middle column) and processed infrared (right column) images with the frame size of $450\\times450$ pixels ( $0.25^{\\circ}\\times 0.25^{\\circ}$ ). The processed radio images highlight the categories of extended radio galaxies, and the bounding boxes denote their total radio extent encompassing all of its components. The infrared images show host galaxies inside the circles. Figure 2. The dataset split distributions of the RadioGalaxyNET. Shown are the distributions of extended radio galaxies in one frame (left), their categories (middle) and the occupied area per radio galaxy (right). The tables presented below the figures display the precise counts of galaxy instances within the training, validation, and test sets. Although the primary goal of this study is to detect radio galaxies, the RadioGalaxyNET dataset\u2019s unique multimodality can be leveraged for the simultaneous identification of infrared host galaxies. Additionally, it could be insightful to explore approaches for grouping multiple components of galaxies. Instead of component association using given box boundaries, the direct segmentation of related galaxy components could present a greater challenge for models. This could also be linked to instance segmentation approaches, where different input modalities could provide an interesting challenge. The dataset\u2019s unlabelled extended radio galaxies in a given frame make it suitable for experimenting with semi-supervised and contrastive learning methods. Furthermore, RadioGalaxyNET dataset could be used to validate signal enhancement in previous radio sky surveys. By downweighing detections that resemble extended galaxies in the dataset images, the dataset could be used to discover new galaxies in the radio sky. Finally, the modalities in the dataset could be used to model extended radio galaxy emissions from infrared hosts and vice versa. In this paper, we only focused on extended radio galaxies for the current dataset and have not included labels for several compact sources in radio images. Few extended radio galaxies, such as Odd Radio (Norris, Crawford, & Macgregor Reference Norris, Crawford and Macgregor 2021a), some Giant Radio Galaxies and other peculiar galaxies (Gupta et al. Reference Gupta 2022), are also not included in the dataset. Future efforts should focus on including a balanced representation of these sources in the dataset. 2.4. Related work 2.4.1. Existing radio galaxy dataset The availability of datasets for detecting and classifying radio galaxies is limited. The MiraBest Batched Dataset is a labelled dataset of FR galaxies extracted from Miraghaei & Best ( Reference Miraghaei and Best 2017). It contains FR-I, FR-II, and hybrid extended radio sources, with any nonstandard morphology reported. The dataset comprises a total of 1 256 images obtained from the VLA FIRST sky survey (Becker, White, & Helfand Reference Becker, White and Helfand 1995), with all images measuring $150 \\times 150$ pixels, with one-pixel corresponding to an angular size of 1.8 arcsec. The dataset is divided into seven training batches and one test batch, with each batch consisting of approximately 157 images, and the number of objects in each class is distributed relatively evenly across batches. The test batch contains at least one example of each class. It is important to note that the MiraBest dataset only provides information about the classes of radio galaxies without annotations for bounding boxes, segmentation masks, or infrared hosts, making it challenging to apply to multi-component association problems. Another dataset is sourced from the Radio Galaxy Zoo (RGZ) citizen science initiative, as described by Wu et al. ( Reference Wu 2019). Over 12 000 volunteers visually identified radio galaxies, resulting in a dataset of 6 536 extended radio galaxies with a user-weighted consensus level (CL) of at least 0.6. The CL reflects the level of agreement among citizens regarding the classification. The images in this dataset were obtained from the FIRST radio survey, and the annotations include the position of galaxies in the sky and the bounding boxes derived from web portal clicks by volunteers. These boxes are saved as the approximate angular size in the RGZ dataset. However, the dataset does not provide information on the segmentation masks and infrared host positions. The RMS noise in the FIRST radio images is approximately ten times larger than that in the EMU-PS, resulting in a lower density of galaxies in the same area. This high galaxy density makes RadioGalaxyNET dataset images derived from EMU-PS challenging for object detection. Table 1 shows a comparison between the existing and our new dataset. It is important to emphasize that the previous dataset possesses radio image noise levels that are an order of magnitude higher than our dataset. This higher noise level renders low-intensity extended structures essentially invisible. As a result, these previous datasets are not optimal for training networks aimed at detecting radio galaxies in the next generation of radio telescopes. 2.4.2. Existing machine learning applications In recent years, radio galaxy detection in images has attracted increasing attention, particularly focusing on deep learning algorithms. These algorithms are commonly divided into two categories: region proposal-based methods and classification-based methods. Wu et al. ( Reference Wu 2019) used Faster Region-based Convolutional Neural Network (Faster RCNN; Ren et al. Reference Ren, He, Girshick, Sun, Cortes, Lawrence, Lee, Sugiyama and Garnett 2015a) based method to locate and classify radio galaxies in the RGZ dataset. Lao et al. ( Reference Lao 2021) used a combination of residual neural network (ResNet; He et al. Reference He, Zhang, Ren and Sun 2016) and Feature Pyramid Network (FPN; Lin et al. Reference Lin 2017) to detect and classify FR galaxies. Scaife & Porter ( Reference Scaife and Porter 2021) classified FR galaxies in the MiraBest dataset using Group equivariant Convolutional Neural Networks (G-CNNs; Cohen &Welling Reference Cohen and Welling 2016). Slijepcevic et al. ( Reference Slijepcevic 2022) used FixMatch (Sohn et al. Reference Sohn 2020) to classify both MiraBest and RGZ radio galaxies. Zhang, Jiang, & Zhang ( Reference Zhang, Jiang and Zhang 2022b) used You Only Look Once method (YOLOv5; Redmon et al. Reference Redmon, Divvala, Girshick and Farhadi 2016a) to classify radio galaxies. 3. RadioGalaxyNET: Novel computer vision methods While the machine learning techniques employed in prior studies (refer to Section 2.4.2) have their own strengths. Recent advancements in computer vision have introduced several more effective algorithms that outperform the previously utilized methods in real-world scenarios. In addition, none of the previously employed techniques possess the ability to concurrently detect both multiple-component radio galaxies and their corresponding infrared hosts. In this section, we describe these state-of-the-art object detection approaches and explain our novel enhancements to these methods, which allow for the simultaneous detection of both radio galaxies and infrared hosts. 3.1. Gal-DETR In this paper, we introduce Gal-DETR, multimodal model for computer vision. The Gal-DETR model consists of two primary components: the DEtection TRansformers (DETR), as described in Carion et al. ( Reference Carion 2020) that is trained for the class and bounding box prediction for radio galaxies, and our novel Keypoint detection module, trained concurrently to detect infrared hosts. Note that the existing multimodal methods are tailored to specific tasks. Here we have radio images where galaxies appear larger due to extended emission, while in infrared images, the host galaxies look like point objects (as depicted in columns 2 and 3 of Fig. 1). To the best of our knowledge, there are no specific models that deal with objects that look completely different in two image modalities. As a result, we introduce our own approach to modelling, illustrated in Fig. 3. Table 1. Datasets currently available for the machine learning tasks of classification and object detection involving radio galaxies. The annotations C, B, S, and K are categories, bounding boxes, segmentation and keypoint labels, respectively. Section 2 provides a detailed description of the annotations for both our dataset and the existing dataset. 3.1.1. Class and bounding box detection for radio galaxies DETR model leverages the Transformer architecture (Vaswani et al. Reference Vaswani 2017), initially developed for natural language processing, to tackle the complex task of object detection in images following (Dosovitskiy et al. Reference Dosovitskiy 2020). Unlike traditional methods that rely on region proposal networks (e.g. Faster RCNN; Ren et al. Reference Ren, He, Girshick and Sun 2015b), DETR introduces end-to-end object detection using Transformers. The model begins with a convolutional neural network (CNN) backbone, such as ResNet, to process the input image and extract relevant feature maps. ResNet-50 is a convolutional neural network architecture designed to address the challenge of vanishing gradients in very deep neural networks. It incorporates 50 layers and utilizes skip connections, also referred to as residual connections, to enhance gradient flow during training (He, Zhang, Ren, & Sun Reference He, Zhang, Ren and Sun 2015). To incorporate spatial information into the Transformer architecture, DETR introduces positional encodings. These encodings are added to the feature maps, providing the model with information about the relative positions of objects within the image. The feature maps, enhanced with positional encodings, are then passed through a Transformer encoder. This component enables the model to simultaneously process the entire image, capturing contextual relationships between various regions. DETR introduces learned object queries, similar to class-specific anchor boxes in traditional detectors (e.g. Tian et al. Reference Tian, Shen, Chen and He 2019). Note that the anchor boxes are prior boxes defined as a set of pre-determined, fixed-size boxes of different scales and aspect ratios. These anchor boxes are chosen based on prior knowledge of the expected object sizes and shapes within the dataset. However, unlike fixed anchor boxes, the object queries in DETR are learned during training through the transformer decoder and represent the classes of objects the model aims to detect. The final output from the decoder has two distinct output heads: one for class prediction, which estimates the class probabilities for each object query, and another for bounding box prediction, which calculates the coordinates (x, y, width, height) of each object query\u2019s bounding box (see Fig. 3). DETR employs a Hungarian loss Footnote 2 function to establish associations between predicted bounding boxes and ground truth boxes. This loss enforces a one-to-one mapping between predicted and ground truth objects, ensuring the model\u2019s permutation invariance. The overall loss function for DETR combines the classification loss (cross-entropy) for class predictions and the box loss (smooth L1 loss) for bounding box predictions, (1) \\begin{equation}\\mathcal{L}_{\\text{DETR}} = \\mathcal{L}_{\\text{class}} + \\mathcal{L}_{\\text{box}},\\end{equation} where $\\mathcal{L}_{\\text{class}}$ is the cross-entropy loss for class predictions and $\\mathcal{L}_{\\text{box}}$ is the smooth L1 loss for bounding box predictions. In the context of object detection, the L1 loss is often used for bounding box regression. It calculates the absolute difference between the predicted bounding box coordinates (e.g. x, y, width, height) and the ground truth bounding box coordinates. This loss penalizes the model for deviations between the predicted and true bounding box values, with larger differences leading to higher loss values. 3.1.2. Keypoint detection for infrared hosts In addition to the object detection method that employs bounding boxes to detect extended radio galaxies, the integration of keypoint detection techniques (e.g. Simon et al. Reference Simon, Joo, Matthews and Sheikh 2017) can offer a complementary approach for identifying the corresponding infrared hosts. Keypoints, representing specific landmarks or distinctive features within the radio and infrared images, provide valuable spatial information that aids in precisely determining the location of the host galaxy. Unlike bounding boxes that enclose the entire source, keypoints allow for a more fine-grained localization, providing a more accurate representation of the host\u2019s position within the radio source. This precise localization is especially valuable when the radio emission exhibits complex morphologies. In the present work, we extended the capabilities of DETR by incorporating keypoint detection. We refer to this enhanced version as Gal-DETR. In Gal-DETR, we integrated keypoint detection to complement the existing object detection capabilities of the original DETR algorithm (see Fig. 3). By incorporating keypoint detection, Gal-DETR gains the ability to identify salient keypoints within the objects, providing additional spatial information and fine-grained details. The keypoint detection module in Gal-DETR leverages the transformer-based architecture of DETR to capture global context and local details. By attending to the keypoint embeddings and utilizing self-attention mechanisms, Gal-DETR localizes and associates keypoints for the infrared host galaxies. The overall loss function for Gal-DETR combines the DETR loss for class and bounding box predictions, in addition to the keypoint detection loss as (2) \\begin{equation}\\mathcal{L}_{\\text{Gal-DETR}} = \\mathcal{L}_{\\text{DETR}} + \\mathcal{L}_{\\text{keypoint}}\\end{equation} where $\\mathcal{L}_{\\text{keypoint}}$ is the L1 loss for keypoint detection to detect infrared hosts. In the context of keypoint detection, the L1 loss calculates the absolute difference between the predicted keypoint coordinates (e.g. x, y position of host) and the ground truth keypoint coordinates. Figure 3. An overview of the multimodal modelling strategy introduced in this study. In the context of the Gal-DETR model (refer to Section 3.1), we introduce a keypoint estimation module within the transformer encoder-decoder framework. This enables the simultaneous detection of categories and bounding boxes for radio galaxies, and the positions of infrared hosts. A similar multimodal strategy is introduced for Gal-Deformable DETR and Gal-DINO (as detailed in Sections 3.2 and 3.3). 3.2. Gal-deformable DETR The second multimodal model we introduce in this paper is Gal-Deformable DETR. Similar to Gal-DETR, the Gal-Deformable DETR model consists of two primary components: the Deformable DEtection TRansformers (Deformable DETR), as described in Zhu et al. ( Reference Zhu 2021) that is trained for the class and bounding box prediction for radio galaxies, and our novel Keypoint detection module, trained concurrently to detect infrared hosts. Deformable DETR builds upon the foundation of DETR and introduces several key enhancements. Deformable attention mechanisms allow the model to adaptively adjust the spatial sampling locations for better feature extraction, especially for objects with complex shapes or poses. Unlike DETR, which relies solely on learned positional encodings, Deformable DETR adds spatial positional encodings to the feature maps. This addition helps the model better capture the spatial relationships between objects. In this study, we have expanded the functionalities of Deformable DETR by introducing keypoint detection, resulting in an enhanced version known as Gal-Deformable DETR. Much like the Gal-DETR model, Gal-Deformable DETR incorporates keypoint detection as a complementary component to the existing object detection capabilities inherited from the original Deformable DETR algorithm. Specifically, we have integrated keypoint detection in conjunction with the deformable convolutional layers originally introduced in the Deformable DETR framework. Similar to Equation (2), the L1 loss for keypoint detection is combined with the class and bounding box loss during the training of the Gal-Deformable DETR model. 3.3. Gal-DINO The third multimodal model we introduce in this paper is Gal-DINO. Following Gal-DETR and Gal-Deformable DETR models, Gal-DINO also consists of two primary components: the DETR with Improved deNoising anchOr boxes (DINO), as described in Zhang et al. ( Reference Zhang 2022a) that is trained for the class and bounding box prediction for radio galaxies, and our novel Keypoint detection module, trained simultaneously to detect infrared hosts. DINO extends the DETR model with improved de-noising anchor boxes, introducing several key enhancements. DINO improves anchor boxes, which are predefined boxes used for object detection. It introduces better strategies for selecting and placing these anchor boxes, enhancing the model\u2019s ability to detect objects of different sizes and aspect ratios. DINO introduces an improved mechanism for matching anchor boxes to ground truth objects during training, making the model more accurate in localization and classification. DINO employs adaptive convolutional features, allowing the model to focus on informative regions of the image, thus improving both efficiency and accuracy. Much like our approach with Gal-DETR, we integrated keypoint detection into the DINO algorithm, which already has improved de-noising anchor boxes. This enhanced version, featuring keypoint detection, is denoted as Gal-DINO. By reducing the impact of noise and outliers, Gal-DINO produces more robust and precise bounding box predictions, resulting in better localization of the extended radio sources and their associated infrared hosts within these enhanced bounding boxes. In a manner similar to the approach outlined in Equation (2), the Gal-DINO model incorporates the L1 loss for keypoint detection combined with the class and bounding box loss during the training process. 3.4. Gal-SIOD Detection of objects in situations with imperfect data has recently become a focal point. Weakly supervised object detection (WSOD) encounters notable challenges in localization due to the lack of direct annotations (e.g. Gupta et al. Reference Gupta 2023). Li et al. ( Reference Li, Pan, Yan, Tang and Zheng 2022) introduced an approach known as Single Instance Annotated Object Detection (SIOD). We refer the reader to their paper for detailed information about the SIOD method. Briefly, SIOD requires just one instance annotation for each category present in an image. SIOD offers a more robust and informative source of prior knowledge for detecting the remaining unlabelled instances. This approach strikes a balance between annotation cost and performance, providing a valuable solution to object detection challenges under imperfect data conditions. This holds significance in the context of our current study on radio galaxy detection. As detailed in Section 2, even after conducting three rounds of manual search of EMU-PS, not all extended sources could be precisely located. This arises from the fact that visual inspections entail an exhaustive search for faint extended radio galaxies, a process demanding a substantial allocation of scientific resources. This implies that certain extended and peculiar sources within the same image are not annotated in the dataset. Utilizing SIOD for radio galaxy detection offers us the possibility to detect these unlabelled extended radio galaxies within a given image. Note that we have not incorporated keypoint detection into the radio galaxy detection process using SIOD. This decision stems from our primary objective, which is to assess whether we can detect additional radio galaxies not labelled in the dataset using this method. Future work should integrate keypoint detection into SIOD to enable the simultaneous detection of infrared hosts alongside radio galaxy detections. While our current implementation directly employs SIOD for our task, we have named our implementation as Gal-SIOD for naming consistency. 3.5. Gal-SIOD-DMiner SIOD-DMiner (Li et al. Reference Li, Pan, Yan, Tang and Zheng 2022) improves upon SIOD by introducing the Dual-Mining (DMiner) framework. SIOD, while effective in certain scenarios, faces challenges when it comes to dealing with unlabelled regions. Directly assigning all unlabelled regions as background can adversely affect the training process and detector performance. SIOD-DMiner tackles this challenge and improves object detection efficacy by integrating a Similarity-based Pseudo-Label Generating module (SPLG). This module retrieves instances by assessing feature similarity between labelled reference instances and the remaining unlabelled area in the image. This improves object detection over SIOD, which lacks this mechanism for leveraging unlabelled data effectively. In addition, the SIOD-DMiner recognizes that relying solely on pseudo-labels generated by SPLG can be problematic. It can lead to confusion due to false pseudo-labels, especially when the model focuses on learning a hyperplane for discriminating each class from the others. To mitigate this issue, SIOD-DMiner introduces a Pixel-level Group Contrastive Learning module (PGCL). PGCL improves the model\u2019s ability to withstand inaccurate pseudo-labels, reducing reliance on potentially flawed annotations. For similar considerations as mentioned earlier, we have not integrated keypoint detection into the radio galaxy detection process using SIOD-DMiner. Future work should integrate keypoint detection into SIOD-DMiner to enable the simultaneous detection of unlabelled infrared hosts. Furthermore, we have employed the SIOD-DMiner from Li et al. ( Reference Li, Pan, Yan, Tang and Zheng 2022) for our task but named our implementation Gal-SIOD-DMiner to maintain naming consistency. 3.6. Gal-Faster RCNN Faster Region-based Convolutional Neural Network (Faster RCNN; Ren et al. Reference Ren, He, Girshick and Sun 2015b) significantly improved the speed and accuracy of object detection compared to the proposal-based predecessor methods. Faster RCNN follows a two-stage approach to object detection, which distinguishes it from earlier methods like Fast RCNN (Girshick Reference Girshick 2015). The first stage of Faster RCNN is a Region Proposal Network (RPN), which efficiently generates region proposals (candidate bounding boxes) that are likely to contain objects of interest. The RPN operates on feature maps extracted from the input image and predicts regions with high scores. In the second phase, the system fine-tunes and categorizes these region proposals. Region of Interest (RoI) pooling is employed to derive standardized feature maps of fixed dimensions from each region proposal, making them suitable for a standard CNN classifier. Faster RCNN uses a CNN classifier to categorize the content within each RoI into predefined object classes (e.g. FR-I, FR-II etc.) and regress the bounding box coordinates for precise localization. The entire network, including both the RPN and the classifier, is trained end-to-end. This means that the model learns to generate region proposals and classify objects simultaneously during training. While Deformable DETR and DINO have demonstrated superior performance over Faster RCNN when applied to real-life images from the COCO dataset (Zhu et al. Reference Zhu 2021; Zhang et al. Reference Zhang 2022a), we have opted to utilize Faster RCNN on our dataset for the sake of comparison. In line with this primary objective of comparing Faster RCNN with Transformer-based methods, we have refrained from incorporating Keypoint detection into Faster RCNN. We have named our implementation Gal-Faster RCNN to maintain naming consistency. 3.7. Gal-YOLOv8 You Only Look Once version 8 (YOLOv8) is an object detection model latest in the YOLO (Redmon et al. Reference Redmon, Divvala, Girshick and Farhadi 2016b) series of object detection models. YOLOv8 follows the one-stage detection paradigm, which means it directly predicts bounding boxes and class probabilities for objects in a single pass through the neural network. This makes it faster compared to two-stage detectors like Faster RCNN. YOLOv8 employs a CNN backbone architecture that is designed to capture features at multiple scales. YOLOv8 uses a detection head consisting of convolutional layers to predict bounding boxes and class probabilities. It predicts class labels and confidence scores for each detected object. Similar to initial YOLO versions, YOLOv8 uses anchor boxes to help predict the shape and location of objects. However, YOLOv8 has the option to automatically calculate anchor box sizes based on the dataset, which can simplify the training process. In this study, we perform fine-tuning on a pre-trained YOLOv8 model using our dataset and designate our customized implementation as Gal-YOLOv8 to maintain naming consistency. It is worth noting that we have not integrated keypoint detection into YOLOv8 in this implementation. Future work should explore methods for detecting infrared hosts alongside radio galaxy detections within the YOLO class of models. 4. Training and evaluation In this section, we provide details of the network training process. Additionally, we outline the evaluation metrics employed for comparing different computer vision models in this section. 4.1. Training details The dataset division into training, validation, and test sets is detailed in Fig. 2 and Section 2.3. The training data is used to train the networks, while the validation and test sets serve as inference datasets during and after training, respectively. The networks described in Section 3 are trained for different numbers of epochs, which depend on their convergence speed and the stability of validation results. In this context, one epoch signifies a single pass through the entire training dataset during the model\u2019s training process. During each epoch, the training dataset is subjected to various randomly applied augmentations. These augmentations involve random flipping, random rotations, random resizing, and random cropping of a randomly selected set of 3-channel images from the training data. Random flipping, performed horizontally (left to right), exposes the model to various object orientations and viewpoints. Random rotations, ranging from \u2212180 to 180 degrees, promote rotational invariance in the network \u2013 a critical aspect for handling radio galaxies with random orientations in the sky. Random resizing operations entail scaling images up or down by selecting a target size randomly within predefined bounds. We have set the lower and upper bounds to $400\\times400$ and $1\\,300\\times1\\,300$ pixels, respectively. This strategy enables the model to learn from objects at different scales while preventing overfitting to specific sizes or aspect ratios. Additionally, random cropping involves the random selection of a portion (or crop) from an input image, discarding the rest. This cropping operation, always applied after image resizing, introduces spatial variability in object locations within an image. The application of these augmentations enhances the model\u2019s capacity to generalize effectively and perform well on unseen data. These augmentations are applied during the training of all the networks described in this study. All networks are trained and evaluated on an Nvidia Tesla P100. We retained the original hyperparameters for each algorithm during training, except for specific modifications. These hyperparameters are configuration settings that are not learned from the training data but are set prior to the training process. The most important ones include the learning rate, which dictates the magnitude of weight adjustments during training; the batch size, indicating the number of data samples processed at a time; architecture parameters, specifying neural network architecture details like layer counts and filter sizes; dropout rate for preventing overfitting by deactivating units during training; activation functions applied to the output of neural network layers to introduce non-linearity into the model; and optimizer for weight updates. While we do not present all the hyperparameters for various networks here to keep the discussion concise, we refer the reader to the network architectures available in the provided repositories for these details. Here, we focus on the critical training aspects. As detailed in Section 3.1, Gal-DETR introduces multimodal modelling for radio and infrared detections. Specifically, we implemented keypoint detection to the model architecture and Hungarian loss function. We reduced the learning rate to $5\\times 10^{-5}$ and the number of queries to 10 from 100. The number of queries is decreased due to the fact that there are no more than five extended galaxies per image in our dataset, as depicted in the left panel of Fig. 2. As indicated in Table 2, Gal-DETR has 41 million parameters and undergoes training over the course of 500 epochs for $\\sim$ 10 h on a single P100 GPU. Table 2. Bounding box and keypoint detection results on the test set of RadioGalaxyNET. From left to right, the columns display the multimodal models introduced in this study, the number of model parameters in millions, the number of training epochs, the average precision for IoU (or OKS) thresholds ranging from 0.50 to 0.95 (AP), a specific IoU (or OKS) threshold of 0.5 (AP $_{50}$ ), IoU (or OKS) threshold of 0.75 (AP $_{75}$ ), and the average precision for small-sized radio galaxies (AP $_{\\mathrm {S}}$ ), medium-sized radio galaxies (AP $_{\\mathrm {M}}$ ), and large-sized radio galaxies (AP $_{\\mathrm {L}}$ ), categorized by areas less than $24^2$ , between $24^2$ and $48^2$ , and greater than $48^2$ pixels, respectively. Detailed information on the training and development of these models is provided in Section 4, while the models themselves are described in Section 3. Table 3. Bounding box detection results using Gal-SIOD and Gal-SIOD-DMiner networks. The AP $_{50}$ , AP $_{\\mathrm {S}}$ , AP $_{\\mathrm {M}}$ , and AP $_{\\mathrm {L}}$ reported here correspond to those in Table  2 . The average precision values in this table are provided for various confidence thresholds (S), ranging from no limit to 0, 0.3, and 0.5 confidence scores. Comprehensive information regarding the models and their training (or evaluation) can be found in Sections 3 and 4, respectively. Similar changes were made for Gal-Deformable DETR model (Section 3.2), where keypoint detection was also implemented in the deformable attention mechanism. Training Gal-Deformable DETR, which comprises 40 million parameters, spanned 100 epochs and consumed approximately 8 h on a single GPU. For Gal-DINO model (Section 3.3), we made the same changes as for Gal-DETR and additionally implemented keypoint detection in the de-noising anchor box mechanism. Training Gal-DINO, featuring 47 million parameters, involved a 30-epoch training process that took approximately 6 h on a single GPU. As Gal-SIOD (Section 3.4) necessitates only one instance annotation per category within an image, we performed a selection process where we retained unique categories of radio galaxies in each image. For example, we ensured that each image contained at most one random annotation for FR-I sources, FR-II sources, FR-x sources, and R radio sources. This selection reduced the overall number of training annotations in all training images from 2 910 to 2 534, resulting in an annotation keeping ratio of 0.87. No additional changes were made for Gal-SIOD-DMiner (Section 3.5) except for the reduction in annotations with the same keeping ratio. Both the Gal-SIOD and Gal-SIOD-DMiner networks, each comprising 14.4 million parameters, underwent separate 200-epoch training sessions, with each session taking approximately 8 h on a single GPU. The Gal-Faster RCNN (Section 3.6) model underwent training for 20 000 epochs, which took approximately 5 h on a single GPU. To train Gal-YOLOv8 (Section 3.7), we utilized the pre-trained YOLOv8 model from Ultralytics Footnote 3 for object detection. The training process took approximately 12 h for 30 epochs and was conducted on a single GPU. Figure 4. Object detection results: Shown are the processed radio-radio-infrared images and ground truth annotations (first column), ground truth and Gal-DINO keypoint detections as circles and triangles over infrared images (second column), Gal-DINO (third column) and Gal-SIOD-DMiner (fourth column) class and bounding box predictions over radio images with a confidence threshold of 0.25. These models exhibit the capability to detect additional extended galaxies that lack ground truth annotations. 4.2. Evaluation metric We employ the standard evaluation metrics outlined by Lin et al. ( Reference Lin, Fleet, Pajdla, Schiele and Tuytelaars 2014) for computer vision to evaluate and compare the performance of the seven algorithms on the test dataset. Specifically, we utilize the Intersection over Union (IoU), a metric commonly used for assessing object detection algorithm performance. The IoU is calculated as the ratio of the intersection between the predicted bounding boxes ( $P_{\\mathrm {B}}$ ) and the ground truth bounding boxes ( $T_{\\mathrm {B}}$ ) to the union of the two boxes. The metric can be expressed as (3) \\begin{equation} \\text{IoU}(P_{\\mathrm {B}}, T_{\\mathrm {B}}) = \\frac{{\\text{Area of Overlap between $P_{\\mathrm {B}}$ and $T_{\\mathrm {B}}$}}}{{\\text{Area of Union between $P_{\\mathrm {B}}$ and $T_{\\mathrm {B}}$}}},\\end{equation} In the domain of bounding box prediction, the area of each predicted box is evaluated to ascertain its classification as a true positive (TP), false positive (FP), or false negative (FN) concerning the ground truth box\u2019s area for each radio galaxy. To be more specific, a bounding box is classified as TP if it accurately identifies an object and exhibits a sufficiently high IoU overlap with a corresponding ground truth bounding box. In essence, this means that the algorithm\u2019s detected bounding box correctly recognizes an object present in the ground truth data. An FP bounding box, on the other hand, is one generated by the algorithm but fails to accurately correspond to any ground truth object. Finally, a false negative (FN) bounding box occurs when an object is present in the ground truth data, but the algorithm fails to detect it, indicating a missed opportunity to identify a genuine object. The metric employed to assess the keypoint detection of infrared hosts is called Object Keypoint Detection (OKS). It is determined by the Euclidean distance between the predicted and true positions of the infrared hosts and is expressed as: (4) \\begin{equation}\\mathrm{OKS} = \\exp \\left(-\\frac{d^2}{2r^2c^2}\\right).\\end{equation} In this equation, d represents the Euclidean distance, r represents the ratio of the bounding box to the image area, and $c=0.107$ instead of 10 values in Lin et al. ( Reference Lin, Fleet, Pajdla, Schiele and Tuytelaars 2014), as there is one infrared host per bounding box in our case. The OKS score ranges from 0 to 1, with 1 signifying optimal detection. Table 4. Bounding box detection results for Gal-Faster RCNN and Gal-YOLOv8 models. The columns here align with those presented in Table  2 . Additional information regarding the networks can be found in Sections 3 and 4. We assess the performance of all seven networks using the average precision metric, a widely adopted standard for evaluating object detection models (Lin et al. Reference Lin, Fleet, Pajdla, Schiele and Tuytelaars 2014). Precision is a metric that measures the accuracy of positive predictions made by a model. It is calculated as the ratio of TPs (correctly identified instances of the positive class) to the sum of TPs and FPs (incorrectly identified instances of the positive class). Recall, also known as sensitivity or true positive rate, is a metric that measures the ability of a model to correctly identify all relevant instances of the positive class. It is calculated as the ratio of TPs to the sum of TPs and FPs (instances of the positive class that were not identified). The Precision-Recall Curve depicts how the balance between precision and recall changes at various thresholds. Average Precision (AP) is a metric calculated from the precision-recall curve, representing the area under that curve. An AP of 1 indicates a perfect model, achieving both maximum precision and recall. On the other hand, an AP of 0 signifies that the model fails to correctly identify any positive instances, resulting in minimal precision and recall. We compute average precision values by employing standard IoU and OKS thresholds for bounding boxes and keypoints, respectively. The IoU threshold determines the correctness of a prediction based on the extent of overlap it shares with the ground truth; predictions with an IoU exceeding this threshold are considered correct. Similarly, the OKS threshold assesses the correctness of predicted keypoints based on their similarity scores, with scores above this threshold indicating correctness. We calculate average precision at IoU (or OKS) thresholds ranging from 0.50 to 0.95, denoted as AP, as well as at specific IoU (or OKS) thresholds of 0.50 (AP $_{50}$ ) and 0.75 (AP $_{75}$ ) for radio galaxies of all sizes. Additionally, in order to assess performance across varying scales of structures within radio images, we compute the Average Precision for small (AP $_{\\mathrm {S}}$ ), medium (AP $_{\\mathrm {M}}$ ), and large (AP $_{\\mathrm {L}}$ ) area ranges, defined as pixel areas less than $24^2$ , between $24^2$ and $48^2$ , and greater than $48^2$ , respectively. We evaluate the performance of bounding boxes for radio galaxies and the identification of keypoints indicating the positions of infrared hosts using the multimodal networks Gal-DINO, Gal-Deformable DETR, and Gal-DINO, all introduced in the present study. For Gal-SIOD, Gal-SIOD-DMiner, Gal-Faster RCNN, and Gal-YOLOv8 networks, we exclusively provide average precision values for the bounding boxes. In the case of Gal-SIOD and Gal-SIOD-DMiner, a confidence constraint to the COCO-style evaluation metrics is used. This constraint requires a predicted box to meet specific IoU and confidence threshold (S) criteria in order to be considered a true match. 5. Results We evaluate the performance of state-of-the-art object detection algorithms on our dataset, which includes processed radio and infrared images and annotations that are tailored for the detection of extended radio galaxies. Experiments involving noisy radio are discussed in Appendix 1. Our novel multimodal modelling approach is introduced to enable the simultaneous detection of radio galaxies and their corresponding infrared hosts. This approach incorporates keypoint detection into the Gal-DETR, Gal-Deformable DETR, and Gal-DINO algorithms. Additionally, we train Gal-SIOD, Gal-SIOD-DMiner, Gal-Faster RCNN, and Gal-YOLOv8 models to compare their performance in radio galaxy bounding box detection. Figure 5. Confusion Matrices: Shown are the normalized matrices for the Gal-DINO model and Gal-YOLOv8 detection model in the left and right panels, respectively. Here the diagonal values corresponding to various galaxy classes represent the true positive (TP) instances at IoU and confidence thresholds of 0.5 and 0.25, respectively. Beyond these thresholds, the false positive (FP) values indicate detections without corresponding ground truth instances, while the false negative (FN) values signify instances where the model failed to detect the galaxies. Table 2 provides the Gal-DETR, Gal-Deformable DETR, and Gal-DINO results for both bounding box and keypoint detection on the test set of the RadioGalaxyNET dataset. Notably, Gal-DINO emerged as the top-performing model, achieving the highest AP of 53.7%. This outstanding performance underscores its excellence in detecting bounding boxes for radio galaxies. Gal-Deformable DETR also demonstrated competence in identifying radio galaxies, with an AP of 40.2%. In contrast, Gal-DETR, while capable, achieved a comparatively lower AP of 22.6%. Gal-DINO\u2019s superiority extended across all IoU thresholds (AP $_{50}$ and AP $_{75}$ ), securing an AP $_{50}$ of 60.2% and an AP $_{75}$ of 58.9%, signifying its robustness in radio galaxy detection across varying IoU thresholds. Moreover, Gal-DINO consistently outperformed other models for small, medium, and large-sized radio galaxies (AP $_{\\mathrm {S}}$ , AP $_{\\mathrm {M}}$ , and AP $_{\\mathrm {L}}$ ). Additionally, Gal-DINO excelled in keypoint detection, achieving an AP of 48.1% and an AP $_{50}$ of 53.4%. In summary, these results affirm Gal-DINO as the most effective model for both bounding box and keypoint detection in the realm of radio galaxy and infrared host detection, displaying strong performance across diverse IoU thresholds and galaxy sizes. Table 3 presents the outcomes for Gal-SIOD and Gal-SIOD-DMiner, incorporating a confidence constraint into the COCO-style evaluation metrics. A predicted box is considered a true match only when it meets particular IoU and confidence threshold (S) criteria. Here also we use the same area range as above for evaluation. With no confidence constraint ( $S=0$ ), Gal-SIOD achieves a relatively high AP $_{50}$ of 45.9%. As the confidence threshold increases, the overall AP values decrease. For instance, at $S=0.3$ and $S=0.5$ , the AP $_{50}$ drops to 41.6% and 18.3%, respectively. The model exhibits similar trends across all confidence thresholds for small, medium, and large-sized radio galaxies, as seen in the values of AP $_{\\mathrm {S}}$ , AP $_{\\mathrm {M}}$ , and AP $_{\\mathrm {L}}$ . Gal-SIOD-DMiner achieves slightly higher AP $_{50}$ of 46.8% with no confidence constraint. Similar to Gal-SIOD, as the confidence threshold increases, the overall AP values decrease. The model also exhibits consistent performance trends across all confidence thresholds for small, medium, and large-sized radio galaxies. Fig. 4 displays RGB images and ground truth annotations (first column), ground truth and predicted keypoints as circles and triangles over infrared images (second column), Gal-DINO bounding box predictions over radio images (third column), and Gal-SIOD-DMiner predictions over radio images (fourth column). All predictions are above the confidence threshold of 0.25. Notably, these models detect more extended galaxies where the ground truth annotation is not available in the same frame. However, it is worth noting that some of these detections do not correspond to FR radio galaxies; instead, they include peculiar radio sources like the Odd Radio Circle, as illustrated in the bottom right panel of the figure. Table 4 shows results for Gal-Faster RCNN and Gal-YOLOv8 models. Gal-YOLOv8 outperforms Gal-Faster RCNN by a significant margin, achieving an AP $_{50}$ of 58.5% compared to 48.4% for Gal-Faster RCNN. Gal-YOLOv8 and Gal-DINO are among the best-performing models that exhibit similar AP of 54.5% and 53.7%, respectively. Both models achieve high AP scores, with Gal-YOLOv8 displaying a slight advantage in detecting smaller radio galaxies, while Gal-DINO excels in identifying medium and large-sized galaxies. Fig. 5 shows confusion matrices for the best-performing Gal-DINO and Gal-YOLOv8 models. These matrices are calculated for IoU (and OKS for Gal-DINO) and confidence thresholds of 0.5 and 0.25, respectively. In object detection, the confusion matrix, as explained in Gupta et al. ( Reference Gupta 2023), differs from the one used in classification. Unlike classification, where each image has only one label, object detection allows for multiple instances of the same or different classes within an image. This leads to multiple TP, FP, and FN values for each class in the confusion matrix. When constructing the confusion matrix, attention is paid to the intersection between predicted and true bounding boxes (and keypoints for Gal-DINO), assessed using an IoU (and OKS for Gal-DINO) threshold of 0.5. The left panel of Fig. 5 displays Gal-DINO model performance. In the FR-II class, the TP value indicates 79% accurate detection in the test set. However, there are moderate FPs, signifying 11% mispredictions, and FNs, suggesting an 8% miss rate. Similar patterns are observed for the FR-I, FR-x, and R classes. The right panel shows that Gal-YOLOv8 displays a behaviour similar to that of Gal-DINO. However, the TP value for FR-x is considerably smaller, indicating that the model tends to confuse FR-II or FR-I sources with FR-x to a greater extent. 6. Conclusions The next generation of radio telescopes has the capability to rapidly survey extensive regions of the sky, culminating in the generation of extensive catalogues comprising millions of radio galaxies. Nevertheless, these highly sensitive surveys are also detecting a very large number of complex radio sources, rendering conventional source extraction approaches less useful. We introduce RadioGalaxyNET, comprising a labelled dataset and a suite of computer vision models designed for detecting extended radio sources and their corresponding infrared host galaxies. The dataset encompasses 2 800 images, comprising both radio and infrared sky channels, and includes 4 155 instances of labelled sources. Radio images are sourced from the Evolutionary Map of the Universe pilot survey (EMU-PS), which was carried out using the Australian Square Kilometre Array Pathfinder (ASKAP) telescope. The identification of radio galaxies and the curation of annotations, including class labels, bounding boxes, and segmentation masks, are performed through visual inspections. Additionally, infrared images from the Wide-field Infrared Survey Explorer (WISE) are aligned with the sky positions of the radio images, and the infrared host galaxies are visually identified in the infrared images. Our computer vision methods include multimodal models, including Gal-DETR, Gal-Deformable DETR, and Gal-DINO, where we introduce a mechanism for simultaneous detection of radio galaxies and infrared hosts through bounding box and keypoint detections, respectively. We employ the Average Precision (AP) metric to assess all the models presented in this study for both the prediction of bounding boxes for radio sources and the prediction of keypoints for infrared hosts. Our findings reveal that the Gal-DINO model exhibits superior performance in detecting both radio galaxies and infrared hosts, achieving AP $_{50}$ scores of 60.2% and 53.4%, respectively. In addition to these models, we conduct a comparative analysis of our radio galaxy detection results with those produced by Gal-SIOD, Gal-SIOD-DMiner, Gal-Faster RCNN, and Gal-YOLOv8 models. Our results indicate that Gal-DINO and Gal-YOLOv8 yield comparable outcomes in radio galaxy detection. Future work should consider our dataset and the computer vision methodologies for cataloguing radio galaxies and infrared hosts in ongoing and upcoming radio surveys. The availability of our dataset will facilitate the development of more advanced machine learning techniques for detecting radio galaxies and infrared hosts in the next generation of radio surveys, such as the EMU main survey. In order to further enrich the diversity of training data across the entire southern sky, future research should also explore the possibilities of incorporating online learning and active learning with a human-in-the-loop approach for the EMU main survey. Data availability RadioGalaxyNET dataset can be downloaded from https://doi.org/10.25919/btk3-vx79. Network architectures for Gal-DETR, Gal-Deformable DETR and Gal-DINO can be cloned from http://hdl.handle.net/102.100.100/602494?index=1. GitHub to all networks: Gal-DETR: https://github.com/Nikhel1/Gal-DETR Gal-Deformable DETR: http://github.com/Nikhel1/Gal-Deformable-DETR Gal-DINO: https://github.com/Nikhel1/Gal-DINO Gal-SIOD and Gal-SIOD-DMiner: https://github.com/Nikhel1/Gal-SIOD Gal-Faster RCNN: https://github.com/Nikhel1/Gal-Faster-RCNN Gal-YOLOv8: https://github.com/Nikhel1/Gal-YOLOv8 Acknowledgements The Australian SKA Pathfinder is part of the Australia Telescope National Facility, which is managed by CSIRO. The operation of ASKAP is funded by the Australian Government with support from the National Collaborative Research Infrastructure Strategy. ASKAP uses the resources of the Pawsey Supercomputing Centre. The establishment of ASKAP, the Murchison Radio-astronomy Observatory and the Pawsey Supercomputing Centre are initiatives of the Australian Government, with support from the Government of Western Australia and the Science and Industry Endowment Fund. We acknowledge the Wajarri Yamatji people as the traditional owners of the Observatory site. The photometric redshifts for the Legacy Surveys (PRLS) catalogue used in this paper were produced thanks to funding from the U.S. Department of Energy Office of Science and Office of High Energy Physics via grant DE-SC0007914. This research has made use of the NASA/IPAC Extragalactic Database (NED), which is operated by the Jet Propulsion Laboratory, California Institute of Technology, under contract with the National Aeronautics and Space Administration. NG acknowledges support from CSIRO\u2019s Machine Learning and Artificial Intelligence Future Science Impossible Without You (MLAI FSP IWY) Platform. Appendix A. Model Analysis with Noisy/Raw Radio Images We provide object detection results using raw radio images in this additional study. The 3-channel RGB images utilized for training and testing the networks consist of two channels containing noisy raw radio images instead of processed ones. Specifically, the B channel is filled with 8\u201316 bit raw radio information, while the G channel contains 0\u20138 bit raw radio information. For the R channel, we keep 8\u201316 bit infrared information as before. We train Gal-DETR, Gal-Deformable DETR and Gal-DINO-4scale multimodel models using the same set of hyperparameters and annotations as before. In Fig. A.1., the first column showcases RGB images with ground truth annotations. The second column displays the ground truth and predicted keypoints represented by circles and triangles, respectively, overlaid on infrared images. The third column shows the bounding box predictions made by the Gal-DINO model over radio images. All predictions shown in the figure are above the confidence threshold of 0.25. Figure A.1. Object detection results: Shown are the raw radio and processed infrared 3-channel RGB images and ground truth annotations (first column), ground truth and Gal-DINO keypoint detections as circles and triangles over infrared images (second column), Gal-DINO class and bounding box predictions over raw radio images (third column). Better viewed in colour. Table A.1. showcases the evaluation outcomes of Gal-DETR, Gal-Deformable DETR, and Gal-DINO for the detection of bounding boxes around extended radio galaxies and keypoints representing the positions of infrared host galaxies. It is worth noting that the Average Precision values are lower compared to the results achieved with processed radio images, as presented in the main paper. The presence of noise in radio images poses additional challenges to object detection tasks. Nevertheless, with further enhancements, these models have the potential to be directly applied to raw radio data, expanding their applicability. Table A.1. Bounding box and keypoint detection results on the test set of RadioGalaxyNET. Instead of using processed images, the 3-channel RGB images used for training and testing the networks include two channels that contain noisy raw radio information, and one channel has processed infrared images. Footnotes 1 https://www.skatelescope.org/the-ska-project/. 2 https://github.com/mmgalushka/hungarian-loss. 3 https://ultralytics.com. References Alger, M. J., et al. 2018, MNRAS, 478, 5547Google Scholar Becker, B., Vaccari, M., Prescott, M., & Grobler, T. 2021, MNRAS, 503, 1828CrossRefGoogle Scholar Becker, R. H., White, R. L., & Helfand, D. J. 1995, ApJ, 450, 559CrossRefGoogle Scholar Bowles, M., Scaife, A. M. M., Porter, F., Tang, H., & Bastien, D. J. 2020, MNRAS, 501, 4579CrossRefGoogle Scholar Brand, K., et al. 2023, MNRAS, 522, 292CrossRefGoogle Scholar Carion, N., et al. 2020, in Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part I 16 (Springer), 213CrossRefGoogle Scholar Cohen, T., & Welling, M. 2016, in International Conference on Machine Learning, PMLR, 2990Google Scholar Comrie, A., et al. 2021, CARTA: The Cube Analysis and Rendering Tool for Astronomy, Zenodo, doi: 10.5281/zenodo.3377984 CrossRefGoogle Scholar Cutri, R. M., et al. 2021, VizieR Online Data Catalog, II/328Google Scholar DeBoer, D. R., et al. 2009, IEEE Proc., 97, 1507CrossRefGoogle Scholar Dosovitskiy, A., et al. 2020, arXiv preprint arXiv:2010.11929Google Scholar Fanaroff, B. L., & Riley, J. M. 1974, MNRAS, 167, 31PCrossRefGoogle Scholar Galvin, T. J., et al. 2020, MNRAS, 497, 2730Google Scholar Girshick, R. 2015, in Proceedings of the IEEE International Conference on Computer Vision, 1440Google Scholar Gupta, N., et al. 2022, PASA, 39, e051Google Scholar Gupta, N., et al. 2023, PASA, 40, e044Google Scholar Hay, S., O\u2019Sullivan, J., Kot, J., & Granet, C. 2006, in ESA Special Publication, Vol. 626, The European Conference on Antennas and Propagation: EuCAP 2006, ed. Lacoste, H., & Ouwehand, L., 663Google Scholar He, K., Zhang, X., Ren, S., & Sun, J. 2015, arXiv e-prints, arXiv:1512.03385Google Scholar He, K., Zhang, X., Ren, S., & Sun, J. 2016, in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)Google Scholar Hotan, A. W., et al. 2021, PASA, 38, e009Google Scholar Johnston, S., et al. 2007, PASA, 24, 174Google Scholar Jonas, J., & MeerKAT Team. 2016, in MeerKAT Science: On the Pathway to the SKA, 1Google Scholar Lao, B., et al. 2021, SciB, 66, 2145Google Scholar Li, H., Pan, X., Yan, K., Tang, F., & Zheng, W.-S. 2022, in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 14197Google Scholar Lin, T.-Y., et al. 2017, in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)Google Scholar Lin, T.-Y., et al. 2014, in Computer Vision \u2013 ECCV 2014, ed. Fleet, D., Pajdla, T., Schiele, B., & Tuytelaars, T. (Cham: Springer International Publishing), 740Google Scholar Lukic, V., et al. 2018, MNRAS, 476, 246CrossRefGoogle Scholar Maslej-Kre\u0161\u0148\u00e1kov\u00e1, V., El Bouchefry, K., & Butka, P. 2021, MNRAS, 505, 1464CrossRefGoogle Scholar Miraghaei, H., & Best, P. N. 2017, MNRAS, 466, 4346Google Scholar Mostert, R. I. J., et al. 2021, A&A, 645, A89CrossRefGoogle Scholar Norris, R. P., Crawford, E., & Macgregor, P. 2021a, Galaxies, 9, 83CrossRefGoogle Scholar Norris, R. P., et al. 2021b, PASA, 38, e046Google Scholar Perley, R. A., Chandler, C. J., Butler, B. J., & Wrobel, J. M. 2011, APJ, 739, L1CrossRefGoogle Scholar Redmon, J., Divvala, S., Girshick, R., & Farhadi, A. 2016a, in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)Google Scholar Redmon, J., Divvala, S., Girshick, R., & Farhadi, A. 2016b, in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 779Google Scholar Ren, S., He, K., Girshick, R., & Sun, J. 2015a, in Advances in Neural Information Processing Systems, ed. Cortes, C., Lawrence, N., Lee, D., Sugiyama, M., & Garnett, R., Vol. 28 (Curran Associates, Inc.)Google Scholar Ren, S., He, K., Girshick, R., & Sun, J. 2015b, Advances in Neural Information Processing Systems, 28Google Scholar Scaife, A. M. M., & Porter, F. 2021, MNRAS, 503, 2369CrossRefGoogle Scholar Simon, T., Joo, H., Matthews, I., & Sheikh, Y. 2017, in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)Google Scholar Slijepcevic, I. V., et al. 2022, MNRAS, 514, 2599Google Scholar Sohn, K., et al. 2020, Advances in Neural Information Processing Systems, 33, 596Google Scholar Tian, Z., Shen, C., Chen, H., & He, T. 2019, in Proceedings of the IEEE/CVF International Conference on Computer Vision, 9627Google Scholar van Haarlem, M. P., et al. 2013, A&A, 556, A2Google Scholar Vaswani, A., et al. 2017, Advances in Neural Information Processing Systems, 30Google Scholar Wayth, R. B., et al. 2018, PASA, 35, e033Google Scholar Whiting, M., Voronkov, M., Mitchell, D., & Askap Team. 2017, in Astronomical Society of the Pacific Conference Series, Vol. 512, Astronomical Data Analysis Software and Systems XXV, ed. Lorente, N. P. F., Shortridge, K., & Wayth, R., 431Google Scholar Wright, E. L., et al. 2010, AJ, 140, 1868Google Scholar Wu, C., et al. 2019, MNRAS, 482, 1211Google Scholar Zhang, H., et al. 2022a, arXiv preprint arXiv:2203.03605Google Scholar Zhang, Z., Jiang, B., & Zhang, Y. 2022b, PASP, 134, 064503Google Scholar Zhu, X., et al. 2021, in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 13149Google Scholar You have Access Open access Related content AI-generated results: by UNSILO [Opens in a new window] Radio Continuum Surveys with Square Kilometre Array Pathfinders Type Article Title Radio Continuum Surveys with Square Kilometre Array Pathfinders Authors Ray P. Norris , J. Afonso , D. Bacon , Rainer Beck , Martin Bell , R. J. Beswick , Philip Best , Sanjay Bhatnagar , Annalisa Bonafede , Gianfranco Brunetti , Tam\u00e1s Budav\u00e1ri , Rossella Cassano , J. J. Condon , Catherine Cress , Arwa Dabbech , I. Feain , Rob Fender , Chiara Ferrari , B. M. Gaensler , G. Giovannini , Marijke Haverkorn , George Heald , Kurt Van der Heyden , A. M. Hopkins , M. Jarvis , Melanie Johnston-Hollitt , Roland Kothes , Huib Van Langevelde , Joseph Lazio , Minnie Y. Mao , Alejo Mart\u00ednez-Sansigre , David Mary , Kim Mcalpine , E. Middelberg , Eric Murphy , P. Padovani , Zsolt Paragi , I. Prandoni , A. Raccanelli , Emma Rigby , I. G. Roseboom , H. R\u00f6ttgering , Jose Sabater , Mara Salvato , Anna M. M. Scaife , Richard Schilizzi , N. Seymour , Dan J. B. Smith , Grazia Umana , G.-B. Zhao  and Peter-Christian Zinn   Journal Publications of the Astronomical Society of Australia Published online: 27 March 2013 Deep learning for morphological identification of extended radio galaxies using weak labels Type Article Title Deep learning for morphological identification of extended radio galaxies using weak labels Authors Nikhel Gupta , Zeeshan Hayder , Ray P. Norris , Minh Huynh , Lars Petersson , X. Rosalind Wang , Heinz Andernach , B\u00e4rbel S. Koribalski , Miranda Yew  and Evan J. Crawford   Journal Publications of the Astronomical Society of Australia Published online: 7 September 2023 The First Large Absorption Survey in H i (FLASH): I. Science goals and survey design Type Article Title The First Large Absorption Survey in H i (FLASH): I. Science goals and survey design Authors James R. Allison , E. M. Sadler , A. D. Amaral , T. An , S. J. Curran , J. Darling , A. C. Edge , S. L. Ellison , K. L. Emig , B. M. Gaensler , L. Garratt-Smithson , M. Glowacki , K. Grasha , B. S. Koribalski , C. del P. Lagos , P. Lah , E. K. Mahony , S. A. Mao , R. Morganti , V. A. Moss , M. Pettini , K. A. Pimbblet , C. Power , P. Salas , L. Staveley-Smith , M. T. Whiting , O. I. Wong , H. Yoon , Z. Zheng  and M. A. Zwaan   Journal Publications of the Astronomical Society of Australia Published online: 21 March 2022 Discovery of peculiar radio morphologies with ASKAP using unsupervised machine learning Type Article Title Discovery of peculiar radio morphologies with ASKAP using unsupervised machine learning Authors Nikhel Gupta , Minh Huynh , Ray P. Norris , X. Rosalind Wang , Andrew M. Hopkins , Heinz Andernach , B\u00e4rbel S. Koribalski  and Tim J. Galvin   Journal Publications of the Astronomical Society of Australia Published online: 20 October 2022 EMU: Evolutionary Map of the Universe Type Article Title EMU: Evolutionary Map of the Universe Authors Ray P. Norris , A. M. Hopkins , J. Afonso , S. Brown , J. J. Condon , L. Dunne , I. Feain , R. Hollow , M. Jarvis , M. Johnston-Hollitt , E. Lenc , E. Middelberg , P. Padovani , I. Prandoni , L. Rudnick , N. Seymour , G. Umana , H. Andernach , D. M. Alexander , P. N. Appleton , D. Bacon , J. Banfield , W. Becker , M. J. I. Brown , P. Ciliegi , C. Jackson , S. Eales , A. C. Edge , B. M. Gaensler , G. Giovannini , C. A. Hales , P. Hancock , M. T. Huynh , E. Ibar , R. J. Ivison , R. Kennicutt , Amy E. Kimball , A. M. Koekemoer , B. S. Koribalski , \u00c1. R. L\u00f3pez-S\u00e1nchez , M. Y. Mao , T. Murphy , H. Messias , K. A. Pimbblet , A. Raccanelli , K. E. Randall , T. H. Reiprich , I. G. Roseboom , H. R\u00f6ttgering , D. J. Saikia , R. G. Sharp , O. B. Slee , Ian Smail , M. A. Thompson , J. S. Urquhart , J. V. Wall  and G.-B. Zhao   Journal Publications of the Astronomical Society of Australia Published online: 2 January 2013 Science with the Australian Square Kilometre Array Pathfinder Type Article Title Science with the Australian Square Kilometre Array Pathfinder Authors Journal Publications of the Astronomical Society of Australia Published online: 5 March 2013 ASKAP commissioning observations of the GAMA 23 field Type Article Title ASKAP commissioning observations of the GAMA 23 field Authors Denis A. Leahy , A. M. Hopkins , R. P. Norris , J. Marvil , J. D. Collier , E. N. Taylor , J. R. Allison , C. Anderson , M. Bell , M. Bilicki , J. Bland-Hawthorn , S. Brough , M. J. I. Brown , S. Driver , G. Gurkan , L. Harvey-Smith , I. Heywood , B. W. Holwerda , J. Liske , A. R. Lopez-Sanchez , D. McConnell , A. Moffett , M. S. Owers , K. A. Pimbblet , W. Raja , N. Seymour , M. A. Voronkov  and L. Wang   Journal Publications of the Astronomical Society of Australia Published online: 19 July 2019 The Evolutionary Map of the Universe pilot survey Type Article Title The Evolutionary Map of the Universe pilot survey Authors Ray P. Norris , Joshua Marvil , J. D. Collier , Anna D. Kapi\u0144ska , Andrew N. O\u2019Brien , L. Rudnick , Heinz Andernach , Jacobo Asorey , Michael J. I. Brown , Marcus Br\u00fcggen , Evan Crawford , Jayanne English , Syed Faisal ur Rahman , Miroslav D. Filipovi\u0107 , Yjan Gordon , G\u00fclay G\u00fcrkan , Catherine Hale , Andrew M. Hopkins , Minh T. Huynh , Kim HyeongHan , M. James Jee , B\u00e4rbel S. Koribalski , Emil Lenc , Kieran Luken , David Parkinson , Isabella Prandoni , Wasim Raja , Thomas H. Reiprich , Christopher J. Riseley , Stanislav S. Shabala , Jaimie R. Sheil , Tessa Vernstrom , Matthew T. Whiting , James R. Allison , C. S. Anderson , Lewis Ball , Martin Bell , John Bunton , T. J. Galvin , Neeraj Gupta , Aidan Hotan , Colin Jacka , Peter J. Macgregor , Elizabeth K. Mahony , Umberto Maio , Vanessa Moss , M. Pandey-Pommier  and Maxim A. Voronkov   Journal Publications of the Astronomical Society of Australia Published online: 7 September 2021 SPT-CL J2032\u20135627: A new Southern double relic cluster observed with ASKAP Type Article Title SPT-CL J2032\u20135627: A new Southern double relic cluster observed with ASKAP Authors S. W. Duchesne , M. Johnston-Hollitt , I. Bartalucci , T. Hodgson  and G. W. Pratt   Journal Publications of the Astronomical Society of Australia Published online: 18 January 2021 Remnant radio galaxies discovered in a multi-frequency survey Type Article Title Remnant radio galaxies discovered in a multi-frequency survey Authors Benjamin Quici , Natasha Hurley-Walker , Nicholas Seymour , Ross J. Turner , Stanislav S. Shabala , Minh Huynh , H. Andernach , Anna D. Kapi\u0144ska , Jordan D. Collier , Melanie Johnston-Hollitt , Sarah V. White , Isabella Prandoni , Timothy J. Galvin , Thomas Franzen , C. H. Ishwara-Chandra , Sabine Bellstedt , Steven J. Tingay , Bryan M. Gaensler , Andrew O\u2019Brien , Johnathan Rogers , Kate Chow , Simon Driver  and Aaron Robotham   Journal Publications of the Astronomical Society of Australia Published online: 9 February 2021 Librarians Authors Publishing partners Agents Corporates Accessibility Our blog News Contact and help Cambridge Core legal notices Feedback Sitemap Select your country preference Afghanistan Aland Islands Albania Algeria American Samoa Andorra Angola Anguilla Antarctica Antigua and Barbuda Argentina Armenia Aruba Australia Austria Azerbaijan Bahamas Bahrain Bangladesh Barbados Belarus Belgium Belize Benin Bermuda Bhutan Bolivia Bosnia and Herzegovina Botswana Bouvet Island Brazil British Indian Ocean Territory Brunei Darussalam Bulgaria Burkina Faso Burundi Cambodia Cameroon Canada Cape Verde Cayman Islands Central African Republic Chad Channel Islands, Isle of Man Chile China Christmas Island Cocos (Keeling) Islands Colombia Comoros Congo Congo, The Democratic Republic of the Cook Islands Costa Rica Cote D'Ivoire Croatia Cuba Cyprus Czech Republic Denmark Djibouti Dominica Dominican Republic East Timor Ecuador Egypt El Salvador Equatorial Guinea Eritrea Estonia Ethiopia Falkland Islands (Malvinas) Faroe Islands Fiji Finland France French Guiana French Polynesia French Southern Territories Gabon Gambia Georgia Germany Ghana Gibraltar Greece Greenland Grenada Guadeloupe Guam Guatemala Guernsey Guinea Guinea-bissau Guyana Haiti Heard and Mc Donald Islands Honduras Hong Kong Hungary Iceland India Indonesia Iran, Islamic Republic of Iraq Ireland Israel Italy Jamaica Japan Jersey Jordan Kazakhstan Kenya Kiribati Korea, Democratic People's Republic of Korea, Republic of Kuwait Kyrgyzstan Lao People's Democratic Republic Latvia Lebanon Lesotho Liberia Libyan Arab Jamahiriya Liechtenstein Lithuania Luxembourg Macau Macedonia Madagascar Malawi Malaysia Maldives Mali Malta Marshall Islands Martinique Mauritania Mauritius Mayotte Mexico Micronesia, Federated States of Moldova, Republic of Monaco Mongolia Montenegro Montserrat Morocco Mozambique Myanmar Namibia Nauru Nepal Netherlands Netherlands Antilles New Caledonia New Zealand Nicaragua Niger Nigeria Niue Norfolk Island Northern Mariana Islands Norway Oman Pakistan Palau Palestinian Territory, Occupied Panama Papua New Guinea Paraguay Peru Philippines Pitcairn Poland Portugal Puerto Rico Qatar Reunion Romania Russian Federation Rwanda Saint Kitts and Nevis Saint Lucia Saint Vincent and the Grenadines Samoa San Marino Sao Tome and Principe Saudi Arabia Senegal Serbia Seychelles Sierra Leone Singapore Slovakia Slovenia Solomon Islands Somalia South Africa South Georgia and the South Sandwich Islands Spain Sri Lanka St. Helena St. Pierre and Miquelon Sudan Suriname Svalbard and Jan Mayen Islands Swaziland Sweden Switzerland Syrian Arab Republic Taiwan Tajikistan Tanzania, United Republic of Thailand Togo Tokelau Tonga Trinidad and Tobago Tunisia Turkey Turkmenistan Turks and Caicos Islands Tuvalu Uganda Ukraine United Arab Emirates United Kingdom United States United States Minor Outlying Islands United States Virgin Islands Uruguay Uzbekistan Vanuatu Vatican City Venezuela Vietnam Virgin Islands (British) Wallis and Futuna Islands Western Sahara Yemen Zambia Zimbabwe Join us online Rights & Permissions Copyright Privacy Notice Terms of use Cookies Policy \u00a9 Cambridge University Press 2024",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "AI-Enhanced Teaching Materials for Education: A Shift Towards Digitalization",
    "doi": "10.61707/j6sa1w36",
    "description": "Considering recent technological advances and the growing prevalence of digitalization, Islamic educational instruction and t raining will need to adopt a fresh perspective. The field of artificial intelligence offers a path for additional research that has the potential to have a favorable impact on both the efficiency and the development of competencies. This article describes the process followed to create multimedia-based teaching materials for Islamic religious education subjects used in Senior High Schools in West Sumatra. These materials were designed to assist Islamic education students with their academic pursuits. While developing this model, the ADDIE (Analysis, Design, Development, Implementation, and Evaluation) services that Dick and Carry developed were utilized during the design phase. In Islamic education, students engage in hands-on learning by interacting with previously crafted designs and observing how an evaluation of the model is built through time. These findings, implications, and potential future research areas involving artificial intelligence in Islamic religious education and traini ng at Indonesia's senior high school level will be discussed.",
    "journal": "International Journal of Religion",
    "authors": [
      "Syahrizal S.",
      "Yasmi F.",
      "Mary T."
    ],
    "citation_count": "0",
    "full_text": "CURRENT ARCHIVES ANNOUNCEMENTS ABOUT SUBMISSIONS SEARCH Register Login HOME / ARCHIVES / VOL. 5 NO. 1 (2024) / Articles AI-Enhanced Teaching Materials for Education: A Shift Towards Digitalization S Syahrizal Universitas PGRI Sumatera Barat, Padang, Indonesia Fifi Yasmi Universitas PGRI Sumatera Barat, Padang, Indonesia Thomson Mary Universitas PGRI Sumatera Barat, Padang, Indonesia DOI: https://doi.org/10.61707/j6sa1w36 Keywords: Artificial Intelligence, Education, Islamic Education, Students, Teaching Materials ABSTRACT Considering recent technological advances and the growing prevalence of digitalization, Islamic educational instruction and training will need to adopt a fresh perspective. The field of artificial intelligence offers a path for additional research that has the potential to have a favorable impact on both the efficiency and the development of competencies. This article describes the process followed to create multimedia-based teaching materials for Islamic religious education subjects used in Senior High Schools in West Sumatra. These materials were designed to assist Islamic education students with their academic pursuits. While developing this model, the ADDIE (Analysis, Design, Development, Implementation, and Evaluation) services that Dick and Carry developed were utilized during the design phase. In Islamic education, students engage in hands-on learning by interacting with previously crafted designs and observing how an evaluation of the model is built through time. These findings, implications, and potential future research areas involving artificial intelligence in Islamic religious education and training at Indonesia's senior high school level will be discussed. PDF PUBLISHED 2024-01-19 ISSUE Vol. 5 No. 1 (2024) SECTION Articles LICENSE This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. CC Attribution-NonCommercial-NoDerivatives 4.0 HOW TO CITE AI-Enhanced Teaching Materials for Education: A Shift Towards Digitalization. (2024). International Journal of Religion, 5(1), 203-217. https://doi.org/10.61707/j6sa1w36 MORE CITATION FORMATS Similar Articles Al-Qawabah R. H, The Impact of Artificial Intelligence on Students in the First Three Grades in Basic Schools in the City of Amman-Jordan from The Perspective of Their Teachers , International Journal of Religion: Vol. 5 No. 2 (2024) Zulfikar Ali Buto Siregar, Jarudin ., Evolution of Islamic Education Teachers' Competence in Indonesia , International Journal of Religion: Vol. 5 No. 4 (2024) Mohd Lokman Sapiee, Nurshahira Ibrahim, Faridah Che Husain, Maziah Mahmud, Abu Bakar Jaafar, Md Hamzaimi Azrol Md. Baharudin, How can Creativity be Enhanced through Personality Traits and Emotional Intelligence Towards Muslim Employees? , International Journal of Religion: Vol. 5 No. 2 (2024) Dong Huong Lan, Current Situation of Teaching and Learning Elective Sports Subjects for Non-Major Students of Hong Duc University , International Journal of Religion: Vol. 5 No. 2 (2024) Mohammad Fahmi Abdul Hamid, Muhamad Hanif Jofri, Khairul Azhar Meerangani, Norazmi Anas, Mohd Farhan Md Ariffin, Muhammad Afif Ab Arif, Muhammad Taufik Bin Md Sharipp, The Quality of Experience of Integrated Management Tahfiz Model (IM-Tahfiz) in Malaysian Education , International Journal of Religion: Vol. 5 No. 2 (2024) Rocio Katherine Ramos Barrera, Digna Luz Zapata Barrera, Jessica del Pilar Ramos Barrera, Pedagogy Applied in the Teaching Process in Regular Basic Education (EBR): Systematic Review Article , International Journal of Religion: Vol. 5 No. 1 (2024) Zainab Taher Tawfiq Abu Al-Hamad, The Effectiveness of The Mental Thinking Stimulation Model in Developing Probing Thinking in Statistics and Reducing Mental Wandering Among Female Students in The Psychology Department at Najran University , International Journal of Religion: Vol. 5 No. 1 (2024) Lee, Chih Ying, Li, Kun Chung, AIGC-Assisted Instructional Design for the Self-Regulated Learning Course on \"Implementing 2D Animation for the Ziyun Temple Stories\" , International Journal of Religion: Vol. 5 No. 1 (2024) Nursyuhada Ab Wahab, Melor Md Yunus, Harwati Hashim, Blended Language Learning Strategies used among Religious School Leavers in an English Language Course , International Journal of Religion: Vol. 5 No. 3 (2024) Sizwe Marcus Mahlangu, Thokozani Isaac Mtshali, Inclusive Education Strategies for Knowledge Development of Teachers Enrolled in the Advanced Vocational and Training Education Program , International Journal of Religion: Vol. 5 No. 3 (2024) 1-10 of 124 NEXT You may also start an advanced similarity search for this article. LATEST PUBLICATIONS INFORMATION For Readers For Authors For Librarians MAKE A SUBMISSION KEYWORDS catholics law marriage non-catholics vietnam indian migrant physical strain workplace safety gulf countries thaipusam murugan cultural continuum kavadi expert consensus hamka sustainability entrepreneurship fintech malaysia islamic fintech nonexistence annulment lawsuit denial decision Dr. Harper Smith, Managing Editor International Journal of Religion ISSN: 2633-352X | e-ISSN: 2633-3538 Scopus Indexed : https://www.scopus.com/sourceid/21101158583 E-mail: editor@ijor.co.uk  ",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "Diabetes and its associated factors: A Retrospective cohort analysis of a large database at Indus Hospital Health Network",
    "doi": "10.12669/pjms.40.2(ICON).8948",
    "description": "Objectives: This is a retrospective cohort analysis of diabetes and its associated factors from Electronic Medical Record (EMR) of 2020-2022 of Indus Hospital Health Network (IHHN), Korangi campus Karachi. Methods: Retrospective cohort study was conducted at Indus Hospital & Health Network (IHHN), Korangi Karachi. Out-patient records of adult patients of 2020-2022 were extracted from EMR of IHHN in March 2023. Descriptive statistics were presented as median (IQR) and frequency and percentage. Chi-square test determined association of risk-factors with diabetes and Wilcoxon-sign-rank test compared change in HbA1C from baseline. Results: Data of 460,799 adult patients were extracted and analyzed. Median age of patients was 38.71 (27.8752) years. Female preponderance was observed in our study. Out of 460,799, HbA1C was seen in 42,638 (9.25%) patients. Among these 29,596 (69.4%) had a HbA1C \u2265 6.5% while 13,042 (30.6%) had a HbA1C in the pre-diabetes range. Significant association was found between age, baseline creatinine, LDL and diabetes with no association depicted between gender, BMI, blood pressure, triglycerides, HDL and diabetes status. Patients in general had higher HbA1C at baseline as compared to last visit (p-value<0.001). Conclusion: High blood pressure, obesity, increased creatinine, micro albuminurea, high LDL and Triglycerides were important risk factors for diabetes. This study reports a snap shot of the status of diabetes and associated risk-factors in the Pakistani population. This was the first time that a large data was extracted and analyzed from a healthcare institution in Pakistan, which would guide physicians and public health practitioners to take evidence-based decisions for prevention and management of diabetes.",
    "journal": "Pakistan Journal of Medical Sciences",
    "authors": [
      "Amin F.",
      "Imran M.",
      "Hafeez S.A.",
      "Zehra B."
    ],
    "citation_count": "1",
    "full_text": "Pakistan Journal of Medical Sciences Current Archives Past Issues (2013-2018) Past Issues (2002-2012) About Advertising Search Register Login Home / Archives / Vol. 40 No. 2(ICON) (2024): ICON Supplement 2024 / Original Articles Diabetes and its associated factors: A Retrospective cohort analysis of a large database at Indus Hospital Health Network Faridah Amin Muhammad Imran Syed Asif Hafeez Beenish Zehra DOI: https://doi.org/10.12669/pjms.40.2(ICON).8948 Keywords: Diabetes in Pakistan, Non-communicable diseases in Pakistan, Diabetes Registry Pakistan, NCD Registry Pakistan Abstract Objectives: This is a retrospective cohort analysis of diabetes and its associated factors from Electronic Medical Record (EMR) of 2020-2022 of Indus Hospital Health Network (IHHN), Korangi campus Karachi. Methods: Retrospective cohort study was conducted at Indus Hospital & Health Network (IHHN), Korangi Karachi. Out-patient records of adult patients of 2020-2022 were extracted from EMR of IHHN in March 2023. Descriptive statistics were presented as median (IQR) and frequency and percentage. Chi-square test determined association of risk-factors with diabetes and Wilcoxon-sign-rank test compared change in HbA1C from baseline.   Results: Data of 460,799 adult patients were extracted and analyzed. Median age of patients was 38.71 (27.87-52) years. Female preponderance was observed in our study. Out of 460,799, HbA1C was seen in 42,638 (9.25%) patients. Among these 29,596 (69.4%) had a HbA1C \u2265 6.5% while 13,042 (30.6%) had a HbA1C in the pre-diabetes range. Significant association was found between age, baseline creatinine, LDL and diabetes with no association depicted between gender, BMI, blood pressure, triglycerides, HDL and diabetes status. Patients in general had higher HbA1C at baseline as compared to last visit (p-value<0.001).   Conclusion: High blood pressure, obesity, increased creatinine, micro albuminurea, high LDL and Triglycerides were important risk factors for diabetes. This study reports a snap shot of the status of diabetes and associated risk-factors in the Pakistani population. This was the first time that a large data was extracted and analyzed from a healthcare institution in Pakistan, which would guide physicians and public health practitioners to take evidence-based decisions for prevention and management of diabetes. doi: https://doi.org/10.12669/pjms.40.2(ICON).8948 How to cite this: Amin F, Imran M, Hafeez SA, Zehra B. Diabetes and its associated factors: A Retrospective cohort analysis of a large database at Indus Hospital Health Network. Pak J Med Sci. 2024;40(2):S10-S14. doi: https://doi.org/10.12669/pjms.40.2(ICON).8948 This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. PDF Published 2023-12-05 How to Cite Amin, F., Imran, M., Hafeez, S. A., & Zehra, B. (2023). Diabetes and its associated factors: A Retrospective cohort analysis of a large database at Indus Hospital Health Network. Pakistan Journal of Medical Sciences, 40(2(ICON). https://doi.org/10.12669/pjms.40.2(ICON).8948 More Citation Formats Issue Vol. 40 No. 2(ICON) (2024): ICON Supplement 2024 Section Original Articles Most read articles by the same author(s) Syeda Bushra Ahmed, Aisha Qamar, Muhammad Imran, Muhammad Faisal Fahim, Comparison of neck length, relative neck length and height with incidence of cervical spondylosis , Pakistan Journal of Medical Sciences: Vol. 36 No. 2 (2020): January \u2013 February 2020 Fivzia Herekar, Samreen Sarfaraz, Muhammad Imran, Nida Ghouri, Saba Shahid, Marvi Mahesar, Clinical spectrum and outcomes of patients with different resistance patterns of Salmonella enterica , Pakistan Journal of Medical Sciences: Vol. 38 No. ICON-2022 (2022): ICON 2022 Supplement Make a Submission Pak J Med Sci at PubMed Central Information For Readers For Authors For Librarians   Pakistan Journal of Medical Sciences is published by PROFESSIONAL MEDICAL PUBLICATIONS Office # 701, Seventh Floor, Business Center, PECHS, Shahrah-e-Faisal, Karachi-Pakistan. Phones: +92-021-34324732  & +92-021-34324733 Email: pjms@pjms.org.pk",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "Privacy-preserving federated learning based on partial low-quality data",
    "doi": "10.1186/s13677-024-00618-8",
    "description": "Traditional machine learning requires collecting data from participants for training, which may lead to malicious acquisition of privacy in participants\u2019 data. Federated learning provides a method to protect participants\u2019 data privacy by transferring the training process from a centralized server to terminal devices. However, the server may still obtain participants\u2019 privacy through inference attacks and other methods. In addition, the data provided by participants varies in quality, and the excessive involvement of low-quality data in the training process can render the model unusable, which is an important issue in current mainstream federated learning. To address the aforementioned issues, this paper proposes a Privacy Preserving Federated Learning Scheme with Partial Low-Quality Data (PPFL-LQDP). It can achieve good training results while allowing participants to utilize partial low-quality data, thereby enhancing the privacy and security of the federated learning scheme. Specifically, we use a distributed Paillier cryptographic mechanism to protect the privacy and security of participants\u2019 data during the Federated training process. Additionally, we construct composite evaluation values for the data held by participants to reduce the involvement of low-quality data, thereby minimizing the negative impact of such data on the model. Through experiments on the MNIST dataset, we demonstrate that this scheme can complete the model training of federated learning with the participation of partial low-quality data, while effectively protecting the security and privacy of participants\u2019 data. Comparisons with related schemes also show that our scheme has good overall performance.",
    "journal": "Journal of Cloud Computing",
    "authors": [
      "Wang H.",
      "Wang Q.",
      "Ding Y.",
      "Tang S.",
      "Wang Y."
    ],
    "citation_count": "0",
    "full_text": "Typesetting math: 100% Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Advertisement Search Get published Explore Journals Books About Login Journal of Cloud Computing Advances, Systems and Applications About Articles Submission Guidelines Submit manuscript Research Open access Published: 18 March 2024 Privacy-preserving federated learning based on partial low-quality data Huiyong Wang, Qi Wang, Yong Ding, Shijie Tang & Yujue Wang  Journal of Cloud Computing  13, Article number: 62 (2024) Cite this article 87 Accesses Metrics Abstract Traditional machine learning requires collecting data from participants for training, which may lead to malicious acquisition of privacy in participants\u2019 data. Federated learning provides a method to protect participants\u2019 data privacy by transferring the training process from a centralized server to terminal devices. However, the server may still obtain participants\u2019 privacy through inference attacks and other methods. In addition, the data provided by participants varies in quality, and the excessive involvement of low-quality data in the training process can render the model unusable, which is an important issue in current mainstream federated learning. To address the aforementioned issues, this paper proposes a Privacy Preserving Federated Learning Scheme with Partial Low-Quality Data (PPFL-LQDP). It can achieve good training results while allowing participants to utilize partial low-quality data, thereby enhancing the privacy and security of the federated learning scheme. Specifically, we use a distributed Paillier cryptographic mechanism to protect the privacy and security of participants\u2019 data during the Federated training process. Additionally, we construct composite evaluation values for the data held by participants to reduce the involvement of low-quality data, thereby minimizing the negative impact of such data on the model. Through experiments on the MNIST dataset, we demonstrate that this scheme can complete the model training of federated learning with the participation of partial low-quality data, while effectively protecting the security and privacy of participants\u2019 data. Comparisons with related schemes also show that our scheme has good overall performance. Introduction In recent years, machine learning technology has greatly benefited from the development of computing processors and data acquisition methods, expanding its practical applications and improving its effectiveness [1]. Cloud computing platforms provide high-performance computing resources, enabling large-scale data processing and model training. The diversity of data also allows machine learning to be more accurate and reliable in applications such as prediction, classification, and recommendation systems. For example, the biotechnology company Berg [2] utilizes a machine learning platform to analyze extensive biological outcome data from patients (including lipids, metabolites, enzymes, and protein spectra) to emphasize critical distinctions between diseased cells and healthy cells and to identify novel cancer mechanisms. In cases where machine learning involves multiple participants, participants are required to upload their data to a third-party server, which aims to collect large and diverse datasets for training to obtain more reliable models [3]. Most of these data are sourced from edge devices such as smartphones, glucose monitors, GPS devices, and the like. However, this data often contains participants\u2019 sensitive information, such as medical records and travel history [4]. Unauthorized access to this sensitive information could result in significant harm. Furthermore, in certain specialized industries, data sharing is not permitted [5]. Therefore, protecting the privacy of participants\u2019 data while conducting machine learning becomes of paramount importance. Federated Learning [6] is a distributed machine learning solution proposed by Google in 2016. It aims to protect data privacy by training models on local devices. The goal is to transfer the training process of data to edge devices where participants train model parameters (gradients) on their local environments. In each iteration, participants only provide local gradient information to the server, and the cloud server aggregates the local gradients using aggregation algorithms (e.g.FedAvg) [7] to obtain updates for the global model. While Federated Learning addresses the issue of \u201cdata silos\u201d and mitigates privacy risks for participants, it still involves certain privacy-related concerns. Recent research has shown that malicious attackers can potentially infer sensitive participant data by analyzing the local gradients and global parameter information uploaded by participants [8, 9]. Additionally, due to varying levels of expertise and the advanced nature of data collection devices, the quality of data provided by participants may vary [10]. For example, in the context of autonomous driving [11], different vehicle models collecting road data may not guarantee global consistency, resulting in significant variations in data quality. Vehicles equipped with better perception systems often provide higher-quality data compared to those with inferior systems. Furthermore, even if a vehicle is equipped with a high-quality perception system, it does not guarantee that the collected data is absolutely complete and accurate, as error-prone perception systems or data recording processes may introduce significant errors. The involvement of a large amount of low-quality data in training can directly lead to a decrease in the accuracy of the final model or render it unusable. Therefore, introducing functionality to handle low-quality data in privacy-preserving federated learning is of practical significance. Contributions To the aforementioned issues, this paper proposes a privacy-preserving federated learning scheme that allows partial low-quality data to participate in training. Based on the distributed Paillier cryptosystem [12], our approach enables participants to perform offline training on their local datasets after receiving the global gradient parameters. They then engage in collaborative learning by transmitting their local gradient parameters to other participants. To prevent member inference attacks, we employ distributed Paillier homomorphic encryption to protect the transmitted gradient data. The main contributions of this work are as follows: We have developed an evaluation algorithm called DCEM(Data Composite Evaluation Method) to assess the quality of participant data. Based on a composite rating of data quality, we control the level of participation of data in the global iterations of Federated training, aiming to mitigate the negative impact of low-quality data on model accuracy; By using a single-cloud outsourcing approach, we transfer complex computations to a cloud server in order to reduce the computational burden on participants and improve the inclusiveness of the model for participants with limited computing capabilities; By utilizing the distributed Paillier homomorphic encryption mechanism, we have introduced a federated learning multi-party aggregation scheme that allows partial low-quality data to participate in training. This scheme effectively ensures the privacy and security of participants\u2019 private data while being user-friendly for participants to join or exit midway. Experimental results have shown that this scheme exhibits excellent overall performance. Organization The rest of this paper is organized as follows. Related work section gives a brief overview of related work. Preliminaries section describes the prerequisites. System model section discusses the system model and security requirements, Our proposed scheme and Security analysis sections describe the proposed scheme in detail and analyze its security. Subsequently, in Performance analysis section, the expenses and accuracy will be introduced through experiments. Finally, Conclusion section offers a summary of the entire document. Related work To address privacy leakage concerns in federated learning, researchers have proposed various solutions leveraging privacy protection technologies such as differential privacy [13], homomorphic encryption [14], and secure multi-party computation [15]. Haokun Fang et al. [16] proposed a federated learning scheme based on the Paillier additive homomorphic algorithm. The core idea is that all participants encrypt their local gradients that need to be uploaded using Paillier homomorphic encryption. The server aggregates these encrypted gradients iteratively and uses the Federated multi-layer perceptron algorithm to reduce communication overhead. However, all participants use the same public key, which could potentially lead to a model being compromised by malicious participants. Jaehyoung Park et al. [17] addressed this issue by constructing a multi-key homomorphic encryption scheme to protect participants\u2019 local gradients. Since each participant holds different public and private keys, it effectively prevents malicious participation. During the iteration of global gradient updates, a joint decryption method is used, allowing the cloud server to operate in plaintext, thereby reducing the computational burden on the cloud server during the Federated training process. However, achieving collusion resistance among multiple computation servers required for joint decryption is a significant challenge. However, none of the above-mentioned schemes have considered the issue of involving partial low-quality data in Federated training. When low-quality data excessively participates in the Federated training process described in those schemes, it can potentially result in a decrease in model accuracy or even render the model unusable. According to my knowledge, Lingchen Zhao et al. [18] was the first to consider the participation of participants holding partial low-quality data in federated learning by employing differential privacy. They achieved privacy protection by adding noise to perturb the training of neural networks and manipulating the target data. However, recent research has suggested that existing differential privacy mechanisms may not adequately balance privacy and acceptable utility in complex tasks. Yu Han et al. [19] proposed a fair incentive scheme called the Federated Learning Incentivizer, which dynamically adjusts participants\u2019 contributions based on three criteria to ensure that participants are not treated unfairly during training. However, the scheme lacks universality and fails to consider the impact of incentive strategies on data security. Guowen Xu et al. [20] proposed a method called MethIU, which uses the chi-square distribution to describe the reliability of participant data in federated learning. They employed garbled circuits and homomorphic encryption techniques to construct secure protocols for multiplication and division operations between two parties. Additionally, they improved the efficiency of the multiplication protocol. MethIU ensures that participants\u2019 reliable information is not leaked, avoiding the occurrence of training discrimination during the training process. It enables fair and equitable participation of all parties and leverages the reliability of participants to influence their involvement in global model iteration, thereby improving model accuracy. However, the dual-cloud structure of MethIU imposes significant costs on demanders, and this method is not resilient against collusion attacks between cloud servers and between cloud servers and participants. In subsequent work, Guowen Xu et al. [21] proposed a privacy-preserving single-cloud federated learning scheme (EPPFL) using the threshold Paillier homomorphic encryption mechanism. They analyzed the composition of low-quality data and employed SchUU for data evaluation, reducing the involvement of low-quality data in the Federated training process and addressing the collusion problem among servers. However, SchUU may discard some low-quality data, which can be considered unreasonable. According to the literature review, existing federated learning schemes that support the participation of partial low-quality data while preserving privacy still face challenges regarding data integrity and privacy protection. Addressing these issues is crucial for the application of federated learning, which has motivated our research in this area. Preliminaries Federated learning The data in federated learning can be classified into three types: horizontal federated learning, vertical federated learning, and Federated transfer learning [22]. This paper primarily focuses on horizontal federated learning, where participants have diverse features, but their data has little to no overlap. Horizontal federated learning refers to the scenario where participants are distributed across different regions or organizations. Each participant possesses a private dataset, and the features among participants are diverse, and characterized by a high quantity and dimensionality. In horizontal federated learning, there may be differences in the data among participants, but their feature spaces have little to no overlap. In contrast, vertical federated learning pertains to scenarios where the feature spaces among participants overlap, but each participant possesses different sample data. On the other hand, Federated transfer learning involves participants with overlapping features and samples, but with potentially different task objectives. In this paper, we primarily focus on investigating and exploring the scenario of horizontal federated learning, where participants possess large-scale feature data but have minimal overlap in their feature spaces. DNN (Deep Neural Network) serves various machine learning scenarios. This paper implements federated learning using a fully connected neural network. As shown in Fig. 1, DNN typically consists of an input layer, an output layer, and several hidden layers, with weights ( ) used to establish fully connected connections between neurons. Given a data set (x, y), where , , DNN can be used as a function to describe the relationship between an input value and a label. That is , , DNN searches for the optimal parameter that best reflects the relationship between data and labels and make the output value wirelessly close to the real label. Fig. 1 Total neural network structure diagram Full size image In federated learning, processing a large amount of data during training for each iteration can lead to significant computational costs. To address this problem, the technique of mini-batch stochastic gradient descent (SGD) [23] can be employed, which is a common approach in previous works. Mini-batch SGD improves convergence speed and efficiency by randomly selecting a smaller subset of the data for each iteration instead of using all the data. In mini-batch SGD, the data is strategically divided into small batches to avoid computation on the entire dataset in each iteration. This approach not only reduces computational burden but also introduces beneficial noise during the learning process, helping to avoid getting stuck in local optima and improving generalization performance. Specifically, given a training set , we first define the loss function , Where , and represents the 2-norm of a vector. In iteration, the participants randomly selects part of the held data, where . Then participants only used the selected data to participate in the training in this round of iteration and uploaded the local gradient information to the cloud server for aggregation. So in federated learning, can update the weight as: (1) Finally, the cloud server will broadcast to each participant to iterate the participant data again until our preset convergence conditions are met. Distributed paillier cryptosystem Our solution utilizes the distributed Paillier cryptosystem to achieve secure aggregation, as depicted in Fig. 2. The distributed Paillier cryptosystem offers several advantages in practical applications. Firstly, by setting a threshold, we can decompose the private key and distribute partial private keys to the participants. By collecting a sufficient number of partially decrypted ciphertexts, we can aggregate them to obtain the plaintext information. Secondly, the distributed Paillier cryptosystem satisfies additive homomorphism, meaning that we can perform addition operations on the plaintext by conducting multiplication operations on the ciphertext. This property allows us to protect data privacy while performing secure aggregation. By utilizing the distributed Paillier cryptosystem, we ensure secure aggregation while preserving data privacy, enabling efficient computations. Fig. 2 \u201cSAP\u201d decryption diagram Full size image The distributed paillier cryptosystem can be divided into four parts: key generation, private key splitting, encryption algorithm and decryption algorithm. Key generation: Let be the security parameter, p and q are two randomly selected large prime numbers of the same length, calculate and . The public key is set to and the private key is set to . where lcm represents the calculation of the least common multiple between two numbers. Private key splitting: Let\u2019s choose satisfy both and . And then we define a polynomial ; where is random numbers selected in . are n different non-zero elements known by each party. Part of the private key is , send to participant. Encryption algorithm: For a given plaintext m we choose a random number , ciphertext c can be generated as ; where . Decryption algorithm: Partial decryption of ciphertext c by partial private keys held by the participant;For convenience, we use to represent partial decryption results. Because according to the Chinese residual theorem: , . Each user holding part of the private key partially decrypts the ciphertext, obtains the partial decryption result, and sends the result to the cloud server. After receiving the decryption result, the cloud server aggregates the plaintext by the method described in the document [24]. System model System architecture As shown in Fig. 3, this paper considers a system framework with two entities: participants and cloud server. Collaboration between these two entities is essential for federated learning. Specifically, before federated training started, all participants agreed to use the DNN model for training. In each iteration, participants use the received global gradients to train their local data to obtain the local gradient set, cooperate with the cloud server to calculate the composite evaluation value of the data, and then encrypt and upload to the cloud server. The cloud server obtains the local gradient data of participants and the composite evaluation value of the data, updates the global model, and broadcasts it to each participant. This process is repeated until the DNN model reaches the convergence criterion. During this iteration, participants collaborate with the cloud server by transmitting their local gradients, allowing them to jointly train a global model. This federated learning framework enables participants to share and merge their model updates while protecting data privacy and resisting the intrusion of low-quality data over participation in training, aiming to improve the overall learning performance. Fig. 3 System model Full size image During this process, the local gradients of participants are considered private data. To ensure the privacy and security of participant data, a secure aggregation framework is introduced using the distributed Paillier homomorphic encryption mechanism. Distributed homomorphic encryption allows participants to perform collaborative computations in a distributed environment, effectively protecting the privacy and security of participant data. Remark 1 We only consider the architecture with a single cloud server, primarily achieving secure aggregation of the transmitted data from participants through cloud server outsourcing. Specifically, when the cloud server S receives the local gradient sets transmitted by each participant, it performs aggregation operations in the cloud, calculating the sum of the locally uploaded gradients in an encrypted state. This secure framework has been widely used in previous works. In recent studies on federated learning [25,26,27], solutions with dual-cloud or multi-cloud structures have also been proposed. However, such setups require ensuring the absence of collusion among multiple servers, posing higher demands on practical applications. In our setting, the federated learning process is accomplished solely through a single cloud server, performing all the aggregation and computations, thereby avoiding the aforementioned issues. Additionally, the use of distributed homomorphic encryption allows for tolerance towards a small number of malicious participants colluding with the cloud server, while also being inclusive of participants\u2019 mid-training joining and exiting. Threat model and privacy objectives In federated learning, we assume that some participants and the server act semi-honestly and treat them as potential adversaries. The threat model is defined as follows: Single malicious participant attack: A single malicious participant in federated training may exhibit curiosity towards the model parameters uploaded by other participants and attempt to infer their private information. Cloud Server Attack: In the process of global model iteration, cloud servers may launch inference attacks on participants\u2019 private data by learning and reasoning over the local parameter data uploaded by participants in federated learning. This can lead to privacy breaches and the potential for malicious actors to infer sensitive information about the participants. Some participants conspired with the cloud server to attack: When some malicious participants collude with the server to launch an attack, they may exploit shared model parameters to infer and obtain private information of other participants, leading to security issues such as privacy leaks among participants. To achieve federated training without compromising the privacy of participants\u2019 data, it is necessary to achieve the following privacy protection goals: Privacy of participant\u2019s local gradients: Attackers may obtain the local gradient data obtained by participants during local training using their data and use this information to reconstruct the original data, leading to privacy breaches (such as medical records, location, visited websites, etc.). To protect the privacy of participant data, we set participants should encrypt the local gradient before uploading it to the cloud server, in addition to local operations. The cloud server only performs aggregation and computation on the encrypted data, ensuring the privacy of the original data. Privacy protection of aggregated evaluation values: The privacy of the aggregated evaluation values of each participant also needs to be ensured. If leaked, participants with lower data quality may face discrimination during the training process, thus impacting the fairness of training. Therefore, it is crucial to maintain the privacy and confidentiality of the aggregated evaluation values to uphold the fairness and integrity of the training process. Our proposed scheme This section provides a detailed description of the Privacy-Preserving Federated Learning with Low-Quality Data Participation (PPFL-LQDP) framework that allows participation of partially low-quality data while ensuring data privacy and security without data deletion. PPFL-LQDP enables interactions between a single cloud server and participants, supporting encryption-based operations on ciphertexts. The framework ensures the fulfillment of specified privacy requirements while preventing the adverse effects of including low-quality data excessively in the Federated training process. Firstly, let introduce our developed DCEM framework. DCEM is capable of conducting a composite evaluation of the contributed data by participants, ensuring a reduction in low-quality data contributions during Federated training. This guarantees that the accuracy and convergence speed of model training will not be negatively affected. The framework also incorporates a key \u201cSAP\u201d (Secure and Accelerate Partnership) protocol that promotes secure interaction between the cloud server and participants, enabling the secure execution of DCEM operations. Finally, we provided a detailed explanation of how the PPFL-LQDP utilizes the \u201cSAP\u201d protocol. This included an overview of the interaction process between the cloud server and participants, encryption of the DCEM operations performed on the data provided by participants, as well as ensuring the privacy and security of the participants\u2019 local gradient information and the composite evaluation values of data quality. Composite evaluations containing participants with low quality data In practical applications of federated learning, it is challenging to avoid excessive participation of low-quality data due to different data sources and varying participants\u2019 capabilities. As a result, participants\u2019 datasets may contain low-quality data, and a large amount of low-quality data participating in training, especially components that are opposite to our global optimal gradient, can lead to negative convergence of the model. Depending on the type of data, the reasons for low data quality can be defined as follows: 1) the gradient vector is in the opposite direction to our global optimal gradient, so we consider the gradient to be negatively correlated; 2) there is significant variability between local gradient data and global optimal gradient data. Both factors can lead to reduced model accuracy and slower convergence speed. To address the impact of low-quality data, it is necessary to adjust the level of data participation properly. In other words, we need to seek an evaluation method to adjust the weight of participant data in the global model. To address the negative impact of excessive participation from low-quality data contributors in federated learning, the PPFL-LQDP framework implements a composite evaluation mechanism. This mechanism evaluates low-quality data contributors by performing DCEM operations and reduces their participation in the Federated training. Specifically, for each participant with low-quality data, the DCEM operation adjusts their gradient values using unique threshold settings and an orthogonal loss-based approach. This adjustment helps mitigate the negative impact of low-quality data while improving the overall accuracy of the model. In this paper, we assume that all the data follows an independent and identically distributed (IID) distribution. In the Federated training process, we have K participants, and each participant performs local mini-batch gradient descent training. As a result, each participant obtains a set of gradients for their respective local data. Each participant can get a set of gradients. We assume that the local gradient of this participant is . During Federated training, each participant transfers its local gradients to the cloud server for global gradient iteration. Building upon the system model, three important components of DCEM are described in detail. Component orientation evaluation The direction of the global gradient indeed determines the iteration speed and direction of our model, and each local gradient component has a certain influence on the global gradient. Based on the previous description, the first step is to evaluate the vector direction difference between the local gradients and the global optimal gradient. Prior research has shown that DNN models exhibit a stable convergence pattern during each iteration. Algorithm 1 COEs Specifically, we first assume that each participant has a local gradient g, and for a given global optimal gradient , we evaluate the direction in which each participant holds the local gradient of the data by implementing the \u201cCOEs\u201d algorithm. First define a piecewise function to calculate the Angle between g and , as follows: (2) Where t is the calculation result of cosine between two vectors. According to Eq. (2), we can calculate the directional difference between the local gradient and the global ideal gradient of each participant, and then output the y value to complete the component orientation evaluation. The \u201cCOEs\u201d component that we have developed requires all participants to execute the protocol in an offline state, with each participant\u2019s local gradient carrying the \u201cCOEs\u201d evaluation result. The \u201cCOEs\u201d evaluation effectively assesses each local gradient, preventing excessive participation of low-quality data that may degrade model accuracy, without deleting any data. Additionally, since all participants\u2019 data is involved in the training, the convergence of the model is not negatively affected. In Chapter 7, we demonstrate the superiority of this approach through experiments and show that it effectively addresses the challenges posed by low-quality data in federated learning. Component dispersion evaluation In the previous section, participants obtained the direction evaluation of all data by executing the \u201cCOEs\u201d protocol. Based on our definition of low-quality data, highly dispersed data is also considered low-quality. Previous research has shown that the Euclidean distance can be used to assess the data quality of participants. Specifically, the shorter the distance between the local gradient and the global optimal gradient, the higher the quality of the data can be deemed. We then assign higher ratings to influence the weight of this participant in Federated training. In this paper, we further analyze the local gradient variance by processing the distances through mean calculation. This allows for a clearer and more accurate reflection of the degree of deviation in participants\u2019 local gradients, facilitating our evaluation process. By incorporating mean analysis into the evaluation process, we can effectively measure the data quality of participants and introduce appropriate perturbations during the training process. Overall, by incorporating mean analysis into the evaluation process, we can more effectively measure the data quality of participants, enabling better assessment and appropriate perturbation during the training process. Algorithm 2 CDEs In this paper, we establish a method called \u201cCDEs\u201d for low-quality screening and evaluation of training data for discreteness, as shown in protocol 2. We only consider the scenario of horizontal federated learning, where the private data held by the participants are all IID samples. Specifically, we set up a total of K participants for training, and each participant obtains a set of local gradients by executing the mini-batch gradient descent method locally. In the \u201cCDEs\u201d approach, each participant calculates the distance between their local gradient and the globally optimal gradient, which is then uploaded to the cloud for aggregation, resulting in an assessment of the participant\u2019s dispersion. The dispersion update for each user\u2019s data is as follows: (3) where \u201cdis\u201d represents the Euclidean distance between two vectors, and the specific calculation formula is . When participants\u2019 data is involved in DNN training, the differences in the data can lead to a certain degree of model loss. Algorithm 1 allows us to evaluate the direction of gradient components during training which helps analyze the components with superior direction, ensuring that the local gradients contributed by participants are beneficial to the convergence of the model. Next, Eq. (3) is used to measure the dispersion and differentiate the participation weights of participant data in training the DNN. This ensures the accuracy and convergence speed of the model are reasonably maintained. Remark 2 In previous research [28, 29], using distance to describe the quality of data held by participants has achieved good results. In our work, we further process the distance evaluation by calculating distance weights through the ratio of distance to the mean. Specifically, for the data under evaluation, we construct the ratio between the average distance between the local gradient and the optimal gradient of the training data, and the distance between the evaluated data and the optimal gradient. A larger ratio indicates a closer distance and higher data quality, resulting in a higher weight in the training process. Conversely, for lower-quality data, we set a threshold to reduce their participation. By calculating the distance weights based on the ratio, we can effectively differentiate and assign weights to data based on their quality. This enables us to include high-quality data more prominently in the training process while reducing the influence of low-quality data through the threshold setting. This approach allows us to better manage the participation of participants with varying data quality and ensure that the overall training process is more robust and accurate. Data evaluation aggregation Given direction evaluation and dispersion evaluation of the training data provided by each participant, the composite evaluation Q of the data can be obtained from Eq. (4): (4) Remark 3 In the two previous sections, we conducted component direction quality evaluation and dispersion quality evaluation on the given data. We can perform a composite evaluation based on Eq. (4) to generate a composite evaluation value for the data. It can be observed that assigning higher weights to the training data provided by a participant, whose local gradient is closer to the expected global optimal gradient value, is reasonable. According to the state-of-the-art research [30, 31], in scenarios where participants hold independent and identically distributed (IID) samples, similar samples exhibit high consistency in direction and dispersion. However, in federated learning, participants\u2019 data differs significantly due to variations in data collection methods and processing capabilities. In this scenario, it is crucial to control the participation ratio of data in training through composite evaluation values to mitigate the negative impact of excessive involvement of low-quality data on model accuracy. Aggregated value update Given the combined evaluation value of each group of training data, the update of each local gradient component is shown as follows: (5) Remark 4 According to Eq. (5), in the summary of participating data, data with higher comprehensive evaluation value will be given higher weight to participate in training, to ensure that the model will not be unavailable due to excessive addition of low-quality data. we filter based on where is a preset threshold that participants collectively negotiate [11, 15, 16]. In our setup, low-quality data is not directly removed, but rather its participation is influenced through a well-designed structure to ensure the confidentiality of the data quality held by each participant. We allow the inclusion of low-quality data, but with a significantly lower weight, ensuring that the majority of the training data is of trusted quality. In the experimental section, the superiority of our approach in terms of model accuracy will be fully demonstrated. Secure aggregation protocol(SAP) The proposed secure aggregation scheme is achieved through the improvement of the Paillier encryption mechanism. we assume that each participant in the Federated training holds a private dataset, and we aim to protect the local gradients of all participants\u2019 data, as well as the composite evaluation values, through the \u201cSAP\u201d protocol. Specifically, as shown in Fig. 2, the privacy data of participants is encrypted and the ciphertext is transmitted to the cloud server S. Upon receiving the ciphertext data from all participants, the cloud server performs multiplication operations on the ciphertext using additive homomorphism and then publicly reveals the aggregated ciphertext result to all participants. Subsequently, participants perform partial decryption on the ciphertext c using their respective partial private keys and send the partially decrypted results to the cloud server S. Finally, the cloud S stops receiving decryption data until it collects the partially decrypted results from t participants then aggregates all the received partially decrypted results to obtain the sum of the local gradients of k participants. The establishment of the PPEL-LQDP The PPEL-LQDP established by us is shown in Algorithm 3, which mainly includes two phases, namely system setup and encrypted execution of DCEM scheme. The steps of PPFL-LQDP are explained in detail next. Algorithm 3 Implementation of PPFL-LQDP System Setup: We first generate the public key and partial private key groups based on the distributed paillier cryptosystem through a third-party authorization center (TA), and distribute partial private keys to each participant through a secret channel. To initiate the DNN model, the cloud server first initializes the global weights and the global optimal gradient. Encrypted DCEM: Participants encrypt their private data using a distributed Paillier cryptosystem and then send it to the cloud server. The cloud server collaborates with the participants to perform the encrypted DCEM operations, obtaining the composite evaluation values of the data. For simplicity, we use to represent the ciphertext of plaintext a. As shown in Algorithm 3, an encrypted DCEM consists of five main parts: 1) component orientation evaluation. 2) component dispersion evaluation. 3) data evaluation aggregation. 4) encrypted aggregated Value Update. 5) weight update. The detailed techniques for each phase are shown below. (1) Component orientation evaluation: In this stage, steps 1 and 2 are performed to evaluate the direction of the data. First, after receiving the global weight and optimal gradient initialized by the cloud server, each participant carries out mini-batch gradient descent operations locally to obtain the local gradient. Then, each participant calculates the vector Angle between the local gradient and the optimal gradient to obtain the direction evaluation of the data through the \u201cCOEs\u201d algorithm. This work is done by the participants on the local network. (2) Component dispersion evaluation: To calculate the participant\u2019s data dispersion rating value in the encrypted state, we performed steps 3-6 through the homomorphism of the distributed Paillier cryptographic mechanism. where the is the Euclidean distance between two vectors and represents the sum of the distance between the local gradient and the global optimal gradient of all participants. (3) Data evaluation aggregation: After the participants obtain the evaluation value of direction and dispersion, they will conduct the evaluation combination through Eq. (3) (Step 7), and have obtained the overall evaluation of the current iteration. Here we use the product combination evaluation method, which can describe the participant data quality. (4) Aggregated Value Update: After each participant obtains the composite evaluation, step 8 is executed to update the current optimal gradient. Each participant first computes based on the homomorphism of the distributed paillier cryptographic mechanism and , the specific calculation is and . Then, the cloud server S performs \u201cSAP\u201d in collaboration with the participant to obtain the plaintext result of the sum of the data. The current most gradient update is then performed. (5) weight update: The cloud server updates the global weight through Eq. (1) (Step 11), and broadcasts the global weight after iteration to all participants. The cloud server S and the participant repeat steps 1-11 until our preset convergence conditions are met. Remark 5 In our setup, there are no offline users, but our scheme is highly tolerant of participants who are unable to complete the current task due to unexpected events during the execution. This is because, in the decryption process, each participant has the privilege to perform partial decryption. Additionally, the cloud server only needs to collect partial decryption results from a minimum of t participants to obtain the decrypted result. Therefore, participants who cannot execute the scheme correctly in the current iteration are considered invalid for that iteration, but it does not affect the overall progress of the model training. In this paper, we did not consider the impact of offline participants on the model accuracy. They are treated as if they do not contribute to the current iteration\u2019s training process. However, it is important to note that in practical applications, the impact of offline participants on the model accuracy may need to be further considered and evaluated. Correctness Theorem 1 Our PPFL-LQDP can accurately compute the dispersion evaluation value of participants\u2019 data in ciphertext state. Proof Remark 6 The discrete evaluation of participant data requires calculation in the encrypted state, and division operations pose a certain challenge to the Paillier cryptosystem. By constructing a logarithm function, the computation can be simplified without altering the distribution of evaluation values. Security analysis Based on Chapter 4, the threat model mainly originates from internal entities of the system, namely participants and cloud servers. Therefore, the goal of PPFL-LQDP is to ensure that the local gradients and data composite evaluation values of each participant are not leaked to other participants and cloud servers. In our constructed DCEM, the \u201cCOEs\u201d algorithm is executed in the local network of participants, so privacy concerns are not necessary. Privacy protection is mainly focused on the \u201cCDEs\u201d algorithm phase and the gradient value update phase. Due to the secure aggregation scheme \u201cSAP\u201d that we use, we can defend against the attack described in System model section. Single malicious participant attack: A single malicious participant seeks to obtain the privacy of other participants through collected information. In our \u201cSAP\u201d protocol, no participant knows all the private keys. Therefore, even if the malicious participant collects the encrypted gradient information sent by other participants to the cloud server, they cannot obtain the plaintext information. Semi-honest cloud server: Participants need to send their locally trained gradient information to the cloud server in an encrypted form, in order to offload large-scale computations to a third party. In our setup, the cloud server will perform all computations as specified, but will infer participants\u2019 information based on the knowledge acquired. During the interaction process of our scheme, the cloud server does not possess the private key, which is held by all participants in the key group. Decryption requires the collaboration of t participants. Therefore, the cloud server can only obtain aggregated information and cannot access participants\u2019 private data. Malicious Participants Collaborating with the Cloud Server: In the case of a collusion attack between participants and the cloud server, malicious participants can provide partial private keys to the cloud server. If the cloud server manages to collect partial private keys from t or more participants, it can access the data of all participants. Therefore, the proposed scheme can resist collusion attacks when the number of malicious participants is less than or equal to , as distributed decryption requires collecting at least t partial decryption results before aggregating the final result. Thus, this scheme possesses a certain level of resilience against collusion attacks. Performance analysis In this section, we conducted training and testing tasks based on the MNIST database. This database consists of 60,000 training samples and 10,000 test samples, which are used to evaluate the proposed approach in this paper. Specifically, we compared the proposed PPFL-LQDP scheme with traditional federated learning methods and the ecProbe scheme in this paper. The experimental settings are as follows: All programs were compiled in Python and simulated on a Lenovo desktop computer with an Intel(R) Core(TM) i3-12100 3.30GHz processor and 16.0GB of RAM. The participants used Lenovo 310s laptops with an Intel(R) Core(TM) i5-7200U CPU @ 2.50GHz 2.70GHz processor for simulation. We set the learning rate to 0.01, and the batch size for gradient descent to be 128 samples per group. Functionality To illustrate the superiority of our PPFL-LQDP in terms of functionality, we compare it with three recent methods for privacy-preserving federated learning: SecProbe [18], PPFDL [20], and EPPFL [21]. As shown in Table 1, SecProbe, being the first framework in privacy-preserving federated learning to consider the involvement of untrusted participants, successfully defends against collusion attacks between the cloud server and users while ensuring the security of private data through differential privacy. However, if a single participant goes offline during the interaction, the normal operation of the model cannot be guaranteed. In PPFDL, improvements were made to address the offline issue of participants, but the dual-cloud architecture is challenging to ensure collusion-free in practice. As a follow-up to PPFDL, EPPFL addresses the dual-cloud issue with a single-cloud architecture and reduces the secure computation cost of scoring untrusted participants using logarithmic operations. However, in this setup, data with significant directional bias is classified as irrelevant and does not participate in training. Compared to the aforementioned methods, the PPFL-LQDP privacy-preserving framework is further built upon EPPFL. Similarly, it utilizes the distributed Paillier cryptosystem to construct a secure aggregation protocol, which addresses the issue of participants joining or going offline while ensuring privacy. Additionally, constructing DCEM and utilizing linear relationships, enables composite evaluation of the data quality of participants, allowing all participants to participate in training without losing data. Table 1 Functional comparison with other works Full size table Accuracy We discuss the accuracy of our PPFL-LQDP in this part. To illustrate the superiority of the experimental results, we compare with two representative methods, i.e., PFL [31] (Primitive Federated Learning) and SecProbe. Remark 7 PFL is the most primitive model in federated learning, which doesn\u2019t require any operations on the data. On the other hand, SecProbe is the first privacy-preserving federated learning model that considers the participation of unreliable participants. This comparison demonstrates the necessity of handling unreliable participants in federated learning and highlights the superiority of the proposed solution. Therefore, it is reasonable to make such a comparison. To verify the accuracy of the proposed solution after incorporating low-quality data in the training process, we randomly selected a portion of the data from the training set and introduced noise to simulate low-quality data. This same setup was applied to both the PFL and SecProbe approaches (with a privacy budget of 10 for the SecProbe solution). We conducted experiments in our Federated training using different proportions of low-quality data. As shown in Fig. 4, we set P as the proportion of low-quality data in the training set data. The accuracy varies with P (P=10 , P=15 , P=20 , P=25 , P=30 ), and the model gradually levels off with increasing number of training iterations. It can be seen that our scheme PPFL-LQDP is higher in accuracy than PFL and SecProbe, and under the same number of iterations, our scheme is also relatively accurate. At the same time, when the content of low-quality data is high, the accuracy of PFL and SecProbe decreases very fast, while our PPFL-LQDP scheme has almost no significant difference. Specific reasons: 1) PFL does not consider the addition of low-quality data, so it will cause low-quality data to over-participate in the training, directly affecting the accuracy of the model, and even making the model unusable. 2) Differential privacy to protect private data needs to be achieved by adding noise, and in order to ensure the privacy security of participants, the accuracy will cause a certain loss. However, For the low-quality data, we construct a linear relationship, so that the data can participate in the training level according to the data quality, avoiding the accuracy degradation caused by the excessive participation of low-quality data in the training process. At the same time, all the data will participate in the training, and no data loss will be caused. Referring to previous works, our scheme uses distributed paillier cryptosystem to protect private data. Fig. 4 Variations in model accuracy with changing proportions of low-quality data contributed by participants Full size image Computation overhead In this section, we evaluated the computational overhead of the PPFL-LQDP approach. To provide a clear visualization of the experimental results, we compared them with the PPML [32] approach. To ensure the fairness of the experiment, both methods are tested using the same hardware configuration and data set. The experimental environment and learning rate are kept consistent. The PPFL-LQDP algorithm constructed in this article utilizes distributed Paillier homomorphic encryption mechanism for additional operations to protect the privacy of participants\u2019 private data. It also performs a decryption operation to allow the cloud server to obtain intermediate values for calculating a composite evaluation value of participants\u2019 data quality. Figure 5a depicts the computational overhead of participants in the PPFL-LQDP process as the number of local gradient calculations increases. From the figure, it can be observed that the computational overhead on the participant side does not increase significantly. In PPFL-LQDP, participants only need to perform local computations of encrypted gradient sets and participate in partial decryption, while all the cryptographic operations are handled by the server. This setup is quite favorable for the participants. Furthermore, based on Fig. 5b, it can be seen that the computational cost for participants in Federated training does not increase significantly as the number of participants in the training increases. Fig. 5 Computation overhead of PPFL-LQDP Full size image Figure 6 illustrates the comparison of computational costs between PPFL-LQDP and PPML in terms of participant computational overhead and server computational overhead. From the figure, it is evident that as the volume of participant data increases, the computational overhead of PPML grows more rapidly compared to PPFL-LQDP. This is mainly due to the exponential increase in computational costs for PPML with an increasing number of users. However, the PPFL-LQDP algorithm can complete computations with a time complexity of . This is primarily because the PPFL-LQDP algorithm performs composite evaluation value calculations on low-quality data on the server. The server only needs to bear the collaborative part of the \u201cCDEs\u201d process and the aggregation calculation of the composite evaluation values, resulting in a linear growth trend in server-side overhead. when the number of participants is large, the cost of our scheme on the server side will be better. Fig. 6 Comparison of computational overhead between PPFL-LQDP and PPML Full size image Communication overhead Figure 7a demonstrates the variation in communication overhead between participants and the cloud server as the number of local gradient calculations increases. the majority of the communication workload is handled by the server, and the increase in overhead for each participant is not significant. In Fig. 7b, it can be observed that the communication overhead for each participant does not significantly change as the number of participants increases. Fig. 7 Communication Overhead of PPFL-LQDP Full size image As shown in Fig. 8, the comparison of communication overhead between PPFL-LQDP and PPML can be observed. It is evident that when the number of participants varies, PPFL-LQDP incurs significantly lower communication overhead compared to PPML. This is because PPFL-LQDP only requires each participant to transmit a fixed amount of encrypted data to the cloud server, and the communication between the server and participants remains relatively stable. PPFL-LQDP also exhibits relatively stable overhead, making it participant-friendly. Therefore, compared to other approaches, PPFL-LQDP demonstrates certain advantages in terms of communication overhead. Fig. 8 Comparison of Communication Overhead between PPFL-LQDP and PPML Full size image Conclusion The paper presents a novel privacy-preserving federated learning solution, PPFL-LQDP, that addresses the issue of excessive participation of low-quality data in Federated training. By constructing a composite evaluation value for the data, the negative impact of low-quality data on Federated training is reduced, while ensuring privacy and security of participant data through a secure framework. The experimental results demonstrate the capability of PPFL-LQDP in handling low-quality data, and the comparison with other approaches highlights the superior overall performance of our proposed solution. Availability of data and materials The datasets are available online.The URL is as follows: MNIST database: http://yann.lecun.com/exdb/mnist. References Jordan MI, Mitchell TM (2015) Machine learning: Trends, perspectives, and prospects. Science 349(6245):255\u2013260 Article   MathSciNet   CAS   PubMed   Google Scholar   Fleming N (2018) How artificial intelligence is changing drug discovery. Nature 557(7706):S55\u2013S55 Article   CAS   PubMed   Google Scholar   Zhou ZH (2016) Learnware: on the future of machine learning. Front Comput Sci 10(4):589\u2013590 Article   Google Scholar   Liu B, Ding M, Shaham S, Rahayu W, Farokhi F, Lin Z (2021) When machine learning meets privacy: A survey and outlook. ACM Comput Surv (CSUR) 54(2):1\u201336 Article   Google Scholar   De Cristofaro E (2021) A critical overview of privacy in machine learning. IEEE Secur Priv 19(4):19\u201327 Article   Google Scholar   McMahan HB, Moore E, Ramage D, y Arcas BA (2016) Federated learning of deep networks using model averaging. arXiv preprint arXiv:1602.05629 McMahan B, Moore E, Ramage D, Hampson S, y Arcas BA (2017) Communication-efficient learning of deep networks from decentralized data. In: Proceedings of the 20th International Conference on Artificial Intelligence and Statistics. Proceedings of Machine Learning Research, pp 1273\u20131282 Aono Y, Hayashi T, Wang L, Moriai S (2017) Privacy-preserving deep learning via additively homomorphic encryption. IEEE Trans Inf Forensic Secur 13(5):1333\u20131345 Google Scholar   Hitaj B, Ateniese G, Perez-Cruz F (2017) Deep models under the GAN: Information leakage from collaborative deep learning. In: Proceedings of the ACM SIGSAC Conference on Computer and Communications Security, Dallas, 30 October-3 November 2017. https://doi.org/10.1145/3133956.3134012. pp 603\u2013618 Richardson A, Filos-Ratsikas A, Faltings B (2020) Budget-bounded incentives for federated learning. Federated Learn Priv Incent vol.12500:176\u2013188 Liang W, Tadesse GA, Ho D, Fei-Fei L, Zaharia M, Zhang C, Zou J (2022) Advances, challenges and opportunities in creating data for trustworthy AI. Nat Mach Intell 4(8):669\u2013677 Article   Google Scholar   Fouque P A, Poupard G, Stern J (2000) Sharing decryption in the context of voting or lotteries. In: Financial Cryptography: 4th International Conference, Anguilla, British West Indies, 20-24 February 2000. pp 90\u2013104 Wei K, Li J, Ding M, Ma C, Yang HH, Farokhi F, Poor HV (2020) federated learning with differential privacy: Algorithms and performance analysis. IEEE Trans Inf Forensic Secur 15:3454\u20133469 Article   Google Scholar   Falcetta A, Roveri M (2022) Privacy-preserving deep learning with homomorphic encryption: An introduction. IEEE Comput Intell Mag 17(3):14\u201325 Article   Google Scholar   Ma C, Li J, Ding M, Yang HH, Shu F, Quek TQ, Poor HV (2020) On safeguarding privacy and security in the framework of federated learning. IEEE Netw 34(4):242\u2013248 Article   Google Scholar   Fang H, Qian Q (2021) Privacy Preserving Machine Learning with Homomorphic Encryption and Federated Learning. Future Internet 13(4):94 Article   Google Scholar   Park J, Lim H (2022) Privacy-preserving federated learning using homomorphic encryption. Appl Sci 12(2):734 Article   CAS   Google Scholar   Zhao L, Wang Q, Zou Q, Zhang Y, Chen Y (2019) Privacy-preserving collaborative deep learning with unreliable participants. IEEE Trans Inf Forensic Secur 15:1486\u20131500 Article   Google Scholar   Yu H, Liu Z, Liu Y, Chen T, Yang Q (2020) A Sustainable Incentive Scheme for Federated Learning. IEEE Intell Syst 35(4):58\u201369 Article   Google Scholar   Xu G, Li H, Zhang Y, Xu S, Ning J, Deng RH (2020) Privacy-preserving Federated deep learning with irregular users. IEEE Trans Dependable Secure Comput 19(2):1364\u20131381 Google Scholar   Li Y, Li H, Xu G, Huang X, Lu R (2021) Efficient privacy-preserving federated learning with unreliable users. IEEE Internet Things J 9(13):11590\u201311603 Article   Google Scholar   Nguyen DC, Ding M, Pathirana PN, Seneviratne A, Li J, Poor HV (2021) federated learning for internet of things: A comprehensive survey. IEEE Commun Surv Tutorials 23(3):1622\u20131658 Article   Google Scholar   Danner G, Jelasity M (2015) Fully distributed privacy preserving mini-batch gradient descent learning. In: Distributed Applications and Interoperable Systems: 15th IFIP WG 6.1 International Conference, Grenoble, France, 2-4 June 2015, Springer, Cham. pp 30\u201344 Damg\u00e5rd I, Jurik M (2001) A generalisation, a simplification and some applications of Paillier\u2019s probabilistic public-key system. In: Public Key Cryptography: 4th International Workshop on Practice and Theory in Public Key Cryptosystems, PKC 2001 Cheju Island, Korea, 13-15 February 2001 Proceedings 4. Springer Berlin Heidelberg. pp 119\u2013136 Bohli JM, Gruschka N, Jensen M, Iacono LL, Marnau N (2014) Security and privacy-enhancing multicloud architectures. IEEE Trans Dependable Secure Comput 10(4):212\u2013224 Article   Google Scholar   Xu G, Li H, Lu R (2018) Practical and privacy-aware truth discovery in mobile crowd sensing systems. In: Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security. https://doi.org/10.1145/3243734.3278529. pp 2312\u20132314 Choi I, Song Q, Sun K (2019) Federated-cloud based deep neural networks with privacy preserving image filtering techniques. In: IEEE Conference on Dependable and Secure Computing (DSC), Hangzhou, China, November 2019. https://doi.org/10.1109/DSC47296.2019.8937635. pp 1\u20138 Vaziri R, Mohsenzadeh M, Habibi J (2019) Measuring data quality with weighted metrics. Total Qual Manag Bus Excell 30(5\u20136):708\u2013720 Article   Google Scholar   D\u00edaz C, Calderon-Ramirez S, Aguilar LDM (2022) Data Quality Metrics for Unlabelled Datasets. In: IEEE 4th International Conference on BioInspired Processing (BIP), Cartago, Costa Rica, November 2022. https://doi.org/10.1109/BIP56202.2022.10032475. pp 1\u20137 Luping W, Wei W, Bo L C (2019)CMEL: Mitigating Communication Overhead for Federated Learning. In: 2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS). Dallas, TX, USA. https://doi.org/10.1109/ICDCS.2019.00099. pp 954\u2013964 Smith V, Chiang CK, Sanjabi M, Talwalkar AS (2017) Federated multi-task learning. Adv Neural Inf Process Syst 30:4424\u20134434 Google Scholar   Bonawitz K, Ivanov V, Kreuter B, Marcedone A, McMahan HB, Patel S, Seth K (2017) Practical secure aggregation for privacy-preserving machine learning. In: proceedings of the ACM SIGSAC Conference on Computer and Communications Security, New York, USA, October 2017. https://doi.org/10.1145/3133956.3133982. pp 1175\u20131191 Download references Funding This article is supported in part by the Guangxi Natural Science Foundationunder grant 2023GXNSFAA026236, the National Natural Science Foundation of China under project 61962012, and the National Key R &D Program of China under project 2020YFB1006003. Author information Authors and Affiliations School of Mathematics and Computing Science, GuiLin University of Electronic Technology, Guilin, 541004, China Huiyong Wang & Qi Wang Guangxi Key Laboratory of Cryptography and Information Security, School of Computer Science and Information Security, Guilin University of Electronic Technology, Guilin, 541004, China Huiyong Wang & Yong Ding Cyberspace Security Research Center, Peng Cheng Laboratory, Shenzhen, 518055, China Yong Ding School of Electronic Engineering and Automation, GuiLin University of Electronic Technology, Guilin, 541004, China Shijie Tang Hangzhou Innovation Institute, Beihang University, Hangzhou, 310052, China Yujue Wang Contributions Huiyong Wang provided the research direction and innovation points of this paper, Qi Wang was mainly responsible for the implementation of the algorithm and the writing of the code, Yong Ding, Shijie Tang and Yujue Wang mainly provided the hardware support and English polishing and all the authors participated in the writing of the manuscript. Corresponding author Correspondence to Shijie Tang. Ethics declarations Ethics approval and consent to participate This declaration is not applicable. Competing interests The authors declare no competing interests. Additional information Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Rights and permissions Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. Reprints and permissions About this article Cite this article Wang, H., Wang, Q., Ding, Y. et al. Privacy-preserving federated learning based on partial low-quality data. J Cloud Comp 13, 62 (2024). https://doi.org/10.1186/s13677-024-00618-8 Download citation Received 07 October 2023 Accepted 24 February 2024 Published 18 March 2024 DOI https://doi.org/10.1186/s13677-024-00618-8 Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Keywords Federated learning Privacy protection Low-quality data Distributed homomorphic encryption Download PDF Collection Advanced Blockchain and Federated Learning Techniques Towards Secure Cloud Computing Sections Figures References Abstract Introduction Related work Preliminaries System model Our proposed scheme Security analysis Performance analysis Conclusion Availability of data and materials References Funding Author information Ethics declarations Additional information Rights and permissions About this article Advertisement Support and Contact Jobs Language editing for authors Scientific editing for authors Leave feedback Terms and conditions Privacy statement Accessibility Cookies Follow SpringerOpen By using this website, you agree to our Terms and Conditions, Your US state privacy rights, Privacy statement and Cookies policy. Your privacy choices/Manage cookies we use in the preference centre. \u00a9 2024 BioMed Central Ltd unless otherwise stated. Part of Springer Nature.",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "Measuring decision aid effectiveness for end-of-life care: A systematic review",
    "doi": "10.1016/j.pecinn.2024.100273",
    "description": "Objective: To systematically review research analyzing the effectiveness of decision aids for end-of-life care, including how researchers specifically measure decision aid success. Methods: We conducted a systematic review synthesizing quantitative, qualitative, and mixed-methods study results using Preferred Reporting Items for Systematic Reviews and Meta-Analysis guidelines. Four databases were searched through February 18, 2023. Inclusion criteria required articles to evaluate end-of-life care decision aids. The review is registered under PROSPERO (#CRD42023408449). Results: A total of 715 articles were initially identified, with 43 meeting the inclusion criteria. Outcome measures identified included decisional conflict, less aggressive care desired, knowledge improvements, communication improvements, tool satisfaction, patient anxiety and well-being, and less aggressive care action completed. The majority of studies reported positive outcomes especially when the decision aid development included International Patient Decision Aid Standards. Conclusion: Research examining end of life care decision aid use consistently reports positive outcomes. Innovation: This review presents data that can guide the next generation of decision aids for end-of-life care, namely using the International Patient Decision Aid Standards in developing tools and showing which tools are effective for helping to prevent the unnecessary suffering that can result when patients' dying preferences are unknown.",
    "journal": "PEC Innovation",
    "authors": [
      "Hughes M.C.",
      "Vernon E.",
      "Egwuonwu C.",
      "Afolabi O."
    ],
    "citation_count": "0",
    "full_text": "Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Highlights Abstract Keywords 1. Introduction 2. Methods 3. Results 4. Discussion and conclusion Funding CRediT authorship contribution statement Declaration of competing interest Appendix A. Supplementary data References Show full outline Figures (1) Tables (2) Table 1 Table 2 Extras (1) Supplementary material PEC Innovation Volume 4, December 2024, 100273 Measuring decision aid effectiveness for end-of-life care: A systematic review Author links open overlay panel M. Courtney Hughes a, Erin Vernon b, Chinenye Egwuonwu a, Oluwatoyosi Afolabi a Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.pecinn.2024.100273 Get rights and content Under a Creative Commons license open access Highlights \u2022 End-of-life care decision aid use consistently reports positive outcomes. \u2022 International Patient Decision Aid Standards enhance end-of-life care decision aid. \u2022 End-of-life care decision aids provide value across different countries. Abstract Objective To systematically review research analyzing the effectiveness of decision aids for end-of-life care, including how researchers specifically measure decision aid success. Methods We conducted a systematic review synthesizing quantitative, qualitative, and mixed-methods study results using Preferred Reporting Items for Systematic Reviews and Meta-Analysis guidelines. Four databases were searched through February 18, 2023. Inclusion criteria required articles to evaluate end-of-life care decision aids. The review is registered under PROSPERO (#CRD42023408449). Results A total of 715 articles were initially identified, with 43 meeting the inclusion criteria. Outcome measures identified included decisional conflict, less aggressive care desired, knowledge improvements, communication improvements, tool satisfaction, patient anxiety and well-being, and less aggressive care action completed. The majority of studies reported positive outcomes especially when the decision aid development included International Patient Decision Aid Standards. Conclusion Research examining end of life care decision aid use consistently reports positive outcomes. Innovation This review presents data that can guide the next generation of decision aids for end-of-life care, namely using the International Patient Decision Aid Standards in developing tools and showing which tools are effective for helping to prevent the unnecessary suffering that can result when patients' dying preferences are unknown. Previous article in issue Next article in issue Keywords End-of-life careDecision aidsSystematic reviewAdvance care planningPalliative careDying 1. Introduction End-of-life care refers to the medical care and support provided during the days, weeks, or even months surrounding death. Often, individuals nearing the end of their lives experience unaddressed symptoms and requirements, including pain, debility, emotional anguish, and anxiety [1]. Some goals of quality end-of-life care that patients have identified include adequate pain control, preventing undue prolongation of dying, relieving concerns, and improving relationships with loved ones [1,2]. The end-of-life stage also involves making substantial decisions that impact patients, their caregivers, and healthcare workers. This stage has been described as stressful for patients due to inadequate preparation, with healthcare workers sometimes making decisions for their patients [3]. The fear of causing distress for patients, feeling unprepared, and being unsure of prognosis have been identified as barriers healthcare workers face in discussing end-of-life care with patients [4]. From the patient's perspective, this has resulted in inconsistency with the goals of care, reflecting the crucial value of effective decision making in end-of-life care [5]. Advance care planning (ACP) involves discussions between patients and their care providers about their preference for care in the near-term and future, including decisions to make in case of possible deterioration that might limit their decision making capacity [6]. Using decision aids to assist with medical decision making has been found to help improve the quality of end-of-life care among older patients [7]. Decision aids are customized tools developed to guide patients in making informed decisions regarding treatment or diagnostic options that allow for considering possible benefits or harms. Compared to routine decision making, they have the added benefits of improving the patient's knowledge of treatment or diagnostic options, reducing the burden of decision making, increasing the patient's participation in making decisions, creating risk perceptions of benefits and harms, and reducing decisional conflicts [3,[7], [8], [9]]. Yet, despite these benefits, a systematic review showed that decision aids may be insufficient in addressing patient's needs [6]. Previous systematic reviews on decision aids have evaluated their effectiveness in supporting shared decision making for treatment options for specific diseases [[10], [11], [12]] or treatment in general [7] or limited their scope to contemporaneous decision-making in end-of-life care and did not include advance care planning [6]. There is a gap in examining the effectiveness of decision aids for end-of-life care that is not limited to a specific disease or a dying population. Thus, there is limited holistic knowledge about the effectiveness of decision aids for end-of-life care. Such knowledge would inform researchers and practitioners who are studying and developing tools for general end-of-life care decision making. We aim to provide the first systematic review of the literature to date focusing on the effectiveness of decision aids for end-of-life care across populations with and without disease who may or may not be dying. Such decision aids may include guidance on palliative care and/or hospice options, help with advance directive decision making, or provide guidance on both. 2. Methods 2.1. Search strategy The systematic review is registered at PROSPERO (CRD 42023408449). We performed full-length database searches on articles published through February 18, 2023 using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines (14). We explored the databases of Pubmed, CINAHL, Proquest Federated and PsycInfo. The keyword strings used to capture relevant studies were \u201cdecision aid\u201d or \u201cdecision tool\u201d along with any of the following: \u201cterminal care,\u201d \u201ccaregiver*,\u201d \u201cbereave*,\u201d \u201cinpatient,\u201d \u201cattitude to death,\u201d \u201cend of life,\u201d \u201chospice*,\u201d \u201cterminally ill,\u201d \u201cpalliative*,\u201d \u201cadvance care,\u201d \u201cadvanced,\u201d \u201cmorphine and cancer,\u201d or \u201ccancer pain.\u201d (Note that \u201c*\u201d represents any group of characters, including no character.) We initially included peer-reviewed scholarly literature that contained these keywords in either the title or the abstract. 2.2. Inclusion /exclusion criteria To be included, the articles must have examined the use of decision aids at the end of life.The researchers aimed to capture research that focused on decision aids tailored for individuals either entering the end-of-life care stage or those explicitly interested in planning for such a time. As such, the decision aids included in the articles could have different focuses, including making emergent hospice and palliative care decisions or preparing for advance directives related to future care. We included articles related to disease-specific decision aids if they examined a decision aid specifically related to an end-of-life care focus. Both qualitative and quantitative analysis articles were included. Duplicates were excluded. Articles that were not focused on end-of-life, not evaluative, not focused on decision aids, and not in English were excluded. Review articles were also excluded. 2.3. Extraction process At least two authors independently examined the titles and abstracts of every study that met the inclusion criteria. Disagreements were resolved by accessing the full-text articles. At least two authors independently read the full-text articles to determine study inclusion. Any disagreements were resolved by discussion among the four authors. At least two authors independently extracted key information from all articles, including the decision aid name, decision aid description, decision aid format, study population disease focus, country, study design, outcomes measured, results, and whether the International Patient Decision Aid Standards (IPDAS) [13] were used in the decision aid development. One way to help ensure better quality (e.g., realistic expectations, values-choice agreement, knowledge [14]) for patient decision aids is for individuals and groups developing and evaluating decision aids to use the framework and 64-item checklist provided by the International Patient Decision Aid Standards (IPDAS) Collaboration [13]. This collaboration was established 20 years ago to guide researchers, practitioners, and other stakeholders in designing and improving patient decision aids. We assessed article quality using the Mixed Methods Appraisal Tool version 2018 [15]. This tool appraises the quality of the methods used for qualitative, quantitative, and mixed method studies. Studies were rated as low, medium or high based on the criteria outlined in the tool. Studies were of low-quality if 75% of the methodology criteria were met, of medium-quality if 76%\u201386% of the methodology criteria were met and of high-quality if above 86% of the criteria were met [16]. Disagreements were resolved via deliberations among the four researchers. 3. Results 3.1. Search results We initially retrieved a total of 715 articles from PubMed, CINAHL, ProQuest Federated, and PsycInfo. After removing duplicates, we screened 443 abstracts and reviewed 146 articles in full. Fig. 1 presents our selection process following PRISMA guidelines. Table 1 presents the study characteristics for the 43 studies we included after exclusions. More detailed information about each study is in Supplementary Tables 1 and 2. Download : Download high-res image (452KB) Download : Download full-size image Fig. 1. PRISMA flow diagram. Table 1. Characteristics of the studies (n = 43). Empty Cell Number of studies Quantitative study quality (n = 39)\u204e  High 20 (51.3%)  Medium 12 (30.8%)  Low 7 (17.9%) Qualitative study quality (n = 9)\u204e  High 8 (88.9%)  Medium 0 (0%)  Low 1 (11.1%) Countries\u204e\u204e  USA 32 (74.4%)  South Korea 2 (4.7%)  Canada 2 (4.7%)  Taiwan 2 (4.7%)  Japan 2 (4.7%)  Germany 1 (2.3%)  Korea 1 (2.3%)  Netherlands 1 (2.3%)  France 1 (2.3%) Decision aid format  Video 15 (34.9%)  Online (static) 10 (23.2%)  Online (interactive) 7 (16.3%)  Video and booklet 5 (11.6%)  Paper 3 (7.0%)  Interview 2 (4.7%)  Video and interview 1 (2.3%) Disease focus  General population 15 (35.0%)  Cancer 10 (23.3%)  General, terminally ill 9 (20.9%)  Dementia 5 (11.6%)  Advanced liver disease 1 (2.3%)  Chronic obstructive pulmonary disease 1 (2.3%)  End stage renal disease 1 (2.3%)  High-risk surgery 1 (2.3%) Focus areas (study type)\u204e\u204e\u204e  Decisional conflict (quant = 13, qual = 1, mixed = 3) 17 (39.5%)  Knowledge improvements (quant = 10, qual = 2, mixed = 3) 15 (34.9%)  Communication improvements (quant = 9, qual = 1, mixed = 5) 15 (34.9%)  Less aggressive care desired (quant = 10, qual = 1, mixed = 3) 14 (33.0%)  Tool satisfaction (quant = 5, qual = 2, mixed = 1) 8 (18.6%)  Less aggressive care action completed (quant = 6, qual = 0, mixed =0) 6 (14.0%)  Patient anxiety or well-being (quant = 4, qual = 0, mixed = 1) 5 (11.6%) Notes: quant = quantitative; qual = qualitative. \u204e Mixed methods studies included in both quantitative and qualitative sections. \u204e\u204e One study took place in both the USA and Japan so the percentages do not add up to 100%. \u204e\u204e\u204e Section totals do not equate to total studies due to multiple examined outcomes within studies. The studies were conducted in 14 countries, with about three-fourths from the United States. All countries included in the studies have high-income economies based on World Bank classifications [17]. The majority of the studies (over 80%) were of either medium or high quality. Decision aids were publicly accessible for 37% of the decision aids mentioned in the articles and are shown in Table 2, which presents all decision aids found in the studies. (Note: we counted each decision aid only once, even if it appeared in more than one reviewed article.) Of the 27 decision aids studied, one-third (9) mentioned using IPDAS standards within the tool development and two-thirds (6) of those using IPDAS reported positive outcomes. Nearly half of the decision aids were video-based and two-thirds were web-based. The decision aids in the study were either geared toward the general population (35%), those with a terminal illness diagnosis (21%), or a specific terminal diagnosis such as advanced cancer or dementia (44%). We present the following results by the outcome focus area of the decision aids in the studies. Table 2. Description of decision aids. Decision Aid Description Provider Type and Role Website IPDAS\u204e Studies and Outcome Success\u204e\u204e Advance Care Planning for Seniors A booklet with cartoons intended to educate older adults and their surrogates about advance care planning. N/A N/A N/S Ke (2021) [Y] Advance care planning video (no official name) 5-min video that introduces choices for medical care at the end of life that included visual images N/A N/A Y Ufere (2022) [Y] Advance directive for artificial nutrition and hydration Video-based tool which presented possible harms and benefits of artificial nutrition and hydration as well as a value clarification exercise. N/A N/A Y Friend (2021) [Y] Choice Help (\u201cKkeuzehulppz\u201d) Interactive short videos portraying actors discussing their chosen locations of death and their associated values. Depending on users' selected values, certain videos were played (two with location supporting their values and one with location that does not match values). N/A https://www.dz.nl/patient/keuzes-rond-het-levenseindeN/A N/S Kerstholt (2012) [Y] CPR-VDA 7-min video designed for participants to view independently on a portable screen. It includes information about CPR, the alternative option of comfort care, and information about the patient experience and health outcomes. N/A A Decision Aid to Prepare Patients And Their Families For Shared Decision-Making About Cardio-Pulmonary Resuscitation (CPR) on Vimeo N/S Kapell Brown (2018) [Y] Decision Aid Form (DAF) (no official name) 1-page decision aid for physicians to stratify hospitalized patients for care Sheet filled out by provider during admission, consultation, transfer or change of clinical state. https://cdn.amegroups.cn/static/magazine_modules/imgRender/dist/index.html?imgSource=https://cdn.amegroups.cn/journals/amepc/files/journals/8/articles/90359/public/90359-PB6-9674-R1.jpg N/S Vigouret-Viant (2022) [M] DecisionKEYS for Balancing Choices: Cancer Care Multicomponent program intended to improve decision making skills when there are multiple complex and stressful choices, help with a specific decision, and provide structured time for support by healthcare providers for decision making Patients and decision partners complete the decision aid in a clinical setting just prior to provider conversation. N/A N/S Jones (2018) [Y] Four Conversations An online and personalized coping and decision aid curriculum, on the completion of advance care directives and shared decision making among patients and their loved ones, clinicians, and spirit. \u201cFour [online] modules, each of which consists of a series of interactive videos and workbook activities focusing on EOL reflections and wishes for \u2018how one wants to live and die.\u2019 The web-based videos comprised a therapist conversing with a patient around EOL and exercises such as worksheets, visualizations, and tools were available to the participants to access at any time\u201d Participants complete the activities in each module, and then communicate with a specially trained \u201cPillar Guide\u201d by e-mail and/or telephone to discuss what they have learned over a four-week period. N/A N/S Smith (2020) [N] Goals of Care 18-min video, designed for surrogate decision makers of nursing home patients, that uses patient stories, balanced presentation, and simple language to enable comprehension at an 8th grade educational level. Content includes information about advanced dementia, role of the surrogate decision-maker, treatment goals, and treatment options consistent with each goal. Also included print handout (Einterz) After video, a structured meeting between the surrogate and the interdisciplinary care plan team at the nursing home occurs within the next 3 months N/A Y Einterz (2014) [Y], Hanson (2015) [Y] InformedTogether Web-based decision aid designed to support shared advance care planning between severe COPD patients and their doctors. Intended to be used by provider and patient together during clinic visit N/A Y Uhler (2015) [M] Living with Metastatic Breast Cancer: Making the Journey Your Own\u2019 30-min video and booklet decision aid aimed \u201cto help women learn about the disease and the options for treatment and to communicate their preferences and goals for treatment to providers and family members. The decision aid follows four women living with metastatic breast cancer and depicts how they live with the diagnosis, how they work with their doctors to make decisions, and how they continue to have hope\u201d N/A N/A N/S Ozanne (2009) [N] Looking Ahead: Choices for Medical Care When You're Seriously Ill 37-min DVD and 51-page booklet to encourage conversations, advance care planning and patient-centered decision making related to advanced illness N/A N/A N/S Bakitas (2017) [Y], Jones (20,150 [M]), Matlock (2014) [M}] Making Your Wishes Known: Planning Your Medical Future 1\u20132 h comprehensive computer-based educational program designed to facilitate ACP discussions between patients and their medical team N/A https://vitaldecisions.net/solutions/my-living-voice/ N/S Green (2009) [Y], Green (2015) [M[, Green (2020) [Y], Hossler (2011), Markham (2015) [Y[, Levi (2017) [M], Lipnick (2020) [M], Schubart (2019) [N], Simmons (2022) [M], Thiede (2021) [M], Van Scoy (2016) [Y] Patient decision aids before high risk surgery (no official name) 2 booklets a patient could write in to 1) consider a treatment preference and communicate it to a surrogate decision-maker or health care provider, and 2) decide to continue or stop treatment with the hope of prolonging life if recovery becomes difficult N/A https://bmcpalliatcare.biomedcentral.com/articles/10.1186/s12904-022-01068-2/tables/1 Y Yamamoto (2022) [Y] Patients Want to Know the Truth/Advance Care Planning 20-min decision support video on a notebook computer and a 43-page book on advance care planning. Advance Care Planning is the use of the same material modified for the general population (versus advanced cancer population). N/A N/A Y Kang (2020) [Y],Yun (2011) [M], Yun (2019), [Y] Person-Centered Oncologic Care and Choices (P-COCC) Video decision aid on end-of-life care options and an interview eliciting patient values regarding their goals, concerns, and support systems for oncology patients Interviewer trained in cognitive interviewing and serious illness research conducted value-focused patient interview N/A N/S Agarwal (2020) [Y] Plan Well Guide Online interactive program with paper-based values clarification form that generates a personalized \u201cDear Doctor\u201d letter recording the nature of the conversation, the stated values, and expressed treatment preferences Trained facilitator walks patient through guide and works with patient to complete \u201cDear Doctor\u201d letter https://planwellguide.com/healthcare-professionals/#:~:text=Plan%20Well%20Guide%20can%20help,of%20your%20time%20and%20energy. Y Heyland (2020) [M] PREPARE plus Advance Directive Web-based guide which uses video stories, modeling of behaviors, and a five-step process. Goals are \u201cto motivate and prepare individuals to discuss their values and care preferences and, using behavior change techniques, help individuals move along the ACP behavior change pathway.\u201d An easy to read advance directive form was included. N/A www.prepareforyourcare.org N/S Lum (2018) [Y] PRT Video Tool (no official name) 10-min video tool with four segments explaining: the process of radiation simulation, what to expect at the time of treatment;, common side effects, and the purpose of palliative care. N/A https://www.mskcc.org/videos/palliative-radiation-therapy Y Dharmarajan (2019) [M] Supportive and Palliative Care Indicators Tool (SPICT-DE\u2122) Online information sheet supporting primary care physicians in the identification of patients with deteriorating health and potentially unmet palliative care needs Physician used tool https://www.spict.org.uk/ N/S van Baal (2022) [Y] Tables of information (no official name) Tables of information which provides a concise review of diagnosis, prognosis, treatment options, side effects, and when to call the doctor N/A N/A N/S Smith (2011) [Y] Video support tool of advanced dementia (no official name) 2-min video support tool of advanced dementia patient and verbal narratives about advanced dementia and goals of care Person (position not stated) to read narrative https://www.bmj.com/content/338/bmj.b2159 N/S Volandes (2009) [Y], Volandes (2010) [Y] Video support tool of advanced dementia (no official name) 6-min video support tool of advanced dementia patient and verbal narratives about advanced dementia and goals of care Person (position not stated) to read narrative N/A N/S Volandes (2011) [Y] Video portraying choices of health care in advanced cancer (no official name) 6-min video portraying three choices of health care in advanced cancer: life-prolonging care, basic medical care and comfort care N/A N/A N/S Volandes (2012) [M] Video regarding physician orders for life-sustaining treatment (no official name) 7-min video decision aid for the Cardiopulmonary Resuscitation and Medical Interventions sections of the West Virginia version of Physician Orders for Life-Sustaining Treatment N/A N/A Y Gallegos (2020) [Y] Video regarding CPR and intubation (no official name) 3-min digital video regarding CPR and intubation played on an iPad at patient's bedside Physician not on patient's care team verbally communicated participants' post-video CPR and intubation preferences to at least one physician on patient's care team after decision aid was used https://www.acpdecisions.org/\u204e\u204e\u204e N/S El-Jawahri (2015) [Y] Virtual reality video and handout (no official name) 6-min virtual reality video presenting a first-person perspective of a patient with chronic obstructive pulmonary disease (COPD) to allow participants to immerse themselves in the complete clinical process of typical end-of-life care, starting with CPR in the intensive care unit, followed by withdrawn LST, hospice ward care, and hospice home care. N/A N/A N/S Hsieh (2020) [Y[ \u204e The International Patient Decision Aid Standards (IPDAS) was used in development. \u204e\u204e For Y = yes; N = no; M = mixed qual = qualitative. \u204e\u204e\u204e A code from a patient's healthcare provider is required to access the decision aid. Therefore, this decision aid is not considered publicly accessible. 3.2. Decisional conflict Decisional conflicts refer to internal struggles or uncertainty that patients or their families face when making choices related to end-of-life treatment options [18] and were examined in about 40% of the studies. Ten out of 13 of the quantitative studies examining such conflicts found positive outcomes from decision aid use. The results from the studies reporting positive decisional conflict outcomes were all from the patient's perspective and varied in characteristics such as country of origin, tool format, length, disease focus, and whether IPDAS were used during development. One quantitative study reported a reduction in patient reported decisional conflict after decision aid use but no reduction from the provider perspective [19]. The 4 qualitative studies that reported decisional conflict themes were all from the United States and consistently reported positive results [[20], [21], [22], [23]]. 3.3. Knowledge improvements Knowledge improvements about end-of-life care refer to enhancing one's understanding about the medical, emotional, and practical aspects of nearing the end of life. This knowledge can help individuals make more informed decisions [24]. Nine of the 10 quantitative studies examining knowledge improvements reported positive results. Four United States quantitative studies noted improved ACP knowledge for patients using the Making Your Wishes Known decision aid [[25], [26], [27], [28]]. Three other United States quantitative studies also reported increased knowledge after the use of video decision aids, including reported improved goals of care knowledge after patients viewed a 6-min decision aid video geared toward advanced cancer patients [29], a better understanding of Physician Orders for Life-Sustaining Treatment form options after a 7-min decision aid video on the topic [30], and improved treatment knowledge after a video specific to palliative radiation therapy [31]. Only one quantitative study reported no knowledge improvements associated with decision aid use: a US study of a 37-min decision aid DVD and associated booklet reported no improvements to patient advance directive knowledge [32]. 3.4. Communication improvements Communication improvements refer to enhancing the quality and effectiveness of exchanging information, ideas, and feelings between patients, their family, and their healthcare providers [33]. Of the 9 quantitative studies that examined communication improvements, 5 focused on the interaction between patients and healthcare providers. Two of these studies, one from Canada [19] and one from the United States [28], reported decision aids improved concordance between patients and providers, while two other of these studies from the United States reported no improvements in patient and provider communication after patient decision aid usage [34,35]. One United States quantitative study examined a decision aid specifically designed for family or surrogate caregivers of nursing home patients and found patient and provider improvements in long-term goal concordance [36]. Note that a surrogate caregiver is someone appointed to make medical decisions on behalf of a patient who is unable to do so. Three qualitative studies touched on themes of provider and patient relationships, with two noting potential improvements after using different tools in the United States [22] and Japan [37]. The decision aid Making Your Wishes Known had positive and neutral outcomes regarding patient and provider communication, depending on the study, two of which were quantitative [28,35] and one of which was qualitative [20]. The studies examining communication between patients and their family members or surrogates mainly reported positive outcomes. However, of the 4 quantitative studies in this category, one was a randomized control trial of a Korean decision aid that found that it did not change the decision to discuss the terminal diagnosis with loved ones [38]. Additionally, a quantitative study of a United States decision aid reported mixed results in this area noting that while there were improvements in conversations with the patient and medical team, there was no change in surrogates' preparedness for decision making [23]. Qualitative studies examining patient and surrogate communication themes reported positive findings [21,23,37]. 3.5. Less aggressive care desires and actions Less aggressive care desires refer to preferences for receiving comfort and management of pain and symptoms rather than life-sustaining medical interventions and treatment that often have burdensome side effects and cause high discomfort [39]. Of the 10 quantitative studies examining the topic, all found that decision aids led to patients wanting less aggressive care. Studies of five different video decision aids in the United States associated the aids with less desire for CPR [29,40,41], artificial hydration therapy [42], or aggressive care in general [29,43]. Decision aid studies outside of the US reported similar findings, with South Korea [44], Canada [45], Taiwan [46], and Japan [42] studies all reporting less aggressive care desired after decision aid use. Four qualitative studies, all examining various US decision aids, echoed most quantitative research with themes about patients desiring less aggressive care after decision aid exposure [22,23,47,48]. The 6 quantitative studies examining decision making action outcomes related to end-of-life care experienced more mixed results. For example, while the patients in two different studies expressed more of a desire for less aggressive care, there was no increase in documented do-not-resuscitate orders [29] or observed pursuance of less aggressive care [49]. Another United States quantitative study that reported increased knowledge of treatment options did not find changes to palliative care consultations [31]. Three other United States quantitative studies did report positive actions toward less aggressive care with increased orders to withhold CPR and intubation [40], documented ACP [50] and the number of life-sustaining medical treatments after decision aid use [51]. 3.6. Patient anxiety or well-being Patient anxiety refers to a state of uneasiness or fear related to their health condition or the healthcare system. In contrast, patient well-being refers to a positive state of mind, functioning, and satisfaction [52]. Four quantitative studies and 1 mixed study examined decision aid impact on patients' anxiety levels or well-being. In their quantitative examination of the video and book-based decision aid Patients Want to Know the Truth/Advance Care Planning, Yun and colleagues [38] found the tool positively impacted patients' mood and general wellbeing. A quantitative study in Germany also observed patient quality of life improvements with decision aid use [53]. In contrast, 2 United States quantitative studies did not find decision aid use improved patient anxiety [25,28], and 1 United States mixed methods study did not find decision aid use improved general stress levels [21]. 3.7. Tool satisfaction While not a direct measure of patient outcomes, tool satisfaction was a common measurement across studies. Tool satisfaction refers to the level of fulfillment of one's expectations or needs that individuals experience from using the decision aids. The 8 studies measuring tool satisfaction (5 quantitative, 2 qualitative, and 1 mixed) were all from the United States, reporting positive patient satisfaction [27,41,47,[54], [55], [56], [57], [58]]. Only one qualitative study noted a lack of tool satisfaction; however, it was with physicians. In that study, while the patients expressed appreciation for the tool, the non-palliative care providers reported low satisfaction rates, discussing concerns that the tool would devalue their role while also providing the patients a \u201cdeath message\u201d [57]. 4. Discussion and conclusion 4.1. Discussion Our research suggests that decision aid use for end-of-life care is viewed favorably by patients and improves outcomes related to patients' decision certainty, knowledge, and desires for less aggressive care. Studies across numerous countries report these positive findings, suggesting that these patient-centered tools can provide value across different cultures and health systems. Furthermore, our review shows that using IPDAS guidelines when developing decision aids may result in more effective decision aids for end-of-life care. There has been a paradigm shift in healthcare over the last couple of decades to a more patient-centered system [59]. With this approach, the patient is a more active participant in their healthcare. The use of decision aids ties in with this transforming approach to care; these tools help align the care received with the patient's values and preferences. Our review provides evidence across studies that decision aids for end-of-life care can effectively accomplish this goal. Therefore, payers, including private and public programs like Medicare, should consider investing in developing and implementing decision aids to help their members choose their dying preferences. Two of the handful of studies that did not report positive results examined outcomes from the provider perspective [19,57]. In these cases, the providers' viewpoints on the aids did not coincide with their patients. Further research should examine whether providers are observing actual negative consequences for patients and their surrogates or whether these results relate to a reluctance to change practices or some other conflicting viewpoint. While the evidence consistently highlights that decision aids improve patient knowledge of end-of-life choices and increase desires to pursue less aggressive care, whether patients and their surrogates take steps to complete forms that would help ensure meeting patient preferences is unclear. In examining our review findings through the lens of the Stages of Change Model, also called the Transtheoretical Model [60], it appears that decision aids may have more of an impact on the earlier stages of change (pre-contemplation, contemplation, and preparation) than the later \u201caction\u201d stage of change. Future research should investigate strategies for helping patients and their surrogates progress through the action stage of change, where they modify their end-of-life care wishes in writing; this, in turn, would likely increase the chances of receiving their intended end-of-life care experience. Decision aids for end-of-life care should ideally be tools that the patients and families can revisit. In a longitudinal analysis of a discrete choice experiment, Yong and colleagues [61] found that advanced cancer patients' preferences for quality-of-life outcomes versus survival extension in Malaysia changed over time. After three months, the patients attributed more importance to physical functioning, pain control, and costs and less importance to psychological functioning, social functioning, survival, and place of death than they had initially. Healthcare professionals and researchers who develop decision aids for end-of-life care should consider that patient preferences may change and integrate flexibility and adaptability into the tools. With all studies reviewed from high-income economies [17], patients and their families and surrogates from lower-income countries are not represented. Future studies must examine decision aids delivered to individuals across the globe. People from different cultures can respond to decisions about death in various ways [62], and decision aids for one cultural group may not have the same effectiveness for a group from a separate region of the world or even another area of the same country. 4.2. Innovation Opting for comfort care instead of life-sustaining treatment often happens despite the patient not intending that choice [63] or patients and their families not being aware of palliative care and its benefits [64]. Our review is innovative in that we examine all studies that investigated the effectiveness of decision aids for end-of-life care to determine which decision aids may work to potentially prevent the unintended outcome that happens too frequently - pursuing life-sustaining treatment that results in unnecessary patient suffering. With the recent advent of available machine learning technology, there is an opportunity to build upon the effective decision aids identified in this review to enhance decision aids in the future. Lamanna and Byrne [65] suggest that an autonomy algorithm could help predict patient preferences using health records and other patient characteristics. Our review finding that following IPDAS guidelines during decision aid development is associated with positive end-of-life care outcomes reinforces the importance of incorporating these guidelines when using innovative technologies such as machine learning in developing decision aids. 4.3. Limitations By limiting our study to peer-reviewed research, we may be missing case studies or reports evaluating end-of-life decision aids. The inclusion criteria required studies to explicitly highlight an end-of-life care focus of the decision aid. As such, research on comprehensive disease-specific decision aids which may have an end-of-life care arm were not included in the scope of this review. In addition, by summarizing the themes of qualitative research, certain nuances related to specific decision aids were not included. Similarly, our process of categorizing quantitative outcomes and summarizing success simplified complex statistical findings related to the decision aids studied. 4.4. Conclusion Our systematic review highlights the vital role decision aids can play in improving the end-of-life experience for patients and their families and surrogates. While there are many effective decision aids, implementing them in practice and before it's too late for patients should be a focus of future research. As researchers and healthcare professionals work to improve the quality of life for dying individuals, using effective decision aids can contribute to patient-centered care, promoting dignity and respect at a most challenging stage of life. Funding This research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors. CRediT authorship contribution statement M. Courtney Hughes: Writing \u2013 review & editing, Writing \u2013 original draft, Supervision, Methodology, Formal analysis, Data curation, Conceptualization. Erin Vernon: Writing \u2013 review & editing, Writing \u2013 original draft, Supervision, Methodology, Formal analysis, Data curation, Conceptualization. Chinenye Egwuonwu: Writing \u2013 original draft, Formal analysis, Data curation. Oluwatoyosi Afolabi: Writing \u2013 original draft, Formal analysis, Data curation. Declaration of competing interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Appendix A. Supplementary data Download : Download Word document (48KB) Supplementary material References [1] National Institute on Aging Providing care and comfort at the end of life https://www.nia.nih.gov/health/providing-comfort-end-life (2022) (accessed November 9, 2023) Google Scholar [2] L.C. Kaldjian, A.E. Curtis, L.A. Shinkunas, K.T. Cannon Goals of care toward the end of life: a structured literature review Am J Hosp Palliat Med, 25 (2009), pp. 501-511 CrossRefView in ScopusGoogle Scholar [3] M. Cardona-Morrell, G. Benfatti-Olivato, J. Jansen, R.M. Turner, D. Fajardo-Pulido, K. Hillman A systematic review of effectiveness of decision aids to assist older patients at the end of life Patient Educ Couns, 100 (2017), pp. 425-435, 10.1016/j.pec.2016.10.007 View PDFView articleView in ScopusGoogle Scholar [4] L.J. Brighton, K. Bristowe Communication in palliative care: talking about the end of life, before the end of life Postgrad Med J, 92 (2016), pp. 466-470, 10.1136/postgradmedj-2015-133368 View in ScopusGoogle Scholar [5] N. Khandelwal, J.R. Curtis, V.A. Freedman, J.D. Kasper, P. Gozalo, R.A. Engelberg, et al. How often is end-of-life care in the United States inconsistent with patients\u2019 goals of care? J Palliat Med, 20 (2017), pp. 1400-1404 CrossRefView in ScopusGoogle Scholar [6] G. Phillips, K. Lifford, A. Edwards, M. Poolman, N. Joseph-Williams Do published patient decision aids for end-of-life care address patients\u2019 decision-making needs? A systematic review and critical appraisal Palliat Med, 33 (2019), pp. 985-1002 CrossRefView in ScopusGoogle Scholar [7] E.A. Gans, L.A. van Mun, J.F. de Groot, B.C. van Munster, E.A. Rake, J.C. van Weert, et al. Supporting older patients in making healthcare decisions: the effectiveness of decision aids; a systematic review and meta-analysis Patient Educ Couns, 107981 (2023) Google Scholar [8] D. Stacey, F. L\u00e9gar\u00e9, K. Lewis, M.J. Barry, C.L. Bennett, K.B. Eden, et al. Decision aids for people facing health treatment or screening decisions Cochrane Database Syst Rev, 319 (7212) (2017), pp. 731-734 Google Scholar [9] A. Jain, S. Corriveau, K. Quinn, A. Gardhouse, D.B. Vegas, J.J. You Video decision aids to assist with advance care planning: a systematic review and meta-analysis BMJ Open, 5 (2015), Article e007491 CrossRefView in ScopusGoogle Scholar [10] I. Spronk, J.S. Burgers, F.G. Schellevis, L.M. van Vliet, J.C. Korevaar The availability and effectiveness of tools supporting shared decision making in metastatic breast cancer care: a review BMC Palliat Care, 17 (2018), p. 74, 10.1186/s12904-018-0330-4 View in ScopusGoogle Scholar [11] N. Davies, B. Schiowitz, G. Rait, V. Vickerstaff, E.L. Sampson Decision aids to support decision-making in dementia care: a systematic review Int Psychogeriatr, 31 (2019), pp. 1403-1419, 10.1017/S1041610219000826 Google Scholar [12] N.D. Eneanya, S.G. Percy, T.L. Stallings, W. Wang, D.J.R. Steele, M.J. Germain, et al. Use of a supportive kidney care video decision aid in older patients: a randomized controlled trial Am J Nephrol, 51 (2020), pp. 736-744, 10.1159/000509711 View in ScopusGoogle Scholar [13] International Patient Decision Aid Standards (IPDAS), Collaboration, International Patient Decision Aid Standards (IPDAS) Collaboration http://ipdas.ohri.ca (2019) Google Scholar [14] K.R. Sepucha, C.M. Borkhoff, J. Lally, C.A. Levin, D.D. Matlock, C.J. Ng, et al. Establishing the effectiveness of patient decision aids: key constructs and measurement instruments BMC Med Inform Decis Mak, 13 (2013), pp. 1-11 Google Scholar [15] Q. Hong, P. Pluye, S. F\u00e0bregues, G. Bartlett Mixed Methods Appraisal Tool (MMAT), version 2018 (2018) Google Scholar [16] R. Pace, P. Pluye, G. Bartlett, A.C. Macaulay, J. Salsberg, J. Jagosh, et al. Testing the reliability and efficiency of the pilot Mixed Methods Appraisal Tool (MMAT) for systematic mixed studies review Int J Nurs Stud, 49 (2012), pp. 47-53 View PDFView articleView in ScopusGoogle Scholar [17] World Bank Country and Lending Groups, World Bank, n.d. https://datahelpdesk.worldbank.org/knowledgebase/articles/906519-world-bank-country-and-lending-groups [accessed November 9, 2023]. Google Scholar [18] S.M. Symmons, K. Ryan, S.M. Aoun, L.E. Selman, A.N. Davies, N. Cornally, et al. Decision-making in palliative care: patient and family caregiver concordance and discordance\u2014systematic review and narrative synthesis BMJ Support Palliat Care, 13 (2023), pp. 374-385 Google Scholar [19] D.K. Heyland, R. Heyland, A. Bailey, M. Howard A novel decision aid to help plan for serious illness: a multisite randomized trial Can Med Assoc Open Access J, 8 (2020), pp. E289-E296 CrossRefView in ScopusGoogle Scholar [20] D.B. Simmons, B.H. Levi, M.J. Green, I.S. La, D. Lipnick, T.J. Smith, et al. What surrogates understand (and don\u2019t understand) about patients\u2019 wishes after engaging Advance Care Planning: a qualitative analysis Am J Hosp Palliat Med, 39 (2022), pp. 427-432 CrossRefView in ScopusGoogle Scholar [21] D. Lipnick, M. Green, E. Thiede, T.J. Smith, E.B. Lehman, R. Johnson, et al. Surrogate decision maker stress in advance care planning conversations: a mixed-methods analysis from a randomized controlled trial J Pain Symptom Manage, 60 (2020), pp. 1117-1126, 10.1016/j.jpainsymman.2020.07.001 View PDFView articleView in ScopusGoogle Scholar [22] R. Agarwal, E. Shuk, D. Romano, M. Genoff, Y. Li, E.M. O\u2019Reilly, et al. A mixed methods analysis of patients\u2019 advance care planning values in outpatient oncology: Person-Centered Oncologic Care and Choices (P-COCC) Support Care Cancer, 28 (2020), pp. 1109-1119, 10.1007/s00520-019-04910-1 View in ScopusGoogle Scholar [23] E. Thiede, B.H. Levi, D. Lipnick, R. Johnson, I. Seo La, E.B. Lehman, et al. Effect of advance care planning on surrogate decision makers\u2019 preparedness for decision making: results of a mixed-methods randomized controlled trial J Palliat Med, 24 (2021), pp. 982-993, 10.1089/jpm.2020.0238 View in ScopusGoogle Scholar [24] National Institute on Aging What are palliative care and hospice care? https://www.nia.nih.gov/health/hospice-and-palliative-care/what-are-palliative-care-and-hospice-care (2021) (accessed November 23, 2023) Google Scholar [25] M.J. Green, J.R. Schubart, M.M. Whitehead, E. Farace, E. Lehman, B.H. Levi Advance care planning does not adversely affect hope or anxiety among patients with advanced cancer J Pain Symptom Manage, 49 (2015), pp. 1088-1096, 10.1016/j.jpainsymman.2014.11.293 View PDFView articleView in ScopusGoogle Scholar [26] S.A. Markham, B.H. Levi, M.J. Green, J.R. Schubart Use of a computer program for advance care planning with African American participants J Natl Med Assoc, 107 (2015), pp. 26-32 View PDFView articleView in ScopusGoogle Scholar [27] L.J. Van Scoy, M.J. Green, A.E. Dimmock, R. Bascom, J.P. Boehmer, J.K. Hensel, et al. High satisfaction and low decisional conflict with advance care planning among chronically ill patients with advanced chronic obstructive pulmonary disease or heart failure using an online decision aid: a pilot study Chronic Illn, 12 (2016), pp. 227-235, 10.1177/1742395316633511 View in ScopusGoogle Scholar [28] B.H. Levi, Z. Simmons, C. Hanna, A. Brothers, E. Lehman, E. Farace, et al. Advance care planning for patients with amyotrophic lateral sclerosis Amyotroph Lateral Scler Front Degener, 18 (2017), pp. 388-396, 10.1080/21678421.2017.1285317 View in ScopusGoogle Scholar [29] A.E. Volandes, T.T. Levin, S. Slovin, R.D. Carvajal, E.M. O\u2019Reilly, M.L. Keohan, et al. Augmenting advance care planning in poor prognosis cancer with a video decision aid: a pre-post study Cancer., 118 (2012), pp. 4331-4338, 10.1002/cncr.27423 View in ScopusGoogle Scholar [30] J.V. Gallegos, B. Edelstein, A.H. Moss Evaluation of a video decision aid to reduce decisional conflict in Physician Orders for Life-Sustaining Treatment (POLST) decision-making J Palliat Care, 35 (2020), pp. 243-247, 10.1177/0825859720923437 View in ScopusGoogle Scholar [31] K.V. Dharmarajan, C.B. Walters, T.T. Levin, C.A. Milazzo, C. Monether, R. Rawlins-Duell, et al. A video decision aid improves informed decision-making in patients with advanced cancer considering palliative radiation therapy J Pain Symptom Manage, 58 (2019), pp. 1048-1055.e2, 10.1016/j.jpainsymman.2019.08.014 View PDFView articleView in ScopusGoogle Scholar [32] D.D. Matlock, T.A.E. Keech, M.B. McKenzie, M.R. Bronsert, C.T. Nowels, J.S. Kutner Feasibility and acceptability of a decision aid designed for people facing advanced or terminal illness: a pilot randomized trial Health Expect Int J Public Particip, 17 (2014), pp. 49-59, 10.1111/j.1369-7625.2011.00732.x Health Care Health Policy View in ScopusGoogle Scholar [33] S.H. Sharkiya Quality communication can improve patient-centred health outcomes among older patients: a rapid review BMC Health Serv Res, 23 (2023), p. 886 View in ScopusGoogle Scholar [34] E.M. Ozanne, A. Partridge, B. Moy, K.J. Ellis, K.R. Sepucha Doctor\u2013patient communication about advance directives in metastatic breast cancer J Palliat Med, 12 (2009), pp. 547-553, 10.1089/jpm.2008.0254 View in ScopusGoogle Scholar [35] J.R. Schubart, B.H. Levi, M.M. Bain, E. Farace, M.J. Green Advance care planning among patients with advanced cancer J Oncol Pract, 15 (2019), pp. e65-e73, 10.1200/JOP.18.00044 Google Scholar [36] L.C. Hanson, S. Zimmerman, M.-K. Song, F.-C. Lin, C. Rosemond, T.S. Carey, et al. Effect of the goals of care intervention for advanced dementia: a randomized clinical trial JAMA Intern Med, 177 (2017), p. 24, 10.1001/jamainternmed.2016.7031 View in ScopusGoogle Scholar [37] K. Yamamoto, T. Kaido, T. Yokoi, G. Shimada, T. Taketa, K. Nakayama Implementation of advance care planning decision aids for patients undergoing high-risk surgery: a field-testing study BMC Palliat Care, 21 (2022), p. 179, 10.1186/s12904-022-01068-2 View in ScopusGoogle Scholar [38] Y.H. Yun, M.K. Lee, S. Park, J.L. Lee, J. Park, Y.S. Choi, et al. Use of a decision aid to help caregivers discuss terminal disease status with a family member with cancer: a randomized controlled trial J Clin Oncol, 29 (2011), pp. 4811-4819, 10.1200/JCO.2011.35.3870 View in ScopusGoogle Scholar [39] A.A. Wright, N.L. Keating, J.Z. Ayanian, E.A. Chrischilles, K.L. Kahn, C.S. Ritchie, et al. Family perspectives on aggressive cancer care near the end of life JAMA., 315 (2016), pp. 284-292 CrossRefView in ScopusGoogle Scholar [40] A. El-Jawahri, S.L. Mitchell, M.K. Paasche-Orlow, J.S. Temel, V.A. Jackson, R.R. Rutledge, et al. A randomized controlled trial of a CPR and intubation video decision support tool for hospitalized patients J Gen Intern Med, 30 (2015), pp. 1071-1080, 10.1007/s11606-015-3200-2 View in ScopusGoogle Scholar [41] N.N. Ufere, B. Robinson, J. Donlan, T. Indriolo, J. Bloom, A. Scherrer, et al. Pilot randomized controlled trial of an advance care planning video decision tool for patients with advanced liver disease Clin Gastroenterol Hepatol, 20 (2022), pp. 2287-2295.e3, 10.1016/j.cgh.2021.10.027 View PDFView articleView in ScopusGoogle Scholar [42] J.M. Friend, D.L. Alden Improving patient preparedness and confidence in discussing advance directives for end-of-life care with health care providers in the United States and Japan Med Decis Making, 41 (2021), pp. 60-73 CrossRefView in ScopusGoogle Scholar [43] A.E. Volandes, L.A. Ferguson, A.D. Davis, N.C. Hull, M.J. Green, Y. Chang, et al. Assessing end-of-life preferences for advanced dementia in rural patients using an educational video: a randomized controlled trial J Palliat Med, 14 (2011), pp. 169-177, 10.1089/jpm.2010.0299 View in ScopusGoogle Scholar [44] Y.H. Yun, E. Kang, S. Park, S.-J. Koh, H.-S. Oh, B. Keam, et al. Efficacy of a decision aid consisting of a video and booklet on advance care planning for advanced cancer patients: randomized controlled trial J Pain Symptom Manage, 58 (2019), pp. 940-948.e2, 10.1016/j.jpainsymman.2019.07.032 View PDFView articleView in ScopusGoogle Scholar [45] C. Kapell Brown, J. Kryworuchko, W. Martin Evaluation of the CPR video decision aid with patients with end stage renal disease BMC Nephrol, 19 (2018), p. 226, 10.1186/s12882-018-1018-y View in ScopusGoogle Scholar [46] W.-T. Hsieh Virtual reality video promotes effectiveness in advance care planning BMC Palliat Care, 19 (2020), p. 125, 10.1186/s12904-020-00634-w View in ScopusGoogle Scholar [47] M. Bakitas, J.N. Dionne-Odom, L. Jackson, J. Frost, M.F. Bishop, Z. Li \u201cThere were more decisions and more options than just yes or no\u201d: evaluating a decision aid for advanced cancer patients and their family caregivers Palliat Support Care, 15 (2017), pp. 44-56, 10.1017/S1478951516000596 View in ScopusGoogle Scholar [48] R.A. Jones, P.J. Hollen, J. Wenzel, G. Weiss, D. Song, T. Sims, et al. Understanding advanced prostate cancer decision-making utilizing an interactive decision aid Cancer Nurs, 41 (2018), pp. 2-10, 10.1097/NCC.0000000000000442 View in ScopusGoogle Scholar [49] L. Vigouret-Viant, C. Legoupil, A. Bardet, C. Laurent, M. Ducreux, S. Laurent, et al. Development of a Decision-Aid Form (DAF) for the stratification of care in a French comprehensive cancer center, a tool to support identification of care goals Ann Palliat Med, 11 (2022), 10.21037/apm-21-2854 1876887\u20131871887 Google Scholar [50] H.D. Lum, D.E. Barnes, M.T. Katen, Y. Shi, J. Boscardin, R.L. Sudore Improving a full range of advance care planning behavior change and action domains: the PREPARE randomized trial J Pain Symptom Manage, 56 (2018), pp. 575-581.e7, 10.1016/j.jpainsymman.2018.06.007 View PDFView articleView in ScopusGoogle Scholar [51] M.J. Green, L.J. Van Scoy, A.J. Foy, A.E. Dimmock, E. Lehman, B.H. Levi Patients with advanced cancer choose less aggressive medical treatment on vignettes after using a computer-based decision aid Am J Hosp Palliat Med, 37 (2020), pp. 537-541 CrossRefView in ScopusGoogle Scholar [52] National Center for Health Statistics Chapter 18: Health-related quality of life and well-being Healthy people 2020 midcourse rev (2016) Hyattsville, MD https://www.cdc.gov/nchs/data/hpdata2020/HP2020MCR-C18-HRQOL-WB.pdf Google Scholar [53] K. van Baal, B. Wiese, G. M\u00fcller-Mundt, S. Stiel, N. Schneider, K. Afshar Quality of end-of-life care in general practice \u2013 a pre\u2013post comparison of a two-tiered intervention BMC Prim Care, 23 (2022), p. 90, 10.1186/s12875-022-01689-9 View in ScopusGoogle Scholar [54] M.J. Green, B.H. Levi Development of an interactive computer program for advance care planning Health Expect, 12 (2009), pp. 60-69, 10.1111/j.1369-7625.2008.00517.x View in ScopusGoogle Scholar [55] C. Hossler, B.H. Levi, Z. Simmons, M.J. Green Advance care planning for patients with ALS: feasibility of an interactive computer program Amyotroph Lateral Scler, 12 (2011), pp. 172-177, 10.3109/17482968.2010.509865 View in ScopusGoogle Scholar [56] T.J. Smith, L.A. Dow, E.A. Virago, J. Khatcheressian, R. Matsuyama, L.J. Lyckholm A pilot trial of decision aids to give truthful prognostic and treatment information to chemotherapy patients with advanced cancer J Support Oncol, 9 (2011), pp. 79-86, 10.1016/j.suponc.2010.12.005 View in ScopusGoogle Scholar [57] J. Jones, C. Nowels, J.S. Kutner, D.D. Matlock Shared decision making and the use of a patient decision aid in advanced serious illness: provider and patient perspectives Health Expect, 18 (2015), pp. 3236-3247, 10.1111/hex.12313 View in ScopusGoogle Scholar [58] L.M. Uhler, R.E. P\u00e9rez Figueroa, M. Dickson, L. McCullagh, A. Kushniruk, H. Monkman, et al. InformedTogether: usability evaluation of a web-based decision aid to facilitate shared advance care planning for severe chronic obstructive pulmonary disease JMIR Hum Factors, 2 (2015), Article e2, 10.2196/humanfactors.3842 View in ScopusGoogle Scholar [59] W.B. Applegate, J.G. Ouslander, G.A. Kuchel Implementing \u201cpatient-centered care\u201d: a revolutionary change in health care delivery J Am Geriatr Soc, 66 (2018), pp. 1863-1865 CrossRefView in ScopusGoogle Scholar [60] J.O. Prochaska Decision making in the transtheoretical model of behavior change Med Decis Making, 28 (2008), pp. 845-849 View in ScopusGoogle Scholar [61] A.S.J. Yong, K.K. Lim, J. Fox-Rushby, F. Ismail, E. Hamzah, M.W.L. Cheong, et al. A longitudinal evaluation of advanced cancer patients\u2019 preferences for quality of life and survival in Malaysia: a discrete choice experiment Value Health, 26 (12) (2023), pp. 1772-1781 View PDFView articleView in ScopusGoogle Scholar [62] M.C. Hughes, E. Vernon \u201cWe are here to assist all individuals who need hospice services\u201d: Hospices\u2019 perspectives on improving access and inclusion for racial/ethnic minorities Gerontol Geriatr Med, 6 (2020) 2333721420920414 Google Scholar [63] J. Breslin The status quo bias and decisions to withdraw life-sustaining treatment CMAJ., 190 (2018), pp. E265-E267 CrossRefView in ScopusGoogle Scholar [64] S.P. Flieger, K. Chui, S. Koch-Weser Lack of awareness and common misconceptions about palliative care among adults: insights from a national survey J Gen Intern Med, 35 (2020), pp. 2059-2064 CrossRefView in ScopusGoogle Scholar [65] C. Lamanna, L. Byrne Should artificial intelligence augment medical decision making? The case for an autonomy algorithm AMA J Ethics, 20 (2018), pp. 902-910 Google Scholar Cited by (0) \u00a9 2024 The Authors. Published by Elsevier B.V. Part of special issue Palliative, hospice, and end-of-life care Edited by Emily Mroz Yale School of Medicine, New Haven, Connecticut, United States of America, Jordan Alpert Cleveland Clinic Center for Value-Based Care Research, Cleveland, Ohio, United States of America View special issue Recommended articles Hemoglobin Levels Pre- and Posttreatment as a Surrogate for Disease Severity in Early-Onset Scoliosis Spine Deformity, Volume 7, Issue 4, 2019, pp. 641-646 Michael Glotzbecker, \u2026, John Emans An online intervention to improve the health and well-being of informal caregivers of individuals with Alzheimer's disease: A pilot study PEC Innovation, Volume 3, 2023, Article 100229 Yujun Liu, \u2026, Lily Derain View PDF About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright \u00a9 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply.",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "Machine learning-driven prognostic analysis of cuproptosis and disulfidptosis-related lncRNAs in clear cell renal cell carcinoma: a step towards precision oncology",
    "doi": "10.1186/s40001-024-01763-1",
    "description": "Cuproptosis and disulfidptosis, recently discovered mechanisms of cell death, have demonstrated that differential expression of key genes and long non-coding RNAs (lncRNAs) profoundly influences tumor development and affects their drug sensitivity. Clear cell renal cell carcinoma (ccRCC), the most common subtype of kidney cancer, presently lacks research utilizing cuproptosis and disulfidptosis-related lncRNAs (CDRLRs) as prognostic markers. In this study, we analyzed RNA-seq data, clinical information, and mutation data from The Cancer Genome Atlas (TCGA) on ccRCC and cross-referenced it with known cuproptosis and disulfidptosis-related genes (CDRGs). Using the LASSO machine learning algorithm, we identified four CDRLRs\u2014ACVR2B-AS1, AC095055.1, AL161782.1, and MANEA-DT\u2014that are strongly associated with prognosis and used them to construct a prognostic risk model. To verify the model's reliability and validate these four CDRLRs as significant prognostic factors, we performed dataset grouping validation, followed by RT-qPCR and external database validation for differential expression and prognosis of CDRLRs in ccRCC. Gene function and pathway analysis were conducted using Gene Ontology (GO) and Gene Set Enrichment Analysis (GSEA) for high- and low-risk groups. Additionally, we have analyzed the tumor mutation burden (TMB) and the immune microenvironment (TME), employing the oncoPredict and Immunophenoscore (IPS) algorithms to assess the sensitivity of diverse risk categories to targeted therapeutics and immunosuppressants. Our predominant objective is to refine prognostic predictions for patients with ccRCC and inform treatment decisions by conducting an exhaustive study on cuproptosis and disulfidptosis.",
    "journal": "European Journal of Medical Research",
    "authors": [
      "Chen R.",
      "Wu J.",
      "Che Y.",
      "Jiao Y.",
      "Sun H.",
      "Zhao Y.",
      "Chen P.",
      "Meng L.",
      "Zhao T."
    ],
    "citation_count": "0",
    "full_text": "Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Advertisement Search Explore journals Get published About BMC Login European Journal of Medical Research Home About Articles Submission Guidelines Submit manuscript Research Open access Published: 16 March 2024 Machine learning-driven prognostic analysis of cuproptosis and disulfidptosis-related lncRNAs in clear cell renal cell carcinoma: a step towards precision oncology Ronghui Chen, Jun Wu, Yinwei Che, Yuzhuo Jiao, Huashan Sun, Yinuo Zhao, Pingping Chen, Lingxin Meng & Tao Zhao  European Journal of Medical Research  29, Article number: 176 (2024) Cite this article 209 Accesses 1 Altmetric Metrics Abstract Cuproptosis and disulfidptosis, recently discovered mechanisms of cell death, have demonstrated that differential expression of key genes and long non-coding RNAs (lncRNAs) profoundly influences tumor development and affects their drug sensitivity. Clear cell renal cell carcinoma (ccRCC), the most common subtype of kidney cancer, presently lacks research utilizing cuproptosis and disulfidptosis-related lncRNAs (CDRLRs) as prognostic markers. In this study, we analyzed RNA-seq data, clinical information, and mutation data from The Cancer Genome Atlas (TCGA) on ccRCC and cross-referenced it with known cuproptosis and disulfidptosis-related genes (CDRGs). Using the LASSO machine learning algorithm, we identified four CDRLRs\u2014ACVR2B-AS1, AC095055.1, AL161782.1, and MANEA-DT\u2014that are strongly associated with prognosis and used them to construct a prognostic risk model. To verify the model's reliability and validate these four CDRLRs as significant prognostic factors, we performed dataset grouping validation, followed by RT-qPCR and external database validation for differential expression and prognosis of CDRLRs in ccRCC. Gene function and pathway analysis were conducted using Gene Ontology (GO) and Gene Set Enrichment Analysis (GSEA) for high- and low-risk groups. Additionally, we have analyzed the tumor mutation burden (TMB) and the immune microenvironment (TME), employing the oncoPredict and Immunophenoscore (IPS) algorithms to assess the sensitivity of diverse risk categories to targeted therapeutics and immunosuppressants. Our predominant objective is to refine prognostic predictions for patients with ccRCC and inform treatment decisions by conducting an exhaustive study on cuproptosis and disulfidptosis. Introduction Renal cancer is a common urologic malignancy, with 81,800 new cases of renal and pelvic cancer and 14,890 projected deaths according to the 2023 US cancer statistics [1]. Renal cell carcinoma (RCC) constitutes approximately 85% of all renal tumors, with clear cell renal cell carcinoma (ccRCC) being the most prevalent subtype, accounting for 75% of RCC cases [2, 3]. Surgical removal of renal tissue is the main treatment modality for early-stage ccRCC, and about 1/3 of ccRCC patients are already advanced at diagnosis, which often means high mortality, and metastasis rates [4]. ccRCC is characterized by a high degree of resistance to chemotherapy and a dense vascular distribution. Treatment commonly involves tyrosine kinase inhibitors (TKIs) targeting the VEGFR pathway [5]. Recent years have seen the validation of immunotherapy's efficacy, with studies indicating that combining TKIs with immunotherapy yields better clinical outcomes compared to monotherapy with targeted agents [6, 7]. Immune checkpoint inhibitors in combination with targeted agents are now the first-line option of choice for advanced ccRCC [8]. Prognostic scoring systems for ccRCC have contributed significantly to clinical diagnosis and prognostic assessment, for which better prognostic models are urgently needed to guide immune combination targeted drug therapy and to assess and guide the direction of clinical treatment for ccRCC patients. The mechanism of action of antitumor drugs largely depends on inducing cell death, with numerous small molecules targeting cell death pathways having been identified and utilized in clinical trials [9]. Unlike known cell death mechanisms such as apoptosis, autophagy, and ferroptosis, the emergence of cuproptosis and disulfideptosis provides new directions for understanding cell metabolism and the tumor microenvironment (TME), laying the foundation for novel tumor treatment strategies. Cuproptosis is defined as the process whereby copper ions induce proteotoxic stress. This occurs when copper ions bind to the lipid-acylated constituents of the tricarboxylic acid cycle (TCA), instigating lipid-acylated protein aggregation. This aggregation subsequently results in the downregulation of iron-sulfur (Fe-S) cluster proteins, culminating in proteotoxic stress [10]. Disulfidptosis is a condition in which abnormal expression of SLC7A11 under glucose starvation causes a decrease in NADPH that counteracts disulfide toxicity and inadequate reduction of disulfide cystine, resulting in disulfide accumulation that generates disulfide stress, induces the disulfide bond between actin and cytoskeletal proteins to be stripped from the cytoplasmic membrane, and ultimately leads to cell death [11]. The discovery of cuproptosis and disulfidptosis represents a significant advancement in the identification of novel metabolic regulatory mechanisms in cancer [12, 13], potentially indicating new pathways for cancer therapy. Cuproptosis and disulfidptosis are mechanisms of cellular demise intricately linked to the progression of various oncological pathologies, potentially serving as pivotal determinants of cancer prognoses [13, 14]. Studies conducted by Bian et al. [15] have posited that genes implicated in copper-mediated cytotoxicity may serve as viable prognostic biomarkers for ccRCC. Furthermore, research by Yuan et al. [16] underscores the significance of these genes in forecasting ccRCC patient outcomes in response to immunotherapeutic and targeted treatment modalities. Complementarily, Liu et al. [11] have substantiated the occurrence of disulfidptosis within renal carcinoma cells and in vivo animal models, facilitated by targeted pharmacological interventions. Prognostic models currently in development, which incorporate disulfidptosis-associated genetic markers, are poised to enhance prognostic accuracy and inform drug response evaluations in clinical settings [17, 18]. Despite existing research integrating ferroptosis with cuproptosis [19], studies investigating their concurrent impact remain elusive. Considering the pronounced association of ccRCC with both cuproptosis and disulfidptosis, it is hypothesized that their amalgamation could unveil novel avenues for prognostic refinement and therapeutic approaches for afflicted individuals. Long non-coding RNAs (lncRNAs) are involved in the regulation of tumor protein-coding gene expression through binding to chromatin-modifying proteins, transcription factors, miRNAs, etc. [20]. lncRNAs regulate mitochondrial dynamics such as the TCA cycle, synthesis of cytoplasmic biological precursors, and in ccRCC cells through metabolic reprogramming to regulate cancer cell malignant transformation and control cellular energy expression [21, 22]. Machine learning, an offshoot of artificial intelligence, refines prediction models to forecast individual survival outcomes using extensive prognostic parameters [23]. Notably, the LASSO and Cox regression algorithms excel in accuracy and effectiveness for survival prediction modeling [24, 25]. The integration of machine learning with LncRNA analysis now markedly enhances prognostic and drug sensitivity assessments in oncology [26, 27]. Motivated by these advancements, we propose to leverage machine learning in investigating LncRNAs pertinent to cuproptosis and ferroptosis in ccRCC. This study aims to develop a prognostic model of cuproptosis and disulfidptosis-related lncRNAs (CDRLRs) by analyzing real data of ccRCC patients in the TCGA database, combining cuproptosis and disulfidptosis-related genes, analyzing the TME, tumor mutational burden (TMB), and prognostic survival analysis to further analyze potential immune checkpoint inhibitors and targeted drugs with high clinical value. Figure 1 depicts the flowchart delineating the process of this study. Fig. 1 Research process flowchart Full size image Materials and methods Data collecting The RNA-seq data for ccRCC were obtained from The Cancer Genome Atlas (TCGA) database (https://portal.gdc.cancer.gov) specifically the TCGA-KIRC dataset, which included details from 542 tumor samples and 72 normal tissue samples (accessed on 23 March 2023). The data were evaluated utilizing the \u201climma\u201d package [28] in R software (version: R-4.2.2). This analysis incorporated pertinent clinical information including patient age, gender, tumor stage, histological grading, survival results, and duration of follow-up. To extract the RNA-seq data, we used a Perl script [29] (version Strawberry-perl-5.30.0.1; https://www.perl.org), and the extracted data were standardized to FPKM format. Genes with zero expression were excluded from the sample set. Additionally, somatic mutation data in mutation annotation format (MAF) were processed and visualized with the assistance of the \u201cmaftools\u201d package [30]. Differential expression identification and association of CDRGs with CDRLRs We extracted genes related to cuproptosis and disulfidptosis-related genes (CDRGs) from various published sources [11, 31]. In total, 23 CDRGs were identified, with 13 being CDRGs: DLD, PDHB, ATP7B, ATP7A, DLAT, DLST, SLC31A1, DBT, FDX1, LIPIT1, LIAS, GCSH, and PDHA1, and the remaining 10 identified as disulfidptosis-related genes: GYS1, NDUFS1, OXSM, LRPPRC, NDUFA11, NUBPL, NCKAP1, RPN1, SLC3A2, and SLC7A11. The correlation between cuproptosis and disulfidptosis was analyzed based on the STRING database (https://cn.string-db.org/), and the network diagram of CDRGs was plotted using Cytoscape (version: 3.9.1). The expression matrix of cuproptosis and disulfidptosis-related lncRNAs was obtained using the R packages \u201cBiocManager\u201d and \u201climma\u201d [28, 32], with selection criteria of |Pearson R|>\u20090.5 and p\u2009<\u20090.001. The Sankey diagram elucidating the relationship between CDRLRs and CDRGs was generated with the R packages \u201cggplot2\u201d and \u201cggalluvial\u201d [33]. Construction and validation of risk model for CDRLRs by machine learning algorithms LASSO represents a machine learning algorithm rooted in regression. It incorporates a regularization function atop logistic regression, mitigating overfitting and independently eliminating low correlation covariates to secure relatively substantial model variables. The LASSO-Cox regression algorithm, implemented via the \u201cglmnet\u201d R package, was utilized to scrutinize the correlation between CDRLRs and the overall survival (OS) of ccRCC patients. A comprehensive integration of univariate and multivariate Cox regression analyses enabled the identification of CDRLRs significantly related to OS. Subsequently, risk scores were computed for each patient using the ensuing formula: The symbol \u201cn\u201d represents the quantity of ccRCC prognosis-associated CDRLRs, \u201ci\u201d symbolizes the ith CDRLR, and the expressions of lncRNA and regression coefficients are denoted by Coefi and LncRNAexpri respectively [34]. The training set, testing set, and the entire set were classified into high- and low-risk categories based on the median risk scores. Nomogram plotting and Kaplan\u2013Meier (K\u2013M) survival analysis To measure the model\u2019s accuracy, Receiver Operating Characteristic (ROC) curves accompanied by C-index plots were generated using R packages \u201csurvminer\u201d, \u201csurvival\u201d, \u201ctimeROC\u201d, \u201crms\u201d and \u201cpec\u201d [35]. The R package \u201cregplot\u201d was employed to produce nomogram and calibration plots, facilitating the prediction of patient prognosis and the assessment of prognostic accuracy. The correlation between clinical characteristics and Kaplan\u2013Meier survival curves for high- and low-risk groups was delineated using the \u201csurvivor\u201d and \u201csurvminer\u201d R packages. GO and GSEA analysis We applied the R package \u201cclusterProfiler\u201d [36] to perform Gene Ontology (GO) and Gene Set Enrichment Analysis (GSEA) on the differentially expressed genes (DEGs) within the high- and low-risk groups. We considered a P-value less than 0.05 to signify significant enrichment. We used \u201cggpubr\u201d and \u201ccirclize\u201d [37] to visualize the outcomes of the GO functional enrichment analysis, while we employed \u201cenrichplot\u201d to depict the results of the GSEA pathway analysis. TMB prognostic analysis and targeted drug prediction Somatic mutation data of ccRCC patients were scrutinized employing the R package \u201cmaftools\u201d. This facilitated the illustration of the somatic mutation landscape in both high- and low-risk groups, enabled the comparison of TMB variations between these groups, and provided further analysis within the context of patients\u2019 prognosis. The R package \u201concoPredict\u201d [38] was used to predict the IC50 values of targeted therapeutics available for ccRCC within the high- and low-risk cohorts. TME analysis and immunotherapy prediction The R packages \u201climma\u201d, \u201cggpubr\u201d, and \u201creshape2\u201d were employed to construct violin plots with immune infiltration landscape maps for the high- and low-risk groups, thereby indicating the proportions of 22 types of tumor-infiltrating immune cells and comparing their differences. Furthermore, the R packages \u201climma\u201d, \u201cBiocManager\u201d, \u201cggpubr\", and \u201creshape2\u201d were utilized to illustrate the disparities in immune function between the high- and low-risk groups. The study included an analysis of ccRCC patients regarding five immune checkpoint inhibitors: Programmed Death 1 (PD-1 or PDCD1), Programmed Death Ligand 1 (PD-L1 or CD274), Cytotoxic T Lymphocyte Antigen 4 (CTLA-4), Interleukin 6 (IL-6), and Lymphocyte Activating 3 (LAG3). The latter is a scoring scheme developed through machine learning algorithms to identify and quantify the determinants of tumor immunogenicity and has been demonstrated to predict solid cancers\u2019 responses to CTLA-4 and PD-1 antibody-based immunotherapy [39]. The Cancer Immunome Atlas (TCIA, https://tcia.at/home) can be referred to for obtaining the Immunophenoscore (IPS) of ccRCC. Cell line culture and RT-qPCR The human cell lines, 769-P and Caki-1, serve as specific models for ccRCC, whereas HK-2 functions as the normal control cell line. These cell lines are procured from Saibaikang, based in Shanghai, China. Each cell line was nurtured in a distinctive medium: HK-2 cells thrived in Dulbecco\u2019s Modified Eagle Medium: Nutrient Mixture F-12 (DMEM/F12, Gibco, USA), 769-P in Roswell Park Memorial Institute 1640 medium (RPMI 1640, Gibco, USA), and Caki-1 in McCoy's 5A (Modified) Medium (McCoy's 5A, Gibco, USA). The media were fortified with 10% fetal bovine serum (FBS, Excell Bio, Uruguay) and 1% combined streptomycin and penicillin. Subsequently, the cells were incubated at 37 \u00b0C with 95% humidity in a dedicated cell incubator. Total RNA was isolated using TRIzol reagent (DP424, TIANGEN, Beijing, China) according to the manufacturer's instructions. cDNA synthesis was performed using total RNA using the PrimeScript RT kit (RR047A, TaKaRa, Beijing, China). Gene expression was quantified using SYBR Premix Ex TaqII (RR820A, TaKaRa, Beijing, China). All primers for RT-qPCR were synthesized by GENEWIZ Biotechnology Co., Ltd (Suzhou, China) (Additional file 1: Table S1). The PCR program was as follows: 40 cycles at 95 \u00b0C for 30 s, 95 \u00b0C for 5 s and 60 \u00b0C for 34 s. GAPDH was used as a standardized internal reference. Relative expression levels were estimated using the 2\u2212\u0394\u0394Ct method. External database validation and Statistical analysis CDRLRs were validated using the Kaplan\u2013Meier Plotter database [40] (accessed on 1st June 2023), a tool equipped for performing network survival analysis through both univariate and multivariate methods. Discrepancies in proportions of clinical characteristics were analyzed using the chi-square test. Differences between Kaplan\u2013Meier curves were identified using the log-rank test. The analysis of PCR data was conducted using an independent sample t-test, facilitated by GraphPad Prism 8.0 software. A p-value less than 0.05 was deemed statistically significant. Results Construction of a prognostic risk model for ccRCC based on CDRLRs Using the STRING database, we constructed a network relationship map of CDRGs (Fig. 2A) and demonstrated the association of cuproptosis and disulfidptosis death-related genes. In accordance with published literature and TCGA-KIRC data, 21 CDRGs were identified via co-expression analysis (Fig. 2B) (Additional file 1: Table S2). Following Pearson analysis, 247 eligible lncRNAs were established with parameters |Pearson R|>\u20090.5 and p\u2009<\u20090.001 (Additional file 1: Table S3). Univariate Cox regression analysis was applied to identify 108 lncRNAs significantly correlated with OS (p\u2009<\u20090.05, Fig. 2C). To prevent overfitting, LASSO regression was utilized, mitigating lncRNAs with a high correlation to prognosis. Subsequent multifactorial Cox regression resulted in the selection of four CDRLRs (Fig. 2D, E). The risk models were constructed using ACVR2B-AS1, AC095055.1, AL161782.1, and MANEA-DT (Additional file 1: Table S4). The corresponding risk score equations for ccRCC patients are provided below: Fig. 2 Identification of the prognostic CDRLRs and construction of prognostic risk model. A Protein\u2013protein interactions among CDRGs based on STRING database. B The sankey relation between CDRGs and CDRLRs. C Forest plot showing univariate Cox regression analysis of prognosis-related CDRLRs (p\u2009<\u20090.05). D The LASSO regression coefficient spectrum. E Cross-validation of parameter selection in the LASSO model. F Heatmap of the correlation between CDRGs and 4 CDRLRs (*p\u2009<\u20090.05, **p\u2009<\u20090.01, ***p\u2009<\u20090.001) Full size image Subsequently, we generated a correlation heatmap to visualize the associations between four CDRLRs and CDRGs. This heatmap revealed that ten CDRGs\u2014specifically, OXSM, NUBPL, NDUFS1, NCKAP1, LRPPRC, LIAS, GCSH, DBT, ATP7B, and ATP7A\u2014showed a strong correlation with CDRLRs (Fig. 2F). Intergroup validation of prognostic risk models Median risk scores were computed based on CDRLRs. Subsequently, the training set, test set, and the entire set were divided into high- and low-risk groups for survival analysis. This revealed an increasing mortality rate among ccRCC patients in correlation with escalating risk scores (Fig. 3A\u2013F). In the low-risk group, ACVR2B-AS1, AC095055.1, and AL161782.1 exhibited significant expression, whereas MANEA-DT was highly expressed in the high-risk group (Fig. 3G\u2013I). This reinforced that ACVR2B-AS1, AC095055.1, and AL161782.1 are beneficial prognostic factors and MANEA-DT is a poor prognostic factor. The high-risk group demonstrated significantly lower OS compared to the low-risk group (Fig. 3J\u2013L). These findings were confirmed in the three data sets. Fig. 3 Validation of the prognostic risk model in the training, testing, and entire groups. A\u2013C Survival status distribution maps. D\u2013F Distribution of association between risk score and survival status between high- and low-risk groups. G\u2013I Risk heatmap of the four CDRLRs. J\u2013L Kaplan\u2013Meier survival curves between high- and low-risk groups Full size image Independent prognosis of risk scores A comparison of survival probability among ccRCC patients in high- and low-risk groups, based on patient age, gender, histological grade, and tumor stage, revealed that the risk score effectively assessed prognosis across all these clinical characteristics (p\u2009<\u20090.01, Fig. 4A\u2013H). Risk scores were indeed adept at predicting OS in ccRCC patients, independent of clinical characteristics. After univariate and multivariate Cox regression analyses, risk scores and clinical characteristics such as age, histological grade, and tumor stage emerged as independent prognostic factors in ccRCC patients (p\u2009<\u20090.01, Fig. 5A, B). Factors correlating negatively with prognosis were excluded, and nomogram plots were drawn based on independent prognostic factors (Fig. 5C). Calibration curves were subsequently used to verify the reliability of these findings, which revealed a C-index value of 0.783 (95% CI 0.7750\u20130.816) (Fig. 5D). The 1-year, 3-year, and 5-year subject operating characteristic curves (ROC) were then plotted, with an area under the curve (AUC) of 0.725, 0.718, and 0.762, respectively (Fig. 5E). When the AUC values of clinical characteristics within each group were compared, the risk score\u2019s AUC was 0.718, second only to tumor stage (Fig. 5F). The 10-year Concordance index further validated these findings (Fig. 5G). These results suggest that the risk score surpasses other clinical characteristics, except tumor stage, as a factor in assessing prognosis. Thus, the risk score can effectively serve as a biomarker for predicting ccRCC patient prognosis. Fig. 4 Kaplan\u2013Meier survival curve analysis of high- and low-risk groups in ccRCC patients with different age (A, B), gender (C, D), histological grade (E, F), and tumor stage (G\u2013H) Full size image Fig. 5 Independent prognostic value assessment of risk scores and clinical characteristics. A Univariate Cox regression analysis of risk scores and clinical characteristics. B Multivariate Cox regression analysis of risk scores and clinical characteristics. C Nomogram of 1, 3 and 5-year OS of ccRCC patients after excluding unrelated variables (*p\u2009<\u20090.05; **p <\u20090.01; ***p < 0.001). D Calibration curves for OS at 1, 3 and 5 years. E ROC validation curve for 1, 3 and 5 years-OS risk model in ccRCC patients. F Prognostic function comparison of risk model and other clinical characteristics. G Risk model and other clinical characteristics for 10-year concordance index Full size image GO and GSEA of high- and low-risk groups From the high- and low-risk groups, we identified 683 DEGs that met the selection criteria (Padjust\u2009<\u20090.05, |log2 (fold change)|\u2265\u20091) (Additional file 1: Table S5). These DEGs were used for functional and pathway enrichment analyses to explore potential biological differences between the groups (Fig. 6A). The Gene Ontology (GO) enrichment analysis showed an enrichment of biological processes (BP), such as antigen binding and immunoglobulin receptor binding. Cellular components (CC) involving the immunoglobulin complex and the external side of the plasma membrane were also enriched, along with molecular functions (MF) like humoral immune response and immunoglobulin production (Fig. 6B) (Additional file 1: Table S6). Utilizing Gene Set Enrichment Analysis (GSEA), we identified differences in pathways between the risk groups, with 89 signaling pathways significantly enriched (p\u2009<\u20090.05) (Additional file 1: Table S7). The high-risk group displayed significant enrichment in the top five pathways: complement and coagulation cascades, drug metabolism by cytochrome P450, metabolism of xenobiotics by cytochrome P450, retinol metabolism, and steroid hormone biosynthesis (Fig. 6C). Conversely, the low-risk group exhibited enrichment in the following top five pathways: endocytosis, insulin signaling pathway, neurotrophin signaling pathway, pathways in cancer, and valine leucine and isoleucine degradation (Fig. 6D). These enrichment patterns may offer valuable insights into the prognostic differences observed between the high- and low-risk groups. Fig. 6 Identification and analysis of the biological functions and pathways of DEGs of CDRGs. GO enrichment analysis of A circle and B bar graphs showing the BP, CC, and MF groups of DEGs. C, D GSEA plots significantly enriched top five pathways between high- and low-risk groups Full size image Immune cell infiltration and immunotherapy sensitivity Significant differences were observed in TME scores, notably ESTIMATE scores (p\u2009<\u20090.001) and immune scores (p\u2009<\u20090.001), among ccRCC patients, with the high-risk group presenting notably higher scores than the low-risk group (Fig. 7A). To explore potential relationships in immune cell infiltration between the risk groups, we compared 22 immune cell enrichment scores and 29 immune-related function enrichment scores (Additional file 1: Tables S8 and S9). Using the CIBERSORT algorithm, we created an immune infiltration landscape for the high- and low-risk groups. The correlation box line plot illustrated significant associations between multiple immune cells and risk scores (Fig. 7B). High-risk groups showed enrichment of T cells CD8, T cells follicular helper, and T cells regulatory (Tregs) (p\u2009<\u20090.001), while the low-risk group exhibited a significant upregulation of T cells CD4 memory resting, Macrophages M1, Macrophages M2, and Mast cells resting (p\u2009<\u20090.001, Fig. 7C). Our immune function analysis indicated that the risk models demonstrated significant discrepancies across multiple immune function scores, including the checkpoint (p\u2009<\u20090.001, Fig. 7D). Guided by these immune function analyses, we compared the differential expression of five key immune checkpoints (PD1, PD-L1, CTLA-4, IL-6, LAG3) using the IPS. Results showed that except for PD-L1, which was highly expressed in the low-risk group, all other checkpoints were overexpressed in the high-risk group (p\u2009<\u20090.001, Fig. 7E\u2013I). This suggests the IPS's potential in predicting the immune response to checkpoint inhibitors in ccRCC patients based on risk score grouping. The immune efficacy, predicted by PD-1 and CTLA-4 expression in the TCIA database, yielded significantly different risk scores in the ctla4(\u2212) pd1(\u2009+), ctla4(\u2009+) pd1(\u2212), and ctla4(\u2009+) pd1(\u2009+) groups (p\u2009<\u20090.05). Higher scores were found in the high-risk group, indicating that high-risk ccRCC patients demonstrated a heightened sensitivity to PD-1 and CTLA-4 single-agent and dual-agent combination immunotherapies (Fig. 7J\u2013M). Fig. 7 TME and sensitivity to immune checkpoint inhibitors analysis of high- and low-risk groups. A Association of high- and low-risk groups with stromal, immune, and ESTIMATE algorithm scores (***p\u2009<\u20090.001). B Immune cell infiltration landscape. C Differences in immune cell infiltration between high- and low-risk groups. D Differences in immune function scores between high- and low-risk groups. Boxplot of PD1 (E), PD-L1 (F), CTLA-4 (G), IL-6 (H), and LAGE (I) expression in different risk groups. Four types of IPS classification based on risk score grouping [CTLA4-neg-PD1-neg (J), CTLA4-neg-PD1-pos (K), CTLA4-pos-PD1-neg (L), and CTLA4-pos-PD1-pos (M)] Full size image TMB prognostic analysis and potential drug sensitivity To explore somatic mutations within the high- and low-risk groups, TCGA-KIRC mutation data were downloaded and categorized. The results demonstrated identical 15 driver genes with the highest mutation frequencies in both groups, with STED2 and BAP1 hypermutations being more prevalent in the high-risk group (Fig. 8A, B). Although no statistically significant association was found between the risk groups and TMB (p\u2009=\u20090.11, Fig. 8C), both TMB grouping and TMB\u2009+\u2009risk grouping significantly differentiated survival statuses of ccRCC patients (p\u2009<\u20090.001, Fig. 8D, E). Here, the High-TMB\u2009+\u2009high risk group exhibited the lowest overall survival rate, while the Low-TMB\u2009+\u2009low risk group showed the highest. Thus, a combination of the risk score and TMB presents a promising prognostic marker for patients. Several common drugs were selected to analyze their sensitivity in the risk groups. The results indicated that Alpelisib, Ipatasertib, Lapatinib, Selumetinib, and Pictilisib demonstrated higher sensitivity in the low-risk group, whereas AZD4547 showed high sensitivity in the high-risk group (p\u2009<\u20090.0001, Fig. 8F\u2013K). Fig. 8 TMB and sensitivity to targeted drugs analysis of high- and low-risk groups. A Genes with the top 20 mutation frequencies in the high-risk group. B Genes with the top 20 mutation frequencies in the low-risk group. C Boxplot of TMB and risk group correlations. D The relationship between TMB and Kaplan\u2013Meier survival. E Kaplan\u2013Meier survival with TMB status and risk level. Differences in drug sensitivity across risk groups for F Alpelisib, G Ipatasertib, H Lapatinib, I Selumetinib, J Pictilisib, and K AZD4547 Full size image Differential expression and prognostic validation of CDRLRs in ccRCC To further examine CDRLRs' expression in ccRCC, we utilized two ccRCC cell lines (769-P, Caki-1), with normal renal tubular epithelial cells (HK-2) as a control. RT-qPCR evaluated the mRNA expression levels of the four key CDRLRs in these cell lines. The findings demonstrated a significantly higher expression of AC095055.1 in both 769-P (p\u2009<\u20090.05) and Caki-1 (p\u2009<\u20090.01) cell lines compared to the HK-2 cell line (Fig. 9B). However, AL161782.1 showed significant expression only in the 769-P cell line (p\u2009<\u20090.0001, Fig. 9C). Conversely, ACVR2B-AS1 (p\u2009<\u20090.01) and MANEA-DT (p\u2009<\u20090.0001) expressions were significantly lower in 769-P and Caki-1 cell lines compared to HK-2 (Fig. 9A, D). To corroborate the independent prognostic role of CDRLRs in ccRCC patients, we performed a prognostic analysis of ACR2B-AS1 and MANEA-DT using the KM Plotter database (AC095055.1 and AL161782.1 were not found in the database). The results identified ACR2B-AS1 as a protective prognostic factor (HR\u2009=\u20090.48 (0.35\u20130.65), p\u2009<\u20090.0001), while MANEA-DT (HR\u2009=\u20092.05 (1.51\u20132.79), p\u2009<\u20090.0001) indicated a poor prognosis (Fig. 9E, F). This prognosis based on CDRLRs aligns with the survival analysis results from external databases. Fig. 9 Validation of CDRLRs in cell lines and prognostic validation of external database. A\u2013D RT-qPCR validation of CDRLRs expression levels in normal and clear cell renal cell carcinoma cell lines and expression levels of four CDRLRs in HK-2, 769-P, and Caki-1 cells (*p\u2009<\u20090.05; **p\u2009<\u20090.01; ***p\u2009<\u20090.001; ****p\u2009<\u20090.0001). E, F OS analysis of ACVR2B-AS1 and MANEA-DT from the Kaplan\u2013Meier Plotter database Full size image Discussion ccRCC is the most common type of renal cell carcinoma, characterized by high heterogeneity, frequent recurrence, a significant risk of metastasis, and a poor prognosis [41]. Approximately 30% of patients present with advanced metastasis at the time of diagnosis [42], and the disease often shows resistance to both radiotherapy [43, 44] and systemic treatments, which significantly impacts patient survival and prognosis. Recent advances in immunotherapy and targeted therapeutic mechanisms have revolutionized treatment options for ccRCC [45]. ccRCC is a malignant tumor characterized by high immune infiltration and dense vascular distribution [46, 47], Regulating specific metabolic pathways in renal cancer, including ccRCC, can modulate immune cell responses and inflammatory characteristics [48,49,50,51]. Immune cells within the TME can inhibit tumor growth by eliminating cancer cells but may also protect certain cancer cell subpopulations, contributing to drug resistance [52,53,54]. Recent research has shown that activating or inhibiting cuproptosis-related metabolic pathways can alter the TME composition of ccRCC, thereby impacting the overall treatment response [55, 56]. Additionally, models of renal cancer subtypes based on disulfidptosis, utilizing transcriptomic analysis and characterization of immune infiltration, demonstrate the potential of disulfidptosis biomarkers in predicting the efficacy of targeted and immunotherapeutic drugs [57]. However, given the abundance of biometric sequencing data for tumor patients and the complexity of clinical characteristics, manual analysis is insufficient for discerning underlying correlations. Machine learning algorithms, as an innovative approach within the field of artificial intelligence, have revolutionized the analysis of large datasets, offering promising prospects in advancing the subtype analysis, mechanistic research, and treatment strategies for renal cancer [58, 59]. Han et al. [60] have differentiated renal cancer subtypes using radiographic imaging combined with machine learning algorithms to assess prognosis. Similarly, Li et al. [61] explored the association between radiomics models and VHL gene mutation characteristics to understand their correlation further. Previous studies have used machine learning to investigate ferroptosis-related lncRNAs and build prognostic models for ccRCC patients [62]. Bai et al. [26] and Zhao et al. [63] have similarly employed machine learning to study copper-related lncRNAs and disulfide-related genes, respectively, and construct survival models for ccRCC and bladder cancer. These models provide valuable guidelines for cancer immunotherapy and targeted therapy. Currently, the development of cancer prognostic models that integrate the analysis of ferroptosis, cuproptosis, and disulfidptosis is at the forefront of oncological research, aiming to predict drug sensitivity and validate crucial factors through in vitro experimentation [64, 65]. In this study, we utilized a machine learning algorithm, LASSO regression, to construct a risk-prognosis model based on CDRLRs. We then combined this risk score with TMB and TME for further analysis, to assess targeted drug sensitivity. Additionally, by applying an immune immunophenoscore algorithm, we evaluated the susceptibility to immune checkpoint inhibitors, offering significant contributions to the therapeutic direction of ccRCC and addressing the existing gap in CDRLR-related research. Copper ions, which are integral to human physiological processes as cofactors for key metabolic enzymes, are regulated by a network of copper-dependent proteins to maintain low levels within the body [66]. Notably, tumor tissues and serological copper ion levels are typically higher in cancer patients than in normal controls. While dysregulation of copper homeostasis may trigger cytotoxic responses, altered copper ion levels can also influence cancer development [67]. Cancer cells often show preferential induction in copper carriers, and the application of copper ion carriers and copper chelators in anticancer therapy has shown promise for inducing cancer cell death by modulating copper metabolism [68]. ccRCC is characterized by metabolic reprogramming. Wettersten et al. [69] revealed hierarchical metabolic reprogramming in ccRCC tumor tissues through proteomics and metabolomics. Studies have shown that the regulation of the TCA cycle and fatty acid synthesis correlates with tumor aggressiveness and survival rates in ccRCC patients [70, 71]. Cuproptosis, a cell death mechanism characterized by protein lipoylation in the TCA cycle [72], has been shown by Nanni et al. [73] to offer cancer preventive effects through controlling metabolic extracts related to copper ion regulation, affecting mitochondrial and DNA damage pathways linked to cuproptosis. Genes associated with cuproptosis have been identified as potential predictors for prognosis, immunotherapy, and targeted therapy in ccRCC patients [15, 74]. Disulfidptosis results from metabolic reactions caused by the toxicity of disulfide bonds and the accumulation of cysteine under conditions of glucose starvation following SLC7A11 dysfunction [11]. SLC7A11, a key protein in regulating cancer cell metabolism, allows most cancer cells to intake cystine, reduce it to cysteine, and then use it for glutathione synthesis for antioxidation. Yan et al. [75] discovered that overexpression of SLC7A11 can modulate oxidative stress in metastatic cancer cells and inhibit tumor metastasis. Notably, 90% of ccRCC cases involve the loss of both alleles of the VHL gene [76], and VHL-deficient ccRCC exhibits a specific dependency on cysteine for glutathione synthesis, making it a therapeutic target. Activating the Src-p38 signaling pathway leads to cysteine-deprivation-induced necrosis, but this mechanism becomes inactive upon VHL restoration [77]. While the FDA has approved targeted agents such as sunitinib for ccRCC treatment, these agents carry significant cytotoxicity [78]. Belzutifan, approved by the FDA for immunotherapy in renal cell carcinoma associated with VHL syndrome [79], can also be used in combination with the multi-targeted anticancer agent cabozantinib for immunotherapy-resistant clear cell renal carcinoma [80]. Even though immune inhibitors have been widely applied in ccRCC patients, their potential for drug resistance warrants significant attention [81]. Consequently, cuproptosis and disulfidptosis exhibit immunogenic properties that regulate immune cell infiltration and modulate tumor metabolism. Extensive research has demonstrated a potential association between these two cell death mechanisms and the prognosis and drug resistance in ccRCC patients. A comprehensive and in-depth investigation of cuproptosis and disulfidptosis within ccRCC patients could enhance prognostic predictions and aid in circumventing specific drug resistance mechanisms. In our research, we leveraged the STRING database to clarify the relationship between cuproptosis and disulfidptosis. We then employed machine learning algorithms to investigate the correlation between the clinical prognosis of ccRCC patients in the TCGA database and CDRLRs. The culmination of our study was the development of a prognostic model anchored on ACRR2B-AS1, AC095055.1, AL161782.1, and MANEA-DT. ACRR2B-AS1 is a long non-protein coding RNA. Recent studies have identified ACVR2B-AS1 as an OS-independent prognostic factor in digestive system tumors, including gastric and hepatocellular carcinomas, leading to the construction of prognostic models based on this lncRNA [82, 83]. Our study is the first to confirm the independent prognostic significance of ACVR2B-AS1 in ccRCC. AL161782.1 has been utilized in creating relevant prognostic models for m6A and cuproptosis mechanisms in ccRCC-related studies. However, comprehensive studies on two lncRNAs, MANEA-DT and AC095055.1, remain scarce. Our research pioneers the validation of ACRR2B-AS1 and MANEA-DT as independent prognostic factors for ccRCC through RT-qPCR experiments at the mRNA level using cell lines, complemented with data from external databases. The cuproptosis and disulfidptosis-related risk scores displayed superior prognostic evaluation capability when compared to other clinical attributes, exhibiting 1-, 3- and 5-year AUC values exceeding 0.7. This highlights the robust reliability of risk scores in predicting the prognosis of ccRCC patients. The high-risk group, classified based on median risk score, was notable for high CD8\u2009+\u2009T cell infiltration, significant mutations in the BAP1 gene, and worse prognosis compared to the low-risk group. These observations largely align with the subtype group characteristics noted in prior studies [47, 84, 85]. Immune function scores revealed a substantial increase in immune checkpoint function scores within the high-risk group compared to the low-risk group. Consequently, significant expression differences in five crucial immune checkpoints between high and low-risk groups were confirmed. The high-risk group demonstrated high expression in all immune checkpoints except CD274, suggesting an increased sensitivity to immunotherapy. Further analysis of the immunophenoscore of these targets revealed a notable response in ccRCC patients to combined PD-1 and CTLA-4 immune therapies. This indicates that dual-target immunotherapy in ccRCC patients, based on risk score assessments, may be beneficial. The prognostic superiority of combined PD-1 and CTLA-4 inhibitors as a first-line treatment for advanced RCC has been clinically validated [86, 87]. Although clinical data on immunotherapy's prognostic influence in ccRCC patients are sparse, it provides valuable direction for subsequent clinical trials. In the context of targeted drug sensitivity, the PI3K inhibitor Alpelisib was subjected to screening. Rugo et al. [88] observed a significant reduction in adverse effects and improved progression-free survival with Alpelisib in conjunction with the fulvestrant regimen. Though Curigliano et al. [89] found minimal changes in the pharmacokinetics of Alpelisib combined with everolimus\u2009\u00b1\u2009exemestane for renal cell carcinoma, our model presents novel insights for the application of Alpelisib. Ipatasertib, an Akt inhibitor, in combination with chemotherapy, or Lapatinib, an EGFR/HER-2 tyrosine kinase inhibitor, has shown efficacy. Ipatasertib, an Akt inhibitor, has demonstrated good tolerability and safety when combined with chemotherapy or hormonal treatments for prostate cancer, though its effect on renal cell carcinoma remains unexplored [90, 91] Lapatinib, an EGFR/HER-2 tyrosine kinase inhibitor, exhibits better overall tolerance compared to hormonal therapy among advanced RCC patients who have progressed following initial cytokine treatment. Moreover, it offers survival benefits to EGFR (3\u2009+) patients. Selumetinib, a selective MEK1 inhibitor, coupled with Everolimus, can attenuate angiogenesis during renal cell carcinoma proliferation by reducing VEGF secretion, consequently enhancing antitumor activity [92]. Rausch et al. [93] achieved a significant reduction in cell line metabolic activity and induction of apoptosis in renal cell carcinoma utilizing optimized low-dose combinations of AZD4547 (an FGFR signaling pathway inhibitor) and pictilisib (a pan-phosphatidylinositol 3-kinase inhibitor). Notably, distinct sensitivity differences between AZD4547 and pictilisib have been observed across different risk groups, underscoring the need for in-depth investigation into the mechanisms of cuproptosis and disulfidptosis. Our study is subject to several limitations. Firstly, there is an inherent bias in the transcriptomics and clinical data available in public databases, necessitating the support of additional external clinical trial data to strengthen our retrospective analysis. Secondly, our investigation into the genes associated with cuproptosis and disulfidptosis lacks empirical experiments to verify the mechanisms and functional relationships. Lastly, our research only extends to external validation of differential expression for the lncRNAs involved in our model at the cellular and protein levels. In the future, we aim to enhance the generalizability and reliability of our model through integrative approaches such as radiomics and histopathomics, among other multi-omics studies. Conclusions In this study, we devised a cuproptosis and disulfidptosis-related prognostic risk model for ccRCC patients using machine learning algorithms. The reliability of four CDRLRs as key prognostic factors was corroborated through external databases and experiments. This process further facilitated the prediction of the sensitivity to immune and targeted drugs and implied guidance for prognostic assessment and personalized treatment for ccRCC patients. Data availability The data supporting the findings and conclusions of this study are available in the article. References Siegel R, Miller K, Wagle NS, Jemal A. Cancer statistics, 2023. CA Cancer J Clin. 2023;73:17\u201348. https://doi.org/10.3322/caac.21763. Article   PubMed   Google Scholar   Lalani A-KA, Lalani A-K, McGregor BA, Albiges L, Choueiri TK, Motzer RJ, et al. Systemic treatment of metastatic clear cell renal cell carcinoma in 2018: current paradigms, use of immunotherapy, and future directions. Eur Urol. 2019;75:100\u201310. Article   PubMed   Google Scholar   Mendhiratta N, Muraki P, Sisk A, Shuch B. Papillary renal cell carcinoma: review. Urol Oncol Semin Orig Investig. 2021;39:327\u201337. Google Scholar   Motzer RJ, Bacik J, Mazumdar M. Prognostic factors for survival of patients with stage IV renal cell carcinoma: memorial sloan-kettering cancer center experience. Clin Cancer Res. 2004;10:6302S\u20133S. Article   CAS   PubMed   Google Scholar   Choueiri TK, Choueiri TK, Motzer RJ, Motzer RJ. Systemic therapy for metastatic renal-cell carcinoma. N Engl J Med. 2017;376:354\u201366. Article   CAS   PubMed   Google Scholar   Motzer RJ, Motzer RJ, Penkov K, Penkov K, Haanen JBA, Haanen JBA, et al. Avelumab plus axitinib versus sunitinib for advanced renal-cell carcinoma. N Engl J Med. 2019;380:1103\u201315. Article   CAS   PubMed   PubMed Central   Google Scholar   Rini BI, Plimack ER, Stus V, Gafanov R, Hawkins R, Nosov D, Pouliot F, Alekseev B, Souli\u00e8res D, Melichar B, Vynnychenko I. Pembrolizumab plus axitinib versus sunitinib for advanced renal-cell carcinoma. N Engl J Med. 2019;380:1116\u201327. Article   CAS   PubMed   Google Scholar   US Food and Drug Administration. FDA approves pembrolizumab plus axitinib for advanced renal cell carcinoma. Case medical research. 2019. Hadian K, Stockwell BR. The therapeutic potential of targeting regulated non-apoptotic cell death. Nat Rev Drug Discov. 2023;22:723\u201342. Article   CAS   PubMed   Google Scholar   Tang D, Tang D, Tang D, Chen X, Chen X, Kroemer G, et al. Cuproptosis: a copper-triggered modality of mitochondrial cell death. Cell Res. 2022;32:417\u20138. https://doi.org/10.1038/s41422-022-00653-7. Article   PubMed   PubMed Central   Google Scholar   Liu X, Nie L, Zhang Y, Yan Y, Wang C, Colic M, et al. Actin cytoskeleton vulnerability to disulfide stress mediates disulfidptosis. Nat Cell Biol. 2023;25:404\u201314. https://doi.org/10.1038/s41556-023-01091-2. Article   CAS   PubMed   PubMed Central   Google Scholar   Zheng P, Zhou C, Ding Y, Duan S. Disulfidptosis: a new target for metabolic cancer therapy. J Exp Clin Cancer Res. 2023;42:103. https://doi.org/10.1186/s13046-023-02675-4. Article   PubMed   PubMed Central   Google Scholar   Xie J, Yang Y, Gao Y, He J. Cuproptosis: mechanisms and links with cancers. Mol Cancer. 2023;22:46. https://doi.org/10.1186/s12943-023-01732-y. Article   CAS   PubMed   PubMed Central   Google Scholar   Meng Y, Chen X, Deng G. Disulfidptosis: a new form of regulated cell death for cancer treatment. Mol Biomed. 2023;4:18. https://doi.org/10.1186/s43556-023-00132-4. Article   PubMed   PubMed Central   Google Scholar   Bian Z, Fan R, Xie L. A novel cuproptosis-related prognostic gene signature and validation of differential expression in clear cell renal cell carcinoma. Genes. 2022;13:851. Article   CAS   PubMed   PubMed Central   Google Scholar   Yuan H, Qin X, Wang J, Yang Q, Fan Y, Xu D. The cuproptosis-associated 13 gene signature as a robust predictor for outcome and response to immune- and targeted-therapies in clear cell renal cell carcinoma. Front Immunol. 2022;13:971142. Article   CAS   PubMed   PubMed Central   Google Scholar   Peng K, Wang N, Liu Q, Wang L, Duan X, Xie G, et al. Identification of disulfidptosis-related subtypes and development of a prognosis model based on stacking framework in renal clear cell carcinoma. J Cancer Res Clin Oncol. 2023;149:13793\u2013810. https://doi.org/10.1007/s00432-023-05201-3. Article   CAS   PubMed   Google Scholar   Yang L, Liu J, Li S, Liu X, Zheng F, Xu S, et al. Based on disulfidptosis, revealing the prognostic and immunological characteristics of renal cell carcinoma with tumor thrombus of vena cava and identifying potential therapeutic target AJAP1. J Cancer Res Clin Oncol. 2023;149:9787\u2013804. https://doi.org/10.1007/s00432-023-04877-x. Article   CAS   PubMed   Google Scholar   Shen Y, Li D, Liang Q, Yang M, Pan Y, Li H. Cross-talk between cuproptosis and ferroptosis regulators defines the tumor microenvironment for the prediction of prognosis and therapies in lung adenocarcinoma. Front Immunol. 2023;13:1029092. https://doi.org/10.3389/fimmu.2022.1029092. Article   CAS   PubMed   PubMed Central   Google Scholar   Kopp F, Kopp F, Mendell JT. Functional classification and experimental dissection of long noncoding RNAs. Cell. 2018;172:393\u2013407. Article   CAS   PubMed   PubMed Central   Google Scholar   Outeiro-Pinho G, Barros-Silva D, Correia MP, Henrique R, Jer\u00f3nimo C. Renal cell tumors: uncovering the biomarker potential of ncRNAs. Cancers. 2020;12:2214. Article   CAS   PubMed   PubMed Central   Google Scholar   Tang Y, Cheung BB, Atmadibrata B, Marshall GM, Dinger ME, Liu PY, et al. The regulatory role of long noncoding RNAs in cancer. Cancer Lett. 2017;391:12\u20139. Article   CAS   PubMed   Google Scholar   Rajkomar A, Dean J, Kohane I. Machine learning in medicine. N Engl J Med. 2019;380:1347\u201358. Article   PubMed   Google Scholar   Tibshirani R. The lasso method for variable selection in the cox model. Stat Med. 1997;16:385\u201395. Article   CAS   PubMed   Google Scholar   Poldrack RA, Huckins G, Varoquaux G. Establishment of best practices for evidence for prediction: a review. JAMA Psychiat. 2020;77:534\u201340. Article   Google Scholar   Bai Z, Lu J, Chen A, Zheng X, Wu M, Tan Z, et al. Identification and validation of cuproptosis-related LncRNA signatures in the prognosis and immunotherapy of clear cell renal cell carcinoma using machine learning. Biomolecules. 2022;12:1890. https://doi.org/10.3390/biom12121890. Article   CAS   PubMed   PubMed Central   Google Scholar   Lu D, Liao J, Cheng H, Ma Q, Wu F, Xie F, et al. Construction and systematic evaluation of a machine learning-based cuproptosis-related lncRNA score signature to predict the response to immunotherapy in hepatocellular carcinoma. Front Immunol. 2023;14:1097075. https://doi.org/10.3389/fimmu.2023.1097075. Article   CAS   PubMed   PubMed Central   Google Scholar   Ritchie ME, Phipson B, Wu DI, Hu Y, et al. limma powers differential expression analyses for RNA-sequencing and microarray studies. Nucleic Acids Res. 2015;43:e47. Article   PubMed   PubMed Central   Google Scholar   Goodswen SJ, Gondro C, Gilliham M, Watson-Haigh NS, Kadarmideen HN. FunctSNP: an R package to link SNPs to functional knowledge and dbAutoMaker: a suite of Perl scripts to build SNP databases. BMC Bioinformatics. 2010;11:311. Article   PubMed   PubMed Central   Google Scholar   Mayakonda A, Lin D-C, Assenov Y, Plass C, Koeffler HP. Maftools: efficient and comprehensive analysis of somatic variants in cancer. Genome Res. 2018;28:1747\u201356. Article   CAS   PubMed   PubMed Central   Google Scholar   Tsvetkov P, Coy S, Petrova B, Dreishpoon M, Verma A, Abdusamad M, et al. Copper induces cell death by targeting lipoylated TCA cycle proteins. Science. 2022;375:1254\u201361. Article   ADS   CAS   PubMed   PubMed Central   Google Scholar   Yu G, Wang L-G, Yan G-R, He Q-Y. DOSE: an R/Bioconductor package for disease ontology semantic and enrichment analysis. Bioinformatics. 2015;31:608\u20139. Article   CAS   PubMed   Google Scholar   Gustavsson EK, Zhang D, Reynolds RH, Garcia-Ruiz S, Ryten M. ggtranscript: an R package for the visualization and interpretation of transcript isoforms using ggplot2. Bioinformatics. 2022;38:3844\u201346. https://doi.org/10.1093/bioinformatics/btac409. Article   CAS   PubMed   PubMed Central   Google Scholar   Pang Y, Wang Y, Zhou X, Ni Z, Chen W, Liu Y, et al. Cuproptosis-related LncRNA-based prediction of the prognosis and immunotherapy response in papillary renal cell carcinoma. Int J Mol Sci. 2023;24:1464. https://doi.org/10.3390/ijms24021464. Article   CAS   PubMed   PubMed Central   Google Scholar   Mogensen UB, Ishwaran H, Gerds TA. Evaluating random forests for survival analysis using prediction error curves. J Stat Softw. 2012;50:1\u201323. Article   PubMed   PubMed Central   Google Scholar   Wu T, Hu E, Xu S, Chen M, Guo P, Dai Z, et al. clusterProfiler 4.0: a universal enrichment tool for interpreting omics data. Innovation. 2021;2:100141. CAS   PubMed   PubMed Central   Google Scholar   Gu Z, Gu L, Eils R, Schlesner M, Brors B. circlize Implements and enhances circular visualization in R. Bioinformatics. 2014;30:2811\u20132. Article   CAS   PubMed   Google Scholar   Maeser D, Gruener RF, Huang RS, Huang RS. oncoPredict: an R package for predicting in vivo or cancer patient drug response and biomarkers from cell line screening data. Brief Bioinform. 2021;22:bbab260. https://doi.org/10.1093/bib/bbab260. Article   CAS   PubMed   PubMed Central   Google Scholar   Charoentong P, Finotello F, Angelova M, Mayer C, Efremova M, Rieder D, et al. Pan-cancer immunogenomic analyses reveal genotype-immunophenotype relationships and predictors of response to checkpoint blockade. Cell Rep. 2017;18:248\u201362. Article   CAS   PubMed   Google Scholar   L\u00e1nczky A, Gy\u0151rffy B. Web-based survival analysis tool tailored for medical research (KMplot): development and implementation. J Med Internet Res. 2021;23:e27633. Capitanio U, Bensalah K, Bex A, Boorjian SA, Bray F, et al. Epidemiology of renal cell carcinoma. Eur Urol. 2019;75:74\u201384. Article   PubMed   Google Scholar   Motzer RJ, Bukowski RM, Figlin RA, Hutson TE, Hutson TE, Freedman ML, et al. Prognostic nomogram for sunitinib in patients with metastatic renal cell carcinoma. Cancer. 2008;113:1552\u20138. Article   CAS   PubMed   Google Scholar   Goyal R, Gersbach E, Yang XJ, Rohan SM. Differential diagnosis of renal tumors with clear cytoplasm: clinical relevance of renal tumor subclassification in the era of targeted therapies and personalized medicine. Arch Pathol Lab Med. 2013;137:467\u201380. Article   CAS   PubMed   Google Scholar   Rini BI, Campbell SC, Escudier B. Renal cell carcinoma. Lancet. 2009;373:1119\u201332. https://doi.org/10.1016/S0140-6736(09)60229-4. Article   CAS   PubMed   Google Scholar   Ballesteros P\u00c1, Chamorro J, Rom\u00e1n-Gil MS, Pozas J, G\u00f3mez Dos Santos V, Granados \u00c1R, et al. Molecular mechanisms of resistance to immunotherapy and antiangiogenic treatments in clear cell renal cell carcinoma. Cancers. 2021;13:5981. Article   CAS   PubMed   PubMed Central   Google Scholar   Yoshihara K, Shahmoradgoli M, Mart\u00ednez E, et al. Inferring tumour purity and stromal and immune cell admixture from expression data. Nat Commun. 2013;4:2612\u20132612. Article   ADS   PubMed   Google Scholar   \u015eenbabao\u011flu Y, Gejman RS, Winer AG, Liu M, et al. Tumor immune microenvironment characterization in clear cell renal cell carcinoma identifies prognostic and immunotherapeutically relevant messenger RNA signatures. Genome Biol. 2016;17:231\u2013231. Article   PubMed   PubMed Central   Google Scholar   Pio R, Ajona D, Ortiz-Espinosa S, et al. Complementing the cancer-immunity cycle. Front Immunol. 2019;10:774\u2013774. Article   CAS   PubMed   PubMed Central   Google Scholar   Gigante M, Mandic M, Wesa AK, et al. Interferon-alpha (IFN-\u03b1)-conditioned DC preferentially stimulate type-1 and limit treg-type in vitro T-cell responses from rcc patients. J Immunother. 2008;31:254\u201362. Article   CAS   PubMed   Google Scholar   Montinaro V, Serra L, Perissutti S, et al. Biosynthesis of C3 by human mesangial cells. Modulation by proinflammatory cytokines. Kidney Int. 1995;47:829\u201336. Article   CAS   PubMed   Google Scholar   Netti GS, Lucarelli G, Spadaccino F, et al. PTX3 modulates the immunoflogosis in tumor microenvironment and is a prognostic factor for patients with clear cell renal cell carcinoma. Aging. 2020;12:7585\u2013602. Article   PubMed   PubMed Central   Google Scholar   Klemm F, Joyce JA. Microenvironmental regulation of therapeutic response in cancer. Trends Cell Biol. 2015;25:198\u2013213. Article   PubMed   Google Scholar   Sharma P, Hu-Lieskovan S, Wargo JA, Ribas A. Primary, adaptive, and acquired resistance to cancer immunotherapy. Cell. 2017;168:707\u201323. Article   CAS   PubMed   PubMed Central   Google Scholar   Weissleder R, Pittet MJ. The expanding landscape of inflammatory cells affecting cancer therapy. Nat Biomed Eng. 2020;4:489\u201398. Article   CAS   PubMed   PubMed Central   Google Scholar   Xie M, Cheng Bo, Shuang Yu, Yajie He Yu, Cao TZ, et al. Cuproptosis-related MiR-21-5p/FDX1 axis in clear cell renal cell carcinoma and its potential impact on tumor microenvironment. Cells. 2022;12:173\u2013173. Article   PubMed   PubMed Central   Google Scholar   Wang X, Jia JH, Zhang M, Meng QS, Yan BW, Ma ZY, et al. Adrenomedullin/FOXO3 enhances sunitinib resistance in clear cell renal cell carcinoma by inhibiting FDX1 expression and cuproptosis. FASEB J. 2023;37:e23143. Article   CAS   PubMed   Google Scholar   Li Y, Tang M, Dang W, Zhu S, Wang Y. Identification of disulfidptosis-related subtypes, characterization of tumor microenvironment infiltration, and development of a prognosis model in colorectal cancer. J Cancer Res Clin Oncol. 2023;149:13995\u20134014. Article   CAS   PubMed   Google Scholar   Ferro M, Crocetto F, Barone B, Del Giudice F, Maggi M, Lucarelli G, et al. Artificial intelligence and radiomics in evaluation of kidney lesions: a comprehensive literature review. Therap Adv Urol. 2023;15:175628722311648\u2013175628722311648. Article   Google Scholar   Ferro M, Musi G, Marchioni M, Maggi M, Veccia A, Del Giudice F, et al. Radiogenomics in renal cancer management\u2014current evidence and future prospects. Int J Mol Sci. 2023;24:4615\u20134615. Article   CAS   PubMed   PubMed Central   Google Scholar   Han S, Hwang SI, Lee HJ. The classification of renal cancer in 3-phase CT images using a deep learning method. J Digit Imaging. 2019;32:638\u201343. Article   PubMed   PubMed Central   Google Scholar   Li ZC, Zhai G, Zhang J, et al. Differentiation of clear cell and non-clear cell renal cell carcinomas by all-relevant radiomics features from multiphase CT: a VHL mutation perspective. Eur Radiol. 2019;29:3996\u20134007. Article   PubMed   Google Scholar   Xing XL, Yao ZY, Ou J, Xing C, Li F. Development and validation of ferroptosis-related lncRNAs prognosis signatures in kidney renal clear cell carcinoma. Cancer Cell Int. 2021;21:591. Article   CAS   PubMed   PubMed Central   Google Scholar   Zhao S, Wang L, Ding W, Ye B, Cheng C, Shao J, et al. Crosstalk of disulfidptosis-related subtypes, establishment of a prognostic signature and immune infiltration characteristics in bladder cancer based on a machine learning survival framework. Front Endocrinol. 2023;14:1180404. https://doi.org/10.3389/fendo.2023.1180404. Article   Google Scholar   Zhang C, Xu T, Ji K, Cao S, Ai J, Pan J, et al. Development and experimental validation of a machine learning-based disulfidptosis-related ferroptosis score for hepatocellular carcinoma. Apoptosis. 2023;29:103\u201320. https://doi.org/10.1007/s10495-023-01900-x. Article   CAS   PubMed   Google Scholar   Xu L, Wang S, Zhang D, Wu Y, Shan J, Zhu H, et al. Machine learning- and WGCNA-mediated double analysis based on genes associated with disulfidptosis, cuproptosis and ferroptosis for the construction and validation of the prognostic model for breast cancer. J Cancer Res Clin Oncol. 2023;149:16511\u201323. https://doi.org/10.1007/s00432-023-05378-7. Article   CAS   PubMed   Google Scholar   Kim B-E, Nevitt T, Thiele DJ. Mechanisms for copper acquisition, distribution and regulation. Nat Chem Biol. 2008;4:176\u201385. Article   CAS   PubMed   Google Scholar   Babak MV, Ahn D. Modulation of intracellular copper levels as the mechanism of action of anticancer copper complexes: clinical relevance. Biomedicines. 2021;9:852. Article   CAS   PubMed   PubMed Central   Google Scholar   Li Y-Q. Copper homeostasis: emerging target for cancer treatment. IUBMB Life. 2020;72:1900\u20138. Article   CAS   PubMed   Google Scholar   Wettersten HI, Hakimi AA, Morin D, et al. Grade-dependent metabolic reprogramming in kidney cancer revealed by combined proteomics and metabolomics analysis. Cancer Res. 2015;75:2541\u201352. Article   CAS   PubMed   PubMed Central   Google Scholar   Ricketts CJ, de Cubas AA, Fan H, Smith CC, Lang M, Reznik E, et al. The Cancer Genome Atlas comprehensive molecular characterization of renal cell carcinoma. Cell Rep. 2018;23:313. Article   CAS   PubMed   PubMed Central   Google Scholar   Gatto F, Nookaew I, Nielsen J. Chromosome 3p loss of heterozygosity is associated with a unique metabolic network in clear cell renal carcinoma. Proc Natl Acad Sci USA. 2014;111:201319196. Article   Google Scholar   Kahlson MA, Dixon SJ. Copper-induced cell death. Science. 2022;375:1231\u20132. Article   ADS   CAS   PubMed   Google Scholar   Nanni V, Di Marco G, Sacchetti G, Canini A, Gismondi A. Oregano phytocomplex induces programmed cell death in melanoma lines via mitochondria and DNA damage. Foods. 2020;9:1486. Article   CAS   PubMed   PubMed Central   Google Scholar   Zhang G, Chen X, Fang J, Tai P, Chen A, Cao K. Cuproptosis status affects treatment options about immunotherapy and targeted therapy for patients with kidney renal clear cell carcinoma. Front Immunol. 2022;13:954440. https://doi.org/10.3389/fimmu.2022.954440. Article   CAS   PubMed   PubMed Central   Google Scholar   Yan Y, Teng H, Hang Q, Kondiparthi L, Lei G, Horbath A, et al. SLC7A11 expression level dictates differential responses to oxidative stress in cancer cells. Nat Commun. 2023;14:3673. https://doi.org/10.1038/s41467-023-39401-9. Article   ADS   CAS   PubMed   PubMed Central   Google Scholar   Hsieh JJ, Le VH, Oyama T, Ricketts CJ, Ho TH, Cheng EH. Chromosome 3p loss-orchestrated VHL, HIF, and epigenetic deregulation in clear cell renal cell carcinoma. J Clin Oncol. 2018;36:3533\u20139. Article   CAS   PubMed Central   Google Scholar   Tang X, Wu J, Ding CK, Ding C-K, Lu M, Keenan MM, et al. Cystine deprivation triggers programmed necrosis in VHL-deficient renal cell carcinomas. Cancer Res. 2016;76:1892\u2013903. Article   CAS   PubMed   PubMed Central   Google Scholar   Xin H, Zhang C, Herrmann A, Herrmann A, Du Y, Figlin RA, et al. Sunitinib inhibition of Stat3 induces renal cell carcinoma tumor cell apoptosis and reduces immunosuppressive cells. Can Res. 2009;69:2506\u201313. Article   CAS   Google Scholar   Jonasch E, Donskov F, Iliopoulos O, Rathmell WK, Narayan V, Maughan BL, et al. Belzutifan for renal cell carcinoma in von Hippel-Lindau disease. N Engl J Med. 2021;385:2036\u201346. Article   CAS   PubMed   PubMed Central   Google Scholar   Choueiri T, McDermott D, Merchan J, Bauer T, Figlin R, Heath E, et al. Belzutifan plus cabozantinib for patients with advanced clear cell renal cell carcinoma previously treated with immunotherapy: an open-label, single-arm, phase 2 study. Lancet Oncol. 2023;24:553\u201362. https://doi.org/10.1016/S1470-2045(23)00097-9. Article   CAS   PubMed   Google Scholar   Au L, Hatipoglu E, de Massy MR, Litchfield K, Beattie G, et al. Determinants of anti-PD-1 response and resistance in clear cell renal cell carcinoma. Cancer Cell. 2021;23:313. Google Scholar   Hu J, Song Y, Cai X, Halina H, Qiao K, Lu J, et al. A novel pyroptosis gene expression-based risk score for survival in gastric cancer. Front Endocrinol. 2023;14:1120216. https://doi.org/10.3389/fendo.2023.1120216. Article   Google Scholar   Nie Y, Jiao Y, Jiao Y, Li Y, Li Y, Li W, et al. Investigation of the clinical significance and prognostic value of the lncRNA ACVR2B-As1 in liver cancer. Biomed Res Int. 2019;2019:4602371. Article   PubMed   PubMed Central   Google Scholar   Clark D, Clark D, Dhanasekaran SM, Petralia F, Pan J, Song X, et al. Integrated proteogenomic characterization of clear cell renal cell carcinoma. Cell. 2019;179:207. Article   Google Scholar   Wang T, Lu R, Kapur P, Kapur P, Jaiswal BS, Hannan R, et al. An empirical approach leveraging tumorgrafts to dissect the tumor microenvironment in renal cell carcinoma identifies missing link to prognostic inflammatory factors. Cancer Discov. 2018;8:1142\u201355. Article   CAS   PubMed   PubMed Central   Google Scholar   Ali S, Camarero J, van Hennik P, Bolstad B, Gr\u00f8nvold MS, Syvertsen C, et al. European Medicines agency extension of indication to include the combination immunotherapy cancer drug treatment with nivolumab (Opdivo) and ipilimumab (Yervoy) for adults with intermediate/poor-risk advanced renal cell carcinoma. ESMO Open. 2020;5:e000798. Motzer RJ, Rini BI, McDermott DF, Frontera OA, Hammers HJ, Carducci MA, et al. Nivolumab plus ipilimumab versus sunitinib in first-line treatment for advanced renal cell carcinoma: extended follow-up of efficacy and safety results from a randomised, controlled, phase 3 trial. Lancet Oncol. 2019;20:1370\u201385. Article   CAS   PubMed   PubMed Central   Google Scholar   Rugo HS, Pusztai L, Andre F, Yamashita T, Cerda H, Toledano I, et al. Time course and management of key adverse events during the randomized phase III SOLAR-1 study of PI3K inhibitor alpelisib plus fulvestrant in patients with HR-positive advanced breast cancer. Ann Oncol. 2020;31:1001\u201310. Article   CAS   PubMed   Google Scholar   Curigliano G, Mart\u00edn M, Martin M, Jhaveri K, Beck JT, Beck J, et al. Alpelisib in combination with everolimus \u00b1 exemestane in solid tumours: phase Ib randomised, open-label, multicentre study. Eur J Cancer. 2021;151:49\u201362. Article   CAS   PubMed   Google Scholar   Sutaria DS, Rasuo G, Harris A, Johnson R, Miles D, Gallo JD, et al. Drug\u2013drug interaction study to evaluate the pharmacokinetics, safety, and tolerability of ipatasertib in combination with darolutamide in patients with advanced prostate cancer. Pharmaceutics. 2022;14:2101\u20132101. Article   CAS   PubMed   PubMed Central   Google Scholar   Sweeney C, Bracarda S, Sternberg CN, Chi KN, Olmos D, Sandhu S, et al. Ipatasertib plus abiraterone and prednisolone in metastatic castration-resistant prostate cancer (IPATential150): a multicentre, randomised, double-blind, phase 3 trial. Lancet. 2021;398:131\u201342. Article   CAS   PubMed   Google Scholar   Zou Y, Zou Y, Zou Y, Zou Y, Wang J, Leng X, et al. The selective MEK1 inhibitor Selumetinib enhances the antitumor activity of everolimus against renal cell carcinoma in vitro and in vivo. Oncotarget. 2017;8:20825\u201333. Article   PubMed   PubMed Central   Google Scholar   Rausch M, Weiss A, Achkhanian J, Rotari A, Nowak-Sliwinska P. Identification of low-dose multidrug combinations for sunitinib-naive and pre-treated renal cell carcinoma. Br J Cancer. 2020;123:556\u201367. Article   CAS   PubMed   PubMed Central   Google Scholar   Download references Acknowledgements Thanks for the data provided by the TCGA database and Kaplan\u2013Meier Plotter database. Thanks to chatGPT for the AI-assisted techniques in the writing process, which the authors use only to improve readability and language. The authors were genuinely grateful to the central laboratory of People\u2019s Hospital of Rizhao, for providing technical support for this study. Funding National Natural Science Foundation of China (82002083); Young experts of Taishan Scholars (tsqn202211380). Author information Ronghui Chen and Jun Wu contributed equally to this work. Authors and Affiliations School of Clinical Medicine, Shandong Second Medical University, Weifang, 261053, China Ronghui Chen Department of Oncology, People\u2019s Hospital of Rizhao, Rizhao, 276826, China Ronghui Chen, Jun Wu & Lingxin Meng Department of Central Laboratory, Shandong Provincial Key Medical and Health Laboratory, Rizhao Key Laboratory of Basic Research on Anesthesia and Respiratory Intensive Care, The People\u2019s Hospital of Rizhao, Rizhao, 276826, Shandong, China Yinwei Che, Yuzhuo Jiao, Huashan Sun & Tao Zhao Department of Pathology, People\u2019s Hospital of Rizhao, Rizhao, 276826, China Yinuo Zhao & Pingping Chen Contributions Conceptualization, RC and JW. Data curation, RC and JW. Formal analysis, RC, Funding acquisition, LM, and TZ. Investigation, YZ, and PC. Methodology, RC and JW. Project administration, RC and TZ. Resources, YZ and PC. Software, RC and JW. Supervision, YC, YJ, and HS. Validation, YC, YJ, HS, and TZ. Visualization, RC, Y.Z., and PC. Writing\u2014original draft, RC. Writing\u2014review and editing, JW, LM, and XZ. All authors have read and agreed to the published version of the manuscript. Corresponding author Correspondence to Lingxin Meng. Ethics declarations Informed consent Not applicable. Competing interests The authors declare that they have no known competing financial interest or personal relationships that could have appeared to influence the work reported in this paper. Additional information Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Supplementary Information Additional file 1: Table S1. Primers for RT-qPCR. Table S2. The expression matrix of cuproptosis and disulfidptosis-related genes (CDRGs). Table S3. The expression matrix of cuproptosis and disulfidptosis-related lncRNAs (CDRLRs). Table S4. The risk scores for all samples based on four key CDRLRs. Table S5. DEGs between high- and low-risk groups. Table S6. Detailed information of GO analysis for high- and low-risk groups. Table S7. Detailed information of GSEA analysis for high- and low-risk groups. Table S8. The proportion of immune cells in all samples according to CIBERSORT algorithm. Table S9. Immune function score of all samples. Rights and permissions Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data. Reprints and permissions About this article Cite this article Chen, R., Wu, J., Che, Y. et al. Machine learning-driven prognostic analysis of cuproptosis and disulfidptosis-related lncRNAs in clear cell renal cell carcinoma: a step towards precision oncology. Eur J Med Res 29, 176 (2024). https://doi.org/10.1186/s40001-024-01763-1 Download citation Received 01 February 2024 Accepted 01 March 2024 Published 16 March 2024 DOI https://doi.org/10.1186/s40001-024-01763-1 Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Keywords Clear cell renal cell carcinoma Prognostic risk model Machine learning algorithm Cuproptosis Disulfidptosis Long non-coding RNA Targeted drugs Immune inhibitors Download PDF Sections Figures References Abstract Introduction Materials and methods Results Discussion Conclusions Data availability References Acknowledgements Funding Author information Ethics declarations Additional information Supplementary Information Rights and permissions About this article Advertisement European Journal of Medical Research ISSN: 2047-783X Contact us Submission enquiries: jacinth.kennady@springernature.com General enquiries: info@biomedcentral.com Read more on our blogs Receive BMC newsletters Manage article alerts Language editing for authors Scientific editing for authors Policies Accessibility Press center Support and Contact Leave feedback Careers Follow BMC By using this website, you agree to our Terms and Conditions, Your US state privacy rights, Privacy statement and Cookies policy. Your privacy choices/Manage cookies we use in the preference centre. \u00a9 2024 BioMed Central Ltd unless otherwise stated. Part of Springer Nature.",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "Biomimetic nanocluster photoreceptors for adaptative circular polarization vision",
    "doi": "10.1038/s41467-024-46646-5",
    "description": "Nanoclusters with atomically precise structures and discrete energy levels are considered as nanoscale semiconductors for artificial intelligence. However, nanocluster electronic engineering and optoelectronic behavior have remained obscure and unexplored. Hence, we create nanocluster photoreceptors inspired by mantis shrimp visual systems to satisfy the needs of compact but multi-task vision hardware and explore the photo-induced electronic transport. Wafer-scale arrayed photoreceptors are constructed by a nanocluster-conjugated molecule heterostructure. Nanoclusters perform as an in-sensor charge reservoir to tune the conductance levels of artificial photoreceptors by a light valve mechanism. A ligand-assisted charge transfer process takes place at nanocluster interface and it features an integration of spectral-dependent visual adaptation and circular polarization recognition. This approach is further employed for developing concisely structured, multi-task, and compact artificial visual systems and provides valuable guidelines for nanocluster neuromorphic devices.",
    "journal": "Nature Communications",
    "authors": [
      "Wen W.",
      "Liu G.",
      "Wei X.",
      "Huang H.",
      "Wang C.",
      "Zhu D.",
      "Sun J.",
      "Yan H.",
      "Huang X.",
      "Shi W.",
      "Dai X.",
      "Dong J.",
      "Jiang L.",
      "Guo Y.",
      "Wang H.",
      "Liu Y."
    ],
    "citation_count": "0",
    "full_text": "Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Advertisement View all journals Search Log in Explore content About the journal Publish with us Sign up for alerts RSS feed nature nature communications articles article Article Open access Published: 16 March 2024 Biomimetic nanocluster photoreceptors for adaptative circular polarization vision Wei Wen , Guocai Liu , Xiaofang Wei , Haojie Huang, Chong Wang, Danlei Zhu, Jianzhe Sun, Huijuan Yan, Xin Huang, Wenkang Shi, Xiaojuan Dai, Jichen Dong, Lang Jiang , Yunlong Guo , Hanlin Wang & Yunqi Liu   Nature Communications  15, Article number: 2397 (2024) Cite this article 1254 Accesses 2 Altmetric Metrics Abstract Nanoclusters with atomically precise structures and discrete energy levels are considered as nanoscale semiconductors for artificial intelligence. However, nanocluster electronic engineering and optoelectronic behavior have remained obscure and unexplored. Hence, we create nanocluster photoreceptors inspired by mantis shrimp visual systems to satisfy the needs of compact but multi-task vision hardware and explore the photo-induced electronic transport. Wafer-scale arrayed photoreceptors are constructed by a nanocluster-conjugated molecule heterostructure. Nanoclusters perform as an in-sensor charge reservoir to tune the conductance levels of artificial photoreceptors by a light valve mechanism. A ligand-assisted charge transfer process takes place at nanocluster interface and it features an integration of spectral-dependent visual adaptation and circular polarization recognition. This approach is further employed for developing concisely structured, multi-task, and compact artificial visual systems and provides valuable guidelines for nanocluster neuromorphic devices. Similar content being viewed by others High-speed and large-scale intrinsically stretchable integrated circuits Article 13 March 2024 Blueprinting extendable nanomaterials with standardized protein blocks Article Open access 13 March 2024 Real-time analysis of large-scale neuronal imaging enables closed-loop investigation of neural dynamics Article 11 March 2024 Introduction Artificial vision systems (AVSs) that adapt to complex environments and fulfill multi-task photoperception have become increasingly desired in facial recognition, autonomous vehicles, and visual prostheses. State-of-the-art AVSs are not as exquisite as their biology prototypes in terms of structure simplicity, self-regulation, and multi-functions. For example, photoadaptation devices and neuromorphic phototransistors are designed either with sophisticated multilayers or integration of detectors and processors, increasing manufacturing costs and difficulty1,2,3,4,5,6,7,8. It remains a critical challenge to compact a multiple of functions into an all-in-one single cell. Visual systems of mantis shrimps are equipped with 16 photoreceptors to fulfill multiple tasks of color recognition, adaptative vision, and circularly polarized light (CPL) perception9. Though aforementioned functions have discretely been enabled by panchromatic absorbing materials10, circularly polarized molecule-assemblies11,12 or chiral compounds13 and photoadaptative devices. It is of high theoretical and practical value to develop bioinspired hardware that enables parallel processing of color recognition, tunable adaptation, CPL perception, and multi-state readout. Nanoclusters are precise metal atoms coordinated by alternative protective ligands and this unique structure allows tunable physical properties, such as discrete energy levels and sizable bandgaps due to quantum size effects14. Additionally, nanoclusters possess excellent photon-to-electron conversion, thus being advantageous for the construction of artificial photoreceptors15. Herein, inspired by mantis shrimps, we demonstrate an artificial nanocluster photoreceptor (ACP) array based on a heterostructure formed by chiral nanoclusters and organic semiconductors. Nanoclusters are embedded as in-sensor light valve charge reservoir, enabling decoding wavelength and intensity from incident photons. Furthermore, established nanocluster-conjugated molecule interface (NMI) functions as an adaptative vision by outputting multi-state results with tunable kinetics. On the other hand, by employing the chirality of nanoclusters, ACP perceives circular polarization information. Hence, ACP combines color vision, photoadaptation, and circular polarization vision, thereby opening up opportunities for structurally simplified all-in-one AVSs. Results Mantis shrimp-inspired nanocluster photoreceptors Mantis shrimps have incredibly structured eyes comprising thousands of closely packed and parallelly arranged ommatidia. A six-row midband (MB) sandwiched by dorsal hemispheres (DH) and ventral hemispheres (VH) is shown in Fig. 1a. A comprehensive illustration of structure-related visual functions in Mantis shrimps is depicted in Fig. 1b and Supplementary Note 1. Ommatidia in the MB region are as optically sensitive units including corneal lens, crystalline cone, and rhabdom (R)16. The rhabdom consists of 8 retinular cells with spectral sensitivity from the ultraviolet (UV) to the red17. In rows 5 and 6, planes of microvilli in the R8 cells are oriented at an angle of 45\u00b0 to planes of the R1\u2013R7 cells, acting as 1/2 and 1/4 wave plates to distinguish CPL18,19. Moreover, photomechanical changes and tunable filters enable the shrimps to adapt to the variable changes in lighting environments20,21. Eventually, optical nerve located at the bottom of each rhabdom transmits signals to the brain. Fig. 1: Mantis shrimp-inspired artificial nanocluster photoreceptors. a A schematic of a mantis shrimp and a front view of its eyes. R1\u2013R8 represent rhabdoms. The eye is comprised of dorsal hemispheres (DH), midband (MB), and ventral hemispheres (VH). b Mantis shrimp visual system comprises parallel-arranged ommatidia, optical nerve, and brain. c Schematic of an artificial nanocluster photoreceptor (ACP) based on pentacene and chiral silver nanocluster heterostructure sensitive to ultraviolet-visual light and circularly polarized light (CPL). Translucent spheres represent the nanoclusters with 6 chiral silvers (core, small yellow ball) and 6 chiral ligands (shell, translucent section). d The chemical structure of pentacene and chiral silver nanocluster enantiomorph. e Shrimp-like functions and anatomical structure of ACP. VG gate voltage. f Imitation of all-in-one functional behaviors, including color vision, adaptative vision, and circular polarization vision. IDS drain current, R red, G green, B blue, UV ultraviolet. Plight light intensity, LCPL left-handed circularly polarized light, RCPL right-handed circularly polarized light. Full size image Inspired by the multi-layered structure of the ommatidia, we fabricate ACP by embedding atom-precise chiral silver nanoclusters beneath a typical organic semiconductor, pentacene layer to form a\u2009NMI (Fig. 1c, d and Supplementary Note 2). Chiral Ag nanoclusters with six chiral ligands and 6 chiral Ag cores play a similar role to R8 cells owing to their sensitivity to UV and CPL. Meanwhile, pentacene layer functions analogously to the R1\u2013R7 cells with a broadband photoresponse (Supplementary Fig. 1). Here, pentacene also undertakes the role of optical nerves, transforming incident photons into readable electrical signals (Fig. 1e). Note that the density of photogenerated charge carriers in the pentacene layer can be tuned effectively by trapping and de-trapping dynamics in Ag nanoclusters, under the joint stimulation of light and gate biasing. Therefore, biomimetic visual functionalities, e.g., color vision, adaptative vision, and circular polarization vision, are realized in our all-in-one system (Fig. 1f, Supplementary Note 3). Furthermore, Table 1 illustrates the comparison in terms of photoperception characteristics between our ACP array and counterpart eyes of Mantis shrimps. Moreover, advanced functions are demonstrated in an ACP, manifesting the successful application of our system to multi-task, intelligent devices, and high-density integrated pixelated arrays. Table 1 A comprehensive comparison of ACP arrays and mantis shrimp vision system Full size table Microstructure and in-sensor charge reservoir An ACP array is fabricated on a 4-inch wafer with 200 photoreceptors arbitrarily chosen to test the feasibility of large-scale fabrication (Fig. 2a and Supplementary Fig. 2). Ag nanoclusters and pentacene layers are fabricated by spin-coating and vacuum evaporation, respectively. This combination forms a heterostructure with a smooth and highly-distinguishable interface (Fig. 2b and Supplementary Fig. 3). Detailed fabrication processes are described in Methods. Different means of microscopes are used to elucidate the uniformity of Ag nanocluster layer (Fig. 2c\u2013e and Supplementary Fig. 4). It is discovered that given sufficient nucleation and self-assembly time, Ag nanoclusters form highly crystalline aggregates (Supplementary Fig. 5). However, it represents a challenge for the fabrication of uniform interface with organic semiconductors. We carefully control crystallization and aggregation of Ag nanoclusters by high-speed spin-coating with volatile solvents, hence an ultrasmooth film with a root-mean-square roughness of 0.45\u2009nm is obtained (Supplementary Note 4). No significant X-ray diffraction (XRD) peaks are observed in as-fabricated Ag nanocluster layer, being adequate for homogeneous interface formation in conjunction with pentacene (Supplementary Figs. 6 and 7). Crystallinity of pentacene deposited on Ag nanoclusters is effectively suppressed with respect to that on silica (Supplementary Fig. 7). The hole mobility of pentacene deposited on Ag nanoclusters is measured to be half of the neat pentacene on SiO2 (0.027\u2009cm2\u2009V\u22121\u2009s\u22121 versus 0.055\u2009cm2\u2009V\u22121\u2009s\u22121). However, this difference shows limited influence on the biomimetic functions of ACP (Supplementary Fig. 8). Fig. 2: Microstructure and in-sensor charge reservoir. a Optical image of a wafer-scale artificial nanocluster photoreceptor (ACP) array. Channel width and length of the device are 4500\u2009\u03bcm and 20\u2009\u03bcm, respectively. b Cross-sectional transmission electron microscope image of a pentacene/Ag nanoclusters/SiO2 stack. Scale bar: 200\u2009nm. c Optical microscope image of Ag nanocluster film. Scale bar: 8\u2009\u03bcm. d Scanning near-field optical microscopy of Ag nanocluster film. Scale bar: 2\u2009\u03bcm. e Cryo-transmission electron microscope image of Ag nanocluster film. Scale bar: 20\u2009nm. f Transfer characteristics of a typical device under 30 times of repetitive bidirectional scanning or after VG pulse (\u221260\u2009V or \u221280\u2009V, 1\u2009s) under darkness. g Hysteric transfer characteristics window in ACP towards different light intensity (460\u2009nm). h Hysteresis window in a device as a function of incident light intensity with different wavelengths (UV: 365\u2009nm, blue: 460\u2009nm, green: 525\u2009nm, red: 620\u2009nm). i Synergistic effect of gate voltage and light on ACP. j Real-time photoadaptation under incident light (2\u2009mW\u2009cm\u22122) with a multiple of wavelengths (VDS\u2009=\u2009\u221210\u2009V, VG\u2009=\u20090\u2009V). k The diagram of light-valve model and charge reservoir of Ag nanoclusters. Full size image Core-shell Ag nanoclusters underneath pentacene function as charge reservoir to perceive light information, such as spectrum and intensity. Threshold voltage of ACP shifts to the negative/positive direction under gate bias contributing to charges storage/release capacity of Ag nanoclusters (Fig. 2f and Supplementary Fig. 9). Moreover, a counterclockwise hysteresis loop with the threshold voltage (VT) shift of 45\u2009V is observed under illumination (Fig. 2g and Supplementary Fig. 10), which indicates a light-amplified charge trapping and recombination process. Interestingly, photocurrent increases in the positive gate voltage (VG) region while the maximum on-state current decreases as light density increases. This observation demonstrates the synergistic modulation of VG and light to the magnitude of channel currents. In this way, ACP can display dual-factor stimulated optoelectronic signals. We further quantify ACP\u2019s light storage capability by means of hysteresis window, and it is found to be a function of light intensity, wavelength, and VG scanning range (Fig. 2h and Supplementary Fig. 11). Incident photons in UV and blue spectrum deliver more evident hysteresis than green and red. This result is ascribed to the wide bandgap feature of Ag nanoclusters. Given the above results, we further study the synergistic effect of gate voltage and light on ACP. Individual application of a positive VG pulse or a light pulse merely causes a weak increase in current. Nevertheless, concurrent application of positive VG and light produces a drastic drain current (IDS) change from 10\u22128 A to 10\u22125\u2009A (Fig. 2i and Supplementary Fig. 12). Here, increment in IDS is attributed to Ag nanocluster gating and photoinduced hole accumulation in pentacene. Furthermore, the kinetics of IDS under photoadaptation modes is investigated (Fig. 2j). IDS decreases exponentially with different rates, and it is found to be wavelength-dependent. Adaptation of ACP is written by: $${I}_{{{{{\\rm{adaptation}}}}}}={A}_{{{{{\\rm{adaptation}}}}}}{{{{{\\rm{e}}}}}}^{-t/{\\tau }_{{{{{\\rm{dec}}}}}}}+{I}_{{{{{\\rm{initial}}}}}}$$ (1) Iadaptation is the current value of light-exposed ACP, Aadaptation is a pre-exponential factor, and \u03c4dec is time constant. UV and blue photons result in a prompt adaptation or decay in IDS (\u03c4dec, 365\u2009nm\u2009=\u20090.25\u2009s, \u03c4dec, 460\u2009nm\u2009=\u200946.4\u2009s). By comparison, milder declination in IDS levels is produced under green and red light (\u03c4dec, 525\u2009nm\u2009=\u2009286\u2009s, \u03c4dec, 620\u2009nm\u2009= 290\u2009s). These results are assigned to release of electrons in Ag nanoclusters under excitation of high energy photons, which depletes holes in pentacene by charge transfer and leads to relaxation of IDS. As a summary, experiments reveal the spectral-relevant photoadaptation in ACP. Here, we propose a light-valve model to describe the charge reservoir behavior of Ag nanoclusters (Fig. 2k and Supplementary Note 5). The instant under illumination, accumulation of photoinduced electrons in Ag nanoclusters prompts hole density of pentacene to approach the borderline. After co-modulation of positive VG and light, ACP switches to closed valve with channel hole density exceeding the borderline and photoinduced electrons preserved in Ag nanoclusters. When the valve is switched on by light, electrons and holes recombine to diminish current levels. Static and dynamic capabilities of charge reservoir are quantitatively analyzed (Supplementary Figs. 13, 14). ACP displays a 105 dynamic range of current levels within 10,000\u2009s and 165 times repeatability in photoresponse and photoadaptation. In addition, multi-levels in photoresponse can be attained by simply varying the magnitude of VG impulses without tuning light intensity (Supplementary Fig. 15). Finally, ACP displayed superior shelf life and still retained retention capacity after being deposited for one year (Supplementary Fig. 16). When humidity in testing environments was over 40%, off-state currents in ACP were found to increase remarkably, which might reduce its dynamic range (Supplementary Note 6). Charge dynamics in nanocluster-conjugated molecule interface Functions of proposed light-valve relies on the interface of pentacene and Ag nanoclusters. Control devices without Ag nanoclusters or with a sandwiched 7\u2009nm tetratetracontane layer into\u2009nmI exhibit a faint response and insignificant hysteresis even under white light with intensity of 10\u2009mW\u2009cm\u22122 (Supplementary Fig. 17). Similar results were observed in parallel devices with interlayer composed of quantum dots and semiconductors (Supplementary Fig. 18 and Supplementary Note 7), which demonstrates indispensable status of our\u2009NMI strategy. Interface guarantees a highly efficient charge-transfer process, as proved by time-resolved photoluminescence spectra (Supplementary Fig. 19). The PL lifetime (\u03c4PL) of Ag nanoclusters is evidently shortened from 1.54\u2009\u03bcs (\u03c41) and 5.74\u2009\u03bcs (\u03c42) to 0.78\u2009\u03bcs (\u03c41) and 3.99\u2009\u03bcs (\u03c42) when interfaced with pentacene. These results demonstrate that photogenerated holes are instantaneously injected into the pentacene channel from Ag nanoclusters. Ligands are critical for the interfacial charge transfer between Ag nanoclusters and organic semiconductors. Phenyl ligands induce \u03c0\u2013\u03c0 interaction with pentacene and are considered to be responsible for highly efficient charge transfer. To verify this hypothesis, charge density difference is calculated based on a simplified heterostructure model, as shown in Fig. 3a. The phenyl group, together with S atoms and Ag cores forms a direct pathway to capture electrons from pentacene. For comparison, in a control simulation, regions along alkyl ligands that gains and loses electrons are ambiguously identified (Supplementary Fig. 20). Aromatic ligands function as a bridge to enable charge transport through hopping, while alkyl ligands break the coherence of \u03c0 systems, which impedes charge transport. As a result, alkyl ligand coordinated Ag nanoclusters contained devices have notably inferior performance as ACPs, with their experimentally-derived energy levels and morphology provided in Supplementary Figs. 21, 22. Spin density distribution (SDD) of negatively charged Ag nanoclusters is calculated (Fig. 3b). Lone-electron spin density is completely centralized on Ag core and isolated from pentacene, providing direct evidence for charge reservoir. Fig. 3: Charge dynamics in nanocluster-conjugated molecule interface. a Charge density difference of pentacene/Ag nanocluster heterostructure. Blue and orange colors indicate the negative (electrons decrease) and positive (electrons increase) values, respectively. The isosurface value is 0.002\u2009e\u2009\u00c5\u22123. b Spin density distributions (SDD) of negatively charged Ag nanoclusters. c Top: femtosecond-transient absorption spectroscopy of pentacene (80\u2009nm)/Ag nanocluster (20\u2009nm) film recorded with several time delays between 0.01\u2009ps and 100\u2009ps in the visible region (\u03bbpump\u2009=\u2009580\u2009nm) at room temperature. Pen+: pentacene radical cation. Bottom: species-associated spectra (SAS) of the film above from global and target analysis. Orange line: LE state, green line: CT state, blue line: T state. d Schematic diagram of the process in the film through localized excited states (LE), charge-transfer state (CT), and triplet state (T). \u03c4LE,CT and \u03c4CT,T are the lifetimes of excitons. e Evolution of the population of the LE, CT, and T states. f Surface potential of pentacene/Ag nanocluster film under different intensities of light generated by 473\u2009nm lasers. Scale bar: 0.5\u2009\u03bcm. g Comparison of the surface potential of pentacene/Ag nanocluster film under different wavelength light (473\u2009nm, 532\u2009nm, 633\u2009nm). h Energy-band diagram of the heterostructure under light illumination. Left dissociation mode, Right recombination mode, Blue ball electron, Red ball hole. Full size image To acquire deeper insight into light-valve mechanism of photoexcited interface, we utilize femtosecond-transient absorption spectroscopy to probe the dynamics under excitation of 580\u2009nm and 365\u2009nm lasers. As shown in Fig. 3c and Supplementary Fig. 23, both pentacene and pentacene/Ag nanoclusters produce similar spectral features, wherein pentacene radical cation as a dynamic intermediate produces an excited state peak located at 400\u2212420\u2009nm22,23. However, the difference in decay dynamics of excited states is evident. As shown in Supplementary Fig. 24, it takes hole absorption (420\u2009nm) 5\u2009ns to decay to zero (pump: 580\u2009nm) and 30\u2009ps (pump: 365\u2009nm) for pentacene, being longer than the decay time measured in pentacene/Ag nanoclusters, 1\u2009ns (pump: 580\u2009nm) and 10\u2009ps (pump: 365\u2009nm). To separate the overlapping spectra of the excited states and obtain the unambiguous charge-transfer kinetics, we use the global target analysis to extract the individual component and corresponding time constants (Supplementary Fig. 25). Evolution of three major species is demonstrated by locally singlet excited states (LE), charge-transfer states (CT), and locally triplet excited states (T) in Fig. 3d. Here, the single fission is also considered as a competitive process since the triplet excited states are observed at a femtosecond timescale24,25. As shown in Fig. 3e, lifetime of the CT (\u03c4CT,T) for pentacene (74\u2009ps) is nearly six times the length of pentacene/Ag nanoclusters (12\u2009ps) under the 580\u2009nm pump light. \u03c4CT,T in heterostructure is even shortened to 4.9\u2009ps when 365\u2009nm pump light is used, fully elucidating the role of Ag nanoclusters to accelerate the charge recombination to T state. Hence, photoexcited interface directly exerts influence on holes behavior in pentacene. Interfacial charge recombination-induced photoadaptation is probed by Kelvin probe force microscopy (KPFM). Surface potential of pentacene decreases with the increment in light intensity, indicating holes depletion under illumination (Fig. 3f). Shorter wavelength leads to more remarkable reduction in surface potential, being consistent with the transient absorption and photoinduced behavior of ACP (Fig. 3g). Therefore, a mechanistic model of ACP is proposed (Fig. 3h). Filled electrons on discrete energy levels will significantly alter the Fermi level of Ag nanoclusters. With low hole density in pentacene, photogenerated excitons are separated at\u2009NMI, resulting in an increment of channel hole density. Meanwhile, captured electrons in Ag nanoclusters directly lead to the upshift of Fermi level. When light with a short wavelength or high intensity is applied, a large number of excited electrons prompt the recombination rate at\u2009NMI and deplete holes in pentacene, leading to rapid current attenuation. Thus, filled hole/electron levels in pentacene/Ag nanoclusters determine the photoadaptation dynamics. It is worth emphasizing that gate voltage is responsible for charge trapping/de-trapping dynamics rather than the polarity of photogenerated carriers in Ag nanoclusters. To conclude, we can facilely modulate ACP through light and gate impulses. Spectral-dependent visual adaptation In response to the brightness changes in environments, visual adaptation has evolved as a self-regulated activity in various living creatures. The aim of adaptation is to modulate the perception range of eyes to attain the best contrast and clear images. The magnitude of visual adaptation can be modulated by both incident light wavelengths and luminance intensities. As far as ACP, photoadaptation functions as a reservoir to regulate the channel current, keeping it at an appropriate level. ACP shows stepwise strengthened, electric-mode adaptation with increased VG (Fig. 4a). This is ascribed to the gate-driven hole transfer from pentacene to Ag nanoclusters. Furthermore, the operation mode of either photopic adaptation or scotopic adaptation is tunable and dependent on VG applied (Fig. 4b and Supplementary Fig. 26). We define adaptation index (AI) by It/Ii to evaluate the magnitude of light adaptation under various wavelengths. ACP has a stronger adaptability to short-wavelength and high-intensity light. It is explained by photons with high energy being capable of inducing charge accumulation in wide bandgap nanoclusters (Fig. 4c). Perception range (PR) and adaptation time (Tadapt) are critical parameters to quantitatively analyze the light-induced adaptability from the device. PR is defined by: $${PR}=20\\times \\log \\left[\\frac{{I}_{\\max }}{{I}_{\\min }}\\right]$$ (2) Fig. 4: Spectral-dependent visual adaptation. a Real-time current recording under various VG amplitude. b Scotopic adaptation (VG\u2009=\u20090\u2009V) and photopic adaptation (VG\u2009=\u2009\u221210\u2009V) under different Plight values. c AI values measured as a function of Plight, VG values and incident photon wavelengths. AI is defined as: It/Ii, It and Ii are defined as the device current instantaneously read from the end and the beginning of light impulse. d IDS plotted against Plight under various PR biasing conditions. e Comparison of the perception range (PR) and adaptation time (Tadapt) of adaptable device in this work with results in literature. f Schematic of the spectral-dependent photopic adaptation. Mapping of signals in 5\u2009\u00d7\u20095 pixel array, which perceives the pattern of letters I (620\u2009nm), F (525\u2009nm), U (460\u2009nm) from a colored alphabet that is illuminated by a multiple of wavelengths. Full size image Adaptation time is quantified by the time required for current to decrease from Imax to Iadapt or adaptation speed. For ACP, Imax/Imin can reach 106 and PR is calculated to be 120. We extract the IDS as a function of light intensity (Plight) under variable VG as shown in Fig. 4d. High photon density significantly leads to more prompt declination of device current under the condition that negative VG is applied. Hence, under VG\u2009=\u2009\u221230\u2009V, adaptation time of ACP to UV light (365\u2009nm, 0.8\u2009mW\u2009cm\u22122) can be shortened to 0.45\u2009s (Supplementary Fig. 27). Accuracy is given by (Imax \u2212 Iadapt)/(Imax \u2212 Imin) and it reaches 99.75% under this condition. As shown in Fig. 4e and Supplementary Table 2, ACP presents a high PR and the shortest Tadapt compared with existing state-of-the-art adaptable devices1,2,3,26,27,28,29,30,31,32,33,34, thereby proving the successful adoption of nanoclusters for fast adaptive vision sensors. To demonstrate spectral-dependent adaptation, we fabricate a 5\u2009\u00d7\u20095 ACP pixel array to perceive patterns and record the image immediately after light illumination (Fig. 4f and Supplementary Fig. 28). Initially, the photocurrents of ACPs are all in a photobleached state after stimulation (VG\u2009=\u200960\u2009V, 1\u2009s; light impulse, 2\u2009mW\u2009cm\u22122, 1\u2009s) and this represents the scene where human eyes could not obtain any information. After a 25\u2009s interval under illumination with various wavelengths, ACP array can distinguish letters in different colors by means of variable current levels. Hence, ACP array demonstrates its capacity for object recognition with spatial and color information by producing adaptative signals. Furthermore, emulation of retinal damage under UV light has been performed. After 20\u2009s illumination of UV light, ID regains its off-state value and discharges all information previously perceived. Circular polarization vision Animals encounter the risk of information disclosure by predators, prey and competitors during intraspecific communication by postures, sound waves, etc18. Polarization of light is an appropriate medium for encoded information exchange and potential high-frame event-triggered vision35,36,37. Mantis shrimps have evolved circular polarization vision as an encrypted way to convey information. Circular polarization vision, capable of detecting and analyzing CPL, has aroused significant attention due to its potential applications in chiral sensing and information encryption38. Although state-of-the-art CPL detectors have achieved recognition of CPL, lack of memory for circularly polarization information limits their potential in AVSs. Core-shell chiral Ag nanoclusters endow ACP with CPL storage capabilities. Figure 5a shows the circular dichroism spectrum of Ag nanocluster film, the maximum dissymmetry factor (gCD) value for Ag nanoclusters has been measured to be ~\u00b11.3\u2009\u00d7\u200910\u22123 at 277\u2009nm. Fig. 5: Circular polarization vision. a Circular dichroism (CD) spectroscopy and gCD characteristics of the chiral Ag nanocluster film on quartz substrates. Solid line: CD value. Dotted lines: gCD value. Real-time saturated drain current in an artificial nanocluster interfaced photoreceptor based on S-Ag nanoclusters (b) and R-Ag nanoclusters (c) under alternatively switched left-handed circularly polarized light (LCPL) and right-handed circularly polarized light (RCPL). Illumination conditions: 270\u2009nm, 100\u2009\u03bcW\u2009cm\u22122. Biasing conditions: VG\u2009=\u20090\u2009V, VDS\u2009=\u2009\u22121\u2009V. d Real-time IDS of an artificial nanocluster interfaced photoreceptor device based on S-Ag nanoclusters under and after 15\u2009s LCPL and RCPL illumination (270\u2009nm, 100\u2009\u03bcW\u2009cm\u22122), VG\u2009=\u20090\u2009V, VDS\u2009=\u2009\u22125\u2009V. e Repetitive IDS current level in response to alternatively switched LCPL and RCPL illumination. f Circular polarization visual adaptation based on S-Ag nanoclusters. Illumination conditions: 270\u2009nm, 100\u2009\u03bcW\u2009cm\u22122. Biasing conditions: VG\u2009=\u20090\u2009V, VDS\u2009=\u2009\u221210\u2009V, VG pulse is set as \u221230\u2009V. Full size image By the chiral assembly of Ag nanoclusters, circularly polarized vision, including response, identification, adaptation, and memory to CPL, can be realized in a single biomimetic cell. Distinct saturated photocurrent signals of ACP exposed to CPL illumination are shown in Fig. 5b, c and Supplementary Fig. 29. ACP with S-Ag nanoclusters has higher photocurrent under right-handed circularly polarized light (RCPL) than left-handed circularly polarized light (LCPL). By comparison, opposite phenomenon is observed for ACP with R-Ag nanoclusters. When ACP is exposed to the light, the photocurrent increases gradually. As the light is switched off, the current decreases to a steady state, demonstrating a memory operation that has not been reported in other CPL detectors. ACP can store and distinguish RCPL/LCPL currents, as shown in Fig. 5d and Supplementary Fig. 30. After 15\u2009s RCPL/LCPL impulses, current switches into an exponential decay curve. Hence, it is reasonable to speculate that ACP can still maintain and distinguish CPL after retention of 100,000\u2009seconds. The reproducibility of CPL discrimination capability has been verified in Fig. 5e. Moreover, adaptation of ACP to CPL light with low light density can be achieved. AI reaches 0.19 while Tadapt is prolonged to a timescale of 7\u2009s. Under alternative switching of RCPL and LCPL, ACP clearly perceives the polarization of incident CPL with good reproducibility (Fig. 5f). Discussion We report biomimetic nanocluster photoreceptors based on visually adaptable chiral-nanocluster-conjugated molecule interface. Light-assisted, tunable Femi energy levels of nanoclusters function as electron reservoir and they precisely control trapping and release of charge carriers in proposed artificial photoreceptors. Inspired by mantis shrimps, visual adaptation in ACP is accomplished by the modulation of photogenerated carriers at the interface of organic molecules and Ag nanoclusters. Wavelength and intensity-dependent adaptations are further demonstrated by the recognition of shapes and colors. Taking advantage of the chirality of Ag nanoclusters, ACP is enabled to distinguish CPL light. As a result, circular polarization vision is successfully emulated and highly similar to the functions of mantis shrimps. To further explore the light-valve mechanism of Ag nanoclusters, charge storage site and charge-transfer pathway in\u2009NMI are surveyed by transient absorption and photoluminescence techniques. In summary, ACP presents an emulation of the complex visual system in mantis shrimps. Its multi-task feature integrates panchromatic adaptation and circularly polarized vision through a simple architecture. As a perspective, this bioinspired system can be upgraded to meet the needs of vision-related AI hardware and communication of encrypted information. Nanocluster-embedded artificial photoreceptors construct a concise model to explore optoelectronic behavior of nanoclusters. We reveal charge carrier dynamics and photoinduced electron transport in the nanocluster-organic heterostructure interface. The core-shell structure of nanoclusters enables them with charge reservoir ability and protective ligands function as signal transduction pathways linking nanoclusters and organic materials. In doing this, we further develop wafer-scale fabrication technology of nanocluster electronics and lead nanoclusters into the era of artificial intelligence. Methods Materials (R/S)-4-Isopropylthiazolidine-2-thione and (R/S)-4-Phenylthiazolidine-2-thione were purchased from Sigma-Aldrich as ligands of nanoclusters. Silver nitrate was purchased from Macklin. Pentacene was purchased from Tokyo Chemical Industry Co., Ltd. (TCI). Tetratetracontane was purchased from Sigma-Aldrich. Preparation of chiral silver nanoclusters Preparation of Ag nanoclusters is conducted in similar protocols to the literature39. Silver nitrate (1\u2009mmol) and ligand (1\u2009mmol) were dissolved in a mixture of 1\u2009mL DMAc/CH3CN (V: V\u2009=\u20093:1) to form a yellowish solution with fluorescence. Afterwards, the yellowish block Ag nanocluster crystals were obtained by slow-evaporation of solvents in darkness at room temperature for 1 day. Fabrication of ACPs P-type silicon wafers with thermally oxidized SiO2 (~300\u2009nm thick) were used as substrates. As the cleaning procedures, wafers were soaked into the piranha solution (70\u2009vol% H2SO4 and 30\u2009vol% H2O2) for 10\u2009min, then rinsed successively via ultrasonication in de-ionized water, acetone, and ethanol for 5\u2009min, respectively. After being blown dry with nitrogen gas, wafers were further passivated by oxygen plasma for 10\u2009min. Chiral Ag nanocluster crystals were dissolved in tetrahydrofuran (5\u2009mg\u2009mL\u22121) and spin-coated on the wafer with a speed of 6000\u2009rpm for 30\u2009s. Due to its low boiling point (66\u2009\u00b0C), most tetrahydrofuran volatilized during spin-coating. Under a pressure of 6\u2009\u00d7\u200910\u22124\u2009Pa, 30-nm-thick pentacene was thermally evaporated on the Ag nanoclusters at a rate of 0.1\u2009\u00c5\u2009s\u22121. Finally, 30-nm-thick gold (Au) was thermally evaporated through a shadow mask to define source and drain electrodes. Channel width-to-length ratio was designed to be 225 (W/L\u2009=\u20094500\u2009\u03bcm/20\u2009\u03bcm). Characterization of ACPs Electrical measurement of all devices was characterized by a semiconductor parameter analyzer (Keithley 4200\u2009A SCS) and source meters (Keysight B2912A). Atomic force microscopy was performed using a NanoMan VS system. SEM images were taken with a Hitachi S-4800 field emission scanning electron microscope. KPFM images were obtained with a NTEGRA Spectra (NT-MDT, Russia) in a Kelvin mode by using a gold-coated silicon probe with force constant ~17\u2009N\u2009m\u22121. The scan rate is 0.5\u2009Hz, and the light was provided by 473\u2009nm, 532\u2009nm, 633\u2009nm lasers. Scan near-filed optical microscopy (SNOM) images were obtained by neaSCOPE. The wavelength of the laser was set to 1331\u2009nm according to the FT-IR spectrum of the Ag nanoclusters. Cryo-transmission electron microscope (Cryo-TEM) image of Ag nanocluster film was captured by Themis 300. The cross-sectional image of the device was captured by transmission electron microscopy (TEM; JEM-2100F, JEOL) operated at 200\u2009kV. The grazing-incidence wide-angle X-ray scattering (GIWAXS) data were obtained at 1W1A Diffuse X-ray Scattering Station, Beijing Synchrotron Radiation Facility (BSRF-1W1A). Steady-state UV-vis spectra were recorded with PerkinElmer LAMBDA 1050 spectrometer. Steady-state PL spectra were measured with a Horiba FluoroMax+ spectrometer. Time-resolved photoluminescence (TRPL) spectra were measured on an FLS980 Steady-State and Transient Fluorescence spectrophotometer with an excitation wavelength of 400\u2009nm. HOMO energy levels of nanoclusters were measured by Ultraviolet photoelectron spectroscopy (Kratos Axis Ultra Dld). The XRD data were measured by X-ray Powder diffractometer (Malvern PANalytical Empyrean). CPL was generated by 270\u2009nm LED through a half-wave plate (Thorlabs, WP25M-UB) and a quarter-wave plate (Thorlabs, AQWP05M-340). The intensity of LCPL and RCPL was calibrated by a standard Si detector (Newport, 818-SL/DB). Transient absorption measurements TA spectra were measured by Vitara T-Legend Elite-TOPAS-Helios-EOS-Omni. Light pulses were provided from a Ti: Sa amplified laser system (Legend Elite-1K-HE). Wavelengths of pump light were 365\u2009nm and 580\u2009nm, while the probe from 380\u2009nm to 800\u2009nm was generated by the laser beam onto a CaF2 plate. Global and target analysis was performed by global target analysis, GloTarAn, based on the R-package TIMP40,41. Singular value decomposition, decay-associated spectra, and species-associated spectra are obtained by global and target analysis. Computational methods Quantum chemical calculation was carried out using Gaussian 09 software package42. The ground-state geometry optimization was performed by Perdew-Burke-Ernzerhof functional using 6\u201331\u2009g* basis set for H, C, N, and S atoms and Lanl2TZ effective core potentials for Ag atoms43,44,45. The single-crystal structure from CCDC was chosen as the initial guess for ground-state geometry optimization. Afterwards, analyzing wavefunction by Multiwfn46, charge density difference, and SDD were performed by B3LYP using def2-TZVP basis set for all atoms and visualized with Visualization for Electronic and Structural Analysis47. Data availability The data are provided to support the plots within this manuscript, and other findings of this study are available from the corresponding authors upon request. Source data are provided with this paper. References Lee, T. J. et al. Realization of an artificial visual nervous system using an integrated optoelectronic device array. Adv. Mater. 33, e2105485 (2021). Article   PubMed   Google Scholar   Kwon, S. M. et al. Environment-adaptable artificial visual perception behaviors using a light-adjustable optoelectronic neuromorphic device array. Adv. Mater. 31, e1906433 (2019). Article   PubMed   Google Scholar   He, Z. H. et al. An organic transistor with light intensity-dependent active photoadaptation. Nat. Electron. 4, 522\u2013529 (2021). Article   CAS   Google Scholar   Wang, H. et al. A ferroelectric/electrochemical modulated organic synapse for ultraflexible, artificial visual-perception system. Adv. Mater. 30, e1803961 (2018). Article   PubMed   Google Scholar   Chen, S. et al. An artificial flexible visual memory system based on an UV-motivated memristor. Adv. Mater. 30, 1705400 (2018). Article   Google Scholar   Seo, S. et al. Artificial optic-neural synapse for colored and color-mixed pattern recognition. Nat. Commun. 9, 5106 (2018). Article   PubMed   PubMed Central   ADS   Google Scholar   Liu, S. C. Silicon retina with adaptive filtering properties. Analog Integr. Circuits Signal Process. 18, 243\u2013254 (1999). Article   Google Scholar   Mafrica, S. et al. A bio-inspired analog silicon retina with Michaelis-Menten auto-adaptive pixels sensitive to small and large changes in light. Opt. Express 23, 5614\u20135635 (2015). Article   CAS   PubMed   ADS   Google Scholar   Marshall, J. et al. Stomatopod eye structure and function: a review. Arthropod. Struct. Dev. 36, 420\u2013448 (2007). Article   PubMed   Google Scholar   Islam, M. M. et al. Multiwavelength optoelectronic synapse with 2D materials for mixed-color pattern recognition. ACS Nano. 16, 10188\u201310198 (2022). Article   CAS   PubMed   Google Scholar   Yang, Y. et al. Circularly polarized light detection by a chiral organic semiconductor transistor. Nat. Photon. 7, 634\u2013638 (2013). Article   CAS   ADS   Google Scholar   Zhang, L. et al. \u03c0-Extended perylene diimide double-heterohelicenes as ambipolar organic semiconductors for broadband circularly polarized light detection. Nat. Commun. 12, 142 (2021). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Han, H. et al. High\u2010performance circularly polarized light\u2010sensing near\u2010infrared organic phototransistors for optoelectronic cryptographic primitives. Adv. Funct. Mater. 30, 2006236 (2020). Article   CAS   Google Scholar   Matus, M. F. et al. Understanding ligand-protected noble metal nanoclusters at work. Nat. Rev. Mater. 8, 372\u2013389 (2023). Article   CAS   ADS   Google Scholar   Chen, L. et al. Metal nanocluster\u2010based devices: challenges and opportunities. Aggregate 3, e132 (2021). Article   Google Scholar   Cronin, T. W. et al. Filtering and polychromatic vision in mantis shrimps: themes in visible and ultraviolet vision. Philos. Trans. R. Soc. B. 369, 20130032 (2014). Article   Google Scholar   Cronin, T. W. et al. Specialization of retinal function in the compound eyes of mantis shrimps. Vis. Res. 34, 2639\u20132656 (1994). Article   CAS   PubMed   Google Scholar   Gagnon, Y. L. et al. Circularly polarized light as a communication signal in mantis shrimps. Curr. Biol. 25, 3074\u20133078 (2015). Article   CAS   PubMed   Google Scholar   Chiou, T. H. et al. Circular polarization vision in a stomatopod crustacean. Curr. Biol. 18, 429\u2013434 (2008). Article   CAS   PubMed   Google Scholar   Meyer-Rochow, V. B. The crustacean eye: dark/light adaptation, polarization sensitivity, flicker fusion frequency, and photoreceptor damage. Zool. Sci. 18, 1175\u20131197 (2001). Article   CAS   Google Scholar   Cronin, T. W. et al. Sensory adaptation. Tunable colour vision in a mantis shrimp. Nature 411, 547\u2013548 (2001). Article   CAS   PubMed   ADS   Google Scholar   Bettis Homan, S. et al. Ultrafast exciton dissociation and long-lived charge separation in a photovoltaic pentacene-MoS2 van der Waals heterojunction. Nano Lett. 17, 164\u2013169 (2017). Article   CAS   PubMed   ADS   Google Scholar   Enengl, S. et al. Spectroscopic characterization of charge carriers of the organic semiconductor quinacridone compared with pentacene during redox reactions. J. Mater. Chem. C. 4, 10265\u201310278 (2016). Article   CAS   Google Scholar   Wilson, M. W. et al. Ultrafast dynamics of exciton fission in polycrystalline pentacene. J. Am. Chem. Soc. 133, 11830\u201311833 (2011). Article   CAS   PubMed   Google Scholar   Nozik, A. J. Nanoscience and nanostructures for photovoltaics and solar fuels. Nano Lett. 10, 2735\u20132741 (2010). Article   CAS   PubMed   ADS   Google Scholar   Liu, J. et al. Mixed-halide perovskite film-based neuromorphic phototransistors for mimicking experience-history-dependent sensory adaptation. ACS Appl. Mater. Interfaces 13, 47807\u201347816 (2021). Article   CAS   PubMed   Google Scholar   Hong, S. et al. Sensory adaptation and neuromorphic phototransistors based on CsPb(Br1-xIx)3 perovskite and MoS2 hybrid structure. ACS Nano. 14, 9796\u20139806 (2020). Article   CAS   PubMed   Google Scholar   Jin, C. et al. Artificial vision adaption mimicked by an optoelectrical In2O3 transistor array. Nano Lett. 22, 3372\u20133379 (2022). Article   CAS   PubMed   ADS   Google Scholar   Ng, S. E. et al. Inorganic electrochromic transistors as environmentally adaptable photodetectors. Nano Energy 97, 107142 (2022). Zhang, M. et al. An irradiance-adaptable near-infrared vertical heterojunction phototransistor. Adv. Mater. 34, e2205679 (2022). Article   PubMed   Google Scholar   Liao, F. Y. et al. Bioinspired in-sensor visual adaptation for accurate perception. Nat. Electron. 5, 84\u201391 (2022). Article   Google Scholar   Chen, Q. et al. Switchable perovskite photovoltaic sensors for bioinspired adaptive machine vision. Adv. Intell. Syst. 2, 2000122 (2020). Article   Google Scholar   Xie, D. et al. Photoelectric visual adaptation based on 0D\u2010CsPbBr3\u2010quantum\u2010dots/2D\u2010MoS2 mixed\u2010dimensional heterojunction transistor. Adv. Funct. Mater. 31, 2010655 (2021). Article   CAS   Google Scholar   Shen, H. et al. Mimicking sensory adaptation with dielectric engineered organic transistors. Adv. Mater. 31, e1905018 (2019). Article   PubMed   Google Scholar   Garcia, M. et al. Bioinspired polarization imager with high dynamic range. Optica 5, 1240\u20131246 (2018). Article   CAS   ADS   Google Scholar   Floreano, D. et al. Miniature curved artificial compound eyes. Proc. Natl. Acad. Sci. USA 110, 9267\u20139272 (2013). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Haessig, G. et al. Bio-inspired polarization event camera. arXiv 2112, 01933 (2021). Google Scholar   Cronin, T. W. et al. A different view: sensory drive in the polarized-light realm. Curr. Zool. 64, 513\u2013523 (2018). Article   PubMed   PubMed Central   Google Scholar   Han, Z. et al. Ultrastable atomically precise chiral silver clusters with more than 95% quantum efficiency. Sci. Adv. 6, eaay0107 (2020). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Snellenburg, J. J. et al. Glotaran: a java-based graphical user interface for the R package TIMP. J. Stat. Softw. 49, 1\u201322 (2012). Article   Google Scholar   Mullen, K. M. et al. TIMP: an R package for modeling multi-way spectroscopic measurements. J. Stat. Softw. 18, 1\u201346 (2007). Article   Google Scholar   Frisch, M. J. Gaussian 09. revision D.01 (Guassian, 2013). Perdew, J. P. et al. Generalized gradient approximation made simple. Phys. Rev. Lett. 77, 3865\u20133868 (1996). Article   CAS   PubMed   ADS   Google Scholar   Hay, P. J. et al. Ab initio effective core potentials for molecular calculations. Potentials for the transition metal atoms Sc to Hg. J. Chem. Phys. 82, 270\u2013283 (1985). Article   CAS   ADS   Google Scholar   Hehre, W. J. et al. Self-consistent molecular orbital methods. XII. Further extensions of gaussian-type basis sets for use in molecular orbital studies of organic molecules. J. Chem. Phys. 56, 2257\u20132261 (1972). Article   CAS   ADS   Google Scholar   Lu, T. et al. Multiwfn: a multifunctional wavefunction analyzer. J. Comput. Chem. 33, 580\u2013592 (2012). Article   PubMed   Google Scholar   Stephens, P. J. et al. Ab initio calculation of vibrational absorption and circular dichroism spectra using density functional force fields. J. Chem. Phys. 98, 11623\u201311627 (2002). Article   Google Scholar   Download references Acknowledgements This work is supported by grants from the Strategic Priority Research Program of the Chinese Academy of Sciences (XDB0520000), the National Natural Science Foundation of China (no. U22A6002, 61890941, 61890943), the National Key R&D Program of China (grant no. 2018YFA0703202), and the CAS-Croucher Scheme for Joint Laboratories (no. CAS20903). A portion of this work is based on the data obtained at BSRF-1W1A. The authors gratefully acknowledge the cooperation of the beamline scientists at the BSRF-1W1A beamline. Author information These authors contributed equally: Wei Wen, Guocai Liu, Xiaofang Wei. Authors and Affiliations Beijing National Laboratory for Molecular Sciences, CAS Key Laboratory of Organic Solids, Institute of Chemistry, Chinese Academy of Sciences, Beijing, 100190, China Wei Wen, Guocai Liu, Xiaofang Wei, Haojie Huang, Danlei Zhu, Jianzhe Sun, Xin Huang, Wenkang Shi, Xiaojuan Dai, Jichen Dong, Lang Jiang, Yunlong Guo, Hanlin Wang & Yunqi Liu School of Chemical Sciences, University of Chinese Academy of Sciences, Beijing, 100049, China Wei Wen, Guocai Liu, Xiaofang Wei, Haojie Huang, Chong Wang, Danlei Zhu, Jianzhe Sun, Huijuan Yan, Xin Huang, Wenkang Shi, Xiaojuan Dai, Jichen Dong, Lang Jiang, Yunlong Guo, Hanlin Wang & Yunqi Liu CAS Key Laboratory of Molecular Nanostructure and Nanotechnology, CAS Research/Education Center for Excellence in Molecular Sciences, Beijing National Laboratory for Molecular Science, Institute of Chemistry, Chinese Academy of Sciences, Beijing, 100190, China Chong Wang & Huijuan Yan Contributions Y.L. conceived the project. W.W., H.W. and Y.L. designed the project and experiments. W.W. and G.L. performed the device fabrication. X.W. performed the spectral characterization. W.W. performed the device characterization. W.W., G.L. and X.W. analyzed the data. H.H. and J.D. performed the theoretical calculation. C.W. analyzed the transient absorption spectra. D.Z. and L.J. provided assistance in the CPL characterization. J.S. provided assistance in SNOM tests. H.Y. performed the KPFM measurements. X.H., W.S., X.D. and Y.G. provided assistance in material characterization. W.W. and H.W. wrote the manuscript. All authors discussed the results and commented on the manuscript. Corresponding authors Correspondence to Hanlin Wang or Yunqi Liu. Ethics declarations Competing interests The authors declare no competing interests. Peer review Peer review information Nature Communications thanks Franck Ruffier and the other anonymous reviewer(s) for their contribution to the peer review of this work. A peer review file is available. Additional information Publisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Supplementary information Supplementary Information Peer Review File Source data Source Data Rights and permissions Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. Reprints and permissions About this article Cite this article Wen, W., Liu, G., Wei, X. et al. Biomimetic nanocluster photoreceptors for adaptative circular polarization vision. Nat Commun 15, 2397 (2024). https://doi.org/10.1038/s41467-024-46646-5 Download citation Received 18 October 2023 Accepted 06 March 2024 Published 16 March 2024 DOI https://doi.org/10.1038/s41467-024-46646-5 Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Subjects Bioinformatics Electronic devices Comments By submitting a comment you agree to abide by our Terms and Community Guidelines. If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate. Download PDF Sections Figures References Abstract Introduction Results Discussion Methods Data availability References Acknowledgements Author information Ethics declarations Peer review Additional information Supplementary information Source data Rights and permissions About this article Comments Advertisement Nature Communications (Nat Commun) ISSN 2041-1723 (online) About Nature Portfolio About us Press releases Press office Contact us Discover content Journals A-Z Articles by subject Protocol Exchange Nature Index Publishing policies Nature portfolio policies Open access Author & Researcher services Reprints & permissions Research data Language editing Scientific editing Nature Masterclasses Research Solutions Libraries & institutions Librarian service & tools Librarian portal Open research Recommend to library Advertising & partnerships Advertising Partnerships & Services Media kits Branded content Professional development Nature Careers Nature Conferences Regional websites Nature Africa Nature China Nature India Nature Italy Nature Japan Nature Korea Nature Middle East Privacy Policy Use of cookies Your privacy choices/Manage cookies Legal notice Accessibility statement Terms & Conditions Your US state privacy rights \u00a9 2024 Springer Nature Limited",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "Evaluating financial fragility: a case study of Chinese banking and finance systems",
    "doi": "10.1057/s41599-024-02932-7",
    "description": "Global financial systems are inherently fragile due to their complexities. Thus, it is of great interest to devise various methods to assess the dynamics of financial fragility. As such, this study builds a financial fragility evaluation index system. The study finds three major fluctuations in the trend of financial fragility due to the great recession in 2008, the huge financial volatility in 2015, and the COVID-19 pandemic in 2019. It also tests the index system on the Chinese finance market from 2007 to 2022. Observations of capital adequacy, non-performing loans, and liquidity ratios, in addition to the average return on total assets, are used to assess banking fragility. The results attained show that amongst the tested banks, the Bank of Ningbo has the lowest vulnerability score, mainly due to its higher average return on total assets, capital adequacy ratios, and lower non-performing loan ratio. On the other end of the spectrum, China Minsheng Bank has the highest vulnerability score due to its lower capital adequacy and higher non-performing loan ratios. These findings provide valuable insights into the banking sector in China for policy formulation.",
    "journal": "Humanities and Social Sciences Communications",
    "authors": [
      "Shang L.",
      "Zhou B.",
      "Li J.",
      "Tang D.",
      "Boamah V.",
      "Pan Z."
    ],
    "citation_count": "0",
    "full_text": "Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Advertisement View all journals Search Log in Explore content About the journal Publish with us Sign up for alerts RSS feed nature humanities and social sciences communications articles article Article Open access Published: 16 March 2024 Evaluating financial fragility: a case study of Chinese banking and finance systems Li Shang, Biao Zhou, Jiannan Li, Decai Tang , Valentina Boamah & Zhiwei Pan  Humanities and Social Sciences Communications  11, Article number: 425 (2024) Cite this article 336 Accesses 12 Altmetric Metrics Abstract Global financial systems are inherently fragile due to their complexities. Thus, it is of great interest to devise various methods to assess the dynamics of financial fragility. As such, this study builds a financial fragility evaluation index system. The study finds three major fluctuations in the trend of financial fragility due to the great recession in 2008, the huge financial volatility in 2015, and the COVID-19 pandemic in 2019. It also tests the index system on the Chinese finance market from 2007 to 2022. Observations of capital adequacy, non-performing loans, and liquidity ratios, in addition to the average return on total assets, are used to assess banking fragility. The results attained show that amongst the tested banks, the Bank of Ningbo has the lowest vulnerability score, mainly due to its higher average return on total assets, capital adequacy ratios, and lower non-performing loan ratio. On the other end of the spectrum, China Minsheng Bank has the highest vulnerability score due to its lower capital adequacy and higher non-performing loan ratios. These findings provide valuable insights into the banking sector in China for policy formulation. Similar content being viewed by others Global supply chains amplify economic costs of future extreme heat risk Article Open access 13 March 2024 The evolution and future of research on Nature-based Solutions to address societal challenges Article Open access 15 March 2024 Quantitative analysis of mass mortality events in salmon aquaculture shows increasing scale of fish loss events around the world Article Open access 07 March 2024 Introduction Banks form integral parts of the global financial system, and their stability is key to stabilizing the overall system. Financial fragility in the banking system threatens the survival and development of the banking industry. It can also hinder sustainable economic development and lead to financial crises. The banking system\u2019s vulnerability is an important manifestation of financial vulnerability. Additionally, banks\u2019 non-performing loans, average return on total assets, liquidity ratio, and capital adequacy ratio collectively stabilize the banking system and ensure the smooth operation of the economy. Reducing the non-performing loan ratio, curbing financial risks, and maintaining the sound operation of banks through the three major frameworks of pre-credit assessment, loan review, and post-loan management are conducive to ensuring the stability of China\u2019s banking system. Consequently, there is abundant research on bank fragility. For example, Yu et al. (2015) studied rural commercial banks through a Probit model-based empirical analysis and found that the increment in loan interest rates increases the probability of farmers defaulting on their loans, leading to an increased risk for banks. Djebali and Zaghdoudi (2020) suggested that banks\u2019 liquidity risk will increase their non-performing loans, reduce their profitability, and threaten their stability. Hajar and Habib (2020) proposed that when assessing bank risks, capital adequacy ratio, financial asset quality, and prevalence cannot be ignored. Smaoui et al. (2020) showed that banks with low liquidity risk might take more radical measures to attract the clients of competitors who could not secure sufficient funding. Therefore, banks with lower liquidity risk are more vulnerable. Using monthly data from 147 developing countries from 1980 to 2016, Haan et al. (2020) found that most banks with high potential risks have the following characteristics: low levels of current assets and domestic financial liabilities, high levels of foreign liabilities, and high financial leverage. Halili et al. (2021) hypothesized that increasing credit derivatives holdings would also increase banks\u2019 risk. In addition, as an important factor affecting bank risk, many scholars have studied and analyzed non-performing loans. Serrano (2021) confirmed that the stock of non-performing loans has a negative impact on the bank\u2019s lending activities and is not conducive to the operational stability of the banks, resulting in a financial crisis. The study also established that profitability and capital adequacy ratios also have an impact on the fragility of banks. Kanga et al. (2020) demonstrated through experiments that bank capital and profitability have positive effects on banks. They argue that the more plentiful the bank\u2019s capital and profitability, the lower its fragility. Fragility indices of financial systems are also important because they are strongly correlated with a nation\u2019s economy and the formulation of economic policies by stakeholders. When financial vulnerability accumulates to a certain extent or reaches a certain critical state, a financial crisis becomes inevitable if it is not controlled and eliminated at the appropriate time. Once there is a financial crisis, it will be extremely harmful and destructive to the economy. The power of human intervention will be insignificant, necessitating much attention to be given to financial vulnerability, which is related to the lifeblood of the entire economy and the formulation of economic policies. Therefore, it is necessary to consider an alternative indicator for measuring China\u2019s financial vulnerability. There are many fragility indicators, including but not limited to GDP growth rate, real interest rate, inflation rate, M2 growth rate, cash savings rate, credit growth rate, return on assets, and foreign investment scale. Laura et al. (2015) found that when the financial market concentration is low, interest rates are low, inflation is high, and there is a decline in GDP, financial risks will be triggered and eventually lead to high financial vulnerabilities. Kim et al. (2020a, 2020b) implied that the diversification of the banking business might also increase financial instability and lead to the collapse of the financial system. Sushanta and Ricardo (2013) suggested that tight monetary policy is a cause of financial fragility and can affect output. In terms of financial fragility, not only general economic indicators can lead to financial risks, but also other factors, such as macroeconomics, wealth distribution, regulatory authority\u2019s policy, and foreign trade, can and will affect the stability of the financial system. For example, Fabio and Claudio (2014) observed that the fluctuations in the financial fragility index could be attributed to certain (global and domestic) macroeconomic, financial, and other factors. Mitkov (2019) suggested that the distribution of wealth affects the degree of financial fragility and that unequal distribution of wealth can also cause financial panic. Danilo (2020) mentioned that in terms of financial vulnerabilities, the government and central bank policies aimed at enhancing market liquidity play a key role. Georgiadis and Zhu (2021) determined from research on the relationship between financial foreign exchange risk and financial fragility that foreign exchange risk may endanger financial stability when the exchange rate depreciates and further hinder macroeconomic stability. Based on these foundations, this paper proposes and builds a new evaluation index to measure fragility in the financial system based on Chinese banks. Banking system vulnerability as discussed is an important manifestation of financial vulnerability, and this paper makes meaningful contributions to the study of financial vulnerability in two main ways. First, based on the cross-sectional data of the vulnerability indicators of 15 banks in China, the indicators of return on average total assets, liquidity ratio, capital adequacy ratio, and non-performing loan ratio are studied. The study observed that banks with lower vulnerability scored better on the liquidity ratio and non-performing loan ratio indicators. Second, through the organization of the indicators of China\u2019s financial system from 2007 to 2022 data, the total score of China\u2019s financial system vulnerability was calculated based on the vulnerability scores of each subsystem. It was found that a good economic environment is the main guarantee for the smooth operation of the financial system. The rest of this paper is structured as follows. Section \u201cMethodology and evaluation index\u201d describes the methodology and proposed evaluation index. Section \u201cExperiments and data\u201d presents the data and experiments using the evaluation index. Section \u201cResults and discussion\u201d gives the results and makes an analysis. Section \u201cConclusion, suggestions, and limitations\u201d summarizes the main findings of this study and provides policy suggestions. Methodology and evaluation index Factor analysis Factor analysis was first developed by Charles Spearman, a British psychologist, who put forward in 1904 that the basic idea of factor analysis is to group the original variables. These variables must be grouped according to the correlation size so that the correlation between variables in the same group is higher, while the correlation between variables in different groups is lower. Each group of variables represents a basic structure, and an unobservable comprehensive variable called a common factor. For a specific problem studied, the original variable can be divided into two parts; a few unmeasurable linear functions or common factors, and special factors unrelated to public factors (Qin and Lin, 2021; Kim et al., 2020a, 2020b). Suppose there are n samples, each sample observes p indicators, and there is a strong correlation between the p indicators. To facilitate research, the sample observation data is standardized, the standardized variable Xi (i\u2009=\u20091, 2, \u2026, p) is used as the evaluation index, and Fj (j\u2009=\u20091, 2, \u2026, m) is used as the common factor. \u03b5k (k\u2009=\u20091, 2, \u2026, p) represents a special factor, and the specific model of the factor analysis is as follows: $$\\left\\{\\begin{array}{c}{X}_{1}={a}_{11}{F}_{1}+{a}_{12}{F}_{2}+\\ldots +{a}_{1m}{F}_{m}+{\\varepsilon }_{1}\\\\ {X}_{2}={a}_{21}{F}_{1}+{a}_{22}{F}_{2}+\\ldots +{a}_{2m}{F}_{m}+{\\varepsilon }_{2}\\\\ \\ldots \\ldots \\\\ {X}_{p}={a}_{p1}{F}_{1}+{a}_{p2}{F}_{2}+\\ldots +{a}_{{pm}}{F}_{m}+{\\varepsilon }_{p}\\end{array}\\right.$$ (1) Where the common factor Fj (j\u2009=\u20091, 2, \u2026, m) is mutually independent and unmeasurable. It is a factor that appears in the expression of the original variable. The special factors and the common factors are also independent of each other. aij is the factor loading. The greater its absolute value, the greater the degree of dependence between Xi and Fj. Fragility indicators of the banking system The key to accurately and comprehensively evaluating the fragility of the banking system lies in selecting evaluation indicators. A study by Gobert et al. (2002) on the issue of financial fragility looked at the indicator of the liquidity ratio of the banking system. In addition, they also argued that liquidity constraint was an important factor that triggered the crisis of financial institutions and led to financial fragility. Karadima and Louri (2020) pointed out that a high non-performing loan rate has aggravated the fragility of banks and has a strong negative impact on economic development. The capital adequacy ratio has become an important indicator of banks\u2019 risk management and avoidance capabilities. Many countries are facing the threat of financial fragility to varying degrees while opening their financial markets. Therefore, from the perspective of safe operation, whether capital is sufficient has become a core issue of increasing concern to the banking industry. As Asteriou and Spanos (2018) mentioned, higher capital adequacy performance maintains the stability of the financial system. While banks are improving security and liquidity, profitability cannot be ignored. It can be represented by an indicator of return on average total assets. Therefore, this article adopts the average return on total assets, capital adequacy ratio, liquidity ratio, and non-performing loan ratio to measure the fragility of the banking system. Fragility indicators of the financial system Discussions on the fragility of the financial system have always received great attention from the theoretical community. Subdividing the financial system and monitoring financial risks from different subsystems is the core issue. Aikman et al. (2017) examine financial fragility from the stock, real estate, and bond market subsystems and highlight that there are many different views on the selection of specific evaluation indicators. Hamdaoui and Maktouf (2020) refer to the research of other scholars and use indicators such as international capital flow, inflation, real exchange rate, the ratio of money supply M2, and supervisory diffusion to measure financial fragility. Kaminsky (2006) mainly selected the main indicators, such as the proportion of fiscal deficit to GDP, the actual excess of M1, the proportion of M2 and foreign exchange reserves, and the ratio of foreign debt to imports. Additionally, Kaminsky subdivided the two subsystems of the stock market and bank credit among the model, making the model more comprehensive. According to the theory of the above scholars, combined with the characteristics of China\u2019s financial system, this paper focuses on establishing the fragility evaluation model of the financial system from four subsystems: economic environment, financial market early warning, financial monitoring, and financial export-oriented. Among them, determining the boundary of some evaluation indexes and the weight setting of subsystems refers to the common international standards and foreign experts (Graciela L Kaminsky, 2006). Other indicators are based on historical data to get the average value and then determine the index range according to the degree of deviation from the average value. Table 1 provides specific information. Table 1 Fragility indicators and boundaries. Full size table Experiments and data Bank fragility analysis The fragility index system of the banking system in this study references Kaminsky (2006), Gobert et al. (2002), and Karadima and Louri (2020). This paper studies cross-sectional data from 15 Chinese banks in 2018 (see Table 2). It can be observed that the average return on total assets of China\u2019s major banks is mainly concentrated around 1%, and the Postal Savings Bank of China is less than 0.6%; the liquidity ratio of China\u2019s banks is not good, mostly concentrated in 50%~60%. The capital adequacy ratio meets the 8% or more stipulated in the Basel Agreement; the non-performing loan ratio is also concentrated at around 1%. To observe the fragility of the banking system more comprehensively, a factor analysis method is adopted to calculate the total score of each bank\u2019s fragility factor. Table 2 Bank statistics. Full size table Due to the homogeneity requirement of the sample data, and the frailty examination requiring that a smaller index score is better, the indicator conversions are taken for return on average total assets, liquidity ratio, and capital adequacy as follows: \\({y}_{i}=\\max ({x}_{i})-{x}_{i}\\). The factor rotation adopts the Varimax method, and the contribution of the three principal components extracted reaches 92.88%. The specific scores are listed in Table 3. It can be seen that the Bank of Ningbo has the smallest fragility score, mainly because its average return on total assets and capital adequacy ratio are better, and its non-performing loan ratio is lower. It is followed by the Bank of Communications, China Construction Bank, and the Industrial Bank. China Minsheng Bank has the highest fragility score due to its low capital adequacy ratio and high non-performing loan ratio. Table 3 Table of fragility factor scores for Chinese banks. Full size table Financial system fragility analysis The degree of fragility of the financial system can be calculated from the related indicators of the financial system\u2019s fragility. This article takes the method of adding up the indicators of each financial system subsystem and averaging to calculate the fragility score of each. Subsequently, the fragility scores of each subsystem are weighted and averaged. The specific method is as follows: $${F}_{i}=\\sum {F}_{ij}/{\\rm{j}}$$ (2) $$FFII=\\sum {f}_{i}{F}_{i}$$ (3) where i\u2009=\u2009A, B, C, D; Fij represents the numerical value of the j-th index of the i-th subsystem, fi represents the number of indicators of the subsystem, and Fi represents the weight of the comprehensive index of the indicators of the subsystem. Early warning and monitoring of the financial market are central to the evaluation model of financial fragility. This gives the provision that the important position that these two subsystems occupy, the weights of these two subsystems are set to 2, and the weights of the remaining two are set to 1. Based on data collected from the China Statistical Yearbook, China Financial Yearbook, China Macro Statistics Database, National Bureau of Statistics, and other statistical departments, the study calculated and sorted out the index values and comprehensive index intervals of each subsystem in China from 2007 to 2022 (see Table 4). Table 4 Index values and comprehensive index intervals of each subsystem. Full size table Results and discussion Based on experimental results, the degree of fragility for each studied bank is given in Fig. 1. It can be seen that the Bank of Ningbo has the smallest degree of fragility, and the F-value is in the innermost circle of the radar chart. Meanwhile, China Minsheng Bank\u2019s degree of fragility is the highest, and the F-value is on the outermost side of the radar chart. The degree of fragility of China\u2019s banking system increases in the clockwise direction. Fig. 1: Fragility levels of major banks in China. The vertices correspond to the individual texts and the names are written above the vertices. Figure shows the level of commercial bank fragility of 15 banks in China in 2018, labeled in blue. Full size image Regarding the degree of fragility of the financial system, this article also analyzes the overall trend chart (see Fig. 2). From 2007 to 2022, the trend of the degree of vulnerability of China\u2019s financial system shows fluctuations. The first round of fluctuations is mainly due to the subprime crisis that swept the world in 2007\u20132009; improper financial regulation led to the fragility of the financial system, the country\u2019s economic situation became grim, and the financial system was in turmoil. As such, the degree of the vulnerability index was in danger. According to the state of the financial system, the country took control by gradually leveling off its economy, stabilizing the degree of vulnerability from fluctuations. The second round of fluctuations was mainly due to the huge financial fluctuations in 2015, limiting the tension of economic growth. However, the return of policies to the rational zone, the shift of exports to a normalized level, and the rational release of financial risks also ensured the long-term stability of the economic development of the situation to a large extent. The third round of volatility was mainly due to the panic in the financial market caused by the COVID-19 pandemic in 2019. This caused the systemic financial risk to gradually decline as domestic COVID-19 was being controlled. Fig. 2: The general trend of financial fragility in China. From 2007 to 2022, the fragility of China\u2019s financial system shows a fluctuating trend, and the fragility of the financial system is categorized into four categories: dangerous, high, normal and safe. Full size image Figure 3 reflects the trend of the fragility of China\u2019s economic environment from 2007 to 2022. It can be seen that the fragility of China\u2019s economic environment is generally relatively low, mostly at a general level in the first few years and basically below the safety line in the next few years. Specifically, China\u2019s GDP, fixed asset investment, M2, and currency growth rates are in a downward trend year by year. Therefore, the fragility of China\u2019s economic environment has also been declining. Moreover, the fragility index of the economic environment shows that the current economic environment has been relatively healthy and relatively stable in recent years. Fig. 3: Trends in the fragility of the economic environment. The fragility of the economic environment has been categorized into four categories: dangerous, high, normal and safe. The basic trend of China\u2019s economic environmental fragility was mostly at the normal level before 2011 and below the safety line after 2011. Full size image The financial market is often an indicator of a country\u2019s financial security. The government judges the degree of financial fragility based on the signals transmitted by the financial market and then establishes a corresponding risk early warning mechanism. Figure 4 reflects the continuous fluctuation of the fragility of China\u2019s financial market early warning system from 2007 to 2022. It can be seen that China\u2019s financial market was at a dangerous level when the subprime mortgage crisis occurred in 2007. The financial market\u2019s early warning levels in 2009 and 2015 were also relatively high. The overall financial market was in a state of volatility. 2019 was affected by the COVID-19 pandemic, and the financial markets expected indicators to be at a dangerous level. Notwithstanding, China\u2019s average price-to-earnings ratio is at a safe level, and the fragility of the total stock market value/GDP and debt dependence is at a high level. This is also the main reason for the high level of warning in the financial market and the volatility of the securities index\u2019s gradually stabilized status. Fig. 4: Time series of the financial market early warning Fragility Composite Index. The figure shows the fluctuation status of the trend of early warning fragility of China\u2019s financial market from 2007 to 2022, and the early warning fragility of the financial market is categorized into four categories, namely, dangerous, high, normal and safe. Full size image Compared with the fragility of the financial monitoring system, the financial market\u2019s fragility is relatively satisfactory. As shown in Fig. 5, China\u2019s financial monitoring fragility has been at a relatively low level from 2007 to 2022, basically within the range of security levels. The good trend of financial monitoring vulnerabilities also shows that the current financial regulatory authorities have improved the level of financial system monitoring. Active and stable fiscal and monetary policies play an important role in reducing the vulnerabilities of the financial monitoring system. With the changes in the fragility of the financial monitoring system, the government\u2019s financial monitoring has also been adjusted accordingly. Implementing a prudent fiscal and monetary policy is consistent with the trend of the fragility of the financial monitoring system. Fig. 5: Trends in financial surveillance fragility. Financial surveillance fragility is categorized as dangerous, high, normal, and safe. China\u2019s financial surveillance fragility has been at a low level from 2007 to 2012, basically in the safe range. Full size image As shown in Fig. 6, regarding financial outward-looking fragility, a downward trend from 2007 to 2022 can be observed, though it remains within the normal range. This suggests that China can handle the impact of opening the market on the financial system, which corresponds to China\u2019s adherence to an independent policy in the process of opening to the outside world. The specific manifestation is the year-on-year decline in foreign trade dependence, debt, and debt service ratios. It has risen in recent years, but they are all at a safe level, while the time to support imports is at a dangerous level due to China\u2019s excessive foreign exchange reserves. Fig. 6: Trends in extroverted financial vulnerabilities. The trend of China\u2019s financial outward fragility shows a decreasing trend from 2007 to 2022, and is basically at an normal level. The financial outward fragility is categorized into four categories: dangerous, high, normal and safe. Full size image Conclusion, suggestions, and limitations Conclusion and suggestions The analysis of financial fragility in this article takes the banking system and the financial system as an entry point. On the one hand, it mainly analyzes the cross-sectional data of 15 bank fragility indicators in China in 2018 and conducts bank fragility in the banking system. The scoring arrangement of vulnerability in the banking system makes each indicator comparable and persuasive. The results of the analysis show that the liquidity ratio and non-performing loan ratio are the key factors that affect the fragility scores of internal members of the banking system. Banks with lower vulnerabilities score better on the liquidity ratio and non-performing loan ratio indicators. On the other hand, the analysis of the fragility of the financial system focuses on establishing evaluation models from four subsystems: economic environment, financial market early warning, financial monitoring, and financial export-oriented. By sorting out the data of various indicators of China\u2019s financial system from 2007 to 2022, the comprehensive fragility index of the subsystem was calculated, and the corresponding fragility score was determined according to the comprehensive index interval. Finally, the fragility score of each subsystem was calculated. China\u2019s financial system fragility scored FFII with an analyzed overall trend. It can be seen that a good economic environment is the main guarantee for the stable operation of the financial system. The continuous improvement of the financial market\u2019s early warning system reduces financial risks, and the financial regulatory authorities\u2019 regulation of appropriate control of strength and appropriate fiscal currency has improved the security of the financial system. Meanwhile, the rapid development of an export-oriented economy has increased the degree of financial fragility to a certain extent. As such, the financial fragility model established from the four systems (economic environment, financial market early warning, financial monitoring, and financial export-oriented) has certain practical significance for comprehensively grasping the problem of financial fragility in China. Based on these insightful findings, the following suggestions are proposed to the government and banks. On policy suggestions for government agencies, the study proposes that first, market information should be thoroughly investigated to predict as much as possible the benefits and risks that changing existing policies or issuing new policies will bring to different industries. Consequently, reasonable economic policies should be formulated and released. Secondly, government agencies must make reasonable use of economic means and functions. Also, before issuing various policies, they must consider their stability and consistency in advance to avoid the deepening of information asymmetry caused by frequent policy changes. At the same time, after the policy is issued, regulatory authorities at all levels should strengthen their supervision of the banking industry and the economic and financial markets. They must also ensure that policies are transparently and effectively implemented to prevent situations of hasty or excessive implementation. Thirdly, after the formulation and issue of economic policies, multimedia platforms should be used to promote and guide the new policies, and precise interpretation should be carried out. Again, communication and exchange with market entities such as residents and enterprises should be emphasized to strengthen the ability of each market entity to grasp the policy direction, understand the policy objectives, and avoid making wrong investment and financing decisions due to information asymmetry. On policy suggestions to the various banks, it is suggested that when developing non-interest income businesses, banks should carefully identify various risks that may arise and carry out non-interest income business in an orderly and reasonable manner within the national regulatory red line for non-interest income businesses based on their business situation. This will minimize the increase in their vulnerability level due to the development of non-interest income businesses and thus achieve the stable development of the bank. Limitations This paper is based on analyzing the financial vulnerability of the banking and financial systems, which is of great significance to the study of China\u2019s financial vulnerability and the prevention of major risks. However, this paper still has some limitations. First, the construction of the stability framework of China\u2019s banking system in the paper is not deep enough, so the proposed stability framework still has some defects. Second, due to data unavailability, there may also be defects in the construction of the indicator system. Third, since this paper focuses on financial vulnerability, the banking data of 2018 before the pandemic was chosen as a representative. In that regard, future research may consider the following aspects. Financial stability is not only a matter for the central government to consider, but local governments should prevent regional financial risks to ensure that the economy is running well, and the society is functioning well. Also, the study of financial market stability is an extremely important topic because the study of financial markets is of great significance to financial vulnerability. Data availability Data can be obtained on request. References Asteriou D, Spanos K (2018) The relationship between financial development and economic growth during the recent crisis: evidence from the EU. Financ Res Lett 28. https://doi.org/10.1016/j.frl.2018.05.011 Aikman D, Kiley M, Lee SJ, Palumbo MG, Warusawitharana M (2017) Mapping heat in the U.S. financial system. J Bank Financ 81:36\u201364. https://doi.org/10.1016/j.jbankfin.2017.04.013 Article   Google Scholar   Djebali N, Zaghdoudi K (2020) Threshold effects of liquidity risk and credit risk on bank stability in the MENA region. J Policy Modeling 42:1049\u20131063. https://doi.org/10.1016/j.jpolmod.2020.01.013 Article   Google Scholar   Danilo LBW (2020) Liquidity policies and financial fragility. Int Rev Econ Financ 70:135\u2013153. https://doi.org/10.1016/j.iref.2020.06.008 Article   Google Scholar   Fabio CB, Claudio M (2014) Determinants of US financial fragility conditions. Res Int Bus Financ 30:377\u2013392. https://doi.org/10.1016/j.ribaf.2012.08.003 Article   Google Scholar   Georgiadis G, Zhu F (2021) Foreign-currency exposures and the financial channel of exchange rates: Eroding monetary policy autonomy in small open economies. J Int Money Financ 110:102265. https://doi.org/10.1016/j.jimonfin.2020.102265 Article   Google Scholar   Gobert K, Gonz\u00e1lez P, Poitevin M (2002) Bank value and financial fragility. Cahiers de recherche. 0202, GREEN Haan JD, Fang Y, Jing Z (2020) Does the risk on banks\u2019 balance sheets predict banking crises? New evidence for developing countries. Int Rev Econ Financ 68:254\u2013268. https://doi.org/10.1016/j.iref.2020.03.013 Article   Google Scholar   Hajar R, Habib A (2020) Risk governance and financial stability: a comparative study of conventional and Islamic banks in the GCC. Glob Financ J https://doi.org/10.1016/j.gfj.2020.100599 Halili A, Fenech JP, Contessi S (2021) Credit derivatives and bank systemic risk: risk enhancing or reducing. Financ Res Lett 42:101930. https://doi.org/10.1016/j.frl.2021.101930 Article   Google Scholar   Hamdaoui M, Maktouf S (2020) Financial reforms and banking system fragility: The role of regulatory frameworks. Struct Change Econ Dyn 52:184\u2013205. https://doi.org/10.1016/j.strueco.2019.10.007 Article   Google Scholar   Kaminsky GL (2006) Currency crises: are they all the same. J Int Money Financ 25(3):503\u2013527. https://doi.org/10.1016/j.jimonfin.2006.01.002 Article   Google Scholar   Kim YS, Choi MK, Han SM, Lee C, Seong PH (2020a) Development of a method for quantifying relative importance of NPP cyber attack probability variables based on factor analysis and AHP. Ann Nucl Energy 149:107790. https://doi.org/10.1016/j.anucene.2020.107790 Article   CAS   Google Scholar   Karadima M, Louri H (2020) Non-performing loans in the euro area: does bank market power matter. Int Rev Financ Anal 72:101593. https://doi.org/10.1016/j.irfa.2020.101593 Article   Google Scholar   Karadima M, Louri H (2020) Economic policy uncertainty and non-performing loans: The moderating role of bank concentration. Financ Res Lett https://doi.org/10.1016/j.frl.2020.101458 Kanga D, Murinde V, Soumar\u00e9 I (2020) Capital, risk and profitability of WAEMU banks: does bank ownership matter. J Bank Financ 114:105814. https://doi.org/10.1016/j.jbankfin.2020.105814 Article   Google Scholar   Kim H, Batten J, Ryu D (2020b) Financial crisis, bank diversification, and financial stability: OECD countries. Int Rev Econ Financ 65:94\u2013104. https://doi.org/10.1016/j.iref.2019.08.009 Article   Google Scholar   Laura BP, Antonio TP, Clara CR (2015) Factors influencing bank risk in Europe: evidence from the financial crisis. North Am J Econ Financ 34:138\u2013166. https://doi.org/10.1016/j.najef.2015.08.004 Article   Google Scholar   Mitkov Y (2019) Inequality and financial fragility. J Monet Econ https://doi.org/10.1016/j.jmoneco.2019.08.004 Qin W, Lin Q (2021) Construction of cultural industry development factor model based on factor analysis, artificial intelligence and big data. Microprocess Microsyst 82:103880. https://doi.org/10.1016/j.micpro.2021.103880 Article   Google Scholar   Serrano AS (2021) The impact of non-performing loans on bank lending in Europe: an empirical analysis. North Am J Econ Financ 55:101312. https://doi.org/10.1016/j.najef.2020.101312 Smaoui H, Mimouni K, Miniaou H, Temimi A (2020) Funding liquidity risk and banks\u2019 risk-taking: Evidence from Islamic and conventional banks. Pac-Basin Financ J 64:101436. https://doi.org/10.1016/j.pacfin.2020.101436 Article   Google Scholar   Sushanta KM, Ricardo MS (2013) The real effects of financial stress in the Eurozone. Int Rev Financ Anal 30:1\u201317. https://doi.org/10.1016/j.irfa.2013.05.003 Article   Google Scholar   Yu JH, Lu Y, Wang ZB (2015) Application of the credit metrics in the credit risk management of commercial banks. Academics 5:297\u2013301. https://doi.org/10.3969/j.issn.1002-1698.2015.05.032 Article   Google Scholar   Download references Author information Authors and Affiliations School of Business, Jiangsu Second Normal University, Nanjing, 211200, China Li Shang School of Foreign Languages, Nanjing University of Finance and Economics, Nanjing, 210023, China Biao Zhou School of Management Science and Engineering, Nanjing University of Information Science & Technology, Nanjing, 210044, China Jiannan Li, Decai Tang, Valentina Boamah & Zhiwei Pan School of Law and Business, Sanjiang University, Nanjing, 210012, China Decai Tang Contributions Conceptualization, D.T. and L.S.; methodology, J.L.; software, D.T.; validation, D.T. formal analysis, D.T., L.S., Z.P., and B.Z.; investigation, J.L. and Z.P.; resources, L.S. and D.T.; data curation, J.L., V.B., and D.T.; writing\u2014original draft preparation, L.S., Z.P., and D.T.; writing\u2014review and editing, D.T., B.Z., J.L., Z.P., and V.B.; visualization, D.T., V.B.; supervision, D.T. and B.Z.; project administration, L.S. and D.T. All authors have read and agreed to the published version of the manuscript. Corresponding author Correspondence to Biao Zhou. Ethics declarations Competing interests The authors declare no competing interests. Ethical approval Ethical approval was not required as the study did not involve human participants. Informed consent This article does not contain any studies with human participants performed by any of the authors. Additional information Publisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Supplementary information Dataset 1 Rights and permissions Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. Reprints and permissions About this article Cite this article Shang, L., Zhou, B., Li, J. et al. Evaluating financial fragility: a case study of Chinese banking and finance systems. Humanit Soc Sci Commun 11, 425 (2024). https://doi.org/10.1057/s41599-024-02932-7 Download citation Received 20 February 2023 Accepted 22 February 2024 Published 16 March 2024 DOI https://doi.org/10.1057/s41599-024-02932-7 Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Subjects Economics Finance Download PDF Sections Figures References Abstract Introduction Methodology and evaluation index Experiments and data Results and discussion Conclusion, suggestions, and limitations Data availability References Author information Ethics declarations Additional information Supplementary information Rights and permissions About this article Advertisement Humanities and Social Sciences Communications (Humanit Soc Sci Commun) ISSN 2662-9992 (online) About Nature Portfolio About us Press releases Press office Contact us Discover content Journals A-Z Articles by subject Protocol Exchange Nature Index Publishing policies Nature portfolio policies Open access Author & Researcher services Reprints & permissions Research data Language editing Scientific editing Nature Masterclasses Research Solutions Libraries & institutions Librarian service & tools Librarian portal Open research Recommend to library Advertising & partnerships Advertising Partnerships & Services Media kits Branded content Professional development Nature Careers Nature Conferences Regional websites Nature Africa Nature China Nature India Nature Italy Nature Japan Nature Korea Nature Middle East Privacy Policy Use of cookies Your privacy choices/Manage cookies Legal notice Accessibility statement Terms & Conditions Your US state privacy rights \u00a9 2024 Springer Nature Limited",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "Role of artificial intelligence in digital pathology for gynecological cancers",
    "doi": "10.1016/j.csbj.2024.03.007",
    "description": "The diagnosis of cancer is typically based on histopathological sections or biopsies on glass slides. Artificial intelligence (AI) approaches have greatly enhanced our ability to extract quantitative information from digital histopathology images as a rapid growth in oncology data. Gynecological cancers are major diseases affecting women's health worldwide. They are characterized by high mortality and poor prognosis, underscoring the critical importance of early detection, treatment, and identification of prognostic factors. This review highlights the various clinical applications of AI in gynecological cancers using digitized histopathology slides. Particularly, deep learning models have shown promise in accurately diagnosing, classifying histopathological subtypes, and predicting treatment response and prognosis. Furthermore, the integration with transcriptomics, proteomics, and other multi-omics techniques can provide valuable insights into the molecular features of diseases. Despite the considerable potential of AI, substantial challenges remain. Further improvements in data acquisition and model optimization are required, and the exploration of broader clinical applications, such as the biomarker discovery, need to be explored.",
    "journal": "Computational and Structural Biotechnology Journal",
    "authors": [
      "Wang Y.L.",
      "Gao S.",
      "Xiao Q.",
      "Li C.",
      "Grzegorzek M.",
      "Zhang Y.Y.",
      "Li X.H.",
      "Kang Y.",
      "Liu F.H.",
      "Huang D.H.",
      "Gong T.T.",
      "Wu Q.J."
    ],
    "citation_count": "0",
    "full_text": "Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Highlights Abstract Graphical Abstract Keywords 1. Introduction 2. Digital pathology 3. AI in digital pathology 4. AI in digital pathology for GCs 5. Limitations and challenges 6. Future directions 7. Conclusions CRediT authorship contribution statement Declaration of Competing Interest Acknowledgements References Show full outline Figures (3) Tables (3) Table 1 Table 2 Table 3 Computational and Structural Biotechnology Journal Volume 24, December 2024, Pages 205-212 Review Article Role of artificial intelligence in digital pathology for gynecological cancers Author links open overlay panel Ya-Li Wang a b, Song Gao c, Qian Xiao a c, Chen Li d, Marcin Grzegorzek e, Ying-Ying Zhang a f g, Xiao-Han Li h, Ye Kang h, Fang-Hua Liu a f g, Dong-Hui Huang a f g, Ting-Ting Gong c, Qi-Jun Wu a c f g i Show more Share Cite https://doi.org/10.1016/j.csbj.2024.03.007 Get rights and content Under a Creative Commons license open access Highlights \u2022 We discusses applications of artificial intelligence for gynecological cancers from digitized histopathology slides. \u2022 The performance of artificial intelligence methods, especially deep learning, performed well in most datasets. \u2022 Novel robust artificial intelligence methods are needed to improve clinical applications. Abstract The diagnosis of cancer is typically based on histopathological sections or biopsies on glass slides. Artificial intelligence (AI) approaches have greatly enhanced our ability to extract quantitative information from digital histopathology images as a rapid growth in oncology data. Gynecological cancers are major diseases affecting women's health worldwide. They are characterized by high mortality and poor prognosis, underscoring the critical importance of early detection, treatment, and identification of prognostic factors. This review highlights the various clinical applications of AI in gynecological cancers using digitized histopathology slides. Particularly, deep learning models have shown promise in accurately diagnosing, classifying histopathological subtypes, and predicting treatment response and prognosis. Furthermore, the integration with transcriptomics, proteomics, and other multi-omics techniques can provide valuable insights into the molecular features of diseases. Despite the considerable potential of AI, substantial challenges remain. Further improvements in data acquisition and model optimization are required, and the exploration of broader clinical applications, such as the biomarker discovery, need to be explored. Graphical Abstract Download : Download high-res image (100KB) Download : Download full-size image Previous article in issue Next article in issue Keywords Artificial intelligenceDigital pathologyDeep learningGynecological cancersMachine learning 1. Introduction Gynecological cancers (GCs), primarily comprising ovarian cancer (OC), endometrial cancer (EC, also known as uterine cancer), and cervical cancer (CC), present a significant global public health concern with profound implications for women's health and quality of life, leading to substantial disease burden. The high mortality rate and poor prognosis associated with these cancers have imposed significant pressure for effective prevention and management strategies [1]. According to the 2020 global cancer statistics, the new cases of OC, CC and EC were 313,959, 604,127, and 417,367, the new deaths were 207,252, 341,831, and 97,370, respectively [2]. The high mortality rate of OC is related to late-stage diagnoses and a high rate of recurrence [3], [4], [5], with 5-year survival rates < 50% in most countries [6]. Premenopausal women account for 14% of EC cases, and 5% of them were younger than 40 years [7]. The standard treatment modalities for GCs entail surgical cytoreduction and systemic chemotherapy; nevertheless, a large proportion of patients experiences disease recurrence after completing chemotherapy [5]. Despite advancements in medical imaging techniques enhancing cancer detection rates, histopathological evaluation remains the gold standard for accurate cancer diagnosis and subsequent management. However, the escalating global incidence of GCs poses a growing challenge due to the expanding volume of pathological data and the shortage of pathologists [8]. Driven by high-dimensionality datasets, advances in computing hardware, and the utilization of deep learning (DL) models, the oncology is increasingly benefiting from artificial intelligence (AI) [9], [10]. Various clinical applications of AI in oncology range from cancer detection [11] and classification [12], to predicting patient responses to therapy [13], lymph node metastasis [14], [15], and prognosis [16], [17]. The cancer types cover breast cancer [11], [18], colorectal cancer [12], [16], gastric cancer [17], lung cancer [19], [20], prostate cancer [21], and lymphoma [22]. As the volume of healthcare data in cancer management continues to grow, the integration of AI holds promises for comprehensive utilization throughout the entire spectrum of cancer prevention and treatment, ultimately guiding clinical decision-making processes [10]. This review will describe the basic concepts and principles of digital pathology and AI in histopathology images analysis. Then, we will present the clinical applications achieved by AI in the digital pathology of GCs. Finally, the challenges of applying AI to the clinic will also be discussed. 2. Digital pathology Histopathology is the examination and analysis of glass slides under a microscope, and it serves as the cornerstone of cancer diagnosis. Manual annotation of histological slides by pathologists is time-consuming, subjective, and susceptible to intra- and inter-observer variability [23], [24]. The demand for diagnostic accuracy in cancer histopathology is increasing because accurate biomarker evaluation is required for personalized cancer therapy [25]. Digital pathology, originating in the 1960 s, is the process of digitizing histopathology slides into whole-slide images (WSIs) that can be reviewed by pathologists on computer monitor [26], [27]. Digital slides are easier to preserve, share and annotate, and facilitate remote diagnosis or educational purposes [23]. The automation and efficiency afforded by digital pathology can enhance productivity and cost-efficiency [26], with its performance having demonstrated superiority over conventional microscopy [28], [29]. Recently, the Food and Drug Administration (FDA) has approved the use of digital pathology for primary diagnosis [30]. Nevertheless, the abundance and intricate information among different cell types, along with the spatial context provided by digital pathology, has underscored the necessity for precise analysis of large datasets [31], [32], [33]. Thus, implementing robust and reproducible AI-based methods might potentially resolve the challenges faced by oncologists and pathologists. 3. AI in digital pathology AI, which originated in the 1950 s, refers to a broad field of computer science that involves utilizes machine-based techniques to model the human decision-making process and generate predictions [34]. Machine learning (ML) refers to computer programs that process data for intelligent analysis, serving as a fundamental research method in the field of AI [35]. The main steps of ML involve annotation, feature extraction, and model prediction, empowering machines to automatically train and optimize models through statistical methods [25]. Supervised, unsupervised, and reinforcement learning represent the key learning types in ML, addressing tasks such as classification, regression, clustering and dimensionality reduction [23]. Weakly supervised learning represents an intermediate learning paradigm that lies between supervised and unsupervised learning. Common ML algorithms encompass linear or logistic regression, decision tree-based methods, and support vector machine (SVM) [23]. DL is a subset of ML which based on neural network structures, comprising interconnected input, hidden, and output layers that automatically extracts data features, overcomes the limitations and challenges of handcrafted features in ML [35]. Convolutional neural networks (CNNs) have gained widespread deployment in pathology image analysis since 2012 when AlexNet secured the first place in the ImageNet Large Scale Visual Recognition Challenge [35]. Subsequently, other deep CNN models have been developed and applied in medical domains. Fig. 1 provides a succinct summary of important historical events in AI and digital pathology. Download : Download high-res image (151KB) Download : Download full-size image Fig. 1. A timeline of important historical events in artificial intelligence and digital pathology. FDA: Food and Drug Administration. 4. AI in digital pathology for GCs The application of AI in GCs predominantly commenced after 2017, with the classification of histopathological subtype accounting for the largest proportion (Table 1). DL methods are the most commonly used AI algorithms (Fig. 2), with CNNs being the most extensively employed model (Table 2). The model's performance, as assessed by the area under the curve (AUC), ranges from 0.71 to 0.99 across all tumor types (Table 3). Table 1. Basic features for the included studies. Author [ref], year Cancer type WSI type Objectives Sample size Participants BenTaieb et al.[36], 2017 Ovarian cancer H&E Subtype classification 133 Ovarian carcinoma patients with different subtypes (HGSC, EN, MC, LGSC, CC) Jiang et al.[37], 2021 Ovarian cancer H&E Subtype classification 30 SBOT and HGSOC patients were retrieved from the institutional pathology system database Wu et al.[38], 2018 Ovarian cancer H&E Subtype classification 85 Ovarian cancer patients with different subtypes (serous carcinoma, MC, endometrioid, and CC) were obtained from the First Affiliated Hospital of Xinjiang Medical University Farahani et al.[39], 2022 Ovarian cancer H&E IHC Subtype classification 485 Patients from the OVCARE archives and the University of Calgary Hong et al.[40], 2021 Endometrial cancer H&E Subtype classification 456 Train, validate, and test data from the TCGA and the Clinical Proteomic Tumor Analysis Consortium (CPTAC). Independent dataset from New York University (NYU) hospitals Song et al.[41], 2022 Endometrial cancer and Cervical cancer H&E Subtype classification 230 (70 for CC, 160 for EC) Data from The Cancer Genome Atlas (TCGA) program and The National Cancer Institute\u2019s Clinical Proteomic Tumor Analysis Consortium (CPTAC) endometrial cancer dataset Li et al.[42], 2023 Cervical cancer H&E Subtype classification 229 Cervical specimens from January 2018 and December 2020 were acquired from the Department of Pathology, Xinhua hospital Chongming branch affiliated with Shanghai Jiaotong University Habtemariam et al.[43], 2022 Cervical cancer H&E Subtype classification 915 WSIs Four cervical cancer classes (normal, precancer, adenocarcinoma, and squamous cell carcinoma) were gathered from Jimma University Medical Center (JUMC) and St. Paul Hospital Shin et al.[44], 2021 Ovarian cancer H&E Diagnosis (tumor vs non-tumor) 142 Ovarian serous cystadenocarcinoma (HGSC) data from the Cancer Image Archive and the Ajou University Medical Center Sengupta et al.[45], 2022 Ovarian cancer IHC Diagnosis (tumor vs non-tumor) NR Ovarian cancer patients were obtained during frontline surgery at Tata Medical Center (TMC), Kolkata Mohammadi et al.[46], 2022 Endometrial cancer H&E Diagnosis (benign vs malignant) 2910 The tissue blocks originate from Glasgow Royal Infirmary (NG), Southern General Hospital (SG), Royal Alexandria Hospital (RAH), and Queen Elizabeth University Hospital (QEUH) (all in Glasgow, Scotland) Zhang et al.[47], 2022 Endometrial cancer H&E Diagnosis (tumor vs non-tumor) 1190 WSIs Endometrial specimens collected from PUPH, including all main pathological subtypes of the endometrium and the Chinese PLA General Hospital (PLAGH) Sun et al.[48], 2020 Endometrial cancer H&E Diagnosis (benign vs malignant) 498 Patients from the Third Affiliated Hospital of Zhengzhou University from October 2017 to August 2018 H.J. Fick et al.[49], 2021 Cervical cancer H&E Diagnosis (benign vs malignant) 1015 WSIs NR Du et al.[50], 2018 Ovarian cancer H&E Prognosis 154 WSIs Breast cancer and ovarian cancer tissue, the former came from the Stanford Tissue Microarray Database (TMAD) and the latter came from the OUHSC Laury et al.[51], 2021 Ovarian cancer H&E Prognosis 30 Stage III-IV high-grade extrauterine serous carcinoma who underwent primary cytoreductive surgery, and at least 6 cycles of adjuvant platinum-based chemotherapy from HUS Helsinki University Hospital between 1982 and 2013 Zeng et al.[52], 2021 Ovarian cancer H&E Prognosis 229 HGSOC patients from The Cancer Genome Atlas (TCGA) Nero et al.[53], 2022 Ovarian cancer H&E Prognosis 664 EOC patients from the Fondazione Policlinico Universitario \u201cAgostino Gemelli\u201d IRCCS of Rome, Italy, from November 2016 to November 2020 Fremond et al.[54], 2022 Endometrial cancer H&E Prognosis 2028 Endometrial cancer patients from three randomised trials and four clinical cohorts: the randomised PORTEC-1 trial (recruited in the Netherlands); the randomised PORTEC-2 trial (the Netherlands); the randomised PORTEC-3 trial (the Netherlands, UK, France, Italy, Canada, Australia, and New Zealand); the retrospective TransPORTEC pilot Study (the Netherlands, UK, and France); the prospective Medisch Spectrum Twente (MST) cohort (the Netherlands); patients with POLEmut endometrial cancer from the Leiden Endometrial Cancer Repository (the Netherlands); and TCGA-Uterine Corpus Endometrial Carcinoma cohort (TCGA-UCEC), extracted from the cBioPortal for Cancer Genomics Chen et al.[55], 2023 Cervical cancer H&E Prognosis 251 Patients with the International Federation of Gynecology and Obstetrics (FIGO) Stage IA1\u2013IIA2 cervical cancer were collected from Nanfang Hospital of Southern Medical University (Guangzhou,China) from January 2009 to December 2016 and other hospitals Wang et al.[56], 2022 Ovarian cancer H&E Therapeutic response 288 WSIs HGSOC patients are collected from the tissue bank of the TriService General Hospital and the National Defense Medical Center, Taipei, Taiwan Heindl et al.[57], 2018 Ovarian cancer H&E IHC Cancer microenvironment 514 Patients with International Federation of Gynecology and Obstetrics (FIGO) stage II-IV HGSOC from TCGA Desbois et al.[58], 2020 Ovarian cancer IHC Cancer microenvironment 370 Epithelial ovarian cancer from mixed histology were collected from the Phase III ICON7 clinical trial. Independent validation collection was procured from Cureline, Inc (Brisbane, CA, USA) Abbreviation: CC: clear cell carcinoma, EN: endometrioid carcinoma, EOC: epithelial ovarian cancer, H&E: hematoxylin and eosin, HGSC: high grade serous carcinoma, HGSOC: high grade serous ovarian cancer, IHC: immunohistochemistry, LGSC: low grade serous carcinoma, MC: mucinous carcinoma, NR: not reported, PUPH: Peking University People\u2019s Hospital, PLAGH: Chinese PLA General Hospital, SBOT: serous borderline ovarian tumor, WSIs: whole slide images. Download : Download high-res image (130KB) Download : Download full-size image Fig. 2. The clinical applications of AI in digital pathology of gynecological cancer. Table 2. Model, algorithm, and model validation for the included studies. Author [ref], year Model Algorithm CV External validation AI vs clinicians BenTaieb et al.[36], 2017 ML SVM leave-one-out No Yes Jiang et al.[37], 2021 ML SVM NR No No Wu et al.[38], 2018 DL CNN (AlexNet) 10-fold No No Farahani et al.[39], 2022 DL CNN 3-fold Yes No Hong et al.[40], 2021 DL CNN (InceptionResnet) NR Yes No Song et al.[41], 2022 DL CNN (Inception-v3) 5-fold Yes No Li et al.[42], 2023 DL CNN (AlexNet, VGG-19, Xception, ResNet-50) 5-fold Yes Yes Habtemariam et al.[43], 2022 DL EffecientNetB0 10-fold Yes No Shin et al.[44], 2021 DL CNN (Inception V3) NR Yes No Sengupta et al.[45], 2022 DL CNN (Inception V3) 5-fold No No Mohammadi et al.[46], 2022 DL CLAM NR Yes No Zhang et al.[47], 2022 DL DeepLab v3, ResNet-50 NR Yes No Sun et al.[48], 2020 DL CNN (VGG-16) 10-fold Yes Yes H.J. Fick et al.[49], 2021 DL SVM, CNN (DenseNet) 10-fold No No Du et al.[50], 2018 DL CNN (AlexNet, Places365-AlexNet, GoogLeNet) NR Yes No Laury et al.[51], 2021 DL CNN NR No No Zeng et al.[52], 2021 ML RF, GBDT, AdaBoost, LR, DT, SVM, NB, KNN 5-fold Yes No Nero et al.[53], 2022 DL CLAM NR No No Fremond et al.[54], 2022 DL HoVer-Net, SVM 4-fold Yes No Chen et al.[55], 2023 DL CNN (ResNet-50) NR Yes No Wang et al.[56], 2022 DL Inception V3 5-fold Yes No Heindl et al.[57], 2018 ML SVM NR Yes No Desbois et al.[58], 2020 ML RF, k-means clustering NR Yes No Abbreviation: AI: artificial intelligence, AdaBoost: adaptive boosting, CV: cross-validation, CNN: convolutional neural network, CLAM: clustering-constrained attention multiple instance learning, DT: decision tree, DL: deep learning, GBDT: gradient boosting decision tree, KNN: K-nearest neighbor, SVM: support vector machine, LR: logistic regression, ML: machine learning, NB: naive Bayesian, NR: not reported, RF: random forest. Table 3. The performance of the model for the included studies. Author [ref], year Performance Accuracy (%) AUC SE (%) SP (%) Precision Recall Kappa F1 score BenTaieb et al.[36], 2017 90.00 / / / / / 0.89 0.66 Jiang et al.[37], 2021 >\u200990.00 / / / / / / / Wu et al.[38], 2018 78.20 / / / / / / / Farahani et al.[39], 2022 / 0.95 / / / / 0.74 0.79 Hong et al.[40], 2021 / 0.97 (0.91-1.00) / / 1 0.60 / 0.75 Song et al.[41], 2022 89.90 0.94 (0.92-0.97) 84.60 93.90 / / / 0.88 Li et al.[42], 2023 92.50\u2009\u00b1\u20091.90 0.95\u2009\u00b1\u20090.01 / / 0.94\u2009\u00b1\u20090.02 0.95\u2009\u00b1\u20090.03 / / Habtemariam et al.[43], 2022 94.50 / / / 0.96 1 0.92 0.98 Shin et al.[44], 2021 80.80 0.92 (0.90-0.93) 95.80 65.80 0.74 0.96 / 0.83 Sengupta et al.[45], 2022 / 0.99 / / / / / / Mohammadi et al.[46], 2022 85.57 0.95 / / / / / / Zhang et al.[47], 2022 / 0.93 92.40 80.10 / / / / Sun et al.[48], 2020 93.53\u2009\u00b1\u20090.81 0.96\u2009\u00b1\u20090.01 81.04\u2009\u00b1\u20093.87 94.78\u2009\u00b1\u20090.87 / / / / H.J. Fick et al.[49], 2021 85.00 / / / / / / / Du et al.[50], 2018 90.20 / / / / / / / Laury et al.[51], 2021 82.00 / 73.00 91.00 / / / / Zeng et al.[52], 2021 / 0.83 / / / / / / Nero et al.[53], 2022 / 0.71 / / / / / / Fremond et al.[54], 2022 / 0.87 (0.86-0.89) / / / / / / Chen et al.[55], 2023 / 0.87 (0.77-0.96) / / / / / / Wang et al.[56], 2022 88.20\u2009\u00b1\u20096 / / / 0.92\u2009\u00b1\u20090.04 0.91\u2009\u00b1\u20090.03 / 0.92\u2009\u00b1\u20090.07 Heindl et al.[57], 2018 85.00 / / / / / / / Desbois et al.[58], 2020 91.00 / / / / / / / Abbreviation: AUC: area under the curve, SE: sensitivity, SP: specificity, /: The results were not reported. 4.1. Classification of histopathological subtype The treatment strategies and clinical prognosis for distinct histopathological types of GCs exhibit variability. ML and DL have been tested as methods for the classification of GCs subtypes. 4.1.1. Ovarian cancer In 2017, BenTaieb et al.[36] utilized weakly-supervised ML approaches based on SVM for the classification of OC subtypes. The model achieved an average multi-class classification accuracy of 90%, obtaining substantial agreement with clinicians (Kappa=0.89). In discerning between the two epithelial OC types, ML models achieved 91\u201395% accuracy [37]. Meanwhile, in the cell-level classification of both tumor and stroma cells, the models demonstrated accuracy exceeding 90%. Wu et al. [38] employed deep CNNs (DCNN) based on AlexNet for OC subtype classification, achieving an accuracy of 78.20% on augmented data. In Farahani\u2019s investigation, DCNNs achieved a diagnostic concordance of 81.38% in the training set and 80.97% in the external set for classifying OC subtypes [39]. 4.1.2. Endometrial cancer The DCNN model achieved a per-patient level AUC of 0.969 (0.905\u20131) for differentiating samples into endometrioid or serous histological subtypes. Additionally, this model offers insights into molecular subtypes and mutation status [40]. On the other hand, the Inception-v3 model attained an AUC value of 0.944 for classifying the EC subtype [41]. 4.1.3. Cervical cancer In 2023, Li et al. [42] employed AlexNet, VGG-19, Xception, and ResNet-50 with five-fold cross-validation to identify cervical malignancies and provide diagnostic interpretability. The AUC for internal validation varied from 0.73 to 0.98. Habtemariam et al. used the EffecientNetB0 pre-trained model for CC classification, and the results were validated using histogram-matched histopathological images. The model achieved a test accuracy of 94.5% for classifying CC [43]. 4.2. Cancer diagnosis The diagnostic task involved the differentiation between tumors and non-tumors, as well as between benign and malignant lesions. All diagnostic tasks were based on DL methods (Table 2). 4.2.1. Ovarian cancer In 2021, Shin et al. [44] utilized the Inception V3 model for the detection of malignancy on tissue slides. They examined a public set of tissue slide images comprising 142 patients diagnosed with ovarian serous cystadenocarcinoma from The Cancer Genome Atlas Ovarian. Notably, the researchers evaluated the classifier\u2019s performance stability using style transfer techniques on a limited institutional dataset. After the style transfer, the AUC and area under the precision recall curve improved from 0.737 (0.708\u20130.764) and 0.710 (0.672\u20130.748) to 0.916 (0.899\u20130.930) and 0.898 (0.872\u20130.922), respectively. The Inception V3 model was also used by Sengupta et al. [45] for OC diagnosis, with lamin-induced morphological changes of the nuclei as the input parameter. The model showed a higher performance in distinguishing between normal and OC tissues, achieving an AUC of 0.99 in both the training and validation sets. 4.2.2. Endometrial cancer Mohammadi et al. [46] employed the CLAM (attention multiple instance learning) model to differentiate between malignant and benign tumors, achieving a validation accuracy of 85% and a test accuracy exceeding 87%. The attention heatmapping, feature visualization, and end-to-end saliency-mapping improved the interpretability of the model. Zhang et al. [47] utilized DeepLab v3 and ResNet-50 for the diagnosis of EC and non-EC in multiple datasets, demonstrating good performance (AUC, sensitivity, and specificity all >0.8). Sun and collaborators [48] proposed the HIENet framework, based on VGG-16 and incorporates two crucial blocks that utilize the visual attention mechanism. HIENet exhibited an AUC of 0.96\u2009\u00b1\u20090.01, with a sensitivity of 81.04\u2009\u00b1\u20093.87% and specificity of 94.78\u2009\u00b1\u20090.87% in the detection of endometrioid adenocarcinoma. 4.2.3. Cervical cancer In 2021, models utilizing CNN and SVM algorithms achieved an 85% classification accuracy in 1015 annotated WSIs [49]. The CNN was employed to predict the probability of each of the four lesion classes at the patch level, and the SVM was utilized to predict the final slide-level lesion status. 4.3. Cancer prognosis The prognosis of cancer is affected by various complex factors, and AI-based methods hold the potential to enhance prognosis prediction in GCs. 4.3.1. Ovarian cancer Du et al. [50] explored diverse transfer learning strategies to effectively differentiate between epithelial and stromal regions in hematoxylin and eosin (H&E) stained histological images. Utilizing DCNNs (AlexNet, Places365-AlexNet, GoogLeNet, and two modified AlexNet models), they extracted natural-image features without fine-tuning, subsequently conducting end-to-end fine-tuning by training the classifiers at certain layers. An accuracy of 90.2 was achieved with the implementation of GoogLeNet. In study by Laury et al. [51], 205 WSIs from 30 patients with high-grade serous ovarian cancer exhibiting distinct treatment responses (platinum-free intervals of \u22646 months or \u226518 months) were analyzed for outcome prediction. CNN-based models effectively differentiated extreme patient responses to primary platinum-based chemotherapy, achieving a sensitivity of 73% and a specificity of 91%. Furthermore, besides prognostication, ML models combined with other data were utilized to infer molecular features. In Zeng\u2019s [52] study, the model\u2019s AUC for predicting 5-year overall survival (OS) was 0.825 and 0.703 in the test and validation sets, respectively. Notably, for the prediction of molecular features (BRCA mutation, microsatellite instability, and molecular subtypes), all AUC values were >\u20090.9. The CLAM method demonstrated an AUC of 0.71 for predicting progression-free survival in 664 epithelial OC patients, while the AUC for predicting BRCA mutation was 0.55 [53]. Despite the relatively modest predictive performance, it also suggests that the AI model has the potential to provide information on molecular features of the disease. 4.3.2. Endometrial cancer A comprehensive analysis integrating data from the PORTEC randomized trials and clinical cohorts was conducted to develop an interpretable DL pipeline aimed at predicting progression (5-year recurrence-free survival) [54]. This model could be clinically applied for pre-screening EC to identify occurrences of p53abn for further confirmatory immunohistochemistry or molecular testing. 4.3.3. Cervical cancer Chen et al. [55] developed a CNN-based pathological risk score (RS) to predict patient prognosis. The performance of the RS in predicting OS and disease-free survival (DFS) was validated through Kaplan\u2013Meier survival analysis in both the training and testing datasets. In the testing cohort, the RS exhibited an AUC of up to 0.80 for predicting both OS and DFS. 4.4. Cancer therapeutic response and microenvironment In addition to the tasks mentioned above, DL models based on H&E staining have also been used to predict the therapeutic efficacy (invalid vs. effective) of bevacizumab in OC. The method achieved an accuracy of 0.882\u2009\u00b1\u20090.06, a precision of 0.921\u2009\u00b1\u20090.04, a recall of 0.912\u2009\u00b1\u20090.03; and an F-measure of 0.917\u2009\u00b1\u20090.07. The findings suggest that the utilization of DL techniques holds promise in providing valuable guidance for treatment decisions [56]. Furthermore, ML combined with omics and clinical data has elucidated the microenvironment of OC, including dysregulation of DNA repair, loss of nuclear integrity [57], and tumour-immune phenotypes [58]. 5. Limitations and challenges The studies illustrates that the utilization of AI has facilitated technological advances in GC\u2019s digital pathology, showing promising potential in various applications. However, the translation of these techniques into clinical practice may take several years attributable to existing limitations and challenges. 5.1. \u2018Black box\u2019 problem and interpretability Despite the robust capabilities of AI-based models, the development of explainable AI models is imperative for clinical practice. Understanding and explaining how AI-based algorithms work and how the model arrives at its decisions is an important hurdle for the adoption of AI-based methods in clinical practice. This \u2018black box\u2019 nature limits its clinical application. In handcrafted approaches, relevant features from the data are manually selected, which requires close collaboration between clinicians and experts. The integration of DL with handcrafted strategies leverages domain expertise to ensure the biological interpretability of the results generated [27]. Furthermore, some visualization methods have been developed to improve interpretability [46]. On the other hand, the integration of algorithms with other patient data, such as follow-up and clinicopathological information, has also contributed to improving interpretability to a certain extent [54]. 5.2. Quality of data The performance of an algorithm is influenced by the nature of the task, including the required level of accuracy and the quality of the samples being assessed [24]. To achieve optimal predictive performance and utility, AI algorithms need to be trained on clean and accurate data with a high signal-to-noise ratio [24], [27]. This can be challenging when dealing with histological data obtained from various laboratories. Various color normalization methods, such as spectral sensing [59], stain color adaptive normalization [60], adaptive color deconvolution [61], and transfer learning approaches [23], [50], can be employed to address this issue. Moreover, loss of data fidelity may occur when the scanner exceeds its maximum scanning capacity. Super-resolution microscopy techniques offer a solution by enabling higher resolution focusing on specific biological elements [62]. 5.3. The generalization of AI models The model\u2019s performance is affected by intrinsic variations in datasets [39]. Therefore, improving the model\u2019s generalization ability as a pressing issue that necessitates resolution. Cross-validation is a common method employed to improve the generalization ability of models. However, due to data constraints, several studies omit the implementation of cross-validation (Table 2). Additionally, refining the model through fine-tuning has the potential to reduce the generalization error [50]. 5.4. AI algorithms and validation The dataset utilized for training AI models is typically divided into training and validation sets. The training set is typically balanced, while the validation set is derived either from the original dataset or sourced from another institution [27]. Validation sets are necessary to prevent overfitting. However, external validation is often lacking due to the difficulty in acquiring data (Table 2). In addition, AI algorithms may exhibit limitations in specific domains, such as mutation detection, where their performance is typically lower [25], [53]. 6. Future directions The advent of digital pathology has ushered in new prospects for generating extensive, high-resolution digital data. The integration of AI in image analysis has catalyzed advancements across various areas of medical imaging. Anticipated future developments in AI for GCs include the identification of biomarkers. However, this new technology is confronted with several challenges that necessitate resolution before its integration into clinical practice. For instance, it is still uncertain whether AI applications can replace some expensive molecular tests for cancer screening and molecular phenotype stratification. However, given the increasing global incidence of cancer and the auspicious potential of AI-based methods in accurately classifying pathological images at a lower cost, it is likely that these challenges will be overcome. 7. Conclusions Digital pathology facilitates the digitized acquisition, management, and interpretation of information. AI in digital pathology provides opportunities for computational analysis. This review summarizes the application of AI-based digital pathology in the diagnosis, histopathological classification, prognosis, and assessment of therapeutic responses in GCs. DL algorithms, particularly CNNs, have demonstrated superior performance. Despite the advantages offered by AI, significant challenges such as interpretability, data quality, model generalization, and validation need to be addressed. Moreover, certain areas such as biomarker detection and multi-center studies remain underexplored. However, with the ongoing advancements in AI algorithms, it is envisaged that their application will improve and become more widespread in clinical practice. Furthermore, the anticipation is that large, prospective studies and clinical trials testing AI methods will become universal in the future. CRediT authorship contribution statement Y-LW, SG, QX, T-TG, and Q-JW conceived the study. Y-LW, SG, T-TG, and Q-JW contributed to the design. Y-LW, QX, Y-YZ, X-HL, YK, D-HH and F-HL collected the data. Y-LW and Y-YZ cleaned the data and checked the discrepancy. Y-LW, SG, QX, CL, MG, Y-YZ, T-TG, and Q-JW drafted the article and revised it critically for important intellectual content. T-TG and Q-JW agreed to be accountable for all aspects of the work in ensuring that questions related to the accuracy or integrity of any part of the work are appropriately investigated and resolved. All authors interpreted the data, read the manuscript, and approved the final vision. Y-LW and SG contributed equally to this work. Declaration of Competing Interest The authors report no conflict of interest. Acknowledgements This work was supported by the National Key R&D Program of China (No. 2022YFC2704200 to Wu QJ), the Natural Science Foundation of China (No. 82073647 and No. 82373674 to Wu QJ and No. 82103914 to Gong TT), Liaoning Province Science and Technology Plan (No. 2023JH2/20200019 to Wu QJ), LiaoNing Revitalization Talents Program (No. XLYC1907102 to Wu QJ), Outstanding Scientific Fund of Shengjing Hospital (No. M1150 to Wu QJ), and 345 Talent Project of Shengjing Hospital of China Medical University (No. M0268 to Wu QJ and No. M0952 to Gong TT). References [1] Pallabi Shrestha, Bhavya Poudyal, Sepideh Yadollahi, Darryl E. Wright, Adriana V. Gregory, et al. A systematic review on the use of artificial intelligence in gynecologic imaging \u2013 background, state of the art, and future directions Gynecol Oncol, 166 (3) (2022), pp. 596-605 View PDFView articleView in ScopusGoogle Scholar [2] Hyuna Sung, Jacques Ferlay, Rebecca L. Siegel, Mathieu Laversanne, Isabelle Soerjomataram, et al. Global Cancer Statistics 2020: GLOBOCAN estimates of incidence and mortality worldwide for 36 cancers in 185 countries CA Cancer J Clin, 71 (3) (2021), pp. 209-249 CrossRefGoogle Scholar [3] Gordon C. Jayson, Elise C. Kohn, Henry C. Kitchener, Jonathan A. Ledermann Ovarian cancer Lancet, 384 (9951) (2014), pp. 1376-1388 View PDFView articleView in ScopusGoogle Scholar [4] Zohre Momenimovahed, Azita Tiznobaik, Safoura Taheri, Hamid Salehiniya Ovarian cancer in the world: epidemiology and risk factors Int J Women\u2019s Health, 11 (2019), pp. 287-299 CrossRefView in ScopusGoogle Scholar [5] Antonio Gonz\u00e1lez-Mart\u00edn, Bhavana Pothuri, Ignace Vergote, Ren\u00e9 DePont Christensen, Whitney Graybill, et al. Niraparib in patients with newly diagnosed advanced ovarian cancer N Engl J Med, 381 (25) (2019), pp. 2391-2402 CrossRefView in ScopusGoogle Scholar [6] Ting-Ting Gong, Fang-Hua Liu, Ya-Shu Liu, Shi Yan, He-Li Xu, et al. A follow-up study of ovarian cancer (OOPS): a study protocol Front Nutr, 9 (2022), Article 872773 View in ScopusGoogle Scholar [7] Philippe Morice, Alexandra Leary, Carien Creutzberg, Nadeem Abu-Rustum, Emile Darai Endometrial cancer Lancet, 387 (10023) (2016), pp. 1094-1108 View PDFView articleView in ScopusGoogle Scholar [8] Stephanie Robertson, Hossein Azizpour, Kevin Smith, Johan Hartman Digital image analysis in breast pathology-from image processing techniques to artificial intelligence Transl Res, 194 (2018), pp. 19-35 View PDFView articleView in ScopusGoogle Scholar [9] Bhavneet Bhinder, Coryandar Gilvary, Neel S. Madhukar, Olivier Elemento Artificial intelligence in cancer research and precision medicine Cancer Discov, 11 (4) (2021), pp. 900-915 CrossRefView in ScopusGoogle Scholar [10] Benjamin H. Kann, Ahmed Hosny, Hugo J.W.L. Aerts Artificial intelligence for clinical oncology Cancer Cell, 39 (7) (2021), pp. 916-927 View PDFView articleView in ScopusGoogle Scholar [11] Qiyuan Hu, Heather M. Whitney, Hui Li, Yu Ji, Peifang Liu, et al. Improved classification of benign and malignant breast lesions using deep feature maximum intensity projection MRI in breast cancer diagnosis using dynamic contrast-enhanced MRI Radio Artif Intell, 3 (3) (2021), Article e200159 CrossRefView in ScopusGoogle Scholar [12] Saima Rathore, Muhammad Aksam Iftikhar, Ahmad Chaddad, Tamim Niazi, Thomas Karasic, et al. Segmentation and grade prediction of colon cancer digital pathology images across multiple institutions Cancers, 11 (11) (2019), p. 1700 CrossRefView in ScopusGoogle Scholar [13] Richard Ha, Christine Chin, Jenika Karcich, Michael Z. Liu, Peter Chang, et al. Prior to initiation of chemotherapy, can we predict breast tumor response? Deep learning convolutional neural networks approach using a breast MRI tumor dataset J Digit Imaging, 32 (5) (2019), pp. 693-701 CrossRefView in ScopusGoogle Scholar [14] David F. Steiner, Robert MacDonald, Yun Liu, Peter Truszkowski, Jason D. Hipp, et al. Impact of Deep Learning Assistance on the Histopathologic Review of Lymph Nodes for Metastatic Breast Cancer. Am J Surg Pathol 42(12): 1636\u20131646. Google Scholar [15] Yun Liu, Timo Kohlberger, Mohammad Norouzi, George E. Dahl, Jenny L. Smith, et al. Artificial intelligence-based breast cancer nodal metastasis detection: insights into the black box for pathologists Arch Pathol Lab Med, 143 (7) (2019), pp. 859-868 CrossRefView in ScopusGoogle Scholar [16] Jakob Nikolas Kather, Johannes Krisam, Pornpimol Charoentong, Tom Luedde, Esther Herpel, et al. Predicting survival from colorectal cancer histology slides using deep learning: a retrospective multicenter study PLoS Med, 16 (1) (2019), Article e1002730 CrossRefView in ScopusGoogle Scholar [17] Dexin Chen, Meiting Fu, Liangjie Chi, Liyan Lin, Jiaxin Cheng, et al. Prognostic and predictive value of a pathomics signature in gastric cancer Nat Commun, 13 (1) (2022), p. 6903 View in ScopusGoogle Scholar [18] German Corredor Jon Whitney, Shridar Ganesan Andrew Janowczyk, Scott Doyle, et al. Quantitative nuclear histomorphometry predicts oncotype DX risk categories for early stage ER+ breast cancer BMC Cancer, 18 (1) (2018), p. 610 Google Scholar [19] Germ\u00e1n Corredor, Xiangxue Wang, Yu Zhou, Cheng Lu, Pingfu Fu, et al. Spatial architecture and arrangement of tumor-infiltrating lymphocytes for predicting likelihood of recurrence in early-stage non-small cell lung cancer Clin Cancer Res, 25 (5) (2019), pp. 1526-1534 CrossRefView in ScopusGoogle Scholar [20] Kun-Hsing Yu, Ce Zhang, Gerald J. Berry, Russ B. Altman, Christopher R\u00e9, et al. Predicting non-small cell lung cancer prognosis by fully automated microscopic pathology image features Nat Commun, 7 (2016), Article 12474 View in ScopusGoogle Scholar [21] Guy Nir, Soheil Hor, Davood Karimi, Ladan Fazli, Brian F. Skinnider, et al. Automatic grading of prostate cancer in digitized histopathology images: learning from multiple experts Med Image Anal, 50 (2018), pp. 167-180 View PDFView articleView in ScopusGoogle Scholar [22] Hanadi El Achi, Tatiana Belousova, Lei Chen, Amer Wahed, Iris Wang, et al. Automated diagnosis of lymphoma with digital pathology images using deep learning Ann Clin Lab Sci, 49 (2) (2019), pp. 153-160 View in ScopusGoogle Scholar [23] Christophe Klein, Qinghe Zeng, Floriane Arbaretaz, Estelle Dev\u00eavre, Julien Calderaro, et al. Artificial intelligence for solid tumour diagnosis in digital pathology Br J Pharm, 178 (21) (2021), pp. 4291-4315 CrossRefView in ScopusGoogle Scholar [24] Vipul Baxi, Robin Edwards, Michael Montalto, Saurabh Saha Digital pathology and artificial intelligence in translational medicine and clinical practice Mod Pathol, 35 (1) (2022), pp. 23-32 View PDFView articleCrossRefView in ScopusGoogle Scholar [25] B. Acs, M. Rantalainen, J. Hartman Artificial intelligence as the next step towards precision pathology J Intern Med, 288 (1) (2020), pp. 62-81 CrossRefView in ScopusGoogle Scholar [26] Alex Ngai Nick Wong, Zebang He, Ka. Long Leung, Curtis Chun Kit To, Chun Yin Wong, et al. Current developments of artificial intelligence in digital pathology and its future clinical applications in gastrointestinal cancers Cancers, 14 (15) (2022), p. 3780 CrossRefView in ScopusGoogle Scholar [27] Kaustav Bera, Kurt A. Schalper, David L. Rimm, Vamsidhar Velcheti, Anant Madabhushi Artificial intelligence in digital pathology \u2014 new tools for diagnosis and precision oncology Nat Rev Clin Oncol, 16 (11) (2019), pp. 703-715 CrossRefView in ScopusGoogle Scholar [28] Alexander D. Borowsky, Eric F. Glassy, William Dean Wallace, Nathash S. Kallichanda, Cynthia A. Behling, et al. Digital whole slide imaging compared with light microscopy for primary diagnosis in surgical pathology Arch Pathol Lab Med, 144 (10) (2020), pp. 1245-1253 CrossRefView in ScopusGoogle Scholar [29] Ayat Aloqaily, Antonio Polonia, Sofia Campelos, Nusaiba Alrefae, Joao Vale, et al. Digital versus optical diagnosis of follicular patterned thyroid lesions Head Neck Pathol, 15 (2) (2021), pp. 537-543 CrossRefView in ScopusGoogle Scholar [30] Sanjay Mukhopadhyay, Michael D. Feldman, Esther Abels, Raheela Ashfaq, Senda Beltaifa, et al. Whole slide imaging versus microscopy for primary diagnosis in surgical pathology: a multicenter blinded randomized noninferiority study of 1992 cases (pivotal study) Am J Surg Pathol, 42 (1) (2018), pp. 39-52 CrossRefView in ScopusGoogle Scholar [31] Famke Aeffner, Mark D. Zarella, Nathan Buchbinder, Marilyn M. Bui, Matthew R. Goodman, et al. Introduction to digital image analysis in whole-slide imaging: a white paper from the digital pathology association J Pathol Inf, 10 (2019), Article 9 View PDFView articleCrossRefView in ScopusGoogle Scholar [32] Jianda Yuan, Priti S. Hegde, Raphael Clynes, Periklis G. Foukas, Alexandre Harari, et al. Novel technologies and emerging biomarkers for personalized cancer immunotherapy J Immunother Cancer, 4 (2016), p. 3 Google Scholar [33] Andreas Heindl, Sidra Nawaz, Yinyin Yuan Mapping spatial heterogeneity in the tumor microenvironment: a new era for digital pathology Lab Invest, 95 (4) (2015), pp. 377-384 View PDFView articleCrossRefView in ScopusGoogle Scholar [34] J. McCarthy, M.L. Minsky, N. Rochester, C.E. Shannon A proposal for the dartmouth summer research project on artificial intelligence August 31, 1955 AI Mag, 27 (4) (2006), p. 12 View in ScopusGoogle Scholar [35] Xue Zhao, Jing-Wen Bai, Qiu Guo, Ke Ren, Guo-Jun Zhang Clinical applications of deep learning in breast MRI Biochim Biophys Acta Rev Cancer, 1878 (2) (2023), Article 188864 View PDFView articleView in ScopusGoogle Scholar [36] A.\u00efcha BenTaieb, Hector Li-Chang, David Huntsman, Ghassan Hamarneh A structured latent model for ovarian carcinoma subtyping from histopathology slides Med Image Anal, 39 (2017), pp. 194-205 View PDFView articleView in ScopusGoogle Scholar [37] Jun Jiang, Burak Tekin, Ruifeng Guo, Hongfang Liu, Yajue Huang, et al. Digital pathology-based study of cell-and tissue-level morphologic features in serous borderline ovarian tumor and high-grade serous ovarian cancer J Pathol Inf, 12 (2021), Article 24 View PDFView articleCrossRefGoogle Scholar [38] Miao Wu, Chuanbo Yan, Huiqiang Liu, Qian Liu Automatic classification of ovarian cancer types from cytological images using deep convolutional neural networks Biosci Rep, 38 (3) (2018), Article BSR20180289 CrossRefView in ScopusGoogle Scholar [39] Hossein Farahani, Jeffrey Boschman, David Farnell, Amirali Darbandsari, Allen Zhang, et al. Deep learning-based histotype diagnosis of ovarian carcinoma whole-slide pathology images Mod Pathol, 35 (12) (2022), pp. 1983-1990 View PDFView articleCrossRefView in ScopusGoogle Scholar [40] Runyu Hong, Wenke Liu, Deborah DeLair, Narges Razavian, David Feny\u00f6 Predicting endometrial cancer subtypes and molecular features from histopathology images using multi-resolution deep learning models Cell Rep Med, 2 (9) (2021), Article 100400 View PDFView articleView in ScopusGoogle Scholar [41] JaeYen Song, Soyoung Im, Sung Hak Lee, Hyun-Jong Jang Deep learning-based classification of uterine cervical and endometrial cancer subtypes from whole-slide histopathology images Diagnostics, 12 (11) (2022), p. 2623 CrossRefView in ScopusGoogle Scholar [42] Yi-Xin Li, Feng Chen, Jiao-Jiao Shi, Yu-Li Huang, Mei Wang Convolutional neural networks for classifying cervical cancer types using histological images J Digit Imaging, 36 (2) (2023), pp. 441-449 Google Scholar [43] Lidiya Wubshet Habtemariam, Elbetel Taye Zewde, Gizeaddis Lamesgin Simegn Cervix type and cervical cancer classification system using deep learning techniques Med Devices, 15 (2022), pp. 163-176 CrossRefView in ScopusGoogle Scholar [44] Seo Jeong Shin, Seng Chan You, Hokyun Jeon, Ji. Won Jung, Min Ho An, et al. Style transfer strategy for developing a generalizable deep learning application in digital pathology Comput Methods Prog Biomed, 198 (2021), Article 105815 View PDFView articleView in ScopusGoogle Scholar [45] Duhita Sengupta, Sk. Nishan Ali, Aditya Bhattacharya, Joy Mustafi, Asima Mukhopadhyay, et al. A deep hybrid learning pipeline for accurate diagnosis of ovarian cancer based on nuclear morphology PLoS One, 17 (1) (2022), Article e0261181 CrossRefView in ScopusGoogle Scholar [46] Mahnaz Mohammadi, Jessica Cooper, Ognjen Arandelovi\u0107, Christina Fell, David Morrison, et al. Weakly supervised learning and interpretability for endometrial whole slide image diagnosis Exp Biol Med, 247 (22) (2022), pp. 2025-2037 CrossRefView in ScopusGoogle Scholar [47] Xiaobo Zhang, Wei Ba, Xiaoya Zhao, Chen Wang, Qiting Li, et al. Clinical-grade endometrial cancer detection system via whole-slide images using deep learning Front Oncol, 12 (2022), Article 1040238 View in ScopusGoogle Scholar [48] Hao Sun, Xianxu Zeng, Tao Xu, Gang Peng, Yutao Ma Computer-aided diagnosis in histopathological images of the endometrium using a convolutional neural network and attention mechanisms IEEE J Biomed Health Inf, 24 (6) (2020), pp. 1664-1676 CrossRefView in ScopusGoogle Scholar [49] Rutger H.J. Fick, Brice Tayart, Capucine Bertrand, Solene Chan Lang, Tina Rey, et al. A partial label-based machine learning approach for cervical whole-slide image classification: the winning tissuenet solution Annu Int Conf IEEE Eng Med Biol Soc, 2021 (2021), pp. 2127-2131 CrossRefView in ScopusGoogle Scholar [50] Yue Du, Roy Zhang, Abolfazl Zargari, Theresa C. Thai, Camille C. Gunderson, et al. Classification of tumor epithelium and stroma by exploiting image features learned by deep convolutional neural networks Ann Biomed Eng, 46 (12) (2018), pp. 1988-1999 CrossRefView in ScopusGoogle Scholar [51] Anna Ray Laury, Sami Blom, Tuomas Ropponen, Anni Virtanen, Olli Mikael Carp\u00e9n Artifcial intelligence-based image analysis can predict outcome in high-grade serous carcinoma via histology alone Sci Rep, 11 (1) (2021), p. 19165 View in ScopusGoogle Scholar [52] Hao Zeng, Linyan Chen, Mingxuan Zhang, Yuling Luo, Xuelei Ma Integration of histopathological images and multi-dimensional omics analyses predicts molecular features and prognosis in high-grade serous ovarian cancer Gynecol Oncol, 163 (1) (2021), pp. 171-180 View PDFView articleView in ScopusGoogle Scholar [53] Camilla Nero, Luca Boldrini, Jacopo Lenkowicz, Maria Teresa Giudice, Alessia Piermattei, et al. Deep-learning to predict BRCA mutation and survival from digital H&E slides of epithelial ovarian cancer Int J Mol Sci, 23 (19) (2022), p. 11326 CrossRefView in ScopusGoogle Scholar [54] Sarah Fremond, Sonali Andani, Jurriaan Barkey Wolf, Jouke Dijkstra, Sin\u00e9ad Melsbach, et al. Interpretable deep learning model to predict the molecular classification of endometrial cancer from haematoxylin and eosin-stained whole-slide images: a combined analysis of the PORTEC randomised trials and clinical cohorts Lancet Digit Health, S2589-7500 (22) (2022), pp. 00210-00212 Google Scholar [55] Chi Chen, Yuye Cao, Weili Li, Zhenyu Liu, Ping Liu, et al. The pathological risk score: a new deep learning-based signature for predicting survival in cervical cancer Cancer Med, 12 (2) (2023), pp. 1051-1063 CrossRefView in ScopusGoogle Scholar [56] Ching-Wei Wang, Cheng-Chang Chang, Yu-Ching Lee, Yi-Jia Lin, Shih-Chang Lo, et al. Weakly supervised deep learning for prediction of treatment effectiveness on ovarian cancer from histopathology images Comput Med Imaging Graph, 99 (2022), Article 102093 View PDFView articleView in ScopusGoogle Scholar [57] Andreas Heindl, Adnan Mujahid Khan, Daniel Nava Rodrigues, Katherine Eason, Anguraj Sadanandam, et al. Microenvironmental niche divergence shapes BRCA1-dysregulated ovarian cancer morphological plasticity Nat Commun, 9 (1) (2018), p. 3917 View in ScopusGoogle Scholar [58] M.\u00e9lanie Desbois, Akshata R. Udyavar, Lisa Ryner, Cleopatra Kozlowski, Guan Yinghui, et al. Integrated digital pathology and transcriptome analysis identifies molecular mediators of T-cell exclusion in ovarian cancer Nat Commun, 11 (1) (2020), p. 5583 View in ScopusGoogle Scholar [59] Shinsuke Tani, Yasuhiro Fukunaga, Saori Shimizu, Munenori Fukunishi, Kensuke Ishii, et al. Color standardization method and system for whole slide imaging based on spectral sensing Anal Cell Pathol, 35 (2) (2012), pp. 107-115 CrossRefView in ScopusGoogle Scholar [60] Massimo Salvi, Nicola Michielli, Filippo Molinari Stain color adaptive normalization (SCAN) algorithm: separation and standardization of histological stains in digital pathology Comput Methods Prog Biomed, 193 (2020), Article 105506 View PDFView articleView in ScopusGoogle Scholar [61] Yushan Zheng, Zhiguo Jiang, Haopeng Zhang, Fengying Xie, Jun Shi, et al. Adaptive color deconvolution for histological WSI normalization Comput Methods Prog Biomed, 170 (2019), pp. 107-120 View PDFView articleView in ScopusGoogle Scholar [62] Bo Huang, Mark Bates, Xiaowei Zhuang Super-resolution fluorescence microscopy Annu Rev Biochem, 78 (2009), pp. 993-1016 CrossRefView in ScopusGoogle Scholar Cited by (0) \u00a9 2024 The Author(s). Published by Elsevier B.V. on behalf of Research Network of Computational and Structural Biotechnology. Part of special issue AI-based Medical Imaging and Assistive Diagnostic Technologies Edited by Prof. Qi Zhao University of Science and Technology Liaoning, Anshan, , China View special issue Recommended articles Resident Education Curriculum in Pediatric and Adolescent Gynecology: The Short Curriculum 4.0 Journal of Pediatric and Adolescent Gynecology, 2024 Ashli A. Lawson, \u2026, Amanda V. French View PDF A comprehensive analysis of the emerging modern trends in research on photovoltaic systems and desalination in the era of artificial intelligence and machine learning Heliyon, Volume 10, Issue 3, 2024, Article e25407 Laxmikant D. Jathar, \u2026, \u00dcmit A\u011fbulut View PDF Stem Cell Therapy in Obstetrics and Gynecology Reference Module in Biomedical Sciences, 2024 Ciro Comparetto, Franco Borruto Show 3 more articles About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright \u00a9 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply.",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "Effective social spider optimization algorithms for distributed assembly permutation flowshop scheduling problem in automobile manufacturing supply chain",
    "doi": "10.1038/s41598-024-57044-8",
    "description": "This paper presents a novel distributed assembly permutation flowshop scheduling problem (DAPFSP) based on practical problems in automobile production. Different from the existing research on DAPFSP, this study considers that each component of the final product is composed of more than one part. Components are processed in a set of identical components manufacturing factories and are assembled into products in the assembly factory. The integration of manufacturing processes is an important objective of Industry 4.0. For solving this problem with the minimum makespan criterion, we introduce a three-level representation and a novel initialization method. To enhance the search ability of the proposed algorithms, we design three local search methods and two restart procedures according to characteristics of the problem. Then, by incorporating the problem specific knowledge with the social spider optimization algorithm (SSO), we propose three SSO variants: the SSO with hybrid local search strategies (HSSO), the HSSO with restart procedures (HSSOR), and the HSSOR with self-adaptive selection probability (HSSORP). Finally, 810 extended instances based on the famous instances are used to test the proposed algorithms. In most cases, HSSOR performs the best, with an average comparison metric value of 0.158% across three termination conditions, while the average comparison metric value for the best comparison method is 2.446%, which is 15.481 times that of HSSOR. Numerical results demonstrate that the proposed algorithms can solve the problem efficiently.",
    "journal": "Scientific Reports",
    "authors": [
      "Zhang W.",
      "Hao J.",
      "Liu F."
    ],
    "citation_count": "0",
    "full_text": "Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Advertisement View all journals Search Log in Explore content About the journal Publish with us Sign up for alerts RSS feed nature scientific reports articles article Article Open access Published: 16 March 2024 Effective social spider optimization algorithms for distributed assembly permutation flowshop scheduling problem in automobile manufacturing supply chain Weiwei Zhang, Jianhua Hao & Fangai Liu  Scientific Reports  14, Article number: 6370 (2024) Cite this article 133 Accesses 1 Altmetric Metrics Abstract This paper presents a novel distributed assembly permutation flowshop scheduling problem (DAPFSP) based on practical problems in automobile production. Different from the existing research on DAPFSP, this study considers that each component of the final product is composed of more than one part. Components are processed in a set of identical components manufacturing factories and are assembled into products in the assembly factory. The integration of manufacturing processes is an important objective of Industry 4.0. For solving this problem with the minimum makespan criterion, we introduce a three-level representation and a novel initialization method. To enhance the search ability of the proposed algorithms, we design three local search methods and two restart procedures according to characteristics of the problem. Then, by incorporating the problem specific knowledge with the social spider optimization algorithm (SSO), we propose three SSO variants: the SSO with hybrid local search strategies (HSSO), the HSSO with restart procedures (HSSOR), and the HSSOR with self-adaptive selection probability (HSSORP). Finally, 810 extended instances based on the famous instances are used to test the proposed algorithms. In most cases, HSSOR performs the best, with an average comparison metric value of 0.158% across three termination conditions, while the average comparison metric value for the best comparison method is 2.446%, which is 15.481 times that of HSSOR. Numerical results demonstrate that the proposed algorithms can solve the problem efficiently. Similar content being viewed by others Modeling and solving the parallel mixed-flow remanufacturing disassembly line balancing problem for multi-variety products Article Open access 13 September 2022 GAILS: an effective multi-object job shop scheduler based on genetic algorithm and iterative local search Article Open access 24 January 2024 Energy-efficient distributed heterogeneous re-entrant hybrid flow shop scheduling problem with sequence dependent setup times considering factory eligibility constraints Article Open access 05 November 2022 Introduction Assembly production systems are widely used in various industries, e.g., in electronic, construction machinery, automobile and auto parts industries. In order to boost the production efficiency of assembly systems, researchers and industrial engineers have paid great attention to it in the past decades. The assembly flowshop scheduling problem (AFSP) was firstly presented by Lee et al.1 Later, Potts et al.2 illustrated the two-stage assembly flowshop problem (TSAFSP) according to the production of personal computers and proved that the general version of the considered problem is NP-hard. Koulamas and Kyparisis3 introduced the three-stage assembly flowshop scheduling problem taking the immediate transportation operation into consideration. Due to the practicality and complexity of AFSP, many literatures have conducted deep researches to it4,5,6,7,8,9,10. Recently, with the trend of globalization in the manufacture, considerable attention is paid to distributed flowshop scheduling problems since Naderi\u2019s innovative paper11. Later, Hatami et al.12,13 first introduced the distributed assembly permutation flowshop scheduling problem (DAPFSP) and proposed effective algorithms to study the modern supply chain. DAPFSP is composed by two stages: component processing and assembly. In the first stage, components are processed in several factories with the identical equipment. The latter stage is to assemble components processed in the first stage into products. As the widespread use of DAPFSP in modern supply chains and the NP-hardness of large-scale DAPFSP, many researchers investigated it in depth and proposed heuristics to achieve near-optimum solutions within reasonable time. Harami, Ruiz and Andres-Romano14 studied DAPFSP with sequence dependent setup times and developed two constructive heuristics to obtain efficient initial solutions. Li et al.15 employed the genetic algorithm (GA) for the DAPFSP, which combining an improved crossover strategy and three novel local search strategies. Wang, Zhang and Liu16 incorporated the variable neighborhood search (VNS) into the memetic algorithm (MA) for the DAPFSP with the makespan criterion. Moreover, Deng et al.17 propose a competitive memetic algorithm for the distributed TSAFSP (DTSAFSP). Lin and Zhang18 hybridized the biogeography-based optimization (BBO) algorithm with several heuristics to minimize the makespan of the DAPFSP. A novel estimation of distribution algorithm based memetic algorithm (EDAMA) was developed by Wang and Wang19 to minimize the makespan of DAPFSP. Lin, Wang and Li20 proposed the backtracking search hyper-heuristic (BS-HH) to figure out the DAPFSP. The effectiveness of BBO, EDAMA and BS-HH was demonstrated on the benchmark instances generated by Hatami et al.12. In addition, Gonzalez-Neira et al.21 considered the DAPFSP with stochastic processing times. More recently, several papers carried further research on the DAPFSP. Ruiz, Pan and Naderi22 proposed iterated greedy (IG) methods for the DAPFSP with makespan criterion. Ferone et al.23 developed a biased-randomized iterated local search for the same problem. Pan et al.24 presented an extension of the DAPFSP and proposed effective heuristics to solve the considered scheduling problem. Recently, Sang et al.25 studied the DAPFSP proposed by Pan et al.24 with the total flowtime criterion and proposed three diffident discrete invasive weed optimization (DIWO). Studies in DAPFSP suppose that each component of the final product consists of only one part but one component could be more complicated and composed of several parts in the practical production. Meanwhile, with the trend of production specialization and internationalization, one factory generally does not engage in all stages of production from raw materials to final products, and the production of semi-finished products is usually completed by other factories. In many practical production scenarios, especially in the automobile production process, one semi-finished product is usually a large-sized component composed of many small parts. For example, in automotive enterprises such as Anhui Jianghuai Automobile Co., Ltd and Jiangling Motors Corporate of China, components from other manufacturers are added to the truck frame on the final assembly line, such as the engine24, the axle, the transmission shaft, and so on. Each of these large-sized components is composed of some small parts and can be considered as semi-finished products produced by other components manufacturing factories. To the best of our knowledge, there is no study on DAPFSP considering that each component of the final product is composed of several parts, but this problem exists in practical production. For this problem, efficient scheduling can improve the production efficiency of enterprises, reduce resource waste and pollutant emissions, and help enterprises achieve green production. Therefore, this paper considers the practical situation in the automobile manufacturing supply chain and addresses a novel DAPFSP based on the innovative work of Hatami et al.12,13 and Pan et al.24. There are several optimization objectives in the flowshop scheduling problem26,27, such as total flow time, total waiting time, makespan, and weighted flow time. This paper aims to minimize makespan of the proposed problem due to the time of delivery is an important content in trade contracts. It has been proved that minimizing makespan of DAPFSP is NP-hard, hence, the presented problem is NP-hard because of more complexity. Over recent years, various meta-heuristics have been proposed and applied to solve production scheduling problems, such as genetic algorithm (GA)28, particle swarm optimization (PSO)29,30,31, artificial bee colony (ABC)32,33,34, firefly algorithm (FA)35,36, grey wolf optimizer (GWO)37,38, whale optimization algorithm (WOA)39,40,41,42, migrating birds optimization algorithm (MBO)43, and so on. Recently, the social spider optimization (SSO), inspired by the cooperative behavior of spiders, is an emerging and excellent swarm intelligent algorithm. The SSO was first proposed by Cuevas and Cienfuegos44 for solving constrained optimization problems. To enhance the search ability of SSO, Klein et al.45 introduced a modified SSO and applied it to electromagnetic optimization. Nguyen46 presented a novel improved SSO (NISSO) for optimal power flow problem. Zhang and Xing47 developed a memetic SSO (MSSO) for the distributed TSAFSP. Inspired by many successful applications of SSO, we adopt SSO to solve the DAPFSP proposed in this paper. Considering the complexity of the proposed DAPFSP in this paper, we introduce a three-level representation and present three shift operators for it. According to the three shift operators, three local search methods are designed respectively. Two restart procedures are presented to maintain the diversity of the population and avoid premature convergence. We combine the problem specific knowledge with the SSO and propose three SSO variants. Experimental results based on 810 extended instances demonstrate the effectiveness of our algorithms. The remainder of our paper is organized as follows. \u201cProblem definition and formulation\u201d section illustrates the proposed DAPFSP in this paper and formulates the proposed problem with makespan criterion. \u201cThe canonical SSO algorithm\u201d section shows the concept and theory of SSO. \u201cThe proposed three social spider optimization algorithms\u201d section reports three variants of SSO in detail. In \u201cExperiment analyses\u201d section, we conduct experiments and analyze the results. Finally, \u201cConclusions\u201d section details conclusions and our future research work. Problem definition and formulation Problem definition This section briefly illustrates the presented DAPFSP similar to examples reported by Hatami et al.12 and Pan et al.24. There are one assembly factory and a set of \\(F\\) identical components manufacturing factories (See in Fig. 1). Under the Make-To-Order (MTO) mode of automobile production, the customer places an order for H products to the assembly factory, and then the assembly factory orders components from F components manufacturing factories according to the customer\u2019s order. Each final product is composed of several components and each component can be manufactured in any of the \\(F\\) components manufacturing factories. Each component manufacturing factory \\(f\\) (\\(f = 1, \\ldots ,F\\)) is formed by the same production stage and an assembly machine. The production stage is a flowshop and consists of \\(m\\) machines. In the flowshop, every part must be processed by \\(m\\) machines in sequence, i.e., \\(M_{1}\\), \\(M_{2}\\), and so on until \\(M_{m}\\). All parts belonging to one component must be processed continuously in one factory. In the assembly stage of one component manufacturing factory, all parts belonging to the same component are assembled on the assembly machine \\(M_{A}\\). Finished components are transported to the final assembly factory. Finally, H products \\(\\left\\{ {P_{1} ,P_{2} , \\ldots ,P_{H} } \\right\\}\\) are assembled on the final assembly line in the assembly factory and delivered to customers within the delivery date. Figure 1 Illustration of the presented DAPFSP. Full size image Problem formulation Following assumptions are used to formulate the considered DAPFSP: All parts of each component are available to be processed at time zero. One component must be processed in one components manufacturing factory. Changing factory is not allowed. The transportation time within and between factories is ignored. The assembly operation of one component can be performed if all parts belong to the component are processed. When all components of a product have been processed, the assembly operation for that product can begin. Parameters, indices, sets, and variables are listed as follows. Parameters: F Number of components manufacturing factories M Number of machines in the production stage \u03b1 Number of products \u03b2 Number of all the components \u03a7 Number of all the parts np Number of the components belonging to product \\(\\Delta_{p}\\),\\(p = 0,1,2, \\ldots ,\\alpha \\cdot n_{0} = 0\\) uc Number of the parts belonging to component \\(\\omega_{c}\\), \\(c = 0,1,2, \\ldots ,\\beta \\cdot u_{0} = 0\\).\\(Bj,m\\) \\(P_{j,m}\\) Processing time of part j on machine m \\(A_{{\\omega_{c} }}\\) Assembly time of component \\(\\omega_{c}\\) \\(A_{{\\Delta_{p} }}\\) Assembly time of product \\(\\Delta_{p}\\) T A very large positive number Indices: f Actory index i j Part index c c\u2032 Component index p p\u2032 Product index m Index of machines in the production stage Sets: \\(\\Delta = \\left\\{ {\\Delta_{1} ,\\Delta_{2} , \\ldots ,\\Delta_{\\alpha } } \\right\\}\\) Set of products \\(\\Delta_{0}\\) A dummy product \\(\\Lambda_{p} = \\left\\{ {\\Lambda_{p,1} ,\\Lambda_{p,2} , \\ldots ,\\Lambda_{{p,n_{p} }} } \\right\\}\\) Set of components belonging to \\(\\Lambda_{p}\\) \\(\\Lambda = \\left\\{ {\\omega_{{k_{0} + 1}} ,\\omega_{{k_{0} + 2}} , \\ldots \\omega_{{k_{1} }} ,\\;\\omega_{k + 1} , \\ldots ,\\omega_{{k_{\\alpha - 1} + 1}} , \\ldots \\omega_{{k_{\\alpha } }} } \\right\\}\\) Set of all the components, where components \\(\\omega_{{k_{p - 1} + 1}} , \\ldots \\omega_{{k_{p} }}\\) belonging to the product \\(\\Delta_{p} \\cdot k_{0} = 0,\\;k_{p} = \\sum\\nolimits_{s = 1}^{p} {n_{s} }\\) \\(\\omega_{0}\\) A dummy component \\(\\theta_{0}\\) A dummy part \\(\\delta_{c} = \\left\\{ {\\delta_{c,1} ,\\delta_{c,2} , \\ldots \\delta_{{c,u_{c} }} } \\right\\}\\) Set of parts belonging to \u03c9c \\(\\delta = \\left\\{ {\\theta_{{z_{0} + 1}} ,\\theta_{{z_{0} + 2}} , \\ldots \\theta_{{z_{1} }} ,\\;\\theta_{{z_{1} + 1}} , \\ldots \\theta_{{z_{\\beta - 1} + 1}} , \\ldots \\theta_{{z_{\\beta } }} } \\right\\}\\) Set of all the parts, where parts \\(\\theta_{{z_{c - 1} + 1}} , \\ldots \\theta_{{z_{c} }} ,\\) belonging to the component \\(\\omega_{c} \\cdot z_{0} = 0,\\;z_{c} = \\sum\\nolimits_{s = 1}^{c} {u_{s} }\\) Variables: \\(B_{j,m}\\) Beginning time of part \\(j\\) on machine \\(m\\) \\(C_{j,m}\\) Completion time of part \\(j\\) on machine \\(m\\) \\(C_{{\\omega_{c} }}\\) Completion time of component \\(\\omega_{c}\\) \\(C_{{\\Delta_{p} }}\\) Completion time of product \\(\\Delta_{p}\\) \\(C_{\\max }\\) Makespan of all products Binary variables: $$X_{i,j} = \\left\\{ {\\begin{array}{*{20}l} 1 \\hfill & {{\\text{if}}\\;{\\text{part}}\\;j\\;{\\text{is}}\\;{\\text{processed}}\\;{\\text{immediately}}\\;{\\text{after}}\\;{\\text{part}}\\;i} \\hfill \\\\ 0 \\hfill & {{\\text{otherwise}}} \\hfill \\\\ \\end{array} } \\right.$$ $$Y_{c,f} = \\left\\{ {\\begin{array}{*{20}l} 1 \\hfill & {{\\text{if}}\\;{\\text{component}}\\;c\\;{\\text{is}}\\;{\\text{process}}\\;{\\text{ed}}\\;{\\text{in}}\\;{\\text{factory}}\\;f} \\hfill \\\\ 0 \\hfill & {{\\text{otherwise}}} \\hfill \\\\ \\end{array} } \\right.$$ $$Z_{{c,c^{\\prime } }} = \\left\\{ {\\begin{array}{*{20}l} 1 \\hfill & {{\\text{if}}\\;{\\text{component}}\\;c\\;{\\text{is}}\\;{\\text{assembled}}\\;{\\text{immediately}}\\;{\\text{after}}\\;{\\text{component}}\\;c^{\\prime } \\;{\\text{on}}\\;{\\text{the}}\\;{\\text{assembly}}\\;{\\text{machine}}} \\hfill \\\\ 0 \\hfill & {{\\text{otherwise}}} \\hfill \\\\ \\end{array} } \\right.$$ $$H_{{p,p^{\\prime } }} = \\left\\{ {\\begin{array}{*{20}l} 1 \\hfill & {{\\text{if}}\\;{\\text{product}}\\;p\\;{\\text{is}}\\;{\\text{assembled}}\\;{\\text{immediately}}\\;{\\text{after}}\\;{\\text{product}}\\;p^{\\prime } \\;{\\text{on}}\\;{\\text{the}}\\;{\\text{final}}\\;{\\text{assembly}}\\;{\\text{factory}}} \\hfill \\\\ 0 \\hfill & {{\\text{otherwise}}} \\hfill \\\\ \\end{array} } \\right.$$ The mathematical model of the presented DAPFSP can be formulated as follows: $$\\min \\;C_{\\max }$$ (1) $$\\begin{aligned}&\\text{S. T}\\\\ &\\sum\\limits_{i = 0,i \\ne j}^{\\chi } {X_{i,j} } = 1,\\quad j = 1,2, \\ldots ,\\chi \\end{aligned}$$ (2) $$\\sum\\limits_{j = 0,j \\ne i}^{\\chi } {X_{i,j} } = 1,\\quad i = 1,2, \\ldots ,\\chi$$ (3) $$\\sum\\limits_{f = 1}^{F} {Y_{c,f} } = 1,\\quad c = 1,2, \\ldots ,\\beta$$ (4) $$\\sum\\limits_{i = 1}^{{z_{l - 1} }} {\\sum\\limits_{{j = z_{l - 1} + 1}}^{{z_{l} }} {X_{i,j} } } + \\sum\\limits_{{i = z_{l} + 1}}^{{z_{\\beta } }} {\\sum\\limits_{{j = z_{l - 1} + 1}}^{{z_{l} }} {X_{i,j} } } = 1,\\quad l = 1,2, \\ldots ,\\beta$$ (5) $$C_{j,m} \\ge C_{j,m - 1} + P_{j,m} ,\\quad j = 1,2, \\ldots ,\\chi ,\\;m = 2,3, \\ldots ,M$$ (6) $$C_{j,m} \\ge C_{i,m} + P_{i,m} + (X_{i,j} - 1) \\cdot T,\\quad i = 1,2, \\ldots ,\\chi ,\\;j = 1,2, \\ldots ,\\chi ,\\;m = 1,2, \\ldots ,M$$ (7) $$C_{{\\omega_{c} }} \\ge C_{j,M} + A_{{\\omega_{c} }} ,\\quad c = 1,2, \\ldots ,\\beta ,\\;j = z_{l - 1} + 1, \\ldots ,z_{l}$$ (8) $$C_{{\\omega_{c} }} \\ge C_{{\\omega_{{c^{\\prime } }} }} + A_{{\\omega_{c} }} + (Z_{{c,c^{\\prime } }} - 1) \\cdot T,\\quad c = 1,2, \\ldots ,\\beta ,\\;c^{\\prime } = 1,2, \\ldots ,\\beta ,\\;c \\ne c^{\\prime }$$ (9) $$C_{{\\Delta_{p} }} \\ge C_{{\\omega_{c} }} + A_{{\\Delta_{p} }} ,\\quad p = 1,2, \\ldots ,\\alpha ,\\;c = k_{p - 1} + 1, \\ldots ,k_{p}$$ (10) $$C_{{\\Delta_{p} }} \\ge C_{{\\Delta_{{p^{\\prime } }} }} + A_{{\\Delta_{p} }} + (H_{{p,p^{\\prime } }} - 1) \\cdot T,\\;p = 1,2, \\ldots ,\\alpha ,\\;p^{\\prime } = 1,2, \\ldots ,\\alpha ,\\;p \\ne p^{\\prime }$$ (11) $$C_{\\max } \\ge C_{{\\Delta_{p} }} ,\\quad p = 1,2, \\ldots ,\\alpha$$ (12) $$Xi,j \\in \\left\\{ {0,1} \\right\\},\\quad \\forall i,j,i \\ne j$$ (13) $$Y_{c,f} \\in \\left\\{ {0,1} \\right\\},\\quad \\forall c,f$$ (14) $$Z_{{c,c^{\\prime } }} \\in \\left\\{ {0,1} \\right\\}\\quad \\forall c,c^{\\prime } ,c \\ne c^{\\prime }$$ (15) $$H_{{p,p^{\\prime } }} \\in \\left\\{ {0,1} \\right\\},\\;\\forall p,p^{\\prime } ,p \\ne p^{\\prime } .$$ (16) Formulation (1) illustrates the objective is minimizing the makespan of all products. Constraint sets (2) and (3) mandate that every part has only one immediate successor and one immediate predecessor. Constraint set (4) ensures that each component must be assigned to only one factory. Constraint set (5) enforces that the parts belonging to the same component should be processed in succession and cannot be separated. Constraint set (6) makes sure that a part cannot start until the previous operation is completed. Constraint set (7) indicates that one machine can only process a part at a time. Constraint set (8) guarantees that the assembly operation of a component can only be started after all parts belonging to it are completed. Constraint set (9) enforces that the assembly machine cannot assemble two components at the same time. Constraint set (10) requires that one product cannot be assembled in the final assembly factory before all the components of the product are completed. Constraint set (11) indicates that the final assembly factory cannot assemble two products at a time. Constraint set (12) defines the makespan of all products. Constraint sets (13)-(16) define the domain of decision variables. An illustrative example Sequence-based variables are used with a set of min {F, \u03b1, \u03b2}\u2009+\u20091 dummy parts. Consider an example with \\(F = 2\\), \\(M = 2\\), \\(\\alpha = 3\\), \\(\\beta = 6\\), \\(\\chi = 12\\), \\(\\Lambda_{1} = \\{ 1,2\\}\\), \\(\\Lambda_{2} = \\{ 3,4\\}\\), \\(\\Lambda_{3} = \\{ 5,6\\}\\), \\(\\delta_{1} = \\{ 1,2\\}\\), \\(\\delta_{2} = \\{ 3,4\\}\\), \\(\\delta_{3} = \\{ 5,6\\}\\), \\(\\delta_{4} = \\{ 7,8\\}\\), \\(\\delta_{5} = \\{ 9,10\\}\\), \\(\\delta_{6} = \\{ 11,12\\}\\). The processing time of products, components and parts are shown in Table 1. One feasible solution is X0,1\u2009=\u2009X1,2\u2009=\u2009X2,3\u2009=\u2009X3,4\u2009=\u2009X4,5\u2009=\u2009X5,6\u2009=\u2009X6,0\u2009=\u2009X0,7\u2009=\u2009X7,8\u2009=\u2009X8,9\u2009=\u2009X9,10\u2009=\u2009X10,11\u2009=\u2009X11,12\u2009=\u2009X12,0\u2009=\u20091, where 0 is the dummy part. The part sequence is {0, 1, 2, 3, 4, 5, 6, 0, 7, 8, 9, 10, 11,12, 0}, where the part sequence {1, 2, 3, 4, 5, 6} and {7, 8, 9, 10, 11,12} are assigned to the factory 1 and 2, respectively. Then the component processing sequence is {1, 2, 3} and {4, 5, 6} in the factory 1 and 2, respectively. Finally, the finished components are transported to the assembly factory to be assembled into products. In the assembly factory, product sequence is {1, 3, 2} and the makespan of the example is 38 (see in Fig. 2). Table 1 Processing time for all parts, components and products. Full size table Figure 2 Gantt chart of the example. Full size image The canonical SSO algorithm The concept and theory of the social spider optimization algorithm was developed by Cuevas and Cienfuegos44 which mathematically models the behaviour of social spiders. The validity of SSO has been proved in many different optimization problems45,46,47. The search space of SSO is regarded as a communal web. Social spiders use the communal web as a communication media to perform cooperative behavior48, such as mating, prey capturing and social contact49. Different from most of existing swarm algorithms, the SSO divides the social spider population into two different groups: the female group and the male group. According to gender, each social spider is executed by a different set of evolution operators. Moreover, SSO adopts mating operator to exchange information among two groups and produce offspring. These operators enhance the search ability of SSO to find the optimal solution. In this way, the SSO can avoid premature convergence and keep the balance between exploration and exploitation. The proposed three social spider optimization algorithms The canonical SSO cannot be used directly for discrete optimization problem because it is designed to solve continuous optimization problem. Therefore, this section presents three discrete SSO algorithms for the proposed DAPFSP in this paper. We first introduce the solution representation, the initialization method, cooperative operators, three neighborhood operators, three local search methods, two restart producers, and present three discrete SSO algorithms in detail. Solution representation Solution representation is an important part in the design of scheduling algorithms. We design a three-level representation for the DAPFSP presented in this paper. The representation includes three parts: a product sequence, \\(\\alpha\\) component sequences and \\(\\beta\\) part sequences. The product sequence \\(\\pi\\) introduce the processing sequence of all the products in the assembly factory. In components manufacturing factories, the components belonging to products are assigned according to the product sequence. In other words, the components of the first product in the sequence are assigned first. And then, the components belonging to the second product in the sequence are considered. The part sequence of a component is a permutation of all the parts belonging to the component. Suppose a solution s, its product sequence can be expressed as \\(\\pi = \\left\\{ {\\pi_{1} ,\\pi_{2} , \\ldots ,\\pi_{\\alpha } } \\right\\}\\) (\\(\\pi_{1}\\): the first product of the product sequence). The component sequence of product \\(\\pi_{k}\\) is \\(\\Lambda_{{\\pi_{k} }} = \\{ \\Lambda_{{\\pi_{k} ,1}} ,\\Lambda_{{\\pi_{k} ,2}} , \\ldots ,\\Lambda_{{\\pi_{k} ,n_{{\\pi_{k} }} }} \\}\\), where \\(n_{{\\pi_{k} }}\\) is the number of components belonging to product \\(\\pi_{k}\\). The part sequence of component \\(\\Lambda_{{\\pi_{k} ,h}}\\) is \\(\\delta_{{\\Lambda_{{\\pi_{k} ,h}} }} = \\left\\{ {\\delta_{{\\Lambda_{{\\pi_{k} ,h}} ,1}} ,\\delta_{{\\Lambda_{{\\pi_{k} ,h}} ,2}} , \\ldots ,\\delta_{{\\Lambda_{{\\pi_{k} ,h}} ,u_{{\\Lambda_{{\\pi_{k} ,h}} }} }} } \\right\\}\\), where \\(u_{{\\Lambda_{{\\pi_{k} ,h}} }}\\) is the number of parts belonging to component \\(\\Lambda_{{\\pi_{k} ,h}}\\). An illustrative example is presented in \u201cAn illustrative example\u201d section. The product sequence in the assembly factory is {1, 3, 2}. Three component sequences are \\(\\Lambda_{1} = \\{ 1,2\\}\\), \\(\\Lambda_{2} = \\{ 3,4\\}\\) and \\(\\Lambda_{3} = \\{ 5,6\\}\\). Six part sequences are \\(\\delta_{1} = \\{ 1,2\\}\\), \\(\\delta_{2} = \\{ 3,4\\}\\), \\(\\delta_{3} = \\{ 5,6\\}\\), \\(\\delta_{4} = \\{ 7,8\\}\\), \\(\\delta_{5} = \\{ 9,10\\}\\), \\(\\delta_{6} = \\{ 11,12\\}\\). Initial population The initial population has an important effect on the quality of the solution for swarm intelligence algorithms. In order to improve the quality of the initial population, there are three interdependent decisions need to be dealt with for the presented DAPFSP: (1) determination of product sequence in the assembly factory; (2) allocation of components to components manufacturing factories and determination of components sequence for each product; (3) determination of part sequence for each component. Inspired by the pioneering work of Naderi and Ruiz11, we assigned each component to the factory which has the minimum makespan among components manufacturing factories when including the component. To maintain the diversity of the population and save computation time, the product sequence and the part sequence for each component are generated randomly. Population division and weight assignation The SSO divides the social spider population (denoted as \\(S\\)) into two different groups: female spiders (denoted as \\(F\\)) and male spiders (denoted as \\(M\\)). In the social spider population, the number of female spiders (denoted as \\(N_{f}\\)) outnumber male spiders (denoted as \\(N_{m}\\)). and \\(N_{f}\\) usually make up 65\u201390% of the population size (denoted as \\(N\\)). In this paper, the female ratio is set to 70%, as in paper45. Therefore, \\(N_{f}\\) is calculated according to the following formula: $$N_{f} = \\left| {70\\% \\cdot N} \\right|$$ (17) where the mathematical symbol | | can take an integer as the number of female spiders. The number of male spiders \\(N_{m} = N - N_{f}\\). The population \\(S = \\{ s_{1} ,s_{2} , \\ldots ,s_{N} \\}\\) is composed of a set of female spiders (\\(F = \\{ f_{1} ,f_{2} , \\ldots ,f_{{N_{f} }} \\}\\)) and a set of male individuals (\\(M = \\{ m_{1} ,m_{2} , \\ldots ,m_{{N_{f} }} \\}\\)). As \\(S = F \\cup M\\),\\(S = \\{ s_{1} = f_{1} ,s_{2} = f_{2} , \\ldots ,s_{{N_{f} }} = f_{{N_{f} }} ,s_{{N_{f} + 1}} = m_{1} ,\\)\\(s_{{N_{f} + 2}} = m_{2} ,...,s_{N} = m_{{N_{m} }} \\}\\). In the proposed three SSO algorithms, the solution quality of the individual (spider) \\(i\\) is measured by a weight \\(w_{i}\\). The following equation is used to calculated the weight \\(w_{i}\\). $$w_{i} = \\frac{{worst - C_{\\max } (s_{i} )}}{worst - best + c}$$ (18-1) $$worst = \\max (C_{\\max } (s_{i} ))\\quad i \\in (1,2, \\ldots ,N)$$ (18-2) $$best = \\min (C_{\\max } (s_{i} ))\\quad i \\in (1,2, \\ldots ,N)$$ (18-3) $$c = 0.001$$ (18-4) Cooperative operators The search space of the SSO is assumed as a communal web, in which social spiders update positions. In the communal web, female and male social spiders update positions according to different cooperative operators. Female cooperative operator Female spiders have two behavior patterns for updating their positions: attraction movement and repulsion movement. The selection of the final behavior pattern for the female spider \\(f_{i}\\) is influenced by three factors: the vibration \\(V_{c,i}\\) perceived by \\(f_{i}\\) form the nearest spider (denoted as \\(s_{c}\\)) with a better weight; the vibration \\(V_{b,i}\\) perceived by \\(f_{i}\\) form the best spider (denoted as \\(s_{b}\\)) of the population; and a stochastic movement. The movement of the female spider \\(f_{i}\\) can be defined as follows: $$f_{new,i} = \\left\\{ {\\begin{array}{*{20}l} \\begin{gathered} f_{i} + r_{1} \\cdot V_{c,i} \\cdot (s_{c} - f_{i} ) + r_{2} \\cdot V_{b,i} \\hfill \\\\ \\quad \\times (s_{b} - f_{i} ) + r_{3} (r_{4} - 0.5) \\hfill \\\\ \\end{gathered} \\hfill & {r \\le PF} \\hfill \\\\ \\begin{gathered} f_{i} - r_{1} \\cdot V_{c,i} \\cdot (s_{c} - f_{i} ) - r_{2} \\cdot V_{b,i} \\hfill \\\\ \\quad \\times (s_{b} - f_{i} ) + r_{3} (r_{4} - 0.5) \\hfill \\\\ \\end{gathered} \\hfill & {r > PF} \\hfill \\\\ \\end{array} } \\right.$$ (19-1) $$V_{c,i} = w_{c} \\cdot e^{{ - \\sqrt {||s_{c} - f_{i} ||} }}$$ (19-2) $$V_{b,i} = w_{b} \\cdot e^{{ - \\sqrt {||s_{b} - f_{i} ||} }}$$ (19-3) where \\(f_{new,i}\\) is the newly generated position of the female spider \\(f_{i}\\). \\(r_{1}\\), \\(r_{2}\\), \\(r_{3}\\), \\(r_{4}\\) and \\(r_{5}\\) are five random numbers between \\(\\left[ {0,1} \\right]\\). \\(PF\\) is a threshold which determines the selection of attraction movement or repulsion movement. In this paper, \\(PF\\) is set to 0.7 for three proposed SSO algorithms. \\(w_{c}\\) and \\(w_{b}\\) are weights of the nearest spider and the best spider, respectively. The notation \\(|| \\cdot ||\\) represents the Euclidean distance. The final random item \\(r_{3} (r_{4} - 0.5)\\) donates a stochastic movement. Male cooperative operator The male spiders are divided into dominant members and non-dominant members according to weight. \\(m_{m}\\) is the male spider whose weight is the median value of the male population. A male spider with a weight greater than the median value is assigned to dominant members; otherwise, it is regarded as one non-dominant member. Dominant male spiders tend towards the nearest female member (denoted as \\(f_{n}\\)) to generate a new generation. On the contrary, non-dominant male spiders move towards the center of the male group to utilize the remaining resources. The male cooperative operator can be formulated as follows: $$m_{new,i} = \\left\\{ {\\begin{array}{*{20}l} \\begin{gathered} m_{i} + r_{1} \\cdot V_{n,i} \\cdot (f_{n} - m_{i} ) \\hfill \\\\ \\quad + r_{2} (r_{3} - 0.5) \\hfill \\\\ \\end{gathered} \\hfill & {w_{i} > w_{m} } \\hfill & {\\left( {20{\\text{-}}1} \\right)} \\hfill \\\\ {m_{i} + r_{1} \\cdot (W_{mean} - m_{i} )} \\hfill & {w_{i} \\le w_{m} } \\hfill & {\\left( {20{\\text{-}}2} \\right)} \\hfill \\\\ \\end{array} } \\right.$$ $$V_{n,i} = w_{n} \\cdot e^{{ - \\sqrt {||f_{n} - m_{i} ||} }}$$ (20-3) $$W_{mean} = \\sum\\limits_{a = 1}^{{N_{m} }} {m_{a} \\cdot w_{a} } /\\sum\\limits_{a = 1}^{{N_{m} }} {w_{a} }$$ (20-4) where \\(m_{new,i}\\) is the newly generated position of the male spider \\(m_{i}\\). \\(r_{1}\\), \\(r_{2}\\) and \\(r_{3}\\) are random numbers between \\(\\left[ {0,1} \\right]\\). \\(V_{n,i}\\) is the vibration perceived by \\(m_{i}\\) form the nearest female spider \\(f_{n}\\). \\(w_{i}\\), \\(w_{m}\\) and \\(w_{a}\\) is the weight of \\(m_{i}\\), \\(m_{m}\\) and \\(m_{a}\\), respectively. \\(W_{mean}\\) is the weighted mean of male spiders. \\(w_{n}\\) is the weight of the nearest female spider \\(f_{n}\\). The male spiders are sorted descending by their weight. The sequence after permutation is \\(M = \\{ m_{1} ,m_{2} , \\ldots ,m_{m} , \\ldots ,m_{{N_{f} }} \\}\\). The movement of dominant male spiders and non-dominant male spiders are modeled by formulas (20-1) and (20-2), respectively. Mating operator Dominant male spiders and female spiders perform mating operator in the communal web. The radius (denoted as \\(r\\)) limits the mating range of each dominant male spider. For one dominant male spider \\(m_{k}\\), it finds out a set of female spiders (denoted as \\(E_{k}\\)) within the mating range. The mating operator is performed in set \\(T_{k} = E_{k} \\cup m_{k}\\). If \\(E_{k}\\) is a non-empty set, the mating operator is executed to generate a new individual \\(m_{new}\\); otherwise, the mating operator is not performed. The radius is calculated by the following formula: $$r = \\left\\| {s_{\\max } - s_{\\min } } \\right\\| \\cdot ratio$$ (21) where \\(s_{\\max }\\) and \\(s_{\\min }\\) represent the boundary of search space. Recall the presented solution representation, there are \\(s_{\\max } = \\{ p,p - 1,p - 2, \\ldots ,1\\}\\) and \\(s_{\\min } = \\{ 1,2, \\ldots ,p\\}\\). \\(ratio \\in (0,1)\\) is a factor controlling the radius \\(r\\). If the new individual \\(m_{new}\\) is generated, compare its weight with the weight of the worst individual in the population. If the new individual \\(m_{new}\\) is better than the worst individual, the worst individual is replaced by \\(m_{new}\\), and \\(m_{new}\\) inherits the gender and index of the replaced individual. Otherwise, the new individual \\(m_{new}\\) is ignored and the population remain unchanged. Neighborhood operators and local search strategies Neighborhood operators play an important role in designing a heuristic algorithm and it can enhance the exploitation ability of the algorithm. According to the representation, there are three types of neighborhoods. The first one is based on the product sequence, the second type is based on the component sequence, the third kind is based on the part sequence. For one solution, we can shift its product sequence and keep the other two types of sequences unchanged. Shift operators are widely used in scheduling problems. A shift operator moves one element in a sequence to another location and keeps the other elements in the same position. Considering a product sequence \\(\\pi = \\left\\{ {\\pi_{1} ,\\pi_{2} , \\ldots ,\\pi_{k} ,\\pi_{k + 1} , \\ldots ,\\pi_{\\alpha } } \\right\\}\\), the first product \\(\\pi_{1}\\) can be shifted to the \\(k^{th}\\) position and generating a new sequence \\(\\pi_{new} = \\left\\{ {\\pi_{2} , \\ldots ,\\pi_{k} ,\\pi_{1} ,\\pi_{k + 1} , \\ldots ,\\pi_{\\alpha } } \\right\\}\\), while keeping the component sequence of each product and part sequence of each component unchanged. The same shift operator applies to the component-based neighborhood and part-based neighborhood. According to the presented three neighborhood operators, we design three local search strategies. The first local search strategy is designed based on the neighborhood operator of the produce sequence. For an individual \\(s_{i}\\) with a product sequence \\(\\pi = \\left\\{ {\\pi_{1} ,\\pi_{2} , \\ldots ,\\pi_{k} ,\\pi_{k + 1} , \\ldots ,\\pi_{\\alpha } } \\right\\}\\), the product \\(\\pi_{k}\\) can be inserted into \\(\\alpha - 1\\) possible positions and generate \\(\\alpha - 1\\) different neighborhood solutions. \\(s_{i}^{*}\\) is the best solution of all the \\(\\alpha - 1\\) neighborhood solutions. If \\(s_{i}^{*}\\) is better than \\(s_{i}\\), replace \\(s_{i}\\) with \\(s_{i}^{*}\\). Otherwise, \\(s_{i}\\) remains unchanged. The above process is performed for each product in the product sequence. The procedure of product-based local search strategy is presented in Algorithm 1. Product-based local search The second local search strategy is designed based on component sequences. \\(\\Lambda_{{\\pi_{k} }} = \\{ \\Lambda_{{\\pi_{k} ,1}} ,\\Lambda_{{\\pi_{k} ,2}} , \\ldots ,\\Lambda_{{\\pi_{k} ,h}} ,\\Lambda_{{\\pi_{k} ,h + 1}} , \\ldots ,\\Lambda_{{\\pi_{k} ,n_{{\\pi_{k} }} }} \\}\\) is the component sequence of product \\(\\pi_{k}\\), where \\(n_{{\\pi_{k} }}\\) is the number of components belonging to product \\(\\pi_{k}\\). The component \\(\\Lambda_{{\\pi_{k} ,h}}\\) can be inserted into \\(n_{{\\pi_{k} }} - 1\\) possible positions and produce \\(n_{{\\pi_{k} }} - 1\\) different neighborhood solutions. \\(s_{i}^{*}\\) is the best solution of all the \\(n_{{\\pi_{k} }} - 1\\) neighborhood solutions. If \\(s_{i}^{*}\\) is better than \\(s_{i}\\), replace \\(s_{i}\\) with \\(s_{i}^{*}\\). Otherwise, \\(s_{i}\\) remains unchanged. The above process is performed for each component of the product \\(\\pi_{k}\\). The procedure of component-based local search strategy is illustrated in Algorithm 2. Component-based local search The third local search strategy is designed based on part sequences. The part sequence of component \\(\\Lambda_{{\\pi_{k} ,h}}\\) is \\(\\delta_{{\\Lambda_{{\\pi_{k} ,h}} }} = \\left\\{ {\\delta_{{\\Lambda_{{\\pi_{k} ,h}} ,1}} ,\\delta_{{\\Lambda_{{\\pi_{k} ,h}} ,2}} ,...,\\delta_{{\\Lambda_{{\\pi_{k} ,h}} ,j}} ,\\delta_{{\\Lambda_{{\\pi_{k} ,h}} ,j + 1}} ,...,\\delta_{{\\Lambda_{{\\pi_{k} ,h}} ,u_{{\\Lambda_{{\\pi_{k} ,h}} }} }} } \\right\\}\\), where \\(u_{{\\Lambda_{{\\pi_{k} ,h}} }}\\) is the number of parts belonging to component \\(\\Lambda_{{\\pi_{k} ,h}}\\). The part \\(\\delta_{{\\Lambda_{{\\pi_{k} ,h}} ,j}}\\) can be inserted into \\(u_{{\\Lambda_{{\\pi_{k} ,h}} }} - 1\\) possible positions and can produce \\(u_{{\\Lambda_{{\\pi_{k} ,h}} }} - 1\\) different neighborhood solutions. \\(s_{i}^{*}\\) is the best solution of all the \\(u_{{\\Lambda_{{\\pi_{k} ,h}} }} - 1\\) neighborhood solutions. If \\(s_{i}^{*}\\) is better than \\(s_{i}\\), replace \\(s_{i}\\) with \\(s_{i}^{*}\\). Otherwise, \\(s_{i}\\) remains unchanged. The above process is performed for each part of the component \\(\\Lambda_{{\\pi_{k} ,h}}\\). The procedure of part-based local search strategy is shown in Algorithm 3. Part-based local search Restart procedure Opposition-based restart procedure In order to maintain the diversity of the population and avoid premature convergence, we introduce an opposition-based restart (OBR) procedure that combines restart procedure with opposition-based learning (OBL). The OBL was proposed by Tizhoosh50 and its effective has been proved in optimization problems51,52,53,54,55. Xu et al.56 described in detail the concept of OBL, and the process of generating opposite numbers is presented as follows. Definition 1 Let \\(x \\in [a,b]\\) be a real number. The opposite number \\(\\tilde{x}\\) can be defined by $$\\tilde{x} = a + b - x.$$ (22) Similarly, the opposite vector for a D-dimensional vector can be defined as follows: Definition 2 Let \\(X = (x_{1} ,x_{2} , \\ldots ,x_{D} )\\) be a D-dimensional vector, where \\(x_{i} \\in [a_{i} ,b_{i} ]\\), \\(i \\in 1,2,...,D\\). the opposite vector \\(\\tilde{X} = (\\tilde{x}_{1} ,\\tilde{x}_{2} , \\ldots ,\\tilde{x}_{D} )\\) can be defined by $$\\tilde{x}_{i} = a_{i} + b_{i} - x_{i} .$$ (23) For example, there is the product permutation \\(\\pi = \\{ 3,2,7,6,8,1,9,4,5\\}\\) consists of 9 products. According to the definition 2, the opposite product permutation can be calculated as \\(\\tilde{\\pi } = \\{ 7,8,3,4,2,9,1,6,5\\}\\). The minimum makespan of each iteration is stored. If the minimum is not improved in ten consecutive iterations, we adopt the following OBR procedure to increase population diversity. Step 1 Sort all spiders in the population in descending order of weight. Step 2: Take the top 10% of individuals and calculate their opposite positions based on the sequence of products. Step 3 An opposite position is accepted if the makespan is better, while a poor opposite position (denoted as \\(\\tilde{\\pi }\\)) is accepted according to the following probability \\(p_{{\\tilde{\\pi }}}\\): $$p_{{\\tilde{\\pi }}} = \\frac{{worst - C_{\\max } (\\tilde{\\pi })}}{worst - best + c}.$$ (24) Step 4 Among the remaining 90% individuals, randomly select the same number of individuals as the opposite positions, and replace the selected individuals with the opposite positions. Inverse-based restart procedure Since the permutation of components and parts is not a set of consecutive integers, the OBL cannot be used directly. For the component-based sequence and part-based sequence, we apply an inverse operation to generate new permutations. The procedure of inverse operator is shown as follows: (a) randomly select two points P1 and P2 of the permutation; (b) reverse the sequence between P1 and P2. Figure 3 presents an instance of the inverse operator. The procedure of inverse-based restart (IBR) is shown as follows: Figure 3 An example of the inverse operator. Full size image Step 1 Sort all spiders in the population in descending order of weight. Step 2 Take the top 10% of individuals and calculate their inverse neighborhoods based on the sequence of components and parts. Step 3 An inverse position is accepted if the makespan is better, while a poor inverse position (denoted as \\(\\tilde{\\pi }\\)) is accepted according to the formula (24). Step 4 Among the remaining 90% individuals, randomly select the same number of individuals as the inverse neighborhoods, and replace the selected individuals with the opposite positions. SSO with hybrid local search strategies Three local search strategies mentioned above are quite different, and they can enhance the search ability of discrete SSO. In order to make full use of the advantages of these strategies and obtain the optimal solution or the near optimal solution, we propose a hybrid SSO (HSSO for short) that adopts these strategies simultaneously. The procedure of HSSO is illustrated in Algorithm 4. HSSO HSSO with restart procedures With the evolution of HSSO, an increasing number of individuals have a tendency to converge together, so the algorithm may be trapped in local optimal. To maintain the diversity of the population and avoid premature convergence, we present the HSSO with two restart procedures (HSSOR for short). The procedure of HSSOR is shown in Algorithm 5. HSSOR HSSOR with self-adaptive selection probability Since the OBR and product-based local search strategy operate the product sequence, and a product is composed of a series of components and parts, they are beneficial to enhance the exploration ability of the algorithm. The IBR and component-based local search strategy and the part-based local search strategy are based on shifting of components and parts, so they can improve the exploitation ability of the algorithm. The OBR and product-based local search strategy are more needed in the early generations, because almost all individuals are far from the optimal solution. In the final iterations, some individuals of the population are close to the optimum solution or near optimal solutions. The IBR and component-based and part-based local search strategies are more needed. To balance exploration and exploitation, a self-adaptive selection probability (denoted as \\(P_{sa}\\)) is introduced to control the use of two restart procedures and three local search strategies. The parameter \\(P_{sa}\\) is defined by the following formula: $$P_{sa} = \\rho_{\\min } + \\frac{t}{T} \\cdot (\\rho_{\\max } - \\rho_{\\min } )$$ (25) where \\(t\\) and \\(T\\) are the current elapsed time and maximum elapsed time respectively. \\(\\rho_{\\min }\\) and \\(\\rho_{\\max }\\) are decimals between 0 and 1. The component-based and part-based local strategies are adopted with probability \\(P_{sa}\\). Otherwise, the product-based local search strategy is used. Algorithm 6 illustrates the procedure of HSSO with self-adaptive selection probability (HSSORP for short). HSSORP Experiment analyses Experimental design Since the DAPFSP presented in this paper is an extension of the innovative work of Hatami et al.12,13 and Pan et al.24, the instances of the proposed problem are extended based on the 810 large instances of Hatami et al.12. We set instances with the number of parts {100, 200, 500}, the number of machines in the production stage \\(M \\in\\){5, 10, 20}, the number of components manufacturing factories \\(F \\in\\){4, 6, 8}, the number of components \\(\\beta \\in\\){30, 40, 50}. To satisfy the assumption that each product is composed of at least two components and limit the number of instances, we assign 30 components, 40 components and 50 components to 10 products, 15 products and 20 products, respectively. For each instance, all time indexes are set to integers. The processing time of each part in different product stages is fixed to U[1, 99]. The assembly time of each component is set to U[\\(1 \\times n\\), \\(99 \\times n\\)], where \\(n\\) is the number of parts belonging to the component. The assembly time of each product in the assembly factory is set to U[\\(1 \\times n\\), \\(99 \\times n\\)], where \\(n\\) is the number of components belonging to the product. There are \\(3 \\times 3 \\times 3 \\times 3\\)\u2009=\u200981 different combinations and each combination has 10 replications. The 810 instances zip file is available. For example, the notation \u201cI_100_5 _4_30_10_1\u201d means an instance consists of 100 parts, 5 machines, 4 components manufacturing factories, 30 components and 10 products. The last number \u20181\u2019 of the notation indicates that the instance is the first one of the combination. The relative percentage deviation (RPD) is used to measure solutions obtained by different algorithms. The formula for calculating RPD is as follows: $$RPD = \\frac{{C_{\\max } - C_{best} }}{{C_{best} }} \\times 100$$ (26) where is \\(C_{\\max }\\) the makespan calculated by one algorithm, and \\(C_{best}\\) is the minimum makespan obtained by all comparing algorithms. Experimental calibration In this subsection, we calibrate the proposed three SSO variants and comparing algorithms. This study is the first work to solve the DAPFSP with the assumption that each component of the final product is composed of several parts. This kind of problem is widespread in the actual production process, especially in auto parts supply chain, but there is no published works to make comparisons. To verify the validity of the proposed three algorithms, we conduct a comparison with two excellent work on the distributed flowshop scheduling problem including CMA17 and EDA19. By incorporating the presented solution representation and the above-mentioned objective function, we adopt CMA and EDA to the proposed DAPFSP. The parameters of the algorithm affect its performance. To calibrate these five algorithms, we generate an instance for each combination randomly and employ Taguchi method57. To set parameters effectively, we conducted preliminary experiments. For the HSSORP, the population size \\(P_{s}\\), the levels of the self-adaptive selection probability \\(P_{sa}\\) (\\(\\rho_{\\min }\\)\u2013\\(\\rho_{\\max }\\)), and the parameter \\(ratio\\) of mating operator, are shown in Table 2. Table 2 Parameter values. Full size table We use C++ o code the HSSOPR in VS 2015 and the elapsed CPU time is set to \\({20} \\times \\chi \\times M\\) milliseconds. For three critical parameters, we chose the orthogonal array L16 (43) that test 16 combinations of different parameter levels. The HSSOPR runs 20 times independently for each combination on a computer with 8 Intel(R) Core (TM) i5-10210U CPU @ 1.60GHz, 8 GB RAM and Windows 10 operation system. The average RPD (aRPD) values is calculated and presented in Table 3. The parameter level trend is shown in Fig. 4. According to Fig. 4, HSSORP performs better with the following parameters: Ps\u2009=\u2009100, \\(\\rho_{\\min }\\)\u2009=\u20090.2, \\(\\rho_{\\max }\\)\u2009=\u20090.8, ratio\u2009=\u20090.6. The other four algorithms are calibrated by the same method, and Table 4 details parameters of all five algorithms. Table 3 Response values. Full size table Figure 4 Factor level trend. Full size image Table 4 Parameters of five algorithms. Full size table Computational evaluation We code all the algorithms using C++ in VS 2015 and solve the 810 instances on the above-mentioned computer. To make the experiment fair, instead of using the number of iterations as the termination condition, we let each algorithm run independently for the same time. Termination is triggered when the algorithm reaches the maximum elapsed CPU time t\u2009=\u2009\\(\\tau \\times \\chi \\times M\\) milliseconds and the parameter \\(\\tau\\) is set to is set to three values 20, 40, and 60 respectively. In the given three different termination times, each algorithm runs 20 times independently for 810 instances. The best solutions of 810 instances calculated by each algorithm can be accessed. Tables 5, 6 and 7 presents the summarized aRPD values of three terminations. Table 5 aRPD at CPU time t\u2009=\u2009\\({20} \\times \\chi \\times M\\) ms. Full size table Table 6 aRPD at CPU time t\u2009=\u2009\\({40} \\times \\chi \\times M\\) ms. Full size table Table 7 aRPD at CPU time t\u2009=\u2009\\({60} \\times \\chi \\times M\\) milliseconds. Full size table Table 5 reports the aRPD values with CPU time t\u2009=\u2009\\({20} \\times \\chi \\times M\\) milliseconds. It can be seen from the last row that HSSOR and HSSORP performs better than HSSO, which proves the effectiveness of the presented restart procedures. There is only a small difference in the performance of HSSOR and HSSORP. EDA gets the worst performance with 12.248% aRPD, which is almost 65 times that of HSSOR. This is because the search method of EDA may not be suitable for the proposed problem. CMA performs much better than EDA. Moreover, the proposed three algorithms outperform the comparison algorithms. Tables 6 and 7 present the aRPD values with CPU time t\u2009=\u2009\\({40} \\times \\chi \\times M\\) milliseconds and CPU time t\u2009=\u2009\\({60} \\times \\chi \\times M\\) milliseconds respectively. As we can see from two tables, as running time increases, our proposed algorithm can maintain a very large lead in performance. At CPU time t\u2009=\u2009\\({40} \\times \\chi \\times M\\) milliseconds, HSSOR and HSSORP are almost equal, while HSSORP outperforms HSSOR at CPU time t\u2009=\u2009\\({60} \\times \\chi \\times M\\) milliseconds. We analyze the results closely. EDA is taken out of the analysis because it is not suitable for the proposed problem. Figures 5, 6 and 7 present box plots for four comparison algorithms at three diffident CPU times. It can be clearly observed that: (1) statistically, our algorithms are much better than CMA, and this can prove that our strategies and algorithms is effective; (2) HSSOR and HSSORP is better than HSSO, and this can illustrate the effectiveness of the proposed restart procedures; (3) HSSOR is slightly better than HSSORP, and this can show that using three local search strategies simultaneously can achieve better results. Figure 5 Box plots for four comparison algorithms at CPU time t\u2009=\u2009\\({20} \\times \\chi \\times M\\) ms. Full size image Figure 6 Box plots for four comparison algorithms at CPU time t\u2009=\u2009\\({40} \\times \\chi \\times M\\) ms. Full size image Figure 7 Box plots for four comparison algorithms at CPU time t\u2009=\u2009\\({60} \\times \\chi \\times M\\) ms. Full size image In addition, five parameters including the number of parts \u03c7, the number of components \u03b2, the number of machines M, the number of factories F, and the number of products \u03b1 determine the proposed problem. We conduct data analysis to figure out the effects of these parameters on the four comparison algorithms. Figure 8 shows variation trend of aRPD for different value levels of five parameters. It can be seen from Fig. 8 that both of HSSOR and HSSORP have very slight fluctuations and small values which illustrate that both of them have excellent robustness and performance. According to the data, all values of HSSOR for each parameter are smaller than HSSORP, which indicates HSSOR is better than HSSORP. Figure 8 Variation trend of aRPD for different value levels of five parameters. Full size image Finally, to illustrate the proposed DAPFSP intuitively, Fig. 9 reports the Gantt chart of instance \u201cI_100_5_4_30_10_1\u201d with the best solution we found so far. Figure 9 Gantt chart of instance \u201cI_100_5_4_30_10_1\u201d. Full size image Conclusions In conclusion, our study makes several contributions from different perspectives: theoretical, managerial, and practical. (i) Theoretical contribution: This paper presents the first study on DAPFSP considering the intricate nature of modern supply chains, where components of one final product are manufactured by multiple companies. Our proposed problem formulation requires determining the optimal product sequence in the assembly factory, as well as the component sequence and part sequence in multiple component manufacturing factories. To address this challenge, we introduce a novel three-level representation and an initialization method, along with three local search methods to enhance the algorithm's search ability. Additionally, to prevent premature convergence, we design two restart procedures tailored to the problem's characteristics. Furthermore, we propose three discrete SSO algorithms for the proposed DAPFSP. Our experiments, calibrated using the Taguchi method, demonstrate the efficiency of these algorithms in solving the problem. (ii) Our study provides insights into the critical role of efficient scheduling in supply chain management. By addressing a crucial aspect of production processes, it partially bridges the gap between academic research and practical applications. However, it is important to acknowledge that our research does not encompass all constraints present in practical production scenarios, such as transportation costs58, production capacity constraints, setup times, machine maintenance, and rescheduling in emergencies59. These aspects are vital considerations for real-world applications and should be incorporated into future research endeavors. (iii) In the view of practical standpoint, our research sets the stage for further exploration into the integration of manufacturing processes in Industry 4.060. Moving forward, we are committed to addressing the aforementioned constraints and designing efficient scheduling algorithms that can significantly enhance production efficiency in practical settings. By focusing on the challenges encountered in real-world production environments, we aim to contribute to the advancement of manufacturing processes and facilitate the transition towards Industry 4.0. Data availability The datasets used and/or analyzed during the current study available from the corresponding author on reasonable request. References Lee, C. Y., Cheng, T. C. E. & Lin, B. M. T. Minimizing the makespan in the 3-machine assembly-type flowshop scheduling problem. Manag. Sci. 39, 616\u2013625 (1993). Article   Google Scholar   Potts, C. N., Sevast\u2019Janov, S. V. & Strusevich, V. A. The two-stage assembly scheduling problem: Complexity and approximation. Oper. Res. 43, 346\u2013355 (1995). Article   MathSciNet   Google Scholar   Koulamas, C. & Kyparisis, G. J. The three-stage assembly flowshop scheduling problem. Comput. Oper, Res. 28, 689\u2013704 (2001). Article   MathSciNet   Google Scholar   Meng, Q., Qiu, D. & Liu, Y. Two-stage assembly flow shop scheduling problem with sequence-dependent setup times. In 2023 IEEE 19th International Conference on Automation Science and Engineering (CASE) 1\u20136 (IEEE, 2023). Karabulut, K., \u00d6ztop, H., Kizilay, D., Tasgetiren, M. F. & Kandiller, L. An evolution strategy approach for the distributed permutation flowshop scheduling problem with sequence-dependent setup times. Comput. Oper. Res. 142, 105733 (2022). Article   MathSciNet   Google Scholar   Framinan, J. M. & Perez-Gonzalez, P. The 2-stage assembly flowshop scheduling problem with total completion time: Efficient constructive heuristic and metaheuristic. Comput. Oper. Res. 88, 237\u2013246 (2017). Article   MathSciNet   Google Scholar   Chung, T. P. & Chen, F. A complete immunoglobulin-based artificial immune system algorithm for two-stage assembly flowshop scheduling problem with part splitting and distinct due windows. Int. J. Prod. Res. 57(10), 3219\u20133237 (2019). Article   Google Scholar   Fernandez-Viagas, V., Talens, C. & Framinan, J. M. Assembly flowshop scheduling problem: Speed-up procedure and computational evaluation. Eur. J. Oper. Res. 299, 869\u2013882 (2022). Article   MathSciNet   Google Scholar   Yokoyama, M. & Santos, D. L. Three-stage flow-shop scheduling with assembly operations to minimize the weighted sum of product completion times. Eur. J. Oper. Res. 161(3), 754\u2013770 (2005). Article   MathSciNet   Google Scholar   Komaki, G. M., Teymourian, E., Kayvanfar, V. & Booyavi, Z. Improved discrete cuckoo optimization algorithm for the three-stage assembly flowshop scheduling problem. Comput. Ind. Eng. 105, 158\u2013173 (2017). Article   Google Scholar   Naderi, B. & Ruiz, R. The distributed permutation flowshop scheduling problem. Comput. Oper. Res. 37(4), 754\u2013768 (2010). Article   MathSciNet   Google Scholar   Hatami, S., Ruiz, R. & Andres-Romano, C. The distributed assembly permutation flowshop scheduling problem. Int. J. Prod. Res. 51(17), 5292\u20135308 (2013). Article   Google Scholar   Hatami, S., Ruiz, R. & Andr\u00e9s Romano, C. Two Simple Constructive Algorithms for the Distributed Assembly Permutation Flowshop Scheduling Problem 139\u2013145 (Springer, 2014). Google Scholar   Hatami, S., Ruiz, R. & Andr\u00e9s-Romano, C. Heuristics and metaheuristics for the distributed assembly permutation flowshop scheduling problem with sequence dependent setup times. Int. J. Prod. Econ. 169, 76\u201388 (2015). Article   Google Scholar   Li, X., Zhang, X., Yin, M. & Wang, J. A genetic algorithm for the distributed assembly permutation flowshop scheduling problem. In IEEE Congress on Evolutionary Computation (CEC) 3096\u20133101 (2015). Liu, B., Wang, K. & Zhang, R. Variable neighborhood based memetic algorithm for distributed assembly permutation flowshop. In IEEE Congress on Evolutionary Computation (CEC) 1682\u20131686 (2016). Deng, J., Wang, L., Wang, S. Y. & Zheng, X. L. A competitive memetic algorithm for the distributed two-stage assembly flow-shop scheduling problem. Int. J. Prod. Res. 54(12), 3561\u20133577 (2016). Article   Google Scholar   Lin, J. & Zhang, S. An effective hybrid biogeography-based optimization algorithm for the distributed assembly permutation flow-shop scheduling problem. Comput. Ind. Eng. 97, 128\u2013136 (2016). Article   Google Scholar   Wang, S. Y. & Wang, L. An estimation of distribution algorithm-based memetic algorithm for the distributed assembly permutation flow-shop scheduling problem. IEEE. T. SYST. MAN. CY-S. 46(1), 139\u2013149 (2015). Article   Google Scholar   Lin, J., Wang, Z. J. & Li, X. A backtracking search hyper-heuristic for the distributed assembly flowshop scheduling problem. Swarm. Evol. Comput. 36, 124\u2013135 (2017). Article   Google Scholar   Gonzalez-Neira, E. M., Ferone, D., Hatami, S. & Juan, A. A. A biased-randomized simheuristic for the distributed assembly permutation flowshop problem with stochastic processing times. Simul. Model. Pract. Th. 79, 23\u201336 (2017). Article   Google Scholar   Ruiz, R., Pan, Q. K. & Naderi, B. Iterated Greedy methods for the distributed permutation flowshop scheduling problem. Omega 83, 213\u2013222 (2019). Article   Google Scholar   Ferone, D., Hatami, S., Gonz\u00e1lez-Neira, E. M., Juan, A. A. & Festa, P. A biased-randomized iterated local search for the distributed assembly permutation flowshop problem. Int. Trans. Oper. Res. 27(3), 1368\u20131391 (2020). Article   MathSciNet   Google Scholar   Pan, Q. K., Gao, L., Xin-Yu, L. & Jose, F. M. Effective constructive heuristics and meta-heuristics for the distributed assembly permutation flowshop scheduling problem. Appl. Soft. Comput. 81, 105492 (2019). Article   Google Scholar   Sang, H. Y. et al. Effective invasive weed optimization algorithms for distributed assembly permutation flowshop problem with total flowtime criterion. Swarm. Evol. Comput. 44, 64\u201373 (2019). Article   Google Scholar   Y\u0131lmaz, B. G. & Y\u0131lmaz, \u00d6. F. Lot streaming in hybrid flowshop scheduling problem by considering equal and consistent sublots under machine capability and limited waiting time constraint. Comput Ind Eng. 173, 108745 (2022). Article   Google Scholar   Y\u0131lmaz, \u00d6. F. An integrated bi-objective U-shaped assembly line balancing and parts feeding problem: Optimization model and exact solution method. Annals of Mathematics and Artificial Intelligence. 90(7\u20139), 679\u2013696 (2022). Article   MathSciNet   Google Scholar   Chen, S. H., Chang, P. C., Cheng, T. C. E. & Zhang, Q. A self-guided genetic algorithm for permutation flowshop scheduling problems. Comput. Oper. Res. 39(7), 1450\u20131457 (2012). Article   MathSciNet   Google Scholar   Liao, C. J., Tjandradjaja, E. & Chung, T. P. An approach using particle swarm optimization and bottleneck heuristic to solve hybrid flow shop scheduling problem. Appl. Soft. Comput 12(6), 1755\u20131764 (2012). Article   Google Scholar   Liu, H., Gao, L. & Pan, Q. A hybrid particle swarm optimization with estimation of distribution algorithm for solving permutation flowshop scheduling problem. Expert. Syst. Appl. 38(4), 4348\u20134360 (2011). Article   Google Scholar   Marinakis, Y. & Marinaki, M. Particle swarm optimization with expanding neighborhood topology for the permutation flowshop scheduling problem. Soft. Comput. 17(7), 1159\u20131173 (2013). Article   Google Scholar   Pan, Q. K., Wang, L., Mao, K., Zhao, J. H. & Zhang, M. An effective artificial bee colony algorithm for a real-world hybrid flowshop problem in steelmaking process. IEEE. Trans. Autom. Sci. Eng. 10(2), 307\u2013322 (2012). Article   Google Scholar   Ribas, I., Companys, R. & Tort-Martorell, X. An efficient Discrete Artificial Bee Colony algorithm for the blocking flow shop problem with total flowtime minimization. Expert Syst. Appl. 42(15\u201316), 6155\u20136167 (2015). Article   Google Scholar   Gong, D., Han, Y. & Sun, J. A novel hybrid multi-objective artificial bee colony algorithm for blocking lot-streaming flow shop scheduling problems. Knowl. Based. Syst. 148, 115\u2013130 (2018). Article   Google Scholar   Vahedi Nouri, B., Fattahi, P. & Ramezanian, R. Hybrid firefly-simulated annealing algorithm for the flow shop problem with learning effects and flexible maintenance activities. Int. J. Prod. Res. 51(12), 3501\u20133515 (2013). Article   Google Scholar   Marichelvam, M. K., Prabaharan, T. & Yang, X. S. A discrete firefly algorithm for the multi-objective hybrid flowshop scheduling problems. IEEE. Trans. Evolut. Comput. 18(2), 301\u2013305 (2013). Article   Google Scholar   Komaki, G. M. & Kayvanfar, V. Grey Wolf Optimizer algorithm for the two-stage assembly flow shop scheduling problem with release time. J. Comput. Sci. 8, 109\u2013120 (2015). Article   Google Scholar   Lu, C., Gao, L., Pan, Q., Li, X. & Zheng, J. A multi-objective cellular grey wolf optimizer for hybrid flowshop scheduling problem considering noise pollution. Appl. Soft. Comput. 75, 728\u2013749 (2019). Article   Google Scholar   Abdel-Basset, M., Manogaran, G., El-Shahat, D. & Mirjalili, S. A hybrid whale optimization algorithm based on local search strategy for the permutation flow shop scheduling problem. Future. Gener. Comput. Syst. 85, 129\u2013145 (2018). Article   Google Scholar   Jiang, T., Zhang, C. & Sun, Q. M. Green job shop scheduling problem with discrete whale optimization algorithm. IEEE Access 7, 43153\u201343166 (2019). Article   Google Scholar   Jiang, T., Zhang, C., Zhu, H., Gu, J. & Deng, G. Energy-efficient scheduling for a job shop using an improved whale optimization algorithm. Mathematics 6(11), 220 (2018). Article   Google Scholar   Luan, F., Cai, Z., Wu, S., Liu, S. Q. & He, Y. Optimizing the low-carbon flexible job shop scheduling problem with discrete whale optimization algorithm. Mathematics 7(8), 688 (2019). Article   Google Scholar   Pan, Q. K. & Dong, Y. An improved migrating birds optimisation for a hybrid flowshop scheduling with total flowtime minimization. Inf. Sci. 277, 643\u2013655 (2014). Article   Google Scholar   Cuevas, E. & Cienfuegos, M. A new algorithm inspired in the behavior of the social-spider for constrained optimization. Expert Syst. Appl. 41(2), 412\u2013425 (2014). Article   Google Scholar   Klein, C. E., Segundo, E. H., Mariani, V. C. & Coelho, L. D. Modified social-spider optimization algorithm applied to electromagnetic optimization. IEEE. Trans. Magn. 52(3), 1\u20134 (2015). Article   Google Scholar   Nguyen, T. T. A high performance social spider optimization algorithm for optimal power flow solution with single objective optimization. Energy 171, 218\u2013240 (2019). Article   Google Scholar   Zhang, G. & Xing, K. Memetic social spider optimization algorithm for scheduling two-stage assembly flowshop in a distributed environment. Comput. Ind. Eng. 125, 423\u2013433 (2018). Article   Google Scholar   Salomon, M., Sponarski, C., Larocque, A. & Avil\u00e9s, L. Social organization of the colonial spider Leucauge sp. in the Neotropics: Vertical stratification within colonies. J. Arachnol. 38(3), 446\u2013451 (2010). Article   Google Scholar   Yip, E. C., Powers, K. S. & Avil\u00e9s, L. Cooperative capture of large prey solves scaling challenge faced by spider societies. Proc. Natl. Acad. Sci. 105(33), 11818\u201311822 (2008). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Tizhoosh, H. R. Opposition-based learning: A new scheme for machine intelligence, CIMCA-IAWTIC\u201906. IEEE 1, 695\u2013701 (2005). Google Scholar   Wang, H., Wu, Z., Rahnamayan, S., Liu, Y. & Ventresca, M. Enhancing particle swarm optimization using generalized opposition-based learning. Inf. Sci. 181(20), 4699\u20134714 (2011). Article   MathSciNet   Google Scholar   Abed-Alguni, B. H., Alawad, N. A., Al-Betar, M. A. & Paul, D. Opposition-based sine cosine optimizer utilizing refraction learning and variable neighborhood search for feature selection. Appl. Intell. 53(11), 13224\u201313260 (2023). Article   Google Scholar   Shekhawat, S. & Saxena, A. Development and applications of an intelligent crow search algorithm based on opposition based learning. ISA Trans. 99, 210\u2013230 (2020). Article   PubMed   Google Scholar   Hussien, A. G. & Amin, M. A self-adaptive Harris Hawks optimization algorithm with opposition-based learning and chaotic local search strategy for global optimization and feature selection. Int. J. Mach. Learn. Cybern. 13, 309\u2013336 (2022). Article   Google Scholar   Tubishat, M., Idris, N., Shuib, L., Abushariah, M. A. & Mirjalili, S. Improved Salp Swarm Algorithm based on opposition based learning and novel local search algorithm for feature selection. Expert. Syst. Appl. 145, 113122 (2020). Article   Google Scholar   Xu, Q., Wang, L., Wang, N., Hei, X. & Zhao, L. A review of opposition-based learning from 2005 to 2012. Eng. Appl. Artif. Intel. 29, 1\u201312 (2014). Article   CAS   Google Scholar   Mongomery, D. C. Design and Analysis of Experiments (Wiley, 2017). Google Scholar   Lu, C., Gao, L., Li, X., Pan, Q. & Wang, Q. Energy-efficient permutation flow shop scheduling problem using a hybrid multi-objective backtracking search algorithm. J. Clean. Prod. 144, 228\u2013238 (2017). Article   Google Scholar   He, X., Dong, S. & Zhao, N. Research on rush order insertion rescheduling problem under hybrid flow shop based on NSGA-III. Int. J. Prod. Res. 58(4), 1161\u20131177 (2020). Article   Google Scholar   Hughes, L., Dwivedi, Y. K., Rana, N. P., Williams, M. D. & Raghavan, V. Perspectives on the future of manufacturing within the Industry 4.0 era. Prod. Plan. Control 33(2\u20133), 138\u2013158 (2022). Article   Google Scholar   Download references Acknowledgements This work is supported by the following Grants: National Natural Science Foundation of China 61772321, Shandong Natural Science Foundation ZR202011020044. Author information Authors and Affiliations School of Science, Shandong Jiaotong University, Jinan, 250357, China Weiwei Zhang School of Information Science and Engineering, Shandong Normal University, Jinan, 250014, China Jianhua Hao & Fangai Liu Contributions J.H. and W.Z.: Literature review and proposed algorithm; J.H.: Implementation; J.H. and F.L.: Results and discussion. Corresponding author Correspondence to Jianhua Hao. Ethics declarations Competing interests The authors declare no competing interests. Additional information Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Rights and permissions Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. Reprints and permissions About this article Cite this article Zhang, W., Hao, J. & Liu, F. Effective social spider optimization algorithms for distributed assembly permutation flowshop scheduling problem in automobile manufacturing supply chain. Sci Rep 14, 6370 (2024). https://doi.org/10.1038/s41598-024-57044-8 Download citation Received 27 October 2023 Accepted 13 March 2024 Published 16 March 2024 DOI https://doi.org/10.1038/s41598-024-57044-8 Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Subjects Computer science Mathematics and computing Comments By submitting a comment you agree to abide by our Terms and Community Guidelines. If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate. Download PDF Sections Figures References Abstract Introduction Problem definition and formulation The canonical SSO algorithm The proposed three social spider optimization algorithms Experiment analyses Conclusions Data availability References Acknowledgements Author information Ethics declarations Additional information Rights and permissions About this article Comments Advertisement Scientific Reports (Sci Rep) ISSN 2045-2322 (online) About Nature Portfolio About us Press releases Press office Contact us Discover content Journals A-Z Articles by subject Protocol Exchange Nature Index Publishing policies Nature portfolio policies Open access Author & Researcher services Reprints & permissions Research data Language editing Scientific editing Nature Masterclasses Research Solutions Libraries & institutions Librarian service & tools Librarian portal Open research Recommend to library Advertising & partnerships Advertising Partnerships & Services Media kits Branded content Professional development Nature Careers Nature Conferences Regional websites Nature Africa Nature China Nature India Nature Italy Nature Japan Nature Korea Nature Middle East Privacy Policy Use of cookies Your privacy choices/Manage cookies Legal notice Accessibility statement Terms & Conditions Your US state privacy rights \u00a9 2024 Springer Nature Limited",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "Dynamic constitutive identification of concrete based on improved dung beetle algorithm to optimize long short-term memory model",
    "doi": "10.1038/s41598-024-56960-z",
    "description": "In order to improve the accuracy of concrete dynamic principal identification, a concrete dynamic principal identification model based on Improved Dung Beetle Algorithm (IDBO) optimized Long Short-Term Memory (LSTM) network is proposed. Firstly, the apparent stress\u2013strain curves of concrete containing damage evolution were measured by Split Hopkinson Pressure Bar (SHPB) test to decouple and separate the damage and rheology, and this system was modeled by using LSTM network. Secondly, for the problem of low convergence accuracy and easy to fall into local optimum of Dung Beetle Algorithm (DBO), the greedy lens imaging reverse learning initialization population strategy, the embedded curve adaptive weighting factor and the PID control optimal solution perturbation strategy are introduced, and the superiority of IDBO algorithm is proved through the comparison of optimization test with DBO, Harris Hawk Optimization Algorithm, Gray Wolf Algorithm, and Fruit Fly Algorithm and the combination of LSTM is built to construct the IDBO-LSTM dynamic homeostasis identification model. The final results show that the IDBO-LSTM model can recognize the concrete material damage without considering the damage; in the case of considering the damage, the IDBO-LSTM prediction curves basically match the SHPB test curves, which proves the feasibility and excellence of the proposed method.",
    "journal": "Scientific Reports",
    "authors": [
      "Li P.",
      "Zhao H.",
      "Gu J.",
      "Duan S."
    ],
    "citation_count": "0",
    "full_text": "Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Advertisement View all journals Search Log in Explore content About the journal Publish with us Sign up for alerts RSS feed nature scientific reports articles article Article Open access Published: 15 March 2024 Dynamic constitutive identification of concrete based on improved dung beetle algorithm to optimize long short-term memory model Ping Li, Haonan Zhao, Jiming Gu & Shiwei Duan  Scientific Reports  14, Article number: 6334 (2024) Cite this article 138 Accesses Metrics Abstract In order to improve the accuracy of concrete dynamic principal identification, a concrete dynamic principal identification model based on Improved Dung Beetle Algorithm (IDBO) optimized Long Short-Term Memory (LSTM) network is proposed. Firstly, the apparent stress\u2013strain curves of concrete containing damage evolution were measured by Split Hopkinson Pressure Bar (SHPB) test to decouple and separate the damage and rheology, and this system was modeled by using LSTM network. Secondly, for the problem of low convergence accuracy and easy to fall into local optimum of Dung Beetle Algorithm (DBO), the greedy lens imaging reverse learning initialization population strategy, the embedded curve adaptive weighting factor and the PID control optimal solution perturbation strategy are introduced, and the superiority of IDBO algorithm is proved through the comparison of optimization test with DBO, Harris Hawk Optimization Algorithm, Gray Wolf Algorithm, and Fruit Fly Algorithm and the combination of LSTM is built to construct the IDBO-LSTM dynamic homeostasis identification model. The final results show that the IDBO-LSTM model can recognize the concrete material damage without considering the damage; in the case of considering the damage, the IDBO-LSTM prediction curves basically match the SHPB test curves, which proves the feasibility and excellence of the proposed method. Similar content being viewed by others Physics-assisted machine learning methods for predicting the splitting tensile strength of recycled aggregate concrete Article Open access 05 June 2023 Computational prediction of workability and mechanical properties of bentonite plastic concrete using multi-expression programming Article Open access 13 March 2024 Inversion study on elastic\u2013plastic material parameters of red sandstone in uniaxial compression test Article Open access 09 December 2023 Introduction Concrete is one of the most common building materials in civil engineering, and it is the basis for building engineering to be realized. Its quality and performance will have a direct determining effect on the quality of engineering projects. During the service of engineering structures, they not only bear quasi-static loads, but also withstand shocks or explosions due to accidental accidents, such as gas explosions, terrorist attacks and explosions caused by improper operation in factories, resulting in high strain rate and high temperature environment of concrete materials in construction projects, resulting in a large number of casualties. The dynamic failure of materials is actually a process of nucleation-growing-connectivity of cross-scale cracks in materials (possibly accompanied by the closure of a few cracks), and the evolution rate of cracks is a function of time/loading rate1. At present, the study of dynamic damage of brittle concrete materials has always been a hot and difficult problem for scholars at home and abroad. The traditional concrete dynamic constitutive model is a mathematical equation in explicit function form that can reflect the performance of concrete material to a certain extent by means of macroscopic or microscopic experimental techniques and based on continuum mechanics or microscopic damage mechanics. Such as: Holmquist-Johnson\u2013Cook (HJC) model2, Taylar\u2013Chen\u2013Kuszmaul (TCK) model3, Z\u2013W\u2013T model4 and so on. In the process of establishing the dynamic constitutive model, the factors such as loading form, loading rate, temperature and damage as well as the coupling between these factors should be taken into account. Because the material parameters are difficult to determine accurately, and even some parameters (such as damage) can not be directly measured, and solving the mathematical equation is too complicated and lacks practicability. Therefore, at present, there is no constitutive model which is convenient for engineering application and can accurately and comprehensively describe the factors affecting the performance of concrete materials and the coupling effects between the factors. With the development of artificial intelligence, machine learning (ML), especially deep learning (DL) algorithm, has been widely used in damage detection, system identification and risk assessment of engineering structures5. The application of machine learning to concrete damage identification and detection can be roughly divided into two categories. One is to collect images of cracks and interface damage in concrete structures, and combine them with deep learning to detect them. For example, Song et al.6, based on the electric drive platform, proposed a method of close-range scanning to capture high-resolution panoramic images of the surface of concrete structures, adopted convolutional neural network to automatically segment panoramic cracks, and quantified panoramic cracks through crack matching and performance calculation methods. Laxman et al.7 developed an integrated CNN model based on the binary class convolutional neural network (CNN) model and combined the convolutional feature extraction layer with the regression model (RF and XGBoost) to automatically detect cracks on the concrete surface and evaluate crack depth. Jiang et al.8 used deep separable convolution, inverse residual network and linear bottleneck structure to optimize the original YOLO-v3 and SSD target detection algorithms, and the complete detection accuracy rate reached about 65%. Cui et al.9 improved YOLO-v4 by combining converter theory and proposed an MHSA-YOLOv4 target detection algorithm adapted to concrete wind erosion damage. The results show that the improved algorithm can accurately identify wind erosion damage in concrete images. The width and depth of concrete cracks can be determined by analyzing concrete images containing damage and combining with deep learning algorithm, but this method can only randomly detect the results of local crack evolution of concrete, but can not get the process of concrete crack evolution. The other is to treat the material damage identification process as a system identification problem. It is therefore possible to determine a system model that identifies the relationship between cause (input) and effect (output). For example, Sun4, Xu et al.10 studied the dynamic constitutive model of polymers at high strain rates by combining SHPB technology with BP neural networks, with or without damage evolution. Sun et al.11 defined the damage of concrete as the deterioration of compressive strength and tensile strength according to the continuum damage mechanics theory. RBF neural network was used to model the damage of concrete under different freeze\u2013thaw cycles, and the number of freeze\u2013thaw cycles, dynamic elastic modulus loss, mass loss and stress ratio were taken as input variables. Concrete damage value as output variable. It is a new way to study the dynamic mechanical properties of concrete from the perspective of system science. The constitutive response and damage evolution law of concrete under different impact loads can be identified by the constructed model according to the test data without any constitutive assumptions in advance. At present, the concrete dynamic constitutive identification model is only a single model, such as BP neural network and RBF neural network, which has the advantages of parallel processing and self-learning, but the single algorithm model is too simple in operation and the identification error is large. Long-term Short-Term Memory (LSTM)12 is a variant of Recurrent Neural networks (RNN). Mainly to solve the problem of gradient disappearance and gradient explosion in the process of long sequence training, LSTM is specially used for processing sequence data. Compared with traditional RNN structure, LSTM is time-sensitive and can learn patterns and features in time series data. A gating mechanism is introduced to better capture long-term dependencies in sequence data. Zhou et al.13 used LSTM models (LSTM, Bi-LSTM, Dense-LSTM) for time series prediction, and compared the experimental results with each other, indicating that LSTM model is one of the most advanced models for predicting time series data. Therefore, LSTM is introduced as the main model in this paper, but since the prediction accuracy of LSTM is closely related to the selection of key parameters, the selection of appropriate parameters is the key to improve the identification of concrete dynamic constitutive. Generally, empirical values alone are not enough to meet the prediction error requirements. Geng et al.14 propose an improved adaptive particle swarm optimization (IAPSO) model to optimize LSTM neural network's hyperparameters (such as time step, hidden unit, batch size and period). And applied to food safety risk analysis and early warning. Li et al.15 proposed a model to optimize LSTM neural network based on variatory mode decomposition (VMD) and improved Dung Beetle Algorithm (IDBO), and applied it to fault detection of PV array, aiming at the problems of low convergence accuracy of Dung Beetle algorithm (DBO) and easy to fall into local optimal. Levy flight strategy, T-distribution perturbation strategy and multi-population mechanism were integrated to improve DBO. In the iterative process, Levy flight strategy was used to perturb elite dung beetles and generate candidate solutions, and combined with greedy selection and elimination of poorly fit dung beetles, the local optimization ability of the algorithm was enhanced. In the later stage of iteration, the T-distribution disturbance mechanism was used to expand the search range of dung beetles, and the predation strategy of grey Wolf algorithm was combined to promote the diversity of the population and avoid falling into local extreme values, which greatly improved the global optimization ability of dung beetle optimization algorithm. Dung Beetle Optimizer (DBO) is an intelligent optimization algorithm proposed by Bo Shen et al.16 in 2022. The algorithm contains few parameters, has no special requirements for the initial setting of model parameters, and has strong universality. When dealing with complex high-dimensional optimization problems, it has the characteristics of high convergence speed, high precision and high stability. In practical application, dung beetle optimization algorithm, like other intelligent optimization algorithms, has the defect that it is easy to fall into local optimal in the late optimization period. Therefore, in view of the above problems, some scholars have improved it and applied it to different projects. Zhu et al.17 proposed a dung beetle optimization algorithm based on quantum computing and multi-strategy mixing, and introduced the best-point set strategy to initialize the population, so that the initial population distribution was more uniform. The T-distribution variation strategy based on quantum computing is used to change the global optimal solution and prevent the algorithm from falling into the local optimal. Zhou et al.18 introduced a periodic mutation mechanism into the Dung Beetle optimization algorithm to improve the optimization ability of the algorithm, and used the improved algorithm to optimize the differential integrated moving average autoregressive model to achieve the prediction of transformer vibration signals. Li et al.19 combined the chaotic initialization method with the reverse learning initial strategy to initialize the population and increase the diversity of the population. By integrating adaptive step size and convex lens imaging strategy and introducing random difference change strategy, the relationship between search diversity and convergence accuracy of the algorithm is balanced, and the convergence speed of DBO is improved. Based on the above analysis, an improved Dung Beetle Algorithm (IDBO) optimized Long short-term memory (LSTM) neural network dynamic constitutive identification model of concrete is proposed in this paper. First, the apparent stress\u2013strain curve of concrete containing damage evolution was measured by split Hopkinson pressure bar test, the damage and rheology were decouple, and the system was modeled by LSTM neural network. Secondly, based on the principle of dung beetle algorithm, improved strategies (greedy lens imaging reverse learning initializing population strategy, curve adaptive weight factor and PID control optimal solution perturbation strategy) are introduced, and their optimization performance is verified by CEC2005 test set. Finally, four LSTM hyperparameters (number of hidden units, maximum training period, initial learning rate and L2 regularization parameter) are optimized using the improved Dung Beetle algorithm. The results show that the proposed IDBO algorithm has good optimization effect and the IDBO-LSTM model has high precision in identifying concrete dynamic constitutive. Algorithm principle and improvement Dung Beetle optimization algorithm Dung Beetle Optimizer (DBO) was inspired by dung beetle behaviors such as ball rolling, dancing, foraging, stealing and reproduction16. Thus, the dung beetle population consists of rolling dung beetles, breeding dung beetles, young dung beetles, and stealing dung beetles. Rolling dung Beetle In nature, dung beetles' habit is to shape animal dung into balls, which is conducive to fast and efficient movement of dung and prevent its peers from robbing them. Dung beetles need to navigate through celestial cues (sun orientation, polarized light, etc.) as they roll to keep the dung ball rolling on a straight path. As it rolls, the beetle's position updates as, $$ \\begin{aligned} & x_{i} (t + 1) = x_{i} (t) + \\alpha \\times k \\times x_{i} (t - 1) + b \\times \\Delta x \\\\ & \\Delta x = |x_{i} (t) - X^{\\omega } | \\\\ \\end{aligned} $$ (1) In the formula, t represents the current number of iterations, \\(x_{i} (t)\\) is where the i beetle is in the t iteration. \\(\\alpha\\) is the natural coefficient and is assigned \u2212\u20091 or 1 using algorithm 1. \\(k \\in (0,0.2]\\) stands for the perturbation coefficient, set to 0.1 for a fixed value. Set the value of \\(b \\in (0,1)\\) to 0.3,\\(X^{\\omega }\\) represents the worst position in the world, \\(\\Delta x\\) is used to simulate the change of strong light. When dung beetles hit an obstacle, they usually climb onto the dung ball and \"dance\" (a series of spins and pauses) to reorient themselves and gain a new route. So the beetle's position update is, $$ x_{i} (t + 1) = x_{i} (t) + \\tan \\theta \\left| {x_{i} (t) - x_{t} (t - 1)} \\right| $$ (2) In the formula, \\(\\theta \\in [0,\\pi ]\\) is the interference Angle, when \\(\\theta = 0,\\pi /2,\\pi\\), the beetle's position does not update. \\(\\left| {x_{i} (t) - x_{i} (t - 1)} \\right|\\) is the difference between where the i beetle was on the t iteration and where it was on the t\u2009\u2212\u20091 iteration. Algorithm 1 \\(\\alpha\\) selection strategy Full size image Breeding dung beetles In order to provide a safe environment for their young, dung beetles roll their balls to a safe place to hide. Therefore, the female dung beetle's spawning zone boundary strategy is expressed as: $$ \\begin{aligned} & Lb^{*} = \\max (X^{*} \\times (1 - R),Lb) \\\\ & Ub^{*} = \\min (X^{*} \\times (1 + R),Ub) \\\\ \\end{aligned} $$ (3) In the formula, \\(X^{*}\\) represents the current local best position, \\(LB^{*}\\) and \\(Ub^{*}\\) are the lower and upper boundaries of the spawning area, respectively. \\(R = 1 - t/T_{\\max }\\),\\(T_{\\max }\\) is the maximum number of iterations, \\(Lb\\) and \\(Ub\\) represent the lower and upper bounds of the optimization problem, respectively. After identifying the spawning area, the female dung beetle chooses that area for laying eggs. Formula (3) represents the dynamic spawning area, therefore, the position update of the oosphere in the iteration process is dynamic, which is expressed as, $$ B_{i} (t + 1) = X^{*} + b_{1} \\times (B_{i} (t) - Lb^{*} ) + b_{2} \\times (B_{i} (t) - Ub^{*} ) $$ (4) In the formula, \\(B_{i} (t)\\) is the position of the i egg ball at the t iteration, \\(b_{1}\\) and \\(b_{2}\\) represent two independent random variables of \\(1 \\times D\\), \\(D\\) represents the dimension of the optimization problem. Therefore, the position of the oocytes is strictly controlled within a certain range. Breeding dung beetle position update Algorithm 2 shows. Algorithm 2 Breeding position renewal strategy of dung beetles Full size image Little dung Beetle When young dung beetles grow up after hatching eggs, they need to establish an optimal feeding area to guide them to be fed. The optimal feeding area boundary strategy is expressed as, $$ \\begin{aligned} & Lb^{b} = \\max (X^{b} \\times (1 - R),Lb) \\\\ & Ub^{b} = \\min (X^{b} \\times (1 + R),Ub) \\\\ \\end{aligned} $$ (5) In the formula, \\(X^{b}\\) represents the global optimal feeding position, \\(Lb^{b}\\) and \\(Ub^{b}\\) are the lower and upper bounds of the optimal feeding region, respectively. The beetle's position update is represented by, $$ x_{i} (t + 1) = x_{i} (t) + C_{1} \\times (x_{i} (t) - Lb^{b} ) + C_{2} \\times (x_{i} (t) - Ub^{b} ) $$ (6) In the formula,\\(x_{i} (t)\\) is where the i beetle is on the t iteration,\\(C_{1}\\) is a random number with a normal distribution, \\(C_{2} \\in (0,1)\\) is a random vector. Dung Beetle stealing There are some misbehaving dung beetles (thieving dung beetles) in the dung beetle population, stealing the fruits of other people's labor. According to formula (5), it is the optimal feeding position, so the setting is the best place for dung beetles to compete for food. During the iteration, the position of the thieving beetle is updated to, $$ x_{i} (t + 1) = X^{b} + S \\times g \\times (\\left| {x_{i} (t) - X^{*} } \\right| + \\left| {x_{i} (t) - X^{b} } \\right|) $$ (7) In the formula, \\(x_{i} (t)\\) is where the i beetle is on iteration t, \\(g\\) is a random vector of \\(1 \\times D\\)-dimension size that follows a normal distribution, \\(S\\) is constant. Improved dung beetle optimization algorithm In the optimization problem, Dung Beetle optimization algorithm (DBO) has the advantages of high precision, faster convergence and stronger stability. According to the No Free Lunch theorem20, no algorithm can perform optimally in any domain. Therefore, three DBO strengthening strategies are proposed in this section to accelerate the convergence speed and enhance the global search capability of the algorithm. IDBO enhances the optimization ability of DBO through greedy lens imaging reverse learning, fusion PID control optimal solution perturbation strategy and introduction of curve adaptive factors. The pseudo-code for the improved dung beetle optimization algorithm is shown in Algorithm 3. Greedy lens imaging reverse learning to initialize the population Ideally, a good algorithm should have the final optimal solution independent of the initial position, but for almost all random algorithms, the reality is the opposite, if the initial solution is established at the optimal position in the population, the probability of the population convergence to the optimal position is very high, and determines the convergence speed and accuracy of the future algorithm21.Therefore, based on the uniform random initialization of the population, the introduction of lens imaging reverse learning to generate new populations, and the use of greedy idea to screen new populations from the combined population according to the fitness value, is conducive to reducing the optimization time in the algorithm iteration process. The lens imaging reverse learning strategy is mathematically expressed as, $$ x_{j} (i + 1) = \\frac{{ub_{j} + lb_{j} }}{2} + \\frac{{ub_{j} + lb_{j} }}{2k} - \\frac{{x_{j} (i)}}{k} $$ (8) In the formula, \\(x_{j} (i)\\) is the ith individual of dimension j, \\(ub_{j}\\) and \\(lb_{j}\\) are the J-dimensional components of the upper and lower bounds of the decision variable, respectively. k is the scaling factor. PID control optimal solution perturbation strategy In the process of iteration, the individuals in the initial population are updated, and the diversity of the population is lost. Researchers used variation-perturbation strategies to increase population diversity to obtain more search information. For example, Guo et al.22 integrated the follower position update mechanism in Sparrow search algorithm to perturb the algorithm, and combined Cauchy-Gauss variation strategy to help the algorithm jump out of the local optimal solution. Pan et al.23 introduced adaptive Gauss-Cauchy hybrid mutation perturbation to enhance the ability of dung beetle algorithm to coordinate its local development and global exploration. Wang et al.24 proposed a decreasing control strategy for the convergence factor of disturbance index to achieve a good coordination between the exploration and development capabilities of Gray Wolf algorithm. Chen et al.25 designed a perturbation strategy for wavelet optimal solutions to improve population diversity and avoid the algorithm falling into local optimality. Vu-Huu et al.26 proposed a push-process technique to improve the effectiveness of the BA algorithm by reducing the wide distribution of the optimal global solution of its to produce an intervention in the BA algorithm, so as to achieve a true global optimal that can be exposed in several generations without many computational times. In this paper, PID control is designed to disturb the optimal solution to get new individuals, so that individuals in the population can be optimized in multiple directions, increase the diversity of the population and improve the search ability of the algorithm. PID algorithm has excellent performance in the field of control, combining proportional control, integral control and differential control, aiming at fast and stable output of setpoint27. In the fitting regression problem, the algorithm is optimized according to the value of the adaptation function. Therefore, the optimal individual is fine-tuned by PID controlling the optimal fitness function value, which helps the algorithm to jump out of the local extreme value and avoid premature maturity. The mathematical expression of PID control is: $$ u(k) = K_{p} err(k) + \\frac{{K_{p} T}}{{T_{i} }}\\sum\\limits_{n = 0}^{k} {err(n) + } \\frac{{K_{p} T_{d} }}{T}(err(k) - err(k - 1)) $$ (9) In the formula,\\(K_{p}\\) is the proportionality constant,\\(K_{i} = (K_{p} *T)/T_{i}\\) is the integral constant, \\(K_{d} = (K_{p} *T_{d} )/T\\) is a microconstant. The experiment \\(K_{p} = 0.4\\) has obtained a good result. Curve adaptive weight factor In order to better coordinate the global search and local exploration capabilities, and enhance the optimization and later development capabilities of the algorithm iteration, Cuong-Le et al.28 proposed a new cuckoo search algorithm (NMS-CS) based on the Levy flight, which uses the Levy distribution to calculate the random step size, and randomly selects the newly created functions (convex function, concave function, linear function, etc.) to control the parameters in the CS algorithm, so as to expand the search space in the early stage of algorithm iteration and improve the development ability in the late iteration stage. Inspired by the idea of inertial weighting in the improved particle swarm optimization29, this paper adds curve adaptive weights to the update formula (2) of the rolling ball dung beetle, and the weight factor is guided by the cosine function, and with the increase of the number of iterations, the curve changes similar to the cosine function (0-\u03c0 range), so the weight factor keeps decreasing slowly in the early stage of iteration, the decline rate accelerates in the middle of iteration, and slowly decreases again in the late iteration, which can ensure that the algorithm slows down the global search performance in the early stage and improves the local optimal in the later stage. The expression is, $$ w_{1} = (\\cos (\\pi \\cdot t/T_{\\max } ) + w_{\\max } )(w_{\\max } + w_{\\min } )/2 + a $$ (10) In the formula, t is the current number of iterations, \\(T_{\\max }\\) is the maximum number of iterations, a is the adjustment factor,\\(w_{\\max }\\) and \\(w_{\\min }\\) are the maximum and minimum values of the factor, respectively. In formula (2), the adaptive weight of the curve is added and modified as follows: $$ x_{i} (t + 1) = w_{1} \\times x_{i} (t) + \\tan \\theta \\left| {(1 - w_{1} ) \\times x_{i} (t) - x_{t} (t - 1)} \\right| $$ (11) Algorithm 3 IDBO pseudo-code Full size image Function optimization simulation experiment and result analysis Simulation experiment In order to test the optimization performance of IDBO algorithm, 9 benchmark test functions in CEC2005 dataset30 are selected in this paper, as shown in Table 1. There are 4 categories: unimodal problem \\(f_{1} - f_{4}\\), Basic multimodal problem \\(f_{{_{7} }} ,f_{{_{10} }}\\), Extended multimodal and hybrid composite problems \\(f_{13} ,f_{15} ,f_{20}\\). Table 1 Benchmark functions. Full size table Analysis of algorithm test results IDBO algorithm is compared with standard Dung Beetle algorithm (DBO), Grey Wolf algorithm (GWO), Firefly algorithm (FA) and Harris Eagle algorithm (HHO) to optimize test functions. In order to reduce the chance of the experiment, set the same experimental parameters, The population size of each algorithm N\u2009=\u200930, maximum number of iterations \\(T_{\\max }\\)\u2009=\u20091000. Perform 30 independent experiments on 9 test functions respectively. Figure 1 draws the fitness iteration convergence comparison curve, and evaluates and compares it by convergence speed and iteration number. The experimental results are shown in Table 2. Figure 1 Convergence curve of the test function. Full size image Table 2 Comparison of test function results. Full size table CEC2005 test set, \\(f_{1} - f_{4}\\) function structure is relatively simple, test algorithm convergence performance; The \\(f_{{_{7} }} ,f_{{_{10} }}\\) function has a local optimal solution and tests the algorithm's ability to balance global development and local exploration in the search space. Function \\(f_{13} ,f_{15}\\) and \\(f_{20}\\) tests the ability of the algorithm to deal with mixed complex problems. From Fig. 1(a\u2013d), it can be clearly seen that IDBO algorithm converges first and has a faster convergence speed as the number of iterations increases. It shows that the introduction of greedy lens imaging reverse learning to initialize the population can effectively improve the population quality and accelerate the convergence speed. From Fig. 1e, f, IDBO can quickly jump out of the local extreme solution at the early stage of iteration, so as to achieve the global optimal explanation, and the introduction of curve adaptive weight factor and PID control optimal solution perturbation strategy can help the algorithm get rid of local extrema and enhance the global optimization ability. As can be seen from Fig. 1g\u2013i, IDBO also has excellent optimization ability in dealing with mixed complex problems. It can be seen that the improved strategy of dung beetle optimization algorithm is effective. In Table 2, the IDBO algorithm and the evaluation indexes of the four algorithms are the best value, the worst value, the standard deviation and the average value respectively. By observing the optimization results in Table 2, we can see that except for \\(f_{7} ,f_{10}\\) and \\(f_{13}\\), IDBO can find theoretical optimal values in other benchmark functions. Standard DBO can find the theoretical optimal value of the \\(f_{1}\\) function, the other algorithms failed to find the theoretical optimal value. IDBO, standard DBO, and HHO have the same standard deviation on the \\(f_{1} ,f_{3}\\) function, the mean and standard deviation of IDBO optimization results on unimodal function are 0. The comprehensive performance of IDBO is obviously better than DBO, HHO, GWO and FA in terms of optimization accuracy and stability. For multi-modal functions, the optimization results of \\(f_{7}\\) function show that IDBO and HHO have similar standard deviations and average values, and their orders of magnitude are 10\u20135, respectively, while DBO, GWO and FA are 10\u20134, 10\u20134 and 10\u20132, respectively. The optimization results of \\(f_{10}\\) function show that IDBO, DBO and HHO have the same standard deviation and average value, which are 0 and 4.44E\u221216 respectively. The index values of GWO and FA are not good. In conclusion, IDBO is significantly better than the comparison algorithm in handling the balance between local exploration and global development. For the mixed composite function, the optimization results of \\(f_{13}\\) function show that the optimal value of DBO is 10\u201332, while IDBO is not good. The optimization results of function \\(f_{15}\\) and \\(f_{20}\\) show that the optimal values of the five algorithms are close to the theoretical optimal values, indicating that IDBO, DBO, HHO, GWO and FA algorithms have the ability to deal with this complex problem. Model principle and parameter optimization process Long short-term memory regression prediction model Long short-term memery (LSTM) is an improvement of recurrent neural networks (RNN), widely used in machine translation31, speech recognition32, and image description. The LSTM network structure newly establishes a memory unit with feedback connections in the direction of time, which is reflected in the addition of three gate structures, namely, forget gate, input gate and output gate. At time step t, input data is \\(x_{t}\\), Then the hidden state of the previous moment is \\(h_{t - 1}\\), and the cell state is \\(c_{t - 1}\\). The LSTM model structure is shown in Fig. 2. Figure 2 LSTM cell structure. Full size image Forgetting gate \\(f_{t}\\), control the forgetting degree of the unit state at the previous moment: $$ f_{t} = \\sigma (W_{f} x_{t} + U_{f} h_{t - 1} + b_{f} ) $$ (12) In the formula, \\(W_{f}\\) is the weight matrix of the input \\(x_{t}\\),\\(U_{f}\\) is the weight matrix of the hidden state \\(h_{t - 1}\\) at the previous time, \\(b_{f}\\) is the biased variable, \\(\\sigma\\) is the sigmoid function. Enter gate \\(i_{t}\\) to control the input of new information: $$ i_{t} = \\sigma (W_{i} x_{t} + U_{i} h_{t - 1} + b_{i} ) $$ (13) In the formula, \\(W_{i}\\) is the weight matrix of the input \\(x_{t}\\),\\(U_{i}\\) is the weight matrix of the hidden state \\(h_{t - 1}\\) at the previous time, \\(b_{i}\\) is the biased variable, \\(\\sigma\\) is the sigmoid function. Output gate A, control output degree: $$ o_{t} = \\sigma (W_{o} x_{t} + U_{o} h_{t - 1} + b_{o} ) $$ (14) In the formula, \\(W_{o}\\) is the weight matrix of the input \\(x_{t}\\),\\(U_{o}\\) is the weight matrix of the hidden state \\(h_{t - 1}\\) at the previous time, \\(b_{o}\\) is the biased variable, \\(\\sigma\\) is the sigmoid function. New cell status \\(\\tilde{c}_{t}\\), update the current cell status: $$ \\tilde{c}_{t} = \\tanh (W_{c} x_{t} + U_{c} h_{t - 1} + b_{c} ) $$ (15) In the formula, \\(W_{c}\\) is the weight matrix of the input \\(x_{t}\\),\\(U_{c}\\) is the weight matrix of the hidden state \\(h_{t - 1}\\) at the previous time, \\(b_{c}\\) is the biased variable,\\(\\tanh\\) is a hyperbolic tangent function. Calculate the cell state A at the current moment and update the hidden state S: $$ \\begin{gathered} c_{t} = f_{t} \\odot c_{t - 1} + i_{t} \\odot \\tilde{c}_{t} \\hfill \\\\ h_{t} = o_{t} \\odot \\tanh (c_{t} ) \\hfill \\\\ \\end{gathered} $$ (16) In the formula,\\(\\odot\\) stands for element-by-element product. Parameter optimization based on IDBO The objective of IDBO algorithm is to help LSTM model select appropriate parameters, which are LSTM hidden unit number, maximum training period, initial learning rate and L2 regularization parameter. So the fitness function of dung beetles is defined as, $$ fitness = \\frac{1}{N}\\sum\\limits_{i = 1}^{N} {\\left( {y_{i} - \\hat{y}_{i} } \\right)} $$ (17) In the formula, N is the number of samples, \\(\\hat{y}_{i}\\) is the predicted value for sample i, \\(y_{i}\\) is the actual value for sample i. Set the total number of dung beetles SearchAgent-n\u2009=\u200930, among them, the proportion of rolling dung beetles, laying dung beetles, small dung beetles and thieving dung beetles was 20%, 40%, 20% and 20% respectively. The maximum number of iterations Max_iter\u2009=\u200910, the number of variables dim\u2009=\u20094, and the search range of variables are determined. The parameter optimization process of LSTM model based on IDBO algorithm is shown in Fig. 3. Figure 3 Flow chart of IDBO optimizing LSTM parameters. Full size image Example analysis Data sources The data comes from a series of experiments designed by our group, and the concrete with a wide range of strength grades C40 is selected as the experimental specimen, and the newly constructed model is verified by using this experimental data. Concrete specimen preparation The test specimen is a cylinder with a diameter of 70 mm and a height of 35 mm. The cement in the concrete material composition is ordinary Portland cement with a strength grade of 42.5, the coarse aggregate is made of pebbles and gravel with a particle size of 5\u201310 mm, and the fine aggregate is made of medium coarse river sand, with a large particle size of 5 mm, a fineness modulus of 2.8\u20133.0, and a mud content of less than 1%. The admixture is polycarboxylic acid high-efficiency superplasticizer mother liquor. The mix ratio of steel fiber concrete specimens is: cement: 425 kg/m3, sand: 600 kg/m3, stone: 1132 kg/m3, water: 184 kg/m3, water reducer: 8 kg/m3, Steel fiber: 39 kg/m3. The concrete specimen is shown in Fig. 4. Figure 4 Concrete sample. Full size image Experimental results of separated Hopkinson bar (SHPB) In order to verify the accuracy of the test results, we performed 6\u201310 repeated tests for each strain rate at room temperature, and took the average of the multiple tests as the test results for the loading condition. The concrete specimen after loading is shown in Fig. 5. Figure 5 Concrete specimen after loading. Full size image recessive modulus constitutive equation of concrete material The dynamic failure of materials is a process in which different forms of micro-damage (micro-cracks, micro-voids, micro-shear bands, etc.) accumulate at a finite rate over time. The macroscopic continuous damage D is defined as follows: $$ D = \\frac{{\\sigma_{0} - \\sigma }}{{\\sigma_{0} }} $$ (18) In the formula, \\(\\sigma_{0}\\) is non-damaging material stress, \\(\\sigma\\) is the apparent stress of the damaged material. In general, material damage evolves with the rheological process, so damage D is \\(\\varepsilon\\) function of strain \\(\\varepsilon\\). However, A large number of dynamic tests show that the evolution of material damage under impact load depends on both strain and strain rate, i.e.\\(D = D\\left( {\\varepsilon ,\\dot{\\varepsilon }} \\right)\\). From a macroscopic point of view, from the perspective of systems science, the constitutive relation is equivalent to the relationship between the cause (input) and the effect (output) of a system, that is, the system identification problem. Therefore, the one-dimensional constitutive relationship of steel fiber reinforced concrete under different strain rates can be expressed as, $$ \\sigma \\left( t \\right) = f\\left[ {\\varepsilon \\left( t \\right),\\dot{\\varepsilon }\\left( t \\right)} \\right]\\varepsilon \\le \\varepsilon_{th} $$ (19) $$ \\sigma \\left( t \\right) = f\\left[ {\\varepsilon \\left( t \\right),\\dot{\\varepsilon }\\left( t \\right),D\\left( t \\right)} \\right] = f\\left[ {\\varepsilon \\left( t \\right),\\dot{\\varepsilon }\\left( t \\right),t^{ - 1} \\left( D \\right)} \\right] \\varepsilon > \\varepsilon_{th} $$ (20) In the formula, \\(\\varepsilon_{th}\\) is the damage threshold (0.75 times the peak strain), measured by the \"damage freezing method\". The damage value D cannot be directly determined in the test. Considering that the damage value D is a function of time, the inverse function of time with respect to the damage value D is taken as the damage. Experimental parameter settings See Table 3. Table 3 The main parameters of the algorithm. Full size table Analysis of simulation results In order to verify the effectiveness of the proposed concrete dynamic constitutive identification model, a steel fiber reinforced concrete specimen with a strain rate of 113.05 s\u22121 is taken as an example. The experimental data were input into the trained LSTM, DBO-LSTM, GWO-LSTM and IDBO-LSTM models for identification, and the identification results of the four models are shown in Fig. 6. Figure 6 Comparison of model identification results. Annotation*: the damage-free curve (red dashed line) is obtained by using strain and strain rate as inputs and stress as output. The damage curve (blue line) is obtained by using strain, strain rate, and time as inputs, and stress as output. Full size image As can be seen from Fig. 6, the LSTM model has the lowest recognition ability among the four constitutive recognition models. LSTM can define macroscopic continuous damage. However, after taking into account the damage data, the curve predicted by the LSTM model does not agree with the test curve, so it cannot be verified to be accurate in defining the damage. Figure 6b, c show that the LSTM model optimized with GWO or DBO has improved the accuracy of its definition of damage, and the verification ability of DBO optimization is relatively high. In Fig. 6e, within the scope of \\(\\varepsilon \\le \\varepsilon_{th}\\),the IDBO-LSTM prediction curve is in good agreement with the test curve, but after the deformation of the concrete specimen exceeds the limit of model learning, the test curve and the prediction curve deviate, and we believe that it is the occurrence of damage that causes the deviation of the curve, as shown in Fig. 6d red dotted line. After considering the damage evolution, that is, adding time as the inverse function of damage, the prediction curve of the IDBO-LSTM model is in good agreement with the test curve in the whole strain range, as shown in Fig. 6d blue underlined. In order to further verify the universality of the IDBO-LSTM model, a steel fiber reinforced concrete specimen with a strain rate of 143.13 s\u22121 was selected, and the sample test data was input into the IDBO-LSTM model, and the identification results are shown in Fig. 7. Figure 7 Identification results of specimens with a strain rate of 143.13 s\u22121. Full size image From the above identification, the continuous damage is determined as a function of strain and strain rate according to Eq. (18), in the form of the evolution of damage D with strain for different constant strain rates as shown in Fig. 8. Figure 8 Damage evolution curves. Full size image Conclusions In this paper, a concrete dynamic constitutive identification model (IDBO-LSTM identification model) based on improved dung beetle algorithm and optimized long short-term memory neural network is proposed. Based on the thermal activation damage evolution model, the damage and rheology are separated by the apparent stress\u2013strain curve of concrete with damage evolution, and the LSTM method is used to model the system. The greedy lens imaging reverse learning strategy, curve adaptive weight factor and PID control optimal solution disturbance strategy are introduced to improve the original shortcomings of the Dung Beetle algorithm, and the improved Dung Beetle algorithm is combined with LSTM method to identify the dynamic constitutive of concrete, and the conclusions are as follows: The greedy lens imaging reverse learning strategy was introduced to initialize the population, which improved the uneven position of the initial dung beetles, and the greedy idea was used to greatly reduce the optimization time in the algorithm iteration process, improve the quality of the initial population, and increase the diversity of the population. The combination of curve adaptive weight factor and PID control optimal solution disturbance strategy dynamically adjusts the balance between global development and local exploration of the algorithm, helps the algorithm quickly jump out of the local optimal value, and improves the optimization accuracy and stability of the algorithm. By combining IDBO-LSTM neural network technology with SHPB test, the constitutive response and damage evolution rate of concrete under impact load can be identified by different input and output modes according to the test data without any constitutive assumptions in advance. Ethical and informed consent for data used The data supporting the findings of this study are available within the supplementary materials. References Wang, L., Hu, S., Yang, L., Dong, X. & Wang, H. Talk about dynamic strength and damage evolution. Explos. Shocks 02, 169\u2013179. https://doi.org/10.11883/1001-1455(2017)02-019-11 (2017) (in Chinese). Article   Google Scholar   Holmquist, T. J., Johnson, G. R., & Cook, W. H. A computational constitutive model for concrete subjected to large strains high strain rates and high pressure. In Proceeding of the Fourteenth International Symposium on Ballistics. American Defense preparedness Association, Vol. 2, 591\u2013600 (1993). Taylor, L. M., Chen, E. P. & Kuszmaul, J. S. Microcrack-induced damage accumulation in brittle rock under dynamic loading. Comput. Methods Appl. Mech. Eng. 55(3), 301\u2013320 (1986). Article   ADS   Google Scholar   Sun, Z. Study on dynamic large deformation intrinsic properties and damage evolution of two PP/PA blended polymers. Ningbo Univ. https://doi.org/10.7666/d.d013942 (2005) (in Chinese). Article   Google Scholar   Mahmoudi, H., Bitaraf, M., Salkhordeh, M., & Soroushian, S. A rapid machine learning-based damage detection algorithm for identifying the extent of damage in concrete shear-wall buildings. In Structures, Vol. 47, 482\u2013499. Elsevier. https://doi.org/10.1016/j.istruc.2022.11.041(2023). Song, L., Sun, H., Liu, J., Yu, Z. & Cui, C. Automatic segmentation and quantification of global cracks in concrete structures based on deep learning. Measurement 199, 111550. https://doi.org/10.1016/j.measurement.2022.111550 (2022). Article   Google Scholar   Laxman, K. C., Tabassum, N., Ai, L., Cole, C. & Ziehl, P. Automated crack detection and crack depth prediction for reinforced concrete structures using deep learning. Constr. Build. Mater. 370, 130709. https://doi.org/10.1016/j.autcon.2021.103785 (2023). Article   Google Scholar   Jiang, Y., Pang, D. & Li, C. A deep learning approach for fast detection and classification of concrete damage. Autom. Constr. 128, 103785. https://doi.org/10.1016/j.autcon.2021.103785 (2021). Article   Google Scholar   Cui, X. et al. Deep learning for intelligent identification of concrete wind-erosion damage. Autom. Constr. 141, 104427. https://doi.org/10.1016/j.autcon.2022.104427 (2022). Article   Google Scholar   Xu, M. & Wang, L. A new method for studying the dynamic response and damage evolution of polymers at high strain rates. Mech. Mater. 38(1\u20132), 68\u201375. https://doi.org/10.1016/j.mechmat.2005.05.010 (2006). Article   Google Scholar   Sun, H. & Shang, H. Neural network study of freeze-thaw damage characteristics of concrete. J. Yantai Univ. (Nat. Sci. Eng. Ed.) 02, 147\u2013151. https://doi.org/10.13951/j.cnki.37-1213/n.2009.02.011 (2009) (in Chinese). Article   Google Scholar   Naheliya, B., Redhu, P. & Kumar, K. MFOA-Bi-LSTM: An optimized bidirectional long short-term memory model for short-term traffic flow prediction. Physica A Stat. Mech. Appl. https://doi.org/10.1016/j.physa.2023.129448 (2023). Article   Google Scholar   Zhou, L., Zhao, C., Liu, N., Yao, X. & Cheng, Z. Improved LSTM-based deep learning model for COVID-19 prediction using optimized approach. Eng. Appl. Artif. Intell. 122, 106157. https://doi.org/10.1016/j.engappai.2023.106157 (2023). Article   PubMed   PubMed Central   Google Scholar   Geng, Z. et al. Novel IAPSO-LSTM neural network for risk analysis and early warning of food safety. Expert Syst. Appl. https://doi.org/10.1016/j.eswa.2023.120747 (2023). Article   Google Scholar   Li, B., Gao, P., & Gao, Z. Improved dung beetle algorithm optimized LSTM for PV array fault diagnosis. J. Power Syst. Autom. (2023) (in Chinese). Xue, J. & Shen, B. Dung beetle optimizer: A new meta-heuristic algorithm for global optimization. J. Supercomput. 79(7), 7305\u20137336. https://doi.org/10.1007/s11227-022-04959-6 (2023). Article   Google Scholar   Zhu, F. et al. Dung beetle optimization algorithm based on quantum computing and multi-strategy fusion for solving engineering problems. Expert Syst. Appl. 236, 121219. https://doi.org/10.1016/j.eswa.2023.121219 (2024). Article   Google Scholar   Zhou, Y. et al. IDBO-ARIMA based vibration signal prediction for power transformers. J. Electron. Meas. Instrum. 08, 11\u201320. https://doi.org/10.13382/j.jemi.B2306485 (2023) (in Chinese). Article   Google Scholar   Li, Y., Sun, K., Yao, Q. & Wang, L. A dual-optimization wind speed forecasting model based on deep learning and improved dung beetle optimization algorithm. Energy 286, 129604. https://doi.org/10.1016/j.energy.2023.129604 (2024). Article   Google Scholar   Service, T. C. A no free lunch theorem for multi-objective optimization. Inf. Process. Lett. 110(21), 917\u2013923. https://doi.org/10.1016/j.ipl.2010.07.026 (2010). Article   MathSciNet   Google Scholar   Sang-To, T., Hoang-Le, M., Wahab, M. A. & Cuong-Le, T. An efficient Planet Optimization Algorithm for solving engineering problems. Sci. Rep. 12(1), 8362. https://doi.org/10.1038/s41598-022-12030-w (2022). Article   ADS   CAS   PubMed   PubMed Central   Google Scholar   Guo, Q., & Zheng, Q. Multi-strategy improved dung beetle optimization algorithm and its applications. Comput. Sci. Explor. 1\u201322 (2023). https://link.cnki.net/urlid/11.5602.tp.20231214.1754.006(in Chinese). Pan, J., Li, S., Zhou, P., Yang, G. & Lv, D. Improved sine algorithm guided dung beetle optimization algorithm. Comput. Eng. Appl. 22, 92\u2013110 (2023) (in Chinese). Google Scholar   Wang, Z. et al. Multi-strategy enhanced grey wolf algorithm for obstacle-aware WSNs coverage optimization. Ad Hoc Netw. 152, 103308. https://doi.org/10.1016/j.adhoc.2023.103308 (2024). Article   Google Scholar   Chen, M., Chen, Y., Niu, X. & Wu, Z. A multi-strategy improved gray wolf algorithm for solving global optimization problems. Electron. Meas. Technol. Abroad 11, 22\u201329. https://doi.org/10.19652/j.cnki.femt.2204260 (2022) (in Chinese). Article   Google Scholar   Vu-Huu, T., Pham-Van, S., Pham, Q. H., & Cuong-Le, T. An improved bat algorithms for optimization design of truss structures. In Structures, Vol. 47 (Elsevier, 2023) 2240\u20132258. https://doi.org/10.1016/j.istruc.2022.12.033. Das, M., Catalkaya, M., Akay, O. E. & Akpinar, E. K. Impacts of use PID control and artificial intelligence methods for solar air heater energy performance. J. Build. Eng. 65, 105809. https://doi.org/10.1016/j.jobe.2022.105809 (2023). Article   Google Scholar   Cuong-Le, T. et al. A novel version of Cuckoo search algorithm for solving optimization problems. Expert Syst. Appl. 186, 115669. https://doi.org/10.1016/j.eswa.2021.115669 (2021). Article   Google Scholar   Jiyue, E., Liu, J. & Wan, Z. A novel adaptive algorithm of particle swarm optimization based on the human social learning intelligence. Swarm Evol. Comput. 80, 101336. https://doi.org/10.1016/j.swevo.2023.101336 (2023). Article   Google Scholar   Suganthan, P. N., Hansen, N., Liang, J. J., Deb, K., Chen, Y. P., Auger, A., & Tiwari, S. Problem definitions and evaluation criteria for the CEC 2005 special session on real-parameter optimization. KanGAL report, 2005005(2005), 2005. http://www.ntu.edu.sg/home/EPNSugan/. Su, C., Huang, H., Shi, S., Jian, P. & Shi, X. Neural machine translation with Gumbel Tree-LSTM based encoder. J. Vis. Commun. Image Represent. 71, 102811. https://doi.org/10.1016/j.jvcir.2020.102811 (2020). Article   Google Scholar   Atila, O. & \u015eeng\u00fcr, A. Attention guided 3D CNN-LSTM model for accurate speech based emotion recognition. Appl. Acoust. 182, 108260. https://doi.org/10.1016/j.apacoust.2021.1082600003-682X/2021 (2021). Article   Google Scholar   Download references Acknowledgements This research was supported by the Natural Science Foundation of China (No. 12102002). Author information These authors contributed equally: Haonan Zhao, Jiming Gu and Shiwei Duan. Authors and Affiliations School of Management Science and Engineering, Anhui University of Technology, Ma\u2019anshan, 243032, China Ping Li, Haonan Zhao & Jiming Gu School of Mechanical Engineering, Anhui University of Technology, Ma\u2019anshan, 243032, China Shiwei Duan Contributions Ping Li : Conceptualization, Methodology. Haonan Zhao : Analyze data, Software, Writing-original draft. Jiming Gu : Validation. Shiwei Duan : Writing-Review and Editing. Corresponding author Correspondence to Ping Li. Ethics declarations Competing interests The authors declare no competing interests. Additional information Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Supplementary Information Supplementary Information. Rights and permissions Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. Reprints and permissions About this article Cite this article Li, P., Zhao, H., Gu, J. et al. Dynamic constitutive identification of concrete based on improved dung beetle algorithm to optimize long short-term memory model. Sci Rep 14, 6334 (2024). https://doi.org/10.1038/s41598-024-56960-z Download citation Received 11 January 2024 Accepted 13 March 2024 Published 15 March 2024 DOI https://doi.org/10.1038/s41598-024-56960-z Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Keywords Dynamic constitutive model of concrete Dung beetle optimization algorithm Long short-term memory network PID control Lens imaging reverse learning Subjects Engineering Materials science Comments By submitting a comment you agree to abide by our Terms and Community Guidelines. If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate. Download PDF Sections Figures References Abstract Introduction Algorithm principle and improvement Model principle and parameter optimization process Example analysis Conclusions References Acknowledgements Author information Ethics declarations Additional information Supplementary Information Rights and permissions About this article Comments Advertisement Scientific Reports (Sci Rep) ISSN 2045-2322 (online) About Nature Portfolio About us Press releases Press office Contact us Discover content Journals A-Z Articles by subject Protocol Exchange Nature Index Publishing policies Nature portfolio policies Open access Author & Researcher services Reprints & permissions Research data Language editing Scientific editing Nature Masterclasses Research Solutions Libraries & institutions Librarian service & tools Librarian portal Open research Recommend to library Advertising & partnerships Advertising Partnerships & Services Media kits Branded content Professional development Nature Careers Nature Conferences Regional websites Nature Africa Nature China Nature India Nature Italy Nature Japan Nature Korea Nature Middle East Privacy Policy Use of cookies Your privacy choices/Manage cookies Legal notice Accessibility statement Terms & Conditions Your US state privacy rights \u00a9 2024 Springer Nature Limited",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "Point biserial correlation symbiotic organism search nanoengineering based drug delivery for tumor diagnosis",
    "doi": "10.1038/s41598-024-55159-6",
    "description": "Nanoparticulate systems have the prospect of accounting for a new making of drug delivery systems. Nanotechnology is manifested to traverse the hurdle of both physical and biological sciences by implementing nanostructures indistinct fields of science, particularly in nano-based drug delivery. The low delivery efficiency of nanoparticles is a critical obstacle in the field of tumor diagnosis. Several nano-based drug delivery studies are focused on for tumor diagnosis. But, the nano-based drug delivery efficiency was not increased for tumor diagnosis. This work proposes a method called point biserial correlation symbiotic organism search nanoengineering-based drug delivery (PBC-SOSN). The objective and aim of the PBC-SOSN method is to achieve higher drug delivery efficiency and lesser drug delivery time for tumor diagnosis. The contribution of the PBC-SOSN is to optimized nanonengineering-based drug delivery with higher r drug delivery detection rate and smaller drug delivery error detection rate. Initially, raw data acquired from the nano-tumor dataset, and nano-drugs for glioblastoma dataset, overhead improved preprocessed samples are evolved using nano variational model decomposition-based preprocessing. After that, the preprocessed samples as input are subjected to variance analysis and point biserial correlation-based feature selection model. Finally, the preprocessed samples and features selected are subjected to symbiotic organism search nanoengineering (SOSN) to corroborate the objective. Based on these findings, point biserial correlation-based feature selection and a symbiotic organism search nanoengineering were tested for their modeling performance with a nano-tumor dataset and nano-drugs for glioblastoma dataset, finding the latter the better algorithm. Incorporated into the method is the potential to adjust the drug delivery detection rate and drug delivery error detection rate of the learned method based on selected features determined by nano variational model decomposition for efficient drug delivery.",
    "journal": "Scientific Reports",
    "authors": [
      "Shukla G.",
      "Singh S.",
      "Dhule C.",
      "Agrawal R.",
      "Saraswat S.",
      "Al-Rasheed A.",
      "Alqahtani M.S.",
      "Soufiene B.O."
    ],
    "citation_count": "0",
    "full_text": "Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Advertisement View all journals Search Log in Explore content About the journal Publish with us Sign up for alerts RSS feed nature scientific reports articles article Article Open access Published: 19 March 2024 Point biserial correlation symbiotic organism search nanoengineering based drug delivery for tumor diagnosis Garima Shukla, Sofia Singh, Chetan Dhule, Rahul Agrawal, Shipra Saraswat, Amal Al-Rasheed, Mohammed S. Alqahtani & Ben Othman Soufiene  Scientific Reports  14, Article number: 6530 (2024) Cite this article 185 Accesses 1 Altmetric Metrics Abstract Nanoparticulate systems have the prospect of accounting for a new making of drug delivery systems. Nanotechnology is manifested to traverse the hurdle of both physical and biological sciences by implementing nanostructures indistinct fields of science, particularly in nano-based drug delivery. The low delivery efficiency of nanoparticles is a critical obstacle in the field of tumor diagnosis. Several nano-based drug delivery studies are focused on for tumor diagnosis. But, the nano-based drug delivery efficiency was not increased for tumor diagnosis. This work proposes a method called point biserial correlation symbiotic organism search nanoengineering-based drug delivery (PBC-SOSN). The objective and aim of the PBC-SOSN method is to achieve higher drug delivery efficiency and lesser drug delivery time for tumor diagnosis. The contribution of the PBC-SOSN is to optimized nanonengineering-based drug delivery with higher r drug delivery detection rate and smaller drug delivery error detection rate. Initially, raw data acquired from the nano-tumor dataset, and nano-drugs for glioblastoma dataset, overhead improved preprocessed samples are evolved using nano variational model decomposition-based preprocessing. After that, the preprocessed samples as input are subjected to variance analysis and point biserial correlation-based feature selection model. Finally, the preprocessed samples and features selected are subjected to symbiotic organism search nanoengineering (SOSN) to corroborate the objective. Based on these findings, point biserial correlation-based feature selection and a symbiotic organism search nanoengineering were tested for their modeling performance with a nano-tumor dataset and nano-drugs for glioblastoma dataset, finding the latter the better algorithm. Incorporated into the method is the potential to adjust the drug delivery detection rate and drug delivery error detection rate of the learned method based on selected features determined by nano variational model decomposition for efficient drug delivery. Similar content being viewed by others Exosomal S100A4 derived from highly metastatic hepatocellular carcinoma cells promotes metastasis by activating STAT3 Article Open access 26 May 2021 Evolutionary computational platform for the automatic discovery of nanocarriers for cancer treatment Article Open access 21 September 2021 Comprehensive analysis of copper-metabolism-related genes about prognosis and immune microenvironment in osteosarcoma Article Open access 12 September 2023 Introduction There has been a boost in the prevailing methods envisaging new applications over the past few years as far as nanotechnology conceptions, materials, and mechanisms are concerned. The current study focuses on the evolution of molecular communication (MC) in nanomedicine for an extensive scope of uses. Drug delivery refers to a distinct form of drug delivery system wherein the medication is individually delivered only to its site of action and not to the target organs. A compartmental model for the Internet of Bio-Nano Things (IoBNT) was proposed in1 that in addition to the targeted wireless body area networks (BANs) represented by the target tissue, concentric efforts were also made to dispatch therapeutic medicines to a particular diseased cell. With this type of disease, the side effects were minimized to a greater extent. Also, a high-affinity legend was designed with the purpose of increasing the binding rate with the concerned receptors at the target cell surface that in turn, not only improved the delivery rate but also with minimum side effects. Despite improvement in delivery rate with minimum side effects, were not found to be sensitive towards noise due to the presence of both categorical and numerical attributes, therefore compromising the overhead involved in drug delivery. Nano-based drug delivery system is hypothesized as one of the most fascinating solutions for cancer treatment due to its low dose and side effects. Nevertheless, both active and passive drug delivery depend on systemic blood circulation and diffusion. On the other hand, in2, an ant-behavior-inspired nanonetwork was proposed. On one end, the big intelligent nanomachine acquired small intelligent nanomachines and drugs to the neighboring tumor area and on the other hand, the small intelligent nanomachines cooperated with each other to identify the most efficient route to the tumor cell for delivering the drug efficiently, therefore improving the convergence speed. Over the past few decades, nanotechnology, in specific nanoparticle manufacturing, has found a revolutionary awareness in wide areas of science. The optimal utilization of nanoparticles has made possible how drugs are delivered. Nanotechnology is contemplated as a multi-disciplinary scientific domain appertaining engineering and manufacturing techniques at molecular level. This is inferred in the recent research areas where nanotechnology\u2019s application in medicine, particularly where nanoparticles have been formulated in altering biological processes. To reduce time and cost in animal anatomy, an activity relationship based on the quantitative structure was designed in3 by providing a review of techniques and algorithms employed for predicting real-time environments. In4, another method for treating cancer employing a swarm of bioinspired nanomachines was utilized to target cancer therapy. Though accuracy was improved, the time process involved in targeting cancer therapy was not focused. By means of the swarm intelligence mechanism, accurate therapy was ensured. Also, mechanisms were introduced in5 by sustaining the drug delivery process by minimizing the dosing of patients. Despite improvement observed in drug delivery efficiency, the computational complexity involved in the overall process was not focused. As a state-of-the-art cancer therapeutics, targeted drug delivery possesses features of high significance, fewer side effects and minimum drug receptivity for patients. Nevertheless, there exist numerous disadvantages to the prevailing targeted therapies, like, few druggable targets, scalability in addressing the entire patient population, and the shortfall of substitute feedback on drug resistance in patients. In6, a review of artificial intelligence techniques in identifying anticancer targets and drug discovery was presented. However, biological barriers were not navigated. To address this aspect, a drug delivery optimization mechanism was introduced in7. Fusing nanotherapeutics and ingrained machine-learning techniques can streamline the evolution of antiviral-drug development systems by analyzing the automation process. Here, a machine learning algorithm was employed in generating graphs with predictions of provided datasets. Moreover, the Gaussian Process, a substitute to the probabilistic machine learning model8 that identified a prior over function, saved time and improved efficiency. Despite the fact that the method was proven to be computationally efficient, the drug delivery rate was not focused. Research problem Nanoparticles tumor delivery efficiency is essential for barrier in the field of cancer nanomedicine. Many nanotechnologies were designed for tumor diagnosis. Strategies on how to improve NP tumor delivery efficiency remain to be determined. However, the drug delivery efficiency was not sufficient. In addition, the relevant feature was not selected with minimum time by performing feature selection. But, it failed to consider computational or communication complexity. To address this issue, the proposed PBC-SOSN method is developed with maximum drug delivery efficiency and less computational or communication complexity. Objectives and goals of proposed PBC-SOSN To increase the drug delivery efficiency for tumor diagnosis, the proposed PBC-SOSN method is introduced. To enhance preprocessed samples with minimum communication complexity, nano variational model decomposition-based preprocessing is applied. To pick highly correlated features with less drug delivery time, variance analysis and point biserial correlation-based feature selection is utilized. To achieve higher drug delivery detection rate and smaller drug delivery error detection rate, symbiotic organism search nanoengineering-based drug delivery model is employed. Contributions of the work The contributions of the proposed PBC-SOSN method are given below. To propose a PBC-SOSN method for increasing the drug delivery efficiency in humans towards efficient tumor diagnosis by incorporating three distinct processes: preprocessing, feature extraction, and nanoengineering-based drug delivery. To design nano variational model decomposition-based preprocessing to normalize a target tumor nanoparticle and provide restricted variation by means of nano variational mode decomposition separately for categorical and numerical feature variables. To present variance analysis and point biserial correlation-based feature selection for extracting robust features via variance analysis and point biserial correlation and avoiding irrelevant features for drug delivery. The feature selection of PBC-SOSN method reduces the drug delivery time with a high accuracy rate. Finally, the symbiotic organism search nanoengineering-based drug delivery model is presented to ensure optimal drug delivery by utilizing nanoengineering formulates via symbiotic mechanism with minimal human intervention. This process enhances the drug delivery detection rate and drug delivery error detection rate in a significant manner. Extensive experimental evaluations are performed using distinct quantitative performance factors like accuracy, computational complexity, drug delivery detection rate, and drug delivery error detection rate by comparing the PBC-SOSN method with the state-of-the-art methods. The paper is organized into different parts: \u201cRelated works\u201d provides a detailed review of drug delivery systems based on nanoparticles using learning techniques. The proposed PBC-SOSN method is explained in detail in \u201cProposed methodology\u201d with the aid of algorithms and architecture diagrams. \u201cExperimental setup\u201d presents the experimental setup and detailed quantitative analysis of the experimental results with different performance metrics by making comparisons with the conventional methods. Lastly, \u201cConclusion\u201d provides the concluding remarks. Related works Conventional pharmaceutical drug delivery processes heavily depend on hit-and-miss processes that are not only said to be laborious but also found to be time-consuming process. Moreover, they are constrained by exploratory state of affairs like inflated equipment supplies, constrained experimental frameworks and empirical experience. Therefore, there necessitates a pivotal requirement in designing a novel mechanism that is efficient in terms of both time and accuracy as far as nanomaterials science is concerned. A drug delivery mechanism employing genetic artificial intelligence techniques was presented in9. Genetic kidney diseases status was discussed by using emerging technological strategies. Yet another method in cancer therapy was designed in10 based on ant behavior. Based on the application of ant behavior for targeted drug delivery improved the overall accuracy. But, it failed to determine an optimal path solution. An imaging technique employing a convolutional neural network was introduced in11 with liver cancer for targeted therapy. This type of design improved the accuracy of targeted drugs in an extensive manner. Magnetic particle imaging employing virtual field free points was presented in12 to facilitate drug delivery in an accurate manner. The magnetic force direction and magnitude controlled with aid of field free point. A reception model was designed in13 for drug delivery based on the communication between biological nanomachines. With this type of design optimal release rate of the molecule was said to be released. Over the past few years, targeted drug delivery has become a significant state-of-the-art in anticancer therapy research. However, in the case of nano-based drug delivery, a nanomachine possessing relevant anticancer drugs moves towards cancer cells and kills the cancer cells by appropriate drug release. However, with constrained space in carrying drugs, the cancer cells possess only finite receptors for finding the corresponding drugs. Hence, to effectively employ cancer drugs, in14, quantitative analysis was made in measuring and optimizing the drug release with the purpose of generating drugs in targeted drug delivery. Nevertheless, a significant amount of error was found. To reduce the error rate, a deep learning technique was applied in15 whereby focusing on the overfitting aspects, the error involved in drug delivery was reduced considerably. But more time was taken for drug delivery by using deep learning methods. In16, a thorough investigation was made in analyzing the characteristics of nanoparticle physicochemical characteristics, different tumor models, and cancer types in measuring the delivery efficiency employing learning techniques. The significance of the Internet of Nano Things (IoNT) was focused in17 with respect to drug delivery. IoNT was a recent advancement in the field of medicine and healthcare services. The development in nanotechnology was resulting in nanomanufacturing insurrection and was making an important impact, especially on healthcare and medical field along by other sectors namely the economy, social, environmental, and military-based real-time applications. In the medical field, many key challenges are included such as limited computational capabilities, limited memory storage and lack of accuracy. Disorders in the central nervous system and the issues related to focusing the drug delivery were analyzed in18. Existing methods combining machine learning (ML) into molecular dynamic simulation though improved the overall procedure. They ensured effective analysis but, however, did not have the potential to provide straight perceptions without the absolute simulation process. In19, an ML-based mechanism was introduced with the purpose of predicting solvent-accessible surface area (SASA). With this type of design, data size and computational complexity were said to be reduced in an extensive manner. In20, a hypothesis of current progress in the field of nanoparticles towards efficient drug delivery was investigated in depth. The time was minimized for cancer treatments. Innovative delivery systems are designed, usually termed smart drug delivery systems in21. The drug delivery system has been evolving very fast with time through the implementation of innovative technology. However, the designed method reduced the unnecessary cost rise of drugs. A high-grade serous ovarian cancer (HGSOC) method was proposed in22 to increase the recurrent disease and chemotherapy resistance. But the systemic toxicities were minimized by the designed method. Multiple novel drug delivery systems (NDDS) have been established in23 to improve medication bioavailability, prevent adverse impacts, and prevent drug degradation. Interacting with G protein-coupled receptors system was carried out in24 to play a major regulatory role in the development of cancer. A microfluidics-based tumor-on-a-chip (TOC) system was introduced in25 to afford a promising approach to address these challenges. Sodium alginate hydrogel was examined in26 for minimizing programmed death-ligand 1 to include elesclomol-Cu and galactose. Sensitization of tumor was enhanced for radiotherapy and immunotherapy. Mn-based cGAS-STING activation was developed in27 for increasing the sensitivity. Bone-targeted nano-delivery system was utilized in28 with higher immunotherapy. Green-synthesized Ag and Cu-doped Bismuth oxide nanoparticles were designed in29 for biomedical advancements. Proposed methodology There are numerous reasons why utilizing nanoparticles for diagnostic reasons and the evolution of drug delivery is significant and much required. One is that conventional drugs obtainable in recent years for administration are only sometimes manufactured as the optimal observation for each drug. On the other hand, each drug necessitates a more ingenious type of carrier system to improve its efficiency and safeguard them from unfavorable degradation. With this objective, after identifying the significance of nanoparticle manipulation to achieve a successful drug delivery system, in this work, a PBC-SOSN method is designed for the evolution of nano-based targeted drug delivery. The detailed description of the PBC-SOSN method is designed following the dataset description. Nano variational model decomposition-based preprocessing model Data preprocessing is crucial prior to its actual utilization. Data preprocessing refers to converting the raw data into a clean data set. The raw nano-tumor dataset is preprocessed to examine missing values and instabilities before executing it to the existing nano-based drug delivery system. In general raw data include incomplete, redundant, or noisy. By using data preprocessing methods, all these mentioned issues are resolved. Hence, in our work, the nano variational mode decomposition (NVMD)-based preprocessing model is suitable for eradicating the noise with minimum communication complexity for avoiding missing values. First, an input matrix is formulated with the raw nano-tumor dataset, nano-drugs for glioblastoma dataset and is mathematically stated as $$IV=\\left[\\begin{array}{cccc}{S}_{1}{F}_{1}& {S}_{1}{F}_{2}& \\dots & {S}_{1}{F}_{n}\\\\ {S}_{2}{F}_{1}& {S}_{2}{F}_{2}& \\dots & {S}_{2}{F}_{n}\\\\ \\dots & \\dots & \\dots & \\dots \\\\ {S}_{m}{F}_{1}& {S}_{m}{F}_{2}& \\dots & {S}_{m}{F}_{n}\\end{array}\\right]$$ (1) From Eq. (1), the input vector \u2018\\(IV\\)\u2019 matrix is formulated based on the \u2018\\(m\\)\u2019 samples and \u2018\\(n\\)\u2019 features, respectively. With the aid of the above input vector matrix, this work proposes a nano variational mode decomposition (NVMD)-based preprocessing model to normalize a target tumor nanoparticle to enhance its prediction from Physiologically based pharmaco kinetic (PBPK) model. Figure 1 shows the structure of nano variational model decomposition-based preprocessing model. Figure 1 Structure of nano variational model decomposition-based preprocessing. Full size image As illustrated in the above figure, the original target tumor nanoparticle formalized as an input vector in the preprocessing stage is decomposed into multiple intrinsic mode functions (IMFs). The normalized target tumor nanoparticle is constructed from the decomposed IMFs by eliminating missing values and instabilities. NVMD is a non-periodic decomposition model to decompose a nanoparticle into several band-limited (i.e., drug delivery efficiency\u201424 h/168 h/last sampling/maximum hours) IMFs having sparsity properties (i.e., possessing distinct cancer types \u2018\\(CT\\)\u2019). Then, with these formulates as constraints, a mode in our work to perform preprocess is modelled in terms of a sinusoid comprising time-varying phase and amplitude as given below. $$f\\left(t\\right)=\\sum_{k=1}^{K}{f}_{k}\\left(t\\right)=\\sum_{k=1}^{K}{IV}_{k}\\left(t\\right){\\beta }_{k}\\left(t\\right)$$ (2) From Eq. (2), \u2018\\(f\\left(t\\right)\\)\u2019 represents the modes obtained for different nanoparticles, each possessing different identifiers \u2018\\(ID\\)\u2019 with respect to a number of band-limited (24 h/168 h/ last sampling /maximum hours) and input vector \u2018\\({IV}_{k}\\)\u2019, respectively. Also, \u2018\\({\\alpha }_{k}\\left(t\\right)\\)\u2019 refers to the instantaneous frequency (i.e., the core material) change much slower than the non-decreasing phase \u2018\\({\\beta }_{k}\\left(t\\right)\\)\u2019 respectively (i.e., drug delivery). NVMD controls the drawbacks of1, like sensitivity toward noise. The decomposed modes are proficient in acquiring the input vector with minimal noise. Then, the restricted variation problem subject to numerical and categorical data with minimal noise is mathematically stated as $$\\underset{\\left\\{\\left({f}_{k},{\\alpha }_{k}\\right)\\right\\}}{{\\text{PS}}={\\text{min}}}\\left\\{\\sum_{k}\\left(\\partial t\\left[{\\beta }_{k}\\left(t\\right)+\\frac{j}{\\pi t}\\right]\\right)\\right\\}$$ (3) From Eq. (3), both the numerical and categorical data with minimal noise and overhead are retrieved using Hilbert transform using partial derivative with respect to different time instances \u2018\\(\\partial t\\)\u2019, respectively. The pseudo-code representation of the nano variational model decomposition-based Preprocessing is given in Algorithm 1. Algorithm 1 Nano variational model decomposition-based preprocessing. Full size image As given in Algorithm 1, a novel mechanism is introduced to split the original input vector matrix into distinct modes according to nanoparticle tumor delivery efficiency, focusing on the overhead incurred in nano-based drug delivery. With the raw data values obtained from the nano-tumor dataset and nano-drugs for glioblastoma dataset, the input vector matrix is formulated for the samples involved in the simulation process. Second, a sinusoid is formulated for each identifier according to time-varying phase and amplitude with instantaneous frequency and non-decreasing phase. Finally, both the numerical and categorical variables are subjected to restricted variation problems so that the processed (i.e., preprocessed) samples are obtained as output with minimal overhead. Variance analysis and point biserial correlation-based feature selection Feature selection mechanisms are employed in obtaining a reduced set of molecular descriptors from a high quantity of them. To be more specific, in these feature selection mechanisms, with the aid of a combinatorial optimization problem, alternative subsets of molecular descriptors are selected and measured to identify a group of descriptors (i.e., features) highly correlated with a target property (i.e., drug delivery for Tumor detection). Though the advantages of using feature selection in drug delivery were included in2, it required high computational effort to measure alternative mixtures of molecular descriptors. The proposed work utilizes the filter-based feature selection model to select the best features (i.e., subsets of molecular descriptors) from the preprocessed samples. Filtering models estimate the data subset quality by examining the inherent data features in which a single or a group of data is compared to a class label. To be more specific, the filter-based feature selection states that if a feature is valid, it can be independent of respective input data but not of class labels. Hence if a feature does not affect the class labels, then that class labels are said to be eliminated from further processing. In this work, variance analysis and point biserial correlation selection was suitable to select the highly correlated features with low drug delivery time. Figure 2 shows the variance analysis and point biserial correlation-based feature selection model structure. Figure 2 Structure of variance analysis and point biserial correlation-based feature selection. Full size image As illustrated in the above figure, the variance analysis filters out the identical features in the preprocessed samples by measuring the variances between and within class labels. This variance analysis algorithm discards the irrelevant and redundant variables with high variance. The point biserial correlation follows the variance analysis algorithm; a statistical technique employed in identifying the absolute value or higher correlated features that had a paramount influence in selecting the feature. The ratio in variance analysis indicates how strongly the \u2018\\(PS\\)\u2019 feature is associated with the class labels or the overall samples \u2018\\(N\\)\u2019. The mathematical formulate given below is utilized to measure the variance ratio \u2018\\(VA\\)\u2019 of preprocessed samples \u2018\\(PS\\)\u2019. $$VA\\left(PS\\right)=\\frac{RoVB\\left(PS\\right)}{RoVW\\left(PS\\right)}$$ (4) From Eq. (4), the variance analysis \u2018\\(VA\\)\u2019 result for the corresponding preprocessed sample is obtained by means or ratio of the variance between \u2018\\(RoVB\\)\u2019 preprocessed samples, respectively. $$RoVB\\left(PS\\right)=\\sum_{l=1}^{u}{N}_{l}\\frac{{\\left(\\left(\\sum_{j=1}^{{N}_{l}}{IV}_{ij}\\left(PS\\right)/{N}_{l}\\right)-\\left(\\sum_{l=1}^{u}\\sum_{j=1}^{{N}_{l}}{IV}_{ij}\\left(PS\\right)/\\sum_{l=1}^{u}{N}_{l}\\right)\\right)}^{2}}{BDofFree}$$ (5) From Eq. (5), the ratio of variance between processed samples \u2018\\(RoVB\\left(PS\\right)\\)\u2019 is obtained based on the number of independent features or betweenness degree of freedom \u2018\\(BDofFree\\)\u2019, respectively for the corresponding input vector matrices \u2018\\({IV}_{ij}\\)\u2019 of the preprocessed samples \u2018\\(PS\\)\u2019. In a similar manner, the ratio of variance within \u2018\\(RoVW\\)\u2019 preprocessed samples are mathematically given by $$RoVW \\left(PS\\right)=\\sum_{l=1}^{u}\\sum_{j=1}^{{N}_{l}}\\frac{{\\left({IV}_{ij}\\left(PS\\right)-\\left(\\sum_{l=1}^{u}\\sum_{j=1}^{{N}_{l}}{IV}_{ij}\\left(PS\\right)/\\sum_{l=1}^{u}{N}_{l}\\right)\\right)}^{2}}{WDofFree}$$ (6) $$Res=RoVB\\left(PS\\right). RoVW \\left(PS\\right)$$ (7) From Eq. (6), the number of withinness degree of freedom \u2018\\(WDofFree\\)\u2019. Next, highly correlated combination of descriptor subsets are measured with the obtained resultant values using point biserial correlation. From that, results of point biserial correlation expressed as, $${R}_{PB}=\\left\\{\\begin{array}{c} 1\\to targeting\\, strategy\\, with\\, active\\, state \\\\ 0\\to targeting \\,strategy \\,with \\,passive \\,state\\end{array}\\right.$$ (8) To measure \u2018\\({R}_{PB}\\)\u2019, the dichotomous molecular descriptor \u2018\\(TS\\)\u2019 (i.e., targeting strategy) has considered two values \u2018\\(1\\)\u2019 (i.e., active) and \u2018\\(0\\)\u2019 (i.e., passive) with which we split the training dataset into two groups, group 1 that received the value \u2018\\(1\\)\u2019 on \u2018\\(TS\\)\u2019 and group 2 that received the value \u2018\\(0\\)\u2019 on \u2018\\(TS\\)\u2019, then the point biserial correlation is mathematically stated as: $${FS=R}_{PB}=\\frac{{MV}_{1}-{MV}_{2}}{{SD}_{m}}\\sqrt{\\frac{{S}_{1}{S}_{2}}{{m}^{2}}}$$ (9) $${SD}_{m}=\\sqrt{\\frac{1}{m}\\sum_{i=1}^{n}{\\left({Res}_{i}-{Res}_{i}{\\prime}\\right)}^{2}}$$ (10) From Eqs. (8) and (9), \u2018\\({MV}_{1}\\)\u2019, \u2018\\({MV}_{2}\\)\u2019 represent the mean value on \u2018\\({Res}_{i}\\)\u2019 for all the molecular descriptors \u2018\\(TS\\)\u2019 (i.e., targeting strategy with active state) in group 1, and the mean value on \u2018\\({Res}_{i}\\)\u2019 for all the molecular descriptors \u2018\\(TS\\)\u2019 (i.e., targeting strategy with passive state) in group 2, respectively. In a similar manner \u2018\\({S}_{1}\\)\u2019, \u2018\\({S}_{2}\\)\u2019, and \u2018\\(m\\)\u2019 denote the number of instances in group 1, group 2, and the overall instance size, respectively. Highly correlated features are obtained with this mechanism as given in Table 1. Table 1 Highly correlated features selected. Full size table In our work, the important highly correlated features are selected by using variance analysis and point biserial correlation from the chemical structure of the molecule based on the type, core materials, targeting strategy, cancer type, tumor model and zeta potential. These molecular descriptors as a measure of drug delivery are used for tumor detection based on nano structure. The pseudo-code representation of variance analysis and point biserial correlation-based feature selection is given in Algorithm 2. Algorithm 2 Variance analysis and point biserial correlation-based feature selection. Full size image As shown in Algorithm 2, highly correlated molecular descriptors must be identified to offer several advantages in treating tumor by target-oriented drug delivery of precise medicines. With this, the convergence speed increases, reducing the drug delivery time also. Based on this objective, first, identical features are filtered out using the ratio of variances, following which highly correlated molecular descriptions possessing significant importance in drug delivery are measured via point biserial correlation, therefore corroborating the objective in terms of both time accuracy. Symbiotic organism search nanoengineering-based drug delivery model In a nano-based drug delivery system, numerous properties (i.e., features selected like TS, CT, and TM etc.) must be optimized owing to the biological hurdles they encounter when applied in tumor diagnosis. Also, these necessitate additional prominence on surging the duration of action of a drug (i.e., drug efficiency in terms of different numbers of hours) to enhance therapeutic results. A novel nano-based drug delivery should possess the advantage of delivering pharmaceutical compounds in the body as required to safely achieve its desired pharmacological effect with maximum drug delivery detection and error detection rates. Nanotechnology can enhance the treatment and diagnosis of tumor detection and ease effective drug delivery. In this work, symbiotic organism search nanoengineering-based drug delivery model is suitable for performing targeting specific cells and drugs delivery. Figure 3 shows the structure of the symbiotic organism search nanoengineering-based drug delivery model. Figure 3 Structure of symbiotic organism search nanoengineering-based drug delivery. Full size image As illustrated in Fig. 3, the symbiotic organism search-based nanoengineering mimics the symbiotic relationship between organisms or nanoparticles. Here, the set of initialized population is referred to as the ecosystem and each individual solution is called an organism or nanoparticle. The symbiotic organism search-based Nanoengineering model comprises of three steps, mutualism, commensalism, and parasitism. The ecosystem is formulated as given below. $$P=\\left[\\begin{array}{cccc}{PS}_{1}{FS}_{1}& {PS}_{1}{FS}_{2}& \\dots & {PS}_{1}{FS}_{n}\\\\ {PS}_{2}{FS}_{1}& {PS}_{2}{FS}_{2}& \\dots & {PS}_{2}{FS}_{n}\\\\ \\dots & \\dots & \\dots & \\dots \\\\ {PS}_{m}{FS}_{1}& {PS}_{m}{FS}_{2}& ...& {PS}_{m}{FS}_{n}\\end{array}\\right]$$ (11) With the above formulated ecosystem \u2018\\(P\\)\u2019 using \u2018\\(m\\)\u2019 preprocessed samples \u2018\\(PS\\)\u2019, and \u2018\\(n\\)\u2019 features selected \u2018\\(FS\\)\u2019, three distinct functions are employed to ensure precise nano-based drug delivery to the corresponding targeting specific cells for tumor diagnosis. Firstly, mutualism is performed that represents the relationship between two nanoparticles with distinct identifiers. One example is the relationship between drug delivery efficiency and targeting strategy. The benefit is mathematically stated as $${P}_{i}^{new}={P}_{i}+Round\\left(\\mathrm{0,1}\\right)*\\left({P}_{best}-MV*{BP}_{1}\\right)$$ (12) $${P}_{j}^{new}={P}_{j}+Round\\left(\\mathrm{0,1}\\right)*\\left({P}_{best}-MV*{BP}_{2}\\right)$$ (13) $$MV=\\left({P}_{i}+{P}_{j}\\right)/2$$ (14) In Eqs. (12), (13), and (14) \u2018\\({P}_{i}\\)\u2019 represents the nanoparticle of the current iteration, whereas \u2018\\({P}_{j}\\)\u2019 represents the nanoparticle selected arbitrarily from the total population or ecosystem, respectively. On the other hand, \u2018\\({BP}_{1}\\)\u2019 and \u2018\\({BP}_{2}\\)\u2019 denote the benefit points that assign a value of 0 or 1, which represents how much the nanoparticle is benefited. In addition, \u2018\\(MV\\)\u2019 represents the mutual vector that denotes the relationship between drug delivery efficiency and targeting strategy, with \u2018\\({P}_{best}\\)\u2019 denoting the fittest nanoparticle in the ecosystem for delivery. Finally, the drug delivery is updated only if the objective function of the new nanoparticle is better than that for the current nanoparticle. Second, commensalism, a relationship between two nanoparticles in which only one is benefited while the other nanoparticle is not affected, is performed. An example of commensalism is the relationship between cancer type and type of nanoparticles. It is mathematically formulated as $${P}_{i}^{new}={P}_{i}+rand\\left(-1,+1\\right)*\\left({P}_{best}-{P}_{j}\\right)$$ (15) From Eq. (15) \u2018\\({P}_{i}\\)\u2019 and \u2018\\({P}_{j}\\)\u2019 represent the cancer type and type of nanoparticles with the drug delivery being updated only when new nanoparticle is better than the old nanoparticle. Finally, parasitism represents the relationship between two nanoparticles in which one nanoparticle is benefited from while the other is affected in a negative way. An example of parasitism is the relationship between drug delivery efficiency and the type of nanoparticles. The mathematical equation of parasite vector is given by: $${P}_{par}=rand\\left(\\mathrm{0,1}\\right)*\\left(HL-LL\\right)+LL$$ (16) From Eq. (16), \u2018\\({P}_{par}\\)\u2019 represent the randomly selected nanoparticles for drug delivery only if the parasite vector is better. From the above three formulations, dynamic tumor-nanoparticle associations are learned in an optimal manner and utilized in making predictions on the significance of dosing. The pseudo-code representation of the symbiotic organism search nanoengineering-based drug delivery is given in Algorithm 3. Algorithm 3 Symbiotic organism search nanoengineering-based drug delivery. Full size image As shown in Algorithm 3, a symbiotic interaction between different nanoparticles for predicting drug-tumor model with minimal human intervention is designed for ensuring optimized drug delivery. Three functions are separately performed. Firstly, mutualism is established to model the benefits of the two nanoparticles involved in simulation. Secondly, commensalism is established to model the benefit on one nanoparticle without affecting the other. Finally, parasitism is established to model the benefit of one nanoparticle while affecting the other. In this way, optimal nanoengineering-based drug delivery is designed with good drug delivery detection rate and drug delivery error detection rate. Experimental setup The experimental evaluation of the proposed PBC-SOSN method and existing Compartmental model for IoBNT [1] and ant-behaviour-inspired nanonetwork [2] are implemented in Python. Nano-tumor dataset and Nano-Drugs for glioblastomo dataset are utilized in this work. Nano-tumor dataset is taken from https://github.com/UFPBPK/Nano-ML-AI. The nano-tumor dataset includes 14 distinct features of nanoparticles. Nano-tumor dataset comprises 376 datasets via PBPK model. The dataset covering a broad range of cancer nanomedicines was published from 2005 to 2018. Multiple features are included such as physicochemical properties of NPs [e.g., log-transformed hydrodynamic diameter (size), original value of Zeta potential (ZP), shape, core material (MAT), type of NPs (type)], tumor therapy strategies such as the targeting strategies (TS), cancer types (CT) and tumor model (TM), etc. Nano-Drugs for glioblastomo dataset are taken from https://github.com/muntisa/nano-drugs-for-glioblastoma/tree/master/datasets. The dataset is obtained by running the correspondent scripts over 800 MB. The dataset is accessed on 21 October 2021. First, the nanoparticle details are gathered from the dataset. Then the nanoparticle features are preprocessed using nano variational model decomposition-based preprocessing algorithm. Then the feature selection process is performed using variance analysis and point biserial correlation-based feature selection algorithm. Finally, symbiotic organism search nanoengineering is used for drug delivery. Table 2 lists the features and its description in the nano-tumor dataset. Table 2 List of features in nano-tumor dataset. Full size table The efficiency of drug delivery is validated by employing the PBC-SOSN method with the aid of the above features in the nano-tumor dataset. Also, the performance of the proposed PBC-SOSN method and existing methods, such as compartmental model for IoBNT [1] and ant-behaviour-inspired nanonetwork [2], are compared by measuring the performance metrics such as computational complexity, communication complexity, drug delivery detection rate and drug delivery error detection rate for different samples. Performance analysis of computational complexity Computational complexity refers to the resources required to run a nano-based data delivery method. Specific concentration is given to computation or execution time and memory storage or storage overhead requirements. The computational complexity or the nano-based drug delivery computation time is measured by: $${DD}_{time}=\\sum_{i=1}^{m}{S}_{i}*Time \\left[DD\\right]$$ (17) From Eq. (17), the computational complexity or the drug delivery times \u2018\\({DD}_{time}\\)\u2019 is measured based on the samples \u2018\\({S}_{i}\\)\u2019taken for the simulation purpose and the actual time involved in drug delivery \u2018\\(Time \\left[DD\\right]\\)\u2019. It is measured in terms of milliseconds (ms). Tables 3 and 4 lists the computation complexity obtained using Eq. (17) for three different methods, PBC-SOSN, Compartmental model for IoBNT [1], and ant-behaviour-inspired nanonetwork [2] in nano-tumor dataset and nano-drugs for glioblastomo dataset. Table 3 Nano-tumor dataset tabulation for computation complexity. Full size table Table 4 Nano-drugs for glioblastomo dataset tabulation for computation complexity. Full size table Figures 4 and 5 illustrates the graphical representation of computational complexity measured on the y-axis with different numbers of samples provided on the x-axis. The above graphical results show an increasing trend in computation complexity with the increase in the sample size since an increase in sample size causes an increase in the samples to be converted from raw data into a clean data set using all three methods. By using nano-tumor dataset, the simulations performed with 35 samples consumed 0.35 ms, 0.42 ms, and 0.45 ms each for drug delivery for three methods namely PBC-SOSN, compartmental model for IoBNT [1], and ant-behaviour-inspired nanonetwork [2] respectively. In Nano-Drugs for glioblastomo dataset, when considering 500samples as input, computation complexity performance attained by proposed PBC-SOSN is 52.25 ms whereas existing IoBNT [1] and ant-behaviour-inspired nanonetwork [2] attains 54.7 ms and 55.95 ms correspondingly. This can be attributed to the Variance Analysis and point biserial correlation-based feature selection algorithm. The variance ratio was separately obtained based on the highly correlated molecular descriptors by applying this algorithm. Next, identical features were filtered to remove similar objective features employing a ratio of variances. Next, based on the ratio of variances results, highly correlated molecular descriptions with paramount significance were obtained. The PBC-SOSN method of computational complexity involved in drug delivery reduced using Nano tumor dataset by 24% compared to Compartmental model for IoBNT [1] and 36% compared to ant-behaviour-inspired nanonetwork [2]. The PBC-SOSN method of computation complexity involved in drug delivery using Nano-Drugs for glioblastoma dataset is minimized by 4% compared to Compartmental model for IoBNT [1] and 8% compared to ant-behaviour-inspired nanonetwork [2]. Figure 4 Graphical representation of computation complexity using nano-tumor dataset. Full size image Figure 5 Graphical representation of computation complexity using nano-drugs for glioblastomodataset. Full size image Performance analysis of communication complexity Secondly, the communication complexity involved in nano-based drug delivery is measured and validated. Communication complexity refers to the memory consumed in the nano-based drug delivery system. It is mathematically given by: $${DD}_{comm}=\\sum_{i=1}^{m}{S}_{i}*Mem \\left[DD\\right]$$ (18) From Eq. (18), the communication complexity involved in drug delivery \u2018\\({DD}_{comp}\\)\u2019 is measured by taking into consideration the samples involved during simulation \u2018\\({S}_{i}\\)\u2019 and the memory consumed in the drug delivery process \u2018\\(Mem \\left[DD\\right]\\)\u2019, respectively. It is measured in kilobytes (KB). Table 5 and 6 provides the communication complexity obtained using Eq. (18) for the three different methods, PBC-SOSN, compartmental model for IoBNT [1], and ant-behaviour-inspired nanonetwork [2] in two dataset such as nano-tumor dataset and nano-drugs for glioblastomo dataset. Table 5 Nano-tumor dataset tabulation for communication complexity. Full size table Table 6 Nano-drugs for glioblastomo dataset tabulation for communication complexity. Full size table Figures 6 and 7 shows the graphical representation of communication complexity using the three methods, PBC-SOSN, compartmental model for IoBNT [1] and ant-behaviour-inspired nanonetwork [2] for two datasets. An increasing trend is observed using all three methods. Specifically, increasing the sample size causes an increase in the time-varying phase and amplitude involved in the drug delivery method, increasing the communication complexity using all three methods. In nano-tumor dataset, simulations performed with 0.015 KB, 0.023 KB and 0.028 KB using the PBC-SOSN method, compartmental model for IoBNT [1] and ant-behaviour-inspired nanonetwork [2]. With this, the overall communication complexity was observed to be 0.525 KB using the PBC-SOSN method, 0.805 KB using1, and 0.98 KB using2, respectively. In Nano-drugs for glioblastomo dataset, when considering 1000 samples as input, communication complexity performance attained by proposed PBC-SOSN is 63 ms whereas existing IoBNT [1] and ant-behaviour-inspired nanonetwork [2] attains 67 ms and 69 ms correspondingly. From the results, it is inferred that the communication complexity involved in the drug delivery between the drug and target cell was found to be comparatively better using the PBC-SOSN method compared to compartmental model for IoBNT [1] and ant-behaviour-inspired nanonetwork [2]. The improvement was due to the application of the symbiotic organism search nanoengineering-based drug delivery (PBC-SOSN) and separates the approach into preprocessing, feature selection, and nanoengineering. At first, both numerical and categorical variables were subjected to restricted variation separately by using nano variational model decomposition-based Preprocessing algorithm. Next, highly correlated molecular descriptions with paramount significance were obtained with variance analysis and point biserial correlation-based feature selection algorithm. With selected preprocessed samples and features, symbiotic organism search nanoengineering-based drug delivery employed for performing three functions that ensures optimized drug delivery. As a result, the communication complexity of PBC-SOSN method reduced using Nano-tumor dataset by 31% compared to Compartmental model for IoBNT [1] and 42% compared to behaviour-inspired nanonetwork [2], respectively. In nano-drugs for glioblastoma dataset, the communication complexity involved in drug delivery using the PBC-SOSN method is minimized by 3% compared to compartmental model for IoBNT [1] and 2% compared to behaviour-inspired nanonetwork [2]. Figure 6 Graphical representation of communication complexity using nano-tumor dataset. Full size image Figure 7 Graphical representation of communication complexity using nano-drugs for glioblastomodataset. Full size image Performance analysis of drug delivery detection rate Thirdly, the actual drug delivery detection rate is measured to analyze the effectiveness of the method in reaching the targeting strategy with minimum convergence. The drug delivery detection rate is mathematically expressed as: $$DDDR=\\sum_{i=1}^{m}\\frac{{S}_{AD}}{{S}_{i}}*100$$ (19) From Eq. (19), the drug delivery detection rate \u2018\\(DDDR\\)\u2019 is measured based on the samples involved in the simulation process \u2018\\({S}_{i}\\)\u2019 and the samples accurately delivery \u2018\\({S}_{AD}\\)\u2019. It is measured in percentage (%). Tables 7 and 8 lists the drug delivery detection rate arrived at using Eq. (18) using the three different methods for nano-tumor dataset and nano-drugs for glioblastomo dataset. Table 7 Nano-tumor dataset tabulation for drug delivery detection rate. Full size table Table 8 Nano-drugs for glioblastomo dataset tabulation for drug delivery detection rate. Full size table Figures 8 and 9 shows the drug delivery detection rate using the three methods, PBC-SOSN, compartmental model for IoBNT [1] and ant-behaviour-inspired nanonetwork [2] by considering two datasets. From the above figure, the x-axis represents the samples in the simulation process, and the y-axis denotes the actual drug delivery detection rate using the three methods. It neither is evident from the above figure that increasing the sample size neither causes an increase in the detection rate nor decreases the detection rate. This may be attributed to the fact that several nanoparticles are involved in the drug delivery process during the drug delivery detection process. This, in turn, does not show an increasing or decreasing trend using all three methods. In nano-tumor dataset, simulations performed using the three methods were observed to be 32, 31 and 30 samples were accurately delivered to the intended target with an overall improvement of 91.42%, 88.57% and 85.71% using PBC-SOSN, compartmental model for IoBNT [1] and ant-behaviour-inspired nanonetwork [2] respectively. In nano-drugs for glioblastomo dataset, when taking 500 samples as input, drug delivery detection rate performance attained by proposed PBC-SOSN is 90% whereas existing IoBNT [1] and ant-behaviour-inspired nanonetwork [2] attains 86% and 85% correspondingly. With this, the overall drug delivery detection rate was found to be better using PBC-SOSN compared to compartmental model for IoBNT [1] and ant-behaviour-inspired nanonetwork [2]. The reason was that by subjecting the symbiotic relationship between organisms or nanoparticles, three different functions were utilized towards precise nano-based drug delivery to target specific cells for tumor diagnosis. As a result, the PBC-SOSN of drug delivery detection rate was found to be better using nano-tumor dataset by 5% compared to compartmental model for IoBNT [1] and 8% compared to behaviour-inspired nanonetwork [2]. The PBC-SOSN method of drug delivery detection rate involved in drug delivery is improved using nano-drugs for glioblastoma dataset by 5% compared to compartmental model for IoBNT [1] and 3% compared to behaviour-inspired nanonetwork [2]. Figure 8 Graphical representation of drug delivery detection rate using nano-tumor dataset. Full size image Figure 9 Graphical representation of drug delivery detection rate using nano-drugs for glioblastomodataset. Full size image Performance analysis of drug delivery error detection rate Finally, in this section, the drug delivery error detection rate is measured to validate the method. The drug delivery error detection rate is mathematically given by: $$DDEDR=\\sum_{i=1}^{m}\\frac{{S}_{IAD}}{{S}_{i}}*100$$ (20) From Eq. (20), the drug delivery error detection rate \u2018\\(DDEDR\\)\u2019 is measured by taking into consideration the actual samples \u2018\\({S}_{i}\\)\u2019 and the samples inaccurately delivered \u2018\\({S}_{IAD}\\)\u2019. It is measured in percentage (%). Tables 9 and 10 lists the drug delivery detection rate arrived at using Eq. (20) for three different methods in nano-tumor dataset and nano-drugs for glioblastomo dataset. Table 9 Nano-tumor dataset tabulation for drug error detection rate. Full size table Table 10 Nano-drugs for glioblastomo dataset tabulation for drug delivery error detection rate. Full size table Finally, Figs. 10 and 11 shows the drug delivery error detection rate for three methods using nano-tumor dataset and nano-drugs for glioblastomo dataset. An increasing trend is observed using all three methods. In nano-tumor dataset, simulations performed for 35 samples showed inaccurate detection of 2, 3 and 4 samples using PBC-SOSN, the compartmental model for IoBNT [1] and ant-behaviour-inspired nanonetwork [2]. The overall drug delivery error detection rate was observed to be 5.71%, 8.57% and 11.42%, respectively. In nano-drugs for glioblastomo dataset, when taking 500 samples as input, drug delivery error detection rate performance attained by proposed PBC-SOSN is 10.42% whereas existing IoBNT [1] and ant-behaviour-inspired nanonetwork [2] attains 13.55% and 16.61% correspondingly. The reason behind the minimization of drug delivery error detection rate using the PBC-SOSN method was due to the application of symbiotic organism search nanoengineering-based drug delivery algorithm. The relationship between drug delivery efficiency and targeting strategy was obtained using mutualism, commensalism, and parasitism by applying this algorithm. The drug delivery error detection rate using the PBC-SOSN method was found to be reduced in nano-tumor dataset by 29% compared to compartmental model for IoBNT [1] and 44% compared to ant-behaviour-inspired nanonetwork [2]. By using nano-drugs for glioblastoma dataset, PBC-SOSN method of drug delivery error detection rate is minimized by 18% compared to 1 and 34% compared to 2. Figure 10 Graphical representation of drug delivery error detection rate using nano-tumor dataset. Full size image Figure 11 Graphical representation of drug delivery error detection rate using nano-drugs for glioblastomodataset. Full size image Limitations and challenges Following are existing limitations and challenges mentioned in this section: Drug delivery detection rate: specificity: in the process of using nanoparticles to target tumors, one of the challenges is attaining a drug delivery detection rate adequate for tumor cells. Researchers are examining novel targeting ligands and techniques to improve the drug delivery detection rate for tumor cells. To handle these limitations and challenges, tumor diagnosis and growth in the field of nanoparticles is required by using researchers, engineers, healthcare providers. Conclusion In this work, contributions of the PBC-SOSN are for early convergence and speed. A nano variational model decomposition-based preprocessing model is designed based on restricted variation separately for modelling numerical and categorical variables. A variance analysis and point biserial correlation-based feature selection algorithm are employed for filtering identical features and choosing highly correlated features. By employing symbiotic organism search nanoengineering, efficient nano-based drug delivery is designed. Simulation results demonstrate the efficient performance of the proposed PBC-SOSN method. The experimental outcome demonstrates the key finds of the proposed PBC-SOSN method in terms of computation complexity, communication complexity, drug delivery detection rate and drug delivery error detection rate as described as given below. Summary of key findings From the experimental results, the following key finds are achieved: Proposed PBC-SOSN method achieved higher drug delivery detection rate by 7% when compared to compartmental model for IoBNT [1], and ant-behaviour-inspired nanonetwork [2]. The proposed PBC-SOSN method also minimizes the computation complexity, communication complexity and drug delivery error detection rate by 30%, 37% and 37% when compared to existing methods. Proposed PBC-SOSN method increases the drug delivery detection rate by 4% with lesser computation complexity, communication complexity, and drug delivery error detection rate by 6%, 17% and 26% when compared to compartmental model for IoBNT [1], and ant-behaviour-inspired nanonetwork [2]. Future work Proposed PBC-SOSN method is implemented to attain maximum drug delivery detection rate with fewer drug delivery error detection rate. The future enhancement is focused on addressing the above-mentioned issue of the proposed method by designing optimization techniques for tumor diagnosis. Also, nanoparticles can be engineered to specifically target biomarkers associated with tumor cells for early detection. This could enable the diagnosis of cancer at its earliest stage, when treatment is most effective. Data availability The datasets used during the current study are available from the corresponding author on reasonable request. References El-Fatyany, A., Wang, H. & Abd El-atty, S. M. Efficient framework analysis for targeted drug delivery based on internet of bio-nanothings. Arab. J. Sci. Eng. 46(10), 9965\u20139980 (2021). Article   CAS   PubMed   PubMed Central   Google Scholar   Lin, L., Huang, F., Yan, H., Liu, F. & Guo, W. Ant-behavior inspired intelligent nanoNet for targeted drug delivery in cancer therapy. IEEE Trans. Nano Biosci. 19(3), 323\u2013332 (2020). Article   Google Scholar   Li, J. et al. Nano-QSAR modeling for predicting the cytotoxicity of metallic and metal oxide nanoparticles: A review. Ecotoxicol. Environ. Saf. 43, 113955 (2022). Article   Google Scholar   Raz, N. R., Akbarzadeh-T, M. R. & Tafaghodi, M. Bio-inspired nanonetworks for targeted cancer drug delivery. IEEE Trans. NanoBiosci. 14(8), 894\u2013990 (2015). Article   Google Scholar   Rizvi, S. A. & Saleh, A. M. Applications of nanoparticle systems in drug delivery technology. Saudi Pharm. J. 26(1), 64\u201370 (2017). Article   PubMed   PubMed Central   Google Scholar   You, Y. et al. Artificial intelligence in cancer target identification and drug discovery. Signal Transduct. Target. Ther. 7(1), 156 (2022). Article   PubMed   PubMed Central   Google Scholar   Mitchell, M. J. et al. Engineering precision nanoparticles for drug delivery. Drug Discov. 20(2), 101\u2013124 (2021). Article   CAS   Google Scholar   Noorain, L., Nguyen, V., Kim, H. W. & Nguyen, L. T. A machine learning approach for PLGA nanoparticles in antiviral drug delivery. Pharmaceutics 15(2), 495 (2023). Article   CAS   PubMed   PubMed Central   Google Scholar   Trac, N. et al. Spotlight on genetic kidney diseases: A call for drug delivery and nanomedicine solutions. Am. Chem. Soc. Nano 17(7), 6165\u20136177 (2023). CAS   Google Scholar   Lin, L., Huang, F., Yan, H., Liu, F. & Guo, W. Ant-behavior inspired intelligent NanoNet for targeted drug delivery in cancer therapy. IEEE Trans. Nano Sci. 19(3), 323\u2013332 (2020). Article   Google Scholar   Liu, H., Gao, H. & Jia, F. The value of convolutional neural network-based magnetic resonance imaging image segmentation algorithm to guide targeted controlled release of doxorubicin nanopreparation. Contrast Media Mol. Imaging 2021, 1 (2021). Article   Google Scholar   Bui, M. P., Le, T. A. & Yoon, J. A magnetic particle imaging-based navigation platform for magnetic nanoparticles using interactive manipulation of a virtual field free point to ensure targeted drug delivery. IEEE Trans. Ind. Electron. 68(12), 12493\u201312503 (2020). Article   Google Scholar   Femminella, M., Reali, G. & Vasilakos, A. V. A molecular communications model for drug delivery. IEEE Trans. Nano Biosci. 14(8), 935\u2013945 (2015). Article   Google Scholar   Zhao, Q., Li, M. & Lin, L. Release rate optimization in molecular communication for local nanomachine-based targeted drug delivery. IEEE Trans. Nanobisci. 20(4), 396\u2013405 (2021). Article   Google Scholar   Harrison, P. J. et al. Deep-learning models for lipid nanoparticle-based drug delivery. Nanomedicine 16(13), 1097\u20131110 (2021). Article   CAS   PubMed   Google Scholar   Lin, Z. et al. Predicting nanoparticle delivery to tumors using machine learning and artificial intelligence approaches. Int. J. Nanomed. 24, 1365\u20131379 (2022). Article   Google Scholar   Pramanik, P. K. et al. Advancing modern healthcare with nanotechnology, nanobiosensors, and internet of nano things: Taxonomies, applications, architecture, and challenges. IEEE Access 8, 65230\u201365266 (2020). Article   Google Scholar   Mittal, K. R., Pharasi, N., Sarna, B., Singh, M. & Rachana, H. S. Nanotechnology-based drug delivery for the treatment of CNS disorders. Transl. Neurosci. 13(1), 527\u2013546 (2022). Article   CAS   PubMed   PubMed Central   Google Scholar   Kibria, M. R. et al. Predicting efficacy of drug carrier nanoparticle designs for cancer treatment: A machine learning based solution. Sci. Rep. 13(1), 547 (2023). Article   ADS   CAS   PubMed   PubMed Central   Google Scholar   Kaushik, P. D. & Chandra, J. Nanoparticles and convergence of artificial intelligence for targeted drug delivery for cancer therapy: Current progress and challenges. Front. Med. Technol. 4, 1067144 (2023). Article   Google Scholar   Rajesh, E. et al. Machine learning for online automatic prediction of common disease attributes using never-ending image learner. Diagnostics 13(1), 95 (2023). Article   Google Scholar   Kong, S., Moharil, P. & Handly-Santana, A. Synergistic combination therapy delivered via layer-by-layer nanoparticles induces solid tumor regression of ovarian cancer. Bio Eng. Transl. Med. 8(2), e10429 (2022). Article   Google Scholar   Vivek, P. C., Aayushi, P. & Kavya, J. Nano-drug delivery systems entrapping natural bioactive compounds for cancer: Recent progress and future challenges. Pharmacol. Anti-Cancer Drugs 12, 867655 (2022). Google Scholar   Zhao, R. et al. Recent advances in CXCL12/CXCR4 antagonists and nano-based drug delivery systems for cancer therapy. Pharmaceutics 14(8), 1541 (2022). Article   CAS   PubMed   PubMed Central   Google Scholar   Chutong, T., Shunzhe, Z., Xinying, L. & Kenichiro, K. Tumor-on-a-chip model for advancement of anti-cancer nano drug delivery system. Dept. Pharm. 20(1), 1\u20136 (2022). Google Scholar   Shen, W. et al. A polymeric hydrogel to eliminate programmed death-ligand 1 for enhanced tumor radio-immunotherapy. ACS Nano 17(23), 23998\u201324011 (2023). Article   CAS   PubMed   Google Scholar   Aiping, H. & Wenhu, Z. Mn-based cGAS-STING activation for tumor therapy. Chin. J. Cancer Res. 35(1), 19 (2023). Article   Google Scholar   Huang, S. et al. Targeting nano-regulator based on metal\u2013organic frameworks for enhanced immunotherapy of bone metastatic prostate cancer. Cancer Nanotechnol. 14(1), 1\u20135 (2023). Article   Google Scholar   Sarani, M. et al. Green synthesis of Ag and Cu-doped Bismuth oxide nanoparticles: Revealing synergistic antimicrobial and selective cytotoxic potentials for biomedical advancements. J. Trace Elem. Med. Biol. 81, 127325 (2024). Article   CAS   PubMed   Google Scholar   Download references Acknowledgements This work was supported by Princess Nourah bint Abdulrahman University Researchers Supporting Project number (PNURSP2024R235), Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia. The authors extend their appreciation to the Deanship of Scientific Research at King Khalid University (KKU) for funding this research through the Research Group Program Under the Grant Number: (R.G.P.2/572/44). Funding This research was financially supported by Princess Nourah bint Abdulrahman University Researchers Supporting Project number (PNURSP2024R235), Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia. The authors extend their appreciation to the Deanship of Scientific Research at King Khalid University (KKU) for funding this research through the Research Group Program Under the Grant Number: (R.G.P.2/572/44). Author information Authors and Affiliations Department of CSE, Amity University, Mumbai, India Garima Shukla Department of AI, ASET, Amity University, Noida, UP, India Sofia Singh & Shipra Saraswat Department of Data Science, IoT, Cybersecurity (DIC), G H Raisoni College of Engineering Nagpur, Nagpur, India Chetan Dhule & Rahul Agrawal Department of Information Systems, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, P.O. Box 84428, 11671, Riyadh, Saudi Arabia Amal Al-Rasheed Radiological Sciences Department, College of Applied Medical Sciences, King Khalid University, 61421, Abha, Saudi Arabia Mohammed S. Alqahtani BioImaging Unit, Space Research Centre, University of Leicester, Michael Atiyah Building, Leicester, LE1 7RH, UK Mohammed S. Alqahtani PRINCE Laboratory Research, ISITcom, Hammam Sousse, University of Sousse, Sousse, Tunisia Ben Othman Soufiene Contributions All authors contributed equally to the conceptualization, formal analysis, investigation, methodology, and writing and editing of the original draft. All authors have read and agreed to the published version of the manuscript. Corresponding authors Correspondence to Garima Shukla or Ben Othman Soufiene. Ethics declarations Competing interests The authors declare no competing interests. Additional information Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Rights and permissions Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. Reprints and permissions About this article Cite this article Shukla, G., Singh, S., Dhule, C. et al. Point biserial correlation symbiotic organism search nanoengineering based drug delivery for tumor diagnosis. Sci Rep 14, 6530 (2024). https://doi.org/10.1038/s41598-024-55159-6 Download citation Received 14 December 2023 Accepted 21 February 2024 Published 19 March 2024 DOI https://doi.org/10.1038/s41598-024-55159-6 Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Keywords Nanotechnology Nanoparticles Variational model decomposition Point biserial correlation Nanoengineering Subjects Computational biology and bioinformatics Diseases Drug discovery Health care Comments By submitting a comment you agree to abide by our Terms and Community Guidelines. If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate. Download PDF Sections Figures References Abstract Introduction Related works Proposed methodology Experimental setup Conclusion Data availability References Acknowledgements Funding Author information Ethics declarations Additional information Rights and permissions About this article Comments Advertisement Scientific Reports (Sci Rep) ISSN 2045-2322 (online) About Nature Portfolio About us Press releases Press office Contact us Discover content Journals A-Z Articles by subject Protocol Exchange Nature Index Publishing policies Nature portfolio policies Open access Author & Researcher services Reprints & permissions Research data Language editing Scientific editing Nature Masterclasses Research Solutions Libraries & institutions Librarian service & tools Librarian portal Open research Recommend to library Advertising & partnerships Advertising Partnerships & Services Media kits Branded content Professional development Nature Careers Nature Conferences Regional websites Nature Africa Nature China Nature India Nature Italy Nature Japan Nature Korea Nature Middle East Privacy Policy Use of cookies Your privacy choices/Manage cookies Legal notice Accessibility statement Terms & Conditions Your US state privacy rights \u00a9 2024 Springer Nature Limited",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "Water-richness evaluation method and application of clastic rock aquifer in mining seam roof",
    "doi": "10.1038/s41598-024-57033-x",
    "description": "Clastic rock aquifer of the coal seam roof often constitutes the direct water-filling aquifer of the coal seam and its water-richness is closely related to the risk of roof water inrush. Therefore, the evaluation of the water-richness of clastic rock aquifer is the basic work of coal seam roof water disaster prevention. This article took the 4th coal seam in Huafeng mine field as an example. It combined the empirical formula method and generalized regression neural network (GRNN) to calculate the development height of water-conducting fracture zone, determined the vertical spatial range of water-richness evaluation. Depth of the sandstone floor, brittle rock ratio, lithological structure index, fault strength index, and fault intersections and endpoints density were selected as the main controlling factors. A combination weighting method based on the analytic hierarchy process (AHP), rough set theory (RS), and minimum deviation method (MD) was proposed to determine the weight of the main controlling factors. Introduced the theory of unascertained measures and confidence recognition criteria to construct an evaluation model for the water-richness of clastic rock aquifers, the study area was divided into three zones: relatively weak water-richness zones, medium water-richness zones, and relatively strong water-richness zones. By comparing with the water inrush points and the water inflow of workfaces, the evaluation model's water yield zoning was consistent with the actual situation, and the prediction effect was good. This provided a new idea for the evaluation of the water-richness of the clastic rock aquifer on the roof of the mining coal seam.",
    "journal": "Scientific Reports",
    "authors": [
      "Qiu M.",
      "Shao Z.",
      "Zhang W.",
      "Zheng Y.",
      "Yin X.",
      "Gai G.",
      "Han Z.",
      "Zhao J."
    ],
    "citation_count": "0",
    "full_text": "Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Advertisement View all journals Search Log in Explore content About the journal Publish with us Sign up for alerts RSS feed nature scientific reports articles article Article Open access Published: 18 March 2024 Water-richness evaluation method and application of clastic rock aquifer in mining seam roof Mei Qiu, Zhendong Shao, Weiqiang Zhang, Yan Zheng, Xinyu Yin, Guichao Gai, Zhaodi Han & Jianfei Zhao  Scientific Reports  14, Article number: 6465 (2024) Cite this article 61 Accesses Metrics Abstract Clastic rock aquifer of the coal seam roof often constitutes the direct water-filling aquifer of the coal seam and its water-richness is closely related to the risk of roof water inrush. Therefore, the evaluation of the water-richness of clastic rock aquifer is the basic work of coal seam roof water disaster prevention. This article took the 4th coal seam in Huafeng mine field as an example. It combined the empirical formula method and generalized regression neural network (GRNN) to calculate the development height of water-conducting fracture zone, determined the vertical spatial range of water-richness evaluation. Depth of the sandstone floor, brittle rock ratio, lithological structure index, fault strength index, and fault intersections and endpoints density were selected as the main controlling factors. A combination weighting method based on the analytic hierarchy process (AHP), rough set theory (RS), and minimum deviation method (MD) was proposed to determine the weight of the main controlling factors. Introduced the theory of unascertained measures and confidence recognition criteria to construct an evaluation model for the water-richness of clastic rock aquifers, the study area was divided into three zones: relatively weak water-richness zones, medium water-richness zones, and relatively strong water-richness zones. By comparing with the water inrush points and the water inflow of workfaces, the evaluation model's water yield zoning was consistent with the actual situation, and the prediction effect was good. This provided a new idea for the evaluation of the water-richness of the clastic rock aquifer on the roof of the mining coal seam. Similar content being viewed by others Deep learning for water quality Article 12 March 2024 Rapid groundwater decline and some cases of recovery in aquifers globally Article Open access 24 January 2024 A triple increase in global river basins with water scarcity due to future pollution Article Open access 06 February 2024 Introduction In the process of coal mine production, mine water disasters are major threats, and a common type of them is the water disaster to the coal seam roof aquifer. In various eras of coal fields in China, clastic rock aquifers such as sandstone and conglomerate are widely developed in coal-bearing strata1. During coal mining, cracks and fractures occur in the roof strata. Once these cracks and fractures communicate with each other, they form a water channel, guiding water from the roof aquifer into the mining site, causing instantaneous large-scale water inrush disasters. In the mild case, it can cause mining machinery losses, and in the severe case, it can lead to flooding of wells or even catastrophic casualties. The clastic rock aquifer within the range of the water-conducting fracture zone of the coal seam roof becomes the direct water-filling aquifer of the mining coal seam, and its water-richness directly determines the occurrence and inflow of water from the roof. Therefore, evaluating the water-richness of coal seam roof clastic rocks has practical guiding significance for the safety production of mines. At present, the methods for evaluating the water-richness of coal seam roof clastic rock aquifers in China are mainly divided into three categories2,3: Firstly, based on the data of unit water inflow, the classification of water-richness is directly based on the \"Detailed Rules for Coal Mine Water Prevention and Control\"4. This method is the most accurate, but it needs to be based on a large amount of hydrological borehole data, and during the mining stage, the boreholes for pumping tests are often scarce and unevenly distributed5. The second is to use geophysical methods such as transient electromagnetic method, high-resolution direct current method, audio frequency electric perspective method, etc6,7, however, geophysical methods are often costly, and the multiplicity of geophysical results cannot be avoided8. The third is the comprehensive analysis method of multiple factors. This method involves in-depth exploration of hydrogeological exploration data, selecting and weighting factors affecting water-richness, and constructing a water-richness evaluation model based on statistical or fuzzy mathematical methods, it comprehensively considers the weights of various influencing factors and indicators, and the zoning results obtained can truly reflect the characteristics of aquifer water-richness9. Currently, it is the most widely used method, but the degree of hydrogeological exploration in most coal mining areas in China is relatively low, and the unit water inflow data of aquifers is limited, which cannot fully reflect the distribution characteristics of aquifers. In addition, some scholars had a relatively single method for weighting impact indicators, which affects the accuracy of water-richness evaluation10. Through comprehensive comparison of the above-mentioned methods for evaluating the water-richness of the coal seam roof, this study decided to use the multi-factor comprehensive analysis method. The main idea of the multi-factor comprehensive analysis method is to first establish an index system for the indicators influencing water-richness, and then couple the indicators with their weights to establish an evaluation model. Yu et al.11 determined the weights of aquifer influencing factors using Analytical Hierarchy Process (AHP) and conducted water-richness zoning using SURFER software. Tang et al.12 combined AHP with entropy weight method and established an evaluation model using ArcGIS software, which yielded reliable results. Bi et al.13 combined AHP with independent weight coefficient method to establish an evaluation model with high accuracy. Wang et al.14 also used AHP to establish an evaluation system and conducted water-richness zoning in the study area, providing scientific guidance for the prevention and control of water disasters in mining areas. Qiu et al.15 successfully applied Fuzzy Delphi Analytic Hierarchy Process (FDAHP) combined with entropy weight method, introducing the Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS) method to construct an aquifer richness evaluation model. In another study area, Qiu et al.5 combined FDAHP with grey correlation analysis to establish a water-richness zoning model with high accuracy. Huang et al.10 combined FDAHP with entropy weight method to establish a water-richness zoning evaluation model through the theory of unascertained measures, and the model has certain reliability. Li et al.16 and Gong et al.17 applied Back-Propagation neural network (BP) in aquifer richness evaluation, summarizing the distribution pattern of aquifer richness and achieving accurate prediction. Li et al.18 used random forest to establish a model and evaluate the weights of various influencing indicators, conducting zoning of water-richness in the study area, with results meeting the accuracy requirements. Some scholars only used one weighting method, and the obtained weights may be too subjective or objective; Some scholars had also adopted various weighting methods but only used simple geometric averaging to combine weights, lacking scientific rigor. So how to balance the influence of subjective and objective weights and improve the accuracy of weights has become an urgent problem to be solved. This article took the 4th coal seam in Huafeng mine field as the research object. Firstly, the Generalized Regression Neural Network (GRNN) and the \"three down\" regulation formula were comprehensively used to calculate the development height of the water-conducting fracture zone in the coal seam roof, to more accurately determine the vertical spatial range of water-richness evaluation. On this basis, the analysis was conducted from two aspects: lithological structural characteristics and structural development characteristics. Lithological structural characteristics refer to the intrinsic properties of the rock itself, including its composition and internal structure, manifested as rock type, rock structure, thickness of sandstone layer, etc. Structural development characteristics refer to the changes in geological structure and geomorphological formations caused by geodynamic effects, manifested as the development of folds and faults formations. The depth of the sandstone floor, brittle rock ratio, lithological structural index, fault strength index, fault intersections and endpoints density were selected as the main controlling factors to evaluate the water-richness of the clastic rock aquifer in the study area. Based on the minimum deviation method, the main controlling factors' subjective and objective weights obtained from Analytic Hierarchy Process (AHP) and Conditional Entropy Improved Rough Set Theory were effectively fused to obtain comprehensive weights, making the weight results more reasonable. Introducing the theory of unascertained measurement and confidence criteria, a water-richness evaluation model for the clastic rock aquifer of the 4th coal seam roof in Huafeng Coalfield was constructed. Compared with the water inrush points and the water inflow of some workfaces in the mine, the zoning prediction results of the evaluation model were relatively consistent. The method in this article provided a new approach for evaluating the water-richness of clastic rock aquifers in coal seam roof during mining. Study area Overview of geological structure Huafeng mine field lies in Huafeng Town, Ningyang County, Shandong Province, China. The site lies between 117\u00b0 07\u2032 28\u2033 E and 117\u00b0 11\u2032 11\u2033 E longitude and 35\u00b0 51\u2032 49\u2033 N and 35\u00b0 54\u2032 52\u2033 N latitude. The Huafeng mine field is a fault block depression bounded by faults on three sides, namely the east, north, and west. It is generally a dustpan shaped syncline structure that plunges towards the northeast, with a dip angle of 17\u00b0 to 40\u00b0. The structure of the mine field is relatively simple (Fig. 1). Local normal faults with a drop of no more than 30 m and a few reverse faults have developed in the mine field, which generally extend relatively short and tip out towards the deep. In addition, multiple secondary folds have also developed in the mine field. However, except for the two obvious synclines at the turning points of the two wings, the scale is generally very small, and the deformation towards the deep is unusually gentle and even disappears. The strata in the study area include the Middle Lower Ordovician, Carboniferous Yuemengou Group Benxi Formation, Carboniferous Permian Yuemengou Group Taiyuan Formation, Permian Yuemengou Group Shanxi Formation, Permian Shihezi Formation, Paleogene Lower Guanzhuang Group, and Quaternary System. The main coal bearing strata have a total thickness of 325.86 m and a total of 24 coal layers. The Shanxi and Taiyuan formations are the main coal bearing strata. Figure 1 Structural outline map of Huafeng mine field. Full size image Hydrogeological overview The aquifer in the Huafeng mine field consists of Quaternary aquifer sand and gravel layer, Paleogene conglomerate, Shanxi Formation sandstone, Taiyuan Formation thin layer limestone, Xucao limestone, and Ordovician limestone. Each aquifer forms a multi-layer structure groundwater type in the coal field, belonging to the northern type of multi aquifer karst fissure water filled deposit. The main aquifers are the Paleogene reddish brown clayey siltstone beneath the conglomerate, the Shihezi Formation variegated clay rock, and the siltstone, mudstone, and clay rock between the various aquifers in the coal bearing strata. The overlying aquifer of 4th coal seam in the mine field is composed of Quaternary water-bearing gravel layer, Paleogene conglomerate, and Shanxi Formation sandstone. The Paleogene conglomerate aquifer directly covers the coal bearing strata and has a small distance between the shallow part and the 4th coal seam, which has a significant impact on the mining of the 4th coal seam; The sandstone of the Shanxi Formation mainly refers to the sandstone on the top and bottom of the 4th coal seam, which under normal circumstances mainly leaks into the mine in the form of water pouring (Fig. 2). Figure 2 Hydrogeologic profile of 4th coal seam roofs. Full size image Data and method The evaluation of the water-richness of the clastic rock aquifer on the roof of the mining coal seam mainly included the following steps: (1) By using empirical formulas and GRNN neural networks, the height of the development of water-conducting fracture zones above coal seams was calculated. (2) Based on the multi-factor control mechanism of water-richness in the coal seam roof and hydrogeological data of the study area, the main controlling factors of the water-richness in the clastic rock aquifer above the mining coal seam were selected. (3) The AHP method and the rough set theory improved by conditional entropy were used to calculate the subjective and objective weights of each main controlling factor, and comprehensive weight was obtained based on the minimum deviation. (4) The evaluation model of water-richness was established for the study area using the theory of uncertain measurement and confidence criteria. The water-richness of clastic rock aquifer above the coal seam was analyzed, and a grading prediction was made (Fig. 3). Figure 3 Technology roadmap. Full size image Prediction of the development height of water-conducting fracture zones After coal seam mining, the overlying rock above the goaf undergoes damage and deformation. According to the \"upper three zones\" theory of coal mining, the areas of damage and deformation are divided into caving zone, fractured zone, and bending subsidence zone. Among them, the caving zone and fractured zone are collectively referred to as water-conducting fracture zone. (Fig. 4) The water-conducting fracture zone connects the clastic rock aquifer on the coal seam roof with the workface. The clastic rock aquifer within this height range constitutes the direct water-filling aquifer for water inrush on the coal seam roof, and the water-conducting fracture zone becomes the main channel for water damage on the coal seam roof. It is of great significance for the safe mining of coal seams to partition and evaluate the water-richness of the coal seam roof directly filled aquifer within the height range of the water-conducting fracture zone during the coal seam mining process. Figure 4 Schematic diagram of the \"upper three belts\". Full size image Empirical formula method At present, on-site technical personnel in coal mines in China widely use the formula provided in the \"Regulations on the Retaining and Mining of Coal Pillars in Buildings, Water Bodies, Railways, and Main Tunnels\"19 to calculate the development height of water-conducting fracture zones. In the regulations, based on the size of uniaxial compressive strength, the roof lithology is divided into four types: hard, medium-hard, weak, and extremely weak, and different formulas are used according to the degree of hardness20. The calculation formula for the development height of water-conducting fracture zones with different lithology is as follows: $${\\text{Hard}}:H = \\frac{100\\sum M }{{1.2\\sum M + 2.0}} \\pm 8.9,$$ (1) $${\\text{Medium}} - {\\text{hard}}:H = \\frac{100\\sum M }{{1.6\\sum M + 3.6}} \\pm 5.6,$$ (2) $${\\text{Weak}}:H = \\frac{100\\sum M }{{3.1\\sum M + 5.0}} \\pm 4.0,$$ (3) $${\\text{Extremely weak}}:H = \\frac{100\\sum M }{{5.0\\sum M + 8.0}} \\pm 3.0,$$ (4) where\u2211M is the total thickness of coal seam mining, in meters, and H is the height of water-conducting fracture zone, in meters. The empirical formula method is simple and fast, but only considers the strength of coal seam overlying rock and mining thickness, and the specific geological and mining conditions of different workfaces are not the same. Therefore, the predicted values obtained by this method are only for reference and need to be further analyzed in conjunction with other methods. Neural network method With the development of computer technology, neural networks have been widely used for predicting the development height of water-conducting fracture zones. Its advantage is that it can process a large amount of data, extract useful features from it, and better identify trends related to the height of hydraulic fracture zones. A trained neural network model can be used for online prediction in actual production processes, which means it can predict real-time data, assist in practical applications, and adjust and optimize accordingly. Generalized regression neural network (GRNN) is a type of Radial Basis Function Neural Network (RBF) that has been widely used in the field of regression prediction. It has stronger approximation ability and learning speed compared to RBF networks, strong nonlinear mapping ability, and learning speed, and simple structure with single parameter setting21,22. The structure of GRNN neural network is shown in Fig. 5, including input layer, pattern layer, summation layer, and output layer23,24,25,26. Figure 5 Structure of GRNN neural network model. Full size image (1) Input layers: the number of input neurons is equal to the dimension of the input vector in the training sample, and the input neurons directly enter the next pattern layer. (2) Pattern layers: the number of neurons in the pattern layer is equal to the number of neurons in the input layer, and non-linear transformation is performed on the output from the input layer. The transfer function of the \\(i\\) neuron is often used as follows: $$P_{i} = exp[ - \\frac{{(X - X_{i} )^{T} (X - X_{i} )}}{{2\\sigma^{2} }}] \\, i = 1,2, \\cdot \\cdot \\cdot ,n$$ (5) where Pi is output layer neuron model; X is input vector for the network; Xi is a learning sample for the corresponding i neuron; \u03c3 is the smoothing factor; n is the number of training samples. (3) Sum layers: this layer is used to calculate the total output from the pattern layer, and there are two types of neurons applied to it. The first neuron algorithm adds all neurons in the pattern layer, with a connection weight of 1 between each neuron in the pattern layer and the transfer function is: $$S_{D} = \\sum\\limits_{i = 1}^{{\\text{n}}} {p_{i} = } \\sum\\limits_{i = 1}^{n} {\\exp \\left( { - \\frac{{\\left( {X - X_{i} } \\right)^{T} \\left( {X - X_{i} } \\right)}}{{2\\sigma^{2} }}} \\right)}$$ (6) Another calculation formula has added weighted sum, where the j element in the i output sample Yi is the connection weight between the i neuron in the pattern layer and the j element in the summation layer and the neuron. Its transfer function is: $$S_{{N_{j} }} = \\sum\\limits_{i = 1}^{n} {Y_{ij} p_{j} } = \\sum\\limits_{i = 1}^{n} {Y_{i} \\exp \\left( { - \\frac{{\\left( {X - X_{i} } \\right)^{T} \\left( {X - X_{i} } \\right)}}{{2\\sigma^{2} }}} \\right)}$$ (7) where Yi is the i output sample; n is the number of nodes in the pattern layer; k is the dimension of output vector; Yij is the j value of the result vector in the i training sample. \\(S_{D}\\) as the denominator of the output layer, this function is mainly used for normalization to ensure the stability of the output results, its calculation is relatively simple, and can avoid the numerical instability caused by the molecular part of the value is too large. \\(S_{{N_{j} }}\\) as the molecule of the output layer, by weighting the contribution of each sample, this function is able to more accurately reflect the similarity between the input vectors and the training samples, thus improving the accuracy of the prediction. (4) Output layers: the number of neurons in the output layer is equal to the dimension k of the output vector in the training sample, and the output result of each neuron is: $$y_{i} = \\frac{{S_{{N_{j} }} }}{{S_{D} }} \\, j = 1,2, \\cdot \\cdot \\cdot ,k$$ (8) where yi is the output of the j node in the output layer, which is the predicted result. The GRNN neural network will be trained by the measured cases of the development of water-conducting fracture zones with similar geological conditions to the study area. Suitable influencing factors need to be selected as input values for the input layer. Based on the drilling data and previous studies in the research area, four factors, namely coal seam thickness, proportion coefficient of hard rock lithology, dip length of the workface, and mining depth, were selected as the influencing factors for the development height of the water-conducting fractured zone. a. Coal seam thickness (m). This factor plays a crucial role in determining the development height and serves as the primary controlling factor for determining the conduit height in traditional empirical formulas. With increasing coal seam thickness, the caving zone expands, leading to a corresponding increase in the development of the water-conducting fractured zone. b. Proportion coefficient of hard rock lithology (b)15. This factor can replace the two influencing factors of the uniaxial compressive strength and structural type of the roof combination rock layer, reflecting the strength type and lithology combination of the coal seam roof. c. Dip length of the workface (l). Prior to the full exploitation of coal seams, the dip length of the workface has a significant impact on the development of the water-conducting fractured zone, with the development height increasing as the workface advances. After the coal seam has been fully exploited, the effect of the dip length of the workface on the development of the fractured zone is not significant. d. Mining depth (s). As the mining depth increases, the mine pressure also increases, causing previously unconnected fractures in the overlying strata of the coal seam to become interconnected, thus forming water-conducting channels. Therefore, mining depth can be considered as a influencing factor. After the training of the GRNN neural network was completed by the measured data, the above influencing factors were substituted into the network as the input layer data, and the predicted value of the height of the development of the water-conducting fracture zone in the roof of the coal seam in the study area could be obtained. Analysis of the main controlling factors of water-richness The selection of the main controlling factors of the coal seam roof aquifer is the prerequisite and foundation for the evaluation of water-richness. Reasonable selection of the main controlling factors can greatly improve the scientific and reliable evaluation of the water-richness of the coal seam roof aquifer. Based on the hydrogeological data of the study area, this article selected the depth of the sandstone floor, brittle rock ratio, lithological structure index, fault strength index, fault intersections and endpoints density as the main controlling factors for evaluating the water-richness of the clastic rock aquifer on the roof of the 4th coal seam in Huafeng mine field. a. Depth of the sandstone floor (D), is the bottom burial depth of the sandstone in the upper part of the mining coal seam. The main impact of this factor is that as the depth increases, the static pressure of the rock will also gradually increase, and the degree of compaction of the sandstone will also increase. This will reduce the probability of cracks in the rock layer and reduce the water-richness27. b. Brittle rock ratio (R), is the ratio of brittle rock thickness to plastic rock thickness within the statistical range. National and international scholars have evaluated the brittleness of rocks from different perspectives, such as mineral composition28, stress\u2013strain curves based on rock brittleness characteristics29, and rock mechanics parameters30. In this study, the brittleness of rocks is analyzed based on the rock mechanics parameters and mineral composition of each stratum in the coal seam roof. From the analysis of rock mechanics parameters, combined with the preliminary geological survey report of the study area, the brittleness of rocks is quantified by calculating the area enclosed by the uniaxial tensile-uniaxial compressive strength curve28. The formula is shown below: $$B{ = }\\sigma_{c} \\sigma_{t} /2,$$ (9) where B is the brittleness of the rock, \\(\\sigma_{c}\\) is the uniaxial compressive strength of the rock, \\(\\sigma_{t}\\) is the uniaxial tensile strength of the rock. The rock mechanics parameters and brittleness degree of the roof strata of the 4th coal seam in Huafeng coal mine are shown in Table 1. Table 1 Rock brittleness evaluation table. Full size table In terms of rock mineral composition, conglomerate, coarse-grained sandstone, medium-grained sandstone, and fine-grained sandstone in the strata often contain brittle minerals such as quartz, while siltstone and mudstone commonly contain clay minerals. Taking all factors into consideration, we classified fine-grained sandstone, medium-grained sandstone, coarse-grained sandstone, and conglomerate as brittle rocks, while classifying siltstone and mudstone as plastic rocks. Compared to plastic rocks, brittle rocks are more prone to generating a large number of cracks under stress, greatly enhancing their water permeability and storage capacity. Therefore, the brittle rock ratio can be used as a factor affecting the water-richness of aquifers, and the larger the ratio, the stronger the water-richness of aquifers11. The formula for calculating the brittle rock ratio is as follows: $$R = \\left( {a + b + c} \\right)/d,$$ (10) where R is the brittle rock ratio; a is the thickness of conglomerate and coarse-grained sandstone, in meters; b, c is the thickness of medium-grained sandstone and fine-grained sandstone, in meters; d is the thickness of plastic rocks such as siltstone and mudstone, in meters. c. Lithological structure index (L). Using this factor to reflect the lithology, thickness, and combination characteristics of sand and mudstone within the range of water-conducting fracture zones, the larger the lithological structure index, the better the water-richness of the aquifer. The calculation method of lithological structure index in this paper is as follows: The thickness of fine-grained sandstone, medium-grained sandstone, conglomerate, etc., is multiplied by an equivalent coefficient to convert it into the thickness of coarse-grained sandstone, and then multiplied by the structural coefficient31. The structural coefficient refers to the coefficient determined by the sand-mud combination structure of the rock layer. The structural coefficients are taken as shown in Table 2. The formula for calculating the lithological structure index is as follows: $$L = (a \\times 1 + b \\times 0.8 + c \\times 0.6) \\times g,$$ (11) where L is the lithological structure index; a is the thickness of conglomerate and coarse-grained sandstone, in meters; b, c is the thickness of medium-grained sandstone and fine-grained sandstone, in meters; g is the structural coefficient. Table 2 Structural coefficients of the lithological structure index. Full size table d. Fault strength index (I). Faults provide storage space and migration channels for groundwater, connecting coal seams and roof aquifers, and are important factors causing water inrush from coal seam roof aquifers. The fault strength index, which combines the fault drop, horizontal extension length, and number of faults, can quantitatively evaluate the development of faults and objectively and truly reflect the complexity of faults. The formula is32: $$I = \\frac{{\\sum\\limits_{i = 1}^{n} {H_{i} L_{i} } }}{S},$$ (12) where I is the fault strength index; n is the total number of faults per grid; Hi is the drop of the I fault in a certain grid, in meters; Li is the length of the I fault in a certain grid, in meters; i\u2009=\u20091, 2, \u2026, n; S is grid area, in square meters. e. Fault intersections and endpoints density (F). At the intersections and endpoints of faults, due to stress concentration and the cutting effect between faults, the degree of rock fracture is greater and the cracks are more developed, increasing the possibility of water inrush from the coal seam floor. Fault intersections and endpoints density is the sum of fault intersections and pinch points per unit area divided by the area of the area, which can intuitively reflect the complexity of the fault, the formula is as follows: $$F = \\frac{n}{S},$$ (13) where F is the fault intersections and endpoints density; n is the total number of intersections and endpoints of all faults in the grid; S is grid area, in square meters. By conducting statistics and analysis on the existing drilling data and geological data exposed in the Huafeng mine field, the Golden Software Surfer software was used to draw thematic maps of various main control factors, as shown in Fig. 6: Figure 6 The main controlling factors of water-richness evaluation. Full size image Calculation of weight of main controlling factors The weight of the main controlling factors plays a crucial role in accurately determining the evaluation results when conducting a multi-factor coupling evaluation of the water-richness of the coal seam roof aquifer. In traditional methods, weighting methods are too single, subjective or objective, or only use simple geometric averaging methods, which do not effectively combine subjective and objective weights, affecting the accuracy of weights. This article used the rough set theory method improved by conditional entropy and AHP to calculate subjective and objective weights respectively, and then effectively combined subjective and objective weights based on the minimum deviation method. Calculating subjective weights based on AHP Analytic Hierarchy Process (AHP) is a hierarchical and systematic multi-objective and multi-criteria decision analysis method that combines qualitative and quantitative analysis. By applying the idea of system analysis, complex multi-objective and multi-criteria decision problems are transformed into simple quantitative decision problems. It has been widely used in the evaluation, prediction, system analysis, and other aspects. The main steps of AHP include three parts: establishing a hierarchical structure model, constructing a judgment matrix, and determining the weights of each main controlling factor12. (1) Establishing a hierarchical structure model. The ultimate goal of this article was to evaluate the water-richness of the clastic rock aquifer on the roof of the mining coal seam, and used this as the target layer (A layer); the lithological structural characteristics and structural development characteristics reflected the water-richness of the aquifer, but their impact needed to be reflected through specific factors related to them as the rule layer of the model (B layer); the specific main controlling factors included the depth of the sandstone floor, brittle rock ratio, lithological structure index, fault strength index, fault intersections and endpoints density, which constituted the decision layer of the model (C layer). The hierarchical structure model was shown in Fig. 7. (2) Constructing a judgment matrix. Based on the varying degrees of influence of various main controlling factors on the evaluation of water-richness of sandstone aquifers, a quantitative analysis was conducted according to a certain scale to construct a judgment matrix. Collected the opinions of coal mine water prevention and control researchers and experts with rich on-site work experience in Huafeng mine field, and used the 1\u20139 scale method (Table 3) proposed by American operations researcher T.L. Satty33 to score the importance of the two major factors in the rule layer and the five main controlling factors in the decision layer, and established corresponding judgment matrices. (3) Consistency checking. Performed a consistency proportion test on each judgment matrix, and only after passing the consistency test can the weights obtained from the judgment matrix be accepted. First, the consistency index CI of the n order judgment matrix was calculated by the following formula: $$CI = \\frac{{\\lambda_{\\max } - n}}{n - 1},$$ (14) where \\(\\lambda_{\\max }\\) is the maximum eigenvalue of judgment matrix. CI\u2009=\u20090 indicates that the judgment matrix is completely consistent, CI\u2009<\u20090.1, the judgment matrix and single ranking of intra layer factors conform to logical consistency; if CI\u2009>\u20090.1, the assignment of factor weights within the judgment matrix needs to be adjusted. Figure 7 Hierarchical structure model. Full size image Table 3 Saaty 1\u20139 rating scale. Full size table Then, the consistency ratio CR could be calculated by the following formula: $$CR = \\frac{CI}{{RI}},$$ (15) where RI is the judgment matrix average random consistency indicator. CR\u2009<\u20090.1, the consistency of the judgment matrix is considered within the allowable range, and the weight vector calculation can be performed using the eigenvectors of the judgment matrix. (4) Obtaining the weight of the main control factor. Using the square root method to calculate weights, firstly calculated the n power of the product of each row of the n order judgment matrix to obtain an n vector. The vector factor calculation formula was as follows: $$\\overline{\\omega }_{i} = \\sqrt[n]{{\\prod\\limits_{j = 1}^{n} {a_{ij} } }},$$ (16) where \\(\\overline{\\omega }_{i}\\) is the I element of an n dimensional vector; \\(a_{ij}\\) is the scale value of the I row and the j column; i,j\u2009=\u20091, 2, \u2026, n. Normalizing the n dimensional vector mentioned above was the weight vector, which could obtain the weight: $$\\omega_{i} = \\frac{{\\overline{\\omega }_{i} }}{{\\sum\\limits_{j = 1}^{n} {\\overline{\\omega }_{i} } }},$$ (17) where \\(\\omega_{i}\\) is the weight value of the I main controlling factor. Calculating objective weights based on rough set theory improved by conditional entropy Rough Set Theory is a mathematical method for dealing with fuzziness and uncertainty34. It can mine potential and valuable knowledge from a large amount of data, reducing the unnecessary workload caused by redundant knowledge in calculation and classification. When processing data, there is no need to provide prior information beyond the data, and the importance of each attribute can be determined. Currently, it is widely used in objective weight calculation. In the process of calculating attribute weights using rough set theory, there may be situations where the weight of a certain attribute is 0. The reason for this phenomenon is that Rough Set Theory only considers the importance of a single attribute to the entire attribute set, without considering the importance of the attribute itself and neglecting the practical significance of the attribute35. To solve this problem, the concept of Conditional Entropy is introduced to improve the method of calculating attribute weights using Rough Set Theory. The objective weight calculation steps for the main controlling factors of water-richness of clastic rocks on the roof of the mining coal seam were as follows. (1) The knowledge system S for data processing related to water-richness evaluation was established as follows: $$S = \\left\\langle {U,A,V,f} \\right\\rangle ,$$ (18) where U is a set of objects, also known as a universe; \\(A = C \\cup D, \\, C \\cap D = \\emptyset\\), C is the set of conditional attributes, D is the set of decision attributes; \\(V = U_{a \\in A} V_{a}\\) is a set of attribute values, Va represents the range of attribute values for attribute A, that is, the range of values for attribute a; \\(f:U \\times A \\to V\\) is an information function that specifies the attribute value of x for each object in U. (2) Data standardization and classification. The selected controlling factors have different dimensions. To make the data more comparable and objective, the original data was standardized using the range standardization formula: $$X_{i} = \\frac{{X - X_{\\min } }}{{X_{\\max } - X_{\\min } }},$$ (19) where X is the original value of this indicator; Xmax, Xmin are the maximum and minimum values in the original data of the indicator, respectively, Xi is the standardized result value of this indicator. Divided the processed data into four levels based on intervals of [0, 0.25], (0.25, 0.5), (0.5, 0.75), and (0.75, 1), corresponding to the levels of small, medium, large, and extremely large mine water inflow. (3) Reducing knowledge system data. In the decision table, if there were identical conditional attribute values and most of the decision attribute values were the same but differ, remove the few rows that caused the difference in the decision attributes and saved the rows with the same decision attribute values; If two rows with the same conditional attribute and different decision attribute values were encountered, these two rows could be deleted, as the sample had no specific significance for classification; If there were several rows in the policy table with consistent values for conditional attributes or decision attributes, then kept one of them36. (4) Using Conditional Entropy to improve the Rough Set method for calculating attribute weights. a. Calculating the conditional entropy of decision attributes. In decision information table \\(S = \\left\\langle {U,C,D,V,f} \\right\\rangle\\), the conditional entropy of decision attribute set \\(D\\left( {U/D = \\left\\{ {D_{1} ,D_{2} , \\cdots ,D_{k} } \\right\\}} \\right)\\) relative to conditional attribute set \\(C\\left( {U/C = \\left\\{ {C_{1} ,C_{2} , \\cdots ,C_{m} } \\right\\}} \\right)\\) could be expressed as: $$I(D|C) = \\sum\\limits_{i = 1}^{m} {\\frac{{|C_{i} |^{2} }}{{|U|^{2} }}} \\sum\\limits_{j = 1}^{k} {\\frac{{|D_{j} \\cap C_{i} |}}{{|C_{i} |}}} \\, \\times \\left[ {1 - \\frac{{|D_{j} \\cap C_{i} |}}{{|C_{i} |}}} \\right],$$ (20) b. Calculating the importance of the condition attribute Ci. In the decision information table, \\(\\forall Ci \\in C\\), the importance of the conditional attribute Ci could be expressed as: $$New \\, Sig\\left( {C_{i} } \\right) = I(D|C - C_{i} ) - I(D|C),$$ (21) where \\(New \\, Sig\\left( {C_{i} } \\right)\\) represents the degree of change in the attribute set after removing the conditional attribute Ci, indicating the importance of the conditional attribute Ci relative to the entire conditional attribute set. c. Calculating attribute weights. By comprehensively considering the above two aspects and standardizing them, the weights of each conditional attribute (factor) could be obtained: $$W\\left( {C_{i} } \\right) = \\frac{{New \\, Sig\\left( {C_{i} } \\right) + I(D|C_{i} )}}{{\\sum\\limits_{i = 1}^{m} {\\left\\{ {New \\, Sig\\left( {C_{i} } \\right) + I(D|C_{i} )} \\right\\}} }},$$ (22) where \\(I(D|C_{i} )\\) indicates the importance of the conditional attribute Ci itself in the system. According to the above steps, the conditional entropy, importance, and weights of each main controlling factor could be obtained. Calculating comprehensive weights based on the minimum deviation method After calculating the subjective and objective weights using AHP and improved rough set theory, to balance the subjectivity and objectivity of the weight indicators and complement each other\u2019s strengths and weaknesses, a combination weighting method based on minimum deviation was adopted to fuse the subjective and objective weights, reduced the errors caused by a single weighting method, and obtained a more scientific and reasonable comprehensive weight37,38. Assuming that decision-makers use a total of q methods to determine indicator weights, including subjective weighting method l and objective weighting method q-l, the weight vector is: $$u_{k} = \\left( {u_{k1} ,u_{k2} , \\cdots ,u_{km} } \\right)^{T} \\, k = 1,2, \\cdots ,q$$ (23) $$\\sum\\limits_{i = 1}^{m} {u_{ki} = 1} .$$ (24) In order to comprehensively consider the subjective opinions of decision-makers and the objectivity of decision-making, a deviation function is introduced to minimize the weight deviation obtained by various weighting methods, and ultimately obtain the weight vector \\(w = \\left\\{ {w_{1} ,w_{2} , \\cdots ,w_{m} } \\right\\}^{T}\\). The specific steps are as follows. (1) Constructing a single objective optimization model: $$\\min J = \\sum\\limits_{k = 1}^{l} {\\sum\\limits_{j = 1}^{n} {a_{k} f_{j} \\left( {u_{k} } \\right)} } + \\sum\\limits_{k = l + 1}^{q} {\\sum\\limits_{j = 1}^{n} {a_{k} g_{j} \\left( {u_{k} } \\right)} } ,$$ (25) $$s.t. \\, \\sum\\limits_{i = 1}^{m} {\\omega_{i} = 1} ; \\, \\omega_{i} \\ge 0$$ (26) where ak is the weight coefficient corresponding to various weighting methods; aj is the weight corresponding to the j weighting method;\\(f_{j} \\left( {u_{k} } \\right)\\), \\(g_{j} \\left( {u_{k} } \\right)\\) is the deviation function of subjective weighting method and objective weighting method, respectively. In order to fully utilize the weight information determined by various weighting methods, the weight deviation of each weighting method should be smaller. Therefore, the constructed model is: $$\\min J = \\mathop \\sum \\limits_{j = 1}^{n} \\mathop \\sum \\limits_{k = 1}^{q} \\mathop \\sum \\limits_{i = 1}^{m} \\left( {a_{k} u_{ki} - a_{j} u_{ij} } \\right)^{2} ,$$ (27) $$s.t. \\, \\sum\\limits_{k = 1}^{q} {a_{k} } = 1; \\, a_{k} \\ge 0; \\, k \\in [1,q]$$ (28) (2) Constructing the corresponding Lagrange function: $$L\\left( {a,\\lambda } \\right) = \\sum\\limits_{j = 1}^{n} {\\sum\\limits_{k = 1}^{q} {\\sum\\limits_{i = 1}^{m} {\\left( {a_{k} u_{ki} - a_{k} u_{ij} } \\right)} } }^{2} + \\lambda \\left( {\\sum\\limits_{k = 1}^{q} {a_{k} - 1} } \\right)$$ (29) where \u03bb is an introduced parameter. According to the necessary conditions for the existence of extreme values, there are: $$\\left\\{ {\\begin{array}{*{20}c} {\\frac{\\partial L}{{\\partial a_{k} }} = qa_{k} \\sum\\limits_{i = 1}^{m} {u_{ki}^{2} } - \\alpha_{1} \\sum\\limits_{i = 1}^{m} {u_{1i} } u_{ki} - \\alpha_{2} \\sum\\limits_{i = 1}^{m} {u_{2i} } u_{ki} - \\cdots - \\alpha_{q} \\sum\\limits_{i = 1}^{m} {u_{qi} } u_{ki} + \\frac{\\lambda }{2} = 0,} \\\\ {\\frac{\\partial L}{{\\partial \\lambda }} = \\sum\\limits_{k = 1}^{q} {a_{k} } - 1 = 0,} \\\\ \\end{array} } \\right.$$ (30) where L is the constructed Lagrange function. According to Kramer's law, the coefficient determinant of the linear equation system is not 0, so the equation system has a unique solution, which is the corresponding weight coefficients of various weighting methods. By weighting them with the indicator weights of the corresponding methods, the final weight value can be obtained. (3) Obtaining a system of comprehensive weighting equations. By substituting the weight values obtained from the two weighting methods into the Lagrange function mentioned above, the equation system for obtaining the comprehensive weighting can be obtained: $$\\left\\{ {\\begin{array}{*{20}c} {\\left( {\\sum\\limits_{i = 1}^{n} {u_{1i}^{2} } } \\right)\\alpha_{1} - \\left( {\\sum\\limits_{i = 1}^{n} {u_{2i} u_{1i} } } \\right)\\alpha_{2} + \\frac{\\lambda }{2} = 0,} \\\\ \\begin{gathered} \\hfill \\\\ - \\left( {\\sum\\limits_{i = 1}^{n} {u_{1i} u_{2i} } } \\right)\\alpha_{1} + \\left( {\\sum\\limits_{i = 1}^{n} {u_{2i}^{2} } } \\right)\\alpha_{2} + \\frac{\\lambda }{2} = 0, \\hfill \\\\ \\end{gathered} \\\\ \\begin{gathered} \\hfill \\\\ \\alpha_{1} + \\alpha_{2} = 1, \\hfill \\\\ \\end{gathered} \\\\ \\end{array} } \\right.$$ (31) (4) Obtaining comprehensive weights. Substituting the obtained subjective and objective weight, \\(\\alpha * = \\left( {\\alpha_{1} , \\, \\alpha_{2} } \\right)\\) could be obtained. The comprehensive weight calculation of the main controlling factors for water-richness evaluation in this article was as follows: $$\\omega_{i} = \\alpha_{1} u_{1i} + \\alpha_{2} u_{2i} ,$$ (32) where \\(\\alpha_{1}\\) is the weight coefficient of subjective weight; \\(\\alpha_{2}\\) is the weight coefficient of objective weight; \\(u_{1i}\\) is the subjective weight; \\(u_{2i}\\) is the objective weight. Constructing a water-richness classification model based on unascertained measurement theory The unknown measurement theory was introduced into the evaluation of the water-richness of the coal seam roof water-bearing layer. This theory satisfies the criteria of non-negativity, additivity, normalization, and temporality, and applies the principle of confidence. The advantage of the comprehensive evaluation model based on the measurement mathematics is that no useful information will be lost when making judgments, and the use of the provided confidence criteria will not result in unclear or unreasonable classifications as in the maximum membership principle, especially for the problem of ordered partition classes, the classification degree is more accurate and detailed39. The steps for constructing the evaluation model were as follows. (1) Classifying evaluation indicators. When evaluating the target with an unascertained measure set, the key was constructing a reasonable unascertained measure function, and the first step was to establish a risk assessment level. On the basis of thorough research and analysis of the hydrogeological characteristics of the Huafeng mine field, a water-richness evaluation index for the study area was established through K-means clustering analysis and combined with the opinions of coal mine water prevention and control researchers, as shown in Table 4. Divided the water-richness in the study area into four levels, namely strong water-richness (C4), relatively strong water-richness (C3), medium water-richness (C2), and relatively weak water-richness (C1). Table 4 Evaluation indicators and grading standards. Full size table (2) Constructing a single indicator measurement function. Assuming there are n evaluation units in the aquifer to be evaluated, the space vector Q\u2009=\u2009{Q1, Q2, Q3, \u2026, Qn} can be used to represent it. For each unit Qi (I\u2009=\u20091, 2, \u2026, n) to be evaluated, there are m evaluation indicators, namely X\u2009=\u2009{X1, X2, X3, \u2026, Xm}. If Xij represents the quantitative value of the j evaluation indicator of the evaluation unit Qi, then the quantitative value of the evaluation indicator Qi of the evaluation unit Qi\u2009=\u2009{Xi1, Xi2, Xi3, \u2026, Xim}. If Qi has s levels of evaluation, then the level space R\u2009=\u2009{C1, C2, C3, \u2026, Cs }. Let Ck (k\u2009=\u20091, 2, \u2026, s) be the k level evaluation, if it satisfies C1\u2009>\u2009C2\u2009>\u2009C3\u2009>\u2009\u2026\u2009>\u2009Cs, then {C1, C2, C3, \u2026, Cs} is called an ordered partition class of the level space R. Let \\(\\alpha_{ijk} = \\alpha \\left( {X_{ij} \\in C_{k} } \\right)\\) represent the degree to which the quantified value of the evaluation index belongs to the k evaluation level Ck. If \u03b1 satisfies \\(0 \\le \\alpha \\left( {X_{ij} \\in C_{k} } \\right) \\le 1, \\, \\alpha \\left( {X_{ij} \\in R} \\right) = 1\\),\\(\\alpha \\left( {X_{ij} \\in C_{l} } \\right) = \\sum\\limits_{l = 1}^{k} {\\alpha \\left( {X_{ij} \\in C_{l} } \\right)}\\), it is called an uncertain measure, abbreviated as a measure. A matrix \\(\\left( {\\alpha_{ijk} } \\right)_{m \\times s}\\) is called a single-index measure evaluation matrix, that is: $$\\left( {\\alpha_{ijk} } \\right)_{m \\times s} = \\left[ {\\begin{array}{*{20}c} {\\begin{array}{*{20}c} {\\alpha_{i11} } & {\\alpha_{i12} } \\\\ \\end{array} } & {\\begin{array}{*{20}c} \\cdots & {\\alpha_{i1s} } \\\\ \\end{array} } \\\\ {\\begin{array}{*{20}c} {\\begin{array}{*{20}c} {\\alpha_{i21} } & {\\alpha_{i22} } \\\\ \\end{array} } \\\\ \\vdots \\\\ {\\begin{array}{*{20}c} {\\alpha_{im1} } & {\\alpha_{im2} } \\\\ \\end{array} } \\\\ \\end{array} } & {\\begin{array}{*{20}c} {\\begin{array}{*{20}c} \\cdots & {\\alpha_{i2s} } \\\\ \\end{array} } \\\\ {\\begin{array}{*{20}c} \\ddots & \\vdots \\\\ \\end{array} } \\\\ {\\begin{array}{*{20}c} \\cdots & {\\alpha_{ims} } \\\\ \\end{array} } \\\\ \\end{array} } \\\\ \\end{array} } \\right].$$ (33) According to the controlling factors and the characteristics of actual mining, this paper performed linear interpolation within the interval, that was, the idea of piecewise interpolation was used to insert linear points in each graded interval of the evaluation index. Based on the inserted points, a linear measure function was constructed as shown in Fig. 8. Figure 8 The linear measure function images. Full size image (3) Constructing a comprehensive measure of multiple indicators based on indicator weights. Let \\(\\alpha_{ik} = \\alpha \\left( {Q_{i} \\in C_{k} } \\right)\\) represent the degree to which the evaluation unit Qi belongs to the k evaluation level Ck. Then, the multi-index measure \\(\\alpha_{ik} = \\sum\\limits_{j = 1}^{m} {\\omega_{j} \\alpha_{ijk} }\\) can be represented by a matrix as follows: $$\\left( {\\alpha_{ik} } \\right)_{n \\times s} = \\left[ {\\begin{array}{*{20}c} {\\begin{array}{*{20}c} {\\alpha_{11} } & {\\alpha_{12} } \\\\ \\end{array} } & {\\begin{array}{*{20}c} \\cdots & {\\alpha_{1s} } \\\\ \\end{array} } \\\\ {\\begin{array}{*{20}c} {\\begin{array}{*{20}c} {\\alpha_{21} } & {\\alpha_{22} } \\\\ \\end{array} } \\\\ \\vdots \\\\ {\\begin{array}{*{20}c} {\\alpha_{n1} } & {\\alpha_{n2} } \\\\ \\end{array} } \\\\ \\end{array} } & {\\begin{array}{*{20}c} {\\begin{array}{*{20}c} \\cdots & {\\alpha_{2s} } \\\\ \\end{array} } \\\\ {\\begin{array}{*{20}c} \\ddots & \\vdots \\\\ \\end{array} } \\\\ {\\begin{array}{*{20}c} \\cdots & {\\alpha_{ns} } \\\\ \\end{array} } \\\\ \\end{array} } \\\\ \\end{array} } \\right].$$ (34) (4) Grading through confidence recognition criteria. To obtain the final evaluation result of the evaluation unit, a \"confidence degree\" identification criterion is adopted for the grading evaluation of aquifer water abundance40. If R\u2009=\u2009(c1\u2009>\u2009c2\u2009>\u2009c3 \u2026\u2009>\u2009cz), the evaluation space R is considered ordered. The confidence degree \u03bb is introduced, where \u03bb\u2009\u2265\u20090.5, and if \\(k_{0} = \\min \\left\\{ {k:\\sum\\limits_{l = 1}^{k} {\\alpha il \\ge \\lambda , \\, \\left( {k = 1,2, \\cdots ,s} \\right)} } \\right\\}\\), it can be regarded that the evaluation unit Qi belongs to the k0 evaluation level Ck0. Results and analysis Prediction of the development height of water-conducting fracture zones (1) Empirical formulas The lithology of the roof strata of the 4th coal seam in the Huafeng mine field was analyzed, and different empirical formulas were used to calculate the development height of the water-conducting fractured zone based on the different roof lithologies. The predicted values using the empirical formula method were plotted using Golden Software Surfer software, as shown in Fig. 10a. (2) The GRNN model A total of 63 measured cases were collected and organized, forming a 63\u2009\u00d7\u20095-dimensional raw data matrix (Table 5) (see the Supplementary Information 1). The selected four influencing factors were used as input parameters for the GRNN model, and the predicted values of the development height of the water-conducting fractured zone were used as output parameters. Since the number of layer parameters in the GRNN neural network model is equal to the number of input layers, and the number of summation layer parameters is one more than the output layer, the initial network structure of the GRNN neural network was designed as 4:4:2:1. Samples numbered 1 to 58 in the table were used as training samples, while samples numbered 59 to 63 were used as testing samples. The GRNN neural network model was trained using Matlab software, and the smoothing factor \u03c3 was adjusted to achieve the best fit of the training results. Finally, a GRNN neural network with a fitting degree of 0.9023 was obtained. Table 5 Measured sample data of the height of the water-conducting fractured zone. Full size table The coal seam thickness, proportion coefficient of hard rock lithology, dip length of the workface, and mining depth of the 4th coal seam in the Huafeng mine field were used as input parameters, and the developed GRNN model was utilized to predict the development height of the water-conducting fractured zone. The results were shown in Fig. 10b. The predicted values of water-conducting fractured zone development height for the test samples obtained from the GRNN neural network method and empirical formula method were compared. The relative error of the two methods was shown in Fig. 9, and the average relative errors were 3.22% and 16.75%, respectively. The prediction accuracy of the GRNN neural network method was significantly higher than that of the empirical formula method. Figure 9 Residual and relative error of different methods. Full size image The development height of the water-conducting fractured zone in the coal seam roof was calculated using the two aforementioned methods. The GRNN neural network method exhibited higher accuracy; however, prioritizing safety, the larger prediction value of the two methods was chosen as the final prediction value. A thematic map illustrating the predicted values of the water-conducting fractured zone development height was generated using Golden Software Surfer, as shown in Fig. 10c. The development trend of the water-conducting fractured zone in the roof of the 4th coal seam followed a relatively regular pattern, gradually increasing in height from south to north. The lowest predicted value for the development height of the water-conducting fractured zone was 58 m, while the highest reached up to 106 m. Figure 10 Predicted value of development height of water-conducting fracture zone. Full size image Calculation of the weight values of the main controlling factors for water-richness (1) Subjective weight. We invited a total of five researchers in coal mine water prevention and control and experts with rich on-site work experience in Huafeng mine field to evaluate and score the relative importance of the main controlling factors for water-richness of the clastic rock aquifer of the mining coal seam roof (Table 6), and constructed a judgment matrix, as shown in Tables 7, 8 and 9. Conducted a consistency check on each judgment matrix, and the test results were shown in the table. The consistency ratio CR was less than 0.1 (Table 10), which met the consistency requirements of the judgment matrix. The weight of each main controlling factor was shown in Table 11. (2) Objective weight. According to Rough Set Theory, by removing redundant parts from the data and combining the concept of Conditional Entropy, following the previously mentioned calculation steps of attribute weights, the objective weights of the main controlling factors for water abundance were obtained as shown in Table 12. (3) Combination weights. After obtaining the subjective and objective weights of each main controlling factor, the weight coefficients of the subjective and objective weights could be obtained by substituting them into Eq. (31), \\({\\alpha }_{1}\\), \\({\\alpha }_{2}\\) were 0.495 and 0.505 respectively (The table used for the calculation is shown in Supplementary Information 2). Therefore, the combination weighting model in this article was \\(\\omega_{i} = 0.495u_{1i} + 0.505u_{2i}\\). Table 6 Assessment of the main controlling factors. Full size table Table 7 Judgment matrix \\({\\varvec{A}}\\sim {{\\varvec{B}}}_{{\\varvec{i}}}({\\varvec{i}}=1\\sim 2)\\). Full size table Table 8 Judgment matrix \\({{\\varvec{B}}}_{1}\\sim {{\\varvec{C}}}_{{\\varvec{i}}}({\\varvec{i}}=1\\sim 3)\\). Full size table Table 9 Judgment matrix \\({{\\varvec{B}}}_{2}\\sim {{\\varvec{C}}}_{{\\varvec{i}}}({\\varvec{i}}=4\\sim 5)\\). Full size table Table 10 Consistency check table for judgment matrix. Full size table Table 11 Subjective weight of main controlling factors. Full size table Table 12 Objective weight of main controlling factors. Full size table From this, the final comprehensive weight of each main control factor could be obtained: the depth of the sandstone floor was 0.1644, the brittle rock ratio was 0.267, the lithological structure index was 0.2111, the fault strength index was 0.2215, and the fault intersections and endpoints density was 0.136. Draw a weighted radar chart to visualize the subjective, objective, and comprehensive weights, as shown in Fig. 11. Figure 11 Weighted radar chart. Full size image Constructing the water-richness evaluation model The mine field was divided into evaluation units with a size of 250 m \\(\\times\\) 250 m. Based on the previously collected and organized data on the controlling factors of water-richness evaluation, the central coordinates of each unit were used to perform Kriging interpolation using Golden Software Surfer. The evaluation units were used as the basis for constructing the water-richness zoning evaluation of the clastic aquifer in the 4th coal seam roof of the Huafeng mine field. Due to space limitations, it was not possible to list all the data for each evaluation unit. Only one evaluation unit, DY59, in the central part of the study area, would be used as an example to illustrate the water-richness rating based on the theory of uncertain measurement and the confidence criterion. The calculation method was as follows. (1) Calculating the single indicator measure evaluation matrix. Collected and organized the main controlling factor values of evaluation unit DY59, as shown in Table 13. Table 13 Measured values of the main controlling factors of DY59. Full size table By substituting the values of each main controlling factor into the linear measure function constructed, the single indicator measure evaluation matrix could be obtained as follows: $$\\alpha_{ijk} = \\left[ {\\begin{array}{*{20}c} {\\begin{array}{*{20}c} {} & {} \\\\ {} & { \\, 0.331} \\\\ \\end{array} } & {\\begin{array}{*{20}c} {\\begin{array}{*{20}c} {} & 1 & 1 \\\\ \\end{array} } \\\\ {\\begin{array}{*{20}c} {} & {} & {} \\\\ \\end{array} } \\\\ \\end{array} } \\\\ {\\begin{array}{*{20}c} {0.995} & {0.669} \\\\ {0.005} & {} \\\\ \\end{array} } & {\\begin{array}{*{20}c} {\\begin{array}{*{20}c} {0.826} & {} & {} \\\\ \\end{array} } \\\\ {\\begin{array}{*{20}c} {0.174} & {} & {} \\\\ \\end{array} } \\\\ \\end{array} } \\\\ \\end{array} } \\right].$$ (2) Calculating the multi-indicator comprehensive measure matrix. In 3.3.3 of this article, the comprehensive weight of the main controlling factors for water-richness evaluation was obtained, and the comprehensive weight vector was \\(\\omega = \\left\\{ {0.1644,0.267,0.2111,0.2215,0.136} \\right\\}\\), According to the equation \\(\\alpha_{ik} = \\sum\\limits_{j = 1}^{m} {\\omega_{j} \\alpha_{ijk} }\\), the evaluation vector \\(\\alpha_{ik} = \\left\\{ {0.358,0.088,0.517,0.038} \\right\\}\\) of the multi-indicator comprehensive measure of DY59 could be obtained. (3) The confidence criterion determines the evaluation level. With a confidence level of \u03bb\u2009=\u20090.5, the water-richness level of the DY59 evaluation unit was classified. When k was sorted from small to large, k0\u2009=\u2009C1\u2009+\u2009C2\u2009+\u2009C3\u2009=\u20090.358\u2009+\u20090.088\u2009+\u20090.517\u2009=\u20090 0.962\u2009>\u2009\u03bb (0.5). When k is sorted from large to small, k0\u2009=\u2009C4\u2009+\u2009C3\u2009=\u20090.555\u2009>\u2009\u03bb (0.5). Therefore, the water-richness level of the DY59 evaluation unit is relatively strong (C3). Through the aforementioned calculation steps, based on the theory of uncertain measurement and the confidence criterion, the water-richness evaluation level of all evaluation units within the study area could be computed, thus obtaining the water-richness zoning results of the aquifer in the mine field (The modeling process is demonstrated in Supplementary Information 3). The water-richness zoning map of the clastic aquifer in the 4th coal seam roof of the Huafeng mine field was created using Golden Software Surfer, as shown in Fig. 12. The water-richness in the study area was categorized into three levels: relatively weak water-richness (C1), medium water-richness (C2), and relatively strong water-richness (C3), with an overall low water-richness. The relatively weak water-richness zone occupied most of the study area, while the medium water-richness zone was distributed in the southwestern, central, and eastern parts of the study area. The relatively strong water-richness zone was present in small portions of the central and eastern parts of the study area. Figure 12 Water-richness zoning map of clastic rock aquifers on the roof of coal seam 4 in Huafeng mine field. Full size image Combined with the water inflow data and water inrush point records provided by the research area, the actual results were compared with the water abundance zoning model in this paper, as shown in Table 14. Table 14 Validation between prediction results and actual data. Full size table Taking the water inrush data as an example, out of 7 water inrush points, 2 of them did not match the model zoning, resulting in an accuracy rate of 71.43% for the model. Taking the water inflow data from workfaces as an example, out of 13 workfaces, 2 of them did not match the model zoning for water inflow, while 9 of them matched the model zoning to a certain extent, resulting in an accuracy rate of 84.62% for the model. Overall, the accuracy rate of the water-richness zoning model in this study could reach 80%. Conclusions (1) The method combining the GRNN neural network with empirical formulas was employed to calculate the predicted values of the development height of the water-conducting fracture zone above the mined coal seam. The predicted values for the development height of the water-conducting fracture zone in the 4th coal seam roof of the Huafeng mine field ranged from 58 to 106 m. This range was determined to assess the vertical extent of water-richness evaluation. Through quantitative analysis, the degree of water hazard threat to the mined coal seam was determined, thereby improving the accuracy of evaluating the water-richness of the clastic aquifer in the coal seam roof. (2) Depth of the sandstone floor, brittle rock ratio, lithological structure index, fault strength index, fault intersections and endpoints density were selected as the main controlling factors for water-richness in the study area, breaking away from the previous reliance on the unit water inflow factor. The method of the minimum deviation was introduced to optimize the combination of subjective weights obtained from the AHP and objective weights derived from the rough set theory improved by conditional entropy. This resulted in a combined weight that possesses the advantages of both subjective and objective weights. The combination weights for each main controlling factor are 0.1644, 0.267, 0.2111, 0.2215, and 0.136 in sequence. This significantly improves the reliability and accuracy of the weights, making the evaluation results more scientifically sound. (3) The theory of uncertain measurement was applied to the construction of a water-richness evaluation model by incorporating confidence identification criteria. The model was used to classify the water-richness of the clastic rock aquifer in the 4th coal seam roof of the Huafeng mine field. It was divided into relatively strong water-richness zones, medium water-richness zones, and relatively weak water-richness zones. By comparing the records of water inflow from workfaces and water inrush points within the study area, a high degree of agreement was observed, reaching 80% accuracy. This validates the feasibility and accuracy of the proposed method in this study. Data availability The datasets used and/or analyzedduring the current study are available from the corresponding author upon reasonable request. References Zhou, W. W. et al. Evaluation method and application of water-rich of clastic rock aquifer in mining seam roof. China Min. Mag. 29(12), 158\u2013164 (2020). Google Scholar   Xue, J. K. Application of water-rich index method based on fractal theory in water-rich evaluation of aquifer. J. Saf. Coal Mines 51(2), 197\u2013201 (2020). Google Scholar   Han, C. H. et al. Water-richness evaluation of sandstone aquifer based on set pair analysis-variable fuzzy set coupling method: A case from Jurassic Zhiluo formation of Jinjiaqu coal mine in Ningdong mining area. J. China Coal Soc. 45(7), 2432\u20132443 (2020). Google Scholar   State Administration of Work Safety, State Administration of Coal Mine Safety. Detailed Rules for Water Prevention and Control in Coal Mines (China Coal Industry Publishing House, 2018). Google Scholar   Qiu, M., Shi, L. Q., Teng, C. & Han, J. Water-richness evaluation of Ordovician limestone based on grey correlation analysis, FDAHP and geophysical exploration. Chin. J. Rock Mech. Eng. 35(S1), 3203\u20133213 (2016). Google Scholar   Li, Z. F. Application research of transient electromagnetic method in water-rich exploration of No. 8 coal seam in Changyuhe coal industry. Coal Mine Mod. 1, 77\u201379 (2020). CAS   Google Scholar   Li, S. Application of comprehensive geophysical exploration method in the detection of water-rich of roof sandstone in a certain mine. Inner Mongolia Coal Econ. 4, 181\u2013182 (2020). Google Scholar   Liu, S. Y. et al. An attempt to reduce ambiguity in geophysical interpretation. Geophys. Geochem. Explor. 34(06), 691\u2013696 (2010). Google Scholar   Zhou, Z. F. et al. Multi-source spatial information fusion-based water abundance zoning of the composite layer of water-bearing seam roof. Coal Geol. Explor. 47(01), 114\u2013120 (2019). Google Scholar   Huang, L., Gou, Q. S., Han, X., Hou, Z. M. & Deng, X. B. Method of evaluating the water-richness of aquifer based on unascertained measurement theory. J. Changjiang River Sci. Res. 39(07), 23\u201328 (2022). CAS   Google Scholar   Yu, X. G., Wang, D. D., Shi, L. Q. & Meng, M. M. Water-richness evaluation method of water-filled aquifer characteristics analysis based on evaluation method. J. Coal Technol. 35(10), 152\u2013154 (2016). Google Scholar   Tang, L. B., Wu, J. W., Bi, Y. S., Zhai, X. R. & Hu, R. Evaluation of aquifer water abundance based on AHP-entropy weight method. J. China Min. Mag. 29(12), 147\u2013152 (2020). Google Scholar   Bi, Y. S. et al. Evaluation of coal mine aquifer water-richness based on AHP and independent weight coefficient method. J. China Hydrol. 40(04), 40\u201345 (2020). Google Scholar   Wang, Y., Pu, Z. G., Ge, Q. & Liu, J. H. Study on the water-richness law and zoning assessment of mine water-bearing aquifers based on sedimentary characteristics. Sci. Rep. 12(1), 14107 (2022). Article   ADS   CAS   PubMed   PubMed Central   Google Scholar   Qiu, M. et al. Multifactor Prediction of the water richness of coal roof aquifers based on the combination weighting method and TOPSIS model: A case study in the Changcheng No. 1 coal mine. ACS Omega 7(49), 44984\u201345003 (2022). Article   CAS   PubMed   PubMed Central   Google Scholar   Li, Z., Zeng, Y. F., Liu, S. Q., Gong, H. J. & Niu, P. K. Application of back propagation artificial neural network in water abundance evaluation. J. Coal Eng. 50(08), 114\u2013118 (2018). Google Scholar   Gong, H. J., Liu, S. Q. & Zeng, Y. F. Evaluation research on water-richness of aquifer based on BP artificial neural network. J. Coal Technol. 37(09), 181\u2013182 (2018). Google Scholar   Li, X. et al. Water-richness zoning technology of karst aquifers at in the roofs of deep phosphate mines based on random forest model. Sustainability 15(18), 13852 (2023). Article   CAS   Google Scholar   State Bureau of Coal Industry. Regulations for the Retention and Mining of Coal Pillars in Buildings, Water Bodies, Railways, and Main Shafts and Tunnels (China Coal Industry Publishing House, 2000). Google Scholar   Hu, X. J., Li, W. P., Cao, D. T. & Liu, M. C. Index of multiple factors and expected height of fully mechanized water flowing fractured zone. J. China Coal Soc. 37(04), 613\u2013620 (2012). Google Scholar   Zhu, Z. J. & Liang, Z. A prediction model for top-coal drawing capability in steep seams based on PCA\u2013GRNN. Geofluids 2022, 1\u20139 (2022). Google Scholar   Xia, M. F. et al. Landslide prediction model based on KPCA-SSA-GRNN. J. Foreign Electron. Meas. Technol. 41(09), 109\u2013115 (2022). Google Scholar   Hu, Z., Zhao, Q. & Wang, J. The prediction model of worsted yarn quality based on CNN\u2013GRNN neural network. Neural Comput. Appli. 31(9), 4551\u20134562 (2019). Article   Google Scholar   Song, C., Wang, L., Hou, J., Xu, Z. S. & Huang, Y. H. The optimized GRNN based on the FDS-FOA under the hesitant fuzzy environment and its application in air quality index prediction. Appl. Intell. 51(11), 8364 (2021). Article   Google Scholar   Chen, T. & Xiao, L. Application of RBF and GRNN neural network model in river ecological security assessment\u2014Taking the middle and small rivers in Suzhou City as an example. Sustainability 15(8), 6522 (2023). Article   Google Scholar   Yu, X. Prediction of chemical toxicity to Tetrahymena pyriformis with four-descriptor models. J. Ecotoxicol. Environ. Saf. 190, 110146 (2020). Article   CAS   Google Scholar   Yin, H. Y. et al. A GIS-based model of potential groundwater yield zonation for a sandstone aquifer in the Juye Coalfield, Shangdong, China. J. Hydrol. 557, 434\u2013447 (2018). Article   ADS   Google Scholar   Jarvie, D. M., Hill, R. J., Ruble, T. E. & Pollastro, R. M. Unconventional shale- gas systems: The Mississippian barnett shale of northcentral Texas as one model for thermogenic shale-gas assessment. J. AAPG Bull. 9(4), 475\u2013499 (2007). Article   Google Scholar   Bishop, A. W. Progressive failure with special reference to the mechanism causing it C. Proc. Geotech. Conf. 142\u201350, 523\u2013527 (1967). Google Scholar   Altindag, R. The evaluation of rock brittleness concept on rotary blast hold drills. J. South. Afr. Inst. Min. Metal. 102(1), 61\u201366 (2002). Google Scholar   Yin, H. Y., Wei, J. C., Guo, J. B. & Li, X. F. Prediction of water-rich of coal measures sandstone based on structure-lithology structure index method. Geol. Rev. 59, 1195\u20131196 (2013). Google Scholar   Shi, L. Q., Liu, J., Qiu, M. & Gao, W. F. Application of quantification in risk assessment of water inrush. J. China Sci. Pap. 15(01), 100\u2013104 (2020). Google Scholar   Saaty, T. L. The analytic hierarchy process. J. Oper. Res. Soc. 41(11), 1073\u20131076 (1980). Google Scholar   Sun, B. & Wang, L. J. Study of the method for determining weight based on rough set theory. J. Comput. Eng. Appl. 29, 216\u2013217 (2006). Google Scholar   Ma, B. C., Tan, F., Jiao, Y. Y. & Gan, Q. Construction method of geological suitability evaluation model of underground space development based on rough set and AHP. J. Saf. Environ. Eng. 27(06), 153\u2013159 (2020). Google Scholar   Liang, Y. H., Li, L. X., Cheng, Y. F. & Liu, G. Comprehensive evaluation of rockburst based on AHP and rough set theory. J. New Technol. New Prod. China 15, 1\u20133 (2021). Google Scholar   Zhang, X. J., Li, J. H. & Ding, K. S. Application of combination weight model with minimum deviation in evaluation of water resources emergency management capability. J. Water Resour. Power 34(06), 22\u201326 (2016). Google Scholar   Fu, W. Z. & Li, N. X. Research on minimum deviation method of index weight of regional innovation capability based on combination of ANP and GRAP. J. Soft Sci. 29(11), 130\u2013134 (2015). Google Scholar   Zhao, D. K. & Zhang, J. A mathematical model for floor water inrush risk evaluation based on entropy weight-unascertained theory. J. Coal Eng. 48(S2), 121\u2013124 (2016). Google Scholar   Cheng, Q. S. Theoretical model of attribute recognition and its application. J. Acta Sci. Nat. Univ. Pekinensis. 1, 14\u201322 (1997). Google Scholar   Download references Acknowledgements We gratefully acknowledge the financial support of the National Natural Science Foundation of China (51804184), the Shandong Province Nature Science Fund (ZR2020KE023). Author information Authors and Affiliations College of Earth Sciences and Engineering, Shandong University of Science and Technology, Qingdao, 266590, China Mei Qiu, Zhendong Shao, Yan Zheng, Guichao Gai, Zhaodi Han & Jianfei Zhao Key Laboratory of Sedimentary Mineralization and Sedimentary Minerals in Shandong Province, Shandong University of Science and Technology, Qingdao, 266590, China Mei Qiu, Zhendong Shao, Yan Zheng, Guichao Gai, Zhaodi Han & Jianfei Zhao Shandong Shengyuan Geological Exploration Co., Ltd, Taian, 271000, China Weiqiang Zhang Jinan Rail Transit Group CO., LTD, Jinan, 250013, China Xinyu Yin Contributions M.Q.: Conceptualization, Review. Z.S.: Methodology, Writing\u2014original draft. W.Z.: Original Draft, Investigation. Y.Z.: Data compilation. X.Y.: Data compilation. G.G.: Data compilation. Z.H.: Data compilation. J.Z.: Data compilation. Corresponding author Correspondence to Mei Qiu. Ethics declarations Competing interests The authors declare no competing interests. Additional information Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Supplementary Information Supplementary Information 1. Supplementary Information 2. Supplementary Information 3. Rights and permissions Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. Reprints and permissions About this article Cite this article Qiu, M., Shao, Z., Zhang, W. et al. Water-richness evaluation method and application of clastic rock aquifer in mining seam roof. Sci Rep 14, 6465 (2024). https://doi.org/10.1038/s41598-024-57033-x Download citation Received 22 December 2023 Accepted 13 March 2024 Published 18 March 2024 DOI https://doi.org/10.1038/s41598-024-57033-x Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Keywords Water-richness Clastic rock Neural network Combination weighting method Unascertained measures theory Subjects Hydrology Natural hazards Comments By submitting a comment you agree to abide by our Terms and Community Guidelines. If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate. Download PDF Sections Figures References Abstract Introduction Study area Data and method Results and analysis Conclusions Data availability References Acknowledgements Author information Ethics declarations Additional information Supplementary Information Rights and permissions About this article Comments Advertisement Scientific Reports (Sci Rep) ISSN 2045-2322 (online) About Nature Portfolio About us Press releases Press office Contact us Discover content Journals A-Z Articles by subject Protocol Exchange Nature Index Publishing policies Nature portfolio policies Open access Author & Researcher services Reprints & permissions Research data Language editing Scientific editing Nature Masterclasses Research Solutions Libraries & institutions Librarian service & tools Librarian portal Open research Recommend to library Advertising & partnerships Advertising Partnerships & Services Media kits Branded content Professional development Nature Careers Nature Conferences Regional websites Nature Africa Nature China Nature India Nature Italy Nature Japan Nature Korea Nature Middle East Privacy Policy Use of cookies Your privacy choices/Manage cookies Legal notice Accessibility statement Terms & Conditions Your US state privacy rights \u00a9 2024 Springer Nature Limited",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "Single-cell transcriptomic sequencing data reveal aberrant DNA methylation in SMAD3 promoter region in tumor-associated fibroblasts affecting molecular mechanism of radiosensitivity in non-small cell lung cancer",
    "doi": "10.1186/s12967-024-05057-2",
    "description": "Objective: Non-small cell lung cancer (NSCLC) often exhibits resistance to radiotherapy, posing significant treatment challenges. This study investigates the role of SMAD3 in NSCLC, focusing on its potential in influencing radiosensitivity via the ITGA6/PI3K/Akt pathway. Methods: The study utilized gene expression data from the GEO database to identify differentially expressed genes related to radiotherapy resistance in NSCLC. Using the GSE37745 dataset, prognostic genes were identified through Cox regression and survival analysis. Functional roles of target genes were explored using Gene Set Enrichment Analysis (GSEA) and co-expression analyses. Gene promoter methylation levels were assessed using databases like UALCAN, DNMIVD, and UCSC Xena, while the TISCH database provided insights into the correlation between target genes and CAFs. Experiments included RT-qPCR, Western blot, and immunohistochemistry on NSCLC patient samples, in vitro studies on isolated CAFs cells, and in vivo nude mouse tumor models. Results: Fifteen key genes associated with radiotherapy resistance in NSCLC cells were identified. SMAD3 was recognized as an independent prognostic factor for NSCLC, linked to poor patient outcomes. High expression of SMAD3 was correlated with low DNA methylation in its promoter region and was enriched in CAFs. In vitro and in vivo experiments confirmed that SMAD3 promotes radiotherapy resistance by activating the ITGA6/PI3K/Akt signaling pathway. Conclusion: High expression of SMAD3 in NSCLC tissues, cells, and CAFs is closely associated with poor prognosis and increased radiotherapy resistance. SMAD3 is likely to enhance radiotherapy resistance in NSCLC cells by activating the ITGA6/PI3K/Akt signaling pathway.",
    "journal": "Journal of Translational Medicine",
    "authors": [
      "Han F.",
      "Chen S.",
      "Zhang K.",
      "Zhang K.",
      "Wang M.",
      "Wang P."
    ],
    "citation_count": "0",
    "full_text": "Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Advertisement Search Explore journals Get published About BMC Login Journal of Translational Medicine Home About Articles Submission Guidelines Submit manuscript Research Open access Published: 16 March 2024 Single-cell transcriptomic sequencing data reveal aberrant DNA methylation in SMAD3 promoter region in tumor-associated fibroblasts affecting molecular mechanism of radiosensitivity in non-small cell lung cancer Fushi Han, Shuzhen Chen, Kangwei Zhang, Kunming Zhang, Meng Wang & Peijun Wang  Journal of Translational Medicine  22, Article number: 288 (2024) Cite this article 372 Accesses 1 Altmetric Metrics Abstract Objective Non-small cell lung cancer (NSCLC) often exhibits resistance to radiotherapy, posing significant treatment challenges. This study investigates the role of SMAD3 in NSCLC, focusing on its potential in influencing radiosensitivity via the ITGA6/PI3K/Akt pathway. Methods The study utilized gene expression data from the GEO database to identify differentially expressed genes related to radiotherapy resistance in NSCLC. Using the GSE37745 dataset, prognostic genes were identified through Cox regression and survival analysis. Functional roles of target genes were explored using Gene Set Enrichment Analysis (GSEA) and co-expression analyses. Gene promoter methylation levels were assessed using databases like UALCAN, DNMIVD, and UCSC Xena, while the TISCH database provided insights into the correlation between target genes and CAFs. Experiments included RT-qPCR, Western blot, and immunohistochemistry on NSCLC patient samples, in vitro studies on isolated CAFs cells, and in vivo nude mouse tumor models. Results Fifteen key genes associated with radiotherapy resistance in NSCLC cells were identified. SMAD3 was recognized as an independent prognostic factor for NSCLC, linked to poor patient outcomes. High expression of SMAD3 was correlated with low DNA methylation in its promoter region and was enriched in CAFs. In vitro and in vivo experiments confirmed that SMAD3 promotes radiotherapy resistance by activating the ITGA6/PI3K/Akt signaling pathway. Conclusion High expression of SMAD3 in NSCLC tissues, cells, and CAFs is closely associated with poor prognosis and increased radiotherapy resistance. SMAD3 is likely to enhance radiotherapy resistance in NSCLC cells by activating the ITGA6/PI3K/Akt signaling pathway. Introduction Lung cancer is the most prevalent type of cancer globally and results in the highest number of deaths compared to other cancer types [1]. The 5-year survival rate for lung cancer is merely 18% [2]. Among the two types of lung cancer, namely small cell lung cancer (SCLC) and non-small cell lung cancer (NSCLC), NSCLC has the highest incidence rate, and patients with this type of lung cancer have a poor prognosis with low 5-year survival rates [3, 4]. Current strategies for lung cancer treatment include surgery, radiation therapy, and chemotherapy [5]. Nevertheless, due to the challenges in early diagnosis and malignant metastasis, the mortality risk for lung cancer patients remains remarkably high [6,7,8]. It is worth noting that the resistance to treatment caused by uncontrolled proliferation, invasion, and migration of lung cancer cells is attributed to various molecular pathways and mechanisms [9]. Radiation resistance is a significant concern in the treatment of non-small cell lung cancer (NSCLC) and is a leading cause of cancer-related mortality [10]. Despite its therapeutic potential, radiotherapy frequently fails to adequately control tumor growth, a failure partly attributed to the emergence of radioresistance [11]. In NSCLC, radioresistance emerges from a multifaceted process encompassing gene expression alterations, DNA damage repair pathway modifications, and changes in various signaling pathways [12]. Additional factors, such as tumor hypoxia and the presence of cancer stem cells, are also implicated in radioresistance development [13]. Consequently, an enhanced understanding of the mechanisms underpinning radioresistance in NSCLC is imperative for devising effective therapeutic strategies aimed at improving patient outcomes in this context [14]. Potential strategies include the development of novel radiosensitizers, targeted therapies, and combination treatment modalities to mitigate radioresistance and thereby enhance the efficacy of radiation therapy in NSCLC patients [15]. Cancer-associated fibroblasts (CAFs), as integral cellular constituents of the tumor microenvironment, play a pivotal role in regulating tumor progression and modulating tumor radioresistance. They exert their influence through the secretion of growth factors, chemokines, cytokines, signaling molecules, and components of the extracellular matrix [16]. Therapeutic approaches targeting the inhibitory modulation of CAF activity or their signaling pathways promise to enhance radiation therapy outcomes in NSCLC, thereby improving clinical responses in patients [17]. SMAD3, functioning as an intracellular signaling molecule for transforming growth factor-\u03b2 (TGF-\u03b2) and activator receptors [18], has been implicated in regulating NSCLC cell proliferation, migration, and invasion. Notably, the silencing of SMAD3 has been observed to inhibit these cellular processes [19]. Furthermore, SMAD3 has been implicated in promoting radiotherapy and cisplatin resistance in NSCLC, mediated by RMRP [20]. The GSE20549 dataset reveals a positive correlation between SMAD3 and integrin subunit alpha 6 (ITGA6), a transmembrane glycoprotein adhesion receptor protein widely expressed in various tumors, known to facilitate cancer cell migration and invasion [21, 22]. Inhibition of ITGA6 has been shown to curtail NSCLC cell proliferation, colony formation, migration, and invasion, while inducing cell cycle arrest and apoptosis [23]. ITGA6 has been identified as a gene associated with radiation resistance, as evidenced by extensive cellular RNA-seq data from esophageal squamous carcinoma tissues and KYSE-150 cell lines of patients treated with radiotherapy [24,25,26]. The knockdown of ITGA6 in gallbladder cancer cells results in the inhibition of the phosphatidylinositol 3-kinase/protein kinase B (PI3K/Akt) pathway activity [27]. This pathway, known for its aberrant activation in cancers, plays a crucial role in tumorigenesis and progression, particularly in NSCLC, thus representing a vital target in combating this disease [28, 29]. Moreover, the activation of the PI3K/Akt pathway has been linked to enhanced radioresistance in NSCLC [12]. Therefore, we hypothesize that SMAD3 secreted by cancer-associated fibroblasts (CAFs) may regulate the downstream PI3K/Akt signaling pathway through its interaction with ITGA6, thereby affecting cell proliferation and survival and consequently influencing the sensitivity of non-small cell lung cancer (NSCLC) to radiation therapy. In this study, we aim to investigate the mRNA and protein expression levels of key molecules in the SMAD3/ITGA6 signaling pathway and relevant post-translational modifications using single-cell RNA sequencing (scRNA-seq) data, as well as in vitro and in vivo experiments. Additionally, by manipulating gene overexpression or silencing, we will explore the molecular mechanisms and biological functions regulated by the SMAD3/ITGA6 signaling pathway. Lastly, we will utilize animal models to further evaluate the potential role of SMAD3/ITGA6 in chemosensitivity of NSCLC, providing new theoretical evidence for the optimization of therapeutic strategies for NSCLC. Materials and methods Retrieval of public data for NSCLC research NSCLC-associated datasets GSE2514, GSE18842, GSE21933, GSE31552, GSE44077, GSE20549, and GSE37745 were obtained from the GEO database. Specifically, dataset GSE2514 comprised 19 control samples and 20 NSCLC samples, GSE18842 included 45 control samples alongside 46 NSCLC samples, GSE21933 encompassed 21 control and 21 NSCLC samples, GSE31552 contained 68 control and 63 NSCLC samples, GSE44077 consisted of 66 control and 55 NSCLC samples, and GSE20549 featured 21 radioresistant NSCLC cell lines in contrast to 21 radiosensitive NSCLC cell lines. Additionally, gene expression data and corresponding clinical information for 196 NSCLC patients were procured from GSE37745 for the purpose of prognostic analysis. The Kaplan\u2013Meier plotter database was employed for the prognosis analysis of genes in NSCLC. The Human Protein Atlas database was also utilized to validate the protein expression in normal lung tissues and NSCLC tissues. DNA methylation profiles (Illumina Human Methylation 450 K) from NSCLC tumor tissues in TCGA were downloaded from the UCSC Xena database. Concurrently, the methylation levels of genes in NSCLC and normal tissues were determined using the UALCAN and DNMIVD databases. Differentially expressed genes (DEGs) in NSCLC were selected using the \u201climma\u201d package in R software. The volcano plot was generated to depict the DEGs, with the threshold set at |log FC|>\u20091, FDR\u2009<\u20090.05, and P value\u2009<\u20090.05 [30]. Analytical procedures for gene expression and protein\u2013protein interactions in NSCLC Differentially expressed genes (DEGs) in NSCLC were identified through the R \u201climma\u201d package, with a significance threshold set at a p-value of less than 0.05. Subsequently, a volcano plot representing these DEGs was constructed. Protein\u2013protein interaction (PPI) analysis of the proteins encoded by target genes was conducted utilizing the STRING database. The visualization of this PPI network was achieved with Cytoscape 3.8.2 software. Within the PPI network, nodes were organized using the Degree method, and the top 15 nodes were selected for advanced analysis. Cox regression analysis and construction of nomogram The GSE37745 dataset underwent univariate Cox regression analysis to discern prognostic genes for NSCLC. Hazard ratios (HR) and 95% confidence intervals (CI) for each gene were computed using the R \u201cforestplot\u201d package, adhering to a significance threshold of a p-value less than 0.05. Following this, both univariate and multivariate Cox regression analyses were executed to ascertain independent prognostic factors for NSCLC. A nomogram, based on the outcomes of the multivariate Cox regression analysis, was developed using the R \u201crms\u201d package to forecast the 1-, 2-, and 3-year overall survival rates. The precision of the nomogram was evaluated through a calibration chart. Enrichment analysis and correlation assessment of DEGs The NSCLC samples from the GSE37745 dataset were divided into two groups based on the median expression value of SMAD3: the high SMAD3 expression group and the low SMAD3 expression group. Gene Set Enrichment Analysis (GSEA) (http://software.broadinstitute.org/gsea/) was utilized to reveal the pathway differences between the high and low SMAD3 expression groups. The \u201cc2.cp.kegg.v7.4.symbols.gmt\u201d gene set from MSigDB was used as a reference gene set, with NOM p-val\u2009<\u20090.05 considered significantly enriched. DEGs between the high and low SMAD3 expression groups were identified using the \u201climma\u201d package, with a threshold of |log FC|>\u20091, FDR\u2009<\u20090.05, and P value\u2009<\u20090.05. Spearman\u2019s method was employed to perform correlation analysis on the DEGs with a correlation coefficient\u2009>\u20090.4 and P\u2009<\u20090.05, yielding the SMAD3-related genes. Patient enrollment and sample collection In this investigation, 120 patients (comprising 54 males and 66 females, aged between 29 and 84 years, with an average age of 62 years) were enrolled. These individuals underwent NSCLC surgery at Tongji Hospital, Tongji University School of Medicine, from January 2018 to January 2020. The study received approval from the Clinical Ethics Committee of Tongji Hospital, Tongji University School of Medicine (Approval No. SBKT-2023-052) and was conducted in strict adherence to the Declaration of Helsinki. Informed consent was duly obtained from all participants. Tissue samples, both from NSCLC and adjacent normal areas, were excised from the enrolled patients and immediately frozen in liquid nitrogen. A portion of each tissue sample was fixed in 10% neutral buffered formalin and preserved in a \u2212 80 \u2103 freezer. None of the patients had received chemotherapy or radiotherapy prior to their inclusion in the study. The histopathological characteristics of the tumors were classified in accordance with the criteria of the eighth edition of the American Joint Committee on Cancer staging system manual [31]. Comprehensive information regarding the enrolled patients is detailed in Additional file 4: Table S1. Follow-up data were systematically collected, with overall survival defined as the duration from the date of surgery to either the date of death or the follow-up endpoint. Isolation of CAFs and normal tissue-associated fibroblasts (Nafs) Tumor tissues and adjacent normal tissues (situated at least 2 cm from the tumor\u2019s outer edge) from four NSCLC patients were surgically resected and dissected into pieces measuring 1\u20133 mm3. These tissue fragments were then digested with 1 mg/mL collagenase I (#C0130, Sigma) at 37 \u00b0C for 2 h. Following digestion, the solution underwent centrifugation at 1000 rpm for 5 min, was washed twice with PBS, and filtered through a 100 \u03bcm filter. The isolated cells were subsequently cultured in 10 cm dishes. Preparation of conditioned medium (CM) from fibroblasts CAFs or NAFs were cultured in 75 cm2 bottles. After 48 h, upon reaching approximately 80% confluence, the medium was harvested and centrifuged at 3000 rpm for 30 min at 4 \u00b0C. The supernatant, designated as conditioned medium (CM), was collected and stored at \u2212 80 \u00b0C, while the normal medium constituted fresh RPMI-1640 medium supplemented with 10% FBS [32]. RT-qPCR Total RNA was extracted from both cell lines and tissue samples utilizing TRIzol reagent (15,596\u2013018, Solarbio). Subsequent to this, cDNA synthesis was performed using the PrimeScript\u2122 RT-PCR kit (TaKaRa) for the purpose of mRNA detection. RT-qPCR analyses were conducted employing the SYBR Premix Ex TaqTM kit (TaKaRa) on the LightCycler 480 system (Roche Diagnostics, Pleasanton, CA). GAPDH served as the internal reference, and fold changes in gene expression were quantified using the relative quantification method (2\u2212\u25b3\u25b3Ct method) [33]. Primers, designed and synthesized by Shanghai General Co., Ltd. (Shanghai, China), are listed in Additional file 4: Table S2. Immunohistochemistry Paraffin-embedded NSCLC tissue and mouse tumor sections, each 4 \u03bcm thick, underwent antigen retrieval and were subsequently blocked with 5% BSA (37,525, Thermo Fisher Scientific Inc., Waltham, MA) for 20 min. The sections were then incubated overnight at 4 \u00b0C with primary antibodies against SMAD3 (1:500, ab40854, Abcam Inc., Cambridge, UK), ITGA6 (1:500, ab181551, Abcam), and Ki67 (1:100, ab15580, Abcam). On the following day, sections were re-incubated with a biotinylated secondary antibody goat anti-rabbit IgG (1:1000, ab6721, Abcam) for 20 min and developed with DAB, followed by hematoxylin counterstaining. Microscopic examination was carried out (Leica-DM2500, Leica, Wetzlar, Germany) across five randomly selected fields from each section, with tan staining indicative of positive staining. Quantitative analysis was performed utilizing Image Pro-Plus 7.1 software (Media Cybernetics, Silver Spring, MD). Western blot Tumor tissues and cells were lysed using enhanced RIPA buffer (P0013B, Beyotime, Shanghai, China) containing a 1% protease inhibitor cocktail for total protein extraction, after which protein concentration was determined. Proteins were separated by SDS-PAGE and electrotransferred onto PVDF membranes. The membranes, laden with protein, were then blocked with 5% BSA and incubated overnight at 4 \u00b0C with rabbit primary antibodies against SMAD3 (ab208182, 1:1000, Abcam), ITGA6 (ab181551, 1:2000, Abcam), PI3K (ab154598, 1:2000, Abcam), phosphorylated AKT (#9271, 1:1000, Cell Signaling Technologies [CST], Beverly, MA), AKT (#9272, 1:1000, CST), and GAPDH (ab181602, 1:10,000, Abcam). The following day, membranes were probed with an HRP-labeled secondary antibody IgG (rabbit, #7074, 1:5000, CST) for one hour at room temperature. ECL reagent (CPSOC, Sigma) was utilized for visualization of results on X-ray film (Z380164, Sigma), and ImageJ software was applied for quantitative analysis, with GAPDH as the internal reference. Methylation-specific PCR (MSP) Modified DNA underwent purification and was subsequently subjected to methylation-specific PCR (MSP). For this assay, both methylation-specific and non-methylation-specific primers were utilized, along with 100 ng of bisulfite-modified DNA. PCR was carried out employing the GeneAmp DNA amplification kit (4,322,288, Applied Biosystems, Foster City, CA) and AmpliTaq Gold polymerase (4,298,813, Applied Biosystems). The PCR products were subsequently analyzed via agarose gel electrophoresis and visualized through ethidium bromide staining. The sequences of the primers used for MSP are detailed in Additional file 4: Table S3. Culture of cell lines The human NSCLC cell lines H460 (HTB-177, ATCC, Manassas, VA), NCI-H2228 (CL-0570, Wuhan Procell Life Science & Technology Co., Ltd., Wuhan, China), NCI-H3122 (CBP60133, COBIOER BIOSCIENCES CO., LTD., Nanjing, Jiangsu, China), PC9 (CBP73272, COBIOER), H1229 (CRL-5803, ATCC), and H520 (CL-0402, Procell), along with the human bronchial epithelial cell line 16HBE (CL0249, Procell), were cultured in RPMI-1640 medium (12,633,012, Gibco, Grand Island, NY) supplemented with 10% FBS (26,140,079, Gibco). The cell culture was maintained in a 5% CO2 incubator at 37 \u00b0C. Cell treatment and lentiviral transduction When H460 cells reached 75% confluence in 6-well plates (1\u2009\u00d7\u2009105 cells/well) after 24 h, they were treated with 50% NAF-CM or CAF-CM. Additionally, these cells were transduced with lentivirus carrying oe-NC, oe-SMAD3, oe-ITGA6, oe-SMAD3\u2009+\u2009sh-NC, oe-SMAD3\u2009+\u2009sh-ITGA6, or co-treated with CAF-CM and either sh-NC or sh-ITGA6. H1229 cells underwent transduction with lentivirus carrying sh-NC, sh-SMAD3, sh-ITGA6, sh-SMAD3\u2009+\u2009oe-NC, or sh-SMAD3\u2009+\u2009oe-ITGA6. Following 8 h of transduction, the cells were exposed to varying doses of radiation (0, 2, 4, and 6 Gy), and 24 h later, subsequent experiments were conducted. Each experimental condition was replicated thrice. The mentioned lentivirus was procured from Shanghai Genechem Co., Ltd. (Shanghai, China), with the sequences presented in Additional file 4: Table S4. CCK-8 assay Post-transduction, H460 and H1229 cells were seeded into 96-well plates at a density of 5\u2009\u00d7\u200910^4 cells/well. They were subsequently exposed to varying radiation doses (0, 2, 4, and 6 Gy) for 48 h. Cell viability was determined using the CCK-8 kit (K1018, Apexbio). To each well, 10 \u03bcL of CCK-8 solution was added, and the cells were incubated for 2 h at 37 \u00b0C. The optical density (OD) value at 450 nm was measured using a Multiskan FC microplate reader (51,119,080, Thermo Fisher Scientific) to ascertain cell viability. Colony formation assay Cells were plated in 6-well plates at a density of 200 cells per well and cultured for 24 h. Following this, the cells underwent irradiation at 6 Gy and were further cultured for an additional 14 days. Subsequently, the cells were fixed with 4% paraformaldehyde, stained with 0.5% crystal violet, and photographed. The number of colonies was counted. Transwell assay A Transwell chamber (8 \u03bcm pore size; Corning Incorporated, Corning, NY, USA) in 24-well plates was utilized for the cell invasion experiment. Initially, 600 \u03bcL of RPMI-1640 medium with 20% FBS was added to the Transwell chamber lined with Matrigel and equilibrated at 37 \u00b0C for 1 h. NSCLC cells, post-transfection for 48 h, were resuspended in RPMI-1640 medium containing 10% FBS, and 100 \u03bcL of 1\u2009\u00d7\u2009109/L cells were placed in the upper chamber. They were cultured at 37 \u00b0C with 5% CO2 for 24 h. Cells were then fixed with 4% methanol, stained with 0.1% crystal violet, and imaged under an inverted microscope (Olympus IX73, Olympus Optical Co., Ltd, Tokyo, Japan) in five randomly selected fields. Immunofluorescence staining Cover glasses underwent washing in PBS and were blocked for 1 h in 10% BSA at 25 \u00b0C. The sections were then incubated with primary rabbit antibodies against \u03b3-H2ax (1:400, #9718, Cell Signaling Technology), \u03b1-SMA (1:200, #19,245, Cell Signaling Technology), and FAP (1:200, #66,562, Cell Signaling Technology) at 4 \u00b0C for 12\u201316 h. This was followed by incubation with Alexa-Fluor 647-containing donkey anti-rabbit IgG (Thermo Fisher Scientific) for 1 h at 25 \u00b0C. Thereafter, sections were stained with DAPI (10 \u03bcg/mL, Sigma) for 15 min at 25 \u00b0C and observed under either an Olympus BX51 fluorescence microscope (Olympus) or a laser scanning confocal microscope (FV500; Olympus). Flow cytometry Cell cycle progression and apoptosis in cells post-6 Gy X-ray radiation exposure were evaluated using a CytoFLEX-S flow cytometer (Beckman Coulter). This analysis employed the Annexin V-APC/PI Cell Apoptosis Detection kit and Cell Cycle Detection kit (KeyGen Biotech). Cells were harvested, washed with cold PBS, and then incubated with 5 \u03bcL Annexin V-APC and 1 \u03bcL PI working solution (100 \u03bcg/mL) in darkness for 15 min at room temperature. The obtained data were processed using FlowJo software. Apoptotic cells were identified, with the second and third quadrants indicating late and early apoptosis, respectively. Xenografts in nude mice Eighty 4-week-old female SPF BALB/c nude mice (Beijing Vital River Laboratory Animal Technology Co., Ltd., Beijing, China) were accommodated individually in an SPF laboratory, maintained at 22\u201325 \u00b0C and 60\u201365% humidity, and subjected to a 12-h light/dark cycle. The mice had unrestricted access to food and water and were acclimatized for one week prior to experimentation. The animal experiments were conducted following approval from the Animal Ethics Committee of Tongji Hospital, Tongji University School of Medicine (Approval No. 2023-DW-SB-018), in compliance with the US National Institutes of Health's Guide for the Care and Use of Laboratory Animals. The mice were subcutaneously injected with H460 cell suspensions (5\u2009\u00d7\u2009105 cells/100 \u00b5L) treated with oe-NC, oe-SMAD3, oe-ITGA6, oe-SMAD3\u2009+\u2009sh-NC, oe-SMAD3\u2009+\u2009sh-ITGA6, or H460 cells equally mixed with NAFs, CAFs, CAFs\u2009+\u2009sh-NC, and CAFs\u2009+\u2009sh-ITGA6. Each group subsequently received 10 Gy X-ray radiation. Irradiation was conducted using a Varian Clinac 600c, set at 250 cGy/min and positioned 80 cm from the skin [34]. Mice were anesthetized with isoflurane, shielded with lead to expose only the tumors to radiation. The irradiated tumor area was 1 cm larger than the tumor margin covered by the lead. Once the tumor volume reached 70 mm^3, the mice underwent 10 Gy X-ray radiation weekly for three weeks. After 28 days, the mice were euthanized under anesthesia with 1% sodium pentobarbital, and the tumors were excised and weighed. Each experimental setup was replicated three times. Tumor volume was calculated using the formula: volume\u2009=\u2009(length\u2009\u00d7\u2009width2)/2. TUNEL assay Apoptosis within tumor tissues was detected using the TUNEL Apoptosis Detection Kit (Millipore, Billerica, MA). The sections were incubated in a 3% hydrogen peroxide solution in PBS for 20 min at room temperature, followed by incubation with a biotin labeling solution for 60 min at 37 \u00b0C in darkness. Subsequently, the sections were incubated with 50 \u03bcL Streptavidin-HRP working solution for 30 min at room temperature. The development process involved 0.2\u20130.5 mL DAB solution for 5\u201330 min, and images were captured under an inverted microscope from ten randomly selected fields per section. The count of apoptosis-positive cells (displaying brownish-yellow nuclei) and total cells (with blue-stained nuclei) was conducted. The apoptosis rate was calculated as the percentage of brownish-yellow cells to blue cells. Statistical analysis For data processing, R statistical software (v4.1.1) (R Foundation for Statistical Computing, Vienna, Austria) and SPSS 21.0 (IBM Corp. Armonk, NY) were utilized. The correlation between SMAD3 gene expression and methylation levels at CpG sites was assessed using Spearman correlation analysis. Differences in methylation levels between the high and low SMAD3 expression groups were evaluated using Student\u2019s t-test. Measurement data were represented as mean\u2009\u00b1\u2009standard deviation. Comparisons between two groups were made using independent sample t-tests, while comparisons among multiple groups were conducted via one-way ANOVA, followed by Tukey\u2019s post hoc tests. Time-based data were analyzed using repeated measures ANOVA. A p-value of less than 0.05 was considered indicative of statistical significance. Results Fifteen genes related to the radioresistance of NSCLC cells are identified based on the GEO datasets To identify the key genes in NSCLC, we first performed differential analysis of the five datasets from GEO database (GSE2514, GSE18842, GSE21933, GSE31552 and GSE44077). The obtained results showed 3736 DEGs in the GSE2514 dataset, including 1986 upregulated DEGs and 1750 downregulated DEGs, 13,375 DEGs comprising 7185 upregulated DEGs and 6190 downregulated DEGs in the GSE18842 dataset, 6917 DEGs comprising 2811 upregulated DEGs and 3238 downregulated DEGs in the GSE21933 dataset, 7455 DEGs comprising 4125 upregulated DEGs and 3330 downregulated DEGs in the GSE31552 dataset, and 13,687 DEGs including 7949 upregulated DEGs and 5738 downregulated DEGs in the GSE44077 dataset (Additional file 1: Fig. S1A). Following intersection analysis of the up-regulated or downregulated DEGs from the five datasets, 637 upregulated DEGs (Additional file 1: Fig. S1B) and 610 downregulated DEGs (Additional file 1: Fig. S1C) were obtained. Due to the significant impact of radioresistance on the survival of patients with non-small cell lung cancer (NSCLC), we conducted a differential analysis on the NSCLC cell lines in the GSE20549 dataset. We used a threshold of |log FC|>\u20091, FDR\u2009<\u20090.05, and P value\u2009<\u20090.05 to determine radioresistance and radiosensitivity. As a result, we identified 2795 differentially expressed genes (DEGs), including 1574 upregulated DEGs and 1221 downregulated DEGs (Additional file 1: Fig. S1D). Following Venn diagram analysis of the upregulated DEGs in NSCLC tissues and radioresistant NSCLC cell lines, 60 genes related to radioresistance were obtained (Fig. 1A). A PPI network was constructed using STRING database and visualized with Cytoscape software (Fig. 1B). The top 15 genes were displayed based on the Degree values: MCM4, FOXM1, NCAPD2, CDT1, NDC80, HDAC1, KIF2C, MELK, TPX2, HDAC2, SMAD3, HIST1H2BJ, LEF1, FBL and MMP13 (Fig. 1C). Collectively, 15 key genes related to radioresistance of NSCLC cells were identified from the GEO dataset. Fig. 1 Screening of genes involved in the radioresistance of NSCLC cells. A Venn diagram of the upregulated DEGs in NSCLC tissues and radioresistant NSCLC cell lines. B PPI network diagram of the 60 genes related to radioresistance drawn by Cytoscape. C The top 15 genes related to radioresistance ranked by Degree value Full size image High SMAD3 expression is observed in CAFs, which is closely associated with poor prognosis in NSCLC patients To determine the correlation of the obtained 15 radioresistant genes with the prognosis of NSCLC patients, we performed univariate Cox regression analysis on the GSE37745 dataset, and found that SMAD3 had the most significant prognostic value in NSCLC, representing a high-risk gene (Fig. 2A). RT-qPCR data confirmed that the expression of the above 15 genes increased to varying degrees, and the expression of SMAD3 was significantly increased in clinical tissue samples compared with adjacent normal tissue samples (Fig. 2B). The analysis results of the Kaplan\u2013Meier plotter database showed that the high expression of SMAD3 was inversely correlated with the overall survival of NSCLC patients (Fig. 2C). In addition, immunohistochemistry results illustrated that the protein expression of SMAD3 was upregulated in NSCLC tissues (Fig. 2D). Fig. 2 Identification of genes related to the prognosis of NSCLC patients. A Univariate Cox regression analysis of the GSE37745 dataset. The left shows the gene name, the middle is the p value, and the right indicates the risk rate distribution. Hazard ratio represents the risk rate, and a gene with the risk rate greater than 1 represents a high-risk gene, while less than 1, it represents a low-risk gene. B Expression of 15 genes in the clinical tissue samples and adjacent normal tissue samples of NSCLC patients (n\u2009=\u2009120) measured by RT-qPCR. * p\u2009<\u20090.05. C Correlation between SMAD3 expression and overall survival in NSCLC patients analyzed by Kaplan\u2013Meier plotter database. Red indicates SMAD3 high expression, black indicates low SMAD3 expression. D Immunohistochemistry of SMAD3 protein in normal lung tissues and NSCLC tissues (30 samples randomly selected from 120 samples). * p\u2009<\u20090.05. E Univariate Cox regression analysis confirmed SMAD3 as an independent prognostic factor of NSCLC. F Multivariate Cox regression analysis confirmed SMAD3 as an independent prognostic factor of NSCLC. G A nomogram composed of SMAD3 expression, age, and tumor stage. H Accuracy of the predicted 1-, 2- and 3-year survival rate determined by a calibration curve based on the nomogram. I SMAD3 enrichment analyzed by the NSCLC-related scRNA-seq dataset from the TISCH database. The abscissa represents the cell type, the ordinate represents the dataset and color scale indicates expression, with darker color corresponding to higher expression Full size image Univariate Cox regression analysis results showed that SMAD3 expression (p\u2009=\u20090.004, HR\u2009=\u20091.727, 95% CI 1.185\u20132.517), tumor stage (p\u2009=\u20090.014, HR\u2009=\u20091.270, 95% CI 1.049\u20131.539), and age (p\u2009=\u20090.010, HR\u2009=\u20091.025, 95% CI 1.006\u20131.045) considerably affected the overall survival of NSCLC patients (Fig. 2E). Besides, multivariate Cox regression analysis data indicated that SMAD3 expression (p\u2009=\u20090.005, HR\u2009=\u20091.721, 95% CI 1.180\u20132.510), tumor stage (p\u2009=\u20090.010, HR\u2009=\u20091.288, 95% CI 1.063\u20131.561), and age (p\u2009=\u20090.008, HR\u2009=\u20091.026, 95% CI 1.007\u20131.046) could serve as independent prognostic factors for NSCLC (Fig. 2F). A nomogram was constructed based on these three independent prognostic factors to predict the survival rate of NSCLC patients (Fig. 2G), which explained that the predicted 1-, 2- and 3-year survival rate was highly consistent with the actual survival rate (Fig. 2H). This indicates that high expression of SMAD3 is associated with the poor prognosis in NSCLC patients. CAFs have been confirmed as a major component of the tumor microenvironment, which can induce tumor radioresistance [32]. Therefore, we sought to further verify the correlation between SMAD3 expression and CAFs. Analysis of the NSCLC-related scRNA-seq dataset from the TISCH database suggested that SMAD3 was highly enriched in CAFs (Fig. 2I). Accordingly SMAD3 served as an independent prognostic factor, and its high expression is associated with poor prognosis in NSCLC patients. In addition, high SMAD3 expression was found in CAFs in the tumor microenvironment. High SMAD3 expression correlates with DNA hypomethylation at its promoter Next, we moved to determine whether dysregulation of SMAD3 expression is correlated with its altered methylation status. Analysis using the UALCAN (Fig. 3A, B) and DNMIVD databases (Fig. 3C, D) showed significantly lower DNA methylation levels of the SMAD3 promoter region in lung adenocarcinoma (LUAD) and lung squamous cell carcinoma (LUSC) tissues compared to normal tissues. Fig. 3 Increased expression of SMAD3 in NSCLC is correlated with its promoter hypomethylation. A The DNA methylation level of the SMAD3 promoter region between normal tissues and LUAD tissues analyzed by the UALCAN database. B The DNA methylation level of the SMAD3 promoter region between normal tissues and LUSC tissues analyzed by the UALCAN database. C The DNA methylation level of the SMAD3 promoter region between normal tissues and LUAD tissues analyzed by the DNMIVD database. D The DNA methylation level of the SMAD3 promoter region between normal tissues and LUSC tissues analyzed by the DNMIVD database. E Correlation between SMAD3 expression and DNA methylation of the SMAD3 promoter region in TCGA-LUAD (n\u2009=\u2009465). F Correlation between SMAD3 expression and DNA methylation of the SMAD3 promoter region in TCGA-LUSC (n\u2009=\u2009370). G The DNA methylation level of the SMAD3 promoter region between the SMAD3 high (n\u2009=\u2009233) and low expression groups (n\u2009=\u2009232) in TCGA-LUAD. H The DNA methylation level of the SMAD3 promoter region between the SMAD3 high (n\u2009=\u2009185) and low expression (n\u2009=\u2009185) groups in TCGA-LUSC. I The DNA methylation level of the SMAD3 promoter region in promoter region in the tumor tissues of NSCLC patients detected by MSP-PCR (8 samples randomly selected from 120 samples) Full size image Furthermore, increased SMAD3 expression was found to be correlated with the SMAD3 promoter hypomethylation in both LUAD and LUSC tissues (Fig. 3E, F). Eighteen of the 29 promoter CpG sites in LUAD were negatively correlated with SMAD3 expression (Additional file 2: Fig. S2A, C), and 17 of the 29 promoter CpG sites in LUSC were adversely correlated with SMAD3 expression (Additional file 2: Fig. S2B, D). In addition, DNA methylation level of the SMAD3 promoter region was lower in the SMAD3 high expression group than that in the SMAD3 low expression group (Fig. 3G, H). Meanwhile, MSP results showed that DNA methylation level of the promoter region of SMAD3 was decreased in tumor tissues compared with adjacent normal tissues (Fig. 3I). Therefore, high expression of SMAD3 in NSCLC correlates with its promoter hypomethylation. SMAD3 promotes radioresistance of NSCLC cells by activating the ITGA6/PI3K/Akt pathway Subsequently, this study aimed to elucidate the potential regulatory mechanism of SMAD3 in NSCLC. Analysis of the function of SMAD3 using GSEA showed that high SMAD3 expression was related to multiple types of cancer including NSCLC, and cancer-related pathways such as PI3K/Akt/mTOR and KRAS (Fig. 4A, B). Fig. 4 SMAD3 enhances the radioresistance of NSCLC cells via ITGA6/PI3K/Akt pathway activation. A Analysis of the function of SMAD3 using GSEA based on the KEGG gene set. Different curves indicate different pathway names. B Analysis of the function of SMAD3 using GSEA based on the Hallmark gene set. Different curves indicate different pathway names. C A volcano map of the DEGs between the SMAD3 high (n\u2009=\u200998) and low expression groups (n\u2009=\u200998). Green indicates the downregulated genes, red indicates the upregulated genes, and black indicates un-differentially expressed genes. D A heat map of the top 20 DEGs between the SMAD3 high and low expression groups. Color scale from red to blue indicates gene expression from high to low. E A heat map of SMAD3-related genes. Color scale from red to green indicates gene expression from high to low. F A heat map of the DEGs in the GSE20549 dataset, with 6 SMAD3-related genes labeled. Color scale from red to green indicates gene expression from high to low. G Correlation of SMAD3 expression with ITGA6 expression in the GSE37745 dataset (n\u2009=\u2009196). H The protein expression of ITGA6 in tumor tissues of NSCLC patients determined by immunohistochemistry. I Western blot of PI3K/Akt pathway-related proteins in tumor tissues of NSCLC patients (30 samples randomly selected from 120 samples). * p\u2009<\u20090.05 Full size image In addition, 95 DEGs were screened between high SMAD3 expression group and low SMAD3 expression group following differential analysis (Fig. 4C, D), of which, 32 DEGs were correlated with SMAD3 expression, as revealed by Spearman correlation analysis (Fig. 4E). In addition, 6 genes were found in the radiotherapy-related dataset GSE20549 (Fig. 4F). Among them, ITGA6 was highly expressed in radioresistant samples and positively correlated with SMAD3 expression (Fig. 4G). Additionally, ITGA6 has been demonstrated to enhance radioresistance through the PI3K/Akt signaling pathway [35]. Therefore, we hypothesized that SMAD3 may promote radioresistance of NSCLC cells by activating the ITGA6/PI3K/Akt pathway. Immunohistochemistry results suggested increased ITGA6I expression in tumor tissues (Fig. 4H). Western blot results showed that PI3K protein expression and Akt phosphorylation level were increased while total Akt protein expression remained unchanged in tumor tissues compared with adjacent normal tissues (Fig. 4I). These results suggest that SMAD3 may promote radioresistance of NSCLC cells by activating the ITGA6/PI3K/Akt pathway. DNA hypomethylation of the SMAD3 promoter region in CAFs increases the radioresistance of NSCLC cells The above bioinformatics results were then validated in the in vitro experiments. RT-qPCR results showed higher SMAD3 expression in NSCLC cells compared with human bronchial epithelial cells 16HBE, with the highest expression noted in H1299 cells and the lowest expression in H460 cells (Fig. 5A). Thus, H1299 and H460 cells were used for subsequent experiments. Fig. 5 DNA hypomethylation of the SMAD3 promoter region in CAFs leads to increased radioresistance of NSCLC cells. A The expression of SMAD3 in NSCLC cell lines and human bronchial epithelial cells 16HBE measured by RT-qPCR. B The expression of SMAD3 in NAFs and CAFs measured by RT-qPCR. C Western blot of SMAD3 protein in the CAF-CM and NAF-CM. D The DNA methylation level of the SMAD3 promoter region in NAFs and CAFs measured by MSP-PCR. E The expression of SMAD3 in H460 cells treated with oe-SMAD3 or CAF-CM and in H1229 cells treated with sh-SMAD3 measured by RT-qPCR. F Viability of H460 and H1229 cells treated with oe-SMAD3 or sh-SMAD3, respectively, following exposure to different doses of X-ray radiation. G Proliferation of H460 and H1229 cells treated with oe-SMAD3 or sh-SMAD3, respectively, following exposure to 6 Gy X-ray radiation. H Invasion of H460 and H1229 cells treated with oe-SMAD3 or sh-SMAD3, respectively, following exposure to 6 Gy X-ray radiation. I \u03b3H2ax fluorescence in H460 cells treated with oe-SMAD3 or CAF-CM and in H1229 cells treated with sh-SMAD3 following exposure to 6 Gy X-ray radiation. J Apoptosis of H460 cells treated with oe-SMAD3 or CAF-CM and of H1229 cells treated with sh-SMAD3 following exposure to 6 Gy X-ray radiation determined by flow cytometry. K Cell cycle distribution of H460 cells treated with oe-SMAD3 or CAF-CM and of H1229 cells treated with sh-SMAD3 following exposure to 6 Gy X-ray radiation determined by flow cytometry. *p\u2009<\u20090.05 vs. 16HBE, NAF, or oe-NC groups. #p\u2009<\u20090.05 vs. NAF-CM group. &p\u2009<\u20090.05 vs. sh-NC group. Cell experiments were repeated three times Full size image CCK-8 results demonstrated a decline in NSCLC cell viability following exposure to different doses of X-ray radiation compared with 16HBE cells (Additional file 3: Fig. S3A), which was consistent with SMAD3 expression in cells. This indicates that SMAD3 is highly expressed in NSCLC cells and correlated with radioresistance. Human lung NAFs and CAFs were successfully isolated from fresh NSCLC and adjacent normal tissues (Additional file 3: Fig. S3B, C). RT-qPCR and Western blot results showed higher SMAD3 expression in CAFs and the CAF-CM versus the NAFs and NAF-CM (Fig. 5B, C). Additionally, MSP-PCR results revealed that the DNA methylation level of the SMAD3 promoter region was reduced in CAFs compared with the NAFs (Fig. 5D). This indicates that the SMAD3 promoter region is hypomethylated but SMAD3 expression was upregulated in CAFs. Next, we transfected SMAD3 into NSCLC cells or added CAF-conditioned media (CM) to the NSCLC cells. The results of RT-qPCR (Fig. 5E) showed that SMAD3 expression was upregulated in NSCLC cells with oe-SMAD3 transfection and CAFs-CM treatment, while downregulated with sh-SMAD3 (subsequently using sh-SMAD3-1 for experiments). It should be noted that extracellular SMAD3 molecules do not directly enter NSCLC cells to exert their function. We speculate that SMAD3 binds to ITGA6 on the membrane of NSCLC cells. Subsequently, we collected cells for Western blotting experiments, and in the CAF-CM group, we observed an increase in SMAD3 protein levels in the cell lysates (Fig. 5E). This observation, combined with our previous finding of a significant increase in SMAD3 protein content in CAFs-CM (Fig. 5C), and the characteristic of ITGA6 as a transmembrane adhesive receptor protein, supports our hypothesis. Additionally, besides serving as a positive control, the overexpression of SMAD3 in NSCLC cells further confirms the specificity of the phenotypic results induced by CAFs-CM and excludes the influence of other cytokines present in CAFs-CM. Using different intensities of radiation on NSCLC cells, the CCK8 results showed (Fig. 5F) that high expression of SMAD3 in NSCLC cells enhanced cell viability, while silencing SMAD3 resulted in decreased cell viability. Further treatment of cells with a dose of 6 Gy, colony formation, and Transwell experiments revealed (Fig. 5G\u2013H) that high expression of SMAD3 enhanced colony formation and invasion ability, while silencing SMAD3 had the opposite effect. DNA double-strand breaks in NSCLC cells were assessed by immunofluorescence staining of \u03b3H2AX, a marker for DNA damage evaluation. The results of \u03b3H2AX immunofluorescence staining and flow cytometry (Fig. 5IK) showed that in the group with high SMAD3 expression, the intensity of \u03b3H2AX fluorescence decreased, indicating reduced DNA damage and decreased apoptosis. Additionally, the proportion of cells in the G0/G1 phase decreased, while cells in the S phase and cell division increased. The results were opposite when SMAD3 was silenced. Cumulatively, DNA hypomethylation of the SMAD3 promoter region in CAFs can induce the radioresistance of NSCLC cells. SMAD3 from CAFs activates the ITGA6/PI3K/Akt pathway in NSCLC cells Validation of SMAD3 in CAFs activating the ITGA6/PI3K/Akt pathway in NSCLC cells was the next focus. RT-qPCR and Western blot results unveiled increased ITGA6 mRNA and protein expression in NSCLC cells compared with 16HBE cells, with the highest expression found in H1299 cells and the lowest in H460 cells. In addition, PI3K protein expression and Akt phosphorylation level were elevated while total Akt protein expression remained unchanged (Fig. 6A, B). Fig. 6 SMAD3 from CAFs promotes activation of the ITGA6/PI3K/Akt pathway in NSCLC cells. A ITGA6 mRNA expression in NSCLC cell lines and 16HBE cells measured by RT-qPCR. B Western blot of ITGA6 and PI3K/Akt pathway-related proteins in NSCLC cell lines and 16HBE cells. C ITGA6 mRNA expression in H460 cells treated with oe-SMAD3 or CAF-CM and in H1229 cells treated with sh-SMAD3 by RT-qPCR. D Western blot of ITGA6 and PI3K/Akt pathway-related proteins in H460 cells treated with oe-SMAD3 or CAF-CM and in H1229 cells treated with sh-SMAD3. *p\u2009<\u20090.05 vs. 16HBE or oe-NC group. n.s. indicates not significant. #p\u2009<\u20090.05 vs. NAF-CM group. &p\u2009<\u20090.05 vs. sh-NC group. Cell experiments were repeated three times Full size image As depicted in Fig. 6C, D, treatment with oe-SMAD3 or CAF-CM enhanced mRNA and protein expression of ITGA6, PI3K protein expression and Akt phosphorylation level, without altering total Akt protein expression. In contrast, SMAD3 silencing caused opposite results except for the unchanged total Akt protein expression. Together, SMAD3 from CAFs can activate the ITGA6/PI3K/Akt pathway in NSCLC cells. Activation of the ITGA6/PI3K/Akt pathway promotes radioresistance of NSCLC cells Then, we intended to verify the effect of the ITGA6/PI3K/Akt pathway on radioresistance of NSCLC cells. RT-qPCR results indicated augmented ITGA6 expression in H460 cells treated with oe-ITGA6 while sh-ITGA6 in H1229 cells downregulated ITGA6 expression, with the sh-ITGA6-1 showing the most obvious downregulation (Fig. 7A) and thus used for the subsequent assay. In Fig. 7B, overexpression of ITGA6 enhanced PI3K protein expression and Akt phosphorylation level, without altering total Akt protein expression but silencing of ITGA6 downregulated PI3K protein expression and Akt phosphorylation level, in addition to the unaffected total Akt protein expression. These results support that ITGA6 positively regulates the PI3K/Akt pathway. Fig. 7 ITGA6/PI3K/Akt pathway exerts promoting function in the radioresistance of NSCLC cells. A ITGA6 mRNA expression in H460 and H1229 cells treated with oe-ITGA6 or sh-ITGA6, respectively, measured by RT-qPCR. B Western blot of PI3K/Akt pathway-related proteins in H460 and H1229 cells treated with oe-ITGA6 or sh-ITGA6, respectively. C Viability of H460 and H1229 cells treated with oe-ITGA6 or sh-ITGA6, respectively, following exposure to different doses of X-ray radiation. D Proliferation of H460 and H1229 cells treated with oe-ITGA6 or sh-ITGA6, respectively, following exposure to 6 Gy X-ray radiation. E Invasion of H460 and H1229 cells treated with oe-ITGA6 or sh-ITGA6, respectively, following exposure to 6 Gy X-ray radiation. F \u03b3H2ax fluorescence in H460 and H1229 cells treated with oe-ITGA6 or sh-ITGA6, respectively, following exposure to 6 Gy X-ray radiation. G Apoptosis of H460 and H1229 cells treated with oe-ITGA6 or sh-ITGA6, respectively, following exposure to 6 Gy X-ray radiation determined by flow cytometry. H Cell cycle distribution of H460 and H1229 cells treated with oe-ITGA6 or sh-ITGA6, respectively, following exposure to 6 Gy X-ray radiation determined by flow cytometry. *p\u2009<\u20090.05 vs. oe-NC group. #p\u2009<\u20090.05 vs. sh-NC group. Cell experiments were repeated three times Full size image Furthermore, cell viability was promoted in the presence of ITGA6 overexpression following exposure to different doses of X-ray radiation, whereas an opposite result was caused by silencing of ITGA6 (Fig. 7C). Upon exposure to 6 Gy X-ray radiation, cell colony formation and invasion were enhanced in response to ITGA6 overexpression, which was negated by silencing of ITGA6 (Fig. 7D, E). Moreover, ITGA6 overexpression weakened \u03b3H2ax fluorescence intensity, and reduced DNA damage, cell apoptosis, and G0/G1 phase-arrested cells, while increasing S phase-arrested cells and cell division upon exposure to 6 Gy X-ray radiation; contrary results were evident following ITGA6 silencing (Fig. 7F\u2013H). These lines of evidence suggest that activation of the ITGA6/PI3K/Akt pathway may promote the radioresistance of NSCLC cells. SMAD3 from CAFs increases NSCLC cell radioresistance by activating the ITGA6/PI3K/Akt pathway The results of RT-qPCR and Western blot showed unaltered SMAD3 expression and total Akt protein expression yet reduced ITGA6 expression, PI3K protein expression and Akt phosphorylation level in the H460 cells co-treated with sh-ITGA6 and oe-SMAD3 or sh-ITGA6 and CAF-CM than SMAD3 overexpression or CAF-CM alone. In the H1229 cells treated with sh-SMAD3\u2009+\u2009oe-ITGA6, SMAD3 expression and total Akt protein expression showed no changes and ITGA6 expression, PI3K protein expression and Akt phosphorylation level were promoted (Fig. 8A, B). Fig. 8 SMAD3 from CAFs reduces the radiosensitivity of NSCLC cells by activating the ITGA6/PI3K/Akt pathway. A The expression of SMAD3 and ITGA6 in H460 cells treated with sh-ITGA6\u2009+\u2009oe-SMAD3 or sh-ITGA6\u2009+\u2009CAF-CM and in the H1229 cells treated with sh-SMAD3\u2009+\u2009oe-ITGA6 determined by RT-qPCR. B Western blot of SMAD3, ITGA6 and the PI3K/Akt pathway-related proteins in H460 cells treated with sh-ITGA6\u2009+\u2009oe-SMAD3 or sh-ITGA6\u2009+\u2009CAF-CM and in the H1229 cells treated with sh-SMAD3\u2009+\u2009oe-ITGA6. C Viability of H460 cells treated with sh-ITGA6\u2009+\u2009oe-SMAD3 or sh-ITGA6\u2009+\u2009CAF-CM and of H1229 cells treated with sh-SMAD3\u2009+\u2009oe-ITGA6 following exposure to 6 Gy X-ray radiation measured by CCK-8. D Colony formation of H460 cells treated with sh-ITGA6\u2009+\u2009oe-SMAD3 or sh-ITGA6\u2009+\u2009CAF-CM and of H1229 cells treated with sh-SMAD3\u2009+\u2009oe-ITGA6, following exposure to 6 Gy X-ray radiation. E Invasion of H460 cells treated with sh-ITGA6\u2009+\u2009oe-SMAD3 or sh-ITGA6\u2009+\u2009CAF-CM and of H1229 cells treated with sh-SMAD3\u2009+\u2009oe-ITGA6, following exposure to 6 Gy X-ray radiation. F \u03b3H2ax fluorescence in H460 cells treated with sh-ITGA6\u2009+\u2009oe-SMAD3 or sh-ITGA6\u2009+\u2009CAF-CM and in H1229 cells treated with sh-SMAD3\u2009+\u2009oe-ITGA6, following exposure to 6 Gy X-ray radiation. G Apoptosis of H460 cells treated with sh-ITGA6\u2009+\u2009oe-SMAD3 or sh-ITGA6\u2009+\u2009CAF-CM and of H1229 cells treated with sh-SMAD3\u2009+\u2009oe-ITGA6, following exposure to 6 Gy X-ray radiation determined by flow cytometry. H Cell cycle distribution of H460 cells treated with sh-ITGA6\u2009+\u2009oe-SMAD3 or sh-ITGA6\u2009+\u2009CAF-CM and of H1229 cells treated with sh-SMAD3\u2009+\u2009oe-ITGA6, following exposure to 6 Gy X-ray radiation determined by flow cytometry. *p\u2009<\u20090.05 vs. oe-SMAD3\u2009+\u2009sh-NC group. #p\u2009<\u20090.05 vs. CAF-CM\u2009+\u2009sh-NC group. &p\u2009<\u20090.05 vs. sh-SMAD3\u2009+\u2009oe-NC group. Cell experiments were repeated three times Full size image Following exposure to different doses of X-ray radiation, cell viability was impaired upon treatment with sh-ITGA6\u2009+\u2009oe-SMAD3 whereas an opoiste result was found upon treatment with sh-SMAD3\u2009+\u2009oe-ITGA6 (Fig. 8C). In addition, upon exposure to 6 Gy X-ray radiation, cell colony formation and invasion as well as S phase-arrested cells and cell division were reduced but \u03b3H2ax fluorescence intensity, DNA damage, cell apoptosis, and G0/G1 phase-arrested cells were increased in response to treatment with sh-ITGA6\u2009+\u2009oe-SMAD3, the effect of which was reversed by sh-SMAD3\u2009+\u2009oe-ITGA6 (Fig. 8D\u2013H). Taken together, SMAD3 from CAFs can enhance the radioresistance of NSCLC cells by activating the ITGA6/PI3K/Akt pathway. SMAD3 from CAFs promotes tumor growth and radioresistance of NSCLC cells by activating the ITGA6/PI3K/Akt pathway in vivo Finally, we proceeded to characterize whether SMAD3 from CAFs promoted the radioresistance of NSCLC cells through activation of ITGA6/PI3K/Akt pathway in vivo. As displayed in Fig. 9A\u2013C, tumor volume and weight were increased in mice treated with H460/oe-SMAD3\u2009+\u2009Gy or H460/CAFs\u2009+\u2009Gy, and conversely, H460/oe-SMAD3\u2009+\u2009sh-ITGA6\u2009+\u2009Gy or H460/CAFs\u2009+\u2009sh-ITGA6\u2009+\u2009Gy led to reduced tumor volume and weight. Fig. 9 SMAD3 from CAFs induces tumor growth by activating the ITGA6/PI3K/Akt pathway in vivo. Nude mice were treated with H460/oe-NC\u2009+\u2009Gy, H460/NAF\u2009+\u2009Gy, H460/oe-SMAD3\u2009+\u2009Gy, H460/CAFs\u2009+\u2009Gy, H460/oe-SMAD3\u2009+\u2009sh-NC\u2009+\u2009Gy, H460/CAFs\u2009+\u2009sh-NC\u2009+\u2009Gy, H460/oe-SMAD3\u2009+\u2009sh-ITGA6\u2009+\u2009Gy and H460/CAFs\u2009+\u2009sh-ITGA6\u2009+\u2009Gy. A Schematic diagram of xenografts in nude mice. B Tumor volume of nude mice. C Tumor weight of nude mice. D Expression of SMAD3 and ITGA6 in tumor tissues of nude mice determined by RT-qPCR. E Western blot of SMAD3, ITGA6 and the PI3K/Akt pathway-related proteins in tumor tissues of nude mice. F Cell proliferation in tumor tissues of mice determined by immunohistochemical staining for Ki67. G Cell apoptosis in tumor tissues of mice determined by TUNEL staining. n\u2009=\u200910. *p\u2009<\u20090.05 vs. H460/oe-NC\u2009+\u2009Gy or H460/NAF\u2009+\u2009Gy group. #p\u2009<\u20090.05 vs. H460/oe-SMAD3\u2009+\u2009sh-NC\u2009+\u2009Gy or H460/NAF\u2009+\u2009sh-NC\u2009+\u2009Gy group Full size image The results of RT-qPCR and Western blot demonstrated an enhancement in the mRNA and protein expression of SMAD3, ITGA6, PI3K protein expression and Akt phosphorylation level yet unchanged total Akt protein expression in the tumor tissues of mice treated with H460/oe-SMAD3\u2009+\u2009Gy or H460/CAFs\u2009+\u2009Gy. In contrast, H460/oe-SMAD3\u2009+\u2009sh-ITGA6\u2009+\u2009Gy or H460/CAFs\u2009+\u2009sh-ITGA6\u2009+\u2009Gy resulted in opposite results in addition to unaltered total Akt protein expression (Fig. 9D, E). Furthermore, data shown in Fig. 9F, G explained high percentage of Ki67-positive tumor cells and low cell apoptosis in response to H460/oe-SMAD3\u2009+\u2009Gy or H460/CAFs\u2009+\u2009Gy. However, these effects were reversed following treatment with H460/oe-SMAD3\u2009+\u2009sh-ITGA6\u2009+\u2009Gy or H460/CAFs\u2009+\u2009sh-ITGA6\u2009+\u2009Gy. Overall, the above results indicate that SMAD3 from CAFs might favor NSCLC tumor growth in vivo and enhances tumor radioresistance via activation of the ITGA6/PI3K/Akt pathway. Discussion Investigating the molecular pathways and mechanisms that facilitate interaction between CAFs and tumor cells during radiotherapy is crucial for enhancing clinical outcomes in patients with NSCLC [36]. This knowledge is foundational for developing targeted therapies to augment the efficacy of radiotherapy in NSCLC, ultimately aiming to improve patient prognosis [37]. The current study elucidates the contributory role of SMAD3 in NSCLC radioresistance, delineating the mechanism wherein enforced SMAD3 expression activates the ITGA6/PI3K/Akt pathway, thereby intensifying NSCLC radioresistance. These findings underscore the potential of SMAD3 as a targeted therapy and a prognostic indicator for NSCLC patients. The present findings position SMAD3 as an independent prognostic factor in NSCLC, with its heightened expression correlating with poor patient prognosis. Concurrently, recent research has indicated that phosphorylation of SMAD3 in immune cells is predictive of survival in early-stage NSCLC patients, associating increased phosphorylation with reduced survival [38]. Moreover, elevated SMAD3 expression has been identified as an independent marker for better overall survival in NSCLC patients [19]. This study also reveals high SMAD3 expression by CAFs within the tumor microenvironment, correlating with promoter hypermethylation [19]. In breast cancer, CAFs predominantly activate the SMAD pathway through paracrine TGF-b1 [39]. Elevated SMAD3 mRNA expression has been detected in adenocarcinoma-associated fibroblasts [40]. Notably, aberrant genomic DNA methylation in NSCLC tumor-associated fibroblasts is a critical regulator of tumor progression, with SMAD3 promoter hypermethylation associated with reduced gene expression [41]. Evidence suggests that inhibiting SMAD3 in CAFs diminishes its activation and secretion of extracellular matrix components, thereby curtailing tumor cell survival and enhancing radiosensitivity [42]. Thus, strategies to inhibit SMAD3 activity in CAFs may present a novel approach to augment radiotherapy efficacy in NSCLC and improve patient clinical prognosis [19]. This study also indicates that CAF-derived SMAD3 heightens the radioresistance of NSCLC cells, associated with the activation of the ITGA6/PI3K/Akt pathway. CAFs secrete various immunomodulatory soluble factors, including cytokines, growth factors, and chemokines, which directly impact tumor immunity and inflammation, playing a pivotal role in tumor radioresistance [43]. Aligning with these findings, SMAD3 expression significantly differs between radiation-resistant and radiation-sensitive patients; SMAD3 knockdown markedly inhibits cell growth and boosts radiosensitivity of lung adenocarcinoma cells both in vitro and in vivo [44]. Moreover, ITGA6 knockdown is responsible for the inhibition of the TGF-\u03b21/SMAD pathway in choriocarcinoma cells [45]. ITGA6 has emerged as a significant predictive marker of radioresistance, with its silencing attenuating radioresistance in head and neck cancer cells [46]. Data also suggest that ITGA6 inhibition counters radiotherapy resistance in mesenchymal glioblastoma stem-like cells [47]. Forced ITGA6 expression elevates PI3K and Akt phosphorylation levels in oral squamous cell carcinoma cells, but its inhibition impairs the activity of the PI3K/Akt pathway [48]. Additionally, ITGA6 overexpression promotes radioresistance in breast cancer cells by activating the PI3K/Akt pathway [49]. Previous results also indicate that PI3K/Akt pathway inhibition enhances the sensitivity of NSCLC cells to ionizing radiation, suggesting that PI3K/Akt inhibitors may be a strategy to reduce NSCLC radioresistance [50]. Notably, SMAD3 overexpression leads to significant activation of the PI3K/Akt pathway in vascular smooth muscle cells and a rat carotid artery injury model [51]. In summary, our work has provided the first evidence of the radioprotective effect of SMAD3 on NSCLC cells. Furthermore, our study has demonstrated a novel regulatory pathway of SMAD3 in NSCLC cells, namely the SMAD3/ITGA6/PI3K/Akt signaling pathway, as illustrated in Fig. 10. In stromal cells, a decrease in the methylation level of the SMAD3 gene promoter region leads to an overexpression of SMAD3 molecules. These SMAD3 molecules are secreted into the tumor microenvironment and interact with ITGA6 on the membrane of NSCLC cells, resulting in its hyperactivation. Subsequently, ITGA6 further activates the downstream PI3K/Akt signaling pathway, leading to increased cell proliferation, enhanced cell survival, and increased invasion capability, thus enhancing the radiation resistance of NSCLC. Fig. 10 The mechanism graph of the regulatory network and function of SMAD3 in radioresistance of NSCLC. SMAD3 is significantly enriched in CAFs, which may promote the radioresistance of NSCLC cells by activating the ITGA6/PI3K/Akt pathway Full size image Our research suggests that developing drugs targeting the SMAD3 and its downstream ITGA6/PI3K/Akt axis may be an effective strategy for NSCLC prognosis and treatment. SMAD3 has been identified as a potential biomarker for NSCLC prognosis and a driving factor for radiation resistance. These findings could lead to novel targeted treatment strategies aimed at inhibiting the SMAD3 and ITGA6/PI3K/Akt pathways to improve radiotherapy efficacy and patient prognosis. Additionally, the development of targeted therapies to alleviate radiation resistance mediated by CAFs may reduce treatment-related toxicity and improve the quality of life for patients. By increasing the sensitivity of NSCLC cells to radiotherapy, it is possible to reduce the required radiation doses and consequently lower the incidence of treatment-related adverse events in NSCLC patients. Ultimately, by elucidating the molecular mechanisms underlying the role of CAFs in the development of radiation resistance, new treatment strategies can be developed to improve clinical outcomes and reduce the incidence of treatment-related complications in NSCLC patients. Furthermore, the molecular basis of the relationship between the overexpression of SMAD3 and the low DNA methylation in its promoter region needs further investigation. Therefore, future studies can focus on expanding the sample size and conducting more detailed molecular analyses to gain a better understanding of the role of SMAD3 in NSCLC radioresistance. Additionally, there are certain limitations to this study. Firstly, the precise targeting and regulation of molecules such as SMAD3 and ITGA6 in patients with lung cancer remains relatively challenging given the current technological level. Furthermore, the tumor microenvironment is highly complex, and whether the designed drugs can achieve the expected regulatory effects within patients and the corresponding optimal concentrations still require further scientific exploration. Moreover, if systemic treatment methods are employed, the potential side effects of the relevant drugs on a systemic level were not addressed in this study and need to be further investigated. It is also worth noting that the theoretical basis provided by the conclusions of this study is only one possible strategy for reducing the radioresistance of NSCLC cells, and it still remains an auxiliary means for lung cancer prevention or treatment. Therefore, for lung cancer disease, more scientific research is still needed to clarify its pathological mechanisms and provide a more direct theoretical foundation for novel preventive or therapeutic methods. Lastly, it is necessary to further explore whether the SMAD3/ITGA6 signaling pathway has similar biological functions in other types of cancer. Data availabilty The datasets generated and/or analysed during the current study are available in the manuscript and supplementary materials. References Tong Q, Ouyang S, Chen R, Huang J, Guo L. MYCN-mediated regulation of the HES1 promoter enhances the chemoresistance of small-cell lung cancer by modulating apoptosis. Am J Cancer Res. 2019;9(9):1938\u201356. CAS   PubMed   PubMed Central   Google Scholar   Quintanal-Villalonga \u00c1, Molina-Pinelo S. Epigenetics of lung cancer: a translational perspective. Cell Oncol (Dordr). 2019;42(6):739\u201356. https://doi.org/10.1007/s13402-019-00465-9. Article   CAS   PubMed   Google Scholar   Li C, Fan K, Qu Y, et al. Deregulation of UCA1 expression may be involved in the development of chemoresistance to cisplatin in the treatment of non-small-cell lung cancer via regulating the signaling pathway of microRNA-495/NRF2. J Cell Physiol. 2020;235(4):3721\u201330. https://doi.org/10.1002/jcp.29266. Article   CAS   PubMed   Google Scholar   Hammad A, Namani A, Elshaer M, Wang XJ, Tang X. \u201cNRF2 addiction\u201d in lung cancer cells and its impact on cancer therapy. Cancer Lett. 2019;467:40\u20139. https://doi.org/10.1016/j.canlet.2019.09.016. Article   CAS   PubMed   Google Scholar   Tang X, Chen H, Chen G, et al. Validated LC-MS/MS method of Sphingosine 1-phosphate quantification in human serum for evaluation of response to radiotherapy in lung cancer. Thorac Cancer. 2020;11(6):1443\u201352. https://doi.org/10.1111/1759-7714.13409. Article   CAS   PubMed   PubMed Central   Google Scholar   Abadi AJ, Zarrabi A, Gholami MH, et al. Small in size, but large in action: microRNAs as potential modulators of PTEN in breast and lung cancers. Biomolecules. 2021;11(2):304. https://doi.org/10.3390/biom11020304. Article   CAS   PubMed   PubMed Central   Google Scholar   Lin XM, Luo W, Wang H, et al. The role of prostaglandin-endoperoxide synthase-2 in chemoresistance of non-small cell lung cancer. Front Pharmacol. 2019;10:836. https://doi.org/10.3389/fphar.2019.00836. Article   CAS   PubMed   PubMed Central   Google Scholar   Qiu Z, Zhu W, Meng H, et al. CDYL promotes the chemoresistance of small cell lung cancer by regulating H3K27 trimethylation at the CDKN1C promoter. Theranostics. 2019;9(16):4717\u201329. https://doi.org/10.7150/thno.33680. Article   CAS   PubMed   PubMed Central   Google Scholar   Chian S, Zhao Y, Xu M, et al. Ginsenoside Rd reverses cisplatin resistance in non-small-cell lung cancer A549 cells by downregulating the nuclear factor erythroid 2-related factor 2 pathway. Anticancer Drugs. 2019;30(8):838\u201345. https://doi.org/10.1097/CAD.0000000000000781. Article   CAS   PubMed   Google Scholar   Liu B, Liu H, Ma Y, et al. EGFR-mutated stage IV non-small cell lung cancer: what is the role of radiotherapy combined with TKI? Cancer Med. 2021;10(18):6167\u201388. https://doi.org/10.1002/cam4.4192. Article   CAS   PubMed   PubMed Central   Google Scholar   Feng L, Zhao K, Sun L, et al. SLC7A11 regulated by NRF2 modulates esophageal squamous cell carcinoma radiosensitivity by inhibiting ferroptosis. J Transl Med. 2021;19(1):367. https://doi.org/10.1186/s12967-021-03042-7. Article   CAS   PubMed   PubMed Central   Google Scholar   He J, Huang Z, Han L, Gong Y, Xie C. Mechanisms and management of 3rd-generation EGFR-TKI resistance in advanced non-small cell lung cancer (Review). Int J Oncol. 2021;59(5):90. https://doi.org/10.3892/ijo.2021.5270. Article   CAS   PubMed   PubMed Central   Google Scholar   Yang L, Shi P, Zhao G, et al. Targeting cancer stem cell pathways for cancer therapy. Signal Transduct Target Ther. 2020;5(1):8. https://doi.org/10.1038/s41392-020-0110-5. Article   CAS   PubMed   PubMed Central   Google Scholar   Liao J, Chen Z, Yu Z, et al. The role of ARL4C in erlotinib resistance: activation of the Jak2/Stat 5/\u03b2-catenin signaling pathway. Front Oncol. 2020;10:585292. https://doi.org/10.3389/fonc.2020.585292. Article   PubMed   PubMed Central   Google Scholar   Zhao T, Song J, Ping Y, Li M. The application of antimicrobial photodynamic therapy (aPDT) in the treatment of peri-implantitis. Comput Math Methods Med. 2022;2022:3547398. https://doi.org/10.1155/2022/3547398. Article   PubMed   PubMed Central   Google Scholar   Mao X, Xu J, Wang W, et al. Crosstalk between cancer-associated fibroblasts and immune cells in the tumor microenvironment: new findings and future perspectives. Mol Cancer. 2021;20(1):131. https://doi.org/10.1186/s12943-021-01428-1. Article   CAS   PubMed   PubMed Central   Google Scholar   Meng J, Li Y, Wan C, et al. Targeting senescence-like fibroblasts radiosensitizes non-small cell lung cancer and reduces radiation-induced pulmonary fibrosis. JCI Insight. 2021;6(23): e146334. https://doi.org/10.1172/jci.insight.146334. Article   PubMed   PubMed Central   Google Scholar   Itoh Y, Saitoh M, Miyazawa K. Smad3-STAT3 crosstalk in pathophysiological contexts. Acta Biochim Biophys Sin (Shanghai). 2018;50(1):82\u201390. https://doi.org/10.1093/abbs/gmx118. Article   CAS   PubMed   Google Scholar   Tang PC, Chung JY, Xue VW, et al. Smad3 promotes cancer-associated fibroblasts generation via macrophage-myofibroblast transition. Adv Sci (Weinh). 2022;9(1): e2101235. https://doi.org/10.1002/advs.202101235. Article   CAS   PubMed   Google Scholar   Yin H, Chen L, Piao S, et al. M6A RNA methylation-mediated RMRP stability renders proliferation and progression of non-small cell lung cancer through regulating TGFBR1/SMAD2/SMAD3 pathway. Cell Death Differ. 2023;30(3):605\u201317. https://doi.org/10.1038/s41418-021-00888-8. (published correction appears in Cell Death Differ. 2022 Oct 10). Article   CAS   PubMed   Google Scholar   Ellert-Miklaszewska A, Poleszak K, Pasierbinska M, Kaminska B. Integrin signaling in glioma pathogenesis: from biology to therapy. Int J Mol Sci. 2020;21(3):888. https://doi.org/10.3390/ijms21030888. Article   CAS   PubMed   PubMed Central   Google Scholar   Situ AJ, Kim J, An W, Kim C, Ulmer TS. Insight into pathological integrin \u03b1IIb\u03b23 activation from safeguarding the inactive state. J Mol Biol. 2021;433(7): 166832. https://doi.org/10.1016/j.jmb.2021.166832. Article   CAS   PubMed   Google Scholar   Guo X, Zhu R, Luo A, et al. EIF3H promotes aggressiveness of esophageal squamous cell carcinoma by modulating Snail stability. J Exp Clin Cancer Res. 2020;39(1):175. https://doi.org/10.1186/s13046-020-01678-9. Article   CAS   PubMed   PubMed Central   Google Scholar   Bamodu OA, Chang HL, Ong JR, Lee WH, Yeh CT, Tsai JT. Elevated PDK1 Expression Drives PI3K/AKT/MTOR Signaling Promotes Radiation-Resistant and Dedifferentiated Phenotype of Hepatocellular Carcinoma. Cells. 2020;9(3):746. https://doi.org/10.3390/cells9030746. Article   CAS   PubMed   PubMed Central   Google Scholar   Huang W, Zhang L, Yang M, et al. Cancer-associated fibroblasts promote the survival of irradiated nasopharyngeal carcinoma cells via the NF-\u03baB pathway. J Exp Clin Cancer Res. 2021;40(1):87. https://doi.org/10.1186/s13046-021-01878-x. (published correction appears in J Exp Clin Cancer Res. 2021 Mar 22;40(1):108). Article   CAS   PubMed   PubMed Central   Google Scholar   Leiser D, Samanta S, Eley J, et al. Role of caveolin-1 as a biomarker for radiation resistance and tumor aggression in lung cancer. PLoS ONE. 2021;16(11): e0258951. https://doi.org/10.1371/journal.pone.0258951. (published correction appears in PLoS One. 2022 May 3;17(5):e0268256). Article   CAS   PubMed   PubMed Central   Google Scholar   Chen M, Zhang J. miR-186-5p inhibits the progression of oral squamous cell carcinoma by targeting ITGA6 to impair the activity of the PI3K/AKT pathway. J Oral Pathol Med. 2022;51(4):322\u201331. https://doi.org/10.1111/jop.13288. Article   MathSciNet   CAS   PubMed   Google Scholar   Tan AC. Targeting the PI3K/Akt/mTOR pathway in non-small cell lung cancer (NSCLC). Thorac Cancer. 2020;11(3):511\u20138. https://doi.org/10.1111/1759-7714.13328. Article   PubMed   PubMed Central   Google Scholar   Zhu W, Li Y, Zhao J, Wang Y, Li Y, Wang Y. The mechanism of triptolide in the treatment of connective tissue disease-related interstitial lung disease based on network pharmacology and molecular docking. Ann Med. 2022;54(1):541\u201352. https://doi.org/10.1080/07853890.2022.2034931. Article   CAS   PubMed   PubMed Central   Google Scholar   An S, Li Y, Lin Y, et al. Genome-wide profiling reveals alternative polyadenylation of innate immune-related mRNA in patients with COVID-19. Front Immunol. 2021;12:756288. https://doi.org/10.3389/fimmu.2021.756288. Article   CAS   PubMed   PubMed Central   Google Scholar   Koul R, Rathod S, Dubey A, Bashir B, Chowdhury A. Comparison of 7th and 8th editions of the UICC/AJCC TNM staging for non-small cell lung cancer in a non-metastatic North American cohort undergoing primary radiation treatment. Lung Cancer. 2018;123:116\u201320. https://doi.org/10.1016/j.lungcan.2018.06.029. Article   PubMed   Google Scholar   Zhang H, Hua Y, Jiang Z, et al. Cancer-associated fibroblast-promoted LncRNA DNM3OS confers radioresistance by regulating DNA damage response in esophageal squamous cell carcinoma. Clin Cancer Res. 2019;25(6):1989\u20132000. https://doi.org/10.1158/1078-0432.CCR-18-0773. Article   CAS   PubMed   Google Scholar   Duan M, Fang M, Wang C, Wang H, Li M. LncRNA EMX2OS induces proliferation, invasion and sphere formation of ovarian cancer cells via regulating the miR-654\u20133p/AKT3/PD-L1 Axis. Cancer Manag Res. 2020;12:2141\u201354. https://doi.org/10.2147/CMAR.S229013. (retracted in: Cancer Manag Res. 2024 Jan 22;16:67-68). Article   CAS   PubMed   PubMed Central   Google Scholar   Zhou C, Wei W, Ma J, et al. Cancer-secreted exosomal miR-1468\u20135p promotes tumor immune escape via the immunosuppressive reprogramming of lymphatic vessels. Mol Ther. 2021;29(4):1512\u201328. https://doi.org/10.1016/j.ymthe.2020.12.034. (published correction appears in Mol Ther. 2022 Feb 2;30(2):976-977). Article   CAS   PubMed   PubMed Central   Google Scholar   Hu T, Zhou R, Zhao Y, Wu G. Integrin \u03b16/Akt/Erk signaling is essential for human breast cancer resistance to radiotherapy. Sci Rep. 2016;6:33376. https://doi.org/10.1038/srep33376. Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Ren X, Li Y, Nishimura C, Zang X. Crosstalk between the B7/CD28 and EGFR pathways: mechanisms and therapeutic opportunities. Genes Dis. 2021;9(5):1181\u201393. https://doi.org/10.1016/j.gendis.2021.08.009. Article   CAS   PubMed   PubMed Central   Google Scholar   Vinod SK, Hau E. Radiotherapy treatment for lung cancer: current status and future directions. Respirology. 2020;25(Suppl 2):61\u201371. https://doi.org/10.1111/resp.13870. Article   PubMed   Google Scholar   Marwitz S, Ballesteros-Merino C, Jensen SM, et al. Phosphorylation of SMAD3 in immune cells predicts survival of patients with early stage non-small cell lung cancer. J Immunother Cancer. 2021;9(2): e001469. https://doi.org/10.1136/jitc-2020-001469. Article   PubMed   PubMed Central   Google Scholar   Li X, Sun Z, Peng G, et al. Single-cell RNA sequencing reveals a pro-invasive cancer-associated fibroblast subgroup associated with poor clinical outcomes in patients with gastric cancer. Theranostics. 2022;12(2):620\u201338. https://doi.org/10.7150/thno.60540. Article   CAS   PubMed   PubMed Central   Google Scholar   Yang L, Chen Y, Liu N, et al. CircMET promotes tumor proliferation by enhancing CDKN2A mRNA decay and upregulating SMAD3. Mol Cancer. 2022;21(1):23. https://doi.org/10.1186/s12943-022-01497-w. Article   CAS   PubMed   PubMed Central   Google Scholar   Su SF, Ho H, Li JH, et al. DNA methylome and transcriptome landscapes of cancer-associated fibroblasts reveal a smoking-associated malignancy index. J Clin Invest. 2021;131(16): e139552. https://doi.org/10.1172/JCI139552. Article   CAS   PubMed   PubMed Central   Google Scholar   Li C, Fu Y, He Y, et al. Knockdown of LINC00511 enhances radiosensitivity of lung adenocarcinoma via regulating miR-497-5p/SMAD3. Cancer Biol Ther. 2023;24(1):2165896. https://doi.org/10.1080/15384047.2023.2165896. Article   CAS   PubMed   PubMed Central   Google Scholar   Berzaghi R, Tornaas S, Lode K, Hellevik T, Martinez-Zubiaurre I. Ionizing radiation curtails immunosuppressive effects from cancer-associated fibroblasts on dendritic cells. Front Immunol. 2021;12:662594. https://doi.org/10.3389/fimmu.2021.662594. Article   CAS   PubMed   PubMed Central   Google Scholar   Huang C, Hu F, Song D, et al. EZH2-triggered methylation of SMAD3 promotes its activation and tumor metastasis. J Clin Invest. 2022;132(5): e152394. https://doi.org/10.1172/JCI152394. Article   CAS   PubMed   PubMed Central   Google Scholar   Gang EJ, Kim HN, Hsieh YT, et al. Integrin \u03b16 mediates the drug resistance of acute lymphoblastic B-cell leukemia. Blood. 2020;136(2):210\u201323. https://doi.org/10.1182/blood.2019001417. Article   CAS   PubMed   PubMed Central   Google Scholar   Borodins O, Broghammer F, Seifert M, Cordes N. Meta-analysis of expression and the targeting of cell adhesion associated genes in nine cancer types: a one research lab re-evaluation. Comput Struct Biotechnol J. 2023;21:2824\u201336. https://doi.org/10.1016/j.csbj.2023.04.017. Article   CAS   PubMed   PubMed Central   Google Scholar   Salahudeen AA, Choi SS, Rustagi A, et al. Progenitor identification and SARS-CoV-2 infection in human distal lung organoids. Nature. 2020;588(7839):670\u20135. https://doi.org/10.1038/s41586-020-3014-1. Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Guo G, Tan Z, Liu Y, Shi F, She J. The therapeutic potential of stem cell-derived exosomes in the ulcerative colitis and colorectal cancer. Stem Cell Res Ther. 2022;13(1):138. https://doi.org/10.1186/s13287-022-02811-5. Article   CAS   PubMed   PubMed Central   Google Scholar   Ren S, Wang J, Xu A, et al. Integrin \u03b16 overexpression promotes lymphangiogenesis and lymphatic metastasis via activating the NF-\u03baB signaling pathway in lung adenocarcinoma. Cell Oncol (Dordr). 2022;45(1):57\u201367. https://doi.org/10.1007/s13402-021-00648-3. Article   CAS   PubMed   Google Scholar   Icard P, Simula L, Fournel L, et al. The strategic roles of four enzymes in the interconnection between metabolism and oncogene activation in non-small cell lung cancer: therapeutic implications. Drug Resist Updat. 2022;63: 100852. https://doi.org/10.1016/j.drup.2022.100852. Article   CAS   PubMed   Google Scholar   Wang T, Li Y, Chen J, Xie L, Xiao T. TGF-\u03b21/Smad3 signaling promotes collagen synthesis in pulmonary artery smooth muscle by down-regulating miR-29b. Int J Clin Exp Pathol. 2018;11(12):5592\u2013601. CAS   PubMed   PubMed Central   Google Scholar   Download references Acknowledgements We acknowledge the colleagues in our team for their valuable suggestions and technical assistance. Funding This study was supported by Key Research and Development Special Sub-Project of National Ministry of Science and Technology (2022YFC2009904-01), Key Program of National Natural Science Foundation of China (81830059), Special Fund Project of Tongji University Basic Scientific Research Funds of Central Universities (22120190219), Major Project of the Clinical Three-Year Action Plan of Shanghai Shenkang Hospital Development Center (SHDC2020CR1038B), Key Disciplines Construction Plan of Public Health System of Shanghai Municipal Health Commission (GWV 10.1 XK09) and Major Project in the Field of Clinical Medicine of Science and Technology Innovation Action Plan of Shanghai Municipal Science and Technology Commission (19411951400). Author information Authors and Affiliations Department of Medical Imaging, Tongji Hospital, School of Medicine, Tongji University, No. 389, Xincun Road, Putuo District, Shanghai, 200065, People\u2019s Republic of China Fushi Han, Kangwei Zhang & Peijun Wang Institute of Medical Imaging Artificial Intelligence, Tongji University School of Medicine, Shanghai, 200065, China Fushi Han, Kangwei Zhang & Peijun Wang Department of Nuclear Medicine, Tongji Hospital, Tongji University School of Medicine, Shanghai, 200065, People\u2019s Republic of China Shuzhen Chen Department of Internal Medicine, Tongji Hospital, Tongji University School of Medicine, Shanghai, 200065, People\u2019s Republic of China Kunming Zhang Department of Radiotherapy, Tongji Hospital, Tongji University School of Medicine, Shanghai, 200065, People\u2019s Republic of China Meng Wang Contributions FH: conceptualization, methodology, investigation, writing- original draft preparation, writing- reviewing and editing. SC: data curation; formal analysis, software. KZ: data curation; formal analysis, software. KZ: data curation, supervision; validation. MW: visualization, writing\u2014review and editing. PW: conceptualization, funding acquisition, project administration, resource, writing\u2014original draft preparation, writing\u2014reviewing and editing. Corresponding author Correspondence to Peijun Wang. Ethics declarations Competing interests The authors declare no competing interests. Additional information Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Supplementary Information Additional file 1: Figure S1. Differential analysis of datasets from GEO database. A A volcano map of DEGs between control samples and NSCLC samples in five datasets from GEO database (GSE2514, GSE18842, GSE21933, GSE31552 and GSE44077). Green indicates the downregulated genes, red indicates the upregulated genes, and black indicates genes with no differential expression. B Venn diagram of the upregulated DEGs in the five datasets. C Venn diagram shows the downregulated DEGs in the five datasets. D A volcano plot of the DEGs between the radioresistant and radiosensitive NSCLC cell lines in the GSE20549 dataset. Green indicates the downregulated genes, red indicates the upregulated genes, and black indicates genes with no differential expression. Additional file 2: Figure S2. Correlation of SMAD3 expression and methylation at promoter CpG sites. A The DNA methylation level of 29 SMAD3 promoter CpG sites in TCGA-LUAD. B The DNA methylation level of 29 SMAD3 promoter CpG sites in TCGA-LUSC. C 18 CpG sites adversely correlated with SMAD3 expression in TCGA-LUAD. D 17 CpG sites negatively correlated with SMAD3 expression in TCGA-LUSC. Additional file 3: Figure S3. Radioresistance of NSCLC cells and identification of NAFs and CAFs. A CCK-8 detection of viability of 16HBE and NSCLC cells following exposure to different doses of X-ray radiation. B Morphology of primary fibroblasts under a microscope. C Immunofluorescence staining of \u03b1-SMA and FAP proteins in NAFs and CAFs. Cell experiments were repeated three times. *p\u2009<\u20090.05 vs. 16HBE cells. Additional file 4: Table S1. Clinical characteristics of 120 NSCLC patients. Table S2. Primer sequences of qRT-PCR. Table S3. The primer sequences for MSP. Table S4. shRNA sequences. Rights and permissions Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data. Reprints and permissions About this article Cite this article Han, F., Chen, S., Zhang, K. et al. Single-cell transcriptomic sequencing data reveal aberrant DNA methylation in SMAD3 promoter region in tumor-associated fibroblasts affecting molecular mechanism of radiosensitivity in non-small cell lung cancer. J Transl Med 22, 288 (2024). https://doi.org/10.1186/s12967-024-05057-2 Download citation Received 27 December 2023 Accepted 02 March 2024 Published 16 March 2024 DOI https://doi.org/10.1186/s12967-024-05057-2 Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Keywords Single-cell sequencing Non-small cell lung cancer Radiosensitivity Radiotherapy resistance Tumor-associated fibroblasts SMAD3 ITGA6 Download PDF Section Immune RadioBiology Sections Figures References Abstract Introduction Materials and methods Results Discussion Data availabilty References Acknowledgements Funding Author information Ethics declarations Additional information Supplementary Information Rights and permissions About this article Advertisement Journal of Translational Medicine ISSN: 1479-5876 Contact us Submission enquiries: Access here and click Contact Us General enquiries: info@biomedcentral.com Read more on our blogs Receive BMC newsletters Manage article alerts Language editing for authors Scientific editing for authors Policies Accessibility Press center Support and Contact Leave feedback Careers Follow BMC By using this website, you agree to our Terms and Conditions, Your US state privacy rights, Privacy statement and Cookies policy. Your privacy choices/Manage cookies we use in the preference centre. \u00a9 2024 BioMed Central Ltd unless otherwise stated. Part of Springer Nature.",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "Bionanofactory for green synthesis of collagen nanoparticles, characterization, optimization, in-vitro and in-vivo anticancer activities",
    "doi": "10.1038/s41598-024-56064-8",
    "description": "Collagen nanoparticles (collagen-NPs) are promising biological polymer nanoparticles due to their exceptional biodegradability and biocompatibility. Collagen-NPs were bio-fabricated from pure marine collagen using the cell-free supernatant of a newly isolated strain, Streptomyces sp. strain NEAA-3. Streptomyces sp. strain NEAA-3 was identified as Streptomyces plicatus strain NEAA-3 based on its cultural, morphological, physiological properties and 16S rRNA sequence analysis. The sequence data has been deposited under accession number OR501412.1 in the GenBank database. The face-centered central composite design (FCCD) was used to improve collagen-NPs biosynthesis. The maximum yield of collagen-NPs was 9.33\u00a0mg/mL with a collagen concentration of 10\u00a0mg/mL, an initial pH of 7, an incubation time of 72\u00a0h, and a temperature of 35\u00a0\u00b0C. Using the desirability function approach, the collagen-NPs biosynthesis obtained after FCCD optimization (9.53\u00a0mg/mL) was 3.92 times more than the collagen-NPs biosynthesis obtained before optimization process (2.43\u00a0mg/mL). The TEM analysis of collagen-NPs revealed hollow sphere nanoscale particles with an average diameter of 33.15 \u00b1 10.02 nm. FTIR spectra confirmed the functional groups of the collagen, collagen-NPs and the cell-free supernatant that are essential for the efficient capping of collagen-NPs. The biosynthesized collagen-NPs exhibited antioxidant activity and\u00a0anticancer activity against HeP-G2, MCF-7 and HCT116 cell lines. Collagen-NPs assessed as an effective drug loading carrier with methotrexate (MTX), a chemotherapeutic agent. The TEM analysis revealed that the average size of MTX-loaded collagen-NPs was 35.4 \u00b1 8.9 nm. The percentages of drug loading (DL%) and encapsulation efficiency (EE%) were respectively 22.67 and 45.81%.",
    "journal": "Scientific Reports",
    "authors": [
      "El-Sawah A.A.",
      "El-Naggar N.E.A.",
      "Eldegla H.E.",
      "Soliman H.M."
    ],
    "citation_count": "0",
    "full_text": "Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Advertisement View all journals Search Log in Explore content About the journal Publish with us Sign up for alerts RSS feed nature scientific reports articles article Article Open access Published: 15 March 2024 Bionanofactory for green synthesis of collagen nanoparticles, characterization, optimization, in-vitro and in-vivo anticancer activities Asmaa A. El-Sawah, Noura El-Ahmady El-Naggar , Heba E. Eldegla & Hoda M. Soliman  Scientific Reports  14, Article number: 6328 (2024) Cite this article 186 Accesses Metrics Abstract Collagen nanoparticles (collagen-NPs) are promising biological polymer nanoparticles due to their exceptional biodegradability and biocompatibility. Collagen-NPs were bio-fabricated from pure marine collagen using the cell-free supernatant of a newly isolated strain, Streptomyces sp. strain NEAA-3. Streptomyces sp. strain NEAA-3 was identified as Streptomyces plicatus strain NEAA-3 based on its cultural, morphological, physiological properties and 16S rRNA sequence analysis. The sequence data has been deposited under accession number OR501412.1 in the GenBank database. The face-centered central composite design (FCCD) was used to improve collagen-NPs biosynthesis. The maximum yield of collagen-NPs was 9.33 mg/mL with a collagen concentration of 10 mg/mL, an initial pH of 7, an incubation time of 72 h, and a temperature of 35 \u00b0C. Using the desirability function approach, the collagen-NPs biosynthesis obtained after FCCD optimization (9.53 mg/mL) was 3.92 times more than the collagen-NPs biosynthesis obtained before optimization process (2.43 mg/mL). The TEM analysis of collagen-NPs revealed hollow sphere nanoscale particles with an average diameter of 33.15\u2009\u00b1\u200910.02 nm. FTIR spectra confirmed the functional groups of the collagen, collagen-NPs and the cell-free supernatant that are essential for the efficient capping of collagen-NPs. The biosynthesized collagen-NPs exhibited antioxidant activity and anticancer activity against HeP-G2, MCF-7 and HCT116 cell lines. Collagen-NPs assessed as an effective drug loading carrier with methotrexate (MTX), a chemotherapeutic agent. The TEM analysis revealed that the average size of MTX-loaded collagen-NPs was 35.4\u2009\u00b1\u20098.9 nm. The percentages of drug loading (DL%) and encapsulation efficiency (EE%) were respectively 22.67 and 45.81%. Similar content being viewed by others Blueprinting extendable nanomaterials with standardized protein blocks Article Open access 13 March 2024 Natural products in drug discovery: advances and opportunities Article 28 January 2021 Supramolecular polymers form tactoids through liquid\u2013liquid phase separation Article Open access 28 February 2024 Introduction In recent years, nanoparticles have attracted a lot of attention due their unique characteristics. There are several types of nanoparticles, including metal nanoparticles, carbon-based nanoparticles, ceramic nanoparticles, lipid-derived nanoparticles, and polymeric nanoparticles. Polymeric nanoparticles are very small, granular, and colloidal particles with a variety of shapes and structures. There are many different types of natural polymeric nanoparticles, such as those made of collagen, soy, keratin, silk, and elastin. The advantageous characteristics of these particles are their bioavailability, biodegradability, and low costs1. Collagen, the most abundant protein in the human body, is found in the bones, muscles, skin, and other connective tissues. The well-known protein collagen has been utilized extensively in medical applications, including the development of microspheres and microneedles for the administration of drugs2, the production of protein delivery tablets and pellets3, for the therapy of cancer4, the production of gels and the incorporation of liposomes and medications for long-term administration of medicines5, and collagen shields in eye disease6. Collagen-NPs can disperse in water to produce colloidal solutions because of their small size, large surface area, and absorption capacity. Additionally, collagen-NPs enhance cell retention, can be quickly sterilized, maintain their shape under heat, and minimize the dangers of dangerous byproducts created during breakdown7. Collagen-NPs are more advantageous than other naturally occurring and synthetic polymeric NPs as a result of their outstanding biodegradability and biocompatibility, high contact surface, minimal antigenicity, lowered toxicity, and elevated cationic-charge density potential caused by their significant abundance of amino groups. This continues to be true even in the lack of target compound-induced surface change8. Traditionally, Collagen-NPs are synthesized using physical and chemical methods, both of which have several drawbacks. The use of extremely hazardous chemicals, environmental pollution, and carcinogenic solvents are the principal drawbacks of chemical methods that restrict their application in the clinical setting. The use of physical methods requires expensive equipments and an excessive amount of energy. TEM analysis revealed that the chemically synthesised collagen-NPs ranged in size from 50 to 500 nm by the self-assembly method9. After utilizing 4,4-azobis (4-cyanovaleric acid) and 3-acrylamidophenylboronic acid for synthesis, the TEM analysis revealed that the nanoparticles were spherical, evenly distributed, and had an average size of 81.3 nm. The diameter of the nanoparticles was around 79 nm10. By using poly diethylene glycol methyl ether methacrylate, the produced collagen-NPs recorded average diameter was about 100 nm11. The smaller size of nanoparticles is advantageous especially in biomedical applications. To synthesis of smaller size collagen-NPs for biomedical applications, there is a growing demand to develop techniques that are highly reliable, inexpensive, do not require the use of toxic substances, and eco-friendly process. The green synthesis of nanoparticles was accomplished using biological resources as a potential nano-factories, such as microorganisms including bacteria, actinomycetes, algae or fungi are recognized as potential nano-factories for green synthesis of a variety of nanoparticles12,13,14,15. As well as or plant extracts16,17,18, algal pigments19,20, algal derived soluble polysaccharides21 and fungi22. Due to the fact that they function as bio reducers, capping/stabilizing agents, or both, microorganisms or their protein extracts can be utilised to green synthesise nanoparticles in an environmentally sustainable manner, without the need for external chemicals23. Actinomycetes are a diverse microbial group recognized for producing antibiotics and other essential metabolites such as vitamins, antitumor agents, enzyme inhibitors, antibiotics, and enzymes. Streptomyces is the largest and most important genus in the order actinomycetales, and there are many species of Streptomyces in both terrestrial and aquatic environments. Insecticides, antiparasitic medications, immunostimulatory, immunosuppressive, antioxidative, anticancer, and other very useful pharmaceutical compounds with a wide range of medical and agricultural uses are also produced by Streptomyces24,25,26,27. The goals of this study were to biosynthesize ultrafine collagen-NPs using eco-friendly approach, to identify a newly isolated strain, Streptomyces sp. strain NEAA-3 that can biosynthesize collagen-NPs, use the cell-free supernatant of Streptomyces plicatus strain NEAA-3 for biosynthesis of collagen-NPs, to determine the optimum collagen concentration, pH, temperature, and incubation time for maximum biosynthesis of collagen-NPs using a face-centered central composite design, to evaluate the collagen-NPs' antioxidant, and anticancer activity on the HeP-G2, MCF-7, and HCT116 cell lines, to evaluate collagen-NPs' ability to supress tumor growth in mice bearing Ehrlich ascites carcinoma (EAC) and its potential to drug loading for methotrexate (MTX). Materials and methods A schematic representation of the research design framework of this study has been provided in Fig. 1. Figure 1 Schematic diagram of the research process in this study. Full size image Microorganism and cultivation conditions In this investigation, Streptomyces sp. strain NEAA-3 was isolated and kindly provided by Prof. Noura El-Ahmady El-Naggar, 2nd author. Streptomyces sp. strain NEAA-3 was cultured on Petri dishs containing starch-nitrate agar medium which had the following components (g/L) agar, 20; soluble starch, 20; KNO3, 2; NaCl, 0.5; K2HPO4, 1; FeSO4\u00b77H2O, 0.01; and 3; CaCO3. The inoculated Petri dishs were then incubated for seven days at 30 \u00b0C. Streptomyces sp. strain NEAA-3 was stored as spore suspensions in a 20% (v/v) glycerol solution at \u2212 20 \u00b0C for future investigation. Morphological and cultural properties Streptomyces sp. strain NEAA-3 's spore surface ornamentation and spore chain morphology were investigated by TEM (JEOL JSM 6510) after 14 days of incubation at 30 \u00b0C on a medium of starch nitrate agar. The pigmentation of substrate mycelium, color of aerial mycelium, and diffusible pigments production also were studied following the methods of Shirling and Gottlieb28 on ISP 1 (tryptone-yeast extract agar), ISP 2 (yeast-malt extract agar), ISP 3 (oatmeal agar), ISP 4 (inorganic salt starch agar), ISP 5 (glycerol- asparagine agar), ISP 6 (peptone-yeast extract iron agar), ISP 7 (tyrosine agar); within days, all plates were incubated at 30 \u00b0C. physiological properties Streptomyces sp. strain NEAA-3 was investigated for the utilization of different carbon sources, melanin production, NaCl tolerance, milk coagulation and gelatin liquefaction using the methods described by Shirling and Gottlieb28. To examine the strain's ability to produce \u03b1-amylase, it was streaked onto a starch nitrate agar medium plate with 2% soluble starch and grown for 7 days at 28 \u00b0C. After the incubation, the plate was stained using Gram's iodine solution29. Phylogenetic analysis, 16S rRNA sequencing and sequence alignment 16S rRNA of Streptomyces sp. strain NEAA-3 was extracted based on the method of Sambrook et al.30. By using PCR, 16S rRNA was amplified using El-Naggar et al.31 technique. The GenBank database has assigned accession number OR501412.1 to the resulting sequences. Using the BLAST tool (https://blast.ncbi.nlm.nih.gov/Blast.cgi;32), the 16S rRNA gene sequence (partial) of strain NEAA-3 was matched with other related species of the Streptomyces genus using the corresponding 16S rRNA sequences collected from the GenBank, EMBL, DDBJ, and PDB databases. A phylogenetic tree was generated using MEGA 11 software tool33. Cell-free supernatant preparation Streptomyces plicatus strain NEAA-3 was cultured on starch nitrate agar medium. Six discs with a diameter of 9 mm were taken from the culture that had been prepared previously and inoculated into 250 mL Erlenmeyer flasks with 100 mL of the medium consists of the following components: Soluble starch, 20; MgSO4, 0.5; KNO3, 1; NaCl, 0.5; K2HPO4, 0.5; FeSO4\u00b77H2O, 0.1 and 0.3 yeast extract; 1 L of distilled H2O. According to Mohamedin et al.14, flasks were incubated for five days at 30 \u00b0C and 150 rpm in an incubator shaker. The mycelium was subsequently separated from the cell-free supernatant using centrifugation for 15 min at 4 \u00b0C. The cell-free supernatant was lyophilized before being characterized by GC\u2013MS analysis. Extracellular biosynthesis of Collagen-NPs For the biosynthesis of collagen-NPs, 9 mL of freshly prepared cell-free supernatant (pH was adjusted to 7) was mixed with 1 mL of 10 mg/mL of pure marine collagen type I solution (MM Ingredients Ltd, UK) and incubated at 35 \u00b0C for 48 h. The appearance of white turbidity indicates the biosynthesis of collagen-NPs. After the biosynthesis of collagen-NPs using the cell-free supernatant of Streptomyces plicatus strain NEAA-3, the collagen-NPs was centrifuged at 13,000\u00d7g for 10 min, and then the supernatant was discarded. The pellets (collagen-NPs) were washed three times with distilled water for complete elimination of the cell-free supernatant and then re-dispersed by distilled water. Freeze-dried collagen-NPs were used for characterisation and application. Characterization of collagen-NPs The spectroscopic investigation was performed on the biosynthesized collagen-NPs, and the UV\u2013vis absorbance was measured between 200 and 800 nm using the ATI Unicam 5625 UV/VIS Vision Software V3.20. Transmission electron microscopy (TEM) was used to detect the morphology and size of the collagen-NPs using JEOL-JEM-100 CXII instrument, and scanning electron microscopy (SEM, JEOL JSM 6510 lv) was used to characterize the freeze-dried collagen-NPs. The freeze-dried collagen-NPs' elemental composition was identified by Energy-dispersive X-ray (EDX) using Oxford X-Max 20. Fourier-Transform Infrared (FTIR, thermo Scientific Nicolet iS10) was employed to determine the functional groups included in the freeze-dried collagen-NPs. The X-ray diffraction analysis (XRD) spectra of collagen powder and collagen-NPs were recorded using a Bruker D2 PHASER 2nd Gen X-ray diffractometer. The samples were exposed to monochromatic Cu/K radiations (=\u20091.5405) with diffraction angles varying from 10 to 80\u00b0 at a scanning rate of 2 min\u22121. Zeta potential analysis was used to determine the net surface charge of the biosynthesized collagen-NPs using the Zeta sizer nano ZS90 (Malvern Instruments Ltd. in the United Kingdom). The thermal decomposition behavior of collagen and collagen-NPs was examined using DSC (differential scanning calorimetry). The scans were conducted at a variety of temperatures, from ambient temperature to 500 \u00b0C. The graph depicted heat flow against temperature. TGA (Thermogravimetric analysis) of collagen and collagen-NPs were completed using a thermo-analyzer of type 50-H. Both samples were subjected to TGA investigation at temperatures ranging from room temperature to 800 \u00b0C in 10 \u00b0C min\u22121 increments. In a nitrogen atmosphere with a flow rate of 30 mL/min, samples of freeze-drying collagen and collagen-NPs weighing approximately 2.1 mg and 1.7 mg, respectively, were analyzed. The graph depicted the relationship between weight loss and temperature. Optimization of collagen-NPs biosynthesis by Face central composite design (FCCD) The FCCD, with thirty experiments and three replicates, was used to study the effects of four variables on the biosynthesis of collagen-NPs, including collagen concentration (X1), pH level (X2), temperature (X3), and incubation period (X4). Each design variable has been examined at three different levels (\u2212\u20091, 0, and 1). The central values (zero level) for the experimental design were 10 mg/mL of collagen solution, 48 h of incubation time, pH level 7, and 35 \u00b0C. The second polynomial regression equation was used to fit the experiment data: $$Y = \\beta_{0} + \\sum\\limits_{i} {\\beta_{i} X_{i} + \\sum\\limits_{ii} {\\beta_{ii} X_{i}^{2} } } + \\sum\\limits_{ij} {\\beta_{ij} X_{i} X_{j} }$$ (1) where, Y is the predicted collagen-NPs and \u03b2i, \u03b2ii, \u03b2ij are the linear, quadratic, and interaction terms, respectively. \u03b20 is a constant. Xi and Xj are the coded levels symbolized as X1, X2, X3 and X4. Statistical analysis Applying Design Expert 12 software for Windows (version 12; Stat-Ease Inc., USA) (https://www.statease.com/software/design-expert/), optimization and experimental data analysis were carried out. By using Version 8.0, StatSoft Inc., Tulsa, USA, STATISTICA software, the 3D surface graph of two different variables was plotted against the production of collagen-NPs (https://www.statsoft.de/de/software/statistica). ABTS+ antioxidant activity test 3 mL of MnO2 (25 mg/mL) solution and 2 mL of (60 M) ABTS (2, 2\u2032-Azino-bis (3-ethylbenzthiazoline-6-sulfonic acid) solution have been utilized for the detection of the antioxidant activity of collagen-NPs. Both had been pre-prepared in 5 mL of PBS (pH 7, 0.1 M). A green\u2013blue solution (ABTS+ solution) was created by shaking, centrifuging, and filtering the mixture. The absorbance (A control) was then adjusted to a value of roughly 0.5 at 734 nm. Once the combination has sat for 30 min at room temperature, combine 1 mL of the ABTS+ solution with 1 mL of collagen-NPs (500 \u00b5g/mL), and use a microplate reader to measure the absorbance at 734 nm (A test). The same method was carried out to compare native collagen powder. The inhibition percentage was estimated as follows: (Acontrol\u2009\u2212\u2009Atest)/Acontrol\u2009\u00d7\u2009100. Inhibition was utilized for expressing the absorbance (Atest), which connected to the reduction of color intensity. In vitro anticancer activity of collagen-NPs on cancer and normal cell lines In vitro anticancer activity of collagen-NPs was investigated against normal and cancer cell lines by utilizing a 3-(4, 5-Dimethylthiazol-2yl)-2, 5-diphenyl tetrazolium bromide (MTT) assay (colorimetric method). Cell lines for human lung fibroblast (WISH), human amnion (WISH), human colorectal carcinoma (HCT116), human liver cancer (HeP-G2), and mammary gland breast cancer (MCF-7) were obtained from the American Type Culture Collection (ATCC) through the Holding Corporation for Biological Products and Vaccines (VACSERA) in Cairo, Egypt. The appearance of formazan's purple color is directly proportional to the number of living cells because of the presence of NAD-dependent mitochondrial dehydrogenase in viable cells34. The cells were grown in an incubator at 37 \u00b0C with 5% CO2 using RPMI-1640 media with 10% fetal bovine serum, 100 units/mL penicillin, and 100 \u00b5g/mL streptomycin antibiotics. For single-cell suspensions, trypsin-ethylene diamine tetra acetic acid (EDTA) has been used to separate monolayer cells. A hemocytometer has been used to calculate the number of viable cells. In 96-well plates, 10,000 cells/well were seeded using 100 \u00b5L of cell suspensions. The cells were then incubated for 48 h at 37 \u00b0C with 5% CO2, 100% relative humidity, and 95% air to help the cells adhere to the bottoms of the wells. Collagen-NPs were employed to treat the cells at a range of concentrations (1.56, 3.125, 6.52, 12.5, 25, 50, and 100 \u00b5g/mL), and collagen-NPs concentrations were first passed through a 0.45-m filter syringe. Doxorubicin (DOX) was used as the reference. It was used after 24 h of incubation at 37 \u00b0C with 5% CO2 and 100% relative humidity. The study has been replicated to ensure the accuracy of the findings. 20 \u00b5L of the yellow MTT solution and 5 mg/mL of phosphate-buffered saline were administered to each well. The plates were incubated for MTT reduction for 4 h at 37 \u00b0C. Finally, 100 \u00b5L of DMSO was added to the generated purple formazan crystals. An EXL 800 plate reader was used to measure the absorbance at 570 nm. The percentage of cytotoxicity has been determined by: $${\\text{Viability }}\\% \\, = \\, \\left( {{\\text{Test OD}}/{\\text{Control OD}}} \\right) \\, \\times { 1}00$$ (2) $${\\text{Cytotoxicity }}\\% \\, = { 1}00 \\, - {\\text{Viability}}\\%$$ (3) In vivo apoptosis of EAC by Collagen-NPs The effect of collagen-NPs on the apoptosis of Ehrlich solid tumors has been investigated in vivo in order to determine whether or not collagen-NPs are able to induce apoptosis. The EAC cell line was chosen as it is one of the most prevalent tumors. Furthermore, EAC is classified as an undifferentiated carcinoma that is originally hyperdiploid, has a high transplantable capacity, does not regress, proliferates rapidly, and has a shorter life span. EAC is similar to human tumors in that it grows quickly and is undifferentiated, making it the most susceptible to chemotherapy35. Adult Swiss female albino mice were obtained from the Institute of Theodore Bilharz Research in Giza, Egypt, weighing 25\u201330 g. They were kept and housed in standard-sized polycarbonate cages at the Faculty of Pharmacy, Mansoura University, Mansoura, Egypt, with unlimited access to food and water at all times. The animals were kept in laboratories at 26\u2009\u00b1\u20091 \u00b0C, 12-h light/dark cycle, 25 \u00b0C, and a relative humidity of 20%. All mice were initially subcutaneously inoculated with 5\u2009\u00d7\u2009105 EAC cells from Cairo University's National Cancer Institute (NCI), Cairo, Egypt, to produce solid tumors. Before the initiation of the treatment, volumes of solid tumors were roughly 50\u2013100 mm3 (day 0) after five days of inoculation. The mice were then randomly divided into six groups. Each group included Swiss female albino mice (aged 9\u201310 weeks; 25\u201330 g; n\u2009=\u20095). Only EAC-bearing mice were in Group I, which served as the control. In Group II, EAC-bearing mice received a collagen injection in the tumor (2 mg/kg/1 day); in Group III, EAC-bearing mice received a doxorubicin (Dox) injection alone (2 mg/kg/1 day); in Group IV, EAC-bearing mice received a collagen-NPs alone (2 mg/kg/1 day); in Group V, EAC-bearing mice received a collagen in combination with DOX; and EAC-bearing mice received a collagen-NPs in combination with DOX. The same study design has been used in many previous studies as in36,37,38. Although the sample size was not high (n\u2009=\u20095) in each group, many previous researches used the same sample size as in36,39,40. Tumor volumes were assessed after collagen-NPs and DOX inoculation on the fifth day after tumor formation and subsequently every 5 days for a total of 20 days. After completing the trial and treatment (day 21), mice were sacrificed by cervical dislocated under anesthesia according to the weight of the mouse with its tumor using approximately 1.4 mg thiopental sodium (40 mg/kg) and tumor lumps were taken out, weighed, and preserved in buffered formalin solution for histological analysis. The tumor's volume38 can be calculated with Vernier calipers using the following formula: $${\\text{V}} = \\, \\left( {{\\text{L}} \\times {\\text{S}}^{{2}} } \\right) \\, \\times \\, 0.{5}$$ (4) where, V is the volume of the tumor, L is the diameter of the longest tumor and S is the diameter of the shortest vertical tumor. According to the study of Schirner et al.40, the effectiveness of the anti-tumor was calculated as: $${\\text{Growth inhibition }}\\left( \\% \\right){ } = { }100{ }{-}{ }\\left( {{ }\\frac{{{\\Delta T}}}{{{\\Delta C}}}{ } \\times 100} \\right)$$ (5) where \u0394T is the tumor volume change average in the treatment group and \u0394C is the tumor volume change average in the control EAC-bearing mice. Hematoxylin and eosin were used to stain the micrometer-sized slices, which were then viewed under a light microscope. Drug loading and encapsulation efficiency 10 mL of 5 mg/mL methotrexate (MTX) (Hikma Specialized Pharmaceuticals, Badr City, Cairo, Egypt) was added to 100 mg of collagen-NPs in order to assess the drug loading (DL%) and encapsulation efficiency (EE%). The mixture was stirred for 6 h at 25 \u00b0C. The precipitate of MTX-collagen-NPs (MTX-collagen-NPs) was generated by centrifugation at 12,000 rpm for 15 min. The supernatant was immediately harvested after centrifugation to be used in a UV\u2013Vis to measure the absorbance at 377 nm. The procedure was performed three times. An earlier calibration curve was created based on how the absorbance changed with varying MTX concentrations to quantify the free MTX concentration in the solution. Following are the calculations for (DL%) and (EE%) percentages: $$\\mathrm{DL }(\\mathrm{\\%}) = \\frac{\\mathrm{W }({\\text{total}}) -\\mathrm{ W}({\\text{free}})}{{\\text{W}}({\\text{collagen}}-{\\text{NPs}}) }\\times 100\\mathrm{\\%}$$ (6) $$\\mathrm{EE }(\\mathrm{\\%}) = \\frac{\\mathrm{W }\\left({\\text{total}}\\right)-\\mathrm{ W}({\\text{free}})}{\\mathrm{W }\\left({\\text{total}}\\right) }\\times 100\\mathrm{\\%}$$ (7) where W(total) is the total weight of MTX, W(free) is the total weight of free MTX (not loaded) in the supernatant, and W(collagen-NPs) refers to the total weight of collagen-NPs. The precipitate was washed three times and then lyophilized for evaluation of in vitro drug release. In vitro drug release For the in vitro release behavior evaluation of MTX-collagen-NPs at pH 7.4 (blood pH) and pH 5.5 (acidic intracellular environment), phosphate buffer saline (PBS) was utilized. Dialysis tubing (MWCO; 12\u201314 kDa) is loaded with 5 mg of MTX-collagen-NPs powder diluted in 5 mL of PBS (pH 7.4 or pH 5.5). The pH was either 7.4 or 5.5, and the dialysis tube was immersed in 40 mL of PBS while being gently stirred at 100 rpm. At predetermined intervals (0, 3, 6, 8, 12, 24, 48 h), an aliquot of 3 mL was removed from the release medium and replaced with an equal aliquot of fresh PBS. The aliquot sample was examined with the UV\u2013Vis spectrometer. The procedure was performed three times. The following equation was applied to determine the cumulative release percentage (CR%) of MTX-collagen-NPs at each time point: $$\\mathrm{The\\, cumulative\\, release\\, percentage\\, }(\\mathrm{CR \\%}) = \\frac{{\\text{Wt}}}{{\\text{Wi}}}\\times 100$$ (8) where Wt is the released drug weight at time t and Wi is MTX-collagen-NPs initial weight. Ethics approval and consent to participate All experimental protocols were approved by a Research Ethics Committee, Faculty of Medicine, Mansoura University, Mansoura, Egypt (Code number: MDP.21.01.54). All experiments were carried out in accordance with the applicable laws and regulations. All methods in the study are reported in accordance with ARRIVE guidelines. Result and discussion Morphological and cultural properties of Streptomyces sp. strain NEAA-3 Streptomyces sp. strain NEAA-3 is a mesophilic, aerobic, and gram-positive microorganism. Streptomyces sp. strain NEAA-3 culture, which had been growing on starch-nitrate agar for 7 days25, was examined morphologically (Fig. 2A). Both aerial and substrate mycelium were discovered to be plentiful, well-developed, and not fragmented. Spiral spore chains are carried by aerial mycelium; these spores are non-motile, cylindrical with smooth surfaces (Fig. 2B,C). Streptomyces sp. strain NEAA-3 mycelia grew well on the following tested media: tryptone-yeast extract agar, yeast extract-malt extract agar, oatmeal agar, and inorganic salt-starch agar. On the other hand, Streptomyces sp. strain NEAA-3 mycelia did not grow on glycerol-asparagine agar and grew poorly on peptone-yeast extract iron agar and tyrosine agar. Faint brown diffusible pigments were observed on starch nitrate agar medium and no diffusible pigments were discovered on the other tested media. On most media, the mature sporulating aerial mycelium ranged in color from gray to brownish gray, but on oatmeal agar, it was reddish gray. The colony's reverse side is a yellowish-brown on all tested media. The substrate pigment is not a pH indicator. Figure 2 S. plicatus NEAA-3 culture on starch nitrate agar (A), and scan electron microscopy photos of Streptomyces plicatus strain NEAA-3 (B,C), starch hydrolysis (D). Full size image Physiological properties The physiological properties of Streptomyces sp. strain NEAA-3 are shown in Table 1. No melanin pigments were formed in peptone-yeast-iron agar, glycerol tyrosine agar, or tryptone-yeast agar. It was observed that the starch hydrolysis (Fig. 2D), milk coagulation and gelatin liquefaction recorded positive results. The desired temperature for growth was 30 \u00b0C, and the optimal pH level was 7. It was demonstrated that the isolate had a tolerance for NaCl concentrations of up to 7% (w/v). Fructose, ribose, xylose, glucose, maltose, glucose, and lactose were all utilised as the sole carbon source, with the exception of sucrose. Table 1 Phenotypic characteristics that separate Streptomyces sp. strain NEAA-3 from other related Streptomyces species. Full size table Phylogenetic analysis The partial 16S rRNA gene sequence for Streptomyces sp. strain NEAA-3 (650 bp) was submitted to the GenBank/EMBL/DDBJ databases under the accession number OR501412.1 (https://www.ncbi.nlm.nih.gov/nuccore/OR501412.1?report=GenBank). The 16S rRNA gene sequences of the closest members of the genus Streptomyces were compared to those of the Streptomyces sp. strain NEAA-3 strain using BLAST search (https://blast.ncbi.nlm.nih.gov/Blast.cgi)32. The GenBank database of the BLAST has revealed that several Streptomyces genus species are similar to Streptomyces sp. strain NEAA-3. The phylogenetic tree (Fig. 3) was produced using the neighbor-joining technique33, which shows that Streptomyces sp. strain NEAA-3 is substantially correlated to several other Streptomyces species. According to phylogenetic analyses, Streptomyces sp. strain NEAA-3 belonged to subclades with Streptomyces minutiscleroticus strain NRRL B-12202 (accession No. NR _044149.1) with a similarity of 99.53%; Streptomyces olivoverticillatus strain NRRL B-1994 (accession No. NR_115786.1) with a similarity of 99.53%; Streptomyces plicatus strain NRRL 2428 (accession No. NR_ 043382.1) with a similarity of 99.69% as well as Streptomyces enissocaesilis strain NRRL B-16365 (accession No. NR_115668.1) with a similarity of 99.69%. Figure 3 Phylogenetic tree of neighbour-joining constructed on the sequences of 16 S rRNA gene, displaying the relationships between other Streptomyces species of related with strain NEAA-3. Full size image It was determined that Streptomyces sp. strain NEAA-3 was most closely related to the type strain of Streptomyces plicatus strain NRRL 2428 (accession No. NR 043382.1) and Streptomyces enissocaesilis strain NRRL B-16365 (accession No. NR_115668.1) with the highest degree of similarity 99.69%42, but based on the comparative study based on the previous collected data of the morphological, cultural, and physiological characteristics of the isolate. The isolate was thus named Streptomyces plicatus strain NEAA-3. The actinobacteria data for the reference species have been taken from Goodfellow et al.43. GC\u2013MS spectral analysis of the cell-free supernatant of Streptomyces plicatus strain NEAA-3 GC\u2013MS analysis was performed on the lyophilized cell-free supernatant of Streptomyces plicatus strain NEAA-3 that had been dissolved in methanol. A number of fatty acids were identified using GC\u2013MS spectral data (Table 2 and Fig. 4). These fatty acids include linear chain saturated fatty acids methyl ester of; 11-octadecenoic acid, octanoic acid (caprylic acid), pentanoic acid (valeric acid), octadecanoic acid (stearic acid), hexadecanoic acid (palmitic acid), cyclopropaneoctanoic acid, 2-hexyl, ocosanoic acid (behenic acid), tetracosanoic acid (lignoceric acid) and palmitoleic acid. Unsaturated fatty acid; 9-octadecanoic acid (Z) (oleic acid & its isomer elaidic acid) is also present. Methanesulfonic acid nonamethylene also exists. There are three different types of alcohols on display: 1-heptacosanol, cis-1, 2-cyclohexanedimethano and 3-cyclohexylpropyl alcohol. The most prevalent fatty acid was 11-octadecenoic acid, methyl ester, which according to the study of Shoge and Amusan44 possesses antibacterial action. Octadecanoic acid, methyl ester (stearic acid) at the third degree was introduced, followed by 9-octadecanoic acid (Z) (oleic acid) methyl ester. Oleic acid, stearic acid and palmitic acid (second degree in abundance) showed antioxidant, in vitro inflammatory and antibacterial activity according to the studies of Fratianni et al.45. Caprylic acid is used widely in the food and dairy industries as an antibacterial pesticide for surface sanitization and in the cosmetics, dietary supplements, and other industrial items that promote good health46. According to Narang et al.47, palmitoleic acid may have the capacity to boost antioxidant enzymes like superoxide dismutase, catalase and glutathione peroxidase. Due to its high acid strength (pKa\u2009=\u2009\u2212\u20091.9), methanesulphonic acid is a potent organic acid. Additionally biodegradable and not producing hazardous gases is methanesulfonic acid. Therefore, it was regarded as a green acid48. Table 2 Bioactive constituents identified in the cell free supernatant of Streptomyces plicatus strain NEAA-3 using GC\u2013MS analysis. Full size table Figure 4 GC\u2013MS chromatogram and chemical composition of bioactive components identified in the methyl acetate of the cell-free supernatant of Streptomyces plicatus strain NEAA-3. Full size image Evaluation of collagen-NPs biosynthesis by the cell-free superntant of Streptomyces plicatus strain NEAA-3 For the collagen-NPs biosynthesis (Fig. 5A), 1 mL of 10 mg/mL of pure marine collagen solution (type I) was added to 9 mL of freshly prepared cell-free supernatant. Protein nanoparticles can be produced through a process known as desolvation. There are a number of factors that can influence the size of protein nanoparticles during the desolvation process. These factors include the protein concentration, the temperature, the addition of a desolvation agent (like alcohol or natural salt), and the pH of the medium8. Consequently, the GC-mass analysis indicates that three different alcohols, including 1-heptacosanol, cis-1, 2-cyclohexanedimethano and 3-cyclohexylpropyl alcohol, can function as a desolvation factor and can be used to bio-fabricate the collagen-NPs. The desolvation factor can alter collagen's structure and reduce its solubility, as seen, for example, in the production of nanoparticles following the addition of glutaraldehyde to collagen mass49. Fatty acids and alcohols are thought to change how collagen molecules interact to bio-fabricate the collagen-NPs. Mostly all of the fatty acids found in secondary metabolites have antioxidant characteristics, which means they can reduce collagen protein to bio-fabricate the collagen-NPs. According to the findings of a study conducted by Nagarajan et al.50, acetic acid was utilized to bio-fabricate the collagen-NPs. However, methanesulfonic acid nonamethylene is presented in traces; the methanesulfonic acid exhibits a high acidity, which makes it an effective catalyst for chemical processes and collagen-NPs biosynthesis. According to studies conducted by Cinar et al.51, Gupta et al.52, Xia et al.53, and Mourdikoudis et al.54, oleic acid is one of the most appealing fatty acids that have been employed in the creation of metal nanoparticles as well as a great capping agent. According to Agrawal et al.55, palmitic acid methyl ester was abundant and employed as a superhydrophobic coating material for ZnO nanoparticles. Figure 5 (A) Optical observation of collagen soln. (1) Cell-free supernatant of Streptomyces plicatus strain NEAA-3 (2), collagen- NPs (3), (B) Schematic diagram of collagen-NPs biosynthesis & (C) UV\u2013visible absorbance of collagen-NPs biosynthesis by Streptomyces plicatus strain NEAA-3. Full size image Spectroscopy analysis of collagen-NPs The highest absorption peaks for collagen-NPs, marine collagen solution, and the cell-free supernatant of Streptomyces plicatus strain NEAA-3 were determined by UV\u2013visible analyses (Fig. 5B). The highest absorbance peak of marine collagen solution was measured at 240 nm. Saallah et al.56 reported that the pure marine collagen type I extracted from Holothuria scabra showed two maximum absorption peaks at 240 and 220 nm. Since glycine and proline/hydroxyproline make up the majority of collagen, its greatest absorbance peak falls between 210 and 240 nm57, which supports the collagen's purity. Also, the absence of an absorption peak at about 280 nm, which is associated with aromatic amino acids like phenylalanine and tyrosine58, further supports collagen's purity. The collagen-NPs' maximal absorption was measured at 240 nm, confirming collagen's presence. Microscopy analysis of collagen-NPs The morphology of collagen-NPs produced using the cell-free supernatant of Streptomyces plicatus strain NEAA-3 was investigated and confirmed using TEM and SEM analyses (Fig. 6A,B). The transmission electron micrograph revealed the presence of hollow sphere nanoparticles (Fig. 6C). The mean diameter of the produced collagen-NPs was recorded as 33.15\u2009\u00b1\u200910.02 nm, which is less than 100. The small size of nanoparticles is advantageous, especially in the medical applications. The small sizes of nanoparticles allow them to not only transport widely throughout the body, but they can also penetrate cells or be modified to attach to specific types of cells. Collagen-NPs can be an ideal 3D biomaterial due to their nanoscale size between 1 and 100 nm. It also has a high surface area-to-volume ratio that facilitates effective interaction and penetration into wound sites59. Figure 6 Microscopy investigation of collagen-NPs biosynthesis by Streptomyces plicatus strain NEAA-3: (A) TEM image, (B) SEM image, (C) particles size distribution and EDX. Full size image In the EDX results of the collagen-NPs powder (Fig. 6D), the elemental peaks for C, O2, Na, Mn, Si, P, S, Cl, K, Ca, Cu, and Zn were observed. Carbon was the most abundant element, with weight and atomic percentages of 58.83 and 68.81, respectively, followed by oxygen with values of 29.96 and 26.31, respectively. Fourier-transform infra-red (FTIR) For many years, researchers have successfully used FTIR analysis (Fig. 7A) to examine the structural dynamics, conformational changes, secondary structures, and stability studies of proteins60. The produced collagen-NPs revealed several absorption peaks in the FTIR spectrum (3304, 2934, 1641, 1546, 1409, 1245, 1081, 933 and 619 cm\u22121). The peak at 3304 cm\u22121 belongs to the vibrations of N\u2013H stretching that refer to NH2 in aromatic amines, amide A and primary amines that present between 3500 cm\u22121 and 3300 cm\u22121 according to Pati et al.61 research. Amide B refers to CH of symmetric and anti-symmetric stretching that is present in CH3 and CH2 in aliphatic compounds and is detected in the absorption peak at 2934 cm\u22121, which can be observed in the range of 2990 to 2850 cm\u22121 according to Movasaghi et al.62. The amide I bond coupled with the (C=O) group straight with the polypeptide backbone was the distinctive frequency marker of peptide secondary structure found between 1600 and 1700 cm\u22121 according to Haris & Severcan63, which was identified at 1641 cm\u22121. The peak at 1546 cm\u22121, which is found between the amide II's typical absorption ranges (1478\u20131565 cm\u22121), belongs to NH in secondary amides64. The C\u2013C stretch of aromatic compounds is the source of the 1409 cm\u22121 peak. The absorption peak at 1245 cm\u22121 was discovered to fall within the 1411 cm\u22121 (amide II) and 1241 cm\u22121 (amide III) band ratio range, which was almost equal to 1, confirming the collagen triple helical structure65. The peak at 1081 cm\u22121 demonstrated that the C\u2013O stretch in alcohol exists. Peaks at 933 cm\u22121, and 619 cm\u22121 all provided evidence for the occurrence of 1,2,4-trisubust benzene, Ar\u2013OH in phenols, and O\u2013C=O in carboxylic acid, respectively64. Figure 7 FTIR (A), X-ray diffraction analysis (B) and Zeta-potential (C) of collagen-NPs by biosynthesis by Streptomyces plicatus strain NEAA-3. Full size image Analysis of X-ray Diffraction (XRD) The XRD diagram is displayed in Fig. 7B. At diffraction angles (2\u03b8) of 10\u00b0 and 24\u00b0, collagen-NPs exhibited two typical peaks that matched the characteristics diffraction peaks of pure collagen66. The first peak is related with the triple helical structure of collagen, whereas the second peak is related with the distance between skeletons. Diffraction peaks can be used to determine the ordered structures of collagen67. The Zeta potential Zeta potential can be negative or positive and plays a key role in determining the stability of the nanoparticles in colloidal solutions.The surface charges on the particles may influence the stability of the nanoparticle\u2019s preparation through substantial electrostatic repulsion between the particles68. Marine collagen type I nanoparticles have a limited range of Zeta potential, which increases surface area, dispersion capacity, and catalytic activity69. The Zeta potential value was recorded at \u2212 19.3 mV, with a Zeta deviation of 9.72 mV and conductivity of 2.68 mS/cm, as shown in Fig. 7C. Zeta potential value of the biosynthesized collagen-NPs produced by the cell-free supernatant of Streptomyces xinghaiensis NEAA-1 was\u2009\u2212\u200918.4 mV, which coordinates with our result70. The results of this study indicated that the biosynthesized collagen-NPs using the cell-free supernatant of Streptomyces plicatus strain NEAA-3 had notably superior stability to that of the chemically synthesized collagen-NPs. Thermogravimetric analysis (TGA) The thermal stability of polymeric nanoparticles refers to their ability to resist heat and maintain their properties, such as strength, toughness, or elasticity, at a particular temperature71. TGA is typically used to test the thermal stability of collagen-NPs. Figure 8A displays the TGA analysis. The first transition phase of collagen-NPs was initiated by the first weight loss of the particles at a temperature of 116.82 \u00b0C and a weight percentage of 14.684. The weight percentage decreased to 12.77 and the transition temperature shifted to 106.87 \u00b0C when compared to collagen after thermal degradation (Fig. 8B). According to a study by Ebnesajjad et al.72, the first weight loss is attributed to the samples' moisture content and volatile components. The second transition temperature of collagen occurred at 198.96 \u00b0C with a weight percentage of 3.63, while the second transition temperature of collagen-NPs occurred at 188.57 \u00b0C with a weight percentage of 0.9468. The second decomposition phase is caused by the decomposition of collagen and the consumption of collagen organic matrix waste73. Figure 8 Thermal stability investigation of collagen-NPs: TGA analysis for collagen-NPs (A) and collagen (B). DSC of collagen-NPs and collagen. Full size image TGA curves for pure collagen and mineralized collagen revealed the same profile, with weight loss due to the evaporation of physisorbed water between room temperature and 200 \u00b0C, and weight loss related to the decomposition of collagen molecules between 200 and 500 \u00b0C and the combustion of the remaining organic components causing a minor loss of weight between 500 and 700 \u00b0C74,75. The third transition phase is regarded to be the maximum denaturation temperature for both collagen and collagen-NPs. The remaining weight percentages of collagen and collagen-NPs were 43.72 and 69.45, respectively, and their corresponding transition temperatures were 434.37 and 495.46, respectively. The findings of this research demonstrated that the collagen-NPs exhibited enhanced thermal stability due to the pervasive presence of bioactive components on their surfaces as capping agents. The remaining final weight percentages of collagen and collagen-NPs were 18.03% and 7.421%, respectively and their corresponding transition temperatures were 782.46 \u00b0C and 785.82 \u00b0C, respectively due to the combustion of the remaining organic components according to Tampieri et al.74. Differential scanning calorimetry (DSC) DSC approach is a direct method that can reveal details about the actual thermodynamic properties of protein thermal transitions and the evaluation of variables that are crucial to the stability of certain proteins76. Theoretically, information about the thermal transitions of proteins can be obtained by measuring the heat flow between the sample (collagen-NPs) and reference (collagen). At the greatest transition point (Tmax), also known as the endothermic peak of transition curves, the transition temperature value for both collagen-NPs and the collagen sample was calculated. Figure 8C demonstrated an endothermic peak at 96.92 \u00b0C, which was greater than 91.37 \u00b0C for collagen; this is related to the disintegration of the triple helical structure as well as the release of the water-bound collagen molecule77. The high endothermic temperature peak of collagen-NPs is assumed to be caused by the bioactive compounds present in the capping agents, which were derived from the cell-free supernatant of Streptomyces plicatus strain NEAA-3. Face-centered central composite for optimizing the biosynthesis of collagen-NPs The biosynthesis of collagen-NPs was optimized using a face-centered central composite. Table 3 lists the results of 30 trials that used with different combinations of the following four variables: collagen concentration, pH, temperature and incubation time (X1, X2, X3 and X4; respectively). Run orders 4, 11, 17, 26, and 30 showed the highest production of collagen-NPs. The maximal collagen-NPs biosynthesis occurred at a value of 9.33 mg/mL, which appeared in run order 30 under the conditions of 10 mg/L of collagen concentration, 72 h of incubation, initial pH of 7, and 35 \u00b0C. The lowest biosynthesis of collagen-NPs was noticed in run order 21, which achieved 1.8 mg/mL, under the condition of 5 mg/mL of collagen concentration, initial pH of 5, 24 h of incubation time and 25 \u00b0C. Experimented and predicted values are presented in Table 3. Table 3 Face-centered central composite design matrix representing collagen-NPs biosynthesis by Streptomyces plicatus strain NEAA-3 as affected by pH, temperature, collagen concentrations and incubation time with factor levels (coded and actual). Full size table ANOVA and multiple regression analysis Table 4 displays the ANOVA results for the experimental design, the Fisher (F-value), the probability (P-value). Given that the F-value of the model is 379.36, with a very low P-value (<\u20090.0001) it can be concluded that the model is statistically very significant (Table 4). The model terms are significant when the P-value is less than 0.05. Coefficients with smaller P-values are more significant78. With a P-value of less than 0.0001, almost all parameters of the linear effect (X1, X2, X3, X4), interaction effect (X1X2, X1X3, X1X4, X2X3, X2X4) and quadric effect (X12, X22, X32) demonstrated maximum significance suggesting that the model terms are significant. While X3X4 (linear effect) and X42 (quadric effect) are not significant. Table 4 Variance analysis for collagen-NPs biosynthesis by Streptomyces plicatus strain NEAA-3 as affected by pH, incubation time, collagen concentrations and temperature with factor levels (coded and actual). Full size table According to the study of El-Naggar et al.20, there is a perfect correlation between predicted and actual response values when the R2-value is more than 0.9. Consequently, the R2-value of the model (0.9972) demonstrated a robust correlation between the observed and predicted values, which suggests that the current model is reliable for the biosynthesis of collagen-NPs. The adjusted R2 of 0.9946 and the predicted R2 of 0.99 are reasonably in agreement; hence, the difference is less than 0.279. The coefficient estimations also revealed whether collagen-NPs were changed positively or negatively. Antagonism (negative coefficient) and synergism (positive coefficient) are the two possible interactions between two variables80. A large estimated coefficient, whether positive or negative, indicates that the independent factors significantly affect the response. Production increases at high levels of every investigated variable whose expected coefficient has a positive sign81. If the sign is negative, it is implied that production increases when the variable is present at low levels. Table 4 shows the positive coefficient parameters (X1 as a linear effect and X1X3, X2X3 and X3X4 as an interaction effect) that increased the production of collagen-NPs. While all other coefficients are negative, the positive coefficient for X1 indicates that this variable increased collagen-NPs production linearly. The statistical analysis of collagen-NPs biosynthesis reveals a 2.86% coefficient of variation percentage (C.V. %), which is comparatively very low and indicates great accuracy, dependability, and precision of experimental trials. A relatively small value of the coefficient of variation % reflects high precision and accuracy of the experimental values82. The ratio of signal to noise is measured by Adeq Precision. A ratio higher than 4 is desirable since it indicates that the model has high accuracy83. The model's precision is 56.71 in the present investigation, indicating the model's precision. The mean of the model is 6.46, with a standard deviation of 0.18. The fit summary results provided in Table 5 were utilized to choose between the 2FI, linear and quadratic models as the most suitable polynomial model for collagen-NPs biosynthesis by the cell-free supernatant of Streptomyces plicatus strain NEAA-3. Since the lack of fit is not statistically significant (P-value is 0.0816 and the F-value is 3.68), the quadratic model is an appropriate model for the collagen-NPs biosynthesis by the cell-free supernatant of Streptomyces plicatus strain NEAA-3. Furthermore, it is observed that the quadratic model has R2 value of 0.9972, adjusted R2 value of 0.9946 and predicted R2 value of 0.99, all of which are higher than the 2FI and linear models (Table 5). The quadratic model has a lower standard deviation of 0.18 and PRESS value of 1.82. Table 5 Fit summary for face-centered central composite design results for collagen-NPs biosynthesis by Streptomyces plicatus strain NEAA-3 as affected by pH, incubation time, collagen concentrations and temperature with factor levels (coded and actual). Full size table The maximum collagen-NPs biosynthesis by the cell-free supernatant of Streptomyces plicatus strain NEAA-3 that correspond to the four variables' optimum levels were determined using the second-order polynomial model (Eq. 9), and the relationship between collagen-NPs biosynthesis and the independent variables (pH, temperature, incubation time, and collagen concentration) was assessed. The predicted collagen-NPs biosynthesis (Y) that correspond to the four independent variables was calculated as follows. $${\\text{Y}} = { 9}.0{7} + { 1}.{\\text{8X}}_{{1}} - \\, 0.{\\text{32X}}_{{2}} - \\, 0.{\\text{23X}}_{{3}} - \\, 0.{\\text{22X}}_{{4}} - \\, 0.{\\text{37X}}_{{1}} {\\text{X}}_{{2}} + \\, 0.{\\text{36X}}_{{1}} {\\text{X}}_{{3}} - \\, 0.{\\text{3X}}_{{1}} {\\text{X}}_{{4}} + \\, 0.{\\text{19X}}_{{2}} {\\text{X}}_{{3}} - \\, 0.{\\text{3 X}}_{{2}} {\\text{X}}_{{4}} + \\, 0.0{\\text{3X}}_{{3}} {\\text{X}}_{{4}} - { 1}.{\\text{93 X}}_{{1}}^{{2}} - \\, 0.{\\text{85X}}_{{2}}^{{2}} - {1}.{\\text{37X}}_{{3}}^{{2}} - 0.{\\text{2 X}}_{{4}}^{{2}}$$ (9) The model adequacy The normal probability plot (NPP) is a statistic tool that indicates whether or not a model's residuals follow a normal distribution36. The difference between theoretical and experimental data is referred to as the residuals84, and a small residual indicates a high degree of model correctness. NPP is displayed in Fig. 9A, indicating that the residuals are found on the diagonal straight line of collagen-NPs biosynthesis by the cell-free supernatant of Streptomyces plicatus strain NEAA-3. This demonstrates that the predicted data fit the experimental findings, confirming the model's accuracy19,85. Figure 9 (A) Normal probability plotting of internally studentized residuals, (B) plotting of actual versus predicted (C) Box-Cox plotting of model transformation and (D) plotting of internally studentized residuals versus predicted values of collagen-NPs biosynthesis by Streptomyces plicatus strain NEAA-3. CNPs: collagen-NPs. Full size image Figure 9B demonstrated the relationship between the predicted and experimental collagen-NPs biosynthesis values. It demonstrates that all point is located in close proximity to the prediction line, indicating that the model is adequate and explains the excellent agreement between the experimental and theoretical results86,87. The Box-Cox graph of model transformation graph is displayed in Fig. 9C. The red and blue lines show the minimum and maximum confidence intervals (C.I.) values (0.56\u20131.02; respectively), and the blue line shows the current lambda value (lambda\u2009=\u20091). The green line represents the best lambda value (best lambda\u2009=\u20090.79). The blue line lies in the optimal zone between the minimum and maximum C.I., this indicates that the predicted data fits the experimental data well and confirming that no data transformation is required19,88. The externally studentized residuals were plotted against the predicted values of collagen-NPs biosynthesis by the cell-free supernatant of Streptomyces plicatus strain NEAA-3 in Fig. 9D. It shows the residuals against the predicted values. The residual points are scattered randomly nearly along the zero line, which indicates that the values of the experimental results have a constant small variation from the predicted data89,90. Three-dimensional surface plots The four independent bioprocess variables were combined in pairwise combinations to assess their optimal levels and their mutual interaction effects on collagen-NPs biosynthesis by the cell-free supernatant of Streptomyces plicatus strain NEAA-3. These three-dimensional graphs are shown in Fig. 10A\u2013F. Two of the independent variables were plotted against collagen-NPs biosynthesis on the Z-axis while the other two independent variables held at their zero levels. The in vitro synthesis of collagen nanostructures is reported to be influenced by temperature, pH, ionic strength, collagen type or concentration, and pH90. Figure 10 3D plots showing the mutual effects of collagen concentration (X1), pH (X2), temperature (X3) and incubation time (X4). on collagen nanoparticles biosynthesis by Streptomyces plicatus strain NEAA-3. CNPs: collagen-NPs. Full size image Figure 10A displays the relationship between collagen-NPs biosynthesis and the mutual interactions between X1 (collagen concentration) and X2 (initial pH), whereas X3 (temperature) and X4 (incubation time) had been maintained at zero levels (35 \u00b0C and 72 h; respectively). Collagen-NPs biosynthesis value increased gradually until the optimal pH (7) was reached, and decreasing or increasing the pH value, the collagen-NPs biosynthesis will be decreased. By increasing collagen concentration, the collagen-NPs biosynthesis increased up to 10\u201312 mg/mL. However, the biosynthesis of collagen-NPs is gradually reduced by subsequent increases in collagen concentration. Collagen nanostructures were produced in numerous studies using pH values between 7 and 7.4. Collagen type I has a pH of 7.2, which is close to the isoelectric point where the charge of the collagen amino acids is balanced, favoring the creation of nanostructures91. Figure 10B displays the relationship between collagen-NPs biosynthesis and the mutual interactions between X1 (collagen concentration) and X3 (temperature), whereas X2 (pH) and X4 (incubation time) had been maintained at zero levels (7 pH and 72 h; respectively). Collagen-NPs increase gradually as the temperature and collagen concentration increase until they reach their midpoints (10 mg/mL and 35 \u00b0C; respectively). However, the biosynthesis of collagen-NPs is gradually reduced by subsequent increases in temperature or collagen concentration due to the high concentration of collagen and the supernatant's incapacity to transform the collagen protein to collagen-NPs. Room temperature, which was between 35 and 37 \u00b0C, was the ideal temperature for the synthesis of collagen-NPs. According to Luo et al.11, the collagen-like peptide was able to create well-defined nano-vesicles with diameters of about 100 nm and a transition temperature of 37 \u00b0C. Figure 10C displays the relationship between collagen-NPs biosynthesis and the mutual interactions between X1 (collagen concentration) and X4 (incubation time), whereas X2 (initial pH) and X3 (temperature) had been maintained at zero levels (7 pH and 35 \u00b0C; respectively). The collagen-NPs biosynthesis increased rapidly as the concentration of collagen and the incubation time increased. This continued until their midpoints (10 mg/mL and 72 h; respectively) were reached. After that point, collagen-NPs biosynthesis decreased due to the high concentration of collagen and the incapacity of the supernatant transform the collagen to collagen-NPs. In addition, the prolonged incubation period caused agglomeration of nanoparticles, which had a negative impact on collagen-NPs biosynthesis. Figure 10D displays the relationship between collagen-NPs biosynthesis and the mutual interactions between X2 (initial pH) and X3 (temperature), whereas X1 (collagen concentration) and X4 (incubation time) had been maintained at zero levels (10 mg/mL and 72 h; respectively). The collagen-NPs increased as the temperature and initial pH level were increased until they reached their midpoints. Collagen-NPs will then decrease as initial pH and temperature increase. According to Song et al.92, too much acid or alkali can cause collagen molecules to lose their ionic and hydrogen bonds. The pH of the media is the main determining factor since it can affect the charge distribution and electrostatic interactions of the collagen molecules, affecting their ability to form nanostructures93. Figure 10E displays the relationship between collagen-NPs biosynthesis and the mutual interactions between X2 (initial pH) and X4 (incubation time), whereas X1 (collagen concentration) and X3 (temperature) had been maintained at zero levels (10 mg/mL and 37 \u00b0C; respectively). As the initial pH and incubation time increased, collagen-NPs production gradually increased until it reached the midpoint. The collagen-NPs aggregated as a result of the prolonged incubation time. Figure 10F displays the relationship between collagen-NPs biosynthesis and the mutual interactions between X3 (temperature) and X4 (incubation time), whereas the X1 (collagen concentration) and X2 (initial pH) had been maintained at zero levels (10 mg/mL and 7 pH; respectively). The collagen-NPs increase significantly as the temperature and incubation time increase until they reached their midpoints. Collagen-NPs will then decrease as incubation time and temperature increase. Desirability function analysis Desirability function analysis (DFA) is the most widely used technique for determining the optimal predicted conditions that would results in maximum of the response80. The values of the desirability functions range from 0 (undesirable) to 1(desirable). DFA was carried out by Design Expert Software (Version 12) in Fig. 11. The maximum theoretical yield of collagen-NPs biosynthesis using the cell-free supernatant of Streptomyces plicatus strain NEAA-3 was 9.44 mg/mL with a collagen concentration of 11.92 mg/mL, an initial pH of 5.94, an incubation time of 54.79 h, and a temperature of 35.79\u00b0C. The desirability function value reached 1. Under these conditions, collagen-NPs biosynthesis was practically verified. The collagen-NPs biosynthesis obtained experimentally was 9.53 mg/mL. The collagen-NPs biosynthesis value predicted by the polynomial model (9.44 mg/mL) was compared to the experimental result (9.53 mg/mL). A comparison was made between the collagen-NPs biosynthesis value predicted by the polynomial model (9.44 mg/mL) and the experimental result (9.53 mg/mL). The verification demonstrated a high degree of model accuracy, demonstrating the model's validity at the factor levels used in the current study. Using the desirability function approach, the collagen-NPs biosynthesis obtained after FCCD optimization (9.53 mg/mL) was 3.92 times more than the collagen-NPs biosynthesis obtained before optimization process (2.43 mg/mL). Figure 11 Optimization plotting reveals the optimum predicted values for maximum collagen- NPs biosynthesis by Streptomyces plicatus strain NEAA-3 and the desirability value. CNPs: collagen-NPs. Full size image In vitro anticancer activity of collagen-NPs In vitro tumor models are crucial tools for cancer studies and can be used as inexpensive screening platforms for medication therapy94. MTT assay is one of the most popular applications for assessing the cytotoxicity of various medications at various dosages. The MTT assay works on the basis that, in the majority of viable cells, mitochondrial activity. As a result, changes in mitochondrial activity are directly correlated with changes in the number of viable cells95. The MTT assay is based on the reduction of MTT, a yellow water-soluble tetrazolium dye, to purple formazan crystals, mostly by the action of mitochondrial dehydrogenases. The cytotoxic effects of collagen-NPs (Fig. 12A), collagen (Fig. 12B), and Dox, an available anticancer medication, (Fig. 11C), were examined in vitro using cancer cell lines (HCT116, HeP-G2 and MCF-7) and normal cell lines (WI38 and WISH). The inhibitory effect became apparent after 48 h of incubation. In comparison to untreated controls, the results are presented in Table 6 as growth inhibitory concentrations (IC50) values, or half-maximal inhibitory concentrations of cell growth after 48 h of incubation. The IC50 value of HCT116 was 24.82\u2009\u00b1\u20091.7 \u00b5g/mL (moderate inhibition), HeP-G2 was 13.36\u2009\u00b1\u20091.0 \u00b5g/mL (strong inhibition), and MCF-7 was 7.80\u2009\u00b1\u20090.5 \u00b5g/mL (strong inhibition) for collagen-NPs against cancer cell lines. Against normal cell lines, including WI38 and WISH, the IC50 of collagen-NPs was found to be 62.58\u2009\u00b1\u20093.6 and 74.91\u2009\u00b1\u20093.6 \u00b5g/mL, respectively. Therefore, the biosynthesized collagen-NPs showed a stronger cytotoxic effect on the cancer cell lines HCT116, HeP-G2, and MCF-7 compared to the normal cell lines WISH and WI38. Han et al.96 reported that the marine collagen reduced the growth of HepG2 and HeLa cells by 50% and 38%, respectively, with a concentration of 0.2 mg/mL. Collagen-NPs showed a higher cytotoxic effect than collagen. Studies on the size-dependent toxicity of micro- and nanoscale particles has demonstrated97,98 that the toxicity of nanoparticles is greater than that of bigger particles, supporting the theory that nanoparticles are generally more potent at causing damage. So, collagen-NPs could have a cytotoxic effect on mitochondrial, endoplasmic reticulum, and Golgi apparatus enzymes, as well as the lysosomal compartments, which reduce MTT dye to purple formazan. Figure 12 Diagram showing the anticancer (cytotoxicity) effect of collagen-NPs produced using Streptomyces plicatus strain NEAA-3 (A) and collagen (B) against different normal and cancer cell lines at different concentrations ranged from 1.65 to 100 \u00b5g. Doxorubicin used as standard anticancer drug. Full size image Table 6 Showing the growth inhibitory concentration (IC50) values of collagen-NPs produced using Streptomyces plicatus strain NEAA-3, collagen, doxorubicin against different normal and cancer cell lines. Full size table In vivo apoptosis of EAC by collagen-NPs Certain chemical drugs may not always be able to cure cancer individually within in vivo cancer studies. Consequently, combining collagen-NPs in a synergistic approach with such a chemical drug is a promising way to increase efficiency. Collagen-based nanoparticles are thermally stable, reduce drug toxicity systemically, and enhance nanoparticle uptake by cells because of their biodegradability, biocompatibility, and mild antigenicity8. To evaluate the in vivo behavior of collagen-NPs as an efficient inducer of apoptosis, the effects of collagen-NPs and collagen-NPs/doxorubicin (DOX) in a synergistic combination therapy have been studied for their impact on the growth and death of solid tumors caused by Ehrlich ascites carcinoma (EAC) (Fig. 13, Table 7). The average tumor volume in EAC mice (the control group) increased from 72.86 to 857.84 mm3 after 20 days of treatment. Comparing tumor growth in EAC-bearing mice to EAC control animals, collagen, collagen-NPs, and DOX administration significantly slowed tumor growth by 55.89%, 74.24%, and 80.88%, respectively. Additionally, the mice treated with the collagen-NPs/DOX combination treatment showed significant tumor development inhibition (by 95.01%) when compared to animals treated with the DOX and collagen-NPs separately. In comparison to EAC control mice, collagen-NPs, DOX, and collagen-NPs/DOX were observed to significantly lower the weight of tumor lumps in mice. In contrast, mice getting the combined therapy had much lighter tumor lumps (0.79\u2009\u00b1\u20090.16) than mice receiving DOX (2.3\u2009\u00b1\u20090.31) or collagen-NPs (2.01\u2009\u00b1\u20090.37) injections. Figure 13 Effect of collagen-NPs by Streptomyces plicatus strain NEAA-3 and collagen curing alone or in integration with DOX on tumor volume (A) and tumor weight of EAC bearing mice (B); images of solid tumors at the same power of magnification, zooming and distance from camera (C); histopathological analysis micrographs on tumor sections of untreated mice bearing EAC (D1), mice bearing EAC cured with collagen-NPs (D2), mice bearing EAC cured with DOX (D3) and mice bearing EAC cured with collagen-NPs integrated with DOX (D4). Full size image Table 7 Suppression effect of collagen-NPs, collagen, DOX, collagen\u2009+\u2009DOX & collage-NPs\u2009+\u2009DOX on EAC bearing mice tumor parameters. Full size table The collagen used in the research is marine collagen (type I), which is totally safe as the LD50 of hydrolyzed collagen (30% solution in water; fish scale sourced; MW\u2009~\u2009400 Da) was estimated to be greater than 2500 mg/kg body weight in Sprague\u2013Dawley CD rats99. The acute toxicity test was conducted in compliance with OECD TG 423, the Organization for Economic Co-operation and Development's test guideline. According to Liang et al.100, the chronic toxicity assessment of MCP (marine collagen peptides) up to the diet concentration of 18%, estimated to be 8.586 g/kg body weight/day for females and 6.658 g/kg body weight/day for males, showed no evidence of a substantial detrimental effect or health risk. When given orally (up to 100%), hydrolyzed collagen was mostly harmless in acute toxicity tests involving mice and rats101. The test material was administered orally to three female rats in one group at a dose level of 2000 mg/kg body weight, and to three female rats in another group who had fasted, at the same dose level. During the 14 days following the dosage, no deaths or indications of systemic toxicity were noted. Every animal showed the anticipated increases in body weight. At necropsy, there were no abnormalities found99. The anticancer activity of collagen is due to its amino acids. There are 19 amino acids (asparagine, threonine, serine, glutamic acid, alanine, valine, methionine, isoleucine, leucine, tyrosine, phenylalanine, histidine, lysine, and arginine) found in collagen, including hydroxyproline, that are unique to collagen and not found in other proteins. Its unusual amino acid makeup is distinguished by its high proline and glycine content as well as the lack of cysteine102. Glycine, lysine, and leucine are the main amino acid residues found in peptides with anticancer properties103. Hydrophobic positively charged lysine and arginine-rich peptides, for instance, function as cationic peptides and can interact with membranes through a snorkeling mechanism. This interaction can involve the selection of anionic membranes on cancer cells, the disruption of cell membrane integrity, penetration of the membrane, and possibly even a role in the toxicity of cancer cells104. Furthermore, histidine-containing peptides can cause cancer cytotoxicity through membrane permeability in acidic environments because of the protonation of histidine in acidic pH circumstances105. Remaining glutamic and aspartic acids may have anti-proliferative effects on tumor cells106. Analysis of the histopathology of a tumor section stained with hematoxylin and eosin (Fig. 13) Massive malignant cells with anaplasia, pleomorphism, nuclear dyschromasia, multiple atypical nuclei, and condensed chromosomes were shown to proliferate quickly in mice with an untreated tumor (control A). These cells are depicted by the black arrows. When animals with EAC were treated with collagen-NPs (B) or DOX (C), the tumors' growth rates were slowed down, there were more necrotic areas (areas devoid of eosinophilic structures), there were noticeably more apoptotic bodies, and there was modest inhibition (blue arrows). A significant positive synergistic effect on the histopathological pattern was seen when collagen-NPs/DOX (D) were given to animals with EAC. Proposed mode of action Either passive diffusion or non-specific permeation as a result of membrane damage caused by nanoparticles refers to the direct penetration of nanoparticles into cancer cells107. Through several mechanisms, ROS functions as a crucial signaling molecule to induce apoptosis. On one side, elevated lactate dehydrogenase (LDH) levels indicate that ROS cause cellular toxicity, such as damage to the cell membrane. Conversely, elevated ROS triggers the pro-inflammatory cytokine TNF-\u03b1, which in turn triggers p38 phosphorylation, caspase 8 and caspase 3 activation, and therefore initiates the apoptotic signaling cascade108. Other mechanisms include immunological interferences and transcription suppression. Collagen-NPs have a lethal effect on cancer cells as a result of the significant production (accumulation) of reactive oxygen species (ROS). The endoplasmic reticulum (ER), the mitochondria, and the peroxisomes are the places where ROS are produced most frequently109. Nanoparticles have been shown to interfere with the electron transport mechanism, which in turn causes an increase in the production of ROS within cells110, interference with mitochondrial function111, an increase in the ratio of NADP+ to NADPH. They also interfere with the expression of genes related to oxidative stress, such as met9, which is involved in NADPH production112, resulting in cell damage, lactate dehydrogenase (LDH) increasing and lipid peroxidation113, causing chromosome disintegration, aneuploid genic events, and DNA breaking (whether on single or double strands)114,115. Nanoparticles are particularly effective at inducing apoptosis due to their smaller size and better reactivity because of their higher surface area (Fig. 14). Therefore, the synergistic interaction between collagen-NPs and DOX might result in high amounts of (ROS) that may change the redox balance of the cell. Additionally, nanoparticles have been shown to increase protein damage, glutathione depletion, ATP depletion, and lysosome disintegration116. The majority of apoptotic effects manifest after tumor cells experience increased oxidative stress, which is followed by the release of inflammatory mediators that cause DNA and protein damage117. In response to oxidative stress, more proteins are structured to rearrange signaling and metabolic pathways. These modifications to the membrane and redox proteome alterations disturb the cycle of progress and proliferation, causing apoptosis and inhibiting malignancies118. Figure 14 Schematic diagram showing the proposed mode of action of collagen-NPs produced by Streptomyces plicatus strain NEAA-3 against cancer cell. Full size image Encapsulation efficiency and drug loading of MTX-loaded collagen-NPs Figure 15A displays the collagen-NPs that have been loaded with MTX and appear as spherical nanoparticles, as confirmed by the TEM image. The MTX-loaded collagen-NPs' diameter distribution was also examined. The histogram for the collagen-NPs that had been loaded with MTX is shown in Fig. 15B. The average size of the MTX-loaded collagen-NPs was about 35.4\u2009\u00b1\u20098.9 nm, which was larger than the previously estimated average size of collagen-NPs (33.15\u2009\u00b1\u200910.02). The encapsulation efficiency (EE) was 45.81%, and the drug loading (DL) was 22.67%. The majority of currently available nanomedicines do not have sufficient drug loading, usually less than 10%119. According to Musmade et al.120, the physicochemical characteristics of the MTX-loaded polymer (poly (D, L-lactide-coglycolide) (PLGA) nanoparticles were shown to be influenced by the drug-to-polymer ratio and stabilizer concentration. For every batch, the encapsulation efficiency percentage ranged from 8 to 16%. The difference in osmotic pressure between the two stages was the cause of the low encapsulation efficiency percentage. Figure 15 TEM image (A) of MTX loaded collagen-NPs, particles size distribution (B) and In vitro release of MTX loaded collagen-NPs (C). Full size image In vitro release of MTX-loaded collagen-NPs The results demonstrated an initial burst release of the MTX, which was followed by an extended period of continuous release, according to the results (Fig. 15C). The percentage of MTX on the initial release may have contributed to its quick release from the nanoparticles' surface. The results of the in vitro drug release experiment showed that the biosynthesized collagen-NPs will have long-term drug release control. A brief initial release of 4.23% and 20.42% at pH 7.4 and 5.5, respectively, was followed by two phases of MTX release from NPs after one hour. At pH 7.4, the release rate after 12 h was 40.43% and 74.44%, respectively, which is considered to be a little high rate at this pH. Collagen-NPs may dissolve at pH 7.4 (collagen's isoelectric point), which may be the cause of this. The adsorbed MTX on the collagen-NPs' surface appeared to have a high rate of separation from the nanoparticles into the aqueous medium during the first 24 h (the CR% were 45.24% and 83.66% at pH 7.4 and 5.5, respectively). In contrast, at 48 h, the release rate was slower (the CR% were 46.31% and 86.52% at pH 7.4 and 5.5, respectively), due to the continuous hydrolysis and degradation of the collagen-NPs carried on by the penetration of the aqueous medium121. The MTX release rate of collagen-NPs that were loaded with MTX at a pH of 5.5 showed that the rate of MTX release increased as the pH decreased, and the highest value of MTX release occurred in the first 24 h. The cause of that result might be the instability of nanoparticles, which tend to assemble at an acidic pH122. Due to the highly acidic nature of tumor surfaces, this event shows that the medication was only effective against tumor tissue. Therefore, at lower pH levels, MTX can readily be released from nanoparticles in the medium and extracellular space of tumor cells. Collagen nanoparticles can efficiently penetrate tumor microenvironments and deliver anticancer therapies because collagen can resemble these environments123. The size, surface area, and absorption capacity of collagen nanoparticles are easily configurable; because of this, collagen nanoparticles are an excellent option for strategies involving the controlled release of medication124. Antioxidant efficiency using ABTS+ radical scavenging Marine collagen is well-known for its antioxidant activity since it can shield skin cells from dangerous free radicals and oxidants that affect DNA, macromolecules, and cell membranes and speed the aging process of the skin125. The antioxidant capacities of collagen-NPs have been assessed by ABTS radical scavenging. The idea behind the ABTS approach is that antioxidants can eliminate cation colors (decolorization) by giving ABTS+ radicals a hydrogen atom. The findings showed that, in comparison to collagen, collagen-NPs have good antioxidant efficiency. The results showed that, in comparison to collagen (40.78%) and the activity of the common antioxidant ascorbic acid (89.6%), 500 \u00b5g/mL collagen-NPs demonstrated 60.39% radical scavenging effectiveness. Natural polymer collagen can be enzymatically hydrolyzed to generate collagen peptides with greater biological activity, which is crucial for preventing lipid oxidation, free radicals elimination, and maintaining the human body\u2019s free radical balance, which lowers the danger of non-communicable chronic diseases126. Conclusion In the current study, a novel and eco-friendly technique was described for the biosynthesis of collagen-NPs using Streptomyces plicatus strain NEAA-3. To the best of our knowledge, there has been no previous attempt has reported the biosynthesis of collagen-NPs using Streptomyces plicatus. All of the characterization analyses for collagen-NPs proved that the conversion of collagen to collagen-NPs by the cell-free supernatant of Streptomyces plicatus strain NEAA-3 as a bio-reductant agent is very promising. Optimization of the process variables was studied and the yield of collagen-NPs was maximized. The biosynthesized collagen-NPs using the cell-free supernatant of Streptomyces plicatus strain NEAA-3 have an average diameter of 33.15\u2009\u00b1\u200910.02 nm, making them promising for use in various pharmaceutical, and medical sectors. Moreover, both in-vitro and in-vivo investigations demonstrated the suitability of the biosynthesized collagen-NPs for a wide range of biomedical applications. Data availability All data generated or analyzed during this study are included in this article except the datasets that are available in the GenBank of The National Center for Biotechnology Information, (https://www.ncbi.nlm.nih.gov/nuccore/OR501412.1?report=GenBank). References DeFrates, K. et al. Protein polymer-based nanoparticles: fabrication and medical applications. Int. J. Mol. Sci. 19, 1717 (2018). Article   PubMed   PubMed Central   Google Scholar   Aditya, A. et al. Kinetics of collagen microneedle drug delivery system. J. Drug Deliv. Sci. Technol. 52, 618\u2013623 (2019). Article   CAS   Google Scholar   Kumar, D. A review on collagen based drug delivery systems. Int. J. Pharm. Teach. Pract. 4, 811\u2013820 (2013). Google Scholar   Xu, S. The role of collagen in cancer: From bench to bedside. J. Transl. Med. 17, 1\u201322 (2019). Article   Google Scholar   Lee, J. H. Injectable hydrogels delivering therapeutic agents for disease treatment and tissue engineering. Biomater. Res. 22, 1\u201314 (2018). Article   PubMed   PubMed Central   Google Scholar   Shekhter, A. B. et al. Medical applications of collagen and collagen-based materials. Curr. Med. Chem. 26, 506\u2013516 (2019). Article   CAS   PubMed   Google Scholar   Alarcon, E. I. et al. The biocompatibility and antibacterial properties of collagen-stabilized, photochemically prepared silver nanoparticles. Biomater 33, 4947\u20134956 (2012). Article   CAS   Google Scholar   Arun, A. et al. Collagen nanoparticles in drug delivery systems and tissue engineering. Appl. Sci. 11, 11369 (2021). Article   CAS   Google Scholar   Przybyla, D. E. & Chmielewski, J. Metal-triggered collagen peptide disk formation. J. Am. Chem. Soc. 132, 7866\u20137867 (2010). Article   CAS   PubMed   Google Scholar   Jiang, H., Liang, G. & Dai, M. Preparation of doxorubicin-loaded collagen-PAPBA nanoparticles and their anticancer efficacy in ovarian cancer. Ann. Transl. Med. 8, 880 (2020). Article   PubMed   PubMed Central   Google Scholar   Luo, T., He, L., Theato, P. & Kiick, K. L. Thermoresponsive self-assembly of nanostructures from a collagen-like peptide-containing diblock copolymer. Macromol. Biosci. 15, 111\u2013123 (2015). Article   CAS   PubMed   Google Scholar   El-Naggar, N. E. A., Abdelwahed, N. A. & Darwesh, O. M. Fabrication of biogenic antimicrobial silver nanoparticles by Streptomyces aegyptia NEAE 102 as eco-friendly nanofactory. J. Microbiol. Biotechnol. 24(4), 453\u2013464 (2014). Article   CAS   PubMed   Google Scholar   El-Naggar, N. E. A. & Abdelwahed, N. A. Application of statistical experimental design for optimization of silver nanoparticles biosynthesis by a nanofactory Streptomyces viridochromogenes. J. Microbiol. 52(1), 53\u201363 (2014). Article   CAS   PubMed   Google Scholar   Mohamedin, A., El-Naggar, N. E., Shawqi Hamza, S. & Sherief, A. A. Green synthesis, characterization and antimicrobial activities of silver nanoparticles by Streptomyces viridodiastaticus SSHH-1 as a living nanofactory: Statistical optimization of process variables. Curr. Nanosci. 11(5), 640\u2013654 (2015). Article   ADS   CAS   Google Scholar   El-Naggar, N. E., Mohamedin, A., Hamza, S. S. & Sherief, A.-D. Extracellular biofabrication, characterization, and antimicrobial efficacy of silver nanoparticles loaded on cotton fabrics using newly isolated Streptomyces sp. SSHH-1E. J. Nanomater. (2016). El-Naggar, N. E. A., Saber, W. I., Zweil, A. M. & Bashir, S. I. An innovative green synthesis approach of chitosan nanoparticles and their inhibitory activity against phytopathogenic Botrytis cinerea on strawberry leaves. Sci. Rep. 12(1), 1\u201320 (2022). Article   Google Scholar   El-Naggar, N. E. A. et al. (2023) Green fabrication of chitosan nanoparticles using Lavendula angustifolia, optimization, characterization and in-vitro antibiofilm activity. Sci Rep 13, 11127 (2023). Article   ADS   CAS   PubMed   PubMed Central   Google Scholar   El-Naggar, N. E. A. et al. Artificial intelligence-based optimization for chitosan nanoparticles biosynthesis, characterization and in-vitro assessment of its anti-biofilm potentiality. Sci Rep 13, 4401 (2023). Article   ADS   CAS   PubMed   PubMed Central   Google Scholar   El-Naggar, N. E., Hussein, M. H. & El-Sawah, A. A. Phycobiliprotein-mediated synthesis of biogenic silver nanoparticles, characterization, in vitro and in vivo assessment of anticancer activities. Sci. Rep. 8(1), 1\u201320 (2018). Article   Google Scholar   El-Naggar, N. E., Hussein, M. H. & El-Sawah, A. A. Bio-fabrication of silver nanoparticles by phycocyanin, characterization, in vitro anticancer activity against breast cancer cell line and in vivo cytotxicity. Sci. Rep. 7(1), 1\u201320 (2017). Article   CAS   Google Scholar   El-Naggar, N.E.-A., Hussein, M. H., Shaaban-Dessuuki, S. A. & Dalal, S. R. Production, extraction and characterization of Chlorella vulgaris soluble polysaccharides and their applications in AgNPs biosynthesis and biostimulation of plant growth. Sci. Rep. 10, 1\u201319 (2020). Article   Google Scholar   Bhainsa, K. C. & D\u2019souza, S. F. Extracellular biosynthesis of silver nanoparticles using the fungus Aspergillus fumigatus. Colloids Surf. B 47(2), 160\u2013164 (2006). Article   CAS   Google Scholar   El-Naggar, N. E. A. et al. Artificial neural network approach for prediction of AuNPs biosynthesis by Streptomyces flavolimosus, characterization, antitumor potency in-vitro and in-vivo against Ehrlich ascites carcinoma. Sci. Rep. 13(1), 12686 (2023). Article   ADS   CAS   PubMed   PubMed Central   Google Scholar   El-Naggar, N.E.A. Chapter 11\u2014Streptomyces-based cell factories for production of biomolecules and bioactive metabolites, 183\u2013234 (Academic Press, 2021). El-Naggar, N. E. & Abdelwahed, N. A. Optimization of process parameters for the production of alkali-tolerant carboxymethyl cellulase by newly isolated Streptomyces sp. strain NEAE-D. Afr. J. Biotechnol. 11(5), 1185\u20131196 (2012). CAS   Google Scholar   El-Naggar, N. E. Isolation, screening and identification of actinobacteria with uricase activity: Statistical optimization of fermentation conditions for improved production of uricase by Streptomyces rochei NEAE\u201325. Int. J. Pharmacol. 11, 644\u2013658 (2015). Article   CAS   Google Scholar   El-Naggar, N. E. & Hamouda, R. Antimicrobial potentialities of Streptomyces lienomycini NEAE-31 against human pathogen multidrug-resistant Pseudomonas aeruginosa. Int. J. Pharmacol. 12(8), 769\u2013788 (2016). Article   CAS   Google Scholar   Shirling, E. & Gottlieb, D. Methods for characterization of Streptomyces species. Int. J. Syst. Evol. Microbiol. 16, 313\u2013340 (1966). Google Scholar   El-Naggar, N. E., Abdelwahed, N. A., Saber, W. I. & Mohamed, A. A. Bioprocessing of some agro-industrial residues for endoglucanase production by the new subsp.; Streptomyces albogriseolus subsp. cellulolyticus strain NEAE-J. Braz. J. Microbiol. 45, 743\u2013751 (2014). Article   CAS   PubMed   PubMed Central   Google Scholar   Sambrook, J., Fritsch, E. F. & Maniatis, T. Molecular cloning (Cold Spring Harbor Laboratory Press, New York, 1989). Google Scholar   El-Naggar, N. E. A., Sherief, A. & Hamza, S. S. Streptomyces aegyptia NEAE 102, a novel cellulolytic streptomycete isolated from soil in Egypt. Afr. J. Microbiol. Res. 5, 5308\u20135315 (2011). Google Scholar   Altschul, S. F. et al. Gapped BLAST and PSI-BLAST: A new generation of protein database search programs. Nucleic Acids Res. 17, 3389\u20133402 (1997). Article   Google Scholar   Saitou, N. & Nei, M. The neighbor-joining method: A new method for reconstructing phylogenetic trees. Mol. Biol. Evol. 4, 406\u2013425 (1987). CAS   PubMed   Google Scholar   Mosmann, T. Rapid colorimetric assay for cellular growth and survival: application to proliferation and cytotoxicity assays. J. Immunol. Methods 65, 55\u201363 (1983). Article   CAS   PubMed   Google Scholar   Ozaslan, M. et al. Ehrlich ascites carcinoma. Afr. J. Biotechnol. 10, 2375\u20132378 (2011). Google Scholar   El-Naggar, N. E. A., Soliman, H. M. & El-Shweihy, N. M. Extracellular cholesterol oxidase production by Streptomyces aegyptia, in vitro anticancer activities against rhabdomyosarcoma, breast cancer cell-lines and in vivo apoptosis. Sci. Rep. 8, 2706 (2018). Article   ADS   PubMed   PubMed Central   Google Scholar   Elsherbiny, N. M. et al. The synergistic effect between vanillin and doxorubicin in ehrlich ascites carcinoma solid tumor and MCF-7 human breast cancer cell line. Pathol. Res. Pract. 212, 767\u2013777 (2016). Article   CAS   PubMed   Google Scholar   Eisa, N. H. et al. Phenethyl isothiocyanate potentiates anti-tumour effect of doxorubicin through Akt-dependent pathway. Cell Biochem. Funct. 33, 541\u2013551 (2015). Article   PubMed   Google Scholar   Singha, H. A., Sengupta, M. & Bawari, M. Neurobehavioral responses in swiss albino mice induced by an aqueous leaf extract from a medicinal plant named Heliotropium incanum Ruiz & Pav. Bioinformation 16, 679\u2013687 (2020). Article   PubMed   PubMed Central   Google Scholar   Sullivan, P. M. et al. Solid tumor microenvironment can harbor and support functional properties of memory T cells. Front. Immunol. 12, 706150 (2021). Article   CAS   PubMed   PubMed Central   Google Scholar   Schirner, M., Hofmann, J., Menrad, A. & Schneider, M. R. Antiangiogenic chemotherapeutic agents: Characterization in comparison to their tumor growth inhibition in human renal cell carcinoma models. Clin. Cancer Res. 4, 1331\u20131336 (1998). CAS   PubMed   Google Scholar   Zhao, X. Q. et al. Streptomyces xinghaiensis sp. Nov., isolated from marine sediment. Int. J. Syst. Evol. Microbiol. 59, 2870\u20132874 (2009). Article   CAS   PubMed   Google Scholar   Goodfellow, M. et al. Bergey\u2019s manual of systematic bacteriology Vol. 5 (Springer, New York, 2012). Book   Google Scholar   Shoge, M. & Amusan, T. Phytochemical, antidiarrhoeal activity, isolation and characterisation of 11-octadecenoic acid, methyl ester isolated from the seeds of Acacia nilotica Linn. J. Biotechnol. https://doi.org/10.5281/zenodo.3669434 (2020). Fratianni, F. et al. Fatty acid composition, antioxidant, and in vitro anti-inflammatory activity of five cold-pressed prunus seed oils, and their anti-biofilm effect against pathogenic bacteria. Front. Nutr. 8, 775751 (2021). Article   PubMed   PubMed Central   Google Scholar   Belwal, T. et al. Naturally occurring chemicals against Alzheimer\u2019s disease. AP https://doi.org/10.1016/B978-0-12-819212-2.20001-7 (2021). Article   Google Scholar   Narang, D. et al. Effect of dietary palm olein oil on oxidative stress associated with ischemicreperfusion injury in isolated rat heart. BMC Pharmacol. 4, 29. https://doi.org/10.1186/1471-2210-4-29 (2004). Article   CAS   PubMed   PubMed Central   Google Scholar   Kulkarn,. Methane sulphonic acid is green catalyst in organic synthesis. Orient. J. Chem. 31, 447\u2013451 (2015). Article   Google Scholar   Singh, A. N. & Yethiraj, A. Liquid\u2013liquid phase separation as the second step of complex coacervation. J. Phys. Chem. B 125, 3023\u20133031 (2021). Article   CAS   PubMed   Google Scholar   Nagaraja, U. et al. Fabrication of solid collagen nanoparticles using electrospray deposition. Chem. Pharm. Bull. 62, 422\u2013428 (2014). Article   Google Scholar   Cinar, S., G\u00fcnd\u00fcl, G., Mavis, B. & Colak, U. Synthesis of silver nanoparticles by oleylamine-oleic acid reduction and its use in making nanocable by coaxial electrospinning. J. Nanosci. Nanotechnol. 11, 3669\u20133679 (2011). Article   CAS   PubMed   Google Scholar   Gupta, R. et al. Effect of oleic acid coating of iron oxide nanoparticles on properties of magnetic polyamide-6 nanocomposite. JOM 71, 3119\u20133128 (2019). Article   CAS   Google Scholar   Xia, Y., Xie, M., Lyu, Z. & Chen, R. Mechanistic study of the multiple roles of oleic acid in the oil phase synthesis of Pt nanocrystals. Chem. Eur. J. https://doi.org/10.1002/chem.202003202 (2020). Article   PubMed   Google Scholar   Mourdikoudis, S. et al. Oleic acid/oleylamine ligand pair: A versatile combination in the synthesis of colloidal nanoparticles. Nanoscale Horiz 7, 941\u20131015 (2022). Article   ADS   CAS   PubMed   Google Scholar   Agrawal, N., Munjal, S., Ansari, M. Z. & Khare, N. Superhydrophobic palmitic acid modified ZnO nanoparticles. Ceram Int. https://doi.org/10.1016/j.ceramint.2017.07.176 (2017). Article   Google Scholar   Saallah, S. et al. Comparative study of the yield and physicochemical properties of collagen from sea cucumber (Holothuria scabra), obtained through dialysis and the ultrafiltration membrane. Mol 26, 2564 (2021). Article   CAS   Google Scholar   Yan, M. et al. Characterization of acid-soluble collagen from the skin of walleye pollock (Theragra chalcogramma). Food Chem. 107, 1581\u20131586 (2008). Article   CAS   Google Scholar   Adibzadeh, N. et al. Purification and characterization of pepsin-solubilized collagen from skin of sea cucumber Holothuria parva. Appl. Biochem. Biotechnol. 173, 143\u2013154 (2014). Article   CAS   PubMed   Google Scholar   Naskar, A. & Kim, K. S. Recent advances in nanomaterial-based wound-healing therapeutics. Pharmaceutics 12, 499 (2020). Article   CAS   PubMed   PubMed Central   Google Scholar   Kong, J. & Yu, S. Fourier transform infrared spectroscopic analysis of protein secondary structures. Acta Biochim. Biophys. Sin. 39, 549\u2013559 (2007). Article   CAS   PubMed   Google Scholar   Pati, F., Adhikari, B. & Dhara, S. Isolation and characterization of fish scale collagen of higher thermal stability. Bioresour. Technol. 101, 3737\u20133742 (2010). Article   CAS   PubMed   Google Scholar   Movasaghi, Z., Rehman, S. & Rehman, I. Fourier transform Infrared (FTIR) spectroscopy of biological tissues. Appl. Spect. Rev. 43, 134\u2013179 (2008). Article   ADS   CAS   Google Scholar   Haris, P. I. & Severcan, F. FTIR spectroscopic characterization of protein structure in aqueous and non-aqueous media. J. Mol. Catal. B-Enzym. 7, 207\u2013221 (1999). Article   CAS   Google Scholar   Lambert, J. B. introduction to organic spectroscopy (Macmillan Publ, 1987). Google Scholar   Faralizadeh, S. et al. Extraction, characterization and biocompatibility evaluation of collagen from silver carp (Hypophthalmichthys molitrix) skin by-product. Sustain. Chem. Pharm. 22, 100454 (2021). Article   CAS   Google Scholar   Liu, A. et al. Characterization of acid- and pepsin-soluble collagens from the cuticle of Perinereis nuntia (Savigny). Food Biophys. 13, 274\u2013283 (2018). Article   Google Scholar   Cameron, G. J., Cairns, D. E. & Wess, T. J. The variability in type I collagen helical pitch is reflected in the D periodic fibrillar structure. J. Mol. Biol. 372, 1097\u20131107 (2007). Article   CAS   PubMed   Google Scholar   Sharma, D. et al. Formulation and optimization of polymeric nanoparticles for intranasal delivery of lorazepam using Box-Behnken design: In vitro and in vivo evaluation. Biomed. Res. Int. 2014, 156010 (2014). Article   PubMed   PubMed Central   Google Scholar   Khan, I., Saeed, K. & Khan, I. Nanoparticles: Properties, applications and toxicities. Arab. J. Chem. 12, 908\u2013931 (2019). Article   CAS   Google Scholar   El-Sawah, A. A., El-Naggar, N. E., Eldegla, H. E. & Soliman, H. M. Green synthesis of collagen nanoparticles by Streptomyces xinghaiensis NEAA-1, statistical optimization, characterization, and evaluation of their anticancer potential. Sci. Rep. 14, 3283 (2024). Article   CAS   PubMed   PubMed Central   Google Scholar   Charles, J. et al. FTIR and thermal studies on nylon-66 and 30% glass fibre reinforced nylon-66. E-J. Chem. 6, 23\u201333 (2009). Article   CAS   Google Scholar   Ebnesajjad, S. 4 - Surface and material characterization techniques. Surf. Treat. Mater. Adhesion Bond. 2006, 43\u201375 (2006). Article   Google Scholar   Lohrasbi, S. et al. Collagen/cellulose nanofiber hydrogel scaffold: physical, mechanical and cell biocompatibility properties. Cellulose 27, 927\u2013940 (2020). Article   CAS   Google Scholar   Tampieri, A. et al. Biologically inspired synthesis of bone-like composite: Self-assembled collagen fibers/hydroxyapatite nanocrystals. J. Biomed. Mater. Res. A 67, 618\u2013625 (2003). Article   PubMed   Google Scholar   Batista, M. P. et al. Extraction of biocompatible collagen from blue shark skins through the conventional extraction process intensification using natural deep eutectic solvents. Front. Chem. 10, 937036 (2022). Article   ADS   CAS   PubMed   PubMed Central   Google Scholar   Protasevich, I. et al. Conformation and thermal denaturation of apocalmodulin: Role of electrostatic mutations. Biochemistry 36, 2017\u20132024 (1997). Article   CAS   PubMed   Google Scholar   Jaziri, A. A. et al. Biochemical analysis of collagens from the bone of lizardfish (Saurida tumbil Bloch, 1795) extracted with different acids. Peer J 10, e13103 (2022). Article   PubMed   PubMed Central   Google Scholar   El-Naggar, N. E. A. et al. Saber, Innovative low-cost biosorption process of Cr6+ by Pseudomonas alcaliphila NEWG-2. Sci. Rep. 10, 1\u201318 (2020). Article   Google Scholar   El-Naggar, N. E. A., El-Shweihy, N. M. & El-Ewasy, S. M. Identification and statistical optimization of fermentation conditions for a newly isolated extracellular cholesterol oxidase-producing Streptomyces cavourensis strain NEAE-42. BioMed Central Microbiol. 16, 1\u201320 (2016). Google Scholar   El-Naggar, N. E. A., Hamouda, R. A., Saddiq, A. A. & Alkinani, M. H. Simultaneous bioremediation of cationic copper ions and anionic methyl orange azo dye by brown marine alga Fucus vesiculosus. Sci Rep 11, 1\u201319 (2021). Article   Google Scholar   El-Naggar, N. E. A. & El-Shweihy, N. M. Bioprocess development for L-asparaginase production by Streptomyces rochei, purification and in-vitro efficacy against various human carcinoma cell lines. Sci Rep 10, 1\u201321 (2020). Article   Google Scholar   Hamouda, R. A., El-Naggar, N. E., Doleib, N. M., & Saddiq, A. A. Bioprocessing strategies for cost-effective simultaneous removal of chromium and malachite green by marine alga Enteromorpha intestinalis. Sci. Rep. 10(1), 13479 (2020). Article   ADS   CAS   PubMed   PubMed Central   Google Scholar   El-Naggar, N. E. A., Hamouda, R. A., El-Khateeb, A. Y. & Rabei, N. H. Biosorption of cationic Hg2+ and Remazol brilliant blue anionic dye from binary solution using Gelidium corneum biomass. Sci Rep 11, 1\u201324 (2021). Google Scholar   Samuel, E.A. & Oladipupo, O.O. Factorial designs application to study enhanced bioremediation of soil artificially contaminated with weathered bonny light crude oil through biostimulation and bioaugmentation strategy. JEP 3, (2012). Ibrahim, A. M. et al. Bioprocess development for enhanced endoglucanase production by newly isolated bacteria, purification, characterization and in-vitro efficacy as anti-biofilm of Pseudomonas aeruginosa. Sci Rep 11, 9754 (2021). Article   CAS   PubMed   PubMed Central   Google Scholar   El-Naggar, N. E. A., Moawad, H. & Abdelwahed, N. A. Optimization of fermentation conditions for enhancing extracellular production of L-asparaginase, an anti-leukemic agent, by newly isolated Streptomyces brollosae NEAE-115 using solid state fermentation. Ann. Microbiol. 67, 1\u201315 (2017). Article   Google Scholar   Ghoniem, A. A. et al. Statistical modeling-approach for optimization of Cu2+ biosorption by Azotobacter nigricans NEWG-1; characterization and application of immobilized cells for metal removal. Sci. Rep. 10, 9491 (2020). Article   ADS   CAS   PubMed   PubMed Central   Google Scholar   El-Naggar, N. E. A. et al. Process development for scale-up production of a therapeutic L-asparaginase by Streptomyces brollosae NEAE-115 from shake flasks to bioreactor. Sci. Rep. 9, 1357133 (2019). Article   Google Scholar   El-Naggar, N. E. A. et al. Mathematical modeling for bioprocess optimization of a protein drug, uricase, production by Aspergillus welwitschiae strain 1\u20134. Sci. Rep. 9, 1\u201315 (2019). Article   Google Scholar   Yan, M., Li, B., Zhao, X. & Qin, S. Effect of concentration, pH and ionic strength on the kinetic self-assembly of acid-soluble collagen from walleye pollock (Theragra chalcogramma) skin. Food Hydrocoll. 29, 199\u2013204 (2012). Article   CAS   Google Scholar   Li, Y., Asadi, A., Monroe, M. R. & Douglas, E. P. PH effects on collagen fibrillogenesis in vitro: electrostatic interactions and phosphate binding. Mat. Sci. Eng. C 29, 1643\u20131649 (2009). Article   CAS   Google Scholar   Song X, Wang Z, Tao S et al. Observing effects of calcium/magnesium ions and pH value on the self-assembly of extracted swine tendon collagen by atomic force microscopy. J. Food. Sci. (2017) 8 Marelli, B. et al. Fibril formation pH controls intrafibrillar collagen biomineralization in vitro and in vivo. Biomater 37, 252\u2013259 (2015). Article   CAS   Google Scholar   Katt, M. E. et al. In vitro tumor models: advantages, disadvantages, variables, and selecting the right platform. Front. Bioeng. Biotechnol. 12, 4\u201312 (2016). Google Scholar   Meerloo, J. V., Kaspers, G. J. & Cloos, J. Cell sensitivity assays: the MTT assay. Methods Mol. Biol. 731, 237\u2013245 (2011). Article   PubMed   Google Scholar   Han, S. H. et al. Effect of collagen and collagen peptides from Bluefin tuna abdominal skin on cancer cells. Health 3, 129 (2011). Article   CAS   Google Scholar   Brown, D. M. et al. Size-dependent proinflammatory effects of ultrafine polystyrene particles: a role for surface area and oxidative stress in the enhanced activity of ultrafnes. Toxicol. Appl. Pharmacol. 175(3), 191\u2013199 (2001). Article   CAS   PubMed   Google Scholar   Li, Y. et al. Size-dependent cytotoxicity of amorphous silica nanoparticles in human hepatoma HepG2 cells. Toxicol. in Vitro 25(7), 1343\u20131352 (2011). Article   CAS   PubMed   Google Scholar   Burnett, C. L. et al. Safety assessment of skin and connective tissue-derived proteins and peptides as used in cosmetics. Int. J. Toxicol. 41, 21S-42S (2022). Article   CAS   PubMed   Google Scholar   Liang, J. et al. A chronic oral toxicity study of marine collagen peptides preparation from chum salmon (Oncorhynchus keta) skin using Sprague-Dawley rat. Mar. Drugs 10, 20\u201334 (2012). Article   CAS   PubMed   Google Scholar   Elder, R. L. Final report on the safety assessment of hydrolyzed collagen. JACT 4, 199\u2013221 (1985). Google Scholar   Gauza-W\u0142odarczyk, M., Kubisz, L. & W\u0142odarczyk, D. Amino acid composition in determination of collagen origin and assessment of physical factors effects. Int. J. Biol. Macromol. 104, 987\u2013991 (2017). Article   PubMed   Google Scholar   Shoombuatong, W., Schaduangrat, N. & Nantasenamat, C. Unraveling the bioactivity of anticancer peptides as deduced from machine learning. Excli. J. 17, 734\u2013752 (2018). PubMed   PubMed Central   Google Scholar   Dai, Y. X. et al. Pro-apoptotic cationic host defense peptides rich in lysine or arginine to reverse drug resistance by disrupting tumor cell membrane. Amino Acids 49, 1601\u20131610 (2017). Article   CAS   PubMed   Google Scholar   Navarro, S. et al. The cytotoxicity of eosinophil cationic protein/ribonuclease 3 on eukaryotic cell lines takes place through its aggregation on the cell membrane. Cell Mol. Life Sci. 65, 324\u2013337 (2008). Article   CAS   PubMed   Google Scholar   Yamaguchi, Y. et al. Combination of aspartic acid and glutamic acid inhibits tumor cell proliferation. Biomed. Res. 37, 153\u2013159 (2016). Article   CAS   PubMed   Google Scholar   Bartlomiejczyk, T., Lankoff, A., Kruszewski, M. & Szumiel, I. Silver nanoparticles-allies or adversaries?. Ann. Agr. Environ. Med. 20, 48\u201354 (2013). CAS   Google Scholar   Ma, D. D. & Yang, W. X. Engineered nanoparticles induce cell apoptosis: potential for cancer therapy. Oncotarget. 7(26), 40882\u201340903 (2016). Article   PubMed   PubMed Central   Google Scholar   Murphy, M. P. How mitochondria produce reactive oxygen species. Biochem. J. 417, 1\u201313 (2009). Article   CAS   PubMed   Google Scholar   Wang, G. et al. Antibacterial effects of titanium embedded with silver nanoparticles based on electron-transfer-induced reactive oxygen species. Biomater 124, 25\u201334 (2017). Article   CAS   Google Scholar   AshaRani, P. V. et al. Cytotoxicity and genotoxicity of silver nanoparticles in human cells. ACS Nano. 24, 279\u2013290 (2009). Article   Google Scholar   Zhang, Y. et al. Nano-metal oxides induce antimicrobial resistance via radical-mediated mutagenesis. Environ. Int. 121, 1162\u20131171 (2018). Article   CAS   PubMed   Google Scholar   Gu, L. et al. Comparison of nanosilver removal by flocculent and granular sludge and short- and long-term inhibition impacts. Water Res. 58, 62\u201370 (2014). Article   CAS   PubMed   Google Scholar   Kang, S. J., Kim, B. M., Lee, Y. J. & Chung, H. W. Titanium dioxide nanoparticles trigger p53-mediated damage response in peripheral blood lymphocytes. Environ. Mol. Mutagen 49, 399\u2013405 (2008). Article   CAS   PubMed   Google Scholar   Di Bucchianico, S. et al. Aneuploidogenic effects and DNA oxidation induced in vitro by differently sized gold nanoparticles. Int. J. Nanomed. 9, 2191\u20132204 (2014). Article   Google Scholar   Canesi, L. et al. Bivalve molluscs as a unique target group for nanoparticle toxicity. Mar. Environ. Res. 76, 6\u201321 (2012). Article   Google Scholar   Raj, S. et al. Specific targeting cancer cells with nanoparticles and drug delivery in cancer therapy. Semin. Cancer Biol. 69, 166\u2013177 (2021). Article   CAS   PubMed   Google Scholar   L\u00f3pez Grueso, M. J. et al. Peroxiredoxin 6 down-regulation induces metabolic remodeling and cell cycle arrest in HepG2 cells. Antioxidants 8, 505 (2019). Article   PubMed   PubMed Central   Google Scholar   Shen, S., Wu, Y., Liu, Y. & Wu, D. High drug-loading nanomedicines: Progress, current status, and prospects. Int. J. Nanomed. 12, 4085\u20134109 (2017). Article   CAS   Google Scholar   Musmade, K. P. et al. Methotrexate-loaded biodegradable nanoparticles: Preparation, characterization and evaluation of its cytotoxic potential against U-343 MGa human neuronal glioblastoma cells. Bull. Mater. Sci. 37, 945\u2013951 (2014). Article   CAS   Google Scholar   Maleki, H. et al. Methotrexate-loaded PLGA nanopartcles: preparaton, characterizaton and their cytotoxicity effect on human glioblastoma U87MG cells. Int. J. Med. Nano Res. 4, 020 (2017). CAS   Google Scholar   Du, S. et al. Aggregation and adhesion of gold nanoparticles in phosphate bufered saline. J. Nanopart. Res. 14, 758 (2012). Article   ADS   Google Scholar   Le, V.-M. et al. A collagen-based multicellular tumor spheroid model for evaluation of the efficiency of nanoparticle drug delivery. Artif. Cells Nanomed. Biotechnol. 44, 540\u2013544 (2016). Article   CAS   PubMed   Google Scholar   Nitta, S. K. & Numata, K. Biopolymer-based nanoparticles for drug/gene delivery and tissue engineering. Int. J. Mol. Sci. 14, 1629\u20131654 (2013). Article   CAS   PubMed   PubMed Central   Google Scholar   Carvalho, D. N., In\u00e1cio, A. R. & Sousa, R. O. et al. Seaweed polysaccharides as sustainable building blocks for biomaterials in tissue engineering in sustainable seaweed technologies. Elsevier 543\u2013587 (2020b). Jideani, A. I. O. Antioxidant-rich natural fruit and vegetable products and human health. Int. J. Food Prop. 24, 41\u201367 (2021). Article   CAS   Google Scholar   Download references Acknowledgements The authors gratefully acknowledge the City of Scientific Research and Technological Applications (SRTA-City), Alexandria, 21934, Egypt, for providing financial support for most laboratory measurements and analyzes of this paper within the framework of SRTA-City Central Laboratories Services. Funding Open access funding provided by The Science, Technology & Innovation Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank (EKB). Author information Authors and Affiliations Botany Department, Faculty of Science, Mansoura University, Mansoura, Egypt Asmaa A. El-Sawah & Hoda M. Soliman Department of Bioprocess Development, Genetic Engineering and Biotechnology Research Institute, City of Scientific Research and Technological Applications (SRTA-City), New Borg El-Arab City, 21934, Alexandria, Egypt Noura El-Ahmady El-Naggar Medical Microbiology and Immunology Department, Faculty of Medicine, Mansoura University, Mansoura, Egypt Heba E. Eldegla Contributions A.A.E. performed the experiments, collected the data, analyzed and discussed the results, writing of the manuscript, rephrasing and revised the manuscript. N.E.E. proposed the research topic, designed the research plan, provided necessary tools for the experiments and experimental instructions, performed the statistical analysis, rephrasing and critically revised the manuscript. H.E.D. and H.M.S. contributed to the revision of the manuscript. All authors read and approved the final manuscript. Corresponding authors Correspondence to Asmaa A. El-Sawah or Noura El-Ahmady El-Naggar. Ethics declarations Competing interests The authors declare no competing interests. Additional information Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Rights and permissions Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. Reprints and permissions About this article Cite this article El-Sawah, A.A., El-Naggar, N.EA., Eldegla, H.E. et al. Bionanofactory for green synthesis of collagen nanoparticles, characterization, optimization, in-vitro and in-vivo anticancer activities. Sci Rep 14, 6328 (2024). https://doi.org/10.1038/s41598-024-56064-8 Download citation Received 31 October 2023 Accepted 01 March 2024 Published 15 March 2024 DOI https://doi.org/10.1038/s41598-024-56064-8 Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Keywords Collagen nanoparticles Biosynthesis Streptomyces plicatus Characterization Optimization FCCD Antioxidant Anticancer Drug loading Subjects Applied microbiology Nanoparticles Comments By submitting a comment you agree to abide by our Terms and Community Guidelines. If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate. Download PDF Sections Figures References Abstract Introduction Materials and methods Result and discussion Conclusion Data availability References Acknowledgements Funding Author information Ethics declarations Additional information Rights and permissions About this article Comments Advertisement Scientific Reports (Sci Rep) ISSN 2045-2322 (online) About Nature Portfolio About us Press releases Press office Contact us Discover content Journals A-Z Articles by subject Protocol Exchange Nature Index Publishing policies Nature portfolio policies Open access Author & Researcher services Reprints & permissions Research data Language editing Scientific editing Nature Masterclasses Research Solutions Libraries & institutions Librarian service & tools Librarian portal Open research Recommend to library Advertising & partnerships Advertising Partnerships & Services Media kits Branded content Professional development Nature Careers Nature Conferences Regional websites Nature Africa Nature China Nature India Nature Italy Nature Japan Nature Korea Nature Middle East Privacy Policy Use of cookies Your privacy choices/Manage cookies Legal notice Accessibility statement Terms & Conditions Your US state privacy rights \u00a9 2024 Springer Nature Limited",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "Data-driven prediction of colonization outcomes for complex microbial communities",
    "doi": "10.1038/s41467-024-46766-y",
    "description": "Microbial interactions can lead to different colonization outcomes of exogenous species, be they pathogenic or beneficial in nature. Predicting the colonization of exogenous species in complex communities remains a fundamental challenge in microbial ecology, mainly due to our limited knowledge of the diverse mechanisms governing microbial dynamics. Here, we propose a data-driven approach independent of any dynamics model to predict colonization outcomes of exogenous species from the baseline compositions of microbial communities. We systematically validate this approach using synthetic data, finding that machine learning models can predict not only the binary colonization outcome but also the post-invasion steady-state abundance of the invading species. Then we conduct colonization experiments for commensal gut bacteria species Enterococcus faecium and Akkermansia muciniphila in hundreds of human stool-derived in vitro microbial communities, confirming that the data-driven approaches can predict the colonization outcomes in experiments. Furthermore, we find that while most resident species are predicted to have a weak negative impact on the colonization of exogenous species, strongly interacting species could significantly alter the colonization outcomes, e.g., Enterococcus faecalis inhibits the invasion of E. faecium invasion. The presented results suggest that the data-driven approaches are powerful tools to inform the ecology and management of microbial communities.",
    "journal": "Nature Communications",
    "authors": [
      "Wu L.",
      "Wang X.W.",
      "Tao Z.",
      "Wang T.",
      "Zuo W.",
      "Zeng Y.",
      "Liu Y.Y.",
      "Dai L."
    ],
    "citation_count": "0",
    "full_text": "Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Advertisement View all journals Search Log in Explore content About the journal Publish with us Sign up for alerts RSS feed nature nature communications articles article Article Open access Published: 16 March 2024 Data-driven prediction of colonization outcomes for complex microbial communities Lu Wu , Xu-Wen Wang , Zining Tao, Tong Wang , Wenlong Zuo , Yu Zeng, Yang-Yu Liu & Lei Dai   Nature Communications  15, Article number: 2406 (2024) Cite this article 2818 Accesses 21 Altmetric Metrics Abstract Microbial interactions can lead to different colonization outcomes of exogenous species, be they pathogenic or beneficial in nature. Predicting the colonization of exogenous species in complex communities remains a fundamental challenge in microbial ecology, mainly due to our limited knowledge of the diverse mechanisms governing microbial dynamics. Here, we propose a data-driven approach independent of any dynamics model to predict colonization outcomes of exogenous species from the baseline compositions of microbial communities. We systematically validate this approach using synthetic data, finding that machine learning models can predict not only the binary colonization outcome but also the post-invasion steady-state abundance of the invading species. Then we conduct colonization experiments for commensal gut bacteria species Enterococcus faecium and Akkermansia muciniphila in hundreds of human stool-derived in vitro microbial communities, confirming that the data-driven approaches can predict the colonization outcomes in experiments. Furthermore, we find that while most resident species are predicted to have a weak negative impact on the colonization of exogenous species, strongly interacting species could significantly alter the colonization outcomes, e.g., Enterococcus faecalis inhibits the invasion of E. faecium invasion. The presented results suggest that the data-driven approaches are powerful tools to inform the ecology and management of microbial communities. Similar content being viewed by others Nutritional and host environments determine community ecology and keystone species in a synthetic gut bacterial community Article Open access 08 August 2023 Top-down identification of keystone taxa in the microbiome Article Open access 04 July 2023 Ecology-guided prediction of cross-feeding interactions in the human gut microbiome Article Open access 26 February 2021 Introduction Microbial communities are constantly exposed to the invasion of exogenous species, which can significantly alter their composition and function1,2,3,4. The capacity of a microbial community to resist invasion is regarded as an emergent property (i.e., from individual parts to a holistic function) arising from the complex interactions among its constituent species5. Theoretical studies have found that communities with higher diversity or stronger interaction strengths among species are more resistant to potential invaders6,7,8, attributed to the fact that communities with higher diversity can occupy more niches and provide functional redundancy, making it more difficult for an invading species to establish and thrive. The role of host-associated microbiota in defending against pathogens has been extensively studied9,10,11,12, particularly in the context of the human gut microbiome. For the human gut microbiome, invasion of resident microbial communities can occur when non-resident bacteria from foods and the upper gastrointestinal tract reach the gut ecosystem13,14. The resident microbes in the gut ecosystem outcompete and exclude invaders through a combination of mechanisms, such as producing antimicrobial compounds15,16, competing for nutrients and space17,18,19,20, and modulating the host\u2019s immune response21,22. However, the composition of the human gut microbiota can vary significantly across individuals23,24 and over time25,26. Dietary shifts, medication, and other environmental factors can greatly alter the composition of the gut microbial community27,28. These interpersonal and dynamic variations in the gut microbiome can lead to significantly different colonization outcomes, such as resistance to pathogens29,30 and probiotics31,32. For example, antibiotics treatment often leads to a loss of diversity and promotes the invasion of exogenous species30,33. The ability to predict and alter the colonization outcomes (i.e., prevent the engraftment of pathogens and promote the engraftment of probiotics) is critical for personalized microbiota-based interventions in nutrition and medicine. Despite the accumulating empirical studies, predicting the colonization outcomes in complex communities, such as the human gut microbiome, remains a fundamental challenge due to limited knowledge of interspecies interactions. For a meta-community of N species (N ranges from hundreds to thousands for the human gut microbiome), we would need to isolate and culture all these species (which is already a formidable task) and conduct a considerable number of experiments to map pairwise interactions, not to mention higher-order interactions. Thus, novel approaches are needed to study the ecology of highly complex communities. The key question is: can we achieve system-level predictions for complex ecological systems without requiring detailed mechanistic information? Colonization outcome can be viewed as a mapping from the community structure of a complex ecological system (i.e., the pre-invasion community profile) to its function (i.e., the post-invasion abundance of the invading species). Recently, the application of data-driven models (machine learning and deep learning) has shown great promise in predicting the emergent properties of complex biomolecules, such as protein structure (mapping from protein sequence to structure)34, promoter strength (mapping from DNA sequence to function)35. While statistical models have been used to decipher microbial interactions in synthetic human gut microbial communities36 and mouse gut microbiota30, the use of data-driven models has not received much attention in microbial ecology37,38. Here, we proposed a data-driven approach to predict colonization outcomes of exogenous species in complex microbial communities. First, we systematically evaluated the approach using synthetic data generated by classical ecological dynamical models. We found that, with sufficient sample size in training data (on the order of ~O(N)), the colonization outcomes (i.e., whether an exogenous species can engraft and what its abundance would be if it can engraft) can be predicted by machine learning models. Then, we generated large-scale datasets with in vitro experimental outcomes of two representative species (E. faecium and A. muciniphila) colonizing human stool-derived microbial communities. We validated that machine-learning models, including Random Forest and neural ODE, can also predict colonization outcomes in experiments (AUROC\u2009>\u20090.8). Finally, we used the machine learning models to infer species with large colonization impacts and experimentally demonstrated that the introduction of strongly interacting species can significantly alter the colonization outcomes. Our results suggest that the colonization outcome of complex microbial communities can be predicted via data-driven approaches and tunable. Results The data-driven approach of predicting colonization outcomes for complex microbial communities Let\u2019s consider a meta-community with a pool of N microbial species, denoted as \u03a9 = {1,\u22ef,N}. Consider a large set of M microbiome samples, denoted as S = {1,\u2026,M}, collected from this meta-community. A microbiome sample s\u2208S can be considered as a local community of the meta-community with a subset of co-existing species (Fig. 1A). For a local community s, if an exogenous species i (still in the species pool \u03a9, but not in community s) is introduced to community s, whether it can successfully colonize the community or not, as well as its post-invasion abundance xi, will depend on the baseline composition of community s. For example, it is easier (or harder) for species i to colonize community s if some resident species strongly promote (or inhibit) its growth of species i, respectively. Hereafter, we call the community s permissive (or resistant) to species i if species i can (or cannot) successfully colonize community s, respectively. If we only have the information about species i and a community s, it may seem impossible to accurately predict the colonization outcome without detailed knowledge about microbial interactions. However, if we have access to the data from colonization experiments of many local communities, then, in principle, we can formalize the colonization outcome prediction problem as a machine-learning task that can be solved in a data-driven fashion. To ensure the problem is mathematically well-defined, we must assume that the different local communities in this meta-community share identical assembly rules and microbial interactions39. This way, the colonization outcomes of some local communities can be used to train a machine-learning model to predict the colonization outcomes of other local communities. Fig. 1: Prediction of colonization outcomes for complex microbial communities via the data-driven approach. A Each individual\u2019s microbiome can be viewed as a local community, a subset of the meta-community of microbial species. For an exogenous species that invades the local communities, its colonization outcome (e.g., permissive or resistant) can be highly personalized, depending on the composition of local communities. B Colonization outcome prediction (COP) can be solved by learning the mapping from the baseline taxonomic profile to the post-invasion abundance of the exogenous species (i.e., \\(\\varphi :{{{{\\bf{x}}}}}^{0}{\\mapsto {{{\\rm{x}}}}}^{1}\\)). C\u2013E Evaluation of the data-driven approach in solving the classification task of COP. AUROC of three machine learning models, including Logistic Regression (LR), COP-Neural Ordinary Differential Equations classifier (NODE), and Random Forest classifier (RF). F\u2013H Evaluation of the data-driven approach in solving the regression task of COP. Pearson correlation between the true abundance and the abundance predicted by three machine learning models, including Elastic Net Linear Regression (ENET), COP-NODE regressor (NODE), and Random Forest regressor (RF) with network connectivity C = 0.3, 0.4, 0.5. Error bars are the 95% confidence interval, the bottom and top of the box are the 25th and 75th percentiles, the line inside the box is the 50th percentile, and outliers are shown as plots. Full size image Consider species-i as the exogenous species to a local community s. Note that the baseline abundance of species-i is zero (i.e., \\({x}_{i}^{(0)}=0\\)) in s before the invasion. With some initial abundance, the exogenous species will interact with the resident species in s, and its post-invasion steady-state abundance is denoted as \\({x}_{i}^{(1)}\\). We propose to solve the Colonization Outcome Prediction (COP) problem using machine-learning models that treat the baseline (i.e., pre-invasion) taxonomic profile \\({{{{\\bf{x}}}}}^{(0)}\\) as inputs and the steady state abundance of the invasive species \\({x}_{i}^{(1)}\\) as output (Fig. 1B). Mathematically, we intend to learn the mapping from the baseline taxonomic profile of a community \\({{{{\\bf{x}}}}}^{(0)}\\) to the steady state abundance of the invading species \\({x}_{i}^{(1)}\\), i.e., \\(\\varphi :{{{{\\bf{x}}}}}^{(0)}\\mapsto {x}_{i}^{(1)}\\). In addition, this mapping could help us infer the impact of each resident species on the colonization of the exogenous species. We conducted in silico simulations to validate the feasibility of our approach. We generated synthetic data of colonization outcomes using the Generalized Lotka\u2013Volterra (GLV) model with N = 100 species in the meta-community (see Methods)40. The initial species collection of each sample (i.e., a local community) consists of 30 species randomly drawn from the (N\u22121) species pool (the exogenous species is absent in all the local communities). We generated the baseline profiles of local communities by running the GLV dynamics to a steady state. The exogenous species was then added to each local community, and its post-invasion abundance was obtained by running the GLV dynamics to a new steady state. We can formalize COP as two sub-problems: (1) Classification: predict whether an exogenous species can colonize a local community; (2) Regression: predict the steady-state abundance of an exogenous species after colonization. Using the synthetic data generated by the GLV model, we first addressed the classification problem, i.e., predicting whether the invading species can colonize a community. We employed three models covering representative categories of machine learning: Logistic Regression, Random Forest classifier, and COP-Neural Ordinary Differential Equations (COP-NODE) classifier (see Methods). We tuned the complexity of the ecological network (i.e., network connectivity) and evaluated the performance of different models at varying levels of the training sample size (Fig. 1C\u2013E). Here, the network connectivity represents the probability of two species in the species pool interacting with each other. As expected, we observed that the predictive performance of machine learning models improved with the number of training samples. For network connectivity C = 0.3, we found that the Area Under the Receiver Operating Characteristic curve (AUROC, a perfect classifier has AUROC\u2009=\u20091 and AUROC\u2009=\u20090.5 for random guess) of three machine learning models was above 0.9 with training sample size \\({S}_{{{{\\rm{train}}}}}=N\\). For higher network connectivity (e.g., C = \\(0.4\\) and \\(0.5\\)), the increased complexity in inter-species interactions rendered the binary prediction of colonization outcomes more difficult. Nevertheless, with a sample size on the order of ~O(N) per colonizing species, machine learning models were able to achieve accurate classification of colonization outcomes in synthetic data (AUROC\u2009>\u20090.8). Next, we addressed the regression problem, i.e., predicting the steady-state abundance of the exogenous species. For the GLV model (with the interaction matrix A being invertible, which is almost surely true for randomly constructed matrices), our analytical derivations discovered a surprisingly simple linear relation between the post-invasion abundance of the exogenous species and the pre-invasion abundance of resident species (Supplementary Text, Fig. S1). Although the linear relation doesn\u2019t hold for other dynamical models, it suggests that learning the mapping for COP is feasible by the data-driven approach, and the number of parameters required for fitting the relation is on the order of ~O(N). We employed three machine learning models: Elastic Net Linear Regression (ENET), Random Forest regressor, and COP-NODE regressor (Fig. 1F\u2013H). The predictive performance was evaluated with Pearson\u2019s correlation coefficient between the predicted and true abundance (log-transformed), as well as the ratio between the predicted abundance and the true abundance (Fig. S2). We systematically examined the predictive performance of three models at varying levels of network connectivity and training sample size. Similar to the classification problem, we found that increasing network connectivity \\(C\\) rendered the regression problem more difficult. For training sample size \\({S}_{{{{\\rm{train}}}}}=2N\\) or higher, there was a substantial improvement in the quantitative prediction of the post-invasion abundance by ENET and NODE; in contrast, Random Forest had a poor performance at all sample sizes. Finally, we added varying levels of noise in the simulated data to assess the robustness of machine learning models to technical variations (e.g., measurement errors). For both the classification problem and the regression problem, we found that the predictive performance of machine learning models is robust against noise (Fig. S3). Generation of human stool-derived in vitro microbial communities with diverse compositional profiles To systematically study colonization outcomes in complex microbial communities, we used cultivation of human stool-derived in vitro communities in multi-well plates41,42,43,44 (Fig. 2A, Methods). Briefly, we cultured gut microbial communities derived from 24 donors to reach steady states after five rounds of serial passaging in vitro. To increase the diversity in baseline communities, we treated each donor\u2019s sample with a single pulse of 12 antibiotics from different classes (Table S1). After 24\u2009h of antibiotics treatment, in vitro microbial communities were passaged every 24\u2009h with a 1:200 dilution into fresh medium (Fig. 2A). Overall, we obtained more than 300 baseline communities with substantial variation in the compositional profiles at the species level (Fig. 2B, Figs. S4, S5). The compositional profiles of the baseline communities were stable, with around 40 to 120 co-existing species in each community (Fig. S6). Fig. 2: Invasion experiments in human stool-derived in vitro microbial communities. A Schematic representation of in vitro culture of human stool-derived microbial communities in 96-well plates (Methods). Stool samples from 24 donors were treated with 12 different antibiotics for 24\u2009h. The control group was not treated with antibiotics. All communities were passaged five times to reach a stable state, i.e., baseline community profiles (green dot, schematic cartoon below illustrated an example of in vitro baseline communities with diverse composition). B Exogenous species were introduced on Day 6. After 8\u201310 times of passaging, the end-point community profiles (red dot) were sequenced to determine the colonization outcome (C). Full size image For the invasion experiments, we would introduce an exogenous species into the baseline communities and determine its colonization outcome after 8\u201310 rounds of serial passaging (Fig. 2C). We conducted a preliminary experiment to investigate the colonization outcome of different exogenous species (Fig. S7). We found that E. faecium, A. muciniphila, and Fusobacterium nucleatum could successfully colonize in some communities at varying levels of post-invasion abundance. In contrast, Streptococcus salivarius, Bifidobacterium breve, and Lactobacillus spp. could not colonize in nearly all the communities we tested. Moreover, vancomycin treatment significantly altered the colonization outcomes, rendering the gut microbial communities more susceptible to invasion (Fig. S7C). Overall, our results support the use of human stool-derived in vitro communities as a model experimental system for studying colonization outcomes. Colonization outcomes of E. faecium in human stool-derived in vitro communities We selected E. faecium as a representative species for colonization experiments in human stool-derived in vitro communities. E. faecium is a Gram-positive bacterium that inhabits the gut of humans and other animals. Some E. faecium strains have probiotic potential45, and recent studies suggest that it plays a positive role in cancer immunotherapy46,47. On the other hand, some E. faecium strains cause opportunistic infections in hospitalized patients with disrupted gut microbiota48. We introduced E. faecium to ~300 baseline communities (Fig. S8) at a dose of 5% relative to the total abundance of resident species. We passaged all communities for ten rounds to reach the post-invasion steady state (Methods). We observed that the colonization outcomes of E. faecium in different communities were persistent during serial passaging (Fig. S8B). In addition, the composition of in vitro communities before and after E. faecium invasion is highly reproducible across three replicates (Fig. S9). We found that E. faecium was able to colonize 32% of baseline communities (i.e., permissive), with its post-invasion absolute abundances (estimated by multiplying its relative abundance with the total biomass OD600) in permissive communities varying over two orders of magnitude (Fig. 3A). Previous studies suggested that community biomass and diversity are important factors underlying the colonization resistance to exogenous species49,50. For example, reduced diversity of the resident community is often linked to pathogen infection in the human gut or other ecosystems51. Indeed, we found that the biomass and species richness of the baseline communities exhibited a clear negative correlation with the post-colonization abundances of E. faecium (Fig. S10). The diversity of the E. faecium permissive communities was significantly lower than the resistant communities (Fig. 3B, C). Furthermore, we observed a significant difference between the composition of E. faecium permissive communities and resistant communities (Fig. 3D). The colonization success of E. faecium was highly baseline-dependent, with substantial variations across different donors and antibiotics treatments (Fig. S11). Fig. 3: The colonization outcome of E. faecium in human stool-derived in vitro microbial communities is baseline-dependent and discriminable. A The distribution of E. faecium colonization outcomes across permissive communities (colored in red). The abundance of E. faecium in resistant communities is below the detection threshold and not shown. Inset: Percentage of permissive (red) and resistant communities (gray) based on E. faecium colonization outcomes. B, C Shannon diversity and species richness of E. faecium resistant and permissive communities (****p\u2009=\u20092.902e\u221210, Mann\u2212Whitney U-tests, n\u2009=\u2009297 biologically independent samples). C Species richness of E. faecium resistant and permissive communities (****p\u2009=\u20097.655e\u221213, Mann\u2013Whitney U-tests, n\u2009=\u2009297 biologically independent samples). D Principal component analysis (PCoA) based on the Bray-Curtis dissimilarity of the compositional profiles of baseline communities. The difference between permissive and resistant communities was significant (PERMANOVA Adonis test, \\({R}^{2}=0.03,{p}=9.999{{{\\rm{e}}}}-05\\)). E\u2013G ROC curve of machine learning models in binary classification (permissive vs. resistant) of the colonization outcomes of E. faecium. For each 6-fold cross-validation (ROC curves shown in a light color), we used the samples from 20 donors to train each model and the samples from the remaining four donors to evaluate the model. The mean ROC curve is shown in dark color. LR: Logistic Regression, NODE: COP-Neural Ordinary Differential Equations classifier, RF: Random Forest classifier. Error bars are the 95% confidence interval, the bottom and top of the box are the 25th and 75th percentiles, the line inside the box is the 50th percentile, and outliers are shown as plots. Full size image For the regression problem, we need training samples with non-zero post-invasion abundance. Because E. faecium only colonized in ~30% of baseline communities in our experiments, the number of samples is insufficient to train the regression models to predict the post-invasion absolute abundance. To predict the binary colonization outcomes (permissive vs. resistant) of E. faecium, we employed three machine learning models, including Logistic Regression, COP-NODE classifier, and Random Forest classifier (Fig. 3E\u2013G, Fig. S12AB). For 6-fold cross-validation, we used the communities derived from 20 donors (~240 samples) to train the model and the communities derived from the remaining 4 donors (~60 samples) to evaluate the model. Random Forest classifier displayed the best performance in predicting whether E. faecium could successfully colonize based on the species-level community composition (AUROC\u2009=\u20090.86, Accuracy = 0.82), followed by COP-NODE classifier (AUROC\u2009=\u20090.81, Accuracy = 0.81) and Logistic Regression (AUROC\u2009=\u20090.71, Accuracy = 0.75, and the Accuracy of a naive classifier that predicts E. faecium cannot colonize in all communities is around 0.7). We also evaluated the performance of machine learning classifiers with a balanced split of training and test samples, showing that Random Forest remains the best classifier (AUROC\u2009=\u20090.81 for E. faecium colonization, Fig. S13A). For comparison, we used the community diversity (quantified by the relative species richness) as the only feature to predict colonization outcome (see Fig. S14). Our results indicated that the relative species richness alone can be used as a predictor, but its prediction performance (with average AUROC\u2009=\u20090.78 and Accuracy = 0.32) is worse than elaborate classifiers, e.g., Random Forest using the taxonomic profile (with average AUROC\u2009=\u20090.86 and Accuracy = 0.82). Overall, our colonization experiments of E. faecium in complex human gut microbial communities validated that the data-driven approach can solve the classification problem of COP. Quantitatively predict the colonization outcomes of A. muciniphila To investigate the generality of our approach, we selected A. muciniphila as a second representative species for colonization experiments in human stool-derived in vitro communities. A. muciniphila is a Gram-negative mucin-degrading bacterium that inhabits the human gut. Due to its potential beneficial effects on human health52,53,54, A. muciniphila is considered a promising probiotic candidate55. A. muciniphila is found in the gut microbiome of around 30% of adults, and its abundance varies substantially across individuals56. Similar to the experimental design of E. faecium, we introduced A. muciniphila to ~300 baseline communities at a dose of 5% relative to the total abundance of resident species and passaged all communities for eight rounds to reach the post-invasion steady state. The colonization outcome of A. muciniphila in different communities was persistent during serial passaging (Fig. S15), and the composition of in vitro communities post A. muciniphila invasion is highly reproducible across three replicates (Fig. S16). Overall, we found substantial variations in the post-invasion steady-state abundance of A. muciniphila across different donors and antibiotics treatments (Fig. S17). A. muciniphila could colonize in 93.6% of baseline communities (i.e., permissive). For permissive communities, the post-invasion abundance of A. muciniphila displayed a bimodal distribution (Fig. 4A). We classified the permissive communities into two subgroups (high vs. low), depending on the post-invasion abundance of A. muciniphila (abundance threshold at \\({10}^{-2}\\)). The Shannon diversity (Fig. 4B) and species richness (Fig. 4C) of the A. muciniphila high permissive communities were significantly lower than those of the low permissive communities, and there was a significant difference between the community composition of the two groups (Fig. 4D). Fig. 4: The colonization outcomes of A. muciniphila in human stool-derived in vitro microbial communities are quantitatively discriminable. A The distribution of A. muciniphila colonization outcomes across permissive communities. The abundance of A. muciniphila in resistant communities is below the detection threshold and not shown. Inset: Percentage of high permissive (dark blue color), low permissive (light blue), and resistant communities (gray) based on A. muciniphila colonization outcomes. B Shannon diversity of A. muciniphila resistant, permissive (low), and permissive (high) communities (ns, not significant, ****p\u2009=\u20091.644e\u221215, Mann\u2013Whitney U-tests, n\u2009=\u2009257 biologically independent samples). C Species richness of A. muciniphila resistant, permissive (low), and permissive (high) communities (ns, not significant, **p\u2009=\u20090.002307, ****p\u2009=\u20092.623e\u221207, Mann\u2013Whitney U-tests, n\u2009=\u2009257 biologically independent samples). D Principal component analysis (PCoA) plots based on the Bray-Curtis dissimilarity of the compositional profiles of baseline communities. Color of the point showing the abundance of A. muciniphila in communities. The difference between highly permissive and lowly permissive communities was significant (PERMANOVA Adonis test, \\({R}^{2}=0.022,{p}=9.999{{{\\rm{e}}}}-05\\)). E\u2013G ROC curve of machine learning models in binary classification (high permissive vs. low permissive) of the colonization outcomes of A. muciniphila. For each 6-fold cross-validation (ROC curves shown in a light color), we used the samples from 20 subjects to train each model and the samples from the remaining four subjects to evaluate the model. The mean ROC curve is shown in dark color. ENET: Elastic Net Linear Regression, NODE: COP-Neural Ordinary Differential Equations regressor, RF : Random Forest regressor. H\u2013J Pearson\u2019s correlation coefficient and the average squared differences between the predicted and the observed abundance (log-transformed values) of A. muciniphila. Error bars are the 95% confidence interval, the bottom and top of the box are the 25th and 75th percentiles, the line inside the box is the 50th percentile, and outliers are shown as plots. Full size image We evaluated the performance of machine learning models in predicting the colonization outcomes of A. muciniphila, both qualitatively (classification) and quantitatively (regression). Random Forest classifier displayed the best performance in binary classification (high permissive vs. low permissive of A. muciniphila) based on the species-level community composition (AUROC\u2009=\u20090.84), followed by COP-NODE classifier (AUROC\u2009=\u20090.79) and Logistic Regression (AUROC\u2009=\u20090.75) (Fig. 4E\u2013G). To quantitatively predict the post-invasion abundance of A. muciniphila, we employed three machine learning models: ENET, COP-NODE regressor, and Random Forest regressor (Fig. 4H\u2013J, Fig. S18). In comparison to the other two methods, the Random Forest regressor achieved the highest accuracy in quantitative prediction (Pearson\u2019s correlation coefficient between the predicted and true abundances \\({{{\\rm{\\rho }}}}=0.74,p < 2.2\\times {10}^{-16}\\)) and successfully recapitulated the bimodal distribution in the abundance of A. muciniphila. Taken together, we demonstrated the generality of the data-driven approach in predicting baseline-dependent colonization outcomes for complex microbial communities. Colonization impact in simulated and experimental communities Learning the mapping from the baseline taxonomic profile to colonization outcomes can help us infer the impact of each resident species on the colonization of the exogenous species (Fig.1B). To compute the colonization impact of regression (classification), we can perform a thought experiment by introducing a perturbation in the abundance of the resident species and use the trained machine learning model to predict the new colonization outcome of invading species after the perturbation (Fig. 5A). Negative colonization impact means that a resident species inhibits the colonization of the exogenous species in a given local community. In GLV simulations, while the colonization impact of resident species was randomly distributed (Fig. 5B), we found that the median colonization impact of a resident species across different local communities was positively correlated to its interaction strength on the exogenous species (Spearman correlation coefficient \\(\\rho=0.73,p < 2.2{\\times 10}^{-16}\\), Fig. 5C), suggesting that we may use colonization impact to identify strongly interacting species. Fig. 5: Colonization impact in simulated and experimental communities. A To compute the colonization impact, i.e., the impact of a resident species on the colonization outcome of the invading species, we first trained the prediction models using all the samples. Then, we performed a thought experiment by introducing a perturbation in the abundance of the resident species and used the trained machine learning model to predict the new steady state abundance of invading species after the perturbation. A negative colonization impact indicates that a resident species inhibits the colonization of the invading species. B, C In simulated data, the colonization impact is randomly distributed. The median colonization impact of a resident species across different local communities is positively correlated to its interaction strength on the exogenous species (Spearman correlation \\(\\rho=0.73,\\,{p} < 2.2{\\times 10}^{-16}\\left)\\right.\\). Network connectivity \\(C=0.3\\), \\({S}_{{{{\\rm{trian}}}}}/N=5\\). COP-NODE regressor is used. D, E The distribution of colonization impact on E. faecium, and the top-ranking species with negative colonization impact (median across different communities, RF classifier). F, G The distribution of colonization impact on A. muciniphila and the top-ranking species with negative colonization impact (median across different communities, RF regressor). Error bars are the 95% confidence interval, the bottom and top of the box are the 25th and 75th percentiles, the line inside the box is the 50th percentile, and outliers are shown as plots. Full size image We used the Random Forest model to evaluate the colonization impact of all species in human stool-derived in vitro communities on E. faecium and A. muciniphila (Fig. 5D\u2013G). We inferred that most resident species had a weak negative colonization impact (Fig. 5D, F). Based on the median colonization impact of a certain resident species across different local communities, we identified the top-ranking species with negative colonization impact (Fig. 5E, G). Colonization impact on A. muciniphila was overall less negative than E. faecium, consistent with our observation that human gut microbial communities were more permissive to A. muciniphila colonization. The impact of strongly interacting species on colonization outcomes To understand the role of strongly interacting species on colonization outcomes, we systematically studied the impact of E. faecalis on the colonization of E. faecium. E. faecalis was inferred to have the strongest colonization impact on E. faecium across different baseline communities (Fig. 5E). Besides, we found that E. faecalis, as well as other 5 species among the top 20 list (including Faecalibacterium prausnitzii, Ruminococcus gnavus, Blautia sp., Clostridium sp. L.2.50, and Roseburia inulinivorans) were predicted by both Random Forest (Fig. 5E) and NODE (Fig. S19AB) to have a strong impact on E. faecium colonization. In contrast, Logistic Regression classifier did not identify E. faecalis as a strong inhibitor (Fig. S19CD), and its predictive performance is substantially worse than Random Forest and NODE (Fig. 3). The colonization impact of those top-ranking species is also consistent with the result of LIME which is a novel explanation technique that explains the predictions of any classifier57, e.g., the presence of E. faecalis, F. prausnitzii, and Clostridium perfringens in resistant communities increases the probability that E. feacium cannot colonize (see Fig. S19E). We observed a statistically significant negative correlation between the abundance of E. faecalis in baseline communities and the post-invasion abundance of E. faecium (Kendall\u2019s \\({{{\\rm{\\tau }}}}=-0.37\\), \\(p=5.29{\\times 10}^{-16}\\)). In particular, baseline communities derived from some donors (e.g., S10, S07) had a high abundance of E. faecalis and were resistant to E. faecium colonization (Fig. 6A). Fig. 6: The presence of E. faecalis in baseline communities inhibits the invasion of E. faecium. A The post-invasion relative abundance of E. faecium (aqua) is negatively associated with the relative abundance of E. faecalis (red) across baseline communities derived from different human subjects (labeled as S01 to S24). B\u2013D The colonization of E. faecium is significantly inhibited by E. faecalis across different baseline communities (labeled as B1 to B8). There were three different intervention groups: (1) add E. faecalis (or C. symbiosum) into the baseline community, followed by E. faecium on the next day (B); (2) add E. faecalis and E. faecium on the same day (C); (3) add E. faecium into the baseline community, followed by E. faecalis on the next day (D). In the control group, we only added E. faecium. After five passages, the end-point abundance of E. faecium was measured by qPCR. The fold change in the end-point abundance of E. faecium (the intervention group divided by the control group) is lower than 1 (dashed line), indicating that E. faecalis inhibits the colonization of E. faecium. Two different E. faecalis strains, DA462 and DA894, were used. n\u2009=\u20093 replicates, the error bars are standard error of means. Full size image We found that E. faecalis inhibited the growth of E. faecium in pairwise co-culture, either in liquid culture or on agar plates (Fig. S20). Then, we introduced E. faecalis into eight human stool-derived in vitro communities that were permissive to E. faecium invasion, using three different types of interventions (Fig. 6B\u2013D, Fig. S21A): (1) add E. faecalis into the baseline community, followed by E. faecium on the next day; (2) add E. faecalis and E. faecium on the same day; (3) add E. faecium into the baseline community, followed by E. faecalis on the next day. In the control group, we only added E. faecium. In all three intervention groups, the colonization of E. faecium was significantly inhibited by E. faecalis across different baseline communities. Also, the inhibitory effect was consistent for two different E. faecalis strains isolated from human stool samples (Methods). In comparison, Clostridium symbiosum, a species predicted to have a neutral impact, did not alter the colonization of E. faecium (Fig. S21B). Finally, we explored if the strong inhibition of E. faecalis on E. faecium could be shaping their distribution in the human gut via priority effects, i.e., the gut microbiome colonized with E. faecalis becomes resistant to E. faecium. We performed metagenomic sequencing of ~120 healthy volunteers in the SIAT cohort (Methods), whose samples were used to derive the in vitro communities and isolate the Enterococcus strains in this study. Indeed, there was a statistically significant negative correlation between the relative abundance of E. faecalis and E. faecium in the SIAT cohort (Kendall correlation \\({{{\\rm{\\tau }}}}=-0.36,\\,p=0.0044\\), Fig. S22A). A similar pattern was observed in gut metagenomic samples of four independent cohorts (Kendall correlation \u03c4\u2009=\u2009\u22120.36, p\u2009=\u20095.439\u2009\u00d7\u200910\u221215, Fig. S22B). Overall, our experimental validations and analysis suggest that data-driven models can infer species with strong colonization impact and guide the modulation of resident communities to alter the colonization outcomes of exogenous species. Discussion Here we proposed and systematically validated a data-driven approach to predict colonization outcomes of exogenous species, providing a powerful tool to inform the management of complex ecosystems. Pairwise co-culture50,58,59,60 and synthetic communities17,36,61,62 have been widely used to study the ecology and function of microbial communities. These experiments require the isolation and cultivation of individual species, thus are often limited to simple communities. In comparison, our approach is based on sampling an ensemble of complex communities (~100 species, Fig. S4) and using the sampled communities to infer the mapping between community composition and colonization outcomes63 by assuming the compositional profiles represent steady states of the local communities. We demonstrate that the data-driven approach enables accurate function prediction and system-level understanding of complex microbial communities. Understanding the colonization resistance of complex communities is a fundamental question in ecology. In our invasion experiments (~300 local communities and two different exogenous species), we found that resistance to exogenous species was positively correlated to community diversity, supporting the view that colonization resistance is an emergent property of complex communities8. Community diversity (i.e. species richness) alone can provide a reasonable degree of predictive accuracy (Fig. S14). However, it is less effective compared to utilizing full taxonomic profiles. While most resident species had a weak negative impact on the colonization of exogenous species, we identified E. faecalis as a strong inhibitor of E. faecium. We validated that introducing strongly interacting species into baseline communities can alter the colonization outcomes. It should be noted that the colonization impact is dependent on the community context (Fig. 5), because it takes into account both direct and indirect effects on the invading species64, as well as potential higher-order interactions65,66. Previous studies have shown that strongly interacting species can lead to priority effects67, with important implications for community assembly in the infant gut microbiome and the formation of community types68,69. Moreover, strongly interacting species can be used to modulate the resident communities to prevent the colonization of pathogens16 or facilitate the colonization of beneficial microbes (e.g., probiotics, crop fertilizers)70. Our results suggest that the colonization resistance of microbial communities is predictable and tunable via the data-driven approach, given that training data size is sufficient (on the order of ~O(N))71. For synthetic data generated by the classical GLV model in community ecology, we did see that the simple models, e.g., linear regression and ENET work well for both classification problems (Fig. 1C\u2013E) and regression problems (Fig. 1F\u2013H). However, those simple statistical models did not work well in predicting the colonization of A. muciniphila (Fig. 4H). We anticipate that real microbial communities are more complicated than the simple GLV model (which only includes pair-wise inter-species interactions). Sophisticated machine learning models may have to be leveraged to predict colonization outcomes for complex communities. We anticipate that more training samples are required if high-order interactions are considered. However, those high-order interactions might be weak and do not significantly impact the prediction, as the community-function landscapes display a low degree of ruggedness72. The high-throughput cultivation of gut microbial communities in vitro provides a powerful approach to studying the human gut microbiome44,73. In our experiments, the number of species in the meta-community was ~160, and we profiled ~300 baseline communities for proof-of-concept validation. Meeting the sample size requirement for gnotobiotic plants is feasible74,75. However, it could be challenging to gather sufficient training data for gnotobiotic animals and human cohort studies, depending on the complexity of the meta-community. In addition to data size, another critical concern is the technical variability in large-scale experiments76. In future studies, experimental workflows can be automated to minimize technical variability and ensure data quality for training machine learning models. Our study has several limitations. First, we did not account for potential variations at the strain level77. Previous studies have shown that the strength of interspecies interactions can vary across different strains, such as the inhibition of Klebsiella pneumoniae by Klebsiella oxytoca16,78. We also observed strain-level variations in the inhibition of E. faecium by E. faecalis (Fig. 6), and the underlying mechanism remains to be elucidated. Second, our invasion experiments in vitro did not reflect host-mediated interactions, which also contribute to colonization resistance in vivo22. Nevertheless, the higher permissiveness to A. muciniphila than E. faecium in human gut microbial communities in vitro is consistent with the higher prevalence of A. muciniphila in metagenomic samples56,79. Third, we assumed that there was a single post-invasion steady state in simulated and experimental communities. The colonization outcomes may be influenced by multi-stability in microbial communities, e.g., successful colonization depends on the initial abundance of the invading species80,81. Fourth, in our in vitro experiments, we found that A. muciniphila was able to stably colonize in the majority of stool-derived communities with relatively high abundance. It is known that mucin is the preferred nutrient source of A. muciniphila82, so it would be interesting to study to which degree the colonization of A. muciniphila depends on the mucin concentration provided in the medium. Lastly, while the data-driven framework can be generalized to different scenarios, the machine learning models must be re-trained when the environmental condition changes. In contrast, mechanism-based models can better deal with changes in conditions (e.g., pH, nutrient level). We noted a potential difference between the GLV simulated data and experimental data: the exogenous species may already be present in the stool-derived communities, but its steady-state abundance was below the detection threshold. In this scenario, the introduction of the exogenous species (~5% of community biomass) may provide a growth boost (e.g., via some density-dependent mechanism) and enable the species to co-exist with other species at a higher steady-state abundance (i.e., multiple stable states). Moreover, there is a discrepancy between the performance of Random Forest in gGLV simulated data and real data. Potential explanations include: (1) the dynamics of the GLV model may be different from that of experimental communities. For instance, when the GLV model has globally stable equilibria, the final state is solely determined by the species collection. (2) the distribution of interspecies interaction strength used in the GLV model may differ from experimental communities. In experimental communities, a few strongly interacting species may dominate the contribution to the colonization resistance of exogenous species. In contrast, in simulated data, the contribution is more evenly distributed among resident species. Our data-driven approach is independent of any dynamics model to predict colonization outcomes of exogenous species for complex microbial communities without detailed knowledge of the underlying ecological and biochemical process. We anticipate that the data-driven approach can be generalized to predict and engineer the function of microbial communities (i.e., mapping from community composition to function)37,71,83,84. Similarly, this approach can be used to predict the response of microbial communities to various types of perturbations (i.e., mapping from community composition to the shift in composition/function), such as the baseline-dependent response of the human gut microbiome to prebiotics, food additives, etc., refs. 85,86. In parallel to the breakthroughs in predicting the properties of complex biomolecules, we envision that the data-driven approach will lead to a paradigm shift in studying the stability and function of complex ecological systems and guide important applications in healthcare (e.g., personalized nutrition based on the human gut microbiome) and agriculture. Methods Collection and preservation of human stool samples All human participants at SIAT (referred to as \u201cSIAT cohort\u201d) signed the informed consent form in the present study which was approved by the Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences (SIAT-IRB-200315-H0438). Stool samples were collected from healthy human donors and were immediately transferred to an anaerobic workstation (85% N2, 10% H2 and 5% CO2, COY). 10\u2009g of each stool sample was suspended into 50\u2009mL 20% glycerol (v/v, in sterile phosphate-buffered saline, with 0.1% L-cysteine hydrochloride), homogenized by vortexing, and then filtered with sterile nylon mesh to remove large particles in fecal matter. Aliquots of the suspension were stored in sterile cryogenic vials and frozen at \u221280\u2009\u00b0C for long-term storage until processing for DNA extraction and culturing so that the stool-derived community could be revived (thawed) for repeatable experiments. Cultivation of human stool-derived in vitro communities 20ul stool slurries aliquot stocks were inoculated into 980\u2009\u03bcL medium containing antibiotics in triplicate into 96 deep-well plates (PCR-96-SG-C, Axygen) for static culturing at 37\u2009\u00b0C for 24\u2009h in the anaerobic workstation. The concentration for each antibiotic was evaluated as described in the SI method. The medium (MiPro) used for in vitro culture was modified from previous studies, which comprises: peptone water (2.0\u2009g\u2009/L, CM0009, Thermo Fisher), yeast extract (2.0\u2009g\u2009/L, LP0021B, Thermo Fisher), L-cysteine hydrochloride (1\u2009g/\u2009L), Tween 80 (2\u2009mL/L), hemin (5\u2009mg/L), vitamin K1(10\u2009\u03bcL/L), NaCl (1.0\u2009g\u2009/L), K2HPO4 (0.4\u2009g/L), KH2PO4 (0.4\u2009g/L), MgSO4\u22c57H2O (0.1\u2009g/L), CaCl2\u22c52H2O (0.1\u2009g/L), NaHCO3 (4\u2009g/L), porcine gastric mucin (4\u2009g/L, M2378, Sigma-Aldrich), sodium cholate (0.25\u2009g/L) and sodium chenodeoxycholate (0.25\u2009g/L)87. After 24\u2009h of antibiotics treatment, in vitro microbial communities were passaged every 24\u2009h with a 1:200 dilution into fresh medium using the automated 96-format Thermo Scientific\u2122 ClipTip\u2122 (Thermofisher) pipette (every 24\u2009h, 5\u2009\u03bcL of this saturated culture was transferred into 995\u2009\u03bcL of fresh medium). After 5 days of passaging, 500\u2009\u03bcL of the cultures were mixed with 500\u2009\u03bcL sterile 40% glycerol (v/v, in sterile phosphate-buffered saline, with 0.1% L-cysteine hydrochloride) in crimp vials, sealed, and stored as baseline communities at \u221280\u2009\u00b0C for further usage and long-term storage. After each transfer, the remaining samples were centrifuged to remove the supernatant, and the pellets were stored at \u221280\u2009\u00b0C with a plastic seal until DNA extraction. The in vitro microbial community biomass was evaluated by measurement of optical density (OD600) with an Epoch 2 plate reader (BioTek) after 24\u2009h of incubation. Generation of baseline communities with diverse taxonomic profiles To examine if in vitro stool-derived communities can reach stable states and display diverse compositions, we collected stool samples from healthy donors and grew them in MiPro medium, which has shown its capability in capturing and maintaining the diversity of in vitro stool-derived communities42,87,88. We inoculated the stool aliquots into 96-well plates with growth media and incubated them in an anaerobic workstation in triplicate, passing them every 24\u2009h with a 1:200 dilution. The microbial communities were assessed by shallow metagenomic sequencing, which is a cost-effective method for characterizing species-level composition of microbiota samples89. We collected time-series data to examine the dynamics of community establishment on the in vitro platform. The metagenomic analysis revealed that, after an initial period of approximately four days, the composition profiles of almost all in vitro communities reached a stable and reproducible steady state. Our analysis also showed that the stool-derived in vitro communities were highly complex in their compositions and could retain personalized gut microbiota variation, as evidenced by species-level time-series compositions of 4 representative communities derived from 4 donors over ten rounds of in vitro passaging in MiPro (Fig. S6A, B). From the fecal samples of SIAT cohort, we selected 24 donors in which E. faecium and A. muciniphila were not detected by metagenomic sequencing. To increase the diversity in baseline communities, we treated each donor\u2019s sample with 12 antibiotics from different classes90 (Fig. S4). Those stool-derived communities were treated with antibiotics for 24\u2009h on Day 0 (i.e. a single pulse). Afterwards, the communities were passaged five times (from Day 1 to Day 6) in antibiotic-free medium to reach a stable state before introducing the exogenous species. Different antibiotic classes target distinct spectra of bacteria, leading to a remodeling of the community in different directions90. We selected antibiotics from different classes as described in the EUCAST databases91. The optimal concentrations of the antibiotics were determined based on a previous study that evaluated the activity spectrum of antibiotic classes on human gut commensals90. We tested at least three different concentrations for each antibiotic and evaluated the optimized dose based on its ability to partially inhibit (50\u201380%) the overall growth of stool-derived bacteria as measured by OD600 after 24\u2009h of incubation. To ensure reproducibility, we screened at least three different stool aliquot stocks as biological duplicates for each antibiotic. We measured the OD600 of each well every 30\u2009min using an Epoch 2 plate reader (BioTek) and collected growth curves up to 24\u2009h. Bacterial strains Enterococcus faecium, Enterococcus faecalis, Clostridium symbiosum, Streptococcus salivarius, and Bifidobacterium breve strains were isolated from fecal samples of SIAT cohort. Taxonomy of isolates from SIAT cohort was confirmed by whole genome sequencing. Genome sequences have been deposited in PRJEB60398 (see \u201cData availability\u201d). Lactobacillus plantarum HNU08292, Lactobacillus paracasei HNU31293 was provided by Prof. Jiachao Zhang from Hainan University. Akkermansia muciniphila (ATCC BAA-835) and Fusobacterium nucleatum (ATCC 25586) were purchased from ATCC. Profiling the colonization outcomes of different exogenous species We conducted a preliminary experiment to investigate the colonization outcome of gut microbial communities to different exogenous species (Fig. S7), including: E. faecium, A. muciniphila94, F. nucleatum, S. salivarius, B. breve, and Lactobacillus spp. (L. plantarum HNU082 and L. paracasei HNU312). We identified 12 stool samples from healthy donors in which the selected invader species were undetectable in the microbiota. We then cultured the stool samples in vitro and exposed them to antibiotics before introducing the exogenous species (~5% of total biomass, approximately 106 CFUs for each well) into the community. We used shallow metagenomic sequencing to monitor the time-series and final community composition. Invasion experiments of E. faecium and A. muciniphila To conduct invasion experiments, frozen stocks of E. faecium (strain SIAT_DA797) and A. muciniphila (strain ATCC BAA-835) were grown anaerobically in BHI and mGAM at 37\u2009\u00b0C, respectively, until stationary phase. In vitro microbial baseline communities, stored at \u221280\u2009\u00b0C, were thawed and revived by adding 20\u2009\u03bcL of the stocks to 980\u2009\u03bcL of MiPro medium in deep-well plates. After incubation for 24\u2009h at 37\u2009\u00b0C, community biomass was measured by OD600, and 5\u2009\u03bcL of the saturated cultures were diluted into 1\u2009mL of fresh MiPro in a new plate. Each well was invaded with the respective amount of E. faecium or A. muciniphila, with biomass representing 5% of the inoculated communities\u2019 average biomass. The inoculum was passaged every 24\u2009h of incubation, with a 1:200 dilution into fresh medium for 8\u201310 passages until the community reached a steady state (10 passages for E. faecium, 8 passages for A. muciniphila, based on data from Fig. S6). After each passage, the remaining samples were centrifuged to remove the supernatant, and the pellets were stored at \u221280\u2009\u00b0C with a plastic seal in plate until DNA extraction. Metagenomic sequencing and taxonomic profiling DNA was extracted from 200\u2009mg of stool samples using the QIAamp Power Fecal Pro DNA Kit (Qiagen) according to the manufacturer\u2019s instructions. For stool-derived in vitro-cultured samples, 500 uL of cultured samples were used for DNA extraction with the DNeasy UltraClean 96 Microbial Kit (Qiagen) using an automated protocol at Tecan Freedom EVO 200. The Hieff NGS\u00ae OnePot II DNA Library Prep Kit for Illumina\u00ae (Yeasen) was used for library preparation, following the manufacturer\u2019s instructions. The resulting library DNA was cleaned up and size-selected with Hieff NGS\u00ae DNA Selection Beads (Yeasen), and quantified using the dsDNA High Sensitivity kit on a Qubit (Thermo Fisher). Libraries were further pooled together at equal molar ratios, and the purity and library length distribution were assessed using Bioanalyzer High Sensitivity DNA Kit (Agilent). Sequencing was performed on the Illumina HiSeq X Ten system (150\u2009bp paired-end reads; Annoroad Gene Technology Co.), with a target sequencing depth of 0.3 Gbp raw data per sample, as recommended by previous studies89. Samples with fewer than 105 clean reads were excluded from downstream analysis. Prior to analysis, reads were trimmed using the following criteria: (1) Removing reads with more than 50% of the base below quality score 19; (2) Removing reads with more than 5% of the base being N; (3) Discarding paired-end reads if either of the paired reads did not meet the above criteria. Microbial community composition from metagenomic sequencing data was generated using the SHOGUN pipeline and the RefSeq database version 82, as described in previous studies89,95. Species-level abundance profiles were filtered by using a relative abundance threshold of 0.0001 (0.001) for all taxa in colonization prediction of E. faecium (A. muciniphila), and those low-prevalence taxa (present in less than 20% samples) were further filtered to reduce the feature number. The colonization outcomes were evaluated based on the invader\u2019s absolute abundance in the community, which was estimated by multiplying the relative abundance and the OD600 value (OD600\u2009\u00d7\u2009relative abundance). To ensure repeatability, samples with Pearson correlation below 0.8 among replicates were excluded from COP analysis. This resulted in the exclusion of 1.8% of samples for E. faecium and 1.3% for A. muciniphila. Quantification of the relative abundance of E. faecium and A. muciniphila by metagenomic sequencing To confirm the accuracy of shallow metagenomic sequencing in quantifying the relative abundance of E. faecium and A. muciniphila, a spike-in experiment was conducted (Fig. S23A). In this experiment, a predefined amount of bacterial DNA from the target species was added to a metaDNA sample extracted from an in vitro community derived from human stool. This metaDNA sample was used as the background, since it has been previously sequenced and did not contain the target species. The spike-in DNA of the target species (E. faecium or A. muciniphila) was 1:10 diluted for eight times and was added to the microbial metaDNA to a mixed DNA sample (5\u2009\u03bcL of target species DNA into 30\u2009ng of microbial metaDNA). Three replicates were made for each sample. The mixed DNA was then used for library construction and metagenomic sequencing. By comparing the detected relative abundance generated by shallow metagenomic sequencing with the expected abundance, the accuracy and sensitivity of our workflow were determined. The detection threshold of E. faecium is 0.0001 (Fig. S23B) and the detection threshold of A. muciniphila is 0.001 (Fig. S23C). Our results showed that the quantification of the relative abundance of the two target species using the shallow metagenomic sequencing pipeline is accurate and reproducible. Statistical analysis Statistical details for each experiment are indicated in the figure legends. Pearson correlation coefficients and the p-values for testing replicates communities\u2019 composition correlation were calculated on log10(relative abundance). Kendall correlation coefficients and the p-values for testing E. faecium and E. faecalis abundance correlation were calculated on log10(relative abundance). Alpha diversity of the community was calculated on species profile using the observed species richness and Shannon index. The composition of microbiota and variations in colonization outcomes between communities were analyzed by performing PCoA using the Bray-Curtis dissimilarity metric on the species-level abundance profile. Similarities among groups were determined by permutational multivariate analysis of variance (PERMANOVA, Adonis test) based on the Bray-Curtis dissimilarity96, with 999 permutations used to test the significance. These analyses were conducted using the vegan97 package (version 2.6\u20134). Non-parametric Mann\u2013Whitney U-test were used to conduct pairwise comparisons between two groups98. P values of less than 0.05 were considered as statistically significant, as indicated in the figures (ns, not significant, *p\u2009<\u20090.05, **p\u2009<\u20090.01, ***p\u2009<\u20090.001, ****p\u2009<\u20090.0001). Data analysis and plotting was performed in R version 4.1.2 and R studio version 2022.12.0\u2009+\u2009353 using the packages dplyr, ggpubr, vegen, and ComplexHeatmap. Reporting summary Further information on research design is available in the Nature Portfolio Reporting Summary linked to this article. Data availability All sequencing data generated in this study are available from European Nucleotide Archive (ENA) under study accession number PRJEB60398. Sample accession code, metadata and related source data are provided as a Source data file with this paper. Source data are provided with this paper. Code availability The code for simulations and data analysis is available at https://github.com/spxuw/COP. References Buffie, C. G. & Pamer, E. G. Microbiota-mediated colonization resistance against intestinal pathogens. Nat. Rev. Immunol. 13, 790\u2013801 (2013). Article   CAS   PubMed   PubMed Central   Google Scholar   Gensollen, T., Iyer, S. S., Kasper, D. L. & Blumberg, R. S. How colonization by microbiota in early life shapes the immune system. Science 352, 539\u2013544 (2016). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Walter, J., Maldonado-Gomez, M. X. & Martinez, I. To engraft or not to engraft: an ecological framework for gut microbiome modulation with live microbes. Curr. Opin. Biotechnol. 49, 129\u2013139 (2018). Article   CAS   PubMed   Google Scholar   Amor, D. R., Ratzke, C. & Gore, J. Transient invaders can induce shifts between alternative stable states of microbial communities. Sci. Adv. 6, eaay8676 (2020). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   van den Berg, N. I. et al. Ecological modelling approaches for predicting emergent properties in microbial communities. Nat. Ecol. Evol. 6, 855\u2013865 (2022). Article   PubMed   PubMed Central   Google Scholar   Kennedy, T. A. et al. Biodiversity as a barrier to ecological invasion. Nature 417, 636\u2013638 (2002). Article   CAS   PubMed   ADS   Google Scholar   Kurkjian, H. M., Akbari, M. J. & Momeni, B. The impact of interactions on invasion and colonization resistance in microbial communities. PLoS Comput. Biol. 17, e1008643 (2021). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Case, T. J. Invasion resistance arises in strongly interacting species-rich model competition communities. Proc. Natl Acad. Sci. USA 87, 9610\u20139614 (1990). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Vonaesch, P., Anderson, M. & Sansonetti, P. J. Pathogens, microbiome and the host: emergence of the ecological Koch\u2019s postulates. FEMS Microbiol. Rev. 42, 273\u2013292 (2018). Article   CAS   PubMed   Google Scholar   Pamer, E. G. Resurrecting the intestinal microbiota to combat antibiotic-resistant pathogens. Science 352, 535\u2013538 (2016). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Li, P. D. et al. The phyllosphere microbiome shifts toward combating melanose pathogen. Microbiome 10, 56 (2022). Article   CAS   PubMed   PubMed Central   Google Scholar   Mendes, R., Garbeva, P. & Raaijmakers, J. M. The rhizosphere microbiome: significance of plant beneficial, plant pathogenic, and human pathogenic microorganisms. FEMS Microbiol. Rev. 37, 634\u2013663 (2013). Article   CAS   PubMed   Google Scholar   Schmidt, T. S. et al. Extensive transmission of microbes along the gastrointestinal tract. eLife 8, e42693 (2019). Article   PubMed   PubMed Central   Google Scholar   Kok, C. R. & Hutkins, R. Yogurt and other fermented foods as sources of health-promoting bacteria. Nutr. Rev. 76, 4\u201315 (2018). Article   PubMed   Google Scholar   Chassaing, B. & Cascales, E. Antibacterial weapons: targeted destruction in the microbiota. Trends Microbiol. 26, 329\u2013338 (2018). Article   CAS   PubMed   Google Scholar   Kim, S. G. et al. Microbiota-derived lantibiotic restores resistance against vancomycin-resistant Enterococcus. Nature 572, 665\u2013669 (2019). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Eberl, C. et al. E. coli enhance colonization resistance against Salmonella Typhimurium by competing for galactitol, a context-dependent limiting carbon source. Cell Host Microbe 29, 1680\u20131692 e1687 (2021). Article   CAS   PubMed   Google Scholar   Oliveira, R. A. et al. Klebsiella michiganensis transmission enhances resistance to Enterobacteriaceae gut invasion by nutrition competition. Nat. Microbiol. 5, 630\u2013641 (2020). Article   CAS   PubMed   Google Scholar   Litvak, Y. et al. Commensal Enterobacteriaceae protect against Salmonella colonization through oxygen competition. Cell Host Microbe 25, 128\u2013139.e125 (2019). Article   CAS   PubMed   Google Scholar   Lloyd, D. P. & Allen, R. J. Competition for space during bacterial colonization of a surface. J. R. Soc. Interface 12, 0608 (2015). Article   PubMed   Google Scholar   Ivanov, I. I. et al. Induction of intestinal Th17 cells by segmented filamentous bacteria. Cell 139, 485\u2013498 (2009). Article   CAS   PubMed   PubMed Central   Google Scholar   Stecher, B. et al. Salmonella enterica serovar typhimurium exploits inflammation to compete with the intestinal microbiota. PLoS Biol. 5, 2177\u20132189 (2007). Article   CAS   PubMed   Google Scholar   Human Microbiome Project, C. Structure, function and diversity of the healthy human microbiome. Nature 486, 207\u2013214 (2012). Article   ADS   Google Scholar   Franzosa, E. A. et al. Identifying personal microbiomes using metagenomic codes. Proc. Natl Acad. Sci. USA 112, E2930\u2013E2938 (2015). Article   CAS   PubMed   PubMed Central   Google Scholar   Han, N. et al. Time-scale analysis of the long-term variability of human gut microbiota characteristics in Chinese individuals. Commun. Biol. 5, 1414 (2022). Article   PubMed   PubMed Central   Google Scholar   O\u2019Toole, P. W. & Jeffery, I. B. Gut microbiota and aging. Science 350, 1214\u20131215 (2015). Article   PubMed   ADS   Google Scholar   Turnbaugh, P. J., Backhed, F., Fulton, L. & Gordon, J. I. Diet-induced obesity is linked to marked but reversible alterations in the mouse distal gut microbiome. Cell Host Microbe 3, 213\u2013223 (2008). Article   CAS   PubMed   PubMed Central   Google Scholar   Maier, L. et al. Extensive impact of non-antibiotic drugs on human gut bacteria. Nature 555, 623 (2018). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Alavi, S. et al. Interpersonal gut microbiome variation drives susceptibility and resistance to cholera infection. Cell 181, 1533 (2020). Article   CAS   PubMed   PubMed Central   Google Scholar   Buffie, C. G. et al. Precision microbiome reconstitution restores bile acid mediated resistance to Clostridium difficile. Nature 517, 205\u2013U207 (2015). Article   CAS   PubMed   ADS   Google Scholar   Maldonado-Gomez, M. X. et al. Stable engraftment of Bifidobacterium longum AH1206 in the human gut depends on individualized features of the resident microbiome. Cell Host Microbe 20, 515\u2013526 (2016). Article   CAS   PubMed   Google Scholar   Zmora, N. et al. Personalized gut mucosal colonization resistance to empiric probiotics is associated with unique host and microbiome features. Cell 174, 1388\u20131405 e1321 (2018). Article   CAS   PubMed   Google Scholar   Liao, C. et al. Compilation of longitudinal microbiota data and hospitalome from hematopoietic cell transplantation patients. Sci. Data 8, 71 (2021). Article   PubMed   PubMed Central   Google Scholar   Jumper, J. et al. Highly accurate protein structure prediction with AlphaFold. Nature 596, 583\u2013589 (2021). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Vaishnav, E. D. et al. The evolution, evolvability and engineering of gene regulatory DNA. Nature 603, 455\u2013463 (2022). Article   CAS   PubMed   ADS   Google Scholar   Venturelli, O. S. et al. Deciphering microbial interactions in synthetic human gut microbiome communities. Mol. Syst. Biol. 14, e8157 (2018). Article   PubMed   PubMed Central   Google Scholar   Michel-Mata, S., Wang, X. W., Liu, Y. Y. & Angulo, M. T. Predicting microbiome compositions from species assemblages through deep learning. iMeta 1, e3 (2022). Article   PubMed   PubMed Central   Google Scholar   Wang, X. W. et al. Identifying keystone species in microbial communities using deep learning. Nat. Ecol. Evol. 8, 22\u201331 (2023). Article   PubMed   Google Scholar   Bashan, A. et al. Universality of human microbial dynamics. Nature 534, 259\u2013262 (2016). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Bunin, G. Ecological communities with Lotka-Volterra dynamics. Phys. Rev. E 95, 042414 (2017). Article   MathSciNet   PubMed   ADS   Google Scholar   Hernandez-Sanabria, E., Vazquez-Castellanos, J. F. & Raes, J. In vitro ecology: a discovery engine for microbiome therapies. Nat. Rev. Gastroenterol. Hepatol. 17, 711\u2013712 (2020). Article   PubMed   Google Scholar   Javdan, B. et al. Personalized mapping of drug metabolism by the human gut microbiome. Cell 181, 1661\u20131679.e22\uff082020). Li, L. et al. RapidAIM: a culture- and metaproteomics-based Rapid Assay of Individual Microbiome responses to drugs. Microbiome 8, 33 (2020). Article   CAS   PubMed   PubMed Central   Google Scholar   Aranda-Diaz, A. et al. Establishment and characterization of stable, diverse, fecal-derived in vitro microbial communities that model the intestinal microbiota. Cell Host Microbe 30, 260\u2013272 e265 (2022). Article   CAS   PubMed   PubMed Central   Google Scholar   Hanchi, H., Mottawea, W., Sebei, K. & Hammami, R. The genus Enterococcus: between probiotic potential and safety concerns\u2014an update. Front Microbiol. 9, 1791 (2018). Article   PubMed   PubMed Central   Google Scholar   Griffin, M. E. et al. Enterococcus peptidoglycan remodeling promotes checkpoint inhibitor cancer immunotherapy. Science 373, 1040\u20131046 (2021). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Xiong, X. et al. Emerging enterococcus pore-forming toxins with MHC/HLA-I as receptors. Cell 185, 1157\u20131171 e1122 (2022). Article   CAS   PubMed   PubMed Central   Google Scholar   Van Tyne, D. & Gilmore, M. S. Friend turned foe: evolution of enterococcal virulence and antibiotic resistance. Annu. Rev. Microbiol. 68, 337\u2013356 (2014). Article   PubMed   PubMed Central   Google Scholar   Jones, M. L., Rivett, D. W., Pascual-Garcia, A. & Bell, T. Relationships between community composition, productivity and invasion resistance in semi-natural bacterial microcosms. eLife 10, e71811 (2021). Article   CAS   PubMed   PubMed Central   Google Scholar   Hromada, S. et al. Negative interactions determine Clostridioides difficile growth in synthetic human gut communities. Mol. Syst. Biol. 17, e10355 (2021). Article   CAS   PubMed   PubMed Central   Google Scholar   Keesing, F. et al. Impacts of biodiversity on the emergence and transmission of infectious diseases. Nature 468, 647\u2013652 (2010). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Valles-Colomer, M. et al. Variation and transmission of the human gut microbiota across multiple familial generations. Nat. Microbiol. 7, 87\u201396 (2022). Article   CAS   PubMed   Google Scholar   Derosa, L. et al. Intestinal Akkermansia muciniphila predicts clinical response to PD-1 blockade in patients with advanced non-small-cell lung cancer. Nat. Med. 28, 315\u2013324 (2022). Article   CAS   PubMed   PubMed Central   Google Scholar   Dao, M. C. et al. Akkermansia muciniphila and improved metabolic health during a dietary intervention in obesity: relationship with gut microbiome richness and ecology. Gut 65, 426\u2013436 (2016). Article   CAS   PubMed   Google Scholar   Zhai, Q. X., Feng, S. S., Arjan, N. & Chen, W. A next generation probiotic, Akkermansia muciniphila. Crit. Rev. Food Sci. 59, 3227\u20133236 (2019). Article   CAS   Google Scholar   Karcher, N. et al. Genomic diversity and ecology of human-associated Akkermansia species in the gut microbiome revealed by extensive metagenomic assembly. Genome Biol. 22, 209 (2021). Article   CAS   PubMed   PubMed Central   Google Scholar   Ribeiro, M. T., Singh, S. & Guestrin, C. in Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining 1135\u20131144 (2016). Chen, J. et al. A commensal-encoded genotoxin drives restriction of Vibrio cholerae colonization and host gut microbiome remodeling. Proc. Natl Acad. Sci. USA 119, e2121180119 (2022). Article   CAS   PubMed   PubMed Central   Google Scholar   Weiss, A. S. et al. In vitro interaction network of a synthetic gut bacterial community. ISME J. 16, 1095\u20131109 (2022). Article   CAS   PubMed   Google Scholar   Getzke, F. et al. Cofunctioning of bacterial exometabolites drives root microbiota establishment. Proc. Natl Acad. Sci. USA 120, e2221508120 (2023). Article   CAS   PubMed   PubMed Central   Google Scholar   Brugiroux, S. et al. Genome-guided design of a defined mouse microbiota that confers colonization resistance against Salmonella enterica serovar Typhimurium. Nat. Microbiol. 2, 16215 (2016). Article   CAS   PubMed   Google Scholar   Kehe, J. et al. Massively parallel screening of synthetic microbial communities. Proc. Natl Acad. Sci. USA 116, 12804\u201312809 (2019). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Gopalakrishnappa, C., Gowda, K., Prabhakara, K. H. & Kuehn, S. An ensemble approach to the structure-function problem in microbial communities. iScience 25, 103761 (2022). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Xiao, Y., Angulo, M. T., Lao, S., Weiss, S. T. & Liu, Y. Y. An ecological framework to understand the efficacy of fecal microbiota transplantation. Nat. Commun. 11, 3329 (2020). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Mayfield, M. M. & Stouffer, D. B. Higher-order interactions capture unexplained complexity in diverse communities. Nat. Ecol. Evol. 1, 62 (2017). Article   PubMed   Google Scholar   Sanchez-Gorostiaga, A., Bajic, D., Osborne, M. L., Poyatos, J. F. & Sanchez, A. High-order interactions distort the functional landscape of microbial consortia. PLoS Biol. 17, e3000550 (2019). Article   CAS   PubMed   PubMed Central   Google Scholar   Debray, R. et al. Priority effects in microbiome assembly. Nat. Rev. Microbiol. 20, 109\u2013121 (2022). Article   CAS   PubMed   Google Scholar   Rao, C. et al. Multi-kingdom ecological drivers of microbiota assembly in preterm infants. Nature 591, 633\u2013638 (2021). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Gibson, T. E., Bashan, A., Cao, H.-T., Weiss, S. T. & Liu, Y.-Y. On the origins and control of community types in the human microbiome. PLoS Comput. Biol. 12, e1004688 (2016). Article   PubMed   PubMed Central   Google Scholar   You, H. J. et al. Bacteroides vulgatus SNUG 40005 restores Akkermansia depletion by metabolite modulation. Gastroenterology 164, 103\u2013116 (2023). Article   CAS   PubMed   Google Scholar   Sanchez, A. et al. The community-function landscape of microbial consortia. Cell Syst. 14, 122\u2013134 (2023). Article   CAS   PubMed   Google Scholar   Skwara, A. et al. Statistically learning the functional landscape of microbial communities. Nat. Ecol. Evol. 7, 1823\u20131833 (2023). Article   PubMed   Google Scholar   Vrancken, G., Gregory, A. C., Huys, G. R. B., Faust, K. & Raes, J. Synthetic ecology of the human gut microbiota. Nat. Rev. Microbiol 17, 754\u2013763 (2019). Article   CAS   PubMed   Google Scholar   Vogel, C. M., Potthoff, D. B., Schafer, M., Barandun, N. & Vorholt, J. A. Protective role of the Arabidopsis leaf microbiota against a bacterial pathogen. Nat. Microbiol. 6, 1537\u20131548 (2021). Article   CAS   PubMed   PubMed Central   Google Scholar   Herrera Paredes, S. et al. Design of synthetic bacterial communities for predictable plant phenotypes. PLoS Biol. 16, e2003962 (2018). Article   PubMed   PubMed Central   Google Scholar   van de Velde, C. et al. Technical versus biological variability in a synthetic human gut community. Gut microbes 15, 2155019 (2023). Article   PubMed   Google Scholar   Hu, H. et al. StrainPanDA: Linked reconstruction of strain composition and gene content profiles via pangenome\u2010based decomposition of metagenomic data. iMeta 1 e41 (2022). Osbelt, L. et al. Klebsiella oxytoca causes colonization resistance against multidrug-resistant K. pneumoniae in the gut via cooperative carbohydrate competition. Cell Host Microbe 29, 1663\u20131679 e1667 (2021). Article   CAS   PubMed   Google Scholar   Wu, S. et al. GMrepo: a database of curated and consistently annotated human gut metagenomes. Nucleic Acids Res. 48, D545\u2013D553 (2020). Article   CAS   PubMed   Google Scholar   Gonze, D., Lahti, L., Raes, J. & Faust, K. Multi-stability and the origin of microbial community types. ISME J. 11, 2159\u20132166 (2017). Article   PubMed   PubMed Central   Google Scholar   Dai, L., Vorselen, D., Korolev, K. S. & Gore, J. Generic indicators for loss of resilience before a tipping point leading to population collapse. Science 336, 1175\u20131177 (2012). Article   CAS   PubMed   ADS   Google Scholar   Davey, L. E. et al. A genetic system for Akkermansia muciniphila reveals a role for mucin foraging in gut colonization and host sterol biosynthesis gene expression. Nat. Microbiol. 8, 1450\u20131467 (2023). Schubert, A. M., Sinani, H. & Schloss, P. D. Antibiotic-induced alterations of the murine gut microbiota and subsequent effects on colonization resistance against Clostridium difficile. mBio 6, e00974 (2015). Article   CAS   PubMed   PubMed Central   Google Scholar   Clark, R. L. et al. Design of synthetic human gut microbiome assembly and butyrate production. Nat. Commun. 12, 3254 (2021). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Baxter, N. T. et al. Dynamics of human gut microbiota and short-chain fatty acids in response to dietary interventions with three fermentable fibers. mBio 10, e02566\u201318 (2019). Article   CAS   PubMed   PubMed Central   Google Scholar   Suez, J. et al. Personalized microbiome-driven effects of non-nutritive sweeteners on human glucose tolerance. Cell 185, 3307\u20133328 e3319 (2022). Article   CAS   PubMed   Google Scholar   Li, L. et al. An in vitro model maintaining taxon-specific functional activities of the gut microbiome. Nat. Commun. 10, 4146 (2019). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Browne, H. P. et al. Culturing of \u2018unculturable\u2019 human microbiota reveals novel taxa and extensive sporulation. Nature 533, 543 (2016). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   Hillmann, B. et al. Evaluating the information content of shallow shotgun metagenomics. mSystems 3, e00069\u201318 (2018). Article   CAS   PubMed   PubMed Central   Google Scholar   Maier, L. et al. Unravelling the collateral damage of antibiotics on gut bacteria. Nature 599, 120\u2013124 (2021). Article   CAS   PubMed   PubMed Central   ADS   Google Scholar   EUCAST, T. European Committee on Antimicrobial Susceptibility Testing, Breakpoint tables for interpretation of MICs and zone diameters. Version 5.0, 2015 (2015). Huang, S. et al. Candidate probiotic Lactiplantibacillus plantarum HNU082 rapidly and convergently evolves within human, mice, and zebrafish gut but differentially influences the resident microbiome. Microbiome 9, 151 (2021). Article   CAS   PubMed   PubMed Central   Google Scholar   Zhang, Z. et al. Lactobacillus fermentum HNU312 alleviated oxidative damage and behavioural abnormalities during brain development in early life induced by chronic lead exposure. Ecotoxicol. Environ. Saf. 251, 114543 (2023). Article   CAS   PubMed   Google Scholar   Cani, P. D. & de Vos, W. M. Next-generation beneficial microbes: the case of Akkermansia muciniphila. Front. Microbiol. 8, 1765 (2017). Article   PubMed   PubMed Central   Google Scholar   Xu, W. et al. Characterization of shallow whole-metagenome shotgun sequencing as a high-accuracy and low-cost method by complicated mock microbiomes. Front. Microbiol. 12, 678319 (2021). Article   PubMed   PubMed Central   Google Scholar   Clarke, K. R. Non\u2010parametric multivariate analyses of changes in community structure. Aust. J. Ecol. 18, 26 (1993). Article   Google Scholar   Dixon, P. VEGAN, a package of R functions for community ecology. J. Veg. Sci. 14.6, 3 (2003). Google Scholar   Segata, N. et al. Metagenomic biomarker discovery and explanation. Genome Biol. 12, R60 (2011). Article   PubMed   PubMed Central   Google Scholar   Download references Acknowledgements We thank Na Li and volunteers at Shenzhen Institute of Advanced Technology (SIAT) for stool sample collection. We thank Zepeng Qu and Zhenkun Zhang for isolating human gut bacterial strains. We thank Prof. Jiachao Zhang at Hainan University for providing probiotic strains. We thank Huaijie Hao and Yan Tan at Xbiome for providing help with the anaerobic workstation. We thank Shenzhen Infrastructure for Synthetic Biology and Chaobi Lei for providing support in DNA extraction. We thank Zheng Sun, Chen Liao, Hongbin Liu, Lanxiang Wang, and colleagues at SIAT for valuable discussions. L.D. acknowledges support from the National Key R&D Program of China (2019YFA0906700), the National Natural Science Foundation of China (31971513), and Shenzhen Key Laboratory for the Intelligent Microbial Manufacturing of Medicines (ZDSYS20210623091810032). Y.-Y.L. is supported by grants R01AI141529, R01HD093761, RF1AG067744, UH3OD023268, U19AI095219 and U01HL089856 from the National Institutes of Health, USA; a pilot grant from the Biology of Trauma Initiative of Broad Institute, USA; and the Office of the Assistant Secretary of Defense for Health Affairs, through the Traumatic Brain Injury and Psychological Health Research Program (Focused Program Award) under award no. (W81XWH-22-S-TBIPH2), endorsed by the Department of Defense, USA. L.W. acknowledges support from the National Natural Science Foundation of China (32100089). X.W.W. acknowledges the funding support from the National Institutes of Health (K25HL166208). Author information These authors contributed equally: Lu Wu, Xu-Wen Wang. Authors and Affiliations CAS Key Laboratory of Quantitative Engineering Biology, Shenzhen Institute of Synthetic Biology, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China Lu Wu, Zining Tao, Wenlong Zuo, Yu Zeng & Lei Dai Channing Division of Network Medicine, Department of Medicine, Brigham and Women\u2019s Hospital and Harvard Medical School, Boston, MA, USA Xu-Wen Wang, Tong Wang & Yang-Yu Liu Shandong Agricultural University, Tai\u2019an, China Zining Tao Center for Artificial Intelligence and Modeling, The Carl R. Woese Institute for Genomic Biology, University of Illinois at Urbana-Champaign, Champaign, IL, USA Yang-Yu Liu University of Chinese Academy of Sciences, Beijing, China Lei Dai Contributions L.D., Y.Y.L., L.W., and X.W.W. conceived the presented idea, designed the project, interpreted the results, and wrote the manuscript. X.W.W. implemented in silico simulations, machine learning models, and analytical derivations. L.W. and Z.T. performed the in vitro experiments. Y.Z. assisted in experiments. L.W. analyzed the experimental data. T.W. discussed the results and revised the manuscript. W.Z. assisted in data analysis and interpretation. All authors approved the final manuscript. L.D. and Y.Y.L. provided supervision and resources for this study. Corresponding authors Correspondence to Yang-Yu Liu or Lei Dai. Ethics declarations Competing interests The authors declare no competing interests. Peer review Peer review information Nature Communications thanks the anonymous reviewers for their contribution to the peer review of this work. A peer review file is available. Additional information Publisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Supplementary information Supplementary Information Reporting Summary Supplementary Data 1 Supplementary Data 2 Description of Additional Supplementary Files Peer Review File Source data Source data Rights and permissions Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. Reprints and permissions About this article Cite this article Wu, L., Wang, XW., Tao, Z. et al. Data-driven prediction of colonization outcomes for complex microbial communities. Nat Commun 15, 2406 (2024). https://doi.org/10.1038/s41467-024-46766-y Download citation Received 07 July 2023 Accepted 08 March 2024 Published 16 March 2024 DOI https://doi.org/10.1038/s41467-024-46766-y Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Subjects Microbial communities Machine learning Microbial ecology Comments By submitting a comment you agree to abide by our Terms and Community Guidelines. If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate. Download PDF Sections Figures References Abstract Introduction Results Discussion Methods Data availability Code availability References Acknowledgements Author information Ethics declarations Peer review Additional information Supplementary information Source data Rights and permissions About this article Comments Advertisement Nature Communications (Nat Commun) ISSN 2041-1723 (online) About Nature Portfolio About us Press releases Press office Contact us Discover content Journals A-Z Articles by subject Protocol Exchange Nature Index Publishing policies Nature portfolio policies Open access Author & Researcher services Reprints & permissions Research data Language editing Scientific editing Nature Masterclasses Research Solutions Libraries & institutions Librarian service & tools Librarian portal Open research Recommend to library Advertising & partnerships Advertising Partnerships & Services Media kits Branded content Professional development Nature Careers Nature Conferences Regional websites Nature Africa Nature China Nature India Nature Italy Nature Japan Nature Korea Nature Middle East Privacy Policy Use of cookies Your privacy choices/Manage cookies Legal notice Accessibility statement Terms & Conditions Your US state privacy rights \u00a9 2024 Springer Nature Limited",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "Evolving linguistic divergence on polarizing social media",
    "doi": "10.1057/s41599-024-02922-9",
    "description": "Language change is influenced by many factors, but often starts from synchronic variation, where multiple linguistic patterns or forms coexist, or where different speech communities use language in increasingly different ways. Besides regional or economic reasons, communities may form and segregate based on political alignment. The latter, referred to as political polarization, is of growing societal concern across the world. Here we map and quantify linguistic divergence across the partisan left-right divide in the United States, using social media data. We develop a general methodology to delineate (social) media users by their political preference, based on which (potentially biased) news media accounts they do and do not follow on a given platform. Our data consists of 1.5M short posts by 10k users (about 20M words) from the social media platform Twitter (now \u201cX\u201d). Delineating this sample involved mining the platform for the lists of followers (n = 422M) of 72 large news media accounts. We quantify divergence in topics of conversation and word frequencies, messaging sentiment, and lexical semantics of words and emoji. We find signs of linguistic divergence across all these aspects, especially in topics and themes of conversation, in line with previous research. While US American English remains largely intelligible within its large speech community, our findings point at areas where miscommunication may eventually arise given ongoing polarization and therefore potential linguistic divergence. Our flexible methodology \u2014 combining data mining, lexicostatistics, machine learning, large language models and a systematic human annotation approach \u2014 is largely language and platform agnostic. In other words, while we focus here on US political divides and US English, the same approach is applicable to other countries, languages, and social media platforms.",
    "journal": "Humanities and Social Sciences Communications",
    "authors": [
      "Karjus A.",
      "Cuskley C."
    ],
    "citation_count": "0",
    "full_text": "Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Advertisement View all journals Search Log in Explore content About the journal Publish with us Sign up for alerts RSS feed nature humanities and social sciences communications articles article Article Open access Published: 15 March 2024 Evolving linguistic divergence on polarizing social media Andres Karjus & Christine Cuskley  Humanities and Social Sciences Communications  11, Article number: 422 (2024) Cite this article 357 Accesses 4 Altmetric Metrics Abstract Language change is influenced by many factors, but often starts from synchronic variation, where multiple linguistic patterns or forms coexist, or where different speech communities use language in increasingly different ways. Besides regional or economic reasons, communities may form and segregate based on political alignment. The latter, referred to as political polarization, is of growing societal concern across the world. Here we map and quantify linguistic divergence across the partisan left-right divide in the United States, using social media data. We develop a general methodology to delineate (social) media users by their political preference, based on which (potentially biased) news media accounts they do and do not follow on a given platform. Our data consists of 1.5M short posts by 10k users (about 20M words) from the social media platform Twitter (now \u201cX\u201d). Delineating this sample involved mining the platform for the lists of followers (n\u2009=\u2009422M) of 72 large news media accounts. We quantify divergence in topics of conversation and word frequencies, messaging sentiment, and lexical semantics of words and emoji. We find signs of linguistic divergence across all these aspects, especially in topics and themes of conversation, in line with previous research. While US American English remains largely intelligible within its large speech community, our findings point at areas where miscommunication may eventually arise given ongoing polarization and therefore potential linguistic divergence. Our flexible methodology \u2014 combining data mining, lexicostatistics, machine learning, large language models and a systematic human annotation approach \u2014 is largely language and platform agnostic. In other words, while we focus here on US political divides and US English, the same approach is applicable to other countries, languages, and social media platforms. Similar content being viewed by others American cultural regions mapped through the lexical analysis of social media Article Open access 30 March 2023 The Russian war in Ukraine increased Ukrainian language use on social media Article Open access 10 January 2024 Political polarization of news media and influencers on Twitter in the 2016 and 2020 US presidential elections Article Open access 13 March 2023 Introduction All human languages change over time, as linguistic variants are discarded, innovated, and their meanings change. Most change likely stems from variation, whether geographical, cultural or social. Here we examine a division and source of variation intersecting these categories: political polarization. Social and political scientists have been increasingly concerned with the causes and alarming social effects of increasing media polarization and partisan segregation. While happening around the world, one country these effects appear to be particularly pronounced is the United States. The left-right divide has increased on the governmental level (Andris et al. 2015) but also in everyday life, affecting where Americans choose to live (Brown and Enos 2021; Mummolo and Nall 2017), how they raise their children (Tyler and Iyengar 2022), how they deal with misinformation (Gonz\u00e1lez-Bail\u00f3n et al. 2023; Petersen et al. 2023), and which daily cultural and material products they consume (Hetherington and Weiler 2018; Rawlings and Childress 2022). In the information space, besides the growing divergence of news media (Broockman and Kalla 2022; Jurkowitz et al. 2020; Muise et al. 2022), polarization and segregation effects have been observed in diverging public narratives about society and significant events (Demszky et al. 2019; Li et al. 2017), online knowledge curation (Yang and Colavizza 2022), as well as behavior on social media (Adamic and Glance 2005; Mukerjee et al. 2022; Rasmussen et al. 2022; Rathje et al. 2021). Social media does not exist in an online vacuum, meaning it can affect lives in the real world. For example, it has been shown that anti-refugee sentiment on Facebook predicts crimes against refugees in otherwise similar communities (M\u00fcller and Schwarz 2021), or that Twitter data like user network structure and message sentiment can predict results of future political elections (Jaidka et al. 2019). Content personalization algorithms on social media platforms can (intentionally or not) amplify or diminish the visibility of political camps and messaging; Husz\u00e1r et al. (2022) show that US right-leaning officials and news sources enjoyed more amplification on Twitter compared to the left. Division and change Political polarization may also have an effect on the evolutionary dynamics of language change, forming the basis for signals of in-group and out-group status (Albertson 2015), with the potential to lead to more dramatic language speciation over time (Andresen and Carter 2016). While American English varies naturally given the large geographic area and heterogeneous society it spans, it has been shown that there are growing linguistic differences that correlate with party affiliation in politicians (Azarbonyad et al. 2017; Bhat and Klein 2020; Card et al. 2022; Li et al. 2017; Wignell et al. 2020), as well as areas in the US with a strong left or right leaning (Grieve et al. 2018; Louf et al. 2023a). If such divergence is or will become large enough to feasibly lead to misunderstanding in communication, then it can contribute to further polarization, potentially creating a ratchet effect which in turn intensifies polarization. Therefore, understanding the dynamics of emerging linguistic variation is a crucial component in understanding and eventually working towards easing sociopolitical polarization before it reaches a tipping point (Macy et al. 2021). While intervention experiments have shown it is possible to steer people away from misinformation and polarizing narratives (Balietti et al. 2021; Broockman and Kalla 2022; Pennycook et al. 2021), their efficiency is contingent on the ability of groups to communicate in the first place. Some divergence in a given language may be attributed to natural linguistic drift mechanisms or topical fluctuations (Blythe 2012; Croft 2000; Karjus et al. 2020) taking different directions in groups with differing communicative needs (Karjus et al. 2021; Kemp et al. 2018), more so if they do not interact, and engage in different activities. Yet some lexical innovations and group-specific usages may be actively selected for. One such example is that of the \u201cdog whistle\u201d, as used in advertising or political communication: a word or phrase that is expected to mean one thing to the larger public, but carries an additional implicit meaning for a subset of the audience. For example, inner city can mean \u201cthe area near the center of a city\u201d, but also signal an area with social problems or certain racial concentration. The finger gesture previously commonly meaning \u201cokay\u201d or \u201call good\u201d has been appropriated by the far-right (see Albertson 2015; Bhat and Klein 2020; Khoo 2017). Such expressions can be used to circumvent censorship and moderation and convey messages that would be otherwise deemed unfit for publication, including hate speech. Online media as a data source In this contribution, we map and quantify linguistic divergence along the left-right political divide \u2014 focusing on American English and lexical and semantic variation \u2014 using a corpus of posts mined from the social media platform Twitter (at the time of writing, Twitter is in the process of being renamed to \u201cX\u201d, but is still operational at www.twitter.com). The data was collected between February and September 2021. Twitter data \u2014 while subject to a number of issues discussed below \u2014 has been shown to be useful for mapping lexical variation and innovation and other socio-cultural processes (Alshaabi et al. 2021; Ananthasubramaniam et al. 2022; Bhat and Klein 2020; Donoso and S\u00e1nchez 2017; Dzogang et al. 2018; Grieve et al. 2018; Robertson et al. 2020, 2021) and analyzing polarization dynamics (An et al. 2012; Chen et al. 2021; Rathje et al. 2021). Studies of linguistic divergence between political divides have often focused on politicians and activists (Adamic and Glance 2005; Gentzkow et al. 2019; Li et al. 2017). Here we are interested in everyday language by regular speakers, to the extent it can be inferred from social media. The variation and potential underlying mechanisms we seek to quantify in this contribution is of course just one dimension of linguistic variation within a given language. American English, like other languages, also varies across geography (referred to as \u201cdialects\u201d), cultural and social classes and groups (\"sociolects\u201d), other demographics like race, age and gender; and finally, no speaker expresses themselves exactly like another (\"idiolects\u201d). The variation we describe here may well correlate with such dimensions, because political alignment correlates with many of these dimensions, such as geography (\"red states\u201d and \u201cblue states\u201d). More than anything, our results are complementary, not competing with analyses focusing on other dimensions. If geography or age describes a portion of variance in, for example, differences in usage frequencies (Fig. 3 below), then that rather helps piece together puzzles of linguistic variation. As our corpus covers only a few months, we do not approach it as diachronic data, but rather seek to quantify what constitutes a potential evolutionary mechanism in the form of socio-political divergence in apparent time (Bailey et al. 1991). While we base our inferences on public social media data, there are of course other media channels which can and have been studied. For example, Muise et al. (2022) argue that US television audiences are much more partisan-segregated than social media users, despite shrinking TV news audiences. Not all social media behavior is public or accessible either. The advantage of Twitter, compared to some other popular platforms at the time of data collection, was that the public-facing behavior of users (tweets but not private messages) could be easily observed and collected. However, Lobera and Portos (2022) show that platform or communication channel choice can also differ along partisan lines, showing how right-wing supporters in Spanish 2015 elections were more likely to use direct private messaging services for political persuasion activities than the left, who used both public social media and private channels. The approach we describe can be readily adapted to other social media platforms which facilitate data collection and where users post messages and \u201cfollow\u201d or otherwise interact with other accounts. Furthermore, Mukerjee et al. (2022) caution against overestimating the political nature of social media, arguing that \u201cordinary Americans are significantly more likely to follow nonpolitical opinion leaders on Twitter than political opinion leaders\u201d. However, here we focus on corpora of Twitter tweets posted by two groups of users (see Methods) who either follow left-leaning news outlets and not right-leaning ones (likely \u201cleft-leaning users\u201d) or right leaning news outlets and not left ones (likely \u201cright-leaning users\u201d). We consider this a proxy for political preference. It has been argued that using \u201cpurely correlational evidence from large observational [social media] datasets\u201d is risky and prone to spurious results (Burton et al. 2021). Indeed, complimenting \u201cbig data\u201d evidence with other approaches has proven fruitful (Kaiser et al. 2022). In line with this view, we complement machine learning driven findings with a smaller scale annotation exercise probing the perceived meaning of a subset of words and emoji using human annotation. Our contribution is both methodological and exploratory. We build on previous research and operationalize the bias of large news media outlets to delineate right-leaning and left-leaning subcorpora of a large sample of tweets. We exemplify how a combination of unsupervised, mostly language-agnostic statistical and machine learning driven methods (including generative large language models or LLMs), enhanced by systematic data annotation, can be used to make sense of large quantities of textual social media data to estimate linguistic divergence between polarizing communities. The product of applying these methods is a mapping of lexical and semantic similarities and differences between the \u201cleft\u201d and \u201cright\u201d in the United States \u2014 in terms of topics of conversation, usage frequencies of words and emoji, estimated sentiment, and the potentially diverging meaning of everyday words. This allows us to estimate an answer to the question of how much English in the US has diverged across the left-right divide. We find that there is notable divergence in topics and themes of conversation, but also to some extent in lexical semantics. Methods and materials Our dataset is a corpus of 1,483,385 short posts (or \u201ctweets\u201d) and roughly 20 million words on the social media platform Twitter, posted by 10,986 unique users from the United States, between February and September 2021. In the sections below, we describe how these users were selected (2.1), with particular attention to the media bias categories which determined whether tweets were categorized as \u201cright-leaning\u201d or \u201cleft-leaning\u201d (2.2). Before presenting our analysis of the final dataset, we describe criteria for excluding individual tweets and pre-processing of the corpus to exclude some aspects of the data (e.g., hashtag symbols, links, audiovisual data; see (2.3)). Sampling users on Twitter Users were selected using the following criteria: 1. User must follow accounts in one media outlet category to the exclusion of accounts in the other category (detailed in Categorizing media outlets, below) 2. User must self-identify as being in the US, as indicated by the Twitter API. Users who did not mention a location and have geolocation settings disabled were excluded. 3. User must be reasonably active, operationalized as: their account being created no later than February 2021, and having tweeted at least 10 times during the observation period. 4. User must have some engagement with other users: following at least 10 accounts, being followed by at least 5 accounts, and their tweets having a likes to tweets ratio above a threshold of 0.03. Using a ratio in the final step rather than a raw count allowed us to include users across the spectrum of popularity and volume of activity - users included in the dataset may have had as little as ten tweets and three likes during the observation period, but this also ranged into the thousands. While we placed no upper limit on the like to tweet ratio, tweets within each user profile were ranked by engagement (sum of likes and retweets; in the case of ties, preferring longer tweets) and only the 700 highest ranked tweets by any individual user were included. This ensured our sample was not dominated by individual super users (32 users with that maximum number of tweets remain in the sample). Overall, this resulted in a total of 11,071 users in the US. Below, we turn in more detail to the first constraint outlined above, before detailing further text cleaning procedures which removed a further 85 users from the sample, resulting in a final sample of 10,986 users. Categorizing media outlets Previous research using social media data to examine political bias has used various strategies to assign a political category to users. Some research uses self-identification, for example by focusing on prominent individuals or smaller samples of prolific public figures with already known political affiliation (Chin et al. 2022; Penelas-Legu\u00eda et al. 2023; Wignell et al. 2020; Xiao et al. 2022), or collecting data from defined subsections of platforms or discussion forums as the niches or samples of interest (Altmann et al. 2011; Soliman et al. 2019; Stewart and Eisenstein 2018). Other approaches rely on user characteristics or behavior, using geographical region where geo-location is available (Louf et al. 2023a, Louf et al. 2023b), sampling data by topically relevant keywords or hashtags (Chen et al. 2021; Demszky et al. 2019; Oakey et al. 2022), categorizing user-generated content (Fraxanet et al. 2023) or clustering networks built from retweeting/reposting or follower data (Conover et al. 2011). Here, we use the general strategy of delineating users based on what kinds of other accounts they follow or interact with on social media (An et al. 2012; Falkenberg et al. 2023; Sylwester and Purver 2015; Wang et al. 2017). We extend this approach in the following way (elements specific to our study in brackets): 1. Use a defined set of (US) news media organizations, categorized by political bias (AllSides); 2. Find their accounts on the platform of interest (Twitter); 3. Mine their full lists of followers; 4. Group these follower users according to which accounts they do but also do not follow; 5. Mine the posts (tweets) of these users, yielding a subcorpus of text for each group. We use the AllSides media bias rankings (AllSides 2021) as a basis to categorize news sources in terms of their political bias (version 4, current at the start of the data collection in 2021; see Fig. 1. AllSides media bias rankings are based predominantly on multipartisan editorial review of media outlets combined with an annual, large-scale bias survey of thousands of people in the US from across the political spectrum (AllSides 2022). We focus here on the subset of prominent media outlets featured in AllSides\u2019 yearly \u201cMedia Bias Chart\u201d, which categorizes outlets into \u201cleft\u201d, \u201clean left\u201d, \u201ccenter\u201d, \u201clean right\u201d and \u201cright\u201d. We identified 72 Twitter accounts representing these outlets, listed in the Supplementary Information (note that some outlets have more than one account). Fig. 1 The follower counts of the 72 news accounts on Twitter, grouped and arranged according to their corresponding AllSides (2021) media bias ranking, as left, lean left, center, lean right, and right (alphabetically within each group). The account username is displayed on the axis, the full display name on the bars. Full size image We use these accounts to categorize users in the following way. First, we assume that following an account is an indication of preference for a news source, as following (essentially subscribing to) somebody, on a live feed-centric platform like Twitter, makes it considerably more likely to be exposed to their content on the platform. In itself, this is unlikely to be a good proxy for political preference: for example, many left-leaning users may follow left-leaning outlets and right-leaning outlets, in order to see ongoing discourse on the \u201cother side\u201d. However, the premise of our categorization includes an additional criterion: a user who follows left-leaning outlets and only left-leaning outlets is likely to be tweeting within left-leaning circles on the platform (likewise, a user who follows right-leaning outlets to the exclusion of left-leaning ones is likely to be tweeting within right-leaning circles). In short, a user following certain news sources with bias A, but not others with bias B, is taken as proxy indicating the user\u2019s activity sits more in sphere A than sphere B. We define the \u201cleft\u201d aligned group (colored blue in the graphs) as users who follow at least two accounts in the AllSides \u201cleft\u201d category, but do not follow any accounts in any other category. We define the \u201cright\u201d aligned group (colored red in the graphs) as users who follow at least two accounts across the \u201clean right\u201d and \u201cright\u201d categories, but do not follow accounts in any other category. The color choices here are aligned with general conventions widely used in reporting and visualization about US politics. Note that this may seem unintuitive particularly to readers familiar with other political systems (e.g., particularly UK political contexts, where Labour [left] is generally red, and the Conservatives [right] are generally blue). The reason for this slightly asymmetric grouping \u2013 the inclusion of both \u201cright\u201d and \u201clean right\u201d outlets, but only \u201cleft\u201d outlets \u2013 is illustrated in Fig. 1: more left-aligned accounts from the ranking are represented on Twitter, with more followers on average. This may be related to findings that Twitter users overall are more left-leaning (Pew Research Center 2020; Wojcik and Adam 2019), despite the fact that Twitter\u2019s own research shows that right leaning content is more likely to get promoted algorithmically (Husz\u00e1r et al. 2022). Additionally, the boundary between \u201clean right\u201d and \u201cright\u201d is perhaps more porous, evident for example from the movement of Fox News from the \u201clean right\u201d to \u201cright\u201d category in subsequent (2022) iteration of the Media Bias Chart. Note that we only consider larger outlets categorized by AllSides: a user may follow smaller news accounts not considered in our categorization process. This approach allows us to contrast two subcorpora of tweets with fairly clear and opposing preferences in news sources, and excludes people who consume a balanced news diet or atypical users such as journalists who may follow accounts across the spectrum for professional purposes. One downside of this approach is that it requires mining entire follower lists to be able to execute the set operations described above (the does-not-follow part in particular) \u2014 which can be time-consuming, depending on their size and data access speeds of a given platform or API. Then again, this can be entirely automated. Some lists in our sample are quite large, e.g. CNN had 54 million followers at the time of data collection. An upside of the approach is that it allows for starting from users (and then mining their posts and data), instead of requiring the entire corpus of content to be acquired or mined beforehand (cf. Fraxanet et al. 2023). Overall, our implementation churned through the follower lists of the 72 media accounts (totaling 422,607,872 user listings) for about a month between June and July 2021. Using the user-based constraints described here and above, in addition to tweet-based constraints described in more detail below, this yielded two roughly equal subcorpora of 750,180 tweets by 6201 left-leaning users and 733,205 tweets by 4785 right-leaning users. While tailored here for the Twitter platform and its limitations and affordances, Twitter/X recently restricted access to its research API in ways that will have consequences throughout social science (Ledford 2023), including placing limits on the direct replicability of the current study. However, we emphasize that this general approach outlined here is in principle applicable to any kind of (social) media data where the following can be identified: (A) An entity or group of entities with an identifiable polarity or bias of interest, and a large enough following or subscriber base (e.g. news sources, popular social media accounts, platforms, forums, etc.) (B) The audience, as identifiable users or subscribers. (C) Identifiable links between (A) and (B) in the form of following status, subscription, membership, frequent interaction, etc. Tweet selection and text filtering The profiles of users meeting the criteria described above were mined for tweets written by the user between February and early September 2021 (including tweets, quote tweets and replies). First, tweets which were not written in English according to the Twitter API were automatically excluded. In addition, irrelevant parts of tweets were modified, or irrelevant tweets were excluded from the dataset based on the following: 1. Formulaic uninformative elements of tweets (e.g., AM-PM times of the day, URLs, and tagged usernames indicated by the @-symbol) were removed. 2. Punctuation was removed from tweets (except punctuation-based emoticons). 3. Hashtags were treated as normal text, i.e., leading # removed. 4. Sequences of whitespace greater than a single character were replaced with a single space, and variation in the use of case was removed; all text was converted to lower case. 5. Variable-length internally reduplicative expressions (e.g. hahaha, hmmm) were set to uniform lengths. 6. Audiovisual information (e.g., images, videos) was removed from all tweets. 7. Modifier symbols (gender, hair and skin tone) were stripped from emoji. 8. Tweets containing keywords associated with automated content (e.g. people activating automated services like the \u201cThreadReaderApp\u201d or \u201cRemindMeOfThis\u201d bots via tweet) were excluded. Each of these steps was a deliberate choice to make the data feasible to use, and we briefly justify some of these choices here. First, URLs, tagged user names, and times do not reliably contain lexical or semantic information and were thus removed as they were unrelated to our aims in analysis. As we are primarily interested in the lexicon and not syntax, punctuation is removed from the processed tweets (except punctuation-based emoticons). We removed the hashtag # symbol, but retained the text of the tags in place. While hashtags sometimes follow the body of a tweet, in other cases they are used to tag words within usual sentence structure - we retained the text of hashtags in order to retain sentence structure where this is the case, and we assume the meaning of a word with or without a hashtag to be roughly the same. Given the moderate size of our corpus, we chose not to consider variation in case, focusing instead on lexical and semantic variation. Making variable length expressions like hahaha and hmmm uniform in length allowed us to consider their use across groups more effectively. Including all esthetic variations of emoji would greatly increase the complexity of comparisons, and our corpus is of rather moderate size. Given our aim to detect general semantic patterns, this variation was removed. This topic has been investigated elsewhere however: Robertson et al. (2020) show that skin-modified emoji constitute only a minor share of emoji usage on Twitter, is largely self-representational; and that negative usage when referring to others is rare. Finally, a handful of accounts with anomalous tweets were removed from the dataset (i.e. those repeatedly posting identical or promotional tweets; 85 users and all their total of 17,692 tweets, including the anomalous and all other tweets). Prior to all these filtering steps, the corpus had 21,327,634 million whitespace-separated tokens with a type-to-token ratio (TTR) of 0.05, meaning that for every hundred tokens there were approximately five distinct word types, which is very high. For comparison: the 2016-2017 segment of the written part of the Corpus of Contemporary American English (Davies 2008) is 18.6M words; TTR for its lemmatized version is 0.008 and unlemmatized 0.01. After filtering, cleaning and lemmatizing, our final corpus came down to 20,357,194 tokens with a TTR of 0.01, consisting of 1,483,385 tweets from 10,986 users. Lemmatization While most people might think the question of what it means to be a word is a trivial one, linguists disagree substantially on what counts as a word or term for comparative purposes, and on how this should be operationalized in different contexts (Dixon and Aikhenvald 2003; Haspelmath 2011). Nonetheless, this is often not given much attention in computational lexical semantic change literature, which often relies on more or less white space-based tokenization (Feltgen et al. 2017; Hamilton et al. 2016; Schlechtweg et al. 2020). However, using simply tokenized raw text risks losing key lexical and semantic relatedness between similar strings, for example, that both runs and running are uncontroversially instances of the verb to run. Lemmatization is the process of stripping strings of morphological inflection and collapsing them in terms of their root form, in order to detect string tokens which might share a root lexical form. For example, both runs and running are instances of the root run. This process is often used for lexical and semantic analyses, as it allows the detection of similarity between e.g., runs and running, that would otherwise be lost with pure white space tokenization. In particular, this process allows us to make more accurate frequency estimates of root lemmas (by e.g., summing the frequency of runs and running alongside ran,run etc). Overall, we use the term \u201cword\u201d to refer to various meaningful units: words in the dictionary sense, proper nouns, hashtags, emoji, emoticons, and the concatenated collocations. However, lemmatization suits our main goal of ultimately comparing semantic concepts (such as the activity of running, regardless of whether it is expressed as a noun or a verb), rather than morpho-syntax, particularly for our topic, word frequency and semantic divergence analyses (for sentiment analysis and the annotation task, the text was not lemmatized). Here, we use the English-specific tools in the Python spacy library (v3.0.3 Honnibal and Montani 2017) for tokenization (separation of strings, e.g. by white space) and lemmatization. Word embeddings First, we use word embeddings to estimate semantic divergence across the entire lexicon represented in our corpus. \u2019Semantic divergence\u2019 quantifies the extent to which a single lexical item is used in different ways; between two or more communities (as represented by corpora). High semantic divergence means a given word is used in different senses in the different groups or communities. Specifically, we aim to explore whether semantic divergence occurs between right-leaning and left-leaning tweets within our corpus. Following previous research, we use a type-based model which assigns a fixed vector to each word (fastText, essentially word2vec with subword information; Bojanowski et al. 2017). This consists of training two separate embeddings on the left-leaning and right-leaning subcorpora, then normalizing and aligning the vectors (using the Orthogonal Procrustes approach; cf. Hamilton et al. 2016; Schlechtweg et al. 2019). Divergence is estimated via pairwise cosine similarity in the aligned embedding: high similarity across aligned embeddings indicates low semantic divergence, while low similarity indicates high divergence. This approach performs well in detecting diachronic lexical semantic change (Schlechtweg et al. 2020) which is analogous to our case of detecting synchronic divergence. Type-based embeddings are easy to implement and interpret, yet have been shown to outperform more recent resource-intensive models in these kinds of tasks (e.g., BERT-like token-based approaches driven by pretrained LLMs; but cf. Kutuzov et al. 2022; Rosin and Radinsky 2022). For both word embeddings and frequency comparisons, we exclude words with infrequent usage in the comparison: a word must occur at least 100 times in both the left-leaning and right-leaning subcorpora to ensure reasonably reliable semantic inference. This leaves 3582 words (lemmas) and emoji. We optimize the training hyperparameters by maximizing the average of self-similarity of words between the two embeddings (after the alignment step). The assumption is that since this is still the same language, most word pairs should have similar vectors. The final models have dimensionality of 50, window size 5, minimal frequency of 5, and 5 training epochs (training for too long easily leads to overfitting and weakly aligned embeddings, likely due to the moderate size of the dataset). Semantic annotation by humans and machines We use a human annotation to evaluate the perceived semantic divergence of a subset of words and emoji detected by the model as being particularly divergent. Unsupervised machine learning approaches, such as the model described above, are difficult to evaluate in terms of their accuracy. In the case of word embeddings, the model results may reflect genuine semantic (dis)similarity, and/or rather variation in context. Compared subcorpora may also diverge considerably in discussed topics. While training our models from scratch sidesteps the issue of possible biases of large pre-trained models, they may be susceptible to frequency biases (Wendlandt et al. 2018) and sensitive to parameterization. Tests on our data with different training parameters, for example, yielded slightly different results in terms of most divergent words. We therefore select a subset of words and emoji for model validation, using both human and LLM-driven annotation. This takes the form of a semantic annotation exercise adapted from the DURel framework (Blank 1997; Schlechtweg et al. 2018). The advantage of this annotation framework, originally demonstrated on diachronic data tasks (Schlechtweg et al. 2018) but equally applicable here, is that it does not require the annotators to be speakers of the specific variety, just proficient speakers of the language the variety comes from or is closely related to. Annotators are presented with pairs of sentences or passages where the target word of interest occurs. The task is to rate the similarity of the two occurrences of the target word, given their contexts, on a scale of 1 (unrelated) to 4 (identical meaning). Manipulating the subcorpus from which each sentence in a pair is drawn allows for the estimation of both (dis)similarity or divergence (scores of example sentences from different subcorpora) and in-group \u201cpolysemy\u201d or semantic variation (scores of examples from the same subcorpus). This is informative, as the combined results indicate if a given word usage differs on average between subcorpora just because it is polysemous and its different senses are just used with different frequencies \u2014 or, if a given target word refers (only) to different, unrelated concepts (due to semantic divergence across groups represented by the subcorpora; more akin to homonymy). In our exercise, both co-authors independently provided DURel scores for the test set of passages (partial tweets to speed up annotation; a context window of up to \u00b160 characters around the target). We evaluated 8 target words, 40 unique passages each, which were (randomly) combined to produce 20 left-right pairs, 10 left-left and 10 right-right pairs, for a total of 320 paired comparisons completed in a random order. When sampling the corpus for examples for this exercise, we only consider tweets with enough context (\u226570 characters and \u226510 words in length, TTR \u22650.6) and exclude those with irregular use patterns (ratio of the sum of 2 most frequent letters to total length <0.4; ratio of Capitalized words to uncapitalized <0.5). Target nouns are allowed to be in plural form, but not surrounded by hyphens, as these could be meaning-altering compounds. Tweets were randomly sampled from the remaining corpus, including a maximum of one tweet per user, preferring longer tweets to ensure roughly uniform stimuli lengths. In addition to this, we had a generative LLM complete the same task, exploring the feasibility of using current-generation LLMs to estimate divergence and act as data annotators (following Gilardi et al. 2023; Huang et al. 2023; Ziems et al. 2023). We use OpenAI\u2019s gpt-4-0613 model via its API (OpenAI 2023). This model is also referred to as \u201cGPT-4\u201d, which also powers the popular ChatGPT chatbot. We used the following prompt: \u201cThe target words in <x> tags in sentences A and B are spelled the same, but their meaning in context may be similar or unrelated (homonymy counts as unrelated, like bat the animal and bat in baseball). Rate meaning similarity, considering if they refer to the same object/concept. Ignore any etymological and metaphorical connections! Ignore case! Ignore number (cat/Cats\u2009=\u2009identical meaning). Output rating as: 1\u2009=\u2009unrelated; 2\u2009=\u2009distantly related; 3\u2009=\u2009closely related; 4\u2009=\u2009identical meaning. [followed by the two example passages]\u201d. Results Figure 2 depicts our corpus of tweets, colored by the estimated political alignment, arranged by semantic or topical similarity. Technically, this is a UMAP dimension reduction (McInnes et al. 2018) of a doc2vec (or paragraph2vec) text embedding (Le and Mikolov 2014). UMAP provides a two-dimensional topography of the full 50-dimensional embedding. The doc2vec model uses fasttext embeddings (Bojanowski et al. 2017) as input, here trained with the same parameters as the semantic models discussed in the Lexical-Semantic Divergences section below. This is an explorative topic model: tweets with similar contents are clustered together, and the clustering constitutes a topic landscape. The sporadic words and emoji on the graph are salient keywords (frequent in these topics, calculated via term frequency-inverse document frequency or TF-IDF scores) of local DBSCAN tweet clusters (the top2vec approach; cf. Angelov 2020). This allows for a first impressionistic birds-eye view of the entire corpus and the topical clusters within it. Fig. 2: A 1.5 million tweets authored in the US in 2021. Tweets on (a) are colored by estimated political alignment (blue is left-leaning, red is right-leaning). Tweets close together are semantically similar. Topical keywords have been plotted over dense clusters (colored similarly, by the share of red vs blue user tweets in the cluster). Some topics like food and birthdays are discussed regardless of political alignment. The blue areas stand out with everyday life topics (keywords like sleep, car, birthday). The top left blue corner are mostly bilingual tweets containing Spanish. Some political figures, religion and vaccination-related topics appear more popular in the right-leaning subcorpus. The inset (b) is a heatmap of the same UMAP, colored by the average estimated sentiment of the tweets (purple negative through gray neutral to green positive; see the \"Sentiment analysis\" section for details). The political tweet cluster in the bottom right again stands out as notably more negative. This map illustrates how groups of people of opposing political alignment in the US, while sharing some topics of conversation, noticeably diverge in others. Full size image While some areas of the topical map contain tweets from both sides (mix of blue and red dots), some predominantly red and blue areas are immediately visible. This indicates that the distribution of conversation topics is not entirely independent of political leaning. One way to quickly test this impression is to train and test a classifier to predict the (estimated) alignment of the author of each of the 1.5 million tweets. A prediction accuracy above chance would indicate a discriminable difference between the left and right-leaning subcorpora. We use a simple model, Linear Discriminant Analysis, with the 50 latent dimensions of the doc2vec model as the predictor variables. It is able to predict the previously estimated alignment of left or right (see Methods) with an accuracy of 64% (or 27% kappa score, on the roughly 50\u201350 class split; bootstrapped accuracy estimate). While this accuracy is far from perfect, it sits well above random chance, meaning that there is enough topical or usage divergence across users in each subcorpus to guess their news diet preferences (and by proxy, political preferences) with reasonable accuracy. It also mirrors previous research comparing tweet content (both text and images) of followers of Donald Trump and Hillary Clinton and reporting a similar classification accuracy (Wang et al. 2017). In the following sections, we investigate this in further detail by looking at usage frequencies, estimated sentiment and lexico-semantic divergence. Usage frequency differences Word frequencies in comparable corpora, differentiated by e.g. time period, genre or social group, can provide insight into the average usage patterns of the speakers whose utterances make up the data, including social media data, as shown in previous research (Grieve et al. 2018; Louf et al. 2023a). We employ the following operationalization to provide a straightforwardly interpretable overview of aggregated usage differences between our left-leaning and right-leaning subcorpora. To focus on words with reasonably reliable frequency estimates and to reduce possible effects of idiosyncratic usage, we simply filter the lexicon here to only include words which occur \u2265200 times in either subcorpus, \u2265300 times in total, used by \u2265200 users in total, with a users to token frequency ratio \u22650.05. For the comparison itself in Fig. 3, we use the number of tweets a word occurs in as the frequency, normalized by the number of tweets in the respective subcorpus. Tweet frequency instead of token frequency allows for the meaningful comparison of conventional words and emoji on the same scale \u2014 as the latter have reduplicative usage properties, unlike most words. For example, the laughing-with-tears emoji (top middle in Fig. 3) occurs in multiples, in about 42% of the tweets where it is present, whereas the median is 4% among short words (2-3 characters) and 3% among longer words. Fig. 3: Word usage frequency differences between the left and the right, February-September 2021. The difference is on a normalized \\({\\log }_{2}\\) fold scale, straightforwardly interpretable as multiplicative difference. The vertical axis reflects the overall frequency of a word, as percentage of users whose tweets contain it (clipped at 30%, as more frequent words like function words don't display large differences --- the two groups are still speakers of the same broad variety of English). The left-leaning corpus stands out with more non-standard e.g. sis, bestie, bruh, wanna and more emoji (\"sparkles'', various faces) --- with the exception of the \u201cclown'', \u201cpoo\u201d and the \u201cUS flag\u201d emoji. Political terms and names such as Biden, Democrats, liberal etc. are more frequent in the right-aligned corpus. Full size image The frequency difference metric in Fig. 3 is on the logarithmic scale (being more informative than linear given the Zipfian nature of word frequencies), as \\(lo{g}_{2}({f}_{{w}_{r}}/{f}_{{w}_{l}})\\), the logarithmic difference for each word, between the frequencies in the respective left- and right-leaning subcorpus. The binary logarithm value has the convenient advantage of still being interpretable as fold or multiplicative difference for integer values, e.g. the score of a word that is used in 200 tweets per million tweets in the right-leaning subcorpus, and 100 on the left, log2(200/100)\u2009=\u20091, is twice as frequent, log2(400/100)\u2009=\u20092 is 4\u00d7 more, etc. The words with the most different frequency distributions between the subcorpora tend to be political figures and politically charged terms for the right, and emoji for the left. Across all spellings i.e. lower and upper case, Joe Biden is used about 10 times more on the right (used by 674 users; as just Biden 9\u00d7, 1856 users out of the total of 10,986 users in the corpus). In general, as a reminder, we lowercased and lemmatized the corpus, so all frequencies discussed here refer to the sum of occurrences of a term that may or may not include various spellings and morphological variants such as singulars and plurals. Here and in the following, we will present some illustrative example data from our tweet corpus. To be on the safe side, these are however synthetic, either composite or rephrased examples, as publishing original tweets verbatim would make the users and therefore their inferred political leanings identifiable, which may be problematic. Despite being blocked from the platform in January 2021 following the events of January 6th, President Trump still appears in 1659 tweets in our corpus. The term appears almost 21 times more frequently in right-leaning tweets, but is nonetheless only used by a vocal minority of 496 users (<5% of our sample; 460 of them right-leaning) Other names and terms more frequent among the right include communist (17.4\u00d7 more on the right, 416 users total, 372 right-leaning), Fauci (11.7\u00d7 more on the right, 578 users in total, 514 right), liberal (11\u00d7, 924, 778 right), border (7.3\u00d7, 826, 652 right), America (3.2\u00d7, 2097 users, 1347 right-leaning). Again, it is clear that some frequencies may be driven by vocal users rather than large differences in users who would use a given word in general. Some (synthetic) examples include: \"The Democrats are not liberals, they are fascist totalitarian communists, there is nothing liberal about them\u201d, \"Beijing Biden is the one causing the Border Crisis. He is opening Our Borders to traffickers and killers\u201d, \"Happy birthday America! The beacon of freedom! #4thOfJuly #GodBless [US flag emoji]\u201d In the left-leaning subcorpus, we find several emoji which are more frequent than in the right-leaning subcorpus: the \u201csparkles\u201d (13.8\u00d7 more on the left; 631 users in total, 536-left-leaning), \u201ccrying face\u201d (7.4\u00d7, 1501, 1154 left), and the \u201cskull\u201d emoji (6\u00d7, 614 total, 475 left). In addition, we find several terms used more frequently in the left-leaning subcorpus: vibe (4\u00d7, 1087, 849 left), wanna (3\u00d7, 1520, 505 on the left), and additional vernacular usage by smaller groups such as sis (6.3\u00d7, 422 users total), tf and af (largely shorthands for the f*ck and as f*ck, 6\u00d7 and 3.6\u00d7 on the left, 435 and 686 users in total, respectively). Some synthetic examples: \"The best things in this life are not things. [sparkles] Grateful to you all for the smiles. #fridaymood\u201d, \"ppl really just be on their couch, no medical background, just sage and vibes, tryna disprove COVID. get vaxxed please [5 crying face emoji]\u201d, \"Haha sis don\u2019t play me like that\u201d. The only emoji used by more than 5% of the sample that are noticeably more frequent in the right-leaning corpus, are the \u201cclown face\u201d (2.1\u00d7) and the \u201cUS flag\u201d emoji (5.3\u00d7 more). Not all emoji are divergent in usage: the simple \u201cred heart\u201d, tweeted by 3073 users, appears only 1.3\u00d7 more on the left, while the \u201cbiceps\u201d muscle emoji and the \u201cface with rolling eyes\u201d (1207 and 1372 users total) occur almost equally on both sides. Sentiment differences Sentiment or emotional polarity in a corpus could be either interpolated from a manual analysis of a smaller sample, or inferred from rough estimate of a machine learning or statistical analysis of the entire dataset. We opt for the latter, employing the VADER (Valence Aware Dictionary for sEntiment Reasoning) model, due to its robust performance also on social media data (Hutto and Gilbert 2014). Its compound scores, based on the individual words and estimated valence, range in [\u22121,\u20091]. For example, the sentence \u201cThis is great!\u201d scores 0.66. Adding a smiley \u201c:)\u201d raises it to +0.81, while \u201cThis is not great!\u201d gets \u22120.51. To further illustrate the sentiment model, tweets like \u201cIs the gov really paying for this crap? all so FAKE all full of LIES :(\", and \u201cMy vote would never go to some senile old man! [4 screaming face emoji] Sorry for you though!!! [2 crying emoji]\u201d both get strongly negative scores below \u22120.9 (these and the following are synthetic examples, as above). This type of sentiment model, mapping text on an abstract negative-neutral-positive scale, has the downside of marking texts with potentially very different meaning and intention with a similar sentiment score, if the content includes words listed with a similar polarity in the model (while VADER does take negation into account, like all NLP models, it can misinterpret human sarcasm and irony). The upside is that its results are fairly straightforward to interpret, if its limitations are kept in mind (including the nature of the data the sentiment or stance is inferred from, cf. Joseph et al. 2021). The sentiment inset (b) in the overview Fig. 2 is based on the application of the VADER model. These results suggest that there might be differences in that aspect between the groups, as predominantly right-leaning areas of the topic map are also some of the more negative areas on the sentiment map. VADER scores both out-of-vocabulary words and those with neutral sentiment as zero, so here we exclude tweets consisting of solely zero-value word-scores (31% of the corpus; compound scores just averaging at zero are not excluded) for a more precise comparison. The results can be interpreted as differences between the groups in terms of tweets with a detectable polarity. The estimates of the model for all the remaining tweets in the corpus are arranged over time in Fig. 4a, and averaged per user in 4b. On average, both the red and blue US Twitter appear to be fairly stable over the course of 2021, on average staying more positive than negative. While tweets by both sides consistently cover the entire sentiment spectrum, the rolling average of tweets by right-aligned users appears to be slightly more negative (the red line staying below the blue one in Fig. 4a). Controlling for user variation using a mixed effect linear regression model with a random intercept for user, the right-side tweets are on average \u03b2\u2009=\u2009\u22120.07 lower than the left, p\u2009<\u20090.0001 compared to an intercept-only model (model assumptions are roughly met, although the dependent variable is bounded). Fig. 4: Estimated tweet and user average sentiment, negative to positive. Each dot on (a) is a tweet, colored blue for left and red for right (a small amount of vertical noise is added, as many short tweets would overlap due the averaging of word sentiment), superimposed by daily (thin lines) and weekly averages (thicker lines). b depicts the same data as distributions and their means. c depicts all the users in the sample, arranged on the y-axis by the average sentiment of their tweets (excluding neutral-only tweets; see text). Right-aligned users are slightly more negative on average. There is a small positive correlation between popularity (number of followers) and average sentiment, more pronounced among right-wing users. User dots are sized by the number of their tweets in our sample. This figure illustrates the two political sides are rather similar in their average social media sentiment, with a slight skew towards the negative among some smaller right-wing accounts. Full size image Figure 4b averages tweet sentiment for each user, and displays the size of their following. Besides the right being a bit more negative, as already apparent before, we find a small yet significant positive correlation between account popularity (\\({\\log }_{10}\\) number of followers) and averaged sentiment (linear regression, \u03b2\u2009=\u20090.06, p\u2009<\u20090.0001, R2\u2009=\u20090.03, i.e., positivity increases by about +0.06 with each order of magnitude of follower count). As indicated by the regression lines in Fig. 4b, this effect is somewhat more pronounced among right-wing users (positive interaction between side and followers, p\u2009<\u20090.0001, model R2\u2009=\u20090.06), possibly due to the negative less popular accounts dragging its average down. This is only a small correlation, and there is plenty of positive messaging among small accounts, as well as popular accounts with a near-neutral or negative average. In terms of users, variation is similar between the sides: the distributions of standard deviations of user sentiments are similar, with only a tiny albeit significant difference in mean (linear regression with side predicting standard deviation of each user\u2019s tweets, left as baseline, \u03b2\u2009=\u20090.02, p\u2009<\u20090.0001). Among the popular but negative accounts we find the account of a Republican politician with 19k followers (at the time of data collection in 2021) and an average estimated sentiment of \u22120.04. A negative sentiment estimate can stem from very different messages though. For the latter user, it includes language like the following (synthetic examples). \"Joe Biden is the President that every extremist, kidnapper, felon, arms dealer and child molester has always been dreaming of\u201d, and \"Terminating a pregnancy equals murder. They have chosen murder as their call to arms\u201d. For comparison, the tweets of another negative-averaging (\u22120.03) environmental journalist account with a similarly sized follower base includes text such as \u201c#Heat wave in Oregon, fatality count hits 106, a mass casualty incident. #Climate crisis could endanger billions due to #malaria and other viruses\u201d. While the lexicon-based sentiment may be similar, the content is obviously quite different. The largest account in our sample appears to belong to a sports coach with 1.6M followers, who is also among the most positive accounts at +0.7, tweeting mostly various congratulations and happy birthday wishes. Lexical-semantic divergence The previous sections dealt with frequencies of words, and sentiment as inferred from the frequencies of words with a certain polarity. We are also interested in the semantics of words, and in particular, if there are large enough discrepancies in the intended meaning of some words between the left- and right-leaning subcorpora for this to feasibly cause communicative misunderstanding, and therefore potentially fuel further polarization. We approach this using a combination of machine learning driven and qualitative annotation methods. Using a word embedding model, we can easily estimate the semantic difference between the left and right subcorpora for every word in the English lexicon that is represented and sufficiently frequent in our data (see Methods and materials). This complements previous work (on the English language) which has focused on a limited vocabulary of interest rather than the lexicon at scale (Bhat and Klein 2020), semantic and usage pattern differences between specific people (Li et al. 2017) or news sources (Spinde et al. 2021), and comparable diachronic research (Azarbonyad et al. 2017; Rodman 2020). Figure 5a depicts the results of applying the Procrustes-aligned fasttext embeddings approach. The vertical axis corresponds to Fig. 3, the share of users in the sample who use a given word, while the horizontal axis is the semantic divergence, measured as cosine distance (1-similarity) between the vectors of a given word in the aligned embeddings. The most divergent among the more frequent cases are a selection of facial emoji, terms like woke, bs (largely short for bullsh*t), left, lit (which can refer to lights but also mean \u201ccool, awesome\u201d), and the phrase wake up, which can be used literally or figuratively as as a rallying call to pay attention. Fig. 5: Semantic divergence between the left- and right-leaning subcorpora. This is quantified via word embeddings (a) and a human annotation exercise on a smaller subset of terms and emoji of interest (b). The word embeddings highlight a number of words that may be either used in differing senses, or at least in highly different contexts. Some of these are used by a small percentage of users (y-axis), while there appears to be divergence also among more frequent terms (e.g. woke, various laughing and crying emoji). The annotation results show that emoji are fairly monosemous and used in the same function (therefore likely just differ in context), while words like lit and woke are indeed used in different senses. The position of the words (averaged divergence scores across annotations; bars show standard errors) on the x-axis of is identical on the two subplots of (b), while the y-axis reflects polysemy within the respective subcorpora\u2014which is similar, but e.g. woke is more polysemous on the left, used to refer to both waking up and being alert to prejudice and discrimination. Full size image The human annotation results Fig. 5b are limited to a test set of 8 targets: the \u201claughing in tears\u201d emoji, the \u201cvomiting\u201d emoji, the \u201ccrying with tears\u201d emoji, the phrase wake up, and the words woke, energy, lit, and vet. Estimating these results required annotating 320 pairs of example passages; see Methods and materials). The scores depicted in Fig. 5b are a result of averaging the results of the two annotators, who had fairly high inter-rater agreement of \u03c1\u2009=\u20090.87 (measured here using Spearman\u2019s rho, given the ordinal scale). Both divergence and in-group polysemy are presented as an inverse of the DURel scale, representing how different (dissimilar usages between left and right) and how polysemous (dissimilar usages within left and right) the meaning of each target word is. Here more divergent words (across subcorpora) are also more polysemous (within their subcorpora), indicating that while the two sides use different senses, they are still mutually intelligible (this is not surprising given that this is still largely the same language, and also given how meaning extension likely works in diachrony, cf. Blank 1997; Ramiro et al. 2018). For example, when a right-aligned person uses the word vet, they are simply more likely to refer to a (military) veteran, and one on the left to their veterinarian, but both senses still exist on both sides. A complete divergence would be a word located in the bottom right of Fig. 5b \u2014 completely unrelated meanings, and no polysemy that would facilitate sense overlap. The annotation exercise also serves as a way to partially evaluate the word embedding driven results: \u03c1\u2009=\u2009\u22120.9,\u2009n\u2009=\u20098,\u2009p\u2009=\u20090.002. The negative correlation, indicating a mismatch, appears to be driven mostly by the emoji, which the embedding approach infers to be moderately divergent, yet human annotators see as fairly similar in usage. Furthermore, the annotation targets were selected from the diverging (right hand) side of Fig. 5a \u2014 the negative correlation is therefore informative about diverging words but not the entire embeddings. This result still highlights that cosine similarity derived from word embeddings captures not only semantic similarity but also contextual or topic differences. Emoji in particular are multi-functional elements that can be used to illustrate, modulate and change the meaning of a text. For example, we observe the \u201ccrying\u201d emoji being used to express sadness as well as happy tears; and the \u201cpuking\u201d emoji being used literally, to express sarcasm, as a noun, as a verb, and being used in lieu of letters inside a name (presumably to express sentiment towards the person). As such, unlike many words, emoji can occur in highly variable contexts and functions (without being constrained by syntactic rules like words). Where contexts differ, word embeddings and language models are likely to represent them with differing vectors. Previous research has attempted to infer semantic change in emoji using similar embedding methods (Robertson et al. 2021). We would therefore suggest that any such research involving emoji should additionally control for topical variation (cf. Karjus et al. 2020). This does is not to say the current result depicted in Fig. 5a is invalid or uninformative, but it may pick up on signals other than just lexical semantics. We also experimented with applying a pretrained large language model (GPT-4; OpenAI 2023) on the annotation task, prompting it with the same DURel annotation instructions to evaluate the semantic similarity of the target word on a 1\u20134 scale. We find that it achieves moderately good agreement with human annotators (\u03c1\u2009=\u20090.45 and 0.6 respectively). This is lower than the human inter-rater agreement \u2014 partially driven by the emoji, which are indeed difficult to evaluate, as well as to instruct how to evaluate. Nonetheless, without the three emoji, the agreement only rises to 0.54 and 0.66, relative to the 0.87 inter-rater agreement between human annotators. This underscores the limitations of using large language models for complex annotation tasks, and the need to evaluate their output. Example pairs that require interpreting the conveyed sense of the emoji can look like the following (synthetic examples as above): \"Now our sons are off to university. Imma miss the crew [crying emoji] but this was the goal all along...to get in and WE DID IT [heart emoji]\u201d, \"Discovering the hard way why the sauce I ate yesterday is named Red Dragon sauce. Pain pain pain [crying emoji]\u201d (emoji were presented in their original form in the annotation task). Other examples where humans can infer the difference but the LLM can fail are highly contextual, such as this pair: \"This guy is worried about the notion of white rage, he should really worry about vet rage. Soldiers have sacrificed lives and arms and legs for two decades now\u201d, \"We had a kitten brought in last night and she\u2019s struggling today. The follow-up at the vet earlier in the morning went fine, but condition deteriorated this evening.\u201d Regardless, these results are promising, especially given the difficulty of this contextually complex yet minimal-context task. Better models and better instructions may well edge the results closer to human performance, as they already have been in some other applications (Begu\u0161 et al. 2023; Gilardi et al. 2023; Huang et al. 2023; Karjus 2023). Still, the results illustrate the necessity to evaluate machine learning results against human evaluations, but also the potential of enhancing and scaling up the (otherwise highly laborious) human annotation processes using machine learning based tools. Discussion The results on divergence on topics of conversation echo previous research focusing on the differing daily lives of people in the US of opposing political alignment (Brown and Enos 2021; Hetherington and Weiler 2018; Rawlings and Childress 2022). While naturally many topics overlap, others are segregated, and there are a number of words being used several times more on one side compared to the other. On average, the two subcorpora are similar in tweeting sentiment, although we found a small (yet significant) effect of slightly more negativity on the right leaning subcorpus. The topics where negativity tends to occur appear to be predominantly political (see Fig. 2). We also probed lexical semantic divergence using two machine learning models and a systematic data annotation approach. This revealed that while there are some words, emoji and phrases with a diverging or at least variable meaning, the cases we tested via manual annotation exhibit differing distributions of sense usage in polysemous or homonymous word forms, rather than divergence in progress. This is not to say that given time, word senses in American English in the US may not diverge enough to begin to cause genuine misunderstanding. Limitations Our annotation exercise was limited to eight target words and two annotators (the authors). Provided sufficient resources, the DURel framework we used here lends itself well to be scaled up to a larger, potentially crowd-sourced online experiment (with care given the issues with such platforms, cf. Cuskley and Sulik 2022), that could shed light on the usage of more words across the dimensions of in-group polysemy and between-groups divergence. We also experimented with using one of the newest generative LLMs as a data annotator, with promising results of agreement with human annotators that does not fall far behind their inter-rater (dis)agreement. While the results of machine learning models (including LLMs) should be always be critically evaluated, we are reaching a point where they could be used in lieu of human annotators on larger, more tedious or costly tasks, where if the task is simple enough (which can, again, be evaluated using smaller human test sets). The dataset, consisting of written American English as used on a micro-blogging platform, of course has its limitations, including questions like how generalizable and representative of the given society and language it may be \u2014 in this case the United States, and US American English. Naturally, the demographics of users of an online platform like Twitter may not be representative of the society as a whole. A number of previous studies on political differences and polarization cited above have focused on high-profile personas such as politicians or influential opinion leaders, using their writings, speeches or social media content as data. We were interested in unedited natural language as used by regular people in everyday situations. Such naturalistic data is, however, hard to acquire in large volumes from offline usage \u2014 but relatively easy to mine from social media. We accept that language usage on Twitter may only represent a part of the linguistic repertoire and competence of speakers of a given language, and online language use as such may be situational and differ from person-to-person communication (cf. Joseph et al. 2021; McCulloch 2019). However, a case could be made that the only way to observe natural language data is inevitably to observe it in some variety or other; in our case it just happens to be the online one. Future research Data mining Twitter/X, while popular until recently in fields like computational social science, has become difficult given shifts in the platform\u2019s policies (Ledford 2023). As outlined in the Methods however, the proposed framework is in principle applicable to any platform or network where users and links between users can be identified and the data collected. Social media examples may include Reddit or other forum-type platforms (user groups could be grouped by subreddits or subforums they do and do not subscribe to), Wikipedia (e.g. editors grouped by domains where they do and do not edit), or any of the Twitter-like platforms that have emerged following the rebranding and other changes in Twitter, if their policies and infrastructure enables academic research. Follow-up work could look into aspects of potential differences across political divides other than just lexico-statistics and lexical semantics. While easily inferred from textual social media data, these are by no means the only avenues of variation in language. We focused on text, but it may be interesting to compare visual media like profile pictures (as a form of self-representation; Kapidzic and Herring 2015; Robertson et al. 2020), and posted images, memes or videos (scalable using machine learning just as textual data; cf. Beskow et al. 2020; Verma et al. 2020). More broadly, the same operational logic could be used to study other cultural and social domains where more or less complete user or participant data is available. For example, Zemaityte and Karjus et al. (2024) investigate a large dataset from a globally-used platform of film professionals and film festivals; the same approach could be used to delineate potentially diverging groups such as filmmakers (by which festivals they frequent and which they do not). Similarly, television production crews and groupings of individuals and the content they produce could be studied where complete production or historical databases are available (cf. Ibrus et al. 2023; Oiva et al. 2024). Finally, in the linguistic domain, it would be of particular interest to disentangle the relationships between the variation observed along political affiliations and the different sources of underlying natural variation (e.g. regional, as explored in the US and UK contexts by Louf et al. 2023a, Louf et al. 2023b), eventually both in varieties of English and other languages. If this would be possible, then it could be determined if some of the variation or divergence we observe here could be purely politically driven \u2014 as in, not an effect of regional or social differences, but use of in-group markers to express political leanings (cf. Albertson 2015). Conclusions We proposed an approach to delineate groups of users on social media according to their interaction statistics on a given platform, mined a large corpus of US American English language tweets from Twitter, and used a versatile combination of machine learning, lexico-statistical, and human data annotation methods to estimate and illustrate the extent of lexical and semantic differences in the language use of the left-leaning and right-leaning polarities in the US. While we focused here on one potential evolutionary mechanism, a single language and social media platform, we hope the general framework to be a useful contribution for data-driven computational research into language variation and change more generally. Data availability The code used to run the analyses is available at https://github.com/andreskarjus/evolving_divergence. Unfortunately, and exceptionally, at this time we cannot make neither the collected data nor the tweet or user IDs publicly available, in order to avoid potential conflicts with the current Terms of Service of the Twitter/X platform regarding potentially political and sensitive contexts. The data may be shared directly upon reasonable request. References Adamic LA, Glance N (2005) The political blogosphere and the 2004 U.S. election: Divided they blog. In Proceedings of the 3rd International Workshop on Link Discovery, LinkKDD \u201905. Association for Computing Machinery, pp 36\u201343 Albertson BL (2015) Dog-Whistle Politics: Multivocal Communication and Religious Appeals. Political Behavior 37(1):3\u201326 Article   Google Scholar   AllSides (2021) AllSides Media Bias Ratings, Version 4. Available from: https://www.allsides.com/media-bias/media-bias-ratings [Accessed 01.02.2021] AllSides (2022) AllSides February 2022 February 2022 Blind Bias Survey Whitepaper. Available from: https://www.allsides.com/blind-survey/feb-2022-blind-bias-survey [Accessed 01.09.2023]) Alshaabi T, Adams JL, Arnold MV, Minot JR, Dewhurst DR, Reagan AJ (2021) Storywrangler: A massive exploratorium for sociolinguistic, cultural, socioeconomic, and political timelines using Twitter. Sci Adv 7(29):eabe6534 Article   ADS   PubMed   PubMed Central   Google Scholar   Altmann EG, Pierrehumbert JB, Motter AE (2011) Niche as a determinant of word fate in online groups. PLOS One 6(5):1\u201312 Article   Google Scholar   An J, Cha M, Gummadi K, Crowcroft J, Quercia D (2012) Visualizing Media Bias through Twitter. Proc Int AAAI Conf Web Soc Media 6(2):2\u20135 Article   Google Scholar   Ananthasubramaniam A, Jurgens D, Romero DM (2022) Networks and Identity Drive Geographic Properties of the Diffusion of Linguistic Innovation. ArXiv preprint: http://arxiv.org/abs/2202.04842 Andresen JT, Carter PM (2016) Languages In The World: How History, Culture, and Politics Shape Language. John Wiley & Sons, UK Andris C, Lee D, Hamilton MJ, Martino M, Gunning CE, Selden JA (2015) The Rise of Partisanship and Super-Cooperators in the U.S. House of Representatives. PLOS One 10(4):e0123507 Article   PubMed   PubMed Central   Google Scholar   Angelov D (2020) Top2Vec: Distributed Representations of Topics. ArXiv preprint: http://arxiv.org/abs/2008.09470 Azarbonyad H, Dehghani M, Beelen K, Arkut A, Marx M, Kamps J (2017) Words are Malleable: Computing Semantic Shifts in Political and Media Discourse. In: Proceedings of the 2017 ACM on Conference on Information and Knowledge Management. ACM, pp. 1509\u20131518 Bailey G, Wikle T, Tillery J, Sand L (1991) The apparent time construct. Lang Var Change 3(3):241\u2013264 Article   Google Scholar   Balietti S, Getoor L, Goldstein DG, Watts DJ (2021) Reducing opinion polarization: Effects of exposure to similar people with differing political views. Proc Natl Acad Sci 118(52):e2112552118 Article   CAS   PubMed   PubMed Central   Google Scholar   Begu\u0161 G, D\u0105bkowski M, Rhodes R (2023) Large Linguistic Models: Analyzing theoretical linguistic abilities of LLMs. ArXiv preprint: http://arxiv.org/abs/2305.00948 Beskow DM, Kumar S, Carley KM (2020) The evolution of political memes: Detecting and characterizing internet memes with multi-modal deep learning. Inf Process Manag 57(2):102170 Article   Google Scholar   Bhat P, Klein, O (2020) Covert Hate Speech: White Nationalists and Dog Whistle Communication on Twitter. In: Bouvier G, Rosenbaum, JE (eds) Twitter, the Public Sphere, and the Chaos of Online Deliberation. Palgrave Macmillan, Cham. https://doi.org/10.1007/978-3-030-41421-4_7 Blank, A (1997). Prinzipien des lexikalischen Bedeutungswandels am Beispiel der romanischen Sprachen. Tubingen, Max Niemeyer Verlag. https://doi.org/10.1515/9783110931600 Blythe RA (2012) Neutral evolution: A null model for language dynamics. Adv Complex Syst, 15(3\u22124), pp 1150015 Bojanowski P, Grave E, Joulin A, Mikolov T (2017) Enriching word vectors with subword information. Trans Assoc Comput Ling 5:135\u2013146 Google Scholar   Broockman D, Kalla J (2022) The impacts of selective partisan media exposure: A field experiment with Fox News viewers. OSF preprint. https://doi.org/10.31219/osf.io/jrw26 Brown JR, Enos RD (2021) The measurement of partisan sorting for 180 million voters. Nat Hum Behav 5(8):998\u20131008 Article   PubMed   Google Scholar   Burton JW, Cruz N, Hahn U (2021) Reconsidering evidence of moral contagion in online social networks. Nat Hum Behav 5(12):1629\u20131635 Article   PubMed   Google Scholar   Card D, Chang S, Becker C, Mendelsohn J, Voigt R, Boustan L (2022) Computational analysis of 140 years of US political speeches reveals more positive but increasingly polarized framing of immigration. Proc Natl Acad Sci 119(31):e2120510119 Article   CAS   PubMed   PubMed Central   Google Scholar   Chen THY, Salloum A, Gronow A, Yl\u00e4-Anttila T, Kivel\u00e4 M (2021) Polarization of climate politics results from partisan sorting: Evidence from Finnish Twittersphere. Global Environ Change 71:102348 Article   Google Scholar   Chin A, Coimbra Vieira C, Kim J (2022) Evaluating Digital Polarization in Multi-Party Systems: Evidence from the German Bundestag. In: 14th ACM Web Science Conference 2022. ACM: Barcelona, Spain, pp 296\u2013301 Conover M, Ratkiewicz J, Francisco M, Goncalves B, Menczer F, Flammini A (2011) Political Polarization on Twitter. Proc Int AAAI Conf Web Soc Media 5(1):89\u201396 Article   Google Scholar   Croft W (2000) Explaining Language Change: An Evolutionary Approach. Longman, London Cuskley C, Sulik J (2022) The burden for high-quality online data collection lies with researchers, not recruitment platforms. OSF preprint. https://doi.org/10.31234/osf.io/w7qy9 Davies M (2008) The Corpus of Contemporary American English (COCA): 450 Million Words, 1990\u22122012. Available online at https://www.english-corpora.org/coca Demszky D, Garg N, Voigt R, Zou J, Shapiro J, Gentzkow M et al. (2019) Analyzing Polarization in Social Media: Method and Application to Tweets on 21 Mass Shootings. In: Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). Association for Computational Linguistics, Minneapolis, Minnesota, pp. 2970\u20133005 Dixon RMW, Aikhenvald AY (2003) Word: A Cross-linguistic Typology. Cambridge University Press, Cambridge Donoso G, S\u00e1nchez D (2017) Dialectometric analysis of language variation in Twitter. In: Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial). Association for Computational Linguistics, Valencia, Spain, pp. 16\u201325 Dzogang F, Lightman S, Cristianini N (2018) Diurnal variations of psychometric indicators in Twitter content. PLOS One 13(6):e0197002 Article   PubMed   PubMed Central   Google Scholar   Falkenberg M, Zollo F, Quattrociocchi W, Pfeffer J, Baronchelli A (2023) Affective and interactional polarization align across countries. ArXiv preprint: https://arxiv.org/abs/2311.18535 Feltgen Q, Fagard B, Nadal J-P (2017) Frequency patterns of semantic change: Corpus-based evidence of a near-Critical dynamics in language change. Open Sci, 4(11):170830 Fraxanet E, Pellert M, Schweighofer S, G\u00f3mez V, Garcia D (2023) Unpacking polarization: Antagonism and Alignment in Signed Networks of Online Interaction. ArXiv preprint: http://arxiv.org/abs/2307.06571 Gentzkow M, Shapiro JM, Taddy M (2019) Measuring Group Differences in High-Dimensional Choices: Method and Application to Congressional Speech. Econometrica 87(4):1307\u20131340 Article   MathSciNet   Google Scholar   Gilardi F, Alizadeh M, Kubli M (2023) ChatGPT outperforms crowd workers for text-annotation tasks. Proc Natl Acad Sci 120(30):e2305016120 Article   CAS   PubMed   PubMed Central   Google Scholar   Gonz\u00e1lez-Bail\u00f3n S, Lazer D, Barber\u00e1 P, Zhang M, Allcott H, Brown T (2023) Asymmetric ideological segregation in exposure to political news on Facebook. Science 381(6656):392\u2013398 Article   ADS   PubMed   Google Scholar   Grieve J, Nini A, Guo D (2018) Mapping lexical innovation on American social media. J Engl Linguist 46(4):293\u2013319 Article   Google Scholar   Hamilton WL, Leskovec J, Jurafsky D (2016) Diachronic word embeddings reveal statistical laws of semantic change. In: Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Volume 1: Long Papers, pp. 1489\u20131501 Haspelmath M (2011) The indeterminacy of word segmentation and the nature of morphology and syntax. Folia Linguist 45(1):31\u201380 Hetherington M, Weiler J (2018) Prius Or Pickup?: How the Answers to Four Simple Questions Explain America\u2019s Great Divide. Houghton Mifflin Harcourt Honnibal M, Montani I (2017) spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing. https://spacy.io/ Huang F, Kwak H, An J (2023) Is ChatGPT better than Human Annotators? Potential and Limitations of ChatGPT in Explaining Implicit Hate Speech. In: Companion Proceedings of the ACM Web Conference 2023, WWW \u201923 Companion. Association for Computing Machinery, pp 294\u2013297 Husz\u00e1r F, Ktena SI, O\u2019Brien C, Belli L, Schlaikjer A, Hardt M (2022) Algorithmic amplification of politics on Twitter. Proc Natl Acad Sci 119(1):e2025334119 Article   PubMed   Google Scholar   Hutto C, Gilbert E (2014) VADER: A Parsimonious Rule-Based Model for Sentiment Analysis of Social Media Text. Proc Int AAAI Conf Web Soc Media 8(1):216\u2013225 Article   Google Scholar   Ibrus I, Karjus A, Zemaityte V, Rohn U, Schich M (2023) Quantifying public value creation by public service media using big programming data. International Journal Of Communication, 17, 24. Available at https://ijoc.org/index.php/ijoc/article/view/21035 Jaidka K, Ahmed S, Skoric M, Hilbert M (2019) Predicting elections from social media: A three-country, three-method comparative study. Asian J Commun 29(3):252\u2013273 Article   Google Scholar   Joseph K, Shugars S, Gallagher R, Green J, Quintana Math\u00e9 A, An Z et al. (2021) (Mis)alignment Between Stance Expressed in Social Media Data and Public Opinion Surveys. In: Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Online and Punta Cana, Dominican Republic, pp. 312\u2013324 Jurkowitz M, Mitchell A, Shearer E, Walker M (2020) US media polarization and the 2020 election: A nation divided. Pew Research Center. Online report (www.pewresearch.org, accessed 22.01.2022) Kaiser J, Vaccari C, Chadwick A (2022) Partisan Blocking: Biased Responses to Shared Misinformation Contribute to Network Polarization on Social Media. J Commun 72(2):214\u2013240 Article   Google Scholar   Kapidzic S, Herring SC (2015) Race, gender, and self-presentation in teen profile photographs. New Media Soc 17(6):958\u2013976 Article   Google Scholar   Karjus A (2023) Machine-assisted mixed methods: Augmenting humanities and social sciences with artificial intelligence. ArXiv https://arxiv.org/abs/2309.14379 Karjus A, Blythe RA, Kirby S, Smith K (2020) Quantifying the dynamics of topical fluctuations in language. Lang Dyn Change 10(1):86\u2013125 Article   Google Scholar   Karjus A, Blythe RA, Kirby S, Wang T, Smith K (2021) Conceptual Similarity and Communicative Need Shape Colexification: An Experimental Study. Cognit Sci 45(9):e13035 Article   Google Scholar   Kemp C, Xu Y, Regier T (2018) Semantic Typology and Efficient Communication. Ann Rev Linguist 4(1):109\u2013128 Article   Google Scholar   Khoo J (2017) Code Words in Political Discourse. Philosophical Topics 45(2):33\u201364 Article   Google Scholar   Kutuzov A, Velldal E, \u00d8vrelid L (2022) Contextualized language models for semantic change detection: Lessons learned. Northern Eur J Lang Technol, 8(1) Le Q, Mikolov T (2014) Distributed representations of sentences and documents. In: Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32, ICML\u201914. Bejing, China, pp. II\u20131188\u2013II\u20131196 Ledford, H (2023). Researchers scramble as Twitter plans to end free data access. Nature News, 14 February 2023 Li P, Schloss B, Follmer DJ (2017) Speaking two \u201cLanguages\u201d in America: A semantic space analysis of how presidential candidates and their supporters represent abstract political concepts differently. Behav Res Methods 49(5):1668\u20131685 Article   PubMed   Google Scholar   Lobera J, Portos M (2022) The Private Is Political: Partisan Persuasion through Mobile Instant Messaging Services. Int J Public Opin Res 34(1):edab033 Article   Google Scholar   Louf T, Gon\u00e7alves B, Ramasco JJ, S\u00e1nchez D, Grieve J(2023a) American cultural regions mapped through the lexical analysis of social media Humanit Soc Sci Commun 10(1):1\u201311 Article   Google Scholar   Louf T, Ramasco JJ, S\u00e1nchez D, Karsai M (2023b) When Dialects Collide: How Socioeconomic Mixing Affects Language Use. ArXiv preprint: http://arxiv.org/abs/2307.10016 Macy MW, Ma M, Tabin DR, Gao J, Szymanski BK (2021) Polarization and tipping points. Proc Natl Acad Sci 118(50):e2102144118 Article   CAS   PubMed   PubMed Central   Google Scholar   McCulloch G (2019) Because Internet: Understanding the New Rules of Language. Riverhead books: New York McInnes L, Healy J, Saul N, Gro\u00dfberger L (2018) UMAP: Uniform Manifold Approximation and Projection. J Open Source Softw 3(29):861 Article   Google Scholar   M\u00fcller K, Schwarz C (2021) Fanning the Flames of Hate: Social Media and Hate Crime. J Eur Econ Assoc 19(4):2131\u20132167 Article   Google Scholar   Muise D, Hosseinmardi H, Howland B, Mobius M, Rothschild D, Watts DJ (2022) Quantifying partisan news diets in Web and TV audiences. Sci Adv 8(28):eabn0083 Article   PubMed   PubMed Central   Google Scholar   Mukerjee S, Jaidka K, Lelkes Y (2022) The Political Landscape of the U.S. Twitterverse. Political Commun 39(5):565\u2013588 Article   Google Scholar   Mummolo J, Nall C (2017) Why Partisans Do Not Sort: The Constraints on Political Segregation. J Politics 79(1):45\u201359 Article   Google Scholar   Oakey D, Jones C, O\u2019Halloran KL (2022) Phraseology and imagery in UK public health agency COVID-19 tweets. In: Discourses, Modes, Media and Meaning in an Era of Pandemic. Routledge: New York and Oxon Oiva M, Mukhina K, Zemaityte V, Ohm T, Tamm M, Karjus A et al. (2024) A framework for the analysis of historical newsreels. Humanities and Social Sciences Communications (to appear) OpenAI (2023) GPT-4 Technical Report. Available at https://cdn.openai.com/papers/gpt-4.pdf (visited on 03/17/2023) Penelas-Legu\u00eda A, Nunez-Barriopedro E, L\u00f3pez-Sanz JM, Ravina-Ripoll R (2023) Positioning analysis of Spanish politicians through their Twitter posts versus Spanish public opinion. Human Soc Sci Commun 10(1):1\u201311 Google Scholar   Pennycook G, Epstein Z, Mosleh M, Arechar AA, Eckles D, Rand DG (2021) Shifting attention to accuracy can reduce misinformation online. Nature 592(7855):590\u2013595 Article   ADS   CAS   PubMed   Google Scholar   Petersen MB, Osmundsen M, Arceneaux K (2023) The \u201cNeed for Chaos\u201d and Motivations to Share Hostile Political Rumors. Am Political Sci Rev 117(4): 1486\u22121505 Pew Research Center (2020). Differences in How Democrats and Republicans Behave on Twitter (2020). Pew Research Center. Available at https://www.pewresearch.org/politics/2020/10/15/differences-inhow-democrats-and-republicans-behave-on-twitter (Accessed on 09/01/2023) Ramiro C, Srinivasan M, Malt BC, Xu Y (2018) Algorithms in the historical emergence of word senses. Proc Natl Acad Sci 115(10):2323\u20132328 Article   ADS   CAS   PubMed   PubMed Central   Google Scholar   Rasmussen SHR, Osmundsen M, Petersen MB (2022) Political Resources and Online Political Hostility How and Why Hostility Is More Prevalent Among the Resourceful. PsyArXiv preprint. https://doi.org/10.31234/osf.io/tp93r Rathje S, Van Bavel JJ, van der Linden S (2021) Out-group animosity drives engagement on social media. Proc Natl Acad Sci, 118(26):e2024292118 Rawlings C, Childress C (2022) The Polarization of Popular Culture: Tracing the Size, Shape, and Depth of the Oil Spill. SocArXiv preprint. https://doi.org/10.31235/osf.io/4yqve Robertson A, Magdy W, Goldwater S (2020) Emoji skin tone modifiers: Analyzing variation in usage on social media. ACM Trans Soc Comput 3(2):1\u201325 Article   Google Scholar   Robertson A, Liza FF, Nguyen D, McGillivray B, Hale SA (2021) Semantic Journeys: Quantifying Change in Emoji Meaning from 2012-2018. ArXiv preprint: http://arxiv.org/abs/2105.00846 Rodman E (2020) A Timely Intervention: Tracking the Changing Meanings of Political Concepts with Word Vectors. Political Anal 28(1):87\u2013111 Article   Google Scholar   Rosin GD, Radinsky K (2022) Temporal Attention for Language Models. In: Findings of the Association for Computational Linguistics: NAACL 2022. Association for Computational Linguistics, Seattle, pp. 1498\u20131508 Schlechtweg D, Schulte im Walde S, Eckmann S (2018) Diachronic Usage Relatedness (DURel): A Framework for the Annotation of Lexical Semantic Change. In: Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers). Association for Computational Linguistics, New Orleans, Louisiana, pp. 169\u2013174 Schlechtweg D, H\u00e4tty A, Del Tredici M, Schulte im Walde S (2019) A wind of change: Detecting and evaluating lexical semantic change across times and domains. In: Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics, Florence, Italy, pp. 732\u2013746 Schlechtweg D, McGillivray B, Hengchen S, Dubossarsky H, Tahmasebi N (2020) SemEval-2020 Task 1: Unsupervised Lexical Semantic Change Detection. In: Proceedings of the Fourteenth Workshop on Semantic Evaluation. International Committee for Computational Linguistics, Barcelona, pp. 1\u201323 Soliman A, Hafer J, Lemmerich F (2019) A Characterization of Political Communities on Reddit. In: Proceedings of the 30th ACM Conference on Hypertext and Social Media. ACM, Hof Germany, pp. 259\u2013263 Spinde T, Rudnitckaia L, Hamborg F, Gipp B (2021) Identification of Biased Terms in News Articles by Comparison of Outlet-Specific Word Embeddings. In: Diversity, Divergence, Dialogue: 16th International Conference, iConference 2021, Beijing, China, March 17\u201331, 2021, Proceedings, Part II. Springer-Verlag, pp. 215\u2013224 Stewart I, Eisenstein J (2018) Making \u201cFetch\u201d happen: The influence of social and linguistic context on nonstandard word growth and decline. In: Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Brussels, Belgium, pp. 4360\u20134370 Sylwester K, Purver M (2015) Twitter Language Use Reflects Psychological Differences between Democrats and Republicans. PLOS One 10(9):e0137422 Article   PubMed   PubMed Central   Google Scholar   Tyler M, Iyengar S (2022) Learning to Dislike Your Opponents: Political Socialization in the Era of Polarization. Am Political Sci Rev 117(1):347\u2212354 Verma D, Chandiramani R, Jain P, Chaudhari C, Khandelwal, A, Bhattacharjee K et al. (2020) Sentiment Extraction from Image-Based Memes Using Natural Language Processing and Machine Learning. In: Fong S, Dey N, Joshi A, (ed) ICT Analysis and Applications, Lecture Notes in Networks and Systems. Springer, Singapore, pp. 285\u2013293 Wang Y, Feng Y, Hong Z, Berger R, Luo J (2017) How Polarized Have We Become? A Multimodal Classification of Trump Followers and Clinton Followers. In Ciampaglia GL, Mashhadi A, Yasseri T, ed, Social Informatics, Lecture Notes in Computer Science. Springer International Publishing, Cham, p. 440\u2013456 Wendlandt L, Kummerfeld JK, Mihalcea R (2018) Factors Influencing the Surprising Instability of Word Embeddings. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers). Association for Computational Linguistics, New Orleans, Louisiana, pp. 2092\u20132102 Wignell P, Tan S, O\u2019Halloran KL, Chai K (2020) The Twittering Presidents: An analysis of tweets from @BarackObama and @realDonaldTrump. J Lang Politics 20(2):197\u2013225 Article   Google Scholar   Wojcik S, Adam H (2019) Sizing Up Twitter Users. Pew Research Center. Available at https://www.pewresearch.org/internet/2019/04/24/sizing-up-twitter-users/ (Accessed on 09/01/2023) Xiao Z, Zhu J, Wang Y, Zhou P, Lam WH, Porter MA et al. (2022) Detecting Political Biases of Named Entities and Hashtags on Twitter. ArXiv preprint: http://arxiv.org/abs/2209.08110 Yang P, Colavizza G (2022) Polarization and reliability of news sources in Wikipedia. ArXiv preprint: http://arxiv.org/abs/2210.16065 Zemaityte V, Karjus A, Rohn U, Schich M, Ibrus I (2024) Quantifying the global film festival circuit: Networks, diversity, and public value creation. PLOS ONE 19(3):e0297404. https://doi.org/10.1371/journal.pone.0297404 Ziems C, Shaikh O, Zhang Z, Held W, Chen J, Yang D (2023) Can Large Language Models Transform Computational Social Science? Comput Linguist 1\u201353 Download references Author information Authors and Affiliations ERA Chair for Cultural Data Analytics, Tallinn University, Tallinn, Estonia Andres Karjus School of Humanities, Tallinn University, Tallinn, Estonia Andres Karjus Estonian Business School, Tallinn, Estonia Andres Karjus English Literature, Language and Linguistics, Newcastle University, Newcastle upon Tyne, United Kingdom Christine Cuskley Centre for Behaviour and Evolution, Newcastle University, Newcastle upon Tyne, United Kingdom Christine Cuskley Contributions AK designed the study, collected the data, conducted data analysis and data annotation, created the figures, and wrote the manuscript. CC also designed the study, conducted data annotation, and wrote the manuscript. AK is supported by the CUDAN ERA Chair project for Cultural Data Analytics, funded through the European Union Horizon 2020 research and innovation program (Project No. 810961). CC was supported during a part of this research by the ESRC Research Grant \u201cConstraints on the adaptiveness of information content in language (CAIL): Improving communication and detecting failures in audience design\u201d (ES/T005955/1). Corresponding author Correspondence to Andres Karjus. Ethics declarations Competing interests The authors declare no competing interests. Ethical approval This article is based on publicly available textual data and does not contain any studies with human participants. Informed consent This article does not contain any studies with human participants performed by any of the authors. Additional information Publisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Supplementary information Supplementary Information Rights and permissions Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. Reprints and permissions About this article Cite this article Karjus, A., Cuskley, C. Evolving linguistic divergence on polarizing social media. Humanit Soc Sci Commun 11, 422 (2024). https://doi.org/10.1057/s41599-024-02922-9 Download citation Received 06 September 2023 Accepted 04 March 2024 Published 15 March 2024 DOI https://doi.org/10.1057/s41599-024-02922-9 Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Subjects Cultural and media studies Language and linguistics Sociology Download PDF Sections Figures References Abstract Introduction Division and change Online media as a data source Methods and materials Results Discussion Conclusions Data availability References Author information Ethics declarations Additional information Supplementary information Rights and permissions About this article Advertisement Humanities and Social Sciences Communications (Humanit Soc Sci Commun) ISSN 2662-9992 (online) About Nature Portfolio About us Press releases Press office Contact us Discover content Journals A-Z Articles by subject Protocol Exchange Nature Index Publishing policies Nature portfolio policies Open access Author & Researcher services Reprints & permissions Research data Language editing Scientific editing Nature Masterclasses Research Solutions Libraries & institutions Librarian service & tools Librarian portal Open research Recommend to library Advertising & partnerships Advertising Partnerships & Services Media kits Branded content Professional development Nature Careers Nature Conferences Regional websites Nature Africa Nature China Nature India Nature Italy Nature Japan Nature Korea Nature Middle East Privacy Policy Use of cookies Your privacy choices/Manage cookies Legal notice Accessibility statement Terms & Conditions Your US state privacy rights \u00a9 2024 Springer Nature Limited",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  },
  {
    "title": "Prediction of compressive strength of concrete based on improved artificial bee colony-multilayer perceptron algorithm",
    "doi": "10.1038/s41598-024-57131-w",
    "description": "There are many factors that affect the compressive strength of concrete. The relationship between compressive strength and these factors is a complex nonlinear problem. Empirical formulas commonly used to predict the compressive strength of concrete are based on summarizing experimental data of several different mix proportions and curing periods, and their generality is poor. This article proposes an improved artificial bee colony algorithm (IABC) and a multilayer perceptron (MLP) coupled model for predicting the compressive strength of concrete. To address the shortcomings of the basic artificial bee colony algorithm, such as easily falling into local optima and slow convergence speed, this article introduces a Gaussian mutation operator into the basic artificial bee colony algorithm to optimize the initial honey source position and designs an MLP neural network model based on the improved artificial bee colony algorithm (IABC-MLP). Compared with traditional strength prediction models, the ABC-MLP model can better capture the nonlinear relationship of the compressive strength of concrete and achieve higher prediction accuracy when considering the compound effect of multiple factors. The IABC-MLP model built in this study is compared with the ABC-MLP and particle swarm optimization (PSO) coupling algorithms. The research shows that IABC can significantly improve the training and prediction accuracy of MLP. Compared with the ABC-MLP and PSO-MLP coupling models, the training accuracy of the IABC-MLP model is increased by 1.6% and 4.5%, respectively. This model is also compared with common individual learning algorithms such as MLP, decision tree (DT), support vector machine regression (SVR), and random forest algorithms (RF). Based on the comparison of prediction results, the proposed method shows excellent performance in all indicators and demonstrates the superiority of heuristic algorithms in predicting the compressive strength of concrete.",
    "journal": "Scientific Reports",
    "authors": [
      "Li P.",
      "Zhang Y.",
      "Gu J.",
      "Duan S."
    ],
    "citation_count": "0",
    "full_text": "Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Advertisement View all journals Search Log in Explore content About the journal Publish with us Sign up for alerts RSS feed nature scientific reports articles article Article Open access Published: 17 March 2024 Prediction of compressive strength of concrete based on improved artificial bee colony-multilayer perceptron algorithm Ping Li, Yanru Zhang, Jiming Gu & Shiwei Duan  Scientific Reports  14, Article number: 6414 (2024) Cite this article 402 Accesses 1 Altmetric Metrics Abstract There are many factors that affect the compressive strength of concrete. The relationship between compressive strength and these factors is a complex nonlinear problem. Empirical formulas commonly used to predict the compressive strength of concrete are based on summarizing experimental data of several different mix proportions and curing periods, and their generality is poor. This article proposes an improved artificial bee colony algorithm (IABC) and a multilayer perceptron (MLP) coupled model for predicting the compressive strength of concrete. To address the shortcomings of the basic artificial bee colony algorithm, such as easily falling into local optima and slow convergence speed, this article introduces a Gaussian mutation operator into the basic artificial bee colony algorithm to optimize the initial honey source position and designs an MLP neural network model based on the improved artificial bee colony algorithm (IABC-MLP). Compared with traditional strength prediction models, the ABC-MLP model can better capture the nonlinear relationship of the compressive strength of concrete and achieve higher prediction accuracy when considering the compound effect of multiple factors. The IABC-MLP model built in this study is compared with the ABC-MLP and particle swarm optimization (PSO) coupling algorithms. The research shows that IABC can significantly improve the training and prediction accuracy of MLP. Compared with the ABC-MLP and PSO-MLP coupling models, the training accuracy of the IABC-MLP model is increased by 1.6% and 4.5%, respectively. This model is also compared with common individual learning algorithms such as MLP, decision tree (DT), support vector machine regression (SVR), and random forest algorithms (RF). Based on the comparison of prediction results, the proposed method shows excellent performance in all indicators and demonstrates the superiority of heuristic algorithms in predicting the compressive strength of concrete. Similar content being viewed by others Ensemble learning based compressive strength prediction of concrete structures through real-time non-destructive testing Article Open access 21 January 2024 Study of flexural strength of concrete containing mineral admixtures based on machine learning Article Open access 23 October 2023 Prediction of the axial compression capacity of stub CFST columns using machine learning techniques Article Open access 05 February 2024 Introduction Concrete is one of the most commonly used materials in construction engineering, and its compressive strength is an important reference index for structural design and construction. As a multiphase composite material, the complex and diverse composition of concrete, differences in curing time and environment, and nonlinear coupling relationships between its constituent materials pose many challenges to the establishment of compression strength prediction models. Currently, in engineering applications, engineers mostly conduct mechanical performance tests on concrete materials and establish empirical-type compression strength prediction models based on the test data. However, such models are often based on the empirical summaries of test data for one or two types of concrete. When changing one of the constituent materials or curing time, the accuracy of this prediction model will greatly reduce. Therefore, these concrete strength prediction models based on specific constituent materials and curing conditions are often one-sided. With the development of artificial intelligence, machine learning has drawn the attention of civil engineers. Machine learning methods, due to their ability to identify patterns or judgment rules hidden in extensive data sets and construct models with the aid of manual experience adjustment, are a new path for overcoming the limitations of empirical regression models in traditional mix design and predicting the relationship between concrete mix and performance1,2,3,4,5. Artificial neural networks (ANNs) are an important algorithm in machine learning, and more and more scholars are using neural networks for engineering prediction and damage identification6,7,8,9,10,11,12, especially multilayer perceptron (MLP) networks. Nguyen et al.13 used four machine learning algorithms, SVR, MLP, GBR, and XGBoost, to predict the compressive and tensile strength of HPC. Comparative studies showed that based on the GBR and XGBoost training models, the performance was better than that of the models based on SVR and MLP for this specific prediction problem. Imran et al.14 compared MLR, DT, SVM, BR, and GPR, and found that the GPR model had the highest performance and the smallest prediction error in compressive strength prediction. Wang et al.15 trained the artificial neural network through the beetle antenna search algorithm to establish the BAS-MLP concrete strength prediction model, and compared and analyzed it with the SCE-MLP, MVO-MLP coupled algorithm, ANN, and SVM individual learning algorithms. The results showed that combining artificial neural networks with metaheuristic algorithms could better solve such problems. Kova\u010devi\u0107 et al.16 comprehensively reviewed machine learning methods that could be used to estimate SCRC compressive strength, including MLP-ANN, ensemble of MLP-ANN, regression tree ensemble (random forest, boosting, and bagging regression trees), SVR, and GPR. Moodi et al.17 studied the effectiveness of three different machine learning methods, RBNN, MLP, and SVR, in predicting the ultimate strength of square and rectangular concrete columns. The results showed that MLP and RBNN obtained higher accuracy and best model prediction performance. Ghunimat et al.18 selected three models, MLP, Random Forest Regression, and k-nearest neighbor regression, to estimate the compressive strength of concrete mixtures. By comparing the accuracy and stability of the three methods in predicting compressive strength, it was found that compared with KNN, RFR and MLP had better performance and were the closest to the results. Although the above research has made certain achievements, the initial parameter setting of the neural network has a significant impact on the result. When facing a large or complex nonlinear dataset, the neural network algorithm still has shortcomings such as overfitting and dependence on initial values, and often needs to use optimization algorithms to further improve the accuracy of the prediction results. Artificial intelligence optimization algorithms are popular parameter optimization algorithms, such as genetic algorithm, particle swarm optimization algorithm, ant colony optimization algorithm, artificial bee colony algorithm, etc. In the research by Karaboga D et al.19,20,21, it has been shown through numerous experiments that the optimization performance of the artificial bee colony algorithm is better than the other aforementioned algorithms, with the characteristics of less control parameters, strong local optimization ability, and fast convergence speed. Currently, scholars have applied this modeling method of using the artificial bee colony algorithm to optimize neural network parameters to predict the mechanical behavior of civil engineering materials and components. Zhou Hao et al.22 applied the ABC algorithm and SVM algorithm to optimize the concrete mix proportion, establishing a concrete mix proportion optimization model and verified the rationality and applicability of the model through concrete slump and strength tests. Imran, M et al.23 used artificial bee colony (ABC) and cascade forward neural network (CFNN) to optimize and develop a new hybrid model for predicting concrete compressive strength, and model validation using performance indicators showed that the proposed hybrid model was superior to other models in all performance indicators. However, as a random optimization algorithm, the ABC algorithm, similar to other evolutionary algorithms, also has defects of slow convergence speed and easy to fall into local optima. In recent years, various improvement strategies have been proposed for the basic ABC algorithm. Shao Guangcheng et al.24 introduced a Gaussian mutation operator in the basic artificial bee colony algorithm to optimize the initial honey source position, designing and establishing an RBF neural network model (IABC-RBF) based on the improved artificial bee colony algorithm, comprehensively improving the prediction ability of neural networks. Leng Xin et al.25 improved the artificial bee colony algorithm by introducing global optimal solutions and adaptive judgment factors in two aspects of search method and following bee selection probability. The improved algorithm showed that its convergence speed and accuracy were improved compared to the previous version in three function test results. Yao G et al.26 improved the algorithm from three aspects of bee colony initialization, fitness function, and position update formula, overcoming the randomness and easy local optimal solution defects of the initial algorithm. Zhu G et al.27, inspired by the particle swarm optimization algorithm, introduced the global optimal solution (gbest) information into the solution search equation, proposing an improved ABC algorithm\u2014GABC algorithm, which improves the algorithm's development rate. Gao W et al.28 first used the chaos-based oppositional population initialization method to improve the global convergence, and then combined DE with GABC through evaluation strategies, attempting to use more prior search experience and designed a new method called DGABC to improve the performance of the ABC. These improved ABC algorithms have improved the performance of the algorithm to a certain extent, but have not achieved the adaptive learning of the material's mechanical properties by engineering material test data while avoiding premature convergence of the algorithm, in order to improve the efficiency and accuracy of the material strength prediction model. Therefore, this paper conducts research on the prediction of compressive strength of concrete and proposes an improved artificial bee colony algorithm. This algorithm improves the two aspects of the bee colony, namely, initialization and honey source update formula. It overcomes the randomness of honey source initialization and the drawback of easily falling into local optimal solutions. The artificial bee colony algorithm is combined with the MLP neural network to enhance the global search capability of the MLP algorithm. Through simulation experiments on two strength prediction datasets, the effectiveness of the algorithm is confirmed, significantly improving optimization efficiency and performance. This algorithm has certain practical value in the actual application of engineering projects. Model and optimization algorithm MLP neural network The multilayer perceptron (MLP) is a feedforward supervised learning neural network that includes an input layer, an output layer, and at least one hidden layer. In the MLP model, each layer contains several neurons, and there is no direct connection between neurons in the same layer. The neurons between adjacent layers are fully connected through the addition of weights. Except for the input layer, each layer's neurons have a nonlinear activation function. The multilayer perceptron inputs data through the input layer, and the hidden layer neurons analyze and process the data, and finally, the output layer outputs the results, which achieves multi-layer optimization processing of data. MLP has excellent capabilities for nonlinear mapping, high parallelism, and high fault tolerance29,30. Compared to other machine learning algorithms, it performs well in the presence of noise, nonlinearity, and high-dimensional data. At the same time, it can adapt to specific problem requirements by adjusting the number of layers and nodes in the model. In the research problem of concrete strength prediction, it can predict the compressive strength of concrete by learning the nonlinear mapping relationship between input features and outputs. During the training process, known concrete mix proportions, water-cement ratio, age, and other feature parameters are used as input, and their corresponding compressive strength is used as output. The backpropagation algorithm is used to optimize the network parameters, resulting in a more accurate prediction model. Therefore, compared to other neural network models, the multilayer perceptron has outstanding advantages in nonlinear modeling, training speed, and handling of input variable correlations in concrete strength prediction. Its model structure is shown in Fig. 1. Circles usually represent neurons or nodes, and the connecting lines represent connections between neurons, with arrows on the connecting lines indicating the direction of signal transmission from one neuron to another. Figure 1 Structure diagram of MLP model. Full size image MLP determines the number of neurons in the input and output layers based on the target requirements, while the number of neurons and layers in the hidden layer are determined based on the error requirements set. In the MLP model, the output formula for the \\(j - th\\) neuron in the \\(i - th\\) layer is: $$ y_{j}^{(i)} = f_{j}^{(i)} \\left( {W_{j}^{(i)} \\cdot y^{(i - 1)} + b_{j}^{(i)} } \\right). $$ (1) In the equation, \\(W_{j}^{(i)}\\) is the weight vector of the \\(j - th\\) neuron in the \\(i - th\\) layer, with direction from the (\\((i - 1) - th\\) layer to the \\(i - th\\) layer and the \\(j - th\\) neuron; \\(y^{(i - 1)}\\) is the output vector of the \\((i - 1) - th\\) layer; \\(b_{j}^{(i)}\\) is the bias vector of the \\(j - th\\) neuron in the \\(i - th\\) layer; and \\(f_{j}^{(i)}\\) is the activation function of the \\(j - th\\) neuron in the \\(i - th\\) layer. All the parameters of the MLP model are the weights and bias quantities between each layer. The selection of these parameters affects the prediction performance of MLP to a certain extent. Therefore, it is necessary to optimize the weights and bias quantities of MLP, to make the output of the MLP model closer to the true value, thus improving the prediction accuracy of the model. Basic artificial bee colony algorithm There are currently many algorithms inspired by the behavior of insect colonies in nature, simulating the foraging behavior of insect colonies under the \"survival of the fittest\" rule. Artificial Bee Colony Algorithm is one of them, evolved from the foraging behavior of bees in nature. In 2005, Professor Karaboga first modeled the behavior and division of labor of bee colonies in foraging in literature and proposed the Artificial Bee Colony Algorithm model. Due to its ease of implementation, few control parameters, and strong stability, the algorithm performs both global and local searches in each iteration, which increases the likelihood of finding the optimal solution. Compared to other swarm intelligence algorithms, it converges faster and quickly gained attention and research from many researchers. The Artificial Bee Colony Algorithm can simulate the actual honey bee foraging behavior, with the location of the food source representing the solution to the problem, the quality of the pollen representing the fitness of the solution, and the spatial position of a food source representing a set of feasible solutions. The colony is divided into three types of bees: employed bees, which are responsible for randomly searching for food around the hive and carrying information on food sources; follower bees, which follow employed bees to collect nectar; and scout bees, which randomly search for other food sources when a food source has been over-exploited. The individual behavior of bees in the colony is simple, but they coordinate with each other, communicate and cooperate to make the system run smoothly. The workflow is shown in Fig. 2. Figure 2 Workflow diagram of the bee colony. Full size image The basic model of the ABC algorithm includes four stages: the initialization stage, the employed bee stage, the onlooker bee stage, and the scout bee stage. Below is a detailed introduction to each stage of the artificial bee colony algorithm. Stage 1: Initialization Phase: set the dimension of the solution space \\(d\\), the size of the bee colony \\(NP\\), the number of leading bees \\(NP/2\\), the control parameter \u201c\\(limit\\)\u201d for abandoned food sources, and the maximum number of algorithm iterations Max Iterations. The ABC algorithm randomly generates \\(NP/2\\) initial solutions \\(x_{i}\\), \\(i = 1 , 2 , ... , NP/2\\), each of which is a \\(d\\)-dimensional vector, and constructs the fitness function to evaluate the goodness of each food source. Stage 2: Employed Bee Phase: each honey source represents a solution to the problem being solved. At the beginning, the honey source \\(v_{i} = (v_{i1} ,v_{i2} ,...,v_{id} )\\) can be randomly generated according to the following equation: $$ v_{ij} = L_{ij} + r_{1} \\times \\left( {U_{ij} - L_{ij} } \\right), $$ (2) where \\(v_{ij}\\) represents the \\(j - th\\) variable of the \\(i - th\\) honey source, \\(i \\in \\left( {{1 , 2 , }...{ ,} NP/2} \\right){ , }j \\in \\left( {{1 , 2 , }...{ , }d} \\right)\\), \\(U_{ij}\\) and \\(L_{ij}\\) are the upper and lower bounds of \\(g_{ij}\\), and \\(r_{1}\\) is a random number between 0 and 1, which is used to control the range of the neighborhood. Stage 3: Follower Bee Phase: Follower bees select the honey source to search next based on the fitness of the honey source, using roulette wheel selection. The selection probability for honey source \\(i\\) is calculated according to the following equation: $$ p_{i} = \\frac{{fit_{i} }}{{\\sum\\limits_{j = 1}^{NP/2} {fit_{j} } }}, $$ (3) where \\(fit_{i}\\) represents the fitness of the \\(i - th\\) solution, which is the amount of nectar of the \\(i - th\\) honey source, and \"\\(p_{i}\\)\" represents the probability of the \\(i - th\\) honey source being selected. As can be seen from the equation, the probability of selecting a food source increases as its fitness increases. Once a follower bee selects a employed bee to follow, it searches in the neighborhood of the food source using Eq. (2) to find a better food source, which corresponds to the optimal fitness. Stage 4: Scout bee stage: In the bee algorithm, if a local optimum is reached after \\(t\\) iterations of search and the threshold \\(limit\\) for the number of attempts is reached without finding a better quality honey source, the bee responsible for that source becomes a scout bee. The scout bee generates a new honey source according to Eq. (4). $$ v_{i}^{t + 1} = \\left\\{ {\\begin{array}{*{20}c} {L_{i} + r_{1} \\times (U_{i} - L_{i} ),} & {t \\ge limit} \\\\ {v_{i}^{t} } & {t < limit} \\\\ \\end{array} } \\right.. $$ (4) It can be seen that the ABC algorithm has excellent global search capability and adaptability, and has a wide range of applications in scientific research and industry. It is suitable for predicting the strength of concrete. However, it has weaknesses in terms of slow convergence speed and a tendency to get stuck in local optima. Improvements to the artificial bee colony algorithm In order to enhance the optimization accuracy and convergence speed of the ABC algorithm, this study proposes improvements in two aspects: the optimization of the initial solution space and the honey source search mechanism. (1) Honey Source Initialization. The initialization of honey sources has a significant impact on the speed and quality of the solution. In the basic Artificial Bee Colony algorithm, the positions of honey sources are randomly initialized, resulting in an uneven distribution of honey sources in the entire target space. However, chaotic sequences based on chaotic theory possess the properties of traversing the entire space and dynamism. Therefore, using chaotic sequences to improve the initialization of honey sources in the ABC algorithm overcomes the disadvantages of uneven distribution caused by random initialization. A logistic mapping equation is used to generate chaotic sequences, as shown below: $$ x_{k} = \\mu x_{k - 1} \\left( {1 - x_{k - 1} } \\right). $$ (5) In the equation: \\(\\mu\\) represents the growth rate, and when \\(\\mu\\)\u2009=\u20094, the system is in a fully chaotic state. \\(x_{0}\\) is the initial value, and \\(x_{k}\\) represents the value of the algorithm at iteration \\(k\\). According to chaotic theory, when the initial value \\(x_{0}\\) is not equal to 0, 0.25, 0.5, 0.75, or 1.0, the sequence is in a chaotic state, which can expand the search range of the algorithm. After introducing the chaotic sequence, the Eq. (1) can be improved as follows: $$ v_{i} = L_{i} + x_{i} \\times \\left( {U_{i} - L_{i} } \\right), $$ (6) where \\(i \\in \\left( {{1 , 2 , }...{\\text{ , NP/2}}} \\right) \\, \\),\\(U_{i}\\), and \\(L_{i}\\) are the upper and lower bounds of \\(g_{i}\\); \\(x_{i}\\) represents the \\(d\\)-dimensional chaotic sequence after a certain number of iterations. (2) Honey Source Search Mechanism: In order to improve the local search ability of the artificial bee colony algorithm, a Gaussian mutation mechanism is introduced. After each iteration, the fitness function values of the honey sources are sorted, and the worst \\(n \\times \\eta\\) honey sources are selected for Gaussian mutation, where \\(n\\) is the number of honey sources and \\(\\eta\\) is the mutation ratio. Empirically, \\(\\eta\\) is set to 1/12; \\(\\mu\\) is the mean, and \\(\\sigma\\) is the standard deviation. After the worst \\(n \\times \\eta\\) honey sources have been subjected to the Gaussian mutation, the formula for generating a new honey source is as follows: $$ v_{new}^{t} = v_{i}^{t} + Gauss\\left( {\\mu ,\\,\\sigma^{2} } \\right), $$ (7) where \\(v_{i}^{t}\\) and \\(v_{new}^{t}\\) are the positions of the bee colony before and after mutation, respectively. The improved artificial bee colony algorithm flow is shown in Fig. 3. Figure 3 Improved artificial bee colony algorithm flowchart. Full size image Strength prediction model based on IABC-MLP Model framework for prediction MLP is a feedforward artificial neural network that has the advantage of processing complex nonlinear relationships and is therefore introduced for predicting the strength of concrete. In the research of predicting the compressive strength of concrete, its prediction results are easily affected by the model structure and fitting ability, which may lead to problems such as underfitting or overfitting, resulting in inaccurate prediction results. Therefore, in this paper, an improved artificial bee colony algorithm is used to search for the optimal initial weights and thresholds of the MLP neural network, which is then applied to the pre-defined network to construct the final algorithmic training model. In this paper, we propose an integrated model for concrete strength prediction which optimizes the Multilayer Perceptron neural network using an improved Artificial Bee Colony algorithm. Compared to MLP neural networks, the proposed IABC-MLP algorithm exhibits advantages in addressing issues such as poor network stability and susceptibility to local optima. In IABC-MLP, the IABC algorithm is used to find the best weights and biases to minimize prediction errors, so that the new model has stronger global search capability and can search for optimal solutions from a wider range of areas, while avoiding the limitations of traditional multilayer perceptron network that rely on the selection of initial weights and gradient descent, thereby improving the accuracy and stability of the model. Specifically, in the ABC algorithm, individual bees optimize the weights and biases of the MLP through search and selection operations. Each bee represents a solution, which includes a set of values for weights and biases. Bees evaluate solutions based on the performance of the objective function (i.e., prediction error) and perform search and exploration based on a certain probability. The \"employed bees\" phase in the ABC algorithm is used to improve the current solution through information exchange with other worker bees. The \"follower bees\" phase is used to search for new solutions and compare them with the current solution for selection. By optimizing the weights and biases of MLP using the ABC algorithm, the performance and prediction accuracy of the model can be improved, thereby achieving more accurate prediction of concrete strength. The specific flow of the IABC-MLP prediction model is shown in Fig. 4. Figure 4 Flowchart of ABC-MLP algorithm. Full size image Model evaluation index The evaluation of the accuracy of the model established in this paper is comprehensively assessed using mean absolute error (\\(MAE\\)), root mean square error (\\(RMSE\\)), and correlation coefficient (\\(R^{2}\\)) as performance indicators for model prediction. \\(MAE\\) represents the average absolute error between the predicted value and the actual value, reflecting the average size of the predicted value error. The smaller the \\(MAE\\) value, the more accurate the prediction of the model. Its expression is as follows: $$ MAE = \\frac{1}{n}\\sum\\limits_{i = 1}^{n} {\\left| {y_{i} - \\mathop {y_{i} }\\limits^{ \\wedge } } \\right|} . $$ (8) \\(RMSE\\) represents the square root of the mean of the sum of squares of the difference between the predicted value and the true value, and is more sensitive to outliers because it amplifies the square of larger prediction errors. The smaller the value of \\(RMSE\\), the more accurate the prediction of the model. Its expression is as follows: $$ RMSE = \\sqrt {\\frac{1}{n}\\sum\\limits_{i = 1}^{n} {\\left| {y_{i} - \\mathop {y_{i} }\\limits^{ \\wedge } } \\right|}^{2} } . $$ (9) \\(R^{2}\\) indicates the correlation between the predicted result and the true value. The value of \\(R^{2}\\) ranges from 0 to 1, indicating the correlation between the predicted result and the true value. The closer the value is to 1, the better the model effect is. Its expression is as follows: $$ R^{2} = 1 - \\frac{{\\sum\\limits_{i = 1}^{n} {\\left( {y_{i} - \\mathop {y_{i} }\\limits^{ \\wedge } } \\right)^{2} } }}{{\\sum\\limits_{i = 1}^{n} {\\left( {y_{i} - \\overline{y} } \\right)^{2} } }}, $$ (10) where: \\(y_{i}\\) is the measured value; \\(\\mathop {y_{i} }\\limits^{ \\wedge }\\) is the predicted value; \\(\\overline{y}\\) is the mean; \\(n\\) is the number of measured values. Case study analysis Data acquisition Concrete, as a composite material, its compressive strength depends mainly on two factors. Firstly, it depends on the proportion of various materials added during the mixing process, such as cement, slag, ash, water, superplastic, coarse aggregate, and fine aggregate, etc. Secondly, the mixed concrete needs to undergo chemical reactions in the natural environment after mixing in order to harden, so there is a significant correlation between the age of the concrete and its compressive strength. Based on previous research and analysis of a large number of relevant literature and engineering experience, this paper chooses to consider the influence of concrete material proportion and age on its compressive strength and constructs a compressive strength regression prediction model based on MLP. The computer configuration used in this experiment is as follows: 16 GB of memory, AMD R7 processor, CPU frequency of 3.2 GHz, operating system Windows 11 (64-bit), and Python 3.9 as the programming language. Dataset 1 is sourced from the Concrete Compressive Strength dataset of the UCI Machine Learning Repository. This dataset consists of 1030 samples, with each sample having 8 influencing factors: cement content, fly ash content, blast furnace slag content, superplasticizer content, water content, coarse aggregate, fine aggregate, and concrete age. Additionally, there is one target output value, which is the compressive strength of the concrete. Table 1 provides descriptive statistical data for Dataset 1. Table 1 Descriptive statistics of concrete compressive strength and key factors in Dataset 1. Full size table Input variable selection and data preprocessing In order to reveal the extent of correlation between each type of input variable and the final output variable, and thereby optimize the input variables to achieve better predictive performance, we selected 8 initial variables from Dataset 1 and calculated their importance indices for the output variable using a random forest algorithm via Python software. The results and importance index rankings are shown in Table 2. Table 2 Feature importance ranking. Full size table As shown in the table, it can be observed that among the input variables, the age of the concrete has the highest correlation with the output variable, which means that the duration of the age has the greatest impact on the compressive strength of the concrete. This is consistent with the empirical experience in engineering. The influence of cement content and water content on the output is secondary, as the cement content, water content, and water-cement ratio, which is one of the important indicators affecting concrete strength, are closely related. Therefore, the relationship between the calculated inputs and outputs based on this method is reasonable. Meanwhile, the correlation between input variables and the compressive strength of concrete was analyzed using the heatmap method in Python. This analysis aims to validate the importance scores of input variables calculated based on the random forest algorithm. The results are shown in Fig. 5. The variable correlation heatmap describes the correlation between different variables using different coefficient sizes and color depths. The coefficient size indicates the strength of the correlation between two variables, with a larger coefficient indicating a stronger correlation. The color depth represents the direction of the correlation, either positive or negative. A darker color indicates a stronger correlation, while a lighter color indicates a weaker correlation. Figure 5 Heatmap of variable correlation. Full size image As shown in Fig. 5, the correlation coefficient between cement and concrete compressive strength is 0.5, and the color is relatively light red, which indicates that a higher content of cement leads to a higher concrete compressive strength. The correlation coefficient between water and concrete compressive strength is -0.29, and the color is a relatively dark blue, indicating that an increase in water content leads to a decrease in concrete compressive strength. In addition, the effects of cement content, high-efficiency water reducer, water content, and concrete age on concrete compressive strength are apparently higher than those of other variables, which is broadly consistent with the variable importance scores calculated based on the RF algorithm in Table 2, which proves that these four variables have a greater impact on concrete compressive strength. By implementing feature selection based on importance ranking on the training set using GridSearchCV method in Pycharm, with RF parameters n_estimators\u2009=\u2009500 and max_depth\u2009=\u20099, a trend graph of root mean squared error (RMSE) is obtained for different variable combinations after tenfold cross-validation, as shown in Fig. 6. Figure 6 RMSE trend chart of different variable combinations. Full size image From Fig. 6, it can be observed that as important influential factors are sequentially selected from the variable combinations, the overall trend of the model's RMSE shows a gradual decrease. This indicates that the RF algorithm effectively removes some unimportant and redundant influential factors, reduces the deviation between predicted values and actual values, and improves the accuracy of the model's predictions. After traversing all feature variables, the optimal combination of variables is determined to be 8. At this point, the root mean square error is minimized and the predictive accuracy of the model is highest. Therefore, all 8 influencing factors in Dataset 1 are used as input variables for the concrete compressive strength prediction model. From the statistical description of the data, it can be observed that there are significant differences in concrete compressive strength and the physical values of various key factors, and the units are not standardized. Therefore, it is necessary to normalize the samples in order to improve the accuracy of the model training. In this paper, the (0, 1) normalization method is selected as the normalization technique, with the following expression: $$ Y = \\frac{{X - X_{\\min } }}{{X_{\\max } - X_{\\min } }}. $$ (11) In the formula: \\(Y\\) represents the result of normalization; \\(X_{\\min }\\) is the minimum value in the sample; \\(X_{\\max }\\) is the maximum value in the sample; \\(X\\) is the sample value that needs to be normalized. Parameter settings For the MLP model in the IABC-MLP model, the initial weights and thresholds are obtained using the most widely used random initialization method. The transfer functions for the hidden layer and output layer are ReLU function and linear function, respectively. In this study, cross-validation is used to determine the number of hidden layers and nodes in the MLP model. By conducting multiple trainings and tests on the training set, the optimal situation is determined where the test mean squared error (MSE) is small. The calculation results show that when the number of hidden layers in the MLP model is 2, and the number of nodes are 50 and 25, respectively, the test error is smaller. To determine the optimization effects of the PSO, ABC, and IABC algorithms on MLP, the number of hidden layer nodes for the PSO-MLP model, ABC-MLP model, and IABC-MLP model remain unchanged. Therefore, the structures of the three prediction models are determined to be 8-50-25-1. The detailed parameters of the MLP model are shown in Table 3. Table 3 MLP model parameters. Full size table Particle swarm optimization is a heuristic optimization algorithm in which the position and velocity of particles are gradually updated to find the optimal solution to the problem. In this algorithm, the number of particles is specified as 50, indicating that there are 50 particles in the algorithm. The maximum number of iterations for the PSO algorithm is set to 100, which means that the algorithm will terminate after 100 rounds of iteration. In addition, the learning rate and inertia factor are also set to 0.5 and 0.3, respectively, to control the influence of global best position and personal best position on the particle velocity in the algorithm. Artificial bee colony algorithm is a heuristic algorithm based on the biological characteristics of bee colonies. In this algorithm, the number of bees is set to 50, indicating that 50 bees are used in the algorithm. At the same time, the maximum number of iterations is set to 100, which means that the algorithm will also stop after 100 iterations. The improved artificial bee colony algorithm improves the algorithm in two aspects: optimizing the initial solution space and honey source search mechanism, and the parameter settings are the same as those for the standard ABC algorithm. Model comparison Comparison with the coupled model The particle swarm optimization (PSO) algorithm is a swarm intelligence algorithm that imitates the collaboration between particles to search for optimal solutions. Each particle updates its position and velocity continuously by interacting with other particles until the optimal solution is found. In the PSO algorithm, the interaction information between particles includes the current position, velocity, and the optimal position. Similar to the artificial bee colony (ABC) algorithm, the PSO algorithm can simultaneously consider global and local optimal solutions, and converge to the optimal solution quickly. Therefore, to verify the effectiveness of the IABC-MLP coupled model, we compared the IABC algorithm proposed in this paper with the basic ABC algorithm and the PSO algorithm. The normalized concrete strength training set was input into the MLP for training, and three concrete strength prediction models were established by optimizing the weights and biases of the MLP using the particle swarm algorithm, artificial bee colony algorithm, and improved artificial bee colony algorithm, respectively. In order to select the best strength prediction model with a clearer comparison, this study used a Taylor diagram to evaluate and select the models. Figure 7 displays the Taylor diagram of the three prediction models evaluating the accuracy of the training and test sets, providing an intuitive comparison of the performance of the three machine learning models in concrete strength prediction tasks. The scatter points in the figure represent the machine learning models, the red dashed line represents the observation line, the circular arc centered on the origin represents the standard deviation SD, the radiating line represents the correlation coefficient R, and the circular arc centered on the observation point represents the root mean square error RMSE. The coordinates of the training set and test set observation points reach the ideal state, i.e., R\u2009=\u20091, RMSE\u2009=\u20090. The standard deviation SD of the training set is 16.539, which is consistent with the standard deviation of the compressive strength sample of the verification set. The standard deviation SD of the test set is 15.356, which is consistent with the standard deviation of the compressive strength sample of the test set. Figure 7 Taylor diagram for model comparison. Full size image Based on the distribution of the training and test set models displayed in the Taylor diagram (Fig. 7), the following results can be observed: the validation set and test set R values of the three models are all above 0.9, indicating that there is a strong correlation between the predicted output of the model and the actual output. By comparing the rays between each scatter point and the coordinate origin, as well as the angles formed between the scatter points and the vertical coordinate axis, it can be concluded that RIABC-MLP\u2009>\u2009RABC-MLP\u2009>\u2009RPSO-MLP. By comparing the straight-line distances between each scatter point and the observation point in the diagram, it can be concluded that the IABC-MLP model has the closest distance to the observation point, followed by ABC-MLP, and then PSO-MLP, indicating that RMSEIABC-MLP\u2009<\u2009RMSEABC-MLP\u2009<\u2009RMSEPSO-MLP. Therefore, in this analysis, the IABC-MLP model performed the best, and the PSO-MLP model performed the worst. To further analyze the prediction evaluation indicators of various coupling models and ensure the reliability of the results, this study adopted the method of multiple runs and carried out 30 independent computations, and provided the average statistical results. In order to further verify the quality of the research, this study compared the predictive performance of our constructed model with representative concrete strength prediction models published in the literature. Specifically, we chose the TSO-ELM model constructed by Zhang et al.31 and the CS-AdaBoost-CART model constructed by Xue et al.32 for comparison. The evaluation indicator results for the prediction set are shown in Fig. 4. According to the evaluation indicators shown in Table 4, all types of machine learning models constructed in this article have been tested and fully reflect their predictive performance. It is worth noting that the IABC-MLP model exhibited the best predictive ability in all indicator evaluations, specifically with a goodness of fit above 97%, resulting in a 1.5% and 4.2% increase in fitting ability compared to the ABC-MLP and PSO-MLP models, respectively. In addition, the IABC-MLP also performed well in performance indicators such as mean absolute error and root mean square error, making it better suited to meeting the requirements of fitting accuracy for concrete strength prediction. It is worth mentioning that compared with the evaluation indicator results of two models proposed by other research results, the IABC-MLP model is the best model for predicting concrete compressive strength, achieving the optimal level in indicators such as MAE, RMSE, and \\(R^{2}\\). In conclusion, in this research field, the IABC-MLP model exhibited outstanding fitting ability and is expected to provide highly valuable references for related research. Table 4 Results of evaluation indicators for each coupling model. Full size table Convergence speed is an important indicator of the performance of optimization algorithms. Figure 8 shows the convergence curves of PSO-MLP, ABC-MLP, and IABC-MLP algorithms. In the figure, epoch represents the iteration times and loss represents the loss value. Comparing the loss values of the three coupled model algorithms after each iteration, it can be seen that the original ABC algorithm has a certain degree of slow convergence speed and is prone to getting stuck in local optimal solutions. Compared with the original algorithm, the PSO algorithm has faster convergence speed and fewer iterations, but weaker global optimization ability. This paper's IABC algorithm adopted the optimization of initial solution space and honey source search mechanism to avoid problems such as the randomness of initialization of food source positions and being prone to getting stuck in local optimal solutions. The algorithm enables bees to quickly move to the region where the optimal food source is located through the Gaussian mutation operator. Therefore, the IABC algorithm has significantly improved in both iteration speed and global optimization ability. After about 100 iterations, the test error tends to stabilize. Compared with the ABC-MLP algorithm and the PSO-MLP algorithm, the IABC-MLP neural network algorithm is superior in both optimization accuracy and convergence speed in the same number of iterations and can well predict the compressive strength performance of concrete. Figure 8 Loss iteration graph. Full size image Comparison with single model To further observe the prediction effect of the IABC-MLP model, this study also selected four single models for concrete strength prediction experiments: Multi-Layer Perceptron (MLP), decision tree (DT), Support Vector Regression (SVR), and Random Forest (RF). Figure 9 shows the fitting effect of the predicted values and actual values of each model, where it can be visually seen that the DT model has the worst fitting effect compared to other models, and the sample points are not concentrated on the regression line. The performance of all models was measured using evaluation metrics such as mean absolute error, root mean squared error, and correlation coefficient. The calculation results of all models are shown in Table 5. Figure 9 Fitting diagram of predicted values and actual values of each model. Full size image Table 5 Evaluation metrics results of each single model. Full size table From Table 5, it can be seen that the goodness of fit values of the four single models from highest to lowest are: MLP\u2009>\u2009RF\u2009>\u2009SVR\u2009>\u2009DT. Compared to the single MLP model, the ABC-MLP model increased the \\(R^{2}\\) value by 8.35%. This means that ABC adapts and optimizes the model based on the characteristics of the data, overcoming the curse of dimensionality and improving the prediction accuracy and stability of the MLP model. In addition, compared to the other three classical models, the IABC-MLP model shows significantly better prediction performance. The reason is that DT, SVR, and RF are individual learning algorithms, which require a large number of weights and thresholds when dealing with a large number of samples, resulting in low accuracy. On the other hand, IABC-MLP is a coupled metaheuristic algorithm that does not require excessive parameter tuning. It has a fast convergence speed and strong global optimization ability, enabling accurate prediction of concrete compressive strength. Model performance verification In order to further validate the generalization performance of the IABC-MLP neural network model and test its feasibility in practical construction, a new Dataset 2 is selected for validation. It is applied to the dataset publicly available in the paper by Al-Shamiri33, which consists of 324 sets of concrete samples obtained in their laboratory. This dataset has fewer types of input variables, so there is no need for variable optimization. The input variables are the cement, superplastic, water, coarse aggregate, fine aggregate, with the concrete compressive strength as the output variable. This dataset is used to verify the generalization of the proposed model in this paper, and its descriptive statistical data are shown in Table 6. Table 6 Descriptive statistics of concrete compressive strength and key factors for Dataset 2. Full size table The training sample fitting and test sample prediction are shown in Fig. 10. Figure 10 IABC-MLP strength fitting and prediction graphs. Full size image From Fig. 10, it can be seen that for the training set, the data points in the scatter plot of the MLP model optimized by the improved artificial bee colony algorithm are closely distributed around the regression line, indicating that the model can fit the training data well. For the test set, the data points of the model further converge, indicating that the model not only performs well on the training set, but also has higher accuracy and generalization ability on the unseen test data. According to the IABC-MLP evaluation index results in Table 7, it can be analyzed that the model for predicting the compressive strength of concrete performs well. Firstly, the value of the MAE evaluation index is small, indicating that the average error between the predicted value and the actual value is small, and the model has good fitting effect. Secondly, the value of the RMSE evaluation index is also small, indicating that the dispersion degree of predicted values and actual values of the model is small, and the prediction accuracy is high. Finally, the results of the \\(R^{2}\\) evaluation index are 0.977 and 0.986, showing high accuracy in both the training set and the test set, indicating that the model has good fitting ability and strong prediction ability. In conclusion, by observing the IABC-MLP strength fitting effect diagram and analyzing the evaluation index results, it can be clearly seen that the established model has high prediction accuracy and reliability in the study of predicting the compressive strength of concrete, can effectively predict the compressive strength of concrete, provide important reference for engineering design and construction, and is expected to improve engineering quality and safety. Table 7 Evaluation indicator results for IABC-MLP. Full size table Conclusion Given the high requirements for real-time and accuracy in predicting the compressive strength of concrete at construction sites, this study uses the multilayer perceptron with higher predictive fitting quality as the modeling method. Due to the significant impact of parameters on the prediction performance of MLP, the process of optimizing hyperparameters is time-consuming. In this study, the basic artificial bee colony algorithm is improved by introducing a Gaussian mutation operator and optimizing the initial solution space, and an MLP neural network model based on the improved artificial bee colony algorithm is established. Through simulating and modeling the data, the proposed IABC-MLP is validated, and the following conclusions are drawn: (1) To explore the parameter optimization problem of the MLP neural network, we used three metaheuristic algorithms, namely PSO, ABC, and IABC, and analyzed them using three evaluation indicators for the three coupled models. The results show that the fitting quality of IABC-MLP can reach above 97%. Compared to ABC-MLP and PSO-MLP, it is 1.5% and 4.2% higher, respectively, enabling a quicker completion of the prediction process and a more accurate prediction of the compressive strength of concrete. (2) Comparing the IABC-MLP algorithm with four common individual learning algorithms, namely MLP, DT, SVR, and RF, the study found that the IABC-MLP model improved the \\(R^{2}\\) value by 8.35% compared to the single MLP model. In other words, IABC achieves an adaptive adjustment and optimization of the model based on the characteristics of the data, overcomes the curse of dimensionality problem in high-dimensional data, and enhances the prediction accuracy and stability of the MLP model. (3) The newly established IABC-MLP prediction model for the compressive strength of concrete is experimentally simulated on another publicly available dataset. The fitting accuracy reaches 99.2%, demonstrating the good generalization ability of the model and its suitability for predicting the compressive strength of concrete in actual construction sites. In summary, the proposed IABC-MLP model in this study can quickly complete the prediction process, accurately predict the compressive strength of concrete, and has good generalization ability, making it suitable for predicting the compressive strength of concrete in actual construction sites. However, the prediction study in this paper mainly focuses on predicting the compressive strength of concrete under standard conditions at room temperature. It is also important to further research the practical application of predicting the compressive strength of concrete under different temperatures, water contents, and other conditions. Data availability Some or all data, models, or code that support the findings of this study are available from the corresponding author upon reasonable request. References Wang, R., Wu, S. C., Geng, X. J., Sun, J. L. & Zhang, X. Q. Strength prediction of steel fiber shotcrete based on machine learning. J. Kunming Univ. Sci. Technol. Nat. Sci. https://doi.org/10.16112/j.cnki.53-1223/n.2023.06.482 (2023). Article   MATH   Google Scholar   Long, W.J., Luo, S.Y., Cheng, B.Y., Feng, G.L., Li, L.X. Research progress of the use of machine learning algorithm in performance design of self-compacting concrete . Mater. Rep. 1\u201317. http://kns.cnki.net/kcms/detail/50.1078.TB.20230509.1319.006.html (2023). Liu, X. et al. Development on machine learning for durability prediction of concrete materials. J. Chin. Ceramic Soc. 08, 1\u201312. https://doi.org/10.14062/j.issn.0454-5648.20220973 (2023). Article   CAS   MATH   Google Scholar   Luo, G. B., Hong, C. Y., Cheng, Z. L. & Sun, L. Study on prediction of concrete compressive strength based on BP and GA-BP neural network. Concrete 03, 37\u201341. https://doi.org/10.3969/j.issn.1002-3550.2023.03.007 (2023). Article   MATH   Google Scholar   Xu, X. H., Hu, Z. L., Liu, J. P., Li, W. W. & Liu, J. Z. Concrete strength prediction of the three gorges dam based on machine learning regression model. Mater. Rep. 37(02), 45\u201353. https://doi.org/10.11896/cldb.22010068 (2023). Article   MATH   Google Scholar   Zhang, J. & Liu, X. D. Prediction of concrete strength based on least square support vector machine optimized by chaotic particle swarm optimization. J. Jilin Univ. (Eng. Technol. Edn.) 46(04), 1097\u20131102. https://doi.org/10.13229/j.cnki.jdxbgxb201604013 (2016). Article   MATH   Google Scholar   Fan, X. Q., Liu, J. D., Shi, C. Y. & Fe, F. Innovative idea on fracture analysis of FRP reinforced concrete using artificial neural network. J. Disast. Prev. Mitig. Eng. 43(03), 626\u2013636. https://doi.org/10.13409/j.cnki.jdpme.20210429003 (2023). Article   MATH   Google Scholar   Long, X., Mao, M. H., Lu, C. H., Su, T. X. & Jia, F. R. Prediction of dynamic compressive performance of concrete-Like materials subjected to SHPB based on artificial neural network. J. Nanjing Univ. Aeronaut. Astronaut. 53(05), 789\u2013800. https://doi.org/10.16356/j.1005-2615.2021.05.017 (2021). Article   CAS   Google Scholar   Huang, W., Zhou, L., Ge, P. & Yang, T. A comparative study on compressive strength model of recycled brick aggregate concrete based on PSO-BP and GA-BP neural networks. Mater. Rep. 35(15), 15026\u201315030. https://doi.org/10.11896/cldb.20070041 (2021). Article   MATH   Google Scholar   Jin, L., Zhao, R. & Du, X. L. Neural network prediction model of concrete compressive strength size effect. J. Beijing Univ. Technol. 47(03), 260\u2013268. https://doi.org/10.11936/bjutxb2020010020 (2021). Article   MATH   Google Scholar   Yu, H., Zheng, J. & Lin, Q. Strength prediction of seawater sea sand concrete based on artificial neural network in python. Mater. Res. Express. 9(03), 035201. https://doi.org/10.1088/2053-1591/ac5957 (2023). Article   ADS   CAS   MATH   Google Scholar   Asteris, P. G. & Mokos, V. G. Concrete compressive strength using artificial neural networks. Neural Comput. Appl. 32(15), 11807\u201311826. https://doi.org/10.1007/s00521-019-04663-2 (2020). Article   Google Scholar   Nguyen, H. et al. Efficient machine learning models for prediction of concrete strengths. Constr. Build. Mater. 266, 120950. https://doi.org/10.1016/j.conbuildmat.2020.120950 (2021). Article   MATH   Google Scholar   Imran, M., Raza, A. & Touqeer, M. Prediction of compressive strength of high-performance concrete (HPC) using machine learning algorithms. Multiscale Multidiscip. Model. Exp. Des. https://doi.org/10.1007/s41939-023-00310-5 (2023). Article   MATH   Google Scholar   Wang, S.R., Hu, P., Chen, S.B., Xiao, Y. Prediction of concrete compressive strength based on coupled beetle search algorithm. J. Build. Mater. 1\u201315. http://kns.cnki.net/kcms/detail/31.1764.TU.20230308.1421.004.html (2023). Kova\u010devi\u0107, M., Lozan\u010di\u0107, S., Nyarko, E. K. & Hadzima-Nyarko, M. Modeling of compressive strength of self-compacting rubberized concrete using machine learning. Materials 14(15), 4346. https://doi.org/10.3390/ma14154346 (2021). Article   ADS   PubMed   PubMed Central   CAS   MATH   Google Scholar   Moodi, Y., Ghasemi, M. & Mousavi, S. R. Estimating the compressive strength of rectangular fiber reinforced polymer\u2013confined columns using multilayer perceptron, radial basis function, and support vector regression methods. J. Reinf. Plast. Compos. 41(3\u20134), 130\u2013146. https://doi.org/10.1177/07316844211050168 (2022). Article   CAS   MATH   Google Scholar   Ghunimat, D., Alzoubi, A. E., Alzboon, A. & Hanandeh, S. Prediction of concrete compressive strength with GGBFS and fly ash using multilayer perceptron algorithm, random forest regression and k-nearest neighbor regression. Asian J. Civ. Eng. 24(1), 169\u2013177. https://doi.org/10.1007/s42107-022-00495-z (2023). Article   Google Scholar   Karaboga, D. & Basturk, B. A powerful and efficient algorithm for numerical function optimization: Artificial bee colony (ABC) algorithm. J. Glob. Optim. 39, 459\u2013471. https://doi.org/10.1007/s10898-007-9149-x (2007). Article   MathSciNet   MATH   Google Scholar   Karaboga, D. & Akay, B. A comparative study of artificial bee colony algorithm. Appl. Math. Computat. 214(1), 108\u2013132. https://doi.org/10.1016/j.amc.2009.03.090 (2009). Article   MathSciNet   MATH   Google Scholar   Karaboga, D. et al. A comprehensive survey: Artificial bee colony (ABC) algorithm and applications. Artif. Intell. Rev. 42, 21\u201357. https://doi.org/10.1007/s10462-012-9328-0 (2014). Article   MATH   Google Scholar   Zhou, H., Chen, B. & Meng, M. L. Optimization of concrete mix proportion based on SVM-ABC model. Water Resour. Power 39(06), 127\u2013130 (2021). MATH   Google Scholar   Imran, M., Khushnood, R. A. & Fawad, M. A hybrid data-driven and metaheuristic optimization approach for the compressive strength prediction of high-performance concrete. Case Stud. Constr. Mater. 18, e01890. https://doi.org/10.1016/j.cscm.2023.e01890 (2023). Article   MATH   Google Scholar   Shao, G. C., Zhang, K., Wang, Z. Y., Wang, X. J. & Lu, J. Groundwater depth prediction model based on IABC-RBF neural network. J. Zhejiang Univ. Eng. Sci. 53(07), 1323\u20131330. https://doi.org/10.3785/j.issn.1008-973X.2019.07.011 (2019). Article   MATH   Google Scholar   Leng, X., Zhang, S. Q. & Lei, Z. Y. Application of improved artificial bee colony algorithm in neural network. Comput. Eng. Appl. 52(11), 7\u201310. https://doi.org/10.3778/j.issn.1002-8331.1407-0164 (2016). Article   MATH   Google Scholar   Yao, G. et al. Clustering of typical wind power scenarios based on K-means clustering algorithm and improved artificial bee colony algorithm. IEEE Access 10, 98752\u201398760. https://doi.org/10.1109/access.2022.3203695 (2022). Article   Google Scholar   Zhu, G. & Kwong, S. Gbest-guided artificial bee colony algorithm for numerical function optimization. Appl. Math. Computat. 217(7), 3166\u20133173. https://doi.org/10.1016/j.amc.2010.08.049 (2010). Article   MathSciNet   MATH   Google Scholar   Gao, W. et al. Enhanced artificial bee colony algorithm through differential evolution. Appl. Soft Comput. 48, 137\u2013150. https://doi.org/10.1016/j.asoc.2015.10.070 (2016). Article   MATH   Google Scholar   Xie, S. F. et al. Atmospheric weighted mean temperature model based on MLP neural network. J. Geodesy Geodyn. 42(11), 1105\u20131110. https://doi.org/10.14075/j.jgg.2022.11.002 (2022). Article   MATH   Google Scholar   Wei, G., He, Q. H. & OuYang, J. Z. On the function approximation ability of multi-layer perceptron. Inf. Control 06, 2\u20135 (1996). MATH   Google Scholar   Zhang, B. W. & Geng, X. L. Prediction of concrete compressive strength based on tuna swarm algorithm optimization extreme learning machine. Appl. Res. Comput. 41(02), 444\u2013449. https://doi.org/10.19734/j.issn.1001-3695.2023.05.0237 (2024). Article   MATH   Google Scholar   Xue, G. B. et al. Compressive strength prediction of concrete based on the cost-sensitive coefficients. J. Xi\u2019an Univ. Technol. 38(04), 588\u2013593. https://doi.org/10.19322/j.cnki.issn.1006-4710.2022.04.015 (2022). Article   MATH   Google Scholar   Al-Shamiri, A. K. et al. Modeling the compressive strength of high-strength concrete: An extreme learning approach. Constr. Build. Mater. 208, 204\u2013219. https://doi.org/10.1016/j.conbuildmat.2019.02.165 (2019). Article   MATH   Google Scholar   Download references Acknowledgements The authors would like to acknowledge the financial support by National Natural Science Foundation of China (Nos.11802001 and 12102002). Author information Authors and Affiliations School of Mechanical Engineering, Anhui University of Technology, Ma\u2019anshan, 243032, China Ping Li, Yanru Zhang, Jiming Gu & Shiwei Duan Contributions Y.Z.: methodology; S.D.: investigation; P.L.: writing\u2014original draft; J.G.: writing\u2014review & editing. All authors have read and agreed to the published version of the manuscript. Corresponding author Correspondence to Yanru Zhang. Ethics declarations Competing interests The authors declare no competing interests. Additional information Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Supplementary Information Supplementary Information. Rights and permissions Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. Reprints and permissions About this article Cite this article Li, P., Zhang, Y., Gu, J. et al. Prediction of compressive strength of concrete based on improved artificial bee colony-multilayer perceptron algorithm. Sci Rep 14, 6414 (2024). https://doi.org/10.1038/s41598-024-57131-w Download citation Received 07 January 2024 Accepted 14 March 2024 Published 17 March 2024 DOI https://doi.org/10.1038/s41598-024-57131-w Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Keywords Concrete Compressive strength prediction Improved artificial bee colony algorithm Multilayer perceptron Subjects Civil engineering Engineering Comments By submitting a comment you agree to abide by our Terms and Community Guidelines. If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate. Download PDF Sections Figures References Abstract Introduction Model and optimization algorithm Strength prediction model based on IABC-MLP Case study analysis Model comparison Model performance verification Conclusion Data availability References Acknowledgements Author information Ethics declarations Additional information Supplementary Information Rights and permissions About this article Comments Advertisement Scientific Reports (Sci Rep) ISSN 2045-2322 (online) About Nature Portfolio About us Press releases Press office Contact us Discover content Journals A-Z Articles by subject Protocol Exchange Nature Index Publishing policies Nature portfolio policies Open access Author & Researcher services Reprints & permissions Research data Language editing Scientific editing Nature Masterclasses Research Solutions Libraries & institutions Librarian service & tools Librarian portal Open research Recommend to library Advertising & partnerships Advertising Partnerships & Services Media kits Branded content Professional development Nature Careers Nature Conferences Regional websites Nature Africa Nature China Nature India Nature Italy Nature Japan Nature Korea Nature Middle East Privacy Policy Use of cookies Your privacy choices/Manage cookies Legal notice Accessibility statement Terms & Conditions Your US state privacy rights \u00a9 2024 Springer Nature Limited",
    "analysis": "",
    "verbatim_quote1": "",
    "verbatim_quote2": "",
    "verbatim_quote3": "",
    "relevance_score1": 0,
    "relevance_score2": 0,
    "limitations": "",
    "inline_citation": "",
    "full_citation": ""
  }
]